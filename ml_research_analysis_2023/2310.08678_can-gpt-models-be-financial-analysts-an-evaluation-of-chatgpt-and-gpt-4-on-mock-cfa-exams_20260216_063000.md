---
ver: rpa2
title: Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4 on
  mock CFA Exams
arxiv_id: '2310.08678'
source_url: https://arxiv.org/abs/2310.08678
tags:
- level
- chatgpt
- gpt-4
- financial
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comprehensive evaluation of ChatGPT and GPT-4
  on mock CFA exam questions to assess their financial reasoning capabilities. The
  authors tested the models in Zero-Shot, Chain-of-Thought, and Few-Shot settings
  using Level I and II CFA mock exams.
---

# Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4 on mock CFA Exams

## Quick Facts
- **arXiv ID:** 2310.08678
- **Source URL:** https://arxiv.org/abs/2310.08678
- **Reference count:** 7
- **Key outcome:** GPT-4 would have a decent chance of passing CFA Level I and Level II exams with appropriate prompting, while ChatGPT would likely not pass under any tested setting.

## Executive Summary
This paper evaluates ChatGPT and GPT-4 on mock CFA Level I and Level II exams to assess their financial reasoning capabilities. The study tests the models using Zero-Shot, Chain-of-Thought, and Few-Shot prompting methods across multiple exam sections. GPT-4 consistently outperforms ChatGPT, with Few-Shot prompting providing the best results, especially for ChatGPT. While GPT-4 shows strong performance in Level I, it is borderline for passing Level II. The study finds that Chain-of-Thought prompting can amplify errors and that GPT-4's most common errors are calculation-focused rather than knowledge-based.

## Method Summary
The authors evaluated ChatGPT and GPT-4 on CFA mock exams using OpenAI's ChatCompletion API with temperature=0. They tested three prompting methods: Zero-Shot (no examples), Chain-of-Thought (step-by-step reasoning), and Few-Shot (providing 2-10 examples). For Level I, they used five mock exams covering topics like Ethics, Derivatives, and Fixed Income. For Level II, they used two mock exams with case descriptions and tables. Accuracy was measured as percentage of correct answers, with passing thresholds of 60% per topic and 70% overall for Level I, and 50% per topic and 60% overall for Level II.

## Key Results
- GPT-4 outperformed ChatGPT in almost all finance topics across all prompting methods
- Few-Shot prompting yielded the best performance improvement, particularly for ChatGPT
- GPT-4 showed strong performance in Level I but was borderline for passing Level II
- Chain-of-Thought prompting showed limited improvement and sometimes amplified errors

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** GPT-4 outperforms ChatGPT in almost all finance topics when using the same prompting method.
- **Mechanism:** GPT-4 has more complete internal knowledge of both financial information and especially financial formulas and calculation methods compared to ChatGPT, as evidenced by the error mode analysis showing GPT-4's errors are more calculation-focused while ChatGPT makes more knowledge errors.
- **Core assumption:** The pretraining and instruction-tuning of GPT-4 included more diverse and comprehensive financial domain knowledge than ChatGPT.
- **Evidence anchors:** [section] "Rather than knowledge errors, GPT-4's most common error mode on questions requiring calculation are calculation errors. ChatGPT also frequently made these sorts of errors in conjunction with using the wrong formula, which underlines the well-known and more foundational shortcoming of language models' mathematical abilities."
- **Break condition:** If the underlying pretraining data distribution was similar for both models, or if GPT-4's knowledge cutoff date meant missing recent financial concepts, this performance gap could diminish.

### Mechanism 2
- **Claim:** Few-Shot prompting yields better performance improvement than Chain-of-Thought prompting.
- **Mechanism:** Few-Shot prompting provides actual correct answers to different types of mock questions, enabling the models to understand how to best use the table evidence or other information contained in a question. This is more effective than CoT which can amplify missing knowledge and calculation errors.
- **Core assumption:** Providing concrete examples of expected behavior is more valuable than asking the model to reason through problems step-by-step when the model has gaps in domain-specific knowledge.
- **Evidence anchors:** [section] "Compared to ZS and CoT prompting, FS prompting offers significant performance improvements for ChatGPT on the Level I mock exams... FS yields better performance improvement than CoT because it shows actual correct answers to different types of mock questions."
- **Break condition:** If the model has sufficient domain knowledge, CoT might become more effective, or if the examples in Few-Shot prompting are not representative of the actual questions, performance could degrade.

### Mechanism 3
- **Claim:** Chain-of-Thought prompting amplifies the effect of missing knowledge and allows room for calculation errors.
- **Mechanism:** When using CoT, the model states its incorrect assumptions early in the reasoning process, which it then rationalizes in the context of the question, skewing the rest of the answer towards a wrong choice. This is particularly problematic for knowledge-intensive domains like finance.
- **Core assumption:** The sequential nature of CoT means that an early error propagates through the entire reasoning chain, magnifying its impact on the final answer.
- **Evidence anchors:** [section] "This implies that, with CoT reasoning, the gaps in the LLMs internal knowledge are magnified. As the model begins to think through its answer, it states its incorrect assumptions, which it proceeds to rationalize in the context of the question thereby skewing the rest of the answer towards a wrong choice."
- **Break condition:** If the model has sufficient domain knowledge or if the questions are simple enough that errors don't compound, this amplification effect might not occur.

## Foundational Learning

- **Concept:** Financial domain knowledge and terminology
  - Why needed here: The CFA exam tests specific financial concepts like derivatives, fixed income, portfolio management, etc. Without understanding these concepts, the model cannot correctly answer questions even with good reasoning.
  - Quick check question: What is the difference between a call option and a put option in derivatives trading?

- **Concept:** Mathematical reasoning and formula application
  - Why needed here: Many CFA questions require calculations using specific financial formulas. The model needs to correctly apply these formulas and perform accurate calculations.
  - Quick check question: How do you calculate the present value of a future cash flow?

- **Concept:** Table and evidence interpretation
  - Why needed here: Level II questions include case descriptions with tables and evidence that must be interpreted to answer questions. The model needs to extract relevant information from complex formatted data.
  - Quick check question: Given a balance sheet, how would you calculate the current ratio?

## Architecture Onboarding

- **Component map:** Question input -> Prompt template selection -> API call to LLM (gpt-3.5-turbo or gpt-4) -> Response parsing -> Answer comparison with ground truth -> Accuracy calculation
- **Critical path:** Question input → Prompt template selection → API call to LLM → Response parsing → Answer comparison with ground truth → Accuracy calculation
- **Design tradeoffs:** Zero-Shot requires no examples but performs worst; Chain-of-Thought can expose reasoning errors but provides limited improvement; Few-Shot provides best performance but requires finding good examples within context limits.
- **Failure signatures:** Knowledge errors indicate missing domain information; calculation errors suggest mathematical limitations; reasoning errors show the model talking itself into incorrect conclusions; inconsistency errors reveal disconnect between reasoning and answer selection.
- **First 3 experiments:**
  1. Test all three prompting methods (ZS, CoT, FS) on a small sample of Level I questions to establish baseline performance differences
  2. Analyze error modes for each prompting method on a subset of questions to understand failure patterns
  3. Compare performance on calculation-heavy versus conceptual questions to identify domain-specific strengths and weaknesses

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would retrieval-augmented generation using an external knowledge base containing CFA-specific information significantly improve GPT-4's performance on CFA Level II exams?
- Basis in paper: [inferred] The paper mentions retrieval-augmented generation as a potential improvement for LLMs in finance, and notes that GPT-4 struggles more with Level II than Level I due to more specialized and intricate problems.
- Why unresolved: The paper only tested GPT-4's out-of-the-box capabilities without any external knowledge integration. The effectiveness of retrieval-augmented generation for CFA-specific knowledge remains unexplored.
- What evidence would resolve it: Testing GPT-4 on Level II CFA exams with retrieval-augmented generation using a CFA-specific knowledge base and comparing results to the baseline performance.

### Open Question 2
- Question: How would combining Few-Shot prompting with Chain-of-Thought reasoning impact GPT-4's accuracy on Level II CFA exams compared to using either method alone?
- Basis in paper: [explicit] The paper suggests that Level II may benefit from a combination of Few-Shot and Chain-of-Thought prompting with clear explanations.
- Why unresolved: The paper tested Few-Shot and Chain-of-Thought prompting separately but did not experiment with combining these approaches, leaving the potential synergy unexplored.
- What evidence would resolve it: Conducting experiments where GPT-4 is tested on Level II CFA exams using combined Few-Shot and Chain-of-Thought prompting, then comparing accuracy to results from individual prompting methods.

### Open Question 3
- Question: What specific improvements in GPT-4's performance on CFA exams could be achieved through fine-tuning on domain-specific financial datasets versus instruction-tuning?
- Basis in paper: [inferred] The paper discusses various methods to incorporate domain-specific knowledge in LLMs, including continued pre-training and supervised fine-tuning, but only tested out-of-the-box capabilities.
- Why unresolved: The paper did not explore fine-tuning approaches, leaving the relative effectiveness of continued pre-training versus supervised fine-tuning on financial datasets unknown.
- What evidence would resolve it: Comparing GPT-4's performance on CFA exams after fine-tuning with continued pre-training on financial data versus instruction-tuning on CFA-specific question-answer pairs, then measuring the improvement over baseline accuracy.

## Limitations

- **Proprietary exam content:** The study uses CFA mock exams that are not publicly available, making exact replication difficult and limiting external validation.
- **Practical vs. theoretical knowledge:** The analysis focuses on multiple-choice question performance without assessing whether the models can actually perform the practical analytical tasks that CFA charterholders execute in real-world settings.
- **Knowledge cutoff limitations:** The study doesn't account for potential domain shift in financial markets between the exam content and current market conditions, particularly given GPT-4's knowledge cutoff around mid-2021.

## Confidence

- **High confidence:** GPT-4 outperforms ChatGPT across all tested financial topics and prompting methods. This finding is supported by consistent performance gaps across multiple exam sections and question types.
- **Medium confidence:** Few-Shot prompting provides the best performance improvement, particularly for ChatGPT. While the results show clear patterns, the optimal number of examples and selection strategy could vary based on question complexity and topic specificity.
- **Medium confidence:** Chain-of-Thought prompting shows limited improvement and can amplify errors. The mechanism described is plausible, but the extent of error amplification may depend on question difficulty and the model's baseline knowledge in specific topics.

## Next Checks

1. **Cross-validation with open-source financial datasets:** Test the prompting strategies on publicly available financial reasoning datasets (e.g., FinQA, MathQA-Finance) to verify that the performance patterns hold beyond CFA-specific content.

2. **Error analysis reproducibility:** Independently replicate the error mode classification (knowledge errors vs. calculation errors) on a subset of questions to verify the proposed distinction between GPT-4's calculation-focused errors and ChatGPT's knowledge errors.

3. **Temporal generalization test:** Evaluate model performance on financial questions from different years (pre- and post-2021) to assess whether the knowledge cutoff impacts CFA exam performance, particularly for Level II's case-based questions that may reference more recent market conditions.