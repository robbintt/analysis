---
ver: rpa2
title: 'Taiwan LLM: Bridging the Linguistic Divide with a Culturally Aligned Language
  Model'
arxiv_id: '2311.17487'
source_url: https://arxiv.org/abs/2311.17487
tags:
- taiwan
- language
- chinese
- feedback
- traditional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Taiwan LLM, the first large language model
  specifically designed for Traditional Chinese as used in Taiwan. The authors address
  the lack of high-quality language models for Traditional Chinese by continuing pretraining
  Llama2 on a large-scale Taiwanese corpus, followed by supervised fine-tuning on
  dialogue datasets and user feedback.
---

# Taiwan LLM: Bridging the Linguistic Divide with a Culturally Aligned Language Model

## Quick Facts
- arXiv ID: 2311.17487
- Source URL: https://arxiv.org/abs/2311.17487
- Reference count: 30
- First large language model specifically designed for Traditional Chinese as used in Taiwan

## Executive Summary
This paper introduces Taiwan LLM, the first large language model specifically designed for Traditional Chinese as used in Taiwan. The authors address the lack of high-quality language models for Traditional Chinese by continuing pretraining Llama2 on a large-scale Taiwanese corpus, followed by supervised fine-tuning on dialogue datasets and user feedback. Taiwan LLM achieves competitive performance compared to proprietary models like GPT-3.5 turbo, with an average score of 53.99% on the TC-Eval benchmark. The model excels at understanding and generating Traditional Chinese text, outperforming existing models trained on Simplified Chinese or English.

## Method Summary
Taiwan LLM employs a three-phase methodology: Continue-Pretraining (cPT) on a large-scale Taiwanese corpus (35.1 billion tokens) to adapt the base Llama2 model to Traditional Chinese, Supervised Fine-Tuning (SFT) on diverse dialogue datasets to enhance conversational capabilities, and Feedback Supervised Fine-Tuning using real user feedback to align responses with user preferences. The approach combines a comprehensive corpus from social media, news, knowledge bases, and books with instruction datasets and direct user interaction.

## Key Results
- Achieves average score of 53.99% on TC-Eval benchmark, outperforming existing Traditional Chinese models
- Excels at understanding and generating Traditional Chinese text compared to models trained on Simplified Chinese or English
- Demonstrates competitive performance with proprietary models like GPT-3.5 Turbo on Traditional Chinese tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continuing pretraining on a large-scale Taiwanese corpus bridges the linguistic gap between the base Llama2 model and Traditional Chinese as used in Taiwan.
- Mechanism: The base Llama2 model, pretrained on English and Simplified Chinese, lacks exposure to Traditional Chinese vocabulary, grammar, and usage patterns. By continuing pretraining on a large-scale Taiwanese corpus (35.1 billion tokens), the model gains familiarity with Traditional Chinese text and adapts its representations to better capture the linguistic nuances of the language.
- Core assumption: The large-scale Taiwanese corpus is representative of the diverse range of Traditional Chinese text used in Taiwan, including various genres and domains.
- Evidence anchors:
  - [abstract]: "Leveraging a comprehensive pretraining corpus and instruction-finetuning datasets, we have developed a model that not only understands the complexities of Traditional Chinese but also embodies the cultural context of Taiwan."
  - [section 4.1]: "Our continue-pretraining corpus is a comprehensive collection of documents from various sources, meticulously curated to represent the Taiwanese context."
  - [corpus]: The corpus includes 20 million documents from various sources, including social media, news, knowledge base, and books, covering a wide range of text genres.
- Break condition: If the Taiwanese corpus is not representative of the diverse range of Traditional Chinese text used in Taiwan, or if the corpus contains significant noise or irrelevant content, the model's performance may not improve as expected.

### Mechanism 2
- Claim: Fine-tuning on dialogue datasets enhances the model's ability to engage in coherent and culturally appropriate conversations in Traditional Chinese.
- Mechanism: By fine-tuning the continue-pretrained model on a diverse set of multi-turn dialogues, the model learns to understand the nuances of conversation, generate contextually relevant responses, and incorporate cultural references specific to Taiwan. The dialogue datasets include prompts and responses from various sources, such as NLP datasets, human-written instructions, and author-written conversations.
- Core assumption: The dialogue datasets are diverse and representative of the types of conversations and cultural references encountered by Traditional Chinese speakers in Taiwan.
- Evidence anchors:
  - [abstract]: "Our evaluations demonstrate that Taiwan LLM achieves superior performance in understanding and generating Traditional Chinese text, outperforming existing models that are predominantly trained on Simplified Chinese or English."
  - [section 4.1]: "For SFT, we compile a diverse set of instruction datasets... We translate prompts from various instruction datasets using gpt-3.5-turbo and then generate responses to these prompts with the same model."
  - [corpus]: The SFT datasets include a wide range of prompts and responses, covering various topics and domains, such as NLP tasks, code generation, and culturally relevant conversations.
- Break condition: If the dialogue datasets do not cover a diverse range of conversation types or cultural references, or if the quality of the datasets is low, the model's ability to engage in coherent and culturally appropriate conversations may be limited.

### Mechanism 3
- Claim: Incorporating user feedback through feedback fine-tuning aligns the model's responses with user preferences and expectations in the Taiwanese context.
- Mechanism: By collecting feedback from real users on the model's responses and incorporating this feedback into the fine-tuning process, the model learns to generate responses that better match user preferences and expectations. The feedback is used to adjust the model's parameters, with a focus on instances where the user's rating is positive.
- Core assumption: The user feedback is representative of the preferences and expectations of Traditional Chinese speakers in Taiwan.
- Evidence anchors:
  - [abstract]: "Our evaluations demonstrate that Taiwan LLM achieves superior performance in understanding and generating Traditional Chinese text, outperforming existing models that are predominantly trained on Simplified Chinese or English."
  - [section 3]: "In the final stage, we refine the model based on positive feedback from real users. We collect this feedback through a user interface that allows users to interact with the model and provide binary ratings (positive or negative) on its responses."
  - [corpus]: The feedback SFT dataset consists of 20,000 user feedback instances collected from a dedicated platform (https://twllm.com).
- Break condition: If the user feedback is not representative of the preferences and expectations of Traditional Chinese speakers in Taiwan, or if the feedback is biased or low-quality, the model's performance may not improve as expected.

## Foundational Learning

- Concept: Continue pretraining on a large-scale corpus
  - Why needed here: To adapt the base Llama2 model to the linguistic characteristics of Traditional Chinese and bridge the gap between the model's pretraining and the target language.
  - Quick check question: What is the size and composition of the continue-pretraining corpus used for Taiwan LLM?

- Concept: Supervised fine-tuning on dialogue datasets
  - Why needed here: To enhance the model's ability to engage in coherent and culturally appropriate conversations in Traditional Chinese, by learning from a diverse set of multi-turn dialogues.
  - Quick check question: What types of dialogue datasets are used for fine-tuning Taiwan LLM, and how do they cover various conversation topics and cultural references?

- Concept: Incorporating user feedback for alignment
  - Why needed here: To align the model's responses with user preferences and expectations in the Taiwanese context, by collecting feedback from real users and incorporating it into the fine-tuning process.
  - Quick check question: How is user feedback collected and used to refine the model's responses in Taiwan LLM?

## Architecture Onboarding

- Component map: Continue-Pretraining -> Supervised Fine-Tuning -> Feedback Fine-Tuning
- Critical path: 1) Curate large-scale Taiwanese corpus, 2) Continue-pretrain base Llama2 model, 3) Compile diverse dialogue datasets, 4) Fine-tune on dialogue datasets, 5) Collect user feedback, 6) Incorporate feedback into fine-tuning
- Design tradeoffs: Base model choice (Llama2), corpus size and composition, dataset diversity, amount of user feedback collected - all impact performance vs. resource requirements
- Failure signatures: Poor corpus representation leads to linguistic issues; limited dialogue dataset diversity causes conversational limitations; unrepresentative user feedback results in misalignment with user expectations
- First 3 experiments:
  1. Evaluate the model's performance on a held-out test set of Traditional Chinese text to assess the impact of continue-pretraining.
  2. Conduct a human evaluation of the model's responses to a diverse set of dialogue prompts to assess the quality of the supervised fine-tuning.
  3. Collect user feedback on the model's responses in a real-world setting and analyze the feedback to identify areas for improvement.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several important questions emerge from the work:

1. How does the quality of the continue-pretraining corpus affect the performance of Taiwan LLM compared to the quantity of data used?
2. What are the long-term effects of user feedback on the performance of Taiwan LLM, and how can it be systematically incorporated to improve the model?
3. How can Taiwan LLM be adapted to handle other regional dialects or variants of Chinese, and what challenges might arise in this process?

## Limitations

- Lack of detailed information about quality assurance process for filtering spam and toxic content in the continue-pretraining corpus
- Unknown exact composition and volume of the feedback SFT dataset beyond the number of instances
- TC-Eval benchmark not independently validated; comparison with GPT-3.5 Turbo based on single benchmark suite

## Confidence

**High Confidence Claims:**
- Three-phase training methodology is technically sound and follows established practices
- Corpus composition and diversity are well-documented and verifiable
- Model achieves competitive performance on TC-Eval benchmark compared to GPT-3.5 Turbo

**Medium Confidence Claims:**
- Model "excels at understanding and generating Traditional Chinese text" supported by benchmark results but lacks extensive qualitative validation
- Model "embodies the cultural context of Taiwan" demonstrated through corpus selection but not thoroughly validated through user studies

**Low Confidence Claims:**
- Claim about bridging the "linguistic divide" is more aspirational than empirically demonstrated

## Next Checks

1. Conduct an independent evaluation of Taiwan LLM on the TC-Eval benchmark using a different evaluation framework to verify reported performance metrics
2. Design and implement a user preference study with native Traditional Chinese speakers in Taiwan to validate cultural alignment claims
3. Perform detailed analysis of continue-pretraining corpus quality, specifically examining spam and toxic content filtering effectiveness