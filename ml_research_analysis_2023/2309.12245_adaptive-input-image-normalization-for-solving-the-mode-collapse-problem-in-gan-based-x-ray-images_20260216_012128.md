---
ver: rpa2
title: Adaptive Input-image Normalization for Solving the Mode Collapse Problem in
  GAN-based X-ray Images
arxiv_id: '2309.12245'
source_url: https://arxiv.org/abs/2309.12245
tags:
- images
- x-ray
- image
- synthetic
- mode
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study tackles the mode collapse problem in Generative Adversarial
  Networks (GANs) for generating diverse chest X-ray images, which is crucial for
  augmenting imbalanced biomedical datasets. It proposes an adaptive input-image normalization
  (AIIN) technique that enhances feature visibility in X-ray images using contrast-based
  histogram equalization.
---

# Adaptive Input-image Normalization for Solving the Mode Collapse Problem in GAN-based X-ray Images

## Quick Facts
- arXiv ID: 2309.12245
- Source URL: https://arxiv.org/abs/2309.12245
- Reference count: 40
- Primary result: AIIN integration with DCGAN/ACGAN alleviates mode collapse and improves COVID-19/pneumonia detection via synthetic data augmentation

## Executive Summary
This study addresses the mode collapse problem in Generative Adversarial Networks (GANs) for generating diverse chest X-ray images, which is critical for augmenting imbalanced biomedical datasets. The authors propose an adaptive input-image normalization (AIIN) technique that enhances feature visibility in X-ray images using contrast-based histogram equalization. By integrating AIIN with Deep Convolutional GAN (DCGAN) and Auxiliary Classifier GAN (ACGAN), the approach significantly reduces both intra-class and inter-class mode collapse, as evidenced by improved MS-SSIM, IS, and FID scores. The synthetically generated images are used to augment imbalanced datasets, and a Vision Transformer model trained on these augmented datasets achieves superior classification accuracy, precision, and recall compared to un-normalized data.

## Method Summary
The method involves preprocessing chest X-ray images using AIIN, which applies contrast-based histogram equalization on non-overlapping windows to enhance feature visibility. The preprocessed images are then used to train DCGAN and ACGAN models for 500 epochs. The synthetic images generated by these models are evaluated for mode collapse using MS-SSIM, IS, and FID metrics. The best-performing synthetic images are used to augment imbalanced datasets, and a pre-trained Vision Transformer model is trained on the augmented data to evaluate classification performance for COVID-19 and pneumonia detection.

## Key Results
- AIIN integration with DCGAN significantly reduces intra-class mode collapse, improving MS-SSIM and FID scores.
- AIIN integration with ACGAN alleviates inter-class mode collapse, resulting in higher IS scores and better diversity.
- Vision Transformer models trained on AIIN-augmented datasets achieve superior classification accuracy, precision, and recall compared to models trained on un-normalized data.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AIIN improves feature visibility in X-ray images, enabling GANs to generate more diverse synthetic images.
- Mechanism: AIIN applies contrast-based histogram equalization on non-overlapping windows of the input image, enhancing morphological features and highlighting diverse disease-related structures.
- Core assumption: Enhancing local contrast without amplifying noise will make GANs better able to capture and reproduce diverse features from real images.
- Evidence anchors:
  - [abstract] "adaptive input-image normalization (AIIN) technique that enhances feature visibility in X-ray images using contrast-based histogram equalization."
  - [section] "AIIN is a preprocessing technique that enables GANs to generate highly diversified synthetic X-ray images."
  - [corpus] No direct corpus evidence found for AIIN-specific claims; claims are supported by internal experimental results only.
- Break condition: If histogram equalization amplifies noise or oversmooths critical features, the GAN may converge to less diverse modes.

### Mechanism 2
- Claim: AIIN alleviates intra-class mode collapse in DCGAN by improving the generator's ability to capture diverse features within a single class.
- Mechanism: By normalizing images before training, AIIN provides richer feature gradients to the generator, reducing the tendency to produce near-identical samples from different latent inputs.
- Core assumption: Intra-class mode collapse arises from insufficient feature diversity in training data; normalization enriches the feature space.
- Evidence anchors:
  - [abstract] "alleviating the intra-class mode collapse in DCGAN and inter-class mode collapse in ACGAN for X-ray image synthesis."
  - [section] "The intra-class mode collapse in the DCGAN is identified by the higher MS-SSIM score of un-normalized synthetic generated X-ray images than real images."
  - [corpus] No corpus evidence for this specific mechanism; supported only by internal metrics.
- Break condition: If normalization leads to homogenization of intra-class variance, the GAN may collapse to a single representative sample.

### Mechanism 3
- Claim: AIIN alleviates inter-class mode collapse in ACGAN by preserving discriminative features between classes during normalization.
- Mechanism: Normalizing images while maintaining class-specific feature contrast allows the discriminator to better distinguish between classes, providing clearer gradients to the generator.
- Core assumption: Inter-class mode collapse occurs when class features become indistinguishable; preserving class boundaries during preprocessing prevents this.
- Evidence anchors:
  - [abstract] "This work extends that approach of integrating AIIN with DCGAN to alleviate intra-class mode collapse for coronavirus and Pneumonia diseases...This work also contributes to integrating AIIN with ACGAN to alleviate the inter-class mode collapse problem."
  - [section] "The inter-class mode collapse in the ACGAN is identified by a lower score IS score of synthetic images than real images."
  - [corpus] No direct corpus evidence for this mechanism; relies on experimental IS/FID scores.
- Break condition: If AIIN normalizes out critical class-discriminative features, the ACGAN may generate identical samples across classes.

## Foundational Learning

- Concept: Contrast-based histogram equalization
  - Why needed here: X-ray images often have poor contrast, obscuring disease features; equalization improves visibility for GAN training.
  - Quick check question: What is the difference between global and local histogram equalization, and why is local used here?

- Concept: Mode collapse in GANs
  - Why needed here: Mode collapse directly degrades diversity of synthetic images, undermining their utility for data augmentation.
  - Quick check question: What is the difference between intra-class and inter-class mode collapse?

- Concept: Evaluation metrics (MS-SSIM, IS, FID)
  - Why needed here: These metrics quantitatively assess the diversity and quality of synthetic images and validate the effectiveness of AIIN.
  - Quick check question: What does a higher MS-SSIM score indicate about synthetic image diversity?

## Architecture Onboarding

- Component map:
  AIIN preprocessor -> DCGAN/ACGAN generator -> discriminator -> synthetic image output

- Critical path:
  1. Apply AIIN to all training images
  2. Train GAN until convergence (monitor MS-SSIM/IS/FID)
  3. Generate synthetic images for minority classes
  4. Augment dataset and train ViT classifier
  5. Evaluate classification performance

- Design tradeoffs:
  - Window size vs. computational cost: larger windows reduce processing time but may miss fine details
  - Contrast threshold selection: higher thresholds preserve detail but risk noise amplification
  - Batch size: larger batches stabilize training but require more memory

- Failure signatures:
  - MS-SSIM close to 1.0: severe intra-class mode collapse
  - IS significantly lower than real data: inter-class mode collapse
  - High FID: poor diversity relative to real data
  - Unstable GAN training curves: normalization parameters may be too aggressive

- First 3 experiments:
  1. Compare DCGAN with/without AIIN on MS-SSIM/FID using COVID-19 images
  2. Vary window sizes (4x4, 8x8, 16x16) and contrast thresholds; record diversity metrics
  3. Train ViT on augmented datasets from best-performing AIIN-DCGAN and AIIN-ACGAN; compare classification accuracy to baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of contrast threshold and window size in AIIN affect the diversity and quality of synthetic images generated by DCGAN and ACGAN across different medical imaging modalities?
- Basis in paper: [explicit] The paper discusses the impact of window size and contrast threshold on the generation of diversified X-ray images, but does not explore other modalities.
- Why unresolved: The study focuses on chest X-ray images, and the optimal parameters for other modalities remain unexplored.
- What evidence would resolve it: Comparative studies using AIIN with DCGAN and ACGAN across various medical imaging modalities (e.g., MRI, CT) to determine the optimal parameters for each.

### Open Question 2
- Question: What is the long-term stability and performance of GANs with AIIN when used for data augmentation in real-world clinical settings?
- Basis in paper: [inferred] The paper demonstrates improved classification performance using AIIN-augmented datasets, but does not address real-world deployment or long-term stability.
- Why unresolved: Clinical environments present unique challenges, such as data drift and evolving disease patterns, which are not addressed in the study.
- What evidence would resolve it: Longitudinal studies tracking the performance of classifiers trained on AIIN-augmented datasets in dynamic clinical environments.

### Open Question 3
- Question: How does the integration of AIIN with other GAN architectures, such as Progressive Growing GAN (PGGAN) or StyleGAN, compare to its use with DCGAN and ACGAN in terms of alleviating mode collapse and generating high-quality synthetic images?
- Basis in paper: [explicit] The paper focuses on AIIN integration with DCGAN and ACGAN, leaving other architectures unexplored.
- Why unresolved: The study does not investigate the compatibility or effectiveness of AIIN with other advanced GAN architectures.
- What evidence would resolve it: Experimental comparisons of AIIN integration with multiple GAN architectures, evaluating their performance in generating diverse and high-quality synthetic images.

## Limitations
- The method relies heavily on experimental validation without external corpus support for the AIIN mechanism.
- Implementation details such as contrast threshold selection criteria and bilinear interpolation specifics remain underspecified.
- The study focuses exclusively on chest X-ray images, limiting generalizability to other medical imaging modalities.

## Confidence

- Mode collapse alleviation claims: Medium
- Classification performance improvements: Medium
- Generalizability to other imaging modalities: Low

## Next Checks

1. Conduct ablation studies varying AIIN window sizes and contrast thresholds systematically, measuring their impact on mode collapse metrics and synthetic image quality.
2. Compare AIIN against standard normalization techniques (batch normalization, instance normalization) in the same DCGAN/ACGAN frameworks to establish relative effectiveness.
3. Validate classification improvements on an independent COVID-19 chest X-ray dataset using the augmented data generated by AIIN-enhanced GANs.