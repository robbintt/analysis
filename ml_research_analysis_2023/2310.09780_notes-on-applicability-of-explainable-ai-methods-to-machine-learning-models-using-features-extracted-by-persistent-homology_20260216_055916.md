---
ver: rpa2
title: Notes on Applicability of Explainable AI Methods to Machine Learning Models
  Using Features Extracted by Persistent Homology
arxiv_id: '2310.09780'
source_url: https://arxiv.org/abs/2310.09780
tags:
- data
- feature
- each
- machine
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes methods to apply explainable AI (XAI) techniques
  to the PH-ML pipeline, which uses persistent homology (PH) to extract structural
  features from data and then applies machine learning (ML) models to these features.
  The paper focuses on the problem of estimating gas adsorption in metal-organic frameworks
  (MOFs) as a specific use case.
---

# Notes on Applicability of Explainable AI Methods to Machine Learning Models Using Features Extracted by Persistent Homology

## Quick Facts
- arXiv ID: 2310.09780
- Source URL: https://arxiv.org/abs/2310.09780
- Reference count: 10
- Primary result: Proposes Grid-based Explanation and Higher Order Term Evaluation methods to apply XAI to PH-ML pipeline for MOF gas adsorption prediction

## Executive Summary
This paper addresses the challenge of applying explainable AI (XAI) techniques to machine learning models that use features extracted by persistent homology (PH). The authors propose two methods: Grid-based Explanation for normalizing variable-length atomic coordinate data into fixed-length features, and Higher Order Term Evaluation for decomposing feature attributions into contributions from manipulatable parameters. These methods are demonstrated on the task of estimating gas adsorption in metal-organic frameworks (MOFs).

## Method Summary
The paper proposes methods to apply XAI techniques to the PH-ML pipeline, which uses PH to extract structural features from data and then applies ML models to these features. The core method ideas are: 1) Grid-based Explanation - a method to normalize variable-length atomic coordinate data into fixed-length features by dividing the space into grids and counting atoms in each grid; 2) Higher Order Term Evaluation - a method to decompose feature attributions from the PH-ML pipeline into contributions from individual manipulatable parameters by applying Cohort Shapley multiple times. These methods are demonstrated on the specific use case of estimating gas adsorption in MOFs.

## Key Results
- Grid-based Explanation can attribute contributions to individual atoms and empty spaces, providing insights into which atoms or regions are most influential for gas adsorption.
- Higher Order Term Evaluation can decompose feature attributions into contributions from individual manipulatable parameters, revealing the transitive relationships from parameters to features to ML outputs.
- These methods provide unprecedented granularity of interpretability for the PH-ML pipeline, enabling users to understand how each parameter contributes to the composition of cycles in persistent diagrams and ultimately to the ML model's predictions.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Grid-based Explanation can normalize variable-length atomic coordinate data into fixed-length features for XAI application.
- Mechanism: By dividing the supercell into fixed-size grids and counting atoms in each grid, the method transforms variable-length data into fixed-length feature vectors that can be processed by observational XAI methods like IGCS.
- Core assumption: The supercell is large enough to contain all atoms from any MOF in the dataset, ensuring consistent grid dimensions across all data points.
- Evidence anchors:
  - [abstract]: "Grid-based Explanation: A method to normalize variable-length atomic coordinate data into fixed-length features by dividing the space into grids and counting atoms in each grid."
  - [section 3.2]: "The supercell does not necessarily have to be isotropic or limited to the shape of a cube, and the number of atoms is not constant. We ignored the differences in the types of atoms and considered the process of extracting features only from the coordinates of atoms scattered within the supercell using PH."
  - [corpus]: Weak evidence - corpus papers focus on general XAI applications rather than specific normalization techniques for variable-length data.
- Break condition: If the supercell size is insufficient to contain all atoms from the largest MOF, or if atomic types need to be considered for feature extraction, the normalization would fail.

### Mechanism 2
- Claim: Higher Order Term Evaluation decomposes feature attributions into contributions from manipulatable parameters through transitive relationships.
- Mechanism: By applying Cohort Shapley multiple times - first to identify influential cycles in persistent diagrams, then to decompose these contributions into manipulatable parameters - the method reveals how each parameter contributes to specific cycles and ultimately to model predictions.
- Core assumption: The data generation process is controlled by a relatively small number of manipulatable parameters, and the PH-ML pipeline maintains deterministic feature extraction.
- Evidence anchors:
  - [abstract]: "Higher Order Term Evaluation: A method to decompose feature attributions from the PH-ML pipeline into contributions from individual manipulatable parameters (e.g., building blocks of MOFs) by applying Cohort Shapley (CS) multiple times."
  - [section 4.2]: "We first identify the contribution of cycles, represented as pixels in the landscape, to downstream ML using IGCS. We then decompose each contribution assigned to these pixels into contributions from each manipulatable parameter using CS."
  - [corpus]: No direct evidence - corpus papers do not discuss transitive relationship decomposition in PH-ML pipelines.
- Break condition: If the manipulatable parameters cannot uniquely determine the molecular structure, or if the PH-ML pipeline loses its deterministic nature, the decomposition would be invalid.

### Mechanism 3
- Claim: Observational XAI methods like IGCS provide more realistic insights by incorporating data generation constraints compared to interventional methods.
- Mechanism: By using only actual data within the dataset to compute feature attributions, observational XAI methods respect physical and chemical constraints that would be violated by interventional approaches.
- Core assumption: The dataset contains sufficient diversity to represent the constraint space of the data generation process.
- Evidence anchors:
  - [abstract]: "Cohort Shapley (CS) (Mase et al., 2019) is a representative observational XAI method. This method involves computing the conditional expectations appearing in the characteristic values of Shapley values from the average of the output values assigned to a subset of the entire dataset."
  - [section 2.2]: "Observational XAI takes into account the data generation process to obtain feature attributions. This involves generating plausible data to compare with the target data, or seeking characteristic properties of the target data using only actual data contained within the dataset."
  - [corpus]: Weak evidence - corpus papers focus on general observational vs. interventional XAI comparisons but not specifically in the PH-ML context.
- Break condition: If the dataset is too small or unrepresentative of the constraint space, observational XAI would fail to capture realistic insights.

## Foundational Learning

- Concept: Persistent Homology (PH)
  - Why needed here: PH is the core feature extraction method that transforms atomic coordinates into topological features for machine learning.
  - Quick check question: How does persistent homology represent the global structure of molecular data through cycles and their persistence?

- Concept: Shapley Values and Cooperative Game Theory
  - Why needed here: Shapley values provide the theoretical foundation for feature attribution methods used in both Grid-based Explanation and Higher Order Term Evaluation.
  - Quick check question: What axioms must a feature attribution method satisfy to be considered a valid Shapley value?

- Concept: Observational vs. Interventional XAI
  - Why needed here: The paper specifically uses observational XAI methods (IGCS, CS) that respect data generation constraints, which is crucial for meaningful interpretation in the PH-ML pipeline.
  - Quick check question: What is the fundamental difference between observational and interventional XAI methods in terms of how they handle data generation constraints?

## Architecture Onboarding

- Component map: Atomic coordinates -> Grid-based normalization -> PH feature extraction -> IGCS attribution -> CS decomposition -> Interpretability insights
- Critical path: Atomic coordinates → Grid-based normalization → PH feature extraction → IGCS attribution → CS decomposition → Interpretability insights
  - Each step must complete successfully for the final interpretability results to be valid
- Design tradeoffs: Computational cost vs. interpretability granularity
  - Grid size selection affects both computational efficiency and attribution accuracy
  - Number of perturbation samples for cohort affects statistical reliability vs. computation time
- Failure signatures: 
  - Poor R² scores indicate issues with the base PH-ML pipeline
  - Attribution heatmaps with uniform values suggest normalization or XAI parameter issues
  - Unexpected attribution patterns may indicate symmetry assumptions violations
- First 3 experiments:
  1. Verify that grid-based normalization produces consistent feature dimensions across different MOFs
  2. Test IGCS on a simple dataset with known ground truth to validate attribution quality
  3. Apply Higher Order Term Evaluation to a small synthetic dataset to verify transitive relationship calculations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the grid size be optimized for different types of materials and structures when applying the Grid-based Explanation method?
- Basis in paper: [inferred] The paper mentions using a grid size of 2 cubic angstrom for the MOF dataset, but notes that the grid size should be "sufficiently small compared with the birth and death of cycles extracted by PH" for the even distribution of contribution values to be justified.
- Why unresolved: The paper does not provide a systematic approach or guidelines for determining the optimal grid size for different materials and structures. It only mentions the need for the grid size to be small compared to the birth and death of cycles.
- What evidence would resolve it: A study comparing the performance and interpretability of the Grid-based Explanation method using different grid sizes for various materials and structures would provide evidence for optimizing the grid size.

### Open Question 2
- Question: How can the Grid-based Explanation method be extended to handle materials with different types of atoms and their interactions?
- Basis in paper: [inferred] The paper mentions that the Grid-based Explanation method can handle variable-length data by normalizing the number of features to the number of grids, but it does not address how to handle materials with different types of atoms and their interactions.
- Why unresolved: The paper does not provide a clear approach for incorporating information about different atom types and their interactions into the Grid-based Explanation method.
- What evidence would resolve it: A study demonstrating the application of the Grid-based Explanation method to materials with different atom types and their interactions, and comparing its performance to other methods, would provide evidence for extending the method to handle such materials.

### Open Question 3
- Question: How can the Higher Order Term Evaluation method be used to identify and quantify the contributions of complex interactions between manipulatable parameters and cycles in the persistent homology diagram?
- Basis in paper: [explicit] The paper mentions that the Higher Order Term Evaluation method can decompose feature attributions into contributions from individual manipulatable parameters, but it does not provide a detailed explanation of how to identify and quantify complex interactions between parameters and cycles.
- Why unresolved: The paper does not provide a clear approach for identifying and quantifying complex interactions between manipulatable parameters and cycles in the persistent homology diagram.
- What evidence would resolve it: A study demonstrating the application of the Higher Order Term Evaluation method to identify and quantify complex interactions between manipulatable parameters and cycles in the persistent homology diagram, and comparing its performance to other methods, would provide evidence for extending the method to handle such interactions.

## Limitations
- The Grid-based Explanation method may oversimplify the chemical complexity of MOFs by treating all atoms equally and ignoring their types and interactions.
- The Higher Order Term Evaluation relies on the transitivity of feature attributions, which may not hold if the relationship between parameters and PH features is highly non-linear or if there are strong interactions between parameters that are not captured by the decomposition.

## Confidence
- High confidence: The basic approach of using observational XAI methods (IGCS, CS) for interpretability in the PH-ML pipeline is well-founded theoretically.
- Medium confidence: The Grid-based Explanation method for normalizing variable-length data is plausible but needs empirical validation on diverse MOF datasets.
- Medium confidence: The Higher Order Term Evaluation method for decomposing attributions into manipulatable parameters is conceptually sound but may face practical challenges in complex molecular systems.

## Next Checks
1. Test the Grid-based Explanation method on a synthetic dataset with known ground truth attributions to verify that the normalization preserves the relative importance of atoms/regions.
2. Apply the Higher Order Term Evaluation to a small set of MOFs with manually verified parameter-feature relationships to validate the decomposition accuracy.
3. Evaluate the sensitivity of attribution results to grid size selection and number of perturbation samples in Cohort Shapley to establish robustness ranges.