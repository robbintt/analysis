---
ver: rpa2
title: 'DARWIN Series: Domain Specific Large Language Models for Natural Science'
arxiv_id: '2308.13565'
source_url: https://arxiv.org/abs/2308.13565
tags:
- science
- scientific
- language
- instruction
- darwin
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DARWIN Series presents domain-specific large language models tailored
  for natural science, including physics, chemistry, and material science. The series
  leverages open-source LLMs, incorporating structured and unstructured scientific
  knowledge from public datasets and literature.
---

# DARWIN Series: Domain Specific Large Language Models for Natural Science

## Quick Facts
- arXiv ID: 2308.13565
- Source URL: https://arxiv.org/abs/2308.13565
- Reference count: 40
- Key outcome: Domain-specific LLMs for natural science achieve state-of-the-art results on scientific tasks while reducing reliance on closed-source models

## Executive Summary
DARWIN Series presents a collection of domain-specific large language models tailored for natural science applications, including physics, chemistry, and material science. The series leverages open-source LLMs and incorporates structured and unstructured scientific knowledge from public datasets and literature. A novel Scientific Instruction Generation (SIG) model is introduced to automate instruction generation from scientific texts, enhancing the reliability of training data. The DARWIN series achieves state-of-the-art results on various scientific tasks, demonstrating its effectiveness in accelerating scientific discovery and reducing dependence on closed-source AI models.

## Method Summary
The DARWIN series fine-tunes open-source LLMs (LLaMA-7B and Vicuna-7B) using a two-stage approach. First, the LLaMA-7B model is fine-tuned on scientific knowledge from the SciQ dataset and instruction data generated by the Scientific Instruction Generation (SIG) model. The SIG model fine-tunes Vicuna-7B using seed question-answer pairs from GPT-4 and scientific papers to generate new QA pairs from a large corpus of scientific papers. Then, the DARWIN-BASE model is further fine-tuned on multiple FAIR datasets for multi-task learning, creating the DARWIN-MDP model. The model's performance is evaluated on various scientific tasks, including question-answering, classification, regression, and inverse design.

## Key Results
- DARWIN series achieves state-of-the-art results on various scientific tasks, including question-answering, classification, regression, and inverse design.
- The Scientific Instruction Generation (SIG) model automates high-quality instruction generation from scientific texts, reducing reliance on manual annotation.
- Multi-task training on scientific knowledge and FAIR datasets improves model performance on scientific tasks compared to single-task training.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Scientific Instruction Generation (SIG) model automates high-quality instruction generation from scientific texts, reducing reliance on manual annotation.
- Mechanism: The SIG model fine-tunes an open-source LLM (Vicuna-7B) using seed question-answer pairs from GPT-4 and scientific papers, then uses the fine-tuned model to generate new QA pairs from a large corpus of scientific papers.
- Core assumption: The SIG model can effectively learn to generate relevant, complex questions and answers from scientific text that are more informative than self-questioning methods.
- Evidence anchors:
  - [abstract] "During the fine-tuning, we introduce the Scientific Instruction Generation (SIG) model, automating instruction generation from scientific texts."
  - [section] "The SIG model was developed by fine-tuning the LLM using seed papers and their corresponding question-answer pairs."
  - [corpus] Weak evidence - no direct comparison of SIG vs. self-questioning in corpus.

### Mechanism 2
- Claim: Multi-task training on scientific knowledge and FAIR datasets improves model performance on scientific tasks compared to single-task training.
- Mechanism: The DARWIN-MDP model is first fine-tuned on scientific knowledge (SciQ dataset and SIG-generated QA pairs) and then further fine-tuned on multiple FAIR datasets, leveraging shared representations across tasks.
- Core assumption: There are underlying connections between scientific tasks (classification, regression, inverse design) that can be exploited through multi-task learning.
- Evidence anchors:
  - [abstract] "We also explore multi-task training strategies, revealing interconnections between scientific tasks."
  - [section] "When comparing LLaMA-single and LLaMA-all, we observed that fine-tuning on multiple tasks together (LLaMA-all) yields superior performance compared to fine-tuning on individual tasks separately (LLaMA-single)."
  - [corpus] Weak evidence - no explicit discussion of task interconnections in corpus.

### Mechanism 3
- Claim: Fine-tuning on scientific knowledge before multi-task fine-tuning improves performance on FAIR datasets compared to multi-task fine-tuning alone.
- Mechanism: The DARWIN-MDP model is first fine-tuned on scientific knowledge (SciQ dataset and SIG-generated QA pairs) to establish a strong scientific foundation, then fine-tuned on FAIR datasets for task-specific performance.
- Core assumption: Establishing a strong scientific knowledge base before task-specific fine-tuning provides a better foundation for learning scientific tasks.
- Evidence anchors:
  - [abstract] "DARWIN series not only achieves state-of-the-art results on various scientific tasks but also diminishes reliance on closed-source AI models."
  - [section] "Furthermore, when comparing LLaMA-all with DARWIN-MDP, we find that the initial stage of fine-tuning scientific knowledge significantly contributes to further improvements in performance."
  - [corpus] Weak evidence - no explicit comparison of DARWIN-MDP to models fine-tuned only on FAIR datasets in corpus.

## Foundational Learning

- Concept: Scientific Instruction Generation (SIG)
  - Why needed here: To generate high-quality, domain-relevant instruction data for fine-tuning the DARWIN models, reducing reliance on manual annotation and improving instruction dataset reliability.
  - Quick check question: What is the purpose of the Scientific Instruction Generation (SIG) model, and how does it generate instruction data?

- Concept: Multi-task learning
  - Why needed here: To leverage shared representations across scientific tasks (classification, regression, inverse design) and improve model performance on each task compared to single-task training.
  - Quick check question: What is the advantage of multi-task learning in the context of the DARWIN models, and how does it improve performance?

- Concept: Domain-specific fine-tuning
  - Why needed here: To establish a strong scientific knowledge foundation for the DARWIN models before task-specific fine-tuning, improving performance on scientific tasks compared to general LLMs.
  - Quick check question: Why is domain-specific fine-tuning important for the DARWIN models, and how does it improve performance on scientific tasks?

## Architecture Onboarding

- Component map:
  - Input: Scientific papers, FAIR datasets, SciQ dataset
  - Scientific Instruction Generation (SIG) model: Fine-tunes Vicuna-7B to generate QA pairs from scientific papers
  - DARWIN-BASE model: Fine-tunes LLaMA-7B on scientific knowledge (SciQ dataset and SIG-generated QA pairs)
  - DARWIN-MDP model: Further fine-tunes DARWIN-BASE on FAIR datasets for multi-task learning
  - Output: Predictions for scientific tasks (classification, regression, inverse design)

- Critical path: Scientific papers → SIG model → DARWIN-BASE → DARWIN-MDP → Scientific task predictions

- Design tradeoffs:
  - Using Vicuna-7B for SIG vs. larger models: Vicuna-7B balances performance and cost for instruction generation.
  - Fine-tuning on scientific knowledge before FAIR datasets vs. only FAIR datasets: Scientific knowledge fine-tuning provides a stronger foundation but adds an extra training stage.
  - Multi-task learning vs. single-task learning: Multi-task learning can improve performance but may introduce interference between tasks.

- Failure signatures:
  - Poor instruction generation: SIG model generates irrelevant or low-quality QA pairs, leading to poor instruction dataset quality and model performance.
  - Catastrophic forgetting: Multi-task fine-tuning causes the model to forget previously learned knowledge, degrading performance on earlier tasks.
  - Domain mismatch: Scientific knowledge fine-tuning does not transfer well to FAIR tasks, providing no benefit or causing interference.

- First 3 experiments:
  1. Evaluate the quality of QA pairs generated by the SIG model compared to self-questioning methods using human evaluation.
  2. Compare the performance of DARWIN-MDP to models fine-tuned only on FAIR datasets or only on scientific knowledge to assess the benefits of the two-stage fine-tuning approach.
  3. Evaluate the performance of DARWIN-MDP on a held-out test set of scientific tasks to assess its generalization capabilities and compare it to state-of-the-art models.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Scientific Instruction Generation (SIG) model compare to other instruction generation methods, such as self-questioning, in terms of the quality and specificity of generated questions and answers?
- Basis in paper: [explicit] The paper mentions that SIG generates more informative and specific questions compared to self-questioning.
- Why unresolved: While the paper states that SIG performs better, it does not provide a detailed quantitative comparison between the two methods.
- What evidence would resolve it: A comprehensive evaluation comparing the performance of SIG and self-questioning on a standardized dataset, measuring factors like question complexity, relevance, and answer accuracy.

### Open Question 2
- Question: How does the DARWIN series model perform on other scientific tasks not evaluated in this study, such as natural language inference, semantic parsing, or text summarization?
- Basis in paper: [inferred] The paper focuses on the model's performance on specific scientific tasks like question-answering, classification, regression, and inverse design. However, it does not explore its capabilities on other NLP tasks.
- Why unresolved: The paper does not provide any information about the model's performance on a broader range of NLP tasks relevant to scientific literature.
- What evidence would resolve it: Evaluating the DARWIN series on a diverse set of NLP benchmarks commonly used in the scientific domain, such as SciQ, SciTail, and PubMedQA.

### Open Question 3
- Question: How does the multi-task training strategy employed in the DARWIN series impact the model's performance on individual tasks compared to training on each task separately?
- Basis in paper: [explicit] The paper mentions that multi-task training improves the model's overall capabilities compared to single-task training.
- Why unresolved: The paper does not provide a detailed analysis of how multi-task training affects the performance on each individual task within the DARWIN series.
- What evidence would resolve it: Conducting an ablation study where the DARWIN series is trained on different combinations of tasks and evaluating its performance on each task individually to determine the impact of multi-task learning.

## Limitations

- The methodology relies heavily on synthetic data generation through the SIG model, which introduces potential quality control issues. While the paper claims SIG-generated questions are more informative than self-questioning methods, no direct comparison is provided in the corpus.
- The multi-task training benefits are asserted based on performance improvements but lack detailed analysis of task interconnections or potential interference patterns.
- The paper's claims about task interconnections and the specific advantages of multi-task learning over single-task approaches lack supporting evidence in the corpus.

## Confidence

**High Confidence:** The general architecture and two-stage fine-tuning approach (scientific knowledge → FAIR datasets) is well-specified and reproducible. The use of established datasets (SciQ) and metrics (F1, MAE) provides reliable evaluation frameworks.

**Medium Confidence:** The claimed performance improvements over baselines, particularly the assertion that DARWIN-MDP achieves state-of-the-art results, requires validation given the limited comparison details in the corpus. The SIG model's effectiveness in generating high-quality instruction data is asserted but not directly validated against alternatives.

**Low Confidence:** The paper's claims about task interconnections and the specific advantages of multi-task learning over single-task approaches lack supporting evidence in the corpus. The benefits of the two-stage fine-tuning approach versus direct FAIR dataset fine-tuning are asserted but not empirically demonstrated.

## Next Checks

1. Conduct a human evaluation study comparing the quality and relevance of QA pairs generated by SIG versus self-questioning methods on the same scientific texts.

2. Perform ablation studies to quantify the individual contributions of scientific knowledge fine-tuning versus FAIR dataset fine-tuning, including a direct comparison to models trained only on FAIR datasets.

3. Test the models on out-of-distribution scientific tasks not included in the FAIR datasets to evaluate generalization capabilities and assess potential overfitting to the training distribution.