---
ver: rpa2
title: Delegated Classification
arxiv_id: '2306.11475'
source_url: https://arxiv.org/abs/2306.11475
tags:
- contract
- learning
- contracts
- optimal
- min-budget
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the problem of delegating machine learning tasks
  to a rational agent, where the agent may have conflicting incentives. The authors
  propose a framework based on contract design, where the principal (client) designs
  a contract that specifies payments based on the accuracy of the learned model.
---

# Delegated Classification

## Quick Facts
- arXiv ID: 2306.11475
- Source URL: https://arxiv.org/abs/2306.11475
- Reference count: 40
- Primary result: Framework for outsourced ML tasks using contract design with threshold payments

## Executive Summary
This paper addresses the problem of delegating machine learning tasks to potentially self-interested agents. The authors propose a contract design framework where principals (clients) specify payment structures based on model accuracy, while agents (learning providers) choose training set sizes to maximize their utility. Under reasonable assumptions like the Monotone Likelihood Ratio Property (MLRP), optimal contracts take a simple threshold form. The framework connects contract design to statistical hypothesis testing via the Neyman-Pearson lemma, and demonstrates practical applicability through experiments on MNIST and other datasets.

## Method Summary
The authors formulate delegated classification as a principal-agent game where the principal commits to a contract mapping accuracy to payment, and the agent chooses training set size to maximize expected utility. Under MLRP assumptions, they prove optimal contracts take threshold form, which can be found via linear programming. For settings with limited information, they use learning curve extrapolation from small pilot datasets to construct contracts. The framework is evaluated empirically using MNIST and the Learning Curves Database (LCDB), comparing contract types and analyzing budget requirements for target accuracy levels.

## Key Results
- Optimal contracts under MLRP assumptions take simple threshold form, simplifying design
- Threshold contracts can be constructed from small-scale data using learning curve extrapolation
- Performance and economic outcomes evaluated on synthetic and real-world classification tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Agents cannot reliably report their effort, so principals must use outcome-based payments to align incentives
- Mechanism: The principal commits to a contract t that maps observed accuracy j to payment, creating a Stackelberg game where the agent chooses n to maximize utility
- Core assumption: The agent's action (training set size) is private information, creating moral hazard
- Evidence anchors:
  - [abstract] "conflicts of interest might arise and severely impact predictive performance"
  - [section 2.1] "The agent's choice to perform action a yields a random outcome j ~ fa"
- Break condition: If the agent can perfectly report their effort, contracts become unnecessary

### Mechanism 2
- Claim: Under MLRP, optimal contracts take threshold form, simplifying contract design
- Mechanism: When MLRP holds, distributions become "single-crossing," allowing the principal to identify the optimal payment threshold via likelihood ratio testing
- Core assumption: Learning curves exhibit increasing expectation but decreasing variance with more samples (MLRP)
- Evidence anchors:
  - [abstract] "optimal contracts take a simple threshold form under reasonable assumptions"
  - [section 3.2] "Under the MLRP assumption, n2 is always implementable, and the optimal contract assumes a threshold form"
- Break condition: If MLRP doesn't hold, optimal contracts may require complex, non-threshold structures

### Mechanism 3
- Claim: Partial information settings can still yield effective contracts through learning curve extrapolation
- Mechanism: Principals can estimate learning curves from small pilot datasets and extrapolate to larger sample sizes, then design contracts based on these estimates
- Core assumption: Learning curves follow predictable patterns (e.g., power-law scaling) that allow accurate extrapolation
- Evidence anchors:
  - [abstract] "budget-optimal contracts can be constructed using small-scale data, leveraging recent advances in the study of learning curves"
  - [section 4.2] "Using the recent LCDB dataset of learning curves, we show that threshold contracts generally perform well on estimated curves"
- Break condition: If extrapolation is inaccurate (especially over-estimation), contracts may incentivize wrong actions

## Foundational Learning

- Concept: Stackelberg games in contract theory
  - Why needed here: The principal-agent interaction is modeled as a sequential game where the principal commits to a contract first
  - Quick check question: What distinguishes a Stackelberg game from a Nash equilibrium in this setting?

- Concept: Monotone Likelihood Ratio Property (MLRP)
  - Why needed here: MLRP enables simplification of optimal contracts to threshold form
  - Quick check question: How does MLRP relate to the "single-crossing" property of distributions?

- Concept: Neyman-Pearson lemma and hypothesis testing
  - Why needed here: The optimal contract design problem reduces to a statistical hypothesis test
  - Quick check question: What is the connection between the optimal contract and the most powerful hypothesis test?

## Architecture Onboarding

- Component map: Principal (budget controller, contract designer) → Agent (training set size chooser, model trainer) → Validation process (accuracy measurement) → Payment execution
- Critical path: Design contract → Agent chooses n → Train model → Measure accuracy → Pay according to contract
- Design tradeoffs: Simpler threshold contracts vs. potentially more efficient complex contracts; accuracy vs. budget efficiency
- Failure signatures: Agents gaming the contract (choosing suboptimal n), over/under-estimation in partial information settings, numerical instability in LP solvers
- First 3 experiments:
  1. Verify MLRP holds for synthetic learning curves with known properties
  2. Test threshold contract performance against optimal LP solutions on small problems
  3. Evaluate contract performance under varying validation set sizes (m)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do threshold contracts perform when the learning curves do not satisfy the Monotone Likelihood Ratio Property (MLRP)?
- Basis in paper: [inferred] The paper discusses MLRP as a sufficient condition for threshold contracts to be optimal, but does not explore what happens when MLRP is violated
- Why unresolved: The paper provides a counterexample where MLRP does not hold and threshold contracts are not optimal, but does not explore the general performance of threshold contracts in such cases
- What evidence would resolve it: Empirical experiments comparing the performance of threshold contracts versus other contract types on real-world datasets where MLRP does not hold

### Open Question 2
- Question: How robust are threshold contracts to over-estimation versus under-estimation of the learning curve?
- Basis in paper: [explicit] The paper mentions that over-estimation of the learning curve can cause accuracy to plummet, while under-estimation leads to graceful degradation
- Why unresolved: The paper provides qualitative insights but does not quantify the exact impact of over- vs under-estimation on contract performance
- What evidence would resolve it: A systematic study varying the degree of over- and under-estimation of learning curves and measuring the resulting contract performance

### Open Question 3
- Question: How do threshold contracts compare to other contract types in terms of fairness and incentive alignment?
- Basis in paper: [inferred] The paper focuses on optimizing for accuracy and budget, but does not discuss fairness or incentive alignment properties of different contract types
- Why unresolved: The paper does not explore these aspects of contract design
- What evidence would resolve it: A comparison of different contract types on metrics related to fairness (e.g., equitable distribution of payments) and incentive alignment (e.g., how well the contract aligns agent incentives with principal goals)

## Limitations
- MLRP assumption not empirically validated across diverse datasets and algorithms
- Extrapolation accuracy from small pilot datasets remains uncertain, especially for out-of-distribution sample sizes
- Real-world economic incentive alignment not thoroughly tested beyond simplified models

## Confidence

**High Confidence:** The mathematical formulation of the principal-agent problem and the LP approach to finding budget-optimal contracts is sound and well-grounded in contract theory literature.

**Medium Confidence:** The theoretical results showing optimal contracts take threshold form under MLRP assumptions are valid, but their practical applicability depends on whether MLRP actually holds in practice.

**Low Confidence:** The effectiveness of partial information settings using learning curve extrapolation has not been thoroughly validated, particularly regarding the accuracy of extrapolation over multiple orders of magnitude.

## Next Checks
1. Systematically test whether MLRP holds across multiple datasets (beyond MNIST), algorithms, and model families. Quantify the frequency and severity of MLRP violations and their impact on contract performance.
2. Measure the accuracy of learning curve extrapolation from pilot datasets of varying sizes. Establish error bounds and determine how these errors propagate to contract design and agent behavior.
3. Design experiments that test whether the payment structures would actually motivate rational agents in real outsourcing scenarios, considering factors like computational costs, opportunity costs, and market dynamics beyond the simplified model.