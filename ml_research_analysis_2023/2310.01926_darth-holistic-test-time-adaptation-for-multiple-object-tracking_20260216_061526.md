---
ver: rpa2
title: 'DARTH: Holistic Test-time Adaptation for Multiple Object Tracking'
arxiv_id: '2310.01926'
source_url: https://arxiv.org/abs/2310.01926
tags:
- darth
- bdd100k
- shift
- domain
- tracking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of domain shift in multiple object
  tracking (MOT) for autonomous driving systems, where performance degrades when models
  trained on one domain are applied to different domains. The authors propose DARTH,
  a holistic test-time adaptation framework that adapts both object detection and
  instance association stages of appearance-based MOT systems.
---

# DARTH: Holistic Test-time Adaptation for Multiple Object Tracking

## Quick Facts
- arXiv ID: 2310.01926
- Source URL: https://arxiv.org/abs/2310.01926
- Reference count: 40
- Key outcome: +74.7 MOTA improvement over non-adapted models in SHIFT→BDD100K setting

## Executive Summary
DARTH addresses domain shift in multiple object tracking (MOT) for autonomous driving by adapting both object detection and instance association stages simultaneously. The method uses a teacher-student architecture with exponential moving average updates, employing detection consistency loss for photometric robustness and patch contrastive loss for discriminative appearance representations. Evaluated across sim-to-real, outdoor-to-inddoor, and indoor-to-outdoor scenarios, DARTH significantly improves tracking performance while reducing ID switches and recovering false negative detections.

## Method Summary
DARTH is a test-time adaptation framework that employs a teacher-student architecture with EMA updates. It adapts object detection through detection consistency loss that enforces photometric invariance, while adapting instance association via patch contrastive loss that learns discriminative appearance embeddings. The method generates multiple augmented views (teacher, student, contrastive) and applies geometric and photometric augmentations strategically to learn robust representations that generalize across domain shifts.

## Key Results
- Achieves +74.7 MOTA improvement over non-adapted models in SHIFT→BDD100K setting
- Significantly reduces ID switches while recovering false negative detections
- Demonstrates effectiveness across multiple domain shifts: sim-to-real, outdoor-to-indoor, indoor-to-outdoor

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DARTH adapts both detection and instance association stages simultaneously through a holistic teacher-student architecture with EMA updates.
- Mechanism: The teacher model provides stable targets for detection consistency loss, while the EMA updates gradually incorporate improved student representations. The siamese student learns discriminative appearance representations via patch contrastive learning between different augmented views.
- Core assumption: Detection and instance association are interdependent components that must be adapted together for effective domain adaptation in MOT.
- Evidence anchors:
  - [abstract]: "we propose a detection consistency formulation to adapt object detection in a self-supervised fashion, while adapting the instance appearance representations via our novel patch contrastive loss"
  - [section]: "DARTH, a holistic test-time adaptation framework that addresses the manifold nature of MOT"
  - [corpus]: Weak evidence - no direct citations about holistic MOT adaptation in corpus neighbors
- Break condition: If detection consistency loss and patch contrastive learning conflict rather than complement each other, causing performance degradation in either detection or association.

### Mechanism 2
- Claim: Detection consistency loss enforces robustness to photometric changes and stabilizes detection outputs across adjacent frames.
- Mechanism: By applying photometric augmentation ϕS to the teacher view xT to generate student view xS, the detection consistency loss learns global representations invariant to such changes. This addresses the flickering detection issue in MOT under domain shift.
- Core assumption: Photometric consistency between adjacent frames improves tracking stability and reduces ID switches.
- Evidence anchors:
  - [abstract]: "we propose a detection consistency formulation to adapt object detection in a self-supervised fashion and enforce its robustness to photometric changes"
  - [section]: "tracking-by-detection is negatively affected by flickering of detections through time, and domain shift exacerbates this issue"
  - [corpus]: No direct evidence about photometric consistency in MOT adaptation
- Break condition: If photometric augmentations are too aggressive, causing the model to learn incorrect invariances or degrade detection accuracy.

### Mechanism 3
- Claim: Patch contrastive learning adapts local appearance representations by enforcing self-matching under different augmented views.
- Mechanism: The method generates student and contrastive views from the same teacher detections, creating known instance correspondences. The patch contrastive loss then learns discriminative embeddings by matching RoIs across views while considering IoU thresholds for positive/negative pairs.
- Core assumption: Local appearance representations learned through self-matching under augmentation generalize better to target domain variations.
- Evidence anchors:
  - [abstract]: "adapting the instance appearance representations via our novel patch contrastive loss"
  - [section]: "our patch contrastive loss between the siamese student's instance embeddings adapts instance association"
  - [corpus]: No direct evidence about patch contrastive learning in MOT adaptation
- Break condition: If the IoU thresholds (α1=0.7, α2=0.3) are inappropriate for the target domain, leading to incorrect positive/negative pairs.

## Foundational Learning

- Concept: Test-time adaptation (TTA) for MOT
  - Why needed here: Traditional UDA requires labeled target data, but TTA adapts pre-trained models to unlabeled target domains, making it more practical for real-world deployment.
  - Quick check question: What is the key difference between unsupervised domain adaptation and test-time adaptation?

- Concept: Siamese networks for representation learning
  - Why needed here: The siamese architecture enables learning discriminative appearance representations by comparing different views of the same instance.
  - Quick check question: How does a siamese architecture differ from a standard encoder-decoder in terms of learning objectives?

- Concept: Exponential moving average (EMA) in teacher-student frameworks
  - Why needed here: EMA provides stable teacher targets while gradually incorporating student improvements, preventing catastrophic forgetting during adaptation.
  - Quick check question: What advantage does EMA provide over directly using student weights as teacher targets?

## Architecture Onboarding

- Component map:
  Input -> Geometric augmentation -> Teacher view -> Photometric augmentation -> Student view
  Input -> Contrastive augmentation -> Contrastive view
  Teacher model (EMA) -> Detection consistency loss -> Student model
  Student model -> Patch contrastive loss -> Student model updates

- Critical path:
  1. Generate augmented views (teacher, student, contrastive)
  2. Apply teacher detector to identify object regions
  3. Compute detection consistency loss between teacher and student
  4. Apply patch contrastive loss between student and contrastive views
  5. Update student weights and EMA teacher
  6. Use adapted model for MOT inference

- Design tradeoffs:
  - Geometric vs photometric augmentation timing: Applying photometric augmentation after geometric ensures detection consistency while learning photometric invariance
  - IoU thresholds for patch contrastive learning: Stricter thresholds (α1=0.7) ensure reliable positive pairs but may reduce training samples
  - EMA momentum (τ=0.998): Slower updates provide stability but may adapt too slowly to target domain

- Failure signatures:
  - Detection accuracy drops significantly: Detection consistency loss parameters may be misconfigured
  - High ID switches despite good detection: Patch contrastive loss may not be learning discriminative embeddings
  - No improvement over baseline: EMA momentum may be too slow or augmentations too weak

- First 3 experiments:
  1. Test detection consistency loss alone (without patch contrastive) to verify photometric invariance learning
  2. Test patch contrastive loss alone (without detection consistency) to verify embedding quality
  3. Test different EMA momentum values (0.99, 0.998, 0.999) to find optimal stability vs adaptation speed tradeoff

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Lacks ablation studies showing individual contribution of detection consistency vs patch contrastive losses
- Performance on extreme domain shifts (night-to-day, weather changes) not evaluated
- Computational overhead of test-time adaptation during inference not quantified

## Confidence
- Mechanism 1 (Holistic adaptation): High confidence - well-supported by experimental results across multiple benchmarks
- Mechanism 2 (Detection consistency): Medium confidence - theoretical motivation is clear but lacks ablation showing photometric invariance improvement
- Mechanism 3 (Patch contrastive learning): Medium confidence - novel approach but limited comparison to alternative representation learning methods

## Next Checks
1. Perform ablation study isolating detection consistency loss vs patch contrastive loss contributions to quantify their individual impact on tracking performance
2. Test DARTH's effectiveness under extreme domain shifts (night-to-day, severe weather conditions) to evaluate robustness limits
3. Measure inference-time computational overhead and compare against real-time requirements for autonomous driving applications