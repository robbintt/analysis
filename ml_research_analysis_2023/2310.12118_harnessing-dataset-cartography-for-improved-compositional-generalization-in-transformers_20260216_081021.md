---
ver: rpa2
title: Harnessing Dataset Cartography for Improved Compositional Generalization in
  Transformers
arxiv_id: '2310.12118'
source_url: https://arxiv.org/abs/2310.12118
tags:
- dataset
- training
- hard-to-learn
- generalization
- subsets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that leveraging dataset cartography can
  significantly improve compositional generalization in Transformers. By analyzing
  training dynamics, the authors identify hard-to-learn, ambiguous, and easy-to-learn
  samples, and show that training on hard-to-learn subsets (33% or 50% of data) improves
  accuracy by up to 10% on CFQ and COGS datasets.
---

# Harnessing Dataset Cartography for Improved Compositional Generalization in Transformers

## Quick Facts
- arXiv ID: 2310.12118
- Source URL: https://arxiv.org/abs/2310.12118
- Reference count: 40
- Key outcome: Training on hard-to-learn subsets (33% or 50% of data) improves compositional generalization accuracy by up to 10% on CFQ and COGS datasets

## Executive Summary
This paper demonstrates that leveraging dataset cartography can significantly improve compositional generalization in Transformers. By analyzing training dynamics, the authors identify hard-to-learn, ambiguous, and easy-to-learn samples, and show that training on hard-to-learn subsets improves accuracy by up to 10% on CFQ and COGS datasets. Using inverse perplexity as a confidence measure is most effective. The approach also enhances curriculum learning, achieving better performance without hyperparameter tuning.

## Method Summary
The method involves training a vanilla Transformer model on the full training set for a few epochs while storing training dynamics (perplexity, CHIA, BLEU scores for each sample). Data maps are created to identify hard-to-learn, ambiguous, and easy-to-learn subsets (e.g., 33% or 50% of data). New models are then trained on these selected subsets and evaluated on test sets, with results compared to models trained on full data or random subsets.

## Key Results
- Training on hard-to-learn subsets (33% or 50% of data) improves accuracy by up to 10% on CFQ and COGS datasets
- Inverse perplexity as a confidence measure is more effective than BLEU or CHIA for identifying hard-to-learn samples
- Starting training with hard-to-learn samples (reverse curriculum) outperforms traditional curriculum learning for compositional generalization

## Why This Works (Mechanism)

### Mechanism 1
Hard-to-learn samples improve compositional generalization because they contain more challenging compositional structures. These samples have lower confidence and variability during training, indicating they require deeper understanding rather than pattern matching. The difficulty stems from their compositional complexity rather than data quality issues.

### Mechanism 2
Inverse perplexity is more effective than BLEU or CHIA because it uses geometric mean of token probabilities, making it more sensitive to low-probability tokens that indicate compositional difficulty. While BLEU and CHIA use arithmetic means that can mask these issues, geometric mean better captures the difficulty of sequences with rare or complex compositional structures.

### Mechanism 3
Starting training with hard-to-learn samples (reverse curriculum) is more effective than traditional curriculum learning because it forces the model to develop compositional understanding early, preventing it from relying on spurious correlations or simple patterns that would limit generalization.

## Foundational Learning

- **Dataset cartography** - mapping training instances by confidence and variability to identify easy, ambiguous, and hard-to-learn samples. Needed to identify which training samples are most informative for compositional generalization.
  - Quick check: What two dimensions does dataset cartography use to characterize training instances?

- **Compositional generalization** - ability to combine known parts to generate novel compositions. Needed because the paper's entire premise is improving this specific capability in Transformers.
  - Quick check: How does compositional generalization differ from standard language model generalization?

- **Inverse perplexity calculation** - geometric mean of token probabilities across epochs. Needed because this measure is used to identify hard-to-learn samples more effectively than other confidence measures.
  - Quick check: Why might geometric mean be more effective than arithmetic mean for measuring sequence difficulty?

## Architecture Onboarding

- **Component map**: Data preprocessing pipeline for CFQ, COGS, and SMCS datasets → Training dynamics tracker that stores confidence/variability metrics per sample → Subset selection module that uses dataset cartography to create training subsets → Curriculum learning scheduler for hard-to-easy or easy-to-hard ordering → Transformer model (vanilla or Bi-LSTM with attention) for experiments → Evaluation pipeline for accuracy on compositional generalization tasks

- **Critical path**: Data preprocessing → Training dynamics tracking → Subset selection → Model training → Evaluation

- **Design tradeoffs**: Storing training dynamics increases memory usage but enables better sample selection; using smaller subsets (33-50%) reduces training time but requires careful selection to maintain performance; inverse perplexity is computationally expensive to calculate but provides better sample discrimination

- **Failure signatures**: Poor performance on compositional splits despite high overall accuracy; training dynamics not converging properly, leading to unreliable cartography; subset selection not improving performance, suggesting incorrect measure choice or subset composition

- **First 3 experiments**: 1) Implement training dynamics tracking and create data maps for CFQ dataset using inverse perplexity; 2) Compare performance of hard-to-learn vs random 33% subsets on CFQ; 3) Test curriculum learning with hard-to-learn first ordering vs traditional ordering on COGS dataset

## Open Questions the Paper Calls Out

- How does dataset cartography perform on other neural architectures beyond Transformers and Bi-LSTM?
- Does dataset cartography identify hard-to-learn samples due to genuine difficulty or annotation errors in natural datasets?
- What specific properties of hard-to-learn examples make them more effective for training?

## Limitations

- The effectiveness depends heavily on the quality and stability of training dynamics data, which is not fully specified
- The approach may not generalize to naturalistic language datasets with different characteristics
- Memory overhead of storing training dynamics for all samples may become prohibitive for larger datasets

## Confidence

- **High Confidence**: Empirical finding that training on hard-to-learn subsets improves accuracy by up to 10% on CFQ and COGS datasets
- **Medium Confidence**: Inverse perplexity is more effective due to its geometric mean calculation
- **Low Confidence**: Hard-to-learn samples contain more compositional complexity rather than being difficult due to noise

## Next Checks

1. Perform manual annotation or automated analysis to verify that hard-to-learn samples actually contain more complex compositional structures rather than being difficult due to noise, duplication, or labeling issues

2. Apply the dataset cartography approach to a naturalistic language dataset (e.g., WikiText or real-world code generation tasks) to test whether the findings extend beyond synthetic compositional datasets

3. Conduct experiments varying the granularity of training dynamics tracking to determine the minimum tracking frequency needed while maintaining performance improvements