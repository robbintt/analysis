---
ver: rpa2
title: Hierarchical Pretraining for Biomedical Term Embeddings
arxiv_id: '2307.00266'
source_url: https://arxiv.org/abs/2307.00266
tags:
- terms
- biomedical
- term
- embeddings
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of effectively representing biomedical
  terms as semantic embeddings for downstream applications like clinical decision
  making. The core method idea is to leverage hierarchical information from medical
  term hierarchies (PheCODE, LOINC, RxNorm) in addition to UMLS synonyms to train
  biomedical term embeddings.
---

# Hierarchical Pretraining for Biomedical Term Embeddings

## Quick Facts
- arXiv ID: 2307.00266
- Source URL: https://arxiv.org/abs/2307.00266
- Reference count: 23
- Key outcome: HiPrBERT outperforms existing models like SAPBERT and CODER on hierarchical discrimination tasks (0 vs 1 AUC of 0.657 vs 0.599) while maintaining performance on similarity tasks.

## Executive Summary
This paper introduces HiPrBERT, a method for training biomedical term embeddings that leverages hierarchical information from medical ontologies (PheCODE, LOINC, RxNorm, CPT) in addition to UMLS synonyms. The core innovation is adapting the multi-similarity loss function to handle multiple ordered categories of term-term similarity derived from hierarchical relationships. By initializing from PubmedBERT and fine-tuning on specialized biomedical data, HiPrBERT achieves improved performance on tasks requiring discrimination of hierarchical relationships while maintaining general biomedical embedding quality.

## Method Summary
HiPrBERT uses a transformer-based encoder initialized from PubmedBERT and trained on three types of biomedical data: UMLS synonym pairs, UMLS relation pairs, and hierarchical pairs from medical ontologies. The key innovation is modifying the multi-similarity loss function to handle multiple distance categories (0, 1, 2, 3) based on hierarchical relationships rather than binary similarity. The model employs online triplet mining for UMLS data and uses the hierarchical structure directly for hierarchical data, training for one epoch with AdamW optimizer (learning rate 2×10^-5, weight decay 0.01, batch size 256).

## Key Results
- HiPrBERT achieves 0 vs 1 AUC of 0.657 compared to 0.599 for CODER on hierarchical discrimination tasks
- Average AUC of 0.937 vs 0.886 for CODER on detecting relatedness between terms
- Maintains Cadec term normalization performance (0.924 vs 0.929 baseline)
- Outperforms SAPBERT and CODER across multiple biomedical embedding tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-similarity loss with multiple distance thresholds better captures hierarchical relationships in biomedical terms.
- Mechanism: By defining distance categories (0, 1, 2, 3) based on hierarchical relationships and using a modified multi-similarity loss function, the model learns to distinguish between different levels of term relatedness rather than just binary similarity.
- Core assumption: Hierarchical structure contains meaningful distance information that can be captured through pairwise comparisons.
- Evidence anchors: "We adapt the existing contrastive loss function to handle any number of ordered categories without the need of specifying any between-category margin."

### Mechanism 2
- Claim: Initializing from PubmedBERT and fine-tuning on biomedical hierarchies improves embeddings specifically for medical terminology.
- Mechanism: The model starts with a general biomedical language model and adapts it using specialized hierarchical data to create domain-specific embeddings.
- Core assumption: A general biomedical language model provides a good foundation that can be specialized through fine-tuning on hierarchical medical data.
- Evidence anchors: "Our model was initialized from PUBMEDBERT and trained using AdamW... for one epoch."

### Mechanism 3
- Claim: The hard pair mining strategy focuses training on challenging term pairs that are difficult to distinguish.
- Mechanism: The model selects term triplets where the anchor is similar to a positive but dissimilar to a negative, prioritizing pairs where the similarity difference is minimal (threshold of 0.25).
- Core assumption: Training on harder examples where the model struggles improves overall performance more than training on easy examples.
- Evidence anchors: "When sampling UMLS term data, we use an online triplet miner to select negative pairs... we consider the difference between cos(ea, ep) and cos(ea, en)."

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: The model needs to learn embeddings where similar terms are close together and dissimilar terms are far apart in the embedding space.
  - Quick check question: Can you explain how contrastive learning differs from supervised learning in terms of what it tries to optimize?

- Concept: Hierarchical structures in medical ontologies
  - Why needed here: Understanding that medical terms can be organized in tree-like structures where distance from root indicates specificity level.
  - Quick check question: What's the difference between a synonym pair and a parent-child pair in a medical hierarchy?

- Concept: Loss function modification
  - Why needed here: The model adapts existing loss functions (multi-similarity loss) to handle multiple distance categories instead of binary classification.
  - Quick check question: How does a multi-category loss function differ from a binary contrastive loss in terms of what it optimizes?

## Architecture Onboarding

- Component map: Input terms → tokenization → transformer encoding → distance calculation → pair mining → loss computation → gradient update
- Critical path: Input term → tokenization → transformer encoding → distance calculation → pair mining → loss computation → gradient update. The most critical path is ensuring that the distance metric accurately reflects the hierarchical relationships.
- Design tradeoffs: Using hierarchies provides more nuanced information but limits vocabulary size compared to UMLS alone. The multi-similarity loss handles multiple categories but adds complexity compared to standard contrastive loss.
- Failure signatures: Poor discrimination between adjacent distance categories (e.g., 0 vs 1 AUC close to random), degradation in similarity tasks like Cadec term normalization, or failure to improve over baseline models on relatedness tasks.
- First 3 experiments:
  1. Train with only UMLS data (no hierarchies) to establish baseline performance on all tasks.
  2. Train with hierarchies but using standard contrastive loss (no multi-category adaptation) to measure the benefit of the modified loss function.
  3. Train on a subset of hierarchies (e.g., only LOINC) to identify which hierarchical sources contribute most to performance improvements.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the pairwise distance metric be extended to incorporate global hierarchical information, such as the depth of nodes in the tree, rather than just local pairwise relationships?
- Basis in paper: The authors note that "nodes closer to the root of the hierarchies represent broader concepts that are further apart, whereas nodes closer to the leaves represent more specific concepts that are closer together" and suggest this could be explicitly coded into training or ideally learned on the fly.
- Why unresolved: The current distance metric only considers local relationships. Incorporating global tree structure would require developing a more sophisticated metric that accounts for the overall depth and branching of the hierarchy.
- What evidence would resolve it: Experiments comparing embeddings trained with a global distance metric versus the current local metric on tasks like relatedness detection and hierarchical discrimination.

### Open Question 2
- Question: How does the performance of HiPrBERT compare to other models on biomedical tasks beyond those evaluated in the paper, such as clinical decision support or patient trajectory prediction?
- Basis in paper: The authors state that HiPrBERT embeddings can "enhance the representation of patients" and lead to "improvements in downstream tasks such as extracting prediction features and patients clustering," but do not evaluate these specific applications.
- Why unresolved: The paper focuses on evaluating HiPrBERT on tasks like relatedness detection and Cadec term normalization. Its performance on other clinically relevant tasks remains unexplored.
- What evidence would resolve it: Fine-tuning HiPrBERT on datasets for clinical decision support or patient trajectory prediction and comparing its performance to other models.

### Open Question 3
- Question: How sensitive is HiPrBERT's performance to the choice of hyperparameters, such as the learning rate, weight decay, and margin values in the loss function?
- Basis in paper: The authors mention specific hyperparameter values but do not explore the impact of varying these hyperparameters.
- Why unresolved: The optimal values for these hyperparameters may depend on the specific dataset and task, and the chosen values may not be universally optimal.
- What evidence would resolve it: Conducting a hyperparameter search and evaluating HiPrBERT's performance across a range of values for each hyperparameter.

## Limitations
- Vocabulary constraints: The hierarchical pretraining approach is limited to terms present in the medical ontologies, which may not cover all biomedical terminology encountered in practice.
- Distance metric assumptions: The model assumes that hierarchical distance directly corresponds to semantic similarity, which may not always hold true for biomedical concepts.
- Evaluation scope: Most evaluations focus on tasks that specifically test hierarchical understanding, with limited assessment of general biomedical embedding quality.

## Confidence
- Multi-similarity loss improvements: Medium-High
- General biomedical embedding quality: Medium
- Hyperparameter robustness: Medium-Low
- Clinical applicability: Medium

## Next Checks
1. Conduct ablation studies using individual hierarchical sources to determine which ontologies contribute most to performance improvements.
2. Expand evaluation to a broader suite of biomedical embedding tasks beyond hierarchical discrimination, including clinical information extraction tasks.
3. Perform systematic hyperparameter sensitivity analysis by varying training duration, learning rate, batch size, and distance thresholds.