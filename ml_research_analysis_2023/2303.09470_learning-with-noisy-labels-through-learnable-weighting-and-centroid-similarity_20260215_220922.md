---
ver: rpa2
title: Learning with Noisy Labels through Learnable Weighting and Centroid Similarity
arxiv_id: '2303.09470'
source_url: https://arxiv.org/abs/2303.09470
tags:
- samples
- noisy
- noise
- training
- labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces NCOD, a novel method for training deep learning\
  \ models in the presence of noisy labels. The approach leverages class embeddings\u2014\
  average representations of each class in latent space\u2014and an outlier discounting\
  \ mechanism that reduces the influence of samples far from their class centroid,\
  \ particularly those with noisy labels."
---

# Learning with Noisy Labels through Learnable Weighting and Centroid Similarity

## Quick Facts
- arXiv ID: 2303.09470
- Source URL: https://arxiv.org/abs/2303.09470
- Reference count: 5
- Primary result: NCOD achieves significant improvements in classification accuracy on CIFAR-100 and mini WebVision datasets under both synthetic and realistic label noise compared to state-of-the-art methods.

## Executive Summary
This paper introduces NCOD, a novel method for training deep learning models in the presence of noisy labels. The approach leverages class embeddings—average representations of each class in latent space—and an outlier discounting mechanism that reduces the influence of samples far from their class centroid, particularly those with noisy labels. A learnable parameter u is introduced to adaptively discount the contribution of outliers, improving robustness during training. Experiments on CIFAR-100 and mini WebVision datasets with both synthetic and realistic label noise show that NCOD outperforms state-of-the-art methods, achieving significant improvements in classification accuracy across varying noise levels. The method does not require anchor points or prior noise rate estimation, making it practical for real-world applications. Code is available at https://github.com/wanifarooq/NCOD.

## Method Summary
NCOD trains deep learning models with noisy labels by combining class embeddings with a learnable outlier discounting mechanism. The method computes class embeddings as average representations of each class in latent space, then uses sample-similarity to class centroid as a soft label replacing hard noisy labels. A learnable parameter u is optimized to reduce the loss contribution of samples with low similarity to their class centroid. During training, u is updated via a regularization term that penalizes large differences between network prediction and hard label. Class embeddings are dynamically updated each epoch by down-weighting samples with high u values, progressively reducing contamination by noisy samples. The approach is evaluated on CIFAR-100 and mini WebVision datasets under symmetric and asymmetric label noise.

## Key Results
- NCOD achieves state-of-the-art performance on CIFAR-100 under both symmetric and asymmetric label noise across multiple noise rates (20%-80%)
- Significant accuracy improvements demonstrated on mini WebVision dataset with realistic web-crawled noisy labels
- Method shows robust performance without requiring anchor points or prior noise rate estimation
- Code implementation available for reproducibility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The class embedding mechanism allows the model to use sample-similarity to class centroid as a soft label, replacing hard noisy labels during training.
- Mechanism: For each class, a centroid in latent space is computed by averaging all samples' representations. Each sample's similarity to its class centroid becomes its soft label for loss computation, reducing reliance on corrupted one-hot labels.
- Core assumption: Samples closer to their class centroid in latent space are more likely to have correct labels, especially in early training epochs.
- Evidence anchors:
  - [abstract] "...leverages the distance to class centroids in the latent space and incorporates a discounting mechanism, aiming to diminish the influence of samples that lie distant from all class centroids."
  - [section 4.1] "We propose to use the similarity between a sample and a summary of all the samples in the training dataset belonging to the same class as soft-label."
  - [corpus] Weak; neighboring works focus on sample selection or weighting, not centroid-based soft labels.
- Break condition: If centroids are dominated by noisy samples early in training, the soft labels will be unreliable and mislead the model.

### Mechanism 2
- Claim: The learnable parameter u acts as an outlier discounting factor, reducing the loss contribution of samples with low similarity to their class centroid.
- Mechanism: A per-sample scalar u is optimized to minimize a regularization term that penalizes large differences between the network prediction and the hard label. As training progresses and noisy samples drift away from centroids, u increases, reducing their impact on the main loss.
- Core assumption: The mismatch between predicted probability and hard label correlates with label noise, so u can learn to identify and discount noisy samples.
- Evidence anchors:
  - [section 4.2] "We exploit this variable as a regularization threshold to avoid our model overﬁtting on samples with very small similarities."
  - [section 5] "The parameter u tends to measure exactly this difference y−f(x,θ), therefore, in the 'early stage of training' it will be kept small for clean samples, and it will increase for noisy ones."
  - [corpus] Missing direct evidence; most neighboring works use fixed or heuristically set weights.
- Break condition: If u fails to distinguish noisy from clean samples, noisy examples continue to dominate the loss, harming generalization.

### Mechanism 3
- Claim: Dynamically updating class embeddings by down-weighting samples with high u values reduces contamination of centroids by noisy samples over epochs.
- Mechanism: In each epoch, only the subset of samples with the lowest u values is used to recompute class embeddings. This proportion decreases linearly, ensuring centroids are increasingly informed by likely-clean samples.
- Core assumption: Samples with low u are more likely to be clean, so excluding high-u samples improves centroid quality.
- Evidence anchors:
  - [section 4.2] "we gradually decrease the number of samples used choosing the subset of samples from class c that correspond to the lowest values of u."
  - [section 5] "Therefore, in the 'early stage of training' it will be kept small for clean samples, and it will increase for noisy ones."
  - [corpus] Weak; few works dynamically filter training examples for centroid computation.
- Break condition: If too many clean samples are inadvertently excluded, centroids become biased and degrade performance.

## Foundational Learning

- Concept: Class centroids in latent space represent class prototypes.
  - Why needed here: They provide a reference for measuring intra-class consistency and enable soft labeling based on similarity.
  - Quick check question: How is a class centroid computed from embeddings in this method?
- Concept: Learnable sample weights to down-weight outliers.
  - Why needed here: Standard losses treat all samples equally; outlier weights allow the model to focus on likely-clean data.
  - Quick check question: What regularization term drives the learning of the per-sample weight u?
- Concept: Distance-based similarity as a probabilistic soft label.
  - Why needed here: Replaces brittle one-hot labels corrupted by noise with a continuous similarity score.
  - Quick check question: Why is the similarity clipped at zero before being used as a soft label?

## Architecture Onboarding

- Component map:
  - Backbone network (e.g., ResNet34/PreActResNet18) -> embedding extractor
  - Class embedding store: one vector per class, updated each epoch
  - Per-sample scalar u: initialized small, updated by SGD on L2 term
  - Loss function: L1 = cross-entropy(softmax(pred), similarity-soft-label) + u·hard-label; L2 = ||pred + u·hard-label − hard-label||²
  - Optional consistency and class-balance regularizers (NCOD+)

- Critical path:
  1. Forward pass -> embedding extraction
  2. Compute similarity to class centroid -> soft label
  3. Compute L1 with u·hard-label scaling
  4. Compute L2 for u update
  5. Backpropagate: θ via L1, u via L2 only
  6. Update class embeddings using low-u samples

- Design tradeoffs:
  - Using all samples for centroid init vs. only low-u samples: more data vs. cleaner centroids
  - Linear decay of sample proportion vs. fixed proportion: adaptive vs. simpler
  - Adding consistency regularization: better generalization vs. extra compute

- Failure signatures:
  - Accuracy plateaus or drops after early epochs: centroids corrupted or u not learning
  - u values remain uniformly small: model cannot distinguish noise
  - High variance in class embeddings across epochs: unstable centroid computation

- First 3 experiments:
  1. CIFAR-100 with 50% symmetric noise, PreActResNet18, no u or centroids (baseline CE)
  2. CIFAR-100, 50% noise, with centroids only (no u)
  3. CIFAR-100, 50% noise, full NCOD (centroids + u)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal form and function of the discounting parameter u in different noise scenarios?
- Basis in paper: [inferred] The paper uses a linear decrease in the proportion of samples used to compute class embeddings, but notes that a better approach could be to use the percentage of clean data in the final percentage of data used to compute the mean if the noise rate is known.
- Why unresolved: The paper does not explore different discounting functions or how the optimal function might depend on the noise rate or type.
- What evidence would resolve it: Experiments comparing different discounting functions (e.g., exponential, polynomial) and their performance under various noise rates and types.

### Open Question 2
- Question: How does NCOD perform under instance-dependent label noise compared to instance-independent noise?
- Basis in paper: [explicit] The paper mentions that while the method handles both types of noise, experiments only used instance-independent noise and suggests future work on instance-dependent noise like that in the CIFAR-10 N dataset.
- Why unresolved: The paper does not include experiments on instance-dependent label noise, which is more realistic and challenging.
- What evidence would resolve it: Experiments applying NCOD to datasets with instance-dependent noise and comparing its performance to other methods under such conditions.

### Open Question 3
- Question: How does the performance of NCOD change when using different network architectures or larger models?
- Basis in paper: [inferred] The paper uses ResNet34 and PreActResNet18/34 architectures and notes that retraining a pre-trained model for a few epochs can improve performance, but does not explore different architectures or model sizes.
- Why unresolved: The paper does not investigate the impact of using more complex or larger architectures on the method's effectiveness.
- What evidence would resolve it: Experiments applying NCOD to various network architectures (e.g., ResNeXt, EfficientNet) and model sizes to assess performance changes.

## Limitations

- The effectiveness of class embeddings depends critically on their initialization quality; no ablation shows performance when using random or noisy initial centroids.
- The learnable parameter u is updated via a separate loss term that penalizes deviation from hard labels; however, the paper does not validate whether u actually correlates with ground-truth noise labels.
- The claim that centroids become "cleaner" over epochs relies on the assumption that low-u samples are truly clean, but this is not experimentally verified with known noise patterns.

## Confidence

- Mechanism 1 (soft labeling via centroid similarity): Medium - plausible but not directly validated.
- Mechanism 2 (learnable u for outlier discounting): Low - the learning signal for u is indirect and unproven.
- Mechanism 3 (dynamic centroid update via low-u filtering): Low - the benefit of this filtering is not isolated in ablations.

## Next Checks

1. Ablation: Run NCOD with fixed (non-learnable) u values to confirm the necessity of adaptive outlier weighting.
2. Ablation: Initialize centroids from noisy samples and track evolution to test whether centroids improve over epochs.
3. Diagnostic: Correlate u values with known noisy labels in synthetic experiments to verify u identifies corrupted samples.