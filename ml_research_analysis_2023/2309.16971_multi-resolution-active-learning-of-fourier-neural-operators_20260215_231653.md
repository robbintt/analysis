---
ver: rpa2
title: Multi-Resolution Active Learning of Fourier Neural Operators
arxiv_id: '2309.16971'
source_url: https://arxiv.org/abs/2309.16971
tags:
- learning
- cost
- function
- active
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a multi-resolution active learning framework
  for Fourier neural operators (FNO) to reduce the cost of data collection in scientific
  machine learning. The key idea is to dynamically select input functions and resolutions
  to optimize learning efficiency while minimizing data acquisition cost.
---

# Multi-Resolution Active Learning of Fourier Neural Operators

## Quick Facts
- arXiv ID: 2309.16971
- Source URL: https://arxiv.org/abs/2309.16971
- Authors: Authors not specified
- Reference count: 25
- Key outcome: Multi-resolution active learning framework for FNO that dynamically selects input functions and resolutions to optimize learning efficiency while minimizing data acquisition cost, outperforming competing methods on four benchmark operator learning tasks.

## Executive Summary
This paper introduces a multi-resolution active learning framework for Fourier neural operators (FNO) that addresses the high cost of data collection in scientific machine learning. The method dynamically selects both input functions and resolutions during training to optimize learning efficiency. By extending FNO with resolution embeddings and using ensemble Monte-Carlo for posterior inference, the framework can express how resolution choices affect predictive distributions. A novel cost annealing framework prevents over-penalizing high-resolution queries early in the learning process, enabling better exploration of the resolution space.

## Method Summary
The method proposes a probabilistic multi-resolution FNO with resolution embedding that captures how resolution choice affects predictive distributions. The framework uses ensemble Monte Carlo posterior inference (M=5 models) and implements an active learning acquisition function based on utility-cost ratio maximization. The utility computation leverages moment matching and the matrix determinant lemma for efficiency. A cost annealing schedule (exponential decay: c(t)=exp(-αt)) dynamically adjusts resolution costs to avoid early-stage over-penalization of high-resolution queries. The method is evaluated on four benchmark operator learning tasks including Burgers', Darcy flow, nonlinear diffusion, and Navier-Stokes equations.

## Key Results
- Consistently outperforms competing methods in prediction accuracy and data cost efficiency across all four benchmark tasks
- MRA-FNO achieves better uncertainty quantification with significantly lower negative log likelihood compared to probabilistic versions of FNO
- Cost annealing framework successfully prevents getting stuck at low resolutions during early learning stages
- The method demonstrates superior data efficiency, requiring fewer high-cost high-resolution samples while maintaining accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The resolution embedding enables the model to capture how resolution choice affects predictive distributions.
- Mechanism: By appending a resolution embedding to input function samples, the FNO learns to modulate both mean and variance predictions based on resolution, allowing it to express higher uncertainty at low resolutions and lower uncertainty at high resolutions.
- Core assumption: The resolution embedding provides sufficient information for the model to differentiate resolution-dependent effects.
- Evidence anchors:
  - [abstract]: "To capture the influence of the resolution choice on the predictive distribution, we append a resolution embedding to the samples of the input function."
  - [section]: "Both the predictive mean and variance are not only dependent on the input fn but also up to the resolution choice rn."

### Mechanism 2
- Claim: Cost annealing prevents early-stage over-penalization of high-resolution queries.
- Mechanism: By dynamically adjusting resolution costs using a decaying function, the method avoids getting stuck at low-resolution queries when mutual information values are similar across resolutions but costs differ greatly.
- Core assumption: Early-stage mutual information measurements are insufficient to distinguish resolution quality differences.
- Evidence anchors:
  - [abstract]: "We develop a cost annealing framework to avoid over-penalizing high-resolution queries at the early stage."
  - [section]: "This is because at the early stage, the training data is few, and the mutual information does not differ much for candidates at different resolutions."

### Mechanism 3
- Claim: Ensemble Monte-Carlo provides better uncertainty quantification than alternative inference methods.
- Mechanism: Using multiple independent point estimates from the same model trained with different initializations creates a mixture of Gaussians that better captures predictive uncertainty.
- Core assumption: The ensemble captures meaningful variation in predictions rather than just noise.
- Evidence anchors:
  - [section]: "We have shown the advantage of our method in several benchmark operator learning tasks... MRA-FNO consistently outperforms all the probabilistic versions of FNO by a large margin in test log likelihood."

## Foundational Learning

- Concept: Fourier Neural Operators
  - Why needed here: FNO provides the base architecture for learning function-to-function mappings efficiently using FFT-based convolutions.
  - Quick check question: What is the key computational advantage of using FFT in FNO compared to standard convolutions?

- Concept: Active Learning with Utility-Cost Ratio
  - Why needed here: The framework needs to balance information gain against data acquisition costs when selecting new training examples.
  - Quick check question: How does maximizing utility-cost ratio differ from pure information maximization in active learning?

- Concept: Multi-resolution Data and Multi-fidelity Learning
  - Why needed here: The method leverages both cheap low-resolution and expensive high-resolution data to optimize learning efficiency.
  - Quick check question: What is the fundamental tradeoff between low-resolution and high-resolution data in terms of cost and accuracy?

## Architecture Onboarding

- Component map: Input → Resolution embedding → FNN lifting → Fourier layers → Dual output branches → Ensemble inference → Active learning acquisition
- Critical path: Input → Resolution embedding → FNO layers → Dual output branches → Ensemble inference → Active learning acquisition
- Design tradeoffs:
  - Ensemble size M vs. computational cost: Larger M gives better uncertainty but increases training time
  - Resolution embedding complexity: Simple one-hot vs. more complex positional encodings
  - Cost annealing schedule speed: Balancing early exploration vs. late exploitation
- Failure signatures:
  - Stuck at low resolutions: Indicates cost annealing schedule too aggressive or mutual information not discriminative enough
  - High variance predictions: May indicate insufficient ensemble size or poor model training
  - Slow convergence: Could indicate resolution embedding not capturing necessary information
- First 3 experiments:
  1. Test resolution embedding effectiveness: Train with and without resolution embeddings on fixed multi-resolution dataset and compare predictive performance
  2. Validate cost annealing: Run active learning with different annealing schedules and verify it prevents early-stage low-resolution trapping
  3. Benchmark ensemble vs. alternatives: Compare ensemble inference against dropout, SGLD, and VI on uncertainty quantification tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of embedding method (one-hot vs positional encodings) for resolution representation affect the predictive performance of the MRA-FNO model?
- Basis in paper: [explicit] The paper mentions they tried positional encodings as an alternative to one-hot encoding for resolution embedding and found "the performance is close."
- Why unresolved: The paper does not provide quantitative comparisons between different embedding methods or explore the impact of embedding dimension on model performance.
- What evidence would resolve it: Systematic experiments comparing one-hot, positional encodings, and other embedding methods (e.g., learned embeddings) across different operator learning tasks, with analysis of how embedding dimensionality affects performance.

### Open Question 2
- Question: What is the optimal ensemble size for balancing computational efficiency and prediction accuracy in the MRA-FNO model?
- Basis in paper: [explicit] The paper states they used an ensemble size of M=5 but does not explore how varying M affects performance or computational cost.
- Why unresolved: The paper only reports results for a single ensemble size, leaving open questions about the trade-offs between model accuracy, uncertainty quantification, and computational resources at different ensemble sizes.
- What evidence would resolve it: Experiments systematically varying ensemble size M across different tasks, measuring prediction accuracy (L2 error, NLL), computational time, and uncertainty calibration metrics to identify optimal M values.

### Open Question 3
- Question: How does the cost annealing schedule's decay rate α impact the long-term prediction accuracy and data efficiency across different operator learning tasks?
- Basis in paper: [explicit] The paper experiments with different α values (0.002, 0.005, 0.01, 0.02, 0.5, 1.0) and observes performance differences, but does not establish general principles for choosing α.
- Why unresolved: The paper shows α affects performance but doesn't provide guidelines for selecting α based on task characteristics (e.g., resolution cost ratios, problem complexity) or develop adaptive methods for determining α.
- What evidence would resolve it: Comprehensive analysis of how α should scale with cost ratios between resolutions, task complexity, and data availability, potentially leading to task-specific or adaptive α selection methods.

## Limitations
- Scalability concerns for larger resolution problems (e.g., 256×256 or higher) due to computational costs of ensemble inference and moment-matching approximation
- Cost annealing framework effectiveness across different problem domains needs more empirical validation and may be sensitive to hyperparameter tuning
- Assumption that resolution embedding can adequately capture all resolution-dependent effects may not hold for problems with complex resolution-accuracy relationships

## Confidence
- High confidence: The theoretical framework for multi-resolution active learning and the resolution embedding mechanism are well-established and logically sound
- Medium confidence: The cost annealing framework's effectiveness across different problem domains needs more empirical validation
- Medium confidence: The ensemble Monte Carlo inference method's superiority over alternatives requires more direct comparative studies

## Next Checks
1. **Scalability Test**: Evaluate the framework on larger resolution problems (e.g., 256×256 or higher) to assess computational feasibility and verify if the performance advantages persist at scale
2. **Annealing Schedule Robustness**: Systematically test different cost annealing schedules (linear, sigmoid, exponential) across multiple benchmark problems to identify optimal strategies and sensitivity to hyperparameters
3. **Alternative Inference Comparison**: Conduct head-to-head comparisons of ensemble Monte Carlo against other uncertainty quantification methods (dropout, SGLD, variational inference) on the same benchmark tasks, measuring both prediction accuracy and computational overhead