---
ver: rpa2
title: Using Automated Algorithm Configuration for Parameter Control
arxiv_id: '2302.12334'
source_url: https://arxiv.org/abs/2302.12334
tags:
- tuned
- parameter
- algorithm
- best
- tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work proposes a new dynamic algorithm configuration (DAC)\
  \ benchmark based on the (1 + (\u03BB, \u03BB)) genetic algorithm solving OneMax.\
  \ Unlike static tuning, DAC learns a policy that adapts the population size parameter\
  \ \u03BB dynamically."
---

# Using Automated Algorithm Configuration for Parameter Control

## Quick Facts
- arXiv ID: 2302.12334
- Source URL: https://arxiv.org/abs/2302.12334
- Reference count: 40
- Key outcome: Automated algorithm configuration with binning and cascading enables learning of policies that adapt the population size parameter Î» dynamically, outperforming static tuning and theoretical baselines on the (1+(Î»,Î»)) GA for OneMax.

## Executive Summary
This work addresses the challenge of applying automated algorithm configuration to dynamic algorithm configuration (DAC) problems. The authors demonstrate that a naive application of static tuning fails on the (1+(Î»,Î»)) genetic algorithm for OneMax due to a complex, non-smooth parameter landscape. They introduce a binning and cascading strategy that partitions the fitness range into intervals, tunes each separately, and leverages prior results to accelerate convergence. The approach successfully discovers adaptive policies that outperform both static configurations and theoretical baselines.

## Method Summary
The authors apply irace, an automated algorithm configuration tool, to learn dynamic policies that map fitness values to population size parameter Î» for the (1+(Î»,Î»)) GA on OneMax. To overcome the challenges of large parameter spaces and non-smooth landscapes, they implement a binning approach that partitions the objective space into consecutive intervals, with each bin tuned separately. A cascading strategy chains tuning runs by using the best configuration from k bins as the starting point for k+1 bins. Expected runtimes are computed using dynamic programming, and optimal policies are numerically approximated for comparison. The method is evaluated across problem sizes n=10 to 2000.

## Key Results
- Naive static configuration fails on DAC problems due to complex landscapes and large parameter spaces
- Binning and cascading strategy enables discovery of policies that outperform theoretical baselines
- Numerical approximation reveals a small but consistent gap between binned and unrestricted optimal policies
- Performance improves with more bins, though optimization becomes harder

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Binning and cascading overcome large parameter spaces by reducing search space and leveraging prior results
- Mechanism: Binning partitions fitness range into k intervals, reducing parameters from n to k. Cascading uses best configuration from k bins as starting point for k+1 bins, accelerating convergence
- Core assumption: Parameter values within a fitness bin can be effectively represented by a single value
- Evidence anchors:
  - "To reduce the parameter space, we define a binning approach where we partition the objective space [0..n] into k consecutive bins..."
  - "The cascading gives each tuning a head start by leveraging results of the previous step."
- Break condition: If fitness-to-parameter relationship is highly non-linear within bins, binned policy will underperform

### Mechanism 2
- Claim: Non-smooth parameter landscape necessitates dynamic approaches
- Mechanism: Population size parameter Î» exhibits abrupt performance changes at half-integer values due to rounding to Î› = âŒŠÎ»âŒ‰, creating rugged landscape that challenges gradient-based methods
- Core assumption: Performance impact of rounding Î» to Î› is significant enough to create distinct local optima
- Evidence anchors:
  - "One can easily observe the saw-like shape of the plot, which introduces multiple local optima and a complicated search space..."
  - "However, when only the combinations Î› = âŒŠÎ»âŒ‰ are considered, it can happen that the best Î» is at either of the interval endpoints or somewhere in the middle..."
- Break condition: If rounding effects are negligible or landscape becomes smooth in higher dimensions

### Mechanism 3
- Claim: Dynamic programming computes near-optimal policies for strong baselines
- Mechanism: Dynamic programming computes expected runtimes backward from optimum, optimizing Î» for each fitness value based on future state values. For binned policies, numerical optimizer finds optimal bin parameters simultaneously
- Core assumption: Dynamic programming accurately captures stochastic dynamics and can find policies close to global optimum
- Evidence anchors:
  - "Our algorithm essentially considers all possible event chains that the (1 + (Î», Î»)) GA performs, computes their probabilities and saves the computational effort when possible."
  - "It may be tempting to use dynamic programming in a similar way to compute also the best binned policies. However, this time it is not so straightforward."
- Break condition: If state space grows too large or stochastic behavior cannot be accurately modeled

## Foundational Learning

- Concept: Dynamic Algorithm Configuration (DAC)
  - Why needed here: Framework for learning policies that adapt algorithm parameters during execution, which is the core problem addressed
  - Quick check question: What distinguishes DAC from static algorithm configuration?

- Concept: Parameter control landscape analysis
  - Why needed here: Understanding landscape structure (smooth vs. rugged) is crucial for selecting appropriate optimization methods
  - Quick check question: How does the rounding of Î» to Î› create a rugged landscape?

- Concept: Dynamic programming for expected runtime computation
  - Why needed here: Computing expected runtimes enables comparison of different approaches and calculation of optimal baselines
  - Quick check question: Why can we compute expected runtimes backward from the optimum in this setting?

## Architecture Onboarding

- Component map:
  - irace (automated algorithm configuration tool) -> Binning module (partitions fitness range) -> Cascading module (chains tuning runs) -> Dynamic programming engine (computes expected runtimes) -> Numerical optimizer (finds optimal binned policies) -> Evaluation framework (compares policies)

- Critical path:
  1. Define binning scheme for fitness range
  2. Run irace with cascading to find tuned policy
  3. Compute expected runtime using dynamic programming
  4. Compare tuned policy against baselines (theory_dyn, best binned, best unrestricted)

- Design tradeoffs:
  - More bins â†’ better policy quality but harder optimization
  - Binning â†’ reduced parameter space but potential performance loss
  - Cascading â†’ faster convergence but sequential dependency
  - Numerical optimization â†’ precise baselines but computational cost

- Failure signatures:
  - Poor performance improvement with additional bins suggests landscape is too rugged for simple binning
  - Instability in tuned_dyn without cascading indicates landscape has many local optima
  - Large gap between tuned and best policies suggests optimization method limitations

- First 3 experiments:
  1. Run tuned_dyn with 1 bin on n=500 to establish baseline performance
  2. Run tuned_dyn with 5 bins on n=500 to test binning effectiveness
  3. Run tuned_dyn_cas_bin with 5 bins on n=500 to evaluate cascading benefit

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does tunability of evolutionary algorithms change when using stochastic rounding instead of deterministic rounding for parameter values?
- Basis in paper: The paper discusses how deterministic rounding of the parameter ğœ† to obtain the integer population size Î› is likely to be disruptive to parameter tuning, and suggests that stochastic rounding may be nicer to parameter tuning
- Why unresolved: The paper mentions this as a potential direction for future research but does not provide experimental results comparing the two approaches
- What evidence would resolve it: Experimental results comparing tunability using deterministic vs stochastic rounding for parameter values

### Open Question 2
- Question: How does tunability of the (1 + (ğœ†, ğœ†)) GA change when decoupling its parameters?
- Basis in paper: The paper suggests that decoupling the parameters of the (1 + (ğœ†, ğœ†)) GA could lead to new DAC benchmarks requiring control of multiple parameters simultaneously
- Why unresolved: The paper does not provide experimental results on tunability of the decoupled (1 + (ğœ†, ğœ†)) GA
- What evidence would resolve it: Experimental results on tunability of (1 + (ğœ†, ğœ†)) GA with decoupled parameters

### Open Question 3
- Question: How does performance of automated algorithm configuration approach using irace change when increasing problem size beyond 2000?
- Basis in paper: The paper conducts experiments with problem sizes up to 2000, and results suggest performance degrades as problem size increases
- Why unresolved: The paper does not provide experimental results for problem sizes larger than 2000
- What evidence would resolve it: Experimental results on performance for problem sizes larger than 2000

## Limitations

- Empirical validation limited to single algorithm (1+(Î»,Î»)) GA on OneMax, may not generalize to other algorithms or problem domains
- Binning approach assumes parameter values within fitness intervals can be represented by single values, but optimal mapping may be more complex
- Cascading strategy's effectiveness depends on assumption that prior tuning results provide useful starting points for subsequent bins

## Confidence

- **High Confidence**: Observation that static configuration fails on this DAC problem due to complex landscape and large parameter space is well-supported by empirical evidence
- **Medium Confidence**: Binning and cascading strategy improves performance compared to naive approaches, though magnitude of improvement varies with problem size
- **Medium Confidence**: Numerical approximation of optimal policies shows consistent but small gap between binned and unrestricted approaches, though exact causes require further investigation

## Next Checks

1. Test binning and cascading approach on additional dynamic algorithm configuration problems beyond OneMax to assess generalizability
2. Analyze sensitivity of performance to bin size and cascading parameters to establish robust design principles
3. Compare binned policy performance against reinforcement learning approaches for DAC to evaluate relative effectiveness