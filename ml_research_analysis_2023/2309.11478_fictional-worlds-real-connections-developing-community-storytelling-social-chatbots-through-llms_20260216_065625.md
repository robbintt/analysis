---
ver: rpa2
title: 'Fictional Worlds, Real Connections: Developing Community Storytelling Social
  Chatbots through LLMs'
arxiv_id: '2309.11478'
source_url: https://arxiv.org/abs/2309.11478
tags:
- community
- story
- catherine
- social
- david
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduced Storytelling Social Chatbots (SSCs) driven
  by GPT-3 to enhance engagement and believability in online gaming communities. SSCs
  presented live stories with interactive choices, allowing community members to influence
  narrative outcomes.
---

# Fictional Worlds, Real Connections: Developing Community Storytelling Social Chatbots through LLMs

## Quick Facts
- arXiv ID: 2309.11478
- Source URL: https://arxiv.org/abs/2309.11478
- Authors: 
- Reference count: 14
- Key outcome: Catherine, an SSC character, demonstrated significantly higher emotional engagement and believability compared to a non-storytelling chatbot benchmark.

## Executive Summary
This paper introduces Storytelling Social Chatbots (SSCs) driven by GPT-3 to enhance engagement and believability in online gaming communities. SSCs present live stories with interactive choices, allowing community members to influence narrative outcomes. The character Catherine showed significantly higher emotional engagement and believability compared to a non-storytelling chatbot benchmark, Jerry. Qualitative feedback highlighted Catherine's distinct personality, emotional depth, and ability to foster community interactions as key strengths. The study underscores the value of storytelling and character-driven design in creating engaging and believable social chatbots for community contexts.

## Method Summary
The study developed two SSC characters (David and Catherine) with defined personalities and story backgrounds using a three-step story engineering workflow: character creation and story development, presenting live stories to the community, and interactive communication with community members. The SSCs were deployed on Discord using GPT-3 with customized prompts and a clue finder module for static replies. User interactions and feedback were collected via questionnaires (N=15) and interviews (N=8) to assess improvements in engagement and believability compared to a non-storytelling benchmark chatbot.

## Key Results
- Catherine demonstrated significantly higher emotional engagement and believability compared to benchmark chatbot Jerry
- Story engineering transforms static characters into dynamic social entities through interactive storytelling
- SSCs foster indirect community connections and richer social experiences

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Integrating fictional character personas into LLMs enhances believability and engagement by making AI responses emotionally resonant and contextually coherent
- Core assumption: Users perceive AI-generated content as more believable when it consistently reflects a coherent personality and backstory
- Evidence anchors:
  - [abstract]: "storytelling significantly enhances the engagement and believability of SCs in community settings"
  - [section]: "Believable characters can create better player experiences, and accordingly, believable SC should bring a more engaging experience to a community"
- Break condition: If character responses deviate from established personality or backstory, users may lose sense of interaction with coherent entity

### Mechanism 2
- Claim: Story engineering transforms static fictional characters into dynamic social entities by incorporating interactive storytelling elements
- Core assumption: User participation in shaping character's story increases their emotional investment and sense of connection
- Evidence anchors:
  - [abstract]: "Catherine, an SSC character, demonstrated significantly higher emotional engagement and believability compared to a non-storytelling chatbot benchmark"
  - [section]: "Players were motivated to interact with Catherine, likely attributed to the changes in her responses"
- Break condition: If story progression is too rigid or lacks meaningful choices, users may feel less involved and disengaged

### Mechanism 3
- Claim: Deploying SSCs in community settings amplifies social interactions by leveraging existing social context and group dynamics
- Core assumption: Social chatbots can enhance community engagement by acting as catalysts for group interactions
- Evidence anchors:
  - [abstract]: "Catherine's distinct personality, emotional depth, and ability to foster community interactions as key strengths"
  - [section]: "Catherine also facilitated indirect connections within the community... provided richer social experiences"
- Break condition: If community is not receptive or character's presence disrupts group dynamics, intended social benefits may not materialize

## Foundational Learning

- Concept: Believability in AI characters
  - Why needed here: Understanding what makes AI character believable is essential for designing SSCs that users perceive as authentic and engaging
  - Quick check question: What are key components that contribute to virtual agent's believability according to literature?

- Concept: Interactive storytelling
  - Why needed here: Interactive storytelling allows users to influence narrative, increasing their engagement and emotional investment in character
  - Quick check question: How does user participation in story progression affect their perception of AI character?

- Concept: Community dynamics
  - Why needed here: Deploying SSCs in community settings requires understanding how social interactions and group dynamics influence user engagement
  - Quick check question: In what ways can social chatbot act as catalyst for community interactions?

## Architecture Onboarding

- Component map: Character and story creation module -> Live story presentation interface -> Interactive communication system (Words filter -> Clue finder -> LLM configuration with character prompt, live story prompt, dialogue history)
- Critical path: 1. Define character traits and backstory 2. Develop story arcs and interactive elements 3. Implement communication system with LLM integration 4. Deploy in community and monitor interactions
- Design tradeoffs:
  - Openness vs. consistency: Balancing LLM's generative abilities with need for coherent character portrayal
  - Fixed responses vs. dynamic content: Using predefined responses for accuracy but risking repetitiveness
  - Community engagement vs. moderation: Encouraging interactions while managing inappropriate content
- Failure signatures:
  - Inconsistent character behavior leading to loss of believability
  - Low user engagement due to uninteresting story progression
  - Community disruption or negative feedback
- First 3 experiments:
  1. Test character believability with small user group, gathering feedback on personality consistency
  2. Evaluate story engagement by measuring user participation in interactive story elements
  3. Assess community impact by analyzing changes in group interactions and sentiment

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does believability and engagement of social chatbots change when incorporating multiple AI characters with distinct personalities in community setting?
- Basis in paper: [explicit] Paper discusses development of two distinct characters (David and Catherine) but does not explore scenarios with multiple characters interacting simultaneously or combined effect on community engagement
- Why unresolved: Study focused on individual character development and evaluation rather than exploring dynamics of multiple characters coexisting and interacting within same community context
- What evidence would resolve it: Comparative studies analyzing community engagement metrics (participation rates, interaction frequency) between single-character and multi-character scenarios, along with qualitative assessments of community member perceptions of believability in each case

### Open Question 2
- Question: What are long-term effects of sustained interactions with storytelling social chatbots on community members' emotional attachment and community involvement?
- Basis in paper: [inferred] While study demonstrated short-term engagement and emotional responses, it was limited to brief experimental periods (3-4 days) without examining sustained interaction over extended periods
- Why unresolved: Temporal scope of study was limited, preventing analysis of how relationships and engagement patterns evolve over months or years of continued interaction with chatbots
- What evidence would resolve it: Longitudinal studies tracking same community members' interaction patterns, emotional investment, and community participation levels over extended periods (6+ months) with regular checkpoints for qualitative and quantitative assessment

### Open Question 3
- Question: How can storytelling social chatbots be designed to maintain narrative coherence while allowing for user-driven content generation and unexpected AI improvisation?
- Basis in paper: [explicit] Paper discusses challenges with LLM-generated content ("made-up" information) that required manual intervention and story adjustments, highlighting tension between controlled narratives and AI improvisation
- Why unresolved: Study implemented system where most unexpected AI outputs were either manually corrected or incorporated into story, but did not develop systematic approach for balancing narrative control with AI creativity
- What evidence would resolve it: Development and testing of frameworks that establish boundaries for AI improvisation while maintaining story coherence, validated through user studies measuring narrative satisfaction and engagement across different levels of narrative control versus AI freedom

## Limitations

- Study findings based on small sample size (N=15 questionnaires, N=8 interviews) from single online gaming community, limiting generalizability
- Character-driven design heavily depends on GPT-3's performance, which may vary across different LLM implementations or versions
- Study does not address potential ethical concerns around emotional manipulation through character design, nor does it explore long-term engagement beyond 6-day study period

## Confidence

**High Confidence**: Catherine demonstrated significantly higher emotional engagement and believability compared to benchmark chatbot (Jerry) - supported by both quantitative questionnaire data and qualitative interview responses from multiple participants

**Medium Confidence**: Story engineering transforms static characters into dynamic social entities through interactive storytelling - supported by participant feedback but relies on subjective assessments of engagement and emotional investment

**Low Confidence**: Deploying SSCs in community settings amplifies social interactions and fosters indirect connections among community members - primarily based on anecdotal evidence from interviews rather than systematic measurement of community dynamics

## Next Checks

1. **Replicate with Larger, Diverse Samples**: Conduct study across multiple communities with different demographics and interests, increasing sample sizes to 50+ participants per community to validate generalizability of findings

2. **Implement A/B Testing with Different Story Designs**: Create multiple variations of storytelling approaches (linear vs. branching narratives, different levels of user control) and measure engagement metrics across these conditions to isolate specific storytelling elements that drive engagement

3. **Longitudinal Study of Community Impact**: Track community metrics (message volume, member retention, sentiment analysis) over 3-6 months following SSC deployment to assess whether observed social benefits persist beyond initial novelty period