---
ver: rpa2
title: Speech-based Slot Filling using Large Language Models
arxiv_id: '2311.07418'
source_url: https://arxiv.org/abs/2311.07418
tags:
- llms
- slot
- prompt
- were
- fine-tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the use of large language models (LLMs)
  for slot filling with noisy automatic speech recognition (ASR) transcriptions. The
  proposed approach incorporates task-specific fine-tuning with low-rank adaptation
  and a linearised knowledge injection scheme that leverages N-best ASR hypotheses
  to provide dynamic contextual knowledge.
---

# Speech-based Slot Filling using Large Language Models

## Quick Facts
- arXiv ID: 2311.07418
- Source URL: https://arxiv.org/abs/2311.07418
- Reference count: 13
- Key outcome: 8.3% absolute SLU-F1 improvement over Flan-T5-base baseline with LLaMA-13B fine-tuning using LKI and N-best hypotheses

## Executive Summary
This paper addresses slot filling from noisy ASR transcriptions using LLMs through task-specific fine-tuning with LoRA and a linearised knowledge injection scheme. The approach leverages N-best ASR hypotheses to provide dynamic contextual knowledge and constraints valid slot values through linearized knowledge bases. Experiments on the SLURP dataset demonstrate significant improvements over strong baselines, achieving an 8.3% absolute SLU-F1 gain when using the Whisper medium model with 2000 training samples.

## Method Summary
The method reformulates slot filling as a sequence generation task and employs task-specific fine-tuning of LLMs using low-rank adaptation (LoRA) with N-best ASR hypotheses as input. A linearised knowledge injection (LKI) scheme converts knowledge bases into text format and injects them into prompts, providing constraints on valid slot values while incorporating ASR alternatives. The training process concatenates top K hypotheses from ASR systems into prompts, allowing the LLM to learn robustness to transcription errors. The approach uses LLaMA-13B with LoRA fine-tuning on 2000 training samples, generating slot-value pairs through greedy search with post-processing to extract JSON output.

## Key Results
- 8.3% absolute SLU-F1 improvement over Flan-T5-base baseline
- Significant performance gains across multiple ASR error rates on SLURP dataset
- LKI with N-best hypotheses (K=3) achieves optimal balance between robustness and precision
- Parameter-efficient adaptation with LoRA reduces trainable parameters from billions to thousands

## Why This Works (Mechanism)

### Mechanism 1
LoRA enables effective fine-tuning of LLMs with significantly fewer trainable parameters, avoiding overfitting on small datasets. By decomposing the parameter update matrix into two low-rank matrices (A and B), LoRA constrains updates to a low-dimensional subspace, reducing trainable parameters from billions to thousands while preserving adaptation capability. The core assumption is that essential task adaptation information can be captured in a low-rank subspace rather than requiring full parameter updates.

### Mechanism 2
LKI improves LLM performance by constraining generation to valid slot values and leveraging ASR N-best hypotheses for robustness. The approach converts external knowledge bases into text format and injects them into prompts, providing a constrained set of valid values for each slot type while incorporating N-best ASR hypotheses to provide alternative recognition paths. The core assumption is that LLMs benefit from explicit constraints on valid output space and can effectively utilize linearized knowledge when properly formatted in prompts.

### Mechanism 3
Using multiple ASR hypotheses during training improves LLM robustness to transcription errors by exposing the model to the uncertainty distribution in ASR outputs. The training process concatenates top K hypotheses from ASR systems into prompts, allowing the LLM to learn from multiple recognition paths and develop robustness to errors. The core assumption is that exposing the model to the distribution of ASR errors during training enables it to better handle similar errors during inference.

## Foundational Learning

- **Concept**: Slot filling as sequence generation task
  - Why needed here: Reformulates slot filling from sequence tagging to sequence generation, leveraging LLM capabilities for this task formulation
  - Quick check question: Why would sequence generation be preferred over sequence tagging for LLMs in this context?

- **Concept**: In-context learning mechanics
  - Why needed here: Understanding how LLMs can perform tasks without parameter updates by conditioning on task descriptions and examples in prompts
  - Quick check question: What limits the number of in-context examples that can be provided in a prompt?

- **Concept**: Knowledge base linearization
  - Why needed here: Converting structured knowledge (slot-value pairs) into plain text format that LLMs can process within prompts
  - Quick check question: How does the format of linearized knowledge affect LLM comprehension and utilization?

## Architecture Onboarding

- **Component map**: ASR system (Whisper) -> N-best hypothesis generator -> Prompt constructor -> LLM -> Post-processor
- **Critical path**: ASR transcription -> Prompt construction -> LLM inference -> Post-processing
- **Design tradeoffs**:
  - Context length vs. information richness: More examples and hypotheses improve performance but increase cost
  - Knowledge base completeness vs. prompt clarity: More entities provide better coverage but may introduce noise
  - Hypothesis count (K) vs. robustness: More hypotheses improve robustness but may confuse the model
- **Failure signatures**:
  - Low precision: LLM generating values not in knowledge base or outside valid ranges
  - Low recall: LLM missing valid slot values, especially for noisy transcriptions
  - Format errors: LLM failing to output valid JSON structure
  - Context overload: Performance degradation with excessive prompt length
- **First 3 experiments**:
  1. Test basic slot filling with reference transcription and no LKI to establish baseline
  2. Add LKI with single best hypothesis to measure knowledge injection impact
  3. Test with N-best hypotheses (K=3) and LKI to evaluate combined robustness approach

## Open Questions the Paper Calls Out

### Open Question 1
How can the effectiveness of long context be improved in LLMs beyond simply increasing the maximum sequence length? The paper acknowledges this as a limitation but does not provide a solution or further investigation into how to improve the effectiveness of long context in LLMs.

### Open Question 2
What are the specific biases inherited from the language models used in the experiments, and how do they affect the slot filling task? The paper mentions that the framework inherits biases from the language models used but does not elaborate on what these biases are or their impact on the task.

### Open Question 3
How does the performance of the proposed linearised knowledge injection (LKI) scheme vary with different knowledge base sizes or qualities? The paper demonstrates the effectiveness of the LKI scheme but does not explore how variations in the knowledge base (size or quality) affect this performance.

## Limitations
- Effectiveness depends heavily on knowledge base quality and completeness, potentially struggling with open-vocabulary slot values
- Optimal LoRA rank (r=8) was not systematically explored, leaving uncertainty about optimal parameter-efficiency tradeoffs
- N-best hypothesis concatenation strategy introduces critical hyperparameter (K) whose optimal value depends on ASR error characteristics and domain

## Confidence

**High Confidence**: The core mechanism of using LoRA for parameter-efficient fine-tuning of LLMs is well-established in the literature, and the empirical improvements over the Flan-T5 baseline are clearly demonstrated.

**Medium Confidence**: The LKI scheme's effectiveness relies on specific formatting and the assumption that linearized knowledge provides sufficient guidance, which may not generalize across all slot-filling domains or knowledge base structures.

**Medium Confidence**: The benefit of N-best hypothesis concatenation during training is demonstrated, but the optimal strategy for incorporating ASR uncertainty remains an open question.

## Next Checks

1. **Knowledge Base Completeness Analysis**: Systematically measure how performance degrades as the knowledge base becomes incomplete or contains increasing proportions of irrelevant entities to establish robustness bounds for the LKI approach.

2. **Cross-Domain Generalization Test**: Evaluate the fine-tuned model on a different slot-filling dataset with distinct slot types and value distributions to assess whether the adaptation strategy generalizes beyond the SLURP domain.

3. **Prompt Length Sensitivity Analysis**: Quantify the performance tradeoff as the number of in-context examples and N-best hypotheses increases, measuring both accuracy and inference latency to establish practical limits for deployment.