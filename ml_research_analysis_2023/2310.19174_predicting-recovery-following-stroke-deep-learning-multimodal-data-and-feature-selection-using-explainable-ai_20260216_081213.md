---
ver: rpa2
title: 'Predicting recovery following stroke: deep learning, multimodal data and feature
  selection using explainable AI'
arxiv_id: '2310.19174'
source_url: https://arxiv.org/abs/2310.19174
tags:
- data
- images
- accuracy
- were
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of predicting post-stroke aphasia
  recovery using deep learning. The core method involves training convolutional neural
  networks on images that combine regions-of-interest extracted from MRI scans with
  symbolic representations of tabular data.
---

# Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI

## Quick Facts
- arXiv ID: 2310.19174
- Source URL: https://arxiv.org/abs/2310.19174
- Reference count: 6
- Best model: 8 ROIs + 3 tabular features, balanced accuracy 0.854, AUC 0.899, F1 0.901

## Executive Summary
This paper presents a deep learning approach for predicting post-stroke aphasia recovery using a combination of multimodal MRI data and clinical tabular features. The method involves training convolutional neural networks on hybrid images that combine stitched MRI slices with symbolic representations of tabular data. The best-performing model achieved high classification accuracy (0.854 balanced accuracy, 0.899 AUC, 0.901 F1 score) by integrating 8 key brain regions-of-interest with three clinical features. The study employed a lock-box validation strategy to prevent overfitting and used explainable AI to identify the most predictive brain regions and features.

## Method Summary
The method preprocesses T1-weighted MRI scans and clinical data from 758 stroke survivors to create hybrid images combining 2D stitched MRI slices with symbolic representations of tabular features (lesion size, initial severity, recovery time). Key GM-ROIs are selected using feature importance analysis from an initial ResNet-18 model. Multiple CNN architectures (ResNet-18, ResNet3D, early fusion, DAFT) are trained using 4-fold cross-validation with a held-out lock box for final evaluation. The pipeline uses ImageNet-pretrained weights, cross-entropy loss with class weighting, and Platt scaling for probability calibration.

## Key Results
- Highest accuracy achieved with 8 GM-ROIs + 3 tabular features using 2D ResNet-18
- Balanced accuracy: 0.854, AUC: 0.899, F1: 0.901
- Outperforms logistic regression baseline and single-modality approaches
- Lock-box validation confirms generalization without overfitting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining 2D stitched MRI images with symbolic representations of tabular data improves classification accuracy by preserving spatial context while reducing the curse of dimensionality.
- Mechanism: 2D stitching retains local spatial relationships across axial slices, and symbolic encoding of tabular data allows direct pixel-level integration into the CNN input, enabling joint feature learning without complex fusion layers.
- Core assumption: Key predictive information for aphasia recovery is retained in 2D projections of MRI and can be jointly learned with symbolic tabular features.
- Evidence anchors:
  - [abstract] "The highest classification accuracy (0.854), area under the curve (0.899) and F1 (0.901) were observed when 8 regions of interest was extracted from each MRI scan and combined with lesion size, initial severity and recovery time in a 2D Residual Neural Network."
  - [section] "2D CNNs trained on the Stitched MRI dataset had similar accuracies to the 3D Resnet trained on the 3D MRI scans... this loss of information appears to be offset by having a smaller feature space and having less trainable parameters."
  - [corpus] Weak: No direct corpus papers validate this specific 2D-stitching plus symbolic encoding mechanism.
- Break condition: If critical aphasia-relevant information exists only in planes not captured by axial slices, or if symbolic encoding fails to preserve tabular feature importance.

### Mechanism 2
- Claim: Using a lock-box validation strategy prevents overfitting and ensures that reported accuracy generalizes to unseen data.
- Mechanism: The lock-box removes a subset of data before any hyperparameter tuning or training, ensuring that final accuracy is measured only after all model decisions are fixed, avoiding data leakage.
- Core assumption: The lock-box is truly held out until after all optimization decisions are finalized and no tuning decisions are based on lock-box performance.
- Evidence anchors:
  - [section] "The project dataset was partitioned into five groups... All this paper's training and validation was carried out on the first four groups, with the fifth group being held back as a lock box... as long as no decisions concerning the set-up or training of data is made on the lock box, which would be the case if accuracy on the lock box is only assessed once, performance on the lock box is a fair test of generalization (Hosseini et al., 2020)."
  - [section] "There is a subtle issue that if the (out-of-sample) accuracies of multiple learning algorithms are quantified on the same lock-box, the choice of the best amongst these will be inflated by this multiple testing."
  - [corpus] Weak: No corpus papers directly compare lock-box vs k-fold or nested CV in this specific stroke prediction context.
- Break condition: If multiple models are compared on the same lock-box, or if tuning decisions leak information from the lock-box.

### Mechanism 3
- Claim: Selecting key GM-ROIs based on feature importance from an initial ResNet-18 model reduces irrelevant dimensions and improves classification by focusing on brain regions most predictive of aphasia recovery.
- Mechanism: CLEAR Image identifies the GM-ROIs with highest average feature importance across multiple predictions; cross-validation selects the optimal number of ROIs to include, reducing noise and redundancy.
- Core assumption: Aphasia recovery is strongly associated with specific GM regions, and these can be identified reliably from a small sample.
- Evidence anchors:
  - [section] "The key ROIs were identified by first training a ResNet-18 neural network on the original stitched MRI dataset to predict spoken description scores >= 60... CLEAR Image analysed 100 predictions made by the ResNet-18 and calculated each GM-ROI's average feature importance score."
  - [section] "Cross-validation was then used to determine the number of GM-ROIs to include in the GM-ROI images... It was found that the top eight ROIs minimised the ResNet-18's loss function."
  - [corpus] Weak: No corpus papers validate this specific ROI selection and CLEAR Image pipeline for stroke aphasia prediction.
- Break condition: If aphasia-relevant damage is not localized to the selected GM regions, or if ROI selection is overfit to the training data.

## Foundational Learning

- Concept: Multimodal deep learning
  - Why needed here: Combines complementary information from imaging (MRI) and non-imaging (clinical, demographic) data sources to improve prediction accuracy.
  - Quick check question: What is the main advantage of early fusion versus late fusion in multimodal models?

- Concept: Transfer learning with pretrained CNNs
  - Why needed here: Pretrained ImageNet weights provide a strong starting point for feature extraction, reducing the need for large in-domain datasets and improving convergence.
  - Quick check question: Why is ImageNet pretraining beneficial even when the target domain (brain MRI) is visually very different?

- Concept: Explainable AI and feature importance
  - Why needed here: Identifies which brain regions and tabular features drive predictions, enabling clinical interpretation and trust in model outputs.
  - Quick check question: What is the key difference between perturbation-based (e.g., CLEAR Image) and gradient-based (e.g., Grad-CAM) explainability methods?

## Architecture Onboarding

- Component map: MRI scans → 2D stitching → ROI extraction → Symbolic tabular encoding → Hybrid image assembly → CNN (ResNet-18/34) → Classification output → CLEAR Image explainability
- Critical path: MRI → 2D stitching → ROI selection → Hybrid image generation → CNN training with lock-box validation → Evaluation
- Design tradeoffs: 2D stitching reduces dimensionality and overfitting risk but may lose out-of-plane spatial context; symbolic encoding is simple but may not capture complex tabular interactions; ROI selection reduces noise but risks excluding relevant regions
- Failure signatures: Overfitting (accuracy drops sharply on lock-box), underfitting (low accuracy even on training data), poor generalization (large gap between cross-validation and lock-box performance)
- First 3 experiments:
  1. Baseline logistic regression using only tabular features (left lesion size, initial severity, recovery time)
  2. ResNet-18 trained on 2D stitched MRI images only (no tabular data)
  3. ResNet-18 trained on hybrid images combining top 8 GM-ROIs with symbolic representations of all three tabular features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the minimum dataset size needed to train effective 3D CNNs for post-stroke aphasia prediction?
- Basis in paper: [inferred] The paper discusses the challenges of small datasets and the potential for improved 3D CNN performance with larger datasets.
- Why unresolved: The current study used a dataset of 758 patients, which is considered small in machine learning terms. The authors suggest that far larger patient numbers might be needed to adequately populate the high dimensional feature space and mitigate the curse of dimensionality.
- What evidence would resolve it: Conducting experiments with progressively larger datasets and measuring the performance of 3D CNNs to identify the point at which performance plateaus or significantly improves.

### Open Question 2
- Question: How can we ensure that explainable AI methods provide faithful explanations for CNN predictions in post-stroke aphasia recovery?
- Basis in paper: [explicit] The paper discusses the need for explainable AI methods and the challenge of ensuring their explanations are faithful to the CNN's decision-making process.
- Why unresolved: Different explainable AI methods often provide conflicting explanations, and there is a lack of methods to assess the fidelity of these explanations, especially with MRI data.
- What evidence would resolve it: Developing and validating methods to assess the fidelity of explainable AI explanations, such as comparing the explanations to known ground truth or using perturbation techniques to test the robustness of the explanations.

### Open Question 3
- Question: What is the impact of using different pre-training datasets for CNNs in post-stroke aphasia prediction?
- Basis in paper: [inferred] The paper mentions that the current pre-training of ResNet models on the ImageNet dataset is not focused on brain scans and suggests exploring pre-training on large datasets of T1-weighted MRI scans.
- Why unresolved: The effectiveness of pre-training on ImageNet weights is demonstrated, but the potential benefits of pre-training on brain-specific datasets are not explored.
- What evidence would resolve it: Comparing the performance of CNNs pre-trained on different datasets, such as ImageNet, large MRI datasets, or even datasets with cognitive measures, to determine which pre-training strategy yields the best results for post-stroke aphasia prediction.

## Limitations
- Small sample size (758 patients) limits generalizability and may not adequately populate high-dimensional feature spaces
- Symbolic encoding of tabular features into images is a novel approach without validation that it preserves all clinically relevant information
- Lock-box validation may be compromised if multiple models are compared on the same held-out set

## Confidence
- **High confidence**: The multimodal deep learning approach combining MRI and tabular data improves classification accuracy over single-modality baselines
- **Medium confidence**: The specific claim that 2D stitched MRI images combined with symbolic tabular encoding outperforms 3D CNNs and other fusion methods
- **Low confidence**: The feature importance analysis identifying 8 specific GM-ROIs as most predictive

## Next Checks
1. Replicate the lock-box validation: Apply the same model selection and training pipeline to a completely independent stroke dataset to verify generalization
2. Ablation study on tabular features: Test the impact of each tabular feature (lesion size, initial severity, recovery time) when added to the 2D stitched MRI images to confirm their independent contribution
3. Alternative ROI selection methods: Compare the CLEAR Image-selected ROIs with those from established anatomical atlases or statistical parametric mapping to assess clinical validity