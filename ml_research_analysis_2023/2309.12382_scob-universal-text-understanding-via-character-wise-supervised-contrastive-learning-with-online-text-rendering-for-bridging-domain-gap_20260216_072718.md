---
ver: rpa2
title: 'SCOB: Universal Text Understanding via Character-wise Supervised Contrastive
  Learning with Online Text Rendering for Bridging Domain Gap'
arxiv_id: '2309.12382'
source_url: https://arxiv.org/abs/2309.12382
tags:
- text
- scob
- pre-training
- scene
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the instability of pre-training text understanding
  models when combining visual document and scene text domains. The authors propose
  SCOB, a method using character-wise supervised contrastive learning with online
  text rendering to bridge the domain gap.
---

# SCOB: Universal Text Understanding via Character-wise Supervised Contrastive Learning with Online Text Rendering for Bridging Domain Gap

## Quick Facts
- arXiv ID: 2309.12382
- Source URL: https://arxiv.org/abs/2309.12382
- Authors: 
- Reference count: 40
- Key outcome: SCOB improves stability and performance of pre-training text understanding models across visual document and scene text domains, achieving competitive results on 11 benchmarks.

## Executive Summary
This paper addresses the challenge of unstable pre-training when combining visual document understanding (VDU) and scene text understanding (STU) domains. The authors propose SCOB, a method using character-wise supervised contrastive learning with online text rendering to bridge the domain gap between these domains. By leveraging character-level projections and synthetic data generation, SCOB creates a unified representation space that is robust to domain-specific variations in text appearance and background complexity. The approach enables weakly supervised learning, significantly reducing annotation costs while maintaining competitive performance across multiple downstream tasks.

## Method Summary
SCOB employs a Swin-B encoder with a Transformer decoder to process character-level sequences from both real and synthetic text images. The method uses online text rendering to generate synthetic positive samples that correspond one-to-one with real images, creating substantial variance for contrastive learning. Character-wise supervised contrastive learning clusters embeddings of the same characters across domains while pushing away different characters. The weakly supervised approach replaces coordinate annotations with masked tokens for real images, allowing the model to learn coordinate information solely from rendered data. This design eliminates expensive coordinate annotation while maintaining learning effectiveness through teacher-forcing scheme.

## Key Results
- SCOB achieves competitive performance on 11 downstream benchmarks across VDU and STU domains
- Weakly supervised pre-training reduces annotation costs by eliminating coordinate supervision requirements
- Character-wise supervised contrastive learning effectively bridges the domain gap between document and scene text domains
- SCOB improves stability of pre-training compared to existing methods when combining VDU and STU data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Character-wise supervised contrastive learning (SCOB) bridges the domain gap between visual document understanding (VDU) and scene text understanding (STU) domains.
- Mechanism: SCOB uses character-level projections in the embedding space and enforces positive samples (same characters from synthetic, document, and scene text images) to be clustered together while pushing away negative samples. This creates a unified representation space that is robust to domain-specific variations in text appearance and background complexity.
- Core assumption: Characters can be treated as independent learning units for contrastive representation learning, and the variance in character appearance across domains can be effectively captured through synthetic rendering.
- Evidence anchors:
  - [abstract] "leverages character-wise supervised contrastive learning with online text rendering to effectively pre-train document and scene text domains by bridging the domain gap"
  - [section 3.2] "we propose character-wise contrastive learning... Our model takes original (real) and multiview (synthetic) images as the input and auto-regressively generates the token"
  - [corpus] Weak corpus signal - only 1 relevant paper with weak citations; domain gap bridging is not well-established in related literature
- Break condition: If character-level granularity is insufficient to capture domain-specific visual features, or if the synthetic rendering fails to generate realistic character variations that transfer to real domains.

### Mechanism 2
- Claim: Online text rendering serves as an effective augmentation method for contrastive learning in text understanding.
- Mechanism: The renderer generates synthetic text images that correspond one-to-one with real images, creating substantial variance between positive views without requiring strong geometric augmentations. This provides high-quality positive samples for contrastive learning while being computationally efficient.
- Core assumption: Synthetic rendering can create sufficient character appearance variance to serve as effective positive samples for contrastive learning, and this variance transfers to real domain performance.
- Evidence anchors:
  - [abstract] "online text rendering to effectively pre-train document and scene text domains"
  - [section 3.3] "The renderer is designed specifically for the character-wise SupCon... we randomly select various fonts and background colors"
  - [section 3.3] "we propose the online text renderer... Existing methods cannot employ strong geometric augmentations like crop and flip"
- Break condition: If the synthetic rendering fails to generate realistic character variations that match real domain distributions, or if the computational overhead becomes prohibitive.

### Mechanism 3
- Claim: Weakly supervised OCR pre-training reduces annotation costs while maintaining performance.
- Mechanism: SCOB replaces coordinate annotations with masked tokens for real images, allowing the model to learn coordinate information solely from rendered data while learning text annotations from both real and rendered data. This eliminates the need for expensive coordinate annotation while maintaining learning effectiveness.
- Core assumption: Coordinate information can be effectively learned from rendered data alone, and the model can generalize this learning to real images without explicit coordinate supervision.
- Evidence anchors:
  - [abstract] "Moreover, SCOB enables weakly supervised learning, significantly reducing annotation costs"
  - [section 3.3] "we propose a weakly supervised pre-training for OCR-read that eliminates the need for expensive coordinate annotation of real images"
  - [section 3.3] "replacing the input coordinate tokens of real data with mask tokens in a teacher-forcing scheme"
- Break condition: If coordinate information cannot be effectively learned from rendered data alone, or if the performance gap between weakly supervised and fully supervised approaches becomes too large.

## Foundational Learning

- Concept: Contrastive learning and positive/negative sample construction
  - Why needed here: SCOB relies on character-wise contrastive learning, which requires understanding how to construct positive and negative pairs for training
  - Quick check question: How does character-wise contrastive learning differ from image-level contrastive learning in terms of sample construction?

- Concept: Text rendering and synthetic data generation
  - Why needed here: The online renderer generates synthetic text images that serve as positive samples for contrastive learning, requiring understanding of text rendering techniques
  - Quick check question: What are the key parameters that control character appearance variance in synthetic text rendering?

- Concept: Sequence generation models and teacher forcing
  - Why needed here: SCOB uses sequence generation architecture with teacher forcing scheme, which is fundamental to how the model processes and generates text sequences
  - Quick check question: How does the teacher forcing scheme work in the context of SCOB's weakly supervised pre-training?

## Architecture Onboarding

- Component map: Swin Transformer encoder -> Transformer decoder -> Character tokenizer -> Online text renderer -> Character-wise projector -> Contrastive loss layer

- Critical path:
  1. Input image → Swin encoder → visual embeddings
  2. Visual embeddings + previous tokens → Transformer decoder → character predictions
  3. Character predictions → projector → contrastive embeddings
  4. Contrastive loss computed using character-wise SupCon

- Design tradeoffs:
  - Character tokenizer vs subword tokenizer (character provides better OCR performance but longer sequences)
  - Weakly supervised vs fully supervised coordinate learning (cost reduction vs potential performance gap)
  - Synthetic rendering vs strong geometric augmentations (computational efficiency vs potential domain gap)

- Failure signatures:
  - NaN loss during training (indicates domain conflict or numerical instability)
  - Poor OCR performance despite good VDU performance (indicates domain-specific representation issues)
  - Slow convergence on scene text tasks (indicates insufficient domain adaptation)

- First 3 experiments:
  1. Test renderer output quality by generating synthetic images and visually inspecting character variation and realism
  2. Verify contrastive learning by checking if same characters cluster together in embedding space using t-SNE visualization
  3. Validate weakly supervised learning by comparing coordinate prediction accuracy on rendered vs real data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SCOB's character-wise supervised contrastive learning compare to instance-level contrastive learning methods in terms of performance and stability when pre-training on mixed VDU and STU data?
- Basis in paper: [explicit] The paper mentions that character-wise SupCon allows obtaining abundant positive and negative samples even in a small batch, unlike instance-level methods. It also states that character-wise SupCon bridges all synthetic, document, and scene domains by enforcing the same characters close together.
- Why unresolved: While the paper demonstrates SCOB's effectiveness, it doesn't provide a direct comparison with instance-level contrastive learning methods on the same tasks and datasets.
- What evidence would resolve it: A controlled experiment comparing SCOB (character-wise) with an instance-level contrastive learning approach on the same pre-training and fine-tuning tasks, measuring both performance and training stability.

### Open Question 2
- Question: What is the optimal balance between real and synthetic data in SCOB's training pipeline, and how does this balance affect downstream task performance across different domains?
- Basis in paper: [explicit] The paper mentions using a batch ratio of 20% IIT-CDIP and 80% scene text datasets for pre-training, and discusses the use of rendered data as an augmentation method.
- Why unresolved: The paper doesn't explore how varying the ratio of real to synthetic data affects performance, nor does it analyze the impact on specific domains (VDU vs. STU).
- What evidence would resolve it: A systematic study varying the real-to-synthetic data ratio (e.g., 10-90%, 50-50%, 90-10%) and measuring downstream performance on both VDU and STU tasks.

### Open Question 3
- Question: How does SCOB's performance scale with model size, and at what point does increasing model capacity yield diminishing returns?
- Basis in paper: [explicit] The paper mentions that PaLI employs a form of text-read task as a pre-training method and suggests that integration of SCOB could amplify PaLI's performance. It also notes that increasing model size is a significant factor in performance.
- Why unresolved: The paper only evaluates SCOB on a single model size (202M parameters) and doesn't investigate how performance changes with larger or smaller models.
- What evidence would resolve it: Experiments with SCOB applied to models of varying sizes (e.g., 100M, 500M, 1B parameters) and analysis of performance trends to identify scaling limits.

### Open Question 4
- Question: What is the impact of different text rendering parameters (e.g., font variety, background complexity, text size range) on SCOB's effectiveness in bridging the VDU-STU domain gap?
- Basis in paper: [explicit] The paper describes using over 3,000 fonts and random background colors to maximize character variance, but doesn't explore how different rendering parameters affect performance.
- Why unresolved: While the paper demonstrates SCOB's effectiveness with its chosen rendering settings, it doesn't investigate the sensitivity of performance to rendering parameters or identify optimal configurations.
- What evidence would resolve it: A study varying rendering parameters (e.g., number of fonts, background complexity, text size ranges) and measuring their impact on downstream task performance and domain gap bridging.

## Limitations

- Character-wise granularity assumption may not hold for complex scene text with severe perspective distortion or artistic fonts
- Weakly supervised coordinate learning relies entirely on rendered data generalization without validation of real-world performance gaps
- Temperature parameter (0.07) and scaling factor (0.5) for contrastive loss lack justification through ablation studies
- 3000+ Google fonts claim lacks verification of actual font diversity and coverage across languages

## Confidence

**High Confidence**
- Character-wise supervised contrastive learning effectively bridges domain gaps when synthetic rendering is realistic
- Online text rendering provides efficient augmentation compared to geometric transformations
- Weakly supervised learning significantly reduces annotation costs with acceptable performance trade-offs

**Medium Confidence**
- The combined VDU+STU pre-training strategy consistently improves both domains
- The decoder prune layer setting (layer 6) is optimal for downstream fine-tuning
- The character tokenizer is superior to subword tokenization for OCR tasks

**Low Confidence**
- The specific temperature and scaling factor values are optimal
- The exact font distribution in the renderer significantly impacts downstream performance
- The 1M step pre-training duration is sufficient for all domain combinations

## Next Checks

1. **Renderer Quality Validation**: Generate synthetic images across the full font range and measure character recognition accuracy on the synthetic set itself. Compare with real domain performance to quantify rendering quality and domain gap.

2. **Coordinate Supervision Ablation**: Train parallel models with varying levels of coordinate supervision (0%, 25%, 50%, 100%) on real data while keeping rendered data constant. Measure the performance drop curve to determine the minimum supervision needed.

3. **Domain Gap Analysis**: Freeze the encoder and train linear probes on character embeddings from VDU-only, STU-only, and combined datasets. Use t-SNE to visualize embedding distributions and measure domain confusion to quantify how well SCOB bridges the gap.