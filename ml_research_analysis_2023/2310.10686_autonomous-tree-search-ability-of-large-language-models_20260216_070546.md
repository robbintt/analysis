---
ver: rpa2
title: Autonomous Tree-search Ability of Large Language Models
arxiv_id: '2310.10686'
source_url: https://arxiv.org/abs/2310.10686
tags:
- shot
- step
- search
- puzzle
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces autonomous tree-search (ATS) ability for
  large language models (LLMs), enabling them to perform tree-structured search without
  external programs. The proposed ATS-BFS and ATS-DFS methods allow LLMs to generate
  search trajectories in responses.
---

# Autonomous Tree-search Ability of Large Language Models

## Quick Facts
- arXiv ID: 2310.10686
- Source URL: https://arxiv.org/abs/2310.10686
- Reference count: 40
- Key outcome: ATS-BFS improves accuracy by 33% over Chain of Thought and 40.6%/38.5% over CoT-tuned LLaMA2 models when fine-tuned

## Executive Summary
This paper introduces autonomous tree-search (ATS) ability for large language models, enabling them to perform tree-structured search without external programs. The proposed ATS-BFS and ATS-DFS methods allow LLMs to generate search trajectories in responses through carefully crafted system prompts. Experiments on four puzzle games show ATS-BFS significantly outperforms Chain of Thought by 33% accuracy and is more efficient than Tree of Thoughts. Fine-tuning LLaMA with ATS-generated data further improves performance, surpassing CoT-tuned LLaMAs by 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B respectively.

## Method Summary
The paper proposes ATS-BFS and ATS-DFS methods that enable LLMs to perform tree-structured search autonomously through system prompts. ATS-BFS uses breadth-first exploration with multiple scenarios maintained at each step, while ATS-DFS implements depth-first search with backtracking capability within the response text. The methods rely on GPT-4's in-context learning to follow structured generation instructions without external code. Fine-tuning smaller LLaMA models on ATS-generated data transfers the search capability, allowing inference without external programs.

## Key Results
- ATS-BFS achieves 33% higher accuracy than Chain of Thought on four puzzle games
- ATS-BFS is more cost-efficient than Tree of Thoughts methods
- ATS-tuned LLaMA2-7B and LLaMA2-13B outperform CoT-tuned baselines by 40.6% and 38.5% respectively

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ATS-BFS enables LLMs to explore multiple solution paths in a breadth-first manner, improving accuracy over single-trajectory methods like Chain of Thought.
- Mechanism: The fixed system prompt instructs the LLM to explicitly generate and maintain multiple scenarios at each step, iterating until a solution is found. This flattened BFS tree structure is encoded directly into the response text.
- Core assumption: GPT-4 can follow structured generation instructions reliably enough to simulate BFS search without external code.
- Evidence anchors:
  - [abstract] "ATS-BFS method outperforms the Chain of Thought approach by achieving an average accuracy improvement of 33%"
  - [section 4.1] "We supply GPT-4 with a uniform system message... This message briefly introduced ATS ability and encouraged GPT-4 to role-play an assistant who is good at ATS"
- Break condition: If GPT-4 fails to adhere to the BFS structure, the search degenerates into a less efficient exploration pattern.

### Mechanism 2
- Claim: ATS-DFS allows LLMs to backtrack and retry alternative paths within the same response, enabling depth-first exploration without external prompting.
- Mechanism: The system prompt explicitly instructs the model to "step back" and retry operations when a path fails, constructing a DFS traversal in the output text.
- Core assumption: GPT-4's few-shot learning capacity is sufficient to learn and execute DFS backtracking logic from example prompts.
- Evidence anchors:
  - [abstract] "ATS-DFS... when a problem is presented to LLMs, they immediately attempt a solution, retreating and initiating another attempt from the current position"
  - [section 4.1] "ATS-DFS... it performs optimally in the few-shot setting of GPT-4"
- Break condition: Complex DFS logic may overwhelm GPT-4's in-context learning, leading to incomplete or incorrect backtracking.

### Mechanism 3
- Claim: Fine-tuning smaller LLaMA models on ATS-generated data transfers the autonomous search capability, improving performance over CoT-tuned baselines.
- Mechanism: Supervised fine-tuning uses the tree-structured responses from ATS-enhanced GPT-4 as training data, teaching smaller models to generate similar search trajectories internally.
- Core assumption: The tree structure in the fine-tuning data is learnable by smaller models and does not require external code during inference.
- Evidence anchors:
  - [abstract] "Upon fine-tuning this data, the ATS-tuned LLaMAs demonstrated satisfactory search performance... it outperforms CoT-tuned LLaMAs by an average of 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B, respectively"
  - [section 5.1] "we employ supervised fine-tuning, distilling from ATS-enhanced GPT-4 or from the messages generated by ToT method to smaller LLaMA models"
- Break condition: If the tree structure is too complex, smaller models may fail to generalize the search pattern.

## Foundational Learning

- Concept: BFS vs DFS search strategies
  - Why needed here: ATS-BFS and ATS-DFS are direct implementations of these strategies, flattened into text responses.
  - Quick check question: In a search tree, which strategy explores all nodes at a given depth before moving deeper: BFS or DFS?

- Concept: Prompt engineering and in-context learning
  - Why needed here: ATS relies on carefully crafted system prompts to guide LLM behavior without fine-tuning.
  - Quick check question: What is the difference between a system message and a user message in the OpenAI API?

- Concept: Supervised fine-tuning with structured outputs
  - Why needed here: Smaller models are fine-tuned on ATS-generated data to acquire search capability.
  - Quick check question: In supervised fine-tuning, what is the role of the input prompt versus the target output?

## Architecture Onboarding

- Component map: System prompt generator -> GPT-4/LLaMA inference engine -> ATS response parser -> Evaluation harness
- Critical path: Prompt → LLM → Response (tree structure) → Parse → Evaluate
- Design tradeoffs:
  - BFS vs DFS: BFS is simpler but may generate longer responses; DFS can be more concise but requires backtracking logic.
  - Zero-shot vs few-shot: Zero-shot is more flexible but less reliable; few-shot improves reliability at the cost of task-specific prompts.
  - Self-consistency: Improves robustness but increases API cost.
- Failure signatures:
  - ATS-BFS: Response does not maintain multiple scenarios per step.
  - ATS-DFS: Missing or incorrect backtracking steps.
  - Fine-tuned model: Output lacks tree structure or degenerates to CoT-like responses.
- First 3 experiments:
  1. Run ATS-BFS on Drop Water Puzzle with zero-shot prompt; verify BFS structure and accuracy.
  2. Compare ATS-BFS vs ATS-DFS on Arithmetic Puzzle in few-shot setting; measure accuracy and response length.
  3. Fine-tune LLaMA2-7B on ATS-BFS data; evaluate on Number Path Puzzle and compare to CoT-tuned baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ATS performance scale with model size beyond 70B parameters?
- Basis in paper: [explicit] The authors mention "Future research includes training larger LLMs, specifically those exceeding 70B, with ATS ability."
- Why unresolved: The paper only experiments with GPT-4 and LLaMA2-7B/13B models, leaving performance on larger models unexplored.
- What evidence would resolve it: Systematic experiments comparing ATS performance across model sizes from 7B to 175B+ parameters.

### Open Question 2
- Question: What is the impact of ATS capability on other emergent reasoning abilities?
- Basis in paper: [explicit] The authors note uncertainty about "whether the ATS capability could ultimately enhance other abilities akin to search ability."
- Why unresolved: The paper focuses on search-specific tasks but doesn't test whether ATS ability transfers to other reasoning domains.
- What evidence would resolve it: Experiments testing ATS-tuned models on non-search reasoning tasks like mathematical problem-solving or logical inference.

### Open Question 3
- Question: What is the computational complexity trade-off between ATS-BFS and ATS-DFS?
- Basis in paper: [inferred] The authors observe that "DFS logic is complex and often requires task-specific design" and note performance differences between ATS-BFS and ATS-DFS.
- Why unresolved: The paper doesn't provide detailed complexity analysis or explain why DFS sometimes fails despite being theoretically more complete.
- What evidence would resolve it: Analysis of computational steps, token usage, and success rates for ATS-BFS vs ATS-DFS across varying problem depths and branching factors.

## Limitations

- Reliance on GPT-4's in-context learning for BFS/DFS logic introduces uncertainty if the model fails to follow structured prompts consistently
- Fine-tuning results based on a relatively small dataset (200 examples) and limited evaluation across four puzzle domains
- Performance generalizability beyond the four puzzle games tested remains unexplored for real-world reasoning tasks

## Confidence

- High Confidence: The BFS vs DFS accuracy comparison (33% improvement) - directly measurable from reported experiments
- Medium Confidence: The ATS-BFS cost efficiency claims - while API cost metrics are reported, real-world deployment costs may vary
- Low Confidence: The generalizability of ATS capabilities beyond the four puzzle games tested, as performance on real-world reasoning tasks remains unexplored

## Next Checks

1. **Cross-Domain Robustness Test**: Evaluate ATS-BFS/DFS on non-puzzle reasoning tasks (e.g., code generation, mathematical proof, or logical deduction problems) to assess generalizability beyond the current experimental scope.

2. **Prompt Adherence Analysis**: Systematically analyze a sample of ATS responses to verify whether the generated tree structures actually follow BFS/DFS patterns as claimed, or if they degrade to simpler search patterns.

3. **Scaling Study**: Test ATS performance across different model sizes (both larger and smaller than LLaMA2-13B) to understand the minimum model capacity required for effective autonomous tree-search.