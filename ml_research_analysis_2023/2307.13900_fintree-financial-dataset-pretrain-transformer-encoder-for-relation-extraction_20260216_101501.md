---
ver: rpa2
title: 'FinTree: Financial Dataset Pretrain Transformer Encoder for Relation Extraction'
arxiv_id: '2307.13900'
source_url: https://arxiv.org/abs/2307.13900
tags:
- financial
- relation
- fintree
- extraction
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FinTree, a transformer encoder model specifically
  designed for relation extraction tasks in the financial domain. The authors further
  pretrain DeBERTa on financial text to adapt it to financial domain terminology and
  semantics.
---

# FinTree: Financial Dataset Pretrain Transformer Encoder for Relation Extraction

## Quick Facts
- arXiv ID: 2307.13900
- Source URL: https://arxiv.org/abs/2307.13900
- Reference count: 15
- Key outcome: State-of-the-art performance on REFinD dataset with micro F1 score of 80.04

## Executive Summary
FinTree is a transformer encoder model designed for relation extraction in the financial domain. It adapts DeBERTa by further pretraining on financial text and uses a unique approach of predicting a masked token instead of the conventional [CLS] token. The model employs a specific input pattern with Position Information (PI) tokens and post-processing to mask invalid relation classes based on entity types. FinTree achieves state-of-the-art performance on the REFinD dataset, outperforming models like Matching the Blanks and Luke.

## Method Summary
FinTree uses DeBERTa as its backbone, further pretrained on financial corpora using masked language modeling. The model employs a unique input pattern where a query template with a [MASK] token is concatenated with the original text and PI tokens indicating entity boundaries. During training, a linear layer is applied to the [MASK] token's representation to predict the relation. Post-processing masks invalid relation classes based on entity types (MCPP). Training uses AdamW optimizer, learning rate 1e-5, batch size 8, 5 epochs, max sequence length 1536, and includes Adversarial Weight Perturbation (AWP) from epoch 3.

## Key Results
- Achieves micro F1 score of 80.04 on REFinD dataset
- Outperforms Matching the Blanks and Luke baselines
- Demonstrates effectiveness of masked token prediction approach for relation extraction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Predicting the [MASK] token instead of [CLS] aligns the task with masked language modeling pretraining, enabling smoother transfer learning during finetuning.
- Mechanism: By framing the relation extraction task as predicting a masked token in a structured query, the model leverages the same representation space learned during MLM pretraining, reducing domain shift.
- Core assumption: The contextual representations for masked tokens in the model's vocabulary are semantically rich enough to encode the relation between entities.
- Evidence anchors:
  - [abstract] "This structure allows for more accurate relation predictions between two given entities."
  - [section 2.3] "This unique approach aligns with MLM pretraining strategies, enhancing performance."
  - [corpus] Weak evidence: no direct comparison between [MASK]-token vs [CLS]-token classification performance in this corpus.

### Mechanism 2
- Claim: Adversarial Weight Perturbation (AWP) improves model robustness and generalization by creating a smoother decision boundary.
- Mechanism: AWP adds small adversarial perturbations to model weights during training, which encourages the model to learn features that are less sensitive to weight fluctuations.
- Core assumption: Weight-space perturbations during training induce meaningful changes in output predictions that mimic noise robustness.
- Evidence anchors:
  - [section 2.3] "Adversarial perturbation to the model weights during training enhances the model robustness and improves generalization by creating a smoother decision boundary around the training instances."
  - [corpus] No specific evidence in corpus about AWP; general adversarial training principles apply.

### Mechanism 3
- Claim: Masking classes that cannot appear for given entity types (MCPP) prevents invalid predictions and improves precision.
- Mechanism: During inference, classes incompatible with the input entity types are masked out, reducing the effective output space to only plausible relations.
- Core assumption: The dataset reliably encodes type-compatibility constraints for each relation class.
- Evidence anchors:
  - [section 2.3] "If a class's entity type does not match the input data, we mask that class to prevent the model from predicting it."
  - [corpus] No explicit corpus evidence; assumption based on dataset schema.

## Foundational Learning

- Concept: Masked Language Modeling (MLM)
  - Why needed here: MLM pretraining teaches the model to infer missing tokens from context, which is directly leveraged by predicting masked relation tokens.
  - Quick check question: How does MLM pretraining differ from standard left-to-right language modeling, and why is it useful for fine-tuning on downstream tasks?

- Concept: Adversarial Training
  - Why needed here: Adversarial perturbations during training improve robustness to small input or parameter changes, which is beneficial in a specialized domain like finance where noise is common.
  - Quick check question: What is the effect of adding adversarial weight perturbations on the loss landscape, and how does it relate to generalization?

- Concept: Post-processing with Type Constraints
  - Why needed here: Enforcing entity-type compatibility during prediction ensures that only valid relation classes are considered, reducing false positives.
  - Quick check question: How do you encode and enforce entity-type compatibility constraints in a classification model's output layer?

## Architecture Onboarding

- Component map: DeBERTa backbone -> Input formatting layer -> DeBERTa forward pass -> [MASK] token extraction -> Linear layer -> Post-processing (MCPP) -> Loss computation

- Critical path: Data -> Input formatting -> DeBERTa forward pass -> [MASK] token extraction -> Linear layer -> Post-processing -> Loss computation -> Backpropagation with AWP

- Design tradeoffs:
  - Using [MASK] token prediction vs [CLS] token classification: better alignment with MLM but requires query formatting; [CLS] is simpler but less aligned.
  - AWP from epoch 3: balances stability early on with robustness later; starting earlier risks divergence.
  - MCPP filtering: improves precision but may hide model errors if constraints are wrong.

- Failure signatures:
  - Poor performance on dev set: could indicate misalignment in query formatting or MCPP filtering too aggressive.
  - Unstable training after AWP: likely perturbation magnitude too high.
  - No improvement over baselines: could indicate insufficient financial domain adaptation or suboptimal hyperparameters.

- First 3 experiments:
  1. Run the base DeBERTa model (no MCPP, no AWP, no PI) on REFinD dev set to establish baseline.
  2. Add MCPP filtering and evaluate impact on precision/recall.
  3. Introduce PI tokens and measure effect on F1 score.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FinTree's performance compare to other domain-specific relation extraction models beyond those tested in the paper?
- Basis in paper: [explicit] The paper compares FinTree to models like Matching the Blanks and Luke, but does not evaluate it against other domain-specific relation extraction models.
- Why unresolved: The paper does not provide a comprehensive comparison with other domain-specific relation extraction models.
- What evidence would resolve it: Testing FinTree on other domain-specific relation extraction datasets and comparing its performance to other models.

### Open Question 2
- Question: Can FinTree be effectively applied to other domains beyond finance, and if so, how would its performance compare?
- Basis in paper: [inferred] The paper focuses on the financial domain, but does not explore the model's applicability to other domains.
- Why unresolved: The paper does not provide any evidence or experiments to support the model's performance in other domains.
- What evidence would resolve it: Testing FinTree on relation extraction datasets from other domains and comparing its performance to other models.

### Open Question 3
- Question: How does the choice of query pattern affect FinTree's performance, and are there other patterns that could potentially improve it?
- Basis in paper: [explicit] The paper describes the query pattern used in FinTree, but does not explore the impact of different patterns on performance.
- Why unresolved: The paper does not provide any experiments or evidence to support the choice of query pattern or explore alternative patterns.
- What evidence would resolve it: Testing FinTree with different query patterns and comparing their impact on performance.

## Limitations
- No ablation studies for core innovations (MASK token prediction, PI tokens, AWP)
- Relatively modest dataset size (28,676 instances) for domain-specific pretraining
- No statistical significance testing or confidence intervals reported
- Effectiveness of AWP not empirically validated against standard adversarial training

## Confidence

**High Confidence:**
- FinTree achieves state-of-the-art results on the REFinD dataset, as evidenced by reported F1 scores and comparison to established baselines.

**Medium Confidence:**
- The claim that predicting the [MASK] token (rather than [CLS]) improves transfer from MLM pretraining is plausible and methodologically justified, but lacks direct empirical validation in this work.

**Low Confidence:**
- The effectiveness of AWP in this specific context is asserted but not empirically validated; no ablation or comparison with standard adversarial training is presented.

## Next Checks

1. **Ablation Study of Core Architectural Choices:**
   Run controlled experiments ablating each of the following: (a) MCPP post-processing, (b) PI token usage, (c) [MASK] token prediction vs [CLS] token classification. Compare performance on the REFinD dev set to isolate the contribution of each innovation.

2. **Adversarial Training Ablation:**
   Train a FinTree variant without AWP and compare dev set performance. Additionally, test alternative adversarial training strategies (e.g., FGSM or PGD on input embeddings) to assess whether AWP provides unique benefits.

3. **Generalization to External Financial Corpora:**
   Evaluate FinTree on a held-out subset of SEC filings not present in REFinD, or on a different financial relation extraction dataset (e.g., FinRED). Report F1 scores and analyze error patterns to assess robustness and domain generalization.