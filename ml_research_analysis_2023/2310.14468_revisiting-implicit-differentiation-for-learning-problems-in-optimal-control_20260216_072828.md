---
ver: rpa2
title: Revisiting Implicit Differentiation for Learning Problems in Optimal Control
arxiv_id: '2310.14468'
source_url: https://arxiv.org/abs/2310.14468
tags:
- learning
- trajectory
- control
- constraints
- derivatives
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents IDOC, a method for efficiently computing trajectory
  derivatives through non-convex, constrained discrete-time optimal control problems
  using the implicit function theorem. IDOC differs from prior works by directly evaluating
  matrix equations arising from variable elimination on Lagrange multipliers, rather
  than solving differential KKT systems via auxiliary LQR problems.
---

# Revisiting Implicit Differentiation for Learning Problems in Optimal Control

## Quick Facts
- arXiv ID: 2310.14468
- Source URL: https://arxiv.org/abs/2310.14468
- Reference count: 40
- Key outcome: IDOC achieves linear time complexity for trajectory derivatives through COC problems by exploiting block-sparse structure, enabling efficient learning with improved numerical stability.

## Executive Summary
This paper introduces IDOC, a method for efficiently computing trajectory derivatives through non-convex, constrained discrete-time optimal control problems. Unlike prior works that solve differential KKT systems via auxiliary LQR problems, IDOC directly evaluates matrix equations arising from variable elimination on Lagrange multipliers. By exploiting the block-sparse structure of these equations, IDOC achieves linear complexity in trajectory length and enables parallelization. Experiments demonstrate that IDOC computes trajectory derivatives significantly faster than existing approaches while maintaining superior numerical stability, particularly for problems with inequality constraints.

## Method Summary
IDOC uses implicit differentiation to compute derivatives of trajectories through optimal control problems. The method transforms the differential KKT system into matrix equations where H is block diagonal and A is block-banded, allowing efficient computation of H⁻¹A⊤ and AH⁻¹B-C in O(T) time. The block tridiagonal AH⁻¹A⊤ can be inverted in O(T) time using specialized solvers. This approach enables direct computation of vector-Jacobian products without constructing full trajectory derivatives, avoiding the numerical instability associated with recursive Riccati-style equations.

## Key Results
- IDOC achieves O(T) complexity for computing trajectory derivatives, where T is the number of timesteps
- IDOC is 2-4x faster than PDP and Safe-PDP in synthetic and learning-from-demonstration benchmarks
- IDOC demonstrates superior numerical stability, particularly in the presence of inequality constraints
- The method scales linearly with both trajectory length and model size (state/control dimensions)

## Why This Works (Mechanism)

### Mechanism 1
IDOC achieves linear time complexity by exploiting the block-sparse structure of the KKT system. The method uses variable elimination on Lagrange multipliers to transform the differential KKT system into matrix equations where H is block diagonal and A is block-banded. This structure allows efficient computation of H⁻¹A⊤ and AH⁻¹B-C in O(T) time, and the block tridiagonal AH⁻¹A⊤ can be inverted in O(T) time using specialized solvers. The core assumption is that matrix H is non-singular and all blocks in H are non-singular.

### Mechanism 2
IDOC enables direct computation of vector-Jacobian products (VJPs) without constructing full trajectory derivatives. The method provides an explicit matrix equation formulation that allows computing DθL(ξ(θ)) = v⊤Dξ(θ) directly by evaluating v⊤(H⁻¹A⊤(AH⁻¹A⊤)⁻¹(AH⁻¹B - C) - H⁻¹B) from left to right. This avoids the need to construct Dξ(θ) explicitly and significantly reduces computation time compared to constructing the full trajectory derivative.

### Mechanism 3
IDOC provides improved numerical stability compared to Riccati-based approaches by avoiding recursive Riccati-style equations. By solving explicit matrix equations with block structure, IDOC reduces rounding errors that accumulate in long trajectories or poorly conditioned problems. The method can also leverage parallel computation across timesteps for additional stability benefits.

## Foundational Learning

- Concept: Implicit Function Theorem (IFT)
  - Why needed here: The trajectory ξ(θ) is an implicit function of parameters θ through the optimality conditions of the COC problem, and IFT provides the theoretical foundation for computing its derivative
  - Quick check question: What are the key conditions required for the implicit function theorem to guarantee the existence of Dξ(θ)?

- Concept: Karush-Kuhn-Tucker (KKT) conditions
  - Why needed here: The trajectory derivatives are derived by differentiating through the KKT conditions of the underlying optimization problem, which characterize the optimality of the COC solution
  - Quick check question: How do the KKT conditions relate to the Lagrange multipliers λ in the context of constrained optimization?

- Concept: Block-sparse matrix structure
  - Why needed here: The efficiency of IDOC relies on recognizing and exploiting the block-sparse structure of matrices H, A, and AH⁻¹A⊤ that arise from the COC problem formulation
  - Quick check question: Why does the block-banded structure of A (being two blocks wide) allow for O(T) computation time?

## Architecture Onboarding

- Component map: Forward pass COC solver (e.g., IPOPT, DDP) -> IDOC algorithm for trajectory derivatives -> Gradient descent on outer loss L(ξ(θ), ξdemo)
- Critical path: The bottleneck is typically the forward pass COC solver, not the IDOC backward pass. The backward pass involves solving block tridiagonal systems which can be parallelized.
- Design tradeoffs: IDOC trades off requiring non-singular H for avoiding Riccati recursions. The method also assumes access to Lagrange multipliers from the forward solver, though alternatives exist if they're not directly available.
- Failure signatures:
  - If H is singular, IDOC will fail unless the δ/2 I regularization trick is applied
  - If the forward solver fails to find a local optimum, IDOC derivatives will be meaningless
  - If numerical precision is insufficient, block tridiagonal solvers may become unstable
- First 3 experiments:
  1. Implement IDOC on a simple cartpole environment with known analytical derivatives to verify correctness
  2. Compare computation time of IDOC vs PDP on a medium-scale quadrotor problem (n≈10, m≈4, T≈50)
  3. Test numerical stability by running cartpole with varying condition numbers on H and measuring error between 32-bit and 64-bit computations

## Open Questions the Paper Calls Out

### Open Question 1
How does the numerical stability of IDOC compare to other methods when using more sophisticated block tridiagonal solvers instead of the simple recursive block tridiagonal matrix algorithm? The paper mentions that using more sophisticated block tridiagonal solvers will further improve the stability of the backwards pass and is left as future work.

### Open Question 2
Can IDOC be extended to handle COC problems with non-additive cost functions, such as those with a final cost defined over the full trajectory? The paper mentions that relaxing the additive cost assumption and adding a final cost like h_T(ξ; θ) = ξ^T Q ξ is possible using the matrix inversion lemma.

### Open Question 3
How does IDOC perform in terms of computation time and numerical stability for COC problems with a large number of state and control variables compared to methods derived from the PMP? The paper provides numerical experiments for a few standard environments but doesn't explore the scalability of IDOC to problems with a large number of state and control variables.

## Limitations
- The method's performance heavily depends on the forward solver providing accurate Lagrange multipliers, but extraction details from solvers like IPOPT aren't fully specified
- Numerical stability improvements over Riccati methods are demonstrated but not thoroughly quantified across different problem scales and condition numbers
- The claim about linear complexity assumes non-singular H, but the regularization trick introduces approximation error that isn't quantified

## Confidence

- **High confidence**: The core theoretical derivation using implicit differentiation and the block-sparse matrix structure exploitation
- **Medium confidence**: The empirical performance claims on benchmark problems, as the comparison methodology and hyperparameter choices aren't fully specified
- **Low confidence**: The generality of the method across different COC solvers and constraint formulations, particularly for problems where Lagrange multipliers aren't readily available

## Next Checks

1. Test IDOC's numerical stability across a range of condition numbers by systematically varying solver tolerances and measuring error propagation in the block-tridiagonal solves
2. Implement finite-difference gradient checks on small-scale problems to verify the correctness of IDOC's computed derivatives against analytical or numerical baselines
3. Benchmark IDOC against Safe-PDP and PDP on problems with varying numbers of inequality constraints to quantify the claimed stability advantages in constrained settings