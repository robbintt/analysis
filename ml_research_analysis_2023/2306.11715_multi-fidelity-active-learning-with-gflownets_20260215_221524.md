---
ver: rpa2
title: Multi-Fidelity Active Learning with GFlowNets
arxiv_id: '2306.11715'
source_url: https://arxiv.org/abs/2306.11715
tags:
- learning
- multi-fidelity
- active
- function
- fidelity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a multi-fidelity active learning approach with
  GFlowNets to efficiently discover diverse, high-scoring candidates in scientific
  discovery and engineering design. The method uses GFlowNets to jointly sample objects
  and the fidelity of the oracle to evaluate them, allowing for cost-aware exploration
  of the search space.
---

# Multi-Fidelity Active Learning with GFlowNets

## Quick Facts
- arXiv ID: 2306.11715
- Source URL: https://arxiv.org/abs/2306.11715
- Reference count: 40
- Primary result: Multi-fidelity active learning with GFlowNets discovers high-scoring candidates at lower cost than single-fidelity methods while maintaining diversity

## Executive Summary
This paper introduces a multi-fidelity active learning framework using GFlowNets to efficiently explore scientific discovery and engineering design spaces. The approach jointly samples objects and oracle fidelities, allowing cost-aware exploration by querying lower-fidelity oracles when uncertainty is high. GFlowNets naturally maintain diversity in sampled candidates, avoiding the mode collapse seen in RL-based alternatives. Experiments demonstrate significant cost savings while preserving diversity across synthetic and real-world tasks including DNA aptamer design and antimicrobial peptide discovery.

## Method Summary
The method uses GFlowNets to sample candidate objects and their evaluation fidelities proportionally to an acquisition function value. A multi-fidelity Gaussian Process or Deep Kernel Learning model serves as a surrogate, predicting oracle outputs at different fidelities. The max-value entropy search acquisition function is adapted for multi-fidelity settings, weighted by oracle costs. The GFlowNet policy is trained using trajectory balance to generate candidates, with top-scoring candidates evaluated by their corresponding oracles and added to the dataset. This process iterates until the budget is exhausted.

## Key Results
- Multi-fidelity GFlowNets discover high-scoring candidates at a fraction of the budget of single-fidelity methods
- GFlowNets maintain diversity in sampled candidates, unlike RL-based alternatives that collapse to single modes
- The method achieves cost savings of 2-4× compared to single-fidelity approaches on synthetic and biological tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-fidelity active learning with GFlowNets can discover high-scoring candidates at lower cost than single-fidelity methods.
- Mechanism: By jointly sampling objects and fidelity levels, the algorithm allocates queries to lower-fidelity oracles when uncertainty is high, saving budget for high-fidelity evaluations only when necessary.
- Core assumption: The surrogate model can accurately estimate posterior distributions for different fidelities, and the acquisition function can balance fidelity selection with cost.
- Evidence anchors:
  - [abstract]: "multi-fidelity active learning with GFlowNets can discover high-scoring candidates at a fraction of the budget of its single-fidelity counterpart while maintaining diversity."
  - [section 3.2]: "we seek to sample diverse objects with high value of the acquisition function" and "The multi-fidelity variant is designed to select the candidate x and the fidelity m that maximise the mutual information between f⋆M and the oracle at fidelity m, weighted by the cost of the oracle."

### Mechanism 2
- Claim: GFlowNets maintain diversity in the sampled candidates, unlike RL-based alternatives.
- Mechanism: The GFlowNet policy π(x) ∝ R(x) generates a probability distribution over objects proportional to their reward, naturally sampling from diverse high-reward regions rather than collapsing to a single mode.
- Core assumption: The reward function (acquisition function) has multiple peaks corresponding to diverse high-scoring regions.
- Evidence anchors:
  - [abstract]: "maintains diversity, unlike RL-based alternatives."
  - [section 3.1]: "GFlowNets are designed to learn a stochastic policy π that generates x ∈ X with a probability proportional to the reward, that is π(x) ∝ R(x). This distinctive property induces sampling diverse, high-reward objects."

### Mechanism 3
- Claim: The joint learning of object and fidelity policies allows better generalization than random fidelity selection.
- Mechanism: By allowing fidelity selection at any state in the trajectory, the GFlowNet can adaptively decide when to query lower vs. higher fidelity based on the current partial object and available information.
- Core assumption: The augmented state space SM′ = S ∪ M′ with flexible fidelity selection provides meaningful information for better policy learning.
- Evidence anchors:
  - [section 3.3]: "Intuitively, allowing the selection of the fidelity at any step in the trajectory should give flexibility for better generalisation."
  - [section 4.2]: "GFlowNet with random fidelities (Random fid. GFN): Variant of SF-GFN where the candidates are generated with the GFlowNet but the fidelities are picked randomly."

## Foundational Learning

- Concept: Gaussian Processes and Multi-fidelity Kernels
  - Why needed here: The surrogate model h(x,m) needs to model the posterior p(fm(x)|x,m,D) for different fidelities, requiring a multi-fidelity kernel that captures how fidelity affects predictions.
  - Quick check question: How does the multi-fidelity GP kernel combine the Matern kernel over objects with the linear downsampling kernel over fidelity levels?

- Concept: Active Learning and Acquisition Functions
  - Why needed here: The algorithm needs to actively select which candidates to evaluate at which fidelity, requiring an acquisition function that balances exploration and exploitation across fidelities.
  - Quick check question: What is the difference between the single-fidelity MES acquisition function and its multi-fidelity variant?

- Concept: GFlowNet Training and Trajectory Balance
  - Why needed here: The GFlowNet policy needs to be trained to sample objects and fidelities proportionally to the reward (acquisition function value), requiring the trajectory balance objective.
  - Quick check question: How does the trajectory balance objective ensure that the learned policy samples objects with probability proportional to their reward?

## Architecture Onboarding

- Component map:
  - Initial dataset -> Multi-fidelity surrogate model -> Acquisition function -> GFlowNet policy -> Sampled candidates -> Oracle evaluation -> Updated dataset

- Critical path:
  1. Fit surrogate model on current dataset
  2. Compute acquisition function values for candidate-fidelity pairs
  3. Train GFlowNet with acquisition function as reward
  4. Sample N candidates, select top B
  5. Query oracles, update dataset
  6. Repeat until budget exhausted

- Design tradeoffs:
  - GP vs DKL: GPs provide exact inference but don't scale to high dimensions; DKL scales better but introduces approximation
  - Fidelity selection flexibility: Allowing fidelity choice at any state increases generalization but adds complexity
  - Batch size N vs B: Larger N provides better coverage but increases computation

- Failure signatures:
  - Poor diversity: RL-based methods collapse to single modes, GFlowNet maintains diversity
  - Cost inefficiency: Single-fidelity methods use full budget, multi-fidelity methods achieve same performance with less budget
  - Surrogate inaccuracy: Poor predictions lead to suboptimal acquisition function values

- First 3 experiments:
  1. Implement multi-fidelity GP with synthetic Branin function, verify cost savings over single-fidelity
  2. Add GFlowNet policy training, compare diversity metrics with random fidelity selection
  3. Scale to DNA aptamer task, measure cost efficiency and diversity preservation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MF-GFN scale with the number of fidelity levels available?
- Basis in paper: [explicit] The paper mentions "M multi-fidelity oracles f1, . . . , fM" but only evaluates cases with 2-3 fidelities.
- Why unresolved: Experiments were limited to 2-3 fidelity levels, leaving open how performance changes with more levels.
- What evidence would resolve it: Experiments systematically varying M (number of fidelities) from 2 to 10+ while keeping total budget constant.

### Open Question 2
- Question: What is the theoretical relationship between oracle cost ratios and the performance gap between MF-GFN and SF-GFN?
- Basis in paper: [explicit] "The advantage of MF-GFN over SF-GFN decreases as the cost of the lowest-fidelity oracle becomes closer to the cost of the highest-fidelity oracle."
- Why unresolved: While empirical observations are made, no theoretical framework explains the relationship between cost ratios and performance differences.
- What evidence would resolve it: Mathematical analysis deriving performance bounds as a function of oracle cost ratios and fidelity gaps.

### Open Question 3
- Question: How does MF-GFN perform when the fidelity ordering assumption (higher m = higher fidelity) is violated?
- Basis in paper: [inferred] The paper assumes "the larger m, the higher the fidelity" without testing what happens when this assumption fails.
- Why unresolved: No experiments were conducted with misordered fidelities, leaving open whether the method is robust to such violations.
- What evidence would resolve it: Experiments with shuffled fidelity assignments and comparison to correctly ordered cases.

### Open Question 4
- Question: How does the performance change when using different acquisition functions with MF-GFN?
- Basis in paper: [explicit] "we use the multi-fidelity version [63] of max-value entropy search (MES)" but don't compare to alternatives.
- Why unresolved: Only one acquisition function was tested, though the paper notes other information-theoretic options exist.
- What evidence would resolve it: Direct comparisons using expected improvement, probability of improvement, and other information-theoretic acquisition functions.

### Open Question 5
- Question: What is the impact of the batch size B on the exploration-exploitation trade-off in MF-GFN?
- Basis in paper: [inferred] The algorithm uses a fixed batch size B but doesn't analyze how different batch sizes affect performance.
- Why unresolved: No systematic study of batch size effects was presented, despite its importance in active learning.
- What evidence would resolve it: Experiments varying B from small to large values while monitoring diversity and score metrics.

## Limitations

- Limited scalability testing for very large molecular datasets beyond the small-molecule example
- Performance sensitivity to oracle cost ratios not thoroughly characterized
- Single acquisition function used without comparison to alternatives

## Confidence

- **High confidence**: The cost-efficiency advantage of multi-fidelity over single-fidelity methods (supported by synthetic and real-world experiments)
- **Medium confidence**: The superiority of GFlowNet diversity maintenance over RL-based alternatives (limited comparison in experiments)
- **Medium confidence**: The generalization benefit of joint object-fidelity policy learning over random fidelity selection (based on limited ablation studies)

## Next Checks

1. **Reproduce synthetic task results**: Implement the Branin and Hartmann experiments to verify the cost-efficiency claims before scaling to biological tasks
2. **Hyperparameter sensitivity analysis**: Test the robustness of results to changes in batch sizes, fidelity costs, and GFlowNet architecture choices
3. **Comparison with alternative diversity methods**: Implement and compare against explicit diversity constraints or entropy-based sampling to validate GFlowNet's diversity advantage