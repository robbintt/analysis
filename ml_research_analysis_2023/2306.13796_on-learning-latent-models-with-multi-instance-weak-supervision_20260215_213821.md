---
ver: rpa2
title: On Learning Latent Models with Multi-Instance Weak Supervision
arxiv_id: '2306.13796'
source_url: https://arxiv.org/abs/2306.13796
tags:
- learning
- classi
- loss
- where
- partial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel weakly supervised learning setting
  where labels are produced by a transition function of multiple input instances.
  The authors formulate this as a multi-instance partial label learning (PLL) problem
  and prove learnability under minimal assumptions, even when the transition is unknown.
---

# On Learning Latent Models with Multi-Instance Weak Supervision

## Quick Facts
- arXiv ID: 2306.13796
- Source URL: https://arxiv.org/abs/2306.13796
- Reference count: 40
- Primary result: Introduces learnability theory for multi-instance PLL with unknown transitions under M-unambiguity conditions

## Executive Summary
This paper establishes the first theoretical framework for learning under multi-instance weak supervision where labels are generated by transition functions of multiple instances. The authors prove that learning is possible even when the transition function is unknown, provided the transition space satisfies an M-unambiguity condition. They show that the learning difficulty increases exponentially with the number of instances M, exposing critical scalability challenges in weak supervision. The work bridges neuro-symbolic reasoning with weak supervision through semantic loss formulations.

## Method Summary
The paper formulates multi-instance PLL as learning classifiers from examples where each training sample consists of M instances and a partial label produced by applying an unknown transition function to the gold labels. The method uses top-k approximations of semantic loss for tractable training and proves Rademacher-style error bounds under M-unambiguity conditions. Empirical validation employs neuro-symbolic frameworks (DeepProbLog, NeurASP, NeuroLog) to solve weighted sum problems with MNIST digits, comparing known vs unknown transition scenarios.

## Key Results
- Learning is theoretically guaranteed under M-unambiguity even with unknown transitions
- Error bounds show classification risk scales as O(R01P(f;σ)^(1/M)), making learning exponentially harder as M increases
- Top-k semantic loss approximations facilitate learning with unknown transitions, outperforming full DLog-A approximations
- Experiments confirm theoretical predictions: M=2 and M=3 work well, but M=4 suffers significant accuracy degradation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multi-instance weak supervision can be learnable even when the transition function is unknown, provided the transition space is unambiguous.
- **Mechanism:** The learning process exploits the inherent constraints imposed by the partial labels. When the transition space is unambiguous, no candidate transition can map misclassified label vectors to the same observed partial label, allowing error detection and correction.
- **Core assumption:** The transition space contains the true transition and is unambiguous, meaning that for any candidate transition, misclassifications can be detected because they lead to different partial labels.
- **Evidence anchors:**
  - [abstract]: "we provide the first theoretical study of multi-instance PLL with possibly an unknown transition σ"
  - [section 5.1]: "Transition space G is unambiguous, if for each σ ′ ∈ G, each diagonal label vector y = ( li, . . . , l i), where li ∈ Y, and each lj ̸= li, where lj ∈ Y, there exists a vector y′ ∈ { li, l j}M , such that σ ′(y′) ̸= σ (y)"

### Mechanism 2
- **Claim:** Learning becomes harder as the number of instances M increases, due to the exponential growth in the label space.
- **Mechanism:** The error bounds show that the classification risk is inversely proportional to M (R01(f) ≤ O(R01P(f;σ)1/M)). As M grows, the partial label provides less supervision power because there are exponentially more possible label combinations to disambiguate.
- **Core assumption:** The transition function is M-unambiguous, ensuring that misclassifications can be detected.
- **Evidence anchors:**
  - [abstract]: "they also expose the issue of scalability in the weak supervision literature"
  - [section 3.2]: "Theorem 2 suggests that the difficulty of learning increases as M becomes large"

### Mechanism 3
- **Claim:** Using top-k approximations of the semantic loss can facilitate learning under unknown transitions.
- **Mechanism:** Instead of considering all possible label combinations consistent with the partial label, only the k most probable ones are used during training. This reduces computational complexity while maintaining learning guarantees.
- **Core assumption:** The top-k label vectors can be approximated as a formula that is true iff one or more of the top-k label vectors is the gold one.
- **Evidence anchors:**
  - [section 3.2]: "A popular way to reduce the second source of inefﬁciency is to consider only the k most probable label combinations during training"
  - [section 6]: "the approximations in DLog-A (ﬁrst row of Table 2) perform worse than the top-k one of NLog (last row of Table 2), suggesting that this simpler top-k approximation can facilitate learning"

## Foundational Learning

- **Concept: Multi-instance Partial Label Learning (PLL)**
  - Why needed here: This paper extends standard PLL to handle multiple instances per training example, where the label for each instance is hidden but a function of their combined labels is observed.
  - Quick check question: In standard PLL, each example has one instance and a set of candidate labels. How does multi-instance PLL differ in terms of the supervision signal?

- **Concept: Unambiguous Transitions**
  - Why needed here: Unambiguity is a key condition for learnability. It ensures that misclassifications can be detected based on the partial labels.
  - Quick check question: What is the difference between M-unambiguity and 1-unambiguity, and why are both important for learning?

- **Concept: Semantic Loss and Weighted Model Counting**
  - Why needed here: The semantic loss is used as a surrogate loss function for training classifiers under logical constraints, which is essential for neuro-symbolic integration.
  - Quick check question: How does the semantic loss relate to the cross-entropy loss, and why is it particularly useful for training under logical theories?

## Architecture Onboarding

- **Component map:**
  Input instances (x1,...,xM) -> Classifiers (f1,...,fM) -> Label distributions -> Top-k label combinations -> Semantic loss -> Parameter updates

- **Critical path:**
  1. Receive training sample (x1,...,xn,s)
  2. Classifiers predict label distributions for each instance
  3. Compute top-k most probable label combinations consistent with s
  4. Calculate semantic loss based on these combinations
  5. Backpropagate error to update classifiers

- **Design tradeoffs:**
  - M-unambiguity vs. computational efficiency: Stronger conditions ensure learnability but may be harder to satisfy
  - Top-k approximation: Balances computational efficiency with learning accuracy
  - Known vs. unknown transition: Known transitions allow for stronger theoretical guarantees but are less flexible

- **Failure signatures:**
  - Poor accuracy when M is large: Indicates insufficient supervision power
  - No improvement with more training data: Suggests ambiguous transition space
  - Instability in learned classifiers: May indicate issues with the loss function or optimization

- **First 3 experiments:**
  1. Verify M-unambiguity for a simple SUM2 problem with M=2
  2. Test learning with known transition using top-1 semantic loss
  3. Evaluate scalability by increasing M and observing accuracy degradation

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the text provided.

## Limitations

- Theoretical guarantees require strong M-unambiguity conditions that may not hold in practical applications
- Significant scalability challenges when M increases beyond 3, with exponential degradation in learning quality
- Empirical validation limited to synthetic MNIST-based weighted sum problems rather than real-world applications

## Confidence

- **High confidence:** The theoretical framework and proofs are well-constructed and follow established learning theory principles
- **Medium confidence:** The empirical validation using neuro-symbolic frameworks, though limited by the complexity of the experimental setup
- **Low confidence:** The generalizability of the M-unambiguity condition to real-world problems

## Next Checks

1. Test the M-unambiguity condition on synthetic data with varying transition functions to empirically validate the learnability bounds
2. Evaluate the top-k approximation with different k values on the MNIST weighted sum problem to find the optimal trade-off between computational efficiency and accuracy
3. Investigate alternative loss functions that may provide better scalability when M is large, such as hierarchical or curriculum-based approaches