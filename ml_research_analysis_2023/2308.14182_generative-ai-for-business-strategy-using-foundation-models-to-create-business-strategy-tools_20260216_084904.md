---
ver: rpa2
title: 'Generative AI for Business Strategy: Using Foundation Models to Create Business
  Strategy Tools'
arxiv_id: '2308.14182'
source_url: https://arxiv.org/abs/2308.14182
tags:
- apple
- facebook
- business
- news
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a framework for constructing signed business\
  \ networks using generative AI models. The authors combine unstructured news data\
  \ with multiple foundation models\u2014including GPT4, transformer-based NER, and\
  \ entailment-based zero-shot classifiers\u2014to extract firms and infer their relationships\
  \ over time."
---

# Generative AI for Business Strategy: Using Foundation Models to Create Business Strategy Tools

## Quick Facts
- arXiv ID: 2308.14182
- Source URL: https://arxiv.org/abs/2308.14182
- Reference count: 2
- This paper introduces a framework for constructing signed business networks using generative AI models to analyze firm relationships and market dynamics.

## Executive Summary
This paper presents a framework that leverages multiple foundation models to construct signed business networks from unstructured news data. By combining transformer-based Named Entity Recognition (NER), zero-shot classifiers, and instruction-tuned LLMs, the approach extracts firms and infers their relationships over time. The resulting networks provide a graphical abstraction useful for strategic business decision-making, with GPT4 offering textual explanations of network edges. Initial results demonstrate accurate identification of firms and relationships from news headlines, showing the framework's ability to detect market shifts such as Apple's privacy policy changes impacting competitors.

## Method Summary
The framework employs a multi-stage pipeline that processes news headlines to construct signed business networks. It uses XLM-RoBERTa-large fine-tuned on conll2003 for organization entity extraction, an Entailment-based Zero-shot Classifier (ZSC) to infer relationship types (positive, negative, neutral, or unknown) between organizations, and GPT4 to generate textual explanations for the inferred relationships. The approach combines unstructured news data with multiple foundation models to create weighted edges representing business relationships, enabling analysis of market dynamics without requiring technical expertise from users.

## Key Results
- Accurate identification of firms and relationships from news headlines using foundation models
- GPT4 provides textual explanations of network edges, enhancing interpretability
- Successfully detected market shifts, such as Apple's privacy policy changes impacting competitors
- Framework demonstrates potential for strategic business decision-making through graphical network abstraction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer-based NER models can accurately identify organization entities from news headlines, enabling node extraction in signed business networks.
- Mechanism: The XLM-RoBERTa-large model, fine-tuned on the conll2003 dataset, is capable of detecting and classifying organization names in unstructured text, providing the foundation for building business network nodes.
- Core assumption: The fine-tuned NER model generalizes well to business news headlines beyond the training dataset.
- Evidence anchors:
  - [section]: "we employ the XLM-RoBERTa-large model, which is fine-tuned with the conll2003 dataset in English (Conneau et al., 2019), to detect and extract organizations."
  - [abstract]: "we combine unstructured textual data sources (e.g., news data) with multiple foundation models (namely, GPT4, transformer-based Named Entity Recognition (NER) models...)"
- Break condition: If the news headlines contain ambiguous entity references or rare organization names not present in the training data, the NER model's accuracy will degrade significantly.

### Mechanism 2
- Claim: Zero-shot classifiers can infer relationship types between organizations without requiring labeled training data.
- Mechanism: The Entailment-based Zero-shot Classifier uses a pre-trained NLI model to determine if a hypothesis about the relationship (e.g., "the relationship between company A and B is positive") is entailed by the premise (news headline), enabling classification into positive, negative, neutral, or unknown categories.
- Core assumption: The semantic similarity captured by the NLI model is sufficient to distinguish between different relationship types in business contexts.
- Evidence anchors:
  - [section]: "we employ an additional ZSC to extract further details... The classifier assesses whether a hypothesis supports or contradicts a premise... The hypothesis is as follows: 'the relationship between company A and B is <CLASS>'"
  - [abstract]: "transformer-based Named Entity Recognition (NER) models and Entailment-based Zero-shot Classifiers (ZSC)"
- Break condition: If the news headlines contain nuanced or context-dependent relationships that the NLI model cannot capture through simple entailment checking, classification accuracy will suffer.

### Mechanism 3
- Claim: Instruction-tuned LLMs can provide textual explanations for the inferred relationship signs, enhancing interpretability of the business network.
- Mechanism: GPT4 is used to generate explanations for why certain relationships are classified as positive, negative, or neutral by analyzing the context and semantics of news headlines.
- Core assumption: The LLM's instruction-tuning provides sufficient reasoning capability to explain complex business relationships.
- Evidence anchors:
  - [section]: "Complementing this pipeline, as shown in Figure 2, we use an instruction-tuned LLM to provide explanations of the signs inferred from each news headline/article."
  - [abstract]: "Our approach will be augmented with GPT4 for textual explanations of the signs/weights of the learned network."
- Break condition: If the LLM's explanations become inconsistent or fail to align with the actual relationship classifications, users may lose trust in the network's validity.

## Foundational Learning

- Concept: Named Entity Recognition
  - Why needed here: To identify and extract organization names from unstructured news text, which become the nodes in the business network.
  - Quick check question: What type of entities would you expect to find in a business news headline, and how would you categorize them?

- Concept: Zero-shot classification
  - Why needed here: To determine the type of relationship between organizations without requiring a labeled dataset for each possible relationship type.
  - Quick check question: How would you design a zero-shot classifier to distinguish between positive and negative business relationships using natural language inference?

- Concept: Instruction-tuned LLMs
  - Why needed here: To provide human-readable explanations for the relationships inferred by the network, making the results more interpretable for business stakeholders.
  - Quick check question: What kind of prompts would you give to an LLM to generate explanations for business relationship classifications?

## Architecture Onboarding

- Component map:
  News API -> Stock news filter (ZSC) -> Organization NER (XLM-RoBERTa-large) -> Entity linking/disambiguation -> Sub-entity extraction (ZSC) -> Relationship classification (ZSC) -> Relationship explanation (GPT4) -> Signed business network visualization

- Critical path:
  1. Fetch news data for target companies
  2. Filter out stock-only news using ZSC
  3. Extract organizations using NER
  4. Link entity variants to canonical names
  5. Extract sub-entities and relationships
  6. Classify relationship types using ZSC
  7. Generate explanations using GPT4
  8. Build and visualize signed network

- Design tradeoffs:
  - Accuracy vs. speed: Using multiple foundation models provides high accuracy but increases processing time and cost
  - Granularity vs. simplicity: Including sub-entities provides detailed insights but may complicate the network visualization
  - Zero-shot vs. fine-tuned: Zero-shot classifiers avoid training data requirements but may be less accurate than fine-tuned models for specific domains

- Failure signatures:
  - High proportion of "unknown" relationship classifications
  - Inconsistent entity linking resulting in duplicate nodes
  - Explanations that don't align with the relationship classifications
  - Network that doesn't reflect known business realities

- First 3 experiments:
  1. Run the pipeline on a small set of hand-curated news headlines with known relationships to validate accuracy
  2. Compare the output network against a manually constructed network for a small set of companies to check alignment
  3. Test the entity linking component with company names that have multiple common variations to ensure proper deduplication

## Open Questions the Paper Calls Out
- How accurately can the proposed framework identify and classify relationships between firms compared to traditional methods?
- Can the framework effectively scale to analyze relationships across all companies in a specific industry or the entire S&P500?
- How well can the framework predict future relationships between firms based on the learned signed business networks?

## Limitations
- Accuracy of entity linking and disambiguation is not validated, potentially leading to incorrect network structures
- Zero-shot classifiers' performance on complex business relationships is not empirically tested
- Generalizability beyond the tech sector is unproven without quantitative evaluation metrics

## Confidence
- High Confidence: The overall framework design and architectural approach for combining multiple foundation models in a pipeline is sound and well-motivated
- Medium Confidence: The feasibility of using transformer-based NER for entity extraction from news headlines, based on established capabilities of these models
- Low Confidence: The accuracy and reliability of zero-shot classifiers for business relationship inference, and the practical utility of the resulting signed business networks for strategic decision-making

## Next Checks
1. **Quantitative Component Evaluation**: Measure and report precision, recall, and F1 scores for the NER model on a held-out validation set of business news headlines, and evaluate the zero-shot classifier's accuracy on a labeled dataset of business relationships
2. **Cross-Domain Generalization Test**: Apply the complete pipeline to news data from a different industry sector (e.g., healthcare or finance) to assess whether the approach generalizes beyond the tech companies used in the illustrative example
3. **Ground Truth Comparison**: Construct a manually annotated signed business network for a small set of companies over a specific time period, then compare it against the network generated by the automated pipeline to quantify accuracy and identify systematic errors