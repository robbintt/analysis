---
ver: rpa2
title: Incorporating Class-based Language Model for Named Entity Recognition in Factorized
  Neural Transducer
arxiv_id: '2309.07648'
source_url: https://arxiv.org/abs/2309.07648
tags:
- name
- recognition
- named
- neural
- transducer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes C-FNT, a novel end-to-end (E2E) model that
  integrates class-based language models (LMs) into factorized neural Transducer (FNT)
  to improve named entity recognition (NER) in speech recognition. The key idea is
  to use a class-based LM to compute the gross LM probability of a specific class
  (e.g., person name) instead of its surface form.
---

# Incorporating Class-based Language Model for Named Entity Recognition in Factorized Neural Transducer

## Quick Facts
- arXiv ID: 2309.07648
- Source URL: https://arxiv.org/abs/2309.07648
- Reference count: 0
- Key outcome: C-FNT achieves 27.9% and 30.8% relative gain in F1-score for person names on Giga-name-test and NER-name-test test sets, respectively, compared to FNT baseline.

## Executive Summary
This paper introduces C-FNT, a novel end-to-end model that integrates class-based language models into factorized neural Transducer (FNT) to improve named entity recognition in speech recognition. The key innovation is using a class-based LM to compute the gross LM probability of a semantic class (e.g., person name) instead of specific surface forms, addressing the long-tail problem in E2E models. Experimental results show significant improvements in named entity recognition without hurting general word recognition performance.

## Method Summary
The method involves training a baseline FNT model on Gigaspeech-M dataset, then applying an NER toolkit to acoustic transcriptions to generate tagged data with @name class. A class-based LSTM language model is trained on this augmented text data. The class-based LM replaces the word-based LM in FNT to create C-FNT model, with dynamic beam search decoding that handles name class transitions and maintains beams outside name class to avoid decoding collapse.

## Key Results
- C-FNT achieves 27.9% relative gain in F1-score on Giga-name-test test set
- C-FNT achieves 30.8% relative gain in F1-score on NER-name-test test set
- C-FNT maintains general ASR performance while improving named entity recognition
- Dynamic beam search is mandatory; greedy search causes severe performance degradation

## Why This Works (Mechanism)

### Mechanism 1
The class-based LM allows named entity probability to be computed over a semantic class instead of specific surface forms, solving the long-tail problem in E2E models. Instead of computing P(Loretta Lynn | "I will call"), the model computes P(@name | "I will call") * P(Loretta Lynn | @name), where @name is a learned class tag. This allows the LM to generalize over unseen or rare named entities by associating them with a high-level class.

### Mechanism 2
Standard E2E models like neural Transducer jointly optimize acoustic and linguistic features, so if a named entity is rare or unseen in training, the model cannot generate it because both acoustic and linguistic likelihoods are low. C-FNT decouples these via the factorized structure, letting the LM handle linguistic coverage separately.

### Mechanism 3
Beam search decoding in C-FNT must maintain beams outside the name class to avoid getting stuck emitting only named entities, ensuring general word recognition performance is preserved. The decoder tracks beam status (S0=out, S1=entering, S2=staying, S3=exiting). At least one beam is kept in S0 at each step, preventing the model from collapsing into the name class and emitting only blanks.

## Foundational Learning

- **Factorized Neural Transducer (FNT)**: Separates acoustic and linguistic prediction pathways, making it possible to plug in a standalone LM, which is essential for integrating a class-based LM. Quick check: In FNT, how are blank tokens and vocabulary tokens predicted differently from standard neural Transducer?

- **Class-based Language Models**: Allow computing probabilities over named entity classes instead of individual surface forms, solving the data sparsity problem for long-tail entities. Quick check: How does the probability computation change when using a class-based LM versus a word-level LM for a named entity like "Loretta Lynn"?

- **Beam Search with Status Tracking**: C-FNT's beam search must track whether a beam is inside or outside the name class to avoid decoding collapse and maintain recognition of both general words and named entities. Quick check: Why can't greedy search be used in C-FNT, and what problem does it cause?

## Architecture Onboarding

- **Component map**: Encoder -> Blank Predictor -> Joint Net -> Output (blank vocab)
  Encoder -> Vocabulary Predictor (class-based LM) -> Joint Net -> Output (named entity class)
  Both paths feed into beam search with status tracking.

- **Critical path**: The model uses 12-layer Conformer encoder, 2-layer LSTM predictor, and dynamic beam search decoding with name list support. The vocabulary size doubles to include normal vocab and name class.

- **Design tradeoffs**: Vocabulary size doubles (normal + name class), increasing computation. Requires NER model for preprocessing training text. Dynamic beam size in name class to avoid path duplication. Beam search is mandatory (greedy fails).

- **Failure signatures**: WER spikes on general words when name list is large or irrelevant. Decoding gets stuck in name class (only blanks emitted). Named entity F1-score drops if class boundaries are too broad or sparse.

- **First 3 experiments**:
  1. Train C-FNT without name list; verify WER matches FNT baseline on GigaSpeech.
  2. Add small name list; measure F1-score gain on Giga-name-test vs. FNT.
  3. Test dynamic beam search vs. fixed beam; observe trade-offs in decoding stability and accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
How does the C-FNT model perform when dealing with named entities that are not person names, such as organization names or location names? The paper primarily focuses on person names as a case study for named entity recognition, and it is mentioned that the class-based LM can be extended to support other types of named entities or domains.

### Open Question 2
What is the impact of the dynamic beam search strategy on the computational efficiency and real-time performance of C-FNT? The paper mentions that dynamic beam search is used to avoid decoding getting stuck in the name class and to improve ASR and NER performances, but it does not discuss the computational efficiency or real-time performance implications.

### Open Question 3
How does the performance of C-FNT vary with different sizes of the name list and different levels of out-of-vocabulary (OOV) rates? The paper evaluates C-FNT using two test sets with different name list sizes and mentions that the model's performance might be affected by the coverage of named entities in the training data.

## Limitations
- The method depends on an external NER tool (dslim/bert-base-NER-uncased) to tag training text with @name class, which could introduce errors if the NER model has recall/precision issues or domain mismatch.
- The assumption that a single @name class is sufficient for all named entities is weakly justified, as entity types (person, organization, location) have different LM distributions.
- The computational overhead of doubling vocabulary size and implementing dynamic beam search is not analyzed, making scalability unclear.

## Confidence
- **High Confidence**: The core mechanism of decoupling acoustic and linguistic predictions via FNT factorization is well-supported by prior work. The experimental F1-score gains (27.9â€“30.8%) on test sets are clearly demonstrated.
- **Medium Confidence**: The claim that beam search is mandatory (greedy fails) is supported by the paper's experiments but lacks ablation on why greedy search fails or how status transitions prevent collapse.
- **Low Confidence**: The assumption that a single @name class is sufficient for all named entities is weakly justified. No experiments compare single-class vs. multi-class (person/organization/location) LMs.

## Next Checks
1. **Ablation on Class Granularity**: Retrain C-FNT with separate classes (@person, @org, @loc) and compare F1-score vs. single @name class to test whether entity type specificity improves recognition accuracy.

2. **NER Tool Error Analysis**: Measure precision/recall of the NER tool on Gigaspeech transcriptions. Correlate tagging errors with C-FNT F1-score drops to quantify dependency on NER quality.

3. **Beam Search Robustness**: Compare decoding performance across beam sizes (1, 5, 10, 20) and status transition rules. Test whether the mandatory beam search claim holds by measuring WER/F1 degradation under greedy decoding with and without name list.