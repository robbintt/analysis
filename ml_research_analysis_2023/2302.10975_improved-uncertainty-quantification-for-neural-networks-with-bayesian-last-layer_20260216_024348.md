---
ver: rpa2
title: Improved uncertainty quantification for neural networks with Bayesian last
  layer
arxiv_id: '2302.10975'
source_url: https://arxiv.org/abs/2302.10975
tags:
- which
- test
- extrapolation
- where
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a novel approach for training neural networks
  with Bayesian last layer (BLL), a simplified form of Bayesian neural networks that
  yield analytical predictive distributions. The key innovation is a reformulation
  of the log-marginal likelihood that avoids matrix inversion, enabling efficient
  gradient-based optimization of deterministic weights as hyperparameters.
---

# Improved uncertainty quantification for neural networks with Bayesian last layer

## Quick Facts
- arXiv ID: 2302.10975
- Source URL: https://arxiv.org/abs/2302.10975
- Reference count: 38
- Key outcome: A reformulated log-marginal likelihood enables efficient training of Bayesian last layer networks while preserving optimal solutions, with improved extrapolation uncertainty quantification.

## Executive Summary
This paper presents a novel approach for training neural networks with Bayesian last layer (BLL), a simplified form of Bayesian neural networks that yield analytical predictive distributions. The key innovation is a reformulation of the log-marginal likelihood that avoids matrix inversion, enabling efficient gradient-based optimization of deterministic weights as hyperparameters. Additionally, a method is proposed to improve extrapolation uncertainty quantification by relating the BLL covariance to an intuitive metric for extrapolation. The approach is demonstrated in a multivariate toy example and a dynamic system identification task, where it outperforms Bayesian linear regression with fixed neural network features in terms of log-predictive density.

## Method Summary
The method reformulates the BLL log-marginal likelihood by reintroducing the last-layer weights as optimization variables while maintaining the optimal solution through a constrained optimization framework. This eliminates the need for expensive matrix inversion during training. The model treats all weights except the last layer as deterministic, with the last layer following a Gaussian distribution. Training maximizes the log-marginal likelihood with respect to both the deterministic weights and hyperparameters (α, noise variance). For extrapolation detection, the method establishes a relationship between an affine cost metric and the BLL covariance, allowing practical uncertainty quantification without expensive convex hull computations.

## Key Results
- The reformulated BLL training avoids matrix inversion while preserving optimal solutions, enabling efficient backpropagation
- BLL with tuned α outperforms Bayesian linear regression with fixed neural network features on a dynamic system identification task
- The affine cost metric provides an efficient approximation for detecting extrapolation and quantifying uncertainty in BLL models

## Why This Works (Mechanism)

### Mechanism 1
Reformulating the log-marginal likelihood by introducing the last-layer weights as optimization variables avoids expensive matrix inversion while preserving the optimal solution. The original BLL objective marginalizes out the last-layer weights, creating a term involving the inverse of the precision matrix Λp. By reintroducing these weights as variables and adding an equality constraint that enforces their optimal relationship, the Lagrangian analysis shows the Lagrange multiplier vanishes, making the constrained and unconstrained problems equivalent. This reformulation eliminates the need to compute Λp⁻¹ explicitly, enabling gradient-based optimization via backpropagation.

### Mechanism 2
The affine cost metric provides a computationally tractable approximation of the convex hull distance, enabling efficient quantification of extrapolation for BLL models. The affine cost is defined as a weighted least-squares problem that minimizes the norm of spanning coefficients plus a weighted residual term. When the test point lies outside the affine hull of training features, the cost is dominated by the residual term weighted by γ. The authors show that when γ = α, the affine cost equals the scaled BLL covariance. This establishes a direct relationship between a simple computational metric and the model's uncertainty, allowing practical extrapolation detection without expensive convex hull computations.

### Mechanism 3
Maximizing the log-marginal likelihood with appropriate α regularization encourages the feature space to have low rank, creating a proper subspace for the affine hull and enabling meaningful extrapolation detection. The log-determinant regularization term in the marginal likelihood objective penalizes large determinants of the precision matrix Λp. Since Λp contains Φ⊤Φ + α⁻¹Inφ, this regularization encourages Φ⊤Φ to have low rank, meaning the features lie in a subspace of dimension less than nφ. This creates a situation where test points can fall outside the affine hull, making the extrapolation metric meaningful.

## Foundational Learning

- **Concept**: Bayesian linear regression and Gaussian processes as probabilistic regression frameworks
  - Why needed here: BLL is conceptually related to BLR and GPs, sharing the idea of a nonlinear feature space mapped linearly to outputs. Understanding these frameworks provides the theoretical foundation for BLL and helps interpret the results.
  - Quick check question: What is the key difference between Bayesian linear regression and Gaussian processes in terms of feature representation?

- **Concept**: Marginal likelihood maximization (empirical Bayes) for hyperparameter learning
  - Why needed here: The BLL model is trained by maximizing the log-marginal likelihood, which involves integrating out the last-layer weights. Understanding this optimization objective is crucial for implementing the training algorithm.
  - Quick check question: In the BLL setting, what hyperparameters are being optimized when maximizing the marginal likelihood?

- **Concept**: Neural network feature extraction and the role of activation functions
  - Why needed here: BLL depends on the feature space φ(x; WL) extracted by the deterministic layers of the network. The choice of architecture and activation functions directly affects the quality of the learned features and thus the model's performance.
  - Quick check question: How does the choice of activation function in the hidden layers affect the feature space learned by a BLL model?

## Architecture Onboarding

- **Component map**: Input layer (nx-dim) -> Hidden layers (L layers with activation functions gl(·)) -> Output layer (linear with Gaussian weights w) -> Hyperparameters (WL, σe, σw, α)
- **Critical path**:
  1. Forward pass: Compute φ = φ(X; WL) from training inputs
  2. Compute Λp = Φ⊤Φ + α⁻¹Inφ
  3. Compute y = Φw using w = σ⁻²e Λp⁻¹Φ⊤t
  4. Evaluate loss J(Θ;D) using (50)
  5. Backpropagate gradients to update WL, α, and log(σe)
  6. For extrapolation tuning: evaluate LPD on validation data and adjust α
- **Design tradeoffs**:
  - Network depth vs. feature expressiveness: Deeper networks can learn more complex features but may overfit
  - α value: Higher α increases extrapolation uncertainty but may reduce interpolation performance
  - Early stopping vs. training to convergence: Early stopping prevents overfitting but may underfit
- **Failure signatures**:
  - Overconfident predictions (small variance) on extrapolation points
  - Unstable training (exploding/vanishing gradients) due to poor feature scaling
  - Poor performance when features have full rank (α has no effect on uncertainty)
- **First 3 experiments**:
  1. Train a simple 2-layer network on a univariate toy problem and visualize the predicted mean and variance vs. true function
  2. Compare BLL performance with standard BLR using fixed neural network features on a synthetic dataset
  3. Test the extrapolation uncertainty tuning by evaluating LPD on validation data with different α values

## Open Questions the Paper Calls Out

- **Question**: How can the proposed method be extended to handle dynamic systems with time-varying noise characteristics?
  - Basis in paper: [inferred] The paper demonstrates the effectiveness of the method on a linear triple-mass-spring system with constant noise characteristics. However, real-world systems often exhibit time-varying noise.
  - Why unresolved: The current formulation assumes constant noise characteristics, and the extension to time-varying noise is not addressed.
  - What evidence would resolve it: Experimental results demonstrating the effectiveness of the method on dynamic systems with time-varying noise characteristics, such as those encountered in robotics or autonomous systems.

- **Question**: Can the proposed method be adapted to handle non-Gaussian noise distributions?
  - Basis in paper: [inferred] The paper assumes Gaussian noise distributions for both the additive noise and the prior distribution of the weights. However, real-world data often exhibits non-Gaussian noise.
  - Why unresolved: The current formulation is based on Gaussian assumptions, and the extension to non-Gaussian noise is not addressed.
  - What evidence would resolve it: Theoretical analysis and experimental results demonstrating the effectiveness of the method on data with non-Gaussian noise distributions, such as those encountered in sensor measurements or financial data.

- **Question**: How can the proposed method be integrated with other Bayesian techniques, such as Bayesian optimization or active learning, to further improve uncertainty quantification?
  - Basis in paper: [explicit] The paper focuses on the training and inference of Bayesian last layer networks. However, the integration with other Bayesian techniques is not discussed.
  - Why unresolved: The potential benefits and challenges of integrating the proposed method with other Bayesian techniques are not explored.
  - What evidence would resolve it: Case studies and experimental results demonstrating the effectiveness of the proposed method when integrated with other Bayesian techniques, such as Bayesian optimization or active learning, for tasks such as hyperparameter tuning or data selection.

## Limitations
- The theoretical analysis assumes the feature space satisfies Assumptions 1-3, which may not hold for complex neural network architectures
- The extrapolation uncertainty metric relies on a specific relationship between the affine cost and BLL covariance that requires careful tuning of α
- The experimental validation is limited to a single multivariate toy problem and one system identification task, leaving generalizability to other domains uncertain

## Confidence
- **High confidence**: The reformulation of the log-marginal likelihood that avoids matrix inversion is mathematically sound and the gradient-based optimization approach is valid (Mechanism 1)
- **Medium confidence**: The relationship between affine cost and BLL covariance for extrapolation detection is theoretically established but may be sensitive to parameter choices in practice (Mechanism 2)
- **Medium confidence**: The claim that LML maximization encourages low-rank features is supported by the log-determinant regularization argument, but empirical validation across diverse datasets is needed (Mechanism 3)

## Next Checks
1. **Ablation study on α**: Systematically vary α across multiple orders of magnitude and evaluate the impact on both interpolation and extrapolation performance to determine optimal tuning strategies
2. **Feature space analysis**: For trained models, compute the rank of Φ⊤Φ and visualize the affine hull structure to empirically verify that LML maximization creates the expected subspace geometry
3. **Cross-domain generalization**: Apply BLL to additional regression tasks (e.g., time series forecasting, image regression) to assess whether the theoretical advantages translate to diverse real-world problems