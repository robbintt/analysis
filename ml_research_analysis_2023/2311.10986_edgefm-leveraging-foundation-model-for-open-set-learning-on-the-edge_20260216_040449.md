---
ver: rpa2
title: 'EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge'
arxiv_id: '2311.10986'
source_url: https://arxiv.org/abs/2311.10986
tags:
- edgefm
- data
- edge
- accuracy
- latency
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EdgeFM is a novel edge-cloud cooperative system that enables open-set
  recognition for IoT devices by leveraging foundation models (FMs) for selective
  knowledge query and edge model customization. It addresses the challenge of limited
  resources on edge devices, which makes traditional on-device deep learning models
  hard to generalize to diverse environments and tasks.
---

# EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge

## Quick Facts
- arXiv ID: 2311.10986
- Source URL: https://arxiv.org/abs/2311.10986
- Reference count: 40
- Key outcome: EdgeFM reduces end-to-end latency up to 3.2x and increases accuracy up to 34.3% compared to baseline.

## Executive Summary
EdgeFM is a novel edge-cloud cooperative system that enables open-set recognition for IoT devices by leveraging foundation models (FMs) for selective knowledge query and edge model customization. The system addresses the challenge of limited resources on edge devices, which makes traditional on-device deep learning models hard to generalize to diverse environments and tasks. EdgeFM selectively uploads unlabeled data to query FMs on the cloud and customizes specific knowledge and architectures for edge models, while conducting dynamic model switching at runtime considering both data uncertainty and network variations. The system was implemented on two FMs (CLIP and ImageBind) and two edge platforms (Nvidia Jetson Xavier and Nano), and evaluated on three public datasets and two self-collected datasets.

## Method Summary
EdgeFM combines foundation models on the cloud with lightweight edge models, using semantic-driven customization and dynamic model switching. The system trains lightweight CNNs using pseudo labels from FMs via bidirectional contrastive learning and feature projection. During inference, a router model decides whether to use the edge model or query the FM based on uncertainty (measured via semantic similarity margin) and network conditions. The threshold for this decision is tuned in real-time to adapt to dynamic network variations. The system also includes content-aware data uploading and user device profiling to optimize performance for specific tasks and resource constraints.

## Key Results
- Reduces end-to-end latency up to 3.2x compared to baseline
- Achieves 34.3% accuracy increase compared to baseline
- Maintains accuracy close to original FM while minimizing cloud queries

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** EdgeFM reduces end-to-end latency by selectively querying the foundation model on the cloud only when the edge model's uncertainty exceeds a dynamic threshold.
- **Mechanism:** The system uses semantic similarity between the edge model's predictions and a pre-stored text embedding pool to quantify uncertainty. When uncertainty is high, data is offloaded to the cloud; otherwise, the edge model handles inference locally.
- **Core assumption:** The edge model's uncertainty correlates well with the actual need for foundation model knowledge, and the threshold can be tuned in real-time to adapt to network conditions.
- **Evidence anchors:**
  - [abstract] "EdgeFM conducts dynamic model switching at run-time taking into account both data uncertainty and dynamic network variations, which ensures the accuracy always close to the original FM."
  - [section] "The router model ð‘Ÿ (xð‘– ) controls the models switching according to the prediction of the customized small model and a threshold ð‘¡â„Žð‘Ÿð‘’ (ð‘¡)."
- **Break condition:** If the edge model's uncertainty metric fails to capture when foundation model knowledge is truly needed, latency benefits degrade or accuracy drops.

### Mechanism 2
- **Claim:** EdgeFM improves accuracy over static compression by customizing small models with semantic-driven distillation from the foundation model.
- **Mechanism:** The system maps heterogeneous embeddings between the foundation model and lightweight CNNs using a feature projection network, then uses bidirectional contrastive learning loss to align the small model's features with pseudo text embeddings from the foundation model.
- **Core assumption:** The foundation model's pseudo text embeddings provide high-quality supervision for training small models, even without labeled data.
- **Evidence anchors:**
  - [abstract] "EdgeFM selectively uploads unlabeled data to query the FM on the cloud and customizes the specific knowledge and architectures for edge models."
  - [section] "We adopt a bidirectional contrastive learning loss... to further pull the features extracted by customized small models closer to the pseudo text embedding of FMs."
- **Break condition:** If the pseudo text embeddings from the foundation model are unreliable or misaligned, customization degrades accuracy.

### Mechanism 3
- **Claim:** EdgeFM adapts to dynamic network conditions by tuning the model switching threshold in real-time based on estimated latency and accuracy.
- **Mechanism:** The system builds a threshold-searching table offline using calibration data, then selects the optimal threshold online to meet latency constraints while maximizing accuracy.
- **Core assumption:** The offline calibration data and threshold-searching table generalize well to runtime network variations and data distributions.
- **Evidence anchors:**
  - [abstract] "EdgeFM conducts dynamic model switching at run-time taking into account both data uncertainty and dynamic network variations."
  - [section] "EdgeFM tunes the threshold ð‘¡â„Žð‘Ÿð‘’ (ð‘¡) at runtime to adapt to the dynamic network condition."
- **Break condition:** If runtime network conditions change faster than the threshold can be updated, or if the calibration set is not representative, latency or accuracy may suffer.

## Foundational Learning

- **Concept:** Multi-modal foundation models (e.g., CLIP, ImageBind)
  - Why needed here: EdgeFM relies on these models' ability to map different data modalities (image, audio, text) into a shared embedding space, enabling open-set recognition without retraining.
  - Quick check question: Can you explain how CLIP aligns image and text embeddings for zero-shot classification?

- **Concept:** Uncertainty quantification via semantic similarity
  - Why needed here: EdgeFM uses the margin between top-2 semantic similarity scores as a proxy for uncertainty, deciding when to query the foundation model.
  - Quick check question: How does the margin score (top-1 similarity minus top-2 similarity) reflect sample uncertainty?

- **Concept:** Knowledge distillation with heterogeneous architectures
  - Why needed here: EdgeFM customizes lightweight CNNs using knowledge from transformer-based foundation models, requiring specialized distillation techniques.
  - Quick check question: What challenges arise when distilling knowledge from a transformer to a CNN, and how does feature projection help?

## Architecture Onboarding

- **Component map:** Sensor data captured on edge -> Edge model predicts and computes uncertainty -> Router model decides: edge inference or cloud offload -> If cloud, FM processes and returns prediction -> Result returned to edge, threshold updated for next sample

- **Critical path:**
  1. Sensor data captured on edge
  2. Edge model predicts and computes uncertainty
  3. Router model decides: edge inference or cloud offload
  4. If cloud, FM processes and returns prediction
  5. Result returned to edge, threshold updated for next sample

- **Design tradeoffs:**
  - Accuracy vs. latency: Higher threshold increases accuracy but also latency
  - Upload ratio vs. customization quality: More uploads enable better customization but increase network load
  - Model size vs. inference speed: Larger edge models may be more accurate but slower and costlier

- **Failure signatures:**
  - High latency spikes: Likely due to network congestion or misconfigured threshold
  - Accuracy drop: Possibly from stale customization or poor uncertainty estimation
  - Memory overflow on edge: Model too large for device constraints

- **First 3 experiments:**
  1. Run inference with a fixed threshold (e.g., 0.5) and measure latency/accuracy trade-off
  2. Test uncertainty quantification by injecting known "hard" samples and checking if they trigger cloud offload
  3. Simulate network bandwidth variation and observe threshold adaptation behavior

## Open Questions the Paper Calls Out
- How does EdgeFM's performance scale when foundation models are updated or replaced with newer, larger models?
- What is the optimal strategy for determining when to trigger the periodic update cycle in EdgeFM?
- How does EdgeFM handle catastrophic forgetting when the environment undergoes rapid and frequent changes?

## Limitations
- The offline threshold-searching table may not generalize to runtime network variations
- Quality of pseudo text embeddings from FMs is critical but not validated across diverse datasets
- Performance with additional modalities beyond vision and audio is unclear

## Confidence
- Latency Reduction (3.2x): Medium
- Accuracy Increase (34.3%): Medium
- Dynamic Adaptation: Low

## Next Checks
1. Test the threshold-searching table on a dataset with highly variable network conditions to assess its adaptability
2. Conduct a qualitative analysis of pseudo text embeddings from CLIP and ImageBind across different datasets
3. Extend the system to include text or sensor data modalities and evaluate performance without retraining the FMs