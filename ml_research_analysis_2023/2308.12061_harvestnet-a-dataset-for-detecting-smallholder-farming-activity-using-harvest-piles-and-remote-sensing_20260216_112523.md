---
ver: rpa2
title: 'HarvestNet: A Dataset for Detecting Smallholder Farming Activity Using Harvest
  Piles and Remote Sensing'
arxiv_id: '2308.12061'
source_url: https://arxiv.org/abs/2308.12061
tags:
- images
- harvest
- figure
- piles
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HarvestNet, a dataset for detecting smallholder
  farming activity through the identification of harvest piles in satellite imagery.
  The dataset covers Ethiopia's Tigray and Amhara regions from 2020-2023, containing
  7k hand-labeled SkySat images and 2k ground-truth labels.
---

# HarvestNet: A Dataset for Detecting Smallholder Farming Activity Using Harvest Piles and Remote Sensing

## Quick Facts
- **arXiv ID**: 2308.12061
- **Source URL**: https://arxiv.org/abs/2308.12061
- **Reference count**: 30
- **Primary result**: HarvestNet dataset enables 80% classification accuracy on hand-labeled data and detects 56,621 hectares of additional cropland compared to ESA WorldCover in Tigray, Ethiopia.

## Executive Summary
This paper introduces HarvestNet, a dataset for detecting smallholder farming activity through the identification of harvest piles in satellite imagery. The dataset covers Ethiopia's Tigray and Amhara regions from 2020-2023, containing 7k hand-labeled SkySat images and 2k ground-truth labels. The authors benchmark SOTA models including CNNs and transformers, achieving up to 80% classification accuracy on hand-labeled data and 90-98% accuracy on ground-truth data. Visual comparison with ESA WorldCover shows HarvestNet detects an additional 56,621 hectares of cropland in Tigray. The dataset and code are publicly available, demonstrating the potential of harvest pile detection for improving cropland mapping in smallholder farming regions.

## Method Summary
The authors created HarvestNet by collecting high-resolution SkySat (0.5m) and lower-resolution PlanetScope (4.77m) imagery from Tigray and Amhara, Ethiopia (2020-2023). They implemented a multi-stage labeling pipeline: initial crowd filtering of obvious negatives followed by expert review of ambiguous cases, resulting in 7k hand-labeled SkySat patches and 2k ground-truth labels from field surveys. The dataset was used to benchmark several SOTA models including MOSAIKS, SatMAE, Swin Autoencoder, Satlas, and ResNet-50, with evaluation on both hand-labeled test sets and ground-truth validation data, plus comparison against ESA WorldCover land use maps.

## Key Results
- ResNet-50 achieves 80% classification accuracy on hand-labeled test set
- Ground-truth validation shows 90-98% accuracy across models
- HarvestNet detects 56,621 hectares of additional cropland in Tigray compared to ESA WorldCover
- Swin Autoencoder pretrained on unlabelled HarvestNet images outperforms Satlas despite Satlas's larger pretraining dataset

## Why This Works (Mechanism)

### Mechanism 1
Harvest piles are a more dynamic indicator of farming activity than static features like field boundaries or houses. Piles are temporary structures that appear only during harvest season, so their presence in imagery indicates active farming. Detection of these seasonal structures allows mapping of cropland that may be missed by traditional methods focused on static infrastructure. Core assumption: Harvest piles remain visible in satellite imagery long enough after harvest to be detected before they are removed or disturbed. Break condition: If piles are removed too quickly after harvest, or if imagery acquisition does not align with the visible window, detection rates will drop sharply.

### Mechanism 2
Higher-resolution imagery (0.5 m) is necessary to reliably detect small harvest piles, while lower-resolution (4.77 m) imagery is sufficient for ground-truth validation. Harvest piles are small (3-10 m in footprint), so they become indistinguishable at coarser resolutions. Higher resolution enables accurate labeling and training; lower resolution is acceptable for broader coverage in validation when expert labeling is not feasible. Break condition: If ground-truth validation requires pile-level precision, lower-resolution imagery will fail to capture enough detail, undermining accuracy claims.

### Mechanism 3
Multi-stage labeling with expert review balances dataset scale and quality for a novel detection task. Initial crowd labeling filters obvious negatives, reducing expert workload. Experts then label the remaining ambiguous cases, ensuring high precision. This staged approach maximizes usable labeled data while maintaining quality. Break condition: If crowd labelers misclassify subtle pile indicators as negatives, many positives will be lost before expert review, biasing the dataset toward false negatives.

## Foundational Learning

- **Binary classification on satellite imagery patches**: The task is framed as detecting presence/absence of harvest piles in fixed-size image tiles, requiring understanding of image classification pipelines and loss functions. Quick check: What loss function is used for binary classification in this work, and why is it appropriate?

- **Remote sensing indices (e.g., NDVI)**: Traditional cropland mapping often relies on spectral indices; understanding their limitations helps justify why harvest piles are a complementary feature. Quick check: Why might NDVI be insufficient for detecting smallholder cropland in heterogeneous landscapes?

- **Transfer learning with pre-trained vision models**: Models like ResNet-50 and Swin are initialized on ImageNet or remote sensing datasets to leverage learned features before fine-tuning on the harvest pile dataset. Quick check: What is the benefit of freezing pre-trained layers during fine-tuning on a small specialized dataset?

## Architecture Onboarding

- **Component map**: SkySat/PlanetScope imagery → patch extraction → normalization → model input → classification → aggregation → cropland map comparison with ESA WorldCover
- **Critical path**: Labeled data → model training → inference on unlabeled patches → aggregation into cropland map → comparison with ESA
- **Design tradeoffs**: Resolution vs. coverage (high-res SkySat for labeling, low-res PlanetScope for validation); precision vs. recall (models favor precision to reduce false positives); expert time vs. dataset size (multi-stage labeling maximizes usable data while controlling cost)
- **Failure signatures**: Low recall (models miss subtle or early-stage piles; dataset may lack sufficient positive examples); high false positives (models confuse harvest piles with dirt piles, sheds, or altered land; labeling guidelines may be too broad); poor generalization (models overfit to training region geography)
- **First 3 experiments**: 1) Train ResNet-50 on the labeled dataset and evaluate on the hand-labeled test set to establish baseline accuracy; 2) Compare model predictions with ESA WorldCover in Tigray to quantify new cropland detection; 3) Evaluate model performance on ground-truth data from Amhara using the union of monthly predictions to assess robustness

## Open Questions the Paper Calls Out

- **Open Question 1**: How would fine-tuning Satlas with our dataset compare to training from scratch on HarvestNet? The paper only compares Satlas to the Swin autoencoder pretrained on HarvestNet images, not to a Satlas model fine-tuned on HarvestNet.

- **Open Question 2**: Would a multi-class classification approach, distinguishing between different types of harvest activity (cutting, piling, threshing), improve performance compared to the current binary classification? The current dataset and models are designed for binary classification, not multi-class classification.

- **Open Question 3**: How would incorporating time-series data into the detection of harvest piles impact model performance? The current dataset and models do not incorporate time-series data, focusing instead on geographical diversity with the available images.

## Limitations
- SkySat imagery used for labeling is not publicly available due to licensing restrictions, limiting full reproduction
- Expert labeling process lacks detailed documentation on criteria for distinguishing harvest piles from similar features like dirt piles or sheds
- Claim that harvest piles remain visible "until after threshing" assumes consistent post-harvest window across diverse farming practices, which may vary by crop type, weather, or region

## Confidence
- **High**: Classification accuracy results on the hand-labeled test set (80% accuracy) are directly measurable and reproducible with the provided data
- **Medium**: Ground-truth validation accuracy (90-98%) is credible but depends on the quality and representativeness of the 2k field survey labels
- **Low**: The comparison with ESA WorldCover (56,621 ha additional cropland) is an indirect validation that conflates model performance with differences in mapping methodology

## Next Checks
1. Replicate the ResNet-50 baseline training on the publicly available PlanetScope subset and verify reported accuracy metrics
2. Conduct cross-validation on the ground-truth data to assess label consistency and potential geographic or crop-type biases
3. Test model generalization by applying trained models to a held-out region or year not included in the original dataset