---
ver: rpa2
title: 'BLT: Can Large Language Models Handle Basic Legal Text?'
arxiv_id: '2311.09693'
source_url: https://arxiv.org/abs/2311.09693
tags:
- text
- cite
- gpt-4
- page
- sections
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models (LLMs) perform poorly on basic legal text
  tasks like retrieving text by line number in deposition transcripts or by citation
  in statutes. We created a benchmark (BLT) to measure this performance gap.
---

# BLT: Can Large Language Models Handle Basic Legal Text?

## Quick Facts
- arXiv ID: 2311.09693
- Source URL: https://arxiv.org/abs/2311.09693
- Reference count: 40
- Key outcome: Large language models (LLMs) perform poorly on basic legal text tasks like retrieving text by line number in deposition transcripts or by citation in statutes.

## Executive Summary
Large language models struggle with basic legal text tasks that lawyers and paralegals perform routinely, such as finding text at specific line numbers in deposition transcripts or locating content by statutory citation. The BLT (Basic Legal Text) benchmark reveals that even state-of-the-art models like GPT-4 achieve only 78% accuracy on simple deposition text retrieval tasks. However, fine-tuning a smaller model like GPT-3.5-turbo on BLT training data brings performance to near-perfect levels, suggesting that the core issue is a lack of domain-specific expertise rather than fundamental architectural limitations.

## Method Summary
The BLT benchmark evaluates LLMs on 11 different tasks across three types of legal text: deposition transcripts, synthetic sections, and U.S. Code. The tasks involve text-to-citation, citation-to-text, and retrieval operations. The evaluation uses API calls with temperature=0.0 for reproducibility, and fine-tuning experiments involve training GPT-3.5-turbo on 90% of the BLT-4k training data for 2 epochs before testing on held-out prompts.

## Key Results
- GPT-4 achieves only 78% accuracy on deposition text retrieval tasks
- Fine-tuning GPT-3.5-turbo on BLT data brings performance to near 100% on test sets
- Even on simpler hierarchical text, GPT-4 gets wrong subsections or paragraphs 12% of the time

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning on BLT training data rapidly improves LLM performance on basic legal text tasks to near-human levels.
- Mechanism: BLT provides structured, task-specific training data that teaches LLMs the precise citation and text retrieval skills needed for legal practice, compensating for their lack of domain expertise in basic legal text handling.
- Core assumption: LLMs can learn these specific skills through fine-tuning without requiring extensive architectural changes or additional domain knowledge beyond the training data.
- Evidence anchors:
  - [abstract] "fine-tuning on our training set brings even a small model to near-perfect performance"
  - [section] "We find that fine-tuning brings GPT-3.5-turbo... to near the 100% performance expected of lawyers and paralegals"
- Break condition: If the fine-tuning data doesn't capture the full range of citation patterns and text structures used in legal practice, the model may not generalize well to novel legal texts.

### Mechanism 2
- Claim: LLMs struggle with basic legal text tasks because they lack specific domain expertise in citation navigation and hierarchical text processing.
- Mechanism: Despite training on large amounts of legal text, LLMs haven't been specifically trained to handle the precise citation formats and hierarchical structures common in legal documents, leading to poor performance on tasks like finding text at specific line numbers or subsections.
- Core assumption: The poor performance is due to lack of specific training rather than fundamental architectural limitations of LLMs.
- Evidence anchors:
  - [abstract] "LLMs' poor performance on this benchmark casts into doubt their reliability as-is for legal practice"
  - [section] "GPT-4 has its weakest performance in handling transcripts, which is surprising, since transcripts have much simpler numbering than the hierarchical text in synthetic sections"
- Break condition: If the issue is fundamental architectural limitations rather than lack of specific training, fine-tuning may not fully solve the problem.

### Mechanism 3
- Claim: The BLT benchmark's design with multiple text types and tasks creates a comprehensive evaluation of basic legal text handling skills.
- Mechanism: By testing multiple text types (deposition transcripts, synthetic sections, U.S. Code) and multiple tasks (text→cite, cite→text, etc.), BLT captures the full range of basic legal text processing skills needed in practice.
- Core assumption: The variety of text types and tasks in BLT accurately represents the skills needed for practical legal work.
- Evidence anchors:
  - [abstract] "The BLT tasks mimic basic tasks done by lawyers and paralegals"
  - [section] "The BLT benchmark involves three different types of legal text, each of which has between two and five different tasks run on it"
- Break condition: If important legal text handling skills are missing from BLT's task set, the benchmark may not fully capture LLM capabilities for legal practice.

## Foundational Learning

- Concept: Hierarchical text navigation
  - Why needed here: Legal documents use complex hierarchical structures (sections, subsections, paragraphs) that LLMs must navigate to answer citation-based questions
  - Quick check question: Can you explain the difference between finding text at "section 101(a)(2)(B)" versus "section 101(a)(2)" in a statute?

- Concept: Citation format standards
  - Why needed here: Legal citations have specific formats (e.g., "section 1001(b)(2)") that LLMs must recognize and generate correctly
  - Quick check question: What are the standard components of a legal citation to a deposition transcript?

- Concept: Context window management
  - Why needed here: Legal documents can be very long, requiring LLMs to effectively use large context windows to locate relevant text
  - Quick check question: How would you modify a prompt to help an LLM find text in a 100-page deposition transcript?

## Architecture Onboarding

- Component map: LLM (GPT-3.5-turbo or GPT-4) → Fine-tuning module (for BLT training) → Evaluation module (BLT benchmark) → Error classification module
- Critical path: Prompt generation → LLM API call → Answer evaluation → Error classification
- Design tradeoffs: Using synthetic sections allows unlimited training data but may not capture all real-world legal text variations; using real legal text provides authenticity but limits data availability
- Failure signatures: Consistent errors on specific citation formats, confusion between similar hierarchical structures, inability to handle long documents
- First 3 experiments:
  1. Test GPT-4 on 100 BLT-4k transcript prompts and analyze error types
  2. Fine-tune GPT-3.5-turbo on BLT-4k training data and test on held-out prompts
  3. Compare performance on synthetic sections versus U.S. Code to identify generalization issues

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does fine-tuning on BLT data transfer to improved performance on other basic legal text handling tasks beyond those in the BLT benchmark?
- Basis in paper: [inferred] The paper shows that fine-tuning on BLT improves performance on SARA and applies-to tasks, but the improvement on applies-to was unexpected and actually decreased accuracy.
- Why unresolved: The paper only tests a limited number of related tasks (SARA and applies-to) and finds mixed results. It's unclear whether the fine-tuning approach would generalize to other basic legal text handling tasks not included in BLT.
- What evidence would resolve it: Testing the fine-tuned model on a broader range of basic legal text handling tasks and comparing its performance to both the original model and humans.

### Open Question 2
- Question: How does the performance of LLMs on BLT tasks change as the models are trained on larger and more diverse legal datasets?
- Basis in paper: [explicit] The paper notes that GPT-4 performs poorly on BLT tasks despite being trained on a large portion of the internet including legal text, and that fine-tuning a smaller model (GPT-3.5-turbo) on BLT data brings performance close to 100%.
- Why unresolved: The paper only tests current state-of-the-art models (GPT-4, PaLM 2) and a smaller model (GPT-3.5-turbo) fine-tuned on BLT data. It's unclear how future models trained on even larger and more diverse legal datasets would perform on BLT tasks.
- What evidence would resolve it: Testing future LLMs with larger legal training datasets on the BLT benchmark and comparing their performance to current models.

### Open Question 3
- Question: What specific aspects of legal text handling are most challenging for LLMs, and how can training be optimized to address these challenges?
- Basis in paper: [explicit] The paper identifies that LLMs struggle with tasks involving deposition transcripts and hierarchical legal text, particularly with maintaining correct citations and finding precise text.
- Why unresolved: While the paper identifies some challenging areas, it doesn't deeply analyze what specific features of legal text (e.g., nested citations, complex definitions) are most problematic for LLMs or how training could be tailored to address these issues.
- What evidence would resolve it: A detailed analysis of LLM errors on various types of legal text, identifying common failure patterns, and experiments with targeted training approaches to address specific weaknesses.

## Limitations

- The benchmark focuses on text retrieval accuracy but doesn't assess the quality of legal reasoning or interpretation, which are critical for actual legal practice
- The evaluation uses temperature=0.0 for reproducibility, which doesn't reflect typical deployment scenarios where some stochasticity is expected
- The fine-tuning effectiveness is demonstrated primarily on the BLT-4k dataset, but the paper doesn't provide evidence that this translates to other legal domains or more complex reasoning tasks

## Confidence

- High confidence: LLMs perform poorly on basic legal text tasks as measured by BLT benchmark
- Medium confidence: Fine-tuning on BLT data significantly improves performance to near-perfect levels
- Low confidence: The poor performance indicates LLMs lack domain expertise for reliable legal practice

## Next Checks

1. Cross-domain generalization test: Fine-tune the model on BLT training data, then evaluate its performance on legal text with different formatting conventions (e.g., international legal documents, contracts with non-standard citation styles) to assess whether the improvement transfers beyond the specific BLT task formats.

2. Error type analysis: Systematically categorize the errors made by LLMs on BLT tasks (e.g., citation format confusion, hierarchical structure errors, context window limitations) and create targeted interventions for each error type, then measure whether this improves performance more effectively than general fine-tuning.

3. Long-context performance evaluation: Test the fine-tuned model on deposition transcripts that exceed typical context window limits (e.g., 200+ page transcripts) using various chunking and retrieval strategies to determine whether the model can handle realistic legal documents or if the current evaluation underestimates the practical challenges.