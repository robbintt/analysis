---
ver: rpa2
title: Controllable Emphasis with zero data for text-to-speech
arxiv_id: '2307.07062'
source_url: https://arxiv.org/abs/2307.07062
tags:
- emphasis
- speech
- duration
- word
- dd-e
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a method for controllable emphasis in text-to-speech
  (TTS) systems without requiring explicit recordings or annotations. The core idea
  is to achieve emphasis by increasing the predicted duration of phonemes belonging
  to the emphasized word.
---

# Controllable Emphasis with zero data for text-to-speech

## Quick Facts
- arXiv ID: 2307.07062
- Source URL: https://arxiv.org/abs/2307.07062
- Reference count: 0
- The paper presents a method for controllable emphasis in TTS systems without explicit recordings or annotations

## Executive Summary
This paper introduces a method for controllable emphasis in text-to-speech systems that requires no explicit emphasis recordings or annotations. The approach works by increasing the predicted duration of phonemes belonging to emphasized words, leveraging the decoupling of duration and acoustic models in non-attentive deep learning TTS architectures. The method, called DD-E MPH, achieves emphasis through duration lengthening alone, with the model implicitly learning to add appropriate pitch contours and silence based on training data.

The proposed method significantly improves emphasis naturalness and identifiability compared to a baseline approach that modifies mel-spectrograms directly. On a reference female en-US voice, DD-E MPH improved naturalness by 7.3% and correct identification of emphasized words by 40% compared to the baseline. The approach demonstrates cross-linguistic validity across English, Spanish, Italian, and German, and works across different voice types from neutral to expressive.

## Method Summary
The method involves modifying phoneme durations in a non-attentive TTS architecture at inference time by a constant factor (αDD), without requiring re-training. The approach uses the DURIAN+ architecture with separate duration and acoustic models, where emphasis is achieved by lengthening each phoneme in the target word by a constant factor (typically 1.25 or 1.5). This duration modification is integrated within the neural TTS pipeline, allowing the acoustic model to adapt the prosody based on training examples to match the requested phoneme duration. The method contrasts with baseline approaches that modify mel-spectrograms post-hoc, which degrade quality and prosody.

## Key Results
- DD-E MPH improved emphasis naturalness by 7.3% and correct identification of emphasized words by 40% compared to mel-spectrogram modification baseline
- Achieved 70.6 MUSHRA score compared to 74 for methods requiring explicit emphasis recordings
- Demonstrated scalability across four languages (English, Spanish, Italian, German) and different voices/speaking styles
- On expressive voices, DD-E MPH was strongly preferred over baseline (preference gains from 4% to 25.6%)
- Emphasis identifiability improved from 43% to 60% with DD-E MPH on reference voice

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Duration lengthening of phonemes in an emphasized word is sufficient to trigger perceptual emphasis without explicit pitch or intensity modifications
- Mechanism: By uniformly increasing the duration of all phonemes in the target word, the model implicitly learns to associate this lengthening with emphasis through exposure in training data, and adjusts pitch contour and silence accordingly
- Core assumption: The training data contains enough examples of emphasized speech where duration changes correlate with other emphasis cues (pitch, silence) for the model to learn the association implicitly
- Evidence anchors:
  - [abstract] "Our central claim is that modelling a duration increase of the phonemes belonging to the word targeted by emphasis suffices in most cases to trigger the perceptual impression of prominence"
  - [section 3.5] "Our study shows that even if not all properties usually associated with focus are present in the signal, emphasis is still perceived. We suggest that increased phoneme duration, a rise-fall in pitch contour and a short silence before the emphasized portion of speech suffice to convincingly trigger the perception of emphasis"
  - [corpus] Weak evidence - no corpus studies directly cited about duration-only emphasis perception
- Break condition: If training data lacks sufficient examples of emphatic speech (e.g., neutral voices), the model cannot implicitly learn the association between duration lengthening and other emphasis cues

### Mechanism 2
- Claim: Modifying phoneme durations before mel-spectrogram generation produces more natural emphasis than post-hoc mel-spectrogram modifications
- Mechanism: Direct duration modification integrates the emphasis control within the neural TTS architecture, allowing the acoustic model to adapt the prosody based on seen examples in the training set to match the requested phoneme duration
- Core assumption: The non-attentive TTS architecture with disjoint duration and acoustic modeling allows for effective duration modification without retraining
- Evidence anchors:
  - [section 2.5] "Our central claim is that it is possible to produce emphatic speech by lengthening the duration dp of each phoneme p by a constant αDD factor... This approach is done only at inference time and does not require re-training"
  - [section 3.3] "DD-E MPH improves emphasis naturalness over MEL-E MPH by 7.3%. The mel-spectrogram modifications of MEL-E MPH degrades the quality and prosody compared to DD-E MPH, which integrates the duration modification within the neural TTS architecture"
  - [corpus] Weak evidence - no direct comparisons of architecture types in corpus
- Break condition: If the TTS architecture doesn't properly decouple duration and acoustic modeling, or if the acoustic model cannot adapt to duration changes

### Mechanism 3
- Claim: The model implicitly learns to add silence before the syllable carrying primary stress and a pitch contour rise-fall when duration is increased, enhancing emphasis perception
- Mechanism: Through training on expressive data, the model associates duration lengthening with the acoustic patterns of emphasis, including pre-stress silence and pitch contour changes, even though these aren't explicitly controlled
- Core assumption: Expressive training data contains sufficient examples of emphasis with these acoustic features for the model to learn the association
- Evidence anchors:
  - [section 3.5] "The model however appears to have in fact implicitly learned two aspects of emphatic speech that it was not explicitly trained on: 1. The role of silence preceding the syllable carrying primary stress... 2. The contour of f0 shows a clear rise... We take this contour to instantiate well-known H*+L contour, associated with narrow focus..."
  - [section 3.4] "Our model is able to associate duration changes with other acoustic measures of emphasis when the training data is very expressive, providing the model a sufficient number of cases of emphatic speech"
  - [corpus] Weak evidence - no corpus studies cited about silence and pitch patterns in emphasis
- Break condition: If training data is neutral or lacks expressive emphasis examples, the model cannot learn these implicit associations

## Foundational Learning

- Concept: Duration modeling in TTS
  - Why needed here: Understanding how phoneme durations are predicted and used to drive acoustic model generation is crucial for implementing the duration-based emphasis approach
  - Quick check question: How does the duration model in a non-attentive TTS system work, and how can it be modified at inference time?

- Concept: Prosodic features of emphasis
  - Why needed here: Knowledge of how emphasis is typically realized acoustically (duration, pitch, intensity, silence) helps understand why duration modification alone can be effective
  - Quick check question: What are the primary acoustic correlates of emphasis in speech, and how do they typically interact?

- Concept: Neural TTS architecture (encoder-decoder with duration model)
  - Why needed here: Understanding the overall TTS pipeline, including how phoneme sequences are converted to mel-spectrograms, is necessary to implement and debug the duration-based emphasis method
  - Quick check question: How does a non-attentive TTS system with separate duration and acoustic models generate speech from text?

## Architecture Onboarding

- Component map: Text processing -> Phoneme sequence -> Duration model -> Phoneme durations -> Acoustic model (Tacotron2 encoder + phoneme-to-frame upsampler + Bi-LSTM) -> Mel-spectrograms -> Vocoder -> Waveform

- Critical path: Text -> Phonemes -> Duration modification -> Acoustic model -> Mel-spectrograms -> Vocoder -> Audio

- Design tradeoffs:
  - Duration modification vs. mel-spectrogram modification: Direct duration control is more natural but requires architecture support
  - Uniform vs. phoneme-class-specific duration changes: Simpler but may not be optimal for all phonemes
  - Factor magnitude: Larger factors increase emphasis but may degrade quality

- Failure signatures:
  - Unnatural lengthening of stops and affricates (though paper claims this isn't problematic)
  - Degradation on neutral voices (model hasn't learned implicit associations)
  - Monosyllabic words may not emphasize correctly (less common in training data)

- First 3 experiments:
  1. Implement duration modification on a simple non-attentive TTS model and test on an expressive voice
  2. Compare naturalness of duration-modified vs. mel-spectrogram-modified emphasis on the same voice
  3. Test emphasis identifiability on a neutral voice to observe degradation

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in a dedicated section. However, it acknowledges limitations and areas for future work, particularly around the potential for phoneme-class-specific duration modifications and the dependency on expressive training data for implicit learning of emphasis patterns.

## Limitations
- The method relies heavily on expressive training data for implicit learning of emphasis patterns beyond duration lengthening, showing significant degradation on neutral voices
- The approach may not generalize well to languages or speaking styles with different emphasis patterns than those in the training corpus
- The paper doesn't explore more sophisticated duration allocation strategies (e.g., longer stressed syllables) compared to uniform duration lengthening

## Confidence
**High Confidence:** The core claim that duration modification alone can improve emphasis identifiability is well-supported by the 40% improvement over the MEL-E MPH baseline and the preference test results showing DD-E MPH strongly preferred on expressive voices. The architectural claim that duration modification integrates better within the TTS pipeline than post-hoc mel-spectrogram modification is also well-supported by the 7.3% naturalness improvement.

**Medium Confidence:** The claim about implicit learning of silence and pitch contour patterns is supported by qualitative observations but lacks quantitative validation. While the paper identifies these patterns in outputs, there's no systematic analysis of how consistently they appear or their contribution to emphasis perception. The scalability claim across four languages is based on testing but doesn't explore the full range of language-specific emphasis patterns.

**Low Confidence:** The assertion that uniform duration lengthening across all phonemes in a word is sufficient for emphasis perception lacks strong empirical support. The paper doesn't compare against more sophisticated duration allocation strategies (e.g., longer stressed syllables) or analyze the perceptual importance of uniform vs. weighted duration changes.

## Next Checks
1. **Quantitative Analysis of Implicit Learning:** Measure the consistency and correlation of silence insertion and pitch contour changes with emphasis perception across a larger sample of outputs. Use acoustic analysis tools to quantify these features and correlate them with subjective emphasis ratings.

2. **Cross-Voice Generalization Study:** Test the method on a wider range of neutral voices with varying amounts of expressive data in their training sets. Measure how the quality gap between DD-E MPH and MEL-E MPH correlates with the proportion of expressive examples in training data.

3. **Duration Allocation Optimization:** Compare the uniform duration lengthening approach against methods that allocate longer durations to stressed syllables or use phoneme-class-specific factors. Conduct preference tests to determine if more sophisticated duration allocation provides additional naturalness benefits.