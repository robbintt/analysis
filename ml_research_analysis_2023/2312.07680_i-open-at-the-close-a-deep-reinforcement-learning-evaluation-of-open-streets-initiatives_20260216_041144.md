---
ver: rpa2
title: 'I Open at the Close: A Deep Reinforcement Learning Evaluation of Open Streets
  Initiatives'
arxiv_id: '2312.07680'
source_url: https://arxiv.org/abs/2312.07680
tags:
- streets
- traffic
- data
- road
- open
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work tackles the challenge of choosing which streets to open
  in urban open streets initiatives by formulating it as a reinforcement learning
  problem. To do so, it first builds a recurrent graph neural network that predicts
  collisions using years of road network, weather, and traffic data.
---

# I Open at the Close: A Deep Reinforcement Learning Evaluation of Open Streets Initiatives

## Quick Facts
- **arXiv ID**: 2312.07680
- **Source URL**: https://arxiv.org/abs/2312.07680
- **Reference count**: 24
- **Primary result**: Q-learning model identifies streets that consistently reduce collisions and traffic, outperforming NYC Open Streets program's geographically concentrated selections

## Executive Summary
This paper addresses the challenge of selecting optimal streets for urban open streets initiatives using deep reinforcement learning. The authors develop a recurrent graph neural network (RGNN) to predict vehicle collisions using road network, weather, and traffic data, then train a deep Q-learning model to identify which streets to open to minimize collisions and traffic. The RGNN architecture captures both short-term temporal dependencies and spatial road network relationships, outperforming baseline methods. When applied to New York City's Open Streets program, the Q-learning approach identifies streets that consistently reduce collisions and traffic, while the actual program's selections show no significant improvement over random selection and exhibit geographic concentration.

## Method Summary
The authors build a pipeline that first predicts collision risk using a recurrent graph neural network that processes road segments as nodes with features including weather, infrastructure attributes, and inferred traffic patterns. Traffic is inferred from taxi trip data using Dijkstra's algorithm to route vehicles around hypothetical closed streets. With this collision prediction capability, they formulate street selection as a reinforcement learning problem where an agent learns which streets to open to maximize long-term reward (reduced collisions and traffic). The Q-learning agent uses the RGNN architecture to estimate the value of opening each street segment, simulating traffic rerouting and collision risk to learn optimal selection strategies.

## Key Results
- RGNN with recurrent and graph convolutional layers outperforms baseline models for collision prediction
- Q-learning model identifies streets that consistently reduce collisions and traffic
- NYC Open Streets program streets perform similarly to randomly selected streets and show geographic concentration
- Weighted cross-entropy loss enables effective learning from imbalanced collision data

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: RGNNs outperform other models by capturing both short-term temporal dependencies (like weather) and spatial dependencies (road network structure) simultaneously.
- **Mechanism**: The RGNN architecture uses recurrent layers to propagate hidden states that capture temporal dynamics while graph convolutional layers aggregate neighborhood information to capture spatial relationships. This dual capability allows the model to understand how collisions propagate through the road network over time.
- **Core assumption**: The spatial and temporal dependencies in collision prediction are sufficiently local that a recurrent graph architecture can effectively model them.
- **Evidence anchors**:
  - [abstract]: "a recurrent graph neural network, leveraging the graph structure and the short-term temporal dependence of the data, gives the best predictive performance"
  - [section]: "We next evaluated a recurrent GNN (RGNN). We hypothesized that the road structure and traffic patterns interact temporally in the short term and that the recurrent layers could successfully capture these relationships"
- **Break condition**: If temporal dependencies are too long-range or spatial dependencies are too global, the recurrent layers may fail to capture important patterns, leading to degraded performance.

### Mechanism 2
- **Claim**: The reinforcement learning approach (Q-learning) identifies streets that consistently reduce collisions and traffic by simulating the long-term effects of opening different streets.
- **Mechanism**: Q-learning trains a neural network to estimate the expected long-term reward (reduction in collisions and traffic) of opening each street segment. By simulating traffic rerouting and collision risk over time, the model learns which streets provide the most benefit when opened.
- **Core assumption**: The simulation of traffic rerouting and collision prediction accurately reflects real-world outcomes when streets are opened.
- **Evidence anchors**:
  - [abstract]: "we frame a reinforcement learning problem to find which streets to open"
  - [section]: "We train a deep Q-learning model to output the long term value of opening each road segment"
- **Break condition**: If the simulation of traffic rerouting is inaccurate or the collision prediction model is unreliable, the Q-values will not reflect true long-term benefits, leading to poor street selection.

### Mechanism 3
- **Claim**: Using weighted cross-entropy loss instead of downsampling allows the model to utilize all available data while addressing class imbalance.
- **Mechanism**: Instead of throwing away 99% of non-collision examples (as in downsampling), weighted loss assigns higher importance to collision examples during training, allowing the model to learn from all available data.
- **Core assumption**: The loss weighting scheme effectively balances the learning process without introducing bias or instability.
- **Evidence anchors**:
  - [section]: "we weight the loss functions of our collision prediction models so that the positive examples have the same importance as the negative examples"
  - [section]: "The benefit of this approach is that we can utilize all our data for learning"
- **Break condition**: If the weighting scheme is not properly calibrated, it may lead to overfitting on the minority class or underfitting on the majority class.

## Foundational Learning

- **Concept: Graph Neural Networks**
  - Why needed here: The road network is naturally represented as a graph where intersections are nodes and road segments are edges, and collisions have spatial dependencies.
  - Quick check question: What are the key components of a graph neural network and how do they capture structural information?

- **Concept: Reinforcement Learning (Q-learning)**
  - Why needed here: The problem of selecting which streets to open can be framed as sequential decision-making with delayed rewards, making RL appropriate.
  - Quick check question: How does Q-learning differ from other RL methods, and why is it suitable for this problem?

- **Concept: Imbalanced Classification**
  - Why needed here: Collision events are extremely rare compared to non-collision events, requiring special handling to train effective models.
  - Quick check question: What are the trade-offs between different approaches to handling imbalanced classification problems?

## Architecture Onboarding

- **Component map**: Data pipeline -> Traffic inference module -> Collision prediction model -> RL environment -> Q-learning agent -> Street recommendation
- **Critical path**: Data → Traffic inference → Collision prediction → RL simulation → Q-value learning → Street recommendation
- **Design tradeoffs**:
  - Local vs global rerouting: Local rerouting is computationally feasible but less realistic
  - Simulation vs real-world: Simulation allows experimentation but may not capture all real-world complexities
  - Model complexity vs interpretability: More complex models may perform better but be harder to explain
- **Failure signatures**:
  - Poor collision prediction: Indicates issues with feature engineering or model architecture
  - Unstable Q-learning: Suggests exploration-exploitation balance problems or reward function issues
  - Geographic concentration of selected streets: May indicate bias in the model or data
- **First 3 experiments**:
  1. Train baseline collision prediction models (Gaussian NB, XGBoost, LightGBM) and compare performance metrics
  2. Implement and evaluate the RGNN for collision prediction, comparing against baseline models
  3. Set up the RL environment with simplified assumptions (e.g., no traffic rerouting) to validate the basic RL framework before adding complexity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would using a generative model to generate new collision events impact the performance and robustness of the RL algorithm compared to the current supervised learning approach?
- Basis in paper: [inferred] The authors mention that there has been substantial improvements in contrastive learning and deep embeddings, and that generating new collisions using these approaches could be an alternative to predicting collisions with standard supervised learning techniques.
- Why unresolved: The authors state that this is beyond the scope of their work and leave it for future work.
- What evidence would resolve it: Running experiments comparing the performance of the RL algorithm when using a generative model to generate collision events versus the current supervised learning approach, measuring metrics such as Q-values, reward, and geographic diversity of selected streets.

### Open Question 2
- Question: How would using global rerouting instead of local rerouting impact the performance and realism of the traffic simulation in the RL algorithm?
- Basis in paper: [explicit] The authors discuss the limitation of using local rerouting due to computational cost and mention that global rerouting would be more realistic but would increase the time to build a state from seconds to hours.
- Why unresolved: The authors did not implement global rerouting due to computational constraints and leave it for future work.
- What evidence would resolve it: Implementing global rerouting in the traffic simulation and comparing the performance of the RL algorithm in terms of Q-values, reward, and geographic diversity of selected streets to the current approach using local rerouting.

### Open Question 3
- Question: How would using gradient boosting techniques with weak graph learners instead of standard graph neural networks impact the performance and interpretability of the collision prediction model?
- Basis in paper: [explicit] The authors mention that there has been successful work replacing decision trees with shallow neural networks in gradient boosting techniques and suggest that replacing the weak learners with shallow graph neural networks could be an interesting idea.
- Why unresolved: The authors state that this is beyond the scope of their work and leave it for future work.
- What evidence would resolve it: Implementing gradient boosting techniques with weak graph learners for collision prediction and comparing the performance and interpretability of the resulting model to the current graph neural network approach, measuring metrics such as F1-score, recall, and feature importance.

## Limitations
- Local rerouting assumption may not capture realistic citywide traffic patterns when streets are closed
- Collision prediction model relies on historical data from 2013-2015, which may not reflect current traffic patterns
- Q-learning performance depends heavily on the quality of the collision prediction component
- Study doesn't address temporal dynamics of Open Streets usage across seasons or days of the week

## Confidence
- **High Confidence**: The RGNN architecture outperforming baseline models for collision prediction
- **Medium Confidence**: The Q-learning model's ability to identify beneficial streets for opening
- **Low Confidence**: The geographic concentration finding for NYC Open Streets

## Next Checks
1. **Out-of-sample temporal validation**: Test the RGNN and Q-learning models on data from 2016-2023 to assess performance degradation over time and identify any systematic biases in the prediction or selection process.

2. **Alternative rerouting simulation**: Implement a simplified global rerouting algorithm (relaxing the local rerouting assumption) and compare the resulting street recommendations to assess sensitivity to this key modeling assumption.

3. **Cross-city transfer learning**: Train the collision prediction model on NYC data and evaluate its performance on collision prediction in another city (e.g., Chicago or San Francisco) to test the generalizability of the learned representations.