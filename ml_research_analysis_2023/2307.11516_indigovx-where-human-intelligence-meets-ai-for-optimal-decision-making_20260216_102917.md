---
ver: rpa2
title: 'IndigoVX: Where Human Intelligence Meets AI for Optimal Decision Making'
arxiv_id: '2307.11516'
source_url: https://arxiv.org/abs/2307.11516
tags:
- human
- page
- however
- optimal
- goal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The IndigoVX framework introduces a human-AI collaborative approach
  for optimal decision-making, combining human expertise with AI-driven insights through
  an iterative feedback loop. The system employs a three-score evaluation schema with
  0.5 increments on a 0-10 scale, enabling nuanced assessment of strategies against
  well-defined goals.
---

# IndigoVX: Where Human Intelligence Meets AI for Optimal Decision Making

## Quick Facts
- arXiv ID: 2307.11516
- Source URL: https://arxiv.org/abs/2307.11516
- Reference count: 2
- Introduces a human-AI collaborative framework for optimal decision-making through iterative refinement

## Executive Summary
IndigoVX presents a novel framework for combining human expertise with AI capabilities through an iterative feedback loop to achieve optimal decision-making. The system uses a three-score evaluation schema with 0.5 increments on a 0-10 scale, allowing nuanced assessment of strategies against well-defined goals. Through dynamic weighting of scores and continuous refinement, the framework enables convergence on optimal solutions while incorporating contextual knowledge and handling uncertainty. Testing with multiple AI systems alongside human experts demonstrates the framework's effectiveness in producing superior solutions compared to traditional optimization methods.

## Method Summary
The IndigoVX framework operates through an iterative feedback loop where human experts and AI systems collaboratively create and refine strategies toward a well-defined goal. The process begins with an initial draft plan, followed by scoring against three criteria using a 0-10 scale with 0.5 increments. The human expert suggests concrete edits to improve scores, while the AI provides data-driven insights and refinements. Dynamic weighting of the three scores allows adaptation to changing priorities, and the process continues until weighted score differences fall below a defined threshold across several iterations. The framework employs a convergence criterion inspired by gradient descent, ensuring systematic improvement toward optimal solutions.

## Key Results
- The iterative feedback loop converges on optimal solutions through continuous refinement between human experts and AI systems
- Dynamic weighting of three scoring criteria enables adaptation to changing priorities and contexts
- Testing with ChatGPT-4, Bard, and Claude alongside human experts validates the framework's ability to produce superior solutions
- The approach shows particular promise for business strategy, game playing, and creative problem-solving applications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The iterative feedback loop enables convergence on optimal solutions through continuous refinement.
- Mechanism: The system alternates between human scoring of the current plan against three criteria and AI-suggested edits, with convergence defined as weighted score differences falling below a threshold across several iterations.
- Core assumption: Human-AI collaboration produces better solutions than either alone due to complementary strengths.
- Evidence anchors:
  - [abstract] "Indigo operates through an iterative feedback loop, harnessing the human expert's contextual knowledge and the AI's data-driven insights to craft and refine strategies towards a well-defined goal"
  - [section] "The algorithm itself is simple: Rate the current plan against the agreed 3-score schema. Suggest a list of concrete edits to the plan, and explain why each edit boosts the scores."
- Break condition: The iterative cycle breaks when weighted score differences across all three scores fall below a defined threshold (e.g., 0.5) over several iterations.

### Mechanism 2
- Claim: Dynamic weighting of scores allows adaptation to changing priorities and contexts.
- Mechanism: The weights assigned to each scoring function can be adjusted during the feedback loop based on human expert feedback, allowing the system to emphasize different aspects as the situation evolves.
- Core assumption: Multi-objective optimization problems benefit from adaptive rather than static weight assignments.
- Evidence anchors:
  - [section] "The weights assigned to plan scores can be dynamic, not static. They can be adjusted as part of the feedback loop if the expert feels some aspects of their task need more focus."
  - [section] "Inspired by approaches to Pareto optimization, we assign a weighted sum to normalized scores. The weights reflect the importance or priority of each score in the particular context of the plan."
- Break condition: Weight adjustments stop when human expert confirms the current weight distribution adequately reflects priorities.

### Mechanism 3
- Claim: The three-score evaluation schema with 0.5 increments provides sufficient granularity while remaining cognitively accessible.
- Mechanism: A 0-10 scale with 0.5 increments balances precision and cognitive load, allowing nuanced scoring without overwhelming participants.
- Core assumption: Human experts can effectively use intermediate scores (e.g., 7.5) when forced to choose between consecutive whole numbers.
- Evidence anchors:
  - [section] "From our trials, we observed that human experts might hesitate when asked to choose between two consecutive whole numbers, such as 7 or 8. The option of selecting 7.5 can resolve this indecision and enable more nuanced scoring."
  - [section] "We select a quantized 0.5 scale from 0 to 10, for three main reasons: Familiarity, Cognitive accessibility, and Midpoint for neutral positions."
- Break condition: The scoring schema proves insufficient when human experts consistently report difficulty distinguishing meaningful differences between adjacent scores.

## Foundational Learning

- Concept: Multi-objective optimization
  - Why needed here: The framework explicitly treats planning as a multi-objective optimization problem with weighted scoring functions
  - Quick check question: What are the three scoring criteria being optimized, and how do their relative weights change during the process?

- Concept: Reinforcement learning principles
  - Why needed here: The iterative feedback loop resembles policy iteration in RL, though operating in a broader, more abstract context
  - Quick check question: How does the human expert function as a proxy for the environment in this framework?

- Concept: Cognitive load management
  - Why needed here: The design choices around scoring scales and three criteria balance comprehensiveness with human cognitive capacity
  - Quick check question: Why does the 0-10 scale with 0.5 increments reduce cognitive effort compared to larger ranges?

## Architecture Onboarding

- Component map: Human expert (strategic context provider) -> AI system (data-driven suggestions) -> scoring schema (evaluation criteria) -> convergence algorithm (stopping condition) -> dynamic weighting mechanism (priority adjustment)
- Critical path: Objective definition -> Initial plan creation -> Iterative scoring -> AI suggestions -> Plan refinement -> Convergence check -> Final plan
- Design tradeoffs: Granularity vs. cognitive load (0.5 increments), number of criteria vs. comprehensiveness (three scores), human control vs. AI autonomy (feedback loop structure)
- Failure signatures: Oscillation between plans without convergence, human fatigue from repeated iterations, AI suggestions that consistently fail to improve scores, weight adjustments that create instability rather than refinement
- First 3 experiments:
  1. Simple business strategy optimization using predefined scoring criteria
  2. Game strategy refinement with clear win conditions
  3. Creative writing optimization focusing on narrative elements

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the convergence criterion be formally defined to ensure optimal plan selection in IndigoVX?
- Basis in paper: [explicit] The paper mentions using a gradient-descent-inspired approach where convergence is defined as the weighted score difference across all three scores falling below a threshold (e.g., 0.5) over several iterations.
- Why unresolved: The paper does not provide a formal mathematical definition of convergence, nor does it discuss how to set the threshold or the number of iterations needed for different types of problems.
- What evidence would resolve it: A rigorous mathematical proof of convergence conditions, or empirical results showing the convergence behavior across different problem domains and settings.

### Open Question 2
- Question: What are the optimal weighting strategies for dynamic weights in multi-objective optimization within IndigoVX?
- Basis in paper: [explicit] The paper discusses dynamic weighting of scores to reflect the importance or priority of each score in the particular context of the plan, but does not provide specific strategies for adjusting these weights.
- Why unresolved: The paper suggests that weights can be adjusted based on feedback from the human expert, but does not explore how to systematically determine the best weighting strategy or how to balance multiple objectives effectively.
- What evidence would resolve it: Experimental results comparing different weighting strategies, or a theoretical framework for determining optimal weights based on the problem context.

### Open Question 3
- Question: How does the inclusion of subjective criteria in the scoring schema impact the overall effectiveness of IndigoVX?
- Basis in paper: [explicit] The paper acknowledges that the choice of scores can be partly subjective and argues that partially subjective criteria may be a strength, helping to understand the human perspective and providing a more comprehensive approach to problem-solving.
- Why unresolved: The paper does not provide empirical evidence on how subjective criteria affect the quality of solutions or the satisfaction of human collaborators, nor does it discuss methods to mitigate potential biases introduced by subjectivity.
- What evidence would resolve it: Comparative studies of IndigoVX performance with and without subjective criteria, or user studies measuring the impact of subjectivity on solution quality and user satisfaction.

## Limitations
- Limited comparative performance data against established optimization methods
- Specific implementation details for dynamic weighting algorithms and convergence criteria remain underspecified
- Reliance on human expertise introduces potential bottlenecks and subjective biases

## Confidence
- Core iterative feedback mechanism: High confidence
- Dynamic weighting adaptation: Medium confidence
- Three-score evaluation effectiveness: Medium confidence
- Convergence guarantees: Low confidence

## Next Checks
1. **Convergence Reliability Test**: Run multiple IndigoVX sessions on identical problems with different human-AI pairs to measure consistency in final solutions and convergence speed, establishing variance bounds for the iterative process.

2. **Comparative Performance Benchmark**: Implement a baseline optimization algorithm (e.g., weighted sum method or genetic algorithm) for the same problem set and compare solution quality, iteration count, and human effort required.

3. **Scoring Schema Sensitivity Analysis**: Conduct controlled experiments varying the scoring scale granularity (whole numbers vs. 0.5 increments) and number of criteria to empirically determine optimal configuration for decision quality versus cognitive load.