---
ver: rpa2
title: 'MD-IQA: Learning Multi-scale Distributed Image Quality Assessment with Semi
  Supervised Learning for Low Dose CT'
arxiv_id: '2311.08024'
source_url: https://arxiv.org/abs/2311.08024
tags:
- quality
- image
- multi-scale
- regression
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a multi-scale distributions regression approach
  (MD-IQA) for low-dose CT image quality assessment. The method uses a dual-branch
  alignment network combining vision transformer and CNN modules to extract features,
  and predicts quality scores by constraining output distributions.
---

# MD-IQA: Learning Multi-scale Distributed Image Quality Assessment with Semi Supervised Learning for Low Dose CT

## Quick Facts
- arXiv ID: 2311.08024
- Source URL: https://arxiv.org/abs/2311.08024
- Reference count: 0
- Primary result: Achieves P LCC of 0.9771, SROCC of 0.9793, and KROCC of 0.9106 on LDCTIQAC2023 challenge dataset

## Executive Summary
This paper proposes MD-IQA, a multi-scale distributions regression approach for low-dose CT image quality assessment. The method employs a dual-branch alignment network combining Vision Transformer and CNN modules to extract features, and predicts quality scores by constraining output distributions rather than point estimates. Semi-supervised learning is incorporated to leverage unlabeled data, improving model generalization. The approach demonstrates superior performance compared to traditional hand-crafted feature methods and recent deep learning-based approaches, achieving state-of-the-art results on the LDCTIQAC2023 challenge dataset.

## Method Summary
The MD-IQA method uses a dual-branch alignment network with Vision Transformer and ConvNeXt modules to extract global and local features respectively. These features are aligned using deformable convolutions at multiple scales. The network predicts quality scores by modeling output distributions as multi-scale Gaussian distributions, which better capture uncertainty in subjective human ratings. Semi-supervised learning is employed by generating pseudo-labels from ensemble models for unlabeled data, expanding the effective training dataset. The model is trained using a combination of supervised and unsupervised losses over 30 epochs with Adam optimizer.

## Key Results
- Achieves Pearson Linear Correlation Coefficient (P LCC) of 0.9771
- Achieves Spearman rank-order correlation coefficient (SROCC) of 0.9793
- Achieves Kendall rank-order correlation coefficient (KROCC) of 0.9106

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-scale Gaussian distribution regression reduces prediction uncertainty compared to point estimates
- Mechanism: By modeling the output as a probability distribution over possible scores rather than a single point estimate, the method captures label uncertainty inherent in subjective human ratings. The multi-scale approach uses different Gaussian widths to represent varying degrees of uncertainty at different score levels.
- Core assumption: The true quality score distribution for a given image follows a Gaussian-like shape centered around the mean human rating
- Evidence anchors:
  - [abstract]: "predict quality scores by constraining the output distribution, thereby improving model generalization"
  - [section]: "The network is expected to predict several Gaussian distribution with different scales... the Gaussian distribution allows for uncertainty in the label"
  - [corpus]: Weak evidence - no direct citations about Gaussian distribution regression in medical IQA
- Break condition: If the actual score distribution is multimodal or highly skewed, the Gaussian assumption would fail and multi-scale regression would not capture the true uncertainty structure

### Mechanism 2
- Claim: Dual-branch alignment network enhances feature extraction by combining global and local information
- Mechanism: The network architecture uses a Vision Transformer branch to capture global contextual information and a ConvNeXt branch to extract local spatial details. Deformable convolutions align these features at multiple scales, creating a richer representation that combines both perspectives.
- Core assumption: Both global contextual information and local spatial details are necessary for accurate perceptual quality assessment
- Evidence anchors:
  - [abstract]: "we design a dual-branch alignment network to enhance feature extraction capabilities"
  - [section]: "The proposed network consists of three key components: a feature extraction module, dual branch align module, and a score prediction module... The ViT module... The ConvNeXt module serves as the convolutional submodule to extract local features"
  - [corpus]: Weak evidence - no direct citations about dual-branch alignment for medical IQA
- Break condition: If either global or local information dominates the perceptual assessment task, the computational overhead of dual branches would be unnecessary

### Mechanism 3
- Claim: Semi-supervised learning improves generalization by leveraging unlabeled data
- Mechanism: The method uses pseudo-labels generated by ensemble models to train on additional unlabeled CT images. This expands the effective training dataset and helps the model learn more robust features that generalize beyond the limited labeled data.
- Core assumption: The pseudo-labels generated from ensemble models are sufficiently accurate to guide learning on unlabeled data
- Evidence anchors:
  - [abstract]: "semi-supervised learning is introduced by utilizing pseudo-labels for unlabeled data to guide model training"
  - [section]: "Due to the small number of training samples, we adopt semi-supervised learning to train the network on an expanded dataset and improve generalization"
  - [corpus]: Weak evidence - no direct citations about semi-supervised learning for medical IQA
- Break condition: If the pseudo-labeling process introduces significant errors, the model would learn from incorrect supervision and performance would degrade

## Foundational Learning

- Concept: Image quality assessment in medical imaging differs from natural images
  - Why needed here: Medical IQA focuses on diagnostic value rather than pixel-level metrics, requiring different evaluation criteria and feature representations
  - Quick check question: What is the key difference between medical and natural image quality assessment?

- Concept: Label uncertainty in subjective quality ratings
  - Why needed here: Human raters show inter-rater variability and intra-rater inconsistency, making regression targets inherently uncertain
  - Quick check question: Why does modeling score distributions help with subjective quality labels?

- Concept: Feature alignment across different network architectures
  - Why needed here: ViT and CNN extract features at different scales and resolutions, requiring alignment for effective fusion
  - Quick check question: What technique is used to align features from the ViT and CNN branches?

## Architecture Onboarding

- Component map: Input → Data augmentation → Feature extraction (ViT + ConvNeXt) → Dual-branch alignment (deformable convolutions) → Score prediction (weighted patch aggregation) → Multi-scale Gaussian distribution output
- Critical path: Feature extraction → Alignment → Score prediction, as these directly impact the quality assessment output
- Design tradeoffs: ViT provides global context but is computationally expensive; CNN provides local details efficiently; dual branches increase parameter count but improve performance
- Failure signatures: Poor correlation with human ratings suggests feature extraction issues; high variance in predictions indicates distribution modeling problems; overfitting on training data suggests insufficient regularization
- First 3 experiments:
  1. Train with only ViT branch vs only CNN branch to evaluate individual contributions
  2. Compare single-scale vs multi-scale Gaussian regression performance
  3. Test semi-supervised learning with different pseudo-labeling strategies

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed multi-scale Gaussian distribution regression method compare to other uncertainty-aware regression techniques for image quality assessment?
- Basis in paper: [explicit] The paper mentions using multi-scale Gaussian distributions to handle varying degrees of uncertainty in quality scores.
- Why unresolved: The paper does not compare the proposed method to other uncertainty-aware regression techniques.
- What evidence would resolve it: A comparison study evaluating the proposed method against other uncertainty-aware regression techniques on the same dataset.

### Open Question 2
- Question: Can the proposed method be extended to assess image quality in other medical imaging modalities beyond CT?
- Basis in paper: [inferred] The paper focuses on CT image quality assessment but does not discuss applicability to other modalities.
- Why unresolved: The paper does not explore the generalizability of the method to other medical imaging modalities.
- What evidence would resolve it: Experiments applying the proposed method to image quality assessment tasks in other medical imaging modalities (e.g., MRI, X-ray).

### Open Question 3
- Question: How sensitive is the proposed method to the choice of hyperparameters, such as the number of scales and the weighting of the loss terms?
- Basis in paper: [explicit] The paper mentions specific hyperparameter settings used in experiments.
- Why unresolved: The paper does not provide a sensitivity analysis of the method to hyperparameter choices.
- What evidence would resolve it: A comprehensive sensitivity analysis varying the key hyperparameters and evaluating the impact on model performance.

## Limitations
- The multi-scale distribution regression assumes Gaussian-shaped uncertainty, which may not capture all types of score distributions
- The dual-branch architecture significantly increases computational complexity without ablation studies quantifying individual contributions
- The semi-supervised learning component relies on potentially noisy pseudo-labels without validation of their accuracy

## Confidence
**High Confidence**: The quantitative results (P LCC: 0.9771, SROCC: 0.9793, KROCC: 0.9106) are well-documented and directly measurable from the reported experiments on the LDCTIQAC2023 dataset.

**Medium Confidence**: The mechanism claims about why the approach works (multi-scale distribution modeling, dual-branch feature extraction, semi-supervised learning benefits) are theoretically sound but lack extensive ablation studies or ablation evidence from the corpus.

**Low Confidence**: The paper provides limited details about architecture specifications (exact layer configurations, number of scales K, sampling points N) and implementation details necessary for exact reproduction.

## Next Checks
1. Perform ablation study validation by removing the ViT branch, ConvNeXt branch, and multi-scale distribution components individually to quantify their specific contributions to final performance metrics.

2. Analyze the accuracy of pseudo-labels generated for unlabeled data by comparing them against a small subset of manually labeled validation images, and test the sensitivity of final performance to pseudo-label quality.

3. Examine the actual distribution of human ratings across the dataset to verify whether Gaussian assumptions are appropriate, and test alternative distribution models (e.g., Student's t-distribution) to assess robustness to distribution shape assumptions.