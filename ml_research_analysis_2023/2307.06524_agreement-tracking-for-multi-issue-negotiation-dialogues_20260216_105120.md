---
ver: rpa2
title: Agreement Tracking for Multi-Issue Negotiation Dialogues
arxiv_id: '2307.06524'
source_url: https://arxiv.org/abs/2307.06524
tags:
- dialogue
- tracking
- agreement
- state
- negotiation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the task of agreement tracking for multi-issue
  negotiation dialogues, which requires continuous monitoring of agreements within
  a structured state space. To address the scarcity of annotated corpora, the authors
  create GPT-Negochat, a synthesized dataset built using GPT-3 to rephrase and enrich
  the NEGOCHAT corpus.
---

# Agreement Tracking for Multi-Issue Negotiation Dialogues

## Quick Facts
- arXiv ID: 2307.06524
- Source URL: https://arxiv.org/abs/2307.06524
- Reference count: 25
- Key outcome: Pre-training T5 on MultiWOZ 2.4 improves agreement tracking by 21% (T5-small) and 9% (T5-base) in joint slot accuracy over training solely on GPT-Negochat

## Executive Summary
This work introduces agreement tracking for multi-issue negotiation dialogues, requiring continuous monitoring of agreements within a structured state space. To address the scarcity of annotated corpora, the authors create GPT-Negochat, a synthesized dataset built using GPT-3 to rephrase and enrich the NEGOCHAT corpus. They present a strong baseline by transfer-learning a T5 model pre-trained on the MultiWOZ 2.4 corpus, showing that pre-training enhances results by 21% (T5-small) and 9% (T5-base) in joint slot accuracy over training solely on GPT-Negochat. Experiments with smaller training subsets validate the method's sample efficiency. The authors release GPT-Negochat and their baseline models to encourage further research in this area.

## Method Summary
The authors frame agreement tracking as a sequence-to-sequence problem, using T5 models to predict Levenshtein belief spans representing agreement states. They employ transfer learning by pre-training on MultiWOZ 2.4's dialogue state tracking task, then fine-tuning on the synthesized GPT-Negochat dataset. The approach uses a recursive context window strategy to handle long dialogues, maintaining a sliding window of recent utterances plus the previous agreement state. Multi-task training with contrastive learning objectives aims to improve discrimination between correct and incorrect outputs.

## Key Results
- Pre-training T5-small on MultiWOZ 2.4 improves agreement tracking by 21% in joint slot accuracy over training solely on GPT-Negochat
- Pre-training T5-base on MultiWOZ 2.4 improves agreement tracking by 9% in joint slot accuracy over training solely on GPT-Negochat
- T5-base outperforms T5-small in low-resource settings, requiring fewer training samples to achieve comparable performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pre-training on MultiWOZ 2.4 dialogue state tracking task improves agreement tracking performance by transferring turn-level state tracking knowledge
- Mechanism: The model learns to track user goals across dialogue turns in MultiWOZ, developing representations that generalize to tracking agreements in negotiation dialogues
- Core assumption: Dialogue state tracking and agreement tracking share fundamental reasoning patterns about information persistence across turns
- Evidence anchors:
  - [abstract]: "Pre-training T5-small and T5-base on MultiWOZ 2.4's DST task enhances results by 21% and 9% respectively over training solely on GPT-Negochat."
  - [section 4.3]: "Tracking information across dialogue turns is a shared goal of agreement tracking and dialogue state tracking, despite differing focus areas (agreements vs user goals)."

### Mechanism 2
- Claim: Multi-task training with contrastive learning objectives improves agreement tracking by teaching the model to distinguish correct belief spans from incorrect ones
- Mechanism: The binary classification task (CLF) provides explicit training signals that penalize incorrect outputs by separating them in the model's latent space
- Core assumption: The model's main source of error is producing false positives/hallucinations rather than missing true agreements
- Evidence anchors:
  - [section 4.3.1]: "We borrow from multi-task training with contrastive-learning objectives in other dialogue-related tasks... Our approach penalizes incorrect outputs by separating them in the model's latent space."
  - [section 5.2]: "The use of the auxiliary binary classification objective (GEN + NEG) does not lead to a significant performance improvement... This result suggests that the majority of errors made by our model are false negatives, whereas the NEG objective is better suited to tackle the problem of false positives."

### Mechanism 3
- Claim: Recursive context window approach outperforms full-history methods for agreement tracking due to improved information retention in long dialogues
- Mechanism: By using a sliding window of recent utterances and the previous agreement state, the model maintains focus on relevant context without being overwhelmed by dialogue length
- Core assumption: Recent dialogue turns and the current agreement state provide sufficient context for accurate agreement prediction
- Evidence anchors:
  - [section 3.2]: "We opt for a recursive-based approach due to the relatively high average turn-length of 34.27 GPT-Negochat, which exceeds that of most task-oriented dialogue corpora."
  - [section 3.2]: "Rather than predicting the entire dialogue state from scratch at every turn, these approaches use the previously predicted dialogue state as a starting point."

## Foundational Learning

- Concept: Dialogue state tracking (DST) fundamentals
  - Why needed here: Agreement tracking reformulates the problem as a variant of DST, so understanding DST concepts is essential
  - Quick check question: What distinguishes dialogue state tracking from simple slot filling in task-oriented dialogues?

- Concept: Contrastive learning objectives
  - Why needed here: The multi-task training approach uses contrastive learning to improve model discrimination between correct and incorrect outputs
  - Quick check question: How does a contrastive learning objective differ from a standard cross-entropy loss in training setup?

- Concept: Levenshtein belief spans tokenization
  - Why needed here: This tokenization scheme is used to represent agreement states as sequences of edit operations, enabling sequence-to-sequence modeling
  - Quick check question: What advantages does the Levenshtein belief span approach offer over traditional delexicalized representations?

## Architecture Onboarding

- Component map: Context window → Encoder → T5 layers → Decoder → Levenshtein belief span output
- Critical path: Dialogue context and previous agreement state → Encoder → T5 transformer layers → Decoder → Generated belief spans
- Design tradeoffs:
  - Window size vs. context completeness: Larger windows capture more context but increase computational cost
  - Model size vs. sample efficiency: T5-base performs better in low-resource settings but requires more data to converge
  - Multi-task vs. single-task: Contrastive learning may help with hallucinations but doesn't significantly improve overall accuracy
- Failure signatures:
  - Low joint slot accuracy with high individual slot precision: Model is making false negative errors
  - High joint slot accuracy but low individual slot F1: Model is making false positive errors
  - Performance degradation with window size reduction: Model requires longer context than available
- First 3 experiments:
  1. Train baseline T5-small on GPT-Negochat alone to establish performance floor
  2. Train T5-small on MultiWOZ then fine-tune on GPT-Negochat to test transfer learning benefit
  3. Train T5-small with GEN+CLF objective to test contrastive learning impact

## Open Questions the Paper Calls Out

- Question: How would larger T5 models or instruction-tuned variants like FLAN-T5 perform on the agreement tracking task compared to the T5-small and T5-base models used in this study?
- Question: How would the performance of agreement tracking models change when applied to larger, multi-domain datasets with more diverse negotiation dialogues?
- Question: How would the performance of agreement tracking models change when trained on fully organic multi-issue negotiation dialogue datasets with turn-level agreement annotations, compared to the GPT-Negochat dataset?

## Limitations

- The GPT-Negochat dataset was synthetically generated using GPT-3, introducing potential domain shift from the original NEGOCHAT corpus
- Evaluation metrics (joint slot accuracy and joint F1) may not fully capture the nuanced nature of agreement tracking in negotiation contexts
- The long-term effectiveness of transfer learning from MultiWOZ across different negotiation domains and styles remains untested

## Confidence

- High Confidence: Pre-training on MultiWOZ improves agreement tracking performance (21% for T5-small, 9% for T5-base)
- Medium Confidence: The recursive context window approach is effective for handling long dialogues
- Low Confidence: Contrastive learning objectives significantly improve agreement tracking

## Next Checks

1. Evaluate the pre-trained models on a held-out subset of NEGOCHAT to assess whether performance gains generalize to the original domain
2. Conduct detailed error analysis categorizing failures by agreement type to identify model weaknesses
3. Compare the recursive context window approach against full-history and attention-based long-range context mechanisms to determine efficiency-accuracy tradeoffs