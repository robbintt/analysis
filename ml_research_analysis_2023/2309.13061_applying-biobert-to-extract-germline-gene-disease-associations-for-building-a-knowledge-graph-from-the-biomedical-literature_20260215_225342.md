---
ver: rpa2
title: Applying BioBERT to Extract Germline Gene-Disease Associations for Building
  a Knowledge Graph from the Biomedical Literature
arxiv_id: '2309.13061'
source_url: https://arxiv.org/abs/2309.13061
tags:
- knowledge
- genes
- biomedical
- diseases
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of extracting germline gene-disease
  associations from biomedical literature, a task that is becoming increasingly difficult
  due to the rapid growth of published information. The authors propose SimpleGermKG,
  an automated knowledge graph construction approach that connects germline genes
  and diseases.
---

# Applying BioBERT to Extract Germline Gene-Disease Associations for Building a Knowledge Graph from the Biomedical Literature

## Quick Facts
- arXiv ID: 2309.13061
- Source URL: https://arxiv.org/abs/2309.13061
- Reference count: 40
- Key outcome: Automated knowledge graph construction linking germline genes and diseases using BioBERT NER and ontology-based normalization, resulting in 297 genes, 130 diseases, and 46,747 triples

## Executive Summary
This paper presents SimpleGermKG, an automated approach for constructing a knowledge graph that connects germline genes and diseases extracted from biomedical literature. The method employs BioBERT, a pre-trained transformer model fine-tuned on domain-specific corpora, to identify gene and disease entities in germline abstracts. An ontology-based and rule-based algorithm then standardizes and disambiguates these entities using manually curated dictionaries. The resulting semantic relationships between articles, genes, and diseases are captured using a part-whole relation approach, linking each entity to its source PubMed ID and visualizing them in a graph-based representation.

## Method Summary
The study uses a four-stage pipeline to build the SimpleGermKG knowledge graph: (1) tokenization of 11,261 germline abstracts using PunktSentenceTokenizer, (2) named entity recognition using fine-tuned BioBERT models pre-trained on NCBI-disease and BC2GM corpora for diseases and genes respectively, (3) named entity normalization through a dictionary-lookup approach with approximate string-matching to map entities to standardized master terms, and (4) semantic relation establishment using a part-whole relation approach connecting PubMed IDs to genes and diseases. The knowledge graph is stored in a Neo4j database, containing 297 genes, 130 diseases, and 46,747 triples representing gene-disease associations.

## Key Results
- Knowledge graph contains 297 genes, 130 diseases, and 46,747 triples
- Automated extraction of gene-disease associations from 11,261 germline abstracts
- Ontology-based and rule-based normalization successfully standardizes biomedical terms
- Part-whole relation approach effectively links entities to their source PubMed IDs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BioBERT fine-tuned on domain-specific corpora (NCBI-disease and BC2GM) achieves high accuracy in extracting gene and disease entities from biomedical abstracts.
- Mechanism: Pre-trained transformer models like BioBERT leverage contextualized embeddings learned from large biomedical corpora. Fine-tuning on task-specific datasets (NCBI-disease for diseases, BC2GM for genes) adapts the model to recognize domain-specific entity patterns and nomenclature.
- Core assumption: The BioBERT model, when fine-tuned on NCBI-disease and BC2GM corpora, can effectively generalize to extract gene and disease entities from new germline abstracts.
- Evidence anchors:
  - [abstract] "For the extraction of genes and diseases, we employ BioBERT, a pre-trained BERT model on biomedical corpora."
  - [section] "We used a fine-tuned BioBERT model pre-trained on NCBI-disease corpus [...] For extracting genes from germline abstracts, we used a fine-tuned BioBERT model pre-trained on the BC2GM corpus."
  - [corpus] Weak evidence - The paper claims effectiveness but doesn't provide quantitative performance metrics for the BioBERT NER task on the germline corpus.
- Break condition: If the fine-tuned BioBERT model fails to generalize to new germline abstracts, or if the entity mentions in the abstracts significantly deviate from the training data patterns.

### Mechanism 2
- Claim: Ontology-based and rule-based normalization resolves ambiguities in biomedical terms, mapping extracted entities to standardized master terms.
- Mechanism: The approach uses manually curated dictionaries containing gene and disease names along with their synonyms. An approximate string-matching algorithm converts identified entities to lexical variations (lowercasing, removing whitespace and punctuations) and maps them to specific master terms in the dictionaries.
- Core assumption: The manually curated dictionaries are comprehensive enough to cover the synonyms and variations of gene and disease terms found in the germline abstracts.
- Evidence anchors:
  - [abstract] "We propose an ontology-based and rule-based algorithm to standardize and disambiguate medical terms."
  - [section] "We used a dictionary-lookup approach using our two manually curated dictionaries and an approximate string-matching algorithm."
  - [corpus] Weak evidence - The paper mentions the use of dictionaries but doesn't provide details on their coverage or the effectiveness of the normalization process.
- Break condition: If the dictionaries lack coverage for certain gene or disease synonyms, or if the string-matching algorithm fails to accurately disambiguate entities with similar names.

### Mechanism 3
- Claim: The part-whole relation approach, specifically the "data source" relation type, effectively connects extracted gene-disease pairs with their source PubMed IDs, establishing semantic relationships in the knowledge graph.
- Mechanism: For each gene-disease pair mentioned in an abstract, a relationship is created linking the entities to the corresponding PubMed ID. This approach assumes that co-occurrence of genes and diseases in the same abstract implies a potential relationship.
- Core assumption: The presence of a gene and disease in the same abstract is a sufficient indicator of a semantic relationship between them in the context of germline mutations.
- Evidence anchors:
  - [abstract] "For semantic relationships between articles, genes, and diseases, we implemented a part-whole relation approach to connect each entity with its data source and visualize them in a graph-based knowledge representation."
  - [section] "We defined the semantic relation as 'GENES_IN', and 'DISEASES_IN' to capture the connection between a PubMed ID and genes and/or diseases."
  - [corpus] Weak evidence - The paper doesn't provide validation or evaluation of the semantic relationships established by the part-whole approach.
- Break condition: If the co-occurrence assumption doesn't hold for germline gene-disease associations, or if the part-whole relation approach fails to capture more complex relationships between entities.

## Foundational Learning

- Concept: Named Entity Recognition (NER)
  - Why needed here: NER is crucial for identifying and extracting gene and disease entities from biomedical text, which forms the basis for constructing the knowledge graph.
  - Quick check question: What is the purpose of using BioBERT for NER in this study, and how does it differ from traditional NER approaches?

- Concept: Named Entity Normalization (NEN)
  - Why needed here: NEN is necessary to resolve ambiguities in biomedical terms, mapping extracted entities to standardized master terms using dictionaries and string-matching algorithms.
  - Quick check question: How does the ontology-based and rule-based algorithm proposed in this study help in disambiguating gene and disease entities?

- Concept: Knowledge Graph Construction
  - Why needed here: Knowledge graphs provide a structured representation of complex biomedical data, enabling efficient storage, querying, and visualization of gene-disease associations and their relationships.
  - Quick check question: What are the advantages of using a graph database like Neo4j for storing and querying the SimpleGermKG, compared to traditional relational databases?

## Architecture Onboarding

- Component map:
  - Data Sources: Manually curated dictionaries for genes and diseases
  - Pre-processing: Tokenization of abstracts using PunktSentenceTokenizer
  - NER: BioBERT fine-tuned on NCBI-disease and BC2GM corpora
  - NEN: Dictionary-lookup approach with approximate string-matching
  - Semantic Relation: Part-whole relation approach connecting entities to PubMed IDs
  - Knowledge Graph: Neo4j graph database storing triples of genes, diseases, and relationships

- Critical path:
  1. Tokenize abstracts into sentences
  2. Extract gene and disease entities using BioBERT NER
  3. Normalize entities using the ontology-based and rule-based algorithm
  4. Establish semantic relationships using the part-whole relation approach
  5. Store the resulting triples in the Neo4j graph database

- Design tradeoffs:
  - Using BioBERT for NER provides high accuracy but requires fine-tuning on domain-specific corpora.
  - The dictionary-lookup approach for NEN is simple but relies on the comprehensiveness of the manually curated dictionaries.
  - The part-whole relation approach is straightforward but may not capture complex relationships between entities.

- Failure signatures:
  - Low recall in NER: BioBERT fails to identify gene or disease entities in the abstracts.
  - High ambiguity in NEN: The string-matching algorithm incorrectly maps entities to master terms.
  - Incorrect relationships: The part-whole relation approach establishes false connections between entities.

- First 3 experiments:
  1. Evaluate the performance of the BioBERT NER model on a held-out test set of germline abstracts.
  2. Assess the coverage and accuracy of the ontology-based and rule-based normalization algorithm using a sample of extracted entities.
  3. Query the constructed knowledge graph to verify the presence and correctness of gene-disease relationships and their connections to PubMed IDs.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we improve the precision of gene-disease extraction by exploring pre-trained language models fine-tuned on well-known gene and disease datasets?
- Basis in paper: Explicit. The paper states: "Experimenting and exploring state-of-the-art approaches for the NER task. We aim to improve the precision of the gene-disease extraction by exploring pre-trained language models that have been fine-tuned on well-known gene and disease datasets in the literature."
- Why unresolved: The paper does not provide details on which specific models or datasets could be used, nor does it discuss the potential improvements in precision that could be achieved.
- What evidence would resolve it: Conducting experiments with different pre-trained language models and datasets, and comparing the results to the current BioBERT-based approach.

### Open Question 2
- Question: How can we expand our dictionaries for the NEN task to improve the accuracy of the named entity normalization process?
- Basis in paper: Explicit. The paper states: "Exploring a method of expanding our dictionaries for the NEN task. Larger gene-disease ontologies can be explored to enrich the vocabulary and improve the accuracy of the named entity normalization process."
- Why unresolved: The paper does not provide specific methods or ontologies that could be used to expand the dictionaries, nor does it discuss the potential improvements in accuracy that could be achieved.
- What evidence would resolve it: Conducting experiments with different ontologies and dictionaries, and comparing the results to the current approach.

### Open Question 3
- Question: How can we develop a technique for obtaining relationships from germline corpora, considering the gene carrier probability to select risk families for extracting relationships between cancer susceptibility genes?
- Basis in paper: Explicit. The paper states: "Developing a technique for obtaining relationships from germline corpora. Due to the nature of germline mutations, conventional relation extraction techniques do not apply in the semantic relation of a germline corpus. Therefore, training a model on germline corpora should consider the gene carrier probability to select risk families for extracting relationships between cancer susceptibility genes."
- Why unresolved: The paper does not provide specific techniques or models that could be used to extract relationships from germline corpora, nor does it discuss the potential improvements in accuracy that could be achieved.
- What evidence would resolve it: Conducting experiments with different techniques and models, and comparing the results to the current approach.

## Limitations

- The evaluation framework for SimpleGermKG remains incompletely specified, with no quantitative validation of the NER or NEN components' performance on the germline corpus.
- The effectiveness of the part-whole relation approach for establishing semantic relationships between entities is not evaluated, and the coverage and comprehensiveness of the manually curated dictionaries used for normalization are unknown.
- The paper does not provide details on the specific configuration and fine-tuning parameters used for the BioBERT models on NCBI-disease and BC2GM corpora, which could impact reproducibility.

## Confidence

- **High Confidence**: The general methodology of using BioBERT for NER, followed by dictionary-based normalization and graph construction, is sound and aligns with established practices in biomedical text mining.
- **Medium Confidence**: The effectiveness of the ontology-based and rule-based normalization algorithm relies on the quality and coverage of the manually curated dictionaries, which are not fully characterized in the paper.
- **Low Confidence**: The semantic relationships established by the part-whole relation approach are assumed to be valid based on co-occurrence, but this assumption is not validated or evaluated in the study.

## Next Checks

1. **Evaluate NER Performance**: Assess the precision, recall, and F1-score of the fine-tuned BioBERT models on a held-out test set of germline abstracts to quantify the accuracy of gene and disease entity extraction.
2. **Validate NEN Accuracy**: Conduct a manual review of a sample of extracted entities to measure the coverage and accuracy of the ontology-based and rule-based normalization algorithm, ensuring correct mapping to master terms.
3. **Assess Semantic Relationships**: Perform a query-based validation of the knowledge graph to verify the presence and correctness of gene-disease relationships and their connections to PubMed IDs, ensuring the part-whole relation approach captures meaningful associations.