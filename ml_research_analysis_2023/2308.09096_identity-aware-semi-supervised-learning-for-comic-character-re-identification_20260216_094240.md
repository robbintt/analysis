---
ver: rpa2
title: Identity-Aware Semi-Supervised Learning for Comic Character Re-Identification
arxiv_id: '2308.09096'
source_url: https://arxiv.org/abs/2308.09096
tags:
- character
- body
- face
- identity
- comic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an identity-aware semi-supervised learning
  framework for comic character re-identification, addressing the challenge of limited
  annotated data and complex character appearance variations. The method combines
  metric learning with a novel identity-aware self-supervision approach, using contrastive
  learning on face-body pairs within a unified network architecture to generate identity-aligned
  character embeddings.
---

# Identity-Aware Semi-Supervised Learning for Comic Character Re-Identification

## Quick Facts
- arXiv ID: 2308.09096
- Source URL: https://arxiv.org/abs/2308.09096
- Reference count: 40
- Key outcome: Identity-aware semi-supervised learning framework combining metric learning with identity-aware contrastive learning on face-body pairs achieves superior comic character re-identification performance on newly curated datasets.

## Executive Summary
This paper introduces an identity-aware semi-supervised learning framework for comic character re-identification that addresses the challenge of limited annotated data and complex character appearance variations. The method processes both facial and bodily features within a unified network architecture using identity-aware contrastive learning to generate identity-aligned character embeddings. This parameter-efficient approach outperforms independent face or body re-identification methods. The framework is validated on two newly curated datasets: the Comic Character Instances Dataset (over 1 million instances) and the Comic Sequence Identity Dataset (3000+ annotated sequences), showing strong performance in both in-series and inter-series evaluation metrics.

## Method Summary
The approach combines self-supervised pre-training with identity-aware contrastive learning on face-body pairs, followed by semi-supervised fine-tuning with metric learning using limited labeled comic sequence data. The framework uses a unified ResNet50-based architecture with an identity-aware projection head, processes character instances from the COMICS dataset using the DASS model, and employs meta-mining strategies to create accurate training pairs. After self-supervised training, a linear projector is fine-tuned using Triplet-Margin loss with Multi-similarity miner, and Agglomerative Clustering assigns character identities to embeddings.

## Key Results
- Identity-aware model outperforms face-only, body-only, and combined baseline approaches on both local (in-series) and global (inter-series) metrics
- Strong performance on Comic Character Instances Dataset with over 1 million instances and Comic Sequence Identity Dataset with 3000+ annotated sequences
- Parameter-efficient unified network architecture achieves better results than separate face and body re-identification networks
- Identity-awareness loss and contrastive learning on face-body pairs significantly improve character embedding alignment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Identity-aware contrastive learning improves character re-identification by jointly encoding face and body features with identity-aware supervision
- Mechanism: The model learns to minimize distance between embeddings of face-body pairs from the same character while maximizing distance between embeddings of different characters using identity-awareness loss
- Core assumption: Face and body features of the same character share identity-related information that can be aligned through contrastive learning
- Evidence anchors:
  - [abstract] "Our approach involves processing both facial and bodily features within a unified network architecture, facilitating the extraction of identity-aligned character embeddings that capture individual identities while preserving the effectiveness of face and body features."
  - [section] "The third task introduces pairs of face and body images depicting the same character. These images undergo weak transformations to ensure that the embeddings of both coarse face and body images exhibit similarity in the feature space."
- Break condition: If face and body features do not share sufficient identity-related information, the identity-awareness loss would not effectively align the embeddings

### Mechanism 2
- Claim: Semi-supervised fine-tuning with metric learning improves re-identification performance by learning a discriminative embedding space
- Mechanism: The model uses labeled data from comic sequences to fine-tune a linear projector on top of the self-supervised backbone, optimizing for metric learning losses that enforce similar identities to be close and dissimilar identities to be far apart
- Core assumption: Limited labeled data from comic sequences contains sufficient information to learn a discriminative embedding space
- Evidence anchors:
  - [abstract] "By clustering identity features, we address the task of comic character re-identification, demonstrating the potential to achieve robust results even with a restricted amount of annotated data."
  - [section] "To address the comic character re-identification task, we adopted the subsequent strategy. After self-supervised model training, we retained the core encoder f(·) and the projection head until the middle layer—discarding the rest, denoted as f'(·) which is frozen during fine-tuning."
- Break condition: If the labeled data is too limited or noisy, the metric learning optimization would not converge to a discriminative embedding space

### Mechanism 3
- Claim: Meta-mining strategy improves the quality of training pairs for metric learning by ensuring accurate similarity/dissimilarity labels across comic sequences
- Mechanism: The meta-mining strategy creates character identity cliques from sequence annotations and uses them to filter training pairs, preventing incorrect similarity/dissimilarity assignments between characters from different sequences
- Core assumption: Characters appearing in intersecting panels across sequences belong to the same identity
- Evidence anchors:
  - [section] "This approach establishes character relationships using cliques formed from all character identities and ensures the accuracy of mining similar and dissimilar pairs."
  - [section] "To utilize the dataset more efficiently and extract more information, we increased the number of similar-dissimilar pairs that can be obtained by linking characters between sequences."
- Break condition: If the character identity cliques are incorrectly formed or the linking strategy introduces errors, the meta-mining would propagate incorrect labels

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: Contrastive learning is the foundation for the identity-aware self-supervision, allowing the model to learn meaningful representations by contrasting positive and negative pairs
  - Quick check question: What is the primary objective of contrastive learning in self-supervised representation learning?

- Concept: Metric learning
  - Why needed here: Metric learning is essential for fine-tuning the model with limited labeled data, enabling it to learn a discriminative embedding space for character re-identification
  - Quick check question: How does metric learning differ from traditional classification in terms of the objective function?

- Concept: Clustering algorithms
  - Why needed here: Clustering algorithms are used to assign character identities across panels based on the learned embeddings, as the number of identities is not known beforehand
  - Quick check question: What is the main difference between K-means clustering and Agglomerative Clustering in terms of the number of clusters?

## Architecture Onboarding

- Component map: Self-supervised backbone (ResNet50) -> Identity-aware projection head (3-layer MLP) -> Linear projector for metric learning fine-tuning -> Clustering algorithm (Agglomerative Clustering)

- Critical path: 1. Self-supervised pre-training with identity-aware contrastive learning 2. Fine-tuning with metric learning using limited labeled data 3. Clustering of embeddings to assign character identities

- Design tradeoffs:
  - Unified face-body network vs. separate networks: Unified network is parameter-efficient but may not capture modality-specific features as well
  - Strong vs. weak augmentations: Strong augmentations improve robustness but may introduce noise; weak augmentations preserve identity information better
  - Number of clusters in Agglomerative Clustering: Too few clusters merge different identities; too many clusters split the same identity

- Failure signatures:
  - Poor re-identification performance: Could be due to ineffective self-supervised pre-training, insufficient labeled data for fine-tuning, or suboptimal clustering threshold
  - High variance in results: Could be due to randomness in the training process or sensitivity to hyperparameters

- First 3 experiments:
  1. Evaluate the impact of identity-awareness loss by comparing the aligned vs. unaligned models on a held-out validation set
  2. Test different fusion strategies (sum, concatenation, weighted sum) for combining face and body embeddings
  3. Experiment with different clustering thresholds to find the optimal value for assigning character identities

## Open Questions the Paper Calls Out

- Question: Does the identity-awareness loss function generalize well to comic series with significantly different drawing styles or character designs?
- Basis in paper: [inferred] The paper mentions evaluating models on different series but doesn't specifically test on vastly different artistic styles
- Why unresolved: The current evaluation focuses on performance metrics but doesn't explicitly test cross-style generalization
- What evidence would resolve it: Experiments showing consistent performance when trained on one artistic style and tested on another, or ablation studies removing identity-awareness loss for different styles

- Question: What is the optimal trade-off between face and body features for character re-identification across different comic genres (e.g., action vs. slice-of-life)?
- Basis in paper: [explicit] The paper compares face-only, body-only, and combined models but doesn't analyze performance across different comic genres
- Why unresolved: The evaluation uses a general dataset without genre-specific analysis of when face or body features are more important
- What evidence would resolve it: Genre-specific performance analysis showing which feature type (face/body) dominates in different comic styles, potentially leading to adaptive fusion strategies

- Question: How would the framework perform if trained on real-world face and body data before fine-tuning on comics?
- Basis in paper: [explicit] The paper uses self-supervised learning directly on comic data without pre-training on real images
- Why unresolved: The paper doesn't explore whether pre-training on real face/body datasets could improve performance or reduce training data requirements
- What evidence would resolve it: Comparative experiments showing performance differences between direct comic training vs. pre-training on real data followed by comic fine-tuning

## Limitations

- Reliance on DASS model for face-body pairing introduces potential bottleneck in detection accuracy
- Identity-awareness loss effectiveness not fully validated with sufficient empirical evidence
- Clustering-based evaluation lacks precision of supervised metrics and introduces variability based on distance threshold
- Dataset biases and generalizability to diverse comic styles not thoroughly addressed

## Confidence

- High Confidence: The overall framework design and the multi-step approach for character re-identification are well-defined and logically structured
- Medium Confidence: The performance improvements demonstrated on the newly curated datasets are significant, but the lack of comparison with other comic-specific re-identification methods limits the conclusiveness of these results
- Low Confidence: The specific impact of the identity-awareness loss and the optimal configuration of the meta-mining strategy are not fully elucidated, requiring further investigation

## Next Checks

1. Conduct ablation studies to quantify the contribution of the identity-awareness loss by comparing the performance of the aligned model against an unaligned baseline on a held-out validation set
2. Experiment with different fusion methods (sum, concatenation, weighted sum) for combining face and body embeddings to determine the optimal approach for capturing identity-related information
3. Perform a systematic search over different distance thresholds for Agglomerative Clustering to identify the value that maximizes re-identification accuracy while minimizing false merges and splits