---
ver: rpa2
title: Contrastive Denoising Score for Text-guided Latent Diffusion Image Editing
arxiv_id: '2311.18608'
source_url: https://arxiv.org/abs/2311.18608
tags:
- image
- loss
- editing
- source
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Contrastive Denoising Score (CDS), a method
  for text-guided image editing that improves structural preservation over the baseline
  Delta Denoising Score (DDS) by incorporating contrastive learning. CDS applies the
  CUT loss using intermediate features from self-attention layers in latent diffusion
  models, enabling zero-shot image-to-image translation and NeRF editing.
---

# Contrastive Denoising Score for Text-guided Latent Diffusion Image Editing

## Quick Facts
- arXiv ID: 2311.18608
- Source URL: https://arxiv.org/abs/2311.18608
- Reference count: 40
- Key outcome: CDS improves structural preservation in text-guided image editing over DDS by using contrastive learning with self-attention features, achieving 97.5% CLIP accuracy and 0.0203 structure distance.

## Executive Summary
This paper introduces Contrastive Denoising Score (CDS), a method for text-guided image editing that improves structural preservation over the baseline Delta Denoising Score (DDS) by incorporating contrastive learning. CDS applies the CUT loss using intermediate features from self-attention layers in latent diffusion models, enabling zero-shot image-to-image translation and NeRF editing. The method achieves a better balance between maintaining structural details of the source image and transforming content to match the target text prompt.

## Method Summary
CDS modifies DDS by adding a contrastive learning component using intermediate features from self-attention layers of latent diffusion models. Instead of employing auxiliary networks as in the original CUT approach, CDS leverages the self-attention features that naturally contain spatial information between patches. During the denoising process, CDS extracts these intermediate features and applies PatchNCE loss to regularize the gradients, preserving structural consistency between source and edited images while still allowing semantic transformations to match the target text prompt.

## Key Results
- CDS achieves 97.5% CLIP accuracy and 0.0203 structure distance on image editing tasks, outperforming DDS (97.9%, 0.0226)
- The method successfully performs zero-shot image-to-image translation and NeRF editing while preserving structural details
- Qualitative results demonstrate improved structural preservation while following text prompts compared to DDS baseline

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Intermediate features from self-attention layers contain rich spatial information that can be directly utilized for CUT loss calculation.
- Mechanism: The self-attention layers in latent diffusion models compute similarity between spatial patches, providing a natural representation for patch-wise contrastive learning without requiring additional encoders.
- Core assumption: Self-attention features maintain spatial correspondence while being disentangled from semantic information, making them suitable for CUT loss computation.
- Evidence anchors: [section] "intermediate representations from self-attention layers have been shown to contain rich spatial information, disentangled from semantic information [27]"; [section] "self-attention layers contain similarity information between spatial patches in the given representations, which is exactly CUT loss requires"

### Mechanism 2
- Claim: The contrastive loss (ℓcon) regularizes DDS gradients to preserve structural details while allowing semantic changes.
- Mechanism: By maximizing mutual information between corresponding patches from input and output features while minimizing it for non-corresponding patches, the CUT loss constrains the editing process to maintain spatial relationships.
- Core assumption: The gradient updates from ℓcon effectively balance between preserving source structure and achieving target semantics.
- Evidence anchors: [section] "we can regularize DDS to maintain structural consistency between the z and ˆz"; [section] "the gradient has much more detailed structural information such as cat's ears and pose" (Figure 5)

### Mechanism 3
- Claim: Using latent diffusion model features eliminates the need for auxiliary networks in CUT loss computation.
- Mechanism: By leveraging the intermediate features from the existing LDM architecture, CDS achieves zero-shot image editing without requiring additional training or network inference.
- Core assumption: The self-attention features extracted during the DDS denoising process contain sufficient spatial information for effective contrastive learning.
- Evidence anchors: [section] "we demonstrate that the intermediate features of LDM, particularly those from self-attention, contain rich spatial information, allowing them to be directly utilized for applying CUT loss"; [abstract] "Instead of employing auxiliary networks as in the original CUT approach, we leverage the intermediate features of LDM"

## Foundational Learning

- Concept: Score Distillation Sampling (SDS) framework
  - Why needed here: CDS builds upon SDS as its foundation, extending it with contrastive regularization for structural preservation
  - Quick check question: How does SDS use diffusion model gradients to optimize image generation?

- Concept: Patch-wise contrastive learning (CUT loss)
  - Why needed here: The CUT loss is the core mechanism for maintaining structural correspondence between source and edited images
  - Quick check question: What is the objective function of patchNCE loss in maximizing mutual information between corresponding patches?

- Concept: Self-attention mechanisms in transformers
  - Why needed here: Self-attention layers provide the spatial features used for CUT loss computation in CDS
  - Quick check question: How do self-attention layers encode spatial relationships between patches in the latent representation?

## Architecture Onboarding

- Component map: Source image + target text -> DDS framework with two branches -> Self-attention feature extraction -> PatchNCE loss computation -> Combined DDS and contrastive loss -> Updated image latent representation

- Critical path:
  1. Initialize with source image and target text prompt
  2. Extract self-attention features from both branches during denoising
  3. Compute patchNCE loss between corresponding features
  4. Calculate DDS loss as feature difference
  5. Combine losses and update image latent representation

- Design tradeoffs:
  - Patch size vs. computational efficiency: Smaller patches (1×1) provide better structural preservation but increase computation
  - Number of patches vs. regularization strength: More patches improve structural consistency but may over-constrain editing
  - Loss weight tuning: Higher ℓcon weight improves structure preservation but may limit semantic changes

- Failure signatures:
  - Excessive structural preservation: Image doesn't transform to match target text (ℓcon weight too high)
  - Loss of structural details: Edited image looks unrealistic or deformed (ℓcon weight too low or patch size inappropriate)
  - Computational inefficiency: Very small patches or too many patches slow down editing significantly

- First 3 experiments:
  1. Baseline DDS vs. CDS with default settings on cat→dog transformation to verify structural improvement
  2. Ablation study varying ℓcon weight (0.0, 1.0, 3.0, 5.0) to find optimal balance
  3. Comparison of different feature extraction locations (score output, cross-attention, self-attention) to validate self-attention choice

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of feature extraction layer (e.g., self-attention vs. cross-attention) affect the performance of CDS in preserving structural consistency?
- Basis in paper: [explicit] The paper mentions that applying the CUT loss on the hidden state of self-attention layers yields the best performance in editing, as opposed to other layers like cross-attention.
- Why unresolved: The paper provides qualitative results showing the effectiveness of self-attention layers but does not offer a detailed analysis of why this layer outperforms others.
- What evidence would resolve it: Conducting experiments to compare the performance of CDS using different feature extraction layers (e.g., self-attention, cross-attention, and score network output) and quantifying the differences in structural preservation.

### Open Question 2
- Question: What is the impact of varying the patch size and number of patches on the balance between structural preservation and semantic transformation in CDS?
- Basis in paper: [explicit] The paper discusses ablation studies on patch size and number of patches, showing their effects on content preservation and structural details.
- Why unresolved: While the paper provides qualitative results, it does not quantify the trade-offs between structural preservation and semantic transformation for different patch configurations.
- What evidence would resolve it: Performing quantitative evaluations with different patch sizes and numbers, measuring both structural consistency and semantic accuracy, to determine the optimal configuration.

### Open Question 3
- Question: Can CDS be extended to other domains beyond image editing and NeRF, such as video or audio editing, and what challenges might arise?
- Basis in paper: [inferred] The paper mentions that CDS is grounded in the score distillation framework, which could potentially be applied to multiple domains, but does not explore extensions beyond image editing and NeRF.
- Why unresolved: The paper focuses on image editing and NeRF but does not investigate the applicability of CDS to other domains or the potential challenges in such extensions.
- What evidence would resolve it: Experimenting with CDS in other domains, such as video or audio, and analyzing the challenges and adaptations required for successful application.

## Limitations
- The effectiveness of self-attention features for CUT loss depends heavily on their spatial disentanglement from semantic information, which is not directly validated for the specific features extracted during denoising.
- The optimal weight for the contrastive loss (set to 3.0) appears to be determined through limited ablation studies, and its sensitivity to different editing scenarios remains unclear.
- While improvements over DDS baselines are demonstrated, the absolute performance metrics need independent verification to assess their practical significance.

## Confidence
- **High Confidence**: The overall framework of combining DDS with contrastive regularization is technically sound and well-explained. The use of self-attention features as a computational shortcut for CUT loss is a novel and practical contribution.
- **Medium Confidence**: The quantitative improvements over DDS baselines are demonstrated, but the absolute performance metrics (97.5% CLIP, 0.0203 structure distance) need independent verification to assess their practical significance.
- **Low Confidence**: The claim that self-attention features are naturally disentangled from semantic information is based on prior work [27] but not directly validated for the specific features extracted during the denoising process in this paper.

## Next Checks
1. **Ablation on Feature Sources**: Compare the performance of CDS using features from different layers (score output, cross-attention, self-attention) to empirically validate the claim that self-attention features provide optimal spatial information for CUT loss while maintaining semantic disentanglement.

2. **Hyperparameter Sensitivity Analysis**: Systematically vary the contrastive loss weight (ℓcon) across a wider range (e.g., 0.1 to 10.0) and measure the trade-off between structural preservation and semantic alignment to determine if 3.0 is universally optimal or task-dependent.

3. **Cross-Dataset Generalization**: Evaluate CDS on datasets beyond LAION 5B (such as COCO or Flickr) with diverse image types and editing prompts to assess whether the structural preservation benefits generalize beyond the training distribution of the base diffusion model.