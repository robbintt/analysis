---
ver: rpa2
title: 'UFDA: Universal Federated Domain Adaptation with Practical Assumptions'
arxiv_id: '2311.15570'
source_url: https://arxiv.org/abs/2311.15570
tags:
- source
- domain
- target
- label
- adaptation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of Universal Federated Domain
  Adaptation (UFDA), a more practical scenario than conventional Federated Domain
  Adaptation (FDA). UFDA relaxes assumptions by only requiring black-box models and
  label set information for each source domain, allowing inconsistent label sets across
  sources and an unknown target label set.
---

# UFDA: Universal Federated Domain Adaptation with Practical Assumptions

## Quick Facts
- arXiv ID: 2311.15570
- Source URL: https://arxiv.org/abs/2311.15570
- Reference count: 15
- Key outcome: Proposes HCLD framework achieving 77.2% accuracy on Office-Home, 89.28% on Office-31, and 68.3% on VisDA+ImageCLEF-DA

## Executive Summary
This paper addresses Universal Federated Domain Adaptation (UFDA), a more practical scenario than conventional Federated Domain Adaptation (FDA). UFDA relaxes assumptions by requiring only black-box models and label set information for each source domain, allowing inconsistent label sets across sources and an unknown target label set. The authors propose Hot-Learning with Contrastive Label Disambiguation (HCLD) to tackle these challenges. HCLD leverages one-hot outputs from source black-box models to generate multiple candidate pseudo-labels for target samples, uses a Gaussian Mixture Model (GMM)-based strategy to disambiguate these candidates, and employs a cluster-level Mutual-Voting Decision (MVD) strategy to extract robust consensus knowledge across peer classes. Extensive experiments demonstrate that HCLD achieves comparable performance to previous methods with significantly fewer assumptions.

## Method Summary
The paper proposes HCLD, a framework for Universal Federated Domain Adaptation that relaxes conventional assumptions. HCLD operates on black-box source models and label set information, generating Pseudo-Hot-Labels (PHL) by ensembling one-hot outputs from multiple sources. It then applies Gaussian Mixture Model-based Contrastive Label Disambiguation (GCLD) to distinguish shared classes from unknown ones using contrastive learning and self-entropy distributions. Finally, Mutual-Voting Decision (MVD) leverages consensus knowledge across domains to identify shared and unknown classes. The framework trains the target model using refined pseudo-labels and contrastive loss, achieving comparable performance to previous methods while requiring fewer assumptions.

## Key Results
- Achieves 77.2% average accuracy on Office-Home dataset
- Achieves 89.28% average accuracy on Office-31 dataset
- Achieves 68.3% average accuracy on VisDA+ImageCLEF-DA dataset

## Why This Works (Mechanism)

### Mechanism 1
- Claim: HCLD reduces the impact of falsely high confidence predictions for non-existent target classes by using one-hot outputs from source models to generate multiple candidate pseudo-labels.
- Mechanism: Instead of relying on a single high-confidence prediction from each source model, HCLD aggregates the one-hot outputs from multiple source models. This ensemble approach ensures that correct labels are more likely to be included among the candidate pseudo-labels, mitigating the impact of overconfident but incorrect predictions.
- Core assumption: The correct label for a target sample will be included in the one-hot output of at least one source model, even if other source models are overconfident in incorrect labels.
- Evidence anchors: [abstract]: "It particularly tackles UFDA's domain shifts and category gaps problem by using one-hot outputs from the black-box models of various source domains."; [section]: "To mitigate the limitation, unlike (Litrico, Del Bue, and Morerio 2023; Liu et al. 2023) that design the pseudo-labels with these confidences and the weight normalization technique, we propose ensemble multiple one-hot outputs to form the pseudo-labels denoted as Pseudo-Hot-Label (PHL) Cpse (See Figure. 4), which contains more than one candidate pseudo-labels for each target sample."

### Mechanism 2
- Claim: The Gaussian Mixture Model (GMM) based Contrastive Label Disambiguation (GCLD) strategy sharpens the confidence of shared-class samples and smooths the confidence of unknown-class samples.
- Mechanism: GCLD uses contrastive learning to generate cluster prototypes and then fits a GMM to the self-entropy distribution of the embeddings. Samples with low self-entropy (easy to learn) are treated as shared-class samples, while samples with high self-entropy (hard to learn) are treated as unknown-class samples. This allows the model to iteratively refine the pseudo-labels by increasing the confidence of shared-class samples and decreasing the confidence of unknown-class samples.
- Core assumption: The self-entropy distribution of the embeddings can be effectively modeled by a two-component GMM, where one component represents shared-class samples and the other represents unknown-class samples.
- Evidence anchors: [abstract]: "Moreover, to better distinguish the shared and unknown classes, we further present a cluster-level strategy named Mutual-V oting Decision (MVD) to extract robust consensus knowledge across peer classes from both source and target domains."; [section]: "To produce better pseudo-labels, we propose to weaken the information in the unknown class and strengthen the information in the shared classes in the above PHL. The critical challenge is distinguishing between shared- and unknown-class samples. Inspired by (Permuter, Francos, and Jermyn 2006), GMM can better distinguish clean and noisy samples due to its flexibility in the sharpness of distribution."

### Mechanism 3
- Claim: The Mutual-Voting Decision (MVD) strategy leverages consensus knowledge across peer classes from source and target domains to distinguish shared and unknown classes.
- Mechanism: MVD calculates a voting score for each class based on the proportion of overlapping samples recognized as the same category by all APIs (source + target). Classes with high voting scores are considered shared classes, while classes with low voting scores are considered unknown classes. This consensus-based approach helps to identify classes that are consistently recognized across domains.
- Core assumption: Shared classes will have higher voting scores because they are consistently recognized across source and target domains, while unknown classes will have lower voting scores due to lack of consistency.
- Evidence anchors: [abstract]: "Moreover, to better distinguish the shared and unknown classes, we further present a cluster-level strategy named Mutual-V oting Decision (MVD) to extract robust consensus knowledge across peer classes from both source and target domains."; [section]: "Inspired by the consensus knowledge of shared classes among different domains, we consider utilizing cluster-level consensus from multi-source and target APIs to distinguish between shared and unknown classes."

## Foundational Learning

- Concept: Federated Learning (FL)
  - Why needed here: UFDA builds upon the principles of FL, where models are trained across decentralized devices without sharing raw data. Understanding FL is crucial for grasping the motivation behind UFDA and its assumptions.
  - Quick check question: What is the primary advantage of using FL in scenarios like UFDA, and what are the potential security concerns associated with it?

- Concept: Domain Adaptation (DA)
  - Why needed here: UFDA is a specific type of domain adaptation that addresses the challenge of transferring knowledge from multiple source domains to a target domain with different label sets. Familiarity with DA techniques and their limitations is essential for understanding the novelty and challenges of UFDA.
  - Quick check question: What are the key differences between conventional DA and UFDA, and how do these differences impact the design of adaptation strategies?

- Concept: Contrastive Learning (CL)
  - Why needed here: HCLD leverages contrastive learning to generate cluster prototypes and improve the quality of pseudo-labels. Understanding CL is important for comprehending how HCLD disambiguates candidate pseudo-labels and distinguishes shared from unknown classes.
  - Quick check question: How does contrastive learning help in improving the quality of pseudo-labels in HCLD, and what are the key components of the CL-based strategy used in the GCLD module?

## Architecture Onboarding

- Component map: Black-box models -> PHL Generation -> GCLD -> MVD -> Target Model Training

- Critical path:
  1. Generate Pseudo-Hot-Labels (PHL) by aggregating one-hot outputs from source models.
  2. Apply GCLD to disambiguate PHL and refine pseudo-labels.
  3. Use MVD to distinguish shared and unknown classes based on consensus knowledge.
  4. Train the target model using the refined pseudo-labels and contrastive loss.

- Design tradeoffs:
  - Tradeoff between using soft outputs (with confidence scores) vs. one-hot outputs for pseudo-label generation. One-hot outputs are less sensitive to overconfident predictions but may lack the granularity of soft outputs.
  - Tradeoff between using a simple voting strategy vs. a more complex GMM-based approach for distinguishing shared and unknown classes. GMM provides a more nuanced distinction but requires fitting a model to the data.

- Failure signatures:
  - If the GMM does not accurately model the self-entropy distribution, the distinction between shared and unknown classes may be incorrect, leading to poor performance.
  - If the voting scores are not well-separated or if the threshold for distinguishing shared and unknown classes is not well-calibrated, the classification of classes may be incorrect, leading to poor performance.
  - If the source models are consistently incorrect in their predictions, the PHL may not contain the correct labels, leading to poor performance.

- First 3 experiments:
  1. Evaluate the performance of HCLD on a simple UFDA task with a small number of source domains and a limited number of classes.
  2. Compare the performance of HCLD with different settings of the threshold parameter λ in the MVD strategy.
  3. Analyze the impact of using different numbers of source models on the quality of the PHL and the overall performance of HCLD.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does HCLD perform compared to state-of-the-art methods when the label sets of the source domains have a large intersection?
- Basis in paper: [explicit] The paper mentions that HCLD performs well with all category settings and shows a more stable performance compared with HCLD⋆, which is sensitive to different category settings.
- Why unresolved: The paper does not provide specific comparisons for cases with large label set intersections.
- What evidence would resolve it: Conducting experiments with datasets where the source domains have a large label set intersection and comparing HCLD's performance with other state-of-the-art methods.

### Open Question 2
- Question: What is the impact of the number of communication rounds on HCLD's performance in the Federated Domain Adaptation setting?
- Basis in paper: [explicit] The paper mentions that the number of communication rounds r plays a crucial role and that they adopt r = 1 for all tasks.
- Why unresolved: The paper does not explore the effect of varying the number of communication rounds on HCLD's performance.
- What evidence would resolve it: Experimenting with different values of r and analyzing the performance of HCLD in terms of accuracy and convergence.

### Open Question 3
- Question: How does HCLD handle cases where the target domain has a significantly different label set compared to the source domains?
- Basis in paper: [explicit] The paper mentions that HCLD can accurately classify target samples if they correspond to the shared class C, but it does not explicitly address how HCLD handles cases with significantly different label sets.
- Why unresolved: The paper does not provide specific experiments or analysis for this scenario.
- What evidence would resolve it: Conducting experiments with datasets where the target domain has a significantly different label set compared to the source domains and evaluating HCLD's performance in terms of accuracy and robustness.

## Limitations

- The GMM-based sample divisions and pseudo-label updating process in the GCLD strategy are not fully specified, making exact reproduction challenging.
- The choice of threshold values (σ for GMM-based divisions, λ for MVD) and hyperparameters (δ for memory bank mixing, γ for prototype updating) significantly impacts performance but are not clearly defined.
- The paper lacks ablation studies to isolate the contribution of each component (PHL, GCLD, MVD) to the overall performance.

## Confidence

- High Confidence: The overall framework design and the three key components (PHL, GCLD, MVD) are well-motivated and logically sound. The experimental results on benchmark datasets demonstrate the effectiveness of HCLD in addressing UFDA challenges.
- Medium Confidence: The specific implementation details of the GMM-based sample divisions and pseudo-label updating process in the GCLD strategy are not fully specified, introducing some uncertainty in reproducing the exact results. The choice of hyperparameters and threshold values may also impact performance.
- Low Confidence: The scalability of the approach to a large number of source domains and classes is not thoroughly evaluated. The impact of the assumptions (e.g., access to black-box models, label set information) on real-world applicability is not discussed.

## Next Checks

1. **Ablation Study**: Conduct an ablation study to isolate the contribution of each component (PHL, GCLD, MVD) to the overall performance. This will help identify the most critical components and guide future improvements.

2. **Hyperparameter Sensitivity Analysis**: Perform a sensitivity analysis to determine the impact of key hyperparameters (σ, λ, δ, γ) on the performance of HCLD. This will provide insights into the robustness of the approach and guide hyperparameter tuning.

3. **Scalability Evaluation**: Evaluate the scalability of HCLD by testing it on datasets with a larger number of source domains and classes. This will help assess the practical applicability of the approach to real-world scenarios with complex label spaces and diverse source domains.