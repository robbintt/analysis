---
ver: rpa2
title: 'R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning
  in Large Language Models under Noisy Context'
arxiv_id: '2310.16535'
source_url: https://arxiv.org/abs/2310.16535
tags:
- prompting
- number
- noisy
- books
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'R3 prompting improves chain-of-thought reasoning in large language
  models under noisy context by introducing a three-stage interactive prompting process:
  reviewing (extracting key sentences), rephrasing (converting to variables), and
  resolving (predicting answers). Evaluated on five reasoning tasks with noisy context,
  R3 prompting achieves an average 3.7% accuracy improvement over the best baseline
  using GPT-3.5-turbo.'
---

# R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context

## Quick Facts
- arXiv ID: 2310.16535
- Source URL: https://arxiv.org/abs/2310.16535
- Reference count: 28
- Key outcome: R3 prompting achieves 3.7% average accuracy improvement over best baseline on 5 reasoning tasks with noisy context

## Executive Summary
R3 prompting introduces a three-stage interactive prompting framework to improve chain-of-thought reasoning in large language models under noisy contexts. The method systematically extracts key sentences, converts them to explicit variables, and uses these variables to predict answers. Evaluated on five arithmetic reasoning tasks with added irrelevant information, R3 prompting demonstrates robustness to increasing noise levels and achieves consistent accuracy improvements over baseline CoT methods.

## Method Summary
R3 prompting uses a three-stage interactive process where each stage builds on the previous one's output. The review stage extracts key sentences from noisy input, the rephrase stage converts these sentences to explicit variable declarations, and the resolve stage predicts the final answer using the declared variables. The approach uses few-shot demonstrations with noisy context examples to guide the model through each stage. All stages employ greedy decoding and use the same set of 8 demonstrations for consistency.

## Key Results
- Achieves 3.7% average accuracy improvement over best baseline using GPT-3.5-turbo
- Shows robustness to increasing amounts of irrelevant information in input
- All three stages (review, rephrase, resolve) contribute meaningfully to performance
- Maintains stable performance across different types of noise patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-stage interaction reduces attention to irrelevant context
- Mechanism: By explicitly separating key sentence extraction, variable declaration, and answer prediction, the model focuses on one reasoning step at a time
- Core assumption: LLMs can maintain coherent intermediate reasoning states across multiple prompt-response interactions
- Evidence anchors:
  - [abstract] "R3 prompting interacts with LLMs to perform key sentence extraction, variable declaration and answer prediction"
  - [section] "The responses generated at the last interaction will perform as hints to guide toward the responses of the next interaction"
  - [corpus] Weak - no direct corpus evidence for multi-stage attention mechanisms in LLMs

### Mechanism 2
- Claim: Structured variable declarations improve mathematical reasoning
- Mechanism: Converting natural language sentences to explicit variables with assigned values creates a clear computational structure
- Core assumption: LLMs have stronger numerical reasoning capabilities when presented with variable assignments versus contextual descriptions
- Evidence anchors:
  - [section] "we guide LLMs to reformulate the problem narratives to variables with the hint of extracted key sentences"
  - [section] "resolve stage, LLMs predict the final answers taking account of the generated variables"
  - [corpus] Weak - no corpus evidence specifically about variable declaration improving reasoning

### Mechanism 3
- Claim: Few-shot demonstrations with noisy context examples improve denoising ability
- Mechanism: By showing exemplar problems containing both in-topic and off-topic noise along with expected key sentence extractions, LLMs learn to distinguish relevant from irrelevant information
- Core assumption: LLMs can learn denoising patterns through in-context learning from carefully selected demonstrations
- Evidence anchors:
  - [section] "we synthesize exemplar problems containing diverse noisy contexts" and "the demonstrations should show the expected key sentences"
  - [section] "we randomly sample several problems from the training data which includes in-topic noisy sentences"
  - [corpus] Weak - no corpus evidence about denoising through few-shot learning

## Foundational Learning

- Concept: Chain-of-thought prompting
  - Why needed here: R3 builds upon CoT by adding structure to handle noisy contexts
  - Quick check question: What is the primary benefit of CoT prompting over direct answer prompting?

- Concept: Variable assignment in mathematical reasoning
  - Why needed here: The rephrase stage converts narrative to explicit variables for clearer computation
  - Quick check question: How does variable declaration help reduce ambiguity in mathematical word problems?

- Concept: Few-shot in-context learning
  - Why needed here: R3 uses demonstrations to teach the model how to extract key sentences and declare variables
  - Quick check question: What is the role of exemplar problems in few-shot prompting?

## Architecture Onboarding

- Component map: Review stage -> Rephrase stage -> Resolve stage
- Critical path:
  1. Review stage processes input and extracts key sentences
  2. Rephrase stage converts key sentences to variable declarations
  3. Resolve stage computes final answer from variables
  4. Output is generated

- Design tradeoffs:
  - Multi-stage interaction vs. single-stage prompting (R3 adds complexity but improves denoising)
  - Explicit variable declaration vs. implicit reasoning (variables provide clarity but require extra processing)
  - Few-shot demonstrations vs. zero-shot prompting (demonstrations improve guidance but require careful selection)

- Failure signatures:
  - Review stage fails: Model includes irrelevant sentences in key sentence extraction, leading to incorrect variable declarations
  - Rephrase stage fails: Model cannot convert key sentences to meaningful variables or misses essential variables
  - Resolve stage fails: Model cannot perform correct mathematical operations on declared variables

- First 3 experiments:
  1. Test R3 prompting on a simple arithmetic problem with one in-topic and one off-topic sentence to verify each stage works
  2. Compare R3 with Manual-CoT on problems with increasing numbers of irrelevant sentences to measure robustness
  3. Run ablation study removing the rephrase stage to measure impact on mathematical reasoning accuracy

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided text.

## Limitations
- Reliance on few-shot exemplars makes performance sensitive to demonstration quality and representativeness
- Multi-stage interaction design increases complexity and latency compared to simpler methods
- Evaluation limited to GPT-3.5-turbo, leaving uncertainty about performance with other LLM architectures

## Confidence
**High Confidence Claims:**
- R3 prompting achieves measurable accuracy improvements over baseline methods on tested datasets
- All three stages contribute meaningfully to the overall performance
- The method shows robustness to increasing amounts of irrelevant information

**Medium Confidence Claims:**
- The mechanism by which structured variable declarations improve mathematical reasoning
- The specific impact of the rephrase stage relative to other components
- The generalizability of results across different LLM architectures

**Low Confidence Claims:**
- Performance under extreme noise conditions beyond those tested
- Transferability to domains outside the tested reasoning tasks
- Computational efficiency compared to simpler baseline methods

## Next Checks
1. **Noise Pattern Generalization Test**: Evaluate R3 prompting on datasets with different noise distribution patterns to assess whether few-shot demonstrations adequately prepare the model for novel noise types.

2. **Computational Efficiency Analysis**: Measure and compare token usage, latency, and API costs of R3 prompting versus baseline methods across all tested datasets.

3. **Model Architecture Transfer**: Implement and test R3 prompting with multiple LLM architectures (including smaller models like LLaMA-7B) to verify whether effectiveness depends on model scale.