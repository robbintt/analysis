---
ver: rpa2
title: Graph-based methods coupled with specific distributional distances for adversarial
  attack detection
arxiv_id: '2306.00042'
source_url: https://arxiv.org/abs/2306.00042
tags:
- adversarial
- attacks
- graph
- neural
- degree
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a graph-based approach to detect and interpret
  adversarial attacks on neural networks. The method involves computing a sparse graph
  from the neural network's architecture using the layer-wise relevance propagation
  algorithm, and then analyzing graph quantities such as node degree and importance
  to predict whether an input image is benign or adversarial.
---

# Graph-based methods coupled with specific distributional distances for adversarial attack detection

## Quick Facts
- arXiv ID: 2306.00042
- Source URL: https://arxiv.org/abs/2306.00042
- Reference count: 38
- Primary result: Graph-based approach achieves up to 99.98% AUROC for adversarial attack detection

## Executive Summary
This paper introduces a novel graph-based approach for detecting adversarial attacks on neural networks by leveraging layer-wise relevance propagation (LRP) to construct sparse graphs from neural network architectures. The method analyzes graph quantities such as node degree and importance to distinguish between benign and adversarial inputs, achieving high detection accuracy across multiple datasets and attack types. Two classification methods are presented: a Wasserstein distance-based statistical approach and logistic regression on graph features. The approach is claimed to be robust against adaptive attacks due to its non-differentiable thresholding step.

## Method Summary
The method constructs sparse graphs from neural networks using LRP to compute relevance scores, then applies thresholding to retain only the top 1% of relevance values. Graph features including node degree, node importance, and edge relevance are extracted and used for classification through either logistic regression or Wasserstein distance-based statistical tests (WSR). The approach is evaluated on MNIST, CIFAR-10, and SVHN datasets against various attack types including FGSM, PGD, Carlini-Wagner, DeepFool, Square, and Auto attacks.

## Key Results
- Achieves up to 99.98% AUROC for some model/attack combinations using Wasserstein distance approach
- Outperforms existing detection methods like LID and RSA in most cases
- Shows degraded performance for stronger attacks like Carlini-Wagner and DeepFool
- Degree-based features are the most reliable predictors across all attacks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph thresholding using relevance scores enables non-differentiable adversarial detection, preventing gradient masking attacks
- Mechanism: LRP assigns importance scores to neuron connections, and thresholding the top 1% creates a sparse graph preserving only significant connections, making it impossible for attackers to compute gradients through detection
- Core assumption: Top 1% relevance threshold captures sufficient structural information to distinguish benign from adversarial inputs
- Break condition: If attackers can create adversarial examples with similar relevance distributions to benign examples

### Mechanism 2
- Claim: Wasserstein distance comparisons between benign and adversarial degree distributions provide robust statistical detection
- Mechanism: Computes empirical degree distributions and uses Wasserstein-1 distance to measure transformation work between distributions for classification
- Core assumption: Benign and adversarial samples generate sufficiently different degree distributions distinguishable via Wasserstein distance
- Break condition: If adversarial attacks can craft degree distributions closely matching benign distributions in Wasserstein distance terms

### Mechanism 3
- Claim: Logistic regression on graph-derived features provides interpretable and accurate classification
- Mechanism: Extracts degree, node importance, and edge relevance features from sparse graphs and trains logistic regression model for classification
- Core assumption: Combination of graph features provides sufficient discriminative power for classification
- Break condition: If feature space becomes too noisy or adversarial attacks manipulate graph features to fool the model

## Foundational Learning

- Concept: Layer-wise Relevance Propagation (LRP)
  - Why needed here: Provides mechanism to assign importance scores to neural network connections for graph construction
  - Quick check question: What is the key difference between LRP and simple gradient-based attribution methods?

- Concept: Wasserstein distance
  - Why needed here: Provides principled way to compare distributions of graph features between benign and adversarial samples
  - Quick check question: How does Wasserstein distance differ from other distributional comparison metrics like KL divergence?

- Concept: Graph theory basics (degree, centrality, sparse graphs)
  - Why needed here: Essential for interpreting extracted features and their role in detection
  - Quick check question: Why might degree be more useful than closeness centrality for bipartite or stacked bipartite graphs?

## Architecture Onboarding

- Component map: Input preprocessing -> Neural network inference -> LRP relevance computation -> Graph thresholding -> Feature extraction -> Classification -> Output
- Critical path: 1) Neural network forward pass with input image, 2) LRP algorithm execution to compute relevance scores, 3) Thresholding to create sparse graph, 4) Feature computation from graph, 5) Classification decision
- Design tradeoffs: Memory vs. accuracy (using only last two layers reduces memory but may lose information), threshold selection (1% balances sparsity with information retention), statistical vs. ML approach (WSR provides theoretical guarantees but logistic regression may be more flexible)
- Failure signatures: High false negative rate suggests adversarial attacks mimic benign graph structures, high false positive rate indicates benign inputs generate unusual graph features, degraded performance on specific attacks suggests attack-specific weaknesses
- First 3 experiments: 1) Verify LRP implementation by comparing relevance scores against MNIST benchmarks, 2) Test graph construction by visualizing sparse graphs for benign and adversarial examples, 3) Benchmark WSR classification performance across different threshold values and attack types

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed graph-based approach perform compared to other detection methods across various neural network architectures?
- Basis in paper: Authors compare their approach to LID and RSA, finding it outperforms these methods in most cases
- Why unresolved: Paper only provides comparison with limited detection methods and architectures
- What evidence would resolve it: Comprehensive comparison with wide range of detection methods and neural network architectures

### Open Question 2
- Question: How do different adversarial attack strengths affect the performance of the proposed graph-based approach?
- Basis in paper: Authors note accuracy decreases as attack strength increases
- Why unresolved: Paper lacks detailed analysis of how attack strengths affect performance
- What evidence would resolve it: Systematic evaluation across range of attack strengths

### Open Question 3
- Question: How do the proposed graph-based quantities (node importance, degree, edge relevance) compare in their ability to detect adversarial attacks?
- Basis in paper: Authors introduce three graph-based quantities and evaluate their performance
- Why unresolved: Paper lacks detailed comparison of the three quantities' effectiveness
- What evidence would resolve it: Comparative analysis of the three quantities' performance

## Limitations

- Performance degrades for stronger attacks like Carlini-Wagner and DeepFool
- Limited analysis of threshold sensitivity and its impact on detection performance
- Implementation details for LRP and logistic regression hyperparameters are unspecified

## Confidence

- **High confidence**: Basic graph construction methodology using LRP relevance scores and thresholding is well-established
- **Medium confidence**: Non-differentiable thresholding prevents gradient masking attacks is theoretically sound but lacks empirical validation
- **Medium confidence**: Performance claims (up to 99.98% AUROC) are impressive but rely on specific model/attack combinations
- **Low confidence**: Interpretability claims about which graph features matter most are not well-supported

## Next Checks

1. Design and implement gradient-free attacks specifically targeting the graph thresholding mechanism to test claimed robustness against adaptive adversaries
2. Systematically vary the relevance threshold (1%, 5%, 10%, etc.) and measure how detection performance changes across different attack types
3. Conduct ablation studies removing each graph feature (degree, node importance, edge relevance) individually to verify claimed relative importance rankings