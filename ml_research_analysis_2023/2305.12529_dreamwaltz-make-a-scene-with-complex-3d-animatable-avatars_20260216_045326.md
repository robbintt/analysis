---
ver: rpa2
title: 'DreamWaltz: Make a Scene with Complex 3D Animatable Avatars'
arxiv_id: '2305.12529'
source_url: https://arxiv.org/abs/2305.12529
tags:
- avatar
- avatars
- generation
- animation
- complex
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents DreamWaltz, a novel framework for generating
  high-quality 3D avatars with complex shapes and appearances that can be animated
  and composed into scenes with diverse interactions. DreamWaltz leverages text guidance
  and parametric human body prior to create 3D avatars.
---

# DreamWaltz: Make a Scene with Complex 3D Animatable Avatars

## Quick Facts
- arXiv ID: 2305.12529
- Source URL: https://arxiv.org/abs/2305.12529
- Reference count: 40
- Key outcome: Novel framework for generating high-quality 3D avatars with complex shapes and appearances that can be animated and composed into scenes with diverse interactions

## Executive Summary
DreamWaltz introduces a novel framework for generating 3D avatars with complex shapes and appearances that can be animated and composed into scenes. The key innovation is 3D-consistent occlusion-aware Score Distillation Sampling (SDS) to optimize implicit neural representations with canonical poses, combined with an animatable 3D avatar representation learned from abundant image priors. This enables creation of complex scenes with avatar-avatar, avatar-object, and avatar-scene interactions without the multi-face problem common in previous approaches.

## Method Summary
DreamWaltz employs a trainable Neural Radiance Field (NeRF) as the 3D avatar representation, a pre-trained text-and-skeleton-conditional diffusion model for shape and appearance supervision, and SMPL models for extracting 3D-aware posed-skeletons. The framework uses SMPL-guided NeRF initialization, 3D-consistent occlusion-aware SDS to optimize the NeRF, and trains a density weighting network (MLPDRN) for animation generalization. The approach enables text-guided generation of complex 3D avatars that can be animated to arbitrary poses without retraining.

## Key Results
- Achieves state-of-the-art results on avatar generation and animation as demonstrated by extensive experiments and user studies
- Resolves the Janus (multi-face) problem through 3D-consistent SDS with occlusion-aware skeleton conditioning
- Enables complex scene composition with avatar-avatar, avatar-object, and avatar-scene interactions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: 3D-consistent occlusion-aware SDS resolves view disparity between diffusion model supervision images and NeRF-rendered images
- Mechanism: By conditioning the diffusion model on 3D-aware skeleton maps extracted from SMPL models with occlusion culling, the supervision image viewpoint is aligned with NeRF's rendering viewpoint
- Core assumption: Diffusion model can effectively utilize 3D-aware skeleton conditioning to generate consistent supervision images
- Evidence anchors: [abstract] "DreamWaltz proposes 3D-consistent occlusion-aware SDS... via 3D-aware skeleton conditioning which enables complex avatar generation without artifacts and multiple faces"
- Break condition: If diffusion model cannot effectively interpret skeleton conditioning or if occlusion culling fails to remove invisible keypoints

### Mechanism 2
- Claim: Learning a generalizable density weighting network (MLPDRN) enables high-quality animation of complex non-skin-tight avatars without retraining
- Mechanism: MLPDRN learns to downweight density contribution when points are far from closest SMPL vertex, preventing artifacts like extra limbs
- Core assumption: Distance between NeRF point and closest SMPL vertex is a reliable indicator of whether point should be suppressed
- Evidence anchors: [abstract] "Our method learns an animatable and generalizable avatar representation which could map arbitrary poses to the canonical pose representation"
- Break condition: If MLPDRN fails to learn generalizable function across diverse poses or point-vertex distance is not a good proxy for suppression

### Mechanism 3
- Claim: SMPL-guided initialization and 3D-consistent SDS supervision improve convergence speed and final quality
- Mechanism: Pre-training NeRF on SMPL silhouettes provides reasonable initial geometry aligned with human shape prior, while 3D-consistent SDS reduces optimization ambiguity
- Core assumption: SMPL model provides reasonable shape prior for diverse avatars and 3D-consistent supervision is more effective than view-inconsistent supervision
- Evidence anchors: [section] "We empirically found that SMPL-guided NeRF initialization significantly improves the geometry and the convergence speed for avatar generation"
- Break condition: If SMPL prior is too restrictive for complex avatars or 3D-consistent supervision doesn't provide meaningful improvement

## Foundational Learning

- Concept: Neural Radiance Fields (NeRF)
  - Why needed here: NeRF provides learnable 3D representation that can be optimized using 2D diffusion model supervision, enabling text-to-3D avatar generation without requiring large 3D datasets
  - Quick check question: What is the key difference between NeRF and traditional mesh-based 3D representations?

- Concept: Score Distillation Sampling (SDS)
  - Why needed here: SDS enables transfer of knowledge from pre-trained 2D diffusion model to 3D representation by using diffusion model's denoising score as supervision
  - Quick check question: How does SDS differ from traditional differentiable rendering loss functions?

- Concept: SMPL human body model
  - Why needed here: SMPL provides parametric 3D human body model used for both initialization of avatar geometry and extraction of 3D-aware skeletons for conditioning diffusion model
  - Quick check question: What are the two main components of SMPL deformation, and how do they differ?

## Architecture Onboarding

- Component map: Text prompt, body shape (β), and pose (ξ) parameters -> SMPL model -> ControlNet -> NeRF -> MLPDRN -> Output 3D avatar

- Critical path: 1. Sample SMPL parameters (β, ξ) from pose prior 2. Initialize NeRF with SMPL silhouette rendering 3. Extract 3D-aware skeleton with occlusion culling 4. Condition ControlNet with text and skeleton 5. Optimize NeRF via 3D-consistent SDS 6. Train MLPDRN for animation generalization 7. Apply arbitrary poses using MLPDRN-weighted transformation

- Design tradeoffs: SMPL-guided initialization vs. random initialization (faster convergence vs. potential bias toward human-like shapes), 3D-consistent SDS vs. vanilla SDS (better view consistency vs. simpler implementation), MLPDRN for animation vs. direct pose mapping (better quality for complex avatars vs. simpler implementation for skin-tight avatars)

- Failure signatures: Multiple faces or inconsistent geometry (likely view inconsistency in SDS supervision), extra limbs or artifacts during animation (MLPDRN not learning proper density weighting), poor convergence or quality (SMPL prior too restrictive or initialization not effective)

- First 3 experiments: 1. Test SMPL-guided NeRF initialization on simple avatar to verify faster convergence compared to random initialization 2. Evaluate 3D-consistent SDS with occlusion culling on complex avatar to check for elimination of Janus problem 3. Test MLPDRN on simple animation sequence to verify it prevents extra limbs and artifacts compared to direct SMPL-based transformation

## Open Questions the Paper Calls Out

- Question: How does occlusion culling algorithm impact quality of 3D avatar generation compared to methods without occlusion culling?
- Question: How does proposed density weighting mechanism improve animation quality of complex avatars compared to other methods like Inverse-LBS or AvatarCraft?
- Question: How does proposed framework handle avatar-avatar interactions in complex scenes, and what are limitations of this approach?

## Limitations

- SMPL priors may limit ability to generate truly alien or abstract shapes that deviate significantly from human anatomy
- Computational efficiency and practical implementation feasibility for real-world applications involving multiple avatars and complex interactions remains unclear
- Generalizability to highly diverse and complex avatars beyond evaluated examples needs more extensive validation

## Confidence

**High Confidence Claims:**
- 3D-consistent occlusion-aware SDS mechanism effectively resolves view inconsistency and eliminates Janus problem
- SMPL-guided initialization significantly improves convergence speed and geometry quality

**Medium Confidence Claims:**
- Density weighting network (MLPDRN) successfully enables high-quality animation of complex non-skin-tight avatars
- Framework achieves state-of-the-art results compared to existing methods

**Low Confidence Claims:**
- Framework's ability to scale to highly diverse and complex avatar categories beyond evaluated examples
- Computational efficiency and practical implementation feasibility for real-world applications

## Next Checks

1. **Cross-category robustness test**: Evaluate DreamWaltz on diverse benchmark of 50+ avatar categories spanning extreme body shapes, abstract forms, and non-anthropomorphic designs to assess generalizability limits

2. **Ablation study on SMPL dependence**: Generate avatars with varying degrees of deviation from human anatomy (gradually increasing SMPL parameter noise) to quantitatively measure how SMPL priors constrain shape diversity

3. **Multi-avatar scene complexity scaling**: Measure computational resources (memory, time) and quality degradation when simultaneously generating, animating, and composing scenes with 2, 5, 10, and 20 complex avatars to establish practical limits for real-world applications