---
ver: rpa2
title: Wearable data from subjects playing Super Mario, sitting university exams,
  or performing physical exercise help detect acute mood episodes via self-supervised
  learning
arxiv_id: '2311.04215'
source_url: https://arxiv.org/abs/2311.04215
tags:
- data
- learning
- task
- segments
- uniform
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of detecting mood disorder (MD)
  acute episodes versus stable states using wearable data, which is typically hindered
  by the scarcity of labeled data due to the resource-intensive nature of collecting
  and annotating such data. The authors propose leveraging self-supervised learning
  (SSL) to overcome this data bottleneck by utilizing unlabelled data from open-access
  datasets recorded with the Empatica E4 wristband.
---

# Wearable data from subjects playing Super Mario, sitting university exams, or performing physical exercise help detect acute mood episodes via self-supervised learning

## Quick Facts
- arXiv ID: 2311.04215
- Source URL: https://arxiv.org/abs/2311.04215
- Authors: 
- Reference count: 40
- Key outcome: Self-supervised learning on unlabelled wearable data achieves 81.23% accuracy for mood disorder acute episode detection, outperforming supervised methods (75.35%) and classical ML (72.02%)

## Executive Summary
This study addresses the challenge of detecting mood disorder acute episodes versus stable states using wearable data, which is typically hindered by the scarcity of labeled data due to the resource-intensive nature of collecting and annotating such data. The authors propose leveraging self-supervised learning (SSL) to overcome this data bottleneck by utilizing unlabelled data from open-access datasets recorded with the Empatica E4 wristband. They introduce E4SelfLearning, the largest open-access collection of such data, and develop a pre-processing pipeline. The novel E4-tailored Transformer architecture (E4mer) is employed for SSL, outperforming both fully-supervised E4mer and classical machine learning (XGBoost) models in distinguishing MD acute episodes from euthymia, achieving 81.23% accuracy compared to 75.35% and 72.02%, respectively. The study highlights the importance of the specific surrogate task used for pre-training and the availability of unlabelled data in SSL performance.

## Method Summary
The study employs self-supervised learning to detect mood disorder acute episodes using physiological signals from Empatica E4 wearables. The method involves three main stages: (1) Pre-processing diverse unlabelled datasets from open-access sources (Super Mario gaming, university exams, physical exercise) using on-/off-body detection, sleep-wake detection, and segmentation; (2) Pre-training a Transformer-based E4mer architecture using masked prediction or transformation prediction pretext tasks on the unlabelled data; and (3) Fine-tuning the pre-trained encoder on a small labeled dataset of 64 patients (half acute, half stable) and evaluating against supervised E4mer and XGBoost baselines. The study systematically investigates the impact of unlabelled dataset size and pretext task choice on downstream performance.

## Key Results
- SSL with masked prediction achieves 81.23% accuracy, outperforming supervised E4mer (75.35%) and XGBoost (72.02%) baselines
- Masked prediction pretext task is more effective than transformation prediction for mood disorder detection
- Strong correlation (95.41-96.14%) between unlabelled data availability and SSL performance

## Why This Works (Mechanism)

### Mechanism 1
Self-supervised pre-training on unrelated wearable datasets allows the model to learn general physiological signal representations that transfer to mood disorder detection. The encoder is exposed to diverse, unlabelled physiological data (stress, gaming, exercise) and learns robust features via masked prediction or transformation prediction tasks. These learned representations are then fine-tuned on the small labeled mood disorder dataset. Core assumption: Physiological signals contain underlying structure (e.g., sleep-wake patterns, activity levels) that is shared across different tasks and can be leveraged for mood disorder detection.

### Mechanism 2
Masked prediction as a pretext task is more effective than transformation prediction for learning representations useful for mood disorder detection. By masking portions of the input and training the model to reconstruct the original signal, the encoder learns to understand the temporal and contextual dependencies in the physiological data, which are relevant for detecting mood episodes. Core assumption: The temporal structure and contextual information in physiological signals are crucial for mood disorder detection, and masked prediction forces the model to learn these aspects.

### Mechanism 3
The size of the unlabelled dataset used for pre-training significantly impacts the performance of the downstream mood disorder detection task. Larger unlabelled datasets provide more diverse examples and contexts for the model to learn from, leading to more robust and generalizable representations that can be fine-tuned on the smaller labeled dataset. Core assumption: More diverse and representative unlabelled data leads to better pre-training and, consequently, better downstream performance.

## Foundational Learning

- **Concept**: Self-supervised learning (SSL)
  - **Why needed here**: SSL allows the model to learn useful representations from unlabelled data, mitigating the data scarcity problem in mood disorder detection.
  - **Quick check question**: What are the two main components of an SSL model, and what are their roles in the pre-training and fine-tuning phases?

- **Concept**: Masked prediction and transformation prediction as pretext tasks
  - **Why needed here**: These pretext tasks provide the supervisory signal for the model to learn from unlabelled data, and their choice impacts the quality of the learned representations.
  - **Quick check question**: How do masked prediction and transformation prediction differ in terms of the pseudo-labels they generate and the assumptions they make about the data?

- **Concept**: Transfer learning and fine-tuning
  - **Why needed here**: The representations learned during SSL pre-training are transferred to the downstream mood disorder detection task by fine-tuning the encoder on the labeled data.
  - **Quick check question**: What are the two main approaches to fine-tuning the encoder on the downstream task, and how do they differ in terms of the parameters that are updated?

## Architecture Onboarding

- **Component map**: Input physiological signals (ACL, BVP, EDA, TEMP) -> Pre-processing (on-/off-body detection, sleep-wake detection, segmentation, feature extraction) -> E4mer architecture (CE + RM + Hsl) -> SSL models (CE + RM + Hssl) -> Baselines (E4mer, XGBoost)

- **Critical path**: 1. Pre-process unlabelled data from open-access datasets 2. Pre-train E4mer encoder using SSL (masked prediction or transformation prediction) 3. Fine-tune pre-trained encoder on labeled mood disorder data 4. Evaluate performance on test set

- **Design tradeoffs**:
  - Masked prediction vs transformation prediction: Masked prediction forces the model to learn temporal and contextual dependencies, while transformation prediction encourages robustness to signal disturbances.
  - Linear readout vs fine-tuning: Linear readout keeps the pre-trained encoder frozen and only trains a new classification head, while fine-tuning updates the encoder parameters along with the new head.
  - Segment length and step size: Longer segments may capture more context but result in fewer training examples, while shorter segments provide more data but may miss important patterns.

- **Failure signatures**:
  - Poor SSL pre-training performance: The pretext tasks may not be well-suited to the data, or the unlabelled dataset may be too small or too dissimilar from the downstream task.
  - Good SSL pre-training but poor downstream performance: The learned representations may not be relevant to the mood disorder detection task, or the fine-tuning process may be suboptimal.
  - Overfitting to the downstream task: The model may be too specialized to the training data and not generalize well to unseen examples.

- **First 3 experiments**:
  1. Pre-train E4mer encoder on unlabelled data using masked prediction, then fine-tune on labeled mood disorder data using linear readout. Compare performance to supervised E4mer baseline.
  2. Pre-train E4mer encoder on unlabelled data using transformation prediction, then fine-tune on labeled mood disorder data using fine-tuning. Compare performance to masked prediction approach.
  3. Vary the size of the unlabelled dataset used for SSL pre-training (e.g., 100%, 80%, 60%, 40%, 20%, 0%) and evaluate the impact on downstream performance. Identify the minimum dataset size required for effective SSL.

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal pretext task design for self-supervised learning in mood disorder detection from wearable data? While masked prediction outperformed transformation prediction in this study, the paper acknowledges that different pretext tasks might be more effective for other downstream tasks or datasets. Systematic comparison of various pretext task designs (e.g., contrastive learning, rotation prediction) on multiple mood disorder datasets and downstream tasks would help identify the most effective approaches.

### Open Question 2
How does the amount of unlabeled data impact the performance of self-supervised learning models for mood disorder detection? The paper performs ablation analyses showing a strong dependence of SSL performance on unlabeled data availability, but only investigates a limited range of unlabeled data sizes. Experiments varying the size of unlabeled datasets and analyzing the resulting model performance curves would provide insights into the data requirements for effective SSL in this domain.

### Open Question 3
Can self-supervised learning models generalize to different mood disorder types and severities beyond the acute episode vs. euthymia classification task? The study focuses on a binary classification task and does not explore the model's ability to detect other mood states or severities. Evaluating SSL models on datasets with more diverse mood disorder labels and severities would determine their generalizability and potential for detecting nuanced changes in mental health status.

## Limitations
- Relatively small clinical dataset (64 patients) constrains robustness of performance estimates
- Comparison to baselines may not fully account for all potential supervised learning configurations
- Focus on single wearable device (Empatica E4) limits applicability to other sensing platforms

## Confidence
**High Confidence**:
- SSL outperforms fully-supervised E4mer and XGBoost baselines in distinguishing mood disorder acute episodes from euthymia (81.23% accuracy vs 75.35% and 72.02%)
- Masked prediction pretext task is more effective than transformation prediction for this application
- Performance correlates strongly with the amount of available unlabelled data (Pearson correlation 95.41-96.14%)

**Medium Confidence**:
- The E4SelfLearning dataset enables effective SSL for mood disorder detection
- The E4mer architecture is well-suited for processing multimodal physiological signals from Empatica E4
- The proposed pipeline effectively addresses the data scarcity challenge in mood disorder monitoring

**Low Confidence**:
- Results generalize to other wearable devices beyond Empatica E4
- Findings extend to broader mood disorder populations beyond the studied cohort
- Performance remains stable across different clinical settings and data collection protocols

## Next Checks
1. **External validation on independent datasets**: Test the trained models on mood disorder data collected from different clinical sites, with different Empatica E4 devices, and potentially different demographic compositions to assess generalizability.

2. **Comparison with state-of-the-art supervised methods**: Implement and evaluate recent supervised deep learning approaches specifically designed for physiological time series (e.g., Transformers with advanced positional encoding, specialized temporal modeling architectures) to ensure the SSL advantage is robust.

3. **Ablation study on unlabelled data composition**: Systematically vary the types and characteristics of unlabelled data used for pre-training (e.g., stress vs. physical activity, short vs. long sequences) to identify which data properties are most critical for successful transfer learning.