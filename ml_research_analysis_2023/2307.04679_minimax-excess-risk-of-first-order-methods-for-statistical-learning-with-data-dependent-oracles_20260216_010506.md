---
ver: rpa2
title: Minimax Excess Risk of First-Order Methods for Statistical Learning with Data-Dependent
  Oracles
arxiv_id: '2307.04679'
source_url: https://arxiv.org/abs/2307.04679
tags:
- learning
- error
- function
- where
- gradient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a unified framework for analyzing generalization
  error in statistical learning under data-dependent oracles. The authors introduce
  a novel quantity called "best approximation error" which generalizes conditional
  standard deviation, and use it to derive sharp upper and lower bounds on minimax
  excess risk for strongly convex and smooth optimization problems.
---

# Minimax Excess Risk of First-Order Methods for Statistical Learning with Data-Dependent Oracles

## Quick Facts
- arXiv ID: 2307.04679
- Source URL: https://arxiv.org/abs/2307.04679
- Reference count: 40
- This paper provides a unified framework for analyzing generalization error in statistical learning under data-dependent oracles.

## Executive Summary
This paper introduces a novel framework for analyzing the generalization error of first-order methods in statistical learning problems where gradient observations come from data-dependent oracles. The key innovation is the introduction of "best approximation error" as a quantity that unifies and generalizes existing measures of oracle quality. The authors derive sharp upper and lower bounds on minimax excess risk that are proportional to the smallest mean square error achievable by gradient estimators. The framework is applied to various learning settings including supervised learning, transfer learning, and federated learning, providing both recovery of known results and new bounds for specific problems.

## Method Summary
The method centers on analyzing generalization error through a novel quantity called best approximation error, which measures how well gradient observations from a data-dependent oracle can approximate the true expected gradient. The approach involves: (1) defining an oracle interface that provides partial gradient observations, (2) computing the best approximation error for specific oracle-function class pairs, and (3) deriving bounds on minimax excess risk that scale with this approximation error. The framework is applied to iterative algorithms of the form xt+1 = xt - 1/L ϕ(ot) where ot represents oracle observations, with specific strategies for warm-up phases and increasing mini-batch sizes to optimize the trade-off between approximation and variance errors.

## Key Results
- The best approximation error σH,2(ED|O) provides tight upper and lower bounds on minimax generalization error for strongly convex and smooth problems
- For empirical risk minimization with mini-batch gradient descent and increasing batch sizes, the method achieves optimal rates up to a multiplicative factor
- The framework recovers known generalization bounds and provides new ones for transfer learning and federated learning scenarios

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The best approximation error σH,2 (ED|O) directly controls the minimax generalization error in strongly convex and smooth learning problems.
- **Mechanism**: The oracle provides partial gradient observations that approximate the true gradient expectation. The best approximation error quantifies how well these observations can estimate the gradient expectation over the target distribution. Since the learning problem is strongly convex, the excess risk is proportional to the squared error in gradient estimation, scaled by 1/µ.
- **Core assumption**: The oracle satisfies translation invariance (Assumption 2) and the loss function is µ-strongly convex and L-smooth with gradient in function class H.
- **Evidence anchors**:
  - [abstract] "Our upper and lower bounds are proportional to the smallest mean square error achievable by gradient estimators."
  - [section] "We show that this quantity provides upper and lower bounds for the minimax generalization error..."
  - [corpus] No direct matches, but related to gradient-based optimization bounds.
- **Break condition**: If the oracle violates translation invariance or if the function class H doesn't contain the gradients, the mechanism fails.

### Mechanism 2
- **Claim**: For i.i.d. oracles with increasing batch sizes, the minimax generalization error scales as Θ(n^{-2a}) where a relates to the convergence rate of the best approximation error.
- **Mechanism**: The increasing batch size strategy balances bias (approximation error) and variance (stochastic error). Early iterations use small batches to quickly reduce the optimization error, while later iterations use larger batches to refine the solution with higher precision. The optimal batch size schedule depends on the problem's smoothness parameter κ = L/µ.
- **Core assumption**: The oracle follows the form On with i.i.d. observations and σH,2 (ED|On) = Θ(n^{-a}).
- **Evidence anchors**:
  - [abstract] "For empirical risk minimization with mini-batch gradient descent and increasing batch sizes, the method achieves optimal rates..."
  - [section] "The logarithmic factor can be removed when the best approximation error is bounded by a quantity of the form a + b/n."
  - [corpus] Weak match to "Sharper Guarantees for Learning Neural Network Classifiers with Gradient Methods" but different focus.
- **Break condition**: If the oracle observations are not i.i.d. or if the best approximation error doesn't decay polynomially, the scaling breaks.

### Mechanism 3
- **Claim**: The minimax generalization error for transfer learning is bounded by dH(D,D')² + ∥VD'∥H/n where dH is an integral probability metric.
- **Mechanism**: Transfer learning introduces a distribution shift between training and test distributions. The first term captures the bias from this shift (distance between distributions), while the second term captures the variance from finite samples from the source distribution. The bound separates these two sources of error.
- **Core assumption**: The oracle provides i.i.d. samples from the source distribution D' and the function class H is rich enough to approximate the gradient well.
- **Evidence anchors**:
  - [abstract] "This novel class of oracles can query the gradient with any given data distribution, and is thus well suited to scenarios in which the training data distribution does not match the target (or test) distribution."
  - [section] "σH,2(ED|OTL_n)² ≤ dH(D, D')² + ∥VD'∥H/n"
  - [corpus] Weak match to "Wasserstein Distributionally Robust Nonparametric Regression" which also uses distribution distances.
- **Break condition**: If the source and target distributions are too dissimilar (dH too large) or if the source distribution has high variance (∥VD'∥H large), the bound becomes vacuous.

## Foundational Learning

- **Concept: Strongly convex optimization**
  - Why needed here: The paper's bounds rely on strong convexity to relate gradient estimation error to excess risk through the Polyak-Łojasiewicz condition.
  - Quick check question: Why does µ-strong convexity imply the 2µ-PL condition, and how does this affect the error bounds?

- **Concept: Integral Probability Metrics (IPM)**
  - Why needed here: IPMs like dH(D,D') are used to quantify distribution shift in transfer learning scenarios, which directly impacts the generalization bounds.
  - Quick check question: How does the choice of function class H affect the value of dH(D,D'), and why is this important for transfer learning bounds?

- **Concept: Rademacher Complexity**
  - Why needed here: The paper connects its bounds to Rademacher complexity through the relationship ∥VD∥H/n ≤ RadD,n(H0), providing a bridge to classical statistical learning theory.
  - Quick check question: Why does the upper bound on ∥VD∥H/n by Rademacher complexity allow comparison with classical generalization bounds?

## Architecture Onboarding

- **Component map**: Oracle interface -> Gradient estimation -> Parameter update -> Excess risk computation
- **Critical path**: The key sequence is: Oracle observation → Gradient estimation → Parameter update → Excess risk computation. The bottleneck is the best approximation error computation, which requires optimizing over all measurable functions ϕ.
- **Design tradeoffs**: Using average-based ϕ is computationally efficient but may be suboptimal. Increasing batch sizes improves final precision but requires more computation per iteration. The choice of function class H affects both the tightness of bounds and computational tractability.
- **Failure signatures**: If bounds are vacuous (much larger than empirical error), check if the function class H is too restrictive or if the oracle violates translation invariance. If optimization fails to converge, verify the smoothness and strong convexity assumptions.
- **First 3 experiments**:
  1. Implement the basic oracle framework with synthetic data where the ground truth gradient is known, and verify that the best approximation error matches the theoretical bounds.
  2. Test the increasing batch size strategy on a strongly convex problem and measure how the error scales with different batch size schedules.
  3. Apply the transfer learning framework to a domain adaptation problem with known distribution shift and verify the dH term captures the error correctly.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise relationship between the best approximation error σH,2(ED|O) and the Rademacher complexity for different function classes H?
- Basis in paper: [explicit] The paper shows that ∥VD∥H/n ≤ RadD,n(H0) where H0 = {h ∈ H : ED(h) = 0} and RadD,n(H0) is the multivariate Rademacher complexity.
- Why unresolved: The paper establishes an upper bound but doesn't provide a tight characterization of how these quantities relate for general function classes H.
- What evidence would resolve it: Precise bounds showing whether σH,2(ED|O) is always within a constant factor of Rademacher complexity, or identifying function classes where the gap is large.

### Open Question 2
- Question: Can the increasing mini-batch size strategy with T = ⌊n/2⌋ steps be proven optimal for all function classes H?
- Basis in paper: [explicit] The paper shows this strategy achieves near-optimal rates for specific cases but leaves open whether it's optimal for general H.
- Why unresolved: The proof relies on specific properties of the best approximation error that may not hold for all function classes.
- What evidence would resolve it: A lower bound showing no other strategy can achieve better rates, or a counterexample where a different strategy outperforms this one.

### Open Question 3
- Question: How do the generalization bounds change when the oracle is not translation invariant (violating Assumption 2)?
- Basis in paper: [inferred] The paper assumes translation invariance throughout and notes it's verified in most settings, but doesn't analyze what happens when it's violated.
- Why unresolved: The lower bound proof relies heavily on translation invariance, and removing this assumption could significantly change the bounds.
- What evidence would resolve it: Generalization bounds for specific non-translation-invariant oracles, or a proof that translation invariance is necessary for the current bounds to hold.

## Limitations
- The framework relies heavily on translation invariance assumptions that may not hold in practical learning scenarios
- Computing the best approximation error is computationally challenging and not fully specified for general function classes
- The bounds are derived for strongly convex and smooth problems, limiting applicability to non-convex settings common in deep learning

## Confidence
- **High confidence**: The mechanism connecting best approximation error to minimax excess risk for strongly convex problems is well-supported by the theoretical derivations and consistent with established optimization theory.
- **Medium confidence**: The transfer learning bounds involving dH(D,D') are plausible but rely on assumptions about the oracle's behavior that may be difficult to verify in practice.
- **Low confidence**: The practical implementation of the increasing batch size strategy and the computation of optimal mixing functions are not fully specified, making it difficult to assess their real-world effectiveness.

## Next Checks
1. **Empirical verification of increasing batch sizes**: Implement the iterative algorithm with warm-up phase and increasing mini-batch sizes on a strongly convex problem with known ground truth. Measure the excess risk at each iteration and verify it matches the theoretical scaling predictions.

2. **Computational complexity analysis**: Develop a practical algorithm for computing or approximating the best approximation error σH,2(ED|O) for different function classes and oracles. Analyze its computational complexity and identify scenarios where it becomes tractable.

3. **Robustness to oracle violations**: Design experiments that test the framework's performance when the oracle violates translation invariance or when the function class H doesn't contain the true gradients. Quantify how these violations affect the excess risk bounds.