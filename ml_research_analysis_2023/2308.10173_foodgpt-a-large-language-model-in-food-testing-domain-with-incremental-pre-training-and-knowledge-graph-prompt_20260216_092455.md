---
ver: rpa2
title: 'FoodGPT: A Large Language Model in Food Testing Domain with Incremental Pre-training
  and Knowledge Graph Prompt'
arxiv_id: '2308.10173'
source_url: https://arxiv.org/abs/2308.10173
tags:
- knowledge
- data
- pre-training
- food
- testing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents FoodGPT, a large language model specifically
  designed for the food testing domain. Unlike previous approaches that fine-tune
  base models without pre-training, the authors recognize that a significant amount
  of domain-specific knowledge exists in non-textual images, scanned documents, and
  private structured data, which are not adequately captured by base models.
---

# FoodGPT: A Large Language Model in Food Testing Domain with Incremental Pre-training and Knowledge Graph Prompt

## Quick Facts
- arXiv ID: 2308.10173
- Source URL: https://arxiv.org/abs/2308.10173
- Reference count: 11
- Key outcome: Introduces FoodGPT, a domain-specific LLM for food testing that uses incremental pre-training and knowledge graph retrieval to address knowledge gaps in base models

## Executive Summary
FoodGPT is a large language model specifically designed for the food testing domain that addresses a critical limitation in existing approaches: base models lack domain-specific knowledge embedded in non-textual sources like images and scanned documents. The authors propose an incremental pre-training approach that injects this domain knowledge into the model, along with a knowledge graph integration system to reduce hallucination. This technical report presents the methodology and architecture, with experimental results to be reported in future versions.

## Method Summary
The authors developed FoodGPT by starting with a Chinese-LLaMA2-13B base model and applying incremental pre-training using domain-specific data including OCR-processed scanned documents, structured data serialized through ChatGPT, and various food testing corpora. They used the LoRA method for efficient fine-tuning and constructed an external knowledge graph to support retrieval during inference. The approach addresses the limitation of previous domain-specific LLMs that rely solely on fine-tuning without domain knowledge injection.

## Key Results
- FoodGPT introduces incremental pre-training to inject domain knowledge from non-textual sources
- The model uses ChatGPT-based serialization for structured data to avoid template limitations
- External knowledge graph integration aims to reduce hallucination during inference
- Technical report format with experimental results to be reported in future versions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incremental pre-training injects domain-specific knowledge from non-textual images and scanned documents into the base model.
- Mechanism: The model applies OCR to images and scanned documents, splits them into chapters, adds document prefixes, and filters high-perplexity sentences before pre-training.
- Core assumption: OCR outputs are sufficiently accurate to represent the original document content for model training.
- Evidence anchors:
  - [abstract] "a significant amount of data in this domain exists in Scanning format for domain standard documents"
  - [section] "We apply OCR to over ten thousand of them" and "split the documents into chapters based on their sections"
  - [corpus] No direct evidence; weak connection to OCR accuracy in food testing context.
- Break condition: OCR fails to extract accurate text, leading to corrupted training data that degrades model performance.

### Mechanism 2
- Claim: Structured knowledge is serialized into natural language using ChatGPT to avoid template limitations.
- Mechanism: ChatGPT generates multiple natural language versions of structured data by randomly selecting fields and varying temperature, ensuring coverage without excessive repetition.
- Core assumption: ChatGPT-generated text adequately captures the semantic meaning of structured data fields.
- Evidence anchors:
  - [section] "we input each data point into ChatGPT to generate text randomly according to specific rules"
  - [corpus] No direct evidence; weak connection to ChatGPT's effectiveness in domain-specific structured data serialization.
- Break condition: ChatGPT generates text that introduces factual errors or hallucinates information not present in the original structured data.

### Mechanism 3
- Claim: External knowledge graph retrieval reduces hallucination by providing grounded facts during inference.
- Mechanism: When a query is input, a retrieval model finds relevant knowledge from the graph, concatenates it with the query, and passes both to the model for response generation.
- Core assumption: The knowledge graph contains comprehensive and accurate domain knowledge that covers most user queries.
- Evidence anchors:
  - [abstract] "we construct a knowledge graph to serve as an external knowledge base for supporting retrieval in the large language model"
  - [section] "This knowledge graph serves as an external knowledge base to support the retrieval and output of FoodGPT"
  - [corpus] No direct evidence; weak connection to knowledge graph completeness in food testing domain.
- Break condition: The knowledge graph lacks coverage for certain queries, causing the model to fall back on hallucinated responses.

## Foundational Learning

- Concept: OCR (Optical Character Recognition)
  - Why needed here: To convert scanned documents and images into text that can be processed by the language model.
  - Quick check question: What happens if OCR misidentifies characters in food testing standards documents?

- Concept: Knowledge Graph Construction
  - Why needed here: To create a structured repository of food testing facts that can be retrieved during inference to prevent hallucination.
  - Quick check question: How would missing relationships in the knowledge graph affect the model's ability to answer complex queries?

- Concept: LoRA (Low-Rank Adaptation)
  - Why needed here: To efficiently fine-tune the large language model with domain-specific data without full model retraining.
  - Quick check question: What trade-offs exist between LoRA rank and fine-tuning quality in domain adaptation?

## Architecture Onboarding

- Component map: Base model (Chinese-LLaMA2-13B) → Incremental pre-training (OCR-processed docs, structured data) → Instruction fine-tuning (forum Q&A + expert seeds) → Knowledge graph retrieval (external facts)
- Critical path: OCR processing → Document preprocessing → Incremental pre-training → Knowledge graph construction → Instruction fine-tuning → Inference with retrieval
- Design tradeoffs: OCR accuracy vs. preprocessing complexity; ChatGPT serialization vs. template consistency; knowledge graph completeness vs. construction effort
- Failure signatures: Poor OCR leads to garbled training text; incomplete knowledge graph causes hallucination; LoRA rank too low causes poor fine-tuning
- First 3 experiments:
  1. Test OCR accuracy on sample scanned food testing documents and measure impact on downstream model perplexity
  2. Compare model performance using template-based vs. ChatGPT-based structured data serialization
  3. Evaluate knowledge graph retrieval effectiveness by measuring hallucination rates with and without retrieval

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of FoodGPT compare to other domain-specific LLMs like ChatLaw and DoctorGLM when evaluated on food testing tasks?
- Basis in paper: [explicit] The paper mentions that previous domain-specific LLMs like ChatLaw and DoctorGLM use fine-tuning without incremental pre-training, while FoodGPT introduces incremental pre-training to inject domain knowledge. However, no comparative experimental results are provided.
- Why unresolved: The paper is a technical report of a pre-release version and states that specific experimental data will be reported in future versions.
- What evidence would resolve it: Comparative experimental results showing FoodGPT's performance on food testing tasks against other domain-specific LLMs like ChatLaw and DoctorGLM.

### Open Question 2
- Question: What is the impact of using different data serialization methods (Datav1 vs. Datav2) on the performance of FoodGPT during incremental pre-training?
- Basis in paper: [explicit] The paper describes two methods for handling structured data during incremental pre-training - Datav1 using manual templates and Datav2 using ChatGPT for random text generation. However, no comparative analysis of their impact on model performance is provided.
- Why unresolved: The paper focuses on the methodology of data handling rather than comparing the outcomes of different approaches.
- What evidence would resolve it: Experimental results comparing FoodGPT's performance when trained with Datav1 versus Datav2, showing the effectiveness of each serialization method.

### Open Question 3
- Question: How effective is the constructed knowledge graph in reducing machine hallucination and improving the accuracy of FoodGPT's outputs?
- Basis in paper: [explicit] The paper mentions constructing a knowledge graph to serve as an external knowledge base for retrieval, aiming to reduce machine hallucination. However, no quantitative evaluation of its effectiveness is provided.
- Why unresolved: The paper is a technical report and states that specific experimental details and analysis will be reported in future versions.
- What evidence would resolve it: Experimental results showing the reduction in hallucination rates and improvement in output accuracy when using the knowledge graph for retrieval compared to not using it.

### Open Question 4
- Question: What is the optimal balance between using structured data and unstructured data (images, scanned documents, text) for incremental pre-training of FoodGPT?
- Basis in paper: [inferred] The paper describes methods for handling both structured data and unstructured data (images, scanned documents, text) during incremental pre-training, but does not discuss the optimal balance or contribution of each data type to the model's performance.
- Why unresolved: The paper focuses on the methodology of data handling rather than optimizing the data mix for incremental pre-training.
- What evidence would resolve it: Experimental results showing FoodGPT's performance with different ratios of structured to unstructured data during incremental pre-training, identifying the optimal balance for best performance.

## Limitations

- The paper is a technical report format without specific experimental results or quantitative evaluations
- OCR accuracy for food testing domain documents is assumed but not empirically validated
- Effectiveness of ChatGPT-based structured data serialization is not compared to template-based approaches
- Knowledge graph completeness and coverage for food testing queries is not assessed

## Confidence

**High confidence**: The general approach of using incremental pre-training followed by instruction fine-tuning is well-established in the literature.

**Medium confidence**: The specific methods for handling structured data and scanned documents are reasonable but lack empirical validation.

**Low confidence**: The effectiveness of the knowledge graph integration in reducing hallucination cannot be assessed without experimental results.

## Next Checks

1. **OCR quality validation**: Test OCR accuracy on a representative sample of scanned food testing documents and measure the impact of OCR errors on model perplexity during incremental pre-training. Compare perplexity scores using clean vs. OCR-processed text.

2. **Structured data serialization comparison**: Implement both template-based and ChatGPT-based approaches for converting structured data to natural language. Train two separate models and evaluate their performance on structured data query tasks to determine which approach better preserves semantic meaning.

3. **Knowledge graph coverage assessment**: Create a test suite of food testing queries that span different complexity levels and knowledge domains. Measure the percentage of queries successfully answered using knowledge graph retrieval versus model generation, and calculate hallucination rates in each scenario.