---
ver: rpa2
title: Polynomial-Model-Based Optimization for Blackbox Objectives
arxiv_id: '2309.00663'
source_url: https://arxiv.org/abs/2309.00663
tags:
- optimization
- function
- pmbo
- polynomial
- objective
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Polynomial-Model-Based Optimization (PMBO),
  a novel blackbox optimization method that approximates the objective function using
  polynomial surrogates and iteratively updates the model using the Expected Improvement
  acquisition function. PMBO is designed to find optimal hyperparameters for complex
  systems where the objective function structure is unknown and expensive to sample.
---

# Polynomial-Model-Based Optimization for Blackbox Objectives

## Quick Facts
- arXiv ID: 2309.00663
- Source URL: https://arxiv.org/abs/2309.00663
- Reference count: 0
- Primary result: PMBO with Chebyshev initialization outperforms all other methods on Hartmann 3D, second-best on Rosenbrock 6D after CMA-ES

## Executive Summary
This paper introduces Polynomial-Model-Based Optimization (PMBO), a novel blackbox optimization method that approximates the objective function using polynomial surrogates and iteratively updates the model using the Expected Improvement acquisition function. PMBO is designed to find optimal hyperparameters for complex systems where the objective function structure is unknown and expensive to sample. The method is evaluated on Hartmann (3D) and Rosenbrock (6D) benchmark functions, comparing against Random Search, Quasi-Random Search, Bayesian Optimization, Particle Swarm Optimization, and CMA-ES.

## Method Summary
PMBO fits a polynomial surrogate to the objective function using multivariate polynomial interpolation via the minterpy library. At each iteration, it computes an Expected Improvement (EI) acquisition function that balances exploitation and exploration based on the surrogate's mean prediction and bootstrapped uncertainty estimate. The method iteratively adds new sample points at locations that maximize EI, updating the polynomial surrogate with each new observation. Initial sampling can use random, Chebyshev, Sobol, or CMA-ES strategies.

## Key Results
- PMBO with Chebyshev initialization outperforms all other methods on the Hartmann 3D function
- PMBO with random and Sobol sampling performs second-best on Rosenbrock 6D after CMA-ES
- The method shows promise for blackbox optimization across various disciplines

## Why This Works (Mechanism)

### Mechanism 1
PMBO iteratively improves a polynomial surrogate by sampling new points in regions where model uncertainty is high, balancing exploitation and exploration. At each iteration, PMBO fits a polynomial to the current sample set, computes an EI acquisition function that weights the surrogate prediction by its estimated uncertainty, and adds the point with maximum EI to the sample set.

### Mechanism 2
PMBO uses bootstrapping to estimate variance on the polynomial surrogate, providing a cheap, analytic uncertainty measure for guiding exploration. Instead of fitting a stochastic process like in classic Bayesian optimization, PMBO models uncertainty via bootstrapping resampling of polynomial coefficients.

### Mechanism 3
The choice of initial sampling seed strongly influences PMBO's final performance, with Chebyshev nodes yielding best results on low-dimensional smooth benchmarks. PMBO starts with a 50-point seed to initialize the polynomial surrogate; better initial coverage leads to faster convergence to the global optimum.

## Foundational Learning

- **Concept**: Multivariate polynomial interpolation and regression (minterpy library)
  - Why needed: PMBO relies on efficiently constructing and updating high-dimensional polynomial surrogates from sample points
  - Quick check: How does minterpy's Lagrange form differ from Newton interpolation for multivariate polynomials?

- **Concept**: Expected Improvement acquisition function and its role in balancing exploration vs. exploitation
  - Why needed: PMBO's sampling strategy is driven by EI on the polynomial surrogate; understanding its formulation is key to tuning γ
  - Quick check: What effect does increasing γ have on the EI weighting of variance vs. mean?

- **Concept**: Curse of dimensionality and its mitigation in polynomial approximation (sparse grids, anisotropic bases)
  - Why needed: PMBO must avoid exponential growth in polynomial terms with dimension; minterpy's sparse multi-index sets are critical
  - Quick check: How do anisotropic multi-index sets reduce the effective polynomial degree in less important dimensions?

## Architecture Onboarding

- **Component map**: Polynomial fitting -> EI computation -> Sample selection -> Objective evaluation
- **Critical path**: Polynomial fitting → EI computation → Sample selection → Objective evaluation
- **Design tradeoffs**: Polynomial degree vs. sample efficiency; bootstrapping vs. GP uncertainty; structured vs. adaptive initial sampling
- **Failure signatures**: Slow convergence on high-dimensional or highly non-smooth functions; EI sampling concentrated in low-variance regions; initial seed missing the global optimum basin
- **First 3 experiments**:
  1. Reproduce PMBO on Hartmann 3D with Chebyshev seed and compare EI sampling pattern to random seed
  2. Sweep γ ∈ {0.1, 0.5, 0.9} on Rosenbrock 6D and measure convergence speed and final objective value
  3. Test PMBO on a simple 2D test function (e.g., Himmelblau) with different initial seeds and visualize surrogate evolution over iterations

## Open Questions the Paper Calls Out

### Open Question 1
What specific theoretical constraints on objective functions enable optimal PMBO initialization?
Basis: Authors mention ongoing research to "theoretically identify mild constraints on the objective function that enable optimal PMBO initialization"
Why unresolved: Presented as ongoing work rather than a solved problem
Evidence needed: Mathematical proof characterizing the class of objective functions for which PMBO initialization is optimal

### Open Question 2
What are the convergence criteria for PMBO and how can they be theoretically justified?
Basis: PMBO updates are "repeated until a convergence criterion is met" but criteria are not specified
Why unresolved: Paper describes algorithm but lacks convergence analysis or formal stopping criteria
Evidence needed: Mathematical proofs of convergence conditions and practical implementations of convergence criteria

### Open Question 3
How does PMBO perform on high-dimensional problems beyond m=6?
Basis: Evaluation limited to 3D and 6D problems with authors acknowledging "non-exhaustive evaluation"
Why unresolved: Empirical evaluation is limited to low-dimensional problems
Evidence needed: Extensive benchmarking on problems with dimensions significantly higher than 6

## Limitations
- Claims based on only two low-dimensional benchmark functions (3D and 6D)
- Performance comparison relies on only 5 repetitions, limiting statistical robustness
- Bootstrapping uncertainty estimation lacks rigorous validation against alternatives
- Computational complexity in higher dimensions remains unclear

## Confidence

**High confidence**: PMBO's basic framework of polynomial surrogate modeling with Expected Improvement acquisition is well-established and clearly described.

**Medium confidence**: Claims about PMBO-Chebyshev outperforming all other methods on Hartmann 3D are supported by presented results but require broader validation due to limited repetitions.

**Low confidence**: The paper does not provide theoretical guarantees for PMBO's convergence or global optimality properties.

## Next Checks

1. **Statistical robustness**: Repeat all benchmark experiments with 30+ independent runs and perform statistical significance testing to validate performance differences between PMBO and competing methods.

2. **Dimensionality scaling**: Evaluate PMBO on synthetic benchmark functions ranging from 5D to 20D (e.g., Griewank, Rastrigin, Ackley) to assess how performance scales with dimensionality.

3. **Uncertainty quantification validation**: Compare PMBO's bootstrapping-based uncertainty estimates against Gaussian process-based uncertainty on the same benchmark problems to verify whether bootstrapping variance meaningfully captures model uncertainty.