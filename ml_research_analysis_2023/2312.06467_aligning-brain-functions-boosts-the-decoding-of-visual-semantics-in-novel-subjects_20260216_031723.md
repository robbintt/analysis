---
ver: rpa2
title: Aligning brain functions boosts the decoding of visual semantics in novel subjects
arxiv_id: '2312.06467'
source_url: https://arxiv.org/abs/2312.06467
tags:
- data
- subject
- subjects
- brain
- decoding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of brain decoding from fMRI
  by proposing a method to align brain responses across subjects, improving out-of-subject
  decoding performance. The core method uses optimal transport to functionally align
  brain responses of a left-out subject to a reference subject, combined with linear
  regression models for decoding.
---

# Aligning brain functions boosts the decoding of visual semantics in novel subjects

## Quick Facts
- **arXiv ID**: 2312.06467
- **Source URL**: https://arxiv.org/abs/2312.06467
- **Reference count**: 40
- **Primary result**: Functional alignment via optimal transport improves out-of-subject fMRI decoding by up to 75% relative to anatomical baselines

## Executive Summary
This paper addresses the challenge of brain decoding from fMRI by proposing a method to align brain responses across subjects, improving out-of-subject decoding performance. The core method uses optimal transport to functionally align brain responses of a left-out subject to a reference subject, combined with linear regression models for decoding. The approach significantly enhances decoding performance, achieving up to 75% improvement in out-of-subject decoding compared to anatomically-aligned baselines. It also outperforms single-subject approaches when limited data is available for the left-out subject, demonstrating the effectiveness of leveraging multi-subject data for individual brain decoding.

## Method Summary
The method consists of two main components: functional alignment and decoding. Functional alignment uses optimal transport (specifically Fused Unbalanced Gromov-Wasserstein) to compute a soft permutation of voxels in a left-out subject to maximize functional similarity with voxels of a reference subject while preserving anatomical organization. This alignment is computed using BOLD signals from both subjects watching the same videos. For decoding, a linear regression model (Ridge) is trained to predict latent representations of visual stimuli from the aligned brain signals. The latent representations are extracted from pre-trained image encoders (CLIP, VDVAE, etc.) applied to the video frames or images shown to subjects.

## Key Results
- Functional alignment improves out-of-subject decoding performance by up to 75% relative to anatomical baselines
- Multi-subject training with functional alignment reaches performance comparable to single-subject models
- Functional alignment is particularly beneficial when limited data (<100 minutes) is available for the left-out subject

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Functional alignment via optimal transport improves out-of-subject decoding by making brain responses of a left-out subject similar to those of a reference subject.
- Mechanism: Optimal transport computes a soft permutation of voxels in the left-out subject to maximize functional similarity with voxels of the reference subject while preserving anatomical organization. This alignment allows decoders trained on the reference subject to generalize to the left-out subject.
- Core assumption: Functional similarity across subjects reflects shared underlying neural representations of visual stimuli.
- Evidence anchors:
  - [abstract]: "This paper addresses the challenge of brain decoding from fMRI by proposing a method to align brain responses across subjects, improving out-of-subject decoding performance."
  - [section]: "This method consists in using functional data to train an alignment that transforms brain responses of a given left-out subject into the brain responses of a reference subject."
  - [corpus]: Weak evidence; no direct citation of optimal transport or alignment methods in related papers.
- Break Condition: If functional similarity does not reflect shared neural representations, alignment will not improve decoding performance.

### Mechanism 2
- Claim: Multi-subject training with functional alignment reaches performance comparable to single-subject models while improving out-of-subject generalization.
- Mechanism: By aligning multiple subjects' brain responses to a reference subject and training a single decoder on the aligned data, the model benefits from more diverse training data while maintaining subject-specific alignment.
- Core assumption: Aligned multi-subject data captures common features across subjects without losing individual variability.
- Evidence anchors:
  - [abstract]: "training a decoder on multiple aligned subjects reaches the same performance as training a single model per subject."
  - [section]: "we show that a single model trained on all functionally aligned subjects can reach slightly better results than models trained on all un-aligned subjects."
  - [corpus]: Weak evidence; no direct citation of multi-subject training with functional alignment in related papers.
- Break Condition: If multi-subject alignment introduces noise or loses critical individual differences, performance may degrade.

### Mechanism 3
- Claim: Functional alignment improves decoding when limited data is available for the left-out subject.
- Mechanism: With only 30 minutes of data, the left-out subject can be aligned to the reference subject, allowing the use of a decoder trained on much larger datasets from the reference subject.
- Core assumption: Limited data from the left-out subject is sufficient to compute a meaningful alignment to the reference subject.
- Evidence anchors:
  - [abstract]: "Moreover, it also outperforms classical single-subject approaches when fewer than 100 minutes of data is available for the tested subject."
  - [section]: "we demonstrate that left-out subjects need not have the same amount of available data than training subjects to benefit from their model: with just 30 minutes of data, left-out subjects can reach performance which would have needed roughly 100 minutes of data in a within-subject setting."
  - [corpus]: Weak evidence; no direct citation of data-limited alignment in related papers.
- Break Condition: If the limited data from the left-out subject is insufficient to capture individual variability, alignment will be poor and decoding performance will not improve.

## Foundational Learning

- Concept: Functional alignment and its role in inter-subject variability
  - Why needed here: Understanding how functional alignment addresses the challenge of inter-subject variability is crucial for implementing and evaluating the proposed method.
  - Quick check question: How does functional alignment differ from anatomical alignment, and why is it more effective for decoding visual semantics?

- Concept: Optimal transport and its application in brain alignment
  - Why needed here: The core alignment method relies on optimal transport to compute voxel correspondences between subjects, so understanding this technique is essential.
  - Quick check question: What are the key components of the optimal transport loss function used in this method, and how do they contribute to the alignment process?

- Concept: Decoding visual semantics from fMRI signals
  - Why needed here: The ultimate goal is to decode visual stimuli from brain activity, so understanding the relationship between fMRI signals and visual representations is crucial.
  - Quick check question: How do pre-trained image encoders like CLIP and VDVAE contribute to the decoding of visual semantics from fMRI signals?

## Architecture Onboarding

- Component map:
  - BOLD signal preprocessing -> Functional alignment (FUGW) -> Linear decoder training (Ridge) -> Evaluation (relative median rank, top-5 accuracy)

- Critical path:
  1. Preprocess BOLD signals from training and test subjects
  2. Compute functional alignment between reference and left-out subjects
  3. Train decoder on aligned brain signals and latent representations
  4. Evaluate decoder performance on left-out subject's test data

- Design tradeoffs:
  - Alignment vs. decoder training data: More alignment data improves alignment quality but reduces data available for decoder training
  - Alignment strength: Stronger alignment may lose individual variability, while weaker alignment may not sufficiently reduce inter-subject variability
  - Latent representation choice: Different pre-trained encoders (CLIP, VDVAE, etc.) may capture different aspects of visual semantics, affecting decoding performance

- Failure signatures:
  - Poor alignment: Left-out subject's brain signals remain dissimilar to reference subject's, resulting in poor decoding performance
  - Overfitting: Decoder performs well on training data but poorly on test data, indicating insufficient regularization or alignment quality
  - Baseline performance: Anatomical alignment baseline performs as well as or better than functional alignment, suggesting alignment method is not effective

- First 3 experiments:
  1. Implement functional alignment between two subjects using optimal transport and evaluate alignment quality using anatomical coherence metrics
  2. Train decoder on aligned brain signals and evaluate performance on left-out subject's test data
  3. Compare performance of functional alignment with anatomical alignment baseline and single-subject decoder

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of functional alignment scale with larger cohorts and more diverse video stimuli beyond the 18 training segments used in this study?
- Basis in paper: [inferred] The paper notes that the small number of participants and limited video diversity in the Wen et al. (2017) dataset calls for replications on larger cohorts and more diverse stimuli to ensure generality of findings.
- Why unresolved: The current study is constrained by the available dataset, which only includes 3 subjects and 18 video segments for training. Scaling up to larger cohorts with more diverse stimuli would require new datasets.
- What evidence would resolve it: Conducting the same experiments on larger datasets like the Natural Scenes Dataset (Allen et al., 2022) or collecting new fMRI datasets with more subjects and diverse video content would provide evidence on scalability.

### Open Question 2
- Question: Can functional alignment improve out-of-subject decoding performance when left-out subjects watch completely different videos than the reference subjects?
- Basis in paper: [inferred] The paper mentions that current functional alignment requires left-out subjects to watch the same videos as reference subjects, and it is unclear whether alignment would still improve performance without this constraint.
- Why unresolved: The current experimental setup does not test alignment on different video content, as all subjects watched the same videos. Testing with different stimuli would require new experimental designs.
- What evidence would resolve it: Conducting experiments where left-out subjects watch different videos than the reference subjects, while still using the same alignment model, would test the robustness of functional alignment to stimulus differences.

### Open Question 3
- Question: How do non-linear decoding models compare to the linear Ridge regression models used in this study for out-of-subject and multi-subject decoding?
- Basis in paper: [explicit] The paper explicitly states that while restricting to linear models makes sense for establishing baselines and ensuring replicability, non-linear models have been shown to be at least comparably efficient in similar tasks.
- Why unresolved: The study only uses linear Ridge regression models for decoding, leaving the potential of non-linear models unexplored in the context of out-of-subject and multi-subject decoding.
- What evidence would resolve it: Replicating the decoding experiments using non-linear models like deep neural networks and comparing their performance to the linear models would provide evidence on the benefits of non-linear approaches.

## Limitations
- Limited dataset size (3 subjects, 18 training segments) may not generalize to larger, more diverse cohorts
- Reliance on pre-trained encoders (CLIP, VDVAE) means decoding performance is bounded by these models' capabilities
- FUGW algorithm's sensitivity to hyper-parameters (λ, γ, α, α_GW, ε, threshold) is acknowledged but not thoroughly explored

## Confidence
- **High Confidence**: The claim that functional alignment improves out-of-subject decoding performance compared to anatomical baselines is supported by quantitative results showing up to 75% improvement in relative median rank and 10% improvement in top-5 accuracy.
- **Medium Confidence**: The claim that multi-subject training with functional alignment reaches performance comparable to single-subject models is supported by the paper's results, but the practical significance of the slight improvements needs further validation.
- **Low Confidence**: The claim that functional alignment is particularly beneficial when limited data is available for the left-out subject relies on results from a specific dataset (Allen et al., 2021) and may not generalize to all fMRI datasets or experimental paradigms.

## Next Checks
1. **Alignment Quality Assessment**: Implement visual and quantitative metrics to directly evaluate the quality of functional alignment (e.g., anatomical coherence scores, voxel-wise similarity measures) beyond decoding performance.
2. **Hyper-parameter Sensitivity Analysis**: Systematically vary FUGW hyper-parameters (λ, γ, α, α_GW, ε, threshold) to determine their impact on alignment quality and decoding performance, identifying robust settings.
3. **Generalization Across Datasets**: Test the proposed method on additional fMRI datasets with different experimental paradigms (e.g., naturalistic movie watching, task-based paradigms) to assess generalizability beyond the Wen et al. (2017) and Allen et al. (2021) datasets.