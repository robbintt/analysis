---
ver: rpa2
title: Using Logic Programming and Kernel-Grouping for Improving Interpretability
  of Convolutional Neural Networks
arxiv_id: '2310.13073'
source_url: https://arxiv.org/abs/2310.13073
tags:
- kernel
- rule-set
- group
- each
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a neurosymbolic framework for interpretable
  image classification. The authors propose a kernel grouping algorithm that groups
  similar kernels in the last convolutional layer of a CNN based on their feature
  maps' cosine similarity.
---

# Using Logic Programming and Kernel-Grouping for Improving Interpretability of Convolutional Neural Networks

## Quick Facts
- arXiv ID: 2310.13073
- Source URL: https://arxiv.org/abs/2310.13073
- Authors: 
- Reference count: 38
- Key outcome: This paper introduces a neurosymbolic framework for interpretable image classification. The authors propose a kernel grouping algorithm that groups similar kernels in the last convolutional layer of a CNN based on their feature maps' cosine similarity. The binarized output of these kernel groups is then used to generate a rule-set via the FOLD-SE-M algorithm, which is a default theory represented as a normal logic program. The authors also introduce a semantic labeling algorithm to map the predicates in the rule-set to human-understandable concepts using semantic segmentation masks. The resulting model, NeSy-G, combines the CNN with the rule-set and allows for goal-directed inference using the s(CASP) system to obtain justifications for predictions. Experiments on various datasets show that the proposed NeSyFOLD-G framework outperforms the previous NeSyFOLD framework in terms of accuracy, fidelity, and interpretability, as measured by the size of the generated rule-set. The rule-set generated by NeSyFOLD-G is significantly smaller than that of NeSyFOLD while maintaining or improving accuracy and fidelity.

## Executive Summary
This paper presents NeSyFOLD-G, a neurosymbolic framework that improves the interpretability of convolutional neural networks for image classification. The key innovation is a kernel grouping algorithm that clusters similar kernels in the last convolutional layer based on feature map cosine similarity, replacing individual kernel predicates with group-based predicates in the generated rule-set. This approach, combined with semantic labeling using segmentation masks, produces significantly smaller and more interpretable rule-sets while maintaining or improving accuracy and fidelity compared to the previous NeSyFOLD framework.

## Method Summary
The NeSyFOLD-G framework trains a CNN (VGG16 with ImageNet pre-training), then extracts feature maps from the last convolutional layer. Kernels are grouped based on cosine similarity of their feature maps, and the output of each group is binarized using a threshold based on mean and standard deviation. FOLD-SE-M generates a rule-set from these binarized values, and semantic labeling maps predicates to human-understandable concepts using segmentation masks. The final NeSy-G model combines the CNN with the rule-set for inference using the s(CASP) system, providing justifications for predictions.

## Key Results
- NeSyFOLD-G generates rule-sets with significantly fewer predicates and rules compared to NeSyFOLD
- Maintains or improves accuracy and fidelity on GTSRB, MNIST, and Places datasets
- Semantic labeling successfully maps kernel group predicates to human-understandable concepts using segmentation masks
- s(CASP) inference provides goal-directed justifications for predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Kernel grouping reduces the number of predicates in the rule-set by replacing multiple similar kernels with a single group-based predicate.
- Mechanism: The kernel grouping algorithm finds groups of similar kernels based on cosine similarity of their feature maps. Each group's collective output is binarized and represented as a single predicate in the rule-set, replacing multiple individual kernel predicates.
- Core assumption: Groups of similar kernels in the last convolutional layer collectively represent a single human-understandable concept.
- Evidence anchors:
  - [abstract] "We present a novel kernel grouping algorithm that finds groups of similar kernels in the CNN based on the cosine similarity score of their corresponding generated feature maps."
  - [section] "Padalkar et al. proposed the NeSyFOLD framework [17] which shares similarities with the NeSyFOLD-G framework. The major difference that separates NeSyFOLD-G from NeSyFOLD is that the truth values of predicates in the generated rule-set is influenced by the binarized output of groups of similar kernels."
- Break condition: If kernel groups do not consistently represent coherent concepts, or if the similarity threshold creates too few or too many groups, the rule-set size reduction and interpretability gains may not materialize.

### Mechanism 2
- Claim: Semantic labeling connects kernel group predicates to human-understandable concepts using semantic segmentation masks.
- Mechanism: For each kernel group, the algorithm identifies top-m images that activate the group most strongly, then calculates IoU scores between the group's feature maps and semantic segmentation masks for each concept. The predicate label is assigned based on concepts with high IoU scores within a specified margin.
- Core assumption: Semantic segmentation masks accurately label the concepts that kernel groups learn to detect.
- Evidence anchors:
  - [abstract] "Each predicate in the rule-set is mapped to a concept using a few semantic segmentation masks of the images used for training, to make it human-understandable."
  - [section] "We introduce a novel semantic labelling algorithm to automate the semantic labelling of the predicates in the rule-set generated."
- Break condition: If semantic segmentation masks are unavailable or inaccurate for the dataset, manual labeling would be required, reducing automation benefits.

### Mechanism 3
- Claim: FOLD-SE-M generates a smaller rule-set from binarized kernel group outputs than from individual kernel outputs.
- Mechanism: The binarization table created from kernel group outputs contains fewer columns (one per group instead of one per kernel) with more informative features. FOLD-SE-M finds the most influential features and generates rules accordingly, resulting in fewer predicates and rules.
- Core assumption: Kernel group outputs provide more informative and discriminative features than individual kernel outputs for rule generation.
- Evidence anchors:
  - [abstract] "FOLD-SE-M then generates a rule-set that can be used to make predictions. We present a novel kernel grouping algorithm and show that grouping similar kernels leads to a significant reduction in the size of the rule-set generated by FOLD-SE-M, consequently, improving the interpretability."
  - [section] "The NeSyFOLD-G framework can be used to create a NeSy-G model which is a composition of the CNN and a rule-set generated from kernels in its last convolution layer."
- Break condition: If kernel grouping does not create sufficiently distinct or informative features, FOLD-SE-M may not generate smaller rule-sets than it would from individual kernels.

## Foundational Learning

- Concept: Cosine similarity for measuring kernel similarity
  - Why needed here: The kernel grouping algorithm relies on cosine similarity between feature maps to identify groups of similar kernels.
  - Quick check question: How would you compute the cosine similarity between two feature maps A and B of dimensions m×n?

- Concept: Binarization of continuous values for rule generation
  - Why needed here: Kernel group outputs (feature map norms) are continuous values that must be converted to binary (0/1) to serve as inputs for FOLD-SE-M rule generation.
  - Quick check question: Given a kernel group with norms [0.2, 0.5, 0.8, 1.0] and mean=0.625, std=0.32, what threshold would be used for binarization using α=0.6 and γ=0.7?

- Concept: Intersection over Union (IoU) for semantic labeling
  - Why needed here: IoU scores measure the overlap between kernel group feature maps and semantic segmentation masks to determine which concepts the kernel groups represent.
  - Quick check question: If a kernel group's masked feature map has 50 non-zero pixels overlapping with a "car" concept mask that has 100 non-zero pixels, what is the IoU score for the "car" concept?

## Architecture Onboarding

- Component map: CNN -> Kernel grouping algorithm -> Binarization module -> FOLD-SE-M rule generator -> Semantic labeling algorithm -> s(CASP) inference engine

- Critical path:
  1. Train CNN on dataset
  2. Extract feature maps from last convolutional layer
  3. Apply kernel grouping algorithm
  4. Binarize kernel group outputs
  5. Generate rule-set using FOLD-SE-M
  6. Apply semantic labeling to predicates
  7. Use s(CASP) for inference and justification

- Design tradeoffs:
  - Kernel grouping threshold (θs): Higher values create fewer, more distinct groups but may miss subtle variations; lower values create more groups but may include dissimilar kernels.
  - Binarization parameters (α, γ): Affect how aggressively kernel group outputs are thresholded; higher values make activation more stringent.
  - Semantic labeling margin: Controls how many concepts are included in predicate labels; smaller margins create more specific labels but may miss relevant concepts.

- Failure signatures:
  - Rule-set size doesn't decrease compared to NeSyFOLD: Kernel grouping threshold may be too low or too high, creating ineffective groups.
  - Low accuracy/fidelity: Binarization parameters may be too aggressive, losing important information.
  - Semantic labels don't match expected concepts: IoU calculation or margin parameter may need adjustment, or segmentation masks may be inadequate.

- First 3 experiments:
  1. Test kernel grouping with varying similarity thresholds (0.7, 0.8, 0.9) on a small dataset and measure resulting rule-set sizes.
  2. Compare binarization performance using different (α, γ) parameter combinations on a validation set.
  3. Evaluate semantic labeling accuracy by manually verifying labels on a subset of kernel groups against their known concepts.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the loss in accuracy due to binarization of kernels be reduced, especially as the number of classes increases?
- Basis in paper: [explicit] The paper mentions that as the number of classes increases, more kernels are needed to represent the knowledge, and consequently, more kernels have to be binarized. This leads to an increase in the loss incurred due to binarization.
- Why unresolved: The paper does not provide a solution to this problem, only acknowledging its existence and suggesting future work to explore end-to-end training of the CNN with the rules generated to reduce this loss during training.
- What evidence would resolve it: Evidence would include experimental results showing a reduction in accuracy loss when using end-to-end training with the rules generated by the NeSyFOLD-G framework, compared to the current approach.

### Open Question 2
- Question: How can the semantic segmentation masks required for the semantic labeling algorithm be obtained for domains where they are not readily available?
- Basis in paper: [explicit] The paper acknowledges that semantic segmentation masks may not be readily available for all domains, and in such cases, manual labeling of predicates is required.
- Why unresolved: The paper does not provide a solution for obtaining semantic segmentation masks for domains where they are not available, only suggesting manual labeling as an alternative.
- What evidence would resolve it: Evidence would include the development of a method to automatically generate semantic segmentation masks for images in domains where they are not readily available, or the successful manual labeling of predicates for a specific domain.

### Open Question 3
- Question: How can the knowledge from multiple CNNs be combined into a single rule-set using the NeSyFOLD-G framework?
- Basis in paper: [explicit] The paper mentions future work to explore combining the knowledge of two or more CNNs by producing a single rule-set that contains the kernels of the corresponding CNNs as predicates.
- Why unresolved: The paper does not provide a solution for combining the knowledge from multiple CNNs, only mentioning it as a future direction.
- What evidence would resolve it: Evidence would include experimental results showing the successful combination of knowledge from multiple CNNs into a single rule-set using the NeSyFOLD-G framework, and demonstrating the interpretability and accuracy of the combined rule-set.

## Limitations
- The kernel grouping algorithm's effectiveness is uncertain without extensive ablation studies on similarity thresholds and validation that groups consistently represent coherent concepts.
- Semantic labeling relies heavily on the availability and accuracy of semantic segmentation masks, which may not be available for all datasets.
- The paper claims improved interpretability through smaller rule-sets, but this relationship is not empirically validated beyond counting predicates and rules.

## Confidence
**Medium**
- The core mechanism of kernel grouping appears sound based on the cosine similarity approach, and the reported improvements in rule-set size and maintained accuracy are promising. However, without detailed ablation studies on the kernel grouping parameters and more extensive human studies on interpretability, there's uncertainty about the robustness of these improvements across different datasets and CNN architectures.

## Next Checks
1. Perform ablation studies on kernel grouping threshold (θs) across multiple values (0.7, 0.8, 0.9) to determine optimal settings and validate that groups consistently represent coherent concepts.

2. Conduct human evaluation studies comparing interpretability of rule-sets generated by NeSyFOLD-G versus NeSyFOLD, measuring comprehension time and accuracy in understanding predictions.

3. Test the framework on additional CNN architectures (e.g., ResNet, EfficientNet) to validate generalizability beyond VGG16 and assess whether kernel grouping effectiveness varies by architecture depth or type.