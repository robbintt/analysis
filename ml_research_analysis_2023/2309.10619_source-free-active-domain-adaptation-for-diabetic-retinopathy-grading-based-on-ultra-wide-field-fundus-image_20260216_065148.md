---
ver: rpa2
title: Source-free Active Domain Adaptation for Diabetic Retinopathy Grading Based
  on Ultra-wide-field Fundus Image
arxiv_id: '2309.10619'
source_url: https://arxiv.org/abs/2309.10619
tags:
- fundus
- images
- domain
- grading
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses diabetic retinopathy grading using ultra-wide-field
  fundus images, which present challenges due to domain gaps and the difficulty of
  obtaining labeled data. The authors propose a source-free active domain adaptation
  (SFADA) framework that leverages annotated traditional fundus images and actively
  selects valuable ultra-wide-field images for labeling.
---

# Source-free Active Domain Adaptation for Diabetic Retinopathy Grading Based on Ultra-wide-field Fundus Image

## Quick Facts
- arXiv ID: 2309.10619
- Source URL: https://arxiv.org/abs/2309.10619
- Reference count: 40
- Key outcome: Achieves 85.36% accuracy and 92.38% quadratic weighted kappa, improving over baseline by 20.9% and 18.63% respectively

## Executive Summary
This paper addresses diabetic retinopathy (DR) grading using ultra-wide-field (UWF) fundus images, which present challenges due to domain gaps with traditional fundus images and the difficulty of obtaining labeled data. The authors propose a source-free active domain adaptation (SFADA) framework that leverages annotated traditional fundus images and actively selects valuable UWF images for labeling. The method introduces three key innovations: modeling evolving DR grade relationships through contrastive loss, local representation matching for active selection, and lesion-based prototype domain adaptation with consistency regularization.

## Method Summary
The proposed framework operates in three stages: (1) A source feature generator is trained on labeled color fundus images using cross-entropy and contrastive loss to model evolving DR relationships; (2) Active local representation matching (ALRM) selects the most valuable UWF samples by computing local representations through nearest neighbor averaging and applying MMD-based greedy selection; (3) Lesion-based prototype domain adaptation (LPDA) adapts the model to UWF images using prototype contrastive alignment, inter/intra-domain consistency regularization, and selective pseudo-labeling with mixup samples. The approach is source-free, requiring only the pre-trained source model without access to source data.

## Key Results
- Achieves 85.36% accuracy and 92.38% quadratic weighted kappa on UWF fundus images
- Outperforms baseline methods by 20.9% in accuracy and 18.63% in quadratic weighted kappa
- Demonstrates superior performance in fine-grained DR grading through modeling evolving grade relationships

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modeling the continuously evolving relationships between DR grades improves fine-grained grading performance.
- Mechanism: The contrastive loss Lchn implicitly optimizes mutual information between neighboring DR grades by increasing angular separation between classes on a hypersphere while maintaining distance relationships.
- Core assumption: High mutual information exists between neighboring DR grades and can be exploited for better classification boundaries.
- Evidence anchors:
  - [abstract] "model the continuously evolving relationship from normal to proliferative DR"
  - [section] "the proposed Lchn successfully models the continuously evolving relationships of DRs"
  - [corpus] Weak evidence - no direct corpus support for this specific contrastive approach in DR grading
- Break condition: If the assumption about mutual information between neighboring grades is incorrect, or if the hypersphere representation fails to capture the true relationships.

### Mechanism 2
- Claim: Local representation matching reduces the impact of outliers during active sample selection.
- Mechanism: By averaging features of nearest neighbors weighted by class probabilities, local representation reduces the influence of outlier samples during MMD-based active selection.
- Core assumption: Local neighborhoods contain more reliable information than individual samples in the presence of outliers and domain gaps.
- Evidence anchors:
  - [section] "local representation is essentially an averaging of the most similar sample features, reducing the influence of outliers on data-sensitive active sample selection"
  - [section] "The proposed ALRM achieves state-of-the-art DR grading performance"
  - [corpus] No direct corpus evidence for this specific local representation matching approach in active DA
- Break condition: If the local neighborhood assumption fails (e.g., in highly heterogeneous datasets where neighbors are not reliable representatives).

### Mechanism 3
- Claim: Lesion-based prototype domain adaptation better utilizes both annotated and pseudo-labeled data through consistency regularization.
- Mechanism: Combines prototype-based contrastive alignment with inter/intra-domain consistency regularization and selective pseudo-labeling with mixup to improve adaptation performance.
- Core assumption: Consistency regularization and prototype alignment can effectively transfer knowledge from source to target domain when combined with selective pseudo-labeling.
- Evidence anchors:
  - [abstract] "adapt model on UWF fundus images with DR lesion prototypes"
  - [section] "The proposed LPDA includes three parts: prototype-based domain contrastive alignment, inter and intra domain consistency regularity, and selecting pseudo label with mixup samples"
  - [corpus] No direct corpus evidence for this specific combination of techniques in source-free DA
- Break condition: If the pseudo-label selection mechanism fails to maintain high accuracy, or if consistency regularization conflicts with the true data distribution.

## Foundational Learning

- Concept: Domain adaptation fundamentals (domain shift, covariate shift, concept drift)
  - Why needed here: Understanding why source and target domains differ and how adaptation techniques bridge this gap
  - Quick check question: What are the main sources of domain gap between traditional fundus images and UWF fundus images?

- Concept: Active learning selection criteria (uncertainty, representativeness, diversity)
  - Why needed here: Understanding how ALRM balances these criteria through local representation matching
  - Quick check question: How does local representation matching differ from traditional uncertainty-based active learning?

- Concept: Semi-supervised learning consistency regularization
  - Why needed here: Understanding how inter/intra-domain consistency regularization improves model robustness
  - Quick check question: What is the difference between inter-domain and intra-domain consistency regularization in this context?

## Architecture Onboarding

- Component map: Source model training → Source feature generator → Active selection (ALRM) → Domain adaptation (LPDA) with mixup-based pseudo-labeling
- Critical path: Generator training → Local representation computation → MMD-based selection → Prototype alignment + consistency regularization → Mixup-based pseudo-labeling
- Design tradeoffs: Resolution vs. computational efficiency (512x512 → 224x224), source-free vs. source-available adaptation, active vs. random sampling
- Failure signatures: Degraded performance on specific DR grades, sensitivity to outlier samples, collapse of pseudo-labeling accuracy
- First 3 experiments:
  1. Ablation study: Remove Lchn to verify its impact on fine-grained grading performance
  2. Compare ALRM vs. random selection with varying budget sizes
  3. Test mixup-based pseudo-labeling vs. standard pseudo-labeling with threshold-based filtering

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the SFADA framework perform when applied to other medical imaging domains beyond diabetic retinopathy grading?
- Basis in paper: [inferred] The paper mentions that the framework is designed to be applicable in real-world scenarios with data privacy and computational efficiency considerations, suggesting potential for broader application.
- Why unresolved: The paper focuses solely on diabetic retinopathy grading and does not explore the framework's performance in other medical imaging domains.
- What evidence would resolve it: Experimental results demonstrating the framework's performance on other medical imaging tasks, such as cancer detection or organ segmentation.

### Open Question 2
- Question: What is the optimal number of rounds for active sample selection in the ALRM process?
- Basis in paper: [explicit] The paper mentions that active learning is performed for K rounds, but does not specify the optimal number of rounds.
- Why unresolved: The optimal number of rounds may depend on various factors such as dataset size, domain gap, and computational resources, which are not explored in the paper.
- What evidence would resolve it: An ablation study varying the number of rounds and reporting the corresponding DR grading performance.

### Open Question 3
- Question: How does the proposed S-PMiS method compare to other pseudo-labeling strategies in terms of accuracy and computational efficiency?
- Basis in paper: [inferred] The paper mentions that S-PMiS is designed to improve pseudo-labeling accuracy, but does not compare it to other methods.
- Why unresolved: The paper does not provide a comparison of S-PMiS with other pseudo-labeling strategies, leaving its relative performance unknown.
- What evidence would resolve it: Experimental results comparing S-PMiS with other pseudo-labeling methods in terms of accuracy and computational efficiency.

## Limitations

- Implementation details are incomplete, particularly regarding mixup parameters (α, β values) and threshold values for pseudo-label selection
- No comparison with other pseudo-labeling strategies to validate the effectiveness of the proposed S-PMiS method
- Limited exploration of optimal parameters such as the number of nearest neighbors K for local representation calculation

## Confidence

- High confidence: The general three-stage framework architecture and the need for domain adaptation in UWF fundus images
- Medium confidence: The specific performance improvements (85.36% accuracy, 92.38% QWK) due to missing implementation details
- Medium confidence: The effectiveness of local representation matching, as the theoretical justification is sound but corpus evidence is limited

## Next Checks

1. Implement ablation studies to isolate the contribution of Lchn contrastive loss on fine-grained grading performance
2. Verify the active selection strategy by comparing ALRM against random selection across multiple budget sizes and random seeds
3. Test the pseudo-labeling mechanism with different threshold values to ensure robustness against collapse