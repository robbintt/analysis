---
ver: rpa2
title: Contrastive Learning for Conversion Rate Prediction
arxiv_id: '2307.05974'
source_url: https://arxiv.org/abs/2307.05974
tags:
- prediction
- learning
- data
- contrastive
- supervised
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes CL4CVR, a framework that combines supervised
  CVR prediction with a contrastive learning task to address data sparsity in online
  advertising. It introduces embedding masking to create two views of augmented samples,
  a false negative elimination component to handle duplicate samples, and a supervised
  positive inclusion component to leverage conversion labels.
---

# Contrastive Learning for Conversion Rate Prediction

## Quick Facts
- **arXiv ID**: 2307.05974
- **Source URL**: https://arxiv.org/abs/2307.05974
- **Reference count**: 31
- **Primary result**: CL4CVR achieves 0.8637 AUC on industrial dataset and 0.6590 on public dataset

## Executive Summary
This paper addresses the challenge of data sparsity in conversion rate (CVR) prediction for online advertising by proposing CL4CVR, a framework that combines supervised CVR prediction with a tailored contrastive learning task. The method introduces three key components: embedding masking to create informative contrastive pairs, false negative elimination to handle duplicate samples, and supervised positive inclusion to leverage conversion labels. Experimental results on two real-world datasets show significant AUC improvements over strong baselines, with the proposed components shown to be complementary and collectively effective.

## Method Summary
CL4CVR integrates supervised ESMM (Entire Space Multi-task Model) with a contrastive learning framework. The method uses embedding masking instead of feature masking to create two augmented views of samples, applies false negative elimination to remove duplicate samples from negative pairs, and includes supervised positive inclusion to add conversion-labeled samples as additional positives. The model shares embedding layers between the supervised and contrastive tasks, optimizing a combined loss function. The approach is designed to address data sparsity while preserving all features and leveraging conversion labels effectively.

## Key Results
- CL4CVR achieves 0.8637 AUC on industrial dataset, outperforming strong baselines
- Model reaches 0.6590 AUC on public dataset (Taobao)
- Embedding masking, FNE, and SPI components are shown to be complementary and collectively improve performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Embedding masking (EM) improves CVR prediction by preserving all features while varying embedding dimensions to create more informative contrastive pairs.
- Mechanism: EM applies element-wise masks on concatenated embedding vectors rather than raw features, allowing both views to retain all features while learning robust representations from partial information.
- Core assumption: Embedding-level augmentation provides sufficient diversity for contrastive learning while maintaining feature completeness needed for CVR tasks.
- Evidence anchors: Abstract states EM is proposed "to create two views of augmented samples"; section explains EM applies masks on concatenated embedding vectors.
- Break condition: If embedding dimensions are too sparse or correlated, masked views may lose critical information for distinguishing conversion patterns.

### Mechanism 2
- Claim: False negative elimination (FNE) corrects the contrastive loss by removing samples with identical features that would otherwise be treated as negatives.
- Mechanism: FNE identifies samples sharing the same original features (e.g., same ad shown to same user at different times) and excludes them from negative pairs in the contrastive loss calculation.
- Core assumption: Samples with identical features should not be treated as negatives in contrastive learning, as this creates contradictory training signals.
- Evidence anchors: Abstract mentions FNE eliminates "samples with the same feature as the anchor sample"; section explains this handles cases where users click and convert multiple times.
- Break condition: If feature hashing or embedding collisions occur, FNE might incorrectly merge distinct samples.

### Mechanism 3
- Claim: Supervised positive inclusion (SPI) leverages conversion labels to create additional positive pairs, improving representation learning for rare conversion events.
- Mechanism: When an anchor sample has a conversion label of 1, SPI includes all other positive samples in the same batch as additional positives in the contrastive loss.
- Core assumption: Conversion events are rare but highly informative; including more positive pairs for these samples enhances learning of conversion-specific patterns.
- Evidence anchors: Abstract states SPI "include additional positive samples for each anchor sample"; section mentions it's "inspired by supervised contrastive learning."
- Break condition: If conversion events are too sparse, including all positives may eliminate meaningful negative pairs, reducing contrastive signal.

## Foundational Learning

- Concept: Contrastive learning framework
  - Why needed here: CL4CVR relies on contrastive learning to improve representation quality for CVR prediction under data sparsity.
  - Quick check question: What is the core objective of contrastive learning, and how does it differ from supervised learning?

- Concept: Data augmentation techniques
  - Why needed here: Understanding different augmentation methods (feature masking vs embedding masking) is crucial for implementing CL4CVR's EM component.
  - Quick check question: How does embedding masking differ from feature masking, and why is it better suited for CVR prediction?

- Concept: Multi-task learning with shared representations
  - Why needed here: CL4CVR combines supervised CVR prediction with contrastive learning using shared embedding layers and encoders.
  - Quick check question: How does sharing embedding layers between supervised and contrastive tasks benefit the overall model?

## Architecture Onboarding

- Component map: Input features → Shared embedding layer → ESMM towers (CTR + CVR) + Contrastive encoder → Contrastive loss (with FNE and SPI) → Combined loss → Output
- Critical path: Feature → Embedding masking → Encoder → Contrastive loss calculation (with FNE/SPI filtering) → Combined optimization
- Design tradeoffs: Embedding masking preserves feature completeness but may reduce augmentation diversity compared to feature masking; FNE prevents contradictory signals but requires feature matching overhead; SPI enhances conversion signal but may reduce negative sample count.
- Failure signatures: Poor AUC gains despite contrastive learning implementation; unstable training with contrastive loss; degraded performance when increasing SPI positives.
- First 3 experiments:
  1. Implement EM component and verify it improves AUC over feature masking baselines
  2. Add FNE to handle duplicate samples and measure impact on training stability
  3. Incorporate SPI for conversion samples and test if rare conversion patterns are better captured

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CL4CVR vary across different advertising domains with varying levels of data sparsity?
- Basis in paper: The paper demonstrates effectiveness on two datasets but does not explore domain-specific performance differences.
- Why unresolved: The study focuses on two specific datasets without analyzing performance across diverse advertising contexts.
- What evidence would resolve it: Comparative experiments across multiple advertising domains with varying data sparsity levels.

### Open Question 2
- Question: What is the impact of incorporating additional post-click behaviors (e.g., favorite, add to cart) on the performance of CL4CVR?
- Basis in paper: The authors mention that more sophisticated models like ESM2, GMCM, and HM3 require additional post-click behaviors but do not explore this in their framework.
- Why unresolved: The paper uses ESMM as the base model and does not investigate the benefits of incorporating additional post-click behaviors.
- What evidence would resolve it: Experiments comparing CL4CVR with and without additional post-click behaviors.

### Open Question 3
- Question: How does the proposed embedding masking strategy compare to other data augmentation techniques in CVR prediction?
- Basis in paper: The authors propose embedding masking as a novel data augmentation technique but do not compare it extensively with other methods.
- Why unresolved: The paper focuses on the effectiveness of embedding masking but lacks a comprehensive comparison with other data augmentation techniques.
- What evidence would resolve it: Comparative studies of embedding masking against other data augmentation methods in CVR prediction tasks.

## Limitations
- Limited empirical validation of individual component contributions (no ablation studies)
- Unclear implementation details for false negative elimination and supervised positive inclusion
- Minimal external validation from related work or comparison with established contrastive learning frameworks

## Confidence
- **High Confidence**: The overall framework architecture combining supervised CVR prediction with contrastive learning is technically sound and addresses a recognized problem in advertising data sparsity.
- **Medium Confidence**: The three proposed components (EM, FNE, SPI) are conceptually reasonable, but their individual effectiveness lacks strong empirical support.
- **Low Confidence**: The claim that these components are complementary and collectively superior to strong baselines needs more rigorous validation through controlled experiments.

## Next Checks
1. Conduct experiments removing each of the three proposed components (EM, FNE, SPI) individually to quantify their independent contributions to overall performance gains.
2. Implement and compare embedding masking against other augmentation strategies (feature masking, dropout, adversarial perturbations) to validate the claimed superiority of the EM approach.
3. Develop and test multiple algorithms for false negative elimination to verify that the proposed method correctly identifies and handles duplicate samples without introducing new biases or errors.