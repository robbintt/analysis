---
ver: rpa2
title: Deep neural networks have an inbuilt Occam's razor
arxiv_id: '2304.06670'
source_url: https://arxiv.org/abs/2304.06670
tags:
- functions
- complexity
- training
- error
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Overparameterized deep neural networks (DNNs) generalize well despite
  high capacity, a key problem in machine learning. Using a Bayesian framework, the
  study analyzes the prior probability of Boolean functions produced by DNNs and their
  generalization performance.
---

# Deep neural networks have an inbuilt Occam's razor

## Quick Facts
- arXiv ID: 2304.06670
- Source URL: https://arxiv.org/abs/2304.06670
- Reference count: 0
- Primary result: DNNs have an exponential inductive bias toward simple functions that enables generalization despite overparameterization

## Executive Summary
This paper investigates why deep neural networks (DNNs) generalize well despite having sufficient capacity to memorize training data. Through a Bayesian framework, the authors show that DNNs possess an intrinsic Occam's razor-like bias toward simple functions, with the prior probability of functions decaying exponentially with their Kolmogorov complexity. This bias is strong enough to counteract the exponential growth in the number of complex functions, enabling DNNs to generalize effectively when combined with structured data.

The authors demonstrate this by exploiting a transition between ordered and chaotic regimes in tanh-activated DNNs, showing that weakening the simplicity bias (by increasing parameter variance) leads to worse performance on simple target functions. Crucially, the Bayesian prior accurately predicts the posterior distribution of functions learned by stochastic gradient descent (SGD), validating the theoretical framework. This work provides a principled explanation for the generalization capability of DNNs that goes beyond traditional PAC-Bayes bounds.

## Method Summary
The paper uses a Bayesian approach to analyze DNN generalization by calculating the prior probability of Boolean functions generated by random parameter sampling in fully-connected networks with tanh activations. The authors vary the network's transition between ordered and chaotic regimes by changing weight initialization variance to control the strength of the simplicity bias. They train networks using SGD and AdvSGD optimizers to zero training error, then measure generalization performance. The theoretical framework combines algorithmic information theory with Bayesian inference to predict the posterior distribution of functions learned by SGD, which is validated against empirical results on Boolean functions, MNIST, and CIFAR-10 datasets.

## Key Results
- DNNs exhibit an exponential inductive bias toward simple functions that decays as $2^{-aK(f)+b}$ where $K(f)$ is function complexity
- The Bayesian prior over functions accurately predicts the posterior distribution obtained by SGD training
- Increasing weight variance pushes networks into the chaotic regime, weakening the simplicity bias and degrading performance on simple functions
- The combination of this inductive bias and structured data enables DNNs to generalize despite overparameterization

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: DNNs express a prior probability over functions that is exponentially biased toward simple (low Kolmogorov) functions.
- **Mechanism**: When a DNN with tanh activation is initialized with a Gaussian parameter distribution, the mapping from parameters to functions follows an algorithmic information theory-inspired bound: $P(f) \lesssim 2^{-aK(f)+b}$, where $K(f)$ is a proxy for Kolmogorov complexity (e.g., LZ complexity). This prior becomes weaker as the network enters the chaotic regime (higher $\sigma_w$).
- **Core assumption**: The prior over functions derived from random parameter sampling approximates the posterior obtained by SGD training.
- **Evidence anchors**:
  - [abstract]: "The prior over functions is determined by the network, and is varied by exploiting a transition between ordered and chaotic regimes."
  - [section]: "P(f) â‰² 2^{-aK(f)+b} towards simple functions with low descriptional complexity..."
  - [corpus]: Weak evidence - corpus focuses on Occam's razor and marginal likelihood, not the prior-over-functions mechanism.
- **Break condition**: If the DNN's parameter-to-function mapping deviates significantly from the AIT-inspired bound, or if training data is not structured (high complexity), the bias may fail to counteract the exponential growth in complex functions.

### Mechanism 2
- **Claim**: The Bayesian posterior probability over functions, when averaged over training sets, accurately predicts the functions learned by SGD-trained DNNs.
- **Mechanism**: The posterior $P(f|S) \propto P(S|f)P(f)/P(S)$ simplifies to $P(f)$ for functions with zero training error, since $P(S|f)=1$ in that case. Averaging over training sets yields $\langle P(f|S) \rangle_m \approx P(f)(1-\epsilon(f))^m / \langle P(S) \rangle_m$, where $\epsilon(f)$ is the generalization error. This averaged posterior matches the distribution of functions found by SGD.
- **Core assumption**: The likelihood $P(S|f)$ is binary (1 if zero training error, 0 otherwise), and the prior $P(f)$ dominates the posterior for functions achieving zero training error.
- **Evidence anchors**:
  - [abstract]: "When combined with the prior, this accurately predicts the posterior, measured for DNNs trained with stochastic gradient descent."
  - [section]: "For a given training set, all the variation in $P(f|S)$ for $f \in U(S)$ comes from the prior $P(f)$ since $P(S)$ is constant."
  - [corpus]: Weak evidence - corpus discusses PAC-Bayes bounds and marginal likelihood, but not the specific posterior prediction mechanism.
- **Break condition**: If SGD introduces biases not captured by the random parameter sampling prior, or if the likelihood approximation fails (e.g., non-zero training error), the posterior prediction may break down.

### Mechanism 3
- **Claim**: The interplay between the exponential growth in the number of complex functions and the exponential decay in their prior probability enables DNNs to generalize well.
- **Mechanism**: The number of functions with complexity $K$ scales as $2^K$, while the prior $P(f)$ decays as $2^{-K}$. This leads to a nearly flat prior over complexity $P(K)$, meaning the DNN is not overwhelmed by complex functions. The combination of this inductive bias and structured data (low complexity targets) results in good generalization.
- **Core assumption**: The data generating process produces functions of relatively low complexity compared to the maximum possible complexity.
- **Evidence anchors**:
  - [abstract]: "...combined with an intrinsic Occam's razor-like inductive bias towards (Kolmogorov) simple functions that is strong enough to counteract the exponential growth of the number of functions with complexity..."
  - [section]: "Basic counting arguments imply that the number of strings of a fixed length that have complexity $K$ scales exponentially as $2^K$."
  - [corpus]: Weak evidence - corpus mentions complexity and Occam's razor, but not the specific interplay between function count and prior decay.
- **Break condition**: If the data is highly complex (close to maximum Kolmogorov complexity), or if the DNN's prior bias is weakened (e.g., by entering the chaotic regime), the exponential growth in complex functions may overwhelm the prior, leading to poor generalization.

## Foundational Learning

- **Concept**: Algorithmic Information Theory (AIT) and Kolmogorov Complexity
  - **Why needed here**: The paper relies on the concept of Kolmogorov complexity to define and measure the "simplicity" of functions, and to establish the prior bias toward simple functions.
  - **Quick check question**: Can you explain the difference between Kolmogorov complexity and other complexity measures like entropy or circuit complexity?

- **Concept**: Bayesian Inference and Posterior Probability
  - **Why needed here**: The paper uses Bayesian inference to relate the prior over functions (determined by the DNN architecture) to the posterior probability of functions given training data, and to predict the functions learned by SGD.
  - **Quick check question**: Can you derive the posterior probability $P(f|S)$ from Bayes' rule, given a prior $P(f)$ and a likelihood $P(S|f)$?

- **Concept**: Bias-Variance Tradeoff and Overfitting
  - **Why needed here**: The paper addresses the question of why overparameterized DNNs generalize well despite their high capacity, which is related to the bias-variance tradeoff and the risk of overfitting.
  - **Quick check question**: Can you explain how a strong inductive bias toward simple functions can help prevent overfitting in high-capacity models?

## Architecture Onboarding

- **Component map**: Input layer (Boolean) -> Hidden layers (FCN with tanh) -> Output layer (threshold)
- **Critical path**:
  1. Initialize DNN parameters from Gaussian distribution
  2. Sample functions by evaluating DNN on all $2^n$ Boolean inputs
  3. Calculate complexity (LZ) of each sampled function
  4. Train DNN on a subset of inputs to zero training error using AdvSGD or Adam
  5. Measure generalization error on remaining inputs
  6. Compare distribution of learned functions to prior over functions

- **Design tradeoffs**:
  - Tanh vs ReLU activations: Tanh allows exploration of the ordered-to-chaotic transition, while ReLU has a fixed simplicity bias
  - Network depth $N_l$: Deeper networks may enter the chaotic regime more easily, weakening the simplicity bias
  - Parameter width $\sigma_w$: Larger $\sigma_w$ pushes the network deeper into the chaotic regime, reducing the simplicity bias

- **Failure signatures**:
  - If the DNN consistently converges to complex functions with high generalization error, the simplicity bias may be too weak
  - If the DNN cannot achieve zero training error on the given dataset, the hypothesis class may be insufficiently expressive
  - If the posterior prediction from the prior fails to match the distribution of functions learned by SGD, the assumptions about the parameter-to-function mapping may be violated

- **First 3 experiments**:
  1. Sample functions from a DNN with $N_l=10$, $\sigma_w=1$, and calculate the prior over complexity $P(K)$ using LZ complexity
  2. Train the same DNN on a simple Boolean target function (e.g., $f(x)=0$ for all $x$) and measure the generalization error distribution
  3. Repeat experiment 2 with a more complex target function (e.g., parity function) and compare the generalization error distribution to the prior prediction

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the strength of the simplicity bias in DNNs vary with network depth and activation functions?
- **Basis in paper**: Explicit
- **Why unresolved**: The paper shows that tanh-activated DNNs exhibit a transition to a chaotic regime with increasing weight variance, weakening the simplicity bias. However, the rate at which this bias disappears and its dependence on other architectural factors remains unexplored.
- **What evidence would resolve it**: Systematic experiments varying depth, width, and activation functions to quantify the simplicity bias across a wider range of architectures.

### Open Question 2
- **Question**: Can the Bayesian prior over functions accurately predict the posterior distribution for more complex tasks beyond Boolean functions?
- **Basis in paper**: Explicit
- **Why unresolved**: The paper demonstrates accurate predictions for Boolean functions and image datasets like MNIST and CIFAR-10. However, extending this approach to more complex, high-dimensional tasks with continuous outputs is an open challenge.
- **What evidence would resolve it**: Applying the Bayesian framework to benchmark datasets in natural language processing or reinforcement learning, comparing predictions to empirical results.

### Open Question 3
- **Question**: How does the inductive bias of DNNs interact with the structure of real-world data to enable generalization?
- **Basis in paper**: Explicit
- **Why unresolved**: The paper argues that structured data combined with a simplicity bias is key to DNN success. However, the precise nature of this interaction and its dependence on data complexity and distribution remains unclear.
- **What evidence would resolve it**: Analyzing the inductive bias of DNNs on a diverse set of datasets with varying levels of structure and complexity, linking it to generalization performance.

### Open Question 4
- **Question**: What are the additional 2nd-order effects of hyperparameter tuning and optimization algorithms on DNN generalization?
- **Basis in paper**: Explicit
- **Why unresolved**: The paper focuses on the 1st-order question of why DNNs generalize at all. While it acknowledges the importance of hyperparameter tuning, the specific mechanisms by which these factors influence generalization are not fully understood.
- **What evidence would resolve it**: Systematic ablation studies varying hyperparameters and optimization algorithms, isolating their individual and combined effects on generalization.

## Limitations

- The theoretical framework is limited to fully-connected networks with tanh activations, leaving uncertainty about whether the Occam's razor effect extends to modern architectures
- The analysis assumes Boolean function classification, and while results on MNIST and CIFAR-10 provide some validation, the extension to continuous domains remains uncertain
- The correspondence between random parameter sampling and SGD-trained networks is a strong assumption that may not hold for all architectures and tasks

## Confidence

- **High confidence**: The existence of a prior bias toward simple functions in DNNs (Mechanism 1)
- **Medium confidence**: The predictive power of the Bayesian posterior for SGD-trained networks (Mechanism 2)
- **Medium confidence**: The interplay between function count and prior decay enabling generalization (Mechanism 3)

## Next Checks

1. Test the prior-to-posterior correspondence on ReLU networks and architectures with batch normalization to determine if the Occam's razor effect is architecture-dependent
2. Investigate whether the prior bias remains predictive when training with realistic noise levels and non-zero training error regimes
3. Apply the framework to continuous regression tasks with known complexity measures to validate the extension beyond Boolean functions