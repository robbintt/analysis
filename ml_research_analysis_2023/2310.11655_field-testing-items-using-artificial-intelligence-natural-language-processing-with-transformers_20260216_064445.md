---
ver: rpa2
title: 'Field-testing items using artificial intelligence: Natural language processing
  with transformers'
arxiv_id: '2310.11655'
source_url: https://arxiv.org/abs/2310.11655
tags:
- roberta
- item
- items
- were
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study explored using AI (RoBERTa transformer) to field-test
  multiple-choice items instead of human examinees. Five thousand variations of RoBERTa
  with degraded vocabulary were created to mimic varying human intelligence levels
  and used to complete 29 English literacy items.
---

# Field-testing items using artificial intelligence: Natural language processing with transformers

## Quick Facts
- arXiv ID: 2310.11655
- Source URL: https://arxiv.org/abs/2310.11655
- Reference count: 2
- Primary result: AI (RoBERTa transformer) can complete multiple-choice items and generate psychometric parameters with moderate correlation to human data

## Executive Summary
This study explores using AI transformers to field-test multiple-choice items instead of human examinees. Five thousand variations of the RoBERTa model with degraded vocabulary were created to mimic varying human intelligence levels and used to complete 29 English literacy items. The resulting item parameter estimates (difficulty and discrimination) showed moderate correlations with those from human data (.39-.47), and RoBERTa's ability estimates were highly similar to human-based estimates (bias=.03, RMSE=.22, r=.99). While RoBERTa successfully completed most items and generated plausible response patterns, considerable disagreement remained between AI and human item statistics, suggesting AI-generated responses may need more sophisticated modeling to fully replace human field-testing.

## Method Summary
The study used RoBERTa-large, a transformer-based language model, to complete multiple-choice items by systematically degrading vocabulary embeddings. Five thousand variations were created by randomly setting word embedding weights to zero, with each variation representing a different "intelligence level." These AI models completed 29 third-grade English literacy items, and the resulting response data was analyzed using the 2-parameter logistic (2PL) IRT model to estimate item parameters. The AI-generated parameters were then compared to human-based parameters to assess the feasibility of using AI for field-testing.

## Key Results
- AI-generated item parameter estimates (difficulty and discrimination) showed moderate correlations with human data (.39-.47)
- RoBERTa's ability estimates were highly similar to human-based estimates (bias=.03, RMSE=.22, r=.99)
- AI models successfully completed most items and generated plausible response patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AI models can simulate human response patterns for multiple-choice items through parameter manipulation
- Mechanism: By systematically degrading vocabulary embeddings in RoBERTa, the study created model variations that produced response data suitable for psychometric analysis
- Core assumption: The degree of vocabulary degradation correlates with human-like response patterns
- Evidence anchors:
  - [abstract] "Five thousand variations of the RoBERTa model... completed an English literacy exam... Data were used to calculate the psychometric properties of the items, which showed some degree of agreement to those obtained from human examinee data."
  - [section] "RoBERTa's ability estimates were obtained using both human (ùúÉ‡∑†‡ØÅ) and RoBERTa (ùúÉ‡∑†‡Øã) item parameters... Ability estimates ùúÉ‡∑†‡ØÅ and ùúÉ‡∑†‡Øã were similar (bias=0.03, RMSE=0.22, r=.99)"
  - [corpus] "PsychAdapter: Adapting LLM Transformers to Reflect Traits, Personality and Mental Health" - shows transformers can be adapted to reflect human-like characteristics
- Break condition: If the correlation between vocabulary degradation and response patterns breaks down, the model variations would no longer produce meaningful psychometric data

### Mechanism 2
- Claim: Transformer attention mechanisms can understand context-dependent word meanings in multiple-choice items
- Mechanism: Multi-headed attention allows transformers to weigh word relationships differently based on context, enabling comprehension of nuanced language in test items
- Core assumption: Contextual understanding in transformers translates to human-like comprehension of test items
- Evidence anchors:
  - [abstract] "The core of transformers is the multiheaded attention mechanism, which create the meaning of each word efficiently by identifying its contextual relationship with the other words."
  - [section] "transformers are able to distinguish the difference in the meaning of 'check' in the phrases 'write a check' and 'check the engine'"
  - [corpus] "A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks" - confirms transformers' superior handling of sequential data
- Break condition: If attention mechanisms fail to capture context-dependent meanings, item responses would become random rather than systematic

### Mechanism 3
- Claim: AI-generated item response data can produce comparable psychometric parameters to human data
- Mechanism: The 2PL model parameters estimated from AI responses showed moderate correlation with human-based parameters, suggesting AI can approximate human psychometric properties
- Core assumption: Psychometric properties are consistent enough across humans and AI to enable comparison
- Evidence anchors:
  - [abstract] "The resulting item parameter estimates (difficulty and discrimination) showed moderate correlations with those from human data (.39-.47)"
  - [section] "Positive correlations were found between the corresponding human and RoBERTa-based item statistics (r=.39 to .47)"
  - [corpus] "Transformers in Healthcare: A Survey" - demonstrates transformers' application in domains requiring human-like reasoning
- Break condition: If item parameters diverge significantly, AI cannot reliably replace human field-testing

## Foundational Learning

- Concept: 2-Parameter Logistic (2PL) IRT Model
  - Why needed here: The study used 2PL to estimate item discrimination and difficulty parameters from both human and AI data
  - Quick check question: What are the two parameters estimated in the 2PL model, and how do they differ from 1PL (Rasch) model?

- Concept: Transformer Architecture and Attention Mechanisms
  - Why needed here: Understanding how transformers process language through attention is crucial for grasping how AI responses were generated
  - Quick check question: How does multi-headed attention in transformers differ from simple attention mechanisms?

- Concept: Vocabulary Embedding Manipulation
  - Why needed here: The study's method of degrading vocabulary to create "less intelligent" models is central to its approach
  - Quick check question: What happens to a transformer's performance when random proportions of word embeddings are set to zero?

## Architecture Onboarding

- Component map: RoBERTa model ‚Üí vocabulary degradation module ‚Üí response generation ‚Üí 2PL parameter estimation ‚Üí comparison with human data
- Critical path: Item selection ‚Üí vocabulary manipulation ‚Üí response generation ‚Üí parameter estimation ‚Üí validation against human data
- Design tradeoffs: Computational efficiency vs. model fidelity (simpler vocabulary degradation is fast but may not capture human complexity)
- Failure signatures: Low correlations between AI and human parameters, systematic biases in parameter estimates, or inability to complete items
- First 3 experiments:
  1. Test vocabulary degradation levels (0%, 25%, 50%, 75%, 100%) to establish relationship between degradation and performance
  2. Compare parameter estimates using anchored vs. freely estimated items to validate scaling approach
  3. Test different item types (different grade levels, subjects) to assess generalizability of the approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would more sophisticated AI intelligence manipulation methods produce item parameter estimates that better match human data?
- Basis in paper: [explicit] The authors noted that human intelligence is not as simple as a random proportion of known vocabulary and that more complex manipulation may be necessary to mimic diverse human knowledge levels
- Why unresolved: This study only tested random vocabulary degradation as a proxy for intelligence; other potential methods were not explored
- What evidence would resolve it: Comparing item parameter estimates from AI models using alternative intelligence manipulation methods (e.g., attention mechanism adjustments, context understanding modifications) against human data

### Open Question 2
- Question: How would field-testing performance change if transformers were fine-tuned using operational items similar to the field-test items?
- Basis in paper: [explicit] The authors suggested that transformers could be fine-tuned using operational items similarly designed to field-test items
- Why unresolved: The study used a pre-trained transformer fine-tuned on a different dataset (RACE)
- What evidence would resolve it: Comparing item parameter estimates from transformers fine-tuned on operational items versus pre-trained transformers on field-test data

### Open Question 3
- Question: How could differential item functioning analysis be incorporated into AI-based field-testing?
- Basis in paper: [explicit] The authors noted that ethics of using AI for field-testing must be considered, including how to incorporate DIF analysis
- Why unresolved: The study did not address fairness or bias in AI-generated responses
- What evidence would resolve it: Developing and testing methods to identify and adjust for DIF in AI-generated response data

## Limitations
- Moderate correlation (.39-.47) between AI-generated and human item parameters suggests AI cannot fully replace human field-testing without refinement
- Vocabulary degradation method may oversimplify complex human cognitive processes
- Study limited to third-grade English literacy items, raising questions about generalizability to other subjects and difficulty levels

## Confidence
- **High Confidence**: Transformer architecture's ability to process contextual language relationships is well-established
- **Medium Confidence**: AI can approximate human psychometric properties with moderate correlations, but remaining discrepancy suggests additional factors not captured by vocabulary degradation
- **Low Confidence**: AI cannot yet reliably replace human field-testing given moderate correlations and narrow scope of study

## Next Checks
1. Test the vocabulary degradation approach with items from multiple subjects (mathematics, science, social studies) and difficulty levels to assess generalizability beyond third-grade English literacy
2. Conduct longitudinal studies to examine whether AI-generated item parameters remain stable across different testing sessions and whether they predict future human performance accurately
3. Compare cognitive processes inferred from AI response patterns with those observed in human think-aloud protocols to identify gaps in the vocabulary degradation model's ability to capture human reasoning