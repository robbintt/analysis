---
ver: rpa2
title: 'counterfactuals: An R Package for Counterfactual Explanation Methods'
arxiv_id: '2304.06569'
source_url: https://arxiv.org/abs/2304.06569
tags:
- counterfactuals
- package
- counterfactual
- methods
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The counterfactuals R package provides a unified interface for
  counterfactual explanation methods, enabling users to generate and compare explanations
  across different models and datasets. It implements three methods - MOC, WhatIf,
  and NICE - and offers extensions to handle regression and multiclass classification
  tasks.
---

# counterfactuals: An R Package for Counterfactual Explanation Methods

## Quick Facts
- arXiv ID: 2304.06569
- Source URL: https://arxiv.org/abs/2304.06569
- Reference count: 40
- Provides unified R6-based interface for counterfactual explanation methods

## Executive Summary
The counterfactuals R package addresses the need for consistent counterfactual explanation methods across diverse machine learning models and datasets. It implements three methods - MOC, WhatIf, and NICE - with extensions to handle regression and multiclass classification tasks. The package provides a modular framework that enables users to generate and compare explanations, evaluate them based on properties like validity and plausibility, and visualize results through various plots.

## Method Summary
The package implements three counterfactual explanation methods: MOC uses multi-objective optimization with NSGA-II to find diverse counterfactuals balancing validity, proximity, sparsity, and plausibility; WhatIf finds nearest training points with desired predictions; NICE uses iterative local search to minimize feature changes. The methods are implemented as R6 classes inheriting from common abstract base classes, enabling a unified interface while maintaining method-specific implementations. Extensions handle regression tasks by changing target prediction spaces and multiclass classification by considering multiple thresholds.

## Key Results
- MOC achieved the highest hypervolume indicator when considering all objectives simultaneously
- WhatIf was fastest but suggested more feature changes compared to MOC and NICE
- The package successfully handles both classification and regression tasks through unified interface
- Benchmark study across six datasets and five model types validated method quality and runtime trade-offs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The unified R6-based interface enables consistent counterfactual explanation generation across diverse model types and datasets.
- **Mechanism**: By implementing counterfactual methods as R6 classes inheriting from common abstract base classes (CounterfactualMethodClassif/-Regr), the package enforces a standardized workflow: initialization with a Predictor wrapper, finding counterfactuals via find_counterfactuals(), and evaluation via Counterfactuals object methods.
- **Core assumption**: Model-agnostic methods can be generalized to both classification and regression tasks by changing the target prediction space definition.
- **Evidence anchors**:
  - [abstract] "provides a modular and unified R6-based interface for counterfactual explanation methods"
  - [section] "a new class inherits from either CounterfactualMethodClassif or CounterfactualMethodRegr"
- **Break condition**: Methods requiring fundamentally different optimization approaches (e.g., causal counterfactuals needing causal graphs) cannot be easily integrated without violating the unified interface.

### Mechanism 2
- **Claim**: Returning multiple counterfactuals improves explanation quality by capturing the Rashomon effect and user preferences.
- **Mechanism**: The package extends methods to generate diverse counterfactuals by either continuing search until recreating the nearest neighbor (NICE) or returning all non-dominated individuals across generations (MOC). WhatIf is extended to return the l closest training points with desired predictions.
- **Core assumption**: Multiple valid counterfactuals exist for most observations and model decisions.
- **Evidence anchors**:
  - [abstract] "The package facilitates practical application of counterfactual explanations for auditing machine learning models"
  - [section] "we argue that a set of counterfactuals is more valuable than a single one"
- **Break condition**: In cases where only one valid counterfactual exists (e.g., extreme feature constraints), the additional computational cost of generating multiple counterfactuals provides no benefit.

### Mechanism 3
- **Claim**: Benchmark comparisons across six datasets and five model types validate method quality and runtime trade-offs.
- **Mechanism**: The benchmark study evaluates counterfactuals using four properties (validity, proximity, sparsity, plausibility) and the hypervolume indicator. Runtime behavior is assessed across row-wise and column-wise subsets of datasets with varying n and p.
- **Core assumption**: The four properties provide sufficient coverage of counterfactual quality dimensions for meaningful comparison.
- **Evidence anchors**:
  - [abstract] "compared the implemented methods for a variety of models and datasets with regard to the quality of their counterfactual explanations and their runtime behavior"
  - [section] "we use a benchmark study to answer the following research questions"
- **Break condition**: If the evaluation metrics do not align with domain-specific explanation requirements (e.g., actionability in healthcare), the benchmark results may not generalize to practical use cases.

## Foundational Learning

- **Concept**: R6 class inheritance and method overriding
  - Why needed here: The package uses R6 classes to create a consistent interface across different counterfactual methods while allowing method-specific implementations.
  - Quick check question: What is the purpose of having CounterfactualMethodClassif and CounterfactualMethodRegr as abstract base classes?

- **Concept**: Multi-objective optimization and Pareto efficiency
  - Why needed here: MOC uses NSGA-II to find counterfactuals that balance multiple competing properties (validity, proximity, sparsity, plausibility) simultaneously.
  - Quick check question: Why does MOC avoid weighting objectives a priori and instead return a Pareto set?

- **Concept**: Gower distance and mixed data types
  - Why needed here: The package uses Gower distance to measure similarity between observations with mixed numerical and categorical features, which is essential for evaluating counterfactual plausibility.
  - Quick check question: How does the Gower distance formula handle categorical features differently from numerical features?

## Architecture Onboarding

- **Component map**: Predictor (model wrapper) → CounterfactualMethod (base class) → Specific method classes (MOC, WhatIf, NICE) → Counterfactuals (evaluation/visualization). Key dependencies: iml for Predictor, data.table for efficient data handling, paradox for parameter spaces.
- **Critical path**: User initializes Predictor → selects counterfactual method class → calls find_counterfactuals() → receives Counterfactuals object → evaluates/visuallyizes results. Each step must complete successfully for the next to function.
- **Design tradeoffs**: Unified interface vs. method flexibility (some methods need specific adaptations), multiple counterfactuals vs. computational cost, evaluation metrics vs. domain-specific requirements.
- **Failure signatures**: Method-specific errors (e.g., MOC optimization failure), data preprocessing issues (feature scaling, encoding), runtime errors from complex model inputs, evaluation metric failures (non-valid counterfactuals).
- **First 3 experiments**:
  1. Generate counterfactuals for a simple logistic regression model on the German Credit dataset using MOC, verify the Counterfactuals object methods work correctly.
  2. Compare WhatIf and NICE on a regression task (plasma dataset), evaluate differences in proximity and sparsity metrics.
  3. Add a new counterfactual method (e.g., featureTweakR) following the extension example, ensure it integrates with the existing evaluation framework.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions. However, based on the content, potential open questions include how the performance of the counterfactuals package scales when integrating more counterfactual explanation methods beyond the current three, how the choice of hyperparameters for the MOC method affects the quality and diversity of the generated counterfactuals, and how the performance of the counterfactuals package compares to other existing implementations in Python or other languages.

## Limitations

- The unified interface may not accommodate future counterfactual methods requiring fundamentally different optimization approaches
- The four evaluation properties may not capture all relevant dimensions of explanation quality
- Computational costs for generating multiple counterfactuals may become prohibitive for large-scale applications

## Confidence

- Unified interface effectiveness: Medium
- Multiple counterfactuals benefit: Medium
- Benchmark results generalizability: Medium

## Next Checks

1. Test the package with a real-world dataset requiring causal counterfactuals to evaluate interface limitations
2. Compare the four evaluation metrics against domain-specific explanation requirements in a healthcare or finance use case
3. Benchmark runtime performance on datasets with 100,000+ observations to assess scalability limits