---
ver: rpa2
title: 'Phase diagram of early training dynamics in deep neural networks: effect of
  the learning rate, depth, and width'
arxiv_id: '2302.12250'
source_url: https://arxiv.org/abs/2302.12250
tags:
- training
- loss
- sharpness
- learning
- phase
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work systematically studies the effect of learning rate,
  depth, and width on the optimization dynamics of deep neural networks trained with
  stochastic gradient descent. The authors identify four distinct regimes in the training
  trajectory: early transient, intermediate saturation, progressive sharpening, and
  late-time edge-of-stability.'
---

# Phase diagram of early training dynamics in deep neural networks: effect of the learning rate, depth, and width

## Quick Facts
- arXiv ID: 2302.12250
- Source URL: https://arxiv.org/abs/2302.12250
- Reference count: 40
- Key outcome: This work systematically studies the effect of learning rate, depth, and width on the optimization dynamics of deep neural networks trained with stochastic gradient descent.

## Executive Summary
This paper presents a systematic study of early training dynamics in deep neural networks, revealing a rich phase diagram that depends on learning rate scaling, depth, and width. The authors identify four distinct training regimes: early transient, intermediate saturation, progressive sharpening, and late-time edge-of-stability. They discover two new phases - sharpness reduction and loss-sharpness catapult - that emerge as depth-to-width ratio increases. The sharpness reduction phase, where the network moves to flatter regions during early training, opens up significantly with larger depth-to-width ratios. The authors demonstrate these phenomena using fully connected networks, CNNs, and ResNets on standard datasets, and provide theoretical insights using a simple two-layer linear network model.

## Method Summary
The study systematically varies learning rate (scaled by initial sharpness), depth, and width in deep neural networks trained with SGD on MNIST, Fashion-MNIST, and CIFAR-10 datasets. Sharpness is measured via power iteration on the Hessian (20 iterations, 2048 samples). Phase diagrams are constructed by tracking loss and sharpness trajectories over 10 training steps across different scaled learning rates (c values). The analysis identifies critical learning rates defining phase boundaries and examines how these boundaries shift with depth-to-width ratios. A uv model (two-layer linear network) is used to provide theoretical insights into the observed phenomena.

## Key Results
- Identification of four distinct training regimes: early transient, intermediate saturation, progressive sharpening, and late-time edge-of-stability
- Discovery of sharpness reduction phase that opens up as depth-to-width ratio increases
- Identification of loss-sharpness catapult phase where both loss and sharpness initially increase before decreasing
- Demonstration that a simple uv model reproduces the observed phenomena
- Phase diagrams showing critical learning rate boundaries that shift with depth and width

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The sharpness reduction phase opens up as the depth-to-width ratio increases because deeper and narrower networks experience larger initial sharpness drops.
- Mechanism: When d/w is large, the network's initial parameter space has higher curvature variations. Early SGD steps with appropriately scaled learning rates (c < closs) exploit these variations, moving the parameters to flatter regions more effectively.
- Core assumption: Sharpness is primarily determined by the top eigenvalue of the Hessian at each training step.
- Evidence anchors:
  - [abstract] "The sharpness reduction phase opens up as the depth-to-width ratio increases."
  - [section 3] "The regime ccrit < c < closs opens up signiﬁcantly with increasing d/w, which is a new result of this work."
  - [corpus] Weak evidence; no direct citation but related works mention sharpness reduction in specific contexts.
- Break condition: If the scaling assumption breaks (e.g., η not proportional to 1/λH0), the phase boundaries may shift or disappear.

### Mechanism 2
- Claim: The loss catapult phase occurs when learning rates are large enough to temporarily increase loss but still converge to flatter regions.
- Mechanism: For closs < c < csharp, SGD takes steps that overshoot the initial basin, temporarily increasing loss but reducing sharpness. Eventually, training stabilizes in a flatter region.
- Core assumption: Loss and sharpness are inversely related; higher loss can lead to lower sharpness after temporary instability.
- Evidence anchors:
  - [abstract] "Loss catapult phase (closs < c < csharp): The first few gradient steps take training to a ﬂatter region but with a higher loss."
  - [section 3.1] "We refer to this spike in sharpness as 'sharpness catapult.'"
  - [corpus] Related work (Lewkowycz et al., 2020) mentions catapult phase but without sharpness analysis.
- Break condition: If batch size is too small or noise dominates, the catapult may not occur or may lead to divergence.

### Mechanism 3
- Claim: The loss-sharpness catapult phase exists only at small widths, where both loss and sharpness increase initially.
- Mechanism: In narrow networks, early steps can simultaneously increase both loss and sharpness due to higher sensitivity to initialization. The increase in sharpness allows subsequent steps to reduce both metrics.
- Core assumption: Narrow networks have more pronounced initial fluctuations in both loss and sharpness.
- Evidence anchors:
  - [section 3.1] "In this regime both the loss and sharpness initially start to increase... training eventually exhibits a signiﬁcant reduction in sharpness."
  - [section 5] "We observe the loss-sharpness catapult phase at small widths."
  - [corpus] Weak evidence; no direct citation but related works mention early time spikes in loss.
- Break condition: If width increases beyond a threshold, the phase disappears as fluctuations average out.

## Foundational Learning

- Concept: Hessian eigenvalues and sharpness measurement
  - Why needed here: Sharpness is defined as the maximum eigenvalue of the Hessian, central to phase boundaries.
  - Quick check question: How does measuring sharpness via power iteration differ from full Hessian computation in practice?

- Concept: Learning rate scaling with sharpness
  - Why needed here: The paper scales η = c/λH0, making sharpness a key hyperparameter tuning factor.
  - Quick check question: What happens to the phase diagram if we scale η differently, e.g., with NTK eigenvalue?

- Concept: Linear mode connectivity
  - Why needed here: Used to analyze loss barriers between initialization and early transient endpoints.
  - Quick check question: How does linear interpolation reveal connectivity in the loss landscape?

## Architecture Onboarding

- Component map:
  Data pipeline -> Models (FCN, CNN, ResNet) -> Training (SGD) -> Sharpness measurement (power iteration) -> Analysis (phase diagrams)

- Critical path:
  1. Initialize network at criticality (He/NTP)
  2. Measure initial sharpness λH0
  3. Train for 10 steps with varying c
  4. Track loss and sharpness trajectories
  5. Identify phase boundaries (closs, csharp, cmax)
  6. Analyze sharpness reduction and catapult phases

- Design tradeoffs:
  - Batch size 512 vs smaller: Larger batch reduces noise but may miss some early phenomena
  - Sharpness measurement cost vs accuracy: Power iteration is approximate but scalable
  - Depth/width scaling: Affects both phase boundaries and variance across initializations

- Failure signatures:
  - Divergence: Loss explodes (c > cmax)
  - No catapult: Sharpness decreases monotonically (c < closs)
  - Chaotic early dynamics: Loss and sharpness fluctuate wildly

- First 3 experiments:
  1. Verify sharpness reduction phase: Train shallow vs deep CNN with c < closs, compare sharpness trajectories
  2. Test catapult phase: Train with closs < c < csharp, measure loss increase then decrease
  3. Explore d/w scaling: Fix total parameters, vary depth/width, plot phase diagram boundaries

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise mechanism by which the sharpness reduction phase opens up as the depth-to-width ratio increases?
- Basis in paper: [explicit] The authors observe that the sharpness reduction phase opens up significantly with increasing d/w, but do not provide a detailed mechanistic explanation.
- Why unresolved: The paper provides empirical evidence but does not offer a theoretical framework to explain why deeper and narrower networks exhibit this phenomenon.
- What evidence would resolve it: A mathematical analysis showing how the interplay between depth and width affects the loss landscape's curvature and the network's ability to reduce sharpness during early training.

### Open Question 2
- Question: How does the choice of initialization scheme and optimization algorithm affect the observed phase diagram of early training dynamics?
- Basis in paper: [explicit] The authors note that the early training dynamics are sensitive to initialization and optimization algorithm, but focus on models initialized at criticality and trained with vanilla SGD.
- Why unresolved: The study's findings may not generalize to other initialization schemes or optimization procedures, which are commonly used in practice.
- What evidence would resolve it: Systematic experiments varying initialization schemes (e.g., LeCun initialization) and optimization algorithms (e.g., SGD with momentum, Adam) to determine their impact on the phase diagram.

### Open Question 3
- Question: What is the relationship between the sharpness catapult phenomenon and the linear connectivity of the loss landscape in deep neural networks?
- Basis in paper: [explicit] The authors demonstrate that for a range of learning rates, the final point after the sharpness catapult lies in the same basin as initialization, connected through a linear path.
- Why unresolved: The paper does not provide a theoretical explanation for why the sharpness catapult does not always result in a barrier to the initial state.
- What evidence would resolve it: An analysis of the loss landscape's topology and the role of sharpness in determining the connectivity between different regions of the loss landscape.

## Limitations
- Sharpness measurement via power iteration introduces approximation error that may affect phase boundary precision
- Analysis focuses on early training dynamics (first 10 steps) which may not fully capture long-term convergence behavior
- Absence of normalization layers and biases limits generalizability to standard deep learning architectures

## Confidence
- **High confidence**: Existence of four distinct training regimes and basic phase diagram structure across different architectures and datasets
- **Medium confidence**: Sharpness reduction and catapult phase mechanisms, particularly their scaling with depth-to-width ratio
- **Low confidence**: Exact critical constants (closs, csharp, cmax) due to sensitivity to sharpness measurement and averaging procedures

## Next Checks
1. **Sharpness measurement validation**: Compare power iteration sharpness estimates with full Hessian computations on small networks to quantify approximation error and its impact on phase boundaries
2. **Batch size sensitivity analysis**: Repeat experiments with batch sizes ranging from 128 to 2048 to determine the minimum batch size required for stable sharpness measurements and phase identification
3. **Normalization layer impact**: Train identical architectures with batch normalization to test whether sharpness reduction and catapult phases persist in standard deep learning setups