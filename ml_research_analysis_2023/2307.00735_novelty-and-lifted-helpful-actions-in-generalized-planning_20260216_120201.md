---
ver: rpa2
title: Novelty and Lifted Helpful Actions in Generalized Planning
arxiv_id: '2307.00735'
source_url: https://arxiv.org/abs/2307.00735
tags:
- planning
- search
- actions
- action
- program
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the action novelty rank to prune the search
  of generalized planning programs, implemented by novelty-based best-first search
  BFS(v) and its progressive variant PGP(v). The novelty rank computes the number
  of action occurrences in a planning program, and the new algorithms BFS(v) and PGP(v)
  prune the search when a newly generated program contains an action with a rank larger
  than a given bound v.
---

# Novelty and Lifted Helpful Actions in Generalized Planning

## Quick Facts
- arXiv ID: 2307.00735
- Source URL: https://arxiv.org/abs/2307.00735
- Authors: 
- Reference count: 11
- Primary result: Novelty-based search with action novelty rank v=1 or v=2 outperforms state-of-the-art in generalized planning

## Executive Summary
This work introduces the action novelty rank to prune the search of generalized planning programs, implemented by novelty-based best-first search BFS(v) and its progressive variant PGP(v). The novelty rank computes the number of action occurrences in a planning program, and the new algorithms BFS(v) and PGP(v) prune the search when a newly generated program contains an action with a rank larger than a given bound v. Besides, new evaluation functions are proposed to encourage the program to build more complex logic and structural program restrictions to improve the search efficiency. Experimental results show that BFS(v) and PGP(v) outperform the state-of-the-art in GP with low v bounds, indicating the scalability of the proposed methods over the standard generalized planning benchmarks.

## Method Summary
The paper introduces novelty-based pruning for generalized planning by computing action novelty ranks and limiting action occurrences in planning programs. BFS(v) and PGP(v) algorithms prune search states where any action's rank exceeds a bound v. Lifted helpful actions are computed using backward reachability on fact landmarks with arguments removed, focusing search on actions that contribute to goal achievement across all instances. Three new evaluation functions (fha, fln, fcn) guide search toward programs with better structural properties for generalized planning. The approach is implemented in a program-based GP framework and tested on standard benchmarks.

## Key Results
- BFS(v) and PGP(v) outperform state-of-the-art GP methods on standard benchmarks
- Ten out of fourteen domains can be solved with v = 1, four require v = 2
- Low novelty bounds (v ≤ 2) maintain completeness while significantly reducing search space
- The approach demonstrates scalability across STRIPS and numerical domains

## Why This Works (Mechanism)

### Mechanism 1: Action Novelty Rank Pruning
Pruning actions that occur more than v times in a program dramatically reduces search space without losing completeness for v ≤ 2. The action novelty rank counts occurrences of each action in a planning program. When generating new program states, any action whose rank exceeds v is pruned. This forces programs to reuse the same action in multiple contexts via pointers rather than duplicating actions, which is exactly how generalized planning programs work. Core assumption: A single action schema with different pointer instantiations can represent all necessary ground actions, so pruning duplicate action occurrences doesn't eliminate needed functionality.

### Mechanism 2: Lifted Helpful Actions
Lifted helpful actions reduce search by focusing on actions that contribute to goal achievement in the lifted (argument-free) representation. Compute lifted helpful actions by backward reachability on fact landmarks with arguments removed. Only actions that support unachieved lifted goals are considered helpful. This prunes actions irrelevant to goal achievement across all instances. Core assumption: Actions irrelevant to achieving lifted goals in any instance are irrelevant to the overall GP problem.

### Mechanism 3: Evaluation Functions
New evaluation functions (fha, fln, fcn) guide search toward programs with better structure for generalized planning. fha(Π, P) counts non-helpful actions to penalize irrelevant actions; fln(Π) counts non-branching/looping instructions to encourage program complexity; fcn(Π, P) counts untested ground atoms to encourage exploration. Core assumption: Programs with fewer non-helpful actions, more branching/looping, and more exploration will solve GP problems more efficiently.

## Foundational Learning

- Concept: Action novelty rank computation
  - Why needed here: Forms the basis for pruning search and is the core contribution of this work
  - Quick check question: Given Π = ⟨inc(z1), inc(z2), visit(z2, z1), visit(z1, z2)⟩, what is the novelty rank of action visit?
  - Answer: 3 (appears twice in the program, so rank = 1 + 2 = 3)

- Concept: Lifted representation and helpful actions
  - Why needed here: Enables computation of helpful actions across all instances in a GP problem
  - Quick check question: If G = {on(a,b), on(b,c)} and I = {on(a,b)}, what is U0 = L(G \ I)?
  - Answer: {on} (the lifted representation of the unachieved goal predicate)

- Concept: Planning programs with pointers
  - Why needed here: The entire framework operates on this program representation
  - Quick check question: In a program with maximum n lines, what is the maximum possible novelty rank for any action?
  - Answer: n + 1 (if the action appears in every line of the program)

## Architecture Onboarding

- Component map: Program generator -> Novelty rank calculator -> Helpful action calculator -> Evaluation function module -> Search controller
- Critical path: 1) Start with empty program Π 2) Generate new program states by adding actions 3) For each new state, compute novelty ranks 4) Prune states where any action's rank > v 5) Compute evaluation function values 6) Select best state for expansion 7) Repeat until solution found or timeout
- Design tradeoffs: v bound (lower = more pruning but risk missing solutions; higher = less pruning but more search), evaluation functions (more complex = better guidance but higher computation), structural restrictions (improve efficiency but may complicate implementation)
- Failure signatures: No solution found with v=1 or v=2 (domain may require more action repetitions than allowed), very slow search even with pruning (evaluation functions may not be guiding effectively), memory issues (program states may still be too large despite pruning)
- First 3 experiments: 1) Verify novelty rank computation on simple programs with known action distributions 2) Test pruning with v=1 on a domain known to require multiple action occurrences (like Fibonacci) 3) Compare search efficiency with and without helpful action pruning on a domain with clear irrelevant actions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of novelty-based search in GP scale with increasing problem complexity and domain size?
- Basis in paper: [inferred] The paper demonstrates novelty-based methods' effectiveness in standard benchmarks but does not analyze scalability to more complex problems.
- Why unresolved: The experiments focus on standard benchmarks without exploring how performance changes with problem complexity or domain size.
- What evidence would resolve it: Systematic experiments testing BFS(v) and PGP(v) on increasingly complex problems and larger domains, measuring runtime and solution quality.

### Open Question 2
- Question: Can the concept of lifted helpful actions be extended to more complex planning domains beyond STRIPS, such as those with numerical fluents or conditional effects?
- Basis in paper: [explicit] The paper introduces lifted helpful actions for STRIPS domains and mentions that numeric domains are precondition-free, implying limitations.
- Why unresolved: The paper does not explore the applicability of lifted helpful actions in domains with more complex features.
- What evidence would resolve it: Experiments applying lifted helpful actions to a variety of complex planning domains and comparing their performance with standard methods.

### Open Question 3
- Question: How do different novelty-based search strategies from classical planning, such as approximate novelty search, impact the performance of GP algorithms?
- Basis in paper: [explicit] The paper mentions that other novelty-based search strategies proposed for classical planning could be adopted in GP research.
- Why unresolved: The paper does not implement or evaluate alternative novelty-based search strategies in the context of GP.
- What evidence would resolve it: Implementing and testing various novelty-based search strategies in GP algorithms and comparing their performance with the current approach.

## Limitations
- Potential incompleteness when v is too low for domains requiring repeated action patterns
- Reliance on specific program representations that may not generalize to other GP frameworks
- Computational overhead from landmark extraction and evaluation function calculations

## Confidence
- Action novelty rank pruning mechanism: Low confidence due to lack of external validation and limited benchmark diversity
- Lifted helpful actions and evaluation functions: Medium confidence as they build on established concepts but specific implementations lack independent verification
- Claim that v ≤ 2 maintains completeness: Low confidence due to empirical rather than theoretical support

## Next Checks
1. **Theoretical completeness analysis**: Formally prove or disprove that BFS(v) with v ≤ 2 maintains completeness for STRIPS domains, identifying specific conditions under which pruning preserves solution paths.

2. **Cross-framework validation**: Implement novelty-based pruning in an alternative GP framework (e.g., LTLMoP or ARGoS) to test whether the approach generalizes beyond the specific program representation used in the paper.

3. **Scalability stress test**: Create synthetic generalized planning problems with increasing instance counts and complexity to empirically determine the upper bounds of v where pruning remains beneficial versus when it causes overhead that outweighs its benefits.