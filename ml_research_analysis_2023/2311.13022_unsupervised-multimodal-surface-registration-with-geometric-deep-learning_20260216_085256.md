---
ver: rpa2
title: Unsupervised Multimodal Surface Registration with Geometric Deep Learning
arxiv_id: '2311.13022'
source_url: https://arxiv.org/abs/2311.13022
tags:
- registration
- network
- cortical
- surface
- geomorph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents GeoMorph, a novel geometric deep learning framework
  for multimodal cortical surface registration. The method employs MoNet-based graph
  convolutions to extract low-dimensional features from input surfaces, followed by
  deep-discrete registration to optimize control point displacements.
---

# Unsupervised Multimodal Surface Registration with Geometric Deep Learning

## Quick Facts
- arXiv ID: 2311.13022
- Source URL: https://arxiv.org/abs/2311.13022
- Authors: 
- Reference count: 40
- Key outcome: Novel geometric deep learning framework for multimodal cortical surface registration achieving comparable performance to classical methods with significantly reduced computation time

## Executive Summary
This paper presents GeoMorph, a geometric deep learning framework for multimodal cortical surface registration that combines MoNet-based graph convolutions with deep-discrete registration and CRF-RNN regularization. The method extracts low-dimensional features from input surfaces, optimizes control point displacements through deep-discrete registration, and ensures smooth deformations using a CRF-RNN network. GeoMorph demonstrates superior performance on univariate sulcal depth alignment with lower areal distortions compared to existing deep learning methods, while achieving comparable results to classical MSMAll for multimodal registration with significantly reduced computation time.

## Method Summary
GeoMorph employs a two-stage pipeline for cortical surface registration: feature extraction using MoNet graph convolutions and deep-discrete registration with control points. The framework first learns low-dimensional feature representations through a series of MoNet convolutional blocks, then classifies these features to obtain initial control point displacements using a ResNet-inspired classifier network. A CRF-RNN network with mean-field iterations regularizes the deformation field to ensure smoothness and biological plausibility. The unsupervised loss function combines similarity and smoothness terms, optimized through ADAM training. The method operates on spherical representations using icospheres with 2542 control points and supports both univariate (sulcal depth) and multimodal (myelin maps, resting-state fMRI) registration.

## Key Results
- Achieved CC similarity of 0.875 for sulcal depth alignment with lower areal distortions (95th percentile: 0.53 vs 0.82) compared to existing deep learning methods
- Demonstrated improved alignment quality for multimodal registration using myelin and resting-state fMRI features over unimodal approaches
- Achieved comparable performance to classical MSMAll framework while significantly reducing computation time
- Successfully validated across two large datasets (HCP with 1110 subjects and UK Biobank with 3000 subjects)

## Why This Works (Mechanism)

### Mechanism 1
The combination of MoNet graph convolutions and deep-discrete registration enables accurate alignment of cortical surfaces with large deformations. MoNet graph convolutions use Gaussian mixture models to achieve rotational equivariance, critical for spherical data, while deep-discrete registration solves a multi-label classification problem at the control point level, allowing for large deformations without computational constraints of classical discrete frameworks.

### Mechanism 2
The deep CRF-RNN network ensures smooth and biologically plausible deformations by encouraging neighboring control points to deform similarly. This network implements a deep conditional random field using a recurrent neural network, updating the deformation field in a way that ensures smoothness by forcing neighboring points to deform similarly based on learned label compatibility functions and Gaussian kernels.

### Mechanism 3
The feature extraction network enables compact, low-dimensional representation of input features, fundamental to multimodal alignment. Using a series of MoNet convolutional blocks, the network learns low-dimensional feature representations for each input surface, which are then concatenated and passed to the classifier network. This compact representation allows for weighting of different input features according to their significance.

## Foundational Learning

- **Graph convolutions on non-Euclidean domains**: Cortical surfaces are inherently non-Euclidean, and traditional convolutional networks are not directly applicable. Graph convolutions allow for the extraction of features from these complex surfaces. *Quick check: What is the key difference between graph convolutions and traditional convolutions in the context of cortical surface registration?*

- **Spherical geometry and topology**: Cortical surfaces are typically represented as meshes on a sphere, and understanding spherical geometry is crucial for developing effective registration algorithms. *Quick check: How does the topology of a sphere differ from that of a plane, and why is this important for cortical surface registration?*

- **Deep-discrete registration and multi-label classification**: Deep-discrete registration allows for large deformations without the computational constraints of classical discrete frameworks, and multi-label classification enables efficient optimization of control point displacements. *Quick check: What are the advantages of deep-discrete registration over classical discrete registration methods in the context of cortical surface alignment?*

## Architecture Onboarding

- **Component map**: Feature extraction network (MoNet graph convolutions) -> Classifier network (ResNet-inspired blocks) -> CRF-RNN network (deep conditional random field) -> Loss function (similarity and smoothness terms)

- **Critical path**: 1) Extract low-dimensional features from input surfaces using the feature extraction network, 2) Classify the extracted features to obtain initial control point displacements using the classifier network, 3) Regularize the deformation field to ensure smoothness and biological plausibility using the CRF-RNN network, 4) Optimize the network parameters using the unsupervised loss function

- **Design tradeoffs**: Resolution of control points vs. computational efficiency, Regularization strength vs. alignment accuracy, Feature dimensionality vs. representation capacity

- **Failure signatures**: High distortion in the resulting deformation field, Poor alignment of cortical features, Over-smoothing or under-smoothing of deformations

- **First 3 experiments**: 1) Train the network on a single subject using sulcal depth features and evaluate the alignment quality and distortion measures, 2) Compare the performance of GeoMorph with existing deep learning methods (e.g., S3Reg) on unimodal registration tasks, 3) Evaluate the benefits of multimodal registration by comparing GeoMorphAll with unimodal approaches and classical frameworks (e.g., MSMAll) on multimodal registration tasks

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed CRF-RNN regularization compare to other regularization techniques in terms of preserving biologically plausible deformations while allowing topology-breaking transformations? The current CRF-RNN implementation has proven beneficial in regularizing the deformation field, but the paper acknowledges the potential for other regularization techniques to further improve performance. Comparative experiments evaluating different regularization techniques (e.g., CRF-RNN, mechanically learnable penalties) on their ability to preserve biologically plausible deformations while allowing topology-breaking transformations would resolve this question.

### Open Question 2
How would the performance of GeoMorph change if it were implemented using a spectral learning framework such as S2CNN, which learns fully expressive, rotation-equivariant convolutions for the sphere? The current implementation of GeoMorph is based on MoNet convolutions, which somewhat limit the expressivity of the features derived from the network. S2CNN could potentially provide more expressive features and improve performance. Comparative experiments evaluating the performance of GeoMorph implemented with MoNet convolutions versus S2CNN convolutions would resolve this question.

### Open Question 3
How would the computational efficiency of GeoMorph change if it were implemented using a more efficient method to overcome the memory constraints associated with high-resolution control point grids? The current implementation of GeoMorph is limited to a control grid on an icosphere of level 4 due to memory constraints, which may impact the accuracy of the registration. More efficient methods could allow for higher resolution control grids and potentially improve performance. Experiments evaluating the computational efficiency and registration performance of GeoMorph implemented with different methods for handling high-resolution control point grids would resolve this question.

## Limitations
- Framework performance depends heavily on quality and resolution of input features, with potential degradation when working with lower-quality or multimodal data
- Substantial computational resources required for training, particularly for high-resolution meshes and multimodal feature integration
- Current implementation focuses on spherical representations, limiting direct applicability to native geometry or other surface parameterizations

## Confidence
- **High confidence**: Sulcal depth alignment performance and runtime efficiency improvements compared to classical methods
- **Medium confidence**: Multimodal registration results, as validation relies on indirect measures (task fMRI cluster mass) rather than ground truth alignment
- **Medium confidence**: Generalization across different feature types, given most experiments use HCP-style features with limited testing on other modalities

## Next Checks
1. Test cross-dataset generalization by training on HCP and validating on UK Biobank or other independent datasets with different acquisition parameters
2. Evaluate sensitivity to control point resolution by systematically varying the mesh density and measuring impact on alignment quality and runtime
3. Validate biological plausibility of deformations by comparing with independent measures of cortical organization and functional connectivity patterns