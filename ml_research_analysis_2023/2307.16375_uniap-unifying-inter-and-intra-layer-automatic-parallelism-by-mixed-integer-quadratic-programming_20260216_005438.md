---
ver: rpa2
title: 'UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer
  Quadratic Programming'
arxiv_id: '2307.16375'
source_url: https://arxiv.org/abs/2307.16375
tags:
- parallelism
- uniap
- strategy
- training
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: UniAP is the first method to unify inter- and intra-layer automatic
  parallelism by mixed integer quadratic programming. It simultaneously optimizes
  pipeline parallelism, data parallelism, tensor parallelism, and fully sharded data
  parallelism to find the globally optimal solution.
---

# UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming

## Quick Facts
- arXiv ID: 2307.16375
- Source URL: https://arxiv.org/abs/2307.16375
- Reference count: 40
- Key outcome: UniAP achieves up to 3.80× higher throughput and reduces strategy search time by up to 107× compared to state-of-the-art methods.

## Executive Summary
UniAP is the first method to unify inter- and intra-layer automatic parallelism by mixed integer quadratic programming (MIQP). It simultaneously optimizes pipeline parallelism, data parallelism, tensor parallelism, and fully sharded data parallelism to find globally optimal solutions for distributed training of large deep learning models. By formulating the automatic parallelism problem as a single MIQP that minimizes time-per-iteration subject to memory constraints, UniAP discovers hybrid strategies that balance communication costs across different interconnects and memory constraints.

## Method Summary
UniAP unifies inter-layer and intra-layer automatic parallelism through a mixed integer quadratic programming approach. The method profiles runtime information including communication efficiency, computation time, memory consumption, and overlap coefficient. It then estimates inter- and intra-layer costs using these profiles and formulates an MIQP problem to maximize throughput. The unified optimization process (UOP) systematically enumerates pipeline stages and chunk sizes, using QIP for intra-layer-only cases and MIQP for combined cases. The approach guarantees optimality by exploring the entire combined strategy space and returns the optimal pipeline degree, chunk size, layer placement, and intra-layer strategies.

## Key Results
- Achieves up to 3.80× higher training throughput compared to state-of-the-art methods
- Reduces strategy search time by up to 107× through efficient optimization
- Demonstrates near-linear scalability with increasing number of nodes

## Why This Works (Mechanism)

### Mechanism 1
Mixed Integer Quadratic Programming (MIQP) finds globally optimal parallelism strategy by encoding both inter- and intra-layer costs in a unified formulation. The solver guarantees optimality by exploring the entire combined strategy space, assuming the computational cost model accurately estimates real-world execution time and memory usage.

### Mechanism 2
Unified strategy space enables discovery of parallelism combinations that separate methods miss. By simultaneously optimizing pipeline parallelism, data parallelism, tensor parallelism, and FSDP in one formulation, UniAP can find hybrid strategies that balance communication costs across different interconnects and memory constraints.

### Mechanism 3
Unified optimization process (UOP) efficiently explores the strategy space by enumerating pipeline stages and chunk sizes. The systematic approach varies pipeline degrees and chunk sizes, using QIP for intra-layer-only cases and MIQP for combined cases, ensuring all combinations are evaluated while pruning invalid configurations early.

## Foundational Learning

- Concept: Mixed Integer Quadratic Programming
  - Why needed here: Provides mathematical framework to encode complex parallelism optimization with both discrete (layer placement) and continuous (cost estimation) variables while guaranteeing optimality.
  - Quick check question: How does MIQP differ from standard integer programming in handling the quadratic objective function?

- Concept: Contiguity constraint in pipeline partitioning
  - Why needed here: Ensures that layers assigned to the same pipeline stage form a contiguous subgraph, preventing disordered assignment that would break model execution.
  - Quick check question: Why can't we allow non-contiguous layer assignments in pipeline parallelism?

- Concept: Computation-communication overlap modeling
  - Why needed here: Accurately estimates effective execution time by accounting for parallel computation and communication operations, which is crucial for correct TPI calculation.
  - Quick check question: How does the overlap coefficient affect the estimation of communication time in the cost model?

## Architecture Onboarding

- Component map: Profiling module -> Cost model -> MIQP formulation engine -> Unified optimization process -> Solution interpreter
- Critical path: Profiling → Cost Modeling → MIQP Formulation → UOP Enumeration → Solver Execution → Strategy Interpretation
- Design tradeoffs: MIQP provides optimality guarantee but may be slower than heuristic methods; unified formulation enables better strategies but increases problem complexity
- Failure signatures: Out-of-memory errors during strategy execution indicate cost model underestimation; suboptimal throughput suggests solver time limits too restrictive or cost model inaccuracies
- First 3 experiments:
  1. Run UniAP on a small model (e.g., BERT-base) with known optimal strategy to validate correctness
  2. Compare UniAP strategy against baseline on different hardware configurations to test adaptability
  3. Stress test MIQP solver with larger models to identify scalability bottlenecks and tune solver parameters

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions but leaves several areas unexplored, including scalability to trillion-parameter models, handling dynamic changes in training environments, and the impact of different MIQP solver configurations on performance.

## Limitations
- Cost model accuracy: The paper relies heavily on profiling-based cost estimation but the specific formulas and assumptions are not fully detailed.
- Scalability concerns: While demonstrated on five models, the approach's scalability to much larger models (GPT-3 scale) is not addressed.
- Solver configuration: The impact of different MIQP solver configurations on solution quality and search time is not explored.

## Confidence
- High confidence: The core MIQP formulation and unified optimization process are well-explained and theoretically sound.
- Medium confidence: The claimed 3.80× throughput improvement and 107× reduction in search time are based on experiments with five specific models, but generalizability to other model architectures needs validation.
- Medium confidence: The comparison with Galvatron baseline is fair, but the specific implementation details and hyperparameters used for Galvatron are not fully disclosed.

## Next Checks
1. Reproduce the cost model accuracy by comparing estimated vs. actual memory consumption and execution time on a small model with known optimal strategy.
2. Test scalability by applying UniAP to progressively larger models (e.g., GPT-2, GPT-3 scale) and measuring solver time and memory usage.
3. Conduct ablation studies to quantify the contribution of each parallelism dimension (pipeline, data, tensor, FSDP) to the overall performance improvement.