---
ver: rpa2
title: Open-ended Commonsense Reasoning with Unrestricted Answer Scope
arxiv_id: '2310.11672'
source_url: https://arxiv.org/abs/2310.11672
tags:
- reasoning
- answer
- commonsense
- question
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles open-ended commonsense reasoning, where the
  model must answer questions without pre-defined answer candidates or a limited answer
  scope. The core challenge is the vast search space and the need for multi-hop reasoning.
---

# Open-ended Commonsense Reasoning with Unrestricted Answer Scope

## Quick Facts
- arXiv ID: 2310.11672
- Source URL: https://arxiv.org/abs/2310.11672
- Reference count: 7
- Primary result: Achieves up to 15% improvement in top-1 accuracy on open-ended commonsense reasoning tasks using iterative reasoning path retrieval from ConceptNet

## Executive Summary
This paper addresses the challenge of open-ended commonsense reasoning where models must answer questions without predefined answer candidates or limited answer scope. The proposed KEEP method leverages pre-trained language models to iteratively retrieve reasoning paths from ConceptNet, using these paths to both generate answers and provide justifications. The approach demonstrates significant performance improvements over existing methods on two benchmark datasets, achieving up to 15% improvement in top-1 accuracy while providing interpretable reasoning paths.

## Method Summary
KEEP tackles open-ended commonsense reasoning by iteratively retrieving reasoning paths from ConceptNet using pre-trained language models (PLMs). The method first extracts entities from questions and maps them to ConceptNet nodes, then expands a local subgraph through multi-hop neighbor exploration while PLMs score and prune irrelevant paths. A finetuning phase trains PLMs on knowledge graph-derived examples to enhance reasoning capability, followed by beam search for efficient answer prediction. The approach combines path retrieval, scoring, and answer generation in an iterative framework that can handle the vast search space without predefined answer candidates.

## Key Results
- Achieves up to 15% improvement in top-1 accuracy compared to baseline methods on CSQA and QASC datasets
- Demonstrates strong performance across multiple PLM architectures (RoBERTa-large, GPT-3, T5-3b, UnifiedQA, DeBERTa-v3-large, RelBERT)
- Provides valid reasoning paths for a high percentage of correct predictions, enabling interpretable results
- Ablation studies confirm the importance of both finetuning on knowledge graph examples and the use of reasoning paths for explanation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pre-trained language models (PLMs) can effectively prune irrelevant reasoning paths during iterative knowledge graph expansion
- Mechanism: PLMs score candidate reasoning paths using masked language modeling score, where higher scores indicate more relevant paths
- Core assumption: PLMs possess implicit commonsense knowledge that can distinguish relevant from irrelevant paths
- Evidence anchors:
  - [abstract] "Without pre-defining an answer scope or a few candidates, open-ended commonsense reasoning entails predicting answers by searching over an extremely large searching space."
  - [section 3.2] "To avoid searching exhaustively over the whole knowledge base, we leverage PLMs to formulate the overall search criteria."

### Mechanism 2
- Claim: Iterative reasoning path expansion with beam search efficiently finds precise answers in large knowledge graphs
- Mechanism: Starting from question entities, the method expands neighbors iteratively up to L hops, using beam search to keep only high-confidence paths
- Core assumption: The correct answer can be reached within L hops from question entities
- Evidence anchors:
  - [abstract] "Without pre-defining an answer scope or a few candidates, open-ended commonsense reasoning entails predicting answers by searching over an extremely large searching space."
  - [section 3.2] "However, expanding L-hops subgraph G_q from c_q is computationally prohibited."

### Mechanism 3
- Claim: Finetuning PLMs on knowledge graph-derived examples significantly improves reasoning capability for open-ended tasks
- Mechanism: The method constructs training examples by extracting reasoning paths between question entities and correct answers from knowledge graph
- Core assumption: Knowledge graph structure captures meaningful reasoning patterns that PLMs can learn to recognize
- Evidence anchors:
  - [abstract] "To further enhance the reasoning ability of the PLM, we propose to leverage task-agnostic reasoning paths extracted directly from the external knowledge base as training instances to finetune the PLM."
  - [section 3.3] "By correctly identifying the knowledge triplets on ConceptNet, we aim to let the PLM comprehend the latent logic behind each retrieved reasoning path."

## Foundational Learning

- Concept: Masked Language Modeling (MLM)
  - Why needed here: MLM scoring is used to evaluate reasoning path relevance by measuring how well the PLM can predict masked tokens in context
  - Quick check question: How does MLM scoring differ from standard language model probability calculation, and why is this distinction important for path evaluation?

- Concept: Knowledge Graph Reasoning
  - Why needed here: The method relies on traversing and extracting multi-hop reasoning paths from ConceptNet to support answer generation
  - Quick check question: What are the key differences between entity linking, relation extraction, and path reasoning in knowledge graph applications?

- Concept: Beam Search Algorithm
  - Why needed here: Beam search controls the expansion of reasoning paths by maintaining multiple high-scoring candidates at each step
  - Quick check question: How does beam width affect the trade-off between search completeness and computational efficiency in path finding?

## Architecture Onboarding

- Component map: Entity extraction → Local graph expansion → Iterative reasoning with PLM scoring → Answer prediction with beam search
- Critical path: Question processing → Entity linking → Multi-hop expansion → Path scoring → Answer selection
- Design tradeoffs: L-hop depth vs. computational cost, beam width vs. path diversity, finetuning vs. zero-shot performance
- Failure signatures: Low top-1 accuracy indicates path pruning issues, poor finetuned performance suggests overfitting, high computation time indicates inefficient expansion
- First 3 experiments:
  1. Evaluate MLM scoring effectiveness on simple reasoning paths vs. random paths
  2. Test different beam widths on a small knowledge graph subset
  3. Compare zero-shot vs. finetuned performance on held-out reasoning patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of KEEP scale with the size of the knowledge graph and the complexity of the reasoning paths?
- Basis in paper: [inferred] The paper mentions scalability issues with exhaustive multi-hop expansion on large knowledge graphs
- Why unresolved: The paper only experiments with a 3-hop reasoning path length and does not explore larger knowledge graphs
- What evidence would resolve it: Experiments evaluating KEEP's performance on larger knowledge graphs (e.g., full ConceptNet) and with longer reasoning paths would provide insights into its scalability

### Open Question 2
- Question: Can KEEP be effectively adapted to handle commonsense reasoning tasks in specialized domains that require domain-specific knowledge?
- Basis in paper: [inferred] The paper discusses the use of ConceptNet, a general-domain knowledge graph
- Why unresolved: The paper does not explore the effectiveness of KEEP on domain-specific commonsense reasoning tasks
- What evidence would resolve it: Experiments evaluating KEEP's performance on domain-specific datasets and investigating the impact of domain-specific knowledge graphs would provide insights into its applicability to specialized domains

### Open Question 3
- Question: How does the quality and relevance of the retrieved reasoning paths impact the final answer prediction?
- Basis in paper: [explicit] The paper discusses the importance of reasoning paths for explanation
- Why unresolved: The paper does not explore the relationship between reasoning path quality and answer prediction
- What evidence would resolve it: Experiments analyzing the correlation between reasoning path quality and answer prediction, as well as methods to assess and filter reasoning paths, would provide insights into improving performance and interpretability

## Limitations
- Method's effectiveness heavily depends on the quality of semantic mapping between question entities and ConceptNet nodes
- Iterative reasoning approach may struggle with complex multi-hop scenarios requiring longer reasoning chains than the L-hop constraint allows
- Finetuning approach on knowledge graph-derived examples might overfit to specific patterns in ConceptNet, limiting generalization

## Confidence

- High confidence: The overall iterative retrieval framework and beam search implementation are well-described and show consistent performance improvements
- Medium confidence: The finetuning approach's effectiveness is demonstrated through ablation studies, but specific training procedures need more investigation
- Low confidence: The exact mechanism of how PLMs score reasoning path relevance through masked language modeling is not fully detailed

## Next Checks

1. Test KEEP's performance on questions requiring more than L hops to verify whether the fixed depth constraint limits reasoning capability
2. Evaluate the finetuned model on held-out reasoning patterns from ConceptNet to assess overfitting risks
3. Compare path scoring effectiveness between zero-shot PLM evaluation and finetuned evaluation to isolate the contribution of task-specific fine-tuning