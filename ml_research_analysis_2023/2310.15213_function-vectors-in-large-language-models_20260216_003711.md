---
ver: rpa2
title: Function Vectors in Large Language Models
arxiv_id: '2310.15213'
source_url: https://arxiv.org/abs/2310.15213
tags:
- layer
- word
- number
- tasks
- gpt-j
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the concept of function vectors (FVs), which
  are compact vector representations of input-output tasks that can be extracted from
  autoregressive transformer language models. Using causal mediation analysis, the
  authors identify a small set of attention heads that transport FVs during in-context
  learning.
---

# Function Vectors in Large Language Models

## Quick Facts
- arXiv ID: 2310.15213
- Source URL: https://arxiv.org/abs/2310.15213
- Reference count: 40
- One-line primary result: Function vectors (FVs) are compact vector representations of input-output tasks that can be extracted from autoregressive transformer language models and used to trigger task execution in diverse contexts.

## Executive Summary
This paper introduces the concept of function vectors (FVs), which are compact vector representations of input-output tasks that can be extracted from autoregressive transformer language models. Using causal mediation analysis, the authors identify a small set of attention heads that transport FVs during in-context learning. They find that FVs are robust and can trigger task execution in diverse contexts, including zero-shot and natural text settings. The authors also investigate the internal structure of FVs and demonstrate that to some extent they can be composed to create vectors that trigger new complex tasks.

## Method Summary
The authors use causal mediation analysis to identify attention heads that transport function vectors during in-context learning. They extract FVs from these heads and add them to hidden states at specific layers to trigger task execution. They evaluate the robustness of FVs across diverse contexts and test their compositionality by combining FVs to create new complex tasks. The method involves implementing causal mediation analysis, extracting FVs, adding them to hidden states, and evaluating task performance in zero-shot and shuffled-label contexts.

## Key Results
- Function vectors are compact representations of input-output tasks that can be extracted from autoregressive transformer language models
- FVs are robust to changes in context and can trigger task execution in diverse settings including zero-shot and natural text
- FVs can be composed to some extent to create vectors that trigger new complex tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Function vectors are compact vector representations that can trigger task execution in diverse contexts
- Mechanism: Causal mediation analysis identifies a small set of attention heads that transport function vectors during in-context learning. These vectors can be extracted and added to hidden states to induce task performance
- Core assumption: The identified attention heads are causally responsible for task execution and their outputs can be summed to create a function vector
- Evidence anchors:
  - [abstract] "Using causal mediation analysis on a diverse range of in-context-learning (ICL) tasks, we find that a small number attention heads transport a compact representation of the demonstrated task, which we call a function vector (FV)."
  - [section 2.3] "We describe an activation patching procedure to determine the presence of a handful of attention heads that mediate many ICL tasks."
  - [corpus] Weak - the corpus provides some related papers but no direct evidence for this specific mechanism
- Break condition: If the attention heads identified by causal mediation analysis are not causally responsible for task execution, or if their outputs cannot be summed to create a function vector

### Mechanism 2
- Claim: Function vectors are portable across different contexts
- Mechanism: Function vectors extracted from one context can trigger task execution in diverse settings including zero-shot and natural text contexts
- Core assumption: The information encoded in function vectors is not context-dependent and can be applied to new situations
- Evidence anchors:
  - [abstract] "FVs are robust to changes in context, i.e., they trigger execution of the task on inputs such as zero-shot and natural text settings that do not resemble the ICL contexts from which they are collected."
  - [section 3.1] "We find that FVs are remarkably robust, typically triggering function execution even in contexts that bear no resemblance to the original ICL context."
  - [corpus] Weak - the corpus provides some related papers but no direct evidence for this specific mechanism
- Break condition: If function vectors extracted from one context cannot trigger task execution in diverse settings

### Mechanism 3
- Claim: Function vectors can be composed to create new complex tasks
- Mechanism: Function vectors obey vector algebra compositions, allowing simple functions to be combined into more complex ones
- Core assumption: The space of function vectors has its own vector algebra over functions rather than words
- Evidence anchors:
  - [abstract] "we test semantic vector composition in FVs, and find that to some extent they can be summed to create vectors that trigger new complex tasks."
  - [section 3.3] "We construct a set of composable ICL tasks, and we test the ability of FVs to obey vector algebra compositions."
  - [corpus] Weak - the corpus provides some related papers but no direct evidence for this specific mechanism
- Break condition: If function vectors cannot be composed to create new complex tasks, or if the composition does not obey vector algebra

## Foundational Learning

- Concept: Causal mediation analysis
  - Why needed here: Used to identify the attention heads that transport function vectors during in-context learning
  - Quick check question: What is the difference between causal mediation analysis and other methods for identifying important model components?

- Concept: In-context learning (ICL)
  - Why needed here: The mechanism by which language models learn to perform tasks from examples in the prompt
  - Quick check question: How does in-context learning differ from traditional supervised learning?

- Concept: Vector algebra
  - Why needed here: Used to compose function vectors and create new complex tasks
  - Quick check question: What are the properties of vector algebra that make it useful for composing function vectors?

## Architecture Onboarding

- Component map: Attention heads -> Function vectors -> Hidden states
- Critical path: Causal mediation analysis to identify attention heads -> Extract function vectors -> Add FVs to hidden states to trigger task execution
- Design tradeoffs: The tradeoff is between the number of attention heads used to create the function vector and the performance of the function vector. Using more heads may improve performance but also increase complexity.
- Failure signatures: If the function vectors do not trigger task execution in diverse contexts, or if they cannot be composed to create new complex tasks, this indicates a failure in the mechanism.
- First 3 experiments:
  1. Identify the attention heads that transport function vectors using causal mediation analysis
  2. Extract function vectors from those attention heads and test their ability to trigger task execution in diverse contexts
  3. Compose function vectors to create new complex tasks and test their performance

## Open Questions the Paper Calls Out

- Question: How does the internal structure of function vectors vary across different types of tasks (e.g., cyclic vs. non-cyclic)?
  - Basis in paper: [inferred] The paper notes that function vectors cannot always be reconstructed from their top decoded tokens and that they contain essential information beyond simple word embeddings. It also mentions that cyclic tasks like antonyms cannot be represented as simple semantic vector offsets.
  - Why unresolved: The paper does not provide a detailed analysis of the internal structure of function vectors across different task types, leaving open questions about the specific information they encode.
  - What evidence would resolve it: A systematic analysis of the internal structure of function vectors across a diverse set of tasks, including both cyclic and non-cyclic tasks, would provide insights into their variations and commonalities.

- Question: Can function vectors be composed to create entirely new, more complex tasks beyond the examples provided in the paper?
  - Basis in paper: [explicit] The paper demonstrates that function vectors can be composed to some extent to create new complex tasks, but it also notes that not all tasks are easily composable.
  - Why unresolved: The paper provides limited examples of task composition and does not explore the full potential or limitations of composing function vectors to create entirely new tasks.
  - What evidence would resolve it: Further experimentation with a wider range of tasks and more complex compositions would reveal the extent to which function vectors can be used to create new, nontrivial tasks.

- Question: How do function vectors interact with different language model architectures and sizes?
  - Basis in paper: [explicit] The paper tests function vectors across different models (GPT-J, GPT-NeoX, Llama 2) and sizes, finding consistent patterns in their behavior. However, it does not explore the nuances of these interactions in depth.
  - Why unresolved: While the paper provides some evidence of consistent behavior across models and sizes, it does not delve into the specific ways in which function vectors interact with different architectures or how their effectiveness might scale with model size.
  - What evidence would resolve it: A comprehensive study of function vectors across a broader range of architectures and sizes, including detailed analysis of their interactions and scaling behavior, would provide a clearer understanding of their generalizability.

## Limitations

- The exact implementation details and hyperparameters of the causal mediation analysis and FV extraction process are not specified
- The paper provides limited examples of task composition and does not explore the full potential or limitations of composing function vectors to create entirely new tasks
- While the paper tests function vectors across different models and sizes, it does not explore the nuances of these interactions in depth

## Confidence

- **High Confidence**: The existence of FVs and their ability to trigger task execution in diverse contexts (zero-shot and natural text settings). The evidence from causal mediation analysis and task performance evaluations is strong.
- **Medium Confidence**: The compositionality of FVs and their ability to create new complex tasks. While the vector algebra experiments are promising, the extent and limitations of FV compositionality require further investigation.
- **Low Confidence**: The exact mechanisms by which FVs are transported by attention heads and how they encode task information. The internal structure of FVs and their relationship to the model's internal representations are not fully understood.

## Next Checks

1. Reproduce Causal Mediation Analysis: Implement the causal mediation analysis to identify influential attention heads and extract FVs. Verify that the identified heads are indeed causally responsible for task execution by ablating them and observing the impact on performance.

2. Evaluate FV Robustness Across Contexts: Test the robustness of FVs in a wider range of contexts, including different model architectures, task types, and input formats. Assess whether FVs maintain their effectiveness when transferred between models or when the input distribution changes.

3. Investigate FV Compositionality Limits: Systematically explore the limits of FV compositionality by testing combinations of FVs on increasingly complex tasks. Analyze the failure modes and identify the conditions under which compositionality breaks down.