---
ver: rpa2
title: 'Diversifying Deep Ensembles: A Saliency Map Approach for Enhanced OOD Detection,
  Calibration, and Accuracy'
arxiv_id: '2305.11616'
source_url: https://arxiv.org/abs/2305.11616
tags:
- detection
- ensemble
- sdde
- cation
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving deep ensemble diversity
  and out-of-distribution (OOD) detection by proposing Saliency Diversified Deep Ensemble
  (SDDE), a novel method that leverages saliency maps to encourage ensemble members
  to use different input features. The key innovation is a diversity loss function
  based on cosine similarity of Class Activation Maps (CAMs) that promotes feature
  diversity among models, combined with a logit-based aggregation method for improved
  OOD detection.
---

# Diversifying Deep Ensembles: A Saliency Map Approach for Enhanced OOD Detection, Calibration, and Accuracy

## Quick Facts
- arXiv ID: 2305.11616
- Source URL: https://arxiv.org/abs/2305.11616
- Reference count: 31
- Primary result: SDDE achieves state-of-the-art performance in classification accuracy, calibration metrics, and OOD detection across CIFAR-10, CIFAR-100, TinyImageNet, and MNIST benchmarks.

## Executive Summary
This paper introduces Saliency Diversified Deep Ensemble (SDDE), a novel method that improves deep ensemble diversity and out-of-distribution (OOD) detection by leveraging saliency maps. The key innovation is a diversity loss function based on cosine similarity of Class Activation Maps (CAMs) that encourages ensemble members to focus on different input features during training. Additionally, the paper proposes a logit-based aggregation method for OOD detection that outperforms traditional probability-based approaches. Experimental results demonstrate that SDDE consistently outperforms baseline ensemble methods across classification accuracy, calibration metrics, and OOD detection benchmarks.

## Method Summary
SDDE modifies standard deep ensemble training by adding a diversity loss term that minimizes cosine similarity between Class Activation Maps (CAMs) of ensemble members, forcing models to use different input features. The diversity loss is combined with cross-entropy loss during training. For OOD detection, SDDE uses a logit-based aggregation method (U_avg) that computes the average of raw logits across ensemble members, preserving information lost during softmax normalization. The method is evaluated on CIFAR-10, CIFAR-100, TinyImageNet, and MNIST datasets using ResNet18 and LeNet architectures.

## Key Results
- SDDE achieves state-of-the-art classification accuracy on CIFAR-10, CIFAR-100, TinyImageNet, and MNIST benchmarks.
- SDDE demonstrates superior calibration performance with lower NLL, ECE, and Brier scores compared to baseline methods.
- SDDE outperforms baseline ensemble methods (Deep Ensembles, NCL, ADP, DICE) in OOD detection AUROC scores across multiple benchmarks.
- Logit-based aggregation (U_avg) consistently outperforms probability-based aggregation methods for OOD detection.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SDDE improves ensemble diversity by directly diversifying input features through saliency map regularization.
- Mechanism: The diversity loss minimizes cosine similarity between Class Activation Maps (CAMs) of ensemble members, forcing models to focus on different regions of the input image during training.
- Core assumption: Lower cosine similarity between CAMs correlates with models using different input features for prediction.
- Evidence anchors:
  - [abstract] "Our study introduces Saliency Diversified Deep Ensemble (SDDE), a novel approach that promotes diversity among ensemble members by leveraging saliency maps."
  - [section 3.1] "The idea behind SDDE is to make saliency maps of the models as different as possible... Models' similarity can be measured as a mean cosine similarity between their saliency maps."
- Break condition: If saliency maps don't reliably represent which features models use for prediction, the diversity loss won't achieve meaningful feature diversification.

### Mechanism 2
- Claim: Logit-based aggregation (U_avg) provides better OOD detection than probability-based aggregation.
- Mechanism: Softmax normalization discards information about the magnitude of logits, which contains valuable signal for distinguishing OOD samples from in-distribution samples.
- Core assumption: Raw logit magnitudes contain discriminative information for OOD detection that is lost after softmax transformation.
- Evidence anchors:
  - [section 3.2] "On the other hand, softmax activation loses some information about logits... We thus raise the question, of whether it is better to detect OOD data using probabilities or logits."
  - [abstract] "The proposed logit-based aggregation method (U_avg) is shown to be superior to traditional probability-based averaging for OOD detection."
- Break condition: If logit magnitude doesn't correlate with uncertainty or OOD likelihood, then logit-based aggregation won't improve OOD detection.

### Mechanism 3
- Claim: The combination of saliency diversity loss and logit aggregation creates synergistic improvements in both accuracy and OOD detection.
- Mechanism: Feature diversification prevents models from learning redundant representations while logit aggregation preserves uncertainty information, together improving both in-distribution performance and OOD detection capability.
- Core assumption: The two improvements address complementary aspects of ensemble performance (feature diversity vs. confidence estimation).
- Evidence anchors:
  - [abstract] "SDDE consistently outperforms baseline ensemble methods including Deep Ensembles, NCL, ADP, and DICE across most benchmarks."
  - [section 5.2] "The distributions of cosine similarities are presented in Figure 3. It can be seen, that the baseline methods reduce similarity, compared to Deep Ensemble, but SDDE achieves the lowest cosine similarities among all methods."
- Break condition: If either component degrades the other's performance, the synergistic benefits would not materialize.

## Foundational Learning

- Concept: Deep ensemble training with independent model initialization
  - Why needed here: Understanding the baseline Deep Ensembles approach is essential to appreciate how SDDE modifies the training process.
  - Quick check question: What is the primary source of diversity in standard Deep Ensembles before applying SDDE modifications?

- Concept: Class Activation Maps (CAM) and GradCAM for saliency estimation
  - Why needed here: SDDE relies on GradCAM to compute saliency maps for the diversity loss function.
  - Quick check question: How does GradCAM differ from basic input gradient methods for computing saliency maps?

- Concept: Ensemble aggregation methods for uncertainty estimation
  - Why needed here: SDDE introduces new aggregation methods (particularly logit-based) for OOD detection.
  - Quick check question: What information is lost when converting logits to probabilities via softmax?

## Architecture Onboarding

- Component map: N independently initialized models -> GradCAM-based saliency map computation -> diversity loss (cosine similarity of CAMs) -> cross-entropy loss -> backpropagation -> logit-based aggregation for OOD detection
- Critical path: Forward pass → CAM computation → diversity loss → cross-entropy loss → backpropagation → OOD detection using logit aggregation
- Design tradeoffs: The diversity loss hyperparameter λ controls the trade-off between classification accuracy and ensemble diversity; higher values increase diversity but may reduce accuracy.
- Failure signatures: (1) High cosine similarity between CAMs despite diversity loss (indicates λ is too low or GradCAM implementation is incorrect), (2) Degraded classification accuracy (indicates diversity loss is too strong), (3) OOD detection performance similar to baselines (indicates logit aggregation isn't working as intended).
- First 3 experiments:
  1. Train a single model with GradCAM to verify saliency maps are being computed correctly and represent meaningful feature importance.
  2. Implement SDDE with λ=0 to confirm it behaves identically to standard Deep Ensembles before adding diversity regularization.
  3. Compare CAM cosine similarities between SDDE and Deep Ensembles on a validation set to verify diversity loss is working before evaluating full performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal diversity loss weight (λ) for different dataset characteristics and ensemble sizes?
- Basis in paper: [explicit] The paper notes that λ was set to 0.1 for MNIST and 0.005 for CIFAR10/100 and TinyImageNet, but does not explore systematic tuning or provide guidelines for selecting λ across different scenarios.
- Why unresolved: The paper only reports fixed values for specific datasets without analyzing the sensitivity of performance to λ or providing a principled method for selection.
- What evidence would resolve it: Systematic experiments varying λ across a wide range (e.g., 0.001 to 0.1) for different datasets, ensemble sizes, and model architectures, accompanied by guidelines or heuristics for λ selection.

### Open Question 2
- Question: How does the proposed saliency map diversification compare to other forms of model diversity, such as diversity in decision boundaries or hidden layer activations?
- Basis in paper: [explicit] The paper focuses on diversifying saliency maps but acknowledges that previous works have explored other forms of diversity (e.g., DICE focuses on bottleneck features, NCL on output probabilities).
- Why unresolved: The paper does not provide direct comparisons between saliency map diversity and other diversity mechanisms, nor does it analyze whether saliency map diversity captures complementary information to these other methods.
- What evidence would resolve it: Head-to-head comparisons of SDDE against other diversity-enforcing methods on the same benchmarks, with ablation studies isolating the contribution of saliency map diversity versus other diversity mechanisms.

### Open Question 3
- Question: Does the proposed logit-based aggregation method (U_avg) consistently outperform probability-based methods across different OOD detection scenarios, particularly for complex real-world datasets?
- Basis in paper: [explicit] The paper introduces and evaluates logit-based aggregation methods (U_l_avg, U_l_min, U_l_STD) and finds U_l_avg superior in their experiments, but the evaluation is limited to benchmark datasets.
- Why unresolved: The experiments focus on standard benchmark datasets, and the paper does not explore whether logit-based aggregation generalizes to more complex, real-world OOD detection scenarios with distribution shifts beyond the benchmarked cases.
- What evidence would resolve it: Extensive evaluation of logit-based aggregation on diverse real-world datasets with various types of distribution shifts, including domain adaptation scenarios and datasets with complex, multimodal OOD distributions.

## Limitations
- The paper relies on GradCAM saliency maps which may not perfectly capture feature importance used for prediction, though the empirical results suggest the approach is effective.
- The diversity loss hyperparameter λ requires careful tuning and the paper doesn't provide systematic guidelines for selecting optimal values across different scenarios.
- The evaluation is primarily limited to benchmark datasets, leaving questions about generalizability to more complex real-world OOD detection scenarios.

## Confidence
- **High confidence**: The empirical performance improvements on standard benchmarks (CIFAR-10/100, TinyImageNet) are well-documented with appropriate metrics.
- **Medium confidence**: The mechanism that saliency map diversity improves ensemble performance is plausible but not rigorously validated - the paper shows correlation but not causation.
- **Medium confidence**: Logit-based aggregation superiority is demonstrated empirically but the theoretical justification for why logits contain better OOD signal than probabilities needs further exploration.

## Next Checks
1. **CAM ablation study**: Train SDDE with alternative saliency methods (input gradients, attention maps) to verify that the specific choice of GradCAM isn't driving the diversity improvements.
2. **Diversity vs. accuracy tradeoff**: Systematically vary the diversity loss weight λ across a wider range to characterize the full performance landscape and identify optimal operating points.
3. **OOD detection ablation**: Compare SDDE's OOD performance against a baseline that uses only logit aggregation (without diversity loss) to isolate the contribution of each component.