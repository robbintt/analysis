---
ver: rpa2
title: 'Estimate-Then-Optimize versus Integrated-Estimation-Optimization versus Sample
  Average Approximation: A Stochastic Dominance Perspective'
arxiv_id: '2304.06833'
source_url: https://arxiv.org/abs/2304.06833
tags:
- optimization
- have
- where
- assumption
- stochastic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper compares three approaches to data-driven stochastic
  optimization: estimate-then-optimize (ETO), integrated-estimation-optimization (IEO),
  and sample average approximation (EO). When the model is correctly specified, ETO
  outperforms IEO and EO in terms of asymptotic regret, as measured by stochastic
  dominance.'
---

# Estimate-Then-Optimize versus Integrated-Estimation-Optimization versus Sample Average Approximation: A Stochastic Dominance Perspective

## Quick Facts
- arXiv ID: 2304.06833
- Source URL: https://arxiv.org/abs/2304.06833
- Reference count: 40
- Primary result: When the model is correctly specified, ETO outperforms IEO and EO in terms of asymptotic regret through stochastic dominance.

## Executive Summary
This paper establishes a theoretical framework for comparing three data-driven stochastic optimization approaches: estimate-then-optimize (ETO), integrated-estimation-optimization (IEO), and sample average approximation (EO). Through stochastic dominance analysis, the authors prove that when the underlying model is correctly specified, ETO achieves the best asymptotic performance due to maximum likelihood estimation providing the optimal parameter estimates. The performance ordering reverses under model misspecification, where IEO outperforms ETO. These results are demonstrated across unconstrained, constrained, and contextual optimization problems.

## Method Summary
The paper compares three approaches to data-driven stochastic optimization. ETO first estimates model parameters via maximum likelihood estimation, then solves the optimization problem using the estimated parameters. IEO integrates estimation and optimization by directly minimizing the empirical objective. EO uses sample average approximation of the expected cost. The performance comparison is conducted through asymptotic analysis of regret distributions, using stochastic dominance as the comparison criterion. Experiments are conducted on newsvendor and portfolio optimization problems with both simulated and real data.

## Key Results
- Under correct model specification, ETO achieves lower asymptotic regret than IEO and EO due to MLE providing minimum variance parameter estimates
- Under model misspecification, the performance ordering reverses with IEO outperforming ETO
- Stochastic dominance provides a stronger comparison framework than moment-based criteria, capturing the entire distribution of regrets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: When the model is correctly specified, ETO achieves lower asymptotic regret than IEO due to the use of maximum likelihood estimation, which provides the asymptotically best estimator according to the Cramer-Rao bound.
- Mechanism: The regret in correctly specified models behaves roughly like a quadratic form of the estimated parameters. Since MLE provides the minimum variance estimator asymptotically, ETO's parameter estimates lead to lower regret.
- Core assumption: The model class covers the ground truth distribution and the optimization problem satisfies first and second-order optimality conditions.
- Evidence anchors:
  - [abstract]: "ETO outperforms IEO and EO in terms of asymptotic regret, as measured by stochastic dominance. This is due to ETO's use of maximum likelihood estimation, which provides the asymptotically best estimator."
  - [section 4.3]: "The multivariate Cramer-Rao bound concludes that MLE provides the asymptotically best estimator in terms of the covariance, i.e., I−1 θ0 , which hints at the superiority of ETO over IEO."
  - [corpus]: Weak evidence - related papers discuss bias-variance tradeoffs but don't specifically address the ETO advantage under correct specification.
- Break condition: If the model is misspecified or if the optimization problem violates the required smoothness and optimality conditions.

### Mechanism 2
- Claim: When the model is misspecified, IEO outperforms ETO because IEO directly optimizes the empirical objective performance, while ETO's MLE estimates are biased toward the misspecified model.
- Mechanism: In misspecified models, the MLE estimates parameters that best fit the misspecified family, not the true distribution. IEO, by directly optimizing the empirical objective, can partially compensate for this misspecification.
- Core assumption: The model class does not cover the ground truth distribution.
- Evidence anchors:
  - [abstract]: "The performance ordering reverses when the model is misspecified."
  - [section 4.4]: "The relation of the three approaches completely reverses in the case of the misspecified model, compared to Theorem 2."
  - [corpus]: Weak evidence - related papers discuss local misspecification but don't specifically address the IEO advantage under misspecification.
- Break condition: If the misspecification is extreme enough that even IEO cannot find reasonable solutions, or if the optimization problem becomes ill-posed.

### Mechanism 3
- Claim: Stochastic dominance provides a stronger comparison criterion than mean or moment comparisons, allowing the paper to distinguish between approaches even when asymptotic regrets converge to zero.
- Mechanism: Stochastic dominance compares the entire distribution of regrets, not just moments. This allows the paper to show that one approach consistently produces lower regrets across all possible outcomes.
- Core assumption: The limiting distributions of regrets exist and can be characterized.
- Evidence anchors:
  - [abstract]: "This is due to ETO's use of maximum likelihood estimation, which provides the asymptotically best estimator. The performance ordering reverses when the model is misspecified."
  - [section 3.2]: "Stochastic dominance provides a strong sense of stochastic ordering between distributions, not only for any moments of the two random variables, but for their entire probability distributions."
  - [corpus]: Weak evidence - related papers discuss first-order stochastic dominance but don't specifically apply it to compare optimization approaches.
- Break condition: If the limiting distributions don't exist or if the problems become too complex for the stochastic dominance analysis to be tractable.

## Foundational Learning

- Concept: Maximum Likelihood Estimation (MLE) and its asymptotic properties
  - Why needed here: MLE provides the foundation for ETO's advantage in correctly specified models through the Cramer-Rao bound
  - Quick check question: What property of MLE makes it asymptotically optimal for parameter estimation?

- Concept: Stochastic Dominance
  - Why needed here: Provides the comparison framework that goes beyond moments to compare entire distributions of regrets
  - Quick check question: How does first-order stochastic dominance differ from comparing just the means of two random variables?

- Concept: Karush-Kuhn-Tucker (KKT) conditions and constraint qualification
  - Why needed here: Essential for extending the results to constrained optimization problems
  - Quick check question: What role do KKT conditions play in characterizing the optimality of constrained solutions?

## Architecture Onboarding

- Component map: Data generation -> Parameter estimation (MLE for ETO, empirical for IEO, sample average for EO) -> Optimization (separately for ETO, integrated for IEO and EO) -> Performance evaluation (regret calculation) -> Stochastic dominance comparison

- Critical path: 1) Generate data from ground truth distribution 2) Apply each optimization approach 3) Compute regrets for each approach 4) Analyze asymptotic distributions of regrets 5) Compare using stochastic dominance 6) Validate through experiments

- Design tradeoffs: Correct specification vs. model complexity, Computational efficiency vs. solution quality, Theoretical guarantees vs. practical implementation

- Failure signatures: Violations of smoothness conditions, Non-existence of limiting distributions, Extreme misspecification rendering all approaches ineffective

- First 3 experiments: 1) Unconstrained newsvendor problem with correctly specified Gaussian model 2) Constrained portfolio optimization with misspecified variance structure 3) Contextual newsvendor problem comparing different sample sizes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the results change when the ground truth distribution is heavy-tailed rather than Gaussian?
- Basis in paper: [inferred] The experiments assume Gaussian distributions, but the theory allows for more general conditions
- Why unresolved: The paper only tests Gaussian cases, and heavy-tailed distributions may violate regularity conditions or lead to different convergence rates
- What evidence would resolve it: Experiments comparing all three approaches under heavy-tailed ground truth distributions

### Open Question 2
- Question: What is the optimal trade-off between model misspecification and parameter estimation variance in finite samples?
- Basis in paper: [explicit] The conclusion mentions this could be important in practice but doesn't provide a formal analysis
- Why unresolved: The theoretical results are asymptotic and don't address finite-sample trade-offs between bias and variance
- What evidence would resolve it: A framework for selecting model complexity based on sample size and noise level

### Open Question 3
- Question: How do the results extend to non-smooth optimization problems?
- Basis in paper: [inferred] The theory relies on differentiability assumptions that may not hold in non-smooth settings
- Why unresolved: The smoothness assumptions are crucial for deriving asymptotic normality and quadratic approximations
- What evidence would resolve it: Analysis of the three approaches under non-smooth cost functions or constraints

### Open Question 4
- Question: What is the impact of computational error on the stochastic dominance ordering?
- Basis in paper: [explicit] The algorithms are allowed to have oP(n⁻¹) computation error
- Why unresolved: The theoretical results assume near-optimal solutions, but practical algorithms have non-negligible error
- What evidence would resolve it: Bounds on how computational error affects the regret distribution ordering

## Limitations

- The theoretical results are asymptotic and may not fully capture finite-sample behavior
- The analysis assumes smooth optimization problems with well-behaved constraints
- The performance gaps between approaches in real-world applications could be smaller than suggested by the asymptotic analysis

## Confidence

- High confidence: The asymptotic regret ordering in correctly specified models (ETO > IEO > EO) is well-supported by the Cramer-Rao bound and MLE properties
- Medium confidence: The reverse ordering under misspecification is theoretically sound but may depend on the severity and nature of misspecification
- Medium confidence: The stochastic dominance framework provides a rigorous comparison method, though its practical significance depends on the specific distributions involved

## Next Checks

1. **Finite-sample validation**: Conduct experiments with varying sample sizes (10, 50, 100, 500) to empirically verify the asymptotic ordering holds in practice and identify sample size thresholds where the theoretical advantages manifest

2. **Model misspecification severity**: Systematically vary the degree of misspecification (e.g., using distributions closer or farther from the assumed family) to quantify how severe misspecification must be before IEO outperforms ETO

3. **Constraint qualification robustness**: Test problems with different constraint structures (linear, convex nonlinear, non-convex) to verify that the KKT-based theoretical results extend beyond the specific cases analyzed