---
ver: rpa2
title: Enhancing Biomedical Lay Summarisation with External Knowledge Graphs
arxiv_id: '2310.15702'
source_url: https://arxiv.org/abs/2310.15702
tags:
- knowledge
- article
- text
- which
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first study on using knowledge graphs
  to enhance biomedical lay summarisation, addressing the challenge that source articles
  written for technical audiences lack the explanations and background information
  needed for lay summaries. The authors augment the eLife lay summarisation dataset
  with article-specific knowledge graphs containing structured information about biomedical
  concepts and their relationships, derived from the UMLS.
---

# Enhancing Biomedical Lay Summarisation with External Knowledge Graphs

## Quick Facts
- arXiv ID: 2310.15702
- Source URL: https://arxiv.org/abs/2310.15702
- Reference count: 27
- Primary result: Knowledge graph integration improves biomedical lay summarisation readability and concept explanation

## Executive Summary
This paper introduces the first study on using knowledge graphs to enhance biomedical lay summarisation, addressing the challenge that technical articles lack explanations needed for lay audiences. The authors augment the eLife lay summarisation dataset with article-specific knowledge graphs containing structured biomedical concepts and relationships derived from UMLS. They systematically investigate three distinct approaches for incorporating graph-based knowledge into summarisation models, finding that all three methods significantly improve readability and better explain technical concepts, with the document enhancement approach achieving the largest gains while maintaining factual correctness.

## Method Summary
The authors construct article-specific knowledge graphs using MetaMap to identify biomedical concepts from UMLS, then apply three methods to integrate this knowledge: 1) decoder cross-attention to graph embeddings using Graph Attention Networks, 2) document embedding enhancement by concatenating document and graph embeddings, and 3) article text augmentation by prepending extracted concept definitions to the input. They use Longformer Encoder-Decoder as the base model and evaluate performance using automatic metrics (ROUGE, BERTScore, FKGL, DCRS) and human evaluation for readability and factuality.

## Key Results
- All three knowledge graph integration methods significantly improve readability metrics compared to baseline
- Document embedding enhancement achieves the largest readability gains while maintaining factual correctness
- Knowledge graph augmentation leads to better explanation of technical concepts in generated summaries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decoder cross-attention to graph embeddings improves readability by forcing the model to attend to structured knowledge during generation
- Core assumption: The model can effectively integrate graph-based knowledge during decoding without losing document context
- Evidence anchors: Abstract and section descriptions of the decoder cross-attention approach
- Break condition: If graph attention overwhelms document context, causing factually incorrect or incoherent summaries

### Mechanism 2
- Claim: Document embedding enhancement improves readability by enriching the encoder output with graph-based knowledge
- Core assumption: Additional encoder layer can merge document and graph information without losing either source
- Evidence anchors: Abstract and section descriptions of document embedding concatenation
- Break condition: If scaling factor is too high, causing original document information loss and incoherent summaries

### Mechanism 3
- Claim: Article text augmentation improves readability by providing explicit definitions of key concepts
- Core assumption: Providing explicit definitions in input text leads to more readable summaries with better technical concept explanations
- Evidence anchors: Abstract and section descriptions of concept definition prepending
- Break condition: If prepended definitions are too long or misaligned with article content

## Foundational Learning

- Concept: Knowledge graphs and graph neural networks
  - Why needed here: Paper relies on constructing article-specific knowledge graphs and using GAT for graph embeddings
  - Quick check question: What is the difference between homogeneous and heterogeneous graphs, and which type is used in this paper?

- Concept: Encoder-decoder architecture and cross-attention
  - Why needed here: Experiments with three methods targeting distinct areas of encoder-decoder architecture
  - Quick check question: How does cross-attention work in a transformer decoder, and what is the difference between encoder and decoder cross-attention?

- Concept: Readability metrics and their calculation
  - Why needed here: Evaluates readability using FKGL, CLI, and DCRS metrics
  - Quick check question: How is the Flesch-Kincaid Grade Level calculated, and what does a lower score indicate?

## Architecture Onboarding

- Component map: Input → Encoder → Graph Component → Decoder → Output
- Critical path: Input → Encoder → Decoder → Output
  - Encoder processes article text, optionally enhanced with graph embeddings
  - Decoder generates summary, optionally attending to graph embeddings
- Design tradeoffs:
  - GAT adds computational overhead but enables structured knowledge leverage
  - Prepending definitions increases input length but provides explicit knowledge
  - Adding decoder cross-attention increases parameters and computational cost
- Failure signatures:
  - Factually incorrect summaries indicate misinterpreted graph knowledge or lost document context
  - Verbose or repetitive summaries indicate overwhelming graph knowledge during generation
- First 3 experiments:
  1. Train base Longformer model on eLife dataset to establish baseline
  2. Implement "article text augmentation" method and evaluate readability/factual correctness
  3. Implement "document embedding enhancement" method and compare to text augmentation

## Open Questions the Paper Calls Out

- Question: How would different knowledge graph construction methods compare to UMLS-based approach?
  - Basis in paper: Explicit statement about investigating additional graph representations
  - Why unresolved: Only one construction method investigated
  - What evidence would resolve it: Comparative experiments using different knowledge graph construction methods

- Question: What is the optimal balance between knowledge graph enhancement and maintaining original document information?
  - Basis in paper: Inferred from performance degradation when combining methods
  - Why unresolved: Shows excessive knowledge incorporation degrades performance but doesn't investigate optimal balance
  - What evidence would resolve it: Systematic ablation studies varying knowledge incorporation amounts

- Question: How do different decoder architectures perform when enhanced with knowledge graphs?
  - Basis in paper: Explicit statement about investigating integration into decoder-only models
  - Why unresolved: Only encoder-decoder models used
  - What evidence would resolve it: Experiments applying techniques to decoder-only models

## Limitations

- Knowledge graph construction relies on MetaMap/UMLS which may miss emerging terminology or domain-specific relationships
- Study focuses on single dataset and domain, limiting generalizability to other technical areas
- Computational overhead of knowledge graph integration may limit practical deployment for real-time applications

## Confidence

**High Confidence**: Knowledge graph integration methods are technically sound; all methods improve readability; document enhancement achieves largest gains while maintaining factual correctness

**Medium Confidence**: Knowledge graph augmentation leads to better technical concept explanation; eLife dataset is representative of biomedical challenges

**Low Confidence**: Methods would generalize to other domains; readability improvements translate to meaningful comprehension gains

## Next Checks

1. **Cross-domain validation**: Apply knowledge graph integration methods to different technical domains (e.g., computer science papers) to test generalizability

2. **Comprehension impact study**: Conduct user study measuring actual comprehension and retention among lay readers using summaries with and without knowledge graph augmentation

3. **Knowledge graph quality analysis**: Systematically evaluate impact of different knowledge graph construction approaches on summarisation quality using alternative filtering methods