---
ver: rpa2
title: 'Queer People are People First: Deconstructing Sexual Identity Stereotypes
  in Large Language Models'
arxiv_id: '2307.00101'
source_url: https://arxiv.org/abs/2307.00101
tags:
- words
- regard
- bias
- language
- outputs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated representational bias in large language
  models (LLMs) against queer people by analyzing how the models generate text about
  individuals with different sexual identities. The researchers used gender-neutral
  biographies as prompts, appending them with sexual identity trigger words (straight
  man, straight woman, gay man, lesbian woman) and control prompts without identity
  labels.
---

# Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models

## Quick Facts
- **arXiv ID**: 2307.00101
- **Source URL**: https://arxiv.org/abs/2307.00101
- **Reference count**: 13
- **Primary result**: LLM outputs for queer individuals exhibit lower regard scores compared to straight counterparts, with a post-hoc debiasing method successfully increasing queer-related output regard scores.

## Executive Summary
This study investigates representational bias in large language models (LLMs) against queer people by analyzing how models generate text about individuals with different sexual identities. Using gender-neutral biographies as prompts with sexual identity trigger words, researchers found measurable bias with lower regard scores for queer identities. The authors developed a post-hoc debiasing method based on chain-of-thought prompting and SHAP analysis that successfully increased regard scores while preserving semantic meaning, offering a promising direction for reducing bias in LLM-generated text.

## Method Summary
The researchers gender-neutralized biographies from the WikiBio dataset, then generated prompts by appending sexual identity trigger words (straight man, straight woman, gay man, lesbian woman) or using control prompts without identity labels. GPT-3.5 davinci generated text completions for these prompts. Outputs were analyzed using regard scores, word clouds, PMI, t-SNE visualizations, and cosine similarity. For debiasing, SHAP analysis identified low-regard words, and chain-of-thought prompting was used to rephrase sentences while preserving semantic meaning.

## Key Results
- LLM outputs for queer identities (gay men, lesbian women) showed significantly lower regard scores compared to straight identities and controls
- t-SNE visualizations and cosine similarity confirmed qualitative distinctiveness of queer identity outputs
- Post-hoc debiasing using SHAP analysis and chain-of-thought prompting increased regard scores for queer-related outputs while maintaining semantic meaning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs generate outputs reflecting heteronormative biases due to training data associations
- **Mechanism:** Training data contains more heterosexual references, leading to learned associations that produce lower regard for queer identities
- **Core assumption:** LLMs generate text based on learned associations from training data
- **Evidence anchors:** Regard scores show straight identities similar to controls while queer identities score significantly lower; web text exhibits social biases held by humans who created it
- **Break condition:** If training data were balanced for all sexual identities, this mechanism would not hold

### Mechanism 2
- **Claim:** SHAP analysis identifies words contributing to lower regard scores for targeted text modification
- **Mechanism:** SHAP values indicate word contributions to classifier output, enabling identification of low-regard words for replacement
- **Core assumption:** SHAP analysis accurately identifies words that contribute to lower regard scores
- **Evidence anchors:** SHAP analysis used to detect low-regard words for neural style transfer; SHAP word-level analysis found words driving sentences toward lower regard
- **Break condition:** If SHAP analysis fails to accurately identify low-regard words, this mechanism would not work

### Mechanism 3
- **Claim:** Chain-of-thought prompting enables generation of higher regard text while preserving semantic meaning
- **Mechanism:** LLM explains why certain words lower regard, then generates new text without those words while maintaining original meaning
- **Core assumption:** LLM can understand regard concept and generate semantically equivalent text while increasing regard
- **Evidence anchors:** Approach inspired by controllable debiasing methods; LLM queried for reasons why words lower regard, then prompted to rephrase while preserving meaning
- **Break condition:** If LLM fails to understand regard concept or cannot generate semantically equivalent text, this mechanism would fail

## Foundational Learning

- **Concept:** How LLMs learn from training data and implications for bias
  - **Why needed here:** To understand why LLMs exhibit heteronormative biases and how to address them
  - **Quick check question:** What is the primary source of bias in LLMs according to the paper?

- **Concept:** SHAP analysis and its application in identifying contributing features
  - **Why needed here:** To understand how SHAP is used to identify low-regard words for replacement
  - **Quick check question:** What does SHAP analysis reveal about the words that contribute to lower regard scores?

- **Concept:** Chain-of-thought prompting and its application in controlled text generation
  - **Why needed here:** To understand how chain-of-thought prompting enables generation of higher regard text while preserving semantic meaning
  - **Quick check question:** How does chain-of-thought prompting help in the debiasing process?

## Architecture Onboarding

- **Component map:** Data preprocessing (gender-neutralizing biographies) -> LLM component (generating text with identity trigger words) -> SHAP analysis component (identifying low-regard words) -> Chain-of-thought prompting component (generating higher regard text)
- **Critical path:** From input biography through all components to final debiased output
- **Design tradeoffs:** Post-hoc debiasing offers flexibility but may have performance limitations compared to training-time bias mitigation
- **Failure signatures:** Debiasing failure may result in outputs still containing low-regard words or losing semantic meaning
- **First 3 experiments:**
  1. Test system with simple biography, observe generated output with and without sexual identity trigger words
  2. Apply SHAP analysis to generated output, identify low-regard words
  3. Use chain-of-thought prompting to generate debiased version, compare to original

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What specific words or phrases in LLM outputs are primarily responsible for lower regard scores associated with queer identities?
- **Basis in paper:** Paper discusses using SHAP analysis to identify low-regard words and mentions words like "discrimination" and "challenges" lower regard score
- **Why unresolved:** Paper provides examples but doesn't comprehensively list all low-regard words or their relative impact across different queer identities
- **What evidence would resolve it:** Comprehensive analysis of SHAP values for all low-regard words across multiple outputs for each sexual identity trigger word, ranked by contribution to lowering regard score

### Open Question 2
- **Question:** How does debiasing method affect regard scores for identities beyond four studied (straight man, straight woman, gay man, lesbian woman)?
- **Basis in paper:** Paper acknowledges study focused on four specific identities due to computational constraints and does not explore other queer identities
- **Why unresolved:** Debiasing method's generalizability to other sexual and gender identities is not tested
- **What evidence would resolve it:** Applying debiasing method to LLM outputs generated using prompts with trigger words for other sexual and gender identities and measuring change in regard scores

### Open Question 3
- **Question:** What is long-term effectiveness of post-hoc debiasing method in maintaining high regard scores for queer-related outputs across different contexts and domains?
- **Basis in paper:** Paper demonstrates method's effectiveness in specific setting but does not discuss performance over time or in varied contexts
- **Why unresolved:** Study limited to specific dataset and prompt structure, does not test debiasing method's robustness or longevity
- **What evidence would resolve it:** Longitudinal studies applying debiasing method to LLM outputs in diverse domains and contexts, measuring regard scores over time to assess consistency and durability

## Limitations
- Regard classifier may have shortcut learning, incorrectly associating certain words with lower regard due to training data biases
- Gender-neutralization process may introduce artifacts that influence LLM outputs in ways not fully accounted for
- Effectiveness of debiasing approach is demonstrated but long-term stability and generalizability to other contexts remain unclear

## Confidence

- Heteronormative bias detection in LLM outputs: **High** - Multiple analytical methods converge on this finding
- SHAP-based identification of low-regard words: **Medium** - Effective but potentially capturing spurious correlations
- Chain-of-thought debiasing effectiveness: **Medium** - Quantitative improvements shown but qualitative assessment limited
- Generalizability of findings: **Low** - Results may be specific to chosen biographies, LLM configuration, and debiasing approach

## Next Checks

1. Validate the regard classifier on a manually annotated test set to confirm it measures genuine quality differences rather than spurious correlations with identity terms
2. Test the debiasing approach on biographies with different characteristics (occupation types, writing styles, lengths) to assess generalizability
3. Implement an ablation study comparing the chain-of-thought prompting approach against simpler debiasing methods to isolate the contribution of each component