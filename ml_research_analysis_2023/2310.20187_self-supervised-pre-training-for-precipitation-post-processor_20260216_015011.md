---
ver: rpa2
title: Self-Supervised Pre-Training for Precipitation Post-Processor
arxiv_id: '2310.20187'
source_url: https://arxiv.org/abs/2310.20187
tags:
- precipitation
- data
- learning
- pre-training
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a self-supervised pre-training approach for
  precipitation post-processing in numerical weather prediction (NWP) models. The
  method uses masked reconstruction on atmospheric physics variables to pre-train
  an encoder-decoder, followed by transfer learning for precipitation segmentation.
---

# Self-Supervised Pre-Training for Precipitation Post-Processor

## Quick Facts
- arXiv ID: 2310.20187
- Source URL: https://arxiv.org/abs/2310.20187
- Reference count: 34
- Key outcome: Self-supervised pre-training with masked reconstruction improves heavy rainfall prediction (over 10mm) compared to state-of-the-art methods like MetNet

## Executive Summary
This paper introduces a self-supervised pre-training approach for precipitation post-processing in numerical weather prediction models. The method uses masked reconstruction on atmospheric physics variables to pre-train an encoder-decoder, followed by transfer learning for precipitation segmentation. A heuristic continuous labeling scheme is introduced to handle class imbalance in rainfall data. Experiments on regional NWP data show improved performance in predicting heavy rainfall compared to state-of-the-art methods like MetNet.

## Method Summary
The approach combines self-supervised pre-training on masked atmospheric physics variables with transfer learning for precipitation segmentation. The method uses an InternImage encoder with DSK layers pre-trained via masked reconstruction (90% masking ratio) on 16 atmospheric variables from RDAPS-KIM data. This pre-trained encoder is then transferred to a UPerNet decoder for precipitation segmentation, using continuous probabilistic labeling to address class imbalance. The model is trained on 3km resolution RDAPS data with 5km QPE ground truth for the Korean Peninsula region.

## Key Results
- Improved CSI and F1 scores for heavy precipitation events (>10mm) compared to MetNet baseline
- 39.49% performance improvement at 27-hour forecast lead time
- Better robustness across different forecast lead times
- Effective handling of class imbalance through continuous labeling

## Why This Works (Mechanism)

### Mechanism 1
- Self-supervised pre-training on masked atmospheric physics variables improves precipitation segmentation by learning physical correlations among variables
- Randomly masking 90% of 3D atmospheric patches and reconstructing them forces the encoder to capture spatial-temporal relationships among physics variables, which transfer to precipitation prediction
- Atmospheric variables share redundant physical information, and learning their joint dynamics helps segment precipitation patterns
- Evidence: Pre-training on masked atmospheric variables with DSK layers for reconstruction
- Break condition: If atmospheric variables are independent or masking too aggressive destroys reconstruction signals

### Mechanism 2
- Continuous probabilistic labeling reduces class imbalance bias by smoothing hard labels based on rainfall density
- Instead of one-hot labels, probabilities are assigned continuously across rainfall thresholds, reducing the dominance of frequent low-intensity classes
- Class imbalance can be mitigated by making rare heavy rain events more prominent in the loss function
- Evidence: Continuous probability distribution based on precipitation density
- Break condition: If smoothing reduces discriminative power or introduces label noise

### Mechanism 3
- Transfer learning from pre-trained encoder to precipitation decoder leverages learned atmospheric representations for better segmentation
- Pre-trained encoder weights are frozen and used in a UPerNet decoder for precipitation segmentation, allowing domain adaptation
- Representations learned from atmospheric physics reconstruction are useful for precipitation prediction
- Evidence: Transfer learning from pre-trained encoder to UPerNet decoder
- Break condition: If pre-training domain is too different from precipitation segmentation

## Foundational Learning

- Concept: Masked autoencoding
  - Why needed here: Enables self-supervised learning without labeled precipitation data
  - Quick check question: What happens if masking ratio is too low or too high?

- Concept: Transfer learning
  - Why needed here: Leverages pre-trained atmospheric physics knowledge for precipitation prediction
  - Quick check question: Why freeze encoder weights during decoder training?

- Concept: Class imbalance handling
  - Why needed here: Heavy rain events are rare but critical; standard classification fails
  - Quick check question: How does continuous labeling differ from weighted cross-entropy?

## Architecture Onboarding

- Component map: Input (16 atmospheric variables) -> Patch embedding -> Masking -> Encoder (InternImage+DSK) -> Latent space -> Decoder (UPerNet) -> Segmentation

- Critical path: Input → Patch embedding → Masking → Encoder → Latent space → Decoder → Segmentation

- Design tradeoffs:
  - Masking ratio: Higher pre-training ratio (90%) improves reconstruction but may hurt transfer
  - Label smoothing: Reduces imbalance but may reduce classification sharpness
  - Patch size: Balances spatial resolution vs computational cost

- Failure signatures:
  - Poor reconstruction → Masking too aggressive or model capacity insufficient
  - Degraded segmentation → Encoder-decoder mismatch or insufficient fine-tuning
  - Overfitting on rare classes → Insufficient data augmentation or excessive label smoothing

- First 3 experiments:
  1. Vary masking ratio (50%, 75%, 90%) during pre-training and evaluate reconstruction loss
  2. Test continuous labeling with different smoothing parameters on class-balanced subset
  3. Compare frozen vs fine-tuned encoder during transfer learning on validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the continuous labeling scheme compare to other class imbalance mitigation techniques like focal loss or class weighting in precipitation forecasting?
- Basis in paper: The paper introduces a heuristic continuous labeling approach but doesn't compare to other techniques
- Why unresolved: Only compares continuous labeling to one-hot labeling within their proposed method
- What evidence would resolve it: Direct comparison of continuous labeling against focal loss, weighted cross-entropy, and other class imbalance methods

### Open Question 2
- Question: What is the optimal masking ratio for different atmospheric variables during self-supervised pre-training?
- Basis in paper: The paper uses a fixed 90% masking ratio but notes optimal masking depends on data redundancy
- Why unresolved: Study uses single masking ratio for all variables despite different physical information content
- What evidence would resolve it: Ablation studies varying masking ratios per variable or using adaptive masking

### Open Question 3
- Question: How does the transfer learning performance degrade as forecast lead time increases beyond 24 hours?
- Basis in paper: Tests lead times from 25-30 hours but only reports aggregate results
- Why unresolved: Provides overall performance but doesn't show how transfer learning effectiveness changes with lead time
- What evidence would resolve it: Detailed analysis of CSI/F1 score degradation across all lead times with statistical significance testing

## Limitations
- No ablation studies on masking ratios or pre-training duration
- Limited comparison with alternative imbalance handling methods
- No analysis of computational overhead versus accuracy gains

## Confidence
- High confidence in the general framework of self-supervised pre-training for atmospheric variables
- Medium confidence in the specific continuous labeling implementation and its superiority over alternatives
- Medium confidence in the reported performance improvements, pending verification of baseline implementations

## Next Checks
1. Implement and compare continuous labeling against weighted cross-entropy and focal loss on a class-balanced validation subset
2. Conduct ablation studies varying masking ratios (50%, 75%, 90%) and pre-training epochs to identify optimal parameters
3. Test the transfer learning setup with fine-tuned (vs frozen) encoder weights to quantify representation reuse benefits