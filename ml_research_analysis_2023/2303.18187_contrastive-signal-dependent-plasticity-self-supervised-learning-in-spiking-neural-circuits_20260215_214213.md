---
ver: rpa2
title: 'Contrastive-Signal-Dependent Plasticity: Self-Supervised Learning in Spiking
  Neural Circuits'
arxiv_id: '2303.18187'
source_url: https://arxiv.org/abs/2303.18187
tags:
- spiking
- learning
- neural
- layer
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces contrastive-signal-dependent plasticity,\
  \ a local, online learning rule for spiking neural networks that generalizes the\
  \ forward-forward learning framework to the spike domain. The method operates entirely\
  \ forward in time without feedback synapses, relying instead on local signals\u2014\
  bottom-up, top-down, and lateral\u2014to adjust synaptic weights."
---

# Contrastive-Signal-Dependent Plasticity: Self-Supervised Learning in Spiking Neural Circuits

## Quick Facts
- arXiv ID: 2303.18187
- Source URL: https://arxiv.org/abs/2303.18187
- Authors: 
- Reference count: 40
- Primary result: Achieved 2.54% and 8.86% classification errors on MNIST and K-MNIST respectively using biologically plausible spiking learning

## Executive Summary
This paper introduces contrastive-signal-dependent plasticity, a local, online learning rule for spiking neural networks that extends forward-forward learning to the spike domain. The method operates entirely forward in time without feedback synapses, using local signals—bottom-up, top-down, and lateral—to adjust synaptic weights through spike-level computations. A novel spiking classifier is integrated into the recurrent circuit to enable efficient classification without the expensive goodness search used in prior forward-forward approaches. The model achieves competitive classification performance on MNIST and K-MNIST datasets while maintaining biological plausibility.

## Method Summary
The method implements event-driven forward-forward (ED-FF) learning in recurrent spiking neural circuits with LIF neurons. Each layer maintains membrane potentials updated from bottom-up, top-down, and lateral inputs, generating spikes that drive activity traces. Local contrastive learning updates synaptic weights using combined signals from neighboring layers and the activity trace. A spiking classifier aggregates outputs across all layers for direct class prediction. Training uses mini-batches with Adam optimization, and classification performance is evaluated on MNIST and K-MNIST datasets.

## Key Results
- Achieved 2.54% classification error on MNIST and 8.86% on K-MNIST
- Learned representations form well-separated clusters in latent space (verified via t-SNE)
- Demonstrated effective reconstruction capabilities while maintaining competitive classification performance
- Outperformed other biologically plausible spiking learning rules while approaching rate-coded feedforward baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Local synaptic updates are computed without backpropagation by combining bottom-up, top-down, and lateral signals in a single forward pass.
- Mechanism: Each layer computes membrane potential from weighted sums of spiking inputs from below, above, and laterally, then derives error signal from difference between predicted and actual spike outputs.
- Core assumption: The combination of bottom-up, top-down, and lateral signals provides sufficient information for local credit assignment without global error backpropagation.
- Evidence anchors: Abstract states method operates "entirely forward in time without feedback synapses, relying instead on local signals"; section describes input from previous layer ℓ-1 and ℓ+1.
- Break condition: If any of three signal types is missing or corrupted, local updates may become unstable or fail to converge.

### Mechanism 2
- Claim: Spike activity traces enable spike-level learning by providing smoothed, rate-coded representation of spiking activity.
- Mechanism: Trace variable zℓ(t) is updated using exponential decay that smooths binary spike outputs, allowing learning rule to operate on continuous-valued signals derived from discrete spikes.
- Core assumption: Trace variable accurately captures effective firing rate needed for gradient-like updates while maintaining biological plausibility.
- Evidence anchors: Section describes "additional compartment into each neural layer that is responsible for maintaining what is called an activity variable trace"; mentions trace "smooths out sparse spike trains while still being biologically-plausible".
- Break condition: If trace time constant is too short, learning becomes unstable; if too long, temporal dynamics are lost.

### Mechanism 3
- Claim: Spiking classifier layer enables fast inference by avoiding per-class goodness searches used in traditional forward-forward approaches.
- Mechanism: Dedicated spiking classifier aggregates outputs from all layers and learns to directly predict class labels through local Hebbian updates, providing single inference step rather than iterating over all classes.
- Core assumption: Classifier can learn effective class boundaries despite being trained alongside generative layers rather than through separate optimization.
- Evidence anchors: Abstract mentions "novel spiking classifier is integrated into the recurrent circuit to enable efficient classification without the expensive goodness search"; section describes additional matrices containing generative synapses.
- Break condition: If classifier's learning rate is mismatched with other layers, it may dominate or be dominated by generative learning.

## Foundational Learning

- Concept: Contrastive learning with positive and negative samples
  - Why needed here: Local cost function requires distinguishing between positive (correct class) and negative (incorrect class) samples to compute meaningful error signals for weight updates
  - Quick check question: How does the system generate negative samples during training when labels are available?

- Concept: Spike-timing dependent plasticity (STDP) principles
  - Why needed here: Hebbian-like update rules follow STDP-inspired mechanisms where pre- and post-synaptic activities determine synaptic changes
  - Quick check question: What biological mechanism might implement the error signal δℓ(t) that scales synaptic updates?

- Concept: Leaky integrate-and-fire neuron dynamics
  - Why needed here: Neuron model provides temporal dynamics necessary for spike generation and membrane potential integration that learning rules depend on
  - Quick check question: How does the adaptive threshold mechanism in Equations 4 and 16 influence learning stability?

## Architecture Onboarding

- Component map: Input spikes → membrane potential integration → spike generation → activity trace update → error computation → synaptic updates → classifier prediction

- Critical path: Input spikes flow through membrane potential integration, generate spikes, update activity traces, compute errors, update synapses, and produce classifier predictions

- Design tradeoffs:
  - Spiking vs rate-coded: Spiking offers biological plausibility and energy efficiency but requires careful timing and trace management
  - Parallel vs sequential: Layer-wise parallelism enables faster computation but requires careful synchronization of lateral inhibition
  - Local vs global: Local updates avoid backpropagation but may converge more slowly than global optimization

- Failure signatures:
  - Exploding/vanishing traces: Activity traces growing unbounded or collapsing to zero
  - Oscillating weights: Synaptic updates causing weights to flip signs repeatedly
  - Poor classification: Classifier failing to separate classes despite good reconstruction

- First 3 experiments:
  1. Single layer MNIST classification with only bottom-up connections to verify basic learning
  2. Two-layer network with lateral inhibition to test competitive dynamics
  3. Full recurrent network with classifier to validate end-to-end performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the ED-FF learning rule be extended to handle more complex data types like natural images or video sequences without requiring additional preprocessing or inductive biases?
- Basis in paper: Authors mention that investigating how ED-FF would operate on more complex data like natural images and sequences is a potential direction for future work.
- Why unresolved: Current experimental results are limited to MNIST and K-MNIST datasets.
- What evidence would resolve it: Experimental results demonstrating ED-FF's performance on datasets like CIFAR-10, ImageNet, or video datasets like UCF101, showing competitive performance compared to other methods.

### Open Question 2
- Question: How can negative samples be generated in a self-supervised manner without relying on provided labels, making the ED-FF learning process fully self-contained?
- Basis in paper: Paper discusses this as a limitation, noting that ED-FF currently requires positive and negative samples for contrastive learning, and generating negative samples from sensory input alone is an open challenge.
- Why unresolved: Authors propose potential solutions like using predictive/generative synapses to produce data confabulations, but these approaches have implementation challenges.
- What evidence would resolve it: A working implementation of ED-FF that generates negative samples from input data alone, demonstrating stable learning and performance comparable to label-based contrastive approaches.

### Open Question 3
- Question: Can the ED-FF learning rule be modified to enforce Dale's Law (neurons are either excitatory or inhibitory) while maintaining its effectiveness?
- Basis in paper: Paper mentions that enforcing strictly positive synaptic values (consistent with Dale's Law) is a potential future direction, suggesting current implementation doesn't fully comply with this biological constraint.
- Why unresolved: Current implementation allows negative synaptic weights, which authors acknowledge is biologically unrealistic and propose potential solutions involving inhibitory neurons.
- What evidence would resolve it: A modified ED-FF implementation with strictly positive synaptic weights and separate inhibitory neurons that demonstrates similar or improved performance compared to the current version.

## Limitations
- Biological plausibility concerns regarding simultaneous integration of three distinct signal types in individual synapses
- Trace-based smoothing mechanism lacks direct experimental validation showing correspondence to actual neural processes
- Implementation details of how negative samples are generated during contrastive learning with available labels are not explicitly described

## Confidence
- Mechanism 1 (Local updates via multi-signal integration): Medium confidence
- Mechanism 2 (Trace-based learning): Medium confidence
- Mechanism 3 (Spiking classifier efficiency): Medium confidence

## Next Checks
1. Analyze the training implementation to confirm how negative samples are created during contrastive learning when ground truth labels are available
2. Systematically vary the trace time constant (τtr) and learning rates to determine their impact on classification accuracy and training stability
3. Compare the proposed method against additional spiking neural network approaches (e.g., SLAYER, SpikeGrad) to better contextualize the reported performance metrics