---
ver: rpa2
title: 'Categorical, Ratio, and Professorial Data: The Case for Reciprocal Rank'
arxiv_id: '2312.12672'
source_url: https://arxiv.org/abs/2312.12672
tags:
- mapping
- effectiveness
- serps
- have
- average
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The article argues that search engine results pages (SERPs) are
  categorical data and can be evaluated using any plausible categorical-to-numeric
  effectiveness mapping, provided the mapping reflects user behavior. It challenges
  the claim that effectiveness mappings must use uniformly spaced target points on
  the real line.
---

# Categorical, Ratio, and Professorial Data: The Case for Reciprocal Rank

## Quick Facts
- arXiv ID: 2312.12672
- Source URL: https://arxiv.org/abs/2312.12672
- Reference count: 2
- Primary result: SERP effectiveness scores are ratio scale data that can be meaningfully averaged regardless of whether mapped values are uniformly spaced

## Executive Summary
This paper challenges the conventional wisdom that search engine result pages (SERPs) must be evaluated using effectiveness mappings that produce evenly-spaced numeric values. The author argues that SERPs are categorical data that can be mapped to ratio scale numeric scores through effectiveness mappings like Reciprocal Rank (RR), Precision, Average Precision (AP), NDCG, or RBP. Crucially, the paper demonstrates that averaging these mapped scores is mathematically valid and meaningful even when the mapped values are not uniformly spaced on the real line, provided the mapping reflects user behavior. The work also contends that SERP effectiveness scores are ratio scale data, enabling meaningful ratio-based comparisons, and proposes using mapping-agnostic techniques like IPSO for system comparisons.

## Method Summary
The paper examines the fundamental nature of SERP evaluation by analyzing how categorical SERP data can be transformed into numeric scores through effectiveness mappings. The author reviews various mappings (RR, Precision, AP, NDCG, RBP) and their underlying user behavior assumptions, demonstrating that these mappings assign numeric values to SERPs without requiring uniform spacing. The method involves applying these mappings to convert binary relevance vectors into numeric scores, then computing averages or using IPSO techniques for system comparisons. The key insight is that the physical process of averaging numeric values (analogous to a balance beam with weights at various positions) does not require the values to be evenly spaced, only that they accurately reflect the categorical data they represent.

## Key Results
- SERP effectiveness scores are ratio scale data when mappings assign [0]k to zero, enabling meaningful ratio-based comparisons
- Averaging mapped SERP scores is valid regardless of whether mapped values are uniformly spaced on the real line
- The intervalization process proposed by Ferrante et al. undermines interpretability by destroying ratio-based relativities in effectiveness scores
- Mapping-agnostic techniques like IPSO can be used for system comparisons without requiring equi-interval scales

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SERP effectiveness scores are ratio scale data when mapped via effectiveness mappings that assign [0]k to zero
- Mechanism: The mapping process assigns zero to the absence of usefulness, creating a natural zero point. This enables ratio-based comparisons (e.g., "1.5 times larger") while preserving the categorical nature of SERPs
- Core assumption: The effectiveness mapping assigns [0]k to zero and the zero point represents true absence of usefulness
- Evidence anchors:
  - [abstract]: "The article also highlights that SERP effectiveness scores are ratio scale data, allowing for meaningful ratio-based comparisons."
  - [section 4]: "effectiveness mappings usually have a defined zero point, and hence effectiveness scores are ratio scale data."
- Break condition: If the mapping assigns a non-zero value to [0]k, or if the zero point does not represent absence of usefulness, the ratio scale property fails

### Mechanism 2
- Claim: Averaging mapped SERP scores is valid even when the mapped values are not uniformly spaced on the real line
- Mechanism: The averaging operation is performed on the numeric scores, not the categorical SERPs themselves. The physical analogy of a balance beam demonstrates that weights can be placed anywhere along the ruler, not just at equi-spaced tick points
- Core assumption: The mapping captures user behavior and the average is interpreted within the context of that mapping, not as a universal property
- Evidence anchors:
  - [abstract]: "It challenges the claim that effectiveness mappings must use uniformly spaced target points on the real line."
  - [section 2]: "Averaging numeric and monetary amounts is a routine operation... Those six "(a)"s are also the answers that I'm arguing for in this essay."
- Break condition: If the mapping does not reflect user behavior, or if the average is interpreted as a universal property rather than within the context of the mapping

### Mechanism 3
- Claim: The intervalization process proposed by Ferrante et al. undermines the interpretability of experimental results by distorting ratio-based relativities
- Mechanism: The intervalization process converts ratio scale values to ordinal ranks and then back to equi-interval values, destroying the original ratio-based relationships between scores
- Core assumption: The original ratio scale values represent user satisfaction and should be preserved for meaningful interpretation
- Evidence anchors:
  - [section 4]: "those ratio scale values are then being deliberately stripped of their ratio-based relativities (step 4)."
  - [section 4]: "Intervalization most certainly does not result in order-based, ratio-of-difference-based, or ratio-based score invariance across different effectiveness mappings."
- Break condition: If the goal is solely to compare systems and not to interpret absolute effectiveness scores, the intervalization process might be acceptable

## Foundational Learning

- Concept: Categorical vs. Ratio Data
  - Why needed here: The paper hinges on understanding that SERPs are categorical data that can be mapped to ratio scale data via effectiveness mappings
  - Quick check question: What is the key difference between categorical and ratio data, and how does an effectiveness mapping transform one into the other?

- Concept: Effectiveness Mappings and User Behavior
  - Why needed here: The paper argues that any effectiveness mapping can be used if it reflects user behavior, but not all mappings are equally valid
  - Quick check question: How does the choice of effectiveness mapping influence the interpretation of averaged scores, and what role does user behavior play in this choice?

- Concept: Interval Scales vs. Equi-Interval Scales
  - Why needed here: The paper distinguishes between interval scales (where ratios of differences are meaningful) and equi-interval scales (where the mapped values are uniformly spaced)
  - Quick check question: Why does the author argue that equi-interval spacing is not necessary for valid averaging of mapped SERP scores?

## Architecture Onboarding

- Component map: Effectiveness mapping → SERP abstraction → Numeric score → Averaged score → System comparison
- Critical path: SERP abstraction → Effectiveness mapping → Numeric score (ratio scale property established here)
- Design tradeoffs: Tradeoff between using a simple mapping (like RR) that may be less discriminative vs. a more complex mapping (like NDCG) that may be more discriminative but harder to interpret
- Failure signatures: Averaging scores from different mappings without considering their distinct user models; interpreting averaged scores as universal properties rather than within the context of the mapping
- First 3 experiments:
  1. Apply RR and NDCG to the same set of SERPs and compare the averaged scores. Observe how the choice of mapping affects the results
  2. Use a mapping that does not assign zero to [0]k and attempt to compute ratio-based comparisons. Observe the failure of the ratio scale property
  3. Implement the intervalization process proposed by Ferrante et al. and compare the results to the original ratio scale scores. Observe the distortion of ratio-based relativities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can any categorical-to-numeric effectiveness mapping be used for SERP evaluation, provided it is argued to reflect user behavior?
- Basis in paper: [explicit] The author argues that any mapping can be used if it is plausibly connected to user behavior and SERP "benefit to user"
- Why unresolved: The paper presents opposing views on this issue, with some researchers claiming that mappings must use uniformly spaced target points
- What evidence would resolve it: Empirical studies comparing the performance of different effectiveness mappings in real-world search scenarios, demonstrating whether non-uniform mappings lead to meaningful and interpretable results

### Open Question 2
- Question: Are SERP effectiveness scores interval scale data, allowing for meaningful averaging and comparison?
- Basis in paper: [explicit] The author argues that SERP scores are ratio scale data, allowing for meaningful ratio-based comparisons, while others claim they are interval scale data
- Why unresolved: There is ongoing debate about the appropriate scale of measurement for SERP scores, with implications for how they can be analyzed and compared
- What evidence would resolve it: Further research on the properties of SERP effectiveness scores, including their zero points and the validity of ratio-based comparisons

### Open Question 3
- Question: Is the intervalization process proposed by Ferrante et al. (2021) necessary for meaningful SERP evaluation?
- Basis in paper: [explicit] The author argues against the need for intervalization, claiming that it undermines the interpretability of experimental results
- Why unresolved: The effectiveness and necessity of the intervalization process remain debated, with implications for the design and interpretation of SERP evaluation experiments
- What evidence would resolve it: Comparative studies evaluating the performance of SERP evaluation methods with and without intervalization, assessing the impact on result interpretability and system comparisons

## Limitations
- The paper's core argument relies heavily on the assumption that effectiveness mappings reflect user behavior, but does not provide a rigorous framework for validating this assumption across different mappings
- The claim that SERPs are ratio scale data depends on the existence of a natural zero point, which may not hold for all relevance judgments or user contexts
- While the paper critiques intervalization approaches, it does not provide empirical evidence showing how much distortion these methods introduce in practical retrieval experiments

## Confidence

**High confidence**: The fundamental claim that SERPs are categorical data that can be mapped to numeric scores, and that averaging these scores is mathematically valid regardless of uniform spacing

**Medium confidence**: The assertion that SERPs should be treated as ratio scale data rather than ordinal data, as this depends on specific assumptions about the mapping function

**Medium confidence**: The critique of intervalization methods, which is theoretically sound but lacks empirical validation

## Next Checks

1. Implement a controlled experiment comparing system rankings using RR versus NDCG across multiple datasets, explicitly tracking how different mappings affect system comparisons and whether the differences are practically significant

2. Conduct a user study to validate whether different effectiveness mappings (RR, NDCG, Precision) actually reflect distinct user behaviors as claimed, measuring whether users' satisfaction patterns align with the mathematical properties of each mapping

3. Test the ratio scale property by applying effectiveness mappings that do not assign zero to [0]k and demonstrate how this breaks ratio-based comparisons, then measure the practical impact on system evaluation conclusions