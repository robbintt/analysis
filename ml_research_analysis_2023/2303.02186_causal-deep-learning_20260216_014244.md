---
ver: rpa2
title: Causal Deep Learning
arxiv_id: '2303.02186'
source_url: https://arxiv.org/abs/2303.02186
tags:
- causal
- learning
- which
- structure
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a framework for causal deep learning (CDL)
  that spans three dimensions: structural, parametric, and temporal. The structural
  dimension allows for incomplete causal knowledge, introducing a "rung 1.5" between
  association and full intervention.'
---

# Causal Deep Learning

## Quick Facts
- arXiv ID: 2303.02186
- Source URL: https://arxiv.org/abs/2303.02186
- Reference count: 40
- One-line primary result: Proposes a three-dimensional framework for causal deep learning spanning structural, parametric, and temporal dimensions

## Executive Summary
This paper introduces a comprehensive framework for causal deep learning (CDL) that characterizes methods across three key dimensions: structural (causal knowledge representation), parametric (functional form assumptions), and temporal (time-dependent interactions). The framework introduces a novel "rung 1.5" between pure association and full intervention, allowing for incomplete causal knowledge representation. A topographic map is proposed to characterize CDL methods based on their input requirements and learned representations, enabling method comparison, gap identification, and practitioner guidance.

## Method Summary
The paper proposes a three-dimensional framework for CDL spanning structural, parametric, and temporal dimensions. The structural dimension allows incomplete causal knowledge rather than assuming full or no causal knowledge, introducing a "rung 1.5" between association and intervention. The parametric dimension encompasses different functional forms of relationships among variables, while the temporal dimension captures exposure times and how variables interact over time. A topographic map characterizes CDL methods based on required input and learned representations, enabling comparison of methods, identification of research gaps, and guidance for practitioners.

## Key Results
- Introduces a novel three-dimensional framework for characterizing causal deep learning methods
- Proposes a topographic map to categorize CDL methods based on input assumptions and learned representations
- Demonstrates framework applications across supervised learning, bandit algorithms, reinforcement learning, and generative modeling
- Identifies research gaps and provides guidance for selecting appropriate CDL methods in real-world applications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The structural dimension enables partial causal knowledge representation through a "rung 1.5" that bridges association and full intervention.
- Mechanism: By allowing structures that encode statistical independence (like SâŠ¥D|C) without full causal knowledge, the framework captures more information than pure association while requiring less than complete causal graphs.
- Core assumption: Statistical independence statements can be meaningfully represented as structures that are "plausibly causal" even if not fully causal.
- Evidence anchors:
  - [abstract]: "The structural dimension allows incomplete causal knowledge rather than assuming either full or no causal knowledge."
  - [section 3.1]: "We find there are more structures to be taken into account beyond causal structures, in particular the 'rung 1.5' structures."
- Break condition: If statistical independence statements cannot be reliably identified from data, the structural transitions become meaningless.

### Mechanism 2
- Claim: The parametric dimension captures different functional forms of relationships beyond simple causal structure.
- Mechanism: By explicitly modeling how variables interact (additive noise models, parametric assumptions, fully known factors), the framework accounts for the "how" of causation, not just the "whether."
- Core assumption: The functional form of relationships between variables matters significantly for causal inference and can be meaningfully categorized.
- Evidence anchors:
  - [abstract]: "The parametric dimension encompasses parametric forms that capture the type of relationships among the variables of interest."
  - [section 3.2]: "In Level 2, we make an additional assumption which is a parametric assumption on the factors... for example, additive noise: f(X, UX) = g(X) + UX."
- Break condition: If functional forms cannot be reliably identified or if they don't significantly impact causal inference outcomes.

### Mechanism 3
- Claim: The temporal dimension captures exposure times and temporal interactions between variables.
- Mechanism: By explicitly modeling time, the framework can handle situations where causality depends on temporal exposure or where temporal precedence is crucial.
- Core assumption: Time is an essential component in causality that requires explicit modeling beyond static relationships.
- Evidence anchors:
  - [abstract]: "The temporal dimension captures exposure times or how the variables of interest interact (possibly causally) over time."
  - [section 1]: "Not only is time an essential component in causality (as causes precede effects), but time can also influence whether or not something is causal."
- Break condition: If temporal dependencies don't significantly impact the causal relationships being studied.

## Foundational Learning

- Concept: Structural causal models and d-separation rules
  - Why needed here: Understanding how to represent and manipulate causal structures is fundamental to the framework's structural dimension
  - Quick check question: Given a DAG, can you determine which variables are conditionally independent using d-separation rules?

- Concept: Parametric assumptions in causal models
  - Why needed here: The framework's parametric dimension relies on understanding different levels of functional form assumptions
  - Quick check question: What's the difference between additive noise models and fully parametric assumptions in causal modeling?

- Concept: Temporal causal inference
  - Why needed here: The temporal dimension requires understanding how causality operates in dynamic systems
  - Quick check question: How does Granger causality differ from standard causal inference in static settings?

## Architecture Onboarding

- Component map:
  - Input validation layer -> Structural representation module -> Parametric modeling component -> Temporal processing engine -> Cascading framework

- Critical path:
  1. Validate input data assumptions
  2. Determine required structural and parametric levels
  3. Select appropriate CDL method(s)
  4. Implement transitions if needed
  5. Execute causal inference or learning task

- Design tradeoffs:
  - Flexibility vs. specificity: More flexible assumptions allow broader application but may sacrifice precision
  - Complexity vs. interpretability: More detailed models are harder to interpret but may capture more nuance
  - Computational cost vs. accuracy: More sophisticated methods require more resources but may yield better results

- Failure signatures:
  - Structural assumption violations: When input data doesn't match required structural assumptions
  - Parametric mismatch: When functional form assumptions are incorrect for the data
  - Temporal inconsistencies: When temporal dependencies aren't properly modeled

- First 3 experiments:
  1. Implement a simple structural transition from unknown to plausible causal structure on synthetic data
  2. Test different parametric assumptions (additive noise vs. fully parametric) on the same dataset
  3. Validate temporal dimension by comparing results with and without explicit time modeling on time-series data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal way to cascade multiple CDL models while preserving their respective assumptions?
- Basis in paper: [explicit] The paper discusses cascading models and the importance of maintaining assumptions when chaining methods together.
- Why unresolved: While the paper provides examples of cascading models, it doesn't offer a general framework for optimally combining different CDL methods while preserving their assumptions.
- What evidence would resolve it: A theoretical framework or algorithm that determines the optimal order and combination of CDL models to solve a specific problem while maintaining their assumptions.

### Open Question 2
- Question: How can we effectively evaluate the causal knowledge learned by CDL methods?
- Basis in paper: [inferred] The paper mentions the importance of using data that matches a model's input assumptions and suggests empirical evidence, but doesn't provide a comprehensive evaluation framework.
- Why unresolved: The paper discusses the importance of evaluation but doesn't provide a detailed methodology for assessing the quality and accuracy of causal knowledge learned by CDL methods.
- What evidence would resolve it: A standardized set of benchmarks, metrics, and evaluation protocols specifically designed for assessing the causal knowledge learned by CDL methods.

### Open Question 3
- Question: What are the limitations of the "rung 1.5" concept in representing partial causal knowledge?
- Basis in paper: [explicit] The paper introduces the concept of "rung 1.5" as an intermediary level between association and intervention in the structural scale.
- Why unresolved: While the paper presents the concept, it doesn't explore its limitations or potential issues in representing more complex forms of partial causal knowledge.
- What evidence would resolve it: A thorough analysis of scenarios where the "rung 1.5" concept falls short in representing partial causal knowledge, along with proposed solutions or alternative representations.

## Limitations
- The "rung 1.5" structural dimension introduces novel theoretical concepts lacking extensive empirical validation
- The framework's practical utility in real-world applications beyond discussed examples remains unproven
- The topographic map's effectiveness for method selection depends heavily on accurate characterization of existing methods

## Confidence
- High: The three-dimensional framework structure (structural, parametric, temporal) is well-defined and logically coherent
- Medium: The practical utility of the topographic map for method selection and gap identification
- Low: The novel "rung 1.5" structural dimension's theoretical soundness and empirical validity

## Next Checks
1. **Empirical Validation**: Test the framework's ability to correctly identify appropriate CDL methods across diverse real-world datasets and problems
2. **Method Characterization**: Conduct a systematic review to validate the topographic map's accuracy in characterizing existing CDL methods
3. **Practical Implementation**: Develop and benchmark a concrete implementation of the framework to assess its usability and performance in practice