---
ver: rpa2
title: 'DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language
  Models'
arxiv_id: '2309.03883'
source_url: https://arxiv.org/abs/2309.03883
tags:
- dola
- layers
- layer
- would
- baseline
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a decoding strategy called Decoding by Contrasting
  Layers (DoLa) to reduce hallucinations in large language models. The method works
  by contrasting the logits from later transformer layers with those from earlier
  layers, dynamically selecting which early layer to contrast against based on their
  Jensen-Shannon divergence.
---

# DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models

## Quick Facts
- **arXiv ID:** 2309.03883
- **Source URL:** https://arxiv.org/abs/2309.03883
- **Reference count:** 40
- **Primary result:** DoLa improves truthfulness by 12-17% absolute points on TruthfulQA compared to baseline decoding

## Executive Summary
Decoding by Contrasting Layers (DoLa) is a novel decoding strategy that reduces hallucinations in large language models by dynamically contrasting logits from different transformer layers. The method identifies when factual knowledge is being incorporated by measuring Jensen-Shannon divergence between early and late layer probability distributions, then suppresses less factual predictions from earlier layers while preserving factual signals from later layers. Experiments show DoLa significantly improves factuality on multiple benchmarks while maintaining informativeness and incurring only minimal computational overhead.

## Method Summary
DoLa works by computing the difference between logits from a "mature" final layer and a dynamically selected "premature" early layer for each token prediction. The premature layer is chosen based on maximum Jensen-Shannon divergence from the final layer's distribution, indicating where the model is incorporating factual knowledge. The contrast operation subtracts premature layer log probabilities from mature layer log probabilities for high-probability tokens, effectively suppressing superficial predictions while amplifying factual ones. This approach requires only minor modifications to existing decoding pipelines and works with any pre-trained transformer model.

## Key Results
- DoLa improves truthfulness by 12-17% absolute points on TruthfulQA compared to baseline decoding
- The method achieves higher factuality while maintaining comparable informativeness and rejection rates
- Performance gains are consistent across LLaMA models of various sizes (7B to 65B parameters)
- Computational overhead is minimal (×1.01-1.08 latency increase)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Factual knowledge becomes more distinct in higher transformer layers, while superficial patterns are resolved in earlier layers.
- Mechanism: DoLa contrasts logits from a higher "mature" layer against an earlier "premature" layer to amplify factual signals while suppressing incorrect but syntactically plausible predictions.
- Core assumption: The probability distribution over next tokens changes significantly between early and late layers only when factual knowledge is being incorporated.
- Evidence anchors:
  - [abstract]: "factual knowledge in an LLMs has generally been shown to be localized to particular transformer layers"
  - [section]: Figure 2 shows Jensen-Shannon Divergence between early and final layers spikes when predicting factual tokens like "1986" but remains low for function words like "was" or "the"
  - [corpus]: "PruneCD" and "Active Layer-Contrastive Decoding" also exploit layer-wise differences, supporting the general principle
- Break condition: If factual knowledge is distributed uniformly across layers rather than localized, the contrast signal would be weak or absent.

### Mechanism 2
- Claim: Dynamic selection of the premature layer based on Jensen-Shannon Divergence maximizes the contrast between factual and non-factual predictions.
- Mechanism: At each decoding step, DoLa computes JSD between final layer logits and all candidate early layers, selecting the layer with maximum divergence as the premature layer.
- Core assumption: The layer showing maximum divergence from the final layer contains the most plausible but less factual predictions that need suppression.
- Evidence anchors:
  - [section]: "M = arg max JSD(qN (· | x<t)||qj(· | x<t))" explicitly defines the dynamic selection
  - [corpus]: "Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping" also uses layer selection but for multilingual contexts, supporting the general approach
- Break condition: If JSD does not reliably indicate token difficulty or factual uncertainty, the dynamic selection would fail to pick optimal premature layers.

### Mechanism 3
- Claim: Subtracting premature layer log probabilities from mature layer log probabilities suppresses less factual predictions while preserving high-confidence factual ones.
- Mechanism: DoLa computes F(qN, qM) = log qN - log qM for high-probability tokens from the mature layer, zeroing out low-probability tokens to avoid false positives.
- Core assumption: The difference between mature and premature layer log probabilities effectively amplifies factual knowledge while suppressing superficial patterns.
- Evidence anchors:
  - [section]: Equation (3) shows the contrast operation: "F(qN (xt), qM (xt)) = log qN (xt) - qM (xt) if xt ∈ Vhead"
  - [corpus]: "SLED: Self Logits Evolution Decoding" uses similar self-contrast mechanisms, supporting the general principle
- Break condition: If the premature layer occasionally contains better factual knowledge than the mature layer for specific tokens, the subtraction would incorrectly suppress correct predictions.

## Foundational Learning

- Concept: Jensen-Shannon Divergence as a measure of distribution similarity
  - Why needed here: DoLa uses JSD to quantify how much the probability distribution changes between layers, which indicates whether factual knowledge is being incorporated
  - Quick check question: What property of JSD makes it suitable for comparing probability distributions of next-token predictions?

- Concept: Early exiting in transformer models
  - Why needed here: DoLa builds on early exiting research, using intermediate layer outputs as contrastive priors rather than just for efficiency
  - Quick check question: How do residual connections in transformers affect the relationship between early exit outputs and final layer outputs?

- Concept: Contrastive learning in generation
  - Why needed here: DoLa applies contrastive principles from representation learning to decoding by contrasting different model states
  - Quick check question: What is the key difference between DoLa's internal contrast and external contrastive decoding methods like CD?

## Architecture Onboarding

- Component map: Embedding layer → N transformer layers → Vocabulary head; DoLa inserts layer contrast operation between intermediate layer outputs and final layer output
- Critical path: Token embedding → transformer layers → early exit head computation → JSD-based premature layer selection → contrast operation → final probability computation → token selection
- Design tradeoffs: DoLa trades minimal additional latency (×1.01-1.08) for improved factuality vs. using larger models or retrieval-augmented approaches
- Failure signatures: Performance degradation when factual knowledge is uniformly distributed across layers, or when premature layer occasionally contains better knowledge than mature layer
- First 3 experiments:
  1. Compare JSD patterns between factual and non-factual tokens across different layer ranges to validate the localization hypothesis
  2. Test static vs. dynamic premature layer selection on a validation set to quantify the benefit of adaptivity
  3. Measure the impact of repetition penalty on chain-of-thought tasks to optimize θ hyperparameter

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DoLa's performance compare to retrieval-augmented language models (RALMs) that incorporate external knowledge bases?
- Basis in paper: [inferred] The paper states "Our method relies solely on the model's internal knowledge and does not use external retrieval modules like some retrieval augmented LMs do (Izacard et al., 2022; Borgeaud et al., 2022; Ram et al., 2023). Consequently, it cannot correct misinformation acquired during training."
- Why unresolved: The paper does not compare DoLa's performance to RALMs, which could provide a stronger factual grounding than DoLa's internal knowledge-based approach.
- What evidence would resolve it: Direct experimental comparison of DoLa vs. RALMs on the same factual accuracy benchmarks (e.g., TruthfulQA) would show whether external knowledge retrieval provides significant advantages over DoLa's internal knowledge surfacing approach.

### Open Question 2
- Question: What is the impact of DoLa on the model's ability to follow instructions and perform tasks that require balancing factuality with other capabilities?
- Basis in paper: [inferred] The paper mentions limitations including "Focusing on Factuality: We have not explored how our approach would perform in other dimensions such as instruction following (Wei et al., 2021) or learning from human feedback (Ouyang et al., 2022)."
- Why unresolved: While DoLa improves factuality, the paper does not investigate whether this improvement comes at the cost of other important capabilities like instruction following or task completion.
- What evidence would resolve it: Systematic evaluation of DoLa on benchmarks that measure both factuality and instruction-following ability (e.g., Alpaca, Vicuna) would reveal any trade-offs between these capabilities.

### Open Question 3
- Question: Can DoLa be effectively combined with fine-tuning approaches to further improve factuality beyond what is achievable with decoding alone?
- Basis in paper: [explicit] The paper states "Our approach provides a simple decoding strategy, it has the potential to be combined with a retrieval module" and mentions that DoLa "does not use human labels or factual knowledge bases for fine-tuning (Li et al., 2023)."
- Why unresolved: The paper focuses exclusively on decoding-time improvements and does not explore whether combining DoLa with fine-tuning approaches could yield additional benefits.
- What evidence would resolve it: Experimental results showing the combined performance of DoLa with various fine-tuning approaches (e.g., RLHF, knowledge editing) on factual accuracy benchmarks would demonstrate whether these methods are complementary or redundant.

## Limitations
- The method's reliance on JSD as a reliable indicator of factual incorporation remains unvalidated across diverse domains
- The computational overhead, while modest, scales linearly with layer count and could become prohibitive for very deep models
- The approach may struggle when factual knowledge is distributed across multiple layers rather than localized

## Confidence
- **High**: Factual knowledge localizes to specific transformer layers
- **Medium**: Dynamic layer selection improves performance over static selection
- **Medium-Low**: Logit subtraction reliably amplifies factual knowledge

## Next Checks
1. **Cross-domain JSD validation**: Test whether Jensen-Shannon divergence patterns observed in TruthfulQA hold for domain-specific factual knowledge (e.g., medical or technical domains) by measuring JSD between factual and non-factual tokens across different knowledge domains.

2. **Early layer knowledge quality assessment**: Systematically evaluate whether early transformer layers ever contain superior factual knowledge compared to final layers for specific token predictions, particularly for domain-specific terminology or recent facts that may not be well-encoded in higher layers.

3. **Long-form generation factuality analysis**: Apply DoLa to extended generation tasks (500+ tokens) and track factuality degradation over sequence length compared to baseline decoding, measuring whether layer-wise contrast effects compound or diminish over longer outputs.