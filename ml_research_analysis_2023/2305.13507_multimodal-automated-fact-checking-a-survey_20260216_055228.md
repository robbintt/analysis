---
ver: rpa2
title: 'Multimodal Automated Fact-Checking: A Survey'
arxiv_id: '2305.13507'
source_url: https://arxiv.org/abs/2305.13507
tags:
- pages
- multimodal
- conference
- detection
- fact-checking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey introduces a comprehensive framework for multimodal
  automated fact-checking, organizing tasks across claim detection/extraction, evidence
  retrieval, and verdict prediction (including manipulation, out-of-context, and veracity
  classification) with justification production. It surveys benchmarks and models
  across four prevalent modalities: text, image, audio, and video, addressing limitations
  of text-only approaches.'
---

# Multimodal Automated Fact-Checking: A Survey

## Quick Facts
- arXiv ID: 2305.13507
- Source URL: https://arxiv.org/abs/2305.13507
- Reference count: 40
- Over 28% of real-world claims involve multimodal data requiring verification

## Executive Summary
This survey presents a comprehensive framework for multimodal automated fact-checking (AFC), organizing the task into claim detection/extraction, evidence retrieval, and verdict prediction with justification production. The authors identify that misinformation often spans multiple modalities (text, image, audio, video) and requires systematic approaches to handle diverse manipulation types. The survey analyzes existing benchmarks and models, highlighting critical challenges including claim extraction from multimodal content, evidence retrieval for non-text modalities, multilingual-multimodal integration, and producing interpretable justifications.

## Method Summary
The survey synthesizes approaches across the multimodal AFC pipeline by reviewing 25 related papers and analyzing benchmark datasets. For claim detection, it examines modality-specific encoders (CNNs for images, Transformers for text, MFCCs for audio) combined with OCR and speech-to-text conversion. Evidence retrieval strategies are categorized as content-based (claim-only) or external (search engines, knowledge bases). Verdict prediction encompasses manipulation classification, out-of-context detection, and veracity classification using multimodal fusion techniques. Justification production methods include input highlighting through graph-based inconsistency detection and natural language generation approaches.

## Key Results
- Multimodal fact-checking pipeline decomposes misinformation handling into modular subtasks
- Over 28% of real-world claims require multimodal verification beyond text-only approaches
- Justification production increases system interpretability and user trust
- Major challenges include claim extraction from complex multimodal sources and multilingual support

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multimodal fact-checking pipeline enables systematic handling of diverse misinformation types
- Mechanism: Each pipeline stage isolates specific challenges, allowing targeted modeling approaches
- Core assumption: Misinformation can be decomposed into modular subtasks where each subtask's output becomes the next stage's input
- Evidence anchors: Conceptual framework introduced with three-step process; moderate topical alignment (FMR=0.475) but limited empirical cross-validation

### Mechanism 2
- Claim: Multiple modalities capture misinformation missed by text-only methods
- Mechanism: Modality-specific encoders combined with fusion strategies produce richer joint representations
- Core assumption: Misinformation relies on cross-modal cues (e.g., mismatched captions) that single modalities cannot detect
- Evidence anchors: Most datasets focus on single modalities, necessitating multimodal integration; novelty suggested by zero citations

### Mechanism 3
- Claim: Justification production increases trustworthiness and interpretability
- Mechanism: Explanations via input highlighting or natural language generation clarify model reasoning
- Core assumption: Users require interpretable evidence for verdicts to trust automated systems
- Evidence anchors: Three categories of justification production identified; justification mechanisms understudied (zero citations)

## Foundational Learning

- Concept: Modality-specific feature extraction (CNNs for images, Transformers for text, spectrograms for audio)
  - Why needed here: Each modality has distinct statistical properties requiring specialized models
  - Quick check question: What type of neural network is most common for encoding visual data in multimodal fact-checking?

- Concept: Cross-modal fusion strategies (early, late, hybrid)
  - Why needed here: Fusion determines how modality-specific features are combined; poor fusion can erase complementary information
  - Quick check question: In the surveyed literature, which fusion approach is more prevalent for multimodal fact-checking?

- Concept: Evidence retrieval from external sources (search engines, knowledge graphs)
  - Why needed here: Many claims require external verification beyond the claim itself
  - Quick check question: What are the two main approaches to evidence retrieval in multimodal fact-checking?

## Architecture Onboarding

- Component map: Claim Detection & Extraction → Evidence Retrieval → Verdict Prediction → Justification Production
- Critical path: Claim extraction → Evidence retrieval → Verdict classification → Justification generation
- Design tradeoffs:
  - Modality coverage vs. model complexity (adding modalities increases computational load)
  - External evidence reliance vs. privacy/cost constraints
  - Justification fidelity vs. generation speed
- Failure signatures:
  - Claim extraction fails → downstream stages receive incomplete/incorrect inputs
  - Evidence retrieval returns irrelevant results → classification accuracy drops
  - Justification generation is unfaithful → user trust erodes
- First 3 experiments:
  1. Test unimodal claim detection (text only) on a subset of claims to establish baseline
  2. Evaluate cross-modal consistency detection (e.g., caption-image mismatch) on a curated dataset
  3. Compare early vs. late fusion for multimodal verdict classification on a small benchmark

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the most effective approaches for claim extraction from multimodal content, particularly from data visualizations and audio/video frames?
- Basis in paper: [explicit] The authors identify claim extraction from multimodal content as a major challenge, noting that current approaches focus on text extraction from visual content or transcribing audio/videos, but diverse multimodal misinformation types require more specific approaches
- Why unresolved: The survey identifies this as a challenge but does not provide specific solutions or evaluate existing methods for claim extraction from complex multimodal sources
- What evidence would resolve it: Comparative studies evaluating different claim extraction methods on multimodal misinformation datasets, particularly those involving data visualizations and audio/video content

### Open Question 2
- Question: How can multimodal fact-checking models be effectively developed and evaluated for non-English languages?
- Basis in paper: [explicit] The authors note that most multimodal fact-checking datasets and models are available only in English, leading to potential biases and limitations
- Why unresolved: The survey highlights the need for multilingual-multimodal integration but does not provide specific solutions or evaluate existing multilingual approaches
- What evidence would resolve it: Development and evaluation of multimodal fact-checking models on diverse multilingual datasets, along with studies on cross-lingual performance and bias mitigation techniques

### Open Question 3
- Question: What are the most effective methods for producing natural language justifications for multimodal fact-checking decisions?
- Basis in paper: [explicit] The authors identify the lack of natural language justifications for multimodal fact-checking as a significant gap
- Why unresolved: The survey mentions the need for natural language justifications but does not provide specific solutions or evaluate existing methods for generating such explanations
- What evidence would resolve it: Development and evaluation of methods for generating natural language justifications for multimodal fact-checking decisions, along with user studies on the effectiveness and interpretability of these explanations

## Limitations

- Analysis is primarily conceptual with limited empirical validation of multimodal approaches
- Survey shows zero citations for many related works, suggesting novelty but limited validation
- Specific effectiveness metrics for justification production methods and their impact on user trust remain underexplored

## Confidence

- High confidence: The three-step pipeline architecture (claim detection → evidence retrieval → verdict prediction) is well-established in the literature
- Medium confidence: The importance of multimodal integration for capturing misinformation types missed by text-only approaches
- Low confidence: Specific effectiveness metrics for justification production methods and their impact on user trust

## Next Checks

1. Conduct empirical comparison of multimodal vs. unimodal fact-checking systems on a standardized benchmark to quantify performance gains
2. Evaluate cross-modal consistency detection capabilities on curated datasets with known caption-image mismatches
3. Test the robustness of evidence retrieval systems for audio and video content using reverse search and metadata-based approaches