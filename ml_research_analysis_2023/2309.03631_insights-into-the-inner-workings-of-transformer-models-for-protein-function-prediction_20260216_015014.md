---
ver: rpa2
title: Insights Into the Inner Workings of Transformer Models for Protein Function
  Prediction
arxiv_id: '2309.03631'
source_url: https://arxiv.org/abs/2309.03631
tags:
- protein
- prediction
- sequence
- relevance
- amino
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that finetuned transformer models (ProtBert
  and ProtT5) achieve competitive performance in protein function prediction tasks,
  matching or surpassing state-of-the-art methods. The authors extend integrated gradients
  to analyze transformer latent representations, identifying specialized heads that
  focus on biologically meaningful sequence annotations like transmembrane regions
  and active sites.
---

# Insights Into the Inner Workings of Transformer Models for Protein Function Prediction

## Quick Facts
- arXiv ID: 2309.03631
- Source URL: https://arxiv.org/abs/2309.03631
- Reference count: 40
- Key outcome: Extended integrated gradients method identifies transformer heads that focus on biologically meaningful protein sequence regions

## Executive Summary
This study demonstrates that finetuned transformer models (ProtBert and ProtT5) achieve competitive performance in protein function prediction tasks, matching or surpassing state-of-the-art methods. The authors extend integrated gradients to analyze transformer latent representations, identifying specialized heads that focus on biologically meaningful sequence annotations like transmembrane regions and active sites. Attribution maps from the embedding layer and individual transformer heads correlate significantly with UniProt annotations across multiple protein function prediction tasks, with EC prediction showing particularly strong results. The approach provides statistical evidence that transformer models systematically attend to biologically relevant regions, with class-specific collective dynamics emerging among specialized heads.

## Method Summary
The method involves fine-tuning pretrained transformer models (ProtBert or ProtT5) on protein function prediction tasks, then applying an extended integrated gradients technique to attribute relevance to individual amino acids at each transformer head and layer. The attribution maps are correlated with sequence annotations from UniProtKB/Swiss-Prot using point biserial correlation coefficients, with statistical significance determined through t-tests and false discovery rate control. The analysis identifies specialized transformer heads that show significant correspondence with biologically meaningful annotations, and dimensionality reduction techniques visualize class-specific collective dynamics among these heads.

## Key Results
- Finetuned transformers achieve competitive performance on EC and GO prediction tasks, matching or exceeding state-of-the-art methods
- Extended integrated gradients identifies specialized transformer heads with statistically significant correspondence to UniProt annotations
- Class-specific collective dynamics emerge among transformer heads, with distinct combinations relevant for different protein function classes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The extended integrated gradients method can attribute relevance to individual amino acids at intermediate transformer layers by maintaining a consistent baseline path through the embedding layer.
- Mechanism: By fixing the integration path at the embedding layer while varying the input, the method ensures that attribution calculations remain consistent across different transformer heads and layers, enabling meaningful comparisons of attention patterns.
- Core assumption: The baseline chosen at the embedding layer is appropriate for all intermediate layers, and the resulting curvilinear paths maintain the mathematical properties required for valid attribution.
- Evidence anchors:
  - [abstract]: "extending the widely used XAI method of integrated gradients such that latent representations inside of transformer models... can be inspected too"
  - [section]: "Choosing γ as straight line connecting x′ and x makes IG the unique method satisfying the four axioms from above and an additional symmetry axiom"
  - [corpus]: Weak - no direct evidence about this specific methodological extension in corpus papers
- Break condition: If the curvilinear paths through intermediate layers violate the symmetry or completeness axioms, attributions may become unreliable and fail to reflect true attention patterns.

### Mechanism 2
- Claim: The correlation between attribution maps and sequence annotations provides statistically significant evidence that transformer models focus on biologically meaningful regions.
- Mechanism: Point biserial correlation coefficients between continuous relevance values and binary annotations are aggregated across proteins using t-tests, with false discovery rate control to identify heads showing systematic attention to annotated regions.
- Core assumption: The annotations in sequence databases accurately represent biologically meaningful regions, and the statistical framework properly accounts for multiple comparisons across heads and layers.
- Evidence anchors:
  - [abstract]: "identified transformer heads with a statistically significant correspondence of attribution maps with ground truth sequence annotations"
  - [section]: "We can carry out the same procedure for every transformer layer and combine all results into an nlayer × nhead relevance map"
  - [corpus]: Weak - corpus papers discuss attention mechanisms but don't provide statistical frameworks for validating biological relevance
- Break condition: If annotations are noisy or incomplete, correlations may reflect database biases rather than genuine model behavior, leading to false discoveries.

### Mechanism 3
- Claim: Class-specific collective dynamics emerge among transformer heads, with distinct combinations of heads being relevant for different protein function classes.
- Mechanism: Summed attribution maps across sequences are reduced to 2D via PCA and t-SNE, revealing clusters that correspond to EC classes, suggesting coordinated head behavior for classification decisions.
- Core assumption: The dimensionality reduction preserves meaningful structure in the attribution maps, and the observed clustering reflects genuine class-specific dynamics rather than artifacts of the visualization method.
- Evidence anchors:
  - [section]: "PCA and t-SNE visualization of summed attribution maps... The points form distinctive clusters matching the EC labels"
  - [abstract]: "class-specific collective dynamics emerging among specialized heads"
  - [corpus]: Weak - corpus papers mention attention mechanisms but don't explore collective head dynamics through visualization
- Break condition: If t-SNE produces misleading clusters or if the summed attributions obscure important sequence-specific information, the apparent collective dynamics may not reflect true model behavior.

## Foundational Learning

- Concept: Protein function prediction as multi-label classification
  - Why needed here: The paper treats GO term and EC number prediction as classification tasks where proteins can belong to multiple classes simultaneously
  - Quick check question: Why does the model output a vector of probabilities rather than a single class label?

- Concept: Transformer architecture and multi-head attention
  - Why needed here: The analysis requires understanding how attention heads process sequences at different layers to identify specialized heads
  - Quick check question: What distinguishes the output of different attention heads in the same transformer layer?

- Concept: Integrated gradients attribution method
  - Why needed here: The paper extends this XAI method to attribute relevance to individual amino acids and transformer heads
  - Quick check question: How does integrated gradients satisfy the completeness axiom when applied to neural network layers?

## Architecture Onboarding

- Component map: Pretrained transformer models (ProtBert/ProtT5) → fine-tuning on protein function tasks → extended integrated gradients implementation → attribution map generation → statistical correlation with annotations
- Critical path: Data preprocessing → model finetuning → attribution map calculation → correlation analysis → statistical significance testing → visualization of results
- Design tradeoffs: The choice between ProtBert (smaller, faster) and ProtT5 (larger, potentially more accurate) involves memory constraints versus performance; the extended IG method trades computational complexity for layer-specific insights
- Failure signatures: Weak correlations across all heads may indicate model overfitting or insufficient annotation quality; failure to converge during finetuning suggests hyperparameter issues; unstable attribution maps suggest problems with the IG extension
- First 3 experiments:
  1. Verify the extended IG implementation by comparing layer attribution patterns with known attention mechanisms on simple synthetic sequences
  2. Test statistical significance thresholds by running correlation analysis on shuffled annotations to establish false positive rates
  3. Validate collective dynamics visualization by comparing t-SNE clusters on random attribution maps versus actual model outputs

## Open Questions the Paper Calls Out

- Question: How do attribution maps differ between transformer heads specializing in transmembrane regions versus those focusing on active sites, and what structural or functional characteristics drive these specialization patterns?
  - Basis in paper: [explicit] The authors identify specialized heads for specific protein function prediction tasks and observe different transformer heads are sensitive to different annotated biologically meaningful sites, but don't provide detailed comparative analysis between different types of specialized heads
  - Why unresolved: The paper demonstrates that different heads specialize in different annotation types but doesn't systematically compare the characteristics of attribution maps between head types or explore what drives these specialization patterns
  - What evidence would resolve it: Detailed comparative analysis of attribution maps from different specialized heads, including structural analysis of their attention patterns and correlation with protein sequence/structure features

- Question: Can the identified specialized transformer heads be used for protein function prediction tasks beyond the ones studied (GO and EC prediction), and what is their transferability across different prediction tasks?
  - Basis in paper: [inferred] The authors identify specialized heads for specific tasks and suggest XAI methods could enable discovery of novel sequence patterns, but don't test transferability to other tasks
  - Why unresolved: While the paper demonstrates head specialization for GO and EC prediction, it doesn't explore whether these specialized heads can generalize to other protein function prediction tasks or how transferable the learned representations are
  - What evidence would resolve it: Systematic testing of specialized heads on additional protein prediction tasks, including transfer learning experiments and quantitative assessment of performance gains across tasks

- Question: What is the relationship between the collective dynamics observed in attribution maps and the actual decision-making process of the transformer models, and how do these dynamics contribute to prediction accuracy?
  - Basis in paper: [explicit] The authors observe class-specific collective dynamics among transformer heads through t-SNE visualization but don't investigate the relationship between these dynamics and model decision-making
  - Why unresolved: The paper demonstrates the existence of class-specific structures in attribution maps but doesn't analyze how these collective dynamics relate to the actual prediction process or contribute to model performance
  - What evidence would resolve it: Detailed analysis of how collective dynamics correlate with prediction accuracy, including ablation studies of specific head combinations and analysis of their contribution to final predictions

## Limitations
- The extended integrated gradients method assumes curvilinear paths through intermediate layers maintain required mathematical properties
- Statistical framework relies on completeness and accuracy of UniProtKB/Swiss-Prot annotations
- t-SNE visualization may produce artifacts requiring careful interpretation

## Confidence
- High confidence in the overall framework and statistical methodology
- Medium confidence in the specific implementation details of the extended IG method
- Medium confidence in the interpretation of collective head dynamics visualizations

## Next Checks
1. Validate the extended integrated gradients implementation by comparing attribution patterns on synthetic sequences with known attention mechanisms, ensuring the curvilinear paths maintain mathematical properties
2. Establish false positive rates by running correlation analysis on shuffled annotations to confirm the statistical framework's sensitivity and specificity
3. Test the robustness of collective dynamics visualization by comparing t-SNE clusters from actual model outputs against clusters from randomized attribution maps