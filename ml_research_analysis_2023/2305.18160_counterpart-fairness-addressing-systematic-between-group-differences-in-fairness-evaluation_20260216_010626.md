---
ver: rpa2
title: Counterpart Fairness -- Addressing Systematic between-group Differences in
  Fairness Evaluation
arxiv_id: '2305.18160'
source_url: https://arxiv.org/abs/2305.18160
tags:
- fairness
- groups
- differences
- learning
- group
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces CFair, a novel fairness index that addresses\
  \ systematic between-group differences by evaluating algorithmic fairness on counterparts\u2014\
  similar individuals from different groups. CFair mitigates confounding issues through\
  \ a two-step method combining propensity score matching and metric learning to identify\
  \ counterparts."
---

# Counterpart Fairness -- Addressing Systematic between-group Differences in Fairness Evaluation

## Quick Facts
- arXiv ID: 2305.18160
- Source URL: https://arxiv.org/abs/2305.18160
- Authors: 
- Reference count: 40
- This study introduces CFair, a novel fairness index that addresses systematic between-group differences by evaluating algorithmic fairness on counterparts—similar individuals from different groups.

## Executive Summary
This paper introduces CFair, a novel fairness index that addresses systematic between-group differences by evaluating algorithmic fairness on counterparts—pairs of similar individuals from different groups. The method uses propensity score matching combined with Mahalanobis distance to identify counterparts while mitigating confounding effects. Empirical evaluation on MIMIC-IV and COMPAS datasets demonstrates that CFair reveals unfairness that traditional group-based fairness metrics may miss, providing more accurate fairness assessments through statistical significance testing on counterpart pairs.

## Method Summary
CFair identifies counterparts between groups using a two-step process: first, propensity score matching identifies individuals with similar probabilities of belonging to different groups based on non-sensitive variables; second, Mahalanobis distance refinement ensures baseline characteristics are comparable. The method then calculates demographic parity gaps (CDP) on these counterpart pairs and applies paired t-tests to determine statistical significance. CFair can be extended to other group fairness metrics by substituting counterparts for original groups in existing calculations.

## Key Results
- CFair successfully identifies counterparts in both MIMIC-IV and COMPAS datasets using propensity score matching and Mahalanobis distance
- Traditional group-based fairness metrics may underestimate unfairness when systematic differences exist between groups
- CFair provides statistical significance testing capabilities that reveal whether between-group differences are meaningful or due to chance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CFair mitigates confounding effects by comparing counterparts instead of whole groups
- Mechanism: The method uses propensity score matching to identify subgroups where sensitive variable cannot be algorithmically distinguished, then refines matches using Mahalanobis distance on baseline characteristics
- Core assumption: Non-sensitive variables that predict sensitive variables are the primary source of confounding
- Evidence anchors:
  - [abstract] "evaluate fairness on counterparts (pairs of individuals who are similar with respect to the task of interest but from different groups)"
  - [section] "we believe that a fairness measurement should be based on the comparison between counterparts (i.e., individuals who are similar to each other with respect to the task of interest) from different groups, whose group identities cannot be distinguished algorithmically by exploring confounding factors"
  - [corpus] Weak - only tangentially related papers found
- Break condition: If propensity score model fails to capture true confounding structure, the identified counterparts may still contain systematic differences

### Mechanism 2
- Claim: Statistical significance testing on counterpart pairs provides rigorous fairness evaluation
- Mechanism: Uses paired t-test on model outputs for 1-1 counterpart pairs to determine if between-group differences are statistically significant
- Core assumption: Small CDP gaps can occur by chance and don't necessarily indicate fairness
- Evidence anchors:
  - [abstract] "enables a principled way to statistically evaluate the fairness of an ML model"
  - [section] "utilize the paired samples t-test [19, 48] on the outputs of the ML model on the 1-1 δ-counterparts"
  - [corpus] Weak - no directly relevant papers found
- Break condition: If sample size is too small or variance is too high, paired t-test may lack power to detect true unfairness

### Mechanism 3
- Claim: CFair can be extended to other group fairness metrics beyond demographic parity
- Mechanism: By substituting original groups with δ-counterpart groups in existing fairness calculations
- Core assumption: Most group fairness metrics can be reformulated to operate on matched subgroups
- Evidence anchors:
  - [abstract] "CFair could be generalized to other group fairness measurements, such as, equal performance, equalized odds, equal allocations, and so on"
  - [section] "Extend CFair to other group fairness measurements"
  - [corpus] Weak - only tangentially related papers found
- Break condition: If fairness metric inherently requires whole group comparison (not pairwise), extension may not be straightforward

## Foundational Learning

- Concept: Propensity score matching
  - Why needed here: Identifies individuals with similar probability of belonging to different groups based on non-sensitive variables
  - Quick check question: How does propensity score matching help mitigate confounding in observational studies?

- Concept: Mahalanobis distance
  - Why needed here: Measures similarity between individuals based on their baseline characteristics after initial propensity score matching
  - Quick check question: Why is Mahalanobis distance preferred over Euclidean distance for measuring similarity in this context?

- Concept: Paired statistical testing
  - Why needed here: Determines if differences in model outputs between counterpart pairs are statistically significant
  - Quick check question: What assumptions must hold for paired t-test to be valid when comparing counterpart pairs?

## Architecture Onboarding

- Component map:
  Propensity score model (AdaBoost/Random Forest) -> Initial matching based on propensity score thresholds -> Mahalanobis distance calculation with learned weight matrix -> 1-1 counterpart identification algorithm -> Fairness metric calculation (CDP gap) -> Statistical significance testing

- Critical path: Propensity score model → Initial matching → Mahalanobis refinement → 1-1 counterpart identification → CDP gap calculation → Paired t-test

- Design tradeoffs:
  - Higher propensity score threshold → fewer counterparts but better confounding mitigation
  - More complex propensity score models → better confounding capture but potential overfitting
  - Larger δ threshold → more counterparts but less strict similarity requirements

- Failure signatures:
  - Very few counterparts identified → propensity score distributions too different or threshold too strict
  - High variance in CDP gap → insufficient sample size or high within-counterpart variability
  - CDP gap close to 0 but p-value significant → model systematically biased despite small average difference

- First 3 experiments:
  1. Test sensitivity of CFair to different propensity score model choices (logistic regression vs AdaBoost vs Random Forest)
  2. Vary the propensity score threshold and observe impact on number of counterparts and CDP gap values
  3. Apply CFair to different fairness metrics (equalized odds, equal opportunity) and compare results

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions but several implicit research directions emerge:

- How does the number of counterparts identified by CFair affect the statistical power and reliability of fairness evaluations?
- Can CFair be extended to handle multi-class sensitive attributes beyond binary race/gender categories?
- How sensitive is CFair to the choice of distance metric and propensity score model hyperparameters?

## Limitations

- Requires sufficient overlap in propensity score distributions between groups, which may not hold when systematic differences are large
- The choice of propensity score model and matching thresholds significantly impacts results but lacks clear guidance
- Assumes Mahalanobis distance adequately captures all relevant confounding factors, which remains unverified

## Confidence

- **High**: CFair successfully identifies counterparts using propensity score matching and Mahalanobis distance refinement
- **Medium**: CFair provides more accurate fairness assessment than traditional group-based metrics when systematic differences exist
- **Medium**: CFair can be extended to other group fairness metrics beyond demographic parity

## Next Checks

1. **Sensitivity Analysis**: Systematically vary propensity score model choices (logistic regression, AdaBoost, random forest) and matching thresholds to assess robustness of CFair results across different configurations.

2. **Power Analysis**: Conduct sample size calculations to determine minimum number of counterparts needed for reliable statistical significance testing, considering different effect sizes and variances.

3. **External Validation**: Apply CFair to additional datasets with known confounding structures (e.g., synthetic data with controlled systematic differences) to verify its ability to correctly identify unfairness.