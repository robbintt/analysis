---
ver: rpa2
title: 'DPZero: Private Fine-Tuning of Language Models without Backpropagation'
arxiv_id: '2310.09639'
source_url: https://arxiv.org/abs/2310.09639
tags:
- zeroth-order
- optimization
- private
- gradient
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DPZero addresses the dual challenges of memory constraints and
  privacy requirements in fine-tuning large language models (LLMs). The core idea
  is a nearly dimension-independent differentially private zeroth-order optimization
  method that relies solely on forward passes without backpropagation.
---

# DPZero: Private Fine-Tuning of Language Models without Backpropagation

## Quick Facts
- arXiv ID: 2310.09639
- Source URL: https://arxiv.org/abs/2310.09639
- Authors: 
- Reference count: 40
- One-line primary result: DPZero achieves nearly dimension-independent privacy guarantees for LLM fine-tuning by adding noise only to gradient magnitude

## Executive Summary
DPZero addresses the dual challenges of memory constraints and privacy requirements in fine-tuning large language models (LLMs). The core idea is a nearly dimension-independent differentially private zeroth-order optimization method that relies solely on forward passes without backpropagation. DPZero improves upon standard approaches by adding privacy noise only to the magnitude (scalar) of the gradient estimate rather than all dimensions, and by using a tighter clipping threshold analysis. Under a low effective rank structure assumption, DPZero achieves an error rate of $\tilde{O}(\sqrt{r \log(1/\delta)}/(n\varepsilon))$ for the squared gradient norm, where $r$ is the intrinsic dimension and $d$ appears only logarithmically.

## Method Summary
DPZero implements a zeroth-order optimization approach that estimates gradients using only forward passes through the model. The key innovation is adding privacy noise only to the scalar magnitude of finite-difference gradient estimates rather than to all $d$ dimensions. This is achieved by computing the finite difference $(f(x + \lambda u; \xi_i) - f(x - \lambda u; \xi_i))/(2\lambda)$ for a uniformly sampled direction $u$, clipping this scalar value, adding Gaussian noise, then scaling by the public direction vector $u$. The method also employs a tighter clipping threshold analysis that leverages the uniform distribution of directions to significantly reduce the clipping threshold from $O(L\sqrt{d})$ to $O(L)$, dramatically reducing privacy noise while maintaining the same privacy guarantees.

## Key Results
- Achieves error rate of $\tilde{O}(\sqrt{r \log(1/\delta)}/(n\varepsilon))$ for squared gradient norm
- Nearly dimension-independent: $d$ appears only logarithmically in the error bound
- Matches best known first-order private optimization rates when $r = d$
- Eliminates need for backpropagation, reducing memory overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DPZero improves upon standard approaches by adding privacy noise only to the magnitude (scalar) of the gradient estimate rather than all dimensions.
- Mechanism: Instead of adding Gaussian noise to all d dimensions of the gradient estimate as in Algorithm 1, DPZero adds univariate Gaussian noise only to the scalar value of the finite difference $(f(x_t + \lambda u_t; \xi_i) - f(x_t - \lambda u_t; \xi_i))/(2\lambda)$. The direction $u_t$ is treated as public information and is not privatized.
- Core assumption: The direction of the update vector $u_t$ can be treated as public knowledge without compromising privacy.
- Evidence anchors:
  - [abstract]: "DPZero improves upon standard approaches by adding privacy noise only to the magnitude (scalar) of the gradient estimate rather than all dimensions"
  - [section]: "First, since the direction of the update, $u_t$, is a public knowledge, we only need to make the 'magnitude' of our update private"
  - [corpus]: Weak - no direct evidence in neighbors about scalar vs vector noise addition
- Break condition: If the direction $u_t$ reveals information about the training data that needs to be protected, this mechanism fails.

### Mechanism 2
- Claim: DPZero achieves a tighter clipping threshold analysis that allows significantly smaller thresholds than worst-case bounds.
- Mechanism: While worst-case analysis suggests the finite difference could be as large as $L\sqrt{d}$, DPZero leverages the fact that $u_t$ is sampled uniformly from the sphere, making large values exponentially unlikely. By choosing the clipping threshold $C = O(L)$ instead of $O(L\sqrt{d})$, the noise added for privacy is dramatically reduced.
- Core assumption: The typical size of the finite difference is much smaller than the worst-case bound when $u_t$ is sampled uniformly from the sphere.
- Evidence anchors:
  - [section]: "we introduce a tighter analysis that allows us to choose a significantly smaller clipping threshold, leveraging the fact that the typical norm of the estimated gradient is much smaller than its maximum"
  - [section]: "the typical size of the finite-difference is $|u_t^T\nabla f(x_t; \xi_i)| + \ell^2\lambda d$"
  - [corpus]: Missing - neighbors don't discuss clipping threshold analysis
- Break condition: If the actual distribution of gradients doesn't match the theoretical bounds, the tighter clipping threshold could lead to excessive clipping.

### Mechanism 3
- Claim: Under low effective rank structure assumptions, DPZero achieves nearly dimension-independent rates where the error depends primarily on the intrinsic dimension $r$ rather than the ambient dimension $d$.
- Mechanism: When the Hessian has low effective rank $r \ll d$, both the squared norm of zeroth-order gradients and the DP noise scale with $r$ instead of $d$. DPZero's design with scalar noise and tight clipping preserves this $r$-dependence while avoiding the $d$-dependence present in Algorithm 1.
- Core assumption: The optimization problem exhibits low effective rank structure where $\text{Tr}(H) \leq r\|H\|^2$ with $r \ll d$.
- Evidence anchors:
  - [abstract]: "Under a low effective rank structure assumption, DPZero achieves an error rate of $\tilde{O}(\sqrt{r \log(1/\delta)}/(n\varepsilon))$ for the squared gradient norm, where $r$ is the intrinsic dimension and $d$ appears only logarithmically"
  - [section]: "This renders DPZero a highly practical option for real-world LLMs deployments"
  - [corpus]: Weak - neighbors mention low-rank structures but don't provide evidence for this specific mechanism
- Break condition: If the effective rank $r$ scales with $d$ ($r = d$), DPZero loses its dimension-independent advantage.

## Foundational Learning

- Concept: Differential Privacy (DP) and the Gaussian Mechanism
  - Why needed here: DPZero provides $(\epsilon, \delta)$-differential privacy guarantees for private fine-tuning, requiring understanding of how the Gaussian mechanism adds calibrated noise to ensure privacy
  - Quick check question: How does the variance of Gaussian noise scale with the sensitivity and privacy parameters in the advanced composition theorem?

- Concept: Zeroth-Order Optimization and Gradient Estimation
  - Why needed here: DPZero relies on estimating gradients using only function evaluations via the two-point estimator $g_\lambda(x; \xi_i) = (f(x + \lambda u; \xi_i) - f(x - \lambda u; \xi_i))/(2\lambda)u$, requiring understanding of how this compares to first-order methods
  - Quick check question: What is the relationship between the smoothing parameter $\lambda$ and the bias/variance tradeoff in zeroth-order gradient estimates?

- Concept: Low Effective Rank Structures in LLMs
  - Why needed here: DPZero's dimension-independent guarantees rely on the assumption that the Hessian has low effective rank, which has been empirically observed in LLM fine-tuning scenarios
  - Quick check question: How does the effective rank $r$ relate to the trace and spectral norm of the Hessian matrix?

## Architecture Onboarding

- Component map: Zeroth-order gradient estimator -> Clipping mechanism -> Privacy noise -> Update rule -> Low-rank analysis
- Critical path: Forward pass computation -> finite difference calculation -> clipping -> noise addition -> parameter update
- Design tradeoffs:
  - Memory vs accuracy: Forward passes save memory but may require more samples for accurate gradient estimates
  - Privacy vs utility: Tighter clipping thresholds reduce noise but risk clipping; looser thresholds add more noise
  - Computational cost: Scalar noise addition is cheaper than vector noise, but requires careful analysis
- Failure signatures:
  - Excessive clipping: Check if $C$ is too small by monitoring clipped gradient frequency
  - Poor convergence: Verify $\lambda$ is appropriately sized and $r$ is truly small
  - Privacy leakage: Ensure $u_t$ directions don't leak sensitive information
- First 3 experiments:
  1. Compare memory usage and gradient quality between DPZero and standard DP-SGD on a small LLM
  2. Test convergence sensitivity to clipping threshold $C$ across different tasks and datasets
  3. Verify effective rank $r$ empirically on pretrained LLM fine-tuning tasks and measure impact on DPZero performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can DPZero be extended to stochastic mini-batch settings while maintaining its dimension-independent convergence guarantees?
- Basis in paper: [inferred] The paper notes that DPZero uses full batch gradients and defers extensions to mini-batch settings to future research.
- Why unresolved: Mini-batch methods introduce additional noise and variance that may affect the delicate balance between privacy noise and gradient estimation accuracy.
- What evidence would resolve it: Theoretical analysis showing convergence rates under mini-batch updates, or empirical results comparing full-batch and mini-batch versions of DPZero on large language models.

### Open Question 2
- Question: Does the intrinsic noise in zeroth-order gradient estimators provide any inherent privacy benefits that could reduce the need for explicit DP mechanisms?
- Basis in paper: [explicit] The paper mentions that the exploration of whether zeroth-order gradient estimators' intrinsic noise could aid privacy is left for future research.
- Why unresolved: While the zeroth-order estimators add noise, it's unclear whether this noise provides meaningful differential privacy guarantees comparable to explicit DP mechanisms.
- What evidence would resolve it: Mathematical analysis showing the privacy guarantees of zeroth-order estimators alone, or empirical comparison of privacy leakage between zeroth-order and first-order methods.

### Open Question 3
- Question: Can momentum or variance reduction techniques improve DPZero's convergence rate while maintaining dimension-independence?
- Basis in paper: [explicit] The paper notes that while first-order methods can achieve $O((\sqrt{d \log(1/\delta)/(n\epsilon)})^{4/3})$ with momentum or variance reduction, it remains open whether similar improvements are possible for zeroth-order methods.
- Why unresolved: The challenge lies in adapting momentum or variance reduction techniques to work with zeroth-order gradient estimates without losing the dimension-independent property.
- What evidence would resolve it: Theoretical bounds showing improved convergence rates for DPZero variants incorporating momentum or variance reduction, or empirical results demonstrating speedups while maintaining dimension-independence.

## Limitations

- Theoretical analysis relies heavily on low effective rank assumption, which may not hold universally across all LLM fine-tuning scenarios
- Paper doesn't provide concrete guidelines for measuring or verifying the effective rank r in real-world applications
- Extensions to mini-batch settings and momentum/variance reduction techniques remain open questions

## Confidence

- **High confidence**: The mechanism of adding noise only to the scalar magnitude rather than all dimensions is clearly specified and mathematically sound. The memory efficiency benefits from avoiding backpropagation are well-established.
- **Medium confidence**: The tighter clipping threshold analysis and its impact on privacy-utility tradeoff appears theoretically sound but lacks extensive empirical validation across diverse tasks.
- **Medium confidence**: The dimension-independent rate guarantees under low effective rank assumptions are mathematically rigorous but depend on structural properties that may vary in practice.

## Next Checks

1. **Effective rank verification**: Empirically measure the effective rank $r$ on multiple pretrained LLM fine-tuning tasks to determine how commonly the dimension-independent regime applies.

2. **Clipping threshold sensitivity**: Systematically test DPZero's performance across a range of clipping thresholds $C$ on benchmark tasks to identify optimal settings and quantify sensitivity.

3. **Privacy leakage assessment**: Analyze whether the public direction vectors $u_t$ used in DPZero reveal sensitive information about the training data through gradient alignment or other metrics.