---
ver: rpa2
title: 'HAISTA-NET: Human Assisted Instance Segmentation Through Attention'
arxiv_id: '2305.03105'
source_url: https://arxiv.org/abs/2305.03105
tags:
- mask
- object
- segmentation
- r-cnn
- haista-net
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel human-assisted instance segmentation
  method, HAISTA-NET, which integrates human-specified partial boundaries into the
  existing Strong Mask R-CNN network. The authors present a dataset of hand-drawn
  partial object boundaries, referred to as human attention maps, and the Partial
  Sketch Object Boundaries (PSOB) dataset.
---

# HAISTA-NET: Human Assisted Instance Segmentation Through Attention

## Quick Facts
- arXiv ID: 2305.03105
- Source URL: https://arxiv.org/abs/2305.03105
- Reference count: 40
- One-line primary result: HAISTA-NET achieves +36.7 AP-Mask improvement over Mask R-CNN by integrating human-specified partial boundaries.

## Executive Summary
This paper introduces HAISTA-NET, a novel human-assisted instance segmentation method that integrates human-specified partial boundaries into the Strong Mask R-CNN network. The authors present the Partial Sketch Object Boundaries (PSOB) dataset containing hand-drawn partial object boundaries, referred to as human attention maps. The method demonstrates significant improvements in segmentation accuracy, particularly for small-scale and high-curvature objects, while maintaining user-friendly interaction for creating or editing these attention maps.

## Method Summary
The approach modifies the Strong Mask R-CNN architecture by adding a fourth channel to accept human attention maps, which are concatenated with RGB input at the first convolution layer. The PSOB dataset is created by having users draw partial boundaries on high-curvature regions of objects from the LVIS dataset. The model is trained using SGD with copy-paste augmentation, and the Ramer-Douglas-Peucker algorithm with adaptive epsilon (3% of object perimeter) is used to detect curvature points for generating ground truth attention maps.

## Key Results
- HAISTA-NET achieves +36.7 AP-Mask improvement over baseline Mask R-CNN
- +29.6 AP-Mask improvement over Strong Mask R-CNN
- +26.5 AP-Mask improvement over Mask2Former
- Significant performance gains particularly on small-scale and high-curvature objects

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adding a fourth channel for human attention maps allows the model to explicitly encode high-curvature regions where automated segmentation tends to fail.
- Mechanism: The human attention map is concatenated as a sparse binary channel (255 at attention points, 10 elsewhere) and fed into the first convolution layer, letting the network prioritize these regions during feature extraction.
- Core assumption: High-curvature points are the most problematic for instance segmentation and can be reliably identified and annotated by humans.
- Evidence anchors: [abstract] "...hand-drawn partial object boundaries which represent curvatures of an object's ground truth mask with several pixels." [section] "These sketched points represent human assistance in our work."
- Break condition: If human attention maps are noisy, incomplete, or misaligned with actual curvature failures, the model will not benefit and may overfit to irrelevant cues.

### Mechanism 2
- Claim: Using an adaptive epsilon for the RDP algorithm better detects curvature points across different object scales than a fixed epsilon.
- Mechanism: The epsilon is set to 3% of the object's perimeter, calculated dynamically, to simplify the boundary polygon while preserving true curvature locations.
- Core assumption: Fixed epsilon values in RDP are scale-dependent and may either oversimplify large objects or over-preserve noise in small objects.
- Evidence anchors: [section] "Designated static RDP epsilon values require parameter tuning for every scale of the object. In order to fine tune this value, we calculate the perimeter of the polygon..."
- Break condition: If the 3% heuristic fails for objects with extreme aspect ratios or unusual boundary complexity, curvature detection will degrade.

### Mechanism 3
- Claim: The model benefits more from partial boundary sketches than from full manual annotation in terms of annotation time and segmentation accuracy.
- Mechanism: Partial sketches reduce user input load by focusing only on high-curvature sections, while still enabling the model to reconstruct accurate masks via learned attention integration.
- Core assumption: Full manual annotation is significantly slower than targeted sketching, and partial information is sufficient for accurate mask reconstruction.
- Evidence anchors: [section] "Since our model takes extra user input during training and inference, shorter interaction is better... Time analysis shows that total interaction time is roughly three times longer than sketching time..." [section] "LVIS-Like interactions have the best quality but take the longest time... PSOB annotations are partial data, they take the shortest time."
- Break condition: If high-curvature regions are not the main source of segmentation errors, or if user sketches are imprecise, partial annotation will not yield performance gains.

## Foundational Learning

- Concept: Convolution layer weight initialization and channel expansion
  - Why needed here: The model overrides the first convolution of the backbone to accept a 4-channel input (3 RGB + 1 attention), requiring careful weight initialization to preserve learned features.
  - Quick check question: What happens if the fourth channel weights are initialized with zeros instead of a small random range?

- Concept: Adaptive epsilon calculation in the Ramer-Douglas-Peucker algorithm
  - Why needed here: Ensures curvature detection is scale-invariant and avoids manual tuning for different object sizes.
  - Quick check question: How does the perimeter-based epsilon formula change the number of detected curvature points for very small vs. very large objects?

- Concept: Data augmentation with simple copy-paste and its effect on model performance
  - Why needed here: Increases dataset diversity and addresses rare category performance without extra manual labeling.
  - Quick check question: Why does simple copy-paste yield a smaller AP improvement for HAISTA-NET compared to Mask R-CNN?

## Architecture Onboarding

- Component map: User Attention Map -> 4-Channel Input (RGB + Attention) -> Modified Backbone (ResNeXt-101-FPN) -> Feature Pyramid Network -> Mask R-CNN Head -> Instance Segmentation Output
- Critical path:
  1. User draws attention strokes on high-curvature regions.
  2. Attention map is generated and concatenated with RGB image.
  3. Modified backbone processes the 4-channel input.
  4. Network outputs instance segmentation masks.
  5. Model trained with PSOB dataset (LVIS + human attention maps).
- Design tradeoffs:
  - Partial annotation vs. full annotation: Faster interaction but requires accurate identification of critical curvature points.
  - 4-channel input vs. 3-channel: Adds model complexity but enables targeted feature learning.
  - Adaptive RDP epsilon vs. fixed epsilon: More robust across scales but introduces a hyperparameter choice.
- Failure signatures:
  - Model underperforms if attention maps are misaligned with actual curvature failures.
  - Training instability if fourth channel weights are not properly initialized.
  - Overfitting if training data lacks diversity in object scales or curvature types.
- First 3 experiments:
  1. Ablation study: Train with and without the human attention map channel to measure impact on AP.
  2. Curvature sensitivity test: Compare performance on low, medium, and high curvature objects.
  3. Annotation time study: Measure interaction time for partial sketches vs. full manual annotation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of HAISTA-NET scale with increasing numbers of user attention maps per object?
- Basis in paper: [inferred] The paper mentions that 30 users annotated 18,677 objects, but does not explore the impact of varying the number of annotations per object on model performance.
- Why unresolved: The paper focuses on demonstrating the effectiveness of the approach with the collected dataset, but does not investigate how performance changes with different annotation densities.
- What evidence would resolve it: Experiments varying the number of user attention maps per object and measuring the corresponding changes in AP-Mask and AP-Bbox metrics would clarify the relationship between annotation density and model performance.

### Open Question 2
- Question: Can HAISTA-NET be effectively extended to other computer vision tasks beyond instance segmentation, such as object detection or panoptic segmentation?
- Basis in paper: [explicit] The authors state that HAISTA-NET "can be easily extended to other computer vision tasks such as object detection, panoptic segmentation, etc."
- Why unresolved: While the authors claim extensibility, they do not provide empirical evidence or implementation details for applying HAISTA-NET to other tasks.
- What evidence would resolve it: Implementing and evaluating HAISTA-NET on other computer vision tasks (e.g., object detection, panoptic segmentation) and comparing its performance to state-of-the-art methods would demonstrate its effectiveness across different applications.

### Open Question 3
- Question: How does the quality of human attention maps impact the performance of HAISTA-NET, and what factors influence the quality of these maps?
- Basis in paper: [inferred] The paper introduces human attention maps as a key component of HAISTA-NET, but does not extensively explore the relationship between map quality and model performance or the factors that influence map quality.
- Why unresolved: The paper focuses on demonstrating the effectiveness of human attention maps in general, but does not investigate the nuances of map quality and its impact on performance.
- What evidence would resolve it: Conducting user studies to evaluate the impact of different drawing styles, precision levels, and other factors on the quality of human attention maps and their corresponding effects on HAISTA-NET performance would provide insights into the relationship between map quality and model performance.

## Limitations
- Performance is highly dependent on the quality and accuracy of human attention maps, with no clear analysis of failure modes when attention maps are noisy or misaligned.
- The paper lacks extensive ablation studies to isolate the contribution of different components (adaptive epsilon, 4-channel input, etc.) to the overall performance gains.
- Limited exploration of how the model performs across different object types and scales beyond the initial categorization presented in the PSOB dataset.

## Confidence
- Performance improvement claims: High confidence based on quantitative results
- Efficiency gains from partial annotation: Medium confidence due to limited time measurements and user study scope
- Mechanism claims about curvature encoding: Medium confidence due to lack of ablation studies isolating component contributions

## Next Checks
1. Cross-user reliability test: Measure performance variance when different users provide attention maps for the same objects to quantify the impact of human input quality.
2. Attention map quality ablation: Compare model performance using perfectly aligned attention maps, noisy attention maps, and random attention maps to establish the sensitivity to user input quality.
3. Scale invariance validation: Test the adaptive epsilon formula on objects with extreme aspect ratios (very thin or very wide objects) to verify the 3% perimeter heuristic works across all cases.