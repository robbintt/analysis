---
ver: rpa2
title: Robust Learning with Progressive Data Expansion Against Spurious Correlation
arxiv_id: '2306.04949'
source_url: https://arxiv.org/abs/2306.04949
tags:
- data
- spurious
- learning
- training
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of spurious correlations in deep
  learning, where models learn to rely on easily identifiable but task-irrelevant
  features (e.g., background) rather than the core features genuinely correlated with
  the true label. The authors provide theoretical analysis of a two-layer nonlinear
  CNN model, demonstrating that imbalanced data groups and easily learnable spurious
  features lead to the dominance of spurious features during training, resulting in
  poor worst-group accuracy.
---

# Robust Learning with Progressive Data Expansion Against Spurious Correlation

## Quick Facts
- arXiv ID: 2306.04949
- Source URL: https://arxiv.org/abs/2306.04949
- Reference count: 6
- This paper addresses spurious correlations in deep learning and proposes Progressive Data Expansion (PDE) to improve worst-group accuracy.

## Executive Summary
This paper addresses the problem of spurious correlations in deep learning, where models learn to rely on easily identifiable but task-irrelevant features (e.g., background) rather than the core features genuinely correlated with the true label. The authors provide theoretical analysis of a two-layer nonlinear CNN model, demonstrating that imbalanced data groups and easily learnable spurious features lead to the dominance of spurious features during training, resulting in poor worst-group accuracy. To address this, they propose Progressive Data Expansion (PDE), a two-stage training algorithm that begins with a group-balanced subset of training data and progressively expands it, leveraging momentum to facilitate learning of core features. PDE achieves superior performance on both synthetic and real-world benchmark datasets (Waterbirds, CelebA, and CivilComments-WILDS), with an average 2.8% improvement in worst-group accuracy compared to the state-of-the-art method GroupDRO. Notably, PDE also enjoys up to 10× faster training efficiency due to its efficient warm-up stage and momentum-based expansion.

## Method Summary
The paper proposes Progressive Data Expansion (PDE), a two-stage training algorithm to address spurious correlations. The method starts with a group-balanced warm-up stage where the model learns core features without interference from spurious features. In the expansion stage, new data is progressively added using momentum from the warm-up to amplify core feature learning. The algorithm leverages the theoretical insight that balancing groups cancels spurious gradients while momentum retains historical gradients to amplify core features. PDE is evaluated on synthetic data and real-world benchmarks (Waterbirds, CelebA, CivilComments-WILDS) using worst-group accuracy as the primary metric.

## Key Results
- PDE achieves 2.8% average improvement in worst-group accuracy compared to GroupDRO on benchmark datasets
- PDE demonstrates up to 10× faster training efficiency than state-of-the-art methods
- The method successfully avoids learning spurious features during the warm-up stage as verified on synthetic data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Group imbalance combined with easier learnability of spurious features causes spurious feature dominance in early training.
- Mechanism: When spurious features are stronger and easier to learn than core features, the gradient update magnitudes favor spurious features, leading the model to quickly latch onto them before core features can be learned.
- Core assumption: The data distribution creates a scenario where spurious features are both more frequent (imbalanced groups) and have higher learnability coefficients (β_s >> β_c).
- Evidence anchors:
  - [abstract]: "Our analysis suggests that imbalanced data groups and easily learnable spurious features can lead to the dominance of spurious features during the learning process."
  - [section 2.2]: The data model explicitly constructs scenarios where spurious features are stronger and groups are imbalanced, leading to rapid spurious feature learning.
  - [corpus]: No direct corpus evidence for this specific mechanism; the paper provides theoretical and synthetic experimental support.
- Break condition: If β_c > β_s (core features become easier to learn than spurious features), the model will learn core features first regardless of group imbalance.

### Mechanism 2
- Claim: Training on a group-balanced subset prevents spurious feature learning by canceling spurious gradients.
- Mechanism: In a perfectly balanced dataset, the spurious feature gradients from positive and negative examples cancel out, while core feature gradients reinforce each other, allowing core feature learning without spurious interference.
- Core assumption: The spurious feature is perfectly correlated with one class label, and balancing the groups creates equal and opposite gradient contributions from spurious features.
- Evidence anchors:
  - [section 3.2]: "With bα = 1/2 we have |S0_1| = |S0_2|: an equal amount of data is positively correlated with the spurious feature as the data negatively correlated with the spurious feature. In each update, both groups contribute nearly the same amount of spurious feature gradient with different signs, resulting in cancellation."
  - [corpus]: No corpus evidence for this specific mechanism; the paper provides theoretical justification.
- Break condition: If the spurious correlation is not perfectly balanced (e.g., slight imbalance remains), some spurious gradient will persist and accumulate.

### Mechanism 3
- Claim: Momentum from the warm-up stage amplifies core feature learning when new data is added, allowing tolerance of group imbalance.
- Mechanism: Once the model learns core features during warm-up, the momentum term retains historical gradients containing core feature information. When new data is added, these historical gradients amplify the core feature signal, making it grow faster than the spurious feature even with imbalanced groups.
- Core assumption: Gradient descent with momentum retains sufficient historical gradient information to influence subsequent learning, and the core feature signal is present in the gradients of new data.
- Evidence anchors:
  - [section 3.2]: "the momentum from warm-up, in turn, amplifies the core feature that is present in the gradients of newly added data, facilitating the continued learning of vc in the expansion stage."
  - [section 4.2.3]: "the model has acquired the appropriate features and maintains learning based on its historical gradient stored in the momentum."
  - [corpus]: No corpus evidence for this specific mechanism; the paper provides theoretical and experimental support.
- Break condition: If the learning rate is too high or momentum coefficient too low, the historical gradients may be overwritten before they can effectively amplify core feature learning.

## Foundational Learning

- Concept: Gradient descent dynamics in nonlinear neural networks
  - Why needed here: The paper analyzes how gradient updates behave in a two-layer nonlinear CNN when learning core vs spurious features.
  - Quick check question: In the two-layer CNN with cubic activation, what is the form of the gradient update for a single neuron with respect to a feature vector v?

- Concept: Spurious correlation and domain generalization
  - Why needed here: The entire problem setting revolves around models learning task-irrelevant features that correlate with labels in training data but not in deployment.
  - Quick check question: What is the difference between core features and spurious features in the context of this paper's data model?

- Concept: Momentum-based optimization algorithms
  - Why needed here: The PDE algorithm uses momentum to retain and amplify core feature gradients during the expansion stage.
  - Quick check question: How does the momentum term in gradient descent with momentum (GD+M) differ from standard gradient descent in terms of parameter updates?

## Architecture Onboarding

- Component map:
  - Data preprocessing: Create balanced warm-up set by subsampling groups
  - Model: Two-layer nonlinear CNN (or other architecture) with cubic activation
  - Optimizer: Gradient descent with momentum (γ typically 0.9)
  - Training loop: Warm-up stage → Progressive expansion stage
  - Evaluation: Worst-group accuracy across all (y, a) combinations

- Critical path: Data → Balanced warm-up → Core feature learning → Momentum accumulation → Progressive data addition → Core feature amplification → Final model

- Design tradeoffs:
  - Warm-up size vs. training efficiency: Larger warm-up sets provide better core feature learning but reduce the benefit of progressive expansion
  - Expansion rate vs. robustness: Faster expansion may reintroduce spurious learning; slower expansion is more robust but less efficient
  - Momentum coefficient vs. stability: Higher momentum retains gradients better but may cause instability if learning rate is too high

- Failure signatures:
  - Poor worst-group accuracy indicates spurious feature dominance
  - Very slow convergence suggests insufficient momentum or poor warm-up
  - Sudden drops in performance during expansion indicate spurious feature re-emergence
  - Overfitting to warm-up set shows insufficient expansion or poor generalization

- First 3 experiments:
  1. Run PDE on synthetic data with known β_c < β_s and bα > 0.5 to verify spurious feature avoidance
  2. Compare PDE with GroupDRO on Waterbirds dataset using same learning rate and weight decay
  3. Test PDE with different warm-up durations to find optimal balance between core learning and efficiency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can PDE be effectively extended to multi-class classification problems where spurious correlations exist across multiple classes?
- Basis in paper: [inferred] The authors note that their analysis focuses on a simplified binary classification data model and suggest that future work could involve extending to multi-class classification problems.
- Why unresolved: The current theoretical analysis and algorithm design are tailored for binary classification, and it's unclear how the group-balancing and progressive expansion approach would generalize to scenarios with multiple classes and complex spurious correlation patterns.
- What evidence would resolve it: Experiments demonstrating PDE's effectiveness on benchmark multi-class datasets with known spurious correlations, such as CIFAR-10/100 with background or texture biases, would provide concrete evidence.

### Open Question 2
- Question: How does PDE perform when applied to Transformer architectures, given their different learning dynamics compared to CNNs?
- Basis in paper: [inferred] The authors suggest examining the training of transformer architectures as a direction for future work, implying uncertainty about PDE's applicability to these models.
- Why unresolved: The current theoretical framework and experiments focus on CNNs, and the unique self-attention mechanisms in Transformers may interact differently with spurious features during training.
- What evidence would resolve it: Empirical results showing PDE's performance on Transformer-based models like BERT or ViT when trained on datasets with spurious correlations would clarify its effectiveness across architectures.

### Open Question 3
- Question: What is the impact of data augmentation on PDE's performance, and how does it compare to its effect on other methods like GroupDRO?
- Basis in paper: [explicit] The authors mention that data augmentation leads to slightly worse performance for GroupDRO but effectively benefits PDE, suggesting a differential impact.
- Why unresolved: The underlying reasons for this difference are not fully explored, and it's unclear whether this advantage of PDE holds across various types of data augmentation techniques.
- What evidence would resolve it: A systematic study comparing PDE and GroupDRO across multiple data augmentation strategies (e.g., random cropping, color jittering, mixup) on datasets with spurious correlations would provide insights into the robustness of PDE to augmentation.

## Limitations
- The theoretical analysis assumes a simplified two-layer nonlinear CNN model which may not capture the complexity of modern deep learning architectures.
- The paper lacks empirical validation of the momentum mechanism's amplification effect through ablation studies or gradient dynamics visualization.
- The warm-up stage's reliance on group labels raises concerns about applicability when group information is unknown or costly to obtain.

## Confidence
- **High confidence**: The core claim that group imbalance combined with easier learnability of spurious features leads to spurious feature dominance is well-supported by theoretical analysis and synthetic experiments.
- **Medium confidence**: The mechanism of spurious gradient cancellation through balanced training is theoretically sound but lacks direct empirical validation beyond the synthetic setting.
- **Medium confidence**: The momentum amplification mechanism is theoretically justified but requires more rigorous experimental verification, particularly on complex real-world datasets.

## Next Checks
1. **Ablation study on momentum coefficient**: Systematically vary the momentum coefficient (γ) in PDE to quantify its impact on core feature amplification and worst-group accuracy improvement.
2. **Visualization of gradient dynamics**: Track and visualize the evolution of core and spurious feature gradients during both warm-up and expansion stages to empirically verify the cancellation and amplification mechanisms.
3. **Group-agnostic variant**: Develop and test a variant of PDE that does not require group labels, using unsupervised methods to approximate group-balanced subsets, to assess practical applicability in real-world scenarios.