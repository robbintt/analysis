---
ver: rpa2
title: Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive
  and Language-Contrastive Decoding
arxiv_id: '2309.07098'
source_url: https://arxiv.org/abs/2309.07098
tags:
- translation
- language
- machine
- decoding
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces source-contrastive and language-contrastive
  decoding objectives to mitigate hallucinations and off-target translations in massively
  multilingual machine translation models. The method searches for translations that
  are probable given the correct input but improbable given corrupted inputs, either
  by using a random source segment (source-contrastive) or by varying the language
  indicator token (language-contrastive).
---

# Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding

## Quick Facts
- arXiv ID: 2309.07098
- Source URL: https://arxiv.org/abs/2309.07098
- Reference count: 17
- Reduces defective translations (chrF2 < 10) by 67-83% on average

## Executive Summary
This paper addresses two critical problems in massively multilingual machine translation: hallucinations (nonsense or source-irrelevant outputs) and off-target translations (outputs in wrong language). The authors introduce source-contrastive and language-contrastive decoding objectives that search for translations probable given the correct input but improbable given corrupted inputs. Source-contrastive decoding uses random source segments as contrastive inputs, while language-contrastive decoding varies the language indicator token. Experiments on M2M-100 (418M) and SMaLL-100 models across 57 translation directions show significant reductions in defective translations (chrF2 < 10) by 67-83% on average and chrF2 improvements of 1.7 and 1.3 points respectively.

## Method Summary
The method modifies the standard translation decoding objective by adding contrastive penalties. Source-contrastive decoding adds a penalty term that minimizes the probability of the translation given a corrupted source (random source segment), forcing the model to remain grounded in the correct source context. Language-contrastive decoding adds a penalty that minimizes probability under wrong target language indicators, suppressing off-target translations. The combined objective sums both penalties with tunable weights λsrc and λlang. The approach is implemented using beam search with a beam size of 5, using λsrc = 0.7 and λlang = 0.1 across all experiments.

## Key Results
- chrF2 improves by 1.7 points on M2M-100 and 1.3 points on SMaLL-100 models
- Reduces defective translations (chrF2 < 10) by 67-83% on average across 57 translation directions
- Reduces oscillatory hallucinations by 75-92% in directions prone to this issue
- Reduces off-target translations by 35-100% in affected directions
- spBLEU improvements are more modest (0.2 on M2M-100, 0.3 on SMaLL-100)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive inputs that are improbable given the corrupted source force the model to remain grounded in the correct source context, reducing hallucinations.
- Mechanism: During decoding, the model is penalized for generating translations that are equally probable under both the correct source and a corrupted source. Since hallucinations are detached from the source, they will be similarly probable under both, so this penalty suppresses them.
- Core assumption: Hallucinations are source-agnostic and thus equally probable under the true and corrupted inputs.
- Evidence anchors:
  - [abstract]: "In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment, hypothesising that hallucinations will be similarly probable given either."
  - [section 2]: "Rather than finding a translation that maximizes p(Y |X), we search for one that both maximizes p(Y |X) and minimizes p(Y |X′)."
- Break condition: If hallucinations are actually source-dependent or if the corrupted source introduces confounding patterns, the penalty might not effectively suppress hallucinations.

### Mechanism 2
- Claim: Contrastive inputs that are improbable given the wrong language indicator token suppress off-target translations.
- Mechanism: During decoding, the model is penalized for generating translations that are probable under both the correct target language and a contrastive target language. If a translation is in the wrong language, it will have similar or higher probability under the contrastive language, so this penalty suppresses it.
- Core assumption: Off-target translations are more probable under the wrong target language than the correct one.
- Evidence anchors:
  - [abstract]: "In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token."
  - [section 2]: "Let ly be the language indicator token, and ly the desired target language. We simply add contrastive variants ly for output languages we wish to suppress."
- Break condition: If the model's probability is not sensitive to the language indicator token, or if the contrastive languages are not representative of likely off-target outputs, the penalty may not suppress off-target translations effectively.

### Mechanism 3
- Claim: The combination of source-contrastive and language-contrastive decoding can address both hallucinations and off-target translations simultaneously.
- Mechanism: By summing the penalties from both source-contrastive and language-contrastive decoding, the model is penalized for generating translations that are probable under the corrupted source or the wrong language, forcing it to remain grounded in the correct source and target language.
- Core assumption: The two mechanisms are complementary and do not interfere with each other.
- Evidence anchors:
  - [abstract]: "We can combine source-contrastive and language-contrastive decoding by summing all contrastive variants, and will then refer to the individual weights as λsrc and λlang."
  - [section 3.2]: "Improvements are more modest when measured with spBLEU (0.2 on M2M-100; 0.3 on SMaLL-100)."
- Break condition: If the two mechanisms conflict or if the combined penalty is too strong, it may degrade translation quality.

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: The method relies on contrasting probabilities given different inputs to guide the decoding process.
  - Quick check question: How does contrastive learning differ from standard supervised learning, and why is it suitable for this application?

- Concept: Language identification
  - Why needed here: The method requires identifying the target language to apply the language-contrastive decoding.
  - Quick check question: What are the challenges in language identification, especially for closely related languages like Serbian and Croatian?

- Concept: Beam search decoding
  - Why needed here: The method modifies the decoding objective, which is typically used in beam search.
  - Quick check question: How does beam search work, and how does modifying the decoding objective affect the search process?

## Architecture Onboarding

- Component map: Translation model -> Contrastive input generator -> Decoding objective modifier -> Language identifier -> Evaluation metrics
- Critical path: 1) Generate contrastive inputs for a given source segment 2) Modify the decoding objective to include contrastive penalties 3) Decode the translation using modified objective 4) Evaluate translation using evaluation metrics
- Design tradeoffs: The choice of λsrc and λlang affects the balance between translation quality and hallucination/off-target suppression; the choice of contrastive inputs affects the effectiveness of penalties
- Failure signatures: High chrF2 but high off-target rate (source-contrastive effective but language-contrastive not); low chrF2 and high off-target rate (both objectives ineffective)
- First 3 experiments: 1) Evaluate baseline translation quality without any contrastive decoding 2) Evaluate translation quality with only source-contrastive decoding 3) Evaluate translation quality with both source-contrastive and language-contrastive decoding

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does source-contrastive decoding affect translation quality across different types of hallucinations (e.g., content hallucination vs. non-sense generation)?
- Basis in paper: [inferred] The paper measures hallucination reduction through chrF2 < 10 but does not distinguish between hallucination types.
- Why unresolved: The current evaluation metric (chrF2 < 10) provides a binary classification of defective translations but does not differentiate between types of hallucinations or their severity.
- What evidence would resolve it: Detailed error analysis categorizing hallucinations by type and severity, comparing baseline and contrastive decoding outputs.

### Open Question 2
- Question: What is the optimal λsrc value for different language pairs and resource levels?
- Basis in paper: [explicit] The paper uses a fixed λsrc = 0.7 for all experiments with minimal hyperparameter tuning.
- Why unresolved: The authors acknowledge that using the same hyperparameters across translation directions results in performance degradations for some cases, particularly high-resource directions.
- What evidence would resolve it: Systematic hyperparameter tuning across different language pairs and resource levels, with detailed analysis of optimal λsrc values.

### Open Question 3
- Question: How does language-contrastive decoding perform when applied to modular architectures with language-specific components instead of language indicator tokens?
- Basis in paper: [explicit] The paper explicitly states this limitation in the "Limitations" section.
- Why unresolved: The paper only tested language-contrastive decoding on models that use language indicator tokens, leaving the effectiveness on modular architectures untested.
- What evidence would resolve it: Experiments applying language-contrastive decoding to modular architectures like those mentioned (Firat et al., 2016; Vázquez et al., 2019; Bapna and Firat, 2019).

## Limitations

- The approach increases computational overhead during decoding by requiring probability evaluations under multiple corrupted inputs
- All experiments are conducted on relatively small models (418M parameters), leaving generalization to larger models untested
- The off-target translation evaluation relies on language identification with unspecified confidence thresholds, which may affect reported results

## Confidence

**High Confidence Claims**:
- The contrastive decoding framework is technically sound and mathematically well-defined (equations 1 and 2)
- Source-contrastive decoding effectively reduces the number of severely defective translations (chrF2 < 10)
- Language-contrastive decoding reduces off-target translations in directions prone to this issue

**Medium Confidence Claims**:
- The average chrF2 improvement of 1.7 points on M2M-100 and 1.3 points on SMaLL-100 is statistically significant and practically meaningful
- The λsrc = 0.7 and λlang = 0.1 hyperparameters are reasonable choices that work well across diverse translation directions

**Low Confidence Claims**:
- The approach will generalize equally well to much larger translation models
- The computational overhead is acceptable for practical deployment
- The automatic metrics used (chrF2, spBLEU) fully capture the quality improvements

## Next Checks

1. **Runtime Analysis**: Measure and report the wall-clock time for decoding with and without contrastive penalties across the same translation directions, quantifying the computational overhead and its impact on practical deployment.

2. **Cross-Model Validation**: Apply the method to a larger translation model (e.g., M2M-100 1.2B or a similar-sized model) and evaluate whether the chrF2 improvements and hallucination reduction scale proportionally or if larger models show different patterns.

3. **Manual Quality Assessment**: Conduct human evaluation on a subset of translations (both high and low chrF2) to verify that the automatic metrics correlate with human judgments of translation quality, particularly focusing on whether reduced chrF2 scores correspond to genuinely better translations or just different types of errors.