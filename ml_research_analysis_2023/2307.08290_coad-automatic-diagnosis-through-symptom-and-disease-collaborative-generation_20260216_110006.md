---
ver: rpa2
title: 'CoAD: Automatic Diagnosis through Symptom and Disease Collaborative Generation'
arxiv_id: '2307.08290'
source_url: https://arxiv.org/abs/2307.08290
tags:
- symptom
- disease
- symptoms
- diagnosis
- coad
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents CoAD, a novel disease and symptom collaborative
  generation framework for automatic diagnosis (AD). CoAD addresses two key challenges
  in AD: the mismatch between symptoms observed during training and generation, and
  the effect of different symptom orders on disease prediction.'
---

# CoAD: Automatic Diagnosis through Symptom and Disease Collaborative Generation

## Quick Facts
- arXiv ID: 2307.08290
- Source URL: https://arxiv.org/abs/2307.08290
- Reference count: 11
- Key outcome: Achieves 2.3% average improvement over state-of-the-art in automatic disease diagnosis

## Executive Summary
CoAD introduces a novel framework for automatic diagnosis that addresses key challenges in symptom-disease generation tasks. The framework tackles the mismatch between training and inference symptom availability and the impact of symptom order on disease prediction through three innovations: disease label alignment with multiple symptom inquiry steps, symptom label expansion for sub-sequences, and a repeated symptom input schema with attention masking. Experiments on four datasets demonstrate consistent improvements in disease accuracy and symptom recall compared to previous approaches.

## Method Summary
CoAD is a sequence-to-sequence framework that uses a Transformer decoder to generate symptom sequences and predict diseases. The method introduces three key innovations: aligning disease labels with multiple symptom inquiry steps to bridge training-inference gaps, expanding symptom labels for each sub-sequence to eliminate order effects, and using repeated symptom inputs with attention masking to efficiently learn the expanded labels. The model is trained with combined cross-entropy loss over both symptom and disease predictions, with attention masks ensuring proper temporal dependencies during symptom generation.

## Key Results
- Achieves 2.3% average improvement over previous state-of-the-art results
- Demonstrates consistent performance gains across four datasets (Dxy, Muzhi, Muzhi-2, Ped)
- Shows improved implicit symptom recall and reduced average inquiry turns compared to baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aligning disease labels with multiple symptom inquiry steps bridges the training-inference gap
- Mechanism: For each symptom sequence, the disease label is replicated and assigned to each possible symptom step during training, ensuring the model sees the disease label even when only partial symptoms are available at inference
- Core assumption: The disease label remains valid for partial symptom sequences when symptoms are acquired in the same order as training
- Evidence anchors:
  - [abstract]: "aligning sentence-level disease labels with multiple possible symptom inquiry steps to bridge the gap between training and generation"
  - [section 4.1]: "we assign the disease label d* of a symptom sequence {s1:N E, s1:M I} to each available implicit symptom sK I âˆˆ s1:M I"
- Break condition: If symptom acquisition order differs significantly from training, or if symptoms are missing entirely, the alignment may not bridge the gap effectively

### Mechanism 2
- Claim: Expanding symptom labels for each sub-sequence eliminates the effect of symptom order
- Mechanism: For each sub-sequence of symptoms, all possible subsequent symptom labels are provided as training targets, making the model robust to different symptom orderings
- Core assumption: Disease determination is independent of symptom order
- Evidence anchors:
  - [abstract]: "expanding symptom labels for each sub-sequence of symptoms to enhance annotation and eliminate the effect of symptom order"
  - [section 4.2]: "A sub-sequence of symptoms s1:K I not only has the symptom label of the next symptom sK+1 I, but also of the subsequent symptoms sK+1:M I"
- Break condition: If symptom order does affect disease determination (e.g., temporal dependencies in symptoms), this mechanism may introduce noise

### Mechanism 3
- Claim: Repeated symptom input schema with symptom attention enables efficient learning of expanded labels
- Mechanism: Symptoms are repeated in the input sequence to match the expanded label structure, with attention masks ensuring each repeated symptom only attends to itself, explicit symptoms, and one previous repeated symptom
- Core assumption: The repeated structure with attention masking preserves the sequential nature of symptom acquisition while enabling parallel learning
- Evidence anchors:
  - [abstract]: "developing a repeated symptom input schema to effectively and efficiently learn the expanded disease and symptom labels"
  - [section 4.2]: "we simply repeat the symptoms as many times as their corresponding expanded symptom or disease labels" and "each repeated symptom can only see itself, the explicit symptoms, and only one of the previous repeated symptoms"
- Break condition: If the attention masking is too restrictive or too permissive, it may either underfit or overfit to the repeated structure

## Foundational Learning

- Concept: Sequence-to-sequence modeling with attention mechanisms
  - Why needed here: The model needs to generate symptom sequences and classify diseases based on symptom sequences, requiring understanding of how attention mechanisms work in sequence modeling
  - Quick check question: What is the difference between encoder-decoder attention and self-attention in Transformer architectures?

- Concept: Data augmentation techniques in NLP
  - Why needed here: The paper uses novel data augmentation approaches (label expansion and repeated inputs) to address training-inference mismatch and order invariance
  - Quick check question: How does label expansion differ from traditional data augmentation techniques like synonym replacement or back-translation?

- Concept: Auto-regressive generation and cross-entropy loss
  - Why needed here: The model is trained using auto-regressive generation with cross-entropy loss over the expanded symptom and disease labels
  - Quick check question: What is the difference between teacher forcing and auto-regressive generation during training?

## Architecture Onboarding

- Component map:
  - Input layer: Repeated symptom embeddings, symptom status embeddings, symptom mask
  - Transformer decoder backbone: 6 layers, 768 hidden size, 6 attention heads
  - Output heads: Symptom head (for s-labels) and disease head (for d-labels)
  - Loss function: Combined cross-entropy loss over expanded labels

- Critical path:
  1. Input preparation (repeated symptoms + masks)
  2. Transformer decoding with attention masking
  3. Dual output prediction (symptoms + diseases)
  4. Combined loss computation and backpropagation

- Design tradeoffs:
  - Memory vs. performance: Repeated inputs increase memory usage but improve performance by aligning training and inference
  - Complexity vs. simplicity: The dual-label expansion adds implementation complexity but addresses fundamental training-inference mismatch
  - Attention masking granularity: The masking strategy balances between preserving sequential information and enabling parallel learning

- Failure signatures:
  - Symptom recall drops significantly: May indicate attention masking is too restrictive or repeated input structure is not learned properly
  - Disease accuracy drops: May indicate d-label alignment is introducing noise or the model is overfitting to partial sequences
  - Training instability: May indicate the combined loss is unbalanced or the label expansion is creating conflicting signals

- First 3 experiments:
  1. Test d-label alignment alone (without s-label augmentation) to verify it addresses the training-inference gap
  2. Test s-label augmentation alone (without d-label alignment) to verify it addresses symptom order invariance
  3. Test the repeated input schema with standard labels to verify the attention masking works as intended before adding the complexity of expanded labels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the CoAD framework perform when adapted to scenarios where multiple symptoms can be queried simultaneously?
- Basis in paper: [inferred] The paper states that "CoAD only allows for the querying of one symptom at a time, making it unsuitable for scenarios where multiple symptoms are present."
- Why unresolved: The current CoAD framework is designed to query one symptom at a time, and its performance in scenarios where multiple symptoms are queried simultaneously is not explored.
- What evidence would resolve it: Experiments comparing the performance of CoAD with other models when adapted to allow multiple symptom queries simultaneously, particularly in terms of disease accuracy and symptom recall.

### Open Question 2
- Question: What are the potential impacts of incorporating a natural language understanding (NLU) module to parse plain text symptoms and a natural language generation (NLG) module to translate predicted symptoms or diseases into text in the CoAD framework?
- Basis in paper: [explicit] The paper mentions that "To make it more applicable to end-to-end settings, an natural language understanding module (NLU) is required to parse plain text and obtain the input symptom sequence, and a natural language generation (NLG) module is needed to translate the predicted symptom or disease to text."
- Why unresolved: The integration of NLU and NLG modules with CoAD is not explored, and their potential impacts on the framework's performance are not known.
- What evidence would resolve it: Studies evaluating the performance of CoAD with integrated NLU and NLG modules in terms of disease diagnosis accuracy, symptom recall, and user satisfaction in real-world dialogue scenarios.

### Open Question 3
- Question: How does the performance of CoAD vary with different levels of dropout noise applied to the explicit symptoms during repeated symptom input?
- Basis in paper: [explicit] The paper states that "dropout noise serves as data augmentation by independently sampling dropout masks" during repeated symptom generation.
- Why unresolved: The paper does not explore the impact of varying levels of dropout noise on the performance of CoAD.
- What evidence would resolve it: Experiments analyzing the performance of CoAD with different dropout rates applied to the explicit symptoms, particularly focusing on disease accuracy and symptom recall across various datasets.

## Limitations

- Dataset generalization: All datasets are Chinese-language medical consultation datasets, limiting generalizability to other languages and medical domains
- Order independence assumption: The framework assumes disease determination is independent of symptom order, which may not hold for all medical conditions
- Attention masking sensitivity: The effectiveness of the repeated input schema depends heavily on the specific attention masking parameters, which may require dataset-specific tuning

## Confidence

**High confidence claims:**
- The three key innovations (d-label alignment, s-label augmentation, repeated input schema) are technically sound and implemented as described
- The reported performance improvements over baseline models are likely accurate based on the experimental methodology

**Medium confidence claims:**
- The mechanisms explaining why each innovation works (as detailed in the "Why This Works" section)
- The generalizability of the approach to other medical domains and languages

**Low confidence claims:**
- The assumption that all diseases can be diagnosed without considering symptom order
- The assertion that the training-inference gap is fully bridged by d-label alignment

## Next Checks

1. **Cross-domain validation:** Test CoAD on medical datasets from different domains (e.g., radiology reports, pathology findings) and languages to assess generalizability beyond Chinese consultation transcripts.

2. **Ablation on order-dependent diseases:** Create or identify a subset of diseases where symptom order is clinically significant and test whether CoAD's performance degrades or whether the s-label augmentation introduces harmful noise.

3. **Attention masking sensitivity analysis:** Systematically vary the attention masking parameters (number of previous symptoms visible, self-attention constraints) to identify the optimal configuration and test whether the current settings are near-optimal or could be improved.