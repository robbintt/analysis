---
ver: rpa2
title: 'Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation
  with Large Language Models'
arxiv_id: '2311.00287'
source_url: https://arxiv.org/abs/2311.00287
tags:
- data
- clinical
- tasks
- language
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of generating high-quality synthetic
  clinical text for NLP tasks, addressing privacy concerns and resource constraints
  of directly using large language models (LLMs). The authors propose ClinGen, a framework
  that infuses clinical knowledge into LLM prompting.
---

# Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models

## Quick Facts
- arXiv ID: 2311.00287
- Source URL: https://arxiv.org/abs/2311.00287
- Reference count: 40
- Key outcome: ClinGen framework achieves 8.98% performance gains for PubMedBERTBase and 7.27% for PubMedBERTLarge across 7 clinical NLP tasks with 16 datasets

## Executive Summary
This paper introduces ClinGen, a framework for generating high-quality synthetic clinical text using knowledge-infused prompting with large language models. The approach addresses privacy concerns and resource constraints by extracting clinical topics and writing styles from knowledge graphs and LLMs to create diverse prompts for text generation. Evaluated across 7 clinical NLP tasks and 16 datasets, ClinGen consistently outperforms baselines, better aligns with real data distribution, and enriches the diversity of generated training instances.

## Method Summary
ClinGen is a knowledge-infused prompting framework that generates synthetic clinical text by combining insights from external clinical knowledge graphs and large language models. The method extracts clinical topics and relations from the iBKH knowledge graph and derives writing styles from LLMs, then composes these elements into diverse prompts for text generation. The framework operates in a few-shot setting (5 examples per class) and fine-tunes pre-trained classifiers (PubMedBERTBase/Large) on the generated synthetic data for downstream clinical NLP tasks.

## Key Results
- Achieves 8.98% performance gains over baselines for PubMedBERTBase and 7.27% for PubMedBERTLarge across clinical NLP tasks
- Better aligns generated data distribution with real clinical data compared to baseline approaches
- Enriches diversity of generated training instances while maintaining clinical relevance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Knowledge-infused prompting improves synthetic clinical text quality by aligning generated data distribution with real data distribution
- Mechanism: CLIN GEN extracts clinical topics and writing styles from knowledge graphs and LLMs, then composes them to generate diverse prompts for text generation
- Core assumption: The knowledge graphs contain relevant clinical entities and relations that are representative of real clinical text data
- Evidence anchors:
  - [abstract]: "Our extensive empirical study across 7 clinical NLP tasks and 16 datasets reveals that CLIN GEN consistently enhances performance across various tasks, effectively aligning the distribution of real datasets"
  - [section 4.1.1]: "We employ the iBKH KG (Su et al., 2023) due to its broad coverage over clinical entities"
  - [corpus]: Weak evidence - no specific corpus analysis provided for knowledge graph content
- Break condition: If the knowledge graphs lack coverage of important clinical entities or relations, or if the LLM fails to capture domain-specific knowledge

### Mechanism 2
- Claim: Knowledge-infused prompting improves synthetic clinical text quality by enriching the diversity of generated training instances
- Mechanism: CLIN GEN randomly samples topics and writing styles from candidate sets to augment prompts, encouraging prompt diversity and enhancing the quality and clinical relevance of generated synthetic data
- Core assumption: The sampled topics and writing styles are diverse enough to cover the range of real clinical text data
- Evidence anchors:
  - [abstract]: "CLIN GEN not only aligns more closely with the distribution of the original data but also amplifies the diversity of the generated training samples"
  - [section 4.2]: "we propose a knowledge-infused strategy, where the collected clinical topics and writing styles serve as the base unit"
  - [corpus]: Weak evidence - no specific corpus analysis provided for diversity metrics
- Break condition: If the sampled topics and writing styles are too limited or repetitive, or if the LLM fails to generate diverse text based on the augmented prompts

### Mechanism 3
- Claim: Knowledge-infused prompting improves synthetic clinical text quality by infusing domain-specific knowledge into the prompts
- Mechanism: CLIN GEN refines clinically informed prompts by extracting rich clinically relevant knowledge from parametric (LLMs) or nonparametric sources (knowledge graphs) and tailoring it to clinical NLP tasks
- Core assumption: The LLM and knowledge graphs contain sufficient domain-specific knowledge to guide the generation of high-quality clinical text
- Evidence anchors:
  - [abstract]: "CLIN GEN integrates both non-parametric insights from external clinical knowledge graphs with the intrinsic parametric knowledge encoded in large language models"
  - [section 4.1]: "CLIN GEN emphasizes refining clinically informed prompts. This approach aims to extract rich clinically relevant knowledge from parametric (e.g. LLMs) or nonparametric sources (e.g. knowledge graphs) and tailor it to clinical NLP tasks"
  - [corpus]: Weak evidence - no specific corpus analysis provided for domain-specific knowledge coverage
- Break condition: If the LLM and knowledge graphs lack sufficient domain-specific knowledge, or if the knowledge extraction and tailoring process fails to effectively incorporate the knowledge into the prompts

## Foundational Learning

- Concept: Large Language Models (LLMs)
  - Why needed here: CLIN GEN leverages the capabilities of LLMs for synthetic clinical text generation
  - Quick check question: What are the key characteristics of LLMs that make them suitable for clinical text generation?

- Concept: Knowledge Graphs (KGs)
  - Why needed here: CLIN GEN uses knowledge graphs to extract clinical topics and relations for prompt augmentation
  - Quick check question: How do knowledge graphs represent and organize domain knowledge in a structured way?

- Concept: Prompt Engineering
  - Why needed here: CLIN GEN refines prompts by incorporating clinical topics and writing styles to guide the generation of high-quality clinical text
  - Quick check question: What are the key considerations when designing prompts for LLM-based text generation?

## Architecture Onboarding

- Component map: Knowledge extraction module -> Prompt composition module -> LLM generation module -> Fine-tuning module

- Critical path:
  1. Extract clinical topics and writing styles from KGs and LLMs
  2. Compose sampled topics and writing styles to augment prompts
  3. Generate synthetic clinical text based on the augmented prompts
  4. Fine-tune a pre-trained classifier on the generated synthetic data

- Design tradeoffs:
  - Tradeoff between knowledge graph coverage and LLM domain knowledge: KGs provide structured clinical knowledge, while LLMs capture more implicit knowledge
  - Tradeoff between prompt diversity and prompt specificity: diverse prompts encourage variety, but specific prompts may be more effective for certain tasks

- Failure signatures:
  - Poor synthetic data quality: low alignment with real data distribution, limited diversity, lack of domain-specific knowledge
  - Inefficient knowledge extraction: incomplete or inaccurate extraction of clinical topics and writing styles
  - Ineffective prompt composition: failed to effectively incorporate the extracted knowledge into the prompts

- First 3 experiments:
  1. Evaluate the quality of synthetic data generated by CLIN GEN using distribution alignment and diversity metrics
  2. Compare the performance of CLIN GEN with baselines on a small set of clinical NLP tasks
  3. Investigate the impact of different knowledge extraction methods (KG vs. LLM) on synthetic data quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can Clinical LLMs improve synthetic clinical text generation compared to general-purpose LLMs like ChatGPT?
- Basis in paper: [inferred] The authors mention that clinical LLMs like Med-PALM, fine-tuned on additional clinical contexts, have achieved superior performance on clinical NLP benchmarks but are not open-sourced. They suggest this as a potential future work avenue.
- Why unresolved: The paper only discusses the potential of clinical LLMs but does not provide empirical evidence of their effectiveness in synthetic data generation due to lack of access to these models.
- What evidence would resolve it: Empirical results comparing ClinGen's performance when using clinical LLMs versus general-purpose LLMs like ChatGPT as the generator.

### Open Question 2
- Question: What are the limitations of using knowledge graphs for clinical topic generation in synthetic data generation?
- Basis in paper: [explicit] The authors note that KGs may not always contain the required information for certain tasks, such as relations between chemicals and proteins in the CDR task, which limits performance gains.
- Why unresolved: The paper only provides one example of KG limitations and does not systematically evaluate when KGs are more or less effective than LLMs for topic generation.
- What evidence would resolve it: A systematic study comparing the coverage and effectiveness of KGs versus LLMs for topic generation across various clinical NLP tasks.

### Open Question 3
- Question: How does the hallucination problem in LLM-based synthetic data generation impact clinical NLP applications?
- Basis in paper: [explicit] The authors acknowledge that hallucination in LLM-based synthetic data generation can lead to misinformation propagation, which may have negative impacts in the clinical domain.
- Why unresolved: The paper only mentions the potential issue of hallucination but does not provide any empirical evidence or solutions to mitigate this problem in clinical NLP applications.
- What evidence would resolve it: An empirical study quantifying the extent of hallucination in clinical text generated by LLMs and evaluating its impact on downstream clinical NLP tasks.

## Limitations
- Evaluation relies on a few-shot setting with only 5 examples per class, which may not represent real-world scenarios
- Knowledge graph coverage is limited to iBKH, and its comprehensiveness across all clinical NLP tasks remains uncertain
- Study does not extensively analyze computational costs of knowledge extraction and generation for large-scale applications

## Confidence

- **High confidence**: The 8.98% and 7.27% performance gains over baselines are supported by extensive empirical evaluation across 16 datasets and 7 tasks
- **Medium confidence**: The claim about better alignment with real data distribution is supported by statistical tests but lacks detailed qualitative analysis
- **Medium confidence**: The claim about enriched diversity of generated instances is based on metrics but could benefit from more comprehensive diversity analysis

## Next Checks

1. Evaluate knowledge graph coverage: Conduct a systematic analysis of iBKH's coverage across all entity types and relations relevant to the 7 clinical NLP tasks to identify potential gaps

2. Scale-up analysis: Test the framework's performance and efficiency when generating larger volumes of synthetic data (e.g., 50,000+ samples) and analyze the computational costs of knowledge extraction

3. Cross-domain generalization: Apply the knowledge-infused prompting approach to non-clinical domains to evaluate whether the performance gains are domain-specific or transferable to other specialized text generation tasks