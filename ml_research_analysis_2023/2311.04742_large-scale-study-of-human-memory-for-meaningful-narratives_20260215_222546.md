---
ver: rpa2
title: Large-scale study of human memory for meaningful narratives
arxiv_id: '2311.04742'
source_url: https://arxiv.org/abs/2311.04742
tags:
- narrative
- recall
- story
- clauses
- they
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study used large language models (LLMs) to enable large-scale
  experiments on human memory for meaningful narratives. The authors generated realistic
  narrative stimuli and automatically scored recall responses, overcoming the time-consuming
  manual labor typically required.
---

# Large-scale study of human memory for meaningful narratives

## Quick Facts
- arXiv ID: 2311.04742
- Source URL: https://arxiv.org/abs/2311.04742
- Reference count: 40
- Key outcome: LLM-enabled large-scale experiments reveal that memory for narratives scales linearly with length, and recall depends on coherent structure while recognition does not

## Executive Summary
This study leverages large language models to overcome the practical limitations of studying human memory for meaningful narratives at scale. By using LLMs to generate narrative stimuli, score recall responses, and create recognition lures, the authors conduct extensive experiments comparing recall and recognition across narratives of varying lengths and structures. The results show that both recall and recognition performance scale linearly with narrative length, but recognition is largely unaffected by narrative structure while recall is significantly impaired when narratives are scrambled. This suggests that memory encoding is robust to structure, but retrieval depends on coherent comprehension.

## Method Summary
The authors use LLMs to generate new narratives based on templates from oral narratives, varying length while preserving structure. Narratives are segmented into clauses, and recall and recognition experiments are conducted online with participants. LLM scoring of recall responses is validated against human scoring. Recognition experiments use LLM-generated lures that are contextually appropriate. The scaling of recall and recognition performance with narrative length is analyzed, along with the effects of narrative structure on memory.

## Key Results
- Recall and recognition performance both scale linearly with narrative length
- Recognition performance is largely unaffected by narrative structure
- Recall performance is significantly impaired when narratives are scrambled
- Recall order follows the original narrative sequence even for scrambled inputs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-generated narratives preserve narrative structure while varying content, enabling large-scale memory experiments.
- Mechanism: By using a template narrative and prompting the LLM to generate a new story of the same length and structure, the system creates controlled stimuli that differ only in surface content.
- Core assumption: The LLM can understand and replicate the structural elements of the template narrative (e.g., number of clauses, narrative function of each clause) while generating new, coherent content.
- Evidence anchors:
  - [abstract] "we use LLMs to generate new narratives of a particular type and length"
  - [section] "We therefore instructed LLMs to generate new narratives modeled on the original ones, i.e. exhibiting a similar type of a event sequence and the overall length in terms of the total number of clauses"
  - [corpus] "average neighbor FMR=0.361" (moderate similarity in related work, suggesting this is a recognized approach)

### Mechanism 2
- Claim: LLM scoring of recall is as reliable as human scoring, enabling efficient analysis of large datasets.
- Mechanism: The LLM is prompted to evaluate whether the information in each clause of the original narrative is present in a participant's recall, and this scoring is validated against human scoring.
- Core assumption: The LLM can accurately understand the semantic content of both the original clauses and the participant's recall, and make a reliable judgment about whether the information is present.
- Evidence anchors:
  - [abstract] "We, therefore, prompted an LLM to define which of the clauses of the original narrative were recalled and in which order"
  - [section] "GPT-4 scoring of recalls results in recall probabilities close to ones obtained by human evaluations for a great majority of the clauses"
  - [corpus] "average neighbor FMR=0.361" (moderate similarity in related work, suggesting this is a recognized approach)

### Mechanism 3
- Claim: LLM-generated lures are indistinguishable from true clauses, allowing for valid recognition experiments.
- Mechanism: The LLM is prompted to generate plausible clauses that could fit into the narrative context, creating lures that are difficult for participants to distinguish from true clauses.
- Core assumption: The LLM can generate clauses that are contextually appropriate and similar in style to the true clauses, making them effective lures.
- Evidence anchors:
  - [abstract] "Using the LLM, for each story we obtained the same number of lures as true clauses"
  - [section] "Generating these lures is highly nontrivial as it requires an understanding of the narrative"
  - [corpus] "average neighbor FMR=0.361" (moderate similarity in related work, suggesting this is a recognized approach)

## Foundational Learning

- Concept: Clause segmentation
  - Why needed here: Narratives are segmented into clauses to define the basic units of meaning for recall and recognition experiments.
  - Quick check question: What is the difference between a clause and a sentence, and why is clause segmentation important for this study?

- Concept: Zero-shot prompting
  - Why needed here: The LLM is used to perform novel tasks (e.g., scoring recalls, generating lures) without additional training, relying on its ability to understand and follow instructions.
  - Quick check question: How does zero-shot prompting differ from few-shot prompting, and what are the advantages and disadvantages of each approach?

- Concept: Narrative structure
  - Why needed here: Understanding how the structure of a narrative influences memory is a key goal of the study, and the LLM-generated narratives are designed to preserve structure while varying content.
  - Quick check question: What are the key elements of narrative structure, and how might they influence memory encoding and retrieval?

## Architecture Onboarding

- Component map:
  Narrative generation -> Experiment design -> Data collection -> Data analysis -> Result interpretation

- Critical path:
  1. Generate LLM narratives based on templates
  2. Segment narratives into clauses
  3. Administer recall and recognition experiments online
  4. Score recalls using LLM
  5. Calculate recognition performance
  6. Analyze scaling relationships and effects of narrative structure

- Design tradeoffs:
  - LLM vs human scoring: LLMs are faster and more scalable, but may not be as accurate as human scorers
  - Narrative length: Longer narratives may be more ecologically valid but harder to analyze
  - Clause segmentation: More granular segmentation may capture more detail but be more complex to analyze

- Failure signatures:
  - LLM scoring is unreliable: Recall probabilities do not correlate with human scoring
  - Recognition performance is too high: Lures are not effective, participants can easily distinguish them from true clauses
  - Scaling relationships are not linear: Memory performance does not scale linearly with narrative length

- First 3 experiments:
  1. Generate LLM narratives of different lengths and verify they preserve narrative structure
  2. Conduct pilot recall and recognition experiments to test the reliability of LLM scoring
  3. Analyze the scaling relationships between memory performance and narrative length for a small set of narratives

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the recall performance scale with narrative length beyond the range studied (20-130 clauses)?
- Basis in paper: [explicit] The authors note that as narratives become longer, people start summarizing larger chunks, suggesting a need for better recall metrics beyond clause counting.
- Why unresolved: The study only explored narratives up to 130 clauses. Longer narratives may exhibit different scaling patterns due to increased summarization.
- What evidence would resolve it: Experiments with narratives significantly longer than 130 clauses, using recall metrics that account for summarization (e.g., semantic similarity measures).

### Open Question 2
- Question: What factors predict how well a given clause will be recalled in a narrative?
- Basis in paper: [explicit] The authors observe a wide distribution of recall probabilities across clauses but do not identify predictive factors beyond general importance to the narrative.
- Why unresolved: While importance is noted, specific linguistic, structural, or contextual features that determine recall probability are not explored.
- What evidence would resolve it: Statistical analysis correlating recall probability with features like clause position, semantic complexity, syntactic structure, or emotional valence.

### Open Question 3
- Question: How would expertly crafted or literary stories impact the scaling of memory performance compared to spontaneous oral narratives?
- Basis in paper: [explicit] The authors suggest that expertly told stories may utilize techniques to improve memorability and that this could affect scaling laws.
- Why unresolved: The study focused on spontaneous, personal narratives. Literary techniques like foreshadowing, repetition, or vivid imagery are not accounted for.
- What evidence would resolve it: Comparative experiments using expertly crafted narratives and analysis of scaling patterns against the baseline data from spontaneous narratives.

## Limitations

- The reliability of LLM scoring for recall responses, while validated against human scoring, may still exhibit systematic biases for certain types of narrative content or participant responses.
- The generalizability of results across different narrative genres and styles remains untested, as the study uses narratives from a specific oral tradition.
- The ecological validity of the experimental setup, particularly the time constraints and presentation format, may not fully capture naturalistic narrative comprehension and memory processes.

## Confidence

- High confidence: The linear scaling relationship between narrative length and memory performance (both recall and recognition)
- Medium confidence: The differential effect of narrative structure on recall versus recognition memory
- Medium confidence: The ability of LLM-generated lures to effectively test recognition memory

## Next Checks

1. Conduct a replication study using narratives from different genres (e.g., news articles, fiction, personal anecdotes) to test the generalizability of the scaling relationships and structure effects across diverse meaningful narratives.

2. Perform a systematic error analysis comparing LLM scoring to human scoring across different types of recall errors (e.g., omissions, substitutions, intrusions) to identify potential systematic biases in the automated scoring approach.

3. Test the effects of varying presentation parameters (e.g., reading time, pacing, segmentation) to determine the robustness of the observed memory effects under different naturalistic reading conditions.