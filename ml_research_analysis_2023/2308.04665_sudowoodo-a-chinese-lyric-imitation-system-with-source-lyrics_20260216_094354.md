---
ver: rpa2
title: 'Sudowoodo: a Chinese Lyric Imitation System with Source Lyrics'
arxiv_id: '2308.04665'
source_url: https://arxiv.org/abs/2308.04665
tags:
- lyrics
- source
- keywords
- imitation
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Sudowoodo, a Chinese lyric imitation system
  that generates new lyrics by imitating the style and content of source lyrics. To
  address the lack of a parallel training corpus, the authors propose a novel framework
  to construct aligned training pairs using a keyword-based lyrics generation model.
---

# Sudowoodo: a Chinese Lyric Imitation System with Source Lyrics

## Quick Facts
- arXiv ID: 2308.04665
- Source URL: https://arxiv.org/abs/2308.04665
- Reference count: 3
- One-line primary result: Sudowoodo generates Chinese lyrics that imitate source lyrics with 67.25% top-1 ranking in human evaluation

## Executive Summary
Sudowoodo is a Chinese lyric imitation system that generates new lyrics by imitating the style and content of source lyrics. The system addresses the challenge of lacking parallel training data by constructing an aligned corpus using a keyword-based lyrics generation model (ModelK2L) to generate target lyrics from source lyrics. A post-processing module then filters and ranks generated lyrics based on quality and relevance scores. Human evaluation shows the proposed framework outperforms baseline models in thematic relevance, fluency, and overall quality.

## Method Summary
The system uses a two-stage framework: first, ModelK2L (keyword-to-lyrics) generates target lyrics from source lyrics using extracted keywords and style attributes; second, ModelL2L (lyrics-to-lyrics) is trained on the aligned corpus (generated lyrics, source lyrics) to learn imitation. The system employs a pre-trained GPT-2-based transformer (210M parameters) and uses top-k sampling with format control during inference. A post-processing module combines quality scoring (SLyric) and relevance scoring (Srelevance) to filter and rank outputs.

## Key Results
- ModelL2L achieves top-1 ranking in 67.25% of cases in human evaluation
- System outperforms baselines in thematic relevance, fluency, and overall quality
- Human evaluators rated generated lyrics on a 5-point scale across multiple dimensions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The system constructs a parallel training corpus by generating target lyrics from source lyrics using a keyword-based model (ModelK2L), thereby enabling training of a lyrics-to-lyrics imitation model (ModelL2L) despite the lack of naturally aligned data.
- Mechanism: Source lyrics are processed to extract keywords and attributes (style, emotion). ModelK2L generates new lyrics from these keywords and attributes, forming aligned pairs (generated lyrics, source lyrics). These pairs train ModelL2L to imitate the source style.
- Core assumption: Generated lyrics from ModelK2L are sufficiently aligned in style and structure to serve as valid targets for training the imitation model.
- Evidence anchors:
  - [abstract] "we propose a novel framework to construct a parallel corpus based on a keyword-based lyrics model from source lyrics. Then the pairs (new lyrics, source lyrics) are used to train the lyrics imitation model."
  - [section] "we generate the target lyrics Dk′ using the ModelK2L. Finally, we train a lyrics imitation model with the aligned lyrics corpus (Dk′, Dk)"
  - [corpus] No direct corpus evidence for quality of generated target lyrics; this is an internal assumption.
- Break condition: If generated lyrics diverge too much in theme, structure, or style from the source, the imitation model will learn incorrect mappings and produce poor outputs.

### Mechanism 2
- Claim: The post-processing module filters and ranks generated lyrics by combining a lyrics quality score (SLyric) and a relevance score (Srelevance) to select the highest-quality imitations.
- Mechanism: For each generated lyric sample, a quality classifier scores fluency and correctness (SLyric), while a sentence transformer computes cosine similarity between source and generated lyrics (Srelevance). These are combined linearly to rank candidates.
- Core assumption: Both the quality classifier and the relevance scorer are reliable and complementary; their weighted sum effectively prioritizes the best outputs.
- Evidence anchors:
  - [abstract] "we utilize a post-processing module to filter and rank the generated lyrics, selecting the highest-quality ones."
  - [section] "We train a classification model to determine whether a song lyric is a high-quality lyric... We use the sentence transformer to obtain sentence vectors for both the source and generated lyrics, and then calculate the cosine similarity to rank the relevance."
  - [corpus] No direct corpus evidence for the effectiveness of the combined scoring; evaluation is based on human judgment in results.
- Break condition: If either scorer is poorly calibrated or the weighting is suboptimal, the filtering may discard good candidates or retain poor ones.

### Mechanism 3
- Claim: The encoder-decoder architecture with keyword and attribute conditioning allows controlled lyric generation that respects both content and style of the source.
- Mechanism: ModelK2L and ModelL2L use transformer encoder-decoder structures where keywords, style, and emotion are encoded alongside source lyrics, and the decoder generates target lyrics conditioned on these signals.
- Core assumption: The conditioning mechanism can effectively influence the decoder to produce stylistically coherent and thematically relevant outputs.
- Evidence anchors:
  - [abstract] "the encoder encodes the text and attributes of the source lyrics, and the decoder generates the imitated lyrics."
  - [section] "keywords, style, and emotion serving as encoder inputs and the source lyrics as decoder outputs"
  - [corpus] No corpus evidence for effectiveness of conditioning; performance is measured by human evaluation.
- Break condition: If the conditioning signals are not well represented in the latent space or the decoder ignores them, generated lyrics will lose fidelity to source style.

## Foundational Learning

- Concept: Encoder-decoder architecture with attention mechanisms
  - Why needed here: Enables mapping from source lyrics (and attributes) to target lyrics, essential for both generating aligned training data and the final imitation.
  - Quick check question: In an encoder-decoder model, where do the keywords and style attributes enter the model during training?

- Concept: Text similarity metrics (cosine similarity of sentence embeddings)
  - Why needed here: Provides a quantitative measure of how closely generated lyrics match the source in semantics, used for ranking.
  - Quick check question: What is the main advantage of using sentence transformers over bag-of-words for measuring lyric similarity?

- Concept: Keyword extraction and text preprocessing
  - Why needed here: Extracts the key thematic and stylistic signals from source lyrics to condition generation and build aligned pairs.
  - Quick check question: Why might it be important to truncate input to the model to stay under the maximum sequence length?

## Architecture Onboarding

- Component map: Raw lyrics -> Keyword/attribute extraction -> ModelK2L training -> Aligned corpus creation -> ModelL2L training -> Post-processing -> Output generation
- Critical path: Data extraction → ModelK2L training → aligned corpus creation → ModelL2L training → post-processing → output generation
- Design tradeoffs:
  - Using generated lyrics as training targets trades off data quality for quantity and alignment.
  - Top-k sampling with penalties balances creativity and coherence but may require tuning for lyric-specific rhythm.
  - Post-processing ranking adds latency but improves output quality.
- Failure signatures:
  - Poor thematic relevance: misalignment in generated training targets
  - Fluency issues: model not well-initialized or decoding strategy inadequate
  - Logical jumps: keyword extraction or truncation losing context
  - Model collapse: over-reliance on training data patterns without adaptation
- First 3 experiments:
  1. Test ModelK2L alone: input keywords from a source lyric, verify generated lyrics preserve theme and style.
  2. Train ModelL2L on a small aligned corpus, evaluate imitation on held-out source lyrics.
  3. Apply post-processing ranking to ModelL2L outputs, compare top-ranked vs random selections via human judgment.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can Sudowoodo be adapted to generate lyrics in languages other than Chinese?
- Basis in paper: [explicit] The authors mention that Sudowoodo is a Chinese lyric imitation system and use Chinese pre-trained GPT-2 for initialization.
- Why unresolved: The paper focuses on the development and evaluation of Sudowoodo for Chinese lyrics, but does not discuss the possibility of adapting it to other languages.
- What evidence would resolve it: A study comparing the performance of Sudowoodo when adapted to generate lyrics in different languages, such as English, Spanish, or Japanese, would provide evidence on the system's adaptability to other languages.

### Open Question 2
- Question: How does the quality of Sudowoodo's generated lyrics compare to human-written lyrics in terms of emotional depth and creativity?
- Basis in paper: [inferred] The paper mentions that Sudowoodo generates high-quality lyrics based on human evaluation, but does not directly compare its output to human-written lyrics in terms of emotional depth and creativity.
- Why unresolved: The human evaluation focuses on thematic relevance, fluency, logic, and overall quality, but does not assess the emotional depth and creativity of the generated lyrics compared to human-written lyrics.
- What evidence would resolve it: A comparative study between Sudowoodo's generated lyrics and human-written lyrics, evaluated by professional lyricists on emotional depth and creativity, would provide evidence on the system's ability to match human creativity.

### Open Question 3
- Question: Can Sudowoodo be used to generate lyrics for genres other than pop, hip-hop, and rap?
- Basis in paper: [explicit] The authors mention that they collect a dataset of 800k Chinese lyrics of various styles, including pop, hip-hop, rap, etc., and train Sudowoodo on this dataset.
- Why unresolved: The paper does not provide information on whether Sudowoodo can generate lyrics for genres not included in the training dataset, such as rock, country, or electronic music.
- What evidence would resolve it: An experiment training Sudowoodo on a dataset containing lyrics from various genres, including those not mentioned in the paper, and evaluating its performance in generating lyrics for these genres, would provide evidence on the system's versatility in handling different music styles.

## Limitations

- The core assumption that generated lyrics can serve as valid training targets lacks direct validation corpus evidence.
- The post-processing module's effectiveness relies on two independently trained models without quantitative evaluation of their individual performance.
- Human evaluation results lack statistical significance testing and detailed breakdowns of component contributions.

## Confidence

- **High confidence**: The overall two-stage framework architecture (ModelK2L → ModelL2L) is well-specified and the training methodology is clearly described with appropriate technical detail.
- **Medium confidence**: The claim that ModelL2L achieves top-1 ranking in 67.25% of cases is supported by human evaluation, though the evaluation methodology lacks statistical validation.
- **Low confidence**: The assumption that automatically generated target lyrics provide sufficient quality for training the imitation model, as no direct corpus evidence validates the alignment between generated and source lyrics.

## Next Checks

1. **Alignment Quality Validation**: Generate a small held-out set of (keywords+style, generated lyrics) pairs using ModelK2L, then have human annotators rate the thematic and stylistic alignment between generated lyrics and their source lyrics to quantify the quality of the constructed training corpus.

2. **Post-Processing Component Analysis**: Conduct an ablation study where ModelL2L outputs are evaluated with: (a) no post-processing, (b) only quality scoring, (c) only relevance scoring, and (d) combined scoring, measuring the marginal contribution of each component to final output quality.

3. **Statistical Significance Testing**: Re-analyze the human evaluation results using appropriate statistical tests (e.g., McNemar's test for pairwise comparisons) to determine whether the observed performance differences between the proposed system and baselines are statistically significant at p<0.05.