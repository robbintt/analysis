---
ver: rpa2
title: The perpetual motion machine of AI-generated data and the distraction of ChatGPT-as-scientist
arxiv_id: '2312.00818'
source_url: https://arxiv.org/abs/2312.00818
tags:
- data
- sciences
- learning
- information
- more
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This commentary addresses misconceptions about AI's potential in
  scientific discovery, particularly regarding large language models like ChatGPT
  and AlphaFold2. The author argues that while AI will advance scientific progress,
  major breakthroughs won't come from AI alone due to fundamental differences between
  scientific data and internet-scale datasets used to train LLMs.
---

# The perpetual motion machine of AI-generated data and the distraction of ChatGPT-as-scientist

## Quick Facts
- arXiv ID: 2312.00818
- Source URL: https://arxiv.org/abs/2312.00818
- Authors: 
- Reference count: 1
- This commentary argues AI-generated synthetic data cannot create information from nothing and major scientific breakthroughs won't come from AI alone

## Executive Summary
This commentary challenges common misconceptions about AI's potential in scientific discovery, particularly regarding large language models like ChatGPT and AlphaFold2. The author argues that while AI will advance scientific progress, major breakthroughs won't come from AI alone due to fundamental differences between scientific data and internet-scale datasets used to train LLMs. Scientific data is scarcer, more expensive to obtain, and often not publicly available. The paper emphasizes that AI-generated synthetic data cannot create information from nothing - any useful synthetic data must be anchored to real data or human knowledge.

## Method Summary
This is a theoretical commentary paper that presents conceptual arguments about the limitations of AI-generated synthetic data in scientific discovery. The paper discusses information theory principles, semi-supervised learning strategies, and the role of human knowledge injection in scientific AI applications. Rather than presenting experimental results, the author provides qualitative arguments and analogies (like the perpetual motion machine) to support the thesis that synthetic data cannot replace the need for new experimental measurements.

## Key Results
- AI-generated synthetic data cannot create new scientific information without external input from real data or human knowledge
- Semi-supervised learning using model-generated labels still relies on real data as the information source
- Human knowledge injection through data augmentation or architectural constraints is essential when scientific data is scarce

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AI-generated synthetic data cannot create new scientific information without external input
- Mechanism: Synthetic data is fundamentally limited to what's already encoded in the training data or model architecture; no true novelty emerges without fresh experimental measurements
- Core assumption: Information content cannot increase through mere transformation of existing data
- Evidence anchors:
  - [abstract] "AI-generated synthetic data cannot create information from nothing - any useful synthetic data must be anchored to real data or human knowledge"
  - [section] "we simply cannot get something for nothing— fresh information must be injected into the system one way or another for there to be a win"
  - [corpus] Weak match - neighbor papers focus on AI detection rather than synthetic data generation limitations
- Break condition: If new information could be created through emergent patterns in sufficiently large datasets, though the author argues this is not the case for scientific data

### Mechanism 2
- Claim: Semi-supervised learning using model-generated labels is not true synthetic data generation
- Mechanism: Using unlabeled real data to generate pseudo-labels still relies on real data as the information source, just in a different form
- Core assumption: Information must originate from real measurements, even if the labels are model-generated
- Evidence anchors:
  - [section] "AlphaFold2 used real, but unlabeled sequence data, a strategy classically known as semi-supervised learning... does not make these data entirely AI-generated or synthetic— they remain anchored on real protein sequences"
  - [section] "we cannot generate data from a generative model only to directly feed these generated data back into that same model with the same learning objective— doing so is analogous to trying to build a perpetual motion machine"
  - [corpus] Weak match - neighbor papers don't address semi-supervised learning concepts
- Break condition: If the model could generate genuinely novel information not present in the original data distribution

### Mechanism 3
- Claim: Human knowledge injection is essential for useful synthetic data in scientific domains
- Mechanism: Data augmentation and architectural constraints both encode human beliefs about invariances, providing the information needed for generalization
- Core assumption: Scientific understanding requires explicit encoding of domain knowledge when data is scarce
- Evidence anchors:
  - [section] "we can augment a labeled protein structure data set by rotating protein structure labels... one is encoding the human belief— in this case corresponding to physical reality— that a protein 3D structure is, essentially, the same structure, even if rotated in space"
  - [section] "one can entirely replace such a 'data augmentation' strategy by instead encoding this belief directly into the architecture of the neural network— a testament to the fact that a trained model has a data equivalence"
  - [corpus] Weak match - neighbor papers don't discuss knowledge injection strategies
- Break condition: If the model could discover these invariances purely from data without human guidance

## Foundational Learning

- Concept: Information theory and the conservation of information
  - Why needed here: Understanding why AI cannot create information from nothing is central to the paper's argument about synthetic data limitations
  - Quick check question: Can you explain why a perpetual motion machine analogy applies to synthetic data generation in scientific domains?

- Concept: Semi-supervised learning and its limitations
  - Why needed here: The paper distinguishes between genuine synthetic data and semi-supervised approaches that still rely on real data
  - Quick check question: What's the key difference between using unlabeled real data versus truly synthetic data in model training?

- Concept: Data augmentation vs architectural constraints
  - Why needed here: Both strategies encode human knowledge but represent different approaches to the same problem of information scarcity
  - Quick check question: How are data augmentation and symmetry-encoding architecture fundamentally equivalent in terms of information injection?

## Architecture Onboarding

- Component map: Real experimental data → model training → analysis → new experimental design → new real data (iterative loop)
- Critical path: Real experimental data → model training → analysis → new experimental design → new real data (iterative loop)
- Design tradeoffs: Balancing between data augmentation (explicit transformations) vs architectural constraints (implicit encoding of invariances)
- Failure signatures: Models trained on synthetic data show poor generalization to real experimental conditions; ensemble methods with similar predictions provide no benefit
- First 3 experiments:
  1. Train a protein structure prediction model on augmented data vs architecturally constrained data to compare performance
  2. Test whether generated synthetic data improves a model trained on limited real data vs simply using the real data alone
  3. Compare semi-supervised learning (pseudo-labels from real data) vs true synthetic data generation on a small scientific dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the fundamental limits of synthetic data generation in scientific domains where real data acquisition is extremely expensive or technically challenging?
- Basis in paper: [explicit] The paper argues that "we simply cannot get something for nothing" and that "fresh information must be injected into the system one way or another for there to be a win," suggesting inherent limits to synthetic data generation
- Why unresolved: The paper doesn't provide quantitative bounds or formal proofs for these limits, instead offering qualitative arguments about information preservation and the impossibility of perpetual motion-like cycles
- What evidence would resolve it: Empirical studies measuring information gain/loss across multiple generations of synthetic data, mathematical proofs of information-theoretic bounds on synthetic data utility, or successful demonstrations of synthetic data enabling breakthroughs in previously intractable scientific problems

### Open Question 2
- Question: Under what specific conditions can semi-supervised learning strategies (like those used in AlphaFold2) effectively bridge data gaps in scientific domains beyond protein structure prediction?
- Basis in paper: [explicit] The paper notes that AlphaFold2 used "real, but unlabeled sequence data" and discusses semi-supervised learning as having "both a long history and theoretical underpinnings," while cautioning that "such a strategy may or may not be helpful"
- Why unresolved: The paper acknowledges that semi-supervised learning is not a "magic bullet" but doesn't provide systematic criteria for when it will or won't be effective in different scientific domains
- What evidence would resolve it: Systematic comparisons of semi-supervised vs supervised learning performance across diverse scientific datasets, formal analyses of the information requirements for successful semi-supervised learning, or successful applications of these methods to new scientific domains with different data characteristics

### Open Question 3
- Question: How can we formally quantify and measure the "information content" that different AI models inject into synthetic data generation pipelines to ensure they are truly useful rather than creating trivial cycles?
- Basis in paper: [inferred] The paper emphasizes that for synthetic data to be useful, "any cycle must have feedback in it to inject new information" and compares ineffective approaches to "trying to build a perpetual motion machine"
- Why unresolved: While the paper warns against trivial cycles, it doesn't provide quantitative metrics or formal methods for measuring whether new information is being injected or how much
- What evidence would resolve it: Development of information-theoretic metrics that can measure information gain in synthetic data pipelines, empirical studies demonstrating the relationship between information injection and model performance, or mathematical frameworks for analyzing the information flow in multi-model AI systems

## Limitations
- The paper presents theoretical arguments without empirical validation through controlled experiments
- The information theory-based claims, while intuitive, may not fully capture emergent capabilities of modern AI systems
- The dismissal of synthetic data's potential may be overly pessimistic without systematic exploration of specific use cases

## Confidence
- High Confidence: The core claim that AI-generated synthetic data cannot create information from nothing is well-supported by information theory principles
- Medium Confidence: The assertion that human knowledge injection is essential for scientific AI applications is reasonable but may underestimate AI's autonomous discovery potential
- Low Confidence: The paper's dismissal of synthetic data's potential in certain scientific domains may be overly pessimistic

## Next Checks
1. **Empirical validation of information conservation**: Design a controlled experiment comparing model performance when trained on: (a) real data only, (b) synthetic data generated from real data, and (c) synthetic data plus real data augmentation. Measure whether synthetic data provides any information gain beyond what's already present in the real data.

2. **Semi-supervised vs synthetic data boundary test**: Create a synthetic dataset where the "unlabeled" portion is actually synthetic data generated to mimic real data distribution. Train models using both semi-supervised learning and pure synthetic data approaches to quantify the information gap between these methods.

3. **Knowledge injection vs discovery tradeoff**: Compare three approaches on a small scientific dataset: (a) data augmentation encoding human knowledge, (b) architectural constraints encoding the same knowledge, and (c) pure unsupervised learning without explicit knowledge injection. Measure which approach achieves better generalization while quantifying the information content added by each method.