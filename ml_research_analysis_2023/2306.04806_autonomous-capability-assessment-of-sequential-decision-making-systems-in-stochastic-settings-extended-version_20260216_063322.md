---
ver: rpa2
title: Autonomous Capability Assessment of Sequential Decision-Making Systems in Stochastic
  Settings (Extended Version)
arxiv_id: '2306.04806'
source_url: https://arxiv.org/abs/2306.04806
tags:
- capability
- sdma
- learning
- state
- capabilities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces QACE, a novel method for learning interpretable
  probabilistic models of black-box sequential decision-making systems using minimal
  interaction. The approach uses active querying with policy simulation to efficiently
  learn preconditions and effects of agent capabilities, reducing the problem to FOND
  planning.
---

# Autonomous Capability Assessment of Sequential Decision-Making Systems in Stochastic Settings (Extended Version)

## Quick Facts
- **arXiv ID**: 2306.04806
- **Source URL**: https://arxiv.org/abs/2306.04806
- **Authors**: 
- **Reference count**: 5
- **Key outcome**: QACE learns interpretable probabilistic models of black-box SDMAs using minimal interaction, achieving 96% fewer samples than baselines while generalizing to larger environments.

## Executive Summary
This paper introduces QACE, a novel method for learning interpretable probabilistic models of black-box sequential decision-making systems (SDMAs) in stochastic settings. The approach uses active querying with policy simulation to efficiently learn preconditions and effects of agent capabilities, reducing the problem to FOND planning. Theoretical analysis shows convergence to correct models under identifiable effects, and experiments demonstrate QACE achieves faster convergence and higher sample efficiency compared to baselines across five different SDMAs.

## Method Summary
QACE is a query-based autonomous capability estimation algorithm that learns interpretable probabilistic models of black-box SDMAs through minimal interaction. The method generates distinguishing queries by searching for policies that lead to states where two hypotheses about predicate placement differ, then observes the SDMA's execution traces to prune inconsistent hypotheses from the version space. After learning a non-deterministic model, it uses maximum likelihood estimation on collected execution traces to learn probabilities. The learned model is expressed in terms of object-centric predicates rather than ground states, enabling few-shot generalization to larger environments with more objects than those seen during training.

## Key Results
- QACE learns near-perfect models in minutes with up to 96% fewer samples than alternative methods
- The approach generalizes to larger environments with more objects than seen during training
- Across five SDMAs, QACE achieves faster convergence and higher sample efficiency compared to GLIB-G/L baselines
- Theoretical analysis guarantees convergence to correct models under identifiable effects

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Active querying with policy simulation efficiently learns preconditions and effects of agent capabilities.
- Mechanism: The approach generates distinguishing queries by searching for policies that lead to states where two hypotheses about predicate placement differ. By observing the SDMA's execution traces, it prunes inconsistent hypotheses from the version space.
- Core assumption: The SDMA can execute arbitrary policies in a simulator and provide execution traces.
- Evidence anchors:
  - [abstract]: "Our approach uses a restricted form of interaction with the input SDM agent... to learn an interpretable probabilistic model describing its capabilities."
  - [section]: "We generate an exhaustive set of hypotheses for each predicate at every location... We then take 2 of these (line 5) and generate a query q (line 6) such that the response of the SDMA on that query can help prune out one of the hypotheses."
- Break condition: If the SDMA cannot execute the generated policy or simulator access is unavailable.

### Mechanism 2
- Claim: Convergence to correct models is guaranteed under identifiable effects.
- Mechanism: The algorithm learns a non-deterministic model first, then uses maximum likelihood estimation on collected execution traces to learn probabilities. With infinite samples and identifiable effects, MLE converges to true probabilities.
- Core assumption: All effects of each capability are identifiable (i.e., there exists a state where each effect can be uniquely identified).
- Evidence anchors:
  - [abstract]: "Theoretical analysis shows convergence to correct models under identifiable effects."
  - [section]: "The model M is correct w.r.t. the model T ′ in the limit as η tends to ∞, where η is hyperparameter in query QPS used in Alg. 1."
- Break condition: If effects are not identifiable or infinite samples cannot be collected.

### Mechanism 3
- Claim: Few-shot generalization to larger environments is achieved through lifted predicate representation.
- Mechanism: The learned model is expressed in terms of object-centric predicates rather than ground states, allowing it to generalize to environments with more objects than those seen during training.
- Core assumption: The predicate vocabulary is sufficient to describe capabilities across different object configurations.
- Evidence anchors:
  - [abstract]: "experiments demonstrate QACE achieves faster convergence and higher sample efficiency... while generalizing to larger environments."
  - [section]: "Empirical evaluation shows that these contributions enable our method to carry out scalable assessment in both embodied and vanilla SDMAs."
- Break condition: If the predicate vocabulary is insufficient to capture capability variations in larger environments.

## Foundational Learning

- Concept: Version space reduction through active querying
  - Why needed here: The hypothesis space of possible transition models is infinite, making passive learning inefficient.
  - Quick check question: How does the algorithm ensure it doesn't get stuck exploring irrelevant hypotheses?

- Concept: Maximum likelihood estimation for probability learning
  - Why needed here: After learning non-deterministic effects, we need to assign probabilities to each effect based on observed frequencies.
  - Quick check question: What happens to the learned probabilities as the number of execution traces increases?

- Concept: Identifiable effects in probabilistic models
  - Why needed here: Guarantees that with enough samples, we can correctly learn the probability distribution of each capability's effects.
  - Quick check question: Why is it important that each effect can be uniquely identified in at least one state?

## Architecture Onboarding

- Component map:
  - Query synthesizer (policy generation using PRP planner) -> SDMA interaction layer (sends queries, receives execution traces) -> Hypothesis manager (maintains version space, prunes inconsistent models) -> Probability estimator (MLE on collected traces) -> Model validator (checks soundness and completeness)

- Critical path: Query synthesis → SDMA execution → Trace collection → Hypothesis pruning → Probability learning → Model validation

- Design tradeoffs:
  - Search depth vs. query generation time (deeper searches find distinguishing queries but take longer)
  - Sample size (η) vs. probability estimation accuracy (larger η gives better estimates but requires more SDMA interactions)
  - Predicate granularity vs. generalization capability (finer predicates give more precise models but may not generalize as well)

- Failure signatures:
  - No distinguishing queries found after extensive search (indicates hypothesis space too large or models too similar)
  - SDMA consistently fails to execute generated policies (suggests query generation not aligned with SDMA capabilities)
  - Probability estimates converge slowly (indicates insufficient samples or non-identifiable effects)

- First 3 experiments:
  1. Run QACE on a simple deterministic domain (e.g., Warehouse Robot) with 3-5 objects to verify basic functionality
  2. Test convergence properties on a domain with known identifiable effects, varying η to observe probability estimation accuracy
  3. Evaluate generalization by training on a small problem and testing on a larger problem with twice the number of objects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can QACE be adapted to work in safety-critical scenarios where a simulator is not available and direct interaction with the real-world agent is necessary?
- Basis in paper: [explicit] The paper mentions that using a simulator is a standard assumption in SDM research, but acknowledges that in real-world settings, this assumption can be limiting as users might not have direct access to such a simulator.
- Why unresolved: The paper does not provide a concrete solution or framework for adapting QACE to work without a simulator, especially in safety-critical scenarios where direct interaction might be necessary.
- What evidence would resolve it: A proposed method or framework for safely interacting with real-world agents in the absence of a simulator, along with experimental results demonstrating its effectiveness and safety.

### Open Question 2
- Question: What are the computational complexities of the queries generated by QACE, and how do these complexities impact the overall efficiency and scalability of the approach?
- Basis in paper: [explicit] The paper mentions that the possible set of queries expressible using the literals in a domain is vast, and it uses distinguishability as a measure to identify useful queries. However, it does not provide a detailed analysis of the computational complexities of these queries.
- Why unresolved: While the paper discusses the use of distinguishability to generate useful queries, it does not delve into the specific computational complexities involved or how these might affect the efficiency and scalability of QACE.
- What evidence would resolve it: A detailed analysis of the computational complexities of the queries generated by QACE, including worst-case scenarios and their impact on efficiency and scalability, along with empirical data supporting the findings.

### Open Question 3
- Question: How can QACE be extended to discover the capabilities of an evolving AI SDM system when the instruction set (capability names) is not provided?
- Basis in paper: [explicit] The paper assumes the availability of the instruction set of the SDMA as input in the form of capability names. It mentions that in certain settings, it might be useful to discover the capabilities of an evolving AI SDM system and suggests that methods like iCaML could be used to address this limitation in future work.
- Why unresolved: The paper does not provide a concrete method or approach for discovering the capabilities of an evolving AI SDM system without prior knowledge of the instruction set, leaving this as a potential area for future research.
- What evidence would resolve it: A proposed method for discovering the capabilities of an evolving AI SDM system without prior knowledge of the instruction set, along with experimental results demonstrating its effectiveness and accuracy.

## Limitations

- The method relies on identifiable effects - if an effect cannot be uniquely determined in any state, the method cannot learn correct probabilities regardless of sample size
- While generalization to larger environments is demonstrated, the predicate vocabulary design process is not fully specified
- The approach assumes access to a simulator, which may not be available in real-world safety-critical scenarios

## Confidence

- High confidence in query synthesis and hypothesis pruning mechanisms (well-specified algorithm with clear convergence properties)
- Medium confidence in probability learning guarantees (depends on the identifiable effects assumption which is stated but not extensively validated)
- Medium confidence in few-shot generalization claims (demonstrated empirically but the predicate design process lacks full specification)

## Next Checks

1. Test QACE on domains with deliberately non-identifiable effects to verify the algorithm's behavior and failure modes when the core assumption is violated.
2. Implement a systematic predicate design methodology and evaluate how different predicate granularities affect both model accuracy and generalization performance.
3. Compare QACE's generalization performance against transfer learning baselines that don't use lifted predicate representations to isolate the contribution of the object-centric modeling approach.