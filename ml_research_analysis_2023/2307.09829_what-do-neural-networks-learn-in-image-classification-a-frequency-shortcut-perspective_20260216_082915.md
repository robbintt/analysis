---
ver: rpa2
title: What do neural networks learn in image classification? A frequency shortcut
  perspective
arxiv_id: '2307.09829'
source_url: https://arxiv.org/abs/2307.09829
tags:
- frequency
- learning
- shortcuts
- shortcut
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates what neural networks learn in image classification
  tasks, focusing on frequency shortcut learning. The authors conduct experiments
  on synthetic and natural image datasets to understand how data characteristics influence
  the learning behavior of neural networks.
---

# What do neural networks learn in image classification? A frequency shortcut perspective

## Quick Facts
- **arXiv ID**: 2307.09829
- **Source URL**: https://arxiv.org/abs/2307.09829
- **Reference count**: 36
- **Primary result**: Frequency shortcuts can be transferred across datasets and cannot be fully avoided by larger model capacity and data augmentation.

## Executive Summary
This paper investigates what neural networks learn in image classification tasks by examining frequency shortcut learning. The authors propose that neural networks exhibit simplicity bias, leading them to exploit specific frequency characteristics (texture, shape, or color) for classification rather than learning semantically meaningful features. Through experiments on synthetic and natural image datasets, they demonstrate that frequency shortcuts can be identified, transferred across datasets, and impact out-of-distribution generalization. The study introduces the Accumulative Difference of Class-wise average Spectrum (ADCS) metric to measure class-wise frequency characteristics and a frequency culling method to identify dominant frequency maps. The results suggest that frequency shortcut learning is a fundamental aspect of neural network behavior that cannot be fully mitigated by increasing model capacity or applying data augmentation.

## Method Summary
The authors generate synthetic datasets with frequency biases to study learning behavior, then apply their findings to natural image datasets like ImageNet-10 and ImageNet-SCT. They train ResNet models on these datasets and use frequency analysis techniques including the ADCS metric and frequency culling method to identify dominant frequency characteristics. The frequency culling method identifies the top-X% of frequencies that contribute most to classification for each class, allowing evaluation of true positive and false positive rates on filtered datasets. They also investigate the effects of data augmentation and model capacity on frequency shortcut learning through controlled experiments.

## Key Results
- Neural networks learn frequency shortcuts that can be texture-based or shape-based depending on what best simplifies the classification objective
- Frequency shortcuts learned on one dataset can transfer to out-of-distribution test sets, creating an illusion of improved generalization while actually impairing it
- Larger model capacity and data augmentation cannot fully eliminate frequency shortcut learning, though augmentation can partially mitigate the effect

## Why This Works (Mechanism)

### Mechanism 1
Neural networks exhibit simplicity bias in classification tasks, leading to frequency shortcut learning where specific frequency sets (texture, shape, or color) are exploited for classification. During training, NNs prioritize learning frequency characteristics that most effectively distinguish classes, even if these characteristics are not semantically meaningful. This results in frequency shortcutsâ€”specific frequency subsets used for classification. The core assumption is that the frequency shortcuts learned by NNs are driven by data characteristics and simplicity bias, where the network finds the simplest solution to the classification objective.

### Mechanism 2
The learning dynamics of NNs in classification tasks are influenced by the frequency characteristics of individual classes within a dataset. NNs learn to distinguish classes with the most distinctive frequency characteristics first, regardless of whether these are low- or high-frequencies. This is measured using the Accumulative Difference of Class-wise average Spectrum (ADCS) metric, which computes the average spectrum difference for each class within a dataset. The core assumption is that the more distinctive the frequency characteristics of a class, the faster NNs will learn to distinguish it from other classes.

### Mechanism 3
Frequency shortcuts learned by NNs can be transferred across datasets and impact out-of-distribution (OOD) generalization. The presence of frequency shortcut features in an OOD test set may give an illusion of improved generalization, while actually impairing it. This transfer is not mitigated by larger model capacity or data augmentation. The core assumption is that frequency shortcuts learned on one dataset can be applied to classify images in a different dataset if the frequency characteristics are similar.

## Foundational Learning

- **Frequency analysis in neural networks**: Understanding how NNs process frequency information is crucial for analyzing their learning dynamics and shortcut learning behavior. *Quick check*: How does the frequency spectrum of an image influence the learning behavior of a neural network?

- **Simplicity bias in neural networks**: Simplicity bias drives NNs to find the simplest solution to a classification task, which can lead to frequency shortcut learning. *Quick check*: How does simplicity bias influence the learning dynamics of neural networks in classification tasks?

- **Out-of-distribution (OOD) generalization**: Evaluating how frequency shortcuts affect OOD generalization is crucial for understanding the robustness of NNs. *Quick check*: How can the presence of frequency shortcut features in an OOD test set impact the perceived generalization performance of a neural network?

## Architecture Onboarding

- **Component map**: Synthetic dataset generation -> Model training -> ADCS metric calculation -> Frequency culling method -> OOD testing
- **Critical path**: 1) Generate synthetic datasets with frequency biases 2) Train ResNet models on synthetic datasets 3) Calculate ADCS for natural image classes 4) Identify frequency shortcuts using DFM method 5) Evaluate OOD generalization on ImageNet-SCT
- **Design tradeoffs**: Model capacity (larger models may learn more complex shortcuts but cannot fully avoid them), data augmentation (can partially mitigate but not eliminate shortcuts), frequency culling threshold (choosing right percentage is crucial)
- **Failure signatures**: High TPR and FPR for certain classes in DFM-filtered test sets indicate frequency shortcut learning, poor OOD generalization despite good ID performance, inconsistent performance across architectures
- **First 3 experiments**: 1) Train ResNet18 on synthetic datasets with different frequency biases and measure F1-scores for each class in first 500 iterations 2) Calculate ADCS for classes in ImageNet-10 and identify classes with distinctive frequency characteristics 3) Implement frequency culling method to identify DFMs for classes in ImageNet-10 and evaluate TPR and FPR on DFM-filtered test sets

## Open Questions the Paper Calls Out

### Open Question 1
**How can frequency shortcut learning be effectively mitigated in neural networks to improve generalization performance?**
The authors recommend that future research should focus on effective training schemes mitigating frequency shortcut learning. This remains unresolved as the paper does not provide a definitive solution, only suggesting it as an area for future research. Development and validation of training schemes that demonstrably reduce frequency shortcut learning and improve model generalization on out-of-distribution datasets would resolve this question.

### Open Question 2
**How does the presence of frequency shortcut features in out-of-distribution test sets create an illusion of improved generalization?**
The results suggest that frequency shortcuts can be transferred across datasets and cannot be fully avoided by larger model capacity and data augmentation, indicating frequency shortcuts can lead to false generalization. The paper indicates this phenomenon but does not provide a detailed explanation of the underlying mechanisms. Experimental results demonstrating how frequency shortcut features in out-of-distribution test sets affect model performance and lead to overestimation of generalization capabilities would resolve this question.

### Open Question 3
**What role do data augmentation techniques play in mitigating frequency shortcut learning?**
The authors investigate the effect of data augmentation in mitigating frequency shortcut learning and find that appropriate data augmentation may partially reduce frequency shortcut learning, but neural networks can still find shortcut solutions based on the characteristics of the augmented data. The paper shows data augmentation can partially mitigate frequency shortcut learning but does not provide a comprehensive understanding of which techniques are most effective and under what conditions. Comparative analysis of various data augmentation techniques on their effectiveness in reducing frequency shortcut learning across different datasets and model architectures would resolve this question.

## Limitations
- The paper's core claims rely heavily on synthetic datasets, which may not fully capture the complexity of real-world image distributions
- The ADCS metric requires careful interpretation as frequency distinctiveness may not always correlate with semantic class boundaries
- The frequency culling method's threshold selection introduces potential arbitrariness in identifying shortcuts

## Confidence
- **High confidence**: The existence of frequency shortcut learning in NNs is well-supported by multiple experiments across different datasets and architectures
- **Medium confidence**: The transferability of frequency shortcuts across datasets is demonstrated but the mechanism could benefit from deeper analysis
- **Medium confidence**: The inability of larger models and data augmentation to fully eliminate frequency shortcuts is supported, though the extent may vary with implementation details

## Next Checks
1. **Cross-architecture validation**: Test the frequency shortcut identification method across diverse architectures (Vision Transformers, ConvNeXt) to verify generalizability beyond ResNet and VGG families
2. **Dataset complexity scaling**: Validate findings on more complex natural image datasets (e.g., CIFAR-100, Places365) to assess whether frequency shortcut behavior persists with increased class diversity
3. **Temporal dynamics analysis**: Conduct fine-grained temporal analysis of frequency shortcut emergence during training (per-epoch rather than per-iteration) to better understand the learning trajectory and potential intervention points