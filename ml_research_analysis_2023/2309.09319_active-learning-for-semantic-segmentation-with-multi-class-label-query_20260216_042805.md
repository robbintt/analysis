---
ver: rpa2
title: Active Learning for Semantic Segmentation with Multi-class Label Query
arxiv_id: '2309.09319'
source_url: https://arxiv.org/abs/2309.09319
tags: []
core_contribution: This paper addresses the high cost of annotating semantic segmentation
  labels by proposing a new active learning framework. The core idea is to query an
  oracle for a multi-hot vector indicating all classes existing in a local region,
  which is more efficient than traditional methods like dominant class labeling.
---

# Active Learning for Semantic Segmentation with Multi-class Label Query

## Quick Facts
- arXiv ID: 2309.09319
- Source URL: https://arxiv.org/abs/2309.09319
- Reference count: 40
- Key outcome: Achieves 95% of fully supervised performance with only 4% of the full labeling cost on Cityscapes and PASCAL VOC 2012

## Executive Summary
This paper addresses the high cost of annotating semantic segmentation labels by proposing a new active learning framework. The core innovation is a multi-class labeling strategy where annotators mark all classes present in a local region rather than identifying the dominant class. This approach is more efficient than traditional methods and enables more informative data collection. The authors propose a two-stage training algorithm that handles the ambiguity of partial labels using specialized loss functions and pseudo labeling, achieving state-of-the-art results with significantly reduced annotation costs.

## Method Summary
The method uses 32×32 superpixels as local regions and queries an oracle for a multi-hot vector indicating all classes present in each region. Training proceeds in two stages: Stage 1 uses merged positive loss and prototypical pixel loss to handle partial labels, while Stage 2 generates pseudo labels by finding class prototypes and propagating them to adjacent regions. The acquisition function, PixBal, combines uncertainty with class balancing considerations. The approach is evaluated on Cityscapes and PASCAL VOC 2012 datasets using mIoU as the primary metric.

## Key Results
- Achieves 95% of fully supervised performance with only 4% of the full labeling cost
- Outperforms dominant class labeling by 4.5% mIoU on Cityscapes with 8% labeling budget
- PixBal acquisition function consistently outperforms other acquisition functions across different budgets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-class labeling reduces annotation time per click by allowing annotators to select all classes present in a region in a single interaction, avoiding the need to determine the dominant class.
- Mechanism: Instead of requiring the annotator to identify which single class is most prevalent, the multi-class query simply asks for a binary presence/absence for each class. This eliminates the cognitive load of comparing class areas and speeds up annotation.
- Core assumption: Annotators can efficiently determine class presence without needing to judge dominance.
- Evidence anchors:
  - [abstract] "This multi-class labeling strategy is substantially more efficient than existing ones like segmentation, polygon, and even dominant class labeling in terms of annotation time per click."
  - [section 1] "Multi-class labeling took less time per click on average because, to determine the dominant one, the oracle has to infer every class in the region after all and sometimes should very carefully investigate the region when the classes occupy areas of similar sizes."
  - [corpus] Weak anchor; user study in appendix supports this claim.

### Mechanism 2
- Claim: The two-stage training algorithm effectively handles the ambiguity introduced by partial labels (sets of candidate classes per pixel).
- Mechanism: Stage 1 uses merged positive loss to treat all candidate classes as positives and prototypical pixel loss to enforce at least one pixel per class. Stage 2 generates pseudo labels by finding class prototypes and propagates them to adjacent regions.
- Core assumption: The model can learn meaningful class prototypes from ambiguous supervision and that pseudo labels derived from these prototypes are accurate enough to refine the model.
- Evidence anchors:
  - [section 3.2] "The per-pixel prediction in each region should be one of these candidate classes... encourages to predict any class from the candidate set."
  - [section 3.3] "The pseudo label generation process comprises two steps: intra-region label localization that assigns pseudo class labels to individual pixels within each labeled region, and label expansion that spreads the pseudo labels to unlabeled regions adjacent to the labeled one."
  - [section 4.3] "Utilizing prototypes consistently surpasses the baseline across different budgets due to their adaptability to local regions."

### Mechanism 3
- Claim: The acquisition function designed for multi-class labels selects regions that are both uncertain and class-balanced, improving data efficiency.
- Mechanism: It combines best-versus-second-best uncertainty with a class balancing term that considers all classes in a region, not just the dominant one.
- Core assumption: Regions with multiple uncertain classes provide more informative samples than single-class uncertain regions.
- Evidence anchors:
  - [section 3.1] "Our acquisition function, favoring uncertain regions of rare classes, is defined as... Distinct from an existing acquisition function [9] that considers the dominant class only, our function considers classes of all pixels in a region and thus better aligns with multi-class labeling."
  - [section 4.2] "PixBal consistently outperforms all the others regardless of budget size."
  - [corpus] Weak anchor; paper doesn't deeply validate this mechanism separately.

## Foundational Learning

- Concept: Partial label learning
  - Why needed here: Multi-class labeling assigns a set of candidate classes to each pixel, creating ambiguous supervision that requires specialized loss functions.
  - Quick check question: How does the merged positive loss differ from treating the set as a multi-hot target in standard cross-entropy?

- Concept: Multiple instance learning
  - Why needed here: Each region is a "bag" of pixels, and at least one pixel must represent each class in the region's label set.
  - Quick check question: What's the relationship between prototypical pixel loss and MIL's standard formulation?

- Concept: Prototype-based classification
  - Why needed here: Stage 2 uses feature vectors from prototypical pixels as region-adaptive classifiers to generate pseudo labels.
  - Quick check question: How does cosine similarity between features help determine the most likely class for each pixel?

## Architecture Onboarding

- Component map: Data ingestion → Superpixel generation → Active sampling (PixBal) → Multi-class annotation → Stage 1 training (ResNet + DeepLabv3+ with LMP + LPP) → Stage 2 pseudo labeling (prototype extraction + label expansion) → Final model training
- Critical path: Active sampling → Multi-class annotation → Stage 1 training → Prototype extraction → Stage 2 training
- Design tradeoffs: Multi-class labeling trades off some annotation precision for speed and coverage; two-stage training trades off training complexity for better handling of ambiguous labels
- Failure signatures: Poor superpixel quality leading to mixed-class regions; incorrect pseudo labels from poor prototypes; acquisition function selecting uninformative regions
- First 3 experiments:
  1. Implement superpixel generation and multi-class labeling interface, verify annotation speed vs dominant class
  2. Implement stage 1 losses (LMP + LPP) and validate on a small labeled dataset
  3. Implement prototype extraction and pseudo labeling, test on held-out regions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the proposed method vary with different types of local region partitioning algorithms beyond SEEDS?
- Basis in paper: [explicit] The paper mentions using SEEDS superpixels but notes that multi-class labeling is more robust to superpixel generation quality.
- Why unresolved: The paper only compares SEEDS to SLIC and does not explore other region generation methods.
- What evidence would resolve it: Experiments comparing performance using different superpixel algorithms like QuickShift, Felzenszwalb, or learned over-segmentation methods.

### Open Question 2
- Question: What is the impact of varying the temperature parameter τ in the softmax function on model performance?
- Basis in paper: [explicit] The paper mentions using τ=0.1 but does not explore its sensitivity.
- Why unresolved: The paper does not report results with different temperature values.
- What evidence would resolve it: Experiments showing performance curves as τ varies from 0.01 to 1.0.

### Open Question 3
- Question: How does the proposed method perform when applied to other semantic segmentation datasets like ADE20K or COCO-Stuff?
- Basis in paper: [explicit] The paper only evaluates on Cityscapes and PASCAL VOC 2012.
- Why unresolved: The paper does not report results on other popular segmentation benchmarks.
- What evidence would resolve it: Performance metrics on additional datasets with varying numbers of classes and image complexities.

### Open Question 4
- Question: What is the effect of using more than two stages in the training algorithm?
- Basis in paper: [explicit] The paper proposes a two-stage training method but does not explore multi-stage extensions.
- Why unresolved: The paper does not investigate the potential benefits of additional training stages.
- What evidence would resolve it: Experiments comparing three or more stage training approaches against the proposed two-stage method.

## Limitations

- The paper lacks detailed implementation specifications for the pseudo label generation process, particularly prototype selection and label expansion algorithms.
- Limited empirical evidence beyond a user study in the appendix for annotation time savings claims.
- Effectiveness of the two-stage training approach heavily depends on the quality of pseudo labels, which is not thoroughly validated.
- Performance gains are evaluated only on two standard datasets (Cityscapes and PASCAL VOC), limiting generalizability.

## Confidence

- **High confidence**: The multi-class labeling strategy reduces annotation time per click compared to dominant class labeling (supported by corpus user study)
- **Medium confidence**: The two-stage training algorithm effectively handles partial labels (mechanistic reasoning supported by experimental results)
- **Medium confidence**: The PixBal acquisition function improves data efficiency (experimental results show improvement but mechanism not deeply validated)

## Next Checks

1. **Annotation Time Validation**: Conduct controlled experiments comparing annotation times for multi-class vs dominant class labeling across different annotator skill levels and image complexities.

2. **Pseudo Label Quality Assessment**: Evaluate the accuracy and impact of pseudo labels on model performance by systematically varying the number of labeled regions and measuring the effect on downstream segmentation quality.

3. **Cross-Dataset Generalization**: Test the proposed method on additional datasets (e.g., ADE20K, Mapillary Vistas) to assess robustness across different domain characteristics and class distributions.