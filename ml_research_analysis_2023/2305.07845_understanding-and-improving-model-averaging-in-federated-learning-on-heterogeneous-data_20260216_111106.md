---
ver: rpa2
title: Understanding and Improving Model Averaging in Federated Learning on Heterogeneous
  Data
arxiv_id: '2305.07845'
source_url: https://arxiv.org/abs/2305.07845
tags:
- uni00000011
- uni00000014
- uni00000015
- client
- uni00000016
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper visualizes and analyzes the geometric properties of
  federated model averaging (FMA) to understand its effectiveness on heterogeneous
  data. Through loss landscape visualization, the authors find that client models
  surround the global model within a common basin, with the global model potentially
  deviating from the basin's center while still outperforming client models.
---

# Understanding and Improving Model Averaging in Federated Learning on Heterogeneous Data

## Quick Facts
- **arXiv ID**: 2305.07845
- **Source URL**: https://arxiv.org/abs/2305.07845
- **Reference count**: 40
- **Primary result**: Proposed iterative moving averaging (IMA) improves federated learning accuracy and speed on heterogeneous data

## Executive Summary
This paper investigates the geometric properties of federated model averaging (FMA) to understand why it works effectively on heterogeneous data. Through loss landscape visualization, the authors reveal that client models surround the global model within a common basin, with the global model potentially deviating from the basin's center while still outperforming individual client models. Based on these insights, they propose iterative moving averaging (IMA) on the global model during late training phases to reduce deviation from the expected minimum, while constraining client exploration to limit the maximum distance. Experiments demonstrate that IMA significantly improves accuracy and training speed across various heterogeneous data setups.

## Method Summary
The authors visualize and analyze federated model averaging's geometric properties on heterogeneous data. They propose IMA, which aggregates historical global models in a time window during late training phases to compensate for missing information from non-participating clients. This is combined with aggressive learning rate decay to constrain client exploration and prevent catastrophic forgetting. The method aims to reduce the deviation of the global model from the expected minimum by leveraging information from multiple rounds of global model updates.

## Key Results
- Client models surround the global model within a common basin, with the global model potentially deviating from the basin's center while still outperforming client models
- IMA significantly improves the accuracy and training speed of existing FL methods on various heterogeneous data setups
- The global model's expected error after early training is dominated by client model errors on non-overlapping data and maximum distance between global and client models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: FMA yields a superior global model because client models surround the global model within a common basin, preventing overfitting on heterogeneous data.
- **Mechanism**: The client models act as a "basin wall" around the global model, limiting client drift and allowing the global model to converge to a better optimum than individual client models.
- **Core assumption**: The loss landscape forms a basin where the global model is at or near the bottom, surrounded by client models at the edges.
- **Evidence anchors**: Loss landscape visualization shows client models encompass the global model within a common basin; averaged model is located in regions with lower loss and error than individual client models.

### Mechanism 2
- **Claim**: The global model error after early training is dominated by client model errors on non-overlapping data and the maximum distance between global and client models.
- **Mechanism**: Theoretical decomposition shows that heterogeneous bias (error on data not seen by a client) and locality (distance between models) dominate after initial training. IMA reduces these by interpolating global models and constraining client updates.
- **Core assumption**: The decomposition accurately captures the error sources, and the locality term can be controlled via learning rate decay.
- **Evidence anchors**: Decomposition reveals HeterBias and locality terms dominate FMA-model test error after early training; shows that controlling model drift is important in heterogeneous settings.

### Mechanism 3
- **Claim**: IMA on global models reduces deviation from the expected minimum and improves accuracy and training speed.
- **Mechanism**: IMA aggregates historical global models in a time window, compensating for missing information from non-participating clients. Mild client exploration via aggressive learning rate decay prevents catastrophic forgetting.
- **Core assumption**: Historical global models contain complementary information that can be combined to form a better model than the latest FMA model alone.
- **Evidence anchors**: Experiments show IMA significantly improves accuracy and training speed of existing FL methods; window-based averaging improves generalization in heterogeneous FL.

## Foundational Learning

- **Concept**: Federated Learning (FL) basics - clients train locally on private data, server aggregates models via averaging.
  - Why needed here: The paper builds on FL fundamentals to analyze model averaging's effectiveness on heterogeneous data.
  - Quick check question: What is the primary challenge in FL that the paper addresses? (Answer: Data heterogeneity across clients.)

- **Concept**: Loss landscape visualization - plotting loss/error as a function of model parameters to understand optimization geometry.
  - Why needed here: The authors use landscape visualization to reveal that client models surround the global model within a common basin.
  - Quick check question: What geometric property of the loss landscape is key to understanding FMA's success? (Answer: The basin where client models are at the edges and the global model is at or near the bottom.)

- **Concept**: Bias-variance decomposition - breaking down prediction error into bias (systematic error) and variance (model sensitivity to data).
  - Why needed here: The authors adapt this decomposition to FL, showing that heterogeneous bias and locality dominate global model error.
  - Quick check question: In the FL context, what does "HeterBias" represent? (Answer: Error on data not seen by a client but present in the global dataset.)

## Architecture Onboarding

- **Component map**: Clients (train local models) -> Server (aggregates via FMA/IMA) -> Global model update -> Next round
- **Critical path**: Local training → Model aggregation (FMA/IMA) → Global model update → Next round
- **Design tradeoffs**: IMA vs. FMA - IMA improves accuracy but requires storing historical models; aggressive LR decay in IMA vs. standard decay in FMA - better control of locality but may slow convergence
- **Failure signatures**: Poor performance with mild data heterogeneity (IMA gains depend on heterogeneity level); instability with large IMA window size; ineffective if client updates cannot be sufficiently constrained
- **First 3 experiments**:
  1. Reproduce loss landscape visualization (Figure 1) to verify the basin property on a simple heterogeneous dataset
  2. Implement and test IMA with a small window size (P=3) on CIFAR-10 with moderate heterogeneity (α=0.1) to observe accuracy gains
  3. Ablate the learning rate decay scheme in IMA (e.g., compare exponential vs. constant LR) to find the optimal constraint on client exploration

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the relationship between global-model error and client-model error be explicitly quantified in general cases?
  - Basis in paper: The authors state that although they demonstrate the relationship between global-model and client-model error based on expected error decomposition, it is still not clear how to quantify this relationship explicitly in general cases.
  - Why unresolved: The error decomposition provides insights into the factors affecting the global-model error, but it does not provide a clear method for quantifying the relationship between the global and client model errors.
  - What evidence would resolve it: Developing a mathematical framework or formula that explicitly quantifies the relationship between global-model error and client-model error based on the factors identified in the error decomposition.

- **Open Question 2**: What is the optimal starting round and window size for IMA to achieve the best trade-off between communication efficiency and performance?
  - Basis in paper: The authors mention that there is a trade-off between communication efficiency and performance in IMA, and that starting IMA at a later round requires more communication overhead. They also note that increasing the window size improves training stability but can hurt final accuracy if IMA starts early.
  - Why unresolved: The paper does not provide specific guidelines for determining the optimal starting round and window size for IMA, which would depend on factors such as data heterogeneity and model complexity.
  - What evidence would resolve it: Conducting extensive experiments to determine the optimal starting round and window size for IMA under various data heterogeneity levels and model architectures.

- **Open Question 3**: How can more flexible regularization between the global model and client models be used to further reduce bias and locality in Theorem 1?
  - Basis in paper: The authors suggest that using more flexible regularization between the global model and client models (e.g., elastic weight consolidation) can further reduce the bias and locality in Theorem 1.
  - Why unresolved: The paper does not explore the specific methods or techniques for implementing flexible regularization between the global and client models.
  - What evidence would resolve it: Investigating and comparing the performance of different regularization techniques, such as elastic weight consolidation, on reducing bias and locality in the global-model error decomposition.

## Limitations

- The analysis assumes IID-like conditions within the basin for the geometric interpretation, which may not hold for highly non-convex loss landscapes
- The theoretical error decomposition relies on approximations that simplify the complex interactions between client models
- The dominance of HeterBias and locality terms is demonstrated empirically but not rigorously proven across all scenarios

## Confidence

- Basin geometry mechanism (Mechanism 1): **Medium** - Strong empirical visualization support but limited theoretical proof
- Error decomposition (Mechanism 2): **Medium** - Theoretical framework is sound but empirical validation is dataset-specific
- IMA effectiveness (Mechanism 3): **High** - Well-supported by experiments across multiple datasets and methods

## Next Checks

1. Test IMA performance with different aggregation window sizes (P=3, 5, 7) to determine optimal range and identify overfitting risks
2. Evaluate the method on non-vision tasks (e.g., language models) to verify generalizability beyond image classification
3. Conduct ablation studies on the learning rate decay scheme to isolate its contribution to IMA's effectiveness