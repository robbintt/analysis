---
ver: rpa2
title: Unlocking the Potential of Deep Learning in Peak-Hour Series Forecasting
arxiv_id: '2307.01597'
source_url: https://arxiv.org/abs/2307.01597
tags:
- series
- forecasting
- peak-hour
- seq2peak
- phsf
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles peak-hour series forecasting (PHSF), a critical
  but understudied problem in domains like telecommunications, energy, and transportation.
  Standard TSF models struggle with PHSF due to non-stationarity in peak-hour series
  and sub-optimal loss functions.
---

# Unlocking the Potential of Deep Learning in Peak-Hour Series Forecasting

## Quick Facts
- arXiv ID: 2307.01597
- Source URL: https://arxiv.org/abs/2307.01597
- Reference count: 26
- Primary result: Seq2Peak improves forecasting accuracy by 37.7% average over baselines on four real-world datasets.

## Executive Summary
This paper addresses peak-hour series forecasting (PHSF), a critical but understudied problem where standard time series forecasting models struggle due to non-stationarity in peak-hour series and sub-optimal loss functions. The authors propose Seq2Peak, a framework that enhances existing TSF models through Cyclic Normalization to handle non-stationarity and a Peak-hour Decoder with hybrid loss function that jointly optimizes original and peak-hour series. Extensive experiments demonstrate significant improvements across both transformer and non-transformer architectures on four real-world datasets.

## Method Summary
Seq2Peak is a framework that integrates into existing TSF models to improve peak-hour forecasting. It consists of two key components: Cyclic Normalization (CyclicNorm) that handles non-stationarity by modeling inter-cycle hourly relationships through sub-sequence normalization, and a Peak-hour Decoder that uses max-pooling with a hybrid loss function to jointly optimize both original and peak-hour series. The framework requires preprocessing datasets to extract peak-hour series, implementing CyclicNorm with normalization and cyclic processing, and integrating the decoder with max-pooling and weighted MSE loss into baseline models.

## Key Results
- Seq2Peak achieves 37.7% average relative improvement in forecasting accuracy compared to baseline TSF models
- Framework works across both transformer-based (Transformer, Informer) and non-transformer-based (Autoformer, DLinear) models
- Validated on four real-world datasets: ETTh1, ETTh2, Electricity, and Traffic
- Demonstrates effectiveness in domains like telecommunications, energy, and transportation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CyclicNorm reduces non-stationarity by modeling inter-hour relationships within daily cycles.
- Mechanism: CyclicNorm splits the input series into 24 sub-sequences (one per hour of day), normalizes each separately, and then post-processes the resulting statistics to handle longer-term distribution shifts.
- Core assumption: Hourly sub-sequences exhibit stable intra-hour patterns while the overall daily cycle introduces non-stationary shifts.
- Evidence anchors: [abstract] mentions "Cyclic Normalization (CyclicNorm) to handle non-stationarity by modeling inter-cycle hourly relationships." [section] states: "CyclicNorm achieves this by modeling the correlation of distribution across varying hours within a cyclical interval."
- Break condition: If the daily cycle length changes (e.g., not 24h) or the data lacks hourly periodicity, the sub-sequence split will misalign with true cycle boundaries, breaking the assumption.

### Mechanism 2
- Claim: The hybrid loss function balances learning of both original and peak-hour series simultaneously.
- Mechanism: Seq2Peak Decoder uses a max-pooling layer over 24 timesteps to extract peak values from the original series prediction, then jointly minimizes MSE on both the full series and peak series with weighting factor α.
- Core assumption: The mapping from original to peak values is learnable and consistent enough for the max-pooling operation to recover true peaks.
- Evidence anchors: [abstract] describes "a simple yet effective trainable-parameter-free peak-hour decoder with a hybrid loss function that utilizes both the original series and peak-hour series as supervised signals." [section] explains: "To execute this strategy without introducing more trainable parameters, we attach a max-pooling layer of a stride and kernel size of 24 at the end of the previous standard forecasting result."
- Break condition: If peak values occur at irregular intervals (not every 24h block) or are sparse, max-pooling will miss true peaks, and the joint loss will optimize incorrect targets.

### Mechanism 3
- Claim: Integrating Seq2Peak into existing TSF models improves generalization by focusing optimization on the critical peak-hour task.
- Mechanism: Seq2Peak modifies the model output layer and loss without changing the core architecture, so the underlying TSF model learns both standard and peak forecasting simultaneously.
- Core assumption: The original TSF model has enough capacity to learn the additional mapping without overfitting, and the hybrid loss doesn't destabilize training.
- Evidence anchors: [abstract] reports "a remarkable average relative improvement of 37.7% across four real-world datasets for both transformer- and non-transformer-based TSF models." [section] states: "Effortlessly integrating into various forecasting models, Seq2Peak enhances peak-hour forecasting without considerably increasing computational complexity."
- Break condition: If the base model is too shallow or narrow, the dual-task objective may cause interference, leading to worse performance on both tasks.

## Foundational Learning

- Concept: Time series stationarity
  - Why needed here: The paper explicitly identifies non-stationarity as a key challenge in peak-hour forecasting; understanding how mean/variance shift over time is critical to grasp why CyclicNorm is needed.
  - Quick check question: What statistical property of a time series indicates that its mean and variance are constant over time?

- Concept: Autocorrelation function (ACF)
  - Why needed here: ACF measures self-similarity over lags; the paper contrasts full series ACF with peak-hour series ACF to explain why direct forecasting is harder.
  - Quick check question: How does a lower ACF value for peak-hour series affect its predictability compared to the full series?

- Concept: Hybrid loss functions
  - Why needed here: The paper uses a weighted sum of two MSE terms (original + peak) to balance objectives; understanding how loss weighting affects learning dynamics is essential.
  - Quick check question: If α in the hybrid loss is set to 1, which objective dominates training?

## Architecture Onboarding

- Component map: Input -> CyclicNorm -> Base TSF model -> Seq2Peak Decoder (max-pooling + hybrid loss) -> Output (original series + peak series)
- Critical path: CyclicNorm preprocessing -> TSF model forward pass -> Decoder pooling -> Hybrid loss backprop
- Design tradeoffs: CyclicNorm adds preprocessing overhead but stabilizes training; max-pooling is parameter-free but assumes regular peak intervals; hybrid loss increases training complexity but improves peak accuracy
- Failure signatures: Poor peak prediction accuracy despite good full-series accuracy suggests max-pooling misalignment; unstable training suggests incorrect α weighting; unchanged baseline performance suggests CyclicNorm not effective for the dataset
- First 3 experiments:
  1. Run the base TSF model on peak-hour data only (PFP) to confirm baseline degradation
  2. Apply CyclicNorm alone to see if normalization improves peak forecasting without the decoder
  3. Add the Seq2Peak Decoder with α=0.5 to the normalized output to test joint loss effect

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different cycle lengths (other than 24 hours) affect the performance of CyclicNorm in peak-hour series forecasting?
- Basis in paper: [explicit] The authors mention that the peak-hour value is the maximum value downsampled from an interval of T = 24h consecutively for each time series channel.
- Why unresolved: The paper does not explore the impact of using different cycle lengths on the performance of CyclicNorm.
- What evidence would resolve it: Experiments comparing the performance of CyclicNorm with different cycle lengths (e.g., 12 hours, 48 hours) on various datasets would provide insights into the optimal cycle length for different types of time series data.

### Open Question 2
- Question: What is the impact of using different normalization techniques instead of standard normalization in the CyclicNorm pipeline?
- Basis in paper: [inferred] The authors use standard normalization (mean and standard deviation) in the CyclicNorm pipeline, but do not explore other normalization techniques.
- Why unresolved: The paper does not investigate the effectiveness of alternative normalization methods (e.g., min-max scaling, z-score normalization) in the CyclicNorm pipeline.
- What evidence would resolve it: Comparing the performance of CyclicNorm with different normalization techniques on various datasets would help determine the most effective normalization method for PHSF tasks.

### Open Question 3
- Question: How does the performance of Seq2Peak change when using different loss functions or weighting factors (α) for the hybrid loss function?
- Basis in paper: [explicit] The authors use a hybrid loss function with a weighting factor α that varies between 0 and 1, and they provide a hyper-parameter study for α.
- Why unresolved: The paper does not explore the impact of using different loss functions or other weighting factors on the performance of Seq2Peak.
- What evidence would resolve it: Experiments comparing the performance of Seq2Peak with different loss functions and weighting factors on various datasets would provide insights into the optimal configuration for different types of time series data.

## Limitations

- The effectiveness of CyclicNorm relies heavily on the assumption that daily cycles are consistently 24 hours and that hourly patterns are stable across cycles, which may not hold in all real-world scenarios.
- The max-pooling operation in the Peak-hour Decoder assumes peaks occur regularly every 24 hours, limiting generalizability to datasets with irregular peak occurrences.
- The hybrid loss function introduces a weighting parameter α, but the paper lacks systematic analysis of how different α values affect performance across diverse datasets.

## Confidence

- **High Confidence**: The experimental results showing 37.7% average improvement over baselines are well-documented and reproducible given the specified datasets and metrics.
- **Medium Confidence**: The theoretical justification for CyclicNorm's ability to reduce non-stationarity is plausible but lacks empirical validation through ablation studies comparing it to alternative normalization techniques.
- **Low Confidence**: The claim that Seq2Peak "effortlessly integrates" into various TSF models without considerable computational overhead is not substantiated with runtime or memory usage comparisons.

## Next Checks

1. Conduct ablation studies removing CyclicNorm to quantify its individual contribution to peak forecasting accuracy across all four datasets.
2. Test the framework on datasets with non-24-hour cycles (e.g., weekly patterns or irregular intervals) to evaluate robustness when the core assumptions break.
3. Perform a sensitivity analysis on the hybrid loss weighting parameter α, varying it systematically across [0, 1] to identify optimal settings and stability regions.