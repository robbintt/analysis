---
ver: rpa2
title: Large Language Models Enable Few-Shot Clustering
arxiv_id: '2307.00524'
source_url: https://arxiv.org/abs/2307.00524
tags:
- clustering
- entity
- cluster
- same
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores using large language models (LLMs) to improve
  few-shot semi-supervised text clustering. The authors propose three methods to incorporate
  LLMs into the clustering pipeline: expanding document representations with keyphrases
  generated by an LLM, using an LLM as a pseudo-oracle to provide pairwise constraints
  during clustering, and using an LLM to correct low-confidence cluster assignments
  after clustering.'
---

# Large Language Models Enable Few-Shot Clustering

## Quick Facts
- arXiv ID: 2307.00524
- Source URL: https://arxiv.org/abs/2307.00524
- Authors: 
- Reference count: 27
- This paper demonstrates that large language models can significantly improve few-shot semi-supervised text clustering through keyphrase expansion and pairwise constraint provision.

## Executive Summary
This paper explores using large language models (LLMs) to improve few-shot semi-supervised text clustering. The authors propose three methods to incorporate LLMs into the clustering pipeline: expanding document representations with keyphrases generated by an LLM, using an LLM as a pseudo-oracle to provide pairwise constraints during clustering, and using an LLM to correct low-confidence cluster assignments after clustering. They evaluate these methods on five datasets across three tasks: entity canonicalization, query clustering, and tweet clustering. Results show that expanding document representations with LLM-generated keyphrases is the most effective approach, consistently improving cluster quality across all datasets.

## Method Summary
The paper proposes three LLM-based methods for improving few-shot semi-supervised text clustering. First, keyphrase expansion enriches document representations by generating task-specific keyphrases with an LLM and concatenating their embeddings to the original document embeddings. Second, an LLM acts as a pairwise constraint pseudo-oracle, providing demonstrations to classify document pairs as linked or not linked, which are then incorporated into PCKMeans clustering. Third, LLM post-correction identifies low-confidence cluster assignments and uses the LLM to verify and potentially reassign these points based on pairwise similarity judgments.

## Key Results
- LLM-generated keyphrase expansion consistently improves cluster quality across all five datasets and three tasks
- Using an LLM as a pairwise constraint oracle approaches human oracle performance at a fraction of the cost
- LLM post-correction provides limited improvement in clustering quality
- The keyphrase expansion approach shows the most robust performance across different clustering tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-generated keyphrases expand the semantic representation of documents, improving clustering by capturing task-specific aspects that traditional encoders miss.
- Mechanism: The LLM synthesizes additional context and alternative phrasings for each document, encoding them into a single vector that is concatenated to the original document embedding. This enriched representation better captures the semantic dimensions relevant to the clustering task.
- Core assumption: The LLM can generate keyphrases that are semantically relevant and complementary to the original document representation, and that these keyphrases improve clustering performance when added to the representation.
- Evidence anchors:
  - [abstract] "expanding document representations with keyphrases generated by an LLM"
  - [section] "we find that, compared to traditional K-Means clustering on document embeddings, using an LLM to enrich each document's representation empirically improves cluster quality on every metric for all datasets we consider"
  - [corpus] Weak - the corpus neighbors discuss intent discovery and clustering frameworks but don't specifically address the keyphrase expansion mechanism
- Break condition: If the LLM generates irrelevant or noisy keyphrases, or if the encoder used for keyphrases is not aligned with the original encoder, the concatenated representation could become less informative or even misleading.

### Mechanism 2
- Claim: Using an LLM as a pairwise constraint pseudo-oracle enables cost-effective guidance for semi-supervised clustering, approaching human oracle performance at a fraction of the cost.
- Mechanism: The LLM is prompted with demonstrations to classify pairs of documents as either linked (same cluster) or not linked (different clusters). These pairwise constraints are then incorporated into the clustering algorithm (PCKMeans) to improve cluster quality by penalizing constraint violations.
- Core assumption: The LLM can accurately simulate human judgment for pairwise similarity decisions when given appropriate demonstrations, and these decisions can be effectively incorporated into clustering algorithms.
- Evidence anchors:
  - [abstract] "using an LLM as a pseudo-oracle to provide pairwise constraints during clustering"
  - [section] "we see that GPT-3.5 is remarkably more effective than a true oracle pairwise constraint oracle at this price point"
  - [corpus] Weak - the corpus neighbors discuss clustering frameworks and semi-supervised learning but don't specifically address LLM-based pairwise constraint oracles
- Break condition: If the LLM's accuracy for pairwise judgments is low, or if the clustering algorithm cannot effectively incorporate noisy constraints, the performance gains may be minimal or negative.

### Mechanism 3
- Claim: LLM post-correction can improve clustering quality by reassigning low-confidence points based on pairwise similarity judgments.
- Mechanism: After initial clustering, the algorithm identifies the k points with the least margin between their nearest and second-nearest cluster assignments. The LLM is then asked to verify whether each point belongs to its current cluster or should be reassigned to a different cluster based on pairwise similarity.
- Core assumption: The LLM can accurately determine whether a point belongs to its current cluster or should be reassigned when given the appropriate context and demonstrations.
- Evidence anchors:
  - [abstract] "using an LLM to correct low-confidence cluster assignments after clustering"
  - [section] "LLM post-correction provides limited upside"
  - [corpus] Weak - the corpus neighbors don't discuss post-correction approaches for clustering
- Break condition: If the LLM frequently disagrees with the original clustering or makes incorrect reassignment decisions, the post-correction step may degrade rather than improve cluster quality.

## Foundational Learning

- Concept: Pairwise constraint clustering
  - Why needed here: Understanding how pairwise constraints work is crucial for both the PCKMeans algorithm and the LLM post-correction mechanism, as both rely on pairwise similarity judgments to improve clustering.
  - Quick check question: How does PCKMeans incorporate pairwise constraints into the clustering objective function?

- Concept: Semi-supervised learning tradeoffs
  - Why needed here: The paper explores different approaches to semi-supervised clustering with LLMs, requiring understanding of the tradeoffs between cost, accuracy, and the amount of supervision needed.
  - Quick check question: What are the key differences between using an LLM as a pseudo-oracle versus collecting human annotations for pairwise constraints?

- Concept: Document representation and encoding
  - Why needed here: The effectiveness of the keyphrase expansion approach depends on understanding how document representations are constructed and how additional information can be incorporated.
  - Quick check question: How does concatenating keyphrase embeddings to document embeddings change the geometry of the representation space?

## Architecture Onboarding

- Component map: Document preprocessing and embedding generation -> LLM interaction layer (for keyphrase generation, pairwise constraints, and post-correction) -> Clustering algorithm (KMeans with PCKMeans extension) -> Evaluation and metrics computation

- Critical path: Document → LLM keyphrase generation → Embedding concatenation → Clustering → Evaluation

- Design tradeoffs:
  - Keyphrase expansion: LLM cost vs. performance improvement, choice of encoder for keyphrases
  - Pairwise constraint oracle: Number of constraints vs. cost, quality of LLM demonstrations
  - Post-correction: Number of low-confidence points to correct vs. LLM query cost, potential for introducing errors

- Failure signatures:
  - Keyphrase expansion: Decreased clustering performance, irrelevant or noisy keyphrases in the representation
  - Pairwise constraint oracle: High cost with minimal performance improvement, inconsistent LLM responses
  - Post-correction: Degradation in cluster quality after correction, excessive number of point reassignments

- First 3 experiments:
  1. Implement keyphrase expansion on a small text clustering dataset and compare against baseline KMeans
  2. Test pairwise constraint oracle with a small number of demonstrations and constraints on an entity canonicalization dataset
  3. Evaluate post-correction on a clustered dataset by identifying low-confidence points and measuring improvement

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several implicit questions arise from the work: How do the costs and benefits of using LLMs for semi-supervised clustering scale with dataset size and number of clusters? What is the optimal trade-off between the number of LLM queries and clustering performance for the pairwise constraint approach? How do different LLM architectures and prompt engineering techniques affect clustering performance across various tasks?

## Limitations
- The paper only evaluates English datasets and does not address potential bias or performance degradation in other languages
- Computational overhead of processing large document collections with LLMs is not quantified or discussed
- The clustering quality improvements may not translate to downstream tasks, which is not evaluated in the paper

## Confidence

| Claim | Confidence |
|-------|------------|
| Keyphrase expansion consistently improves cluster quality | High |
| LLM pairwise constraint oracle approaches human performance at lower cost | Medium |
| LLM post-correction provides limited improvement | Medium |

## Next Checks

1. **Ablation study on keyphrase quality**: Systematically evaluate the impact of keyphrase relevance on clustering performance by filtering or modifying LLM-generated keyphrases and measuring the degradation in cluster quality metrics.

2. **Cost-accuracy tradeoff analysis**: Conduct a detailed evaluation of the pairwise constraint oracle approach across different budget constraints, measuring how performance scales with the number of LLM queries and constraints provided.

3. **Cross-dataset generalization test**: Apply the best-performing LLM-enhanced clustering approach to a held-out dataset from a different domain (e.g., scientific paper clustering) to assess generalizability beyond the five datasets used in the paper.