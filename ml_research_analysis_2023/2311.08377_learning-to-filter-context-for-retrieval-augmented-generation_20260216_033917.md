---
ver: rpa2
title: Learning to Filter Context for Retrieval-Augmented Generation
arxiv_id: '2311.08377'
source_url: https://arxiv.org/abs/2311.08377
tags:
- context
- passages
- generation
- tasks
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of irrelevant or distracting content
  in retrieved passages for knowledge-intensive generation tasks. The authors propose
  FILCO, a method that improves the quality of context provided to the generator by
  identifying useful context based on lexical and information-theoretic approaches,
  and training context filtering models that can filter retrieved contexts at test
  time.
---

# Learning to Filter Context for Retrieval-Augmented Generation

## Quick Facts
- arXiv ID: 2311.08377
- Source URL: https://arxiv.org/abs/2311.08377
- Authors: 13 authors
- Reference count: 13
- Primary result: FILCO improves context quality for retrieval-augmented generation, achieving +4.3 to +8.6 EM increase on NQ and +1.0 to +1.3 F1 increase on HotpotQA

## Executive Summary
This paper addresses the problem of irrelevant or distracting content in retrieved passages for knowledge-intensive generation tasks. The authors propose FILCO, a method that improves the quality of context provided to the generator by identifying useful context based on lexical and information-theoretic approaches, and training context filtering models that can filter retrieved contexts at test time. FILCO effectively improves the quality of context, whether or not it supports the canonical output, across six knowledge-intensive tasks including extractive question answering, complex multi-hop and long-form QA, fact verification, and dialog generation tasks.

## Method Summary
FILCO is a fine-grained context filtering approach that identifies and removes irrelevant sentences from retrieved passages to improve generation quality. The method uses three filtering strategies: STRINC (string inclusion), LEXICAL (unigram overlap), and CXMI (conditional cross-mutual information). These strategies are used to create oracle filtered contexts for training a context filtering model. At test time, the filtering model identifies the most relevant sentences from retrieved passages, which are then provided to the generation model along with the input query. The approach is evaluated on six knowledge-intensive tasks using models like FLAN-T5 and LLAMA2.

## Key Results
- FILCO achieves +4.3 and +8.6 EM increase in NQ with FLAN-T5 and LLAMA2 models
- FILCO achieves +1.0 and +1.3 F1 increase in HotpotQA with FLAN-T5 and LLAMA2
- FILCO achieves +6.2 and +4.3 accuracy increase for FEVER with FLAN-T5 and LLAMA2
- FILCO reduces prompt length by 44-64% across tasks while improving performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-grained sentence-level filtering improves context quality by removing distracting content within otherwise relevant passages.
- Mechanism: The model identifies and removes sentences that are not directly useful for generating the answer, reducing noise and helping the generator focus on supporting information.
- Core assumption: Not all sentences in a relevant passage are equally useful; some contain distracting or irrelevant information that harms generation quality.
- Evidence anchors:
  - [abstract] "Our method outperforms existing approaches on extractive question answering (QA), complex multi-hop and long-form QA, fact verification, and dialog generation tasks."
  - [section] "FILCO effectively improves the quality of context, whether or not it supports the canonical output."
- Break condition: If the filtering model cannot distinguish between supporting and distracting sentences, or if the model incorrectly removes useful context.

### Mechanism 2
- Claim: Different filtering strategies (STRINC, LEXICAL, CXMI) are optimal for different task types based on their generation characteristics.
- Mechanism: The model uses string inclusion for extractive tasks, lexical overlap for dialog generation, and conditional cross-mutual information for complex reasoning tasks.
- Core assumption: Different task types have different requirements for context relevance and filtering approaches.
- Evidence anchors:
  - [abstract] "FILCO effectively improves the quality of context, whether or not it supports the canonical output."
  - [section] "Comparing filtering methods on each task, we observe that STRINC, LEXICAL and CXMI-based filtering were best for extractive QA, dialog generation, and more complex tasks, respectively (§5)."
- Break condition: If the filtering strategy selection is incorrect for a given task, or if the filtering measures do not accurately capture context relevance.

### Mechanism 3
- Claim: Filtering reduces input length, leading to more efficient generation with comparable or better performance.
- Mechanism: By providing only the most relevant sentences as context, the model reduces the number of tokens in the input, decreasing computation and improving focus.
- Core assumption: Shorter, more focused context leads to better generation performance and reduced computational cost.
- Evidence anchors:
  - [abstract] "FILCO effectively improves the quality of context, whether or not it supports the canonical output."
  - [section] "FILCO also greatly reduces the prompt length by 44 − 64% across tasks."
- Break condition: If the filtered context is too short and misses essential information, or if the model relies too heavily on its internal knowledge and ignores context.

## Foundational Learning

- Concept: Retrieval-augmented generation (RAG) and its limitations
  - Why needed here: Understanding why retrieval-augmented generation is used and what problems it faces (imperfect retrieval, irrelevant context) is crucial for understanding the motivation behind FILCO.
  - Quick check question: What are the main challenges of retrieval-augmented generation, and how does FILCO address them?

- Concept: Context filtering and its importance
  - Why needed here: FILCO is a context filtering method, so understanding what context filtering is and why it's important for generation is essential.
  - Quick check question: What is context filtering, and how can it improve the quality of generated outputs?

- Concept: Different filtering strategies and their applications
  - Why needed here: FILCO uses different filtering strategies (STRINC, LEXICAL, CXMI) for different task types, so understanding these strategies and their applications is important for implementing and using FILCO.
  - Quick check question: What are the different filtering strategies used in FILCO, and when should each one be applied?

## Architecture Onboarding

- Component map:
  - Retrieval system (DPR) -> Context filtering model (Mctx) -> Generation model (Mgen)

- Critical path:
  - Input query and gold output are provided
  - Retrieval system retrieves passages
  - Context filtering model filters the passages using the appropriate strategy
  - Generation model generates the output using the filtered context and the input query

- Design tradeoffs:
  - Fine-grained vs. coarse-grained filtering: FILCO uses sentence-level filtering, which is more precise but potentially more computationally expensive than passage-level filtering
  - Different filtering strategies for different tasks: Using different strategies for different tasks can improve performance but requires careful selection and tuning

- Failure signatures:
  - Poor generation performance: May indicate that the context filtering is not effective or that the wrong filtering strategy is being used
  - Over-reliance on context: May indicate that the generation model is not using its internal knowledge effectively
  - Under-reliance on context: May indicate that the context filtering is too aggressive and removing useful information

- First 3 experiments:
  1. Evaluate FILCO on a single task (e.g., NQ) with a single filtering strategy (e.g., STRINC) and compare it to baseline methods
  2. Compare the performance of different filtering strategies on a single task to determine which one works best
  3. Evaluate FILCO on multiple tasks with different filtering strategies to demonstrate its versatility and effectiveness

## Open Questions the Paper Calls Out

The paper acknowledges several open questions and limitations, including the need for more extensive experiments on non-English datasets and the potential for neural or human-based evaluation metrics to provide more accurate assessments of generation quality, especially as tasks become more complex and models grow larger.

## Limitations

- The evaluation is limited to English-language tasks and Wikipedia-based knowledge sources, limiting generalizability to other languages and domains
- The paper reports results with specific model sizes without extensive ablation studies on model scale effects
- The paper does not thoroughly analyze computational overhead or latency impacts of the filtering process in real-time applications

## Confidence

- High confidence: The core mechanism of sentence-level filtering and the empirical improvements across multiple tasks are well-supported by the results
- Medium confidence: The selection of optimal filtering strategies (STRINC, LEXICAL, CXMI) for different task types is based on observed performance patterns but could benefit from more theoretical grounding
- Medium confidence: The claim that filtered contexts are more useful regardless of supporting the canonical output requires further validation with diverse evaluation metrics

## Next Checks

1. Conduct ablation studies varying model sizes to understand how FILCO's effectiveness scales with model capacity and whether smaller models benefit equally
2. Test FILCO on non-English datasets and alternative knowledge sources (e.g., specialized domains, proprietary databases) to assess cross-domain applicability
3. Measure and report computational overhead, including inference latency and memory usage, to evaluate practical deployment considerations for real-time applications