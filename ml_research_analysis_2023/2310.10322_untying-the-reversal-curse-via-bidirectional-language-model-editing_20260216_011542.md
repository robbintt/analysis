---
ver: rpa2
title: Untying the Reversal Curse via Bidirectional Language Model Editing
arxiv_id: '2310.10322'
source_url: https://arxiv.org/abs/2310.10322
tags:
- editing
- knowledge
- language
- methods
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the "reversal curse" in large language model
  (LLM) editing, where models fail to recall edited knowledge bidirectionally. The
  authors introduce a new evaluation metric, reversibility, and construct the Bidirectional
  Assessment for Knowledge Editing (BAKE) benchmark.
---

# Untying the Reversal Curse via Bidirectional Language Model Editing

## Quick Facts
- arXiv ID: 2310.10322
- Source URL: https://arxiv.org/abs/2310.10322
- Reference count: 40
- The paper introduces the reversibility metric and BIRD method to address the "reversal curse" in LLM editing, achieving significant improvements in bidirectional knowledge recall.

## Executive Summary
This paper addresses the "reversal curse" in large language model editing, where models fail to recall edited knowledge bidirectionally. The authors introduce a new evaluation metric called reversibility and construct the Bidirectional Assessment for Knowledge Editing (BAKE) benchmark. They find that existing editing methods and LLMs suffer serious deficiencies when evaluated in the reverse direction of editing. To mitigate this, they propose Bidirectionally Inversible Relationship moDeling (BIRD), which incorporates bidirectional relationships between subject and object into the updated model weights. Experiments on four representative LLMs of different sizes demonstrate that BIRD not only improves generalization ability in the editing direction but also achieves highly promising performance in the reverse direction, significantly outperforming other methods on the reversibility metric.

## Method Summary
The authors propose BIRD (Bidirectionally Inversible Relationship moDeling), an extension of the ROME editing method that explicitly models bidirectional relationships between entities. BIRD incorporates word2vec-inspired vector arithmetic into the objective function, enforcing that representations of related entities satisfy symmetric relationships. The method uses KL divergence to preserve the model's understanding of the subject's essence while updating the weights to encode both forward and reverse relationships. The approach is evaluated on the newly constructed BAKE benchmark, which includes the BAKE-Q&J and BAKE-J datasets designed to assess bidirectional knowledge recall.

## Key Results
- BIRD significantly outperforms existing editing methods on the reversibility metric, addressing the "reversal curse" where models fail to recall knowledge bidirectionally
- The reversibility metric reveals that current editing methods perform substantially worse on reverse direction queries compared to forward direction, highlighting a critical gap in model editing capabilities
- BIRD achieves highly promising performance in both editing and reverse directions across four LLMs of different sizes (GPT-2 XL, GPT-J, LLaMA-1, LLaMA-2)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Existing model editing methods fail to capture bidirectional relationships between entities, leading to the reversal curse.
- Mechanism: Current methods only encode knowledge in one direction (subject → object), neglecting the reverse (object → subject) association. This causes models to fail when queried in the reverse direction of editing.
- Core assumption: Factual knowledge in LLMs is stored as directional associations, and these associations must be symmetric for bidirectional recall.
- Evidence anchors:
  - [abstract] "While current model editing methods and LLMs perform significantly well at recalling the editing facts in the direction of editing, they suffer serious deficiencies when evaluated in the reverse direction."
  - [section 5.3] "Although current model editing methods and LLMs can effectively recall the editing facts in the direction of editing, they suffer serious deficiencies when evaluated in the reverse direction."

### Mechanism 2
- Claim: BIRD mitigates the reversal curse by explicitly modeling bidirectional and invertible relationships between subject and object.
- Mechanism: BIRD uses word2vec-inspired vector arithmetic to enforce that the representation of the object is close to the representation of the subject plus the forward relation, and vice versa for the reverse relation. This creates symmetric associations.
- Core assumption: The property V(Paris) - V(France) ≈ V(London) - V(England) in static word vectors holds for contextualized representations in LLMs.
- Evidence anchors:
  - [section 6.1] "To make use of this property, this paper designs a set of simple yet effective objectives and incorporates them into Eq. (2) to improve ROME."
  - [section 6.2] "Experiments on four LLMs of different sizes demonstrate that the proposed editing method not only improves the generalization ability when recalling the editing facts in the direction of editing, but also achieves highly promising performance in the reverse direction."

### Mechanism 3
- Claim: The reversibility metric is more challenging than portability and multi-hop metrics, revealing deeper shortcomings in current editing methods.
- Mechanism: Reversibility requires the model to recall the original subject when given the edited object and reverse relation, which is a stricter test than recalling related content (portability) or answering multi-hop questions.
- Core assumption: The ability to recall knowledge bidirectionally is a fundamental requirement for effective model editing.
- Evidence anchors:
  - [section 5.3] "The results of reversibility were significantly lower than those of portability across most of methods. Even compared to the multi-hop metric, the RQS results were generally lower."
  - [section 5.3] "These results indicate that the proposed reversibility metric is indeed more challenging and points out the urgent shortcomings of current editing methods."

## Foundational Learning

- Concept: Vector arithmetic in word embeddings
  - Why needed here: BIRD relies on the assumption that vector arithmetic properties from static word embeddings (like word2vec) hold in contextualized representations.
  - Quick check question: Can you explain why V(Paris) - V(France) ≈ V(London) - V(England) in word2vec embeddings?

- Concept: Causal mediation analysis
  - Why needed here: ROME, the baseline method, uses causal mediation analysis to locate MLP modules storing factual knowledge.
  - Quick check question: What is the purpose of causal mediation analysis in the context of model editing?

- Concept: KL divergence
  - Why needed here: ROME uses KL divergence to minimize the difference between predictions for the original and edited prompts, preserving the model's understanding of the subject's essence.
  - Quick check question: Why is KL divergence used in the objective function of ROME?

## Architecture Onboarding

- Component map: LLM (GPT-2 XL, GPT-J, LLaMA-1, LLaMA-2) -> Editing Method (ROME, BIRD) -> Evaluation (BAKE-Q&J, BAKE-J datasets)
- Critical path: 1) Sample editing examples from Wikidata. 2) Edit the base LLM using the chosen method. 3) Evaluate efficacy, generalization, locality, and reversibility on BAKE datasets.
- Design tradeoffs: BIRD adds computational overhead due to the additional objectives but significantly improves reversibility. The choice of hyperparameters (α, β) affects the balance between new fact memorization and old fact weakening.
- Failure signatures: Low reversibility scores indicate failure to capture bidirectional associations. High efficacy but low reversibility suggests hard encoding without understanding.
- First 3 experiments:
  1. Compare ROME and BIRD on a small subset of BAKE-Q&J to verify improved reversibility.
  2. Ablate the bidirectional objectives in BIRD to confirm their contribution.
  3. Test BIRD on a model with known bidirectional embeddings to isolate the effect of the editing method.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of BIRD compare to other editing methods when applied to LLMs with different sizes, particularly in terms of efficacy, generalization, and reversibility?
- Basis in paper: [explicit] The paper mentions that BIRD was applied to four LLMs of different sizes (GPT-2 XL, GPT-J, LLaMA-1, and LLaMA-2) and performed better than other editing methods in terms of overall Score, especially in terms of generalization and reversibility.
- Why unresolved: The paper does not provide a detailed comparison of BIRD's performance across different LLM sizes, making it unclear how well BIRD scales with model size.
- What evidence would resolve it: A detailed analysis of BIRD's performance on each LLM size, including efficacy, generalization, and reversibility scores, would help understand how well BIRD scales with model size.

### Open Question 2
- Question: What is the impact of the hyperparameters α and β in BIRD on its performance, and how do they affect the trade-off between efficacy and reversibility?
- Basis in paper: [explicit] The paper mentions that α and β are hyperparameters in BIRD that control the balance between efficacy and reversibility, but it does not provide a detailed analysis of their impact on performance.
- Why unresolved: The paper does not provide a thorough investigation of how α and β affect BIRD's performance, making it unclear how to optimally set these hyperparameters.
- What evidence would resolve it: A detailed analysis of BIRD's performance with different values of α and β, including the trade-off between efficacy and reversibility, would help understand the impact of these hyperparameters.

### Open Question 3
- Question: How does the performance of BIRD compare to other editing methods when evaluated on different types of relations, such as one-to-one, one-to-many, many-to-one, and many-to-many?
- Basis in paper: [explicit] The paper mentions that BIRD was evaluated on different types of relations, but it does not provide a detailed comparison of its performance across these relation types.
- Why unresolved: The paper does not provide a thorough investigation of how BIRD's performance varies across different relation types, making it unclear how well BIRD handles different types of knowledge.
- What evidence would resolve it: A detailed analysis of BIRD's performance on each relation type, including efficacy, generalization, and reversibility scores, would help understand how well BIRD handles different types of knowledge.

## Limitations

- The method relies on the assumption that vector arithmetic properties from static word embeddings hold in contextualized representations, which requires further validation across different model architectures.
- The evaluation primarily focuses on factual knowledge editing and may not generalize well to more complex knowledge structures or procedural knowledge.
- The reversibility metric may not capture all aspects of bidirectional knowledge recall and could be influenced by pattern-based inference rather than genuine understanding.

## Confidence

- High confidence in the identification of the reversal curse as a genuine problem in model editing, supported by consistent experimental results across multiple datasets and models.
- Medium confidence in the effectiveness of BIRD's mechanism, as the improvement in reversibility metrics is significant but the underlying assumption about vector arithmetic properties needs further validation.
- Medium confidence in the claim that reversibility is a more challenging metric than portability and multi-hop, based on comparative results but requiring additional ablation studies to isolate contributing factors.

## Next Checks

1. Conduct ablation studies to isolate the contribution of the bidirectional objectives in BIRD by comparing performance with and without these components across different model sizes and architectures.

2. Test the vector arithmetic assumption (V(subject) + V(relation) ≈ V(object)) across different embedding spaces and model architectures to determine if this property is universal or model-specific.

3. Design edge case experiments to distinguish between genuine bidirectional understanding and pattern-based inference, such as testing with rare relations or entities that appear in different contexts with different reverse associations.