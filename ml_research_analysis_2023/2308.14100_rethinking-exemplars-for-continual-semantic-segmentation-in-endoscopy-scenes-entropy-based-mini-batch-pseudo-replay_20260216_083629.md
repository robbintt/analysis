---
ver: rpa2
title: 'Rethinking Exemplars for Continual Semantic Segmentation in Endoscopy Scenes:
  Entropy-based Mini-Batch Pseudo-Replay'
arxiv_id: '2308.14100'
source_url: https://arxiv.org/abs/2308.14100
tags:
- segmentation
- data
- learning
- endocss
- continual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles catastrophic forgetting in continual semantic
  segmentation (CSS) for endoscopy scenes, where new classes are introduced over time.
  The authors propose the EndoCSS framework, which addresses privacy and storage issues
  by using a mini-batch pseudo-replay (MB-PR) strategy.
---

# Rethinking Exemplars for Continual Semantic Segmentation in Endoscopy Scenes: Entropy-based Mini-Batch Pseudo-Replay

## Quick Facts
- arXiv ID: 2308.14100
- Source URL: https://arxiv.org/abs/2308.14100
- Reference count: 40
- Primary result: MB-PR strategy with SAN-CE loss effectively mitigates catastrophic forgetting in continual endoscopy segmentation.

## Executive Summary
This paper addresses catastrophic forgetting in continual semantic segmentation (CSS) for endoscopy scenes, where new classes are introduced over time. The authors propose the EndoCSS framework, which uses a mini-batch pseudo-replay (MB-PR) strategy to generate synthetic replay images via a generative model and combines them with current training data at the batch level. Additionally, a self-adaptive noisy cross-entropy (SAN-CE) loss is employed to enhance model fitting and robustness. Experiments on public datasets demonstrate that the EndoCSS framework effectively mitigates catastrophic forgetting and improves the model's ability to learn new knowledge while retaining old knowledge.

## Method Summary
The EndoCSS framework tackles continual semantic segmentation by using a mini-batch pseudo-replay strategy to generate synthetic replay images for old classes via SinGAN, combined with current data at each batch. An entropy-based pseudo-label filtering step removes uncertain pixels from generated labels to ensure high-quality supervision. The framework also employs a self-adaptive noisy cross-entropy (SAN-CE) loss that injects Gaussian noise into logits to improve global convergence and robustness. The method is evaluated on EDD2020 and EndoVis datasets using Deeplab-V3 with ResNet101 backbone, trained with SGD optimizer and compared against several baseline continual learning methods.

## Key Results
- EndoCSS outperforms baseline methods (ILT, LWF, MiB, PLOP, RCIL, ACS) on both EDD2020 and EndoVis datasets in terms of mIoU.
- The MB-PR strategy effectively mitigates catastrophic forgetting by combining synthetic replay and current data at the batch level.
- SAN-CE loss improves model fitting and robustness by adjusting output logits with Gaussian noise.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Mini-batch pseudo-replay (MB-PR) corrects model bias by combining synthetic replay and current data at the batch level, rather than concatenating them before training.
- Mechanism: The framework generates pseudo-replay images via a generative model, filters them using IoU ranking and entropy-based pseudo-label filtering, then interleaves a fixed ratio of replay samples into each training batch alongside current samples. This forces the model to update parameters on both old and new tasks in every gradient descent step, reducing bias toward the dominant current data.
- Core assumption: The generative model can produce high-quality pseudo-images that preserve semantic structure and texture, and that IoU-based sample selection yields representative exemplars for each class.
- Evidence anchors:
  - [abstract] "The MB-PR strategy circumvents privacy and storage issues by generating pseudo-replay images through a generative model."
  - [section 3.1.3] "Each batch of data is replayed so that both types of data can participate in the model parameter update in gradient descent through the MB-PR process."
  - [corpus] Weak: No direct neighbor study validating the exact MB-PR batching strategy; evidence is mostly theoretical from this paper.
- Break condition: If the generative model quality degrades, or IoU-based selection fails to cover minority classes, bias correction fails and catastrophic forgetting reappears.

### Mechanism 2
- Claim: Self-adaptive noisy cross-entropy (SAN-CE) loss improves global convergence and robustness by injecting Gaussian noise into logits during training.
- Mechanism: The loss adjusts logits with a term proportional to the current training step, mean, and standard deviation of Gaussian noise, which postpones early saturation for underfitted samples and promotes more uniform learning across samples.
- Core assumption: The model operates in an underfitted regime for most samples, so increasing logit values helps escape local minima and enhances robustness.
- Evidence anchors:
  - [section 3.2] "We explore increasing the logit value of the samples... Gaussian noise can further improve the robustness of training effectively."
  - [abstract] "SAN-CE loss can help model fitting by adjusting the model's output logits, and also improve the robustness of training."
  - [corpus] Weak: No neighbor paper explicitly validates SAN-CE; the claim rests on internal ablation results.
- Break condition: If the noise magnitude is too large or too small, it may destabilize training or become ineffective, causing divergence or no benefit.

### Mechanism 3
- Claim: Entropy-based pseudo-label filtering removes uncertain pixels from generated labels, ensuring high-quality supervision from synthetic data.
- Mechanism: After generating pseudo-labels via the previous model, entropy scores are computed per pixel; pixels with entropy above a threshold are marked as "eliminate" rather than assigned a class, filtering out ambiguous predictions.
- Core assumption: Entropy is a reliable proxy for pixel-wise uncertainty, and removing high-entropy pixels yields cleaner pseudo-labels than thresholding confidence alone.
- Evidence anchors:
  - [section 3.1.2] "We integrate the entropy-based method to filter pseudo-label with high confidence... allowing us to establish the generated replay dataset for classes with accuracy and reliability."
  - [abstract] "Entropy-based methods shall help us filter out poor-quality pairs of generated images and pseudo-labels."
  - [corpus] Weak: No direct neighbor evidence; the claim is supported only by the paper's own ablation experiments.
- Break condition: If the entropy threshold is poorly chosen, too many valid pixels may be discarded or too many uncertain pixels retained, degrading learning.

## Foundational Learning

- Concept: Continual learning and catastrophic forgetting
  - Why needed here: The paper explicitly tackles catastrophic forgetting in class-incremental endoscopy segmentation, so understanding the phenomenon and mitigation strategies is foundational.
  - Quick check question: What is catastrophic forgetting and how does it typically manifest in neural network training?

- Concept: Generative adversarial networks and image synthesis
  - Why needed here: The framework relies on a generative model (SinGAN) to produce pseudo-replay images; understanding GAN architecture and training dynamics is essential.
  - Quick check question: How does an unconditional generative model like SinGAN generate diverse images from a single training sample?

- Concept: Semantic segmentation evaluation metrics (IoU, mIoU)
  - Why needed here: IoU ranking is used for sample selection, and segmentation performance is reported in mIoU; familiarity with these metrics is necessary for interpreting results.
  - Quick check question: What is the difference between IoU for a single class and mean IoU (mIoU) across classes?

## Architecture Onboarding

- Component map:
  SinGAN generator -> IoU ranking filter -> Entropy filter -> Mini-batch combiner -> SAN-CE loss module -> Deeplab-V3 segmentation backbone

- Critical path:
  1. Train SinGAN on highest-IoU images per class.
  2. Generate pseudo-images and pseudo-labels for old classes.
  3. Filter pseudo-labels with entropy threshold.
  4. During each training batch: combine fixed-ratio replay + current data.
  5. Compute SAN-CE loss and update model.

- Design tradeoffs:
  - Replay vs. regularization: Replay-based methods store or generate data; regularization methods penalize weight changes. Replay here trades off training speed for direct feature preservation.
  - Batch interleaving vs. dataset concatenation: Interleaving enforces simultaneous learning per batch but requires careful ratio tuning; concatenation is simpler but risks bias.
  - Noise magnitude in SAN-CE: Larger noise may improve exploration but risk instability; smaller noise may not help underfitting.

- Failure signatures:
  - Training instability or divergence -> likely SAN-CE noise too large or SinGAN poor quality.
  - Sudden drop in old-class mIoU -> replay images not representative or entropy filtering too aggressive.
  - No improvement over baselines -> IoU selection missing minority classes or batch ratio off.

- First 3 experiments:
  1. Train SinGAN on a single class's high-IoU images; generate and visualize synthetic samples; check realism and diversity.
  2. Apply entropy filter to a set of pseudo-labels; plot histogram of retained vs. eliminated pixels; tune threshold.
  3. Run a small continual learning experiment with MB-PR (fixed ratio 1:1) on two synthetic tasks; compare mIoU before/after to baseline concatenation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the EndoCSS framework scale with the number of classes and tasks in the continual learning scenario?
- Basis in paper: [explicit] The paper mentions "We set up and evaluate our method on several CSS protocols, e.g., 4-1, 3-2, and 3-1, respectively" and "4-1 means the model will learn 4 classes in the initial step, and then 1 class in the following step"
- Why unresolved: The paper only evaluates a limited number of protocols and doesn't provide a systematic analysis of how performance scales with increasing number of classes and tasks.
- What evidence would resolve it: Conducting experiments with a wider range of protocols, including those with more classes and tasks, and analyzing the scaling behavior of the framework's performance.

### Open Question 2
- Question: How does the choice of generative model affect the quality of pseudo-replay images and the overall performance of the EndoCSS framework?
- Basis in paper: [explicit] The paper compares SinGAN with other generative models (GPNN and SinDiffusion) in terms of image quality, but doesn't explore how different generative models impact the framework's performance.
- Why unresolved: The paper focuses on SinGAN as the pseudo-sample generator but doesn't investigate the effects of using other generative models.
- What evidence would resolve it: Replacing SinGAN with other generative models (e.g., VAEs, flow-based models) and comparing the resulting pseudo-replay image quality and the framework's performance.

### Open Question 3
- Question: How does the EndoCSS framework perform in scenarios with more complex class relationships, such as hierarchical or fine-grained class structures?
- Basis in paper: [inferred] The paper mentions "Therefore, we take into consideration the incorporation of more explicit features in our framework and devise a meticulously designed pseudo-rehearsal strategy" and "images shall require high-quality preservation of details and textures"
- Why unresolved: The paper focuses on class-incremental scenarios but doesn't explore how the framework handles more complex class relationships.
- What evidence would resolve it: Designing experiments with hierarchical or fine-grained class structures and evaluating the framework's ability to learn and distinguish between these classes in a continual learning setup.

## Limitations
- The exact hyperparameters for entropy threshold, replay ratio, and noise scale are not specified, making exact replication difficult.
- The framework's performance with more than a few tasks is not explored, leaving scalability uncertain.
- SAN-CE loss mechanism lacks strong external validation and depends on assumptions about model saturation.

## Confidence
- **High**: The existence of catastrophic forgetting in continual endoscopy segmentation and the need for replay-based mitigation is well-established.
- **Medium**: The proposed MB-PR strategy's batch-level interleaving approach is logically sound and aligns with prior replay methods, though its relative advantage over concatenation is not directly validated here.
- **Low**: The SAN-CE loss mechanism's benefit (noise injection for underfitting) lacks strong external validation and depends on assumptions about model saturation that may not hold universally.

## Next Checks
1. Ablation on SAN-CE loss: Train identical models with/without SAN-CE on a held-out continual task split to quantify its direct contribution to mIoU stability.
2. Entropy threshold sensitivity: Sweep entropy thresholds and plot retained pixel fraction vs. old-class mIoU to identify optimal filtering.
3. Replay ratio robustness: Systematically vary replay:current batch ratios (e.g., 0.25, 0.5, 1.0, 2.0) and measure forgetting and convergence speed.