---
ver: rpa2
title: 'FROST: Towards Energy-efficient AI-on-5G Platforms -- A GPU Power Capping
  Evaluation'
arxiv_id: '2310.11131'
source_url: https://arxiv.org/abs/2310.11131
tags:
- energy
- power
- o-ran
- consumption
- frost
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FROST, a software-based power profiling framework
  that optimizes energy consumption in ML pipelines deployed in O-RAN environments.
  FROST uses real-time power measurement via hardware APIs and applies power capping
  to limit GPU energy use without degrading model accuracy.
---

# FROST: Towards Energy-efficient AI-on-5G Platforms -- A GPU Power Capping Evaluation

## Quick Facts
- arXiv ID: 2310.11131
- Source URL: https://arxiv.org/abs/2310.11131
- Reference count: 27
- Primary result: GPU power capping achieves up to 26.4% energy savings with minimal accuracy impact

## Executive Summary
This paper introduces FROST, a software-based power profiling framework that optimizes energy consumption in ML pipelines deployed in O-RAN environments. FROST uses real-time power measurement via hardware APIs and applies power capping to limit GPU energy use without degrading model accuracy. Testing across 16 CNN architectures on CIFAR-10 datasets and two GPU setups showed energy savings of up to 26.4%, with minimal impact on training time. The method employs an Energy-Delay Product (EDP)-based optimization to select optimal power profiles, and demonstrates that aggressive capping can cause instability, while moderate limits yield consistent gains. FROST integrates seamlessly into O-RAN's ML workflow, supporting dynamic policy-driven tuning with negligible overhead.

## Method Summary
FROST implements a software-based power profiling framework that profiles GPU, CPU, and DRAM power consumption using NVML and RAPL APIs. The framework runs short 30-second profiling trials across eight power limits (30%-100%) to collect energy and timing data for each CNN model. An Energy-Delay Product (EDP)-based optimization function is fitted to the profiles, and the optimal power cap is selected to minimize energy consumption. The framework is designed for seamless integration into O-RAN environments, using only standard APIs available across different hardware vendors. Testing was conducted on 16 CNN architectures with the CIFAR-10 dataset on RTX 3080 and RTX 3090 GPUs.

## Key Results
- Energy savings of up to 26.4% achieved through GPU power capping
- Minimal impact on model accuracy and training time observed
- EDP-based optimization successfully selects optimal power profiles
- Aggressive power capping (below 30-40%) can cause GPU instability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FROST reduces GPU energy consumption without degrading model accuracy by profiling power limits and selecting an optimal configuration.
- Mechanism: The framework runs short 30-second profiling trials across eight power limits (30%-100%) to collect energy and timing data. It fits an Energy-Delay Product (EDP)-based function to the profiles and uses optimization to select the power cap that minimizes energy consumption for a given model, dataset, and hardware.
- Core assumption: Energy consumption scales linearly with training/inference time and GPU utilization, so short profiling runs reliably predict long-run behavior.
- Evidence anchors:
  - [abstract] states energy savings of up to 26.4% with minimal accuracy impact.
  - [section] describes profiling over 30-second intervals and fitting a logistic-exponential function for EDP minimization.
  - [corpus] shows related GPU power capping studies; however, no direct comparison evidence is available here.
- Break condition: If GPU workload shifts from compute-bound to memory-bound at low power limits, the optimization function may select a limit that causes instability or unexpected slowdowns.

### Mechanism 2
- Claim: FROST integrates seamlessly into O-RAN because it uses only software-based power measurement APIs available across different hardware vendors.
- Mechanism: It relies on NVML for NVIDIA GPUs and RAPL for CPUs/DRAM, which are standard APIs across deployments. Power capping is enforced through these APIs, avoiding the need for hardware modifications or complex DVFS tuning.
- Core assumption: Standardized APIs provide accurate and consistent measurements across heterogeneous hardware in O-RAN environments.
- Evidence anchors:
  - [abstract] mentions minimal overhead and seamless integration into O-RAN ML workflows.
  - [section] explains the choice of power capping over DVFS due to vendor interoperability and cloud-native deployment requirements.
  - [corpus] cites other GPU energy optimization studies but lacks O-RAN-specific API compatibility evidence.
- Break condition: If newer GPU models change their power capping API or disable MSR access, the profiling framework may fail to measure or control power correctly.

### Mechanism 3
- Claim: The EDP-based decision function adapts to different QoS requirements by tuning the exponent parameter.
- Mechanism: The fitted function F(x) = aebx−c + dσ(ex − f) + g combines exponential and logistic terms. Adjusting the exponent in EDP (e.g., ED1P vs. ED3P) shifts the trade-off between energy savings and delay tolerance.
- Core assumption: A single fitted model can generalize across different model architectures and training configurations when re-tuned for each case.
- Evidence anchors:
  - [abstract] claims no accuracy loss while optimizing energy.
  - [section] shows that higher exponents prioritize delay reduction, while lower exponents prioritize energy, with EDP yielding the best energy savings.
  - [corpus] lacks direct evidence of cross-architecture generalization but references EDP as a standard metric in energy-aware software design.
- Break condition: If the error in fitting F(x) exceeds 5%, the model is rejected, and the system falls back to default power limits.

## Foundational Learning

- Concept: Power profiling and measurement via hardware APIs
  - Why needed here: FROST depends on real-time power readings to build energy profiles and optimize hardware settings without intrusive overhead.
  - Quick check question: What APIs does FROST use to measure GPU, CPU, and DRAM power consumption, and why are they chosen over hardware meters?

- Concept: Energy-Delay Product (EDP) as a multi-objective optimization metric
  - Why needed here: EDP balances energy consumption against execution time, enabling tunable trade-offs aligned with O-RAN QoS policies.
  - Quick check question: How does changing the exponent in EDP shift the optimization outcome between energy savings and delay?

- Concept: O-RAN architecture and ML lifecycle integration
  - Why needed here: FROST is designed to operate within O-RAN's non-RT-RIC and near-RT-RIC components, so understanding the deployment model is critical.
  - Quick check question: At which stages of the O-RAN ML lifecycle does FROST intervene, and how does it receive policy inputs?

## Architecture Onboarding

- Component map:
  - Profiler microservice -> Power measurement layer (NVML/RAPL) -> Decision engine -> O-RAN integration interface (A1 policy management)
- Critical path:
  1. Receive new ML model + dataset
  2. Execute profiling trials
  3. Fit optimization function
  4. Select power cap
  5. Apply cap via hardware API
- Design tradeoffs:
  - Short profiling vs. accuracy: 30s trials are fast but may miss edge cases
  - Aggressive capping vs. stability: Lower limits save energy but risk instability
  - Vendor-specific APIs vs. generality: Relying on NVML/RAPL limits cross-platform portability
- Failure signatures:
  - Profiling completes but optimal cap causes training hangs → likely GPU instability at low power
  - No measurable energy reduction → possible API incompatibility or model already optimal
  - Profiling overhead spikes → likely inefficient API polling or system contention
- First 3 experiments:
  1. Profile ResNet18 on CIFAR-10 with default 100% power cap, record baseline energy/time
  2. Run FROST profiler, select optimal cap, retrain and compare energy/time to baseline
  3. Adjust QoS policy exponent from ED2P to ED1P and observe shift in optimal cap and performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FROST's performance scale with larger, more complex neural networks (e.g., large language models) and what is the maximum energy reduction achievable without accuracy loss?
- Basis in paper: [inferred] The paper tested 16 CNN architectures and observed up to 26.4% energy savings, but noted that the more powerful RTX 3090 was suboptimally utilized with the evaluated models, suggesting larger models may yield greater benefits.
- Why unresolved: The study was limited to CNN architectures on CIFAR-10, leaving uncertainty about FROST's effectiveness on larger models or different domains.
- What evidence would resolve it: Testing FROST on diverse large-scale models (e.g., transformer-based networks) across multiple datasets and hardware configurations.

### Open Question 2
- Question: What are the long-term reliability implications of sustained aggressive power capping on GPU hardware, particularly regarding thermal cycling and lifespan?
- Basis in paper: [explicit] The authors noted that extreme power capping (below 30-40%) can cause instability and voltage fluctuations, but did not investigate long-term hardware degradation.
- Why unresolved: The experiments were short-term, focusing on immediate energy savings rather than cumulative hardware effects over extended deployment periods.
- What evidence would resolve it: Longitudinal studies tracking GPU performance and failure rates under different power capping regimes over months or years.

### Open Question 3
- Question: How can FROST be extended to dynamically adjust power profiles in real-time based on network load fluctuations and varying QoS requirements in O-RAN deployments?
- Basis in paper: [inferred] The framework currently uses pre-determined power profiles based on initial profiling, but O-RAN environments require dynamic adaptation to changing conditions.
- Why unresolved: The current implementation assumes static power limits, not addressing the need for continuous, autonomous optimization in response to real-time network demands.
- What evidence would resolve it: Implementation of a feedback control system that monitors network metrics and automatically adjusts power limits while maintaining QoS constraints.

## Limitations
- Energy savings results are based on a narrow set of CNN models and CIFAR-10 dataset, limiting generalizability
- Stability testing at extreme power limits is not reported, leaving safe operational bounds unclear
- Exact implementation details of the EDP optimization function are omitted, complicating direct replication

## Confidence
- Energy savings claim (up to 26.4%): Medium confidence — supported by controlled experiments, but limited to narrow model/dataset scope
- Seamless O-RAN integration: Medium confidence — API choices are standard, but real-world O-RAN compatibility not demonstrated
- EDP optimization efficacy: High confidence — EDP is a well-established metric, and function fitting approach is methodologically sound

## Next Checks
1. Test FROST's optimal power profile selection across a broader set of CNN models and datasets (e.g., ImageNet) to assess generalizability.
2. Run stress tests at power limits below 30% to determine the minimum stable threshold and measure potential instability effects.
3. Verify that the NVML/RAPL-based power measurement remains accurate and consistent across different GPU and CPU architectures, especially under heavy O-RAN workloads.