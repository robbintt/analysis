---
ver: rpa2
title: Unsupervised anomalies detection in IIoT edge devices networks using federated
  learning
arxiv_id: '2308.12175'
source_url: https://arxiv.org/abs/2308.12175
tags:
- data
- devices
- learning
- server
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of unsupervised anomaly detection
  in IoT/IIoT networks under strict data privacy constraints. To address the inability
  to share raw data centrally due to privacy and regulatory concerns, the authors
  adopt federated learning (FL) as a privacy-preserving distributed training paradigm.
---

# Unsupervised anomalies detection in IIoT edge devices networks using federated learning

## Quick Facts
- arXiv ID: 2308.12175
- Source URL: https://arxiv.org/abs/2308.12175
- Reference count: 34
- Primary result: Federated deep autoencoder achieves ≈99.8% accuracy in unsupervised anomaly detection while preserving privacy

## Executive Summary
This paper tackles the challenge of unsupervised anomaly detection in IoT/IIoT networks under strict data privacy constraints. The authors adopt federated learning (FL) as a privacy-preserving distributed training paradigm, implementing a FedAvg-based federated deep autoencoder trained on the EdgeIIoTset dataset. The method uses unlabeled network traffic from heterogeneous edge devices, performing local training on-device and aggregating model updates at a central server without transmitting raw data. Experimental results show that federated training achieves nearly identical accuracy to centralized learning while significantly improving privacy and reducing false positive rates.

## Method Summary
The proposed approach uses federated learning with FedAvg to train an unsupervised deep autoencoder for anomaly detection in IoT/IIoT networks. Edge devices perform local training on their network traffic data without sharing raw data, only transmitting model updates to a central server. The autoencoder learns to reconstruct normal network flows, and anomalies are detected based on reconstruction error thresholds. The method addresses data privacy concerns by keeping data localized while achieving comparable performance to centralized training approaches.

## Key Results
- Federated training achieves nearly identical accuracy (≈99.8%) to centralized learning on the EdgeIIoTset dataset
- Privacy is preserved by avoiding raw data transmission between edge devices and central server
- False positive rates are significantly reduced compared to traditional centralized approaches
- The unsupervised autoencoder effectively learns normal traffic patterns for anomaly detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Federated deep autoencoder achieves privacy-preserving anomaly detection with accuracy comparable to centralized training.
- Mechanism: Local model training on edge devices preserves data privacy by avoiding raw data transmission; model updates are aggregated at the server using FedAvg.
- Core assumption: Local data distributions are sufficiently representative of global patterns for effective model aggregation.
- Evidence anchors:
  - [abstract] states that federated training achieves nearly identical accuracy (≈99.8%) to centralized learning while preserving privacy.
  - [section III.A] explains that FedAvg allows devices to perform local training and send only model updates to the server.
- Break condition: If local data distributions are too heterogeneous or biased, aggregated model may not generalize well.

### Mechanism 2
- Claim: Unsupervised deep autoencoder can learn to reconstruct normal network flows, enabling anomaly detection via reconstruction error thresholding.
- Mechanism: Autoencoder is trained on normal traffic to minimize reconstruction error; anomalies produce higher reconstruction errors and are flagged.
- Core assumption: Normal network traffic has consistent patterns that the autoencoder can learn to reconstruct accurately.
- Evidence anchors:
  - [section III.C] describes how the autoencoder is trained to minimize MSE between input and reconstructed output.
  - [section IV.E] explains that a threshold based on mean and standard deviation of reconstruction errors is used for classification.
- Break condition: If the normal traffic is too diverse or if attack patterns are similar to normal patterns, reconstruction-based detection may fail.

### Mechanism 3
- Claim: Feature representation learning on the server mitigates inconsistencies from asynchronous updates in federated training.
- Mechanism: Relevance scores (α) are computed to weight aggregated model updates, compensating for delayed or missing updates from slower devices.
- Core assumption: Relevance scores can effectively quantify the importance of each device's contribution despite timing differences.
- Evidence anchors:
  - [section III.G] describes using relevance scores from NLP to weight server-side model aggregation.
  - [section III.D] explains that devices may send updates at different times, causing model inconsistency.
- Break condition: If relevance scoring is poorly calibrated, it may introduce bias or instability in model updates.

## Foundational Learning

- Concept: Federated Learning (FL)
  - Why needed here: FL allows training on distributed edge device data without centralizing raw data, preserving privacy.
  - Quick check question: What is the main advantage of FedAvg over centralized training in this context?

- Concept: Autoencoder (unsupervised learning)
  - Why needed here: Autoencoders can learn patterns from unlabeled data, making them suitable for anomaly detection in unlabeled network traffic.
  - Quick check question: How does the reconstruction error threshold differentiate normal from anomalous traffic?

- Concept: Data heterogeneity and non-IID distributions
  - Why needed here: Edge devices may have different data distributions, affecting model convergence in federated learning.
  - Quick check question: Why is non-IID data a challenge for federated averaging?

## Architecture Onboarding

- Component map: Edge devices (clients) -> Central server -> Communication channel -> Edge devices (clients)

- Critical path:
  1. Server sends initial model to selected clients.
  2. Clients train locally on their data and compute model updates.
  3. Clients send updates to server.
  4. Server aggregates updates using FedAvg with relevance weighting.
  5. Server sends updated global model back to clients.
  6. Repeat until convergence.

- Design tradeoffs:
  - Privacy vs. model accuracy: FL preserves privacy but may slightly reduce accuracy compared to centralized training.
  - Communication efficiency vs. fairness: Aggregating updates with relevance scores improves fairness but increases computation on the server.

- Failure signatures:
  - High false positive rate: Threshold may be too low; consider increasing threshold or adjusting relevance weighting.
  - Poor convergence: Check for highly heterogeneous local data distributions or insufficient local training epochs.
  - Communication bottlenecks: Reduce model update size or use sparsification techniques.

- First 3 experiments:
  1. Centralized autoencoder training on the full dataset to establish baseline accuracy.
  2. Federated autoencoder training with FedAvg on simulated non-IID data to measure privacy vs. accuracy tradeoff.
  3. Test federated training with relevance weighting to assess impact on fairness and convergence.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed FairFedAvg algorithm perform in terms of accuracy, precision, recall, and false positive rate compared to vanilla FedAvg and centralized approaches on modern IoT/IIoT datasets?
- Basis in paper: [explicit] The authors explicitly state they designed a FairFedAvg algorithm and mention it as future work to evaluate its performance, but the evaluation was not completed due to time constraints.
- Why unresolved: The algorithm was not implemented and evaluated within the scope of this paper.
- What evidence would resolve it: Implementation and testing of FairFedAvg on the same EdgeIIoTset dataset, comparing its metrics (accuracy, precision, recall, FPR) against both vanilla FedAvg and centralized baselines.

### Open Question 2
- Question: How does the non-IID data distribution across heterogeneous edge devices affect the convergence speed and model accuracy in federated anomaly detection for IoT/IIoT networks?
- Basis in paper: [explicit] The authors mention using a non-IID data distribution function (Latent Dirichlet Allocation) to simulate real-world scenarios and note that data heterogeneity is a challenge in federated learning.
- Why unresolved: While the authors used non-IID data, they did not analyze or report on how this specifically impacts convergence speed or model accuracy in their experiments.
- What evidence would resolve it: Systematic experiments varying the degree of data heterogeneity (alpha values in LDA) and measuring convergence rounds and final accuracy across different non-IID settings.

### Open Question 3
- Question: What is the impact of asynchronous federated learning (compared to synchronous FedAvg) on model consistency and performance in unsupervised anomaly detection for IoT/IIoT networks?
- Basis in paper: [inferred] The authors discuss the issue of straggler devices in synchronous FL and propose a feature representation learning approach on the server to address model inconsistency, implying interest in asynchronous methods.
- Why unresolved: The paper does not implement or evaluate an asynchronous FL approach, only discussing potential improvements.
- What evidence would resolve it: Implementation and evaluation of an asynchronous FL algorithm (e.g., FedAsync) on the EdgeIIoTset dataset, comparing its accuracy, precision, recall, and convergence behavior against the synchronous FedAvg baseline.

## Limitations
- Evaluation relies on simulated non-IID data distributions rather than real heterogeneous edge device data, which may not fully capture practical challenges in federated IoT/IIoT deployments.
- While federated training achieves nearly identical accuracy to centralized learning (≈99.8%), the computational overhead and communication costs of model aggregation are not quantified.
- The proposed Fair FedAvg algorithm is mentioned but not fully implemented, leaving the impact of fairness weighting on model performance unverified.

## Confidence
- Mechanism 1 (privacy-preserving federated training): **High** - Well-supported by experimental results showing accuracy parity with centralized learning.
- Mechanism 2 (unsupervised autoencoder for anomaly detection): **Medium** - Relies on assumptions about normal traffic patterns that may not hold in all IoT/IIoT scenarios.
- Mechanism 3 (relevance weighting for fairness): **Low** - Proposed but not fully implemented; theoretical benefit remains unverified.

## Next Checks
1. Evaluate federated training on real-world heterogeneous edge device data distributions to validate simulation assumptions.
2. Measure and report communication costs and computational overhead of federated model aggregation versus centralized training.
3. Implement and test the Fair FedAvg algorithm with feature representation learning on the server to assess its impact on fairness and convergence.