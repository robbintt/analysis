---
ver: rpa2
title: Conceptual Engineering Using Large Language Models
arxiv_id: '2312.03749'
source_url: https://arxiv.org/abs/2312.03749
tags:
- conceptual
- engineering
- classification
- procedures
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for evaluating conceptual engineering
  definitions using large language models and knowledge graph data. The approach implements
  classification procedures as zero-shot chain-of-thought classifiers that generate
  rationales for categorizing entities.
---

# Conceptual Engineering Using Large Language Models

## Quick Facts
- arXiv ID: 2312.03749
- Source URL: https://arxiv.org/abs/2312.03749
- Authors: 
- Reference count: 33
- This paper introduces a method for evaluating conceptual engineering definitions using large language models and knowledge graph data.

## Executive Summary
This paper presents a novel method for evaluating conceptual engineering definitions using large language models and knowledge graph data. The approach implements classification procedures as zero-shot chain-of-thought classifiers that generate rationales for categorizing entities. Applied to definitions of PLANET and WOMAN from different sources, the method achieved high performance with Cohen's kappa scores of 0.92-0.96 and F1 scores of 0.96-0.98. The generated rationales helped identify issues in both definitions and entity descriptions, demonstrating how empirical, data-driven evaluation can support conceptual engineering projects at scale.

## Method Summary
The method uses zero-shot chain-of-thought prompting with GPT-4 to classify entities from Wikidata knowledge graphs according to conceptual definitions. For each concept, 50 positive and 50 negative entities are sampled and their Wikipedia summaries are retrieved as descriptions. The LLM generates rationales for classifying each entity as "in" or "out" of the concept, then produces a final classification. Performance is evaluated using confusion matrices to calculate Cohen's kappa and F1 scores, with false positives and negatives reviewed to identify issues in either the definitions or the data.

## Key Results
- Achieved Cohen's kappa scores of 0.92-0.96 and F1 scores of 0.96-0.98
- Successfully identified issues in both definitions and entity descriptions through error analysis
- Demonstrated scalability of conceptual engineering evaluation beyond traditional armchair methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The zero-shot chain-of-thought approach enables the LLM to generate structured rationales that map directly to classification decisions, making the system both interpretable and actionable.
- Mechanism: By prompting the LLM to first generate a reasoning chain (rationale) and then a final answer, the model creates an explicit decision pathway that can be inspected and validated against ground truth.
- Core assumption: The LLM's reasoning capabilities are sufficiently aligned with human conceptual understanding to produce meaningful rationales.
- Evidence anchors:
  - [abstract] "rationales for categorizing entities"
  - [section] "Rationales generated by the classification procedures were sound, and answers were faithful to their rationales"
- Break condition: If rationales become disconnected from final answers or fail to capture the conceptual distinctions required by the definitions.

### Mechanism 2
- Claim: The classification procedures can identify issues in both definitions and entity descriptions through systematic error analysis.
- Mechanism: False positives and false negatives are reviewed to determine whether errors stem from problematic definitions or incomplete entity descriptions, creating a feedback loop for refinement.
- Core assumption: The error patterns will reveal systematic issues rather than random noise, allowing targeted improvements.
- Evidence anchors:
  - [abstract] "rationales for their classifications, can contribute to the identification of issues in either the definitions or the data"
  - [section] "False positives/negatives are then reviewed to determine if a given error arises from the concept's definition or the entity's description"
- Break condition: If error patterns are too random or if the system cannot distinguish between definition problems and data quality issues.

### Mechanism 3
- Claim: The method scales conceptual engineering by enabling evaluation of definitions against large numbers of examples beyond what's feasible with traditional armchair methods.
- Mechanism: Automated classification procedures can process thousands of entities from knowledge graphs, providing statistical performance metrics and identifying edge cases that manual review would miss.
- Core assumption: Knowledge graph data is sufficiently representative of the concept's extension to enable meaningful evaluation.
- Evidence anchors:
  - [abstract] "at a scale that 'armchair-based conceptual engineering' cannot"
  - [section] "Applying classification procedures to large numbers of positive and negative examples"
- Break condition: If knowledge graph coverage is too sparse or biased to provide meaningful evaluation data.

## Foundational Learning

- Concept: Zero-shot classification
  - Why needed here: The method uses zero-shot prompting to classify entities without requiring labeled training data, which is essential for evaluating arbitrary conceptual definitions
  - Quick check question: What distinguishes zero-shot from few-shot prompting in this context?

- Concept: Chain-of-thought reasoning
  - Why needed here: The approach relies on generating explicit reasoning chains to produce both rationales and final classifications, enabling error analysis and refinement
  - Quick check question: How does chain-of-thought prompting improve classification accuracy compared to direct prompting?

- Concept: Knowledge graph structure
  - Why needed here: The method uses Wikidata's entity-instance relationships and descriptions as evaluation data, requiring understanding of graph-based knowledge representation
  - Quick check question: What types of knowledge graph relationships are most relevant for this classification task?

## Architecture Onboarding

- Component map: Prompt generation -> LLM classification -> Entity sampling -> Performance calculation -> Error analysis -> Definition refinement
- Critical path: Prompt generation → LLM classification → Entity sampling → Performance calculation → Error analysis → Definition refinement
- Design tradeoffs:
  - Closed API vs. open model: Trade off between convenience and transparency/reproducibility
  - Temperature setting: Lower values ensure consistent classifications but may reduce creative reasoning
  - Entity description length: Longer descriptions provide more context but increase computational cost
- Failure signatures:
  - High false positive rates with specific entity types (indicates definition issues)
  - Inconsistent classifications across similar entities (indicates prompt or model issues)
  - Rationales that don't align with final answers (indicates reasoning chain problems)
- First 3 experiments:
  1. Test classification on a small, manually curated set of entities to validate prompt effectiveness
  2. Run classification on entities with known problematic descriptions to test error detection capability
  3. Compare performance across different LLM temperature settings to find optimal balance between consistency and reasoning quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can conceptual engineering projects incorporate empirical, data-driven methods using large language models?
- Basis in paper: [explicit] The paper discusses using classification procedures implemented with LLMs to evaluate concept definitions using knowledge graph data
- Why unresolved: While the paper demonstrates this approach with two case studies, it doesn't establish a general framework for how other conceptual engineering projects could adopt similar methods
- What evidence would resolve it: Case studies of different conceptual engineering projects successfully implementing LLM-based evaluation methods, along with documented best practices

### Open Question 2
- Question: What are the success conditions for conceptual engineering when incorporating knowledge graph refinement?
- Basis in paper: [explicit] The paper suggests this provides "a new perspective on success conditions for CE" and mentions "ameliorative refinement of knowledge graphs as a topic for future research"
- Why unresolved: The paper only briefly touches on this new perspective without developing a comprehensive theory of how success conditions should be redefined
- What evidence would resolve it: A theoretical framework connecting conceptual engineering success to knowledge graph alignment metrics and practical applications

### Open Question 3
- Question: How can we ensure explanation faithfulness in LLM-based classification procedures for conceptual engineering?
- Basis in paper: [explicit] The paper notes this as a limitation, citing Turpin et al. (2023) on "unfaithful explanations in chain-of-thought prompting"
- Why unresolved: The paper acknowledges this concern but doesn't propose solutions or evaluate faithfulness in their specific implementation
- What evidence would resolve it: Comparative studies of different prompting strategies and evaluation methods for ensuring faithful explanations in LLM-based classification

## Limitations

- The method's effectiveness for concepts with fuzzy boundaries or requiring cultural context beyond Wikipedia descriptions remains uncertain
- Results depend heavily on Wikidata's coverage and quality, with unclear transferability to sparser knowledge graphs
- The approach relies on GPT-4's reasoning capabilities and may not transfer to other models or future versions

## Confidence

- Definition scope and transferability: Medium confidence
- Knowledge graph dependency: Medium confidence
- LLM model dependency: Low confidence

## Next Checks

1. Apply the method to 3-5 additional concepts from different domains (scientific, social, abstract) to test generalizability beyond PLANET and WOMAN
2. Repeat the classification procedure using alternative knowledge graphs or by comparing results with different subsets of Wikidata to assess dependency on specific data sources
3. Test the classification performance using different LLM models (e.g., Claude, LLaMA) and varying temperature settings to quantify the impact of model choice on results