---
ver: rpa2
title: Data-Driven Estimation of Heterogeneous Treatment Effects
arxiv_id: '2301.06615'
source_url: https://arxiv.org/abs/2301.06615
tags:
- treatment
- causal
- estimation
- ects
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper surveys machine learning methods for estimating heterogeneous
  treatment effects (HTE) - how a treatment affects different individuals differently.
  It categorizes methods into counterfactual prediction (predicting outcomes under
  treatment and control, then taking the difference) and effect estimation (directly
  estimating the treatment effect).
---

# Data-Driven Estimation of Heterogeneous Treatment Effects

## Quick Facts
- arXiv ID: 2301.06615
- Source URL: https://arxiv.org/abs/2301.06615
- Reference count: 40
- Primary result: No single HTE estimation method dominates; performance depends on underlying causal structure and use of causal structure learning

## Executive Summary
This paper surveys machine learning methods for estimating heterogeneous treatment effects (HTE) - how a treatment affects different individuals differently. It categorizes methods into counterfactual prediction (predicting outcomes under treatment and control, then taking the difference) and effect estimation (directly estimating the treatment effect). The paper also introduces structural causal models (SCMs) that can help identify which variables should be included in HTE estimation to avoid bias. Through experiments on synthetic, semi-synthetic, and real-world datasets, the authors find that performance varies greatly depending on the underlying causal structure, with causal trees and forests tending to perform well overall.

## Method Summary
The paper conducts empirical evaluation of HTE estimation methods using synthetic, semi-synthetic, and real-world datasets. The synthetic datasets are generated using random structural causal models with varying parameters including number of variables, edge probability, noise variance, confounding, mediation, and heterogeneity-inducing parents. HTE estimators are trained using either counterfactual prediction approaches (predicting outcomes under treatment and control) or direct effect estimation methods (estimating treatment effect directly). Evaluation is performed using root mean squared error (RMSE) of treatment effect estimates, accuracy of decisions, and heuristic metrics like IPW, τ-risk, plugin validation, and CFCV when ground truth is unavailable.

## Key Results
- No single HTE estimation method dominates across all scenarios
- Causal structure learning can help select relevant variables and improve estimation accuracy
- Heuristic evaluation metrics (IPW, τ-risk, plugin validation, CFCV) do not always correlate well with true performance
- Performance is highly dependent on the underlying causal structure of the data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causal structure learning can improve heterogeneous treatment effect (HTE) estimation by identifying valid adjustment variables.
- Mechanism: By learning the underlying causal graph structure from data, methods can identify which variables should be adjusted for to avoid bias from confounders, mediators, or descendants of treatment. This allows focusing on relevant features rather than all available features.
- Core assumption: The learned causal structure accurately represents the true underlying causal relationships, and valid adjustment sets can be identified from this structure.
- Evidence anchors:
  - When the SCM underlying the dataset is known, its graph supports the use of graphical criteria for variable selection for unbiased causal effect estimation, known as adjustment set selection
  - Although causal structure learning can address some problems of data-driven HTE estimation, there are some drawbacks. First, learning the full structure can be computationally expensive for high-dimensional datasets
- Break Condition: If the learned causal structure is inaccurate or if the adjustment set selection misses important heterogeneity-inducing variables, HTE estimation will be biased.

### Mechanism 2
- Claim: Different HTE estimation methods perform differently depending on the underlying causal structure of the data.
- Mechanism: The performance of counterfactual prediction methods, effect estimation methods, and methods using structural causal models varies based on whether the data contains confounders, mediators, or other causal relationships. Some methods handle certain structures better than others.
- Core assumption: The performance differences are due to the underlying causal structure rather than random variation.
- Evidence anchors:
  - Our empirical evaluation under various underlying structural model mechanisms shows the advantages and deficiencies of existing estimators
  - We first investigate how HTE estimation methods perform under different parameter settings (and thus SCMs)
- Break Condition: If the synthetic datasets don't adequately represent real-world causal structures, the observed performance differences may not generalize.

### Mechanism 3
- Claim: Heuristic evaluation metrics for HTE estimators (IPW, τ-risk, plugin validation, CFCV) do not always correlate well with true performance.
- Mechanism: These metrics rely on estimating propensity scores or outcomes, which can be inaccurate. When the underlying causal structure is complex or contains mediators/descendants of treatment, these estimates become less reliable, reducing the correlation with true performance.
- Core assumption: The heuristic metrics are being used correctly and the estimators for propensity scores and outcomes are reasonably accurate.
- Evidence anchors:
  - Since ground truth causal effects are generally not available in real-world datasets, several heuristic HTE evaluation metrics have been developed
  - Table 6 shows the correlation of each heuristic metric ranking to the ground truth ranking over the synthetic datasets and the semi-synthetic (IHDP) datasets
- Break Condition: If the estimators used within the heuristic metrics are highly accurate, the correlation with true performance may be stronger than observed.

## Foundational Learning

- Concept: Structural Causal Models (SCMs)
  - Why needed here: Understanding SCMs is essential for grasping how causal relationships between variables affect HTE estimation and why certain variables should or shouldn't be included in estimation
  - Quick check question: What is the difference between endogenous and exogenous variables in an SCM?

- Concept: D-separation and backdoor criterion
  - Why needed here: These graphical criteria determine which variables should be adjusted for to estimate unbiased causal effects, which is crucial for understanding when HTE estimators will be biased
  - Quick check question: How does the backdoor criterion help identify valid adjustment sets for causal effect estimation?

- Concept: Counterfactual prediction vs effect estimation approaches
  - Why needed here: The paper categorizes HTE estimation methods into these two broad categories, and understanding their differences is key to grasping the survey's organization and findings
  - Quick check question: What is the fundamental difference between counterfactual prediction methods and effect estimation methods?

## Architecture Onboarding

- Component map: Data preprocessing -> HTE estimation method -> Evaluation -> Optional: Causal structure learning
- Critical path:
  1. Data preparation and feature selection
  2. Choice of HTE estimation method
  3. Model training and prediction
  4. Evaluation using appropriate metrics
  5. Interpretation of results in context of underlying causal structure

- Design tradeoffs:
  - Using all features vs. using adjustment sets identified by causal structure learning
  - Counterfactual prediction methods (potentially more interpretable) vs. effect estimation methods (potentially more direct)
  - Computational cost of causal structure learning vs. potential accuracy gains
  - Use of heuristic evaluation metrics vs. waiting for ground truth availability

- Failure signatures:
  - Poor performance correlated with presence of mediators in data
  - Heuristic evaluation metrics showing low correlation with ground truth performance
  - Methods performing well on synthetic data but poorly on real-world data with complex causal structures
  - Overfitting when using too many features without proper adjustment

- First 3 experiments:
  1. Implement a simple T-learner on a synthetic dataset with known ground truth, varying the presence of confounders, mediators, and HTE-inducing parents
  2. Apply causal structure learning (e.g., GFCI) to identify adjustment sets, then compare HTE estimation performance using all features vs. only adjustment set features
  3. Evaluate the correlation between heuristic metrics (IPW, τ-risk, plugin validation, CFCV) and ground truth performance across different synthetic datasets with varying causal structures

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop evaluation metrics that reliably correlate with true performance of heterogeneous treatment effect estimators in real-world scenarios where ground truth effects are unknown?
- Basis in paper: The paper discusses multiple heuristic evaluation metrics (IPW, τ-risk, plugin validation, CFCV) and finds they have low correlation with true performance, especially when the underlying causal structure is unknown or contains invalid variables.
- Why unresolved: Current heuristic metrics rely on assumptions about the causal structure and use of all features, but the paper shows these assumptions often don't hold in practice, leading to poor correlation with true performance.
- What evidence would resolve it: A systematic evaluation of new metrics on diverse real-world datasets with known ground truth (e.g., from randomized controlled trials) comparing their correlation with true performance across different causal structures and data characteristics.

### Open Question 2
- Question: What methods can effectively incorporate causal structure learning into heterogeneous treatment effect estimation to improve accuracy while managing computational complexity?
- Basis in paper: The paper discusses that causal structure learning can help select relevant variables for adjustment, but notes drawbacks including computational expense and inability to learn full causal models with uncertain edges.
- Why unresolved: While structure learning can identify invalid variables to exclude, it remains computationally expensive for high-dimensional data and often can't learn the full causal structure, leaving ambiguity about cause-effect relationships.
- What evidence would resolve it: Comparative studies of HTE estimators using different structure learning algorithms (constraint-based, score-based, continuous optimization) on high-dimensional datasets, measuring both estimation accuracy and computational efficiency.

### Open Question 3
- Question: How can heterogeneous treatment effect estimators be adapted to handle scenarios with latent heterogeneity and unknown heterogeneity-inducing variables?
- Basis in paper: The paper discusses that detecting latent heterogeneity is challenging when the set of heterogeneity-inducing variables is unknown, requiring exponential search over all feature combinations.
- Why unresolved: Current data-driven methods assume strong ignorability and use all features, but the paper shows this can lead to incorrect estimation when important heterogeneity-inducing variables are unknown or when mediators are present.
- What evidence would resolve it: Development and evaluation of methods that can automatically detect and handle latent heterogeneity without prior knowledge of which variables induce heterogeneity, tested on datasets with known but unobserved heterogeneity-inducing variables.

## Limitations
- The synthetic datasets used for experiments may not fully capture the complexity of real-world causal structures
- Performance differences across methods are highly dependent on the specific synthetic data generation process
- The computational expense of causal structure learning remains a significant limitation for high-dimensional data

## Confidence
- Mechanism 1 (causal structure learning improving HTE): Medium confidence
- Mechanism 2 (method performance depends on causal structure): High confidence
- Mechanism 3 (heuristic metrics correlation issues): Medium confidence

## Next Checks
1. Test the correlation between heuristic metrics and true performance on a larger set of real-world datasets with known or well-estimated treatment effects
2. Evaluate the computational efficiency and accuracy trade-offs of causal structure learning methods on high-dimensional real-world datasets
3. Investigate whether ensemble methods that combine multiple HTE estimators can achieve more consistent performance across different causal structures