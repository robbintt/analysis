---
ver: rpa2
title: Online Learning and Planning in Cognitive Hierarchies
arxiv_id: '2310.12386'
source_url: https://arxiv.org/abs/2310.12386
tags:
- cognitive
- hierarchy
- node
- planning
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper extends a formal framework for cognitive robotics by\
  \ incorporating online learning and planning into a meta-theoretic model of cognitive\
  \ hierarchies. The key innovation is a multi-stage process model with five passes\u2014\
  prediction, correction, transition learning, utility updating, and action selection\u2014\
  that allows symbolic planning and reinforcement learning to operate cohesively across\
  \ abstraction levels."
---

# Online Learning and Planning in Cognitive Hierarchies

## Quick Facts
- arXiv ID: 2310.12386
- Source URL: https://arxiv.org/abs/2310.12386
- Reference count: 4
- Key outcome: Extends cognitive robotics framework with online learning and planning through a five-pass process model enabling symbolic planning and reinforcement learning integration across abstraction levels.

## Executive Summary
This paper presents a formal framework that integrates online learning and planning within cognitive hierarchies for robotic systems. The framework employs a multi-stage process with five passes—prediction, correction, transition learning, utility updating, and action selection—that allows symbolic planning and reinforcement learning to operate cohesively across abstraction levels. This enables learned action costs to be passed upward to guide high-level planners toward globally optimal policies while accounting for low-level stochasticity. The approach is demonstrated through a robot navigation example where the system decomposes the problem, learns motion models, and selects optimal paths balancing distance and doorway traversal.

## Method Summary
The method implements a cognitive hierarchy with N0 (external world), N1 (Q-learning motion model), and N2 (ASP planner) nodes connected in a directed acyclic graph. The five-pass process model operates as follows: PredictionUpdate propagates state predictions down the hierarchy; CorrectionUpdate incorporates sensor observations; TransitionFuncUpdate learns transition models using temporal difference learning; UtilityUpdate propagates costs upward to guide planning; and ActionUpdate selects actions down the hierarchy. The framework handles problem decomposition by representing the robot navigation task as separate learning and planning components, where Q-learning at the low level learns motion policies and costs that inform the high-level ASP planner's path selection.

## Key Results
- Five-pass process model successfully integrates symbolic planning with reinforcement learning across hierarchy levels
- Utility propagation enables high-level planners to optimize for global policies considering low-level stochastic dynamics
- Theoretical guarantees include recursive optimality and proven well-definedness of the process model

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-stage hierarchical process enables coherent integration of symbolic planning and reinforcement learning across abstraction levels.
- Mechanism: The five-pass process model (prediction, correction, transition learning, utility updating, action selection) allows information to flow both up and down the cognitive hierarchy, ensuring that low-level stochastic dynamics inform high-level planning while maintaining coherent global behavior.
- Core assumption: Each node can operate with its own representation (symbolic for high-level, sub-symbolic for low-level) while maintaining interface compatibility through the formal framework.
- Evidence anchors:
  - [abstract]: "The framework enables passing learned action costs upward to guide high-level planners toward globally optimal policies, accounting for low-level stochasticity."
  - [section]: "The example established how a reinforcement learner could be used to learn both a transition model and action policy for a robot moving within a room, and how this could be combined with a symbolic planner for navigating between rooms."
  - [corpus]: Weak evidence - corpus neighbors focus on different integration approaches without directly addressing this specific hierarchical learning-planning integration.
- Break condition: The formal interface functions (ϕ, ϱ, σ, ψ) fail to preserve the necessary information between nodes, or the partial ordering constraints of the DAG structure are violated.

### Mechanism 2
- Claim: Problem decomposition through cognitive hierarchies reduces computational complexity while preserving global optimality guarantees.
- Mechanism: Decomposing a large state space (M × N) into smaller hierarchical components (M + N) reduces the search space complexity. The utility update mechanism ensures that context from higher levels informs lower-level learning, maintaining recursive optimality.
- Core assumption: The transition functions and policies learned at lower levels can be composed to achieve optimal behavior at higher levels when utilities are properly propagated.
- Evidence anchors:
  - [section]: "The decomposition into rooms reduces complexity from order n² = 450² to 5×90²+5². Additionally, the similarity of the five rooms allows transfer learning of the transition and policy functions."
  - [section]: "Importantly, this behaviour is dependent on the stochasticity of the motion model and when the amount of slippage increases, an optimal path minimises the number of doorways as an increasing number of attempts may be necessary to move between rooms."
  - [corpus]: Weak evidence - corpus papers discuss decomposition but not with the specific recursive optimality guarantees claimed here.
- Break condition: The learned transition models become too inaccurate to support meaningful utility propagation, or the abstraction levels become too coarse to capture necessary state distinctions.

### Mechanism 3
- Claim: The well-defined process model ensures deterministic behavior and correct information flow through the hierarchy.
- Mechanism: The formal process model Update(X) is proven well-defined through structural inspection of each pass, ensuring that each node update function produces a valid active cognitive hierarchy and that there is only one possible output given the input.
- Core assumption: The partial ordering induced by the DAG structure of the hierarchy is maintained throughout all update passes.
- Evidence anchors:
  - [section]: "Theorem 1. The cognitive process model Update is well-defined. Proof. By inspection on the five individual passes of cognitive hierarchy."
  - [section]: "Consequently, the process model performs what one would intuitively require of an operational cognitive hierarchy; updating nodes up the hierarchy and propagating actions back down the hierarchy."
  - [corpus]: Weak evidence - corpus papers mention formal frameworks but don't provide well-defined process model proofs.
- Break condition: The DAG structure is violated (e.g., cycles introduced), or the node update functions fail to preserve the required data types and structures.

## Foundational Learning

- Concept: Partial ordering in directed acyclic graphs (DAGs)
  - Why needed here: The cognitive hierarchy relies on DAG structures to ensure proper information flow direction (upward for sensing/utilities, downward for actions/context) and to prove the well-definedness of the process model.
  - Quick check question: If node A has edges to nodes B and C, and B has an edge to D, what partial ordering constraint must hold for the update passes?

- Concept: Recursive optimality in hierarchical reinforcement learning
  - Why needed here: The framework claims to achieve globally optimal policies through hierarchical decomposition, which requires understanding when sub-task optimality composes to global optimality.
  - Quick check question: Under what conditions does a recursively optimal policy at each level guarantee a globally optimal policy for the composite system?

- Concept: Transition function learning and value iteration
  - Why needed here: The low-level nodes use reinforcement learning (Q-learning) to learn transition models, which are then used by high-level planners through the utility update mechanism.
  - Quick check question: How does the temporal difference learning update rule ensure convergence to optimal Q-values in the presence of stochastic transitions?

## Architecture Onboarding

- Component map: Cognitive nodes (belief states, policies, transition functions) -> Active cognitive nodes (dynamic coupling with state) -> Hierarchy structure (DAG with sensing, context, utility, task functions) -> Process model (five-pass update)

- Critical path: Prediction → Correction → Transition Learning → Utility Update → Action Update
  - Each pass must complete successfully before the next begins
  - The upward graph partial ordering constrains prediction/correction/transition learning
  - The downward graph partial ordering constrains utility update/action update

- Design tradeoffs:
  - Granularity vs. complexity: Finer abstraction levels provide more accurate planning but increase computational cost
  - Learning rate vs. stability: Faster learning may lead to oscillation, slower learning may not adapt quickly enough
  - Symbolic vs. sub-symbolic representation: Tradeoff between interpretability and ability to handle continuous domains

- Failure signatures:
  - Stalling in prediction/correction passes: Indicates sensing function issues or belief state update failures
  - Oscillating transition functions: Suggests inappropriate learning rate or noisy observations
  - Suboptimal high-level plans: May indicate utility propagation errors or inadequate abstraction level granularity
  - Process model non-termination: Violated DAG partial ordering or cyclic dependencies

- First 3 experiments:
  1. Implement a two-level hierarchy with perfect sensing and deterministic transitions to verify basic process model operation
  2. Add stochasticity to the low-level node and verify utility propagation affects high-level planning decisions
  3. Introduce learning in the low-level node and measure convergence of transition models and resulting policy quality

## Open Questions the Paper Calls Out
- Question: How does the performance of the cognitive hierarchy framework scale when integrating more than two levels of abstraction with complex interactions between planning and learning components?
- Question: What are the theoretical limits on the types of transition functions and utility representations that can be effectively learned and integrated across different levels of the hierarchy?
- Question: How does the cognitive hierarchy framework handle dynamic environments where the transition model and utility functions change over time, requiring continuous adaptation?

## Limitations
- Lack of empirical validation beyond theoretical framework and single robot navigation example
- Assumes perfect sensing in demonstration, which may not hold in real-world applications
- Complexity analysis based on theoretical bounds rather than measured computational performance

## Confidence
- High: The formal framework structure and mathematical proofs for the well-defined process model
- Medium: The theoretical guarantees of recursive optimality and utility propagation mechanisms
- Low: Practical effectiveness and scalability in complex, noisy real-world environments

## Next Checks
1. **Empirical scalability test**: Implement the framework with varying hierarchy depths and measure computational complexity empirically to verify theoretical O(M+N) vs O(M×N) claims across different problem sizes.

2. **Noise sensitivity analysis**: Systematically vary sensing noise and motion stochasticity parameters to evaluate how these affect utility propagation accuracy and resulting plan quality, particularly testing the doorway traversal optimization behavior.

3. **Generalization evaluation**: Test the framework on diverse robotic tasks beyond navigation (e.g., manipulation, multi-robot coordination) to assess the generality of the hierarchical decomposition approach and identify failure modes in different domains.