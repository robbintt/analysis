---
ver: rpa2
title: 'CARLA: Self-supervised Contrastive Representation Learning for Time Series
  Anomaly Detection'
arxiv_id: '2308.09296'
source_url: https://arxiv.org/abs/2308.09296
tags:
- anomaly
- time
- series
- learning
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of detecting anomalies in time
  series data, particularly when labeled data is scarce. The proposed method, CARLA,
  introduces a novel self-supervised contrastive representation learning approach
  that leverages anomaly injection techniques to learn discriminative representations
  of normal and anomalous behavior.
---

# CARLA: Self-supervised Contrastive Representation Learning for Time Series Anomaly Detection

## Quick Facts
- arXiv ID: 2308.09296
- Source URL: https://arxiv.org/abs/2308.09296
- Reference count: 40
- F1 scores exceeding 0.9 on several benchmark datasets

## Executive Summary
This paper introduces CARLA, a novel self-supervised contrastive representation learning framework for time series anomaly detection that addresses the challenge of scarce labeled data. CARLA employs a two-stage approach: a pretext stage that learns discriminative representations through anomaly injection and contrastive learning, followed by a self-supervised classification stage that refines these representations using nearest and furthest neighbor information. Experimental results on seven benchmark datasets demonstrate that CARLA outperforms state-of-the-art methods in both F1 score and AU-PR metrics.

## Method Summary
CARLA is a two-stage self-supervised contrastive representation learning framework for time series anomaly detection. The first stage uses anomaly injection to create synthetic anomalies as negative samples for contrastive learning with triplet loss, learning discriminative representations. The second stage performs self-supervised classification using consistency/inconsistency losses based on nearest and furthest neighbors in the learned representation space, with entropy regularization for better generalization.

## Key Results
- Achieves F1 scores exceeding 0.9 on multiple benchmark datasets
- Outperforms state-of-the-art methods in both F1 score and AU-PR metrics
- Demonstrates effectiveness across seven diverse time series datasets including MSL, SMAP, SMD, SWaT, WADI, Yahoo-A1, and KPI

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Anomaly injection into windows enables contrastive learning to distinguish normal from anomalous behavior.
- Mechanism: Synthetic anomalies are injected into time series windows during the pretext stage, creating negative samples. The contrastive loss then pulls representations of normal windows (anchors) closer to temporally proximate normal windows and pushes them away from anomalous windows.
- Core assumption: Injected anomalies are representative of real anomalies and the model can generalize from synthetic to real anomalies.
- Evidence anchors:
  - [abstract]: "Our contrastive approach leverages existing generic knowledge about time series anomalies and injects various types of anomalies as negative samples."
  - [section]: "By introducing anomalies into the system, the model can learn a more effective decision boundary, resulting in a reduced false positive rate and enhanced precision in identifying anomalies when compared to current state-of-the-art models."

### Mechanism 2
- Claim: Self-supervised classification using nearest and furthest neighbors improves discriminative power.
- Mechanism: After learning initial representations via contrastive loss, the model identifies Q nearest neighbors (likely normal) and Q furthest neighbors (likely anomalous) for each window. A self-supervised classification stage then uses a loss that maximizes similarity to nearest neighbors and minimizes similarity to furthest neighbors.
- Core assumption: Nearest neighbors in representation space are semantically similar and furthest neighbors are semantically dissimilar.
- Evidence anchors:
  - [abstract]: "Additionally, it leverages the information about representations' neighbours through a self-supervised approach to classify windows based on their nearest/furthest neighbours to further enhance the performance of anomaly detection."
  - [section]: "Semantic similarity for a given window wi defined as Q nearest neighbours of ϕp(wi) ∈ ϕp(B), where Q is the number of nearest neighbours. And, semantic dissimilarity for a given window wi defined as Q furthest neighbours of ϕp(wi) ∈ ϕp(B)."

### Mechanism 3
- Claim: Temporal proximity of windows ensures normal behavior consistency.
- Mechanism: The positive pair selection strategy uses a random temporal neighbor from y previous windows, leveraging the assumption that temporally close windows share normal behavior.
- Core assumption: Anomalies are rare and temporally proximate windows are likely both normal.
- Evidence anchors:
  - [section]: "The objective of the pretext triplet loss function is to decrease the distance between the anchor sample and its corresponding positive sample while simultaneously increasing the distance between the anchor sample and negative samples."
  - [section]: "Our experiment demonstrated that selecting positive pairs using a random temporal neighbour is a more effective approach than weak augmentation with noise."

## Foundational Learning

- Concept: Contrastive representation learning
  - Why needed here: To learn discriminative features that separate normal from anomalous time series windows without labeled data.
  - Quick check question: What is the core objective of the triplet loss in contrastive learning?

- Concept: Anomaly injection techniques
  - Why needed here: To create synthetic anomalies that serve as negative samples for contrastive learning.
  - Quick check question: What are the two main categories of anomaly injection used in CARLA?

- Concept: Self-supervised classification
  - Why needed here: To refine representations by leveraging nearest/furthest neighbor information without external labels.
  - Quick check question: How does the self-supervised loss function use nearest and furthest neighbors differently?

## Architecture Onboarding

- Component map: Anomaly injection -> Contrastive learning (triplet loss) -> Nearest/furthest neighbor mining -> Self-supervised classification -> Inference
- Critical path: Anomaly injection → contrastive learning → neighbor mining → self-supervised classification → inference
- Design tradeoffs:
  - Window size vs. temporal resolution: Larger windows capture more context but may smooth over anomalies
  - Number of classes vs. discrimination: More classes can overfit normal data, fewer classes may not capture anomaly diversity
  - Anomaly injection variety vs. realism: More types improve robustness but may introduce unrealistic patterns
- Failure signatures:
  - High precision but low recall: Model is too conservative, likely due to overly tight normal boundaries
  - Low precision but high recall: Model is detecting too many anomalies, possibly due to poor anomaly injection or neighbor mining
  - Unstable performance across window sizes: Model is sensitive to temporal resolution
- First 3 experiments:
  1. Vary window size (50, 100, 200, 250) on MSL dataset and measure F1/AU-PR
  2. Remove each anomaly type (trend, contextual, shapelet, global, seasonal) and measure impact on F1
  3. Test positive pair selection strategies: temporal neighbor vs. weak augmentation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CARLA compare to other state-of-the-art methods when using point adjustment (PA) in evaluation?
- Basis in paper: [explicit] The paper mentions that PA can lead to overestimation of model performance and compares results with and without PA in Appendix B.
- Why unresolved: The paper does not provide a direct comparison of CARLA's performance with other methods when using PA.
- What evidence would resolve it: Conducting experiments with PA and comparing the results with other methods would provide insights into CARLA's performance in this context.

### Open Question 2
- Question: How does the choice of window size affect the performance of CARLA on different datasets?
- Basis in paper: [explicit] The paper conducts an ablation study on the effect of window size on three datasets (MSL, SMD, and Yahoo) and shows that window size 200 consistently outperforms other sizes.
- Why unresolved: The study only focuses on three datasets, and it is unclear if the same window size would be optimal for other datasets or domains.
- What evidence would resolve it: Performing experiments with different window sizes on a wider range of datasets would help determine the optimal window size for CARLA in various contexts.

### Open Question 3
- Question: How does the inclusion of different types of anomalies during the Pretext Stage affect CARLA's performance?
- Basis in paper: [explicit] The paper conducts an ablation study on the effectiveness of different anomaly types (trend, contextual, shapelet, global, and seasonal) on the MSL dataset.
- Why unresolved: The study only focuses on one dataset, and it is unclear if the same trends would be observed in other datasets or domains.
- What evidence would resolve it: Conducting similar ablation studies on other datasets would provide insights into the impact of different anomaly types on CARLA's performance across various contexts.

## Limitations
- Anomaly injection techniques may not fully capture real-world anomaly distributions, limiting generalizability
- Neighbor-based classification relies heavily on the assumption that nearest neighbors in representation space are semantically similar
- Lacks ablation studies showing the individual contribution of each anomaly type to overall performance

## Confidence
- Contrastive learning with anomaly injection improves discrimination: High confidence
- Self-supervised classification using nearest/furthest neighbors enhances performance: Medium confidence
- Temporal proximity ensures normal behavior consistency: Low confidence

## Next Checks
1. Conduct ablation studies removing each anomaly injection type to quantify their individual contributions to overall performance
2. Test the temporal neighbor assumption by comparing against random positive pair selection across datasets with varying temporal dynamics
3. Evaluate CARLA's performance on datasets with known non-temporal anomalies or highly dynamic systems where temporal proximity may not indicate normal behavior