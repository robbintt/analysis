---
ver: rpa2
title: The Impact of Depth on Compositional Generalization in Transformer Language
  Models
arxiv_id: '2310.19956'
source_url: https://arxiv.org/abs/2310.19956
tags:
- generalization
- depth
- size
- compositional
- deeper
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether transformer depth promotes compositional
  generalization by controlling for total parameter count. The authors construct three
  classes of models (41M, 134M, and 374M parameters) with varying depths by trading
  depth for width in the feed-forward dimension.
---

# The Impact of Depth on Compositional Generalization in Transformer Language Models

## Quick Facts
- arXiv ID: 2310.19956
- Source URL: https://arxiv.org/abs/2310.19956
- Authors: 
- Reference count: 40
- Key outcome: Deeper transformer models achieve better compositional generalization, but benefits saturate after a few layers, and improvements cannot be attributed solely to better pretraining or in-distribution performance.

## Executive Summary
This paper investigates whether transformer depth promotes compositional generalization by controlling for total parameter count. The authors construct three classes of models (41M, 134M, and 374M parameters) with varying depths by trading depth for width in the feed-forward dimension. After pretraining on C4 and fine-tuning on four compositional generalization tasks, they find that deeper models achieve better compositional generalization, though the benefits of additional layers diminish rapidly. Most of the advantage comes from the first few layers. They also show that deeper models have better language modeling performance, but the benefits for compositional generalization cannot be attributed solely to better pretraining or in-distribution fine-tuning performance.

## Method Summary
The authors construct three model families with equal total number of parameters but differing depths by reducing the feed-forward dimension to compensate for added depth. Models are pretrained on C4 corpus with context size 1024 and batch size 128 for 1M steps, then fine-tuned on compositional generalization tasks for 10,000 steps. The compositional generalization tasks include COGS, COGS-vf, Geo Query, and English passivization datasets.

## Key Results
- Deeper models achieve better compositional generalization across all tested model sizes
- Benefits of additional layers diminish rapidly, with most gains coming from the first few layers
- Improvements in compositional generalization cannot be attributed solely to better pretraining or in-distribution fine-tuning performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adding transformer layers improves compositional generalization by increasing model depth without increasing parameter count, achieved by reducing feed-forward width proportionally to added depth.
- Mechanism: The authors construct models with equal parameter counts by trading depth for width in the feed-forward dimension. This allows isolating the effect of depth on compositional generalization without the confounding effect of increased model size.
- Core assumption: The feed-forward width reduction does not degrade model performance as long as the feed-forward ratio remains within acceptable bounds.
- Evidence anchors:
  - [abstract]: "we construct three classes of models which trade off depth for width such that the total number of parameters is kept constant (41M, 134M and 374M parameters)."
  - [section]: "we construct three classes of models with equal total number of parameters but differing depths; we do so by reducing the model's feed-forward dimension to compensate for added depth."
  - [corpus]: Weak evidence; corpus mentions compositional generalization but does not directly address depth-width trade-offs.
- Break condition: Performance degradation occurs when the feed-forward dimension becomes smaller than the model's embedding dimension, making the feed-forward transform rank-deficient.

### Mechanism 2
- Claim: Deeper models achieve better compositional generalization because they can represent more complex compositional structures, but benefits saturate after a few layers.
- Mechanism: The additional layers allow the model to learn more complex representations and transformations needed for compositional tasks, but most of the benefit is gained from the first few layers.
- Core assumption: The compositional generalization tasks used have a threshold complexity that can be captured by a relatively small number of layers.
- Evidence anchors:
  - [abstract]: "deeper models generalize more compositionally than shallower models do, but the benefit of additional layers diminishes rapidly."
  - [section]: "Performance on COGS, COGS-vf, and GeoQuery appears to saturate with fewer layers than on COGS despite the fact that the two datasets are equivalent in expressive capacity."
  - [corpus]: Weak evidence; corpus mentions compositional generalization but does not directly address the saturation effect of depth.
- Break condition: When the task complexity exceeds the representational capacity of the available layers, or when the feed-forward dimension becomes too small relative to the embedding dimension.

### Mechanism 3
- Claim: The benefits of depth for compositional generalization are independent of better pretraining or in-distribution performance.
- Mechanism: Even when controlling for equal pretraining perplexity and equal in-distribution fine-tuning performance, deeper models still show better compositional generalization.
- Core assumption: The compositional generalization improvement is a direct result of depth rather than a side effect of better overall model performance.
- Evidence anchors:
  - [abstract]: "the benefits of depth for compositional generalization cannot be attributed solely to better performance on language modeling or on in-distribution data."
  - [section]: "we also show the benefits of depth for compositional generalization are not merely a consequence of the fact that deeper models learn the in-distribution data or pretraining corpus better."
  - [corpus]: Weak evidence; corpus mentions compositional generalization but does not directly address the independence of depth benefits from pretraining or in-distribution performance.
- Break condition: If the compositional generalization tasks are too simple to require the additional representational capacity provided by depth, or if the pretraining data already contains sufficient compositional examples.

## Foundational Learning

- Concept: Transformer architecture
  - Why needed here: Understanding how transformers work is crucial for grasping how depth affects compositional generalization.
  - Quick check question: What are the main components of a transformer layer, and how do they interact?

- Concept: Compositional generalization
  - Why needed here: The paper's focus is on how transformer depth affects the ability to generalize compositionally, so understanding this concept is essential.
  - Quick check question: What is compositional generalization, and why is it important for language models?

- Concept: Feed-forward ratio
  - Why needed here: The paper manipulates the feed-forward ratio to control for parameter count while varying depth, so understanding this concept is crucial.
  - Quick check question: What is the feed-forward ratio, and how does it affect transformer performance?

## Architecture Onboarding

- Component map:
  Transformer layers -> Feed-forward dimension (variable width) -> Embedding dimension (constant) -> Attention mechanism (constant)

- Critical path:
  1. Pretrain models on C4 corpus
  2. Fine-tune models on compositional generalization tasks
  3. Analyze performance across different depths and sizes

- Design tradeoffs:
  - Depth vs. width: Increasing depth while decreasing width to maintain constant parameter count
  - Performance vs. latency: Deeper models may have better performance but also higher latency
  - Complexity vs. generalization: More complex models may generalize better but also be more prone to overfitting

- Failure signatures:
  - Poor performance on compositional tasks despite increased depth
  - Rank-deficient feed-forward transforms when the feed-forward dimension becomes too small
  - Overfitting on pretraining data without improved generalization

- First 3 experiments:
  1. Compare performance of shallow vs. deep models on a simple compositional task to verify the depth benefit
  2. Test the saturation effect by varying depth and measuring performance gains
  3. Verify the independence of depth benefits from pretraining and in-distribution performance by controlling for these factors

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does increasing transformer depth improve compositional generalization in larger models beyond 374M parameters?
- Basis in paper: [explicit] The paper tests models up to 374M parameters and observes that benefits of depth diminish as models get larger, but doesn't explore if this trend continues at larger scales.
- Why unresolved: The authors only tested three model sizes (41M, 134M, 374M parameters) due to compute limitations. They note that the optimal depth increases with model size but can't determine if this trend continues beyond 374M parameters.
- What evidence would resolve it: Testing deeper models (e.g., 1B+ parameters) with varying depths while controlling for parameter count would show if the diminishing returns pattern continues or if larger models benefit more from additional depth.

### Open Question 2
- Question: Would universal transformers with weight sharing achieve better compositional generalization than depth-width traded models?
- Basis in paper: [explicit] The authors mention universal transformers as an alternative approach in the limitations section, noting that weight sharing would allow deeper models to have arbitrarily-wide feed-forward networks.
- Why unresolved: The authors only tested depth-width traded models and didn't implement universal transformers to compare performance. They hypothesize that weight sharing might be beneficial but don't test this.
- What evidence would resolve it: Implementing universal transformers with the same parameter budgets and comparing their compositional generalization performance to the depth-width traded models would reveal if weight sharing provides advantages.

### Open Question 3
- Question: Does including source code in pretraining improve compositional generalization?
- Basis in paper: [explicit] The authors cite OpenAI (2023) and Google (2023) showing that including source code in pretraining improves compositional generalization, and suggest this as an area for future work.
- Why unresolved: The authors only tested models pretrained on natural language data (C4 corpus) and didn't experiment with source code in pretraining.
- What evidence would resolve it: Pretraining models on corpora containing source code and comparing their compositional generalization performance to models pretrained only on natural language would show if source code improves compositional abilities.

## Limitations

- The experimental design trading depth for width may not reflect real-world scaling scenarios where models grow in all dimensions simultaneously
- Results are based on a specific set of compositional generalization tasks and may not generalize to all types of compositional reasoning
- The study does not investigate whether findings hold for different pretraining objectives or data distributions

## Confidence

**High Confidence**: The claim that deeper models achieve better compositional generalization is well-supported by the experimental results across multiple model sizes and tasks. The controlled parameter count design effectively isolates depth as the key variable.

**Medium Confidence**: The finding that benefits of depth diminish rapidly and mostly come from the first few layers is supported but could benefit from more systematic analysis across different task complexities. The observation that these benefits are independent of better pretraining or in-distribution performance is supported but relies on indirect evidence.

**Low Confidence**: The paper does not provide strong evidence for the exact mechanism by which depth improves compositional generalization. While the empirical results are clear, the theoretical explanation for why depth matters remains somewhat speculative.

## Next Checks

1. Evaluate the same depth-varies models on a broader set of compositional tasks (including semantic parsing, logical inference, and program synthesis) to verify whether the depth benefits generalize beyond the current task set.

2. Implement layer-wise training or analysis to identify which specific layers contribute most to compositional generalization improvements, and whether these patterns vary across task types.

3. Test models that scale depth without reducing feed-forward width (maintaining constant parameter count through other means) to verify whether the observed benefits are specifically due to depth or related to the width-depth trade-off.