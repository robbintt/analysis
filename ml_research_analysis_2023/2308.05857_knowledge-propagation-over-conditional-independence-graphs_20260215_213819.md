---
ver: rpa2
title: Knowledge Propagation over Conditional Independence Graphs
arxiv_id: '2308.05857'
source_url: https://arxiv.org/abs/2308.05857
tags:
- graph
- graphs
- matrix
- nodes
- propagation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work focuses on knowledge propagation (KP) over Conditional
  Independence (CI) graphs, which are a special type of Probabilistic Graphical Models
  (PGMs). CI graphs model direct dependencies between input features as an undirected
  graph, with edge weights representing partial correlation strengths.
---

# Knowledge Propagation over Conditional Independence Graphs

## Quick Facts
- arXiv ID: 2308.05857
- Source URL: https://arxiv.org/abs/2308.05857
- Reference count: 5
- Primary result: Analytical solution achieves up to 56.83% accuracy on Cora; iterative-posneg method achieves up to 72.27% accuracy on PubMed Diabetes

## Executive Summary
This paper proposes knowledge propagation algorithms over Conditional Independence (CI) graphs to predict missing attribute values for nodes. The approach converts partial correlation matrices into transition probability matrices, then propagates known labels among unknown features through either iterative or analytical diffusion processes. Experiments on Cora and PubMed datasets demonstrate superior performance compared to state-of-the-art methods, with the analytical solution providing exact closed-form predictions and the iterative method with separate positive/negative matrices excelling on larger datasets.

## Method Summary
The method converts partial correlation matrices from CI graphs into transition probability matrices through entry-wise exponential scaling and row normalization. This transformation emphasizes positive correlations while suppressing negative ones for label propagation. Three algorithm variants are proposed: (1) iterative-exp using the transformed matrix, (2) iterative-posneg using separate positive and negative correlation matrices with KL divergence regularization, and (3) analytical providing a closed-form solution via matrix inversion. The algorithms propagate known attribute values to unknown nodes until convergence, with the analytical method guaranteed to converge to the same result as infinite iterations.

## Key Results
- Analytical solution achieves highest accuracy on Cora dataset (56.83%)
- Iterative-posneg method excels on PubMed Diabetes (72.27% accuracy)
- Both proposed methods outperform state-of-the-art knowledge propagation techniques
- Positive-negative split with KL regularization provides considerable improvements

## Why This Works (Mechanism)

### Mechanism 1
The transition probability matrix derived from partial correlations enables effective label propagation by emphasizing positive correlations over negative ones. Entry-wise exponential scaling followed by row normalization transforms the partial correlation matrix into a transition probability matrix. This exponentially suppresses negative correlations while preserving positive ones, making them more favorable paths for knowledge propagation. The strength of partial correlations between features correlates with the similarity of their attribute values.

### Mechanism 2
The analytical solution converges to the same result as iterative propagation when run to infinity. The analytical update formula nU = (I - PeUU)^(-1) PeUK · nK is mathematically equivalent to running the iterative update infinitely many times. The spectral radius of PeUU is less than 1, ensuring convergence. The choice of initial distribution over categories does not matter for the final result.

### Mechanism 3
Using separate transition matrices for positive and negative correlations with KL divergence regularization improves propagation accuracy. Positive and negative correlation matrices are normalized separately, then used with KL divergence regularization terms to control propagation speed and account for negative correlations. Negative correlations contain meaningful information that should be incorporated but weighted differently than positive correlations.

## Foundational Learning

- Concept: Conditional Independence (CI) graphs
  - Why needed here: The entire approach builds on the assumption that partial correlations represent meaningful relationships between features
  - Quick check question: What is the difference between correlation and partial correlation in the context of CI graphs?

- Concept: Transition probability matrices
  - Why needed here: The core mechanism converts correlation information into probabilities for label propagation
  - Quick check question: Why do we apply exponential scaling before normalization when creating the transition matrix?

- Concept: Matrix inversion and convergence
  - Why needed here: The analytical solution relies on matrix inversion properties to achieve closed-form propagation
  - Quick check question: Under what conditions does the matrix (I - PeUU) have an inverse?

## Architecture Onboarding

- Component map: Preprocessing (correlation matrix conversion) -> Three algorithm variants (iterative-exp, iterative-posneg, analytical) -> Evaluation (accuracy comparison)
- Critical path: For analytical solution: (1) compute partial correlation matrix, (2) transform to transition probability matrix, (3) split into known/unknown blocks, (4) compute inverse and matrix multiplication to get predictions
- Design tradeoffs: Iterative methods scale linearly with iterations but may converge slowly for large graphs; analytical methods are O(D³) but provide exact solutions; the positive/negative split adds complexity but captures more nuanced relationships
- Failure signatures: Poor accuracy indicates either (1) partial correlations don't reflect true feature relationships, (2) graph has disconnected components without labels, or (3) regularization parameters are poorly tuned
- First 3 experiments:
  1. Run all three algorithm variants on Cora with 20% missing values and compare accuracy
  2. Vary the α parameter in the exponential scaling to see its effect on propagation quality
  3. Test the analytical solution on increasingly large subsets to identify the size threshold where iterative methods become preferable

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed analytical solution scale for very large graphs with thousands or millions of nodes, considering the matrix inversion step has a complexity of O(D³)? The paper mentions the analytical solution is dominated by the matrix inverse term with complexity O(D³) and suggests using the iterative method for very large graphs, but does not provide empirical results or theoretical analysis of the analytical solution's performance on large-scale graphs beyond the Cora and PubMed datasets.

### Open Question 2
What are the limitations of the exponential transformation used to convert partial correlation matrices to transition probability matrices, and are there alternative transformations that could perform better in certain domains? The paper describes using entry-wise exponential and row-wise normalization but only tests one specific transformation method and does not explore alternative approaches or analyze the limitations across different types of domains.

### Open Question 3
How sensitive are the knowledge propagation results to the choice of hyperparameters, particularly the scaling intensity parameter α in the exponential transformation? The paper mentions α is a scaling intensity parameter but does not provide a detailed sensitivity analysis of its impact on performance, despite stating that hyperparameters were optimized on validation data.

## Limitations

- The specific CI graph recovery algorithm used to obtain partial correlation matrix P is not specified
- Hyperparameter choices (α scaling, regularization strength, convergence thresholds) are critical but not fully detailed
- The approach may struggle with disconnected graph components lacking known labels
- Empirical scalability analysis for the analytical solution on large graphs is missing

## Confidence

High confidence in mathematical derivations for analytical solution assuming convergence conditions hold.
Medium confidence in accuracy claims given lack of hyperparameter specification and algorithm details.
Low confidence in generalizability without testing on more diverse datasets beyond Cora and PubMed.

## Next Checks

1. Implement and test multiple CI graph recovery algorithms to verify robustness of partial correlation estimates across different methods.
2. Systematically vary the exponential scaling parameter α and regularization strength to identify optimal hyperparameter ranges and their impact on accuracy.
3. Test the analytical solution's scalability by measuring computation time and accuracy degradation on progressively larger subsets of Cora and PubMed datasets to identify practical size limits.