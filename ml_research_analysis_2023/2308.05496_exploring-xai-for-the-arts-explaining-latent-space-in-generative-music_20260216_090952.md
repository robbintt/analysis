---
ver: rpa2
title: 'Exploring XAI for the Arts: Explaining Latent Space in Generative Music'
arxiv_id: '2308.05496'
source_url: https://arxiv.org/abs/2308.05496
tags:
- music
- latent
- musical
- which
- space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper explores how to make latent space in generative music
  models more explainable using explainable AI (XAI) techniques. The authors extend
  the MeasureVAE model for music generation and increase explainability by using latent
  space regularisation to map specific dimensions to meaningful musical attributes,
  providing a user interface for real-time interaction and visualisation of these
  attributes.
---

# Exploring XAI for the Arts: Explaining Latent Space in Generative Music

## Quick Facts
- arXiv ID: 2308.05496
- Source URL: https://arxiv.org/abs/2308.05496
- Reference count: 40
- The paper extends MeasureVAE with latent space regularization to make specific dimensions control meaningful musical attributes, achieving 99.87% reconstruction accuracy and interpretability scores ranging from 0.80-0.99.

## Executive Summary
This paper addresses the challenge of making latent spaces in generative music models more explainable by extending the MeasureVAE architecture with latent space regularization (LSR). The approach forces specific dimensions of the latent space to map directly to musical attributes like rhythmic complexity, note range, note density, and average interval jump. The authors create a user interface that allows real-time interaction with these dimensions, enabling users to observe how changes in latent space affect generated music. The system is trained on 20,000 Irish folk melodies and achieves high reconstruction accuracy while providing interpretable control over musical features.

## Method Summary
The authors modify the MeasureVAE architecture by adding latent space regularization during training, which forces four specific dimensions of the 256-dimensional latent space to directly control four musical attributes. They preprocess 20,000 monophonic Irish folk melodies into a 24-character measure representation and train the model using Adam optimizer for 30 epochs with both standard VAE loss and the LSR regularization loss. The LSR loss minimizes the distance between attribute values and corresponding latent dimensions, creating interpretable mappings. The resulting model achieves 99.87% reconstruction accuracy on the training set while maintaining interpretability scores between 0.80-0.99 for the four musical attributes.

## Key Results
- Achieved 99.87% reconstruction accuracy on training set and 99.68% on validation set
- Interpretability scores: rhythmic complexity (0.80), note range (0.99), note density (0.99), average interval jump (0.91)
- Successfully demonstrated real-time interaction through 2D pads that manipulate latent space dimensions
- Visualizations show clear mapping between latent dimensions and musical attribute surfaces

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Latent space regularization creates interpretable dimensions by forcing specific dimensions to map to meaningful musical attributes
- Mechanism: During training, LSR adds a regularisation loss that minimizes the distance between attribute values and corresponding latent dimensions, making the dimensions directly control specific musical features
- Core assumption: The relationship between latent dimensions and musical attributes is monotonic and stable after training
- Evidence anchors:
  - [abstract]: "using latent space regularisation to force some specific dimensions of the latent space to map to meaningful musical attributes"
  - [section]: "We jointly train our MeasureV AE model with latent space regularisation on all four attributes, to force four specific dimensions of the latent space to represent given musical attributes"
  - [corpus]: Weak - no direct corpus evidence for this specific LSR approach, though related work on attribute control exists
- Break condition: If the monotonic relationship between dimensions and attributes breaks during training or inference, or if the regularisation loss destabilizes the VAE's reconstruction capability

### Mechanism 2
- Claim: The user interface with real-time interaction creates a feedback loop that enables debugging and exploration of the model
- Mechanism: Users can manipulate LSR dimensions via 2D pads, observe immediate changes in generated music, and develop understanding through exploration
- Core assumption: Real-time feedback is sufficient for users to infer the mapping between latent dimensions and musical outcomes
- Evidence anchors:
  - [abstract]: "providing a user interface feedback loop to allow people to adjust dimensions of the latent space and observe the results of these changes in real-time"
  - [section]: "The real-time nature of the feedback provided by our demo would make it easier to inspect and develop an understanding of the AI model"
  - [corpus]: Weak - no corpus evidence for this specific interface design, though real-time interaction in music systems is established
- Break condition: If latency exceeds user expectations, or if the mapping between dimensions and musical features becomes too complex for users to infer through exploration

### Mechanism 3
- Claim: Visualizations of training data contribution and attribute surfaces provide additional explainability by showing what regions of latent space are likely to produce musically coherent outputs
- Mechanism: Surface maps show how attribute values vary across latent space, while training data contribution plots indicate which regions have sufficient training data
- Core assumption: Users can interpret these visualizations to make informed decisions about which regions to explore
- Evidence anchors:
  - [abstract]: "providing a visualisation of the musical attributes in the latent space to help people understand and predict the effect of changes to latent space dimensions"
  - [section]: "We create these surface maps by decoding corresponding latent vectors... These surface maps illustrate how the LSR technique works since the metric values increase for the higher parts of the corresponding axis"
  - [corpus]: Weak - no corpus evidence for this specific visualization approach, though visualization in XAI is established
- Break condition: If users cannot interpret the visualizations, or if the visualizations become misleading due to overfitting or insufficient training data

## Foundational Learning

- Concept: Variational Autoencoders (VAEs) and latent space regularization
  - Why needed here: The entire approach builds on VAE architecture with LSR modifications
  - Quick check question: How does LSR differ from standard VAE training, and what loss term is added?

- Concept: Music feature extraction and representation
  - Why needed here: The model operates on musical attributes like rhythmic complexity and note density
  - Quick check question: What are the four musical attributes used in this work, and how are they calculated from the data?

- Concept: Real-time interactive system design for creative tools
  - Why needed here: The UI design and interaction mechanics are crucial for the explainability claims
  - Quick check question: What are the two 2D pad pairings in the interface, and why were these specific dimension pairings chosen?

## Architecture Onboarding

- Component map: MIDI input -> preprocessing (24-character measure representation) -> encoder -> latent space manipulation -> decoder -> audio/visual output -> user interface with 2D pads and visualizations
- Critical path: Input MIDI → encoding → latent space manipulation → decoding → audio/visual output → user interaction
- Design tradeoffs: LSR improves interpretability but may reduce reconstruction accuracy compared to non-LSR model; real-time generation requires pre-rendering audio files
- Failure signatures: Low interpretability scores indicate LSR isn't working; high reconstruction error indicates model instability; UI latency breaks the feedback loop
- First 3 experiments:
  1. Train non-LSR baseline and compare reconstruction accuracy and interpretability scores
  2. Train LSR model and verify that the four chosen dimensions show high interpretability while others show near-zero correlation
  3. Implement basic UI with one 2D pad and verify real-time interaction works before adding complexity

## Open Questions the Paper Calls Out

- Question: What are the most effective musical features to use for explaining the workings of the AI model in terms of user understandability and debugging capabilities?
- Basis in paper: [explicit] The authors state that the current system uses four musical attributes (rhythmic complexity, note range, note density, and average interval jump) which are somewhat arbitrary selections and represent only a small subset of variables in music creation.
- Why unresolved: The paper acknowledges that these features were chosen based on typical examples in current research rather than through systematic evaluation of their effectiveness for explainability.
- What evidence would resolve it: Comparative studies testing different sets of musical features for explainability, measuring user comprehension and debugging effectiveness across various feature combinations.

- Question: How can we extend explainability beyond the latent space bottleneck to include the encoder and decoder layers of the model?
- Basis in paper: [explicit] The authors mention that their current work focuses only on explainability of the latent space between the encoder and decoder blocks, and suggest Concept Whitening (CW) as a potential technique for extending explainability to other layers.
- Why unresolved: The paper identifies this as a limitation but does not implement or test any techniques for extending explainability to other network layers.
- What evidence would resolve it: Implementation and evaluation of CW or other explainability techniques applied to encoder and decoder layers, measuring improvements in user understanding of the complete model architecture.

- Question: How can we validate the effectiveness of the current user interface design in terms of explainability and user experience?
- Basis in paper: [inferred] The authors acknowledge that in-depth study and validation by users with various musical knowledge is needed, particularly regarding the effectiveness of the 2D pad design and overall interface intuitiveness.
- Why unresolved: The paper presents the interface as a demonstration without empirical validation from actual users, and questions whether the current design choices are optimal.
- What evidence would resolve it: User studies with musicians and non-musicians evaluating the interface's effectiveness in explaining the model, measuring learning outcomes, debugging capabilities, and user satisfaction with the current versus alternative interface designs.

## Limitations

- Limited validation of explainability claims - no user studies to verify mathematical interpretability scores correspond to human-perceived understanding
- Domain specificity - approach trained exclusively on Irish folk melodies in 4/4 time signature, limiting generalizability
- Sparse training data in latent regions - many regions lack sufficient training data to guarantee musically coherent outputs

## Confidence

**High Confidence** (Strong evidence, well-established):
- The MeasureVAE architecture with LSR implementation and training methodology
- Reconstruction accuracy metrics (99.87% training, 99.68% validation)
- The mathematical formulation of LSR loss and its integration with VAE training

**Medium Confidence** (Some evidence but limitations exist):
- Interpretability scores for musical attributes
- The effectiveness of the 2D pad interface for exploring latent space
- The visualization techniques for showing attribute surfaces and training data contribution

**Low Confidence** (Limited or no validation):
- Human-perceived explainability of the system
- Generalizability to other musical domains beyond Irish folk melodies
- Actual usability of the interface for creative music exploration

## Next Checks

1. **User study validation**: Conduct a controlled experiment with musicians and non-musicians using the interface to manipulate musical attributes. Measure their ability to achieve target musical characteristics and their subjective ratings of explainability and usability.

2. **Cross-domain generalization test**: Train the same model architecture on a different musical dataset (e.g., Bach chorales or jazz standards) and evaluate whether the LSR approach achieves similar interpretability scores and reconstruction accuracy in the new domain.

3. **Baseline comparison experiment**: Implement a conditional VAE baseline that directly conditions generation on musical attributes, and compare its performance against the LSR approach on reconstruction accuracy, interpretability scores, and user control precision.