---
ver: rpa2
title: Danish Foundation Models
arxiv_id: '2311.07264'
source_url: https://arxiv.org/abs/2311.07264
tags:
- danish
- language
- arxiv
- foundation
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Danish Foundation Models (DFM) project addresses the lack of
  high-quality, open-source language models for Danish by creating state-of-the-art
  Danish foundation models. It establishes the Danish Colossal Corpus (DCC), a 100B+
  token corpus spanning multiple domains, and develops models like dfm-encoder-large-v1
  (best-performing Danish encoder) and xls-r-300m-danish (top Danish speech model).
---

# Danish Foundation Models

## Quick Facts
- **arXiv ID**: 2311.07264
- **Source URL**: https://arxiv.org/abs/2311.07264
- **Reference count**: 10
- **Primary result**: Creates state-of-the-art Danish foundation models addressing lack of open-source Danish NLP resources

## Executive Summary
The Danish Foundation Models (DFM) project addresses the significant gap in high-quality, open-source Danish language models by establishing a comprehensive framework for creating and deploying Danish foundation models. Through broad cooperation with public and private institutions, the project creates the Danish Colossal Corpus (DCC) containing over 100 billion tokens from diverse domains, and develops state-of-the-art models including the best-performing Danish encoder and speech models. All models and code are open-sourced with extensive documentation including datasheets and model cards to ensure transparency and reproducibility.

## Method Summary
The DFM project employs a systematic approach to developing Danish foundation models, starting with the creation of the Danish Colossal Corpus (DCC) - a 100B+ token corpus spanning multiple domains including government documents, social media, news, and archival text. The project uses continued pre-training of existing multilingual models on this corpus, fine-tuning for specific tasks like automatic speech recognition. Key to the methodology is extensive documentation through model cards and datasheets, ensuring transparency and reproducibility. The project emphasizes open-sourcing all models, datasets, and code while establishing the Scandinavian Embedding Benchmark for evaluation purposes.

## Key Results
- Developed dfm-encoder-large-v1, the best-performing Danish encoder model to date
- Created xls-r-300m-danish, the top-performing Danish speech model
- Established the Scandinavian Embedding Benchmark (SEB) for evaluating document representations
- Built DCC, a 100B+ token corpus covering diverse Danish text domains

## Why This Works (Mechanism)

### Mechanism 1
Open collaboration with public and private institutions ensures high data quality and applicability of trained models. By pooling resources and expertise from diverse stakeholders, the project accesses high-quality, domain-specific data that would be difficult for individual actors to obtain. This mechanism assumes institutional partners have relevant data and are willing to share it under appropriate agreements.

### Mechanism 2
Extensive documentation (model cards, datasheets) increases trust and adoption in critical applications like healthcare and public services. Transparent documentation provides users with insights into model capabilities, limitations, and potential biases, enabling informed decision-making and responsible use. This assumes users will consult and act upon the provided documentation.

### Mechanism 3
Purpose-built monolingual models outperform multilingual models for languages with distinct linguistic features. Monolingual models can be optimized for specific phonological and grammatical structures of a language, leading to better performance on language-specific tasks. This assumes Danish has sufficiently distinct linguistic features that justify monolingual modeling.

## Foundational Learning

- **Concept: Pre-training and fine-tuning**
  - Why needed here: The project involves training foundation models from scratch (pre-training) and adapting them to specific tasks (fine-tuning)
  - Quick check question: What is the difference between pre-training and fine-tuning in the context of language models?

- **Concept: Tokenization**
  - Why needed here: Efficient tokenization is crucial for handling the Danish language, which has complex morphology
  - Quick check question: How does tokenization affect the performance of language models on morphologically rich languages like Danish?

- **Concept: Data filtering and quality assessment**
  - Why needed here: The project emphasizes high data quality, which requires careful filtering and assessment of the training corpus
  - Quick check question: What are some common techniques for filtering and assessing the quality of text data for language model training?

## Architecture Onboarding

- **Component map**: Data collection pipeline -> Preprocessing pipeline -> Model architecture (encoder/decoder/transformer) -> Training infrastructure -> Evaluation framework -> Documentation and release process

- **Critical path**: 1. Data collection and preprocessing, 2. Model architecture design and implementation, 3. Training and hyperparameter tuning, 4. Evaluation and benchmarking, 5. Documentation and release

- **Design tradeoffs**: Model size vs. computational resources, Monolingual vs. multilingual modeling, Open-source vs. proprietary development, Data quality vs. quantity

- **Failure signatures**: Poor performance on Danish-specific tasks, Inability to scale training due to resource constraints, Lack of adoption due to insufficient documentation or unclear licensing

- **First 3 experiments**:
  1. Train a small Danish language model on a subset of the Danish Colossal Corpus to validate the data pipeline and establish a baseline
  2. Fine-tune an existing multilingual model on Danish data to compare performance with monolingual models
  3. Implement and evaluate different tokenization strategies for Danish to optimize model performance

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal balance between multilingual and monolingual Danish models for different NLP tasks? The paper acknowledges performance differences but doesn't provide a clear framework for determining when to use multilingual versus monolingual models for specific Danish NLP applications.

### Open Question 2
How can the quality and representativeness of Danish foundation models be maintained and improved over time? The paper identifies the need for continuous improvement but doesn't provide a concrete strategy for long-term model maintenance, updates, and quality assurance.

### Open Question 3
What are the most effective approaches for addressing potential biases and cultural limitations in Danish foundation models? While the paper acknowledges the importance of addressing biases, it doesn't provide specific methodologies for detecting, measuring, or mitigating cultural and linguistic biases in Danish models.

## Limitations

- Success heavily depends on continued data access and institutional cooperation, which are not guaranteed long-term
- Evaluation metrics focus on Danish-specific tasks, but cross-linguistic generalization and real-world deployment challenges are not fully addressed
- Environmental impact of training large-scale models and sustainability of maintaining open-source models are not discussed

## Confidence

- **High Confidence**: The methodology of creating a large-scale Danish corpus and training monolingual models is well-grounded in established NLP practices
- **Medium Confidence**: The claim that monolingual models outperform multilingual models for Danish is supported by linguistic arguments but requires empirical validation across diverse tasks
- **Low Confidence**: The long-term adoption and impact of these models in critical applications like healthcare and public services are uncertain and depend on factors beyond the project's control

## Next Checks

1. Reproduce model training: Attempt to replicate the training of dfm-encoder-large-v1 and xls-r-300m-danish using provided datasheets and code, documenting deviations and their impact on performance

2. Evaluate cross-linguistic generalization: Test the Danish models on tasks involving other Scandinavian languages to assess claimed advantages of monolingual modeling and identify potential cross-linguistic transfer capabilities

3. Assess real-world deployment: Conduct case studies in healthcare and public services to evaluate models' performance, usability, and impact in critical applications, considering regulatory compliance, user acceptance, and integration challenges