---
ver: rpa2
title: 'Beyond Text: A Deep Dive into Large Language Models'' Ability on Understanding
  Graph Data'
arxiv_id: '2310.04944'
source_url: https://arxiv.org/abs/2310.04944
tags:
- graph
- llms
- arxiv
- tasks
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether large language models (LLMs) like
  GPT-4 can effectively process graph-structured data for node, edge, and graph-level
  prediction tasks. The authors conduct experiments comparing LLMs with specialized
  graph neural networks (GNNs) across five benchmark datasets including citation networks,
  social networks, and WordNet.
---

# Beyond Text: A Deep Dive into Large Language Models' Ability on Understanding Graph Data

## Quick Facts
- arXiv ID: 2310.04944
- Source URL: https://arxiv.org/abs/2310.04944
- Authors: 
- Reference count: 40
- Primary result: LLMs can process graph-structured data for node classification with reasonable accuracy, but specialized GNNs generally outperform them, especially for graph-level tasks

## Executive Summary
This paper investigates whether large language models (LLMs) like GPT-4 can effectively process graph-structured data for node, edge, and graph-level prediction tasks. The authors conduct experiments comparing LLMs with specialized graph neural networks (GNNs) across five benchmark datasets including citation networks, social networks, and WordNet. Their findings show that while LLMs can achieve reasonable performance on node classification even without explicit graph structure, their zero-shot performance lags behind specialized GNNs. However, incorporating graph topology information significantly improves LLMs' performance on edge-level link prediction tasks, with GPT-4 even surpassing certain GNNs in select cases.

## Method Summary
The study evaluates GPT-3.5 and GPT-4 on five graph benchmark datasets (CORA, PUBMED, OGBN-ARXIV, WORDNET 18, REDDIT) for node classification, edge prediction, and graph classification tasks. The researchers use zero-shot and few-shot prompting with varied formats, including and excluding structural information. They compare LLM performance against semi-supervised GNNs like GCN, GAT, and GNN. Node-level tasks use textual features like paper titles and abstracts, while edge-level tasks focus on link prediction in citation networks and WordNet. Graph-level classification uses Reddit communities. The evaluation measures accuracy across these diverse graph analytics tasks.

## Key Results
- LLMs achieve reasonable node classification accuracy without explicit graph structure when node attributes contain rich semantic information
- Incorporating graph topology significantly improves LLM performance on edge-level link prediction, with GPT-4 surpassing certain GNNs in select cases
- LLMs struggle with complex graph classification tasks, showing performance degradation as output space complexity increases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can process graph-structured data by leveraging contextual understanding from textual node attributes
- Mechanism: When node attributes contain rich semantic information, LLMs can use in-context learning to infer relationships and perform classification without explicit graph topology
- Core assumption: Node textual features contain sufficient information for task completion, making structural information optional for node-level tasks
- Evidence anchors:
  - [abstract] "while LLMs can achieve reasonable performance on node classification even without explicit graph structure"
  - [section] "When only node data, excluding neighborhood information, is presented to GPT, the link prediction accuracy on CORA stands at 51.2% for GPT-3.5"
  - [corpus] Weak evidence - corpus neighbors don't directly address this mechanism

### Mechanism 2
- Claim: Incorporating explicit graph topology information significantly improves LLM performance on edge-level tasks
- Mechanism: Providing neighborhood information allows LLMs to leverage pre-trained knowledge about relationships and connectivity patterns
- Core assumption: LLMs have learned sufficient relational reasoning patterns during pre-training to benefit from structural context
- Evidence anchors:
  - [abstract] "incorporating graph topology information significantly improves LLMs' performance on edge-level link prediction tasks"
  - [section] "when we incorporate the nodes' neighbors information. Notably, the zero-shot result of GPT-4 even surpass the performances of all trained GNN models"
  - [corpus] Weak evidence - corpus doesn't contain specific graph topology experiments

### Mechanism 3
- Claim: Task dimensionality affects LLM capability - node-level tasks are more accessible than graph-level tasks
- Mechanism: LLMs struggle with complex output spaces requiring holistic graph understanding
- Core assumption: Output complexity scales with task dimensionality, exceeding LLM's in-context learning capacity for graph-level tasks
- Evidence anchors:
  - [abstract] "limitations compared to specialized graph models, particularly for more complex graph classification tasks"
  - [section] "When GPT needs to make predictions from full 70 communities, the accuracy was 50.7%"
  - [corpus] Weak evidence - corpus doesn't contain graph-level task analysis

## Foundational Learning

- Concept: In-context learning capabilities
  - Why needed here: LLMs rely on pattern recognition from examples rather than parameter updates
  - Quick check question: How many examples can you fit in the context window while maintaining task performance?

- Concept: Graph neural network fundamentals
  - Why needed here: Understanding GNN advantages helps identify LLM limitations and opportunities
  - Quick check question: What graph structural information do GNNs capture that LLMs struggle with?

- Concept: Prompt engineering strategies
  - Why needed here: Different prompt formats significantly impact LLM performance on graph tasks
  - Quick check question: How does including neighborhood information in prompts affect prediction accuracy?

## Architecture Onboarding

- Component map: LLM inference layer → Prompt formatting engine → Graph data preprocessing → Performance evaluation module
- Critical path: Graph data → Preprocessing → Prompt generation → LLM API call → Result parsing → Evaluation
- Design tradeoffs: Zero-shot vs few-shot prompting (accuracy vs cost), including vs excluding structure (performance vs complexity)
- Failure signatures: Performance plateaus despite prompt variations, output quality degrades with increased task complexity, context window overflow
- First 3 experiments:
  1. Node classification with rich text attributes, no structure information
  2. Edge prediction with and without neighborhood information
  3. Graph classification with varying output complexity (1-10 classes)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs consistently outperform specialized graph neural networks (GNNs) on node classification tasks when provided with graph structure information?
- Basis in paper: [explicit] The authors found that while GPT-4 sometimes surpassed GNNs on node classification, this was inconsistent across datasets and not observed for all models.
- Why unresolved: The experiments showed mixed results where GPT-4 performed better than GNNs on PubMed but not on Cora or OGB-ArXiv. The performance depended on factors like number of categories and semantic overlap.
- What evidence would resolve it: Systematic experiments testing multiple LLMs across diverse graph datasets with varying characteristics (number of classes, semantic similarity, domain type) while controlling for structural information availability.

### Open Question 2
- Question: How does the inclusion of different types of graph structural information (e.g., neighbor titles vs neighbor abstracts) affect LLMs' performance on edge-level tasks?
- Basis in paper: [explicit] The authors observed that including neighbor information significantly improved link prediction accuracy, but found that including abstract information actually decreased performance compared to titles alone.
- Why unresolved: The paper only tested a limited set of structural information types. The differential impact of abstract versus title information suggests there may be an optimal type or combination of structural features.
- What evidence would resolve it: Controlled experiments systematically varying the type, amount, and specificity of structural information provided to LLMs, measuring impact on various edge-level prediction tasks.

### Open Question 3
- Question: What is the relationship between task complexity (node vs edge vs graph level) and LLMs' ability to leverage graph structures effectively?
- Basis in paper: [explicit] The authors observed that graph-level tasks were more challenging for LLMs, with performance degrading as the number of possible labels increased from 1 to 70.
- Why unresolved: The paper only tested one graph-level task (Reddit community classification). The significant performance drop with increased label complexity suggests a systematic relationship that needs further exploration.
- What evidence would resolve it: Comprehensive benchmarking of LLMs across multiple graph-level tasks with varying complexity (number of classes, structural intricacy, domain diversity) compared to specialized graph models.

## Limitations

- The study focuses on academic benchmark datasets with relatively clean structures, which may not generalize to noisy, real-world graph data
- Performance evaluation relies heavily on textual node features, potentially overstating LLM capabilities for graphs with non-textual or limited features
- The study doesn't explore computational costs or inference latency differences between LLMs and GNNs, which are critical factors for practical deployment

## Confidence

**High Confidence:** The finding that LLMs can achieve reasonable node classification accuracy even without explicit graph structure (Mechanism 1) is well-supported by multiple experiments and aligns with known LLM capabilities in semantic understanding.

**Medium Confidence:** The claim that incorporating graph topology significantly improves edge-level performance (Mechanism 2) is supported by results, but the specific magnitude of improvement may depend heavily on prompt engineering quality and dataset characteristics.

**Low Confidence:** The assertion about task dimensionality affecting LLM capability (Mechanism 3) has the weakest support, as the study only examines a limited set of graph classification tasks without exploring the full spectrum of complexity levels or investigating why performance degrades.

## Next Checks

1. **Cross-dataset generalization test:** Evaluate the same LLM models on datasets with non-textual node features (e.g., molecular graphs, traffic networks) to determine if the observed performance patterns hold when textual semantic information is unavailable.

2. **Ablation study on structural encoding:** Systematically vary the amount and format of graph structural information provided to LLMs to identify the minimum structural context required for performance gains and whether there are diminishing returns.

3. **Cost-benefit analysis:** Measure and compare the computational costs (API calls, inference time) of LLMs versus GNNs across all task types to provide a more complete picture of practical deployment considerations beyond raw accuracy metrics.