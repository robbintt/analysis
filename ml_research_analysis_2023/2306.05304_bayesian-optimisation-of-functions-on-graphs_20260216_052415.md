---
ver: rpa2
title: Bayesian Optimisation of Functions on Graphs
arxiv_id: '2306.05304'
source_url: https://arxiv.org/abs/2306.05304
tags:
- iters
- regret
- graph
- function
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of optimising functions defined
  on the node set of large-scale, potentially unknown graphs. The authors propose
  a novel Bayesian optimisation framework called BayesOptG that uses learned kernels
  and efficient local modelling to optimise such functions.
---

# Bayesian Optimisation of Functions on Graphs

## Quick Facts
- arXiv ID: 2306.05304
- Source URL: https://arxiv.org/abs/2306.05304
- Reference count: 40
- Primary result: Novel Bayesian optimisation framework for functions on large-scale graphs using learned kernels and local modelling

## Executive Summary
This paper introduces BayesOptG, a novel Bayesian optimisation framework for optimising functions defined on the node set of large-scale, potentially unknown graphs. The key innovation lies in combining learned graph kernels with local subgraph modelling to achieve sample-efficient optimisation. By constructing local subgraphs around the current best node and using Gaussian process surrogates with kernels adapted to the graph structure, the method can handle both large graphs and incomplete graph knowledge effectively.

## Method Summary
BayesOptG optimises functions on graphs by iteratively constructing local subgraphs around the current best node, learning suitable kernels using graph Laplacian spectral properties, and placing Gaussian process surrogates on these subgraphs. The method learns kernel hyperparameters through log-marginal likelihood optimisation and uses acquisition functions to guide the search. Local modelling ensures computational efficiency while the learned kernels adapt to the target function's behaviour. The framework handles incomplete graph knowledge by revealing structure incrementally during optimisation.

## Key Results
- BayesOptG outperforms baseline methods across synthetic and real-world graphs
- The method achieves competitive results on centrality maximisation and team structure optimisation tasks
- Local modelling approach enables efficient optimisation on large-scale graphs with incomplete knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Learned kernels adapt to target function behavior by capturing spectral properties of local subgraphs
- Core assumption: Target functions exhibit smoothness properties captured by spectral decomposition of graph Laplacian
- Evidence: [abstract] "Through the learning of suitable kernels on graphs, our framework has the advantage of adapting to the behaviour of the target function"
- Break condition: Highly non-smooth or discontinuous functions may not be well-captured by spectral-based kernels

### Mechanism 2
- Claim: Local modeling enables efficient optimization on large-scale and potentially unknown graphs
- Core assumption: Optimal solution can be found through local neighborhood exploration
- Evidence: [abstract] "The local modelling approach further guarantees the efficiency of our method"
- Break condition: If optimal node is far from other high-value nodes, local exploration might miss global optimum

### Mechanism 3
- Claim: Combination of learned kernels and local modeling provides sample-efficient optimization
- Core assumption: Sample efficiency improves when accurate function modeling and efficient search space reduction are achieved simultaneously
- Evidence: [abstract] "Bayesian optimisation is a class of promising black-box solvers with superior sample efficiency"
- Break condition: Poor acquisition function optimization or too small subgraph size may lose sample efficiency gains

## Foundational Learning

- **Gaussian Process regression and kernel methods**
  - Why needed: GP surrogates with appropriate kernels model objective function on graphs
  - Quick check: How does kernel choice affect smoothness assumptions in GP regression?

- **Graph spectral theory and Laplacian matrices**
  - Why needed: Kernel design uses graph Laplacian eigenvalues and eigenvectors for node similarity
  - Quick check: What is the relationship between graph Laplacian spectrum and function smoothness on graphs?

- **Bayesian optimization acquisition functions**
  - Why needed: Acquisition functions balance exploration and exploitation in graph search space
  - Quick check: How does acquisition function value change when GP posterior variance is high versus when mean is low?

## Architecture Onboarding

- **Component map**: Local subgraph construction -> Graph Laplacian computation -> Kernel learning -> GP modeling -> Acquisition optimization -> Function evaluation
- **Critical path**: 1) Construct local subgraph around current best node 2) Compute graph Laplacian and spectrum 3) Learn kernel hyperparameters 4) Fit GP surrogate 5) Optimize acquisition function 6) Evaluate function and update best node 7) Check restart conditions
- **Design tradeoffs**: Local vs global modeling (efficiency vs completeness), kernel expressiveness vs overfitting, subgraph size (structure capture vs computational cost)
- **Failure signatures**: Slow convergence (poor kernel choice or small subgraph), oscillating behavior (acquisition optimization issues), getting stuck in local optima (restart tolerance or subgraph construction)
- **First 3 experiments**: 1) Validate kernel predictive power on synthetic graph functions (eigenvectors of Laplacian) 2) Test local subgraph construction on BA graphs with varying sizes 3) Compare optimisation performance on centrality maximization with different kernel choices

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can BayesOptG be extended to optimise functions defined on edges or hypergraphs?
- Basis: Authors mention possible future work including extensions to edges and hypergraphs
- Why unresolved: Paper only focuses on node-based functions, not exploring edge or hypergraph adaptations
- What evidence would resolve: Framework handling edges/hyperedges as search space validated on relevant tasks

### Open Question 2
- Question: How sensitive is BayesOptG to choice of kernel hyperparameters and local subgraph size?
- Basis: Authors conduct ablation study on hyperparameters like Q, fail_tol, and Î·
- Why unresolved: While study shows robustness, optimal values may depend on specific problems
- What evidence would resolve: Systematic experiments varying hyperparameters across different tasks and graph types

### Open Question 3
- Question: How does BayesOptG perform compared to other graph-based optimisation methods?
- Basis: Authors compare to BFS, DFS, random search, and local search but not graph-specific methods
- Why unresolved: Paper doesn't explore performance against graph neural network or evolutionary algorithm methods
- What evidence would resolve: Benchmarking against graph neural network-based and evolutionary algorithm-based methods

## Limitations

- Local exploration may miss global optima if optimal nodes are far from high-value regions
- Kernel learning sensitivity to initialization and hyperparameter settings could affect reproducibility
- Performance on evolving or time-varying graph structures is not evaluated

## Confidence

- **High confidence**: Theoretical framework is sound and kernel design using spectral properties is well-justified
- **Medium confidence**: Local modeling efficiency gains demonstrated, but dependency on subgraph size parameter needs more analysis
- **Low confidence**: Method's behavior with noisy evaluations or adversarial graph structures is unexplored

## Next Checks

1. Test BayesOptG on graphs with known optimal nodes located far from high-value regions
2. Perform ablation studies comparing different kernel choices while keeping local modeling constant
3. Evaluate performance when graph structure is revealed incrementally versus full knowledge