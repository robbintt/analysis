---
ver: rpa2
title: 'Navigating the Structured What-If Spaces: Counterfactual Generation via Structured
  Diffusion'
arxiv_id: '2312.13616'
source_url: https://arxiv.org/abs/2312.13616
tags:
- counterfactual
- diffusion
- diversity
- counterfactuals
- proximity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SCD, a novel plug-and-play framework that
  leverages diffusion models to generate counterfactual explanations for structured
  data. SCD learns the underlying data distribution via a diffusion model, which is
  then used at test time to generate counterfactuals for any black-box model, input,
  and desired prediction.
---

# Navigating the Structured What-If Spaces: Counterfactual Generation via Structured Diffusion

## Quick Facts
- arXiv ID: 2312.13616
- Source URL: https://arxiv.org/abs/2312.13616
- Authors: 
- Reference count: 40
- Key outcome: SCD achieves higher plausibility (NLL 21.21, 42.37, 42.91) than DiCE (121.0, 166.7, 109.5) while maintaining diversity and proximity without explicit terms.

## Executive Summary
This paper introduces SCD, a novel plug-and-play framework that leverages diffusion models to generate counterfactual explanations for structured data. SCD learns the underlying data distribution via a diffusion model, which is then used at test time to generate counterfactuals for any black-box model, input, and desired prediction. Experiments show that SCD achieves high plausibility compared to existing state-of-the-art methods while also improving proximity and diversity.

## Method Summary
SCD trains a diffusion model on structured data embeddings, then uses guided diffusion to generate counterfactuals that satisfy validity, proximity, and diversity objectives. The method learns row embeddings via learned column dictionaries, denoises them through a diffusion model, and applies gradient updates during sampling to steer toward desired counterfactual labels. By leveraging diffusion models' stochastic denoising, SCD avoids explicit diversity/proximity terms while maintaining high performance across plausibility, diversity, and proximity metrics.

## Key Results
- SCD outperforms DiCE in plausibility with negative log-likelihoods of 21.21, 42.37, and 42.91 versus 121.0, 166.7, and 109.5
- SCD maintains high diversity without explicit diversity loss, unlike DiCE which drops to 0 diversity when diversity term is removed
- SCD achieves better proximity scores without requiring explicit proximity terms in the guiding loss

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SCD leverages diffusion models to learn the underlying data distribution, enabling the generation of highly plausible counterfactual explanations.
- Mechanism: By training a diffusion model on structured data, SCD captures complex relationships among attributes, which guides the generation of counterfactuals that are more likely to conform to the true data distribution.
- Core assumption: The diffusion model can effectively learn the complex, high-dimensional distribution of structured data.
- Evidence anchors:
  - [abstract] "SCD learns the underlying data distribution via a diffusion model which is then used at test time to generate counterfactuals..."
  - [section] "In experiments, we show that our counterfactual explainer not only exhibits high plausibility compared to the state-of-the-art approaches..."
  - [corpus] Weak evidence; neighboring works focus on diffusion in vision or language, not structured data.
- Break condition: If the diffusion model fails to capture the true data distribution, the generated counterfactuals will lack plausibility.

### Mechanism 2
- Claim: The guided diffusion process in SCD naturally promotes diversity among generated counterfactuals without requiring an explicit diversity term.
- Mechanism: The stochastic nature of the denoising process in diffusion models introduces inherent randomness, leading to diverse counterfactual samples even when the diversity loss is removed.
- Core assumption: The stochastic denoising steps in diffusion models are sufficient to produce diverse samples.
- Evidence anchors:
  - [abstract] "our method, due to its unique stochastic denoising process, does not require explicit incentives to generate diverse counterfactuals..."
  - [section] "When we drop the diversity term, we note, remarkably, that the diversity of samples of DiCE drops to 0. In comparison, our counterfactuals maintain high diversity..."
  - [corpus] Moderate evidence; diffusion models are known for generating diverse samples in image domains, but structured data is less explored.
- Break condition: If the diffusion model's stochasticity is insufficient, the generated counterfactuals may collapse to similar instances.

### Mechanism 3
- Claim: SCD maintains high proximity between generated counterfactuals and the original input without requiring an explicit proximity term in the guiding loss.
- Mechanism: The guided diffusion starts from the embedding of the original input, and the denoising process inherently preserves proximity by iteratively refining the sample towards a plausible instance close to the original.
- Core assumption: The diffusion process naturally preserves proximity when starting from the original input embedding.
- Evidence anchors:
  - [abstract] "our method can inherently preserve the contents of the original input without requiring an explicit proximity term in the guiding loss..."
  - [section] "When we drop the proximity term, we note that the scores are not significantly affected. We think this is because, in both SCD and the baseline, the process of generating the counterfactual starts with the original input..."
  - [corpus] Weak evidence; proximity preservation is not a well-studied aspect in diffusion-based counterfactual generation for structured data.
- Break condition: If the diffusion process deviates significantly from the original input, the proximity score will degrade.

## Foundational Learning

- Concept: Diffusion Models
  - Why needed here: SCD uses diffusion models to learn the data distribution of structured data, which is crucial for generating plausible counterfactuals.
  - Quick check question: How does a diffusion model gradually transform noise into a sample from the target distribution?

- Concept: Counterfactual Explanations
  - Why needed here: Understanding counterfactual explanations is essential to grasp SCD's goal of generating alternative scenarios that lead to different model predictions.
  - Quick check question: What are the four key characteristics that counterfactual explanations should possess according to the paper?

- Concept: Structured Data Embeddings
  - Why needed here: SCD encodes structured data into embeddings before applying diffusion modeling, so understanding this transformation is key to the method.
  - Quick check question: How does SCD represent a row of structured data as an embedding?

## Architecture Onboarding

- Component map: Row Embedding Layer -> Diffusion Model -> Guided Diffusion Generator -> Decoder
- Critical path: Row Embedding → Diffusion Model (training) → Guided Diffusion (sampling) → Decoder → Counterfactual Output
- Design tradeoffs:
  - Using diffusion models increases plausibility but requires more computation than simpler generative models.
  - Removing explicit diversity/proximity terms simplifies tuning but relies heavily on the diffusion model's inherent properties.
  - Stochasticity aids diversity but may reduce control over specific counterfactual features.
- Failure signatures:
  - Low plausibility: Diffusion model fails to learn the true data distribution.
  - Low diversity: Stochasticity in denoising is insufficient or overly constrained.
  - Low validity: Gradient updates fail to push samples toward the desired counterfactual label.
- First 3 experiments:
  1. Train the diffusion model on a small structured dataset and generate unconditional samples to check if it learns the distribution.
  2. Use guided diffusion to generate counterfactuals for a simple black-box model and evaluate validity and proximity.
  3. Compare SCD's diversity with and without the diversity loss term to confirm natural diversity generation.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several emerge from the limitations section.

## Limitations
- SCD's performance relies heavily on diffusion models' ability to learn complex structured data distributions without extensive ablation studies on embedding dimensions or architecture choices.
- The comparison with DiCE and Wachter et al. baselines is limited to three datasets, and the robustness to different black-box model architectures remains untested.
- The removal of explicit diversity and proximity terms introduces dependence on diffusion model properties without rigorous validation of failure modes.

## Confidence
- High confidence: Plausibility improvement over baselines (supported by NLL metrics)
- Medium confidence: Diversity and proximity claims (partially supported by comparisons)
- Low confidence: Generalization across datasets and black-box models (limited experimental scope)

## Next Checks
1. Conduct ablation studies varying embedding dimensions and diffusion model architecture to assess impact on plausibility, diversity, and proximity
2. Test SCD's performance across diverse black-box model architectures (e.g., decision trees, random forests, neural networks) to evaluate robustness
3. Evaluate SCD's performance on additional structured datasets with different characteristics (e.g., image embeddings, time series) to assess generalization capabilities