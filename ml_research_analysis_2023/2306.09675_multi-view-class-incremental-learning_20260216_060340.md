---
ver: rpa2
title: Multi-View Class Incremental Learning
arxiv_id: '2306.09675'
source_url: https://arxiv.org/abs/2306.09675
tags:
- learning
- views
- multi-view
- class
- classes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Multi-View Class Incremental Learning (MVCIL),
  a new paradigm for learning from multiple views of data that arrive sequentially
  over time, where the model must incrementally classify new classes without access
  to previous views. The key challenge addressed is catastrophic forgetting of old
  information while learning new concepts.
---

# Multi-View Class Incremental Learning

## Quick Facts
- arXiv ID: 2306.09675
- Source URL: https://arxiv.org/abs/2306.09675
- Reference count: 40
- Primary result: MVCNet achieves 85.56% average accuracy on COIL-20(4), outperforming state-of-the-art methods by 3.19%

## Executive Summary
This paper introduces Multi-View Class Incremental Learning (MVCIL), a new paradigm for learning from multiple views of data that arrive sequentially over time, where the model must incrementally classify new classes without access to previous views. The key challenge addressed is catastrophic forgetting of old information while learning new concepts. The proposed MVCNet addresses this through three phases: randomization-based representation learning using sparse autoencoders with random weights to extract compact features for each new view; orthogonality fusion, which integrates new views in a subspace orthogonal to previously learned views using recursive least squares; and selective weight consolidation using Elastic Weight Consolidation on only the final output layer to accommodate new classes while protecting learned knowledge.

## Method Summary
MVCNet implements a three-phase approach to multi-view class incremental learning. First, it uses randomization-based representation learning with sparse autoencoders containing random weights to extract view-optimal features for each arriving view independently. Second, it applies orthogonality fusion using recursive least squares to integrate new views in a subspace orthogonal to previously learned views, preventing interference with existing knowledge. Third, it applies selective weight consolidation by using Elastic Weight Consolidation only on the final output layer, allowing new classes to modify unimportant weights while protecting learned knowledge. This approach balances plasticity and stability while avoiding the computational burden of full EWC application.

## Key Results
- On COIL-20(4), MVCNet achieves 85.56% average accuracy, outperforming the second-best method by 3.19%
- The method shows strong performance on datasets with limited samples and can generalize to unfamiliar views during inference
- Significant performance gains demonstrated over state-of-the-art methods across multiple datasets including COIL-20, AwA, PIE, and MNIST variants

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Randomization-based representation learning enables view-optimal feature extraction without catastrophic forgetting.
- Mechanism: By using sparse autoencoders with random weights (and biases), the model extracts compact features for each new view independently. The random weights are reset after feature extraction, ensuring they can be reused for subsequent views without being overwritten by gradient updates.
- Core assumption: Random weights can generate sufficiently discriminative features when fine-tuned with sparse reconstruction objectives, and resetting them preserves view-specific optimality.
- Evidence anchors:
  - [abstract] "randomization-based representation learning technique serving for feature extraction to guarantee their separate view-optimal working states"
  - [section 3.1] "we present the randomization-based representation learning for view-level feature extraction, a sparse autoencoder with random weights (and biases)"
  - [corpus] Weak or missing; no direct corpus evidence for this specific mechanism
- Break condition: If random weights consistently fail to generate discriminative features across diverse view types, or if fine-tuning becomes computationally prohibitive for high-dimensional views.

### Mechanism 2
- Claim: Orthogonality fusion integrates new views in a subspace orthogonal to previously learned views, preventing interference.
- Mechanism: The method computes an orthogonal projection matrix that projects weight updates onto the subspace orthogonal to the span of previously extracted features. This ensures new views are integrated without overwriting knowledge from past views.
- Core assumption: The orthogonal subspace exists and can be approximated recursively even as the number of views increases, allowing new views to be fused without catastrophic forgetting.
- Evidence anchors:
  - [abstract] "integrate them one by one in the orthogonality fusion subspace spanned by the extracted features"
  - [section 3.2] "we present an orthogonality fusion strategy for a continual stream of views" and "the weights W 1:v c are updated only in the direction orthogonal to the subspace spanned byZc"
  - [corpus] Weak or missing; no direct corpus evidence for this specific orthogonality fusion mechanism
- Break condition: If the number of views grows large enough that the feature collection becomes full rank, making orthogonal projection impossible or numerically unstable.

### Mechanism 3
- Claim: Selective weight consolidation applies Elastic Weight Consolidation only to the final output layer, balancing plasticity and stability.
- Mechanism: Instead of applying EWC to all layers (which causes inflexibility), the method anchors weights at the latest task and applies Fisher regularization only to the output layer. This allows new classes to modify unimportant weights while protecting learned knowledge.
- Core assumption: The final output layer is where catastrophic forgetting most critically manifests, and selective regularization there provides sufficient protection without excessive rigidity.
- Evidence anchors:
  - [abstract] "selective weight consolidation for learning-without-forgetting decision-making while encountering new classes"
  - [section 3.3] "we measure parameter importance and selectively regularize weights on the decision layer to alleviate catastrophic forgetting" and "only apply the consolidation to the final output layer for decision-making"
  - [corpus] Weak or missing; no direct corpus evidence for this selective EWC application
- Break condition: If catastrophic forgetting manifests primarily in earlier layers rather than the output layer, or if the output layer regularization becomes insufficient for complex multi-view fusion.

## Foundational Learning

- Concept: Incremental learning and catastrophic forgetting
  - Why needed here: MVCIL requires learning new classes from sequential views without forgetting previous ones, directly confronting the catastrophic forgetting problem
  - Quick check question: What happens to a neural network's performance on old tasks when trained on new tasks without any forgetting mitigation?

- Concept: Multi-view learning and feature fusion
  - Why needed here: The method must integrate complementary information from multiple views while maintaining view-specific discriminative power
  - Quick check question: How do traditional multi-view learning methods typically fuse information from different views, and what assumptions do they make about data availability?

- Concept: Orthogonal projection and subspace methods
  - Why needed here: The orthogonality fusion mechanism relies on projecting updates onto subspaces orthogonal to previously learned features
  - Quick check question: What mathematical conditions must hold for a vector to be orthogonal to a given subspace, and how is this computed in practice?

## Architecture Onboarding

- Component map: Randomization-based representation learning -> Orthogonality fusion -> Selective weight consolidation -> View extraction and feature concatenation -> Output layer
- Critical path: 1. Receive new view of data for current class 2. Extract features using randomization-based representation learning 3. Compute orthogonal projection matrix recursively 4. Update weights via orthogonality fusion 5. Apply selective weight consolidation to output layer 6. Make predictions across all seen classes
- Design tradeoffs:
  - Random weights vs. learned weights: Randomization enables view-specific optimality but may sacrifice initial discriminative power
  - Full EWC vs. selective EWC: Selective application reduces computational burden but may provide less comprehensive forgetting protection
  - Recursive vs. batch computation: Recursive computation saves memory but may accumulate numerical errors
- Failure signatures:
  - Performance degradation on old classes when learning new ones (insufficient forgetting protection)
  - Inability to integrate new views effectively (orthogonal projection failing)
  - Poor feature quality from randomization (random weights not generating discriminative features)
- First 3 experiments:
  1. Test randomization-based representation learning on a single view dataset to verify feature quality and view-specific optimality
  2. Validate orthogonality fusion by incrementally adding views and measuring interference with previous knowledge
  3. Evaluate selective weight consolidation by comparing full vs. selective EWC application on class-incremental tasks

## Open Questions the Paper Calls Out

The paper does not explicitly call out specific open questions in the traditional sense. However, several implicit questions arise from the methodology and results that warrant further investigation, particularly regarding the scalability of the approach and the theoretical guarantees of the orthogonality fusion mechanism.

## Limitations

- Lack of ablation studies to isolate the impact of each proposed mechanism on overall performance
- No empirical validation for the specific randomization-based representation learning approach
- Limited discussion of scalability with increasing numbers of classes and views per class

## Confidence

- Overall performance claims: Medium (supported by experimental results but lacking ablation studies)
- Randomization-based representation learning: Low (mechanism not empirically validated)
- Orthogonality fusion: Low (mathematical formulation present but empirical validation limited)
- Selective weight consolidation: Medium (EWC is well-established, but selective application untested)

## Next Checks

1. Conduct ablation studies to quantify the individual contributions of randomization, orthogonality fusion, and selective consolidation to overall performance
2. Test the orthogonality fusion mechanism with varying numbers of views to identify the break condition when the feature collection becomes full rank
3. Evaluate the model's performance on scenarios where old classes reappear after many incremental steps to test long-term forgetting resistance