---
ver: rpa2
title: Incomplete Utterance Rewriting as Sequential Greedy Tagging
arxiv_id: '2307.06337'
source_url: https://arxiv.org/abs/2307.06337
tags:
- utterance
- task
- which
- dialogue
- glcs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SGT, a novel sequence tagging-based model
  for the task of incomplete utterance rewriting (IUR). The key idea is to reformulate
  IUR as a sequence tagging problem, where the model learns to identify and order
  fragments (GLCS) from dialogue history to reconstruct the complete utterance.
---

# Incomplete Utterance Rewriting as Sequential Greedy Tagging

## Quick Facts
- arXiv ID: 2307.06337
- Source URL: https://arxiv.org/abs/2307.06337
- Reference count: 12
- Key outcome: SGT achieves state-of-the-art results on all nine restoration scores while maintaining comparable performance on other metrics and demonstrating faster inference speed.

## Executive Summary
This paper introduces SGT, a novel sequence tagging-based model for the task of incomplete utterance rewriting (IUR). The key idea is to reformulate IUR as a sequence tagging problem, where the model learns to identify and order fragments (GLCS) from dialogue history to reconstruct the complete utterance. The model employs BERT as a contextual encoder, incorporates speaker-aware embeddings to model speaker variations, and utilizes two additional tagging tasks to better capture the span and boundaries of target fragments. Experiments on three public datasets show that SGT achieves state-of-the-art results on all nine restoration scores while maintaining comparable performance on other metrics. Furthermore, SGT demonstrates faster inference speed compared to previous models, making it a promising approach for IUR tasks.

## Method Summary
The SGT model reformulates incomplete utterance rewriting as a sequence tagging problem. It uses BERT to encode dialogue context, concatenates speaker-aware embeddings (one-hot vectors) to distinguish between speakers, and applies three parallel linear layers for the main SGT task plus two auxiliary tasks (GLCS Detection and GLCS Edge Detection). The model identifies longest common subsequences (GLCS) between dialogue history and target utterance through greedy selection, tags tokens with their position in the reconstructed utterance, and uses weighted cross-entropy loss for training. Multi-task learning with auxiliary tasks helps capture span and boundaries of target fragments, while speaker-aware embeddings model speaker variations in multi-turn dialogues.

## Key Results
- Achieves state-of-the-art performance on all nine restoration scores across three public datasets
- Maintains comparable performance on other metrics including BLEU, ROUGE, and exact match
- Demonstrates faster inference speed compared to previous models like RUN

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SGT reformulates IUR as a sequence tagging problem, learning to identify and order fragments (GLCS) from dialogue history.
- Mechanism: The model tags tokens in the dialogue context with labels representing their position in the reconstructed utterance (e.g., A for first fragment, B for second). By greedily selecting the longest common subsequence at each step, it builds the target utterance from context fragments.
- Core assumption: Most complete utterances can be constructed from a small number of contiguous fragments extracted from the dialogue history.
- Evidence anchors:
  - [abstract] "reformulate IUR as a sequence tagging problem, where the model learns to identify and order fragments (GLCS) from dialogue history to reconstruct the complete utterance."
  - [section 3.2] "Specifically, we use the tag type to represent the order of GLCS for composing the target rewrite utterance, For example, the first GLCS that constitutes a rewritten utterance would be tagged as A, and the second is B, the third is C, and so on."
- Break condition: If the target utterance requires non-contiguous or context-dependent word ordering not present in the history, the greedy LCS approach may fail.

### Mechanism 2
- Claim: Speaker-aware embeddings model speaker variations and improve performance.
- Mechanism: A one-hot speaker vector is concatenated with BERT embeddings to distinguish between different speakers in multi-turn dialogues.
- Core assumption: The speaker identity affects how information should be extracted and rewritten in the utterance.
- Evidence anchors:
  - [abstract] "incorporates speaker-aware embeddings to model speaker variations"
  - [section 3.2] "To distinguish utterances between different speakers, our approach stitches a one-dimensional one-hot vector at the hidden dimension with the output representation of the BERT encoder."
- Break condition: If dialogue data lacks clear speaker distinctions or if speaker information is irrelevant to the rewriting task.

### Mechanism 3
- Claim: Two additional tagging tasks (GLCS Detection and GLCS Edge Detection) help capture span and boundaries of target fragments.
- Mechanism: Multi-task learning with binary classification tasks to identify which tokens belong to GLCS and mark token boundaries.
- Core assumption: Explicitly detecting fragment boundaries improves the main sequence tagging task's accuracy.
- Evidence anchors:
  - [abstract] "utilizes two additional tagging tasks to better capture the span and boundaries of target fragments"
  - [section 3.2] "To better lock in the span of target GLCS needed to make up the rewritten utterance, we introduced multi-task learning."
- Break condition: If the additional tasks introduce noise or if the main tagging task already captures boundaries effectively without them.

## Foundational Learning

- Concept: Sequence tagging and labeling
  - Why needed here: SGT converts IUR into a sequence tagging problem where tokens are labeled to indicate their role in the reconstructed utterance
  - Quick check question: What is the difference between sequence classification and sequence tagging?

- Concept: Greedy longest common subsequence (GLCS)
  - Why needed here: The model identifies the longest matching fragments between context and target utterance in a greedy manner
  - Quick check question: How does the greedy approach differ from finding all possible subsequences?

- Concept: Multi-task learning
  - Why needed here: Two auxiliary tasks (GLCS detection and edge detection) are trained alongside the main tagging task to improve performance
  - Quick check question: What are the benefits and potential drawbacks of multi-task learning in this context?

## Architecture Onboarding

- Component map: BERT encoder -> Concatenate with speaker embedding -> Three parallel linear layers (SGT, GLCS Detection, GLCS Edge Detection) -> Combined loss -> Optimization

- Critical path: BERT → Concatenate with speaker embedding → Three parallel linear layers → Combined loss → Optimization

- Design tradeoffs:
  - Using sequence tagging instead of generation reduces search space but requires fragments to exist in context
  - Speaker-aware embedding adds minimal complexity but may not help in all dialogue scenarios
  - Multi-task learning improves performance but increases training complexity

- Failure signatures:
  - Poor restoration scores indicate issues with fragment identification
  - Low EM score suggests incorrect token ordering or missing information
  - Imbalanced tag distribution may cause model to ignore less frequent tags

- First 3 experiments:
  1. Ablation study: Remove speaker-aware embedding to measure its impact
  2. Ablation study: Remove GLCS Detection and GLCS Edge Detection tasks
  3. Inference speed comparison with baseline RUN model on REWRITE dataset

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided text.

## Limitations
- The model's reliance on contiguous fragments from dialogue history may struggle with utterances requiring complex transformations
- Speaker-aware embedding mechanism assumes clear speaker distinctions in the data
- Multi-task learning framework increases training complexity without guarantees of improvement across all domains

## Confidence
- **High confidence** in the core mechanism of reformulating IUR as sequence tagging - the paper provides clear algorithmic descriptions and pseudocode for GLCS extraction, with results consistently showing improvements across all nine restoration scores.
- **Medium confidence** in the effectiveness of speaker-aware embeddings - while the paper claims improved performance, the ablation studies only show relative improvements without absolute performance drops, making it difficult to assess true impact.
- **Medium confidence** in the multi-task learning framework - the paper reports performance improvements with auxiliary tasks, but doesn't adequately address whether the gains justify the increased training complexity.

## Next Checks
1. **GLCS Extraction Algorithm Validation**: Implement and test the GLCS extraction algorithm independently to verify its correctness and efficiency, particularly examining how it handles duplicate matches and different granularity settings across languages.

2. **Speaker Embedding Ablation Impact**: Conduct comprehensive ablation studies measuring absolute performance degradation when removing speaker-aware embeddings across all three datasets, comparing against other dialogue modeling approaches that don't use speaker information.

3. **Inference Speed Benchmarking**: Perform controlled timing experiments comparing SGT's inference speed against RUN and RUN++ on identical hardware, measuring end-to-end processing time for batch sizes ranging from 1 to 128 to verify the claimed efficiency improvements.