---
ver: rpa2
title: 'Towards Trustworthy Explanation: On Causal Rationalization'
arxiv_id: '2306.14115'
source_url: https://arxiv.org/abs/2306.14115
tags:
- rationales
- causal
- rationalization
- cpns
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach called causal rationalization
  for finding trustworthy explanations in natural language processing tasks. The core
  method idea is to leverage two causal desiderata, non-spuriousness and efficiency,
  to identify causal rationales from input texts.
---

# Towards Trustworthy Explanation: On Causal Rationalization

## Quick Facts
- arXiv ID: 2306.14115
- Source URL: https://arxiv.org/abs/2306.14115
- Authors: 
- Reference count: 39
- Key outcome: Novel causal rationalization approach identifies trustworthy explanations by distinguishing causal from spurious correlations, outperforming state-of-the-art methods on review and medical datasets.

## Executive Summary
This paper introduces causal rationalization, a novel approach for finding trustworthy explanations in NLP by leveraging two causal desiderata: non-spuriousness and efficiency. The method formally defines probabilities of causation (POC) based on a structural causal model to identify necessary and sufficient rationales for predictions. Through extensive experiments on real-world review and medical datasets, the approach consistently demonstrates superior performance in prediction accuracy, precision, recall, and F1 score compared to state-of-the-art methods, while providing better clinically meaningful explanations.

## Method Summary
The proposed causal rationalization method introduces a novel approach for finding trustworthy explanations by identifying causal rationales from input texts. It leverages two causal desiderata - non-spuriousness and efficiency - through a structural causal model that formally defines probabilities of causation (POC). The method establishes theoretical identification for learning necessary and sufficient rationales, using a lower bound of CPNS (Probability of Causation - Necessary and Sufficient) as a causality constraint during training. The approach employs BERT-based components for selection and prediction, with Gumbel-Softmax sampling for differentiable selection, optimizing both prediction accuracy and causal relevance.

## Key Results
- Consistently better performance in prediction accuracy, precision, recall, and F1 score on the Beer review dataset compared to state-of-the-art methods
- Superior clinically meaningful explanations on the GA medical dataset
- Better out-of-distribution generalization performance by identifying true rationales rather than spurious correlations
- Effective handling of spurious correlation through CPNS constraint, reducing False Discovery Rate

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Causal rationalization identifies true rationales by distinguishing between correlation and causation, avoiding spurious correlations when multiple input snippets are highly correlated.
- **Mechanism**: The approach introduces two causal desiderata—non-spuriousness and efficiency—by defining probabilities of causation (POC) like CPNS that measure whether selected rationales are both necessary and sufficient for prediction. This allows the model to prefer rationales that causally determine the outcome rather than those merely correlated.
- **Core assumption**: The structural causal model assumes that the outcome Y depends on selected rationales Z ⊙ X, not the full input X, and that potential outcomes are well-defined for counterfactual selections.
- **Evidence anchors**:
  - [abstract] "We formally define a series of probabilities of causation based on a newly proposed structural causal model of rationalization, with its theoretical identification established as the main component of learning necessary and sufficient rationales."
  - [section 4] "Theorem 4.2. Assume the causal diagram in Figure 4 holds... CPNSj can be identified by P(Y=y|Zj=zj,Z-j=z-j,X=x) - P(Y=y|Zj≠zj,Z-j=z-j,X=x)."
  - [corpus] Weak—no direct citations found in related papers, though the topic is similar.
- **Break condition**: If the monotonicity assumption fails or if the causal graph is misspecified (e.g., unobserved confounders exist), the CPNS lower bound may not accurately reflect necessity and sufficiency.

### Mechanism 2
- **Claim**: The CPNS regularizer improves out-of-distribution generalization by selecting rationales that are causally relevant rather than spuriously correlated.
- **Mechanism**: By maximizing the lower bound of CPNS during training, the model favors rationales that maintain predictive power under distribution shift, since spurious correlations are less likely to hold out-of-distribution.
- **Core assumption**: The data-generating process remains stable across training and test distributions for the causal mechanisms, even if spurious correlations change.
- **Evidence anchors**:
  - [section 3.1] "true rationales ({X1, X2}) yield the highest scores of the average CPNS and accuracy in both OOD and ID settings."
  - [section 6.3] "Our method is more robust when handling spurious correlation and shows better generalization performance, which indicates CPNS can help identify true rationales under an out-of-distribution setting."
  - [corpus] Moderate—related works like Chang et al. (2020) and Plyler et al. (2021) address spuriousness but use different causal frameworks.
- **Break condition**: If the distribution shift is so extreme that even causal mechanisms change, or if the lower bound of CPNS becomes uninformative due to violated assumptions, OOD performance may degrade.

### Mechanism 3
- **Claim**: The combined CPNS over selected rationales approximates the causality of the entire rationale set, enabling efficient computation while capturing spillover effects.
- **Mechanism**: Instead of computing CPNS for all 2^r - 1 counterfactuals of a rationale set of size r, the method uses a geometric mean of individual CPNS scores, which approximates the full CPNS under uniform spillover effects or independence.
- **Core assumption**: Spillover effects among selected tokens are uniform or negligible, allowing the geometric mean to serve as a proxy for the joint necessity and sufficiency.
- **Evidence anchors**:
  - [section A.3] "We use the geometric mean because we want CPNS over selected rationales... to be a likelihood... we normalize the likelihood, leading to the geometric mean."
  - [section B] Discusses conditions under which the combined CPNS approximates the full CPNS, including uniform spillover effects or conditional independence.
  - [corpus] Weak—no direct citations, though the approximation approach is reasonable given computational constraints.
- **Break condition**: If spillover effects are highly non-uniform or strong, the geometric mean may poorly approximate the true CPNS, leading to suboptimal rationale selection.

## Foundational Learning

- **Concept**: Probabilities of Causation (POC) and counterfactual reasoning
  - **Why needed here**: POC formalizes the difference between correlation and causation, which is essential for identifying rationales that truly cause the prediction rather than just correlate with it.
  - **Quick check question**: What is the difference between P(Y=y|Z=z) and P(Y(y)=y|Z=z) in the context of rationalization?

- **Concept**: Structural Causal Models (SCM) and do-calculus
  - **Why needed here**: SCM provides the formal framework for modeling the data-generating process and defining interventions on selections Z to compute counterfactual outcomes.
  - **Quick check question**: In the proposed SCM, what are the roles of the exogenous variables NX, NY, NZ, and how do they relate to potential dependence among selections?

- **Concept**: Identification assumptions in causal inference (consistency, ignorability, monotonicity)
  - **Why needed here**: These assumptions allow the theoretical identification of CPNS from observational data, enabling the computation of the lower bound used in training.
  - **Quick check question**: Why is the monotonicity assumption critical for the identification of CPNS, and what happens if it is violated?

## Architecture Onboarding

- **Component map**: Raw input -> Selector (gθ) -> Selected rationales -> Predictor (hϕ) -> Prediction + CPNS estimation -> Loss (prediction + sparsity + CPNS) -> Parameter update

- **Critical path**: Raw input → Selector → Selected rationales → Predictor → Prediction + CPNS estimation → Loss (prediction + sparsity + CPNS) → Parameter update

- **Design tradeoffs**:
  - **Computational cost**: Computing CPNS requires counterfactual predictions for each selected token, making it expensive for long texts; the geometric mean approximation mitigates this.
  - **Sparsity vs. causality**: The sparsity penalty and CPNS constraint may conflict; tuning µ balances rationale brevity with causal relevance.
  - **Assumption reliance**: Heavy reliance on identification assumptions means performance may degrade if assumptions are violated in practice.

- **Failure signatures**:
  - **Low CPNS but high accuracy**: Model may be relying on spurious correlations; check for strong correlations between non-causal tokens and labels.
  - **High CPNS but poor accuracy**: Causality constraint may be too strong, excluding necessary tokens; consider reducing µ.
  - **Training instability**: If monotonicity is frequently violated, the lower bound may be uninformative; monitor CPNS variance across batches.

- **First 3 experiments**:
  1. **Sanity check on synthetic data**: Generate data with known true rationales and spurious correlated tokens; verify CPNS selects true rationales and improves OOD accuracy.
  2. **Ablation on Beer review dataset**: Compare full model with and without CPNS constraint; measure impact on F1 and FDR to assess spuriousness reduction.
  3. **Sensitivity analysis on µ and k**: Vary µ ∈ {0.01, 0.1, 1} and k ∈ {1%, 5%, 10%}; plot accuracy and CPNS to find robust hyperparameter ranges.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- Heavy reliance on identification assumptions (monotonicity, ignorability) that may not hold in real-world scenarios
- Computational cost remains significant for long documents due to CPNS evaluation for each selected token
- Limited evaluation to text classification tasks, leaving generalization to other NLP tasks unclear
- Geometric mean approximation for combined CPNS lacks extensive validation under non-uniform spillover effects

## Confidence
- **High confidence**: The core causal desiderata framework (non-spuriousness and efficiency) and the formal definition of CPNS are well-grounded in causal inference theory. The empirical superiority over baselines on multiple datasets is clearly demonstrated.
- **Medium confidence**: The theoretical identification results hold under stated assumptions, but the practical impact of assumption violations is not thoroughly explored. The approximation method for combined CPNS is reasonable but lacks extensive validation.
- **Low confidence**: The generalizability of results to out-of-distribution settings beyond those tested, and the scalability of the approach to longer documents or more complex tasks, remain uncertain.

## Next Checks
1. **Assumption violation stress test**: Systematically evaluate CPNS performance when monotonicity is violated by introducing heterogeneous treatment effects in synthetic data, measuring how quickly identification breaks down.
2. **Approximation accuracy validation**: Compare geometric mean-based combined CPNS against exact computation (on small subsets) to quantify approximation error and identify conditions where it fails.
3. **Cross-task generalization study**: Apply causal rationalization to a non-classification NLP task (e.g., sentiment transfer or text summarization) to assess whether the causal framework transfers beyond the tested domains.