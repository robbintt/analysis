---
ver: rpa2
title: Computational Dualism and Objective Superintelligence
arxiv_id: '2302.00843'
source_url: https://arxiv.org/abs/2302.00843
tags:
- task
- which
- intelligence
- aixi
- optimal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Computational dualism arises when the behavior of software depends
  on the hardware interpreting it, undermining claims about AI performance. This work
  proposes a pancomputational framework where cognition is formalized as embodied,
  embedded, extended, and enactive behavior within the environment, rather than as
  a disembodied policy.
---

# Computational Dualism and Objective Superintelligence

## Quick Facts
- arXiv ID: 2302.00843
- Source URL: https://arxiv.org/abs/2302.00843
- Reference count: 31
- One-line primary result: Computational dualism undermines objective AI performance claims, but pancomputationalism with weakness-based intelligence measurement enables objectively optimal AGI and ASI.

## Executive Summary
This paper addresses the problem of computational dualism - where AI performance depends on the hardware/interpreter, making objective claims impossible. The authors propose a pancomputational framework where cognition is formalized as embedded behavior in the environment rather than a disembodied policy. Using weakness (cardinality of hypothesis extension) instead of description length as an intelligence proxy enables objective performance claims, leading to theoretically optimal AGI and ASI systems that are computable via search despite being computationally intensive.

## Method Summary
The paper proposes a pancomputational framework where cognition is formalized as embodied, embedded, extended, and enactive behavior within the environment. Rather than treating AI as a disembodied policy, it considers every aspect of the environment as a relation between irreducible states. The method uses weakness (cardinality of a hypothesis' extension) as a proxy for intelligence instead of description length, enabling objective performance claims. This leads to an objectively optimal AGI that selects the weakest hypothesis and ASI that selects the optimal vocabulary for a task, both computable via search.

## Key Results
- Computational dualism undermines objective AI performance claims when behavior depends on hardware/interpreter choice
- Pancomputationalism and enactivism enable objective intelligence measurement through weakness (extension cardinality)
- Objectively optimal AGI (weakest hypothesis selection) and ASI (optimal vocabulary selection) are computable via search but computationally intensive

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Computational dualism undermines objective claims about AI performance.
- Mechanism: AIXI's performance depends on the choice of interpreter (UTM), making any optimality claims subjective.
- Core assumption: The choice of interpreter changes which model is considered most plausible, affecting AIXI's predictions.
- Evidence anchors:
  - [abstract] "The behaviour of software is determined by the hardware that "interprets" it."
  - [section] "AIXI is pareto optimal. However, this claim regarding AIXI's performance is highly subjective, because that performance depends upon the choice of interpreter."
  - [corpus] Weak evidence - only related papers on quantum compilers and strategic behavior mention hardware dependence, but not AIXI specifically.
- Break condition: If a universal interpreter exists that doesn't affect model selection, computational dualism is resolved.

### Mechanism 2
- Claim: Enactivism allows for objective claims about intelligent behavior.
- Mechanism: By treating cognition as embedded in the environment rather than a disembodied policy, performance claims become independent of interpreter choice.
- Core assumption: The boundary between agent and environment is unnecessary and can be discarded.
- Evidence anchors:
  - [abstract] "We propose a pancomputational alternative wherein every aspect of the environment is a relation between irreducible states."
  - [section] "The distinction between mental (software) and physical (hardware) can be discarded."
  - [corpus] Weak evidence - no direct corpus support for enactivism's computational formalization.
- Break condition: If separating agent from environment proves necessary for certain tasks, enactivism may not fully address computational dualism.

### Mechanism 3
- Claim: Weakness (cardinality of extension) is a better proxy for intelligence than description length.
- Mechanism: Selecting the weakest hypothesis maximizes generalization probability, making performance claims objective regardless of vocabulary.
- Core assumption: Minimizing description length doesn't guarantee optimal performance for generalization tasks.
- Evidence anchors:
  - [abstract] "Using weakness (cardinality of a hypothesis' extension) instead of description length as a proxy for intelligence allows for objective performance claims."
  - [section] "The cardinality of the extension |Zm| is called the "weakness" of m. Regardless of the language employed, the weakest model remains the optimal hypothesis."
  - [corpus] No direct corpus evidence for weakness as proxy, but related papers on AI testing mention strategic behavior and generalization.
- Break condition: If a task exists where shortest description length outperforms weakest hypothesis, the claim fails.

## Foundational Learning

- Concept: Kolmogorov Complexity and Universal Turing Machines
  - Why needed here: Understanding why AIXI's performance is subjective requires grasping how KC depends on the UTM choice.
  - Quick check question: Why does changing the UTM affect AIXI's predictions but not the number of errors when predicting deterministic sequences?

- Concept: Enactive cognition and pancomputationalism
  - Why needed here: The paper's solution to computational dualism requires understanding how cognition can be formalized as part of the environment.
  - Quick check question: How does treating everything as computational systems help resolve the software-hardware dependency problem?

- Concept: Extensions and generalizations in formal languages
  - Why needed here: The weakness measure and objective optimality claims depend on understanding extensions and generalization in the formal language framework.
  - Quick check question: Why does maximizing the extension cardinality of a hypothesis maximize generalization probability?

## Architecture Onboarding

- Component map: Implementable languages (H, V, L) -> Tasks (S, D, M) -> Hypothesis selection (maximizing |Zm|) -> AGI/ASI systems (searching models/vocabularies)

- Critical path: From defining implementable languages (H, V, L) to specifying tasks (S, D, M), then selecting the objectively optimal hypothesis (maximizing |Zm|), and finally building AGI/ASI systems that either search through models or vocabularies for optimal performance.

- Design tradeoffs: Finite vocabularies limit what can be represented but make computation tractable. Binary correctness simplifies task definitions but may miss nuanced performance measures. Anytime computable ASI sacrifices optimality for tractability.

- Failure signatures: If changing the interpreter still affects performance claims, the enactivist framework has failed. If minimum description length outperforms weakness for certain tasks, the proxy is invalid. If the weakest hypothesis search becomes intractable for practical applications, the approach is limited.

- First 3 experiments:
  1. Implement a simple implementable language and test whether changing the vocabulary affects the objectively optimal hypothesis selection.
  2. Compare performance of weakest hypothesis selection versus minimum description length on a set of benchmark generalization tasks.
  3. Build a prototype AGI that searches for optimal hypotheses given a task specification and measure its generalization performance against standard approaches.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the computational complexity of finding the objectively optimal AGI (selecting the weakest hypothesis) scale with the size of the task and vocabulary?
- Basis in paper: [explicit] The paper states that the weakest model is computable via search but notes that such an approach is computationally complex.
- Why unresolved: The paper mentions computational complexity but does not provide specific analysis of how the search complexity scales with problem size.
- What evidence would resolve it: Empirical studies showing search time for different task sizes and vocabularies, or theoretical analysis of the search space complexity.

### Open Question 2
- Question: Can the pancomputational framework handle continuous environments, or is it limited to discrete symbol manipulation?
- Basis in paper: [inferred] The framework is built on formal languages and sets of statements, which suggests discrete representation, but the paper doesn't explicitly address continuous domains.
- Why unresolved: The paper focuses on formalizing cognition using discrete computational elements without discussing how to handle continuous variables or real-valued states.
- What evidence would resolve it: Demonstrations of the framework working with continuous control tasks or formal proofs about extending the framework to continuous domains.

### Open Question 3
- Question: How does the framework account for tasks where the correct decisions (D) are not fully known or are probabilistic rather than binary?
- Basis in paper: [explicit] The paper defines tasks with binary correctness and assumes complete knowledge of correct decisions, but acknowledges this is a simplification.
- Why unresolved: Real-world tasks often involve uncertainty, graded outcomes, and incomplete knowledge of what constitutes correct behavior.
- What evidence would resolve it: Extensions of the framework to handle probabilistic task definitions or empirical validation on tasks with uncertain reward structures.

## Limitations
- Computational complexity of searching for weakest hypotheses may limit practical applications
- Discrete framework may not handle continuous environments effectively
- Binary correctness assumption may oversimplify real-world tasks

## Confidence
- Computational dualism mechanism: Low-Medium - Theoretical foundation is strong, but practical implications need verification
- Enactivism as solution: Medium - Novel formalization but lacks empirical validation
- Weakness measure validity: Medium - Theoretically sound but untested on real benchmarks

## Next Checks
1. Benchmark comparison: Implement a controlled experiment comparing weakness-based hypothesis selection against minimum description length approaches on standard generalization tasks (MNIST, CIFAR-10 variants). Measure both accuracy and robustness to vocabulary changes.

2. Interpreter dependency test: Design a task where multiple interpreters produce different optimal models under traditional AIXI, then verify whether the enactivist formulation yields consistent results across all interpreters.

3. Computational tractability analysis: Profile the search complexity for weakest hypothesis selection on increasingly complex tasks, determining the practical limits of the proposed AGI/ASI architectures and identifying potential approximation strategies.