---
ver: rpa2
title: Learning Reliable Logical Rules with SATNet
arxiv_id: '2310.02133'
source_url: https://arxiv.org/abs/2310.02133
tags:
- rules
- satnet
- logical
- maxsat
- formula
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework to extract interpretable and
  verifiable logical rules from SATNet, a differentiable MaxSAT solver. SATNet learns
  logical rules but produces weights that are not easily interpretable as human-readable
  rules.
---

# Learning Reliable Logical Rules with SATNet

## Quick Facts
- arXiv ID: 2310.02133
- Source URL: https://arxiv.org/abs/2310.02133
- Reference count: 37
- Key outcome: Framework extracts interpretable logical rules from SATNet with 100% accuracy using exact solvers

## Executive Summary
This paper addresses the challenge of making SATNet's learned weights interpretable as human-readable logical rules. SATNet is a differentiable MaxSAT solver that learns clause weights from examples, but its continuous outputs are not easily convertible to propositional logic. The authors introduce a "maximum equality" specification method that transforms SATNet's learned matrix C into a weighted MaxSAT formula representing explicit logical rules. They also develop verification techniques to validate the correctness of these decoded rules against ground truth rules, achieving perfect accuracy on stream transformations and Sudoku problems.

## Method Summary
The method trains SATNet to learn a clause weight matrix S from input-output examples, then transforms the learned matrix C=ST*S into interpretable weighted MaxSAT formulas using maximum equality specification. Domain knowledge can be incorporated as additional constraints or additive weights. The framework uses exact solvers (Gurobi) for inference on new instances and employs functional equivalence verification to validate decoded rules against ground truth. The approach is tested on stream transformations (parity, addition, counting) and Sudoku puzzles (4x4, 9x9), demonstrating superior accuracy compared to SATNet's original inference.

## Key Results
- Decoded logical rules achieve 100% accuracy on test sets when using exact solvers
- Original SATNet fails to give correct solutions in many cases, while the decoded rules succeed
- Framework formally verifies that decoded logical rules are functionally equivalent to ground truth rules
- Domain knowledge integration improves rule reliability and enables verification

## Why This Works (Mechanism)

### Mechanism 1
SATNet's learned matrix C=ST*S encodes similarity relationships between variables. By minimizing weighted dot products vT_i vj, SATNet implicitly maximizes equality Î´(z_i, z_j) between binary assignments, allowing conversion to weighted MaxSAT clauses that represent logical rules. The core assumption is that dot products serve as valid relaxation of Kronecker delta for binary variables.

### Mechanism 2
Domain knowledge can be added as constraints to the weighted MaxSAT formula or as additive weights to matrix C. This integration improves rule reliability and enables verification against ground truth. The core assumption is that domain knowledge constraints are logically consistent with learned rules.

### Mechanism 3
The maximum equality formulation has sufficient expressive power to represent any propositional logical rules. Any propositional formula can be reduced to Max2SAT, which can then be transformed into maximum equality clauses using auxiliary variables. The core assumption is that the reduction preserves logical equivalence through proper weighting.

## Foundational Learning

- **Concept**: Semidefinite programming relaxation
  - Why needed here: SATNet uses SDP relaxation to make MaxSAT problem differentiable and learnable through gradient descent
  - Quick check question: How does relaxing Boolean variables to unit vectors enable gradient-based optimization in SATNet?

- **Concept**: Weighted MaxSAT formulation
  - Why needed here: Decoded logical rules are expressed as weighted MaxSAT formulas, combining hard constraints (must be satisfied) and soft constraints (optimize satisfaction)
  - Quick check question: What is the difference between hard constraints and soft constraints in a weighted MaxSAT problem?

- **Concept**: Functional equivalence verification
  - Why needed here: Since decoded rules are in weighted MaxSAT form while ground truth is in SAT form, verification requires comparing their solution spaces under functional equivalence definitions
  - Quick check question: Why can't we directly compare the weighted MaxSAT formula with the SAT formula using standard logical equivalence?

## Architecture Onboarding

- **Component map**: SATNet -> Maximum equality specification -> Exact solver (Gurobi) -> Verification module -> Domain knowledge integrator

- **Critical path**: 
  1. Train SATNet on input-output examples to learn matrix C
  2. Apply maximum equality specification to convert C to weighted MaxSAT formula
  3. Use exact solver for inference on new instances
  4. Verify decoded rules against ground truth using functional equivalence

- **Design tradeoffs**:
  - Sparsity vs. expressiveness: Sparser C matrices reduce computational cost but may lose rule accuracy
  - Auxiliary variables: More auxiliary variables increase expressive power but complicate verification
  - Domain knowledge integration: Early integration improves learning but may bias results; late integration maintains flexibility but requires post-processing

- **Failure signatures**:
  - SATNet training fails to converge or achieves low accuracy on training data
  - Decoded weighted MaxSAT formula produces incorrect solutions on test instances
  - Verification fails to establish functional equivalence between decoded and ground truth rules
  - Exact solver takes excessive time or fails to find solutions for large instances

- **First 3 experiments**:
  1. Train SATNet on parity function with 20-bit input, decode rules, verify functional equivalence with ground truth
  2. Apply domain knowledge integration to 4x4 Sudoku decoding and verify sufficient condition for general functional equivalence
  3. Test IHT sparsification on 9x9 Sudoku C matrix and measure impact on solving accuracy and verification time

## Open Questions the Paper Calls Out

### Open Question 1
Can the framework be extended to learn and verify rules in first-order or higher-order logic beyond propositional logic? The authors acknowledge this as a limitation but do not explore how to extend the framework to more expressive logical representations.

### Open Question 2
How can the computational efficiency of the framework be improved when dealing with large numbers of variables (n) that result in O(n^2) clauses? While the authors mention exploring alternative optimization approaches, they do not provide specific solutions or experimental results demonstrating improved efficiency.

### Open Question 3
How robust is the framework to noisy or incomplete data when learning logical rules? The paper does not explicitly address the framework's performance on noisy or incomplete datasets, but this is a common concern in machine learning and rule learning applications.

## Limitations

- SATNet's learned weights are not inherently interpretable without the proposed maximum equality transformation
- The conversion relies on SDP relaxation accurately capturing binary relationships, which may fail for complex logical rules
- Functional equivalence verification assumes access to ground truth rules, which may not always be available in real-world applications

## Confidence

- **High Confidence**: The mechanism of maximum equality specification for transforming SATNet weights to weighted MaxSAT formulas, and the experimental demonstration of improved accuracy using exact solvers
- **Medium Confidence**: The formal proof of expressive power for arbitrary propositional logic rules, as this depends on the reduction to Max2SAT being correctly implemented
- **Medium Confidence**: The domain knowledge integration framework, as the paper shows it works but doesn't extensively test edge cases where domain knowledge might conflict with learned rules

## Next Checks

1. **Ablation Study on SDP Relaxation Quality**: Systematically vary the SDP relaxation parameters and measure how the quality of decoded logical rules degrades, establishing the sensitivity of the maximum equality transformation to approximation errors.

2. **Stress Test with Larger Problem Instances**: Apply the framework to significantly larger logical problems (e.g., 100+ bit parity functions or larger Sudoku variants) to evaluate scalability and identify breaking points in the verification process.

3. **Domain Knowledge Conflict Resolution**: Design experiments where domain knowledge explicitly contradicts learned rules, then test whether the framework can detect such conflicts and gracefully handle inconsistent information.