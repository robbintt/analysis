---
ver: rpa2
title: Wider and Deeper LLM Networks are Fairer LLM Evaluators
arxiv_id: '2308.01862'
source_url: https://arxiv.org/abs/2308.01862
tags:
- evaluation
- network
- each
- neurons
- neuron
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a multi-layer wide network design for LLM evaluation.
  Each neuron in the network has a distinct role, and multiple neurons interact and
  collaborate, much like in deep neural networks.
---

# Wider and Deeper LLM Networks are Fairer LLM Evaluators

## Quick Facts
- arXiv ID: 2308.01862
- Source URL: https://arxiv.org/abs/2308.01862
- Authors: 
- Reference count: 40
- A two-layer wider LLM network significantly improves evaluation accuracy and reduces annotation costs by 60% compared to single-layer evaluators

## Executive Summary
This paper introduces a multi-layer wide network design for LLM evaluation where each neuron has a distinct role, inspired by how different neurons in neural networks detect different concepts. The architecture follows a feedforward approach where neurons in each layer receive inputs from the previous layer, integrating and abstracting evaluation information. Through extensive experiments on multiple benchmarks including the newly introduced LLMEval2, the authors demonstrate that a two-layer wider network yields the best results, enhancing the ability of LLMs to evaluate generated text quality. The approach proves particularly effective for Chinese LLM evaluation, achieving 4.6x speedup and 60% cost reduction compared to traditional human annotation.

## Method Summary
The method employs a multi-layer wide LLM network where each neuron evaluates candidate responses based on a distinct perspective or role. For each evaluation sample, the LLM first generates candidate evaluation perspectives, which are then assigned to neurons in the first layer. Each neuron evaluates responses based on its assigned perspective, and subsequent layers integrate these evaluations by receiving representations from all neurons in the previous layer. The final assessment is obtained through aggregation strategies such as averaging scores or voting across neurons. The approach is evaluated on multiple benchmarks including FairEval, PandaLM, and LLMEval2, demonstrating significant improvements in evaluation accuracy and fairness compared to single-layer evaluators.

## Key Results
- Two-layer wider LLM networks achieve the best performance, with accuracy improving from 71.90% to 78.40% on FairEval
- The approach achieves 4.6x speedup and 60% cost reduction for Chinese LLM evaluation compared to human annotation
- Aggregating results using voting strategy performs better than averaging, with accuracy improving from 71.90% to 78.40% on FairEval
- The method shows strong generalization across multiple benchmarks and outperforms existing LLM evaluators

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Assigning distinct roles to neurons (perspectives) in the first layer improves evaluation fairness by focusing each neuron on specific quality dimensions.
- Mechanism: The LLM generates diverse evaluation perspectives (e.g., coherence, relevance) for each sample. Each neuron is then assigned a specific perspective, ensuring that evaluations are not redundant and cover multiple quality dimensions.
- Core assumption: Different evaluation dimensions are necessary for comprehensive assessment and that a single fixed perspective is insufficient.
- Evidence anchors: [abstract] "inspired by the observation that different neurons in a neural network are responsible for detecting different concepts"; [section 3.1] "we first ask the LLM about the candidate perspectives that could be used to assess the sample quality"
- Break condition: If generated perspectives are too similar or redundant, the benefit of diverse roles diminishes.

### Mechanism 2
- Claim: Stacking layers allows subsequent neurons to integrate and abstract evaluation information from previous layers, leading to more comprehensive assessments.
- Mechanism: Each layer receives representations from all neurons in the previous layer, allowing higher layers to synthesize local evaluations into more global judgments.
- Core assumption: Higher layers in neural networks capture more comprehensive features by combining lower-level features.
- Evidence anchors: [abstract] "each layer receives representations from all neurons in the previous layer, integrating the locally learned evaluation information"; [section 3.1] "each layer receives representations from all neurons in the previous layer, integrating and abstracting the previously learned local evaluation information"
- Break condition: If deeper layers do not effectively integrate information or if the integration prompt is poorly designed.

### Mechanism 3
- Claim: Aggregation strategies (averaging vs. voting) determine how final evaluation decisions are made from multiple neuron outputs.
- Mechanism: Two aggregation methods are used: averaging scores across all neurons for each response, or voting where each neuron chooses the better response and the majority wins.
- Core assumption: Different aggregation strategies may be more appropriate depending on the evaluation context and desired fairness.
- Evidence anchors: [section 3.1] "The strategies employed in this study include: (1) Averaging the scores from all neurons in the network for each response and subsequently comparing the average scores of the responses to determine which is better (c∗1). (2) Comparing the evaluation scores of the responses from each neuron to choose the better one, and then voting over neurons in all layers or each layer (c∗2)."
- Break condition: If aggregation strategy does not align with human evaluation preferences or if it amplifies biases present in individual neuron evaluations.

## Foundational Learning

- Concept: Feedforward neural network architecture
  - Why needed here: Understanding how information flows through layers is crucial for grasping how the LLM network processes evaluations.
  - Quick check question: In a feedforward network, does information flow backward from output to input during inference?

- Concept: Neuron specialization and feature abstraction
  - Why needed here: The paper's core innovation relies on assigning different roles to neurons and having layers abstract information, concepts from deep learning theory.
  - Quick check question: Do neurons in deeper layers of a neural network typically learn more abstract or more specific features compared to earlier layers?

- Concept: Evaluation metrics (accuracy, F1, kappa)
  - Why needed here: The paper reports results using these metrics, and understanding them is essential for interpreting the performance improvements.
  - Quick check question: What does a kappa correlation coefficient measure in the context of inter-rater agreement?

## Architecture Onboarding

- Component map:
  Input layer -> Neuron role generation -> First layer neurons (assigned perspectives) -> Subsequent layers (integrate evaluations) -> Aggregation layer (averaging/voting) -> Output

- Critical path:
  1. Generate evaluation perspectives for the sample
  2. Assign each perspective to a neuron in the first layer
  3. Each neuron evaluates responses based on its perspective
  4. Subsequent layers integrate previous evaluations
  5. Aggregate results to produce final decision

- Design tradeoffs:
  - Wider networks (more neurons) vs. computational cost
  - Deeper networks (more layers) vs. potential information homogeneity
  - Diverse perspectives vs. evaluation consistency
  - Averaging vs. voting aggregation strategies

- Failure signatures:
  - Performance degrades with too many layers (information becomes homogeneous)
  - No improvement when increasing neurons beyond a certain point
  - Generated perspectives are too similar or redundant
  - Aggregation strategy amplifies position bias or other systematic errors

- First 3 experiments:
  1. Test with fixed 2-layer network but varying number of neurons per layer (1, 2, 3, 4, unlimited)
  2. Compare aggregation strategies (averaging vs. voting) on a small dataset
  3. Evaluate performance with and without neuron role generation on the same samples

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the wider and deeper LLM network vary with different LLM models used as neurons?
- Basis in paper: [explicit] The paper uses gpt-3.5-turbo as the LLM neuron for main experiments due to cost constraints, but does not explore the impact of different LLM models on performance.
- Why unresolved: The paper focuses on the architectural design of the network and its impact on evaluation performance, but does not investigate how different LLM models as neurons might affect the results.
- What evidence would resolve it: Conduct experiments using different LLM models as neurons in the wider and deeper network, and compare their performance in terms of accuracy, F1 score, and kappa correlation coefficient.

### Open Question 2
- Question: What is the optimal number of layers and neurons in the wider and deeper LLM network for achieving the best evaluation performance?
- Basis in paper: [explicit] The paper observes that a two-layer wider LLM network performs the best, but it does not explore the optimal number of layers and neurons in detail.
- Why unresolved: The paper demonstrates the effectiveness of a two-layer network but does not provide a comprehensive analysis of how varying the number of layers and neurons impacts the evaluation performance.
- What evidence would resolve it: Perform extensive experiments by varying the number of layers and neurons in the network, and analyze the performance trends to identify the optimal configuration.

### Open Question 3
- Question: How does the wider and deeper LLM network perform in evaluating responses generated by other language models, such as GPT-4 or other open-source models?
- Basis in paper: [inferred] The paper focuses on evaluating responses generated by Vicuna-13b, ChatGPT, and other models, but does not explicitly explore the performance of the wider and deeper network in evaluating responses from different language models.
- Why unresolved: The paper demonstrates the effectiveness of the wider and deeper network in evaluating responses from specific models, but does not provide insights into its generalizability across different language models.
- What evidence would resolve it: Conduct experiments using the wider and deeper network to evaluate responses generated by various language models, including GPT-4 and other open-source models, and compare the performance across different models.

## Limitations
- The optimal network depth and width remain unclear - while the paper claims 2-layer wider networks perform best, the experimental design doesn't systematically explore configurations beyond this point.
- The neuron role generation process is critical but underspecified, with no validation of role quality or analysis of potential biases in generated perspectives.
- The aggregation strategy comparison shows voting performs better, but the paper doesn't analyze when each strategy might be preferable or how they handle edge cases.

## Confidence

- High Confidence: The core finding that multi-layer wide networks outperform single-layer evaluators on the tested benchmarks.
- Medium Confidence: The claim about specific performance improvements (4.6x speedup, 60% cost reduction) - these depend heavily on implementation details.
- Medium Confidence: The assertion that wider networks are universally "fairer" - fairness is context-dependent and the paper doesn't establish cross-domain generalization.

## Next Checks
1. **Depth-Width Tradeoff Analysis**: Systematically test network configurations beyond 2 layers with varying neuron counts to establish where performance plateaus or degrades.
2. **Role Quality Validation**: Implement a human evaluation study to assess the quality, diversity, and bias of automatically generated neuron roles across different evaluation domains.
3. **Cross-Domain Generalization**: Test the evaluator on datasets outside the current benchmarks (e.g., different languages, domains, or task types) to verify the claimed fairness improvements aren't benchmark-specific.