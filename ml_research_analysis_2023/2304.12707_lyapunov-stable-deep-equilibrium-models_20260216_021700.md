---
ver: rpa2
title: Lyapunov-Stable Deep Equilibrium Models
arxiv_id: '2304.12707'
source_url: https://arxiv.org/abs/2304.12707
tags:
- adversarial
- lyapunov
- neural
- lyadeq
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LyaDEQ, a robust variant of Deep Equilibrium
  (DEQ) models that leverages Lyapunov theory to improve adversarial robustness. The
  key idea is to treat DEQ models as nonlinear dynamic systems and ensure the stability
  of their fixed points using a Lyapunov function.
---

# Lyapunov-Stable Deep Equilibrium Models

## Quick Facts
- **arXiv ID**: 2304.12707
- **Source URL**: https://arxiv.org/abs/2304.12707
- **Reference count**: 40
- **Primary result**: LyaDEQ improves adversarial robustness on MNIST, SVHN, and CIFAR10/100 datasets with up to 19.25% accuracy gains under PGD attacks.

## Executive Summary
This paper introduces LyaDEQ, a robust variant of Deep Equilibrium (DEQ) models that leverages Lyapunov stability theory to improve adversarial robustness. By treating DEQ models as nonlinear dynamic systems and ensuring their fixed points are Lyapunov stable, the method guarantees that minor input perturbations won't significantly affect model outputs. The approach combines a Lyapunov stability module with orthogonalization to separate class-specific fixed points, achieving substantial robustness improvements across multiple datasets while maintaining compatibility with other defense methods.

## Method Summary
The method treats DEQ models as nonlinear dynamic systems and ensures their fixed points are Lyapunov stable by jointly learning a convex positive definite Lyapunov function and constraining the dynamics accordingly. An orthogonal fully connected layer is added after the Lyapunov stability module to increase the distance between stable fixed points corresponding to different classes. The architecture integrates with existing DEQ frameworks and can be combined with adversarial training methods for enhanced robustness.

## Key Results
- LyaDEQ achieves 19.25% higher accuracy than baseline DEQ under PGD attacks on CIFAR10
- Outperforms IBP-MonDEQ on multiple datasets including MNIST, SVHN, and CIFAR10/100
- Maintains compatibility with adversarial training methods, showing further improvements when combined

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The DEQ model's fixed point is stabilized against adversarial perturbations via Lyapunov stability.
- **Mechanism**: The Lyapunov stability module jointly learns a convex positive definite Lyapunov function V(z) and constrains the dynamics so that dV/dt ≤ -c·V(z) everywhere in state space. This ensures that any perturbed fixed point remains within the same stable neighborhood as the unperturbed point, preventing successful adversarial attacks.
- **Core assumption**: The Lyapunov function V(z) can be effectively parameterized as an input-convex neural network (ICNN) with positive weights and convex non-decreasing activation functions.
- **Evidence anchors**:
  - [abstract] "The crux of our method is ensuring the fixed points of the DEQ models are Lyapunov stable, which enables the LyaDEQ models to resist minor initial perturbations."
  - [section] "We ensure the robustness of the DEQ model by jointly learning a convex positive definite Lyapunov function along with dynamics constrained to be stable according to these dynamics everywhere in the state space."
- **Break condition**: If the Lyapunov function fails to satisfy the positive definiteness or strict decrease conditions, the stability guarantee breaks down.

### Mechanism 2
- **Claim**: Orthogonalization separates fixed points for different classes, preventing closely located stable neighborhoods.
- **Mechanism**: After the Lyapunov stability module produces stable fixed points, an orthogonal fully connected layer is added that enforces ZT·Z = I. This increases the distance between fixed points corresponding to different classes, preventing small perturbations from causing misclassification due to overlapping stable neighborhoods.
- **Core assumption**: Class-specific fixed points exist and can be separated by orthogonalization without destroying the Lyapunov stability properties.
- **Evidence anchors**:
  - [abstract] "To avoid poor adversarial defense due to Lyapunov-stable fixed points being located near each other, we orthogonalize the layers after the Lyapunov stability module to separate different fixed points."
  - [section] "We add an orthogonal FC layer after the Lyapunov stability module to increase the distance between Lyapunov stable equilibrium points."
- **Break condition**: If the orthogonalization significantly perturbs the fixed points beyond the stable neighborhood boundaries, stability may be compromised.

### Mechanism 3
- **Claim**: LyaDEQ can be combined with adversarial training methods for enhanced robustness.
- **Mechanism**: The Lyapunov stability framework provides a foundational robustness property that is orthogonal to other defense mechanisms. When combined with adversarial training methods like TRADES, robust dataset training, or PGD-AT, the model benefits from both the stability guarantees and the additional adversarial exposure during training.
- **Core assumption**: The stability properties learned via Lyapunov theory do not conflict with adversarial training objectives.
- **Evidence anchors**:
  - [abstract] "Furthermore, we show that the LyaDEQ model can be combined with other defense methods, such as adversarial training, to achieve even better adversarial robustness."
  - [section] "Our method is orthogonal to other adversarial defense methods, such as adversarial training, which means we can combine the LyaDEQ model with adversarial training to achieve further defense performance."
- **Break condition**: If adversarial training objectives directly conflict with maintaining Lyapunov stability, the combined approach may fail.

## Foundational Learning

- **Concept: Lyapunov Stability Theory**
  - Why needed here: Provides the mathematical framework for certifying that small perturbations to inputs won't significantly change the model's output fixed point.
  - Quick check question: What are the three conditions required for a function V(z) to be a Lyapunov function for a fixed point?

- **Concept: Deep Equilibrium Models**
  - Why needed here: Understanding how DEQs find fixed points through root-finding rather than explicit layer stacking is essential for integrating Lyapunov stability.
  - Quick check question: How does a DEQ model differ from a traditional deep neural network in terms of architecture?

- **Concept: Input-Convex Neural Networks (ICNNs)**
  - Why needed here: The Lyapunov function must be convex in the state variable z, which is achieved through ICNN parameterization.
  - Quick check question: What constraint must be placed on the weights of an ICNN to ensure convexity in the input variable?

## Architecture Onboarding

- **Component map**: Feature Extractor (FCN or ResNet) -> DEQ Model (implicit layer) -> Lyapunov Stability Module (ICNN) -> Orthogonal FC Layer -> Classification

- **Critical path**: Input -> Feature Extractor -> DEQ -> Lyapunov Stability -> Orthogonalization -> Classification

- **Design tradeoffs**:
  - Stability vs. accuracy: Stronger stability constraints may limit model expressiveness
  - Orthogonalization vs. stability: The orthogonal layer must not violate Lyapunov conditions
  - Computational cost: ICNN parameterization adds overhead to fixed point finding

- **Failure signatures**:
  - Reduced accuracy on clean data indicates over-constrained stability
  - Degraded robustness suggests Lyapunov conditions are not properly satisfied
  - Training instability indicates ICNN parameterization issues

- **First 3 experiments**:
  1. Verify Lyapunov stability on synthetic data with known stable/unstable fixed points
  2. Test orthogonalization effect by visualizing fixed point separation with t-SNE
  3. Compare robustness against I-FGSM and PGD attacks with varying perturbation magnitudes

## Open Questions the Paper Calls Out

- **Open Question 1**: Can Lyapunov stability theory be effectively extended to guarantee general stable invariant sets in DEQ models, rather than just equilibrium points?
  - **Basis in paper**: The authors note that Lyapunov theory is limited to handling finite equilibria and is not suitable for guaranteeing general stable invariant sets, which are common in physics and biology applications.
  - **Why unresolved**: The paper focuses on equilibrium points as the target of stability, and does not explore how to handle more complex invariant sets like limit cycles or line attractors.
  - **What evidence would resolve it**: Successful extension of Lyapunov-based methods to handle general invariant sets in DEQ models, with experimental validation on tasks involving such sets.

- **Open Question 2**: How does the choice of orthogonalization technique affect the separation of Lyapunov-stable fixed points in different classes, and what is the optimal method?
  - **Basis in paper**: The authors introduce an orthogonal FC layer to increase the distance between Lyapunov-stable fixed points for different classes, but do not explore the impact of different orthogonalization techniques.
  - **Why unresolved**: The paper only uses a single orthogonal FC layer without comparing it to other orthogonalization methods or analyzing its optimal configuration.
  - **What evidence would resolve it**: Comparative study of different orthogonalization techniques on DEQ models, demonstrating which method provides the best separation of fixed points for classification tasks.

- **Open Question 3**: What is the theoretical relationship between the stable neighborhood size of fixed points in LyaDEQ and the model's robustness to adversarial attacks of varying magnitudes?
  - **Basis in paper**: The authors suggest that Lyapunov stability keeps perturbed fixed points within the same stable neighborhood, but do not provide a formal analysis of how neighborhood size relates to robustness against attacks of different strengths.
  - **Why unresolved**: The paper presents empirical results showing improved robustness but lacks a theoretical framework linking stable neighborhood size to attack resistance.
  - **What evidence would resolve it**: Mathematical analysis establishing the relationship between stable neighborhood size and adversarial robustness, validated through experiments on DEQ models with varying neighborhood sizes.

## Limitations
- The orthogonalization technique's effectiveness lacks sufficient empirical validation
- Limited ablation studies on component contributions to overall robustness
- Claims about combined method effectiveness need more detailed analysis

## Confidence
- **High confidence**: The core Lyapunov stability framework for DEQs is mathematically sound and the general approach of using stability theory for adversarial robustness is well-established in control theory.
- **Medium confidence**: The implementation details of the ICNN and orthogonalization layers appear reasonable, though some specifics are unclear. The experimental results show consistent improvements across datasets.
- **Low confidence**: The claims about orthogonalization benefits and combined method effectiveness lack sufficient empirical validation.

## Next Checks
1. **Stability verification test**: Create a synthetic DEQ model with known stable/unstable fixed points and verify that the Lyapunov module correctly identifies and stabilizes them under perturbations.

2. **Orthogonalization ablation**: Remove the orthogonal FC layer and measure the exact degradation in robustness. Compare t-SNE visualizations of fixed points with and without orthogonalization to quantify separability improvements.

3. **Combined method stress test**: Systematically vary the strength of adversarial training (different PGD iterations, perturbation magnitudes) and measure how LyaDEQ's stability interacts with these different training regimes to identify potential conflicts or synergies.