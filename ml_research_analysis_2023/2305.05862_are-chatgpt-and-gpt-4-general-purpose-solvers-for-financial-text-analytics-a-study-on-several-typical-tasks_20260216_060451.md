---
ver: rpa2
title: Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics?
  A Study on Several Typical Tasks
arxiv_id: '2305.05862'
source_url: https://arxiv.org/abs/2305.05862
tags:
- chatgpt
- gpt-4
- tasks
- dataset
- nancial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper examines ChatGPT and GPT-4''s performance on four financial
  text analytics tasks: sentiment analysis, arithmetic reasoning, text classification,
  and question-answering. Using five benchmark datasets, the study compares zero-shot
  and few-shot learning performance against fine-tuned and domain-specific models.'
---

# Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? A Study on Several Typical Tasks

## Quick Facts
- arXiv ID: 2305.05862
- Source URL: https://arxiv.org/abs/2305.05862
- Reference count: 6
- GPT-4 outperforms BloombergGPT on numerical reasoning but struggles with sentiment analysis and NER

## Executive Summary
This paper evaluates ChatGPT and GPT-4 on four financial text analytics tasks using five benchmark datasets. The study compares zero-shot and few-shot learning performance against fine-tuned and domain-specific models. While GPT-4 demonstrates strong performance on numerical reasoning tasks, outperforming BloombergGPT, it still lags behind specialized models like FinBert and FinQANet on sentiment analysis and named entity recognition. The results highlight the limitations of general-purpose LLMs in handling domain-specific knowledge and terminology in financial text analytics.

## Method Summary
The study evaluates ChatGPT and GPT-4 on financial text analytics tasks using five benchmark datasets: FinQA, ConvFinQA, Headlines, Financial PhraseBank, and NER. The evaluation employs zero-shot and few-shot learning approaches with prompts tailored to each task. Performance is measured using accuracy, macro F1 score, and weighted F1 score. The models are accessed via API using 'gpt-3.5-turbo' and 'GPT-4(8k)' versions and compared against fine-tuned models like FinBert and BloombergGPT.

## Key Results
- GPT-4 achieves 62.87% accuracy on numerical reasoning, outperforming BloombergGPT
- GPT-4 reaches 86.0% weighted F1 score on news classification with few-shot learning
- GPT-4 struggles with sentiment analysis and NER compared to specialized models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPT and GPT-4 outperform domain-specific models on numerical reasoning tasks due to their ability to process structured data and perform complex calculations.
- Mechanism: The models leverage their training on diverse datasets to handle financial numerical reasoning tasks without needing domain-specific fine-tuning.
- Core assumption: The numerical reasoning tasks rely on general mathematical operations rather than deep domain-specific knowledge.
- Evidence anchors:
  - [abstract]: "GPT-4 achieves strong performance on numerical reasoning tasks, outperforming BloombergGPT"
  - [section]: "GPT-4 demonstrates the highest accuracy of 62.87, followed by 61.24 of FinQANet"
  - [corpus]: Found 25 related papers, but none specifically addressing this mechanism in detail.
- Break condition: When tasks require deep understanding of financial concepts or domain-specific terminology that isn't present in general training data.

### Mechanism 2
- Claim: Few-shot learning significantly improves GPT-4's performance on news classification tasks compared to zero-shot learning.
- Mechanism: GPT-4 can leverage a small number of examples to adapt to the task format and improve accuracy.
- Core assumption: The model can generalize from few examples to the broader task without extensive fine-tuning.
- Evidence anchors:
  - [section]: "GPT-4 exhibits the highest performance with an average weighted F1 score of 86.0"
  - [section]: "These results demonstrate the superior performance of few-shot learning of GPT-4"
  - [corpus]: No direct evidence found in corpus for this specific mechanism.
- Break condition: When the task requires extensive domain knowledge that cannot be captured in a few examples.

### Mechanism 3
- Claim: ChatGPT and GPT-4 struggle with sentiment analysis in financial texts due to a lack of domain-specific knowledge and exposure to financial terminology.
- Mechanism: The models' training data may not adequately represent the nuanced language and context of financial sentiment.
- Core assumption: Sentiment analysis in finance requires understanding of domain-specific expressions and their impact on market sentiment.
- Evidence anchors:
  - [abstract]: "they still struggle with sentiment analysis and named entity recognition compared to specialized models like FinBert and FinQANet"
  - [section]: "GPT-4 has difficulties in relating the financial statements to human sentiment over stock movements"
  - [corpus]: Weak evidence found in corpus for this mechanism.
- Break condition: When models are fine-tuned on domain-specific data or when tasks don't require deep understanding of financial context.

## Foundational Learning

- Concept: Numerical reasoning and arithmetic operations
  - Why needed here: The models need to perform calculations and logical operations to answer financial questions.
  - Quick check question: Can the model correctly calculate "753 million + 785 million + 1,134 million"?

- Concept: Named Entity Recognition (NER) in financial contexts
  - Why needed here: To identify and classify financial entities like organizations, locations, and persons in text.
  - Quick check question: Can the model correctly identify and classify entities in financial reports?

- Concept: Sentiment analysis and understanding of financial language
  - Why needed here: To determine the sentiment of financial news and its potential impact on markets.
  - Quick check question: Can the model accurately classify the sentiment of financial news sentences as positive, negative, or neutral?

## Architecture Onboarding

- Component map: Data preparation -> Prompt engineering -> Model invocation -> Result evaluation -> Comparison with baseline models
- Critical path: Data preparation → Prompt engineering → Model invocation → Result evaluation → Comparison with baseline models
- Design tradeoffs: General-purpose models vs. domain-specific models, zero-shot vs. few-shot learning, accuracy vs. computational efficiency
- Failure signatures: Basic calculation errors, inability to understand financial context, struggles with domain-specific terminology
- First 3 experiments:
  1. Evaluate ChatGPT and GPT-4 on the FinQA dataset using zero-shot learning.
  2. Test few-shot learning performance on the Headlines dataset.
  3. Compare sentiment analysis results on the Financial PhraseBank dataset with FinBert model.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can ChatGPT and GPT-4 be further improved to better handle domain-specific terminology and knowledge in financial text analytics?
- Basis in paper: [explicit] The paper highlights that ChatGPT and GPT-4 struggle with tasks requiring domain-specific knowledge and terminology, such as sentiment analysis and named entity recognition, despite their strong performance in numerical reasoning tasks.
- Why unresolved: The paper suggests that these models, although impressive in general NLP tasks, fall short when dealing with specialized financial domain tasks compared to fine-tuned models like FinBert and FinQANet.
- What evidence would resolve it: Comparative studies testing improved versions of ChatGPT and GPT-4 on financial datasets, alongside existing fine-tuned models, would demonstrate whether enhancements in domain-specific understanding have been achieved.

### Open Question 2
- Question: To what extent does scaling up the model size enhance the effectiveness of AI models in complex financial tasks such as numerical reasoning and sentiment analysis?
- Basis in paper: [inferred] The paper notes that while GPT-4 outperforms other models in numerical reasoning tasks, there remains a significant gap between AI models and human experts, suggesting that scaling up model size might further enhance effectiveness.
- Why unresolved: The paper implies potential benefits of larger models but does not provide empirical evidence on the impact of scaling on model performance in financial tasks.
- What evidence would resolve it: Experiments comparing the performance of current models with scaled-up versions on the same financial datasets would provide insights into the benefits of increased model size.

### Open Question 3
- Question: What specific architectural or training modifications could enhance the contextual understanding and coreference handling capabilities of ChatGPT and GPT-4 in conversational financial tasks?
- Basis in paper: [explicit] The paper identifies issues with ChatGPT's understanding of contextual information and coreference in conversational tasks, such as those in the ConvFinQA dataset.
- Why unresolved: The paper points out these limitations but does not propose specific solutions or modifications to address them.
- What evidence would resolve it: Research demonstrating improved conversational task performance through architectural or training modifications would indicate successful enhancements in contextual understanding and coreference handling.

## Limitations

- Evaluation only covers four specific financial tasks, potentially missing other critical applications
- Results based on June 2023 models may not reflect improvements in newer versions
- Does not explore the impact of prompt engineering variations or cost-benefit tradeoffs

## Confidence

**High Confidence**: The finding that GPT-4 outperforms BloombergGPT on numerical reasoning tasks is well-supported by the 62.87% accuracy score and the controlled comparison conditions. The superior performance of few-shot learning over zero-shot learning is also robustly demonstrated with average weighted F1 scores of 86.0% versus 72.8%.

**Medium Confidence**: The claim that GPT-4 struggles with sentiment analysis compared to FinBert has moderate support but may be influenced by dataset-specific factors. The difficulty with named entity recognition is also moderately supported but could vary with different NER benchmarks.

**Low Confidence**: The assertion that general-purpose LLMs cannot handle domain-specific terminology without extensive fine-tuning is not strongly supported by the current results, as GPT-4 shows competitive performance on several tasks without domain adaptation.

## Next Checks

1. **Temporal Validation**: Re-run the benchmark tests with current versions of GPT-4 and newer LLMs to assess whether the performance gaps have narrowed since June 2023.

2. **Domain Adaptation Study**: Fine-tune GPT-4 on financial domain data and re-evaluate on all four tasks to quantify the performance improvement versus specialized models like FinBert and BloombergGPT.

3. **Cost-Performance Analysis**: Measure the computational cost and API expenses of using general-purpose LLMs versus specialized models across all tasks to determine economic viability for production deployment.