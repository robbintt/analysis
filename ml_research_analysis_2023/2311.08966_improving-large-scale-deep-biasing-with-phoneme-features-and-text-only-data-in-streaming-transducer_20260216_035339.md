---
ver: rpa2
title: Improving Large-scale Deep Biasing with Phoneme Features and Text-only Data
  in Streaming Transducer
arxiv_id: '2311.08966'
source_url: https://arxiv.org/abs/2311.08966
tags:
- biasing
- words
- deep
- rare
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of recognizing rare words in
  streaming automatic speech recognition (ASR) systems, particularly when using large-scale
  bias lists containing many distractors and similar-sounding words. The authors propose
  a method that combines phoneme and textual information of rare words within Transducers
  to improve discrimination between similar words.
---

# Improving Large-scale Deep Biasing with Phoneme Features and Text-only Data in Streaming Transducer

## Quick Facts
- arXiv ID: 2311.08966
- Source URL: https://arxiv.org/abs/2311.08966
- Reference count: 0
- Primary result: Achieves state-of-the-art rare word error rate (B-WER) improvements of 75.81% and 71.85% relative reductions on test-clean and test-other sets respectively with 2000-word bias lists

## Executive Summary
This paper addresses the challenge of recognizing rare words in streaming ASR systems when using large-scale bias lists containing many distractors and similar-sounding words. The authors propose combining phoneme and textual information within Transducers to improve discrimination between similar words. They introduce a BiasingModule with WordEncoder that can utilize both textual and phoneme features, and combine it with USTR (Unified Speech-Text Representation) for training with text-only data containing more rare words. Experiments on LibriSpeech demonstrate significant improvements in rare word error rates across different bias list sizes, achieving state-of-the-art performance.

## Method Summary
The approach combines phoneme and textual information for rare words using a BiasingModule with WordEncoder that processes rare words through parallel textual and phoneme branches. The model is trained with group-based learning rate policies and incorporates text-only data via USTR framework. During inference, it uses FST to combine the transducer outputs with bias lists. The method is evaluated on LibriSpeech corpus with 209.2k rare words, comparing different word encoding strategies (textual-only, phoneme-only, and combined) across various bias list sizes.

## Key Results
- With 2000-word bias lists, achieves relative B-WER reductions of 75.81% and 71.85% on test-clean and test-other sets respectively
- Combined textual-phoneme encoding (Tex-Pho-WE) outperforms both textual-only and phoneme-only approaches
- Training with text-only data containing more rare words further improves biasing performance from 14.69% to 6.99%/7.57% B-WER
- The approach maintains good performance across bias list sizes from 100 to 2000 words

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining phoneme and textual information improves discrimination between similar rare words.
- Mechanism: WordEncoder processes rare words through two parallel paths - one extracting textual (subword) embeddings and another extracting phoneme embeddings. These representations are concatenated and projected to form a unified embedding that captures both spelling and pronunciation cues.
- Core assumption: Similar grapheme sequences often correspond to similar pronunciations, and having both representations allows the model to distinguish between words that might be confused based on only one modality.
- Evidence anchors:
  - [abstract] "we combine the phoneme and textual information of rare words in Transducers to distinguish words with similar pronunciation or spelling"
  - [section 5.2] "compared with Textual-WE, Tex-Pho-WE obtained the best results, with relative reductions of 10.47% (7.64% → 6.84%) and 7.08% (15.81% → 14.69%) on the B-WERs"
  - [corpus] Weak - no direct corpus evidence for this specific mechanism
- Break condition: If the Grapheme-to-Phoneme system (g2pE2) generates incorrect phoneme sequences for rare words, the phoneme branch would provide misleading information and degrade performance.

### Mechanism 2
- Claim: Using text-only data containing more rare words enhances the biasing capability of the BiasingModule.
- Mechanism: The USTR framework is employed to train the TextEncoder on unpaired text data containing rare words. This creates a richer representation space for rare words that can be leveraged during biasing.
- Core assumption: Exposing the model to more rare word instances during training improves its ability to recognize and prioritize these words during inference.
- Evidence anchors:
  - [abstract] "the introduction of training with text-only data containing more rare words benefits large-scale deep biasing"
  - [section 5.3] "When trained with unpaired text data C/L, the B-WER of deep biasing model on test-other is improved from 14.69% to 6.99%/7.57%"
  - [corpus] Weak - no direct corpus evidence for this specific mechanism
- Break condition: If the text-only data contains domain shifts or noise that differs significantly from the speech domain

## Foundational Learning

**Phoneme Features**: Why needed - To capture pronunciation information that complements textual representations for better discrimination of similar-sounding words. Quick check - Verify that the g2pE2 system generates accurate phoneme sequences for rare words in the test domain.

**Unified Speech-Text Representation (USTR)**: Why needed - To leverage large amounts of text-only data for improving rare word representations without requiring paired speech-text data. Quick check - Confirm that the text encoder trained on unpaired text data can effectively transfer knowledge to the biasing task.

**BiasingModule Architecture**: Why needed - To integrate rare word information into the transducer framework while maintaining streaming capabilities. Quick check - Ensure the BiasingModule doesn't significantly increase computational complexity or degrade unbiased word recognition.

## Architecture Onboarding

**Component Map**: Input features -> Conformer Encoder -> BiasingModule (WordEncoder with textual/phoneme branches) -> Predictor -> Join Network -> Output Distribution

**Critical Path**: The BiasingModule is the critical component that combines textual and phoneme information, with the WordEncoder being the core subcomponent that processes rare words through parallel branches.

**Design Tradeoffs**: The approach trades increased model complexity and computational overhead for improved rare word recognition. Using both phoneme and textual information provides better discrimination but requires a Grapheme-to-Phoneme system and additional computation.

**Failure Signatures**: 
- Degradation in unbiased word recognition when BiasingModule learning rate is too high
- Memory issues during inference with large bias lists due to sequence length expansion
- Poor performance on rare words when phoneme extraction fails for certain words

**First Experiments**:
1. Implement WordEncoder with textual-only branch and verify basic biasing functionality
2. Add phoneme branch to WordEncoder and measure improvement over textual-only baseline
3. Train with text-only data using USTR and evaluate impact on rare word recognition

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method scale to real-world applications with millions of rare words compared to the tested 2000 bias list size?
- Basis in paper: [explicit] The paper tests bias list sizes up to 2000 but doesn't evaluate performance at scale
- Why unresolved: The experimental results only cover bias list sizes up to 2000, leaving uncertainty about performance at real-world scales
- What evidence would resolve it: Experiments with bias lists of 10,000+ entries and corresponding error rate measurements

### Open Question 2
- Question: What is the computational overhead of combining phoneme and textual information during inference compared to text-only approaches?
- Basis in paper: [inferred] The paper mentions lower computational complexity for Enc-Pre Query but doesn't quantify the full computational cost of the phoneme-text combination
- Why unresolved: While the paper discusses computational complexity, it doesn't provide specific measurements of inference time or memory usage for the complete system
- What evidence would resolve it: Benchmark measurements comparing inference speed and memory usage between different word encoding methods

### Open Question 3
- Question: How does the performance change when using different phoneme-to-text conversion systems or when handling multiple pronunciations?
- Basis in paper: [explicit] The paper mentions using "a Grapheme-to-Phoneme system, i.e., g2pE2" but doesn't explore alternatives
- Why unresolved: The paper uses a specific G2P system without comparing it to other systems or exploring how pronunciation variations affect performance
- What evidence would resolve it: Comparative experiments using different G2P systems and evaluations with homographs/homophones

### Open Question 4
- Question: What is the impact of rare word distribution in the text-only corpus on the biasing performance?
- Basis in paper: [explicit] The paper mentions using "text-only data containing more rare words" but doesn't analyze the effect of different rare word distributions
- Why unresolved: The paper doesn't investigate how the frequency and distribution of rare words in the training corpus affects the final performance
- What evidence would resolve it: Controlled experiments varying the proportion and distribution of rare words in the text-only training data

## Limitations

- Architecture Complexity: The BiasingModule with combined phoneme and textual encoding adds significant complexity with limited architectural details provided
- Evaluation Scope: Results are limited to LibriSpeech dataset, potentially overestimating real-world performance on diverse domains
- Text-only Data Integration: USTR framework lacks implementation details for how text-only data is incorporated and potential domain mismatches handled

## Confidence

**High Confidence** in the core finding that combining phoneme and textual features improves rare word recognition compared to using either modality alone, based on ablation studies showing consistent improvements with the Tex-Pho-WE approach.

**Medium Confidence** in the overall methodology due to strong experimental results on LibriSpeech, but tempered by lack of architectural details and single-dataset evaluation limiting generalizability assessment.

**Low Confidence** in practical deployment implications given limited discussion of computational overhead, inference latency, and real-world performance in non-LibriSpeech domains.

## Next Checks

1. **Architectural Reproducibility Test**: Implement the WordEncoder with both textual and phoneme branches using publicly available phoneme extraction tools, and verify that the concatenation and projection mechanism produces the reported performance improvements on a small-scale benchmark.

2. **Cross-Domain Generalization**: Evaluate the approach on a different ASR dataset (e.g., Common Voice or TED-LIUM) with rare words from a different domain than LibriSpeech to assess how well the phoneme-text combination generalizes beyond the training domain.

3. **Computational Overhead Analysis**: Measure the inference time and memory requirements of the BiasingModule with full phoneme-text encoding compared to baseline transducer approaches, and assess whether the performance gains justify the additional computational cost in practical deployment scenarios.