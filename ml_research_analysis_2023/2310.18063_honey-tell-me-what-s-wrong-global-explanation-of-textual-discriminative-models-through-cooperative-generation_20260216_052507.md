---
ver: rpa2
title: '"Honey, Tell Me What''s Wrong", Global Explanation of Textual Discriminative
  Models through Cooperative Generation'
arxiv_id: '2310.18063'
source_url: https://arxiv.org/abs/2310.18063
tags:
- methods
- therapy
- input
- data
- texts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Therapy is a global, model-agnostic explanation method for textual
  discriminative models that does not require input data. Instead of perturbing real
  instances, Therapy uses cooperative generation to create synthetic texts following
  the distribution learned by the classifier.
---

# "Honey, Tell Me What's Wrong", Global Explanation of Textual Discriminative Models through Cooperative Generation

## Quick Facts
- arXiv ID: 2310.18063
- Source URL: https://arxiv.org/abs/2310.18063
- Reference count: 30
- Key outcome: Therapy achieves competitive results with LIME and SHAP when no input data is available, and outperforms them when input data is not representative of the studied model.

## Executive Summary
Therapy is a novel method for globally explaining textual discriminative models without requiring input data. Unlike traditional methods that perturb real instances, Therapy uses cooperative generation to create synthetic texts following the distribution learned by the classifier. It leverages Monte Carlo Tree Search to guide a pre-trained language model, generating texts stereotypical of each class, and then trains a logistic regression on tf-idf representations to extract word importance. Experiments show Therapy provides insightful global explanations, especially in scenarios where traditional methods struggle due to lack of representative data.

## Method Summary
Therapy generates synthetic texts following the distribution of a classifier through cooperative generation using Monte Carlo Tree Search (MCTS). At each decoding step, MCTS selects the next token based on both the language model's likelihood and the classifier's probability for the target class, creating sequences that are both well-formed and stereotypical of the target class. The generated texts are then processed with tf-idf to filter out common words across classes, and a logistic regression is trained on these representations. The learned weights provide global explanations of the most important words for each class, allowing explanation even when no input data is available.

## Key Results
- Therapy achieves competitive performance with LIME and SHAP on both Amazon Polarity and AG News datasets
- When compared to versions of LIME and SHAP using non-representative data, Therapy significantly outperforms them
- Therapy requires only 100-500 generated texts per class to achieve optimal explanation quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cooperative generation using MCTS-guided decoding creates synthetic texts following p(x) * D(c|x)
- Mechanism: MCTS selects tokens at each decoding step using both LM likelihood and classifier probability, creating texts that are both well-formed and stereotypical of target classes
- Core assumption: Classifier probability outputs D(c|x) meaningfully correlate with important features
- Evidence anchors: Abstract states "Therapy generates texts following the distribution of a classifier through cooperative generation"; Section 3.2 details MCTS steps using D(c|x) as scores
- Break condition: If classifier outputs don't correlate with important features, cooperative generation fails

### Mechanism 2
- Claim: tf-idf representations filter common words and identify class-specific features
- Mechanism: tf-idf applied to entire corpus of generated texts downweights words frequent across classes, while logistic regression identifies distinctive features
- Core assumption: Distribution p(x) is same across classes, allowing tf-idf to filter out common words
- Evidence anchors: Section 4 states "by using tf-idf on the whole corpus... words that are frequent because of p(x) or in multiple classes will be filtered out"; Section 5.1 describes logistic regression training
- Break condition: If p(x) varies across classes or important features are common, tf-idf removes relevant information

### Mechanism 3
- Claim: Therapy provides global explanations without requiring input data
- Mechanism: Generates synthetic texts from classifier's learned distribution instead of perturbing real instances
- Core assumption: Synthetic texts capture classifier's important features and are representative of learned distribution
- Evidence anchors: Abstract emphasizes "it allows to generate explanations even when data is absent"; Section 5.3 shows Therapy's performance advantage when input data is non-representative
- Break condition: If cooperative generation fails to produce representative samples, global explanation is inaccurate

## Foundational Learning

- Concept: Monte Carlo Tree Search (MCTS)
  - Why needed here: Guides language model during text generation, allowing classifier to influence token selection
  - Quick check question: How does MCTS balance exploration and exploitation during token selection?

- Concept: Language Model Decoding Strategies
  - Why needed here: Essential for implementing cooperative generation and comparing to baseline methods
  - Quick check question: What is the key difference between traditional left-to-right decoding and MCTS-guided decoding?

- Concept: Feature Attribution Methods
  - Why needed here: Therapy compared to LIME and SHAP, so understanding their local explanation approaches is essential
  - Quick check question: How do LIME and SHAP generate local explanations for text classification models?

## Architecture Onboarding

- Component map:
  Language Model -> MCTS Algorithm -> Classifier -> Text Preprocessing -> Logistic Regression -> Feature Importance Output

- Critical path:
  1. Initialize MCTS with LM and classifier
  2. Generate synthetic texts for each class using MCTS-guided decoding
  3. Apply tf-idf to entire corpus of generated texts
  4. Train logistic regression on tf-idf features
  5. Extract and return feature importance weights

- Design tradeoffs:
  - Number of generated texts vs. computation time
  - Token selection strategy (most played vs. highest score) vs. text quality
  - Choice of language model vs. domain specificity
  - tf-idf vs. other feature weighting schemes

- Failure signatures:
  - Low Spearman correlation between generated explanations and ground truth
  - Plateau in recall scores for compared methods when using different datasets
  - Similar or worse insertion/deletion performance compared to baseline methods

- First 3 experiments:
  1. Generate 100, 500, 1000, 3000 texts per class and measure Spearman correlation to find optimal number
  2. Compare most-played vs. highest-scored token selection strategies
  3. Test on a simple glass-box model with known feature importance as ground truth

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Therapy perform on multi-label classification tasks with overlapping classes?
- Basis in paper: [inferred] Paper mentions Therapy handles datasets with overlapping classes but only tested binary and multi-class classification
- Why unresolved: Experiments limited to binary and multi-class classification; performance on multi-label tasks unexplored
- What evidence would resolve it: Experiments on multi-label datasets comparing Therapy with other explanation methods

### Open Question 2
- Question: What is the impact of using different language models on explanation quality?
- Basis in paper: [explicit] Paper notes LM choice defines explanation domain and general domain LM works well, but only tested OPT-125m
- Why unresolved: Only one LM (OPT-125m) used across all datasets; impact of different LMs not investigated
- What evidence would resolve it: Compare Therapy performance using different LMs (domain-specific, larger models) on same datasets

### Open Question 3
- Question: How does Therapy handle datasets with many classes or fine-grained distinctions?
- Basis in paper: [inferred] Paper tested only datasets with few classes; scalability to many classes or subtle distinctions unexplored
- Why unresolved: Tested only datasets with small number of classes; scalability to many classes or fine distinctions uncertain
- What evidence would resolve it: Evaluate Therapy on datasets with large number of classes or fine-grained distinctions, compare with other methods

## Limitations

- The effectiveness of cooperative generation depends on classifier probability outputs being meaningful guides for text generation, which isn't directly validated
- tf-idf filtering may not work optimally if language model's prior varies across classes or important features are common across classes
- The method's scalability to datasets with many classes or fine-grained distinctions remains unexplored

## Confidence

- **High confidence**: Therapy can provide global explanations without requiring input data, well-supported by experimental results
- **Medium confidence**: MCTS-guided cooperative generation mechanism is theoretically sound but lacks direct validation of its effectiveness
- **Low confidence**: Assumption that tf-idf is optimal feature weighting scheme for this application, not thoroughly tested with alternatives

## Next Checks

1. **Mechanism validation experiment**: Test Therapy's performance when classifier probability outputs are deliberately perturbed or when using a classifier with known but different decision boundaries to validate reliance on classifier outputs

2. **Feature weighting comparison**: Implement and compare Therapy using alternative feature weighting schemes (chi-squared, mutual information) instead of tf-idf to determine if current choice is optimal

3. **Synthetic text quality analysis**: Conduct qualitative analysis of synthetic texts generated by Therapy to examine whether they capture stereotypical features of each class and align with human judgments of class importance