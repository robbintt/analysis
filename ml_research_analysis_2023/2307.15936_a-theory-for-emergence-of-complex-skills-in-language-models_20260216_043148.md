---
ver: rpa2
title: A Theory for Emergence of Complex Skills in Language Models
arxiv_id: '2307.15936'
source_url: https://arxiv.org/abs/2307.15936
tags:
- skills
- text
- language
- training
- skill
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper develops a theoretical framework to explain the emergence
  of complex skills in language models as they are scaled up. The authors introduce
  a statistical framework that relates cross-entropy loss of LLMs to competence on
  the basic skills underlying language tasks.
---

# A Theory for Emergence of Complex Skills in Language Models

## Quick Facts
- arXiv ID: 2307.15936
- Source URL: https://arxiv.org/abs/2307.15936
- Reference count: 12
- Key outcome: This paper develops a theoretical framework explaining how complex skills emerge in language models as they scale up, showing that competence on skill combinations emerges at the same rate as elementary skills through "slingshot generalization."

## Executive Summary
This paper presents a theoretical framework for understanding how complex skills emerge in language models as they scale up. The authors introduce a statistical framework that relates cross-entropy loss to competence on basic language skills, showing that scaling laws create a strong inductive bias called "slingshot generalization." This allows pre-trained models to learn very efficiently, even on tasks combining multiple skills. The framework explains how language models can acquire abilities to solve tasks that combine skills, even when the number of such combinations is too large to be seen in the training data.

## Method Summary
The authors develop a statistical framework that connects cross-entropy loss reduction to skill competence improvement in language models. They analyze how scaling laws create an inductive bias that enables efficient learning of both individual skills and their combinations. The method involves training language models on diverse datasets containing multiple skill combinations, measuring competence through cloze-based tests, and using random bipartite graph theory to prove that skill combinations can emerge without explicit training examples. The framework relies on the observation that test loss scales predictably with model size and dataset size.

## Key Results
- Mathematical analysis showing that scaling laws imply strong inductive bias enabling efficient learning of skill combinations
- Proof that competence at executing tasks involving k-tuples of skills emerges at the same scaling and rate as competence on elementary skills
- Demonstration that random bipartite graph structure enables emergence of skill combinations without explicit training examples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-entropy loss reduction drives skill competence improvement through "slingshot generalization."
- Mechanism: When models are trained on diverse datasets containing multiple skill combinations, the scaling law creates an inductive bias where competence on individual skills improves faster than traditional learning theory predicts. This occurs because the model's parameters can aggregate structural information across all skills simultaneously.
- Core assumption: The scaling law continues to hold for text data derived from multiple skill sources, and reduction in excess cross-entropy captures the rate of learning.
- Evidence anchors:
  - [abstract] "Mathematical analysis showing that the Scaling Laws imply a strong form of inductive bias that allows the pre-trained model to learn very efficiently."
  - [section 4] "Training on the full dataset gives hugely better performance on individual skills than if we trained separate models on individual skills."
  - [corpus] Found 25 related papers exploring scaling laws and emergence, though empirical validation of the specific slingshot generalization mechanism remains limited.
- Break condition: If scaling laws deviate significantly from the assumed polynomial form, or if the relationship between cross-entropy loss and skill competence is not maintained across diverse datasets.

### Mechanism 2
- Claim: Random bipartite graph structure enables emergence of skill combinations without explicit training examples.
- Mechanism: Text pieces are generated using random combinations of skills, creating a bipartite graph where skills connect to text pieces. Even though the number of possible skill combinations exceeds training data, random graph theory guarantees that most skills will have edges outside the "error set," enabling competence emergence.
- Core assumption: Each text piece requires exactly k skills chosen iid from an underlying skill distribution, and the skill graph has random edges.
- Evidence anchors:
  - [abstract] "Competence at executing tasks involving k-tuples of skills emerges essentially at the same scaling and same rate as competence on the elementary skills themselves."
  - [section 6] "The very fact of text-pieces having been produced using random combinations of skills is powerful enough... to imply that reduction in cross-entropy manifests itself as improvement in competence on the basic skills."
  - [corpus] Limited direct evidence for random bipartite graph models in LLM emergence literature.
- Break condition: If skill combinations in natural text are not sufficiently random, or if the random graph assumptions break down due to skill correlations.

### Mechanism 3
- Claim: Cloze prompts effectively measure skill competence through excess cross-entropy.
- Mechanism: When humans can answer cloze questions perfectly, any model errors contribute to excess cross-entropy. The model's prediction loss on cloze questions tracks its overall excess cross-entropy, allowing us to infer skill competence from prediction accuracy.
- Core assumption: An unknown process CLOZE adds suitable cloze prompts to test comprehension, and these prompts capture the model's misunderstanding of text.
- Evidence anchors:
  - [section 3] "If the model is split50-50 between the two options this implies it has cross-entropy log 2, all of which is excess cross entropy!"
  - [section 5] "The model's 'comprehension' of a text piece is testable via suitable Cloze prompts analogous to the Winograd example."
  - [corpus] Weak empirical evidence for cloze-based skill measurement in LLM literature.
- Break condition: If cloze prompts fail to capture the full range of language skills, or if the relationship between cloze performance and overall competence breaks down.

## Foundational Learning

- Concept: Statistical learning theory and cross-entropy loss
  - Why needed here: The framework connects model performance to statistical tasks, using cross-entropy as the primary loss function
  - Quick check question: Can you explain why minimizing cross-entropy loss helps a model learn the underlying probability distribution of language?

- Concept: Random graph theory and bipartite graphs
  - Why needed here: The theory relies on properties of random bipartite graphs to prove that skill combinations can emerge without explicit training examples
  - Quick check question: How does random bipartite graph structure ensure that most skills have edges outside the error set?

- Concept: Scaling laws and power-law relationships
  - Why needed here: The entire framework depends on the observation that test loss scales predictably with model size and dataset size
  - Quick check question: What does it mean for loss to scale as 1/D^0.28, and why is this important for the emergence phenomenon?

## Architecture Onboarding

- Component map: Data pipeline -> Model -> Evaluation -> Analysis
- Critical path:
  1. Prepare text corpus with diverse skill representations
  2. Add cloze prompts to test comprehension
  3. Train model using cross-entropy loss
  4. Measure performance on skill clusters
  5. Verify emergence of skill combinations

- Design tradeoffs:
  - Skill granularity vs. computational complexity: Finer skill definitions enable more precise measurements but increase computational overhead
  - Random vs. structured skill combinations: Random combinations enable theoretical guarantees but may not reflect natural language patterns
  - Cloze prompt density vs. training efficiency: More prompts improve skill measurement but increase training time

- Failure signatures:
  - No emergence of skill combinations despite scaling up
  - Performance improvement on individual skills but not on combinations
  - Cloze prompt effectiveness varies significantly across skill types

- First 3 experiments:
  1. Verify scaling law holds for your dataset by training models of different sizes
  2. Measure cloze performance on individual skills vs. skill combinations
  3. Test emergence by training on skill combinations not present in the training data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the scaling laws for complex skills like math or coding compare to those for basic language skills?
- Basis in paper: [explicit] The paper mentions that the scaling laws are adaptable to different types of losses and skills, but notes that there is a lack of detailed study of scaling laws for interesting parts of language such as math or coding.
- Why unresolved: The paper acknowledges that while the framework is adaptable, there hasn't been a thorough experimental study of scaling laws for specific domains like math or coding.
- What evidence would resolve it: Conducting experiments to measure the scaling laws for math and coding tasks and comparing them to those for basic language skills.

### Open Question 2
- Question: To what extent do current language models have capabilities that go beyond simple statistical explanations?
- Basis in paper: [explicit] The paper suggests that many skills and combinations of skills may not get learned, and the ones that do get learned may be incorrectly applied on some fraction of the data distribution, indicating limitations in the current understanding.
- Why unresolved: The paper points out that the theory shares limitations with other statistical frameworks and hopes to inspire more thorough experimental study to determine if current models have capabilities beyond statistical explanations.
- What evidence would resolve it: Conducting experiments to test language models on tasks that require skills not present in the training data and comparing their performance to the predictions of the statistical framework.

### Open Question 3
- Question: How does the rate of emergence within individual skill clusters compare when the model is trained on a mixture of corpora versus a single corpus?
- Basis in paper: [explicit] The paper mentions that when each text-piece appears in a single cluster, the analysis continues to apply, but it cannot predict the rate at which loss decrease (and hence emergence) happens within clusters without mechanistic insight.
- Why unresolved: The paper acknowledges that it lacks mechanistic insight to predict the rate of emergence within individual clusters when trained on a mixture of corpora.
- What evidence would resolve it: Conducting experiments to train language models on different mixtures of corpora and measuring the rate of emergence within individual skill clusters compared to training on a single corpus.

## Limitations

- The framework heavily relies on random bipartite graph theory and scaling law assumptions that may not hold in real-world language data
- The cloze-based approach for measuring skill competence assumes that human-perfect answers provide a meaningful baseline, but this may not capture the full complexity of language understanding
- While the framework focuses on text data, it's unclear whether the same principles apply to other modalities or more complex task combinations

## Confidence

**High Confidence** (supported by mathematical proof and scaling law evidence):
- The core scaling law relationship between model size, data size, and cross-entropy loss
- The theoretical framework connecting excess cross-entropy to skill competence improvement

**Medium Confidence** (theoretical predictions with limited empirical validation):
- Slingshot generalization mechanism and its efficiency claims
- Random bipartite graph structure enabling skill combination emergence
- Cloze-based measurement of skill competence

**Low Confidence** (largely theoretical with minimal empirical support):
- Exact rate and conditions for skill combination emergence
- Practical applicability to real-world LLM architectures and training scenarios

## Next Checks

1. **Empirical Scaling Law Verification**: Train models of varying sizes on diverse skill combinations to verify that the predicted 1/D^0.28 scaling relationship holds in practice, and measure whether competence on k-tuple skills truly emerges at the same rate as elementary skills.

2. **Cloze Measurement Validation**: Design controlled experiments comparing cloze-based skill competence measurements against alternative evaluation methods (e.g., fine-tuning on specific skills) to verify that excess cross-entropy accurately captures skill understanding.

3. **Randomness Assumption Testing**: Analyze real text corpora to quantify the degree of randomness in skill combinations, and test how deviations from the assumed random bipartite graph structure affect skill emergence patterns.