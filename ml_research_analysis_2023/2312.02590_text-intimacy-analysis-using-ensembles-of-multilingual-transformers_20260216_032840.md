---
ver: rpa2
title: Text Intimacy Analysis using Ensembles of Multilingual Transformers
arxiv_id: '2312.02590'
source_url: https://arxiv.org/abs/2312.02590
tags:
- dataset
- languages
- language
- multilingual
- intimacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles multilingual tweet intimacy analysis using transformer
  ensembles. The authors experiment with ensembles of multilingual models (m-BERT,
  XLM-R, XLM-T) and a language-specific monolingual model per language.
---

# Text Intimacy Analysis using Ensembles of Multilingual Transformers

## Quick Facts
- arXiv ID: 2312.02590
- Source URL: https://arxiv.org/abs/2312.02590
- Reference count: 10
- Best ensemble (multilingual + language-specific) achieves Pearson correlation of 0.5715 on test set

## Executive Summary
This paper addresses the challenge of multilingual tweet intimacy analysis using ensembles of transformer models. The authors propose combining multiple multilingual transformers (m-BERT, XLM-R, XLM-T) with language-specific models to predict intimacy scores across 10 languages. Their experimental results show that ensembles outperform individual models on seen languages, while data augmentation via translation underperforms. The work demonstrates the effectiveness of model ensembles for cross-lingual intimacy scoring while highlighting the limitations of multilingual models on unseen languages.

## Method Summary
The approach uses ensembles of multilingual transformers (m-BERT, XLM-R, XLM-T) combined with language-specific models (e.g., CamemBERT, Chinese BERT). Models are fine-tuned on intimacy-labeled tweets using MSE loss and Adam optimizer, with different learning rates for multilingual (8e-6) and language-specific (6e-6) models. Predictions are aggregated using weighted averaging based on individual model performance. The system handles 10 languages, with 6 seen during training and 4 unseen languages for testing.

## Key Results
- Ensemble of multilingual models with language-specific models achieves best overall performance (Pearson r=0.5715)
- Multilingual models perform well on seen languages but poorly on unseen languages (except Dutch and Arabic)
- Translation-based data augmentation underperforms compared to using original language data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ensembling multiple multilingual models captures diverse feature representations, improving performance on seen languages.
- Mechanism: The ensemble aggregates predictions from m-BERT, XLM-R, and XLM-T, each trained on different corpora and language coverage. Weighted averaging leverages each model's strengths.
- Core assumption: Different multilingual models capture complementary aspects of linguistic features relevant to intimacy scoring.
- Evidence anchors:
  - [abstract] "We conduct several experiments and show that an ensemble of multilingual models along with a language-specific model has the best performance."
  - [section 4.1] "We choose multilingual BERT, XLM-RoBERTa, and XLM-T for our system based on their good performance."
  - [corpus] Weak evidence; neighbor papers focus on data augmentation and multilingual sentiment analysis but not specifically on transformer ensembles for intimacy scoring.
- Break condition: If models are too similar in architecture or training data, the ensemble provides little additional benefit over a single model.

### Mechanism 2
- Claim: Adding language-specific models improves performance on seen languages by leveraging domain-specific linguistic patterns.
- Mechanism: Models like Italian BERT or Chinese BERT are fine-tuned on the target language's data, capturing nuances missed by general multilingual models.
- Core assumption: Language-specific fine-tuning enhances the model's understanding of culturally and linguistically specific intimacy cues.
- Evidence anchors:
  - [abstract] "We also evaluate other data augmentation methods such as translation and present the results."
  - [section 4.2] "As the tweets individually largely contain only one language, we can use language-specific models as well."
  - [corpus] No direct evidence; neighbor papers do not discuss language-specific fine-tuning for intimacy tasks.
- Break condition: If the training data for a language is too small or unrepresentative, fine-tuning may overfit or fail to generalize.

### Mechanism 3
- Claim: Multilingual models perform poorly on unseen languages due to lack of language-specific training data, except for languages with larger or higher-quality pre-training corpora.
- Mechanism: Models trained on large, diverse corpora (e.g., CommonCrawl) generalize better across languages, but still struggle with low-resource languages.
- Core assumption: The quality and size of the pre-training corpus directly impact a model's ability to handle unseen languages.
- Evidence anchors:
  - [section 5] "It is ostensible that the predicted intimacy scores on unseen languages are bound to be less accurate than on seen languages."
  - [corpus] Weak evidence; neighbor papers focus on data augmentation but do not analyze multilingual model performance on unseen languages.
- Break condition: If a language has sufficient data in the pre-training corpus, the model may perform adequately without fine-tuning.

## Foundational Learning

- Concept: Transformer architecture and self-attention mechanism
  - Why needed here: Understanding how transformers process text is crucial for designing effective ensembles and interpreting model behavior.
  - Quick check question: How does self-attention allow transformers to weigh the importance of different words in a sentence?

- Concept: Multilingual model pre-training and fine-tuning
  - Why needed here: Knowing how models like m-BERT and XLM-R are pre-trained helps in selecting the right models for the ensemble and understanding their limitations.
  - Quick check question: What is the difference between multilingual pre-training and language-specific fine-tuning?

- Concept: Ensemble learning and weighted averaging
  - Why needed here: The ensemble approach relies on combining multiple model predictions; understanding this is key to optimizing the ensemble weights.
  - Quick check question: How does weighted averaging of model predictions improve robustness compared to using a single model?

## Architecture Onboarding

- Component map:
  Data preprocessing -> Language identification -> Model inference (multilingual and language-specific) -> Weighted averaging -> Pearson correlation evaluation

- Critical path:
  1. Load and preprocess tweet data
  2. Identify language of each tweet
  3. Pass tweet through appropriate multilingual and language-specific models
  4. Aggregate predictions using weighted average
  5. Evaluate performance using Pearson correlation

- Design tradeoffs:
  - Ensemble complexity vs. performance gain
  - Model size and inference time vs. accuracy
  - Language-specific fine-tuning vs. generalization

- Failure signatures:
  - Poor performance on unseen languages indicates lack of language coverage in pre-training
  - Overfitting on seen languages suggests insufficient regularization or data augmentation
  - High variance between model predictions signals instability in the ensemble

- First 3 experiments:
  1. Train and evaluate each multilingual model individually to establish baseline performance
  2. Create a simple ensemble with equal weights and compare to individual models
  3. Add language-specific models to the ensemble and test impact on seen languages

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do multilingual models perform significantly better on Dutch and Arabic compared to Hindi and Korean, despite all being unseen languages during training?
- Basis in paper: [explicit] The authors observe that multilingual models perform poorly on Hindi and Korean but substantially better on Dutch and Arabic, despite all four being absent from the training data.
- Why unresolved: The paper suggests this could be due to either better pre-training data for Dutch/Arabic or superior language-agnostic understanding, but does not definitively establish which factor is more important or how to disentangle their effects.
- What evidence would resolve it: A controlled study comparing model performance on languages with similar pre-training data sizes but different language-agnostic understanding, or vice versa, would help isolate the contributing factors.

### Open Question 2
- Question: What is the optimal weighting scheme for ensemble models that maximizes performance across both seen and unseen languages?
- Basis in paper: [inferred] The authors use fixed weights based on individual model performance, but the ensemble with language-specific models performs best overall while the multilingual-only ensemble performs best on seen languages, suggesting current weighting may not be optimal.
- Why unresolved: The paper does not explore dynamic weighting strategies or optimization techniques to find the best combination of model contributions.
- What evidence would resolve it: Systematic experimentation with different weighting schemes, including learnable weights and language-specific adjustments, would reveal optimal ensemble configurations.

### Open Question 3
- Question: How does the presence of code-switching or multilingual tweets affect intimacy prediction accuracy, and what modeling approaches can better handle such cases?
- Basis in paper: [explicit] The authors note that "some tweets contain some text from a different script, used for purposes such as acronyms and names," but do not evaluate how this affects model performance.
- Why unresolved: The paper focuses on monolingual tweets and does not investigate the impact of code-switching or develop specialized models for handling multilingual content within single tweets.
- What evidence would resolve it: Analysis of model performance on code-switched tweets and development/testing of models specifically designed to handle multilingual content would address this gap.

## Limitations

- Results based on a single dataset (SemEval-2023 Task 9) may not generalize to other domains or tasks
- The explanation for why certain unseen languages (Dutch, Arabic) perform better than others is speculative without corpus analysis
- Translation-based data augmentation underperforms but the nature of semantic information loss is not systematically investigated

## Confidence

High confidence: The basic experimental setup and evaluation methodology are sound. The observation that multilingual models perform better on seen languages than unseen ones is straightforward and well-supported.

Medium confidence: The conclusion that ensemble models with language-specific components perform best is supported by the results, but the specific weight assignments and their impact on performance are not fully transparent.

Low confidence: The explanation for why certain unseen languages (Dutch, Arabic) perform better than others is largely speculative without concrete evidence about pre-training corpus composition or linguistic similarities.

## Next Checks

1. **Pre-training corpus analysis**: Analyze the CommonCrawl-based pre-training corpora for XLM-R and m-BERT to determine actual coverage of Dutch and Arabic compared to Hindi and Korean. This would validate or refute the speculation about why certain unseen languages perform better.

2. **Translation quality assessment**: Conduct a systematic study of translation quality for intimacy-related tweets, measuring semantic drift and information loss. Compare machine translation outputs with human translations to quantify the degradation in semantic content.

3. **Ensemble weight sensitivity**: Perform an ablation study varying the ensemble weights to determine how sensitive the final performance is to the specific weighting scheme. This would help understand whether the ensemble approach is robust or dependent on precise weight calibration.