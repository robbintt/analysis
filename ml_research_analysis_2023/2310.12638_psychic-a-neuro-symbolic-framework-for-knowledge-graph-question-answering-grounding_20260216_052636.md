---
ver: rpa2
title: 'PSYCHIC: A Neuro-Symbolic Framework for Knowledge Graph Question-Answering
  Grounding'
arxiv_id: '2310.12638'
source_url: https://arxiv.org/abs/2310.12638
tags:
- question
- entity
- knowledge
- query
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents PSYCHIC, a neuro-symbolic framework for knowledge
  graph question answering and entity linking. The system uses a DistilBERT-based
  extractive QA model trained to output SPARQL queries and entity lists from question-context
  pairs.
---

# PSYCHIC: A Neuro-Symbolic Framework for Knowledge Graph Question-Answering Grounding

## Quick Facts
- arXiv ID: 2310.12638
- Source URL: https://arxiv.org/abs/2310.12638
- Authors:
- Reference count: 30
- Primary result: PSYCHIC achieves 00.18% F1-QA and 71.00% F1-EL on DBLP-QUAD using a two-phase evaluation with symbolic context delimiters.

## Executive Summary
PSYCHIC is a neuro-symbolic framework for knowledge graph question answering and entity linking. It uses a DistilBERT-based extractive QA model trained to output SPARQL queries and entity lists from question-context pairs. By incorporating symbolic tokens ([CLS], [SEP]) in the context, the model learns to discriminate between query and entity patterns. The system is evaluated in a two-phase approach: a development phase with full SPARQL-question pairs achieving perfect scores, and a final phase using only questions and entity linker predictions, resulting in 00.18% F1 for QA and 71.00% F1 for entity linking. The results highlight the importance of context for extractive QA models and demonstrate PSYCHIC’s ability to generalize entity linking despite limited training.

## Method Summary
PSYCHIC is based on DistilBERT and is trained to predict SPARQL queries and entity lists from question-context pairs using symbolic tokens ([CLS], [SEP]) to guide the learning process. The model is fine-tuned on the DBLP-QUAD dataset with specific hyperparameters (learning rate = 2e-05, batch size = 16, epochs = 3). The training involves constructing context strings that include the question, SPARQL query, entities, and symbolic tokens. The system is evaluated in two phases: a development phase with full SPARQL-question pairs and a final phase using only questions and entity linker predictions. Sanitizers are used to correct malformed outputs and ensure valid SPARQL queries and entity lists.

## Key Results
- PSYCHIC achieves 00.18% F1 for question answering (QA) in the final evaluation phase.
- PSYCHIC achieves 71.00% F1 for entity linking (EL) in the final evaluation phase.
- The two-phase evaluation design isolates the impact of missing context on model performance, with perfect scores in the development phase and significant degradation in the final phase.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PSYCHIC's extractive QA design can reliably parse structured SPARQL-query and entity-list outputs when given consistent symbolic delimiters.
- Mechanism: The model is trained on concatenated context strings containing symbolic markers [CLS] and [SEP] that segment query type, template ID, query, and entities. These delimiters teach the model to recognize output boundaries.
- Core assumption: Symbolic tokens provide enough structural grounding for the model to distinguish between query and entity segments.
- Evidence anchors:
  - [abstract] states the model "learns to discriminate between query and entity patterns" via symbolic tokens.
  - [section] explains the context pattern: `[CLS] + QUERY_TYPE + [SEP] + TEMPLATE_ID + [SEP] + QUERY + [SEP] + ENTITIES`.
  - [corpus] evidence is limited: no direct citations found, only related papers mentioning symbolic tokens.
- Break condition: If context lacks these delimiters (e.g., in the final evaluation phase), the model cannot reliably separate query from entities, leading to near-zero F1-QA.

### Mechanism 2
- Claim: Two-phase evaluation (dev vs final) isolates the impact of missing context on extractive QA performance.
- Mechanism: During dev, the input structure matches training; in final, only questions are provided, forcing reliance on an external EL model to supply entity lists.
- Core assumption: PSYCHIC's performance depends critically on having a structured context input.
- Evidence anchors:
  - [section] describes the dev phase achieving perfect scores and the final phase dropping to 00.18% F1-QA.
  - [section] notes that the final phase input "contains no accompanying context for questions."
  - [corpus] does not cite similar dev/final setups, so this is a novel experimental design.
- Break condition: If the external EL predictions are noisy or misaligned, PSYCHIC cannot recover the necessary context, hurting both QA and EL performance.

### Mechanism 3
- Claim: The neuro-symbolic pipeline leverages symbolic post-processing to correct malformed outputs from the extractive model.
- Mechanism: Query and entity sanitizers split the raw output string by [SEP] and validate against SPARQL and entity patterns, fixing formatting errors.
- Core assumption: Most errors are syntactic (missing brackets, wrong spacing) rather than semantic.
- Evidence anchors:
  - [section] details how sanitizers transform malformed SPARQL strings into valid queries and entity lists.
  - [section] explains that sanitizers perform "error-correction to account for malformed strings returned by the model."
  - [corpus] does not cite similar sanitizer approaches; this is a unique design choice.
- Break condition: If the model's output deviates too far from expected patterns, sanitizers cannot recover, leading to failed query execution or incorrect entity lists.

## Foundational Learning

- Concept: Structured query generation via symbolic markers
  - Why needed here: PSYCHIC must produce syntactically valid SPARQL and entity lists from a single string output; markers help segment and identify each component.
  - Quick check question: What would happen if you removed [CLS] and [SEP] tokens from the training context?
- Concept: Extractive QA vs. generative QA trade-offs
  - Why needed here: The choice of extractive QA confines the model to picking answer chunks from context, simplifying output consistency but requiring complete context.
  - Quick check question: How would performance differ if a generative model were used instead of extractive?
- Concept: Two-phase evaluation design
  - Why needed here: Comparing dev (context-present) and final (context-absent) phases isolates the effect of input structure on model performance.
  - Quick check question: Why is it important to have a dev phase with identical input to training?

## Architecture Onboarding

- Component map:
  - Question and paraphrase (seed data) or question alone (final phase) -> Context builder -> PSYCHIC model -> Sanitizers -> SPARQL executor -> Answer
  - EL predictor (Final phase only) -> Supplies entity lists when context is missing
- Critical path: Question → Context builder → PSYCHIC → Sanitizers → SPARQL executor → Answer
- Design tradeoffs:
  - Using extractive QA ensures output consistency but limits flexibility in handling open-ended questions.
  - Relying on symbolic delimiters simplifies training but makes the model brittle to context changes.
  - Two-phase evaluation provides clear performance attribution but increases experimental complexity.
- Failure signatures:
  - Near-zero F1-QA: Missing or mismatched context delimiters in input.
  - Malformed SPARQL: Sanitizer fails to correct output string.
  - Wrong entities: EL predictor outputs incorrect or incomplete entity lists.
- First 3 experiments:
  1. Train PSYCHIC with and without symbolic delimiters; compare dev F1 scores to validate delimiter importance.
  2. Evaluate on final-phase data using ground-truth entities vs. EL-predicted entities; measure performance gap.
  3. Introduce noise into the output string (e.g., random spacing, missing brackets) and test sanitizer robustness.

## Open Questions the Paper Calls Out

- Open Question 1: How does the performance of PSYCHIC change when using different types of symbolic tokens or token arrangements in the context?
  - Basis in paper: [explicit] The paper mentions using symbolic tokens ([CLS], [SEP]) in the context to help the model discriminate between query and entity patterns.
  - Why unresolved: The paper does not explore the impact of different symbolic token configurations or arrangements on the model's performance.
  - What evidence would resolve it: Comparative experiments using different symbolic token configurations or arrangements in the context and measuring the resulting F1-QA and F1-EL scores.

- Open Question 2: How would the performance of PSYCHIC change if the model were trained on a larger and more diverse dataset?
  - Basis in paper: [inferred] The paper mentions using DBLP-QUAD dataset for training, which contains 10,000 question-SPARQL pairs.
  - Why unresolved: The paper does not explore the impact of training on a larger and more diverse dataset on the model's performance.
  - What evidence would resolve it: Experiments training PSYCHIC on larger and more diverse datasets and comparing the resulting F1-QA and F1-EL scores with the current results.

- Open Question 3: How does the performance of PSYCHIC change when using different entity linking approaches in the final phase?
  - Basis in paper: [explicit] The paper mentions using an entity linker provided by the task organizers in the final phase.
  - Why unresolved: The paper does not explore the impact of using different entity linking approaches on the model's performance in the final phase.
  - What evidence would resolve it: Experiments using different entity linking approaches in the final phase and comparing the resulting F1-QA and F1-EL scores with the current results.

## Limitations
- The model's performance heavily depends on the presence of symbolic context delimiters, making it brittle to input structure changes.
- The sanitizer module's error correction rules are underspecified, leaving uncertainty about its robustness to noisy outputs.
- The entity linker's integration and performance are not detailed, making it difficult to assess its impact on final-phase results.

## Confidence
- **High Confidence**: The mechanism by which symbolic tokens ([CLS], [SEP]) help PSYCHIC differentiate between query and entity segments is well-supported by the described context structure and the observed perfect scores in the dev phase.
- **Medium Confidence**: The claim that the two-phase evaluation isolates the impact of missing context is plausible, given the stark performance drop in the final phase, but the lack of detailed explanation of the entity linker's performance leaves some uncertainty.
- **Low Confidence**: The robustness of the sanitizer module to malformed outputs is asserted but not empirically validated, leaving uncertainty about its reliability in diverse scenarios.

## Next Checks
1. **Delimiter Sensitivity Test**: Train two versions of PSYCHIC—one with symbolic delimiters ([CLS], [SEP]) and one without—on the same dataset. Compare their dev F1 scores to quantify the importance of these markers for structured output parsing.
2. **EL Predictor Impact Analysis**: Run the final-phase evaluation twice: once with ground-truth entities and once with EL-predicted entities. Measure the difference in F1-QA and F1-EL to isolate the contribution of entity linking accuracy to overall performance.
3. **Sanitizer Robustness Evaluation**: Generate synthetic noisy outputs (e.g., missing brackets, extra spaces, wrong delimiters) and test whether the sanitizer can recover valid SPARQL queries and entity lists. Measure the success rate to assess sanitizer reliability.