---
ver: rpa2
title: Do Language Models Learn about Legal Entity Types during Pretraining?
arxiv_id: '2310.13092'
source_url: https://arxiv.org/abs/2310.13092
tags:
- entity
- legal
- types
- entities
- type
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the ability of language models to acquire
  domain-specific legal knowledge during pretraining, focusing on legal entity typing
  as a proxy task. The study systematically evaluates different language models, including
  generic BERT-based models and a decoder-only model (Llama2), on the task of identifying
  legal entity types in text.
---

# Do Language Models Learn about Legal Entity Types during Pretraining?

## Quick Facts
- arXiv ID: 2310.13092
- Source URL: https://arxiv.org/abs/2310.13092
- Reference count: 8
- Primary result: Llama2 performs well on certain legal entity types with optimized prompts, while law-oriented LMs show inconsistent performance

## Executive Summary
This paper investigates whether language models acquire legal knowledge during pretraining by evaluating their ability to perform legal entity typing. The study uses zero-shot prompting to test both generic and law-specific language models on identifying legal entity types in Canadian Refugee Decisions. Two prompting strategies are employed: cloze-style for BERT-based models and QA-style for Llama2. Results show that while models can type entities including multi-token ones, they struggle with domain-specific refugee law entities, and law-oriented LMs perform inconsistently compared to generic models.

## Method Summary
The study evaluates legal entity typing using zero-shot prompting without fine-tuning. It employs the AsyLex dataset of 19,115 annotated Canadian Refugee Decisions and tests multiple models including RoBERTa, DeBERTa, CaseHOLD, Pile of Law, LexLM, and Llama2. Two prompting strategies are used: cloze-style prompts where entities are masked for BERT-based models, and QA-style prompts for Llama2. The models predict from a predefined list of 151 entity types, with performance measured using recall and F1 scores.

## Key Results
- Llama2 performs well on certain legal entity types and shows potential for improvement with optimized prompts
- Law-oriented LMs exhibit inconsistent performance compared to generic BERT-based models
- All models struggle with entities specific to the refugee law sub-domain, with some achieving as low as 0.006 recall for CASE_DECISION

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cloze-style prompts enable BERT-based models to leverage their masked language modeling (MLM) objective for entity typing.
- Mechanism: By masking entities in input sentences, BERT-based models can predict the masked tokens using contextual information, effectively inferring the entity type from surrounding words.
- Core assumption: The MLM objective during pretraining has embedded sufficient syntactic and semantic cues for the model to recognize entity types.
- Evidence anchors:
  - [abstract] "We use cloze-style prompts that perfectly fit masked language models (MLM). We replace the entities in the sentences with a masked token and use BERT-based models with an MLM objective."
  - [section 5.3] "Multi-token entities are substituted with a single masked token."
- Break condition: If the masked entity is too abstract or the context is insufficient, the model may fail to infer the correct type.

### Mechanism 2
- Claim: QA-style prompts allow Llama2 to use its autoregressive generation capability for entity typing.
- Mechanism: By framing the task as a question-answering problem, Llama2 can generate entity type predictions based on the given entity and predefined list of types.
- Core assumption: Llama2's pretraining on diverse text corpora has provided it with enough general knowledge to infer entity types from contextual cues.
- Evidence anchors:
  - [abstract] "We introduce the use of autoregressive LM (Llama2) in a zero-shot setting, similar to the approach employed in Epure and Hennequin (2022)."
  - [section 5.4] "To provide a simple task framing, we prompt the language model according to the following template: 'What entity types is {entity}?'"
- Break condition: If the prompt template is not well understood or the entity is highly domain-specific, Llama2 may generate incorrect or irrelevant answers.

### Mechanism 3
- Claim: Legal entity typing can be performed without extensive fine-tuning by leveraging the knowledge acquired during pretraining.
- Mechanism: The models can use their pre-existing knowledge of language structure and domain-specific vocabulary to classify entities into types, even without task-specific training.
- Core assumption: The pretraining corpora, especially for legal LMs, contain sufficient examples of legal entities and their contexts to enable zero-shot entity typing.
- Evidence anchors:
  - [abstract] "We propose to explore the task of Entity Typing, serving as a proxy for evaluating legal knowledge as an essential aspect of text comprehension."
  - [section 3.2] "The legal LMs exhibit a greater overlap in vocabulary compared to their counterparts with generic training."
- Break condition: If the entity is too niche or the model has not encountered similar contexts during pretraining, performance will degrade significantly.

## Foundational Learning

- Concept: Masked Language Modeling (MLM)
  - Why needed here: MLM is the core mechanism that allows BERT-based models to predict masked tokens and infer entity types from context.
  - Quick check question: What happens when a BERT-based model encounters a masked entity in a sentence during entity typing?

- Concept: Autoregressive Generation
  - Why needed here: Llama2 uses autoregressive generation to produce entity type predictions in response to QA-style prompts.
  - Quick check question: How does Llama2 generate an answer when prompted with "What entity type is X?"?

- Concept: Zero-shot Learning
  - Why needed here: The experiments rely on the models' ability to perform entity typing without task-specific fine-tuning, using only their pretraining knowledge.
  - Quick check question: What is the main advantage of using zero-shot learning for entity typing in this study?

## Architecture Onboarding

- Component map:
  Input sentences with masked entities (Experiment MLM) or entities with QA prompts (Experiment Llama2) -> BERT-based models (RoBERTa, DeBERTa, CaseHOLD, Pile of Law, LexLM) and Llama2 -> Predicted entity types from predefined list of 151 types -> Recall and F1 score metrics

- Critical path:
  1. Prepare dataset with gold-standard entity type annotations
  2. Generate prompts (cloze or QA style) for each entity
  3. Run prompts through the selected models
  4. Collect predictions and compare against gold labels
  5. Analyze results by entity type, prompt type, and model performance

- Design tradeoffs:
  - Using a large predefined list of entity types increases task difficulty but improves generalizability
  - Cloze-style prompts provide less context than QA-style prompts, potentially reducing accuracy
  - Multi-token entities add complexity but reflect real-world legal text better than single-token entities

- Failure signatures:
  - Random predictions indicate the model is not leveraging context effectively
  - Contextually accurate but incorrect predictions suggest the model understands syntax but not semantics
  - Closely related predictions reveal subtle distinctions between entity types that the model struggles with

- First 3 experiments:
  1. Evaluate BERT-based models on cloze-style prompts with single-token entities
  2. Evaluate Llama2 on QA-style prompts with single-token entities
  3. Compare performance across entity types grouped by generality (generic, legal, refugee law-specific)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of legal entity typing models vary across different refugee law sub-domains?
- Basis in paper: [explicit] The paper notes that "all models struggle with entities belonging to sub-domains of the law."
- Why unresolved: The study focuses on a general dataset of Canadian Refugee Decisions without analyzing performance differences across specific sub-domains of refugee law.
- What evidence would resolve it: Detailed analysis of model performance on entity types specific to different refugee law sub-domains, such as asylum seekers vs. refugee status determinations.

### Open Question 2
- Question: What is the impact of using larger language models on legal entity typing performance?
- Basis in paper: [inferred] The paper uses relatively small models (e.g., RoBERTa, DeBERTa, Llama2) and notes potential for improvement with optimized prompts.
- Why unresolved: The study does not explore the use of larger language models, which might have better capacity for legal entity typing.
- What evidence would resolve it: Experiments comparing the performance of smaller models (used in the study) with larger models on the same legal entity typing task.

### Open Question 3
- Question: How does the inclusion of contextual information beyond the input sentence affect legal entity typing accuracy?
- Basis in paper: [explicit] The paper notes that "LMs demonstrate the ability to type entities even in the case of multi-token entities" but also mentions the lack of extra context provided.
- Why unresolved: The study limits context to the input sentence, but legal entities often require broader context for accurate typing.
- What evidence would resolve it: Experiments comparing model performance with and without additional contextual information from surrounding sentences or the entire document.

## Limitations

- The performance comparison between Llama2 and BERT-based models is problematic due to their fundamentally different prompting strategies (QA-style vs cloze-style)
- Law-specific LMs perform inconsistently and worse than generic models on generic entities, with no clear explanation for this counterintuitive finding
- All models struggle significantly with domain-specific refugee law entities, suggesting pretraining corpora may not adequately represent specialized legal domains

## Confidence

- High: BERT-based models' ability to perform cloze-style entity typing
- Medium: Llama2's general capability for entity typing with QA prompts
- Low: Explanations for law-specific LM underperformance

## Next Checks

1. Replicate the entity typing experiments using identical prompting strategies (QA-style) for both BERT-based models and Llama2 to enable fair performance comparison
2. Analyze the pretraining corpora of all evaluated models to identify specific knowledge gaps for refugee law entities and correlate these with prediction failures
3. Conduct ablation studies varying prompt context length and template wording to quantify their impact on Llama2's performance variability