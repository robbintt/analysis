---
ver: rpa2
title: Word Sense Disambiguation as a Game of Neurosymbolic Darts
arxiv_id: '2307.16663'
source_url: https://arxiv.org/abs/2307.16663
tags:
- sense
- word
- senses
- ball
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a novel neurosymbolic methodology for Word Sense
  Disambiguation (WSD) that achieves over 90% F1 score. The core idea is to represent
  word senses as regions (balls) in vector space, where inclusion relations among
  balls encode symbolic hypernym relations among senses.
---

# Word Sense Disambiguation as a Game of Neurosymbolic Darts

## Quick Facts
- arXiv ID: 2307.16663
- Source URL: https://arxiv.org/abs/2307.16663
- Reference count: 0
- Primary result: Achieves over 90% F1 score on WSD tasks using neurosymbolic approach with ball embeddings

## Executive Summary
This paper introduces a novel neurosymbolic approach to Word Sense Disambiguation (WSD) that represents word senses as regions (balls) in vector space, where inclusion relations among balls encode hypernym relationships. A Transformer network learns to map contextualized word embeddings to sense ball centers, treating WSD as a game of "darts" where the goal is to place embeddings inside the correct sense ball region. The method achieves exceptional performance (90.1%-100.0% F1) across six benchmark datasets by combining the reasoning power of symbolic hypernym structures with the learning capability of neural networks.

## Method Summary
The approach uses pre-trained n-ball embeddings where each word sense is represented as a ball with a center and radius in vector space. The Transformer takes contextualized word embeddings as input and outputs vectors that are compared via cosine similarity to hypernym ball centers. The sense whose direct hypernym ball has the highest similarity is selected. This neurosymbolic framework leverages the geometric representation of taxonomic hierarchies while using neural networks for the mapping function, requiring significantly less training data than pure supervised methods.

## Key Results
- Achieves F1 scores ranging from 90.1% to 100.0% across six benchmark WSD datasets
- Demonstrates superior performance compared to traditional supervised deep learning approaches
- Shows that mapping to hypernym ball centers is more effective than direct sense ball mapping

## Why This Works (Mechanism)

### Mechanism 1
Representing word senses as nested balls in vector space enables precise encoding of hypernym relationships. Each sense is mapped to a ball whose inclusion relations encode taxonomic hierarchies, with child senses contained within parent sense balls. This assumes the hypernym structure can be geometrically embedded without loss into nested ball configurations.

### Mechanism 2
Mapping contextualized embeddings to sense ball centers is easier than mapping to exact sense vectors. The neural network learns to place contextualized embeddings inside the correct sense ball region rather than hitting an exact point, assuming the ball radius is large enough to tolerate variance while preserving semantic distinction.

### Mechanism 3
Using direct hypernym balls for disambiguation leverages implicit sense information without requiring exact sense matching. The network maps to the center of the direct hypernym ball, and the intended sense is selected from senses within that ball, assuming sibling senses under the same hypernym have similar enough embeddings for this approach to work.

## Foundational Learning

- **Vector space geometry and distance metrics**: The method relies on geometric relationships (inclusion, distance to centers) to represent and reason about senses. Quick check: How would you determine if one ball is inside another using their center coordinates and radii?

- **Hypernymy and taxonomic hierarchies**: The ball nesting structure directly encodes WordNet's hypernym hierarchy. Quick check: What is the hypernym path for "apple.n.01" in WordNet?

- **Transformer architecture basics**: The model uses a Transformer to map contextualized embeddings to ball centers. Quick check: What is the role of the attention mechanism in capturing context for word sense disambiguation?

## Architecture Onboarding

- **Component map**: Word embedding layer (GloVe 50D) -> Context extraction (average of k-window neighbors) -> Transformer encoder (sequence-to-sequence mapping) -> Perceptron layers (linear + ReLU + linear) -> Ball geometry module (cosine similarity to hypernym ball centers) -> Hypernym structure (precomputed from WordNet)

- **Critical path**: Context → Transformer → Ball center → Cosine similarity → Sense selection

- **Design tradeoffs**: Using hypernym balls instead of exact sense balls trades some precision for geometric reasoning power and reduced data requirements

- **Failure signatures**: Poor performance on verbs with shared hypernyms; degraded results when ball sizes are poorly calibrated

- **First 3 experiments**: 1) Train with sense balls as targets (baseline) 2) Train with direct hypernym balls as targets 3) Train with second-level hypernym balls as targets

## Open Questions the Paper Calls Out

### Open Question 1
How would performance change if we replaced the cosine similarity loss function with spatial functions that explicitly account for topological relations among regions? The paper suggests this would be promising but lacks experimental evidence.

### Open Question 2
How would performance change if we extended n-ball embeddings to cover all missing senses and related hypernym relations? Current experiments are limited by coverage (~58-72% of senses).

### Open Question 3
How would performance change if we used a different Transformer architecture that learns contextualized word embeddings more effectively than the current approach using average neighborhood word embeddings?

## Limitations

- The geometric interpretation of hypernym hierarchies as nested ball embeddings is elegant but unverified and may not capture all taxonomic structures
- Exceptionally high F1 scores (90.1%-100.0%) lack transparency in computation methodology and may be inflated
- The approach struggles with verb senses and cases where multiple senses share the same hypernym, limiting real-world applicability

## Confidence

- **High confidence**: The core mechanism of using geometric embeddings to represent word senses is sound and the basic experimental framework is reproducible
- **Medium confidence**: The claim that training on hypernym ball centers is easier than direct sense matching is plausible but requires more rigorous comparison
- **Low confidence**: The exceptionally high performance metrics and the assertion that this approach "breaks the ceiling" of deep learning methods for WSD are not fully substantiated

## Next Checks

1. **Geometric Feasibility Test**: Verify that the WordNet hypernym hierarchy can be embedded into nested ball configurations without violations

2. **Alternative Hypernym Path Analysis**: Systematically test disambiguation performance using different hypernym path lengths to determine if the direct hypernym choice is optimal

3. **Sense Coverage Stress Test**: Evaluate model performance on senses that lack complete hypernym coverage in the n-ball embeddings, particularly verbs and cases where multiple senses share the same hypernym