---
ver: rpa2
title: PromptASR for contextualized ASR with controllable style
arxiv_id: '2309.07414'
source_url: https://arxiv.org/abs/2309.07414
tags:
- text
- prompt
- style
- promptasr
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PromptASR integrates text prompts into end-to-end ASR systems to
  enable contextualized recognition with controllable transcription style. A dedicated
  text encoder processes content prompts (e.g., previous utterances or rare-word lists)
  and style prompts (e.g., casing and punctuation) via cross-attention with speech
  encoder features.
---

# PromptASR for contextualized ASR with controllable style

## Quick Facts
- arXiv ID: 2309.07414
- Source URL: https://arxiv.org/abs/2309.07414
- Reference count: 0
- Key outcome: 21.9% relative WER reduction on book reading data using ground truth preceding text as content prompts

## Executive Summary
PromptASR introduces a novel approach to contextualized automatic speech recognition by integrating text prompts into end-to-end ASR systems. The system employs a dedicated text encoder to process content prompts (such as preceding utterances or rare-word lists) and style prompts (controlling casing and punctuation) through cross-attention with speech encoder features. This unified framework achieves significant improvements in recognition accuracy while enabling controllable transcription style, addressing both utterance-level and word-level context biasing in a single system.

## Method Summary
PromptASR extends standard end-to-end ASR systems by adding a pre-trained text encoder (BERT or in-domain transformer) that processes text prompts and injects them into the speech encoder via cross-attention layers. During training, the system uses SpecAug and MUSAN for data augmentation, with occasional prompt dropout to improve robustness. The model is trained with RNN-T loss on Libriheavy and in-house NPR datasets, with evaluation on Libriheavy test sets and NPR evaluation data. Content prompts include ground truth preceding text or rare-word lists, while style prompts control output formatting through casing and punctuation indicators.

## Key Results
- 21.9% relative WER reduction on book reading data using ground truth preceding text as content prompts
- 13.4% relative WER reduction for word-level biasing with rare-word lists even with 1000 distractors
- Successful control of output formatting through style prompts for casing and punctuation

## Why This Works (Mechanism)

### Mechanism 1
Cross-attention fusion of text and speech embeddings improves ASR accuracy through modality alignment. The text encoder produces prompt embeddings that are injected into the speech encoder through cross-attention layers, where text embeddings serve as query and acoustic features as key/value pairs. This approach assumes effective semantic alignment between text and speech modalities can be achieved without joint training from scratch.

### Mechanism 2
Content prompts provide contextual information that reduces recognition errors by encoding ground truth preceding text or word lists to provide context about topic, logical relationships, or rare word biasing. This mechanism assumes that context from preceding utterances or word lists is semantically relevant and can be effectively encoded to influence current recognition.

### Mechanism 3
Style prompts control output formatting (casing, punctuation) through style indicators added to style prompt embeddings, which guide the decoder to produce transcriptions in specified formats. This mechanism assumes the style prompt can effectively signal desired output format without interfering with content recognition.

## Foundational Learning

- **Cross-attention mechanisms in multimodal learning**: Critical for understanding how text and speech modalities are fused through cross-attention without requiring joint training from scratch. Quick check: Can you explain how cross-attention differs from self-attention in transformer architectures?

- **Prompt engineering for language models**: Essential for understanding how text prompts guide ASR generation similarly to LLMs. Quick check: What are the key differences between zero-shot, few-shot, and prompt-based approaches in LLMs?

- **Biasing strategies in ASR systems**: Important for understanding how traditional n-gram language model biasing approaches differ from neural context biasing methods implemented through prompts.

## Architecture Onboarding

- **Component map**: Pre-trained text encoder → cross-attention layers in speech encoder → ASR decoder → output
- **Critical path**: Text prompt encoding → cross-attention fusion → acoustic feature processing → joint decoding
- **Design tradeoffs**: Pre-trained text encoder provides strong semantic understanding but adds computational overhead and requires careful alignment with speech features
- **Failure signatures**: Degraded performance when prompts are irrelevant, style conflicts with content, or cross-attention becomes unstable
- **First 3 experiments**: 1) Baseline ASR without prompts vs PromptASR with ground truth preceding text as content prompt 2) Word-level biasing performance with varying distractor ratios (N=100, 500, 1000) 3) Style control evaluation comparing mixed-cased with punctuation vs upper-cased without punctuation outputs

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions but several critical unresolved issues emerge from the analysis. The relationship between content prompt size and performance across different tasks remains unexplored, with no systematic analysis of how varying prompt lengths impacts recognition accuracy. The system's behavior with ambiguous or contradictory prompts is not thoroughly evaluated beyond basic robustness training through prompt dropout. Additionally, the computational overhead of integrating the text encoder is not quantified, leaving open questions about practical deployment constraints including inference latency, memory usage, and energy consumption.

## Limitations

- Limited evaluation scope focused on book reading and conversational podcast data, with insufficient testing on spontaneous speech or diverse acoustic conditions
- Cross-attention alignment quality and failure cases not thoroughly analyzed, with potential modality mismatch issues from pre-trained BERT text encoding
- Style control evaluation restricted to basic formatting without exploring nuanced stylistic controls like formality levels or domain-specific conventions

## Confidence

- **High Confidence**: 21.9% relative WER reduction on book reading data using ground truth preceding text as content prompt
- **Medium Confidence**: 13.4% relative WER reduction for word-level biasing with rare-word lists
- **Medium Confidence**: Successful control of output formatting through style prompts for casing and punctuation

## Next Checks

1. **Cross-Modal Alignment Analysis**: Conduct qualitative and quantitative analysis of cross-attention alignment quality, including attention weight visualizations and error analysis for misaligned prompts.

2. **Real-World Distractor Evaluation**: Test word-level biasing performance with domain-shifted distractor sets and varying distractor ratios beyond the 1000 distractor evaluation.

3. **Style Control Robustness Testing**: Evaluate style prompt robustness across diverse content types, including testing for style interference with content recognition and multi-style prompting capabilities.