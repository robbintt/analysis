---
ver: rpa2
title: Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts
arxiv_id: '2308.08810'
source_url: https://arxiv.org/abs/2308.08810
tags:
- label
- shift
- adapter
- distribution
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of test-time adaptation (TTA)
  when both source and target domains have class-imbalanced label distributions, which
  previous TTA methods often fail to handle. The authors propose a novel label shift
  adapter that produces optimal parameters according to the target label distribution
  during inference.
---

# Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts

## Quick Facts
- arXiv ID: 2308.08810
- Source URL: https://arxiv.org/abs/2308.08810
- Reference count: 40
- Key outcome: A novel label shift adapter improves test-time adaptation under simultaneous covariate and label shifts, particularly when both source and target domains have class-imbalanced label distributions.

## Executive Summary
This paper addresses the challenge of test-time adaptation (TTA) when both source and target domains have class-imbalanced label distributions, which previous TTA methods often fail to handle. The authors propose a novel label shift adapter that produces optimal parameters according to the target label distribution during inference. The adapter is trained before deployment using a pre-trained source model and various simulated label distributions. At test time, it estimates the target label distribution and generates parameters to adapt the model, improving robustness under covariate and label shifts. Extensive experiments on six benchmarks show significant performance gains over state-of-the-art TTA methods when integrated with approaches like TENT and IABN, particularly under severe label shifts. The method is architecture-agnostic and computationally efficient, requiring negligible additional parameters.

## Method Summary
The Label Shift Adapter (LSA) is a hypernetwork that generates optimal parameters for a pre-trained source model based on the estimated target label distribution. During training, LSA learns to map various simulated label distributions to parameter adjustments using a frozen source model. At inference, LSA estimates the target label distribution through exponential moving average of model predictions and generates classifier weight deltas and feature affine parameters. These generated parameters adapt the source model to the target domain's label distribution during test-time adaptation, improving performance under both covariate and label shifts.

## Key Results
- LSA significantly outperforms state-of-the-art TTA methods (TENT, IABN) when integrated, particularly under severe label shifts
- LSA shows consistent improvements across six benchmark datasets (CIFAR-10-C, CIFAR-100-C, ImageNet-C, VisDA-C, OfficeHome, DomainNet)
- The adapter effectively estimates various label distributions and generates optimal parameters, as demonstrated by ablation studies
- LSA is architecture-agnostic and computationally efficient, requiring negligible additional parameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The label shift adapter generates optimal parameters conditioned on target label distribution, enabling stable adaptation under label shifts.
- Mechanism: The adapter network takes an estimated target label distribution vector as input and produces classifier weight deltas (∆W, ∆b) and feature affine parameters (γh, βh). These deltas adjust the source model to match the target domain's label distribution during test-time adaptation.
- Core assumption: The adapter can learn a mapping from label distribution vectors to optimal parameter adjustments through training on simulated label distributions.
- Evidence anchors:
  - [abstract] "we estimate the label distribution of the target domain to feed it into the label shift adapter. Subsequently, the label shift adapter produces optimal parameters for target label distribution."
  - [section 3.2] "The label shift adapter Gϕ receives the label distribution π ∈ RC as conditional input... the label shift adapter Gϕ predicts affine parameters γh ∈ R1×d, βh ∈ R1×d and the weight difference ∆W ∈ Rd×C, ∆b ∈ R1×C"
  - [corpus] Weak evidence - no direct mention of adapter architecture in related works
- Break condition: If the estimated label distribution is inaccurate, the generated parameters may not optimally adapt the model.

### Mechanism 2
- Claim: Using a mapping vector m⊺π instead of direct π as input improves label shift adapter training stability.
- Mechanism: The adapter receives a scalar input m⊺π representing the degree of imbalance rather than the full label distribution vector. This simplifies the condition space and makes training more stable.
- Core assumption: The scalar degree of imbalance is sufficient information for the adapter to produce appropriate parameter adjustments.
- Evidence anchors:
  - [section 3.2] "We discovered that it is more effective to utilize a mapping vector m ∈ RC to make the label distribution π a scalar, instead of directly using label distribution π as the input of the label shift adapter."
  - [corpus] No direct evidence - this appears to be a novel architectural choice
- Break condition: If the scalar representation loses critical information about the label distribution structure, adaptation performance may degrade.

### Mechanism 3
- Claim: Estimating target label distribution through exponential moving average of model predictions enables dynamic adaptation.
- Mechanism: At each inference step t, the adapter estimates the target label distribution ˆYt using a momentum update: ˆYt = α¯yt + (1 − α)ˆYt−1, where ¯yt is the average prediction on the current batch.
- Core assumption: Model predictions become increasingly accurate as adaptation progresses, making the moving average a reliable estimate of the true target label distribution.
- Evidence anchors:
  - [section 3.2] "To estimate the label distribution ˆY of Dt, we employ an exponential moving average... the estimated target label distribution ˆYt at t-th step is updated recursively"
  - [section 4.4] "This result shows that the model with the label shift adapter is superior for estimating various label distributions compared to the model without the label shift adapter"
  - [corpus] Weak evidence - similar EMA approaches exist but not specifically for label distribution estimation
- Break condition: If the source model is highly biased, early predictions may be poor, causing the EMA to converge to an inaccurate estimate.

## Foundational Learning

- Concept: Label shift vs covariate shift distinction
  - Why needed here: Understanding the difference between distribution shifts in input space (covariate) versus label space (label) is fundamental to grasping why existing TTA methods fail under label shifts.
  - Quick check question: What is the key difference between ps(x) ̸= pt(x) and ps(y) ̸= pt(y) in terms of their impact on model performance?

- Concept: Hypernetwork architecture
  - Why needed here: The label shift adapter is a hypernetwork that generates weights for another network, so understanding this architecture pattern is crucial for implementation.
  - Quick check question: How does a hypernetwork differ from standard neural network architectures in terms of its input-output relationship?

- Concept: Long-tailed recognition techniques
  - Why needed here: The paper builds on long-tailed recognition methods like balanced softmax and inverse softmax, so familiarity with these techniques is necessary to understand the adaptation strategy.
  - Quick check question: How does balanced softmax modify the standard softmax to handle class imbalance during training?

## Architecture Onboarding

- Component map: Input (estimated label distribution) → Label shift adapter → Parameter adjustments → Adapted model → Prediction

- Critical path: Estimated label distribution vector → Label shift adapter Gϕ → Parameter adjustments (∆W, ∆b, γh, βh) → Adapted classifier and feature normalization layers → Prediction

- Design tradeoffs:
  - Adapter predicts only partial parameters (not entire model) for efficiency
  - Uses scalar input rather than full distribution vector for stability
  - Estimates label distribution online rather than requiring prior knowledge

- Failure signatures:
  - Poor adaptation when source model is highly biased
  - Suboptimal performance if estimated label distribution diverges from true distribution
  - Potential overfitting if adapter is too complex relative to training data

- First 3 experiments:
  1. Verify adapter produces reasonable parameter adjustments for simple synthetic label distributions
  2. Test label distribution estimation accuracy on controlled datasets with known shifts
  3. Validate that adapter integration with TENT/IABN improves performance over baselines on CIFAR-10-C with varying label shifts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method compare to other long-tailed recognition approaches, such as LADE and SADE, in terms of computational efficiency and accuracy?
- Basis in paper: [explicit] The authors mention that LADE, SADE, and BalPoE are difficult to apply to TTA algorithms due to their multiple expert architectures and requirement for true test label distribution.
- Why unresolved: The authors do not provide a direct comparison between their method and LADE, SADE, or BalPoE in terms of computational efficiency and accuracy.
- What evidence would resolve it: A direct comparison of the proposed method with LADE, SADE, and BalPoE in terms of computational efficiency and accuracy on the same benchmark datasets used in the paper.

### Open Question 2
- Question: How does the proposed method perform when applied to other types of distribution shifts, such as class-imbalanced test samples or temporally correlated test data?
- Basis in paper: [inferred] The authors mention that recent TTA studies have addressed similar challenging issues, such as temporally correlated test data and class-imbalanced test samples, but do not cover the situation where the source domain data has a long-tailed label distribution.
- Why unresolved: The authors do not provide experimental results on the performance of the proposed method when applied to other types of distribution shifts, such as class-imbalanced test samples or temporally correlated test data.
- What evidence would resolve it: Experimental results on the performance of the proposed method when applied to other types of distribution shifts, such as class-imbalanced test samples or temporally correlated test data, on the same benchmark datasets used in the paper.

### Open Question 3
- Question: How does the proposed method handle the case when the target label distribution is highly skewed, with a few dominant classes and many rare classes?
- Basis in paper: [explicit] The authors mention that the proposed method is designed to handle label distribution shifts in TTA, but do not provide specific information on how it handles highly skewed target label distributions.
- Why unresolved: The authors do not provide experimental results on the performance of the proposed method when the target label distribution is highly skewed, with a few dominant classes and many rare classes.
- What evidence would resolve it: Experimental results on the performance of the proposed method when the target label distribution is highly skewed, with a few dominant classes and many rare classes, on the same benchmark datasets used in the paper.

## Limitations

- The method's performance heavily depends on accurate estimation of target label distributions, and poor initial estimates can lead to suboptimal adaptation
- Hyperparameter sensitivity, particularly the choice of τ values for different datasets, is not thoroughly explored and may impact performance
- While claimed to be architecture-agnostic, the method has only been validated on ResNet and Swin architectures, limiting generalizability claims

## Confidence

**High Confidence**: The core mechanism of using a hypernetwork to generate parameter adjustments conditioned on estimated label distributions is technically sound and well-supported by the experimental results. The integration with established TTA methods (TENT, IABN) is straightforward and demonstrates consistent improvements across multiple benchmarks.

**Medium Confidence**: The claim that using a scalar mapping vector m⊺π instead of the full label distribution vector improves training stability is supported by the authors' empirical findings but lacks theoretical justification. The assertion that the adapter learns a robust mapping across various label distributions is plausible but not extensively validated across diverse scenarios.

**Low Confidence**: The paper's assertion that the method is "architecture-agnostic" is based on experiments with ResNet-50 and Swin-Tiny architectures, which may not be representative of all possible architectures. Additionally, the claim about computational efficiency being "negligible" lacks quantitative evidence comparing parameter counts and inference times with and without the adapter.

## Next Checks

1. **Robustness to Label Distribution Estimation Errors**: Systematically evaluate performance degradation when the initial label distribution estimate is intentionally biased by varying degrees, using datasets with known ground truth label distributions.

2. **Hyperparameter Sensitivity Analysis**: Conduct a comprehensive ablation study varying τ values across all datasets to quantify the sensitivity of performance to these hyperparameters and identify optimal selection strategies.

3. **Architectural Generalization Test**: Implement and evaluate the label shift adapter on architectures substantially different from ResNet and Swin (e.g., vision transformers with different patch sizes, or convolutional architectures with varying depths) to validate the claimed architecture-agnostic nature.