---
ver: rpa2
title: Can We Utilize Pre-trained Language Models within Causal Discovery Algorithms?
arxiv_id: '2311.11212'
source_url: https://arxiv.org/abs/2311.11212
tags:
- causal
- prior
- discovery
- graph
- gpt-4
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether pre-trained language models (PLMs)
  can be integrated with causal discovery algorithms to improve causal inference.
  The authors highlight limitations of using PLMs alone for causal reasoning, including
  lack of data analysis, dependence on prompt design, and risk of false predictions.
---

# Can We Utilize Pre-trained Language Models within Causal Discovery Algorithms?

## Quick Facts
- arXiv ID: 2311.11212
- Source URL: https://arxiv.org/abs/2311.11212
- Reference count: 36
- Primary result: Proposed framework combining PLM-derived prior knowledge with score-based causal discovery methods improves performance over vanilla algorithms and PLM reasoning alone

## Executive Summary
This paper investigates integrating pre-trained language models (PLMs) with causal discovery algorithms to improve causal inference. The authors identify limitations of using PLMs alone for causal reasoning, including lack of data analysis, dependence on prompt design, and risk of false predictions. They propose a framework that combines PLM-derived prior knowledge with score-based causal discovery methods by initializing the algorithm's adjacency matrix using PLM predictions and adding regularization to align the learned structure with the PLM prior. Experiments on physics-inspired synthetic data and real-world datasets (Arctic Sea Ice and Sachs) demonstrate that the framework generally improves performance over vanilla causal discovery algorithms and PLM-based reasoning alone.

## Method Summary
The framework integrates PLM-generated prior knowledge into causal discovery algorithms through graph initialization and regularization. First, PLMs generate prior knowledge K by predicting causal relationships between variable pairs using a prompt template. This prior is then incorporated into causal discovery algorithms (NOTEARS, DAG-GNN, CGNN) in two ways: initializing the structural coefficient matrix W with λinit*K, or adding ℓ1-regularization loss between W and K. The framework is evaluated on synthetic datasets based on physics-inspired causal graphs with 3, 5, and 7 nodes, as well as real-world datasets (Arctic Sea Ice with 12 variables and Sachs with 11 variables), using metrics like Structural Hamming Distance, False Discovery Rate, and True Positive Rate.

## Key Results
- Framework reduces false positives and false discovery rates while maintaining or improving true positive rates
- Performance improvements are most pronounced when the number of nodes exceeds three
- Integration of PLM prior knowledge generally outperforms both vanilla causal discovery algorithms and PLM-based reasoning alone

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PLM prior knowledge improves causal discovery by providing an informed initial graph structure and regularization
- Mechanism: The framework initializes the causal discovery algorithm's adjacency matrix using PLM predictions and adds regularization to align the learned structure with the PLM prior. This prevents the algorithm from getting stuck in suboptimal local optima and guides the search toward more plausible causal structures
- Core assumption: The PLM's causal reasoning, though imperfect, provides useful prior knowledge that can be integrated with data-driven causal discovery methods
- Evidence anchors: [abstract] "We propose a framework that combines PLM-derived prior knowledge with score-based causal discovery methods. The framework initializes the causal discovery algorithm's adjacency matrix using PLM predictions and adds regularization to align the learned structure with the PLM prior."

### Mechanism 2
- Claim: PLM-based causal reasoning can bypass data scarcity issues in causal discovery
- Mechanism: By relying solely on text-based descriptions of causal relationships, PLMs can infer causal structures without requiring large datasets. This is particularly useful when dealing with multiple variables where data scarcity is a significant challenge
- Core assumption: PLMs have learned relevant causal knowledge from their pre-training corpus that can be applied to new domains
- Evidence anchors: [abstract] "Causal reasoning of PLM relies solely on text-based descriptions, in contrast to causal discovery which aims to determine the causal relationships between variables utilizing data."

### Mechanism 3
- Claim: Combining PLM reasoning with data-driven causal discovery improves performance over either method alone
- Mechanism: PLM reasoning provides an informed prior that guides the causal discovery algorithm, while the algorithm refines the structure using data. This combination leverages the strengths of both approaches - the PLM's broad knowledge and the algorithm's ability to learn from specific data
- Core assumption: The PLM's causal reasoning, though imperfect, is generally aligned with the true causal structure and can be improved through data-driven learning
- Evidence anchors: [abstract] "Experiments on physics-inspired synthetic data and real-world datasets... show that the proposed framework generally improves performance over vanilla causal discovery algorithms and PLM-based reasoning alone."

## Foundational Learning

- Concept: Causal discovery and its challenges
  - Why needed here: Understanding the limitations of causal discovery algorithms (data scarcity, combinatorial complexity) is crucial for appreciating how PLM integration can help
  - Quick check question: What are the main challenges in causal discovery, and how does the proposed framework address them?

- Concept: Pre-trained Language Models (PLMs) and their capabilities
  - Why needed here: Knowing how PLMs work and their strengths/limitations in causal reasoning is essential for understanding the proposed framework
  - Quick check question: How do PLMs perform causal reasoning, and what are the limitations of this approach?

- Concept: Score-based causal discovery methods
  - Why needed here: The proposed framework integrates PLM prior knowledge with score-based methods, so understanding these methods is crucial
  - Quick check question: What are score-based causal discovery methods, and how do they evaluate candidate causal graphs?

## Architecture Onboarding

- Component map: PLM → Prior knowledge extraction → Causal discovery initialization and regularization → Final causal graph
- Critical path: PLM generates prior knowledge K → Causal discovery algorithm initializes and regularizes using K → Final causal graph is learned
- Design tradeoffs:
  - Using PLM prior vs. relying solely on data: PLM prior can help in data-scarce scenarios but may introduce bias if inaccurate
  - Initialization vs. regularization: Both methods integrate PLM prior, but initialization provides a starting point while regularization guides the learning process
- Failure signatures:
  - Poor performance despite PLM integration: Indicates the PLM prior may be inaccurate or the regularization strength is inappropriate
  - Inconsistent results across datasets: Suggests the framework may not generalize well to different domains
- First 3 experiments:
  1. Test the framework on a synthetic dataset with known causal structure to evaluate its ability to recover the true graph
  2. Compare the framework's performance to vanilla causal discovery and PLM-based reasoning alone on a real-world dataset
  3. Analyze the impact of PLM prior quality on the framework's performance by using different PLM models or prompt designs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the uncertainty of PLM's causal predictions be quantified and incorporated into causal discovery algorithms?
- Basis in paper: [explicit] The paper mentions the need to explore appropriate uncertainty design for PLM-based causal reasoning and suggests defining a certainty matrix C based on the reciprocal of standard deviation of K
- Why unresolved: While the paper proposes a potential method for quantifying uncertainty, it does not provide empirical results or demonstrate the effectiveness of this approach in improving causal discovery performance
- What evidence would resolve it: Experiments comparing the performance of causal discovery algorithms with and without the proposed uncertainty quantification method, using metrics such as SHD, FDR, and TPR, would provide evidence of its effectiveness

### Open Question 2
- Question: How can prompt design be improved to better capture chain structures and intricate causal patterns in PLM-based causal reasoning?
- Basis in paper: [explicit] The paper discusses the limitations of current prompt designs, which focus on pairwise relationships and lack an "unknown" option for PLM, leading to overconfident predictions
- Why unresolved: The paper does not propose specific improvements to prompt design or demonstrate how these improvements would enhance PLM's causal reasoning capabilities
- What evidence would resolve it: Developing and testing new prompt designs that address the limitations mentioned in the paper, followed by experiments comparing their performance with the current designs, would provide evidence of the effectiveness of improved prompt design

### Open Question 3
- Question: How can the sequence of operations in the proposed framework be reorganized to leverage causal discovery outcomes for PLM-based causal reasoning?
- Basis in paper: [explicit] The paper suggests inverting the framework structure by using causal discovery outcomes as prior knowledge for PLM-based causal reasoning, but acknowledges the challenges in implementing this approach
- Why unresolved: The paper does not provide a concrete method for reorganizing the sequence of operations or demonstrate its potential benefits in improving causal discovery performance
- What evidence would resolve it: Developing a method for reorganizing the sequence of operations, implementing it in the proposed framework, and conducting experiments to compare its performance with the original framework would provide evidence of its effectiveness

## Limitations

- Framework effectiveness depends critically on the quality of PLM-generated prior knowledge
- Performance may degrade when PLMs lack relevant causal knowledge for the target domain
- Requires careful hyperparameter tuning of regularization strength, which wasn't fully explored across all dataset conditions

## Confidence

- PLM integration improves causal discovery performance: **Medium** - supported by experimental results but limited to specific datasets
- Regularization prevents suboptimal local optima: **Medium** - theoretically sound but not empirically validated through ablation studies
- Framework reduces false positives while maintaining true positives: **High** - clearly demonstrated in experimental results

## Next Checks

1. Test framework robustness by intentionally corrupting PLM priors with varying degrees of noise to quantify sensitivity to prior quality
2. Conduct ablation studies comparing initialization-only vs regularization-only approaches to isolate their individual contributions
3. Evaluate performance on datasets with different characteristics (e.g., non-linear relationships, discrete variables) to assess generalizability beyond physics-inspired and climate datasets