---
ver: rpa2
title: 'RED CoMETS: An ensemble classifier for symbolically represented multivariate
  time series'
arxiv_id: '2307.13679'
source_url: https://arxiv.org/abs/2307.13679
tags:
- time
- series
- multivariate
- co-eye
- comets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RED CoMETS is a novel ensemble classifier for multivariate time
  series classification that builds on the success of Co-eye. The key innovation is
  a random pair selection process that overcomes a computational bottleneck in Co-eye,
  resulting in a 40x speedup with no loss in accuracy.
---

# RED CoMETS: An ensemble classifier for symbolically represented multivariate time series

## Quick Facts
- arXiv ID: 2307.13679
- Source URL: https://arxiv.org/abs/2307.13679
- Reference count: 32
- Key outcome: 40x speedup over Co-eye with state-of-the-art accuracy on benchmark datasets

## Executive Summary
RED CoMETS is a novel ensemble classifier for multivariate time series classification that builds on the success of Co-eye. The key innovation is a random pair selection process that overcomes a computational bottleneck in Co-eye, resulting in a 40x speedup with no loss in accuracy. Three new voting methods are also proposed. When combined with two multivariate extensions, RED CoMETS achieves state-of-the-art accuracy on benchmark datasets, outperforming methods like ROCKET and HIVE COTE-2.0 on several datasets. Notably, RED CoMETS achieves the highest reported accuracy on the HandMovementDirection dataset.

## Method Summary
RED CoMETS improves upon Co-eye by replacing its computationally expensive grid search with random sampling of parameter pairs for SAX/SFA transformations. The method uses random selection of <α,w> pairs proportional to series length, achieving comparable performance with 40x speedup. Three voting methods replace Co-eye's dynamic voting approach, and two multivariate extensions (concatenation and ensembling) enable the classifier to handle multivariate data. The ensemble combines per-lens Random Forest outputs using weighted aggregation strategies.

## Key Results
- Achieves 40x speedup compared to Co-eye while maintaining accuracy
- Outperforms ROCKET and HIVE COTE-2.0 on several benchmark datasets
- Achieves highest reported accuracy on HandMovementDirection dataset
- Shows particular strength on datasets with minimal phase shifting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Random pair selection replaces grid search to reduce computational cost without accuracy loss.
- Mechanism: Instead of exhaustively evaluating all <α,w> pairs for SAX/SFA, the method randomly samples pairs proportional to series length, achieving comparable performance with 40x speedup.
- Core assumption: Random sampling adequately explores the parameter space to find near-optimal lens combinations.
- Evidence anchors:
  - [abstract] states "random pair selection process that overcomes a computational bottleneck in Co-eye, resulting in a 40x speedup with no loss in accuracy."
  - [section] reports "we adopt a different approach inspired by the work of Bergstra and Bengio [7]. They suggest that random searches can yield comparable performance to grid searches for hyper-parameterisation."
  - [corpus] has no direct evidence; the related papers focus on different aspects of time series classification.
- Break condition: If the parameter space has sharp performance cliffs or strong local optima, random sampling might miss optimal combinations.

### Mechanism 2
- Claim: Three new voting methods improve ensemble decision-making over dynamic voting.
- Mechanism: The sum rule scheme applies different weighting strategies (uniform, mean-max confidence, cross-validation accuracy) to combine per-lens Random Forest outputs.
- Core assumption: Weighted aggregation of per-lens predictions captures more discriminative information than dynamic voting.
- Evidence anchors:
  - [abstract] mentions "three new voting methods are also proposed."
  - [section] describes "three voting methods to replace Co-eye's existing dynamic voting approach" with detailed algorithmic descriptions.
  - [corpus] has no direct evidence; related works focus on different ensemble approaches.
- Break condition: If lens predictions are highly correlated, weighting schemes may not provide meaningful differentiation.

### Mechanism 3
- Claim: Two multivariate extensions enable univariate Co-eye to handle multivariate data effectively.
- Mechanism: (1) Concatenation reduces multivariate series to univariate by joining dimensions; (2) Ensembling builds separate classifiers per dimension and fuses predictions.
- Core assumption: Either reducing dimensionality through concatenation or parallel per-dimension classification preserves discriminative information.
- Evidence anchors:
  - [abstract] states "two multivariate extensions, these approaches form RED CoMETS."
  - [section] details "two approaches. When combined with the univariate foundation...these approaches form RED CoMETS."
  - [corpus] has no direct evidence; related papers focus on different multivariate approaches.
- Break condition: If inter-dimensional relationships are critical for classification, both approaches may lose important joint information.

## Foundational Learning

- Concept: Symbolic representation (SAX/SFA) transforms time series into discrete sequences for pattern recognition.
  - Why needed here: Enables multi-resolution analysis and lens-based ensemble construction that captures both fine details and broad shapes.
  - Quick check question: What is the primary difference between SAX and SFA in how they discretize time series?
- Concept: Random search for hyperparameter optimization.
  - Why needed here: Provides computational efficiency while maintaining performance when exploring large parameter spaces.
  - Quick check question: Under what conditions might random search outperform grid search?
- Concept: Ensemble voting strategies (uniform, confidence-weighted, validation-weighted).
  - Why needed here: Different weighting schemes can capture varying levels of prediction certainty across ensemble members.
  - Quick check question: How does cross-validation accuracy weighting differ computationally from confidence-based weighting?

## Architecture Onboarding

- Component map: Input -> Z-normalization -> Random pair selection -> SAX/SFA transformation -> Random Forest per lens -> Voting aggregation -> Output
- Critical path: Pair selection → Symbolic transformation → Random Forest training → Voting aggregation
- Design tradeoffs:
  - R5% vs R10%/R15%/R20%: Speed vs accuracy balance
  - Concatenation vs Ensembling: Computational efficiency vs potential loss of inter-dimensional relationships
  - Voting method choice: Computational cost vs potential accuracy gain
- Failure signatures:
  - Poor accuracy: Inappropriate pair selection ratio, ineffective voting weights, loss of critical multivariate information
  - Slow performance: Excessive pair selection ratio, validation-based voting, large series dimensions
  - Unstable results: Insufficient resampling, inappropriate normalization strategy
- First 3 experiments:
  1. Benchmark R5% pair selection against R10% on a medium-sized dataset to verify the speed-accuracy tradeoff.
  2. Compare concatenation vs ensembling approaches on a dataset with known inter-dimensional dependencies.
  3. Test all three voting methods on a validation set to determine which provides best accuracy improvement.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of hyperparameters (α and w) for SAX and SFA affect the performance of RED CoMETS on multivariate time series classification tasks?
- Basis in paper: [inferred] The paper discusses the use of SAX and SFA for symbolic representation transformations but does not explore the impact of different hyperparameter values on the performance of RED CoMETS.
- Why unresolved: The paper focuses on the random pair selection process and does not investigate the effects of varying the hyperparameters for SAX and SFA on the classification accuracy.
- What evidence would resolve it: Conduct experiments with different combinations of α and w values for SAX and SFA and compare the classification accuracy of RED CoMETS across these combinations.

### Open Question 2
- Question: Can RED CoMETS be extended to handle non-stationary time series data effectively?
- Basis in paper: [inferred] The paper does not address the performance of RED CoMETS on non-stationary time series data, which is a common challenge in time series classification.
- Why unresolved: The paper focuses on the evaluation of RED CoMETS on stationary time series data and does not explore its effectiveness on non-stationary data.
- What evidence would resolve it: Test RED CoMETS on a dataset containing non-stationary time series and compare its performance with other state-of-the-art classifiers on this dataset.

### Open Question 3
- Question: How does the performance of RED CoMETS scale with the number of dimensions in multivariate time series data?
- Basis in paper: [inferred] The paper does not investigate the scalability of RED CoMETS with respect to the number of dimensions in multivariate time series data.
- Why unresolved: The paper evaluates RED CoMETS on a fixed set of multivariate datasets but does not explore its performance as the number of dimensions increases.
- What evidence would resolve it: Evaluate RED CoMETS on datasets with varying numbers of dimensions and analyze the impact on classification accuracy and computational efficiency.

## Limitations

- Random sampling may miss optimal parameter combinations in high-dimensional spaces
- Limited evaluation of performance on datasets with significant phase shifting
- No comparison with recently developed transformer-based time series methods

## Confidence

- High Confidence: The computational efficiency improvement (40x speedup) is well-supported by the random pair selection mechanism.
- Medium Confidence: The claim of "state-of-the-art" accuracy is supported for specific datasets but shows mixed performance compared to other top methods.
- Low Confidence: The paper doesn't fully address how the random sampling strategy might miss optimal parameter combinations in high-dimensional spaces.

## Next Checks

1. Conduct ablation studies to quantify the individual contribution of random pair selection versus voting method improvements
2. Test RED CoMETS on datasets with varying degrees of phase shifting to better characterize its limitations
3. Benchmark against recently published transformer-based methods on the same UCR datasets to assess current competitive standing