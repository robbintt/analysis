---
ver: rpa2
title: 'Brain-Inspired Efficient Pruning: Exploiting Criticality in Spiking Neural
  Networks'
arxiv_id: '2311.16141'
source_url: https://arxiv.org/abs/2311.16141
tags:
- pruning
- criticality
- regeneration
- networks
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of pruning deep spiking neural
  networks (SNNs) for deployment on resource-constrained devices. Existing SNN pruning
  methods are inefficient and incur high computational costs due to the binary and
  non-differentiable nature of spike signals.
---

# Brain-Inspired Efficient Pruning: Exploiting Criticality in Spiking Neural Networks

## Quick Facts
- **arXiv ID**: 2311.16141
- **Source URL**: https://arxiv.org/abs/2311.16141
- **Reference count**: 20
- **Primary result**: Achieves up to 95.26% reduction in pruning costs while maintaining higher accuracy than state-of-the-art methods

## Executive Summary
This paper addresses the challenge of pruning deep spiking neural networks (SNNs) for deployment on resource-constrained devices. Existing SNN pruning methods are inefficient and incur high computational costs due to the binary and non-differentiable nature of spike signals. To overcome this, the authors propose a brain-inspired pruning approach that exploits the concept of criticality from neuroscience. They design a low-cost metric to assess neuron criticality based on the distance between the membrane potential and the threshold voltage. Using this metric, they develop a pruning-regeneration method that preserves critical neurons during the pruning process. Experimental results on VGG-16 and ResNet-19 architectures demonstrate that their method achieves higher performance compared to state-of-the-art approaches while significantly reducing pruning costs by up to 95.26%.

## Method Summary
The authors propose a brain-inspired pruning approach for SNNs that exploits neuron criticality based on membrane potential threshold distance. The method consists of three main steps: (1) compute a low-cost criticality metric using the derivative of a surrogate function with respect to membrane potential distance from threshold, (2) perform global magnitude pruning to obtain an initial sparse network, and (3) regenerate pruned neurons based on criticality scores using a specified regeneration ratio. The regenerated network is then fine-tuned to recover performance. This approach differs from standard pruning by preserving neurons that are more responsive to input changes, as indicated by their proximity to the firing threshold.

## Key Results
- Achieves up to 95.26% reduction in pruning costs compared to state-of-the-art methods
- Maintains higher accuracy after pruning on VGG-16 and ResNet-19 architectures
- Demonstrates improved feature uniformity and reduced overfitting during fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Preserving neurons with membrane potentials closer to the threshold voltage maintains model sensitivity to inputs.
- **Mechanism**: The criticality metric ranks neurons by how close their membrane potential is to the firing threshold. Neurons near the threshold are more responsive to input changes, so regenerating these neurons after pruning preserves the model's ability to extract relevant features.
- **Core assumption**: Neurons with membrane potentials near the threshold are more critical for information processing in SNNs.
- **Evidence anchors**:
  - [abstract]: "we propose a low-cost metric for neuron criticality based on the distance between the membrane potential and the threshold voltage"
  - [section]: "we propose that neuronal criticality is related to the distance between the membrane potential and the threshold voltage"
  - [corpus]: Weak - related papers focus on pruning efficiency but do not explicitly discuss criticality-based regeneration or threshold proximity.
- **Break condition**: If membrane potential distribution becomes uniform across neurons, the criticality metric loses discriminative power.

### Mechanism 2
- **Claim**: Regeneration based on criticality preserves latent potential structures that become more important during fine-tuning.
- **Mechanism**: After pruning, the method regenerates neurons ranked by criticality scores. These regenerated neurons often have lower initial importance but gain significance during fine-tuning, as shown by their higher scaling factors after training.
- **Core assumption**: Neurons with high criticality scores but low initial importance contain latent potential that becomes activated during fine-tuning.
- **Evidence anchors**:
  - [section]: "we find that: (1) our method selects critical structures with latent potential which become more important after fine-tuning"
  - [section]: "the channels regenerated by our method exhibit significantly higher importance compared to those without regeneration"
  - [corpus]: Weak - related papers discuss pruning but do not address the concept of latent potential in neuron selection.
- **Break condition**: If fine-tuning fails to activate the latent potential in regenerated neurons, performance gains disappear.

### Mechanism 3
- **Claim**: Criticality-based pruning improves feature uniformity and reduces overfitting during fine-tuning.
- **Mechanism**: By preserving critical neurons, the method maintains more consistent feature representations across training and test samples, reducing intra-cluster variance and improving cosine similarity between feature means.
- **Core assumption**: Critical neurons contribute to more stable and consistent feature extraction across different data samples.
- **Evidence anchors**:
  - [section]: "our model achieved lower variances in almost all classes, indicating enhanced compactness in class features"
  - [section]: "our model exhibits higher similarity in feature extraction across almost all classes"
  - [corpus]: Weak - related papers focus on pruning efficiency but do not discuss feature uniformity or overfitting reduction.
- **Break condition**: If the model architecture changes significantly, the relationship between criticality and feature uniformity may not hold.

## Foundational Learning

- **Concept**: Spiking Neural Networks and LIF model
  - **Why needed here**: Understanding how spikes and membrane potentials work is essential to grasp the criticality metric.
  - **Quick check question**: What happens to the membrane potential when a neuron fires, and how does this relate to the threshold voltage?

- **Concept**: Critical brain hypothesis
  - **Why needed here**: The method draws inspiration from neuroscience, specifically the idea that brains operate at a critical state for optimal information processing.
  - **Quick check question**: How does the critical state in neuroscience relate to the concept of criticality in this pruning method?

- **Concept**: Network pruning techniques
  - **Why needed here**: Understanding standard pruning methods (magnitude-based, structured) provides context for how this criticality-based approach differs.
  - **Quick check question**: What are the main differences between unstructured and structured pruning, and how does criticality-based regeneration fit into these approaches?

## Architecture Onboarding

- **Component map**: SNN model -> Membrane potential calculator -> Criticality metric calculator -> Pruning module -> Regeneration module -> Fine-tuning module
- **Critical path**: During training, compute membrane potentials → calculate criticality scores → prune based on magnitude → regenerate critical neurons → fine-tune. The regeneration step is critical as it determines which neurons are preserved.
- **Design tradeoffs**: Higher regeneration ratios preserve more critical neurons but reduce sparsity gains. The choice between mean and max aggregation for convolutional layers affects which features are preserved. Structured vs. unstructured pruning offers different hardware efficiency benefits.
- **Failure signatures**: If accuracy drops significantly after pruning, it may indicate insufficient regeneration of critical neurons. High variance in feature extraction suggests the criticality metric is not effectively preserving important structures. If fine-tuning leads to overfitting, the feature uniformity improvement may not be working as intended.
- **First 3 experiments**:
  1. Run unstructured pruning with criticality regeneration on VGG-16 with 90% sparsity and compare accuracy to baseline magnitude pruning.
  2. Test structured pruning with criticality regeneration on ResNet-19 and measure Flops reduction vs. accuracy compared to state-of-the-art methods.
  3. Vary the regeneration ratio (r) from 0.1 to 0.6 and plot accuracy vs. sparsity to find the optimal balance between compression and performance.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the proposed criticality metric generalize to other spiking neuron models beyond LIF (e.g., Izhikevich, Hodgkin-Huxley)?
- **Basis in paper**: [inferred] The paper focuses on LIF model and uses its membrane potential dynamics to define criticality. Other models may have different dynamics affecting criticality assessment.
- **Why unresolved**: The paper does not test or discuss generalization to other spiking neuron models.
- **What evidence would resolve it**: Experiments applying the criticality metric to SNNs using different spiking neuron models and comparing performance with LIF-based results.

### Open Question 2
- **Question**: What is the optimal regeneration ratio (r) across different network architectures and datasets?
- **Basis in paper**: [explicit] The paper tests different regeneration ratios (0.1 to 0.6) but finds relatively stable performance. Optimal values may depend on architecture and dataset.
- **Why unresolved**: The paper uses fixed regeneration ratios without systematic analysis of optimal values for different scenarios.
- **What evidence would resolve it**: Comprehensive experiments varying regeneration ratios across multiple architectures (VGG, ResNet, etc.) and datasets to identify patterns or guidelines for optimal settings.

### Open Question 3
- **Question**: How does the criticality-based pruning approach compare with other pruning criteria (e.g., second-order information, activation-based metrics) in terms of generalization to unseen data?
- **Basis in paper**: [inferred] The paper compares performance but focuses on accuracy. Generalization to unseen data is not explicitly analyzed.
- **Why unresolved**: The paper does not provide analysis of how criticality-based pruning affects model generalization beyond test set performance.
- **What evidence would resolve it**: Experiments measuring generalization metrics (e.g., cross-validation performance, robustness to noise, adversarial examples) comparing criticality-based pruning with other pruning criteria.

## Limitations

- The criticality metric relies on membrane potential threshold distance, which may not generalize well across different SNN architectures or datasets.
- The method's performance claims are based primarily on VGG-16 and ResNet-19 architectures, with limited validation on more complex or diverse network structures.
- The computational overhead of calculating criticality scores during pruning, while claimed to be low, is not thoroughly benchmarked against existing methods.

## Confidence

- **High confidence**: The pruning efficiency claims (95.26% reduction in pruning costs) are well-supported by experimental results on standard datasets.
- **Medium confidence**: The criticality metric's effectiveness in preserving model performance during pruning is demonstrated but could benefit from more extensive ablation studies across different network architectures.
- **Low confidence**: The theoretical connection between membrane potential threshold distance and neuron criticality lacks strong empirical validation beyond the presented results.

## Next Checks

1. Test the criticality metric on diverse SNN architectures (e.g., MobileNet, EfficientNet) to evaluate generalization beyond VGG-16 and ResNet-19.
2. Conduct ablation studies varying the regeneration ratio (r) systematically across different sparsity levels to identify optimal configurations.
3. Benchmark the computational overhead of the criticality metric calculation against standard magnitude-based pruning to verify the claimed efficiency gains.