---
ver: rpa2
title: 'Treat Different Negatives Differently: Enriching Loss Functions with Domain
  and Range Constraints for Link Prediction'
arxiv_id: '2303.00286'
source_url: https://arxiv.org/abs/2303.00286
tags:
- loss
- functions
- triples
- semantic
- semantically
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes semantic-driven loss functions for link prediction
  in knowledge graphs by incorporating domain and range constraints of relations.
  The core method idea is to differentiate between semantically valid and invalid
  negative triples during training by introducing a semantic factor that adjusts their
  treatment in the loss computation.
---

# Treat Different Negatives Differently: Enriching Loss Functions with Domain and Range Constraints for Link Prediction

## Quick Facts
- arXiv ID: 2303.00286
- Source URL: https://arxiv.org/abs/2303.00286
- Reference count: 21
- One-line primary result: Semantic-driven loss functions improve semantic awareness (Sem@K) while maintaining or improving traditional link prediction metrics (MRR, Hits@K)

## Executive Summary
This paper addresses the challenge of incorporating ontological knowledge into knowledge graph embedding models for link prediction. The key insight is that not all negative samples are equally informative - semantically valid negatives (those that satisfy domain and range constraints) provide more meaningful contrastive learning signals than invalid negatives. By introducing a semantic factor that adjusts how these different types of negatives are treated in the loss function, the authors propose enhanced versions of three popular loss functions (pairwise hinge, binary cross-entropy, and pointwise logistic). Experiments across three public knowledge graphs demonstrate that these semantic-driven losses consistently improve semantic awareness while maintaining or enhancing traditional evaluation metrics.

## Method Summary
The proposed method enriches standard knowledge graph embedding loss functions with domain and range constraints by introducing a semantic factor ε that treats semantically valid and invalid negative triples differently during training. For each loss function, the semantic factor adjusts the margin between positive and negative scores, with valid negatives receiving less penalty than invalid ones. This approach is applied to three main loss types: pairwise hinge loss (PHL), 1-N binary cross-entropy loss (BCEL), and pointwise logistic loss (PLL). The semantic factor ε is typically set between 0 and 1, with smaller values giving more weight to semantic validity. The method is evaluated across multiple KG embedding models (TransE, DistMult, ComplEx, etc.) on three schema-defined knowledge graphs with entity types and relation constraints.

## Key Results
- Semantic-driven losses consistently improve Sem@K metrics while maintaining or improving MRR and Hits@K scores
- The approach shows significant improvements across all tested knowledge graphs (FB14K, DB77K, YAGO14K)
- In 19 out of 24 comparisons between vanilla and semantic-driven versions, better MRR values were achieved
- The semantic factor ε requires careful tuning, with different optimal values for different loss functions and datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The semantic factor ε improves link prediction by treating semantically valid negative triples as "less negative" during training.
- Mechanism: The loss function adjusts the score margin between positive and negative triples based on semantic validity. For valid negatives, the margin is reduced by multiplying γ with ε, making their scores closer to positive triples.
- Core assumption: Semantically valid negatives provide useful contrastive signal for learning embeddings, rather than just being treated as hard negatives.
- Evidence anchors: [abstract] "negative triples that are semantically valid w.r.t. signatures of relations (domain and range) are high-quality negatives" [section] "A choice of ε < 1 leads the KGEM to apply a higher margin between scores of positive and semantically invalid triples than between positive and semantically valid ones"
- Break condition: If domain/range constraints are incorrect or entities have multiple types, the semantic factor could mislead the model by giving too much weight to invalid negatives.

### Mechanism 2
- Claim: The semantic-driven loss functions maintain or improve rank-based metrics (MRR, Hits@K) while significantly improving semantic awareness (Sem@K).
- Mechanism: By keeping semantically valid negatives closer to positive triples, the model learns embeddings where ground-truth entities rank higher and semantically plausible alternatives also rank highly, satisfying both traditional and semantic metrics.
- Core assumption: Rank-based metrics and semantic awareness are not mutually exclusive optimization objectives.
- Evidence anchors: [abstract] "the proposed loss functions (1) lead to better MRR and Hits@10 values, and (2) drive KGEMs towards better semantic correctness as measured by the Sem@K metric" [section] "in 19 out of 24 (≈ 79%) one-to-one comparisons between the same KGEM trained with vanilla vs. semantic-driven loss functions, better MRR values are reported"
- Break condition: When relations have very large sets of semantically valid candidates (B3 bucket), the relative benefit decreases as rank-based metrics are already high.

### Mechanism 3
- Claim: The semantic factor works across different loss function types (pairwise, pointwise, binary cross-entropy) through different implementation strategies.
- Mechanism: For PHL, ε scales the margin; for BCEL, it modifies the label values of valid negatives; for PLL, it controls the probability of treating valid negatives as positive during training.
- Core assumption: The semantic validity concept can be meaningfully integrated into different loss formulations without breaking their mathematical properties.
- Evidence anchors: [abstract] "we propose semantic-driven versions for the three mostly used loss functions for the link prediction task, leveraging BK about relation domains and ranges" [section] "The tailoring of these losses and the experiments are left for future work" (suggesting this cross-loss generalization is novel)
- Break condition: If the semantic factor is poorly tuned for a specific loss type, it could degrade performance more than it helps.

## Foundational Learning

- Concept: Knowledge Graph Embeddings (KGEs)
  - Why needed here: The entire approach depends on understanding how entities and relations are represented as vectors in latent space
  - Quick check question: What is the fundamental difference between TransE's scoring function and DistMult's scoring function?

- Concept: Domain and Range Constraints
  - Why needed here: The semantic factor relies on knowing which entity types can be heads/tails for each relation
  - Quick check question: Given relation "birthPlace" with domain "Person" and range "Location", which of these triples is semantically valid: (New York, birthPlace, Person) or (Person, birthPlace, Location)?

- Concept: Loss Functions in Machine Learning
  - Why needed here: Understanding how different loss formulations (pairwise vs pointwise vs BCE) affect training objectives
  - Quick check question: How does the hinge loss differ from logistic loss in terms of handling negative examples?

## Architecture Onboarding

- Component map: Data layer (Knowledge graphs with entity types) -> Embedding layer (Entity and relation vector representations) -> Scoring functions (Domain-specific implementations) -> Loss functions (Three semantic-driven variants with semantic factor) -> Training loop (Negative sampling + semantic factor application) -> Evaluation (MRR, Hits@K, Sem@K metrics)

- Critical path: Data → Embedding initialization → Negative sampling → Semantic factor application → Loss computation → Parameter update → Evaluation

- Design tradeoffs:
  - Granularity vs coverage: More fine-grained type constraints improve semantic validity but reduce available negatives
  - ε tuning: Higher ε gives more weight to semantic validity but risks overfitting to type constraints
  - Computational cost: Semantic factor adds minimal overhead but requires type checking

- Failure signatures:
  - Sem@K improves but MRR degrades: Semantic factor too aggressive, needs ε reduction
  - Both metrics degrade: Domain/range constraints likely incorrect or too restrictive
  - No improvement over vanilla: Semantic factor ε too close to 1, needs adjustment

- First 3 experiments:
  1. Run TransE with vanilla PHL on FB14K, record baseline MRR and Sem@10
  2. Run TransE with semantic PHL (ϵ=0.25) on FB14K, compare improvements
  3. Test different ϵ values (0.1, 0.25, 0.5) to find optimal semantic factor for each loss type

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal semantic factor (ϵ) value for each loss function across different knowledge graph datasets and models?
- Basis in paper: [explicit] The paper mentions that hyperparameter tuning was performed to find the best ϵ value, but it only did so on YAGO14K due to computational limitations. The optimal values found on YAGO14K were then used for all other datasets and models.
- Why unresolved: The paper explicitly states that more thorough tuning of ϵ on the other datasets would have potentially provided even more satisfying results, especially for the LPLL loss function. This suggests that the current ϵ values may not be optimal for all scenarios.
- What evidence would resolve it: Comprehensive hyperparameter tuning of ϵ for each loss function on each dataset and model would provide the optimal values and demonstrate the impact of using these optimized values on performance.

### Open Question 2
- Question: How would the proposed semantic-driven loss functions perform on knowledge graphs that do not have well-defined domain and range constraints for relations?
- Basis in paper: [inferred] The paper focuses on knowledge graphs with schema-defined relations that have domain and range constraints. It does not discuss the applicability of the approach to graphs without such constraints.
- Why unresolved: The paper's experimental setup and results are limited to schema-defined KGs. The performance on graphs without explicit domain and range information is not evaluated, leaving the generalizability of the approach unclear.
- What evidence would resolve it: Experiments on a diverse set of knowledge graphs, including those without schema-defined relations, would demonstrate the robustness and applicability of the semantic-driven loss functions in different scenarios.

### Open Question 3
- Question: What is the impact of incorporating other types of ontological constraints, such as equivalentClass or inverseOf axioms, into the loss functions?
- Basis in paper: [explicit] The paper mentions that future work will study how the proposed loss functions can accommodate other types of ontological constraints. It also references previous works that have incorporated equivalentClass and inverseOf axioms as regularization terms.
- Why unresolved: The current study only considers domain and range constraints. The effect of incorporating additional ontological information, which is available in many KGs, is not explored.
- What evidence would resolve it: Extending the semantic-driven loss functions to include other ontological constraints and evaluating their impact on link prediction performance would provide insights into the benefits of leveraging diverse semantic information.

## Limitations
- The semantic factor ε requires careful tuning and may not generalize well across different datasets without dataset-specific optimization
- The approach assumes accurate domain and range constraints, which may not hold in real-world KGs with polysemous relations or multi-typed entities
- Computational cost increases due to type checking and semantic factor application, though the paper claims this is minimal

## Confidence

- Semantic factor mechanism: Medium
- Cross-loss generalization: Low-Medium  
- Empirical improvements: Medium

## Next Checks

1. Perform ablation studies varying ε across a wider range (0.01 to 0.9) for each loss type to understand optimal settings and robustness
2. Test on KGs with noisy or incomplete type constraints to evaluate real-world applicability
3. Compare semantic awareness improvements against alternative approaches like type-aware negative sampling or curriculum learning strategies