---
ver: rpa2
title: 'Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go Indifferent'
arxiv_id: '2311.01205'
source_url: https://arxiv.org/abs/2311.01205
tags:
- graph
- neural
- networks
- attack
- pbfa
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Injectivity Bit Flip Attack (IBFA), the
  first bit flip attack designed specifically for graph neural networks (GNNs). Unlike
  traditional weight-based fault injection attacks, IBFA targets the learnable neighborhood
  aggregation functions in quantized message passing neural networks to degrade their
  ability to distinguish graph structures.
---

# Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go Indifferent

## Quick Facts
- **arXiv ID**: 2311.01205
- **Source URL**: https://arxiv.org/abs/2311.01205
- **Reference count**: 38
- **Primary result**: IBFA is the first bit flip attack designed specifically for GNNs, targeting learnable aggregation functions to degrade WL-expressivity

## Executive Summary
This paper introduces IBFA (Injectivity Bit Flip Attack), the first bit flip attack specifically designed for graph neural networks. Unlike traditional weight-based fault injection attacks that target CNNs, IBFA focuses on degrading the injectivity of learnable neighborhood aggregation functions in quantized message passing neural networks. The attack demonstrates that by strategically flipping bits in GIN models, it can force structurally different graphs to produce similar embeddings, effectively breaking the network's ability to distinguish non-isomorphic structures. IBFA significantly outperforms transferred CNN attacks, degrading GIN's performance to random output with fewer bit flips while maintaining model functionality.

## Method Summary
IBFA targets quantized INT8 GIN models by attacking their learnable aggregation functions across multiple layers. The attack uses a minimization approach that focuses on making network outputs similar for structurally different inputs, rather than maximizing classification loss. It employs two variants: IBFA1 which samples input pairs and iteratively searches for vulnerable bits, and IBFA2 which more aggressively searches for maximally different input pairs. The attack uses KL divergence loss for multi-class tasks and L1 loss for binary tasks, combined with a progressive bit search algorithm. By distributing bit flips across the MLP layers in GIN's aggregation pipeline, IBFA degrades the network's WL-expressivity - its ability to distinguish non-isomorphic graph structures.

## Key Results
- IBFA outperforms transferred PBFA attacks on CNN models, requiring fewer bit flips to degrade GIN performance to random output
- On molecular property prediction datasets, IBFA degrades GIN's AUROC and AP metrics significantly more than random bit flips or PBFA
- The attack successfully breaks GIN's injectivity across multiple layers (MLP1-4), demonstrating the vulnerability of multi-layer aggregation functions
- IBFA2 provides faster and more consistent degradation than IBFA1, though at higher computational cost (O(kn²) vs O(kn))

## Why This Works (Mechanism)

### Mechanism 1
- Claim: IBFA degrades GIN's ability to distinguish non-isomorphic graph structures by targeting injectivity in the neighborhood aggregation functions
- Mechanism: IBFA minimizes the difference between network outputs on structurally different inputs (Xa and Xb) rather than maximizing classification loss. This forces the network to produce similar embeddings for different graphs, breaking the injective property required for WL-expressivity
- Core assumption: GIN's discriminative power depends on its ability to compute injective functions on multisets of node features during aggregation
- Evidence anchors:
  - [abstract]: "Our attack targets the learnable neighborhood aggregation functions in quantized message passing neural networks, degrading their ability to distinguish graph structures"
  - [section 3]: "IBFA focuses on degrading GIN trained on tasks requiring high structural expressivity... attacking injectivity will lead to a higher degradation than performing PBFA"
  - [corpus]: Weak - only 5 related papers found, suggesting this specific attack mechanism is novel and under-explored
- Break condition: If the network's MLP layers can compensate for non-injective aggregation through higher layers, or if the task doesn't require full structural discrimination

### Mechanism 2
- Claim: IBFA's data selection strategy maximizes attack effectiveness by choosing structurally dissimilar inputs
- Mechanism: IBFA2 iteratively searches for input pairs (Xa, Xb) that maximize the unperturbed network's output difference, ensuring the attack targets the most informative structural distinctions
- Core assumption: Starting with inputs that are already easily distinguishable makes it easier to measure and degrade the network's discriminative capability
- Evidence anchors:
  - [section 4]: "We chose inputs Xa and Xb to be as different as possible from one another w.r.t. to the unperturbed network's outputs before the attack by iteratively solving..."
  - [section 5]: "Choosing input samples... is crucial as selecting inputs that have identical outputs... will not yield any degradation"
  - [corpus]: Moderate - related work mentions data selection in BFA but not this specific structural approach for GNNs
- Break condition: If the network becomes insensitive to structural differences after initial bit flips, making further discrimination impossible

### Mechanism 3
- Claim: IBFA targets learnable neighborhood aggregation functions across multiple layers rather than single-layer injectivity
- Mechanism: IBFA1/2 distribute bit flips across multiple GIN layers (particularly MLP1-4) rather than concentrating on one layer, ensuring degradation of the complete aggregation chain
- Core assumption: Full WL-expressivity requires injectivity across the entire aggregation pipeline, not just individual layers
- Evidence anchors:
  - [section 3]: "it would not suffice to just consider the injectivity of a single layer's COMBINE and AGGREGATE functions... an attack considering the whole network is necessary"
  - [section 5]: "IBFA1/2 both target bit flips in at least 4 layers across the entire model, with the majority of flips occurring in the learnable aggregation functions"
  - [corpus]: Moderate - related work focuses on single-layer attacks for CNNs, not multi-layer approaches for GNNs
- Break condition: If the network can maintain discriminative power through residual connections or skip connections that bypass attacked layers

## Foundational Learning

- Concept: Weisfeiler-Lehman (WL) graph isomorphism test
  - Why needed here: IBFA's effectiveness depends on understanding how GNNs achieve WL-expressivity through injective aggregation functions
  - Quick check question: What does it mean for a GNN to be "as powerful as the WL test" and why is this relevant to IBFA's attack strategy?

- Concept: Message passing neural networks and neighborhood aggregation
  - Why needed here: IBFA specifically targets the aggregation functions (COMBINE and AGGREGATE) that compute node representations from neighbor features
  - Quick check question: How does the choice of aggregation function (mean vs. sum vs. MLP) affect a GNN's ability to distinguish graph structures?

- Concept: Quantization and Straight Through Estimation (STE)
  - Why needed here: IBFA operates on quantized INT8 models, requiring understanding of how quantization affects bit flip vulnerability and how STE enables gradient-based attacks
  - Quick check question: Why is quantization necessary for IBFA to work effectively, and what role does STE play in enabling the attack?

## Architecture Onboarding

- Component map: Data selection module -> Progressive bit search algorithm -> Loss function module (L1/KL divergence) -> Attack execution loop
- Critical path: Data selection → Bit search optimization → Bit flip application → Output similarity measurement → Repeat until degradation achieved
- Design tradeoffs: IBFA2 offers faster and more consistent degradation but has O(kn²) complexity, while IBFA1 is more scalable but potentially slower; KL divergence loss works better for multi-task classification while L1 works for binary
- Failure signatures: Attack fails if network becomes insensitive to structural differences (outputs become random), if data selection cannot find sufficiently different inputs, or if quantization prevents effective bit manipulation
- First 3 experiments:
  1. Implement IBFA1 on a 5-layer GIN with ogbg-molhiv dataset using L1 loss and 1% subset sampling to verify basic functionality
  2. Compare IBFA1 vs PBFA on ogbg-moltoxcast dataset to demonstrate effectiveness against structurally expressive tasks
  3. Test IBFA2 on COLLAB dataset to evaluate the impact of different data selection strategies on degradation speed and consistency

## Open Questions the Paper Calls Out

- Question: How effective is IBFA on graph neural networks with higher expressive power than GIN, such as those exceeding the 1-WL test?
- Question: How does IBFA perform under different quantization schemes, such as ternary or binary quantization, compared to the INT8 quantization used in the experiments?
- Question: Can IBFA be adapted to target other mathematical properties of graph neural networks, such as those related to graph isomorphism or structural roles?

## Limitations
- IBFA is specifically designed for GIN models and may not directly transfer to other GNN architectures with different aggregation mechanisms
- The attack's effectiveness depends on the availability of structurally different input pairs, which may be limited in certain datasets
- IBFA requires quantized models, limiting its applicability to models trained with quantization-aware training

## Confidence
- Effectiveness on GIN models: High
- Generalizability to other GNN architectures: Medium
- Scalability to larger graphs/datasets: Medium
- Applicability to non-molecular graph tasks: Medium

## Next Checks
1. Test IBFA against other GNN architectures (GraphSAGE, GAT) to verify the attack's effectiveness across different neighborhood aggregation approaches beyond GIN's sum-MLP design.

2. Evaluate IBFA on graph-level tasks requiring different structural properties (e.g., graph classification on social networks vs. molecular properties) to assess task-specific vulnerability patterns.

3. Investigate defensive mechanisms by implementing the "Crossfire" elastic defense framework mentioned in the corpus to measure how well it mitigates IBFA's injectivity-targeting strategy.