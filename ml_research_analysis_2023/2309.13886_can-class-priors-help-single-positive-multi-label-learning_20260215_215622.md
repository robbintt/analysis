---
ver: rpa2
title: Can Class-Priors Help Single-Positive Multi-Label Learning?
arxiv_id: '2309.13886'
source_url: https://arxiv.org/abs/2309.13886
tags:
- learning
- multi-label
- label
- class-priors
- labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the single-positive multi-label learning (SPMLL)
  problem where each training example is annotated with only one positive label. Existing
  SPMLL methods typically assume identical prior probabilities for all classes, but
  this assumption is unrealistic in real-world scenarios where class-priors can differ
  significantly.
---

# Can Class-Priors Help Single-Positive Multi-Label Learning?

## Quick Facts
- **arXiv ID**: 2309.13886
- **Source URL**: https://arxiv.org/abs/2309.13886
- **Reference count**: 40
- **Primary result**: CRISP framework estimates class-priors for SPMLL, achieving unbiased risk estimation and superior performance over existing methods on ten benchmark datasets.

## Executive Summary
This paper addresses the challenge of single-positive multi-label learning (SPMLL), where each training example has only one positive label. The key insight is that existing SPMLL methods incorrectly assume identical class-priors for all labels, which is unrealistic in practice. The authors propose CRISP (Class-pRiors Induced Single-Positive multi-label learning), a novel framework that estimates class-priors and derives an unbiased risk estimator based on these estimates. This approach theoretically guarantees convergence to ground-truth class-priors and ensures learning consistency, resulting in improved performance across multiple benchmark datasets.

## Method Summary
The CRISP framework introduces a class-priors estimator that theoretically converges to ground-truth class-priors with sufficient training samples. It then derives an unbiased risk estimator using these estimated priors, avoiding the bias introduced by assuming identical class-priors. The method trains a multi-label classifier using this unbiased risk estimator while avoiding direct use of potentially noisy pseudo-labels. The framework alternates between class-prior estimation and risk minimization, with empirical validation showing superior performance compared to existing SPMLL approaches on ten multi-label learning benchmark datasets.

## Key Results
- CRISP demonstrates superior performance over existing SPMLL methods on ten benchmark datasets
- The class-priors estimator is theoretically guaranteed to converge to ground-truth class-priors with sufficient samples
- The unbiased risk estimator ensures learning consistency, with the risk minimizer approximately converging to the optimal risk minimizer on fully supervised data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Estimating class-priors allows for unbiased risk estimation in SPMLL.
- Mechanism: By estimating the ratio of positive-labeled samples to total samples above a threshold, the method derives an unbiased risk estimator that avoids the bias introduced by assuming identical class-priors.
- Core assumption: The class-prior estimator converges to the true class-prior with sufficient training samples.
- Evidence anchors:
  - [abstract]: "a class-priors estimator is introduced, which could estimate the class-priors that are theoretically guaranteed to converge to the ground-truth class-priors."
  - [section 4.1]: "The estimated class-prior ˆπj of j-th category will converge to the ground-truth class-prior with enough training samples."
  - [corpus]: No direct evidence found in corpus papers.
- Break condition: If the assumption of convergence fails (e.g., insufficient samples or non-representative data), the risk estimator becomes biased.

### Mechanism 2
- Claim: The unbiased risk estimator ensures learning consistency.
- Mechanism: The derived risk estimator decomposes the risk over the dataset into terms estimable using both labeled positive and unlabeled samples, avoiding direct use of potentially noisy pseudo-labels.
- Core assumption: The loss function remains non-negative when absolute value is added to the last term.
- Evidence anchors:
  - [section 4.1]: "Therefore, we could express the empirical risk estimator via: bRsp(f) = ..."
  - [section 4.2]: "Theorem 4.2 shows that ˆfsp would converge to f ⋆ as n → ∞."
  - [corpus]: No direct evidence found in corpus papers.
- Break condition: If the loss function is not properly bounded or the decomposition is incorrect, learning consistency is not guaranteed.

### Mechanism 3
- Claim: Avoiding pseudo-labels reduces model susceptibility to errors and uncertainties.
- Mechanism: By not directly utilizing pseudo-labels, the model is less affected by the inaccuracies and uncertainties inherent in pseudo-labeling approaches.
- Core assumption: The model can effectively learn from the unbiased risk estimator without relying on pseudo-labels.
- Evidence anchors:
  - [section 4.1]: "Importantly, the loss function does not directly utilize pseudo-labels, which helps to avoid the potential negative impact of noisy labels on the model."
  - [corpus]: No direct evidence found in corpus papers.
- Break condition: If the unbiased risk estimator is insufficient for effective learning, the model's performance may degrade compared to methods using pseudo-labels.

## Foundational Learning

- Concept: Multi-label learning (MLL)
  - Why needed here: Understanding MLL is crucial as SPMLL is a variant where each instance has only one positive label.
  - Quick check question: What is the main difference between MLL and SPMLL?

- Concept: Risk consistency and empirical risk minimization
  - Why needed here: The method relies on deriving an unbiased risk estimator and ensuring the risk minimizer converges to the optimal risk minimizer.
  - Quick check question: What does it mean for a method to be risk-consistent?

- Concept: Rademacher complexity and generalization error bounds
  - Why needed here: The estimation error bound is established using Rademacher complexity to demonstrate learning consistency.
  - Quick check question: How does Rademacher complexity relate to the generalization error of a learning algorithm?

## Architecture Onboarding

- Component map:
  - Class-priors estimator -> Unbiased risk estimator -> Multi-label classifier

- Critical path:
  1. Estimate class-priors for each label.
  2. Derive the unbiased risk estimator using the estimated class-priors.
  3. Train the multi-label classifier using the unbiased risk estimator.
  4. Iterate steps 1-3 to refine the estimates and improve the model.

- Design tradeoffs:
  - Using class-priors vs. assuming identical class-priors: More accurate but requires additional estimation.
  - Avoiding pseudo-labels vs. using them: Reduces noise but may require more sophisticated risk estimation.

- Failure signatures:
  - Poor convergence of class-prior estimates: Check if sufficient training samples are available and representative.
  - Ineffective learning from the unbiased risk estimator: Verify the correctness of the risk decomposition and loss function.

- First 3 experiments:
  1. Test the class-prior estimation on a simple dataset with known class-priors.
  2. Evaluate the unbiased risk estimator's performance compared to a baseline method using pseudo-labels.
  3. Assess the overall method's performance on a benchmark dataset and compare it to existing SPMLL approaches.

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- The method relies on sufficient training samples for accurate class-prior estimation, potentially underperforming with sparse data.
- The framework assumes static class-prior distributions and does not address temporal shifts in label distributions.
- Performance may degrade when single positive labels contain noise or errors, though robustness to label noise is not explored.

## Confidence
- **High**: Theoretical guarantees for class-prior estimation convergence and risk consistency
- **Medium**: Empirical validation on ten benchmark datasets
- **Low**: Specific neural network architecture remains unspecified

## Next Checks
1. Test CRISP on datasets with deliberately manipulated class-prior distributions to verify sensitivity to estimation errors
2. Compare performance against a strong pseudo-label baseline to quantify the benefit of avoiding pseudo-labels
3. Analyze convergence behavior on progressively smaller subsets of training data to establish minimum sample requirements