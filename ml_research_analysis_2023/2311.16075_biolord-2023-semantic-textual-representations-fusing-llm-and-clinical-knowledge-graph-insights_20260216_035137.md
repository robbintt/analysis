---
ver: rpa2
title: 'BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical Knowledge
  Graph Insights'
arxiv_id: '2311.16075'
source_url: https://arxiv.org/abs/2311.16075
tags:
- biomedical
- language
- knowledge
- clinical
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents BioLORD-2023, a state-of-the-art model for
  semantic textual similarity and biomedical concept representation in the clinical
  domain. The authors propose a novel three-step training strategy that includes an
  improved contrastive learning phase, a self-distillation phase, and a weight averaging
  phase.
---

# BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical Knowledge Graph Insights

## Quick Facts
- arXiv ID: 2311.16075
- Source URL: https://arxiv.org/abs/2311.16075
- Reference count: 40
- Primary result: State-of-the-art model for biomedical semantic textual similarity and concept representation using LLM-generated definitions and self-distillation

## Executive Summary
BioLORD-2023 introduces a novel three-phase training strategy that significantly advances biomedical semantic representation learning. The approach combines contrastive learning on concept names and definitions, self-distillation to preserve general language capabilities, and weight averaging to improve robustness. By leveraging LLM-generated definitions to augment limited human-annotated data, the model achieves substantial improvements across multiple biomedical downstream tasks including semantic textual similarity, biomedical concept representation, and named entity linking. The authors also release a multilingual version compatible with 50+ languages.

## Method Summary
BioLORD-2023 employs a three-step training strategy: (1) Contrastive learning phase that aligns concept names with their definitions in embedding space using UMLS concepts and LLM-generated definitions; (2) Self-distillation phase where the base model learns to predict embeddings from the contrastive model through supervised regression, preserving general language understanding; (3) Weight averaging phase that merges multiple self-distilled models to improve accuracy and robustness. The approach uses STAMB2 as the base model and incorporates 400,000 LLM-generated definitions from AGCT to address the scarcity of human-written definitions in clinical knowledge graphs.

## Key Results
- Consistent performance improvements across multiple biomedical benchmarks including MedSTS, UMNSRS, and MayoSRS
- State-of-the-art results in semantic textual similarity and biomedical concept representation tasks
- Release of multilingual model compatible with 50+ languages
- Substantial improvements over BioLORD-2022 baseline through incorporation of LLM-generated definitions and self-distillation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-distillation phase preserves general language understanding while accelerating biomedical knowledge acquisition
- Mechanism: Instead of unsupervised contrastive learning that distorts semantic space and loses general language capabilities, BioLORD-2023 distills the learned biomedical embeddings into the base model via supervised regression on averaged name+definition embeddings
- Core assumption: The biomedical knowledge captured in the contrastive model's embeddings can be effectively transferred to the base model through regression without requiring extensive contrastive optimization
- Evidence anchors: [abstract]: "self-distillation approach... accelerate the convergence process... at a reduced loss of general language understanding capabilities"

### Mechanism 2
- Claim: LLM-generated definitions substantially enhance biomedical concept representations by filling gaps in human-written definitions
- Mechanism: Only 5% of clinical concepts have human-written definitions. BioLORD-2023 uses GPT-3.5 to generate definitions for 400,000 concepts grounded in SnomedCT ontology
- Core assumption: LLM-generated definitions are sufficiently accurate and informative to improve downstream task performance when used as training data
- Evidence anchors: [abstract]: "leveraging... LLMs to generate definitions for biomedical concepts... demonstrate consistent and substantial performance improvements"

### Mechanism 3
- Claim: Model weights averaging (model soups) improves accuracy and robustness without increasing inference cost
- Mechanism: Different random seeds during self-distillation produce slightly different models focusing on different aspects. Weight averaging merges these models, improving overall performance while maintaining single-model inference speed
- Core assumption: Averaging weights of models fine-tuned with different hyperparameter configurations produces a better performing model than any individual model
- Evidence anchors: [abstract]: "weight averaging phase" and "We evaluate the impact of the weight averaging"

## Foundational Learning

- Concept: Contrastive learning for representation learning
  - Why needed here: BioLORD uses contrastive objectives to align concept names with their definitions in embedding space, creating meaningful biomedical representations
  - Quick check question: What is the loss function used when training a model to bring related pairs (concept name, definition) closer together while pushing unrelated pairs apart?

- Concept: Knowledge distillation
  - Why needed here: The self-distillation phase transfers learned biomedical knowledge from the contrastive model back to the base model through regression, preserving general language capabilities
  - Quick check question: In knowledge distillation, what is the typical relationship between the teacher model and student model in terms of knowledge transfer?

- Concept: Cross-lingual distillation
  - Why needed here: Enables the English BioLORD model to be adapted for 50+ languages by training a multilingual model to produce similar outputs regardless of input language
  - Quick check question: What type of training data is required for cross-lingual distillation to work effectively between two languages?

## Architecture Onboarding

- Component map: Base model → Contrastive phase → Self-distillation phase → Weight averaging → Cross-lingual distillation (optional)
- Critical path: Base model → Contrastive phase → Self-distillation phase → Weight averaging → Cross-lingual distillation (optional)
- Design tradeoffs:
  - Using LLM-generated definitions vs. human-written ones (coverage vs. potential quality issues)
  - Self-distillation vs. continuing contrastive learning (preserves general capabilities vs. potentially slower biomedical acquisition)
  - Model averaging vs. single best model (improved robustness vs. complexity)
- Failure signatures:
  - Poor STS performance on general tasks → base model lost general language understanding
  - Good STS but poor NEL → contrastive learning didn't effectively capture biomedical entities
  - Cross-lingual model performs worse than monolingual → distillation didn't preserve quality
- First 3 experiments:
  1. Run contrastive phase only and evaluate on MedSTS to establish baseline improvement
  2. Run self-distillation phase only (without contrastive) to measure knowledge transfer capability
  3. Compare weight-averaged model vs. single best model on UMNSRS similarity to validate averaging benefit

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the knowledge graphs be expanded or updated to include more recent biomedical information and concepts, especially for rare or very specific entities?
- Basis in paper: [explicit] The paper mentions that knowledge graphs trail the literature and might not include all new pieces of knowledge mentioned in published biomedical papers
- Why unresolved: The paper does not provide a specific solution for expanding or updating knowledge graphs with more recent and relevant information
- What evidence would resolve it: A method or system that successfully incorporates recent biomedical literature into knowledge graphs, improving the representation and differentiation of rare or very specific entities

### Open Question 2
- Question: What is the optimal balance between the size and complexity of the base model and the effectiveness of the BioLORD training strategy in terms of performance and generalization?
- Basis in paper: [explicit] The paper mentions that they investigated the effect of using different biomedical models as base models for BioLORD models, but the results did not confirm the expectation that biomedical models would have an advantage over general-purpose language models fine-tuned on STS
- Why unresolved: The paper does not provide a clear answer on the optimal balance between base model size and BioLORD training strategy effectiveness
- What evidence would resolve it: A comprehensive study comparing the performance and generalization of BioLORD models trained on various base models of different sizes and complexities

### Open Question 3
- Question: How can the cross-lingual distillation process be improved to better handle the differences in language structure and biomedical terminology across languages?
- Basis in paper: [explicit] The paper mentions that they used a cross-lingual distillation technique to create a multilingual model, but the results show some performance degradation in sentence-level STS tasks compared to the monolingual model
- Why unresolved: The paper does not provide a detailed analysis of the challenges and potential solutions for improving cross-lingual distillation in the biomedical domain
- What evidence would resolve it: A study that identifies the specific challenges in cross-lingual distillation for biomedical terminology and proposes effective methods to address these challenges, resulting in improved performance across languages

## Limitations

- The evaluation relies heavily on proxy metrics without ablation studies comparing LLM-generated definitions against human-written alternatives
- Cross-lingual evaluation lacks coverage of diverse language families beyond the 50+ languages claimed
- Training pipeline assumes self-distillation effectively preserves general language capabilities without direct validation
- No systematic analysis of performance degradation on non-biomedical tasks across training phases

## Confidence

**High Confidence**: The three-phase training strategy (contrastive → self-distillation → weight averaging) and its implementation details are well-specified and reproducible. The architectural approach of using LLM-generated definitions to augment limited human-annotated data is methodologically sound.

**Medium Confidence**: The performance improvements on downstream biomedical tasks are credible given the systematic evaluation across multiple benchmarks (MedSTS, UMNSRS, NEL), though the magnitude of improvement depends on the specific metric and task.

**Low Confidence**: Claims about cross-lingual generalization and the specific benefits of LLM-generated definitions over alternatives lack sufficient empirical validation. The paper asserts broad multilingual applicability but provides limited evidence of performance consistency across diverse language families.

## Next Checks

1. **Ablation Study on Definition Sources**: Train parallel models using (a) human-written definitions only, (b) LLM-generated definitions only, and (c) no definitions, then compare performance on MedSTS and UMNSRS to isolate the impact of LLM-generated definitions versus contrastive learning alone.

2. **Cross-Lingual Robustness Analysis**: Select a diverse set of languages representing different families (e.g., Chinese, Arabic, Swahili) and evaluate the multilingual model on concept similarity and NEL tasks, comparing against monolingual baselines to quantify cross-lingual transfer effectiveness.

3. **General Language Capability Preservation**: After each training phase (contrastive, self-distillation), evaluate the model on general language understanding benchmarks like STS-B and GLUE tasks to measure semantic space distortion and confirm that general language capabilities are preserved as claimed.