---
ver: rpa2
title: 'TBGC: Task-level Backbone-Oriented Gradient Clip for Multi-Task Foundation
  Model Learning'
arxiv_id: '2307.03465'
source_url: https://arxiv.org/abs/2307.03465
tags:
- gradient
- clip
- task
- training
- backbone
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the gradient norm bias problem in multi-task
  foundation model learning, where different tasks generate gradient norms that vary
  greatly, causing the backbone to be overly biased towards one specific task. The
  proposed method, Task-level Backbone-Oriented Gradient Clip (TBGC), performs gradient
  clipping independently for each task and rescales backbone gradients to the same
  norm scale, ensuring each task has equal influence on the backbone parameters.
---

# TBGC: Task-level Backbone-Oriented Gradient Clip for Multi-Task Foundation Model Learning

## Quick Facts
- arXiv ID: 2307.03465
- Source URL: https://arxiv.org/abs/2307.03465
- Reference count: 0
- Primary result: Achieved 1st place in Leaderboard A and 2nd place in Leaderboard B of CVPR2023 Foundation Model Challenge

## Executive Summary
This paper addresses the gradient norm bias problem in multi-task foundation model learning, where different tasks generate gradient norms that vary greatly, causing the shared backbone to be overly biased towards one specific task. The proposed Task-level Backbone-Oriented Gradient Clip (TBGC) performs gradient clipping independently for each task and rescales backbone gradients to the same norm scale, ensuring each task has equal influence on the backbone parameters. Additionally, a multi-branch data augmentation strategy is introduced to avoid conflicts between strong augmentation techniques. Experiments demonstrate TBGC's effectiveness, achieving top placements in the CVPR2023 Foundation Model Challenge with improvements across detection, segmentation, and classification tasks.

## Method Summary
The paper proposes a solution to gradient norm bias in multi-task learning by implementing task-level gradient clipping where each task's gradients are clipped independently, followed by rescaling the backbone gradients to the same norm scale. The method uses a shared backbone (InternImage) with task-specific heads for detection (DINO), segmentation (Mask2Former), and classification (MLP+arcface). A multi-branch data augmentation strategy is employed where conflicting augmentations like Mosaic and Autoaugment are placed in separate branches to prevent distribution shifts. The training process releases computation graphs immediately after each task iteration to save CUDA memory, enabling larger batch sizes.

## Key Results
- Achieved 1st place in Leaderboard A and 2nd place in Leaderboard B of the CVPR2023 Foundation Model Challenge
- Improved performance across all three tasks: detection (mAP50), segmentation (mIoU), and classification (top-1 accuracy)
- Demonstrated effectiveness of TBGC in eliminating gradient norm bias and ensuring equal task influence on backbone parameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task-level backbone-oriented gradient clipping equalizes the influence of different tasks on the shared backbone parameters.
- Mechanism: By clipping gradients for each task independently and then rescaling the backbone gradients to the same norm scale, each task contributes equally to the backbone update regardless of their original gradient magnitudes.
- Core assumption: The backbone is the shared component where gradient conflicts occur; task-specific heads are less sensitive to gradient imbalance.
- Evidence anchors:
  - [abstract] "gradient clip is performed independently for each task. 2) backbone gradients generated from each task are rescaled to the same norm scale."
  - [section] "TBGC eliminates the gradient norm bias problem and make sure that every task has the exact save level of influence on the backbone parameters."
  - [corpus] Weak - no direct neighbor papers address gradient norm bias in multi-task learning.
- Break condition: If task-specific heads also experience performance degradation from gradient imbalance, this mechanism may be insufficient.

### Mechanism 2
- Claim: Multi-branch data augmentation avoids conflicts between strong augmentation strategies.
- Mechanism: Placing conflicting augmentations in separate branches ensures each training sample only experiences one strong augmentation, preventing distribution shifts that harm performance.
- Core assumption: Strong augmentations like Mosaic and Autoaugment can conflict when applied together, causing train-test inconsistency.
- Evidence anchors:
  - [abstract] "multi-branch data augmentation strategy where conflict augmentations are placed in different branches."
  - [section] "We argue that it is because some augmentation strategies are so strong that they cause a huge change to the original data distribution, and a combined use of them will make the distribution of training data differ hugely from the counterpart of testing data, thus harm the model performance."
  - [corpus] Weak - no direct neighbor papers address multi-branch augmentation strategies.
- Break condition: If augmentations are not truly conflicting or if curriculum learning is poorly implemented, performance gains may be minimal.

### Mechanism 3
- Claim: Releasing computation graphs immediately after each task iteration saves CUDA memory, enabling larger batch sizes.
- Mechanism: By clearing the computation graph for each task before moving to the next, memory overhead is reduced, allowing more data to be processed per batch.
- Core assumption: PyTorch's computation graph consumes significant CUDA memory during training, especially with multiple tasks.
- Evidence anchors:
  - [section] "The training process we adopted is detailed in Algorithm 1. By using this training process, in which each task's computation graph is released immediately after its iteration is done, the CUDA memory is greatly saved, we thus can use a much larger batchsize."
  - [corpus] Weak - no direct neighbor papers address computation graph management in multi-task learning.
- Break condition: If memory savings are negligible or if batch size increases do not improve convergence, this optimization may not be worthwhile.

## Foundational Learning

- Concept: Gradient clipping
  - Why needed here: Prevents exploding gradients in multi-task training where different tasks generate vastly different gradient norms
  - Quick check question: What happens to model parameters when gradient norms are too large during training?

- Concept: Multi-task learning optimization
  - Why needed here: Standard single-task optimization fails when tasks have conflicting gradients or vastly different scales
  - Quick check question: How does gradient imbalance between tasks affect the shared backbone parameters?

- Concept: Data augmentation strategy design
  - Why needed here: Different augmentations can conflict and harm model performance when combined inappropriately
  - Quick check question: What is the difference between applying multiple augmentations sequentially versus in separate branches?

## Architecture Onboarding

- Component map: Shared backbone (InternImage) -> Task-specific heads (Mask2Former for segmentation, DINO for detection, MLP+arcface for classification)
- Critical path: Backbone forward -> Task-specific head forward -> Loss computation -> Task-level gradient clipping -> Gradient aggregation -> Parameter update
- Design tradeoffs: Single base with multiple heads reduces parameter count but requires careful gradient balancing; multi-branch augmentation increases training complexity but avoids conflicts
- Failure signatures: Detection performance dominates while segmentation/classification underperform (indicates gradient bias); performance drops when strong augmentations are combined (indicates augmentation conflict)
- First 3 experiments:
  1. Implement task-level gradient clipping without rescaling to verify it reduces gradient bias
  2. Test multi-branch augmentation with curriculum learning schedule on segmentation task
  3. Profile CUDA memory usage with and without immediate computation graph release

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical explanation for why rescaling backbone gradients to the same norm scale in TBGC leads to improved performance across all tasks?
- Basis in paper: [explicit] The paper states that TBGC ensures each task has equal influence on the backbone parameters by rescaling gradients, but does not provide theoretical justification for why this specific approach works.
- Why unresolved: The paper focuses on empirical results rather than theoretical analysis of the gradient scaling mechanism.
- What evidence would resolve it: Mathematical analysis showing how gradient norm scaling affects the convergence dynamics of multi-task learning and why equal scaling leads to optimal performance.

### Open Question 2
- Question: How does the performance of TBGC scale with the number of tasks in the multi-task learning setup?
- Basis in paper: [inferred] The paper only evaluates TBGC on three specific tasks (detection, segmentation, classification) and does not explore its effectiveness with more or fewer tasks.
- Why unresolved: The experiments were limited to the CVPR2023 Foundation Model Challenge's three-task setup, without exploring the method's scalability.
- What evidence would resolve it: Experiments testing TBGC on multi-task setups with varying numbers of tasks, from two to ten or more, to determine if the method maintains effectiveness.

### Open Question 3
- Question: What is the optimal placement strategy for conflicting augmentations in the multi-branch augmentation paradigm?
- Basis in paper: [explicit] The paper proposes placing conflicting augmentations in different branches but does not explore different branch assignment strategies or their impact on performance.
- Why unresolved: The paper uses a fixed assignment of augmentations to branches without comparing alternative strategies or optimizing the branch structure.
- What evidence would resolve it: Comparative experiments testing different augmentation-to-branch assignments and their effects on final model performance.

## Limitations
- The paper lacks comprehensive ablation studies to isolate the contribution of each component (TBGC, multi-branch augmentation, memory optimization)
- Several critical implementation details are omitted, including exact curriculum learning schedules and precise probability distributions for augmentation branches
- The multi-branch augmentation strategy is introduced with minimal justification beyond anecdotal observations about distribution shifts

## Confidence
- High Confidence: The experimental results showing improved performance on the foundation model challenge leaderboards are verifiable and clearly reported
- Medium Confidence: The claim that gradient norm bias causes backbone parameters to be overly influenced by one task is plausible but the specific mechanism and proposed solution could benefit from more rigorous validation
- Low Confidence: The effectiveness of the multi-branch augmentation strategy is primarily supported by intuition about augmentation conflicts rather than systematic ablation studies or theoretical analysis

## Next Checks
1. **Ablation Study on TBGC Components**: Systematically test each component of TBGC (independent gradient clipping vs. rescaling, vs. combined approach) to isolate which mechanism contributes most to performance improvements

2. **Memory Profiling Validation**: Conduct controlled experiments measuring actual CUDA memory usage with and without immediate computation graph release to verify the claimed memory savings and their impact on batch size and training efficiency

3. **Augmentation Conflict Analysis**: Design experiments that isolate and measure the specific negative effects of combining conflicting augmentations (e.g., Mosaic + Autoaugment) versus the multi-branch approach to quantify the claimed benefits