---
ver: rpa2
title: 'DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based
  Data Sampling'
arxiv_id: '2307.03550'
source_url: https://arxiv.org/abs/2307.03550
tags:
- samples
- subjectivity
- subjective
- english
- styles
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates style-based data augmentation for subjectivity
  detection in news articles using GPT-3 models. The authors generate additional training
  data in English, Turkish, and German by rewriting objective sentences with different
  journalistic styles (e.g., emotional, propaganda, derogatory) via prompts.
---

# DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based Data Sampling

## Quick Facts
- arXiv ID: 2307.03550
- Source URL: https://arxiv.org/abs/2307.03550
- Reference count: 31
- Primary result: Style-based data augmentation improves subjectivity detection F1 scores in English and Turkish news articles

## Executive Summary
This paper investigates the use of GPT-3 models to generate style-based training data for subjectivity detection in news articles across English, Turkish, and German languages. The authors create prompts based on journalistic subjectivity styles (emotional, propaganda, derogatory, exaggerated, partisan, prejudiced) and use these to rewrite objective sentences, creating augmented datasets for transformer model training. Results show that style-based oversampling outperforms normal paraphrasing in English and Turkish, with partisan and exaggerated styles being particularly effective for Turkish and propaganda/exaggerated styles for English. German results were less consistent, highlighting challenges in multilingual text generation.

## Method Summary
The method involves generating additional training data using GPT-3 models with journalistic-style prompts, then fine-tuning language-specific transformer models on the augmented datasets. The approach uses a subjectivity checklist to define six subjective styles, creates language-specific prompt templates, and employs GPT-3 models (text-davinci-003 and gpt-3.5-turbo) to generate style-based texts. The authors apply sampling strategies to address class imbalance, using under-sampling and over-sampling techniques, and fine-tune language-specific transformers (RoBERTa for English, German BERT for German, BERTurk for Turkish) for 3 epochs with batch size 8.

## Key Results
- Style-based oversampling improves subjectivity detection F1 scores more than normal paraphrasing in English and Turkish
- Partisan and exaggerated styles are particularly effective for Turkish subjectivity detection
- Propaganda and exaggerated styles help improve English subjectivity detection performance
- GPT-3 models sometimes struggle to produce linguistically coherent subjective texts in non-English languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Style-based oversampling improves subjectivity detection performance more than normal paraphrasing in English and Turkish.
- Mechanism: GPT-3 models rewrite objective sentences using prompts derived from journalistic subjectivity styles (emotional, propaganda, derogatory, exaggerated, partisan, prejudiced), creating training data that better captures the stylistic nuances of subjective text.
- Core assumption: Journalistic subjectivity requires specific stylistic markers that normal paraphrasing fails to capture.
- Evidence anchors:
  - [abstract] "style-based oversampling is better than paraphrasing in Turkish and English"
  - [section] "Our second finding is that style-based oversampling outperforms normal paraphrasing in Turkish and English datasets"
  - [corpus] No corpus evidence found
- Break condition: If GPT-3 models fail to generate linguistically coherent subjective texts in target languages, the style-based approach loses its advantage over paraphrasing.

### Mechanism 2
- Claim: Different subjective styles have varying effectiveness across languages due to cultural differences and dataset bias.
- Mechanism: Partisan and exaggerated styles are particularly effective in Turkish, while propaganda and exaggerated styles help in English. German results are less consistent.
- Core assumption: Subjectivity detection benefits from culturally-tailored subjective styles rather than universal approaches.
- Evidence anchors:
  - [abstract] "Partisan and exaggerated styles are particularly effective in Turkish, while propaganda and exaggerated styles help in English"
  - [section] "Among the various styles, partisan followed by exaggerated and prejudiced styles are particularly useful for the Turkish transformers, whereas propaganda and exaggerated styles are impactful for the English transformers"
  - [corpus] No corpus evidence found
- Break condition: If cultural differences are not properly accounted for in style selection, the approach may perform worse than language-agnostic methods.

### Mechanism 3
- Claim: Language-specific prompt templates yield more plausible style-based texts than a universal English template.
- Mechanism: Creating prompt templates in each target language (English, Turkish, German) improves the quality of generated subjective texts compared to using translated templates.
- Core assumption: GPT-3 models generate more linguistically coherent outputs when prompts are written in the model's native language.
- Evidence anchors:
  - [section] "we created templates that are written in each language" and "the template yielded highly implausible samples when applied to languages other than English"
  - [section] "Model 2 appeared to produce texts that were more grammatically and semantically correct compared to the other model" for Turkish
  - [corpus] No corpus evidence found
- Break condition: If language-specific templates do not account for linguistic nuances, they may still produce implausible outputs.

## Foundational Learning

- Concept: Subjectivity detection in journalism
  - Why needed here: The task requires distinguishing between objective reporting and subjective opinion, which differs from general subjectivity detection tasks
  - Quick check question: What are the key differences between journalistic subjectivity and general subjectivity in text?

- Concept: Text style transfer
  - Why needed here: The approach relies on rewriting objective sentences in various subjective styles to create training data
  - Quick check question: How does style-based data augmentation differ from normal paraphrasing in creating subjective training examples?

- Concept: Class imbalance handling in NLP
  - Why needed here: The dataset has significantly more objective samples than subjective ones, requiring sampling strategies
  - Quick check question: What are the advantages and disadvantages of under-sampling versus over-sampling for addressing class imbalance?

## Architecture Onboarding

- Component map: Subjectivity checklist -> Prompt generation -> GPT-3 generation -> Sampling -> Transformer training -> Classification

- Critical path: Subjectivity checklist → Prompt generation → GPT-3 generation → Sampling → Transformer training → Classification

- Design tradeoffs:
  - Language-specific vs. universal prompts: More accurate but requires more development effort
  - Under-sampling vs. over-sampling: Under-sampling preserves original data distribution but may lose information; over-sampling increases training data but risks overfitting
  - Style selection: More styles provide better coverage but increase complexity and may introduce noise

- Failure signatures:
  - Poor F1 scores despite style-based augmentation indicate GPT-3 generation quality issues
  - Disproportionate performance differences between languages suggest prompt/template problems
  - Overfitting on generated data shows sampling strategy needs adjustment

- First 3 experiments:
  1. Compare F1 scores of transformers trained on original data vs. data augmented with normal paraphrasing
  2. Test individual subjective styles (emotional, propaganda, derogatory, exaggerated, partisan, prejudiced) to identify most effective ones
  3. Evaluate language-specific vs. universal English prompts to verify template language importance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do specific cultural contexts influence the effectiveness of different subjective styles across languages?
- Basis in paper: [explicit] The authors note that "The effectiveness of different styles across languages may be attributed to factors such as dataset bias or variations in subjectivity across different cultures."
- Why unresolved: While the paper observes cultural variations, it does not systematically investigate how specific cultural factors impact style effectiveness or provide cross-cultural comparisons.
- What evidence would resolve it: Comparative analysis of style effectiveness across culturally diverse datasets with controlled variables, or ethnographic studies mapping journalistic subjectivity norms across cultures.

### Open Question 2
- Question: What are the optimal prompt engineering strategies for generating linguistically coherent subjective texts in non-English languages?
- Basis in paper: [explicit] The authors observe that "the generation of plausible style-based texts by GPT-3 models can be challenging in non-English languages" and that "Better prompting and parameter tuning aimed at a higher subtlety and more linguistic diversity in the generated outputs could therefore lead to improved results."
- Why unresolved: The paper uses simple, short prompts but does not explore more complex prompting strategies or parameter tuning techniques for multilingual generation.
- What evidence would resolve it: Systematic experimentation with diverse prompt structures, parameter configurations, and evaluation of output quality across languages using standardized metrics.

### Open Question 3
- Question: How can sample selection methods be optimized to improve the quality of style-transferred data for subjectivity detection?
- Basis in paper: [explicit] The authors state "we recognize the importance of sample selection in achieving successful style transfer" and plan to "investigate data selection methods, with a particular emphasis on challenging samples."
- Why unresolved: The paper uses random sampling but does not explore how different selection criteria (e.g., sentence complexity, semantic similarity) affect style transfer quality.
- What evidence would resolve it: Comparative studies of different sample selection algorithms applied to the same generation framework, measuring downstream model performance and human evaluation of generated text quality.

## Limitations

- GPT-3 models sometimes produce linguistically incoherent subjective texts in non-English languages, limiting augmentation effectiveness
- The approach shows inconsistent results across languages, with German particularly underperforming
- Cultural adaptation of subjective styles is not systematically investigated, raising questions about generalizability

## Confidence

- Style-based oversampling improves English/Turkish performance: Medium
- Different styles work better for different languages: Low
- Language-specific prompts yield better results: Medium

## Next Checks

1. **Cross-linguistic robustness test**: Apply the style-based augmentation approach to a parallel corpus containing identical news articles in multiple languages to isolate whether performance differences stem from cultural factors versus model/language-specific issues.

2. **Human evaluation study**: Conduct blinded assessments where human annotators rate the quality and subjective nature of GPT-3 generated texts versus original data to verify that style-based augmentation genuinely improves subjectivity detection rather than introducing artifacts.

3. **Ablation analysis of style effectiveness**: Systematically remove individual styles from the augmentation process to quantify their independent contribution to performance gains, particularly testing whether the most effective styles (partisan, exaggerated, propaganda) maintain their advantage when isolated from other styles.