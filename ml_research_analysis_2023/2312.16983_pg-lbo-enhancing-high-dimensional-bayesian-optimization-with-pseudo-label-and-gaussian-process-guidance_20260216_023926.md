---
ver: rpa2
title: 'PG-LBO: Enhancing High-Dimensional Bayesian Optimization with Pseudo-Label
  and Gaussian Process Guidance'
arxiv_id: '2312.16983'
source_url: https://arxiv.org/abs/2312.16983
tags:
- data
- labeled
- optimization
- unlabeled
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of utilizing both labeled and
  unlabeled data in high-dimensional Bayesian optimization using Variational Autoencoders
  (VAEs). The authors propose PG-LBO, a method that leverages pseudo-labels from unlabeled
  data and Gaussian Process (GP) guidance to enhance the discriminative power of the
  latent space.
---

# PG-LBO: Enhancing High-Dimensional Bayesian Optimization with Pseudo-Label and Gaussian Process Guidance

## Quick Facts
- **arXiv ID**: 2312.16983
- **Source URL**: https://arxiv.org/abs/2312.16983
- **Reference count**: 24
- **Key outcome**: PG-LBO outperforms existing VAE-BO methods in three tasks (topology shape fitting, expression reconstruction, and chemical design) by leveraging pseudo-labels from unlabeled data and Gaussian Process guidance

## Executive Summary
This paper addresses the challenge of utilizing both labeled and unlabeled data in high-dimensional Bayesian optimization using Variational Autoencoders (VAEs). The authors propose PG-LBO, a method that enhances the discriminative power of the latent space by combining pseudo-label training with Gaussian Process (GP) guidance. The approach assigns pseudo-labels to unlabeled data based on GP posterior means, applies rank-based weighting during VAE training, and integrates labeled data directly into the VAE training process through GP guidance. Experimental results on three diverse tasks demonstrate that PG-LBO achieves superior optimization performance compared to existing VAE-BO methods.

## Method Summary
PG-LBO enhances high-dimensional Bayesian optimization by leveraging unlabeled data through pseudo-label training and improving labeled data utilization through GP guidance. The method generates pseudo-labels for unlabeled data using GP posterior means, applies rank-based weighting to emphasize relative objective values during VAE training, and filters high-uncertainty samples dynamically. GP guidance unifies the VAE encoder and GP surrogate as a deep kernel learning process, optimizing the latent space representation to improve GP prediction accuracy. The approach is evaluated on three tasks with datasets of varying sizes and dimensionalities, demonstrating improved optimization performance over baseline methods.

## Key Results
- PG-LBO outperforms existing VAE-BO methods on topology shape fitting, expression reconstruction, and chemical design tasks
- The method achieves better optimization results by effectively exploiting unlabeled data potential and improving labeled data utilization
- PG-LBO demonstrates robust performance even with limited labeled data (<1% of total data)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pseudo-label training with weighted unlabeled data improves latent space discriminativeness by emphasizing relative objective value relationships
- Mechanism: The method assigns pseudo-labels (posterior GP means) to unlabeled data, then uses rank-based weighting to prioritize points with higher pseudo-label values during VAE training
- Core assumption: Relative ranking of pseudo-labels reliably reflects relative optimization objective values, even when absolute values are uncertain
- Evidence anchors:
  - [abstract] "pseudo-labels to explicitly reveal the relative magnitudes of optimization objective values hidden within the unlabeled data"
  - [section] "s(ˆx) represents the pseudo-label of the unlabeled data sample ˆx, which only needs to reflect the relative magnitudes of the black-box function values among unlabeled data"
- Break condition: If pseudo-label uncertainty becomes too high relative to the optimization objective's sensitivity, the weighting scheme may amplify noise rather than useful signal

### Mechanism 2
- Claim: Gaussian Process guidance directly optimizes the VAE encoder to produce latent representations that improve GP surrogate accuracy
- Mechanism: The method treats VAE encoder + GP as unified deep kernel learning, minimizing MSE between GP predictions and actual labels while regularizing variance for unlabeled data
- Core assumption: Improving GP accuracy on labeled data through latent space optimization will translate to better BO performance
- Evidence anchors:
  - [abstract] "we propose a more streamlined method for exploiting labeled data. Specifically, we unify the V AE encoder and the Gaussian Process (GP) in BO as a cohesive deep kernel learning process"
  - [section] "we treat the V AE encoder and the Gaussian Process (GP) model of the BO as a unified process and directly incorporate the goal of improving GP prediction accuracy into the training of the V AE"
- Break condition: If the GP model's inductive bias doesn't align with the true objective function structure, optimizing for GP accuracy may degrade actual optimization performance

### Mechanism 3
- Claim: Dynamic uncertainty-based filtering of pseudo-labeled data improves model robustness by removing high-error samples
- Mechanism: The method uses GP posterior variance as uncertainty measure and filters samples above an exponentially moving average threshold
- Core assumption: GP posterior variance reliably indicates prediction error for pseudo-labeled samples
- Evidence anchors:
  - [section] "we use uncertainty to select robust pseudo-label data... The variance conveniently doubles as a measure of prediction uncertainty"
  - [section] "we set the uncertainty threshold τt for filtering as the model's average prediction variance on unlabeled data"
- Break condition: If the GP model systematically underestimates uncertainty for certain regions of the latent space, useful data may be incorrectly filtered out

## Foundational Learning

- **Concept**: Variational Autoencoders and latent space representations
  - Why needed here: The method relies on VAEs to map high-dimensional structured inputs to lower-dimensional continuous latent spaces for efficient BO
  - Quick check question: How does the VAE reconstruction loss ensure that the latent space preserves information needed for optimization?

- **Concept**: Gaussian Process regression and acquisition functions
  - Why needed here: The method uses GPs as surrogate models for the black-box function and needs to understand how GP predictions guide BO decisions
  - Quick check question: What role does the acquisition function play in balancing exploration vs exploitation in BO?

- **Concept**: Semi-supervised learning and pseudo-labeling techniques
  - Why needed here: The method adapts pseudo-labeling from semi-supervised learning to utilize unlabeled data in BO context
  - Quick check question: How does the rank-based weighting in pseudo-label training differ from standard cross-entropy loss in classification?

## Architecture Onboarding

- **Component map**:
  - VAE Encoder: Maps high-dimensional inputs to latent space
  - VAE Decoder: Reconstructs inputs from latent representations
  - GP Model: Surrogate for black-box function in latent space
  - Pseudo-label Module: Assigns relative objective values to unlabeled data
  - Weighted Retraining Module: Applies rank-based weights during VAE training
  - Data Sampling Module: Generates unlabeled data points via noise/heuristic sampling
  - Threshold Filtering: Removes high-uncertainty pseudo-labeled samples

- **Critical path**: VAE training → GP fitting → Acquisition optimization → New point evaluation → Data sampling → Pseudo-labeling → Weighted retraining

- **Design tradeoffs**:
  - Pseudo-label accuracy vs computational cost of GP predictions
  - Sampling quality vs diversity of unlabeled data
  - Weighting aggressiveness vs overfitting risk
  - Threshold strictness vs data utilization

- **Failure signatures**:
  - VAE latent space becomes too compressed, losing optimization-relevant information
  - GP predictions become overconfident in regions with sparse data
  - Pseudo-label filtering removes too many samples, limiting unlabeled data utility
  - Sampling focuses too narrowly on known high-scoring regions

- **First 3 experiments**:
  1. Implement basic VAE with weighted retraining on labeled data only (LBO baseline)
  2. Add pseudo-label training with fixed threshold filtering to verify rank-based weighting improves performance
  3. Integrate GP guidance loss and test with different λG values to find optimal balance between reconstruction and GP accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical foundation for the choice of uncertainty as the threshold for pseudo-label selection, and how does it compare to other potential thresholding strategies?
- Basis in paper: [explicit] The paper discusses using uncertainty derived from Gaussian Process models as a selection threshold for pseudo-labels, citing its effectiveness in avoiding cognitive bias and enhancing the accuracy of pseudo-labels.
- Why unresolved: The choice of uncertainty as a threshold is motivated by empirical evidence showing a correlation between pseudo-label error and variance, but the paper does not explore other potential thresholding strategies or provide a theoretical foundation for this choice.
- What evidence would resolve it: A theoretical analysis of different thresholding strategies, including uncertainty-based, confidence-based, and data-driven methods, comparing their effectiveness in improving pseudo-label quality and overall model performance.

### Open Question 2
- Question: How does the performance of PG-LBO vary with the size of the labeled dataset, and what is the minimum amount of labeled data required to achieve significant improvements over baseline methods?
- Basis in paper: [explicit] The paper presents results on a small-scale labeled dataset, showing that PG-LBO outperforms baseline methods even with less than 1% of the labeled data. However, the performance of all methods declines with smaller labeled datasets.
- Why unresolved: While the paper demonstrates the effectiveness of PG-LBO on a small labeled dataset, it does not explore the relationship between labeled dataset size and performance in detail, nor does it identify the minimum amount of labeled data required for significant improvements.
- What evidence would resolve it: A comprehensive study varying the size of the labeled dataset across multiple tasks, identifying the point at which PG-LBO's performance starts to significantly degrade and comparing it to the performance of baseline methods.

### Open Question 3
- Question: How do the different sampling methods (noisy sampling, heuristic sampling, and random sampling) affect the quality of pseudo-labels and the overall performance of PG-LBO?
- Basis in paper: [explicit] The paper introduces two sampling methods (noisy sampling and heuristic sampling) and compares them to random sampling, finding that noisy sampling and heuristic sampling outperform random sampling in terms of model performance.
- Why unresolved: While the paper provides empirical evidence for the effectiveness of noisy and heuristic sampling, it does not delve into the reasons behind their superior performance or explore the potential impact of other sampling methods on pseudo-label quality and model performance.
- What evidence would resolve it: An in-depth analysis of the sampling methods, including a comparison of their ability to generate high-quality pseudo-labels, their computational efficiency, and their impact on the overall performance of PG-LBO across multiple tasks and dataset sizes.

## Limitations
- The effectiveness of pseudo-label quality depends on the accuracy of GP posterior variance as an uncertainty measure
- The method's scalability to extremely high-dimensional spaces (>1000 dimensions) remains untested
- Careful tuning of threshold parameters for dynamic uncertainty filtering is required, which could significantly impact performance

## Confidence
- **High Confidence**: The overall optimization performance improvements demonstrated in the three experimental tasks
- **Medium Confidence**: The mechanism by which pseudo-label weighting improves latent space discriminativeness
- **Medium Confidence**: The effectiveness of GP guidance in unifying VAE and GP training objectives

## Next Checks
1. **Pseudo-label quality validation**: Measure correlation between GP posterior variance and actual prediction error on pseudo-labeled samples to verify the uncertainty filtering mechanism's effectiveness
2. **Latent space interpretability**: Visualize and analyze how the pseudo-label weighted training affects the distribution of high-scoring versus low-scoring points in the latent space
3. **Ablation study on GP guidance**: Compare performance with and without GP guidance (varying λG) to quantify its contribution to the overall method's effectiveness