---
ver: rpa2
title: Human-centred explanation of rule-based decision-making systems in the legal
  domain
arxiv_id: '2310.16704'
source_url: https://arxiv.org/abs/2310.16704
tags:
- explanation
- legal
- system
- decision-making
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a human-centred explanation method for rule-based
  decision-making systems in the legal domain. The method uses a graph database to
  enable question-driven explanations and multimedia display, allowing for tailored
  explanations to different users.
---

# Human-centred explanation of rule-based decision-making systems in the legal domain

## Quick Facts
- arXiv ID: 2310.16704
- Source URL: https://arxiv.org/abs/2310.16704
- Reference count: 23
- Primary result: Introduces a human-centred explanation method for rule-based legal decision systems using graph databases

## Executive Summary
This paper presents a novel method for generating human-centred explanations of rule-based decision-making systems in the legal domain. The approach leverages graph database management systems to structure explanations according to a legal analysis schema, enabling question-driven user-system interaction and multimedia display. The method aims to improve transparency and understanding for different user groups, including model experts and legal support professionals. A case study at the Dutch Tax and Customs Administration demonstrates the practical application of this approach.

## Method Summary
The method uses a graph database to structure explanations based on a legal analysis schema, combining it with question-driven user interaction and multimedia display. It focuses on three internal components (content, communication, adaptation) and three external dependencies (domain, system properties, recipient). The approach is implemented using Neo4j graph database and applied to rule-based systems created with the ALEF tool. Explanations are generated by querying the graph database to retrieve relevant information about decisions, rules, and their relationships.

## Key Results
- Graph database enables structured, question-driven explanations for legal decision systems
- Method successfully tailors explanations to different user groups (model experts vs. legal support professionals)
- Case study demonstrates practical application in Dutch Tax and Customs Administration

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph database enables structured, question-driven explanations by representing legal concepts and relationships
- Mechanism: Legal concepts (legal subject, object, relationship, fact) are modeled as nodes, with relationships capturing their legal connections
- Core assumption: The legal analysis schema accurately captures the essential components and relationships of the legal domain
- Evidence anchors:
  - [abstract] "The method uses a graph database to enable question-driven explanations and multimedia display, allowing for tailored explanations to different users."
  - [section] "In our explanation method, we utilise GDBMS to structure our explanations according to the legal analysis schema... and we combine it with question-driven user-system interaction and multimedia display to account for the three internal components."
- Break condition: If the legal analysis schema is incomplete or inaccurate, the graph database structure will fail to capture essential legal relationships

### Mechanism 2
- Claim: Question-driven explanations adapt to user needs by focusing on specific decision aspects and varying detail levels
- Mechanism: Users can ask different types of questions and filter information by focusing on specific parts, nodes, or relationships
- Core assumption: Users have clear information needs that can be addressed through specific question types and filtering options
- Evidence anchors:
  - [abstract] "This way, we can tailor the explanation to the user."
  - [section] "Recipients can question both the decision model and a specific decision (focus), filter information by, for instance, focusing on a specific part, node or relationship (level of detail) and extract causal relations between conditions, rules and derivations of these rules (causality)"
- Break condition: If users' information needs are too diverse or unpredictable, the predefined question types may not adequately address their needs

### Mechanism 3
- Claim: Multimedia display enhances explanation comprehension by presenting information in multiple formats
- Mechanism: Explanations are communicated through visual graphs, verbal text answers, and customized filtering options
- Core assumption: Users benefit from receiving information in multiple formats
- Evidence anchors:
  - [abstract] "The method uses a graph database to enable question-driven explanations and multimedia display..."
  - [section] "Explanations are answers to predefined questions that can be communicated through visual graphs, verbal text answers and customised filtering options."
- Break condition: If users prefer a single format or find multimedia display overwhelming, additional formats may hinder understanding

## Foundational Learning

- Concept: Graph Database Management Systems (GDBMS)
  - Why needed here: GDBMS enables representation of legal concepts and relationships as nodes and connections
  - Quick check question: What are the key components of a graph database, and how do they differ from traditional relational databases?

- Concept: Legal Analysis Schema
  - Why needed here: Provides a framework for structuring legal concepts and relationships in the graph database
  - Quick check question: What are the main elements of the legal analysis schema, and how do they relate to each other in legal decision-making?

- Concept: Question-Driven Explanations
  - Why needed here: Allows users to actively engage with the system and receive tailored information
  - Quick check question: What are the different types of questions users might ask about a decision-making system?

## Architecture Onboarding

- Component map: Graph Database -> Question Engine -> Explanation Generator -> User Interface
- Critical path: User question → Question Engine processing → Graph Database query → Explanation Generator formatting → User Interface display
- Design tradeoffs:
  - Flexibility vs. Complexity: Allowing for diverse user needs requires a more complex system
  - Performance vs. Comprehensiveness: Balancing depth of explanations with speed of retrieval
- Failure signatures:
  - Incomplete or inaccurate explanations: Issues with legal analysis schema or graph database structure
  - Slow response times: Performance bottlenecks in question engine or explanation generator
  - User confusion or disengagement: Issues with user interface or explanation formats
- First 3 experiments:
  1. Implement basic graph database with simple legal analysis schema and test query performance
  2. Develop question engine that processes limited question types and retrieves information
  3. Create explanation generator that formats information into text and visual explanations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the explanation method be extended to handle "what if" and "why not" questions for legal support professionals?
- Basis in paper: [explicit] The paper states that the current method can answer "what" and "why" questions but cannot provide answers to "what if" and "why not" questions
- Why unresolved: The paper acknowledges this limitation but does not propose a specific solution
- What evidence would resolve it: A prototype implementation demonstrating the method's ability to answer these questions

### Open Question 2
- Question: How can the explanation method be adapted to handle dynamic changes in the target audience's knowledge and goals?
- Basis in paper: [inferred] The paper mentions creating different perspectives for different recipient categories but doesn't address changes over time
- Why unresolved: The paper does not discuss mechanisms for updating explanations based on changing user needs
- What evidence would resolve it: A user study showing how the method adapts to changing user needs

### Open Question 3
- Question: How can the explanation method be generalized to other domains beyond the legal domain?
- Basis in paper: [explicit] The paper states the method could be applied to other domains but doesn't provide guidelines
- Why unresolved: The paper doesn't provide a clear framework for adapting the method to other domains
- What evidence would resolve it: A case study applying the method to a different domain

## Limitations

- Effectiveness of explanations for diverse legal domains and user groups remains to be thoroughly validated
- Potential challenges in scaling the method for large, complex legal systems not addressed
- Handling of dynamic changes in legal regulations not discussed

## Confidence

- High confidence: The mechanism of using a graph database to structure explanations according to a legal analysis schema
- Medium confidence: The claim that question-driven explanations can effectively adapt to user needs
- Medium confidence: The assertion that multimedia display enhances explanation comprehension

## Next Checks

1. Conduct user studies with diverse legal domains and user groups to assess effectiveness and adaptability of explanations

2. Evaluate scalability and performance when applied to large, complex legal systems with frequent regulatory changes

3. Investigate integration with other explainable AI techniques (LIME, SHAP) to explore potential synergies and enhance transparency