---
ver: rpa2
title: 'Towards Objective Evaluation of Socially-Situated Conversational Robots: Assessing
  Human-Likeness through Multimodal User Behaviors'
arxiv_id: '2308.11020'
source_url: https://arxiv.org/abs/2308.11020
tags:
- human-likeness
- evaluation
- user
- dialogue
- robot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an objective evaluation method for socially-situated
  conversational robots by leveraging multimodal user behaviors. The key innovation
  is assessing the human-likeness of the robot based on observable user behaviors
  such as speech, gaze, and dialogue features, rather than relying on subjective user
  evaluations.
---

# Towards Objective Evaluation of Socially-Situated Conversational Robots: Assessing Human-Likeness through Multimodal User Behaviors

## Quick Facts
- arXiv ID: 2308.11020
- Source URL: https://arxiv.org/abs/2308.11020
- Reference count: 27
- Primary result: Proposed method predicts human-likeness scores with MAE of 0.146 using multimodal user behaviors

## Executive Summary
This paper addresses the challenge of objectively evaluating socially-situated conversational robots (SCRs) by developing a method that assesses human-likeness based on observable user behaviors rather than subjective evaluations. The approach leverages multimodal user behaviors—including speech patterns, gaze, and dialogue features—as proxies for human-likeness. Using an attentive listening dialogue corpus, the authors demonstrate that a support vector regression model can predict human-likeness scores with reasonable accuracy, providing a reproducible evaluation framework that avoids the limitations of subjective assessments.

## Method Summary
The method involves collecting attentive listening dialogue data with varying human-likeness conditions (autonomous vs WOZ), annotating user behaviors across four categories (voice activity, linguistic features, gaze, and dialogue features), and having third-party evaluators classify dialogue segments as human or autonomous system to generate human-likeness scores. The authors then calculate correlation coefficients between user behaviors and human-likeness scores, and train a support vector regression model to predict human-likeness scores with leave-one-out cross-validation.

## Key Results
- Weak correlations observed between human-likeness scores and user behaviors: total utterance time (r = 0.35), number of unique words (r = 0.33), and average switching pause length (r = -0.35)
- SVR model predicts human-likeness scores with mean absolute error of 0.146
- Four behavioral categories analyzed: voice activity, linguistic features, gaze, and dialogue features
- Method provides objective alternative to subjective user evaluations for SCR assessment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Observable user behaviors can serve as a proxy for robot human-likeness
- Mechanism: Users unconsciously adjust their multimodal behaviors based on how human-like they perceive the robot to be. By measuring these behaviors, we can infer human-likeness without direct subjective evaluation
- Core assumption: User behaviors differ systematically between human-like and less human-like interactions
- Evidence anchors:
  - [abstract] "our approach aims to evaluate the robot's human-likeness based on observable user behaviors indirectly"
  - [section] "In this study, we empirically explore multimodal user behaviors that relate to the human likeness of the robot"
  - [corpus] Weak correlation found in corpus - only 5 neighbors with average FMR 0.379, suggesting limited prior work directly validating this behavioral proxy
- Break condition: If user behaviors do not systematically differ between human-like and non-human-like interactions, the proxy fails

### Mechanism 2
- Claim: Multiple behavior modalities provide complementary signals for human-likeness assessment
- Mechanism: Different behavioral dimensions capture different aspects of human-likeness. Combining these signals improves prediction accuracy beyond any single modality
- Core assumption: Each behavioral dimension captures unique information about human-likeness
- Evidence anchors:
  - [abstract] "By investigating Spearman's rank correlation coefficients, we observed weak correlations in several behaviors"
  - [section] Lists four distinct behavioral categories (voice activity, linguistic, gaze, dialogue) with specific features for each
  - [corpus] No corpus evidence directly supports multi-modality benefits; this appears to be an assumption from the paper
- Break condition: If behaviors are highly correlated or redundant, multi-modality adds little value

### Mechanism 3
- Claim: Support vector regression can effectively model the relationship between user behaviors and human-likeness scores
- Mechanism: SVR maps the multidimensional behavioral feature space to the human-likeness score space, learning the underlying relationship from annotated data
- Core assumption: The relationship between behaviors and human-likeness is learnable and generalizable
- Evidence anchors:
  - [abstract] "A support vector regression model could predict human-likeness scores with a mean absolute error of 0.146"
  - [section] "We conducted leave-one-out cross-validation using support vector regression"
  - [corpus] No corpus evidence about SVR performance; this appears to be novel to this paper
- Break condition: If the relationship is too complex or noisy for SVR to capture, prediction accuracy will remain low

## Foundational Learning

- Concept: Multimodal signal processing
  - Why needed here: The method relies on extracting and analyzing multiple behavioral signals from user interactions
  - Quick check question: Can you name three different types of behavioral features extracted from user interactions in this study?

- Concept: Correlation analysis and regression modeling
  - Why needed here: The study investigates correlations between behaviors and human-likeness, then builds a regression model to predict human-likeness from behaviors
  - Quick check question: What statistical method was used to measure the relationship between individual behaviors and human-likeness scores?

- Concept: Evaluation metric design
  - Why needed here: The study creates a novel evaluation framework using human-likeness scores and establishes prediction accuracy targets
  - Quick check question: What was the mean absolute error achieved by the SVR model, and how does it compare to the scale of human-likeness scores?

## Architecture Onboarding

- Component map: Data collection -> Annotation pipeline -> Feature extraction -> Correlation analysis -> SVR modeling -> Validation

- Critical path: Data collection → Annotation → Feature extraction → Correlation analysis → SVR modeling → Validation

- Design tradeoffs:
  - Manual vs. automatic feature extraction (manual provides richer features but limits scalability)
  - Single vs. multiple behavior modalities (multi-modal provides richer information but increases complexity)
  - Correlation vs. causation (correlation provides practical utility but doesn't prove causal relationship)

- Failure signatures:
  - Low correlation coefficients between behaviors and human-likeness
  - High prediction error from SVR model
  - Poor generalization to different dialogue types or robot systems

- First 3 experiments:
  1. Test correlation analysis on a subset of the data to verify behavioral differences exist
  2. Train SVR model on half the data and test on the other half to check for overfitting
  3. Apply the evaluation method to a different dialogue type (e.g., job interview) to test generalizability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well do human-likeness scores generalize across different types of dialogues and robot interfaces beyond the attentive listening task studied?
- Basis in paper: [explicit] Authors mention this as future work, stating "we are now extending this work to job interviews and first-time meeting scenarios where the role of the robots is different from the one in the attentive listening scenario."
- Why unresolved: The current study only uses data from an attentive listening dialogue corpus with an android robot. Different dialogue types and robot interfaces may elicit different user behaviors and human-likeness perceptions.
- What evidence would resolve it: Testing the proposed evaluation method across diverse dialogue scenarios (e.g., counseling, interviews, casual conversations) and robot interfaces (e.g., different embodiments, virtual agents) and validating correlation between user behaviors and human-likeness scores in each context.

### Open Question 2
- Question: Can human-likeness be predicted with comparable accuracy using automatically extractable features rather than manually annotated ones?
- Basis in paper: [inferred] The authors note that some behaviors like voice activity can be extracted automatically, but most used features require manual annotation. They achieve MAE of 0.146 with manually annotated features.
- Why unresolved: The study relies on manually annotated features, which is time-consuming and limits scalability. The relationship between human-likeness and automatically extractable features remains unknown.
- What evidence would resolve it: Training and testing prediction models using only automatically extractable features (e.g., from audio, text, and low-level visual analysis) and comparing performance to the current manual annotation approach.

### Open Question 3
- Question: What is the causal relationship between user behaviors and perceived human-likeness - do behaviors cause perceptions or do perceptions influence behaviors?
- Basis in paper: [explicit] The authors state "Intuitively, those user behaviors are different depending on the human likeness of the robot" and analyze correlations, but acknowledge this doesn't establish causation.
- Why unresolved: The study establishes correlation but cannot determine if more human-like robots elicit different user behaviors, or if user behaviors signal to robots how to respond more human-like, or if a bidirectional relationship exists.
- What evidence would resolve it: Controlled experiments manipulating robot behaviors while measuring resulting user behaviors and perceptions, or longitudinal studies tracking changes in both robot behaviors and user perceptions over time.

## Limitations

- Weak correlations (r = 0.35 to -0.35) between user behaviors and human-likeness scores suggest the behavioral proxy may not be robust
- Reliance on manual annotation of user behaviors limits scalability and may introduce observer bias
- Limited prior work directly validating this behavioral proxy approach (only 5 related papers found with FMR of 0.379)

## Confidence

- High Confidence: The methodological framework for correlating user behaviors with human-likeness scores is sound and the SVR prediction results (MAE = 0.146) are within the acceptable range for the scale used.
- Medium Confidence: The weak correlations suggest that while the approach works in principle, the relationship between behaviors and human-likeness may be more complex than captured by the current feature set.
- Low Confidence: The generalizability of this evaluation method to other dialogue types or robot systems remains untested, and the reliance on manual annotations raises concerns about practical implementation.

## Next Checks

1. **Cross-validation with alternative dialogue types**: Apply the evaluation method to different conversational scenarios (e.g., task-oriented dialogues, emotional support conversations) to test generalizability beyond attentive listening.

2. **Automatic vs. manual feature extraction comparison**: Implement automated behavioral feature extraction and compare prediction accuracy with the manual annotation approach to assess scalability potential.

3. **Ablation study on behavioral modalities**: Systematically remove individual behavioral feature categories to quantify their relative contribution to human-likeness prediction and identify the most informative modalities.