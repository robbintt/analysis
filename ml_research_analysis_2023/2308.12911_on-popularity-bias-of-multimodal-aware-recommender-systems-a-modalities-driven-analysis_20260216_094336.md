---
ver: rpa2
title: 'On Popularity Bias of Multimodal-aware Recommender Systems: a Modalities-driven
  Analysis'
arxiv_id: '2308.12911'
source_url: https://arxiv.org/abs/2308.12911
tags:
- bias
- recommendation
- popularity
- multimodal
- items
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work analyzes how multimodal-aware recommender systems may
  amplify popularity bias, which favors popular items over niche ones. The study evaluates
  four state-of-the-art multimodal recommendation models (VBPR, MMGCN, GRCN, LATTICE)
  on Amazon datasets, measuring accuracy, diversity, and popularity bias metrics.
---

# On Popularity Bias of Multimodal-aware Recommender Systems: a Modalities-driven Analysis

## Quick Facts
- **arXiv ID:** 2308.12911
- **Source URL:** https://arxiv.org/abs/2308.12911
- **Reference count:** 40
- **Primary result:** Multimodal-aware recommender systems amplify popularity bias, with LATTICE excelling in accuracy but amplifying bias most, while VBPR and GRCN balance accuracy with diversity and bias reduction better.

## Executive Summary
This paper analyzes how multimodal-aware recommender systems amplify popularity bias, which favors popular items over niche ones. The study evaluates four state-of-the-art multimodal recommendation models (VBPR, MMGCN, GRCN, LATTICE) on Amazon datasets, measuring accuracy, diversity, and popularity bias metrics. Results show that while LATTICE excels in accuracy, it also amplifies popularity bias the most. VBPR and GRCN perform better in balancing accuracy with diversity and reducing popularity bias. Additionally, the study finds that using individual modalities (visual or textual) instead of the full multimodal setting can improve accuracy but often reduces diversity and increases popularity bias.

## Method Summary
The study evaluates four multimodal recommender systems on three Amazon datasets (Office, Toys, Clothing) with visual features (4,096-dim) and textual features (1,024-dim embeddings). Datasets are filtered using p-core strategy (p=5) and split 80%/20% train/test. The four models (VBPR, MMGCN, GRCN, LATTICE) are trained in three modality settings: multimodal, visual-only, and textual-only. Hyperparameters are tuned on validation set using Recall@20 metric. Models are evaluated using accuracy metrics (Recall, nDCG), diversity metric (iCov), and popularity bias metric (APLT).

## Key Results
- LATTICE achieves highest accuracy but amplifies popularity bias most significantly
- VBPR and GRCN provide better balance between accuracy, diversity, and bias reduction
- Using individual modalities can improve accuracy but typically reduces diversity and increases popularity bias
- Textual modality has significant accuracy impact with minimal effects on diversity and bias
- Visual modality reduces accuracy and exacerbates popularity bias while limiting diversity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multimodal-aware recommender systems amplify popularity bias because their base MF-BPR architecture inherently favors popular items, and adding multimodal features can intensify this tendency.
- Mechanism: The MF-BPR model learns latent embeddings for users and items and optimizes to rank positive interactions higher than negative ones. Since popular items have more interactions, they dominate the learning signal, and adding multimodal features may reinforce these signals if they correlate with popularity.
- Core assumption: MF-BPR's optimization inherently biases toward items with more interactions, and multimodal features can act as additional popularity signals.
- Evidence anchors:
  - [abstract] "While most of such methods rely on factorization models (e.g., MFBPR) as base architecture, it has been shown that MFBPR may be affected by popularity bias, meaning that it inherently tends to boost the recommendation of popular (i.e., short-head) items at the detriment of niche (i.e., long-tail) items"
  - [section] "driven from the assumptions above, and differently from the related literature, we propose one of the first analyses on how multimodal-aware recommender systems may amplify popularity bias in the produced recommendation lists"
  - [corpus] Weak: The corpus neighbors focus on popularity bias in recommender systems but don't specifically discuss multimodal features amplifying the bias. However, the overall theme of popularity bias in recommender systems supports the mechanism.
- Break condition: If multimodal features are decorrelated from item popularity, the amplification effect may not occur.

### Mechanism 2
- Claim: Different modalities (visual vs. textual) have distinct effects on popularity bias, with visual modality often exacerbating bias while textual modality may have less impact.
- Mechanism: Visual features may capture aspects that correlate more strongly with item popularity (e.g., aesthetic appeal, brand recognition), while textual features may provide more diverse signals that don't correlate as strongly with popularity.
- Core assumption: Visual and textual modalities contain different information that relates differently to item popularity.
- Evidence anchors:
  - [abstract] "the study finds that using individual modalities (visual or textual) instead of the full multimodal setting can improve accuracy but often reduces diversity and increases popularity bias. Specifically, the textual modality has a significant impact on accuracy with minimal effects on diversity and bias, whereas the visual modality reduces accuracy and exacerbates popularity bias while limiting diversity."
  - [section] "to better investigate this aspect, we decide to study the separate influence of each modality (i.e., visual and textual) on popularity bias in different evaluation dimensions"
  - [corpus] Weak: The corpus doesn't provide specific evidence about how different modalities affect popularity bias differently.
- Break condition: If visual features are carefully engineered to be decorrelated from popularity, the exacerbation effect may not occur.

### Mechanism 3
- Claim: Graph-based multimodal recommender systems (like MMGCN and GRCN) are particularly susceptible to popularity bias due to their reliance on user-item interaction graphs that inherently contain popularity signals.
- Mechanism: These systems refine adjacency matrices based on user preferences, which are influenced by the popularity of items. The graph convolution operations then propagate these popularity signals throughout the network, amplifying the bias.
- Core assumption: User-item interaction graphs inherently contain popularity signals that graph neural networks can amplify.
- Evidence anchors:
  - [abstract] "Results, which demonstrate how the single modality may augment the negative effect of popularity bias, shed light on the importance to provide a more rigorous analysis of the performance of such models."
  - [section] "Specifically, the textual modality has a significant impact on accuracy with minimal effects on diversity and bias, whereas the visual modality reduces accuracy and exacerbates popularity bias while limiting diversity."
  - [corpus] Weak: The corpus neighbors discuss popularity bias in recommender systems but don't specifically address graph-based multimodal systems.
- Break condition: If the graph is carefully preprocessed to remove popularity signals, the amplification effect may be mitigated.

## Foundational Learning

- Concept: Popularity bias in recommender systems
  - Why needed here: Understanding what popularity bias is and how it manifests is crucial for interpreting the study's findings and implications.
  - Quick check question: What is the difference between short-head and long-tail items in the context of recommender systems?

- Concept: Multimodal-aware recommender systems
  - Why needed here: Understanding how these systems integrate different types of content (visual, textual) as side information is key to grasping how they might amplify popularity bias.
  - Quick check question: How do multimodal recommender systems differ from traditional collaborative filtering approaches?

- Concept: Matrix factorization and BPR optimization
  - Why needed here: These are the foundational techniques used by the studied recommender systems, and understanding them is crucial for grasping how popularity bias can emerge and be amplified.
  - Quick check question: What is the core idea behind matrix factorization in the context of recommender systems?

## Architecture Onboarding

- Component map: Data preprocessing (p-core filtering) -> Model training (VBPR, MMGCN, GRCN, LATTICE) -> Evaluation (Recall, nDCG, iCov, APLT)
- Critical path: Prepare datasets → Train models in three modality settings → Evaluate using accuracy, diversity, and bias metrics
- Design tradeoffs: The study trades off between evaluating a comprehensive set of models and metrics and the computational cost of doing so.
- Failure signatures: Failure could manifest as poor performance on one or more metrics, or as inconsistent results across different datasets or modality settings.
- First 3 experiments:
  1. Train and evaluate VBPR on the Office dataset in the multimodal setting, using Recall@10, iCov@10, and APLT@10.
  2. Train and evaluate MMGCN on the Toys dataset in the visual-only setting, using Recall@20, iCov@20, and APLT@20.
  3. Train and evaluate GRCN on the Clothing dataset in the textual-only setting, using Recall@50, iCov@50, and APLT@50.

## Open Questions the Paper Calls Out

- Open Question 1: How do multimodal-aware recommender systems perform in terms of accuracy, diversity, and popularity bias when using only visual or textual modalities compared to the multimodal setting?
  - Basis in paper: [explicit] The paper explicitly investigates the influence of each modality (visual, textual, multimodal) on performance metrics and reports findings that single modalities can improve accuracy but often reduce diversity and increase popularity bias.
  - Why unresolved: The paper provides results for individual modalities but doesn't fully explore why these trade-offs occur or how to mitigate them.
  - What evidence would resolve it: Further studies examining the mechanisms behind modality-specific effects on bias and diversity, along with potential mitigation strategies.

- Open Question 2: What are the underlying causes of popularity bias amplification in multimodal recommender systems, and how can this be addressed?
  - Basis in paper: [explicit] The paper identifies that certain models like LATTICE amplify popularity bias and that single modalities can exacerbate this issue, but it doesn't explore the root causes or solutions.
  - Why unresolved: The analysis focuses on measuring bias but doesn't delve into the reasons for its amplification or propose methods to counteract it.
  - What evidence would resolve it: Research investigating the interaction between modalities and bias, along with experiments testing debiasing techniques.

- Open Question 3: How do different multimodal recommender system architectures (e.g., VBPR, MMGCN, GRCN, LATTICE) handle dataset sparsity, and what architectural features contribute to their performance?
  - Basis in paper: [explicit] The paper compares these models' performance on sparse datasets and notes differences, but doesn't analyze the architectural reasons for these differences.
  - Why unresolved: While performance is measured, the paper doesn't investigate how specific architectural choices affect handling of sparsity.
  - What evidence would resolve it: Ablation studies isolating architectural components and their impact on performance across varying levels of dataset sparsity.

## Limitations
- The study focuses on specific Amazon datasets and four particular multimodal recommender systems, limiting generalizability to other domains or architectures
- While the paper demonstrates that multimodal-aware systems amplify popularity bias, it doesn't provide detailed analysis of why this occurs at the feature level or propose concrete mitigation strategies
- The evaluation relies on standard metrics that may not capture all aspects of popularity bias in real-world recommendation scenarios

## Confidence
- High confidence in the finding that multimodal-aware systems amplify popularity bias, supported by consistent results across datasets and models
- Medium confidence in the specific ranking of models by bias amplification (LATTICE > others) due to potential hyperparameter sensitivity
- Medium confidence in the differential effects of visual vs. textual modalities, as the study provides empirical evidence but limited theoretical explanation

## Next Checks
1. Replicate the study on additional datasets from different domains (e.g., MovieLens, Yelp) to test generalizability of findings
2. Conduct feature-level analysis to identify which specific visual or textual features correlate most strongly with item popularity and bias amplification
3. Test whether preprocessing techniques (e.g., popularity decorrelation, adversarial debiasing) can mitigate the observed popularity bias amplification in multimodal systems