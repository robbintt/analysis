---
ver: rpa2
title: Robust Collaborative Filtering to Popularity Distribution Shift
arxiv_id: '2310.10696'
source_url: https://arxiv.org/abs/2310.10696
tags:
- popularity
- popgo
- shortcut
- test
- item
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of popularity bias in collaborative
  filtering models, where the models learn spurious correlations between popularity
  and user preference from training data, leading to poor generalization to out-of-distribution
  (OOD) test data with different popularity distributions. The authors propose a debiasing
  strategy called PopGo, which quantifies and reduces interaction-wise popularity
  shortcuts without assuming any prior knowledge of the test data.
---

# Robust Collaborative Filtering to Popularity Distribution Shift

## Quick Facts
- arXiv ID: 2310.10696
- Source URL: https://arxiv.org/abs/2310.10696
- Authors: 
- Reference count: 40
- Key outcome: PopGo achieves NDCG@20 improvements of 1.59% - 42.86% in OOD settings and 15.87% - 48.43% in ID settings over best debiasing baselines

## Executive Summary
This paper addresses the problem of popularity bias in collaborative filtering models, where models learn spurious correlations between popularity and user preference from training data, leading to poor generalization to out-of-distribution (OOD) test data with different popularity distributions. The authors propose PopGo, a debiasing strategy that quantifies and reduces interaction-wise popularity shortcuts without assuming prior knowledge of test data. PopGo creates a shortcut model with the same architecture as the target CF model to capture popularity-relevant information and predict user preference based on popularity features. The CF model is then trained by adjusting its predictions with the interaction-wise shortcut degrees, encouraging it to focus on popularity-agnostic information.

## Method Summary
PopGo addresses popularity bias through a two-stage approach. First, it trains a shortcut model (with the same architecture as the target CF model) to predict user-item interactions based solely on popularity features (user/item frequency). This shortcut model captures the spurious correlation between popularity and interactions. Second, the target CF model is trained using a modified loss function where its predictions are masked by the shortcut model's output, forcing the CF model to focus on popularity-agnostic features that better represent true user preference. This approach is theoretically grounded in causal inference (separating total direct effect from pure indirect effect) and information theory (maximizing conditional mutual information).

## Key Results
- PopGo achieves NDCG@20 improvements of 1.59% - 42.86% in OOD settings over best debiasing baselines
- On in-distribution (ID) tests, PopGo improves NDCG@20 by 15.87% - 48.43% compared to top debiasing methods
- PopGo consistently outperforms state-of-the-art baselines (IPS-CN, CausE, DICE, MACR, SAM-REG) across all four benchmark datasets (Yelp2018, Tencent, Amazon-Book, Alibaba-iFashion)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PopGo identifies interaction-wise popularity shortcuts by creating a shortcut model that captures popularity-relevant information independently of the target CF model.
- Mechanism: The shortcut model, with the same architecture as the target CF model, learns shortcut representations from popularity features (user/item frequency). It predicts interaction likelihood based solely on these popularity representations, producing a shortcut degree for each user-item pair. The target CF model is then trained by masking its predictions with these shortcut degrees, forcing it to focus on popularity-agnostic information.
- Core assumption: Popularity features (frequency counts) contain sufficient information to predict interactions when popularity bias is the primary driver.
- Evidence anchors:
  - [abstract]: "It first learns a shortcut model, which yields a shortcut degree of a user-item pair based on their popularity representations."
  - [section]: "Here we devise a function ð‘“ð‘(Â·), which has the same architecture as ð‘“ (Â·) but takes the superficial features ð‘ = (ð‘‘ð‘¢, ð‘‘ð‘–) as the input."
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism.

### Mechanism 2
- Claim: PopGo improves generalization by maximizing conditional mutual information ð¼(ð‘‹ ; ð‘Œ |ðµ) instead of mutual information ð¼(ð‘‹ ; ð‘Œ).
- Mechanism: The shortcut model maximizes ð¼(ðµ; ð‘Œ) by learning to predict interactions from popularity features alone. The target CF model then maximizes ð¼(ð‘‹ ; ð‘Œ |ðµ) by learning to predict interactions from user-item pairs while conditioning on popularity, effectively removing the popularity bias effect.
- Core assumption: Conditional mutual information provides a better measure of true user preference than unconditional mutual information when popularity bias exists.
- Evidence anchors:
  - [abstract]: "From the perspective of information theory, PopGo intends to maximize the conditional mutual information between the interaction and prediction, conditioning on the popularity."
  - [section]: "As ð¼(ð‘‹ , ðµ; ð‘Œ ) = ð¼(ð‘‹ ; ð‘Œ |ðµ) + ð¼(ðµ; ð‘Œ ) based on the information theory, the first term approaches the desired conditional mutual information ð¼(ð‘‹ ; ð‘Œ |ðµ)."
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism.

### Mechanism 3
- Claim: PopGo disentangles total direct effect (TDE) from pure indirect effect (PIE) in causal inference terms, focusing on TDE for better generalization.
- Mechanism: The shortcut model estimates PIE by predicting interactions based on popularity features alone. The target CF model then focuses on TDE by predicting interactions based on user-item pairs while subtracting the PIE effect. This approach isolates the true causal effect of user preference from popularity bias.
- Core assumption: The causal graph structure (user-item pair â†’ popularity â†’ interaction) accurately represents the relationships in collaborative filtering.
- Evidence anchors:
  - [abstract]: "By taking both causal- and information-theoretical looks at PopGo, we can justify why it encourages the CF model to capture the critical popularity-agnostic features while leaving the spurious popularity-relevant patterns out."
  - [section]: "We expect the target CF models to exclude PIE and emphasize TDE."
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism.

## Foundational Learning

- Concept: Causal inference and causal graphs
  - Why needed here: Understanding the causal relationships between user-item pairs, popularity features, and interactions is crucial for designing effective debiasing strategies like PopGo.
  - Quick check question: What is the difference between total effect and total direct effect in causal inference?

- Concept: Information theory and mutual information
  - Why needed here: The information-theoretic perspective explains why conditioning on popularity features helps isolate true user preference signals from popularity bias.
  - Quick check question: How does conditional mutual information differ from regular mutual information, and why is this difference important for debiasing?

- Concept: Representation learning and debiasing techniques
  - Why needed here: Understanding how different representation learning approaches (e.g., identity embeddings vs. graph-based embeddings) can amplify or mitigate popularity bias is essential for evaluating PopGo's effectiveness.
  - Quick check question: How does the choice of representation learning method (e.g., MF vs. LightGCN) affect the susceptibility to popularity bias?

## Architecture Onboarding

- Component map: Target CF model (MF/LightGCN) -> Shortcut model (same architecture) -> Popularity feature extractor (user/item frequency) -> Loss functions (softmax loss) -> Temperature parameter Ï„

- Critical path: 1. Extract popularity features from training data 2. Train shortcut model to predict interactions from popularity features 3. Train target CF model using masked predictions based on shortcut model output 4. Deploy target CF model for inference (without shortcut model)

- Design tradeoffs:
  - Tradeoff between model complexity (additional shortcut model) and debiasing effectiveness
  - Choice of temperature parameter Ï„ affecting the balance between popularity and preference signals
  - Computational cost of training two models vs. single model with debiasing regularization

- Failure signatures:
  - Poor performance on both ID and OOD tests (shortcut model not capturing relevant patterns)
  - Significant performance gap between ID and OOD tests (incomplete debiasing)
  - Overfitting to popularity features (shortcut model too dominant)

- First 3 experiments:
  1. Verify that shortcut model performance correlates with popularity bias in the dataset
  2. Test PopGo with different temperature parameters Ï„ to find optimal balance
  3. Compare PopGo's performance against baselines on both ID and OOD test sets to validate generalization improvements

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PopGo's performance change when using different target CF models beyond MF, LightGCN, and UltraGCN?
- Basis in paper: [explicit] The paper mentions that PopGo was tested on MF, LightGCN, and UltraGCN, but suggests potential for broader applicability.
- Why unresolved: The paper only tested three specific CF models, leaving open how PopGo would perform with other popular models like NGCF or PinSage.
- What evidence would resolve it: Extensive testing of PopGo on a wider range of CF models, including both traditional and state-of-the-art models, with comparative performance metrics.

### Open Question 2
- Question: What is the optimal way to handle temporal popularity distribution shifts in PopGo, beyond the current dataset-specific tuning?
- Basis in paper: [explicit] The paper mentions temporal distribution shifts as a challenge and tests on a temporally split dataset, but doesn't provide a general solution.
- Why unresolved: While PopGo shows good performance on temporal splits, the paper doesn't propose a systematic approach for handling continuous temporal shifts.
- What evidence would resolve it: Development and testing of a dynamic PopGo variant that can adapt to changing popularity distributions over time, with long-term performance evaluation.

### Open Question 3
- Question: How does PopGo's shortcut model perform when dealing with extremely sparse datasets where popularity statistics are less reliable?
- Basis in paper: [inferred] The paper shows PopGo works well on datasets with varying sparsity levels, but doesn't specifically address the challenges of extremely sparse data.
- Why unresolved: The paper doesn't explore the lower limits of dataset sparsity where popularity statistics might become unreliable for the shortcut model.
- What evidence would resolve it: Extensive testing of PopGo on ultra-sparse datasets, along with analysis of shortcut model performance degradation and potential mitigation strategies.

## Limitations

- The approach requires training two separate models (shortcut and target CF), potentially doubling computational costs and complexity
- Effectiveness heavily depends on the quality of popularity feature extraction and the assumption that popularity bias is the primary source of generalization error
- The paper doesn't extensively explore scenarios where multiple biases coexist or where popularity features don't strongly correlate with user preferences

## Confidence

- **High confidence**: The theoretical framework connecting causal inference, information theory, and debiasing is well-established and internally consistent. The experimental methodology and dataset preparation are clearly specified.
- **Medium confidence**: The specific implementation details of the shortcut model and the temperature parameter tuning process are described but not exhaustively validated across different parameter ranges.
- **Low confidence**: The paper doesn't provide extensive ablation studies on alternative popularity feature extraction methods or comparisons with non-neural debiasing approaches that might offer computational advantages.

## Next Checks

1. **Ablation study on popularity feature representation**: Compare the effectiveness of different popularity feature encodings (one-hot frequency counts vs. learned embeddings) on the debiasing performance.
2. **Computational efficiency analysis**: Measure the training time and inference latency of PopGo compared to single-model debiasing approaches to quantify the overhead cost.
3. **Cross-dataset robustness evaluation**: Test PopGo's performance on datasets with different popularity distributions and bias patterns to assess generalizability beyond the four benchmark datasets used.