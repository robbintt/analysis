---
ver: rpa2
title: Clinical Trial Recommendations Using Semantics-Based Inductive Inference and
  Knowledge Graph Embeddings
arxiv_id: '2309.15979'
source_url: https://arxiv.org/abs/2309.15979
tags:
- knowledge
- embeddings
- clinical
- graph
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces NVKG, a first-of-a-kind knowledge graph for
  clinical trials, designed to improve trial design through recommendations. Using
  data from clinicaltrials.gov, it evaluates multiple knowledge graph embedding (KGE)
  methods, including node2vec, TransE, and HRGAT, and develops a novel inductive inference
  technique that leverages node semantics for unseen nodes.
---

# Clinical Trial Recommendations Using Semantics-Based Inductive Inference and Knowledge Graph Embeddings

## Quick Facts
- arXiv ID: 2309.15979
- Source URL: https://arxiv.org/abs/2309.15979
- Reference count: 0
- One-line primary result: Semantics-based inductive inference using knowledge graph embeddings achieves 70%-83% relevance scores for clinical trial design recommendations.

## Executive Summary
This paper introduces NVKG, a knowledge graph specifically designed for clinical trial data, to improve clinical trial design through automated recommendations. The approach combines multiple knowledge graph embedding methods with a novel inductive inference technique that leverages node semantics to generate recommendations for unseen clinical trials. The system evaluates both transductive (link prediction for known nodes) and inductive (recommendations for new trials) inference, demonstrating that semantics-aware embeddings can effectively capture clinical trial design patterns. Results show promising relevance scores of 70%-83% for recommended design elements like primary endpoints and inclusion criteria.

## Method Summary
The method constructs NVKG by extracting clinical trials data from clinicaltrials.gov and integrating it with drug information from DrugBank. The knowledge graph encodes clinical trials as nodes connected through common design elements, with text normalization applied to create unified representations of similar textual entities. Multiple KGE methods including node2vec, TransE, and HRGAT are trained on this graph. For inductive inference, the approach estimates embeddings for unseen trials by computing text embeddings, finding k-nearest neighbors in text space, and averaging their KG embeddings weighted by text similarity. Recommendations are then generated by finding similar nodes in the KG embedding space and evaluating their relevance through text similarity to actual trial elements.

## Key Results
- Achieved relevance scores of 70%-83% for clinical trial design recommendations
- Most relevant recommendations appear near the top of the ranked list
- HRGAT and other GNN-based methods show strong performance in capturing graph structure
- The inductive inference method successfully generates recommendations for unseen clinical trials without retraining

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The knowledge graph embedding (KGE) captures clinical trial design semantics by encoding both structural relationships and textual node attributes.
- Mechanism: The graph uses text normalization and similarity clustering to create a unified representation of textual entities (e.g., inclusion criteria), allowing semantically similar but syntactically different criteria to be treated as the same node. This normalization reduces redundancy and improves embedding quality.
- Core assumption: Textual similarity in clinical trial design elements correlates with functional similarity in trial design.
- Evidence anchors:
  - [abstract] "Our study also suggests potential improvement in training KGE using node semantics."
  - [section] "we used text normalization based on similarity and the normalized text was stored as the attribute of the entity's node"
  - [corpus] Weak - no direct corpus evidence for text normalization effectiveness in clinical trials
- Break condition: If textual similarity does not reflect functional trial design similarity, or if normalization removes critical distinguishing features.

### Mechanism 2
- Claim: Inductive inference using estimated embeddings enables recommendations for unseen clinical trials without retraining the entire KG.
- Mechanism: For a new trial title, text embeddings are computed, k-nearest neighbors are found in the text embedding space, and their KG embeddings are averaged (weighted by text similarity) to estimate the new trial's KG embedding. This estimated embedding is then used to find recommendations.
- Core assumption: The text embedding space preserves semantic similarity that is relevant to KG embedding space.
- Evidence anchors:
  - [abstract] "a novel inductive inference technique that leverages node semantics for unseen nodes"
  - [section] "Our approach is based on node attribute values, which happened to be text segments in NVKG"
  - [corpus] Weak - no direct corpus evidence for the effectiveness of this specific inductive inference approach
- Break condition: If the text embedding space does not preserve semantic similarity relevant to KG embeddings, or if the averaging approach produces poor estimates.

### Mechanism 3
- Claim: KGE methods (especially GNNs like HRGAT) learn discriminative representations that enable effective link prediction and recommendations.
- Mechanism: Graph neural networks use message passing to aggregate neighbor information, learning representations that capture both local and global graph structure. This enables the model to predict missing links and generate recommendations.
- Core assumption: Graph structure contains sufficient information to learn meaningful representations for clinical trial design.
- Evidence anchors:
  - [abstract] "evaluates multiple knowledge graph embedding (KGE) methods, including node2vec, TransE, and HRGAT"
  - [section] "Graph neural networks (GNNs) are now the de facto technique for training graph embeddings"
  - [corpus] Moderate - corpus contains related work on KGE methods but not specifically for clinical trials
- Break condition: If the graph structure is too sparse or noisy to learn discriminative representations, or if the chosen KGE method is not suitable for the graph's characteristics.

## Foundational Learning

- Knowledge Graph Construction:
  - Why needed here: Understanding how to represent clinical trials data as a graph is fundamental to the entire approach. The schema design choices (node types, edge types, attribute handling) directly impact embedding quality and downstream performance.
  - Quick check question: What are the key design decisions made in constructing NVKG, and how do they differ from other biomedical knowledge graphs like PharmKG?

- Knowledge Graph Embedding Methods:
  - Why needed here: Different KGE methods (translational, semantic, neural network-based) have different strengths and weaknesses. Understanding these is crucial for selecting and evaluating appropriate methods for NVKG.
  - Quick check question: What are the key differences between TransE, TransR, ComplEx, ConvKB, and HRGAT, and why might some be more suitable for NVKG than others?

- Inductive vs. Transductive Inference:
  - Why needed here: The paper distinguishes between transductive inference (predicting missing links between known nodes) and inductive inference (generating embeddings for new nodes). Understanding this distinction is key to understanding the novel inductive inference method proposed.
  - Quick check question: What is the difference between transductive and inductive inference in the context of knowledge graphs, and why is inductive inference particularly relevant for clinical trial design recommendations?

## Architecture Onboarding

- Component map:
  Data Ingestion -> KG Construction -> KGE Training -> Transductive Inference -> Inductive Inference -> Recommendation Generation

- Critical path:
  1. Data extraction and KG construction
  2. KGE training on the constructed KG
  3. Transductive inference evaluation to assess KGE quality
  4. Inductive inference method development and implementation
  5. Recommendation generation and evaluation

- Design tradeoffs:
  - Schema complexity vs. embedding quality: More complex schemas may capture more information but could lead to sparser graphs and harder embedding learning.
  - Text normalization vs. information loss: Normalizing text reduces redundancy but may remove distinguishing features.
  - KGE method selection: Different methods have different strengths; the choice impacts both transductive and inductive inference performance.

- Failure signatures:
  - Poor transductive inference performance: Suggests issues with KGE training or graph structure.
  - Low relevance of recommendations: Could indicate problems with the inductive inference method or KG embeddings.
  - High variance in performance across KGE methods: Might suggest the graph structure is not well-suited to some methods.

- First 3 experiments:
  1. Reproduce transductive inference results on a small subset of NVKG to validate the KGE training pipeline.
  2. Implement the inductive inference method on a small set of new trial titles and evaluate the estimated embeddings.
  3. Generate recommendations for a small set of new trials and calculate text similarity to ground truth to assess relevance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can node semantics be effectively incorporated into knowledge graph embedding training to improve transductive inference performance?
- Basis in paper: [explicit] The paper notes that the current KGE methods start with random values for node embeddings and do not consider node attributes during training. The authors suggest that incorporating node attributes could help improve node embedding representativeness.
- Why unresolved: The paper only suggests exploring this direction but does not provide concrete methods or results.
- What evidence would resolve it: Experimental results comparing KGE performance with and without incorporating node semantics in training.

### Open Question 2
- Question: Can the proposed inductive inference method be extended to recommend design elements based on drug targets and/or drug mechanism of action?
- Basis in paper: [explicit] The paper mentions that NVKG is the first to integrate clinical trials data with drug characteristics and suggests exploring how the model can be used to recommend design elements and relevant trials based on drug targets and/or drug mechanism of action.
- Why unresolved: The paper only proposes this as a future direction without providing concrete methods or results.
- What evidence would resolve it: Experimental results demonstrating the effectiveness of the extended inductive inference method for recommending design elements based on drug targets and/or drug mechanism of action.

### Open Question 3
- Question: How can the proposed inductive inference method be used to predict operational aspects of a proposed clinical trial design, such as the probability of completion?
- Basis in paper: [explicit] The paper mentions that the estimated KG embeddings of a new clinical trial can be used as inputs in a model to predict outcomes such as the probability of completion for the trial being designed.
- Why unresolved: The paper only mentions this as a future direction without providing concrete methods or results.
- What evidence would resolve it: Experimental results demonstrating the effectiveness of the proposed method in predicting operational aspects of a proposed clinical trial design.

## Limitations

- The inductive inference method's performance depends heavily on the quality of text embedding similarity, which is not thoroughly validated against baselines
- Evaluation relies solely on text similarity to ground truth, potentially missing practical utility for clinical trial designers
- The study lacks ablation studies on text normalization to quantify information loss

## Confidence

- **High**: KG construction methodology and data sources are well-specified and reproducible
- **Medium**: KGE methods are standard approaches with established implementations
- **Low**: The novel inductive inference method lacks validation against baselines and thorough sensitivity analysis

## Next Checks

1. **Ablation study on text normalization**: Compare recommendation quality with and without text normalization to quantify information loss
2. **Baseline comparison**: Implement and compare against simpler inductive inference methods (e.g., direct text similarity without KG embeddings)
3. **Human evaluation**: Conduct expert review of top-5 recommendations to assess practical relevance beyond text similarity scores