---
ver: rpa2
title: The Sample Complexity of Approximate Rejection Sampling with Applications to
  Smoothed Online Learning
arxiv_id: '2302.04658'
source_url: https://arxiv.org/abs/2302.04658
tags:
- theorem
- sampling
- then
- function
- some
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies the sample complexity of approximate rejection\
  \ sampling under f-divergence constraints. The authors show that \u02DC\u0398((f\u2032\
  )\u22121(Df(\u03BD||\xB5)/\u03B5)) samples are both necessary and sufficient to\
  \ generate an \u03B5-approximate sample from \u03BD using samples from \xB5, generalizing\
  \ classical rejection sampling bounds."
---

# The Sample Complexity of Approximate Rejection Sampling with Applications to Smoothed Online Learning

## Quick Facts
- arXiv ID: 2302.04658
- Source URL: https://arxiv.org/abs/2302.04658
- Reference count: 40
- Primary result: Shows that $\tilde\Theta((f')^{-1}(D_f(\nu||\mu)/\epsilon))$ samples are necessary and sufficient for approximate rejection sampling, with applications to smoothed online learning.

## Executive Summary
This paper establishes tight bounds on the sample complexity of approximate rejection sampling under f-divergence constraints. The authors prove that the optimal sample complexity scales as $\tilde\Theta((f')^{-1}(D_f(\nu||\mu)/\epsilon))$, generalizing classical rejection sampling bounds. They then apply these results to smoothed online learning, extending previous work to f-smoothed adversaries and deriving optimal regret bounds for both improper and proper oracle-efficient algorithms.

## Method Summary
The paper studies approximate rejection sampling where given n independent samples from base distribution μ, the goal is to select one sample that approximates a target distribution ν within ε total variation distance. The authors analyze this problem under f-divergence constraints $D_f(\nu||\mu) \leq D$ and show that sample complexity scales inversely with $(f')^{-1}(D/\epsilon)$. For online learning applications, they use a coupling technique to connect f-smoothed adversaries to the base measure, enabling oracle-efficient algorithms with provable regret bounds. The improper algorithm requires 2 ERM calls per round while the proper FTPL-based algorithm needs only 1 call.

## Key Results
- Proves tight sample complexity bounds $\tilde\Theta((f')^{-1}(D_f(\nu||\mu)/\epsilon))$ for approximate rejection sampling under f-divergence constraints
- Shows linear f functions lead to impossibility results while superlinear functions enable meaningful bounds
- Derives optimal regret bounds $\tilde{O}(\sigma^{-1/(2\lambda-1)})$ for Renyi-smoothed adversaries using improper algorithms
- Shows proper FTPL-based algorithms achieve $\tilde{O}(\sigma^{-1/(4\lambda-1)})$ regret for Renyi-smoothed adversaries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The sample complexity for approximate rejection sampling under f-divergence constraints scales as $\tilde\Theta((f')^{-1}(D_f(\nu\|\mu)/\epsilon))$.
- Mechanism: When the f-divergence $D_f(\nu\|\mu)$ is bounded, the optimal selection rule is essentially the classical rejection sampling method with an appropriately chosen threshold M. The threshold M is determined by the growth rate of $f'$ at infinity, and the required number of samples scales inversely with $(f')^{-1}(D_f(\nu\|\mu)/\epsilon)$.
- Core assumption: The function f satisfies the conditions in Definition 1 (convex, f(1)=f'(1)=0, and f' grows to infinity for superlinear cases).
- Evidence anchors:
  - [abstract]: "we show that the optimal total variation distance as a function of n is given by $\tilde\Theta(\frac{D}{f'(n)})$"
  - [section 3]: "as n ↑ ∞, we can always use rejection sampling to get an increasingly good approximation of a sample from ν because $(f')^{-1}$ is finite on the entire positive real line"
- Break condition: If f' is bounded above (linear case), then the approximate sampling problem becomes impossible as shown in Proposition 4.

### Mechanism 2
- Claim: The sample complexity lower bound is achieved by considering Bernoulli distributions with carefully chosen parameters.
- Mechanism: By constructing pairs of Bernoulli distributions where the Radon-Nikodym derivative is uniformly bounded by n, we can show that the E_γ divergence (which lower bounds total variation) remains large unless n satisfies the required lower bound. This construction works because the joint range of E_γ and f-divergence is characterized by Bernoulli distributions.
- Core assumption: The f-divergence and E_γ divergence are related through the Radon-Nikodym derivative bounds.
- Evidence anchors:
  - [section 3]: "By combining Lemmas 28 and 31, it suffices to exhibit two measures μ, ν such that E_n(ν||μ) > ε and D_f(ν||μ) is bounded"
  - [section 3]: "we let μ = Ber(q) and ν = Ber(p), for q = ε/n, p = 2ε"
- Break condition: If the mild growth condition on f is not satisfied, the lower bound construction may fail.

### Mechanism 3
- Claim: The coupling technique from smoothed online learning can be generalized to f-smoothed adversaries using rejection sampling bounds.
- Mechanism: Instead of requiring uniform bounds on the Radon-Nikodym derivative, we use the f-divergence constraint to construct a coupling between the adversary's distribution and the base measure. The coupling ensures that with high probability, we can find selection rules that produce samples close in total variation distance, with the sample complexity determined by the rejection sampling bounds.
- Core assumption: The function f satisfies sup f'(t) = ∞ so that the rejection sampling bounds are non-vacuous.
- Evidence anchors:
  - [section 4]: "we employ the following definition: Fix a base measure μ on some set X. We say that a measure ν is (f, σ)-smooth (or f-smooth) with respect to μ if D_f(ν||μ) ≤ 1/σ"
  - [section 4]: "we apply our bounds on the sample complexity of approximate rejection sampling to generalize the approach of these works and achieve upper bounds on the information theoretic rates of f-smoothed online learning"
- Break condition: If sup f'(t) < ∞, the coupling cannot guarantee the required total variation bounds.

## Foundational Learning

- Concept: f-divergence
  - Why needed here: The paper uses f-divergence as the primary measure of similarity between distributions, generalizing total variation, KL divergence, and Renyi divergences. This allows for a unified treatment of different smoothness constraints.
  - Quick check question: What is the f-divergence for f(x) = x log x - x + 1?

- Concept: Radon-Nikodym derivative
  - Why needed here: The Radon-Nikodym derivative dν/dμ is crucial for both rejection sampling and the analysis of f-divergence. Understanding when it exists and how it relates to different divergences is essential.
  - Quick check question: When does the Radon-Nikodym derivative dν/dμ exist?

- Concept: VC dimension and scale-sensitive VC dimension
  - Why needed here: These combinatorial measures of complexity are used to bound the regret in smoothed online learning. The scale-sensitive version vc(F, α) is particularly important for the analysis.
  - Quick check question: What is the relationship between vc(F) and vc(F, α) for a given function class F?

## Architecture Onboarding

- Component map:
  - Rejection sampling core -> Selection rule generator -> Approximate sample from ν
  - Coupling construction -> Adversary-base measure relationship -> Oracle-efficient algorithms
  - Oracle-efficient algorithms -> ERM oracle wrapper -> Low-regret online learner

- Critical path:
  1. Input: n samples from base distribution μ
  2. Process: Apply rejection sampling with threshold determined by f-divergence bound
  3. Output: Selection rule j* that produces X_{j*} with TV distance ≤ ε from ν
  4. For online learning: Use coupling to relate adversary contexts to base measure samples
  5. For oracle-efficient algorithms: Call ERM oracle with modified loss functions

- Design tradeoffs:
  - Linear vs superlinear f: Linear f leads to impossibility results, while superlinear f enables meaningful bounds
  - Proper vs improper algorithms: Improper algorithms achieve better regret rates but require more oracle calls
  - ε parameter: Smaller ε requires more samples but provides better approximation quality

- Failure signatures:
  - Rejection sampling fails when f' is bounded above
  - Coupling construction fails when sup f'(t) < ∞
  - Oracle-efficient algorithms fail when f-divergence constraint is too weak

- First 3 experiments:
  1. Verify the rejection sampling bound for simple cases (e.g., KL divergence with Bernoulli distributions)
  2. Test the coupling construction for a simple f-smoothed adversary (e.g., Gaussian noise added to adversarial input)
  3. Implement the improper algorithm and verify regret bounds on a simple function class (e.g., thresholds)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the sample complexity bound for approximate rejection sampling be improved for certain classes of functions f beyond the general bound of Θ((f')^{-1}(D_f(\nu||\mu)/\epsilon))?
- Basis in paper: [explicit] The authors show this bound is tight for all superlinear f-divergences but leave open whether tighter bounds exist for specific function classes.
- Why unresolved: The lower bound proof relies on general properties of f-divergences and doesn't exploit structure specific to particular f functions.
- What evidence would resolve it: Constructing specific pairs (μ, ν) with bounded f-divergence where the sample complexity is provably better or worse than the general bound for certain function classes f.

### Open Question 2
- Question: Can oracle-efficient proper algorithms achieve better regret bounds against KL-smoothed adversaries compared to the current σ^{-1/2} scaling?
- Basis in paper: [explicit] The authors show that their FTPL-based proper algorithm achieves σ^{-1/4} regret against Renyi-smoothed adversaries but only σ^{-1/2} against KL-smoothed adversaries, leaving open whether better bounds are possible.
- Why unresolved: The proof for KL-smoothed adversaries requires bounding exponential moments which seems to necessitate the weaker regret bound, but the authors don't rule out alternative approaches.
- What evidence would resolve it: Designing a proper oracle-efficient algorithm or proving a matching lower bound showing σ^{-1/2} is optimal for proper algorithms against KL-smoothed adversaries.

### Open Question 3
- Question: Can the gap between oracle-efficient and information-theoretic regret bounds against smoothed adversaries be closed?
- Basis in paper: [explicit] The authors note that while information-theoretic bounds give polylogarithmic dependence on smoothness parameter σ, oracle-efficient algorithms only achieve polynomial dependence, creating an exponential gap.
- Why unresolved: The coupling technique used for information-theoretic bounds doesn't seem to extend to computationally efficient algorithms, and proving lower bounds against oracle-efficient algorithms is challenging.
- What evidence would resolve it: Either designing an oracle-efficient algorithm matching the polylogarithmic rate or proving a computational lower bound showing exponential separation is necessary.

## Limitations
- Sample complexity bounds critically depend on growth properties of f', with linear f functions leading to impossibility results
- Analysis assumes independent samples from μ, which may not hold in practical settings with dependent data
- Online learning applications assume specific structure of f-smoothed adversaries that may not capture all natural adversarial scenarios

## Confidence

**High Confidence**: The upper bound on sample complexity for superlinear f functions is well-established through classical rejection sampling arguments. The oracle-efficient algorithm constructions for smoothed online learning follow established patterns in the literature.

**Medium Confidence**: The lower bound construction using Bernoulli distributions, while theoretically sound, may not be tight for all f-divergence measures. The coupling argument for f-smoothed adversaries, though intuitive, requires careful verification for specific f choices.

**Low Confidence**: The extension to improper algorithms achieving optimal rates requires empirical validation, as the theoretical analysis relies on strong stability assumptions that may not hold uniformly across all function classes.

## Next Checks
1. Implement the rejection sampling algorithm for KL-divergence (f(x) = x log x - x + 1) with Gaussian base distributions and verify empirical sample complexity matches theoretical predictions.
2. Test the coupling construction on a simple online learning problem (e.g., 1-dimensional threshold classification) with Gaussian-smoothed adversaries to empirically verify the regret bounds.
3. Conduct a computational study comparing the improper and proper oracle-efficient algorithms on benchmark online learning tasks to validate the claimed trade-offs between oracle complexity and regret rates.