---
ver: rpa2
title: On the Overconfidence Problem in Semantic 3D Mapping
arxiv_id: '2311.10018'
source_url: https://arxiv.org/abs/2311.10018
tags:
- calibration
- semantic
- fusion
- segmentation
- mapping
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the problem of overconfidence in semantic\
  \ 3D mapping, where conventional methods produce highly confident 3D maps even when\
  \ incorrect, leading to miscalibrated outputs. The authors propose several approaches\
  \ to improve uncertainty calibration, including alternative fusion strategies like\
  \ Na\xA8\u0131ve Averaging and Geometric Mean, sample weighting based on distance\
  \ and angle, and calibrating the 2D segmentation model via temperature/vector scaling."
---

# On the Overconfidence Problem in Semantic 3D Mapping

## Quick Facts
- arXiv ID: 2311.10018
- Source URL: https://arxiv.org/abs/2311.10018
- Reference count: 40
- Key outcome: This paper addresses the problem of overconfidence in semantic 3D mapping, where conventional methods produce highly confident 3D maps even when incorrect, leading to miscalibrated outputs.

## Executive Summary
This paper identifies and addresses the overconfidence problem in semantic 3D mapping, where conventional fusion strategies like Recursive Bayesian Update (RBU) produce highly confident 3D maps even when the underlying 2D segmentation is incorrect. The authors demonstrate that 2D calibration techniques have limited impact on 3D map calibration, and instead propose several approaches including alternative fusion strategies (Naïve Averaging, Geometric Mean), sample weighting based on distance and angle, and calibrating the 2D segmentation model via temperature/vector scaling. They introduce a generalized learned fusion strategy (GLFS) that learns optimal combinations of fusion methods, sample weighting, and logit scaling in a unified framework while remaining real-time capable. Experiments on ScanNet show these strategies improve map calibration without degrading accuracy, and downstream ObjectNav experiments demonstrate the practical importance of proper uncertainty propagation.

## Method Summary
The paper systematically evaluates semantic 3D mapping by comparing multiple fusion strategies on ScanNet, starting with RBU and alternative methods like Naïve Averaging and Geometric Mean. They calibrate 2D segmentation models using temperature/vector scaling, then extend this to 3D calibration by applying scaling directly to fused voxel outputs. The key innovation is GLFS, which uses differentiable gating variables to switch between fusion strategies while simultaneously learning sample weights based on distance/angle and logit scaling parameters, optimizing directly for calibration metrics. The framework is implemented in PyTorch and optimized using mDECE + NLL loss, maintaining real-time capability while improving both accuracy and calibration.

## Key Results
- RBU fusion is among the worst calibrated methods, highly sensitive to outlier observations due to independence assumptions
- Traditional 2D calibration improves pixel-level calibration but barely affects 3D voxel calibration (mECE)
- GLFS achieves simultaneously higher accuracy and better calibration while retaining real-time capability
- Proper semantic fusion in downstream ObjectNav agents improves success rates by incorporating uncertainty

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RBU fusion produces overconfident 3D maps even with well-calibrated 2D models
- Mechanism: RBU assumes independence between semantic observations across viewpoints and is highly sensitive to outlier observations, amplifying confident errors through multiplicative integration
- Core assumption: Semantic observations from different viewpoints are conditionally independent given the true class label
- Evidence anchors:
  - [abstract] "the most widely used fusion strategy, Recursive Bayesian Update (RBU) [30], to be especially susceptible to overconfidence"
  - [section] "A single overconfident input can drastically change the RBU posterior" and "RBU assumes semantic likelihood observations are independent"
  - [corpus] No direct corpus evidence on RBU overconfidence, but related work on "Robust Fusion for Bayesian Semantic Mapping" suggests this is a recognized problem
- Break condition: When independence assumption is violated or sufficient view diversity exists to average out outliers

### Mechanism 2
- Claim: 2D calibration doesn't effectively improve 3D map calibration
- Mechanism: 3D overconfidence arises from fusion strategy limitations rather than poor 2D calibration, so 2D calibration has minimal impact on final map calibration
- Core assumption: Primary source of 3D overconfidence is the fusion strategy rather than underlying 2D segmentation model
- Evidence anchors:
  - [section] "Traditional 2D calibration improves pixel mECE but voxel mECE is barely changed" and "segmentation models that are calibrated to yield better calibrated maps can be quite uncalibrated at the pixel level!"
  - [abstract] "we show that the most widely used Bayesian fusion strategy is among the worst calibrated"
  - [corpus] No direct corpus evidence on 2D calibration ineffectiveness for 3D maps
- Break condition: When fusion strategy itself is modified to be less sensitive to outliers and independence violations

### Mechanism 3
- Claim: GLFS improves both accuracy and calibration by learning optimal combinations
- Mechanism: GLFS uses differentiable gating variables to switch between fusion strategies while simultaneously learning sample weights and logit scaling, optimizing directly for calibration metrics
- Core assumption: Calibration can be improved through end-to-end learning without sacrificing accuracy
- Evidence anchors:
  - [abstract] "propose a learned pipeline that combines fusion and calibration, GLFS, which achieves simultaneously higher accuracy and 3D map calibration while retaining real-time capability"
  - [section] "This unified procedure generalizes to all the listed fusion strategies and incorporates logit adjustments via vector scaling and pose-dependence adjustments through learned sample weighting"
  - [corpus] No direct corpus evidence on GLFS, but related work suggests learned fusion approaches are emerging
- Break condition: When learned parameters overfit to calibration dataset or real-time constraints prevent sufficient model complexity

## Foundational Learning

- Concept: Expected Calibration Error (ECE) and its limitations for multi-class problems
  - Why needed here: To measure and optimize the calibration of 3D semantic maps, understanding proper calibration metrics is essential
  - Quick check question: Why is Top-Label ECE still problematic for semantic mapping even though it addresses class frequency issues in standard ECE?

- Concept: Bayesian fusion and its independence assumptions
  - Why needed here: Understanding how RBU works and its assumptions is critical to diagnosing why it produces overconfident maps
  - Quick check question: What happens to the RBU posterior when two observations are highly correlated but disagree on the predicted class?

- Concept: Temperature scaling and logit calibration
  - Why needed here: These are the fundamental techniques used to calibrate both 2D segmentation models and the 3D fusion process itself
  - Quick check question: How does temperature scaling affect the entropy of predicted probability distributions?

## Architecture Onboarding

- Component map: 2D semantic segmentation → TSDF-based metric reconstruction → 3D semantic fusion → calibration optimization → downstream navigation agent
- Critical path: RGB-D observation → 2D segmentation → voxel projection → fusion update → map output
- Design tradeoffs: Real-time capability vs. fusion accuracy (RBU is fastest but least calibrated; learned methods are slower but more accurate)
- Failure signatures: Overconfident predictions in error regions, poor minority class calibration, failure to propagate uncertainty from 2D to 3D
- First 3 experiments:
  1. Compare RBU vs. Naïve Averaging on a simple ScanNet scene with known viewpoint biases
  2. Apply 2D temperature scaling to Segformer and measure impact on voxel mECE
  3. Implement GLFS with fixed sample weights and optimize only fusion strategy parameters

## Open Questions the Paper Calls Out

- **Open Question 1**: What specific calibration strategies beyond temperature/vector scaling and Dirichlet calibration could be applied to improve 3D semantic map calibration?
  - Basis in paper: [explicit] The paper mentions potential future work to "quantify the effects of other calibration strategies like position-dependent calibration [27] and Dirichlet calibration [24] on 3D semantic map calibration."
  - Why unresolved: While the paper introduces and evaluates temperature/vector scaling, it only briefly mentions other potential strategies without implementation or testing.
  - What evidence would resolve it: Implementing and evaluating alternative calibration strategies (e.g., position-dependent, Dirichlet calibration) on the same dataset and metrics would provide concrete comparisons and identify their effectiveness.

- **Open Question 2**: How can ObjectNav agents better leverage 3D semantic uncertainty to guide exploration and improve performance?
  - Basis in paper: [explicit] The paper suggests future work to "investigate how ObjectNav agents can better leverage 3D semantic uncertainty to guide their exploration [2] and how that would affect their performance."
  - Why unresolved: The current ObjectNav experiments only use semantic fusion for goal detection and don't actively incorporate uncertainty into exploration strategies.
  - What evidence would resolve it: Developing and testing ObjectNav agents that use uncertainty maps for active exploration (e.g., prioritizing uncertain areas) and comparing their performance against baseline agents would demonstrate the benefits of uncertainty-aware exploration.

- **Open Question 3**: What are effective methods to quantify and improve uncertainty in open-set metric-semantic mapping scenarios?
  - Basis in paper: [explicit] The paper identifies future work to "study the quantification and improvement of uncertainty in open-set metric-semantic maps [12, 22]."
  - Why unresolved: The paper focuses on closed-set semantic mapping with predefined classes, but real-world scenarios often involve novel objects.
  - What evidence would resolve it: Developing metrics to evaluate uncertainty in open-set scenarios and proposing methods to handle novel classes while maintaining calibrated uncertainty estimates would address this challenge.

## Limitations
- The analysis is limited to ScanNet dataset characteristics and may not generalize to outdoor datasets with different viewpoint distributions
- GLFS's real-time capability claims depend on specific hardware configurations not fully detailed in the paper
- The learned approach introduces complexity that may not generalize across different datasets or hardware constraints

## Confidence
- **High Confidence**: The core finding that RBU fusion produces overconfident maps even with well-calibrated 2D models is well-supported by empirical evidence across multiple experiments and metrics (mECE, TL-ECE, Brier score)
- **Medium Confidence**: The effectiveness of 2D calibration approaches for improving 3D map calibration is demonstrated but shows limited impact, suggesting fusion strategy is the primary driver of overconfidence
- **Medium Confidence**: GLFS's simultaneous improvement of accuracy and calibration is promising, though the learned approach introduces complexity that may not generalize

## Next Checks
1. **Cross-dataset validation**: Evaluate the proposed fusion strategies and GLFS on outdoor datasets like SemanticKITTI to assess generalizability beyond indoor scenes
2. **Correlation analysis**: Systematically measure viewpoint correlation structures in real ScanNet data to quantify how often RBU's independence assumption is violated
3. **Runtime profiling**: Conduct detailed profiling of GLFS on different GPU configurations to verify real-time capability claims across hardware platforms