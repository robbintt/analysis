---
ver: rpa2
title: Trustworthiness of Children Stories Generated by Large Language Models
arxiv_id: '2308.00073'
source_url: https://arxiv.org/abs/2308.00073
tags:
- stories
- children
- generated
- text
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates the trustworthiness of children's stories
  generated by large language models (LLMs) using various metrics, comparing them
  with both old and modern children's stories. The study uses two open-source LLMs,
  OPT and LLaMA, and an instruction-following model, Alpaca, to generate children's
  stories.
---

# Trustworthiness of Children Stories Generated by Large Language Models

## Quick Facts
- arXiv ID: 2308.00073
- Source URL: https://arxiv.org/abs/2308.00073
- Authors: 
- Reference count: 5
- One-line primary result: Generated children's stories show modern readability trends but lack nuanced quality and can contain toxic content

## Executive Summary
This paper evaluates the trustworthiness of children's stories generated by large language models (LLMs) using various metrics and compares them against both old and modern children's stories. The study uses OPT, LLaMA, and Alpaca models to generate stories, then analyzes them using sentence length, Flesch reading ease score, toxicity, topic modeling, and sentence structure metrics. Results show that while generated stories share thematic similarities with actual stories and reflect modern readability trends, they fail to capture the nuanced sentence structures and literary quality of genuine children's literature, and can produce toxic content even from innocuous prompts.

## Method Summary
The study collected 122 old children's stories from Project Gutenberg and 10 modern stories from online sources, then generated stories using OPT, LLaMA, and Alpaca models with various prompts and instruction templates. Generated stories were compared against actual stories using multiple metrics including sentence length, Flesch reading ease score, toxicity detection via Detoxify, topic modeling with pyLDAvis, and sentence structure analysis using dependency trees and Weisfeiler-Lehman hashing. The analysis aimed to evaluate how well LLMs capture the characteristics of quality children's literature and whether they produce trustworthy content.

## Key Results
- Generated stories exhibit shorter sentence lengths and higher readability scores compared to older stories but align with modern stories
- LLMs can generate toxic content even from innocuous prompts, with toxicity levels correlating with context length
- Generated stories share thematic content with actual stories but lack the nuanced sentence structures characteristic of quality children's literature
- Alpaca instruction-following model produces slightly less toxic content than general LLMs but still struggles with structural fidelity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Generated stories reflect modern trends in children's literature (shorter sentences, higher readability)
- Mechanism: LLMs are trained on large corpora that predominantly include recent text, causing them to generalize patterns found in modern children's stories rather than older ones
- Core assumption: The training data distribution for LLMs heavily skews toward modern text sources, especially post-2000
- Evidence anchors:
  - [abstract] "The generated children's stories exhibit shorter sentence lengths compared to the older original stories but are similar in sentence length to modern stories."
  - [section] "As most of the training data for LLMs comes from newer text, the model tends to follow the trend of modern children's stories in their generated text for sentence length and word selection."
  - [corpus] Weak; corpus analysis shows only 25 related papers, average citations = 0.0, indicating limited direct support for this mechanism
- Break condition: If LLMs are fine-tuned on balanced datasets including more older children's literature, the trend toward modern patterns may diminish

### Mechanism 2
- Claim: LLMs can generate toxic content even from innocuous prompts
- Mechanism: The presence of toxic text in training data leads to generative models replicating these patterns, regardless of prompt innocence
- Core assumption: LLMs retain and reproduce undesirable patterns present in their training corpora
- Evidence anchors:
  - [abstract] "LLMs can even generate toxic text from a very innocuous prompt."
  - [section] "We see that LLMs tend to learn patterns from the context they are provided with... the toxicity aligns with older stories and gradually increases with an increase in the length of the context."
  - [corpus] Weak; no direct corpus evidence of toxic content frequency in training data
- Break condition: If training datasets are rigorously filtered for toxicity and models are fine-tuned with adversarial debiasing, the mechanism's effect may be mitigated

### Mechanism 3
- Claim: Generated stories share thematic content with actual stories but lack nuanced sentence structure
- Mechanism: LLMs can replicate high-level thematic clusters (e.g., princes, fairies, moral lessons) but fail to reproduce the complex syntactic dependencies characteristic of high-quality children's literature
- Core assumption: LLMs capture statistical co-occurrence of topics but not the deep grammatical patterns that give stories their unique narrative flow
- Evidence anchors:
  - [abstract] "While the generated children's stories do share similarities in topics and patterns with the actual stories... they fail to capture all the nuances present in children's literature."
  - [section] "We observe a higher percentage of overlap between old original stories and the stories generated by OPT and LLaMA... the stories generated by Alpaca have a slightly higher overlap with modern stories compared to old stories, but the percentage overlap in sentence structures is still relatively low (≤ 20%)."
  - [corpus] Weak; corpus lacks direct evidence of sentence structure similarity metrics
- Break condition: If models are trained with explicit syntactic constraints or fine-tuned on stylistically annotated children's stories, sentence structure fidelity may improve

## Foundational Learning

- Concept: Readability metrics (Flesch Reading Ease Score)
  - Why needed here: To quantify how accessible generated stories are to children compared to actual stories
  - Quick check question: What does a higher Flesch score indicate about text complexity?

- Concept: Dependency tree graphs and Weisfeiler-Lehman hashing
  - Why needed here: To compare sentence structure patterns between generated and actual stories in a language-agnostic way
  - Quick check question: Why is hashing used instead of direct graph comparison?

- Concept: Topic modeling with pyLDAvis
  - Why needed here: To assess whether generated stories cover the same thematic content as real children's stories
  - Quick check question: How does removing stopwords and names improve topic modeling quality?

## Architecture Onboarding

- Component map: Data collection -> Story generation -> Toxicity evaluation -> Topic modeling -> Structural comparison -> Analysis
- Critical path: Prompt generation → Story generation → Toxicity evaluation → Topic modeling → Structural comparison → Analysis
- Design tradeoffs:
  - Using generic LLMs vs. fine-tuned children's story models (quality vs. generalization)
  - Manual vs. automatic toxicity detection (control vs. scalability)
  - Small modern story sample size vs. larger older story dataset (bias vs. representativeness)
- Failure signatures:
  - High toxicity scores in generated stories indicate unsafe outputs
  - Low overlap in sentence structure hashes signals poor grammatical fidelity
  - Disparate topic distributions reveal thematic misalignment
- First 3 experiments:
  1. Generate stories with varying prompt lengths and measure Flesch scores to confirm trend toward modern readability
  2. Apply Detoxify to generated stories and compare toxicity distributions across models and templates
  3. Compute Weisfeiler-Lehman hash overlaps between generated and actual stories to quantify structural similarity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do children's stories generated by instruction-following models like Alpaca compare to those generated by general LLMs in terms of toxicity, and what specific elements in the instruction templates influence this difference?
- Basis in paper: [explicit] The paper discusses the comparison of toxicity levels between stories generated by Alpaca and other LLMs, noting that Alpaca tends to produce less toxic content
- Why unresolved: While the paper highlights the difference in toxicity, it does not delve into the specific elements of the instruction templates that contribute to this reduction in toxic content
- What evidence would resolve it: A detailed analysis of the instruction templates used by Alpaca, comparing the language and structure of each template, could reveal which elements are most effective in reducing toxicity in generated stories

### Open Question 2
- Question: What are the specific aspects of sentence structure that LLMs fail to capture when generating children's stories, and how do these deficiencies impact the overall quality and readability of the stories?
- Basis in paper: [explicit] The paper mentions that LLMs struggle to capture the nuances and intricacies of children's literature, evident from the disparity in sentence structure between generated and actual stories
- Why unresolved: The paper identifies a gap in sentence structure but does not specify which aspects of sentence structure are problematic or how these deficiencies affect story quality
- What evidence would resolve it: A comparative analysis of sentence structures, focusing on elements like complexity, variety, and coherence, could identify specific deficiencies and their impact on story quality

### Open Question 3
- Question: How do the topics in children's stories generated by LLMs align with current trends in children's literature, and what does this alignment indicate about the training data used for these models?
- Basis in paper: [explicit] The paper discusses the comparison of topics between generated stories and actual children's stories, noting similarities in themes but differences in modern trends
- Why unresolved: While the paper notes the alignment of topics, it does not explore how this alignment reflects the composition and recency of the training data
- What evidence would resolve it: An analysis of the training data composition, including the time period and themes of the texts used, could provide insights into how well the generated stories reflect current trends in children's literature

## Limitations

- Modern children's story dataset is extremely small (10 stories) compared to older stories dataset (122 stories), creating potential sampling bias
- Toxicity detection relies on Detoxify's perspective-based model, which may not be optimized for children's content and could produce false positives or negatives
- The study does not examine whether generated stories maintain age-appropriate complexity or whether they would actually engage child readers

## Confidence

- High Confidence: The finding that generated stories exhibit shorter sentence lengths and higher readability scores compared to older stories but align with modern stories
- Medium Confidence: The claim that LLMs can generate toxic content from innocuous prompts
- Low Confidence: The assertion that generated stories "lack the nuances and quality of actual children's literature" based primarily on sentence structure analysis

## Next Checks

1. **Toxicity Context Analysis**: Manually review and categorize the specific toxic content detected by Detoxify to distinguish between truly harmful content versus potentially false positives related to children's story conventions (e.g., references to "evil" characters or "danger")

2. **Cross-Generational Comparison**: Expand the modern stories dataset to match the size of the older stories dataset and stratify by publication decade to determine whether the observed trends toward shorter sentences and higher readability are consistent across different modern eras

3. **Structural Quality Assessment**: Conduct expert evaluation of generated story structures by comparing them against children's literature guidelines and standards, focusing on narrative coherence, character development, and age-appropriate complexity beyond syntactic analysis