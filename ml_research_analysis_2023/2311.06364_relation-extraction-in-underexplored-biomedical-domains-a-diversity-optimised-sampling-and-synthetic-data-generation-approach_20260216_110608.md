---
ver: rpa2
title: 'Relation Extraction in underexplored biomedical domains: A diversity-optimised
  sampling and synthetic data generation approach'
arxiv_id: '2311.06364'
source_url: https://arxiv.org/abs/2311.06364
tags:
- data
- synthetic
- arxiv
- generation
- extraction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel sampling method called GME-sampler
  to build a diverse and balanced evaluation dataset for relation extraction between
  organisms and natural products. The method is inspired by diversity metrics in ecology
  and aims to minimize selection of popular items in the original LOTUS dataset.
---

# Relation Extraction in underexplored biomedical domains: A diversity-optimised sampling and synthetic data generation approach

## Quick Facts
- **arXiv ID**: 2311.06364
- **Source URL**: https://arxiv.org/abs/2311.06364
- **Reference count**: 40
- **Primary result**: BioGPT-Large achieves 59.0 F1-score on curated evaluation dataset using synthetic data and diversity-optimized sampling

## Executive Summary
This paper addresses the challenge of relation extraction between organisms and natural products in biomedical literature, focusing on the "produces" or "is isolated from" relationships. The authors introduce a novel diversity-optimized sampling method called GME-sampler to create balanced evaluation datasets, inspired by ecological diversity metrics. They also propose synthetic data generation using large language models to overcome noisy label issues in the original LOTUS dataset. The approach demonstrates substantial improvements over baseline methods, with the best-performing BioGPT-Large model achieving an F1-score of 59.0 on the curated evaluation set.

## Method Summary
The method involves two key innovations: (1) GME-sampler, a diversity-optimized sampling technique based on Shannon entropy to create balanced training and evaluation datasets from the LOTUS database, and (2) synthetic data generation using Vicuna-13B to create credible abstracts that embed correct relation labels while avoiding text-label mismatches. The authors evaluate multiple models including Seq2Rel, BioGPT, and GPT-2 with QLoRA fine-tuning, comparing performance on original noisy data versus synthetic data. The evaluation uses a manually curated dataset of 100 abstracts focusing on organism-chemical relations.

## Key Results
- BioGPT-Large achieves an F1-score of 59.0 on the manually curated evaluation dataset
- All evaluated models show substantial improvements when fine-tuned on synthetic abstracts versus original noisy data
- The GME-sampler produces significantly more diverse datasets in terms of distinct organisms, chemicals, and relations compared to random sampling
- Synthetic data generation successfully addresses the noisy label problem while maintaining reasonable entity diversity

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Diversity-optimized sampling via GME-sampler increases recall by improving entity diversity in training data.
- **Mechanism**: The Greedy Maximum Entropy sampler selects documents that maximize Shannon entropy over organisms and chemicals, ensuring balance and coverage across biological kingdoms while minimizing popularity bias.
- **Core assumption**: Diversity in entities leads to better generalization in relation extraction because models learn to recognize entities in varied contexts.
- **Evidence anchors**: The impact of diversity-sampling is evaluated by comparing composition against random samples, showing significantly richer diversity in chemicals, organisms, and relations.
- **Break condition**: If diversity does not correlate with performance improvements, or if entropy-based selection misses important but rare entities.

### Mechanism 2
- **Claim**: Synthetic data generation using LLM-generated abstracts improves performance over noisy raw data.
- **Mechanism**: Vicuna-13B is prompted with seed abstracts to generate new abstracts that embed desired relations while avoiding label-text mismatches in training data.
- **Core assumption**: Generated abstracts are "credible" enough to serve as effective training signals, even if not factually identical to real abstracts.
- **Evidence anchors**: All evaluated models exhibited substantial improvements when fine-tuned on synthetic abstracts rather than original noisy data.
- **Break condition**: If generated abstracts contain too many hallucinations or if distribution shift between synthetic and real data harms generalization.

### Mechanism 3
- **Claim**: QLoRA fine-tuning achieves comparable or better performance than full fine-tuning while using fewer parameters.
- **Mechanism**: QLoRA applies LoRA adapters to quantized model weights, allowing efficient adaptation of large models for the RE task.
- **Core assumption**: Low-rank updates to quantized weights preserve enough model capacity for task-specific adaptation.
- **Evidence anchors**: QLoRA was adopted for efficient fine-tuning with minimal memory requirements for BioGPT and GPT-2 models.
- **Break condition**: If adapter rank or quantization introduces too much degradation, or if task complexity exceeds LoRA capacity.

## Foundational Learning

- **Concept**: Entropy-based diversity metrics (Shannon entropy)
  - **Why needed here**: Used to quantify and optimize the balance of organisms/chemicals in the sampled dataset
  - **Quick check question**: How does Shannon entropy differ from simple species richness in ecological sampling?

- **Concept**: LoRA (Low-Rank Adaptation) for efficient fine-tuning
  - **Why needed here**: Enables fine-tuning of large models with minimal memory footprint
  - **Quick check question**: What is the mathematical form of the LoRA update to a weight matrix?

- **Concept**: Synthetic data generation via instruction-tuned LLMs
  - **Why needed here**: Generates training examples with correct label-text alignment, avoiding noise from mismatched annotations
  - **Quick check question**: How does the "verbalized main findings" pattern influence the semantic content of generated abstracts?

## Architecture Onboarding

- **Component map**: LOTUS DB -> pre-processing -> GME-sampler -> Diversity/Extended datasets -> Vicuna-13B generation -> synthetic datasets -> QLoRA fine-tuning -> BioGPT/GPT-2/Seq2Rel -> manually curated evaluation set
- **Critical path**: GME-sampler -> synthetic data generation -> QLoRA fine-tuning -> evaluation
- **Design tradeoffs**: 
  - Diversity vs sample size: Higher diversity reduces dataset size but improves balance
  - Synthetic vs real data: Synthetic improves label-text alignment but may introduce hallucinations
  - QLoRA vs full fine-tuning: QLoRA saves memory but may limit adaptation capacity
- **Failure signatures**:
  - Low recall despite high precision: May indicate overfitting to frequent entities
  - Hallucinations dominate synthetic data: May indicate poor instruction design or model instability
  - Memory errors during QLoRA: May indicate insufficient GPU memory or incorrect quantization settings
- **First 3 experiments**:
  1. Run GME-sampler on LOTUS with kingdom stratification; verify entropy curves plateau appropriately
  2. Generate 100 synthetic abstracts using Vicuna-13B; manually inspect for hallucination rate
  3. Fine-tune BioGPT-Large with QLoRA on Diversity-synt; compare f1-score to baseline on validation set

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the diversity of synthetic abstracts compare to human-written abstracts in terms of linguistic style and expression of relationships?
- **Basis in paper**: [inferred] The authors acknowledge that synthetic abstracts exhibit a narrow range of styles compared to human-written abstracts and suggest that synthetic data may mostly improve entity recognition rather than relationship decoding
- **Why unresolved**: The paper does not provide a quantitative or qualitative analysis of linguistic diversity of synthetic versus human-written abstracts
- **What evidence would resolve it**: A comparative linguistic analysis measuring diversity in vocabulary, syntax, and patterns of expressing relationships would clarify the extent of the difference

### Open Question 2
- **Question**: How do alternative data augmentation strategies (e.g., paraphrasing, back-translation) compare to the proposed synthetic data generation approach in improving RE performance?
- **Basis in paper**: [inferred] The paper proposes a novel synthetic data generation approach but does not compare it to other data augmentation methods commonly used in NLP
- **Why unresolved**: The authors focus on evaluating their proposed method and do not benchmark it against alternative data augmentation techniques
- **What evidence would resolve it**: A controlled experiment comparing performance of RE models trained on synthetic data versus those trained on data augmented by alternative methods

### Open Question 3
- **Question**: How does the performance of the proposed GME-sampler compare to other diversity-aware sampling methods in different biomedical domains?
- **Basis in paper**: [explicit] The authors propose the GME-sampler as a novel diversity-optimised sampling method but only evaluate it on the natural products domain
- **Why unresolved**: The paper does not provide evidence of the GME-sampler's generalizability in other biomedical domains with different entity distributions
- **What evidence would resolve it**: Applying the GME-sampler to other biomedical datasets and comparing its performance to other diversity-aware sampling methods would demonstrate its generalizability

## Limitations
- The synthetic data generation process lacks systematic evaluation of hallucination rates and factual consistency
- The manually curated evaluation dataset is relatively small (100 abstracts) and may not fully represent domain complexity
- The comparison between QLoRA and full fine-tuning is incomplete, as only QLoRA was implemented
- The entropy-based diversity metric may not perfectly align with task performance requirements

## Confidence
- **High confidence**: The overall framework of using synthetic data to improve RE performance is well-supported by empirical results showing substantial F1-score improvements
- **Medium confidence**: The diversity-optimized sampling methodology and its impact on entity balance is reasonably well-established through comparative analysis with random samples
- **Low confidence**: The synthetic data generation process and hallucination mitigation strategies lack sufficient empirical validation

## Next Checks
1. **Hallucination Analysis**: Conduct blind human evaluation of 100 randomly sampled synthetic abstracts to quantify hallucination rates and assess relation alignment with biological plausibility
2. **Ablation Study**: Implement full fine-tuning (not just QLoRA) for BioGPT and GPT-2 models on the same synthetic datasets, then compare performance metrics
3. **Temporal Generalization**: Test model performance on abstracts published 1-2 years after training data cutoff date to assess generalization to emerging organism-chemotype relationships