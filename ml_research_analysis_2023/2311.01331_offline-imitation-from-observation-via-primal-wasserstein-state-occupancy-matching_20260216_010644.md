---
ver: rpa2
title: Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching
arxiv_id: '2311.01331'
source_url: https://arxiv.org/abs/2311.01331
tags:
- state
- distance
- learning
- expert
- wasserstein
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Primal Wasserstein DICE (PW-DICE), a novel
  offline Learning from Observation (LfO) method that minimizes the primal Wasserstein
  distance between expert and learner state occupancies. PW-DICE leverages a contrastively
  learned distance metric and a pessimistic regularizer for offline imitation learning.
---

# Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching

## Quick Facts
- arXiv ID: 2311.01331
- Source URL: https://arxiv.org/abs/2311.01331
- Reference count: 40
- Key outcome: PW-DICE achieves better results than several state-of-the-art methods on multiple testbeds, including Hopper, HalfCheetah, Ant, and Walker2d environments.

## Executive Summary
This paper introduces Primal Wasserstein DICE (PW-DICE), an offline Learning from Observation (LfO) method that minimizes the primal Wasserstein distance between expert and learner state occupancies. PW-DICE leverages a contrastively learned distance metric and pessimistic regularizers to address the limitations of prior Wasserstein-based methods that constrain the underlying distance metric to be Euclidean. The method is theoretically proven to generalize SMODICE and unifies f-divergence and Wasserstein minimization. Empirically, PW-DICE demonstrates superior performance compared to state-of-the-art methods across multiple Mujoco environments.

## Method Summary
PW-DICE is an offline imitation learning method that minimizes the primal Wasserstein distance between expert and learner state occupancies. It uses a contrastively learned distance metric to avoid the Euclidean constraint imposed by Rubinstein duality and employs pessimistic regularizers to ensure offline stability. The method involves training a contrastive embedding network on task-agnostic data, optimizing dual variables, deriving policy weights, and training a policy via weighted behavior cloning. PW-DICE generalizes SMODICE and unifies f-divergence and Wasserstein minimization.

## Key Results
- PW-DICE outperforms state-of-the-art methods (SMODICE, LobsDICE, OTR, ORIL, DWBC, BC) on Hopper, HalfCheetah, Ant, and Walker2d environments.
- The use of a contrastively learned distance metric improves Wasserstein matching quality compared to Euclidean distance.
- PW-DICE with pessimistic regularizers achieves better performance and stability in offline imitation learning.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PW-DICE unifies f-divergence and Wasserstein minimization by adding pessimistic regularizers to the primal Wasserstein objective.
- Mechanism: The regularizers (ϵ₁ and ϵ₂) penalize divergence between the learner's occupancy and task-agnostic data, converting a constrained bi-level optimization into a single-level unconstrained convex problem in the dual space.
- Core assumption: The added KL divergences are sufficiently pessimistic to ensure offline stability without requiring data coverage of expert by non-expert data.
- Evidence anchors:
  - [abstract]: "minimizes the primal Wasserstein distance between the expert and learner state occupancies with a pessimistic regularizer"
  - [section]: "we modify the objective as follows: min x (c′)T x + ϵ₁Df(Π∥U) + ϵ₂Df(dπ_sa∥d_I_sa), s.t. Ax = b, x ≥ 0"
  - [corpus]: Weak evidence—no direct comparison to other regularizers or coverage conditions found.
- Break condition: If the pessimistic regularizers are too weak, the optimization may overfit to non-expert data; if too strong, learning may be overly conservative.

### Mechanism 2
- Claim: Using the primal form of Wasserstein distance with an arbitrary distance metric avoids the Euclidean constraint imposed by Rubinstein duality.
- Mechanism: The primal form allows embedding-based or contrastive distance metrics (e.g., cosine similarity, learned reachability) instead of gradient-enforced Euclidean distances.
- Core assumption: The learned or chosen metric better captures state reachability than Euclidean distance for the task.
- Evidence anchors:
  - [abstract]: "enables more flexible distance metrics... contrastively learned distance metric"
  - [section]: "different from all prior works, we explore the possibility of contrastively learning the metric from data"
  - [corpus]: Moderate—comparison with Euclidean baseline in Figure 5 shows better performance.
- Break condition: If the chosen metric does not reflect true reachability or similarity, the matching may be meaningless.

### Mechanism 3
- Claim: The learned distance metric via contrastive learning improves the Wasserstein matching quality.
- Mechanism: The InfoNCE-based embedding learns to place reachable states close together, so the primal Wasserstein distance reflects true transition dynamics rather than raw state similarity.
- Core assumption: Adjacent state pairs in task-agnostic data are good proxies for reachable states.
- Evidence anchors:
  - [abstract]: "leverages a contrastively learned distance metric"
  - [section]: "we use the following loss function: Lc = log exp(q^T W k+) / (exp(q^T W k+) + Σ_k- exp(q^T W k-))"
  - [corpus]: Weak—no ablation of embedding quality or alternative metric learning methods.
- Break condition: If task-agnostic data is sparse or non-representative, contrastive learning may fail to capture true reachability.

## Foundational Learning

- Concept: State occupancy d_π(s) = (1-γ) Σ_t γ^t P(s_t = s)
  - Why needed here: Core to measure how often states are visited by policies, enabling occupancy matching.
  - Quick check question: What is the formula for state occupancy under a policy with discount γ?

- Concept: f-divergence (e.g., KL, χ²) measures distribution difference
  - Why needed here: Used as the pessimistic regularizer to penalize divergence from task-agnostic data.
  - Quick check question: How does KL-divergence differ from χ²-divergence in terms of sensitivity to support mismatch?

- Concept: Fenchel conjugate f*(y) = max_x ⟨x,y⟩ - f(x)
  - Why needed here: Transforms the constrained dual problem into an unconstrained convex objective.
  - Quick check question: What is the Fenchel conjugate of f(x) = x log x?

## Architecture Onboarding

- Component map:
  - Contrastive embedding network (f(s)) trained with InfoNCE loss
  - Dual variable estimator (3-head neural network) for λ_s, λ_{s+|S|}, λ_{s+2|S|}
  - Weighted behavior cloning policy head using derived weights
  - Task-agnostic dataset I (state-action) and expert dataset E (state-only)

- Critical path:
  1. Train contrastive embedding on I
  2. Optimize dual variables λ via Eq. 8
  3. Derive policy weights via Eq. 9
  4. Train policy via weighted behavior cloning

- Design tradeoffs:
  - Using primal Wasserstein allows flexible metrics but increases computational complexity over dual form.
  - Adding pessimistic regularizers stabilizes offline learning but may slow convergence if too strong.
  - InfoNCE embedding requires task-agnostic data; without it, fallback to heuristic metrics is needed.

- Failure signatures:
  - Policy collapses to uniform if contrastive embedding fails (states become equidistant).
  - Divergence between expert and learner occupancies remains high if λ optimization is unstable.
  - Negative regret on some environments suggests overly conservative regularization.

- First 3 experiments:
  1. Train contrastive embedding on I and verify nearest-neighbor reachability matches expected dynamics.
  2. Run PW-DICE with λ optimization only (no policy) to confirm convergence and occupancy matching.
  3. Perform ablation: replace InfoNCE embedding with Euclidean distance and compare occupancy TV distance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PW-DICE perform on high-dimensional state spaces compared to its performance on tabular environments?
- Basis in paper: [inferred] The paper demonstrates PW-DICE's effectiveness on tabular MDPs and 4 Mujoco environments, but the scalability to higher-dimensional spaces remains untested.
- Why unresolved: The paper focuses on low-dimensional tabular MDPs and standard Mujoco benchmarks, which may not fully represent the complexity of real-world high-dimensional tasks.
- What evidence would resolve it: Testing PW-DICE on more complex, high-dimensional environments (e.g., Atari games, robotics tasks with image-based states) and comparing its performance to other methods.

### Open Question 2
- Question: What is the impact of different f-divergence choices (beyond KL and χ²) on PW-DICE's performance?
- Basis in paper: [explicit] The paper mentions that PW-DICE can use any f-divergence but only tests KL and χ² divergences.
- Why unresolved: The paper does not explore the performance of PW-DICE with other f-divergences, leaving their potential benefits or drawbacks unexplored.
- What evidence would resolve it: Conducting experiments with various f-divergences (e.g., Hellinger, Jensen-Shannon) and analyzing their impact on PW-DICE's performance across different environments.

### Open Question 3
- Question: How does PW-DICE's performance scale with the size of the task-agnostic dataset?
- Basis in paper: [explicit] The paper shows that PW-DICE performs better with larger task-agnostic datasets in tabular environments but does not explore this relationship in detail.
- Why unresolved: The paper provides limited insights into how PW-DICE's performance scales with dataset size in continuous control tasks.
- What evidence would resolve it: Conducting experiments with varying sizes of task-agnostic datasets in Mujoco environments and analyzing the relationship between dataset size and PW-DICE's performance.

## Limitations
- The effectiveness of the contrastive embedding is primarily demonstrated through downstream performance rather than direct evaluation of the learned metric's quality.
- The empirical validation is limited to four Mujoco environments, and the method's robustness to different types of task-agnostic data distributions remains unproven.
- The choice and tuning of pessimistic regularizers significantly impact performance, but the paper does not provide systematic sensitivity analysis.

## Confidence
- **High Confidence**: The theoretical derivation of PW-DICE as a primal Wasserstein optimization with pessimistic regularizers is mathematically sound and well-founded.
- **Medium Confidence**: The empirical results showing improved performance over baselines on Mujoco benchmarks are compelling but limited in scope.
- **Low Confidence**: The claim that contrastive learning of distance metrics significantly improves Wasserstein matching is supported by weak evidence, primarily relying on downstream performance without direct metric evaluation.

## Next Checks
1. Perform ablation studies comparing different distance metrics (Euclidean, learned contrastive, and heuristic alternatives) while keeping all other components fixed to isolate the impact of the metric learning approach.
2. Conduct systematic sensitivity analysis on the pessimistic regularizer coefficients (ϵ₁, ϵ₂) across different environments to understand their impact on stability and performance.
3. Evaluate PW-DICE on environments with varying task-agnostic data quality and quantity to assess the robustness of the contrastive learning approach under different data conditions.