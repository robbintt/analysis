---
ver: rpa2
title: Optimal Observation-Intervention Trade-Off in Optimisation Problems with Causal
  Structure
arxiv_id: '2309.02287'
source_url: https://arxiv.org/abs/2309.02287
tags:
- causal
- stopping
- optimal
- osco
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the observation-intervention trade-off in
  optimization problems with known causal structure, formulating it as a non-myopic
  optimal stopping problem. The proposed method, OSCO, determines whether to intervene
  or observe at each step based on cost-effectiveness.
---

# Optimal Observation-Intervention Trade-Off in Optimisation Problems with Causal Structure

## Quick Facts
- arXiv ID: 2309.02287
- Source URL: https://arxiv.org/abs/2309.02287
- Reference count: 40
- Key outcome: OSCO formulation determines whether to intervene or observe at each step, finding optimal interventions within budget constraints while balancing exploration and exploitation

## Executive Summary
This paper addresses the observation-intervention trade-off in optimization problems with known causal structure by formulating it as a non-myopic optimal stopping problem. The proposed OSCO method determines whether to intervene or observe at each step based on cost-effectiveness, allowing integration with existing causal Bayesian optimization algorithms. Experimental results show OSCO enhances convergence and outperforms baselines on real and synthetic benchmarks, finding optimal interventions within budget constraints while balancing exploration and exploitation.

## Method Summary
The method formulates the observation-intervention trade-off as an optimal stopping problem where the decision to stop (intervene) or continue (observe) depends on a cost-effectiveness criterion. The solution exploits the Markov property of the observation process, allowing efficient computation of the optimal stopping time. The approach integrates with existing causal Bayesian optimization algorithms by replacing their heuristic observation-intervention policies with the optimal stopping solution. A key component is the Minimal Observation Set (MOS) characterization, which identifies the smallest set of variables needed to estimate causal effects and reduce observation costs.

## Key Results
- OSCO successfully enhances existing causal Bayesian optimization algorithms by providing optimal policies for the observation-intervention trade-off
- The method finds optimal interventions within budget constraints while balancing exploration and exploitation
- Experimental results on synthetic and real-world benchmarks show improved convergence compared to baseline approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The optimal stopping formulation allows efficient computation of when to intervene vs observe by exploiting the Markov property.
- Mechanism: The problem is transformed into a Markov Decision Process (MDP) where the decision to stop (intervene) or continue (observe) depends only on the current state. The optimal stopping time is found by solving a Bellman equation that balances immediate reward of intervening against expected future reward of collecting more observations.
- Core assumption: The observation process is Markovian and stationary.
- Evidence anchors: [abstract] "The observation-intervention trade-off can be formulated as an optimal stopping problem which permits an efficient solution." [section 4] "The growth of the dataset Dt follows a stationary Markov process governed by the probability law..."
- Break condition: If the observation process is non-Markovian or non-stationary, the Bellman equation solution no longer applies.

### Mechanism 2
- Claim: The Minimal Observation Set (MOS) identifies the smallest set of variables needed to estimate causal effects, reducing observation costs.
- Mechanism: By applying Pearl's do-calculus rules, the intervention effect P(Y|do(X=x)) can be expressed in terms of observational probabilities. The MOS is the minimal set of variables Z such that this expression can be estimated from P(Z).
- Core assumption: The causal effect is identifiable from observational data.
- Evidence anchors: [section 2.2] "The set of variables Z ⊆ V occurring in QX Y is the minimal observation set..." [abstract] "...we characterise a set of variables called the minimal observation set (MOS)..."
- Break condition: If the causal effect is not identifiable from observational data, the MOS cannot be defined.

### Mechanism 3
- Claim: OSCO enhances existing causal Bayesian optimization (CBO) algorithms by providing an optimal policy for the observation-intervention trade-off.
- Mechanism: OSCO integrates with existing CBO algorithms by replacing their heuristic observation-intervention policies with the optimal stopping solution. This allows the algorithm to look ahead and decide whether collecting more observations or intervening immediately will lead to better optimization performance within the budget constraint.
- Core assumption: The underlying optimization policy πO can be implemented using standard acquisition functions.
- Evidence anchors: [abstract] "Experimental results show that our formulation can enhance existing algorithms on real and synthetic benchmarks." [section 4] "We place no restrictions on how this policy is obtained or implemented."
- Break condition: If the optimization policy πO cannot be implemented or doesn't provide meaningful exploration-exploitation balance.

## Foundational Learning

- Concept: Causal inference and structural causal models (SCMs)
  - Why needed here: The entire framework relies on understanding how interventions affect outcomes through causal mechanisms represented as DAGs.
  - Quick check question: Can you explain what the do-calculus does and how it differs from standard conditioning?

- Concept: Optimal stopping theory and MDPs
  - Why needed here: The observation-intervention trade-off is formulated as an optimal stopping problem, which requires understanding Bellman equations and Markov properties.
  - Quick check question: What is the difference between a policy that always intervenes and one that uses optimal stopping?

- Concept: Bayesian optimization and acquisition functions
  - Why needed here: The paper integrates with existing CBO algorithms, so understanding how acquisition functions balance exploration and exploitation is crucial.
  - Quick check question: How does an ε-greedy policy differ from more sophisticated acquisition functions like Expected Improvement?

## Architecture Onboarding

- Component map: Causal Graph (G) -> MOS Computation -> Optimization Policy (πO) -> Optimal Stopping Decision -> Data Collection -> Model Update -> Repeat

- Critical path: Graph → MOS Computation → Optimization Policy → Optimal Stopping Decision → Data Collection → Model Update → Repeat

- Design tradeoffs:
  - Computational cost vs optimality: Exact optimal stopping is expensive; approximations may be needed
  - Model accuracy vs data requirements: Better models need more data, but data collection is costly
  - Observation scope vs cost: Collecting more variables gives better estimates but increases costs

- Failure signatures:
  - Non-identifiable causal effects: MOS cannot be computed, fallback to intervention-only
  - Non-Markovian observations: Optimal stopping solution invalid, need alternative approach
  - Poor model quality: Bad estimates lead to wrong decisions, need more exploration

- First 3 experiments:
  1. Chain SCM with known structure: Validate that OSCO finds optimal interventions faster than baselines
  2. Chain SCM with unobserved confounder: Test robustness to hidden variables
  3. PSA SCM with real-world costs: Demonstrate practical cost savings in healthcare setting

## Open Questions the Paper Calls Out

- Question: How would OSCO perform with soft interventions rather than the hard interventions assumed in the paper?
  - Basis in paper: [explicit] "‘Soft’ or ‘stochastic’ [17] intervention settings are left for future work."
  - Why unresolved: The paper only evaluates OSCO with hard interventions, leaving the performance under soft interventions unexplored.
  - What evidence would resolve it: Experimental results comparing OSCO's performance on synthetic and real-world SCMs using both hard and soft interventions.

- Question: What is the impact of increasing the planning horizon beyond the next intervention in the optimal stopping problem?
  - Basis in paper: [inferred] "Most existing algorithms deal with these problems by truncating the planning horizon to one step [ 22, 2, 3, 60]. We propose to instead truncate the planning horizon to the next intervention, which may involve simulating many observation steps."
  - Why unresolved: The paper only evaluates OSCO with a planning horizon truncated to the next intervention, not considering longer horizons.
  - What evidence would resolve it: Comparative experimental results showing OSCO's performance with different planning horizons on synthetic and real-world SCMs.

- Question: How sensitive is OSCO's performance to the choice of reward function in the optimal stopping problem?
  - Basis in paper: [explicit] "Another direction is to evaluate different reward functions in the optimal stopping problem."
  - Why unresolved: The paper uses a specific reward function but does not explore the impact of alternative reward functions on OSCO's performance.
  - What evidence would resolve it: Experimental results comparing OSCO's performance using different reward functions on synthetic and real-world SCMs.

## Limitations

- The approach relies heavily on the assumption of known causal structure, which may not hold in many real-world scenarios
- The Markov property assumption for the observation process may be violated in non-stationary environments
- Computational complexity grows with the size of the action space and budget, potentially limiting scalability

## Confidence

- **High Confidence**: The mathematical formulation of the optimal stopping problem and its connection to Markov Decision Processes is well-established and correctly applied
- **Medium Confidence**: The characterization of the minimal observation set and its application to reduce observation costs is theoretically sound but relies on assumptions about causal identifiability
- **Low Confidence**: The experimental results showing performance improvements over baselines, while promising, are based on synthetic examples and a single real-world case

## Next Checks

1. **Robustness to Model Misspecification**: Test OSCO's performance when the assumed causal structure is partially incorrect or when the structural equations have misspecified parameters.

2. **Scalability Analysis**: Evaluate the computational complexity of solving the optimal stopping problem as the number of variables, intervention options, and budget increase.

3. **Cross-Algorithm Integration**: Implement OSCO with multiple different causal Bayesian optimization algorithms to verify that the approach is genuinely algorithm-agnostic.