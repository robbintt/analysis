---
ver: rpa2
title: 'Case Repositories: Towards Case-Based Reasoning for AI Alignment'
arxiv_id: '2311.10934'
source_url: https://arxiv.org/abs/2311.10934
tags:
- cases
- case
- reasoning
- legal
- process
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using case-based reasoning to align AI systems
  with human values by constructing repositories of case studies and associated judgments.
  The authors describe a process to assemble such case repositories by gathering seed
  cases from online communities, eliciting expert dimensions through workshops, using
  LLMs to generate synthetic cases, and engaging the public to judge and refine cases.
---

# Case Repositories: Towards Case-Based Reasoning for AI Alignment

## Quick Facts
- arXiv ID: 2311.10934
- Source URL: https://arxiv.org/abs/2311.10934
- Reference count: 10
- Primary result: Proposes a human-AI hybrid method for building case repositories to align AI systems with human values through case-based reasoning

## Executive Summary
This paper introduces case repositories as a novel approach to AI alignment that complements constitutional AI methods. The approach uses case-based reasoning to construct repositories of real-world scenarios with associated human judgments, enabling AI systems to learn from precedent rather than abstract principles. The authors present a four-stage process involving seed case collection from online communities, expert dimension elicitation, LLM-assisted case generation, and public crowdsourcing to judge and refine cases.

## Method Summary
The method involves a human-AI hybrid process for assembling case repositories: collecting seed cases from online communities like Reddit's r/legaladvice, conducting expert workshops to identify key dimensions for evaluation, using LLMs to generate synthetic cases by extending seed cases along those dimensions, and engaging the public through crowdsourcing to judge response appropriateness and refine cases iteratively.

## Key Results
- Demonstrates a four-stage process for assembling case repositories that captures real-world complexity
- Shows how expert elicitation can identify meaningful dimensions for case expansion
- Illustrates the use of LLM-generated synthetic cases to expand the case space
- Presents a framework for public engagement in refining and judging cases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The process generates cases that are closer to real-world scenarios than generic synthetic data.
- Mechanism: By starting with seed cases sourced from actual community discussions and then perturbing them along expert-identified dimensions, the synthetic cases retain realistic structure and context.
- Core assumption: The seed cases and LLM-generated perturbations preserve semantic coherence and domain relevance.
- Evidence anchors: [abstract] describes gathering seed cases from online communities and using LLMs to generate variations; [section 2.1] describes collecting questions from r/legaladvice.

### Mechanism 2
- Claim: Expert elicitation ensures that case dimensions are aligned with professional standards and ethical norms.
- Mechanism: Workshops with domain experts identify key dimensions that impact their evaluation of AI responses, ensuring case expansion captures factors that matter in practice.
- Core assumption: The expert panel represents the relevant professional community and their judgments are reliable.
- Evidence anchors: [section 2.2] describes conducting workshops with legal experts and lists dimensions like "location of operation," "involvement of minors," and "terms of service."

### Mechanism 3
- Claim: Public crowdsourcing refines cases and grounds them in diverse lived experiences.
- Mechanism: Crowdworkers judge the appropriateness of AI responses and refine cases, ensuring the repository reflects a wide range of perspectives.
- Core assumption: The crowd sample is sufficiently diverse and representative of the target user population.
- Evidence anchors: [abstract] states engaging the public "to judge and improve cases"; [section 2.4] describes judgement and refinement tasks with crowdworkers.

## Foundational Learning

- Concept: Case-Based Reasoning (CBR)
  - Why needed here: The paper's approach is fundamentally grounded in CBR, which uses past cases to inform future decisions.
  - Quick check question: What are the four main steps in the CBR cycle, and how do they apply to the case repository approach?

- Concept: Legal Precedent and Casuistry
  - Why needed here: The paper draws parallels between legal case law and CBR, suggesting AI alignment can learn from how legal systems use precedents.
  - Quick check question: How does casuistry differ from applying universal moral principles, and why is this distinction relevant to AI alignment?

- Concept: AI Alignment and Value Pluralism
  - Why needed here: The paper addresses aligning AI with diverse and sometimes conflicting human values.
  - Quick check question: What are the main criticisms of using a single set of abstract principles for AI alignment, and how does the case repository approach address these?

## Architecture Onboarding

- Component map: Seed Case Collection -> Expert Workshop -> LLM-Assisted Case Generation -> Public Crowdsourcing -> Case Repository -> AI System
- Critical path: 1) Collect seed cases, 2) Conduct expert workshops to identify dimensions, 3) Generate synthetic cases using LLMs, 4) Engage crowdworkers to judge and refine cases, 5) Assemble final case repository
- Design tradeoffs:
  - Expert vs. Public Input: More expert input may produce narrow cases; more public input may introduce noise
  - LLM-Generated vs. Human-Written Cases: LLM generation is faster but may introduce hallucinations; human writing is slower but more controlled
  - Granularity of Dimensions: Finer-grained dimensions allow precise case generation but increase complexity
- Failure signatures: Low agreement among crowdworkers, LLM-generated cases that are nonsensical or violate domain logic, expert dimensions that are too abstract
- First 3 experiments: 1) Validate LLM-generated cases by having experts rate a sample, 2) Measure inter-rater reliability among crowdworkers, 3) Test case repository's impact on AI response quality

## Open Questions the Paper Calls Out

- Question: How can case repositories be effectively used to align AI systems with diverse human values while avoiding the imposition of hegemonic perspectives?
  - Basis in paper: [explicit] The authors discuss the need to avoid imposing hegemonic perspectives and homogenizing diverse viewpoints in AI alignment.
  - Why unresolved: The paper acknowledges the challenge of balancing common ground with individual differences but does not provide a concrete solution.
  - What evidence would resolve it: Research demonstrating successful methods for incorporating diverse perspectives without imposing dominant views.

- Question: What are the most effective methods for engaging the public in evaluating and refining cases for AI alignment?
  - Basis in paper: [explicit] The authors propose engaging the public through crowdsourcing but acknowledge the need for further exploration of metrics and tools.
  - Why unresolved: The paper identifies the importance of public engagement but does not provide specific metrics or tools for evaluating effectiveness.
  - What evidence would resolve it: Studies comparing different methods of public engagement and their impact on case repository quality.

- Question: How can case repositories be designed to ensure portability across AI models and domains?
  - Basis in paper: [explicit] The authors mention case repositories are designed to be model-agnostic and domain-agnostic.
  - Why unresolved: The paper highlights the importance of portability but does not offer concrete strategies for designing portable repositories.
  - What evidence would resolve it: Research demonstrating successful methods for designing case repositories adaptable to various AI models and domains.

## Limitations

- Limited quantitative validation of human judgment reliability at multiple stages
- Legal domain example represents a narrow slice of potential alignment challenges
- Heavy reliance on subjective human judgments from experts and crowdworkers

## Confidence

- High confidence in the general CBR framework and its theoretical relevance to AI alignment
- Medium confidence in the expert elicitation process and identified dimensions
- Low confidence in the LLM case generation quality without systematic validation
- Low confidence in the public crowdsourcing approach without demonstrated inter-rater reliability

## Next Checks

1. Conduct inter-rater reliability analysis on a sample of crowdsourced judgments to measure agreement levels and identify sources of disagreement
2. Perform expert review of 50-100 LLM-generated cases to assess coherence, domain relevance, and potential hallucinations
3. Run controlled experiments comparing AI behavior with and without case repository access on held-out test cases