---
ver: rpa2
title: Large Language Models for Propaganda Span Annotation
arxiv_id: '2311.09812'
source_url: https://arxiv.org/abs/2311.09812
tags:
- annotation
- span
- propaganda
- gpt-4
- techniques
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We explored using GPT-4 for annotating propaganda spans in Arabic
  news articles, comparing its performance across different annotation roles. GPT-4
  was tested as a general annotator, a span extractor, and a consolidator using prompts
  of increasing information richness.
---

# Large Language Models for Propaganda Span Annotation

## Quick Facts
- arXiv ID: 2311.09812
- Source URL: https://arxiv.org/abs/2311.09812
- Reference count: 15
- One-line primary result: GPT-4 can serve as a high-quality annotator for propaganda detection tasks with sufficient context

## Executive Summary
This paper explores the use of GPT-4 for annotating propaganda spans in Arabic news articles. The authors compare GPT-4's performance across different annotation roles (general annotator, span extractor, and consolidator) using prompts of varying information richness. Results show that providing more context significantly improves GPT-4's agreement with human annotators and overall performance. In the consolidator role, GPT-4 achieved a micro-F1 of 0.671 and γ agreement of 0.609, outperforming human annotators in some metrics. However, the model frequently generated incorrect span indices, requiring post-processing correction. The authors plan to release all annotations to the community.

## Method Summary
The study uses an in-house manually annotated dataset of 8,000 paragraphs from 2,800 Arabic news articles. GPT-4 is tested in three roles with increasing information richness: Annotator (zero-shot detection and labeling), Selector (provided with propaganda technique annotations), and Consolidator (provided with all human annotations). The experiments follow a zero-shot prompting approach using the LLMeBench framework, with performance evaluated using standard metrics including micro-F1, macro-F1, Krippendorff's alpha, average observed agreement, and gamma agreement.

## Key Results
- GPT-4's performance improves with increasing information richness in prompts
- In consolidator role, GPT-4 achieved micro-F1 of 0.671 and γ agreement of 0.609
- Post-processing heuristics were required to correct incorrect span indices generated by GPT-4
- GPT-4 outperformed human annotators in some metrics despite span indexing errors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4's performance in propaganda span annotation improves with increasing information richness in prompts
- Mechanism: Providing more context reduces ambiguity and narrows the decision space, allowing better identification and labeling of propaganda techniques
- Core assumption: Additional information is relevant and accurately processed by GPT-4
- Evidence anchors: Abstract and section 4.2 results showing performance improvement with more context

### Mechanism 2
- Claim: GPT-4 can serve as a high-quality annotator for propaganda detection tasks, especially in consolidator role
- Mechanism: GPT-4 leverages its synthetic capabilities to integrate and refine annotations from multiple human annotators
- Core assumption: GPT-4's processing abilities allow effective integration of human annotation work
- Evidence anchors: Abstract results showing consolidator role outperforming human annotators in some metrics

### Mechanism 3
- Claim: GPT-4's incorrect start/end indices for spans can be corrected through post-processing heuristics
- Mechanism: Assigning start and end indices of the first occurrence of each predicted span improves annotation accuracy
- Core assumption: First occurrence is a reasonable approximation of correct span indices
- Evidence anchors: Section 6 results showing performance doubled after applying correction heuristic

## Foundational Learning

- Concept: Understanding propaganda techniques and their detection
  - Why needed here: To effectively annotate propaganda spans, one must recognize and categorize various propaganda techniques
  - Quick check question: Can you list at least three common propaganda techniques mentioned in the paper?

- Concept: Familiarity with Large Language Models (LLMs) and their capabilities
  - Why needed here: GPT-4, an LLM, is used for annotation, so understanding its strengths and limitations is crucial
  - Quick check question: What are the key differences between zero-shot and few-shot learning in the context of LLMs?

- Concept: Knowledge of evaluation metrics for annotation tasks
  - Why needed here: To assess GPT-4's performance, one must understand metrics like F1 score and agreement measures
  - Quick check question: How does the γ agreement metric differ from traditional inter-rater agreement measures?

## Architecture Onboarding

- Component map: Dataset -> GPT-4 with prompts -> Annotated spans -> Post-processing -> Evaluation
- Critical path: 1) Prepare dataset and split into training, development, and testing sets 2) Design prompts for GPT-4 with increasing information richness 3) Run GPT-4 on dataset using designed prompts 4) Apply post-processing heuristics to correct span indices 5) Evaluate performance using F1 scores and agreement metrics
- Design tradeoffs: Tradeoff between prompt complexity and GPT-4's ability to process information effectively; balancing cost of human annotation with quality of GPT-4 annotations
- Failure signatures: Low F1 scores indicating poor annotation quality; high disagreement between GPT-4 annotations and gold labels; inconsistent span indices requiring frequent post-processing corrections
- First 3 experiments: 1) Test GPT-4 with Annotator prompt setup on small dataset subset to establish baseline 2) Evaluate GPT-4 with Selector prompt setup to assess impact of providing technique annotations 3) Run GPT-4 as Consolidator with full annotation information to determine optimal setup for performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between providing annotation context and computational cost when using LLMs for propaganda span annotation?
- Basis in paper: [explicit] The paper explores different levels of information richness in prompts, showing that more context improves performance, but doesn't optimize the trade-off
- Why unresolved: The study only compares three fixed prompt types without analyzing the cost-benefit relationship or finding the optimal point
- What evidence would resolve it: A systematic study varying the amount of context provided while measuring both annotation quality and computational costs

### Open Question 2
- Question: How well do GPT-4's propaganda span annotations generalize to other languages and cultural contexts?
- Basis in paper: [inferred] The study focuses exclusively on Arabic and doesn't test cross-linguistic or cross-cultural generalization
- Why unresolved: The paper only evaluates GPT-4 on Arabic news articles without testing its performance on other languages or different cultural contexts
- What evidence would resolve it: Testing GPT-4's annotation performance across multiple languages and cultural contexts while comparing to human annotators

### Open Question 3
- Question: What specific prompt engineering techniques could minimize the span indexing errors observed in GPT-4's annotations?
- Basis in paper: [explicit] The paper identifies that GPT-4 frequently generates incorrect start/end indices for spans, requiring post-processing correction
- Why unresolved: While the paper acknowledges the problem and applies a basic correction, it doesn't explore systematic solutions or alternative prompt formulations
- What evidence would resolve it: Testing various prompt modifications and fine-tuning strategies specifically targeting span indexing accuracy

## Limitations

- Performance gains from increased context may not generalize beyond Arabic news articles
- Span indexing errors persist even after post-processing, limiting practical deployment
- Zero-shot approach may underperform compared to fine-tuned models for specialized propaganda detection tasks

## Confidence

- **High Confidence**: The core finding that GPT-4 can perform propaganda span annotation with reasonable accuracy, particularly in consolidator roles
- **Medium Confidence**: The mechanism by which context richness improves performance, as results are specific to this dataset and prompt design
- **Medium Confidence**: The effectiveness of post-processing heuristics for correcting span indices, though this remains an imperfect solution

## Next Checks

1. Test the prompt context sensitivity on a different language corpus to verify generalization beyond Arabic news articles
2. Implement a benchmark comparison between GPT-4's consolidator role and traditional majority voting approaches on the same dataset
3. Evaluate the impact of different post-processing strategies for span correction, including machine learning-based approaches versus heuristic methods