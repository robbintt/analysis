---
ver: rpa2
title: 'BiomedJourney: Counterfactual Biomedical Image Generation by Instruction-Learning
  from Multimodal Patient Journeys'
arxiv_id: '2310.10765'
source_url: https://arxiv.org/abs/2310.10765
tags:
- image
- counterfactual
- generation
- medical
- biomedjourney
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BiomedJourney, a novel method for counterfactual
  biomedical image generation that leverages instruction-learning from multimodal
  patient journeys. Given two biomedical images of a patient taken at different time
  points, GPT-4 is used to generate a natural language description of disease progression
  from the corresponding imaging reports.
---

# BiomedJourney: Counterfactual Biomedical Image Generation by Instruction-Learning from Multimodal Patient Journeys

## Quick Facts
- arXiv ID: 2310.10765
- Source URL: https://arxiv.org/abs/2310.10765
- Reference count: 19
- Key outcome: BiomedJourney substantially outperforms state-of-the-art methods like InstructPix2Pix and RoentGen on counterfactual medical image generation tasks

## Executive Summary
BiomedJourney introduces a novel approach for counterfactual biomedical image generation by leveraging instruction-learning from multimodal patient journeys. The method uses GPT-4 to generate natural language descriptions of disease progression from radiology reports, creating training triples of (prior image, progression description, new image) for a latent diffusion model. A two-stage curriculum learning approach addresses the scarcity of image time series data by first pretraining on abundant single image-report pairs and then fine-tuning on counterfactual triples. Experiments on the MIMIC-CXR dataset demonstrate significant improvements over existing methods in generating counterfactual medical images that accurately reflect prescribed changes while preserving patient-specific invariants.

## Method Summary
BiomedJourney generates counterfactual biomedical images by processing multimodal patient journeys through GPT-4 to extract disease progression descriptions from radiology reports. These descriptions, combined with prior and new medical images, create training triples for a latent diffusion model. The method employs a two-stage curriculum learning approach: first pretraining on abundant single image-report pairs using a dummy prior image, then fine-tuning on the scarce counterfactual triples with real prior images. The model uses BiomedCLIP for text encoding and operates in latent space using a pre-trained Stable Diffusion v1.5 backbone. The approach addresses the challenge of limited image time series data while maintaining patient-specific invariants during counterfactual generation.

## Key Results
- BiomedJourney outperforms state-of-the-art methods like InstructPix2Pix and RoentGen on counterfactual medical image generation
- The method shows strong instruction-following capability while preserving patient-specific invariants such as race and age
- Two-stage curriculum learning effectively addresses data scarcity by leveraging abundant single image-report pairs for pretraining

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BiomedJourney achieves counterfactual biomedical image generation by leveraging GPT-4 to synthesize instruction-following data from multimodal patient journeys
- Mechanism: GPT-4 extracts disease progression descriptions from radiology reports, creating triples of (prior image, progression description, new image) that train a latent diffusion model to generate counterfactual images
- Core assumption: GPT-4 can reliably synthesize accurate and natural disease progression descriptions that capture key differences between time points
- Evidence anchors: [abstract] "we use GPT-4 to process the corresponding imaging reports and generate a natural language description of disease progression"
- Break condition: If GPT-4 generates inaccurate disease progression descriptions, the training triples would be unreliable and the model would learn incorrect mappings

### Mechanism 2
- Claim: The two-stage curriculum learning approach effectively addresses the scarcity of image time series data
- Mechanism: First pretrain on abundant single image-report pairs using a dummy prior image, then fine-tune on scarce counterfactual triples with real prior images
- Core assumption: The latent space learned from single image-report pairs provides a useful initialization for learning the more complex mapping to counterfactual images
- Evidence anchors: [abstract] "we introduce a two-stage curriculum that first pretrains the denoising network using the much more abundant single image-report pairs"
- Break condition: If the latent space from single pairs is too different from the space needed for counterfactual generation, fine-tuning may not effectively adapt the model

### Mechanism 3
- Claim: BiomedCLIP provides better text encoding for medical images than general domain encoders like CLIP
- Mechanism: BiomedCLIP is pre-trained on biomedical image-text pairs, giving it domain-specific knowledge and a larger context length suitable for clinical reports
- Core assumption: Domain-specific pre-training and larger context window enable better understanding of medical terminology and longer clinical narratives
- Evidence anchors: [section 4.2] "we explore replacing CLIP with BiomedCLIP, which was pretrained on image-text pairs extracted from biomedical papers"
- Break condition: If the biomedical domain is sufficiently different from pre-training data, BiomedCLIP may not provide significant advantages

## Foundational Learning

- Concept: Diffusion models and latent diffusion models
  - Why needed here: BiomedJourney builds upon latent diffusion models as its base architecture, extending them to condition on both images and text
  - Quick check question: How does a latent diffusion model differ from a standard diffusion model, and why is the latent space approach beneficial for image generation?

- Concept: Image registration and alignment
  - Why needed here: The paper emphasizes the importance of image registration to mitigate artifacts from varying image positions and angles across studies
  - Quick check question: What specific registration technique is mentioned in the paper, and how does it help reduce spurious correlations in the training data?

- Concept: Counterfactual reasoning and causal inference
  - Why needed here: The entire goal is counterfactual generation - answering "what if" questions about disease progression
  - Quick check question: How does the paper distinguish between spurious correlation and genuine causal structure in counterfactual medical image generation?

## Architecture Onboarding

- Component map: GPT-4 → (prior image, progression description, new image) triples → LDM training → counterfactual image generation
- Critical path: GPT-4 generates progression descriptions → triples create training data → latent diffusion model learns mapping → counterfactual images generated
- Design tradeoffs: Single image-report pairs vs. counterfactual triples (abundance vs. specificity), general domain vs. biomedical domain encoders, image resolution for training vs. evaluation
- Failure signatures: Hallucinations (duplicated organs/ribs), failure to preserve patient invariants (race, age), poor pathology accuracy, spatial misalignment
- First 3 experiments:
  1. Train BiomedJourney without image registration to observe impact on feature retention and pathology accuracy
  2. Replace BiomedCLIP with CLIP to quantify benefit of domain-specific text encoding
  3. Train using only counterfactual triples (skip stage 1) to demonstrate necessity of curriculum learning

## Open Questions the Paper Calls Out
- The paper notes that the optimal curriculum learning strategy is yet to be explored and suggests investigating higher resolution training in future work
- The authors acknowledge that exploring other medical domains and image modalities beyond chest X-rays is an important direction for future research

## Limitations
- Relies heavily on GPT-4's ability to accurately synthesize disease progression descriptions from radiology reports
- Evaluation framework may not fully capture clinical utility or safety implications of generated counterfactuals in real diagnostic scenarios
- Effectiveness of two-stage curriculum learning assumes single image-report pairs provide relevant initialization, but this relationship is not empirically validated

## Confidence

- High confidence: Technical implementation of latent diffusion models, use of MIMIC-CXR dataset, basic architecture design combining GPT-4, BiomedCLIP, and latent diffusion
- Medium confidence: Superiority over baseline methods based on quantitative metrics, effectiveness of two-stage curriculum learning
- Low confidence: Clinical validity and safety of generated counterfactual images for diagnostic purposes, generalizability to other medical imaging modalities

## Next Checks

1. **Human expert evaluation**: Conduct a blinded study where radiologists assess whether generated counterfactual images accurately represent described disease progression while maintaining patient-specific characteristics, comparing BiomedJourney outputs to ground truth images and baseline method outputs.

2. **Cross-modal generalization test**: Apply BiomedJourney to a different medical imaging modality (such as brain MRI or retinal fundus images) to evaluate whether the approach generalizes beyond chest X-rays, particularly testing the robustness of GPT-4-generated progression descriptions for different imaging contexts.

3. **Ablation study on text encoder**: Systematically compare BiomedCLIP against other text encoders including general domain CLIP, domain-specific biomedical encoders, and medical concept extraction methods to quantify the specific contribution of the BiomedCLIP component to overall performance.