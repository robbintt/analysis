---
ver: rpa2
title: 'Pre-trained Recommender Systems: A Causal Debiasing Perspective'
arxiv_id: '2310.19251'
source_url: https://arxiv.org/abs/2310.19251
tags:
- item
- domain
- user
- bias
- domains
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of building a pre-trained recommender
  system that can generalize across domains despite heterogeneous biases. The authors
  identify in-domain (e.g., popularity bias) and cross-domain biases (e.g., cultural
  differences) as key obstacles to transferability.
---

# Pre-trained Recommender Systems: A Causal Debiasing Perspective

## Quick Facts
- arXiv ID: 2310.19251
- Source URL: https://arxiv.org/abs/2310.19251
- Authors: 
- Reference count: 40
- Pre-trained recommender system with causal debiasing shows significant gains in cross-domain zero-shot recommendation

## Executive Summary
This paper addresses the challenge of building pre-trained recommender systems that can generalize across domains despite heterogeneous biases. The authors identify in-domain biases (like popularity bias) and cross-domain biases (like cultural differences) as key obstacles to transferability. To address these, they propose PreRec, a hierarchical Bayesian deep learning framework with a causal debiasing mechanism. PreRec explicitly models domain-specific and popularity-related confounders, then uses causal intervention during zero-shot inference to remove cross-domain bias while incorporating target-domain in-domain bias.

## Method Summary
PreRec uses a hierarchical Bayesian framework to model user interests, item properties, and user-item interactions while explicitly capturing domain-specific and popularity-related confounders. During pre-training on source domains, the model learns to extract cross-domain bias into domain confounders and individual in-domain bias into popularity confounders. During zero-shot inference, causal intervention (do-calculus) is applied by setting domain confounders to zero, effectively removing cross-domain bias while maintaining in-domain popularity bias. The model uses multilingual Sentence-BERT for item embeddings and a transformer-based sequential model for user embeddings.

## Key Results
- PreRec achieves 19.38% improvement in Recall@20% over fine-tuned baseline in zero-shot settings
- PreRec shows consistent performance gains across multiple cross-market and cross-platform datasets
- The model demonstrates effectiveness in both zero-shot, incremental, and full fine-tuning settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The hierarchical Bayesian framework isolates domain-specific and popularity-related confounders through explicit modeling, enabling causal debiasing during inference.
- Mechanism: PreRec explicitly models domain-specific confounders (D‚Çñ) and popularity confounders (Z‚±º) as latent variables. During pre-training, these confounders explain away variability in user interests, item properties, and user-item interactions. Causal intervention (do-calculus) is then applied during zero-shot inference by setting D‚Çñ=0 to remove cross-domain bias while incorporating target-domain in-domain bias.
- Core assumption: The domain property D‚Çñ and popularity property Z‚±º can be effectively modeled as independent latent variables that causally influence user interests, item properties, and interactions.
- Evidence anchors:
  - [abstract] "PreRec explicitly models domain-specific and popularity-related confounders, then uses causal intervention (do-calculus) during zero-shot inference to remove cross-domain bias while incorporating target-domain in-domain bias."
  - [section 3.2] "PreRec defines the domain property D‚Çñ as an independent latent variable... PreRec will automatically extract the cross-domain bias shared across users and items into D‚Çñ, while extracting the individual in-domain bias for each item ùëó into Z‚±º."
- Break condition: If domain properties and popularity effects cannot be effectively isolated as independent confounders, the causal debiasing mechanism may fail to properly remove bias during inference.

### Mechanism 2
- Claim: The popularity factors F‚±º are designed to be transferable across domains by normalizing interaction counts with domain-specific norms.
- Mechanism: Popularity factors F‚±º are computed using a normalization term that considers different orders of norms (L‚ÇÅ to L‚ÇÑ) for the denominator. This design ensures that popularity scores are comparable across domains despite differences in traffic volume and item catalog size.
- Core assumption: Interaction counts follow a distribution that can be normalized using domain-specific norms to create comparable popularity scores.
- Evidence anchors:
  - [section 3.2] "We design a method inspired by the half Gaussian distribution... The popularity factor F‚±º of item ùëó can be measured as: F‚±º = ùëêùëá‚±º / ‚àö(Œ£·µ¢‚ààùêΩ‚Çñ (ùëêùëá·µ¢)¬≤/|ùêΩ‚Çñ|)"
  - [supplement] "To address the abovementioned issue, we design a method inspired by the half Gaussian distribution."
- Break condition: If the interaction distribution significantly deviates from the assumed half Gaussian distribution, the normalization may not produce truly comparable popularity scores across domains.

### Mechanism 3
- Claim: The causal intervention during zero-shot recommendation effectively removes cross-domain bias by approximating the expectation over the domain bias distribution.
- Mechanism: During zero-shot inference, PreRec sets D‚Çñ=0 for both user and item embeddings, which approximates the output expectation over the distribution of D‚Çñ. This removes cross-domain bias while maintaining the in-domain popularity bias.
- Core assumption: Setting D‚Çñ=0 approximates the expectation over the domain bias distribution, effectively removing cross-domain bias.
- Evidence anchors:
  - [section 3.3] "This serves as an approximation to the output expectation over the distribution of D‚Çñ as input, and we found this approach achieved similar performance in practice."
  - [section 3.3] "Following the back-door formula [27] we have: P(R·µ¢‚±º‚Çñ|do(U·µ¢, V‚±º, Z‚±º)) = ‚à´ P(R·µ¢‚±º‚Çñ|U·µ¢, V‚±º, D‚Çñ, Z‚±º)P(D‚Çñ)dD‚Çñ"
- Break condition: If the approximation of setting D‚Çñ=0 to the true expectation over D‚Çñ distribution is poor, cross-domain bias may persist in the recommendations.

## Foundational Learning

- Concept: Causal inference and do-calculus
  - Why needed here: The paper relies on causal intervention to remove cross-domain bias during zero-shot inference, which requires understanding do-calculus and causal graphs.
  - Quick check question: What is the difference between observing a variable and intervening on a variable in a causal graph?

- Concept: Hierarchical Bayesian modeling
  - Why needed here: PreRec uses a hierarchical Bayesian framework to model latent variables (domain bias, popularity bias, user interests) at different levels, which is crucial for understanding how the model captures and debiases different types of bias.
  - Quick check question: How does a hierarchical Bayesian model differ from a flat Bayesian model in terms of capturing structured relationships between variables?

- Concept: Recommendation system evaluation metrics
  - Why needed here: The paper uses Recall@K% and r-NDCG@K% for evaluation, which require understanding how these metrics work and why they're suitable for cross-domain recommendation evaluation.
  - Quick check question: Why might standard NDCG@K be problematic for comparing recommendation performance across domains with different numbers of items?

## Architecture Onboarding

- Component map:
  - Item Universal Embedding Network (item UEN) -> User Universal Embedding Network (user UEN) -> Causal Debiasing Layer -> Popularity Factor Calculator -> Inference Engine

- Critical path: Pre-training on source domains ‚Üí Causal debiasing during zero-shot inference ‚Üí Fine-tuning on target domain

- Design tradeoffs:
  - Using multilingual Sentence-BERT vs. domain-specific language models: Tradeoff between generalizability and domain-specific semantic understanding
  - Setting D‚Çñ=0 vs. sampling from D‚Çñ distribution during zero-shot inference: Tradeoff between computational efficiency and approximation accuracy
  - Using popularity factors vs. raw interaction counts: Tradeoff between comparability across domains and capturing absolute popularity

- Failure signatures:
  - Poor zero-shot performance despite good pre-training results: Indicates failure of causal debiasing mechanism
  - Large gap between zero-shot and fine-tuned performance: Suggests model is not effectively transferring knowledge
  - Inconsistent performance across target domains: May indicate domain bias not properly modeled

- First 3 experiments:
  1. Compare PreRec with and without causal debiasing on a single target domain to verify the debiasing mechanism works
  2. Test the transferability of popularity scores by computing them on source domains and applying to target domains
  3. Evaluate the approximation of setting D‚Çñ=0 by comparing with sampling from D‚Çñ distribution during zero-shot inference

## Open Questions the Paper Calls Out

- How to address other types of in-domain bias, such as position bias and exposure bias
- How to model user-item interactions in cold-start scenarios where no interaction data exists
- How to efficiently model temporal dynamics in user interests and item properties

## Limitations

- The causal debiasing mechanism relies on assumptions about the causal structure and distributional properties that may not hold in all domains
- The popularity factor normalization method uses heuristic choices (L‚ÇÅ to L‚ÇÑ norms) without systematic comparison
- The multilingual Sentence-BERT model may not capture domain-specific semantic nuances equally well across all languages and product categories

## Confidence

**High Confidence:** The hierarchical Bayesian framework architecture and the basic concept of using causal intervention for debiasing are well-established. The experimental methodology (datasets, evaluation metrics, comparison with baselines) is clearly specified and reproducible.

**Medium Confidence:** The effectiveness of the specific popularity factor normalization method and the causal debiasing mechanism's ability to generalize across diverse domains. While results show improvement, the underlying assumptions about causal structure and distributional properties warrant further validation.

**Low Confidence:** The absolute performance gains compared to fine-tuned baselines in cross-platform settings, as the paper doesn't thoroughly analyze failure cases or identify when the approach might not work well.

## Next Checks

1. **Causal Structure Validation:** Perform ablation studies systematically removing either D‚Çñ or Z‚±º from the model to quantify their individual contributions to performance gains, and test alternative causal graph structures.

2. **Distribution Assumption Testing:** Analyze the distribution of interaction counts across domains to verify the half-Gaussian assumption, and test the sensitivity of popularity factors to different normalization schemes.

3. **Approximation Accuracy:** Compare the performance of setting D‚Çñ=0 against sampling from the D‚Çñ distribution during zero-shot inference across multiple domains to quantify the approximation error.