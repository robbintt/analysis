---
ver: rpa2
title: 'Technical Report for ICCV 2023 Visual Continual Learning Challenge: Continuous
  Test-time Adaptation for Semantic Segmentation'
arxiv_id: '2310.13533'
source_url: https://arxiv.org/abs/2310.13533
tags:
- source
- miou
- data
- entropy
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a solution for the ICCV 2023 Visual Continual
  Learning Challenge focused on test-time adaptation (TTA) for semantic segmentation.
  The task involves adapting a model to gradually changing domains in video sequences,
  specifically a synthetic driving dataset (SHIFT) with varying weather and lighting
  conditions.
---

# Technical Report for ICCV 2023 Visual Continual Learning Challenge: Continuous Test-time Adaptation for Semantic Segmentation

## Quick Facts
- arXiv ID: 2310.13533
- Source URL: https://arxiv.org/abs/2310.13533
- Reference count: 8
- This paper presents a solution that achieved 3rd place in the ICCV 2023 Visual Continual Learning Challenge with an innovation award.

## Executive Summary
This paper presents a solution for the ICCV 2023 Visual Continual Learning Challenge focused on test-time adaptation (TTA) for semantic segmentation. The task involves adapting a model to gradually changing domains in video sequences, specifically a synthetic driving dataset (SHIFT) with varying weather and lighting conditions. The proposed method builds upon the entropy minimization approach from the TENT baseline, introducing three key modifications: dynamic batch normalization (BN) statistics update, entropy-based pixel filtering, and adapting only the backbone's BN weights. The dynamic BN update adjusts the statistics based on the severity of domain shift, while the pixel filtering removes uncertain predictions from the adaptation process. Experiments show that each modification improves performance, with the final method achieving 3rd place in the challenge and an innovation award. The method demonstrates strong performance without relying on external pretrained models or specialized data augmentations, highlighting its generalizability across different scenarios.

## Method Summary
The proposed method extends the TENT baseline for test-time adaptation by implementing three modifications: (1) dynamic batch normalization statistics update that interpolates between source and current batch statistics based on symmetric KL divergence of their distributions, (2) entropy-based pixel filtering that masks uncertain predictions above a threshold during loss computation, and (3) adaptation limited to backbone BN weights while keeping the segmentation head fixed. The method uses a DeepLabv3+ model with ResNet50 backbone and adapts to the SHIFT dataset's gradually changing weather and lighting conditions. The dynamic BN update parameter β is controlled by γ and α values (0.1 and 0.005 respectively), while the entropy threshold is set at 0.3×ln(14). The approach successfully handles both gradual domain shifts (weather changes) and abrupt shifts (day-to-night transitions) without requiring external models or specialized augmentations.

## Key Results
- Achieved 3rd place in the ICCV 2023 Visual Continual Learning Challenge with an innovation award
- Dynamic BN statistics update improved performance by adjusting interpolation weights based on KL divergence of distribution shifts
- Entropy-based pixel filtering enhanced adaptation reliability by excluding uncertain predictions from the loss calculation
- Adapting only backbone BN weights while keeping segmentation head fixed provided optimal balance between adaptation and stability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic batch normalization statistics update improves adaptation by interpolating between source statistics and current batch statistics based on KL divergence of their distributions.
- Mechanism: The method calculates the distance between previous and current batch distributions using symmetric KL divergence, then adjusts the interpolation weight β dynamically. When the distribution shift is large, more weight is given to current batch statistics; when the shift is small, more weight is retained from source statistics.
- Core assumption: The degree of domain shift can be reliably measured by KL divergence between batch distributions, and this metric correlates with adaptation performance.
- Evidence anchors:
  - [abstract] "The dynamic BN update adjusts the statistics based on the severity of domain shift"
  - [section 4.1] "We utilize the symmetric KL divergence as a measure of distance between distributions D(ϕt−1, ϕT t) to adjust the value of β accordingly to the severity of the distribution shift"
  - [corpus] No direct corpus evidence for this specific mechanism
- Break condition: If the KL divergence metric fails to capture the true nature of domain shift, or if the exponential moving average smoothing causes lag in adaptation to rapid changes.

### Mechanism 2
- Claim: Entropy-based pixel filtering makes the entropy minimization process more reliable by excluding uncertain predictions from the adaptation loss calculation.
- Mechanism: During adaptation, pixels with prediction entropy above a threshold are masked out and excluded from backpropagation. This prevents the model from learning from potentially incorrect pseudo-labels.
- Core assumption: High entropy predictions are more likely to be incorrect, and excluding them improves the quality of adaptation feedback.
- Evidence anchors:
  - [abstract] "the pixel filtering removes uncertain predictions from the adaptation process"
  - [section 4.2] "Pixels with predictions having an entropy higher than the predefined, constant threshold are masked and do not participate in the backpropagation process"
  - [corpus] No direct corpus evidence for this specific mechanism
- Break condition: If the entropy threshold is set too high (excluding too many pixels) or too low (including too many uncertain predictions), or if the relationship between entropy and prediction correctness doesn't hold for certain types of domain shifts.

### Mechanism 3
- Claim: Adapting only the backbone's batch normalization weights while keeping the segmentation head fixed provides better performance than adapting the entire model.
- Mechanism: The method freezes the segmentation head and only updates the BN parameters in the ResNet50 backbone during test-time adaptation, which reduces the risk of catastrophic forgetting while still allowing feature adaptation.
- Core assumption: The segmentation head learned during source training contains valuable information that should be preserved, and only the feature extraction part needs adaptation to handle domain shift.
- Evidence anchors:
  - [abstract] "adapting only the backbone's BN weights"
  - [section 4] "For segmentation, we only adapt the BN weights of the backbone (ResNet50), leaving the segmentation head fixed"
  - [section 5.4] Table 4 shows that adapting only backbone BN weights achieves the best results compared to other configurations
- Break condition: If the segmentation head becomes incompatible with the adapted features, or if the domain shift requires changes to the segmentation logic itself.

## Foundational Learning

- Concept: Domain adaptation and test-time adaptation
  - Why needed here: The challenge involves adapting a model to gradually changing domains in video sequences without access to ground truth labels during test time
  - Quick check question: What's the difference between traditional domain adaptation and test-time adaptation?

- Concept: Entropy minimization for adaptation
  - Why needed here: The base method (TENT) uses entropy minimization to update BN weights, which the proposed method builds upon
  - Quick check question: How does entropy minimization work as an adaptation criterion?

- Concept: Batch normalization statistics and domain shift
  - Why needed here: The method dynamically adjusts BN statistics based on domain shift severity, which is central to the adaptation approach
  - Quick check question: Why do batch normalization statistics need to be updated during domain adaptation?

## Architecture Onboarding

- Component map: Input frame -> Feature extraction (ResNet50 backbone) -> Segmentation (DeepLabv3+ head) -> Entropy calculation -> KL divergence computation -> Dynamic β update -> BN statistics interpolation -> Loss calculation with pixel filtering -> Backpropagation
- Critical path: Input frame → Feature extraction → Segmentation → Entropy calculation → KL divergence computation → Dynamic β update → BN statistics interpolation → Loss calculation with pixel filtering → Backpropagation
- Design tradeoffs: Adapting only backbone BN weights vs. full model adaptation (reduced flexibility vs. reduced risk of forgetting), dynamic vs. static BN statistics (adaptability vs. stability), entropy filtering vs. no filtering (reliability vs. information loss).
- Failure signatures: Performance degradation when domain shift is too rapid for dynamic statistics to track, poor adaptation when entropy filtering threshold is inappropriate, or when KL divergence fails to capture the true nature of distribution shift.
- First 3 experiments:
  1. Test the dynamic BN statistics update alone with different γ and α parameters to find optimal values
  2. Test entropy-based pixel filtering with different threshold values to determine the optimal balance
  3. Compare the full method against baselines on the validation split to verify performance improvements

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal method for dynamically adjusting batch normalization statistics during test-time adaptation for semantic segmentation?
- Basis in paper: [explicit] The paper proposes a dynamic batch normalization statistics update method but notes that the significance of the distribution shift varies between sequences and that there is a need for a method that adjusts statistics used in BN accordingly.
- Why unresolved: While the paper presents a dynamic approach using symmetric Kullback-Leibler divergence to adjust the influence of source and current batch statistics, it does not explore alternative methods or compare its approach to other potential solutions for dynamic BN adjustment.
- What evidence would resolve it: Comparative experiments evaluating the proposed dynamic BN method against other potential approaches for adjusting batch normalization statistics during test-time adaptation, including different distance metrics or adaptation strategies.

### Open Question 2
- Question: How can test-time adaptation methods be improved to handle both gradual and abrupt domain shifts in video sequences?
- Basis in paper: [explicit] The analysis shows that the magnitude of the distribution shift varies between sequences, with some showing gradual changes (weather conditions) and others showing more abrupt changes (time of day to night). The paper suggests that the developed method should be flexible and able to adapt the model to both gradual and abrupt changes.
- Why unresolved: While the paper implements a dynamic BN statistics update to handle varying degrees of domain shift, it does not explore other potential methods for improving adaptation to both gradual and abrupt changes, such as adaptive learning rates or more sophisticated domain shift detection mechanisms.
- What evidence would resolve it: Comparative experiments evaluating the proposed method against other approaches designed to handle both gradual and abrupt domain shifts, including different adaptation strategies or domain shift detection methods.

### Open Question 3
- Question: What is the optimal threshold for entropy-based pixel filtering during test-time adaptation for semantic segmentation?
- Basis in paper: [explicit] The paper implements an entropy-based pixel filtering approach but notes that discarding the whole images could be sub-optimal, considering the low number of images in sequences and the segmentation task. It presents results with different entropy thresholds but does not explore the full range of possible thresholds or their impact on different types of domain shifts.
- Why unresolved: The paper only tests a limited range of entropy thresholds and does not explore how the optimal threshold might vary depending on the type or severity of domain shift, or how it might interact with other components of the adaptation method.
- What evidence would resolve it: Extensive experiments exploring a wider range of entropy thresholds, their impact on different types of domain shifts, and their interaction with other components of the adaptation method.

## Limitations
- The dynamic BN statistics update relies on KL divergence as a distance metric without theoretical justification for its effectiveness in controlling adaptation rate
- The entropy threshold of 0.3×ln(14) is empirically determined without sensitivity analysis or exploration of optimal values for different domain shift scenarios
- Adapting only backbone BN weights may limit flexibility when more substantial adaptation is required for certain types of domain changes

## Confidence
- High Confidence: The entropy-based pixel filtering mechanism is well-justified theoretically, as high entropy predictions are indeed more likely to be incorrect. The experimental evidence showing performance improvements when this component is added is clear and consistent.
- Medium Confidence: The dynamic BN statistics update shows promise, but the specific parameterization (γ=0.1, α=0.005) and the use of symmetric KL divergence as the distance metric are based on empirical tuning rather than theoretical justification. The effectiveness may vary across different domain shift scenarios.
- Low Confidence: The claim that adapting only backbone BN weights is superior to full model adaptation is supported by the presented experiments, but the comparison is limited to the specific challenge dataset and may not generalize to other domain adaptation scenarios.

## Next Checks
1. **Cross-domain generalization test**: Evaluate the method on a different domain adaptation dataset (e.g., synthetic-to-real adaptation) to verify if the dynamic BN statistics update and entropy filtering mechanisms generalize beyond the SHIFT dataset.

2. **Ablation study with varying adaptation speeds**: Systematically test the method on sequences with different rates of domain shift to determine if the KL divergence-based dynamic adjustment appropriately scales the adaptation rate across varying domain change speeds.

3. **Theoretical analysis of entropy threshold**: Conduct a sensitivity analysis by testing multiple entropy threshold values (0.1×ln(14) to 0.5×ln(14)) to determine if the chosen value of 0.3×ln(14) is optimal or if the method is robust to threshold variations.