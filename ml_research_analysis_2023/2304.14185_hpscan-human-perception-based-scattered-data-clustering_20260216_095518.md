---
ver: rpa2
title: 'HPSCAN: Human Perception-Based Scattered Data Clustering'
arxiv_id: '2304.14185'
source_url: https://arxiv.org/abs/2304.14185
tags:
- cluster
- data
- clustering
- human
- agreement
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ClusterNet is a learned clustering model that directly operates
  on scattered data to predict human-perceived cluster separations. The model uses
  a modified PointNet++ architecture and is trained on a large-scale dataset of 7,320
  human-annotated scatterplots from real-world data.
---

# HPSCAN: Human Perception-Based Scattered Data Clustering

## Quick Facts
- arXiv ID: 2304.14185
- Source URL: https://arxiv.org/abs/2304.14185
- Reference count: 40
- Primary result: ClusterNet achieves 81.9% agreement with human annotators on clustering tasks

## Executive Summary
ClusterNet is a learned clustering model that directly operates on scattered point data to predict human-perceived cluster separations. Trained on 7,320 human-annotated scatterplots, it uses a modified PointNet++ architecture with a novel contrastive loss function to enable order-invariant segmentation and meta-classification learning. The model demonstrates superior performance compared to ten state-of-the-art clustering techniques, with particular robustness to human annotation variability.

## Method Summary
The approach uses a modified PointNet++ architecture that consumes raw point coordinates (x,y,0) rather than rendered images, bypassing visual encoding biases. A novel contrastive loss function reformulates clustering as pairwise similarity prediction, making the model invariant to cluster ID permutations. The model is trained on a large crowdsourced dataset with explicit noise handling through weighted loss terms, achieving 81.9% agreement with human annotators.

## Key Results
- ClusterNet achieves 81.9% average agreement score with human annotators
- Outperforms ten state-of-the-art clustering techniques
- Demonstrates robustness through variability in human annotations

## Why This Works (Mechanism)

### Mechanism 1
ClusterNet learns perceptual clustering by operating directly on scattered point data rather than rendered scatterplot images. Using a modified PointNet++ architecture, the model consumes raw point coordinates and predicts cluster assignments. This bypasses visual encoding biases (color, shape, size) that would otherwise be learned from images, ensuring predictions reflect true spatial cluster perception. The core assumption is that visual encodings do not influence human-perceived clustering; spatial proximity and density are the primary perceptual cues.

### Mechanism 2
Order-invariant contrastive meta-classification enables learning without cluster label permutations. The model formulates clustering as pairwise similarity prediction using a similarity matrix S. Positive pairs are points in the same cluster; negative pairs are in different clusters. This binary classification framework is invariant to cluster ID permutations and point ordering, allowing stable gradient propagation. The core assumption is that cluster IDs are arbitrary labels; only the grouping structure matters for perception.

### Mechanism 3
Robustness to human annotation variability is achieved by training on a diverse crowdsourced dataset with explicit noise handling. The training set includes 7,320 annotations from 384 participants, introducing natural variability. A weighted contrastive loss (ωD) balances cluster sizes and pushes dissimilar points apart. A noise loss term (Lnoise) handles outliers and unclustered points, preventing overfitting to any single annotation style. The core assumption is that human annotators agree on perceptual clusters >80% of the time; variability in annotations improves generalization.

## Foundational Learning

- **Point cloud learning with PointNet++**: Why needed here: Scatterplot data is unstructured; traditional CNNs require regular grids. PointNet++ processes unordered point sets while preserving spatial relationships. Quick check question: Can you explain why farthest point sampling (FPS) is used in PointNet++ and how it helps with hierarchical feature extraction?

- **Contrastive learning and meta-classification**: Why needed here: Multi-class clustering labels are arbitrary; contrastive learning reframes the task as pairwise similarity, sidestepping label permutation issues. Quick check question: What is the difference between positive and negative samples in the similarity matrix S, and how do they affect the contrastive loss?

- **Agreement metrics for subjective data**: Why needed here: Human clustering is subjective; metrics like Vanbelle Kappa Index and the custom κα measure how well model predictions align with group consensus. Quick check question: How does the κα metric differ from traditional inter-rater reliability measures, and why is it useful for evaluating perceptual clustering?

## Architecture Onboarding

- **Component map**: Input (N=512 point coordinates) -> Encoder (4-layer PointNet++ hierarchy) -> Output heads (Cluster probability P (NxC) and noise probability Pnoise (Nx1)) -> Loss (weighted sum of contrastive loss and noise loss) -> Optimizer (Adam)

- **Critical path**: 1. Data augmentation → 2. Encoder feature extraction → 3. Similarity matrix construction → 4. Pairwise loss computation → 5. Noise loss → 6. Parameter update

- **Design tradeoffs**: Fixed point count (512) simplifies batching but requires sampling/downsampling real datasets. Contrastive loss is O(N²) in memory/compute; manageable for N=512 but scales poorly. Using cluster ID 0 for noise simplifies binary conversion but imposes a labeling convention.

- **Failure signatures**: High κα but low κv: Model agrees with one rater but not group consensus → overfitting to single annotation style. Very low noise accuracy: Model merges outliers into clusters → contrastive loss not strong enough to separate noise. Degraded performance on >6 clusters: Training data imbalance leads to poor generalization.

- **First 3 experiments**: 1. Train with D=1.0 and evaluate on a held-out scatterplot with 3 obvious clusters; check if clusters are correctly separated. 2. Train with Tagree=90% and test on a scatterplot with ambiguous clusters; observe if model becomes too conservative. 3. Fine-tune a converged model with D=0.1 and lr=1e-7 on single-cluster cases; verify if cluster merging improves without hurting multi-cluster performance.

## Open Questions the Paper Calls Out

### Open Question 1
How does ClusterNet perform on point clouds with significantly more than 512 points? The authors acknowledge this as a limitation since PointNet++ has O(n²) complexity and they limited themselves to N=512 points to keep computational costs low. Testing ClusterNet on larger point clouds (e.g., 1000+ points) and comparing its performance to state-of-the-art clustering algorithms while measuring computational efficiency would resolve this.

### Open Question 2
How does varying visual encoding (e.g., point size, color, shape) affect ClusterNet's clustering performance? The authors argue that ClusterNet should not learn on image data to avoid learning visual encoding effects, but they also acknowledge that their crowdsourced study used a fixed visual encoding. Training and evaluating ClusterNet on datasets with varied visual encodings, and analyzing how performance changes with different encodings, would resolve this.

### Open Question 3
Can ClusterNet be effectively used to optimize scatterplot visualization parameters (e.g., axis scaling, point opacity) to improve human perception of clusters? The authors mention this as a potential future research direction. Developing a method to use ClusterNet's clustering predictions to guide parameter optimization, and evaluating whether the optimized parameters lead to improved human clustering performance on test datasets, would resolve this.

## Limitations
- The computational scalability of the O(N²) pairwise contrastive loss is not addressed for larger datasets
- The assumption that bypassing visual encodings improves perceptual clustering is stated but not experimentally verified against image-based approaches
- The noise handling via cluster ID 0 is a design choice that may not generalize if other labeling conventions are used

## Confidence
- High: The mechanism of using PointNet++ for unstructured point data and the pairwise contrastive loss formulation are well-grounded and supported by the evidence
- Medium: The robustness to annotation variability is plausible given the large, diverse dataset, but the critical threshold for human agreement is not specified
- Low: The assumption that visual encodings do not influence human-perceived clustering is asserted but not empirically validated

## Next Checks
1. Validate the assumption about visual encodings by comparing ClusterNet's performance on point coordinates vs. rendered scatterplot images with color/size variations
2. Test the computational limits of the contrastive loss by evaluating performance on datasets with N > 512 points to identify scaling bottlenecks
3. Analyze the impact of the cluster ID 0 convention for noise by retraining with an alternative labeling scheme and comparing results