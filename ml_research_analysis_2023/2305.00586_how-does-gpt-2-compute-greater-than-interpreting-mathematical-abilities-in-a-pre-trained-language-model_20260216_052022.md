---
ver: rpa2
title: 'How does GPT-2 compute greater-than?: Interpreting mathematical abilities
  in a pre-trained language model'
arxiv_id: '2305.00586'
source_url: https://arxiv.org/abs/2305.00586
tags:
- year
- circuit
- gpt-2
- figure
- mlps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper uses mechanistic interpretability to explain how GPT-2
  small performs a basic mathematical operation (greater-than) on a simple task involving
  predicting valid end years in sentences like "The war lasted from the year 1732
  to the year 17". They first identify a circuit in GPT-2 - a small subset of its
  computational graph - that computes this task's output.
---

# How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model

## Quick Facts
- arXiv ID: 2305.00586
- Source URL: https://arxiv.org/abs/2305.00586
- Reference count: 40
- Primary result: GPT-2 computes greater-than using a complex but general mechanism that activates across diverse contexts

## Executive Summary
This paper investigates how GPT-2 small performs basic mathematical operations, specifically the greater-than comparison, through mechanistic interpretability. The researchers identify a circuit within GPT-2 that computes this operation when predicting valid end years in sentences like "The war lasted from the year 1732 to the year 17". They demonstrate that this circuit consists of attention heads that detect the start year and multi-layer perceptrons that boost probabilities for years greater than the start year, revealing how a pre-trained language model can perform mathematical reasoning.

## Method Summary
The paper employs mechanistic interpretability techniques, particularly path patching, to analyze GPT-2's computational graph. The researchers generate templated sentences with start years and measure GPT-2's predictions using probability difference and cutoff sharpness metrics. They systematically ablate and patch components in GPT-2 to identify which attention heads and MLPs contribute to the greater-than operation, then use logit lens and PCA to understand how these components transform information to compute the comparison.

## Key Results
- GPT-2 uses a circuit of attention heads and MLPs to compute greater-than operations on year-span prediction tasks
- Individual neurons within MLPs contribute sparsely but collectively to the greater-than computation
- The circuit generalizes to other greater-than scenarios but fails on less-than and equal-to operations
- Attention heads identify the start year through structured information transmission to downstream MLPs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-2 computes greater-than using a circuit of multi-layer perceptrons (MLPs) that boost probabilities for years greater than the start year
- Mechanism: The circuit identifies the start year (YY) through attention heads, then MLPs 9-11 apply transformations to the residual stream that create an upper-triangular pattern in logit space, upweighting years greater than YY
- Core assumption: The circuit components (attention heads and MLPs) work together in a sequential pipeline where attention heads detect YY and MLPs compute the comparison
- Evidence anchors:
  - [abstract] "GPT-2 small's final multi-layer perceptrons boost the probability of end years greater than the start year"
  - [section 3.3] "MLP 8's mostly influences downstream MLPs... MLPs 9, 10, and 11 appear to compute the greater-than operation in tandem"
  - [corpus] Weak - related papers discuss circuit discovery but don't specifically validate the MLP-based greater-than mechanism
- Break condition: If attention heads fail to properly identify YY, or if MLPs cannot compose their individual neuron contributions effectively, the circuit would fail to compute greater-than

### Mechanism 2
- Claim: Individual neurons within MLPs compose to compute greater-than through additive contributions in logit space
- Mechanism: No single neuron computes greater-than alone. Instead, multiple neurons each contribute partial patterns that, when summed, approximate the greater-than operation through their combined logit lens effects
- Core assumption: The MLP output is a sum of individual neuron contributions, and these contributions can be sparse yet collectively sufficient
- Evidence anchors:
  - [section 4.2] "Many neurons can compute greater-than when combined... the top-10 neurons perform an imperfect greater-than when summed together"
  - [section 3.3] "we find that neuron contributions to the task are sparse: most neurons can be patched with near zero effect"
  - [corpus] Weak - related circuit papers don't deeply analyze neuron-level composition mechanisms
- Break condition: If the MLP output normalization or activation functions prevent additive composition, or if neuron sparsity is too extreme, the circuit would fail

### Mechanism 3
- Claim: The circuit generalizes to other greater-than scenarios but not to less-than or equal-to operations
- Mechanism: The same MLP-based circuit activates for different prompts that require identifying years greater than a given value, but fails on prompts requiring the opposite comparison
- Core assumption: GPT-2's training data contains sufficient examples of greater-than contexts to learn this circuit, but insufficient examples of less-than contexts for a separate circuit
- Evidence anchors:
  - [section 5] "GPT-2 produced unusual output for some tasks requiring other mathematical operations... GPT-2 does sometimes 'generalize,' using the same circuit in different situations"
  - [section 5] "We hypothesize that GPT-2's behavior on equal-to and less-than tasks reflects its size and training data"
  - [corpus] Weak - related papers don't specifically test circuit generalization across mathematical operations
- Break condition: If the circuit encounters a greater-than task with substantially different context or structure than training examples, or if it encounters enough less-than examples to learn a separate circuit

## Foundational Learning

- Concept: Residual stream and how information flows through transformer layers
  - Why needed here: Understanding how attention heads and MLPs contribute to the final logits through the residual stream is crucial for interpreting the circuit
  - Quick check question: How does the residual stream at the final position relate to the model's output logits?

- Concept: Path patching and its distinction from interchange interventions
  - Why needed here: Path patching allows isolating the effects of specific components on the circuit without affecting downstream components
  - Quick check question: What's the key difference between path patching and interchange interventions in terms of intervention scope?

- Concept: Logit lens and its interpretation for understanding intermediate representations
  - Why needed here: Logit lens helps visualize how attention heads and MLPs transform information in embedding space
  - Quick check question: What does an upper-triangular pattern in a logit lens heatmap indicate about a component's function?

## Architecture Onboarding

- Component map: Input tokens → attention heads (detect YY) → MLPs 8-11 (compute greater-than) → logits → probabilities
- Critical path: Input tokens → attention heads (particularly a7.h10, a8.h11, a9.h1) → MLPs (8-11) → logits → probabilities
- Design tradeoffs: The circuit relies on composition of multiple components rather than a single dedicated greater-than module, trading specificity for parameter efficiency and generalization within the greater-than domain
- Failure signatures: If MLPs 8-11 are ablated, the model loses greater-than ability; if attention heads fail to detect YY, MLPs cannot compute the comparison; if neuron composition fails, individual MLPs cannot produce correct patterns
- First 3 experiments:
  1. Perform path patching on MLP 10 to verify its direct contribution to logits using the 01-dataset
  2. Apply logit lens to a7.h10 to visualize how it communicates YY information in embedding space
  3. Patch individual neurons in MLP 10 to identify which ones contribute most to greater-than computation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does GPT-2's greater-than circuit generalize to other mathematical operations like less-than or equal-to?
- Basis in paper: [inferred] The paper observes that GPT-2 sometimes incorrectly uses the greater-than circuit for less-than tasks and fails at equal-to tasks, suggesting the circuit may not generalize to other operations
- Why unresolved: The paper only tests a small sample of related tasks and does not provide a comprehensive analysis of the circuit's ability to generalize to other mathematical operations
- What evidence would resolve it: Systematic testing of GPT-2's performance on a wide range of mathematical operations using the same circuit analysis approach would determine if the greater-than circuit generalizes to other operations

### Open Question 2
- Question: What are the specific mechanisms by which individual neurons in GPT-2's MLPs contribute to computing greater-than?
- Basis in paper: [explicit] The paper identifies the top-10 most important neurons in MLP 10 and shows how their combined contributions approximate the greater-than operation, but does not fully explain the mechanisms of individual neurons
- Why unresolved: The paper only analyzes the contributions of the top neurons and does not provide a complete understanding of how each neuron's activation patterns relate to the greater-than computation
- What evidence would resolve it: Detailed analysis of the activation patterns and weight matrices of all neurons in the relevant MLPs, combined with ablation studies, would reveal the specific mechanisms by which individual neurons contribute to the greater-than computation

### Open Question 3
- Question: How do the attention heads in GPT-2's greater-than circuit identify and transmit the start year (YY) information to the MLPs?
- Basis in paper: [explicit] The paper shows that attention heads attend to the YY position and transmit structured information to the MLPs, but does not fully explain the mechanisms of this process
- Why unresolved: The paper only provides a high-level description of the attention heads' roles and does not delve into the specific mechanisms by which they identify and transmit the YY information
- What evidence would resolve it: Detailed analysis of the attention patterns, query/key/value matrices, and residual stream representations at the YY position would reveal the specific mechanisms by which attention heads identify and transmit the YY information to the MLPs

### Open Question 4
- Question: How does GPT-2's training data influence the structure and semantics of its greater-than circuit?
- Basis in paper: [inferred] The paper notes that the length of the year-span receiving higher probability likely reflects patterns in GPT-2's training data, suggesting that the circuit's structure and semantics may be influenced by the training data
- Why unresolved: The paper does not investigate the relationship between GPT-2's training data and the structure and semantics of its greater-than circuit
- What evidence would resolve it: Analysis of GPT-2's training data to identify patterns related to year-span prediction and greater-than operations, combined with comparison to the circuit's structure and semantics, would reveal how the training data influences the circuit

## Limitations
- The generalization claims are based on a limited set of related tasks and may not reflect the circuit's true generalization capabilities
- The neuron composition analysis depends on sparsity assumptions that may miss important collective effects from less prominent neurons
- The path patching technique assumes linear separability of component effects, which may not hold due to nonlinear interactions

## Confidence
- High confidence: The core finding that GPT-2 computes greater-than using a circuit involving attention heads and MLPs
- Medium confidence: The specific neuron composition mechanism and generalization claims
- Low confidence: The exact mechanisms of individual neuron contributions and attention head information transmission

## Next Checks
1. Perform systematic ablation of individual components (attention heads and MLPs) in the identified circuit and measure performance degradation on the year-span task to confirm causal relationships
2. Design novel greater-than scenarios with different contexts and structures than the training data to test the circuit's true generalization capabilities
3. Investigate nonlinear interactions between neurons in MLPs 9-11 using more sophisticated techniques than simple patching to understand how they collectively compute greater-than