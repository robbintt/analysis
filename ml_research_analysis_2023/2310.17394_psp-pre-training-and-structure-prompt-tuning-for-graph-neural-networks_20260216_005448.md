---
ver: rpa2
title: 'PSP: Pre-Training and Structure Prompt Tuning for Graph Neural Networks'
arxiv_id: '2310.17394'
source_url: https://arxiv.org/abs/2310.17394
tags:
- graph
- prompt
- node
- tuning
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SAP, a novel structure-based prompting method
  for graph neural networks (GNNs) that unifies pre-training and prompt tuning while
  consistently exploiting structure information in both stages. The key innovation
  is a dual-view contrastive learning approach that aligns latent semantic spaces
  of node attributes and graph structure, coupled with a structure prompt tuning strategy
  that incorporates structure information in prompted graphs to construct more accurate
  prototype vectors and elicit more pre-trained knowledge.
---

# PSP: Pre-Training and Structure Prompt Tuning for Graph Neural Networks

## Quick Facts
- arXiv ID: 2310.17394
- Source URL: https://arxiv.org/abs/2310.17394
- Reference count: 40
- Achieves up to 5.82% improvement over runner-up on heterophilous graph node classification

## Executive Summary
This paper introduces SAP, a novel structure-based prompting method for graph neural networks that unifies pre-training and prompt tuning while consistently exploiting structure information in both stages. The key innovation is a dual-view contrastive learning approach that aligns latent semantic spaces of node attributes and graph structure, coupled with structure prompt tuning that incorporates structure information to construct more accurate prototype vectors. Experiments show SAP significantly outperforms state-of-the-art baselines, especially in few-shot scenarios on both homophilous and heterophilous graphs.

## Method Summary
SAP employs dual-view contrastive learning for pre-training, using both MLP (node attributes only) and GNN (node attributes + structure) views with contrastive loss to align their representations. For downstream tasks, it adds prototype nodes to the graph and learns edge weights connecting them to all original nodes, forming more accurate prototypes through structure prompt tuning. The pre-trained model weights are frozen during prompt tuning, with only the edge weights optimized. This approach enables effective knowledge transfer from pre-training to downstream tasks while maintaining structural information throughout both stages.

## Key Results
- Achieves up to 2.97% improvement over runner-up on homophilous graph node classification
- Achieves up to 5.82% improvement over runner-up on heterophilous graph node classification
- Achieves up to 5.71% improvement over runner-up on graph classification tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual-view contrastive learning aligns semantic spaces of node attributes and graph structure
- Mechanism: MLP learns from node attributes only while GNN learns from both attributes and structure; contrastive loss maximizes similarity between corresponding node representations
- Core assumption: Node attribute and structural representations contain complementary information that can be aligned
- Evidence anchors: [abstract] mentions dual-view contrastive learning to align latent semantic spaces; [section 4.1] describes MLP and GNN implementation
- Break condition: If attribute and structure information are not complementary or contrastive learning fails to establish alignment

### Mechanism 2
- Claim: Structure prompt tuning leverages graph structure to improve prototype vector accuracy
- Mechanism: Adds prototype nodes with learnable edge weights connecting to all original nodes, aggregating pre-trained knowledge from unlabeled nodes
- Core assumption: Unlabeled nodes contain useful pre-trained knowledge that can be aggregated through learned edge weights
- Evidence anchors: [abstract] mentions incorporating structure information for accurate prototype vectors; [section 4.2.1] describes learnable adjacency matrix W
- Break condition: If learned edge weights fail to capture meaningful relationships or insufficient unlabeled nodes exist

### Mechanism 3
- Claim: Freezing pre-trained model weights prevents catastrophic forgetting and maintains pre-trained knowledge
- Mechanism: Keeps MLP and GNN weights fixed during prompt tuning, only learns edge weights between prototypes and original nodes
- Core assumption: Pre-trained knowledge is sufficiently general to be transferred through learned connections without fine-tuning
- Evidence anchors: [abstract] mentions unifying pre-training and prompt tuning objectives; [section 4.2.3] describes frozen weights during prompt tuning
- Break condition: If pre-trained knowledge becomes obsolete for downstream task or prompt parameters insufficient for adaptation

## Foundational Learning

- Concept: Contrastive learning and its application to graph data
  - Why needed here: Core mechanism for aligning attribute and structure representations during pre-training
  - Quick check question: What is the difference between instance-level and pair-level contrastive learning in graph settings?

- Concept: Graph neural network message passing and aggregation
  - Why needed here: Understanding how GNN computes node representations from neighbors is essential for dual-view approach
  - Quick check question: How does mean aggregation differ from attention-based aggregation in GNNs?

- Concept: Prototype-based classification and few-shot learning
  - Why needed here: Downstream task uses prototype vectors for classification, making prototype methods crucial
  - Quick check question: How does prototypical contrastive learning differ from standard contrastive learning?

## Architecture Onboarding

- Component map: Pre-training (MLP + GNN + contrastive loss) → Prompt tuning (fixed MLP/GNN + learnable edge weights W) → Inference (similarity comparison between node representations and prototypes)
- Critical path: Pre-training phase produces fixed node representations, prompt tuning learns edge weights to form accurate prototypes, inference uses similarity scores for classification
- Design tradeoffs: Choosing between fine-tuning vs. freezing pre-trained models, balancing dual-view approach complexity against simpler alternatives
- Failure signatures: Poor performance on few-shot tasks indicates ineffective prototype learning; failure on heterophilous graphs suggests structural information not properly utilized
- First 3 experiments:
  1. Run ablation study comparing SAP with SAP-np (no prompt) to verify structure prompt improves performance
  2. Vary ratio of added edges to find optimal parameter count for different graph sizes
  3. Test on both homophilous and heterophilous graphs to verify structure heterophily handling claims

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SAP's performance scale with the number of labeled nodes in few-shot learning, particularly for heterophilous graphs?
- Basis in paper: [explicit] Paper shows larger improvements in heterophilous graphs but doesn't analyze performance scaling with labeled node count
- Why unresolved: Paper provides fixed-shot results but doesn't explore performance changes as labeled nodes increase, crucial for heterophilous graphs where performance may degrade more significantly
- What evidence would resolve it: Additional experiments showing SAP's performance across varying labeled node counts for heterophilous graphs compared to other methods

### Open Question 2
- Question: What is the impact of dual-view contrastive learning on pre-training stage for graphs with different structural properties?
- Basis in paper: [explicit] Paper mentions dual-view contrastive learning but doesn't analyze performance on graphs with varying homophily/heterophily
- Why unresolved: Paper demonstrates effectiveness on various datasets but doesn't explore performance on graphs with different structural properties
- What evidence would resolve it: Additional experiments evaluating SAP on graphs with varying degrees of homophily and heterophily

### Open Question 3
- Question: How does the choice of added edge ratio affect SAP's performance across different graph datasets?
- Basis in paper: [explicit] Paper mentions ratio as tunable hyperparameter and provides some results but lacks comprehensive analysis
- Why unresolved: Paper shows comparable performance with small edges on some datasets but doesn't explore optimal ratios across different graph datasets
- What evidence would resolve it: Additional experiments systematically varying edge ratios across different graph datasets to identify optimal ratios

## Limitations
- Limited theoretical justification for why dual-view contrastive learning works across diverse graph types
- Heavy reliance on assumption that unlabeled nodes contain transferable knowledge
- Freezing pre-trained weights may limit adaptation to domain-specific patterns that diverge from pre-training distribution

## Confidence
- High confidence: Experimental results showing performance improvements on benchmark datasets
- Medium confidence: Theoretical claims about why dual-view approach works due to limited rigorous analysis
- Low confidence: Generalizability claims regarding handling extreme heterophily or very few labeled nodes

## Next Checks
1. Conduct comprehensive ablation study removing each component (dual-view contrastive learning, structure prompt tuning, frozen weights) to quantify individual contributions
2. Systematically vary the number of added edges across different graph sizes and node counts to determine if 20% ratio is optimal or dataset-dependent
3. Evaluate SAP on graphs with extreme heterophily (>80% edges connecting different classes) and very few labeled nodes (1-2 per class) to test claimed robustness