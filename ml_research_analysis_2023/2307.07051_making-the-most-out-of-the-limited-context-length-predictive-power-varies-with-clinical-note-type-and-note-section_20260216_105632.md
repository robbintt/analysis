---
ver: rpa2
title: 'Making the Most Out of the Limited Context Length: Predictive Power Varies
  with Clinical Note Type and Note Section'
arxiv_id: '2307.07051'
source_url: https://arxiv.org/abs/2307.07051
tags:
- notes
- clinical
- discharge
- nursing
- power
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores how to efficiently extract predictive information
  from long clinical notes when context length is limited. The authors propose a framework
  to analyze which sections of clinical notes have the highest predictive power for
  readmission prediction.
---

# Making the Most Out of the Limited Context Length: Predictive Power Varies with Clinical Note Type and Note Section

## Quick Facts
- arXiv ID: 2307.07051
- Source URL: https://arxiv.org/abs/2307.07051
- Authors: 
- Reference count: 3
- Key outcome: This paper explores how to efficiently extract predictive information from long clinical notes when context length is limited. The authors propose a framework to analyze which sections of clinical notes have the highest predictive power for readmission prediction. Using MIMIC-III data, they show that predictive power is unevenly distributed in discharge notes (stronger at beginning and end) but more uniform in nursing notes. They also find that combining different note types improves performance when context length is large, but harms it when context length is small. Their findings suggest that carefully selecting which text sections to include can enable more efficient information extraction from clinical notes for downstream prediction tasks.

## Executive Summary
This study addresses the challenge of extracting predictive information from clinical notes when working with language models that have limited context windows. The authors develop a framework to analyze which sections of different clinical note types contain the most predictive information for 30-day readmission prediction. By systematically sampling different portions of discharge and nursing notes, they demonstrate that predictive power is not uniformly distributed - discharge notes show stronger predictive power at the beginning and end, while nursing notes have more uniform predictive distribution. Their findings reveal that optimal sampling strategies depend critically on both the type of clinical note and the available context length.

## Method Summary
The study uses MIMIC-III data to analyze 40,000 admission records that contain both discharge and nursing notes. A sliding window technique extracts token sections from notes based on a midpoint parameter, allowing systematic exploration of different note sections. The extracted text is fed to either ClinicalBERT (max 512 tokens) or ClinicalLongformer (max 4096 tokens) to predict 30-day readmission. The framework tests different combinations of note types and sections, evaluating performance using AUC ROC to determine which sampling strategies maximize predictive power under different context length constraints.

## Key Results
- Predictive power is unevenly distributed in discharge notes, with stronger predictive information at the beginning and end of documents
- Nursing notes show more uniform predictive power distribution throughout the text
- Combining different note types improves performance when context length is large, but harms performance when context length is small
- The optimal sampling strategy depends critically on the maximum sequence length of the underlying model architecture

## Why This Works (Mechanism)

### Mechanism 1
Different clinical note types exhibit distinct predictive power distributions across their text sections. Discharge notes concentrate predictive information at the beginning and end of the document, while nursing notes have more uniform predictive power distribution throughout. This allows targeted selection of text segments rather than uniform truncation.

### Mechanism 2
Combining different note types improves performance when context length is large, but harms performance when context length is small. With sufficient context, combining discharge notes (strong predictive power at boundaries) with nursing notes (uniform distribution) captures complementary information. With limited context, splitting tokens between note types reduces coverage of the most informative discharge note sections.

### Mechanism 3
The optimal sampling strategy depends on the maximum sequence length of the underlying model architecture. ClinicalLongformer (4096 tokens) can allocate tokens across note types and sections, while ClinicalBERT (512 tokens) requires more conservative allocation focused on high-predictive-power discharge note sections.

## Foundational Learning

- Concept: Clinical note structure and content patterns
  - Why needed here: Understanding that discharge notes are more structured with information concentrated at boundaries, while nursing notes are more uniform, is critical for designing effective sampling strategies
  - Quick check question: Why would discharge notes have stronger predictive power at the beginning and end compared to nursing notes?

- Concept: Context length constraints in transformer models
  - Why needed here: Different models (ClinicalBERT vs ClinicalLongformer) have different maximum sequence lengths, which fundamentally affects how tokens should be allocated across note types and sections
  - Quick check question: How does the maximum sequence length of a model influence the optimal sampling strategy for clinical notes?

- Concept: Sliding window text extraction
  - Why needed here: The sliding window technique allows controlled sampling of different sections of clinical notes based on position parameters, enabling systematic exploration of predictive power distribution
  - Quick check question: What is the purpose of using a sliding window approach when analyzing clinical note sections for predictive power?

## Architecture Onboarding

- Component map:
  - MIMIC-III database -> Note type extractor -> Sliding window extractor -> Clinical language model -> Readmission prediction head

- Critical path:
  1. Preprocess MIMIC-III notes to extract discharge and nursing notes
  2. Apply sliding window with position parameter p to extract text sections
  3. Feed extracted text to appropriate clinical language model
  4. Train model to predict 30-day readmission
  5. Evaluate performance using AUC ROC

- Design tradeoffs:
  - Context length vs. computational efficiency: Longer contexts capture more information but increase compute cost
  - Note type selection vs. information coverage: Combining note types provides complementary information but may dilute focus on high-predictive-power sections
  - Window size vs. positional resolution: Smaller windows allow finer-grained analysis but may miss broader context

- Failure signatures:
  - Performance plateaus or degrades when combining note types with small context lengths
  - No significant difference in performance across different window positions for nursing notes
  - Strong performance differences between ClinicalBERT and ClinicalLongformer on the same input

- First 3 experiments:
  1. Test sliding window extraction on discharge notes with varying position parameters (p = 0.0, 0.5, 1.0) using ClinicalBERT
  2. Compare single note type performance (discharge only vs. first nursing note only) with combined note type performance using ClinicalLongformer
  3. Evaluate the "both" position parameter (first n/2 + last n/2 tokens) against traditional truncation for discharge notes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the predictive power distribution differ between physician notes and other clinical note types?
- Basis in paper: The authors note they did not investigate physician notes due to their scarcity in MIMIC-III, but expect this to be resolved with MIMIC-IV's publication.
- Why unresolved: The study only analyzed nursing notes and discharge notes, excluding physician notes due to limited data availability.
- What evidence would resolve it: Analyzing predictive power distribution in physician notes from MIMIC-IV or other large datasets would directly address this question.

### Open Question 2
- Question: What is the optimal relationship between context size and note type allocation for maximizing predictive power?
- Basis in paper: The authors note that the effect of combining different note types depends on context size, with better performance when context is large but worse when small.
- Why unresolved: The study only explored fixed window sizes and did not systematically investigate the relationship between context size and optimal note type allocation.
- What evidence would resolve it: Systematic experiments varying context sizes and note type allocations across different prediction tasks would clarify this relationship.

### Open Question 3
- Question: How does the predictive power distribution vary based on the specific sections of clinical notes?
- Basis in paper: The authors found that predictive power is unevenly distributed in discharge notes but more uniform in nursing notes, with stronger power at the beginning and end of discharge notes.
- Why unresolved: The study only examined broad sections (beginning, middle, end) and did not explore more granular section-level variations.
- What evidence would resolve it: Detailed analysis of predictive power distribution across specific note sections (e.g., subjective vs objective portions) would provide more nuanced insights.

## Limitations

- The findings are based exclusively on MIMIC-III data, which may not generalize to other hospital systems or patient populations with different documentation practices
- The analysis focuses specifically on 30-day readmission prediction and may not apply to other clinical prediction tasks
- The study does not address whether the observed predictive power distributions remain stable across different time periods or evolve as clinical documentation practices change

## Confidence

- High Confidence: The observation that predictive power varies across note sections is well-supported by the experimental results
- Medium Confidence: The claim that combining note types improves performance with large context but harms it with small context is supported by the data
- Medium Confidence: The characterization of discharge notes having stronger predictive power at boundaries while nursing notes have uniform distribution is based on the experimental evidence

## Next Checks

1. **Cross-Dataset Validation**: Apply the same sampling framework to a different clinical dataset (e.g., eICU or a different hospital system) to verify whether the predictive power distributions hold across institutions with different documentation practices.

2. **Task Transferability**: Test the sampling strategies on at least two additional clinical prediction tasks (e.g., in-hospital mortality and length of stay prediction) to determine if the optimal approaches are task-specific or generalize across different prediction objectives.

3. **Temporal Stability Analysis**: Conduct an analysis of how predictive power distributions change over time by training separate models on different time periods within MIMIC-III, assessing whether the observed patterns remain stable or evolve with changing clinical documentation practices.