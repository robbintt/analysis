---
ver: rpa2
title: Large Language Models can accomplish Business Process Management Tasks
arxiv_id: '2307.09923'
source_url: https://arxiv.org/abs/2307.09923
tags:
- process
- tasks
- textual
- output
- gpt4
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates whether GPT-4, a large language model,
  can perform three business process management (BPM) tasks without extensive prompt
  engineering: mining BPMN models from text, mining declarative process models, and
  assessing RPA suitability of tasks. GPT-4 is given carefully designed prompts to
  output in specific formats.'
---

# Large Language Models can accomplish Business Process Management Tasks

## Quick Facts
- arXiv ID: 2307.09923
- Source URL: https://arxiv.org/abs/2307.09923
- Reference count: 20
- Key outcome: GPT-4 achieves comparable recall to specialized approaches for BPMN mining (50-55%) and outperforms baselines for declarative model mining with examples, while performing similarly to baselines for RPA assessment

## Executive Summary
This paper investigates whether GPT-4 can perform three key business process management (BPM) tasks—mining BPMN models from text, mining declarative process models, and assessing RPA suitability—without extensive prompt engineering. Using carefully designed prompts, the authors demonstrate that GPT-4 performs comparably to or better than existing rule-based solutions across these tasks. The results suggest that large language models can serve as general-purpose tools for BPM tasks, though careful prompt design remains important for optimal performance.

## Method Summary
The authors used GPT-4 with carefully designed prompts to perform three BPM tasks: BPMN model mining from six textual process descriptions, declarative model mining on 104 test sentences, and RPA suitability assessment on 33 process descriptions containing 424 tasks. For each task, prompts included general descriptions, output format specifications, and optional examples. The model's outputs were parsed and evaluated against ground truth annotations or existing benchmarks using metrics like recall, precision, and F1-score. No extensive prompt engineering or fine-tuning was performed.

## Key Results
- GPT-4 achieved 50-55% recall for BPMN mining, comparable to a specialized rule-based approach
- With examples in prompts, GPT-4 outperformed baseline approaches in precision and F1-score for most LTL templates in declarative model mining
- For RPA assessment, GPT-4 performed similarly to baseline overall, with higher F1-scores for user tasks
- Output consistency was high across multiple executions of identical prompts, but performance varied with different prompt formulations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 can perform BPM tasks by following structured prompts that specify output format and provide task context
- Mechanism: The model uses in-context learning from the provided examples and task descriptions to generate outputs in a specific format suitable for further processing
- Core assumption: GPT-4's reasoning capabilities are sufficient to understand BPM concepts and translate natural language descriptions into formal representations
- Evidence anchors: [abstract] "we show that, without extensive configuration or prompt engineering, LLMs perform comparably to or better than existing solutions"; [section] "GPT4 is given carefully designed prompts to output in specific formats"
- Break condition: If the model cannot understand the BPM-specific terminology or the prompt instructions are unclear, the output quality will degrade significantly

### Mechanism 2
- Claim: Including examples in prompts significantly improves performance for classification tasks
- Mechanism: Few-shot learning from provided examples helps the model understand the desired output format and classification criteria
- Core assumption: The examples provided are representative of the task and sufficiently clear to guide the model
- Evidence anchors: [section] "for tasks like this with short input text to be classified and a few classification targets, we recommend that the prompt should include examples"; [section] "Except for the response template, GPT4 outperforms the benchmark and has a high precision value of close to 1" when examples were provided
- Break condition: If examples are too specific or not representative of the general task, the model may overfit to those specific cases

### Mechanism 3
- Claim: Output robustness is higher than input robustness in GPT-4's performance
- Mechanism: The model produces consistent outputs when given the same prompt multiple times, but different prompt formulations by different authors can lead to performance variations
- Core assumption: The model's internal processing is stable for identical inputs, but sensitive to phrasing variations in instructions
- Evidence anchors: [section] "we found that the output is relatively insensitive to different executions of the same prompt"; [section] "With respect to input robustness, the evaluation metrics are worse if no examples for the LTL templates are provided"
- Break condition: If the model experiences context window limitations or encounters particularly ambiguous input, output consistency may break down

## Foundational Learning

- Concept: Business Process Management (BPM) lifecycle and key tasks
  - Why needed here: Understanding BPM concepts is crucial for designing effective prompts and interpreting model outputs
  - Quick check question: What are the main phases of the BPM lifecycle and how do they relate to the tasks evaluated in this paper?

- Concept: Natural Language Processing (NLP) techniques for text extraction
  - Why needed here: The paper relies on GPT-4's NLP capabilities to extract information from textual process descriptions
  - Quick check question: How do rule-based NLP approaches differ from LLM-based approaches in extracting process information?

- Concept: Declarative vs. imperative process modeling
  - Why needed here: The paper evaluates both types of process models, requiring understanding of their differences and representation
  - Quick check question: What are the key differences between declarative and imperative process models, and when would each be preferred?

## Architecture Onboarding

- Component map: Textual process descriptions -> GPT-4 with task-specific prompts -> Structured output (BPMN models, LTL formulas, classifications) -> Parsing and compilation into formal languages

- Critical path:
  1. Create task-specific prompt with clear instructions and examples
  2. Input textual descriptions into GPT-4
  3. Parse and process GPT-4 output into formal representations
  4. Evaluate output against ground truth or benchmarks

- Design tradeoffs:
  - Prompt complexity vs. output quality: More detailed prompts may yield better results but require more effort
  - Example inclusion vs. generalization: Examples improve performance but may limit model flexibility
  - Context window limitations vs. task complexity: Large tasks may need to be broken down

- Failure signatures:
  - Inconsistent outputs for identical prompts
  - Misinterpretation of BPM-specific terminology
  - Incomplete or incorrect extraction of process information
  - Format deviations in generated outputs

- First 3 experiments:
  1. Test output consistency by running identical prompts multiple times
  2. Compare performance with and without examples in the prompt
  3. Evaluate the effect of different prompt formulations by multiple authors

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different prompt formulations impact the performance of LLMs on BPM tasks?
- Basis in paper: [explicit] The paper discusses how different prompts, including those with and without examples, can lead to varying results in LLM performance on BPM tasks.
- Why unresolved: The paper indicates that while some prompts with examples led to better results, the exact impact of different prompt formulations on LLM performance is not fully explored.
- What evidence would resolve it: Systematic experimentation with a variety of prompt formulations and their corresponding LLM outputs would provide clarity on the impact of prompt engineering on performance.

### Open Question 2
- Question: What is the impact of the non-deterministic nature of LLM outputs on the reliability of BPM task solutions?
- Basis in paper: [explicit] The paper mentions that generative LLMs have a temperature parameter that adds variability to the output, and it suggests that future research into the behavior of LLMs and their reaction to different inputs is needed.
- Why unresolved: The paper acknowledges the variability in LLM outputs but does not delve into how this affects the reliability and consistency of solutions for BPM tasks.
- What evidence would resolve it: Longitudinal studies tracking the consistency of LLM outputs over time and across different instances of the same task would shed light on the impact of non-determinism on reliability.

### Open Question 3
- Question: Can LLMs be integrated into BPM tools to generate formalized process models directly?
- Basis in paper: [inferred] The paper discusses the current limitation of LLMs not being able to generate files directly and suggests the need for further translation into formalized languages.
- Why unresolved: The paper indicates a gap between LLM outputs and the direct generation of formalized process models, suggesting that this is an area for future development.
- What evidence would resolve it: Development and testing of a compiler or tool that can translate LLM outputs into formalized process models would demonstrate the feasibility of direct integration into BPM tools.

## Limitations

- The evaluation datasets are relatively small (6 process descriptions for BPMN mining, 104 sentences for declarative models, 424 tasks for RPA assessment)
- No comparison against state-of-the-art specialized BPM tools, only against rule-based benchmarks
- Experiments conducted by a single author, raising questions about prompt sensitivity to different authors

## Confidence

- GPT-4 can perform BPM tasks without extensive prompt engineering: Medium confidence
- Including examples in prompts significantly improves classification performance: High confidence
- Output robustness exceeds input robustness: Medium confidence
- GPT-4 achieves comparable performance to specialized approaches: Low confidence

## Next Checks

1. Cross-author validation: Have at least three different authors design prompts for the same tasks independently and measure performance variance across prompt formulations

2. State-of-the-art comparison: Evaluate GPT-4 against current best-in-class tools for each BPM task (e.g., process mining tools like Disco or Celonis for BPMN mining) on larger, more diverse datasets

3. Real-world deployment test: Apply the GPT-4-based approach to actual business process documentation from multiple organizations and assess performance on real-world complexity, including edge cases and noisy inputs