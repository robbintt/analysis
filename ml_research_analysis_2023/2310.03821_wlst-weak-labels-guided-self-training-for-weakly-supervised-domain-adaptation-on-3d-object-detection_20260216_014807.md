---
ver: rpa2
title: 'WLST: Weak Labels Guided Self-training for Weakly-supervised Domain Adaptation
  on 3D Object Detection'
arxiv_id: '2310.03821'
source_url: https://arxiv.org/abs/2310.03821
tags:
- domain
- labels
- object
- pseudo
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses weakly-supervised domain adaptation (WDA)
  for 3D object detection, where few annotations are available in the target domain.
  The proposed WLST framework incorporates an autolabeler into the self-training pipeline
  to generate more robust and consistent pseudo labels.
---

# WLST: Weak Labels Guided Self-training for Weakly-supervised Domain Adaptation on 3D Object Detection

## Quick Facts
- arXiv ID: 2310.03821
- Source URL: https://arxiv.org/abs/2310.03821
- Authors: 
- Reference count: 31
- Key outcome: WLST framework closes the performance gap between source-only and fully-supervised approaches by up to 94.40% in APBEV and up to 91.34% in AP3D

## Executive Summary
This paper addresses weakly-supervised domain adaptation (WDA) for 3D object detection, where few annotations are available in the target domain. The proposed WLST framework incorporates an autolabeler into the self-training pipeline to generate more robust and consistent pseudo labels. It uses a consistency fusion strategy based on geometric and cross-modality consistency to select high-quality pseudo labels from both the 3D detector and autolabeler. Experiments on three widely used datasets show that WLST outperforms previous state-of-the-art methods on all evaluation tasks.

## Method Summary
WLST addresses WDA for 3D object detection by integrating an autolabeler into a self-training framework. The method uses a 3D detector (PV-RCNN) and an autolabeler that converts 2D bounding boxes to 3D pseudo labels. A consistency fusion strategy combines outputs using geometric consistency (2D IoU) and cross-modality consistency (3D IoU). The framework includes pre-training with random object size rescaling, pseudo-label generation, and iterative model re-training with curriculum data augmentation.

## Key Results
- WLST outperforms previous state-of-the-art methods on all evaluation tasks
- Closes performance gap between source-only and fully-supervised approaches by up to 94.40% in APBEV
- Closes performance gap between source-only and fully-supervised approaches by up to 91.34% in AP3D

## Why This Works (Mechanism)

### Mechanism 1
Incorporating an autolabeler into self-training generates more robust and consistent pseudo labels than 3D detector alone. The autolabeler constrains the 3D search space using 2D bounding boxes, which increases precision by reducing false positives. The 3D detector has a larger Field of View and understands object correlations, providing higher recall. The consistency fusion strategy combines these complementary strengths. Core assumption: 2D bounding boxes provide sufficient geometric constraints to meaningfully reduce the 3D search space for pseudo label generation.

### Mechanism 2
The consistency fusion strategy using geometric and cross-modality consistency effectively selects high-quality pseudo labels. Geometric consistency uses 2D IoU to assess pseudo label existence probability - TP boxes have higher IoU with their corresponding 2D boxes while FP boxes have low IoU. Cross-modality consistency matches pseudo labels from different modalities based on location, dimension, and orientation similarity. Core assumption: The 2D IoU between projected pseudo labels and 2D bounding boxes is a reliable indicator of pseudo label quality.

### Mechanism 3
Pre-training with random object size rescaling makes the model more robust to domain shifts in object size statistics. By randomly rescaling object sizes during pre-training, the model learns to handle diverse object size distributions rather than overfitting to the source domain's specific statistics. Core assumption: Object size distribution differences are a primary source of domain shift in 3D object detection.

## Foundational Learning

- Concept: 3D object detection fundamentals (point clouds, bounding box parameterization, evaluation metrics)
  - Why needed here: The entire framework operates on 3D point cloud data and evaluates using 3D detection metrics (AP3D, APBEV)
  - Quick check question: What are the three main approaches to LiDAR-based 3D object detection mentioned in the paper?

- Concept: Domain adaptation theory and techniques
  - Why needed here: The framework addresses domain adaptation challenges between source and target domains with different sensor configurations and environmental conditions
  - Quick check question: What is the key difference between unsupervised domain adaptation (UDA) and weakly-supervised domain adaptation (WDA)?

- Concept: Self-training and pseudo-label generation
  - Why needed here: The framework uses self-training with pseudo labels generated by both a 3D detector and autolabeler
  - Quick check question: How does the consistency fusion strategy select pseudo labels from the 3D detector and autolabeler outputs?

## Architecture Onboarding

- Component map: 3D detector -> Autolabeler -> Consistency fusion -> Retrained models
- Critical path:
  1. Pre-train 3D detector and autolabeler on source domain
  2. Generate pseudo labels on target domain using both models
  3. Apply consistency fusion strategy to select high-quality pseudo labels
  4. Retrain models on pseudo-labeled target data
  5. Iterate until convergence

- Design tradeoffs:
  - Precision vs recall: Autolabeler prioritizes precision while 3D detector prioritizes recall
  - Computational cost: Adding autolabeler increases computation but improves label quality
  - Annotation cost: Requires 2D bounding boxes on target domain (weak labels) rather than full 3D annotations

- Failure signatures:
  - Low precision: Too many false positive pseudo labels passing the consistency filter
  - Low recall: Too many true positive pseudo labels being filtered out
  - Poor convergence: Performance doesn't improve across iterations
  - Domain mismatch: Model performs poorly on target domain despite training

- First 3 experiments:
  1. Run the framework on a synthetic dataset where you control the domain shift to validate each mechanism independently
  2. Test the autolabeler performance with varying quality of 2D bounding boxes to understand the precision-recall tradeoff
  3. Evaluate the consistency fusion strategy with different IoU thresholds to find the optimal balance between precision and recall

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of WLST change when using different types of 3D object detectors (e.g., point-based, grid-based, point-voxel-based) as the base model? The paper states that WLST is "detector-agnostic" and uses PV-RCNN as the 3D detector in experiments, but does not explore other detector types. This remains unresolved because the paper does not provide comparative results using different 3D object detector architectures.

### Open Question 2
How does the quality of the 2D bounding box annotations (weak labels) affect the performance of WLST? The paper mentions that the annotation cost for weak labels is significantly lower than for strong labels, but does not investigate how the quality of these weak labels impacts the final performance. This remains unresolved because the paper does not provide any analysis on the relationship between the quality of weak labels and the effectiveness of WLST.

### Open Question 3
Can WLST be extended to handle domain adaptation for other object categories beyond vehicles in 3D object detection? The paper focuses on the car category for evaluation, but does not discuss the potential of WLST for adapting to other object categories (e.g., pedestrians, cyclists). This remains unresolved because the paper does not provide any insights into the scalability of WLST to different object categories.

## Limitations
- The effectiveness of the 2D IoU criterion for pseudo label quality assessment lacks direct empirical validation
- The autolabeler architecture and hyperparameters are not fully specified, making exact reproduction difficult
- The claim that random object size rescaling is sufficient to handle domain shifts in object size statistics is not rigorously tested against other domain adaptation techniques

## Confidence
- **High Confidence**: The overall framework architecture and experimental results showing WLST outperforms baseline methods
- **Medium Confidence**: The mechanism by which the consistency fusion strategy improves pseudo label quality
- **Low Confidence**: The specific design choices for autolabeler implementation and IoU threshold selection

## Next Checks
1. Conduct ablation studies on the autolabeler's precision-recall tradeoff by varying 2D bounding box quality and IoU thresholds
2. Test the consistency fusion strategy on datasets with known domain shift characteristics to validate its effectiveness
3. Compare random object size rescaling against alternative domain randomization techniques to isolate its contribution to performance gains