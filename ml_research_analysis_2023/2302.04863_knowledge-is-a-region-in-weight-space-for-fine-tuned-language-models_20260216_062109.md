---
ver: rpa2
title: Knowledge is a Region in Weight Space for Fine-tuned Language Models
arxiv_id: '2302.04863'
source_url: https://arxiv.org/abs/2302.04863
tags:
- ne-tuned
- datasets
- region
- loss
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper studies the relationship between fine-tuned language
  models in weight space. It finds that models fine-tuned on the same dataset form
  tight clusters in weight space, while models fine-tuned on datasets from the same
  task form looser clusters.
---

# Knowledge is a Region in Weight Space for Fine-tuned Language Models

## Quick Facts
- arXiv ID: 2302.04863
- Source URL: https://arxiv.org/abs/2302.04863
- Authors: 
- Reference count: 28
- Key outcome: Models fine-tuned on the same dataset form tight clusters in weight space; traversing between models can yield better-performing models, with centroid-based fine-tuning improving accuracy by 3.06% on average.

## Executive Summary
This paper investigates the relationship between fine-tuned language models in weight space, revealing that models trained on the same dataset cluster tightly while those from related tasks form looser clusters. The authors demonstrate that interpolating within these clusters can produce models that match or exceed the performance of standard fine-tuning, even on unseen tasks. By leveraging this insight, they propose using the centroid of a task-specific cluster as a starting point for efficient fine-tuning, achieving consistent accuracy improvements across multiple datasets.

## Method Summary
The method involves fine-tuning RoBERTa-base on multiple datasets with different random seeds, then analyzing the resulting models in weight space using cosine similarity clustering. Models are interpolated via weighted combinations of their weights, and their performance is evaluated using linear probing on target datasets. The centroid of each cluster is computed and used as a starting point for parameter-efficient fine-tuning (BitFit), which is compared against starting from the pre-trained model.

## Key Results
- Models fine-tuned on the same dataset cluster tightly (98% clustering accuracy)
- Interpolating between models within clusters often yields equal or better performance
- Centroid-based fine-tuning improves average accuracy by 3.06% compared to pre-trained initialization
- Cluster structure is dataset-specific but task-related datasets form looser clusters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Models fine-tuned on the same dataset form tight clusters in weight space.
- Mechanism: Fine-tuning optimizes weights toward a region of low loss specific to the training data; repeated fine-tuning on identical data converges to nearby points in this region.
- Core assumption: The loss landscape contains distinct basins corresponding to different tasks/datasets, and gradient descent reliably finds points within the same basin for repeated training.
- Evidence anchors:
  - [abstract]: "language models that have been fine-tuned on the same dataset form a tight cluster in the weight space"
  - [section]: "models fine-tuned on the same dataset with different random seeds are clustered together... clustering accuracy is 98"
  - [corpus]: Found 25 related papers (using 8). Average neighbor FMR=0.508, average citations=0.0. Top related titles: Task Arithmetic in Trust Region: A Training-Free Model Merging Approach to Navigate Knowledge Conflicts, Time is Encoded in the Weights of Finetuned Language Models, Learning to Interpret Weight Differences in Language Models.
- Break condition: If the dataset is too small or noisy, the basin may be shallow or ill-defined, causing scattered fine-tuned models.

### Mechanism 2
- Claim: Interpolating between models in the same cluster yields models with comparable or better performance.
- Mechanism: The low-loss region is convex; any convex combination of weights from this region remains in the region and thus retains low loss.
- Core assumption: The loss surface within a task-specific basin is convex or nearly convex, so linear interpolation does not leave the basin.
- Evidence anchors:
  - [abstract]: "traversing around the region between the models reaches new models that perform comparably or even better than models obtained via fine-tuning"
  - [section]: "the interpolated models perform comparably or even better than the models they are created from"
  - [corpus]: Weak - only indirect support from task arithmetic literature; explicit convexity not confirmed.
- Break condition: If the basin is highly non-convex or contains multiple local minima, interpolation may cross high-loss regions.

### Mechanism 3
- Claim: Models in the convex hull between fine-tuned models often outperform individual fine-tuned models.
- Mechanism: Averaging weights moves toward the center of the low-loss basin, where the loss gradient is smaller and generalization may be better.
- Core assumption: The center of a basin generalizes better than boundary points found by standard fine-tuning.
- Evidence anchors:
  - [abstract]: "a model created by averaging the weights of fine-tuned models... outperforms the pre-trained model... resulting in an average accuracy improvement of 3.06"
  - [section]: "In fact, in 88% of the times In' models are also better than In – i.e. models fine-tuned on MNLI!"
  - [corpus]: Weak - limited direct empirical evidence for generalization gains from center points.
- Break condition: If the basin is asymmetric or has sharp edges, the centroid may fall into a suboptimal region.

## Foundational Learning

- Concept: Loss landscape geometry in high-dimensional weight space
  - Why needed here: Understanding how fine-tuning moves models through weight space and why certain regions correspond to good performance.
  - Quick check question: What property of the loss landscape allows interpolation between fine-tuned models to maintain low loss?

- Concept: Convex combinations and their geometric interpretation in weight space
  - Why needed here: The paper relies on convex hulls and centroids to find better models; understanding these operations is crucial.
  - Quick check question: Why does averaging weights of fine-tuned models potentially improve performance compared to individual models?

- Concept: Parameter-efficient fine-tuning methods (e.g., BitFit)
  - Why needed here: The practical experiments use BitFit to efficiently fine-tune centroid models; understanding this method is necessary to replicate results.
  - Quick check question: How does BitFit differ from full fine-tuning in terms of which parameters are updated?

## Architecture Onboarding

- Component map: Pre-trained RoBERTa-base -> Fine-tuning pipeline -> Linear probing -> Weight averaging -> BitFit fine-tuning
- Critical path:
  1. Fine-tune multiple models on same/similar datasets
  2. Compute weight differences from pre-trained model
  3. Cluster models in weight space using cosine similarity
  4. Sample/interpolate models within clusters
  5. Evaluate generalized loss across target datasets
  6. Compute centroid model for practical fine-tuning
  7. Apply BitFit fine-tuning starting from centroid

- Design tradeoffs:
  - Using cosine similarity vs. Euclidean distance for clustering (cosine ignores magnitude changes)
  - Full fine-tuning vs. parameter-efficient methods for centroid evaluation
  - Random seeds for reproducibility vs. computational cost of multiple runs

- Failure signatures:
  - Poor clustering despite same-dataset training (indicates basin fragmentation)
  - Interpolation performance drops sharply (basin non-convexity)
  - Centroid model underperforms pre-trained model (centroid outside optimal region)

- First 3 experiments:
  1. Fine-tune 5 models on MNLI with different seeds, compute pairwise cosine distances, verify clustering
  2. Interpolate between MNLI model pairs with α from 0.1 to 0.9, evaluate on MNLI and general datasets
  3. Compute centroid of MNLI models, apply BitFit fine-tuning on SST-2, compare to pre-trained baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How far can models be extrapolated from the centroid before performance degrades significantly?
- Basis in paper: [explicit] The paper shows that extrapolation beyond the region defined by fine-tuned models leads to rapid performance degradation (Section 6).
- Why unresolved: The paper only tests extrapolation up to a certain distance (alpha values up to 32) and doesn't explore the exact boundary of the region.
- What evidence would resolve it: Systematically testing extrapolation at increasing distances and identifying the point where performance drops below a certain threshold.

### Open Question 2
- Question: Are the regions in weight space specific to the pre-trained model used, or are they generalizable across different pre-trained models?
- Basis in paper: [explicit] The paper briefly mentions that models fine-tuned on the same datasets from different pre-trained models cluster separately (Appendix B).
- Why unresolved: The paper doesn't extensively explore the impact of different pre-trained models on the formation and characteristics of regions.
- What evidence would resolve it: Replicating the experiments with multiple pre-trained models and comparing the resulting regions.

### Open Question 3
- Question: Can the regions in weight space be used to predict the performance of models on unseen tasks?
- Basis in paper: [inferred] The paper shows that models within a region perform well on tasks related to the datasets used for fine-tuning, suggesting potential generalization.
- Why unresolved: The paper doesn't explicitly test the predictive power of regions for unseen tasks.
- What evidence would resolve it: Training models on a set of tasks, identifying the regions in weight space, and testing the performance of models within those regions on a separate set of unseen tasks.

## Limitations
- The convexity assumption for safe interpolation lacks formal proof and extensive empirical validation
- Quantitative bounds on intra-cluster variance are not provided, limiting precision of "tight" cluster claims
- The mechanism behind centroid model generalization benefits (center vs. averaging effect) is not fully isolated

## Confidence
- High confidence: Dataset-specific clustering (98% accuracy empirically verified)
- Medium confidence: Task-level clustering patterns (consistent but less quantified)
- Medium confidence: Interpolation performance gains (demonstrated but mechanism unclear)
- Medium confidence: Centroid model improvements (statistically significant but limited ablation)

## Next Checks
1. Quantify basin geometry: Measure intra-cluster variance and test interpolation across task boundaries to verify convexity assumptions.
2. Ablation on centroid vs. average: Compare centroid model performance against simple weight averaging to isolate geometric effects.
3. Cross-architecture validation: Test clustering and interpolation patterns on BERT and other architectures to assess generalizability.