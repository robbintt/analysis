---
ver: rpa2
title: Retrofitting Light-weight Language Models for Emotions using Supervised Contrastive
  Learning
arxiv_id: '2310.18930'
source_url: https://arxiv.org/abs/2310.18930
tags:
- learning
- emotion
- embeddings
- emotions
- bert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel retrofitting method to induce emotion
  aspects into pre-trained language models (PLMs) such as BERT and RoBERTa. The method
  updates pre-trained network weights using supervised contrastive learning so that
  text fragments exhibiting similar emotions are encoded nearby in the representation
  space, and fragments with different emotion content are pushed apart.
---

# Retrofitting Light-weight Language Models for Emotions using Supervised Contrastive Learning

## Quick Facts
- arXiv ID: 2310.18930
- Source URL: https://arxiv.org/abs/2310.18930
- Reference count: 23
- Primary result: BERTEmo and RoBERTaEmo achieve ~1% improvement in F1-score on sentiment analysis and sarcasm detection tasks while preserving linguistic knowledge.

## Executive Summary
This paper presents a novel retrofitting method that induces emotion awareness into pre-trained language models (PLMs) like BERT and RoBERTa using supervised contrastive learning. The method updates PLM weights so that text fragments with similar emotions are encoded nearby in representation space while maintaining the linguistic knowledge from pre-training through vector space preservation regularization. The resulting emotion-aware models, BERTEmo and RoBERTaEmo, demonstrate improved performance on sentiment analysis and sarcasm detection tasks, with even greater benefits in few-shot learning settings.

## Method Summary
The approach retrofits pre-trained BERT and RoBERTa models using supervised contrastive learning on the go_emotions dataset. A projection head maps [CLS] embeddings to 64-dimensional space, and the contrastive loss groups similar emotions while the vector space preservation (VSP) term prevents loss of linguistic knowledge. The method uses MPerClassSampler or StratifiedSampler for batch creation and evaluates performance through clustering/retrieval metrics on the emotion dataset and downstream task F1-scores.

## Key Results
- BERTEmo and RoBERTaEmo achieve approximately 1% improvement in F1-score on sentiment analysis and sarcasm detection tasks
- Emotion-aware models show better performance in few-shot learning settings compared to pre-trained baselines
- Clustering metrics (AMI, ARI, FMS) and retrieval metrics (MRR, P@1, MAP@r) demonstrate improved emotion awareness while preserving embedding space topology

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Supervised contrastive learning improves emotion-aware sentence representations by pushing similar emotion examples closer together in embedding space while preserving linguistic knowledge through regularization.
- Mechanism: The retrofitting method uses supervised contrastive learning (SCL) loss to update PLM network weights. SCL maximizes similarity between embeddings of text fragments with the same emotion label and minimizes similarity for different emotion labels. A vector space preservation (VSP) regularization term ensures linguistic knowledge from pre-training is not lost during emotion retrofitting.
- Core assumption: The go_emotions dataset provides high-quality, representative emotion labels that PLMs can learn from without overfitting.
- Evidence anchors:
  - [abstract]: "Our method updates pre-trained network weights using contrastive learning so that the text fragments exhibiting similar emotions are encoded nearby in the representation space, and the fragments with different emotion content are pushed apart."
  - [section 4]: "While Enc(·) comes from step 2, Encfixed(·) is a fixed version where the network weights from PLM are frozen, providing the snapshot of the PLM before the application of contrastive learning."
  - [corpus]: The go_emotions dataset provides 45,446 examples with single emotion labels across 27 categories. Corpus evidence is moderate - while the dataset is large, it's limited to Reddit comments which may introduce domain-specific bias.
- Break condition: If the emotion labels in go_emotions are noisy or the dataset is too domain-specific, the retrofitting process could introduce incorrect emotion associations or fail to generalize to other domains.

### Mechanism 2
- Claim: Vector space preservation regularization prevents catastrophic forgetting of linguistic knowledge during emotion retrofitting.
- Mechanism: The VSP term in the loss function (Lvsp) measures the mean squared difference between sentence embeddings from the updated encoder (Enc) and the frozen pre-trained encoder (Encfixed). This constraint ensures that while the model learns emotion-specific representations, the core linguistic knowledge remains intact.
- Core assumption: The original PLM representations contain valuable linguistic information that should be preserved during retrofitting.
- Evidence anchors:
  - [section 4]: "While doing so, it also ensures that the linguistic knowledge already present in PLMs is not inadvertently perturbed."
  - [section 5.3.1]: "While the VSP loss helps in preserving the topology of the sentence embedding space, the contrastive loss brings robustness to our method."
  - [corpus]: The go_emotions dataset is used to retrofit BERT and RoBERTa, which were originally trained on massive web corpora. Corpus evidence is moderate - the effectiveness of VSP depends on the quality and diversity of the original PLM training data.
- Break condition: If the regularization strength (λ) is too high, the model may not learn meaningful emotion distinctions. If too low, the model may lose important linguistic features.

### Mechanism 3
- Claim: Supervised contrastive learning provides better emotion-aware representations than transfer learning or multi-task learning approaches.
- Mechanism: Unlike transfer learning which fine-tunes the entire model on emotion recognition, or multi-task learning which jointly optimizes for emotion and downstream tasks, supervised contrastive learning directly optimizes the embedding space for emotion similarity. This creates more discriminative emotion-aware representations that transfer better to downstream tasks.
- Core assumption: Directly optimizing the embedding space for emotion similarity creates more useful representations than optimizing for classification accuracy.
- Evidence anchors:
  - [section 5.2]: "The ∗Emo models retrofitted by our method are not only emotion-aware (high values for clustering and retrieval metrics) but also preserve the topology of the embedding space (low values for ∆emb)."
  - [section 5.3]: "The PLMs retrofitted for emotions using transfer learning (TLearn) and multi-task learning (MTL) perform better than the pre-trained baselines on both tasks, exhibiting the positive impact the external emotion signals provide."
  - [corpus]: The go_emotions dataset provides emotion labels for retrofitting, while downstream tasks (sentiment analysis, sarcasm detection) test the effectiveness of the learned representations. Corpus evidence is strong - the ablation studies directly compare different learning approaches.
- Break condition: If the downstream tasks have different optimal representations than emotions, the emotion-aware embeddings may not provide advantages.

## Foundational Learning

- Concept: Supervised Contrastive Learning (SCL)
  - Why needed here: SCL is the core mechanism for creating emotion-aware representations by grouping similar emotions and separating different emotions in embedding space.
  - Quick check question: What is the key difference between supervised and self-supervised contrastive learning?

- Concept: Vector Space Preservation (VSP)
  - Why needed here: VSP prevents the retrofitting process from destroying the linguistic knowledge already present in PLMs while adding emotion awareness.
  - Quick check question: How does the VSP term in the loss function work mathematically?

- Concept: Embedding Space Evaluation
  - Why needed here: Proper evaluation of whether the retrofitted models actually create emotion-aware representations requires clustering and retrieval metrics.
  - Quick check question: What clustering metrics are used to evaluate emotion awareness in the paper?

## Architecture Onboarding

- Component map: Encoder (PLM) -> Projection Head -> Contrastive Loss + VSP Loss -> Updated PLM weights
- Critical path: Encoder → Projection Head → Contrastive Loss + VSP Loss → Updated PLM weights
- Design tradeoffs:
  - Using Linear vs MLP projection head: Linear is simpler but MLP may capture more complex relationships
  - Temperature parameter τ: Lower values emphasize hard examples, higher values treat all pairs equally
  - Regularization strength λ: Higher values preserve more linguistic knowledge but may limit emotion learning
- Failure signatures:
  - High ∆emb values indicate loss of linguistic knowledge
  - Poor clustering/retrieval metrics indicate ineffective emotion learning
  - Overfitting to go_emotions dataset (poor downstream performance)
- First 3 experiments:
  1. Compare clustering metrics (AMI, ARI, FMS) between pre-trained BERT and BERTEmo on go_emotions test set
  2. Evaluate downstream task performance (sentiment analysis) using KNN classifier with [CLS] embeddings
  3. Test few-shot learning performance by fine-tuning on limited data and comparing with pre-trained baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the performance of emotion-aware PLMs change if trained on emotion recognition datasets from multiple domains and genres?
- Basis in paper: [inferred] The paper acknowledges that the go_emotions dataset is limited to English Reddit comments and mentions the potential benefits of training on datasets spanning different genres and domains, but also notes the complexities involved.
- Why unresolved: The paper does not conduct experiments with multiple datasets, focusing solely on go_emotions.
- What evidence would resolve it: Experiments comparing the performance of emotion-aware PLMs trained on single vs. multiple emotion recognition datasets across various downstream tasks.

### Open Question 2
- Question: How would the performance of emotion-aware PLMs compare to large language models like GPT-3.5-turbo when both are fine-tuned on the same downstream tasks?
- Basis in paper: [explicit] The paper compares the fine-tuned RoBERTaEmo with zero-shot and few-shot in-context learning using ChatGPT on sentiment analysis tasks, but acknowledges the need for a more detailed comparison with fine-tuned LLMs.
- Why unresolved: The paper only provides a comparison with zero-shot and few-shot in-context learning, not fine-tuning.
- What evidence would resolve it: Experiments comparing the performance of emotion-aware PLMs and fine-tuned large language models on various downstream tasks, including sentiment analysis, sarcasm detection, and other affective tasks.

### Open Question 3
- Question: How well do emotion-aware PLMs generalize to general NLP tasks that are not explicitly affective in nature?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of emotion-aware PLMs on affective downstream tasks but acknowledges the difficulty in commenting on their effectiveness on general NLP tasks like entity extraction or grammatical error correction.
- Why unresolved: The paper does not conduct experiments on general NLP tasks, focusing solely on affective tasks.
- What evidence would resolve it: Experiments evaluating the performance of emotion-aware PLMs on a variety of general NLP benchmarks, such as GLUE and SuperGLUE, and comparing their performance to pre-trained PLMs.

## Limitations

- The go_emotions dataset is limited to English Reddit comments, raising questions about domain generalizability to other text genres and languages.
- The 1% improvement in downstream task F1-scores, while statistically significant, may not represent a substantial practical advantage in all applications.
- The paper doesn't explore variations in regularization strength (λ) or temperature (τ) parameters extensively, which could impact the robustness of findings.

## Confidence

**High Confidence**: The core mechanism of supervised contrastive learning for emotion retrofitting is well-established and the experimental results showing improved clustering metrics (AMI, ARI, FMS) and downstream task performance are robust and reproducible.

**Medium Confidence**: The claim that vector space preservation prevents catastrophic forgetting is supported by empirical evidence but would benefit from more extensive ablation studies varying the regularization strength. The comparative advantage over transfer learning and multi-task learning approaches is demonstrated but could be strengthened with more diverse baseline comparisons.

**Low Confidence**: The assertion that the 1% improvement in downstream task F1-scores represents a meaningful practical advantage, and the generalizability of findings to domains outside of social media text, require additional validation.

## Next Checks

1. **Domain Transfer Experiment**: Evaluate BERTEmo and RoBERTaEmo on emotion recognition tasks from different domains (e.g., product reviews, clinical notes, or customer service conversations) to assess generalizability beyond Reddit-style text.

2. **Hyperparameter Sensitivity Analysis**: Systematically vary the regularization strength (λ) and temperature (τ) parameters across a wider range to identify optimal values and understand their impact on the tradeoff between emotion awareness and linguistic knowledge preservation.

3. **Bias Audit**: Conduct an analysis of the go_emotions dataset for potential demographic or cultural biases, then test whether these biases are amplified or mitigated in the retrofitted models through controlled experiments on diverse text samples.