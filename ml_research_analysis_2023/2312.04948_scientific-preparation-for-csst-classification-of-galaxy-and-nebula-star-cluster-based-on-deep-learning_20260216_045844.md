---
ver: rpa2
title: 'Scientific Preparation for CSST: Classification of Galaxy and Nebula/Star
  Cluster Based on Deep Learning'
arxiv_id: '2312.04948'
source_url: https://arxiv.org/abs/2312.04948
tags:
- image
- images
- samples
- classification
- galaxy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of real-time identification
  of galaxy and nebula/star cluster images captured by the Chinese Space Station Telescope
  (CSST). To tackle this, the authors developed HR-CelestialNet, a deep learning model
  designed to classify high-resolution local celestial images.
---

# Scientific Preparation for CSST: Classification of Galaxy and Nebula/Star Cluster Based on Deep Learning

## Quick Facts
- arXiv ID: 2312.04948
- Source URL: https://arxiv.org/abs/2312.04948
- Reference count: 6
- HR-CelestialNet achieved 89.09% accuracy on high-resolution celestial image classification

## Executive Summary
This paper presents HR-CelestialNet, a deep learning model specifically designed for classifying high-resolution local celestial images captured by the Chinese Space Station Telescope (CSST). The model addresses the challenge of real-time identification of galaxy versus nebula/star cluster images. HR-CelestialNet outperforms traditional architectures like AlexNet, VGGNet, and ResNet while maintaining faster recognition speeds and demonstrating robustness to image quality degradation.

## Method Summary
The researchers developed HR-CelestialNet using a two-component architecture that processes high-resolution celestial images (2048 × 4096 pixels) from Hubble Space Telescope data. The model employs 12 convolutional layers with varying kernel sizes (7×7, 5×5, 3×3), 7 max-pooling layers, and 3 fully connected layers with 4096 neurons each. Training was conducted using SGD optimizer with learning rate 0.0001 for 20 epochs on a dataset of 7,813 samples partitioned by celestial body. The model was evaluated on both original high-resolution images and resized/blur datasets to assess performance and robustness.

## Key Results
- HR-CelestialNet achieved 89.09% accuracy on the testing set, outperforming AlexNet, VGGNet, and ResNet
- The model demonstrated faster recognition speeds compared to baseline architectures
- On the blurry image dataset, HR-CelestialNet maintained 84.48% accuracy, showing robustness to low image quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: HR-CelestialNet achieves higher accuracy on high-resolution celestial images by using larger convolutional kernels and global max-pooling without padding.
- Mechanism: The larger 7×7 and 5×5 convolutional kernels in the early layers increase the receptive field, allowing the model to capture more contextual information from the large 2048×4096 pixel images. The use of global max-pooling without padding helps preserve spatial information while reducing computational complexity.
- Core assumption: High-resolution images contain more discriminative features that can be effectively captured with larger kernels, and padding removal does not significantly harm feature extraction.
- Evidence anchors:
  - [abstract] "HR-CelestialNet achieved an accuracy of 89.09% on the testing set, outperforming models such as AlexNet, VGGNet and ResNet"
  - [section] "In the design of HR-CelestialNet, we discarded padding and employed a combination of convolutional and pooling layers with various kernel sizes."
  - [corpus] Weak: No direct comparison of kernel sizes in corpus papers.
- Break condition: If larger kernels lead to overfitting on smaller datasets or if padding removal causes loss of critical edge features.

### Mechanism 2
- Claim: HR-CelestialNet maintains efficiency by using a two-component architecture that adapts to different spatial dimensions.
- Mechanism: The first "large-size learning component" handles the initial large feature maps (1×2048×4096 to 128×121×248) with fewer layers and larger kernels, while the second "small-size learning component" processes the reduced feature maps (128×121×248 to final output) using a VGGNet-like backbone. This division optimizes computational resources.
- Core assumption: The spatial dimension of feature maps correlates with the complexity of features to be learned, and a two-stage approach can balance efficiency and accuracy.
- Evidence anchors:
  - [abstract] "demonstrating faster recognition speeds" compared to AlexNet, VGGNet, and ResNet
  - [section] "We can consider HR-CelestialNet as composed of two segments based on the variation in output size."
  - [corpus] Weak: No direct mention of two-component architectures in corpus papers.
- Break condition: If the division between components is not optimal for certain types of celestial images or if it introduces unnecessary complexity.

### Mechanism 3
- Claim: HR-CelestialNet shows robustness to low image quality by maintaining high accuracy on blurry samples.
- Mechanism: The model's architecture and training process enable it to learn features that are resilient to image blur, as evidenced by its performance on the LCID-Blurry validation set where it achieved 84.48% accuracy.
- Core assumption: The features learned by HR-CelestialNet are not overly sensitive to image sharpness, allowing it to generalize well to lower quality images.
- Evidence anchors:
  - [abstract] "demonstrating its robustness to low image quality"
  - [section] "we investigated the factors influencing CSST image quality and evaluated the generalization ability of HR-CelestialNet on the blurry image dataset"
  - [corpus] Weak: No direct mention of blur robustness in corpus papers.
- Break condition: If the model's performance degrades significantly on images with different types of noise or blur.

## Foundational Learning

- Concept: Convolutional Neural Networks (CNNs)
  - Why needed here: CNNs are the foundation for image classification tasks, including the classification of celestial images into galaxies and nebulae/star clusters.
  - Quick check question: What is the primary advantage of using convolutional layers in image classification tasks?

- Concept: Data preprocessing and augmentation
  - Why needed here: Proper preprocessing of celestial images, including cropping, resizing, and handling of different file formats, is crucial for training an effective model.
  - Quick check question: Why is it important to partition the dataset based on celestial bodies rather than individual images?

- Concept: Model evaluation metrics
  - Why needed here: Understanding and calculating metrics such as accuracy, precision, recall, and F1 score is essential for assessing the performance of the classification model.
  - Quick check question: How do precision and recall provide a more comprehensive evaluation than accuracy alone in binary classification tasks?

## Architecture Onboarding

- Component map: Input layer -> 12 Convolutional layers -> 7 Pooling layers -> 3 Fully connected layers -> Output layer
- Critical path:
  1. Input image preprocessing and normalization
  2. Convolutional and pooling layers for feature extraction
  3. Flattening of feature maps
  4. Fully connected layers for classification
  5. Output prediction and loss calculation
- Design tradeoffs:
  - Larger kernels vs. computational efficiency: Using larger kernels (7×7, 5×5) increases the receptive field but also increases computational cost.
  - No padding vs. feature preservation: Removing padding reduces parameters but may lose edge information.
  - Two-component architecture vs. single architecture: Dividing the network into two components optimizes for different spatial dimensions but adds complexity.
- Failure signatures:
  - Overfitting: High training accuracy but low validation accuracy
  - Underfitting: Low accuracy on both training and validation sets
  - Vanishing gradients: Difficulty in training deeper layers
  - Sensitivity to image quality: Significant performance drop on blurry or low-quality images
- First 3 experiments:
  1. Compare HR-CelestialNet's performance on high-resolution images vs. resized images to validate the importance of input resolution.
  2. Test the model's robustness by evaluating its performance on a dataset with varying levels of image blur.
  3. Analyze the impact of different kernel sizes and padding strategies on the model's accuracy and computational efficiency.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of HR-CelestialNet change when trained on CSST-specific simulated data instead of Hubble Space Telescope data?
- Basis in paper: [inferred] The paper states that CSST images are currently simulated and low-resolution, making it difficult to accurately evaluate the model. The authors use Hubble data as a proxy, but acknowledge this may not fully represent CSST data.
- Why unresolved: CSST has not yet launched, so real CSST data is unavailable. The authors mention simulated data but do not test the model on it.
- What evidence would resolve it: Testing HR-CelestialNet on high-quality CSST simulated data would provide insights into its performance on real CSST data.

### Open Question 2
- Question: What is the impact of different image preprocessing techniques on the performance of HR-CelestialNet and other models?
- Basis in paper: [explicit] The authors describe their specific preprocessing steps for ACS/WFC and WFC3/UVIS data, but do not explore the effects of alternative preprocessing methods.
- Why unresolved: The authors focused on their chosen preprocessing pipeline and did not investigate alternative approaches.
- What evidence would resolve it: Experimenting with different preprocessing techniques (e.g., normalization, augmentation) and comparing their impact on model performance would provide insights into the importance of preprocessing.

### Open Question 3
- Question: Can the model be further improved by incorporating additional features or using a different architecture?
- Basis in paper: [explicit] The authors mention that misclassification can occur due to inter-class similarity, insufficient features, and image noise. They also note that HR-CelestialNet maintains moderate performance on blurry samples.
- Why unresolved: The authors acknowledge limitations in the model's performance but do not explore potential improvements beyond the current architecture.
- What evidence would resolve it: Experimenting with different model architectures, incorporating additional features (e.g., spectral information), or using ensemble methods could potentially improve performance.

## Limitations
- The reported accuracy of 89.09% is promising but lacks comparison to state-of-the-art methods on standard astronomical datasets
- The model's performance on only one type of image degradation (blur) does not fully establish robustness to all quality issues
- The two-component architecture's efficiency gains lack direct ablation studies isolating the contribution of architectural choices

## Confidence
- High: The model achieves 89.09% accuracy on high-resolution celestial images
- Medium: HR-CelestialNet demonstrates faster recognition speeds compared to baseline architectures
- Low: The model's robustness to image blur (84.48%) is based on limited evidence

## Next Checks
1. Evaluate HR-CelestialNet on standard astronomical image classification benchmarks (e.g., LSST datasets) to establish relative performance
2. Conduct controlled ablation studies varying kernel sizes and padding strategies while holding other factors constant
3. Test model performance across multiple degradation types (noise, compression artifacts, atmospheric distortion) beyond simple blur