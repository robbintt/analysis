---
ver: rpa2
title: 'BOOST: Harnessing Black-Box Control to Boost Commonsense in LMs'' Generation'
arxiv_id: '2310.17054'
source_url: https://arxiv.org/abs/2310.17054
tags:
- commonsense
- boost
- human
- generation
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of improving commonsense reasoning
  in large language models' text generation. The authors propose BOOST, a framework
  that uses a reference-free evaluator to assign commonsense scores to sentences by
  grounding them to a dynamic knowledge base, and then trains an auxiliary model to
  guide a frozen pre-trained language model towards more commonsensical outputs.
---

# BOOST: Harnessing Black-Box Control to Boost Commonsense in LMs' Generation

## Quick Facts
- arXiv ID: 2310.17054
- Source URL: https://arxiv.org/abs/2310.17054
- Reference count: 40
- This paper proposes BOOST, a framework that improves commonsense reasoning in language model outputs by using a reference-free evaluator to score sentences against a dynamic knowledge base, then training an auxiliary model to guide a frozen pre-trained language model toward more commonsensical outputs.

## Executive Summary
This paper addresses the challenge of improving commonsense reasoning in large language models' text generation. The authors propose BOOST, a framework that uses a reference-free evaluator to assign commonsense scores to sentences by grounding them to a dynamic knowledge base, and then trains an auxiliary model to guide a frozen pre-trained language model towards more commonsensical outputs. The method is tested on GPT-2, Alpaca, and Flan-T5 models on two benchmarks, CommonGen and CSK-PN. Human evaluation results show that BOOST consistently leads to the most commonsensical outputs, outperforming other baseline methods and even ChatGPT in overall preference, though ChatGPT scored higher on commonsense.

## Method Summary
BOOST improves commonsense reasoning in language models by first constructing a reference-free evaluator (O-Scorer) that assigns commonsense scores to sentences by grounding them to a dynamic commonsense knowledge base from four relational aspects. The framework then extends the NADO controllable generation method to train an auxiliary model that guides a frozen pre-trained language model using the O-Scorer as an oracle. For constrained generation tasks, BOOST Joint combines lexical constraint checking with commonsense scoring to ensure both concept coverage and commonsense plausibility. The approach is evaluated on GPT-2, Alpaca, and Flan-T5 models across CommonGen and CSK-PN benchmarks.

## Key Results
- BOOST consistently produces the most commonsensical outputs in human evaluation, outperforming baseline methods
- BOOST Joint achieves better keyword coverage than BOOST CS while maintaining strong commonsense ratings
- On the CSK-PN benchmark, BOOST outperforms existing baselines in generating text that avoids negated commonsense relations
- BOOST performs competitively with ChatGPT in overall preference despite ChatGPT scoring higher on commonsense alone

## Why This Works (Mechanism)

### Mechanism 1
The reference-free commonsense scorer (O-Scorer) improves commonsense reasoning by grounding sentence tuples to a dynamic commonsense knowledge base. The O-Scorer extracts commonsense-relation tuples from sentences and scores them by comparing to valid tails from COMET, a dynamic commonsense knowledge base. This provides a differentiable signal to guide the auxiliary NADO model. Core assumption: Tuple extraction from sentences accurately captures the commonsense relations needed for scoring, and COMET's dynamic tails are representative of commonsense plausibility. Break condition: If tuple extraction fails to capture relevant commonsense relations, or if COMET's tails do not align with human commonsense judgments, the scoring signal becomes unreliable.

### Mechanism 2
The NADO auxiliary model effectively steers a frozen PTLM toward more commonsensical outputs by learning token-level guidance from the O-Scorer. NADO is trained on samples generated by the frozen PTLM, using the O-Scorer's commonsense scores as supervision. It learns to predict expected commonsense scores for incomplete sequences, allowing it to modify the PTLM's output distribution at each decoding step. Core assumption: The closed-form solution for optimal q(y|x) given the oracle O is tractable to approximate with a neural model trained on PTLM-generated data. Break condition: If the PTLM's self-generated samples do not cover the space of commonsensical outputs well, or if the O-Scorer's signal is too noisy, NADO cannot learn effective guidance.

### Mechanism 3
Combining lexical constraint checking with commonsense scoring produces better outputs than using either signal alone. BOOST Joint multiplies the lexical checking Boolean function with the O-Scorer's commonsense score, ensuring both concept coverage and commonsense plausibility are optimized jointly. Core assumption: Lexical constraints and commonsense reasoning are complementary objectives that can be optimized together without significant trade-offs. Break condition: If the multiplication of signals creates a local optimum that satisfies neither objective well, or if one signal dominates the other during training.

## Foundational Learning

- **Concept: Autoregressive language modeling**
  - Why needed here: Understanding how PTLMs generate text token-by-token is crucial for implementing NADO's token-level guidance mechanism.
  - Quick check question: In an autoregressive model, what is the probability distribution for generating the next token given previous tokens?

- **Concept: Knowledge graph reasoning**
  - Why needed here: The O-Scorer relies on commonsense knowledge graphs like ConceptNet to evaluate the plausibility of extracted tuples.
  - Quick check question: How do you determine if a tuple (head, relation, tail) is plausible using a knowledge graph?

- **Concept: Controllable text generation**
  - Why needed here: BOOST extends existing controllable generation methods (NADO) to incorporate commonsense reasoning as a control signal.
  - Quick check question: What is the difference between modifying decoding algorithms versus training auxiliary models for controllable generation?

## Architecture Onboarding

- **Component map**: Frozen PTLM -> Tuple extraction -> O-Scorer scoring -> NADO training -> Guided generation
- **Critical path**: PTLM → Tuple extraction → O-Scorer scoring → NADO training → Guided generation
- **Design tradeoffs**: Using a frozen PTLM enables efficiency but limits direct model improvements; reference-free scoring avoids ground truth dependencies but may be noisier; training NADO on PTLM samples creates distributional shift that must be managed
- **Failure signatures**: Low commonsense scores despite concept coverage → O-Scorer may not capture relevant commonsense; high commonsense scores but poor concept coverage → Lexical constraints not properly enforced; no improvement over base PTLM → NADO not learning effective guidance or distributional shift too large
- **First 3 experiments**: 1) Evaluate O-Scorer correlation with human commonsense ratings on held-out data; 2) Train NADO on PTLM samples and measure O-Scorer improvement on validation set; 3) Compare BOOST Joint vs BOOST CS on concept coverage and commonsense scores

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of BOOST vary when using different base models of varying sizes (e.g., GPT-2 small, medium, large)? The paper tests BOOST on GPT-2-large, Alpaca-7b, and Flan-T5-large, but does not explore the impact of base model size. Experiments comparing BOOST's performance across different base model sizes would clarify the impact of this variable.

### Open Question 2
Can the commonsense scorer (O-Scorer) be extended to handle more complex commonsense relations beyond the four types (IsUsedFor, AtLocation, CapableOf, PartOf) explored in the paper? The authors acknowledge that the tuple extractor covers only four relation types and may miss other important relations such as causal, temporal order, etc. Developing and evaluating an extended commonsense scorer that handles a broader range of relations would address this open question.

### Open Question 3
How does the performance of BOOST compare to other state-of-the-art methods for commonsense reasoning in text generation, such as those using knowledge graphs or retrieval-augmented generation? The paper compares BOOST to several baselines but does not directly compare it to other state-of-the-art methods for commonsense reasoning in text generation. Experiments comparing BOOST's performance to other state-of-the-art methods for commonsense reasoning in text generation would provide a clearer picture of its relative effectiveness.

## Limitations

- The framework heavily relies on the quality of tuple extraction and the representativeness of COMET's dynamic knowledge base, which may not capture all relevant commonsense relations
- The reference-free scoring approach may produce noisy signals that limit the effectiveness of NADO's learning
- The method's performance gains are modest compared to existing lexical constraint approaches, with BOOST Joint achieving slightly lower commonsense ratings than BOOST CS while only marginally improving keyword coverage

## Confidence

- **High confidence**: The overall experimental methodology and human evaluation design are sound and well-executed
- **Medium confidence**: The effectiveness of the O-Scorer in capturing commonsense plausibility, as this depends heavily on the quality of tuple extraction and COMET's coverage
- **Medium confidence**: The NADO auxiliary model's ability to learn effective token-level guidance, as this requires careful hyperparameter tuning and sufficient training data

## Next Checks

1. Conduct ablation studies removing the tuple extraction component to measure its contribution to overall performance, and evaluate O-Scorer correlation with human ratings on a held-out test set
2. Test the framework's generalization to other constrained generation tasks beyond concept combination, such as style transfer or sentiment control
3. Analyze the distributional shift between PTLM-generated training samples and actual test data to quantify potential performance degradation in NADO's guidance