---
ver: rpa2
title: 'DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking'
arxiv_id: '2310.18075'
source_url: https://arxiv.org/abs/2310.18075
tags:
- mind
- dialogue
- slow
- duma
- fast
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DUMA introduces a dual-mind conversational agent framework inspired
  by human dual-process cognition, using two separate LLMs for fast and slow thinking.
  The fast mind handles routine queries directly, while the slow mind is invoked for
  complex tasks requiring deeper reasoning and tool use.
---

# DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking

## Quick Facts
- arXiv ID: 2310.18075
- Source URL: https://arxiv.org/abs/2310.18075
- Reference count: 5
- Key outcome: DUMA significantly outperforms baseline models on six Chinese real estate dialogue metrics using a dual-mind architecture

## Executive Summary
DUMA introduces a dual-mind conversational agent framework inspired by human dual-process cognition, using two separate LLMs for fast and slow thinking. The fast mind handles routine queries directly, while the slow mind is invoked for complex tasks requiring deeper reasoning and tool use. Experimental results in Chinese real estate dialogue scenarios show that DUMA significantly outperforms baseline models, with improvements across six key metrics including house expertise, tool calling ability, and service attitude. A two-stage fine-tuning approach enhanced the fast mind's factuality and logical coherence.

## Method Summary
DUMA uses Baichuan-13B-Chat as the fast mind for quick responses and ChatGLM2-6B as the slow mind for deep reasoning with tool integration. The fast mind evaluates query complexity and conditionally invokes the slow mind, caching results in a Memory Area to avoid redundant processing. Training follows a two-stage process: Stage I trains on full dialogue data for conversational style, while Stage II selectively updates only annotated responses for factuality enhancement. The slow mind uses ReAct-inspired reasoning loops (Reason→Act→Obs→Finish) for multi-step problem solving with external tool calls.

## Key Results
- DUMA outperforms baseline models across six evaluation metrics in Chinese real estate dialogues
- Fast mind's two-stage fine-tuning improves factuality while maintaining logical coherence
- Slow mind's ReAct-inspired reasoning enables effective tool use for complex queries

## Why This Works (Mechanism)

### Mechanism 1
The dual-mind architecture enables task decomposition by routing simple queries to the fast mind and complex queries to the slow mind, improving efficiency and accuracy. The fast mind evaluates query complexity and conditionally invokes the slow mind, which performs deeper reasoning and tool use. The slow mind's results are cached in the fast mind's "Memory Area" to avoid redundant deep processing for similar future queries.

### Mechanism 2
Two-stage fine-tuning improves factuality by separating dialogue training from factuality enhancement, preventing hallucination propagation. Stage I trains on full dialogue data for conversational style; Stage II selectively updates only annotated responses while masking gradients for subsequent turns to maintain logical coherence.

### Mechanism 3
ReAct-inspired reasoning loops in the slow mind enable multi-step problem solving with tool integration, mirroring human analytical processes. The slow mind iterates through Reason→Act→Obs→Finish cycles, calling external tools when needed, and self-terminates when reasoning is complete.

## Foundational Learning

- Concept: Dual-process cognition (fast intuitive vs. slow analytical thinking)
  - Why needed here: Provides theoretical justification for separating fast/slow LLMs and explains why different models suit different cognitive modes
  - Quick check question: What distinguishes System 1 from System 2 thinking in Kahneman's framework, and how does DUMA mirror this distinction?

- Concept: Reinforcement learning for dialogue agents
  - Why needed here: The paper uses reinforcement learning (GRPO variant) in related works; understanding this helps contextualize DUMA's approach within broader LLM agent research
  - Quick check question: How does GRPO differ from standard RLHF, and why might it be preferred for multi-step reasoning tasks?

- Concept: Tool use and API integration in LLMs
  - Why needed here: The slow mind's effectiveness depends on calling external tools; understanding tool use patterns is essential for replicating or extending DUMA
  - Quick check question: What are the key challenges in designing LLM tool-calling interfaces, and how does ReAct address them?

## Architecture Onboarding

- Component map: User query → Fast Mind (Baichuan-13B-Chat) → Slow Mind (ChatGLM2-6B) → Memory Area → Fast Mind response
- Critical path: 1. User query → Fast Mind 2. Fast Mind complexity assessment → invoke Slow Mind or generate response 3. If invoked: Slow Mind reasoning → tool calls → Obs/Finish 4. Results → Fast Mind → cached in Memory Area 5. Fast Mind generates final response
- Design tradeoffs: Fast mind model size vs. latency (smaller models faster but less accurate), slow mind tool access (more tools increase capability but add latency and cost), Memory caching (improves efficiency but risks stale data)
- Failure signatures: Fast mind over-invokes slow mind (system becomes slow for simple queries), slow mind infinite loops (conversation hangs indefinitely), Memory cache misses (repeated slow mind invocations for same query types)
- First 3 experiments: 1. Unit test fast mind query classification on labeled dataset (simple vs complex) 2. Integration test slow mind tool calling with mocked APIs 3. End-to-end latency measurement comparing DUMA vs baseline on mixed query set

## Open Questions the Paper Calls Out

### Open Question 1
How does the DUMA framework's performance vary across different real estate domains (e.g., residential vs. commercial properties)? The paper focuses on Chinese real estate online communication scenarios, suggesting potential domain-specific variations, but does not provide comparative analysis across different real estate subdomains.

### Open Question 2
What is the impact of the two-stage fine-tuning process on the Fast Mind's performance in non-real estate conversational scenarios? The paper mentions a two-stage fine-tuning approach for enhancing factuality and logical coherence in real estate dialogues but does not explore its applicability in other domains.

### Open Question 3
How does the balance between fast and slow thinking in DUMA affect user satisfaction in real-world applications? The paper discusses the balance between fast and slow thinking but does not directly measure user satisfaction, which is not explicitly measured or reported in the experimental results.

## Limitations
- Evaluation is limited to Chinese real estate dialogues without cross-domain or cross-language validation
- Critical implementation details (prompt templates, factuality calibration process) are not fully specified
- Long-term effectiveness of Memory Area caching is not empirically validated

## Confidence

High Confidence: Dual-mind architecture design and theoretical justification through dual-process cognition are well-established. Two-stage fine-tuning approach is explicitly described with specific hyperparameters.

Medium Confidence: Reported experimental results showing improvements across six metrics are credible given the methodology, but evaluation is limited to Chinese real estate dialogues and may not generalize.

Low Confidence: Paper lacks comparison to other dual-process or multi-agent conversational frameworks, making relative performance difficult to assess. Scalability to other domains or languages is not demonstrated.

## Next Checks

1. Evaluate DUMA on a different domain (e.g., healthcare or customer service) using the same six metrics to assess whether the dual-mind architecture provides similar improvements outside real estate.

2. Deploy DUMA in a production environment for at least one month, tracking metrics including query classification accuracy, slow mind invocation frequency, and user satisfaction scores to validate long-term effectiveness.

3. Design an experiment where external tools update their responses over time, then measure how often cached results in the Memory Area become stale or inconsistent with current tool outputs, and quantify the impact on user experience.