---
ver: rpa2
title: Choosing Public Datasets for Private Machine Learning via Gradient Subspace
  Distance
arxiv_id: '2303.01256'
source_url: https://arxiv.org/abs/2303.01256
tags:
- private
- public
- dataset
- distance
- subspace
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of selecting appropriate public
  datasets for private machine learning, which can significantly improve model utility
  by reducing the noise added during differentially private training. The authors
  propose a method called Gradient Subspace Distance (GSD) that measures the similarity
  between public and private datasets by comparing the low-dimensional subspaces of
  their gradients.
---

# Choosing Public Datasets for Private Machine Learning via Gradient Subspace Distance

## Quick Facts
- **arXiv ID**: 2303.01256
- **Source URL**: https://arxiv.org/abs/2303.01256
- **Reference count**: 40
- **Primary result**: Proposes Gradient Subspace Distance (GSD) to select public datasets for private ML, improving utility by reducing DP noise

## Executive Summary
This paper addresses the challenge of selecting appropriate public datasets to improve model utility in differentially private machine learning. The authors introduce Gradient Subspace Distance (GSD), a method that measures similarity between public and private datasets by comparing low-dimensional subspaces of their gradients. GSD effectively predicts which public dataset will yield the best private model performance, with lower GSD correlating with higher accuracy. The method is computationally efficient compared to alternatives like Task2Vec and remains predictive across different model architectures.

## Method Summary
The core method computes GSD by extracting per-example gradients from both private and public datasets, performing SVD on these gradient matrices, and measuring the projection metric distance between their top-k singular vectors. For private settings, DP-GSD uses differentially private top-k subspace computation. The selected public dataset can then be used either for pre-conditioning (Gradient Embedding Perturbation) or transfer learning (second-phase pre-training). The approach theoretically bounds reconstruction error and excess risk based on GSD values, and empirically demonstrates effectiveness across various dataset pairs and model architectures.

## Key Results
- GSD effectively predicts private model utility, with lower GSD correlating with higher accuracy
- GSD remains predictive across different model architectures, allowing simple models for dataset selection
- GSD is computationally more efficient than Task2Vec while providing better predictions in private learning contexts
- Theoretical analysis shows excess risk scales with GSD, with reconstruction error bounded by the distance metric

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GSD effectively predicts which public dataset will yield the best private model utility by measuring similarity between gradient subspaces of public and private data.
- Mechanism: GSD computes projection metric distance between top-k singular vectors of per-example gradient matrices. Lower GSD indicates higher utility because private gradient reconstruction error is bounded by GSD.
- Core assumption: Top-k singular vectors capture most important training signal, and this signal is similar across related datasets.
- Evidence anchors: Abstract states GSD measures low-dimensional subspace distance between gradients; Section 4.1 provides Lemma 1 showing reconstruction error bounded by GSD.
- Break condition: If gradient subspaces are fundamentally different (e.g., chest X-rays vs CIFAR-100), GSD may fail to predict utility.

### Mechanism 2
- Claim: GSD remains predictive across different model architectures, allowing simple models for dataset selection.
- Mechanism: Relative ordering of GSD values between public datasets remains stable when computed using different architectures.
- Core assumption: Gradient subspace structure is preserved across architectures when trained on same dataset.
- Evidence anchors: Section 6.3 shows even simple CNN GSD derives accurate distance measurement; Section 4.2 demonstrates relative ordering preserved.
- Break condition: If dataset's gradient subspace is highly sensitive to architecture changes, simple-model GSD might not predict utility for complex models.

### Mechanism 3
- Claim: GSD provides computationally efficient alternative to Task2Vec for measuring dataset similarity in private learning contexts.
- Mechanism: GSD uses simple SVD on per-example gradients, while Task2Vec requires computing Fisher information matrices.
- Core assumption: Subspace distance metric captures dataset similarity relevant for private learning better than Fisher information-based methods.
- Evidence anchors: Section 6.4 shows GSD outperforms Task2Vec empirically; Section 6.1 compares GSD with Task2Vec in differentially private setting.
- Break condition: If Task2Vec's Fisher information approach captures dataset similarity in ways GSD misses, GSD might fail where Task2Vec succeeds.

## Foundational Learning

- **Concept**: Differential Privacy and Differential Private SGD (DPSGD)
  - Why needed here: Paper's premise relies on understanding how noise injection in DPSGD affects model utility and how public data can help mitigate this.
  - Quick check question: Why does noise magnitude in DPSGD scale with square root of number of parameters?

- **Concept**: Singular Value Decomposition (SVD) and Principal Angles
  - Why needed here: GSD fundamentally relies on computing SVD of gradient matrices and measuring distances between subspaces using principal angles.
  - Quick check question: What do top-k singular vectors of gradient matrix represent in context of model training?

- **Concept**: Projection Metric and Subspace Distance
  - Why needed here: GSD uses projection metric to measure distance between gradient subspaces, directly relating to reconstruction error bounds.
  - Quick check question: How does projection metric distance between two subspaces relate to reconstruction error when projecting one subspace onto another?

## Architecture Onboarding

- **Component map**: Per-example gradient computation → SVD → Top-k singular vector extraction → Projection metric distance calculation
- **Critical path**: GSD computation → Dataset selection → Private training (GEP or transfer learning) → Model evaluation
- **Design tradeoffs**:
  - Non-private vs private GSD computation (privacy vs efficiency)
  - Choice of k (dimensionality of subspace) vs computational cost and accuracy
  - Simple probe network vs target architecture for GSD computation (efficiency vs precision)
- **Failure signatures**:
  - GSD values don't correlate with downstream utility (check dataset domain similarity)
  - GSD values vary significantly across architectures (check gradient subspace stability)
  - Computational cost is prohibitive (check if simpler k or probe network suffices)
- **First 3 experiments**:
  1. Compute GSD between CIFAR-10 and CIFAR-100 using simple CNN, then train with GEP using each public dataset and verify accuracy correlates with GSD.
  2. Compute GSD using probe network, then use same public dataset for second-phase pre-training with transformer model, checking if GSD ordering predicts utility.
  3. Compare GSD computation time and accuracy against Task2Vec for set of dataset pairs to verify efficiency claims.

## Open Questions the Paper Calls Out
- **Open Question 1**: How does GSD behave with extremely large-scale models (e.g., trillion-parameter models) and what modifications might be needed? The paper focuses on models with hundreds of thousands of parameters and mentions noise scaling with square root of parameter count, but doesn't explore extreme-scale scenarios.

- **Open Question 2**: Can GSD be effectively computed using only public data when private data is completely unavailable for even a single batch? The paper shows GSD requires one batch of private examples and mentions it's interesting to understand properties of GSD without private data.

- **Open Question 3**: What is the theoretical relationship between GSD and other established domain adaptation metrics like maximum mean discrepancy or Wasserstein distance? The paper mentions domain adaptation as related work but doesn't compare GSD to other distribution similarity measures.

- **Open Question 4**: How does GSD perform in federated learning settings where data is distributed across multiple devices with privacy constraints? The paper focuses on centralized settings and doesn't address distributed data scenarios.

## Limitations
- Assumption that gradient subspace similarity directly predicts private learning utility may not hold for datasets with fundamental differences (e.g., domain shifts between medical imaging and natural images).
- Theoretical analysis relies on RFF assumption and bounds that may not capture all practical scenarios.
- Empirical validation is limited to specific dataset pairs and model architectures, leaving questions about generalization to other domains and larger-scale problems.

## Confidence
- **High Confidence**: GSD's computational efficiency advantage over Task2Vec, and its general framework for public dataset selection
- **Medium Confidence**: GSD's predictive power for pre-conditioning approaches (GEP), based on reconstruction error bounds
- **Medium Confidence**: GSD's stability across model architectures for relative ranking, though absolute values may vary
- **Low Confidence**: Universal applicability of GSD for all types of dataset relationships and domain shifts

## Next Checks
1. Test GSD's predictive power on cross-domain datasets (e.g., medical imaging to natural images) to validate mechanism's limits
2. Evaluate GSD with different k values and probe network architectures to determine optimal configuration for various problem scales
3. Compare GSD against domain-specific similarity metrics for specialized domains where gradient subspace assumptions may break down