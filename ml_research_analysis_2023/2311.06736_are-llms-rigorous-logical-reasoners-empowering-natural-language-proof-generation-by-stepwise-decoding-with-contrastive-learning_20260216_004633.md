---
ver: rpa2
title: Are LLMs Rigorous Logical Reasoners? Empowering Natural Language Proof Generation
  by Stepwise Decoding with Contrastive Learning
arxiv_id: '2311.06736'
source_url: https://arxiv.org/abs/2311.06736
tags:
- proof
- reasoning
- hard
- language
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines how large language models (LLMs) perform on
  natural language proof generation, a logical reasoning task that requires constructing
  step-by-step explanations from premises to a conclusion. The authors find that while
  LLMs like GPT-4 perform well on final answer generation, they struggle with producing
  rigorous intermediate reasoning steps.
---

# Are LLMs Rigorous Logical Reasoners? Empowering Natural Language Proof Generation by Stepwise Decoding with Contrastive Learning

## Quick Facts
- arXiv ID: 2311.06736
- Source URL: https://arxiv.org/abs/2311.06736
- Reference count: 17
- Key outcome: Contrastive decoding with hard negatives improves LLMs' natural language proof generation, particularly for intermediate reasoning steps

## Executive Summary
This paper examines how large language models perform on natural language proof generation, a logical reasoning task requiring step-by-step explanations from premises to conclusions. While LLMs like GPT-4 excel at final answer generation, they struggle with rigorous intermediate reasoning steps. The authors propose a stepwise contrastive decoding method that uses hard negative examples to train models to better discriminate between semantically correct and incorrect reasoning steps. Experiments on the EntailmentBank dataset demonstrate that this approach significantly improves proof planning accuracy, especially on tasks with distractors or large corpora, outperforming baselines like EntailmentWriter and NLProofS.

## Method Summary
The method uses contrastive decoding with hard negatives to improve natural language proof generation. A generator (Flan-T5-Large) produces reasoning steps, which are trained using a contrastive loss that maximizes similarity between correct input-output pairs while minimizing similarity with hard negative pairs. Hard negatives are constructed through simple substitution or enhanced generation using a reasoner and filtered by a checker. The enhanced approach explores unseen premise combinations, generates plausible conclusions via a trained reasoner, then filters with a checker to ensure semantic validity. The model is trained on EntailmentBank dataset using both MLE loss and contrastive loss.

## Key Results
- Contrastive decoding with hard negatives improves proof planning accuracy on EntailmentBank dataset
- Enhanced hard negatives (generated by reasoner and filtered by checker) outperform vanilla hard negatives
- Method shows particular strength on tasks with distractors or large corpora
- Outperforms baselines EntailmentWriter and NLProofS on multiple evaluation metrics

## Why This Works (Mechanism)

### Mechanism 1
- Contrastive decoding with hard negatives improves intermediate step accuracy by forcing the model to discriminate between semantically correct and incorrect reasoning steps. The contrastive loss maximizes similarity between correct pairs while minimizing similarity with hard negative pairs, forcing finer-grained semantic distinctions during stepwise reasoning. Core assumption: hard negatives are sufficiently challenging (plausible but incorrect). Evidence: abstract shows improved accuracy on tasks with distractors.

### Mechanism 2
- Enhanced hard negatives generated by reasoner and filtered by checker are more effective than simple substitution-based negatives. The enhanced approach explores unseen premise combinations, uses trained reasoner to generate plausible conclusions, then filters with checker to ensure semantic validity. Core assumption: reasoner can generate semantically plausible but incorrect conclusions, and checker can effectively filter. Evidence: section states enhanced hard negatives contain harder or more correct conclusions.

### Mechanism 3
- Stepwise decoding correction addresses error propagation in long reasoning chains. By correcting errors at each step rather than only at final output, the model prevents incorrect intermediate conclusions from corrupting subsequent reasoning steps. Core assumption: intermediate errors are detectable and correctable through contrastive learning. Evidence: section shows contrastive decoding can generate correct intermediate conclusions.

## Foundational Learning

- **Contrastive learning**: Used to improve model's ability to distinguish between correct and incorrect reasoning steps by explicitly training on both positive and negative examples. Quick check: How does contrastive learning differ from standard supervised learning in this context?

- **Hard negative mining**: Needed because simple negative examples are too easy; hard negatives that are semantically similar but incorrect provide more effective training signals. Quick check: Why might randomly generated negatives be less effective than those generated by a reasoner?

- **Error propagation in sequential reasoning**: Understanding how mistakes in early reasoning steps can corrupt entire proof chain, making stepwise correction essential. Quick check: What makes error propagation particularly problematic in proof generation compared to other NLP tasks?

## Architecture Onboarding

- **Component map**: Generator (Flan-T5-Large) → Contrastive decoder with hard negatives → Reasoner (Flan-T5-Large) → Checker (Vera)
- **Critical path**: Generator produces step → Hard negatives generated (vanilla or enhanced) → Contrastive loss applied → Generator parameters updated
- **Design tradeoffs**: Simple substitution negatives are easy to generate but less effective; enhanced negatives are more effective but computationally expensive
- **Failure signatures**: No improvement in intermediate step accuracy, performance degradation on simple tasks, or excessive computational cost
- **First 3 experiments**:
  1. Baseline: Train generator with MLE loss only on Task 2
  2. Add contrastive loss without hard negatives to test if contrastive learning itself helps
  3. Add vanilla hard negatives to verify if simple negatives improve performance before implementing enhanced negatives

## Open Questions the Paper Calls Out

1. How do hard negatives constructed by the reasoner/checker system compare in quality to those created through simple substitution? While the paper shows enhanced hard negatives improve performance, it doesn't provide detailed qualitative analysis of differences between the two types of hard negatives.

2. How does the performance of ConDec scale with the size of the language model used as the generator? The paper uses Flan-T5-Large and shows it outperforms prompting methods, but doesn't explore how larger models would perform.

3. Can ConDec be effectively combined with post-processing methods like search or verification to further improve proof generation accuracy? The authors mention that combining ConDec with search or verification methods could potentially yield better results, but don't explore this possibility.

## Limitations
- Limited evaluation scope confined to EntailmentBank dataset without out-of-domain testing
- Computational cost of enhanced hard negative generation is significant but not thoroughly analyzed
- Checker reliability not thoroughly examined - potential systematic biases could compromise contrastive learning pipeline

## Confidence

**High Confidence**: Claims about effectiveness of contrastive learning with hard negatives on EntailmentBank dataset. Experimental results are clearly presented and demonstrate measurable improvements.

**Medium Confidence**: Claims about superiority of enhanced hard negatives over vanilla negatives. Results show improvement, but computational cost-benefit tradeoff isn't fully explored.

**Medium Confidence**: Claims about error propagation mitigation through stepwise decoding. Paper presents theoretical arguments and some empirical evidence, but more rigorous analysis would strengthen claims.

## Next Checks

1. **Cross-domain generalization**: Test the proposed method on at least two additional datasets from different domains (e.g., mathematical theorem proving, scientific reasoning) to evaluate whether improvements generalize beyond EntailmentBank.

2. **Ablation study on negative quality**: Systematically vary difficulty and semantic similarity of hard negatives (including randomly generated negatives, easy negatives, and very hard negatives) to determine optimal negative quality for contrastive learning.

3. **Checker-independent validation**: Implement alternative checker or human evaluation to verify that Vera checker's filtering decisions are sound and that enhanced hard negatives genuinely represent challenging but semantically incorrect reasoning steps.