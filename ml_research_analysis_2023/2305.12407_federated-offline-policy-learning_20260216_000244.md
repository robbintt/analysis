---
ver: rpa2
title: Federated Offline Policy Learning
arxiv_id: '2305.12407'
source_url: https://arxiv.org/abs/2305.12407
tags:
- policy
- local
- data
- regret
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies federated offline policy learning where multiple
  heterogeneous data sources train a shared policy without sharing raw data. The authors
  analyze both global regret (over the distribution of clients) and local regret (for
  each individual client), showing that local regret suffers from an irreducible term
  due to distribution shift between a client and the global mixture.
---

# Federated Offline Policy Learning

## Quick Facts
- **arXiv ID**: 2305.12407
- **Source URL**: https://arxiv.org/abs/2305.12407
- **Reference count**: 40
- **Primary result**: Proved finite-sample regret bounds for federated offline policy learning with heterogeneous observational data, showing local regret suffers from irreducible distribution shift

## Executive Summary
This paper studies federated offline policy learning where multiple heterogeneous data sources train a shared policy without sharing raw data. The authors analyze both global regret (over the distribution of clients) and local regret (for each individual client), showing that local regret suffers from an irreducible term due to distribution shift between a client and the global mixture. They provide a federated algorithm based on FedAvg with local updates from cost-sensitive classification oracles, and prove finite-sample regret bounds characterized by policy class complexity, skewness of the client distribution, and distribution shift.

## Method Summary
The federated algorithm uses FedAvg with local updates from cost-sensitive classification oracles. Clients estimate nuisance parameters via cross-fitting, construct AIPW scores, and run local CSMC optimization. The central server initializes the global model, aggregates local updates, and maintains the client distribution λ. Raw data stays local while only model parameters and summary statistics are shared.

## Key Results
- Global regret bounds scale with sample size and client skewness
- Local regret suffers from an irreducible distribution shift term
- Skewed client distributions can mitigate local regret degradation at the cost of other clients' performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Global regret bounds scale with sample size and client skewness, while local regret suffers from an irreducible distribution shift term.
- **Mechanism**: The federated averaging algorithm with local updates from cost-sensitive classification oracles allows learning a global policy that performs well across the mixture of client distributions. The regret decomposition separates global performance (root-n scaling) from local performance degradation (distribution shift term).
- **Core assumption**: Doubly robust offline policy evaluation estimates are accurate enough (Assumption 3) and clients contribute asymptotically increasing data (Assumption 2).
- **Evidence anchors**:
  - [abstract]: "We characterize these regret bounds by expressions of client heterogeneity and distribution shift."
  - [section 5.2]: Theorem 1 showing global regret bound with skewness term
  - [corpus]: Weak - related papers focus on reinforcement learning rather than offline policy learning with heterogeneous observational data
- **Break condition**: If the doubly robust estimates fail to satisfy Assumption 3, or if some clients contribute only O(1) data relative to total (violating Assumption 2), the regret bounds break down.

### Mechanism 2
- **Claim**: Distribution shift between local client distributions and the global mixture causes irreducible local regret degradation.
- **Mechanism**: The total variation distance between local and global distributions captures how much the optimal policy for the global mixture differs from what's optimal locally. This gap cannot be eliminated by more samples, only by reducing distribution shift.
- **Core assumption**: Unconfoundedness and overlap assumptions hold (Assumption 1), ensuring valid counterfactual estimation.
- **Evidence anchors**:
  - [section 5.3]: Theorem 2 establishing local regret bound with TV(¯Dc, ¯Dλ) term
  - [section 5.3]: Proposition 1 decomposing distribution shift into covariate, propensity, and outcome components
  - [section 7]: Experiments showing heterogeneous clients suffer local regret degradation
- **Break condition**: If unconfoundedness or overlap assumptions fail, the counterfactual estimation becomes biased and the distribution shift analysis no longer applies.

### Mechanism 3
- **Claim**: Skewed client distributions can mitigate local regret degradation at the cost of other clients' performance.
- **Mechanism**: By upweighting heterogeneous clients in the mixture distribution, their distribution shift from the global mixture decreases, improving their local regret. However, this increases distribution shift for homogeneous clients, degrading their performance.
- **Core assumption**: Client distribution λ can be chosen to balance skewness and distribution shift trade-offs.
- **Evidence anchors**:
  - [section 7]: Experiments showing skewed mixture λ = ¯n + ¯ε improves client 1's local regret while degrading others
  - [section 5.1]: Definition of skewness s(λ||¯n) and its role in regret bounds
  - [section E]: Value of information analysis showing participation incentives depend on TV and skewness trade-off
- **Break condition**: If the optimal λ is unknown or cannot be optimized, clients may not benefit from federation despite theoretical guarantees.

## Foundational Learning

- **Concept: Doubly robust estimation**
  - Why needed here: Provides unbiased policy value estimates even when either the response or propensity estimates are accurate, crucial for heterogeneous data sources
  - Quick check question: What happens to the doubly robust estimator if both nuisance parameter estimates are biased?

- **Concept: Rademacher complexity and covering numbers**
  - Why needed here: Used to bound the complexity of the policy class and establish generalization guarantees in the presence of distribution shift
  - Quick check question: How does the Hamming distance covering number NH(ϵ, Π) relate to the ℓλ,2 covering number Nℓλ,2(ϵ, Π;ω)?

- **Concept: Total variation and KL divergence for distribution shift**
  - Why needed here: Quantify how much local client distributions differ from the global mixture, directly impacting local regret bounds
  - Quick check question: Why is total variation distance preferred over KL divergence for bounding the irreducible distribution shift term?

## Architecture Onboarding

- **Component map**: Central server -> Clients (n×) -> Central server
- **Critical path**: Cross-fit nuisance estimation → AIPW score construction → FedAvg-CSMC iterations → Global policy convergence
- **Design tradeoffs**:
  - Nuisance estimation accuracy vs computational cost (cross-fitting vs single fit)
  - Communication frequency vs convergence speed (local steps T per round)
  - Client distribution λ choice vs regret trade-offs (uniform vs skewed)
  - Parametric policy class vs flexibility (linear vs tree-based policies)
- **Failure signatures**:
  - Local regret much worse than global regret → distribution shift problem
  - Both regrets fail to converge → nuisance estimation issues or insufficient samples
  - Highly variable updates → communication overhead or client heterogeneity problems
  - Skewed λ improves some clients but severely degrades others → poor λ choice
- **First 3 experiments**:
  1. **Homogeneous clients test**: Verify global regret matches local regret bounds when all clients are identical
  2. **Single heterogeneous client**: Test if skewed client distribution λ improves the heterogeneous client's local regret
  3. **Varying sample sizes**: Check if local regret degrades when some clients contribute much less data than others

## Open Questions the Paper Calls Out

- **Open Question 1**: Can federated offline policy learning achieve better global regret than centralized learning under client heterogeneity?
  - Basis in paper: [explicit] The paper shows that federated learning can match locally trained policies when clients are homogeneous, but heterogeneous clients suffer local regret degradation. However, the global regret analysis suggests federated learning might still achieve comparable or better global regret bounds.
  - Why unresolved: The paper focuses on regret bounds and experimental results for both homogeneous and heterogeneous settings, but doesn't directly compare global regret performance between federated and centralized approaches under heterogeneity.
  - What evidence would resolve it: Experiments comparing global regret of federated learning versus centralized learning with the same total sample size, across varying degrees of client heterogeneity.

- **Open Question 2**: How does the choice of client distribution λ affect the trade-off between global regret and local regret across heterogeneous clients?
  - Basis in paper: [explicit] The paper discusses how the choice of λ must balance skewness (affecting global regret) and distribution shift (affecting local regret), and shows experimental results where skewing λ can improve performance for heterogeneous clients at the cost of others.
  - Why unresolved: While the paper provides theoretical bounds and experimental insights, it doesn't provide a systematic method for optimizing λ to achieve a desired balance between global and local regret objectives.
  - What evidence would resolve it: A framework or algorithm for optimizing λ to minimize a weighted combination of global and local regret, with experimental validation showing the effectiveness of the approach.

- **Open Question 3**: Are the established regret bounds for federated offline policy learning optimal?
  - Basis in paper: [explicit] The paper states that lower bounds are left for future work, and while the bounds reduce to known optimal bounds in the homogeneous setting, optimality in the heterogeneous federated setting remains open.
  - Why unresolved: Establishing lower bounds would require a different analytical approach than the upper bounds provided, and the paper explicitly leaves this as future work.
  - What evidence would resolve it: A matching lower bound proof that shows the established upper bounds are tight up to constant factors, or a counterexample demonstrating that the bounds can be improved.

## Limitations
- The analysis relies on assumptions of unconfoundedness and overlap that may not hold with observational data
- The paper doesn't provide practical methods for minimizing the irreducible distribution shift term
- Doubly robust estimation requires accurate nuisance parameter estimation, but propagation of estimation error to regret bounds isn't fully characterized

## Confidence

- **Global regret bounds**: High confidence - The theoretical framework appears sound with clear connections to Rademacher complexity and client skewness
- **Local regret degradation mechanism**: Medium confidence - While the mathematical characterization is rigorous, practical implications need more empirical validation
- **Federated algorithm convergence**: Medium confidence - The FedAvg-CSMC approach is reasonable but requires more thorough experimental validation

## Next Checks
1. **Sensitivity analysis to nuisance estimation error**: Systematically vary the accuracy of propensity and response function estimates to quantify their impact on final regret bounds
2. **Distribution shift quantification**: Implement methods to empirically measure TV(¯Dc, ¯Dλ) on real datasets and test whether skewed mixture λ effectively reduces this term
3. **Scalability testing**: Evaluate the federated algorithm's performance with increasing numbers of clients and varying client participation rates to identify potential bottlenecks in the aggregation process