---
ver: rpa2
title: 'MSight: An Edge-Cloud Infrastructure-based Perception System for Connected
  Automated Vehicles'
arxiv_id: '2310.05290'
source_url: https://arxiv.org/abs/2310.05290
tags:
- object
- perception
- roadside
- detection
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MSight is a full-stack edge-cloud roadside perception system for
  connected automated vehicles that provides real-time vehicle detection, localization,
  tracking, and trajectory prediction with lane-level accuracy. The system uses fisheye
  cameras mounted at a roundabout's corners, processes data through an edge device,
  and transmits results via V2X radio with 40ms latency.
---

# MSight: An Edge-Cloud Infrastructure-based Perception System for Connected Automated Vehicles

## Quick Facts
- arXiv ID: 2310.05290
- Source URL: https://arxiv.org/abs/2310.05290
- Authors: 
- Reference count: 40
- Primary result: 82% MOTA tracking score with 40ms V2X latency at Michigan roundabout

## Executive Summary
MSight is a full-stack edge-cloud roadside perception system for connected automated vehicles that provides real-time vehicle detection, localization, tracking, and trajectory prediction with lane-level accuracy. The system uses fisheye cameras mounted at a roundabout's corners, processes data through an edge device, and transmits results via V2X radio with 40ms latency. Field tests demonstrate detection accuracy with 11.83% false negative rate, 4.51% false positive rate, and 0.63m lateral error using four-camera setup, achieving 82% MOTA tracking score. The system operates 24/7 at a Michigan roundabout and meets CAV requirements for accuracy and latency.

## Method Summary
MSight employs fisheye cameras at roundabout corners connected to an edge device running YOLOX-nano for object detection, with camera calibration using landmark-based methods and image alignment for drift compensation. The system fuses multi-camera detections, performs tracking using SORT with transformer-based trajectory prediction, and transmits encoded results via RSU radio to CAVs. The cloud component handles data storage and microservices. The pipeline includes detection, localization via image-to-world mapping, multi-camera fusion, tracking with modified SORT, and trajectory prediction for 5-frame horizons.

## Key Results
- 82% MOTA tracking score with 11.83% false negative rate and 4.51% false positive rate
- 0.63m lateral localization error with four-camera setup
- 40ms total V2X communication latency (35ms phase 1, 5ms phase 2)

## Why This Works (Mechanism)

### Mechanism 1
Edge-device processing of fisheye images provides low-latency perception results suitable for CAV safety applications. Fisheye cameras mounted at roundabout corners capture wide field-of-view images that are processed by a lightweight YOLOX-nano object detector running on an Nuvo edge device. The edge device fuses detections from multiple cameras and transmits encoded results via RSU radio to CAVs within 40ms. Core assumption: Fisheye cameras provide sufficient resolution and coverage to detect vehicles at lane-level accuracy while edge-device inference latency remains below CAV safety thresholds. Evidence anchors: [abstract] "processes data through an edge device, and transmits results via V2X radio with 40ms latency" [section III-A] "The principal objective of the roadside portion is to execute the perception algorithm... and to convey the resulting perceptions to CA Vs with minimal latency". Break condition: Edge device computational capacity insufficient for real-time YOLOX-nano inference, or fisheye image resolution degrades beyond detection accuracy requirements.

### Mechanism 2
Camera calibration and image alignment compensate for long-term sensor pose drift, maintaining localization accuracy over extended deployment periods. Landmark-based calibration establishes homography transformations between fisheye images and world coordinates. Image alignment using Enhanced Correlation Coefficient compensates for camera view changes caused by pole deformation or metal creep, ensuring consistent calibration accuracy. Core assumption: Landmark positions remain stable and identifiable in both satellite imagery and camera views over time. Evidence anchors: [section IV-A] "landmark-based calibration method... using these landmark pairs from the two images" [section IV-B] "we develop an image alignment algorithm to align the images to a set of standard images". Break condition: Landmarks become obscured, removed, or significantly altered due to construction or environmental changes, making calibration impossible.

### Mechanism 3
Transformer-based trajectory prediction improves tracking continuity by incorporating historical trajectories and multi-object interactions. SORT tracking algorithm is modified to use transformer-predicted future positions instead of Kalman filter estimates for object association. The transformer processes historical trajectories of all objects to predict future positions, enabling detection of complex behaviors like yielding. Core assumption: Historical trajectory patterns contain sufficient information to predict future vehicle behavior with reasonable accuracy. Evidence anchors: [section IV-E] "we use the predicted future locations of each target provided by our transformer-based trajectory prediction module instead of the Kalman Filter for association" [section IV-F-a] "the transformer consists of multiple transformer encoder layers... Each transformer encoder layer contains a self-attention layer". Break condition: Trajectory patterns become too complex or unpredictable for the transformer model to generalize, causing prediction errors that degrade tracking performance.

## Foundational Learning

- Fisheye camera geometry and distortion models: Fisheye cameras are used instead of standard cameras for their wide field-of-view coverage, but require specialized calibration and undistortion techniques for accurate vehicle localization. Quick check question: What mathematical model describes fisheye lens distortion and how does it differ from standard pinhole camera models?

- Object detection and tracking algorithms: The system relies on YOLOX-nano for detection and SORT for tracking, requiring understanding of single-stage detectors and multi-object tracking fundamentals. Quick check question: How does the IoU-based association in SORT differ from other tracking approaches like deep association metrics?

- Transformer architecture for sequence prediction: The trajectory prediction module uses transformer encoders with self-attention to process historical trajectories and predict future vehicle positions. Quick check question: How does positional encoding in transformers enable the model to understand temporal sequence information?

## Architecture Onboarding

- Component map: Fisheye cameras → Edge device (YOLOX-nano detector + image alignment + multi-camera fusion + SORT tracker + transformer predictor) → RSU radio → CAVs; Cloud component for data storage and microservices
- Critical path: Camera capture → Edge processing → V2X transmission → CAV reception (total < 40ms)
- Design tradeoffs: Fisheye cameras provide wider coverage but introduce distortion requiring calibration; lightweight YOLOX-nano sacrifices some accuracy for real-time performance; transformer predictor adds computational complexity but improves tracking
- Failure signatures: High false negative rates indicate detection issues; frequent ID switches suggest tracking failures; latency spikes point to edge device bottlenecks
- First 3 experiments:
  1. Measure YOLOX-nano inference latency and detection accuracy on sample fisheye images
  2. Test camera calibration accuracy using landmark points at different times of day
  3. Validate V2X message encoding/decoding and transmission latency with a test CAV

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of MSight degrade in adverse weather conditions such as heavy rain, snow, or fog? Basis in paper: [inferred] The paper mentions that roadside perception systems can be more accurate and reliable than onboard systems due to elevated positions and reduced occlusion. However, it does not explicitly test the system's performance in adverse weather conditions, which are known to affect perception systems. Why unresolved: The paper focuses on testing the system in normal weather conditions at a roundabout in Michigan. Adverse weather conditions are not simulated or tested, leaving the system's robustness in such scenarios unexplored. What evidence would resolve it: Testing MSight under various adverse weather conditions (rain, snow, fog) and comparing its performance metrics (detection accuracy, false positive/negative rates, tracking accuracy) with those in normal weather would provide evidence of its robustness.

### Open Question 2
What is the impact of sensor maintenance and calibration drift on the long-term performance of MSight? Basis in paper: [explicit] The paper discusses camera calibration and image alignment to compensate for view changes due to pole deformation or metal creep. However, it does not explore how maintenance and calibration drift over extended periods affect system performance. Why unresolved: The paper provides initial calibration error data but does not address long-term maintenance needs or the impact of calibration drift on detection and tracking accuracy over months or years. What evidence would resolve it: Longitudinal studies tracking MSight's performance metrics over extended periods (e.g., 6-12 months) with regular maintenance and recalibration would provide insights into the system's long-term reliability.

### Open Question 3
How does the system handle dynamic changes in the environment, such as construction zones or temporary obstacles? Basis in paper: [inferred] The paper describes the system's ability to detect and track vehicles in a roundabout setting but does not address its adaptability to dynamic environmental changes like construction zones or temporary obstacles. Why unresolved: The evaluation is conducted in a controlled roundabout environment without dynamic changes, leaving questions about the system's flexibility and adaptability in real-world scenarios with temporary obstacles or construction. What evidence would resolve it: Testing MSight in environments with dynamic changes, such as temporary construction zones or moving obstacles, and analyzing its ability to adapt and maintain performance would provide evidence of its adaptability.

## Limitations

- System deployment constraints due to fisheye camera placement requirements and landmark availability for calibration
- Model generalization concerns from limited training data in specific roundabout environment
- Evaluation scope limitations excluding adverse weather conditions and nighttime performance

## Confidence

- **High confidence**: Edge-device processing achieves required 40ms latency; camera calibration methodology with landmark-based approach and image alignment; YOLOX-nano training procedure with specified augmentations
- **Medium confidence**: Detection accuracy metrics (11.83% FN, 4.51% FP); tracking performance (0.82 MOTA); overall system architecture and component integration
- **Low confidence**: Generalization to different environments; performance under adverse weather conditions; scalability to complex traffic scenarios

## Next Checks

1. **Cross-environment testing**: Deploy the system at a different intersection type (e.g., signalized intersection) and measure detection accuracy and tracking performance compared to the original roundabout deployment.

2. **Weather robustness evaluation**: Conduct systematic testing under various weather conditions including heavy rain, snow, and fog to quantify performance degradation and identify failure modes.

3. **High-density traffic scenario testing**: Evaluate system performance with increased vehicle density (3+ simultaneous vehicles) and complex interactions (multiple yielding scenarios, emergency vehicle presence) to assess tracking continuity and prediction accuracy.