---
ver: rpa2
title: 'CMA-ES for Post Hoc Ensembling in AutoML: A Great Success and Salvageable
  Failure'
arxiv_id: '2307.00286'
source_url: https://arxiv.org/abs/2307.00286
tags:
- cma-es
- data
- methods
- automl
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates overfitting in greedy ensemble selection
  (GES) for AutoML post-hoc ensembling. The authors compare GES to CMA-ES, a state-of-the-art
  gradient-free optimizer, across 71 datasets using AutoGluon.
---

# CMA-ES for Post Hoc Ensembling in AutoML: A Great Success and Salvageable Failure

## Quick Facts
- arXiv ID: 2307.00286
- Source URL: https://arxiv.org/abs/2307.00286
- Reference count: 25
- Primary result: CMA-ES overfits for ROC AUC but not balanced accuracy; normalization based on GES constraints salvages performance.

## Executive Summary
This paper investigates overfitting in greedy ensemble selection (GES) versus CMA-ES for post-hoc ensemble selection in AutoML. The authors find that CMA-ES overfits for threshold-independent metrics like ROC AUC while performing well for balanced accuracy. They attribute this to CMA-ES's continuous and dense weight vectors versus GES's pseudo-discrete and sparse weights. The authors propose normalizing CMA-ES weights before aggregation, inspired by GES properties, which successfully combats overfitting for ROC AUC and makes CMA-ES perform as well as or better than GES.

## Method Summary
The study compares CMA-ES to GES across 71 classification datasets using AutoGluon-generated base models. Both methods use 10-fold cross-validation with 4 hours of AutoGluon training. CMA-ES optimizes weight vectors without constraints by default, while GES implicitly constrains weights to be pseudo-discrete and sparse. The authors propose normalizing CMA-ES weights before aggregation using softmax followed by explicit GES normalization (trimming weights below 0.5/Nhyp). They evaluate performance using balanced accuracy and ROC AUC (macro average one-vs-rest for multi-class), analyzing overfitting by comparing validation versus test ranks.

## Key Results
- CMA-ES outperforms GES for balanced accuracy without overfitting
- CMA-ES overfits for ROC AUC, performing worse than GES on test data
- Normalized CMA-ES (CMA-ES-ExplicitGES) successfully combats overfitting for ROC AUC
- Normalized CMA-ES performs as well as or better than GES for both metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Normalization before aggregation prevents CMA-ES from overfitting by constraining weight vectors to be sparse and sum to 1, similar to GES's implicit constraints.
- Mechanism: The normalization step transforms the weight vector into a form that mimics GES's pseudo-discrete and sparse property. By applying softmax and then rounding to the nearest fraction with denominator Nhyp, the method ensures weights sum to 1 and are sparse.
- Core assumption: The sparsity and pseudo-discrete nature of GES's weight vectors are essential for preventing overfitting.
- Evidence anchors:
  - [section] "While analysing GES, we found two constraints of the weight vector WpDisc that we believe to be essential for its performance. That is, WpDisc is pseudo-discrete and sparse."
  - [section] "Thus, our first idea was to constrain the optimization process of CMA-ES such that it would produce results that match the constraints of GES."
- Break condition: If the normalization step does not adequately enforce sparsity or the sum-to-1 constraint, CMA-ES may still overfit.

### Mechanism 2
- Claim: CMA-ES's continuous and dense weight vectors without constraints lead to overfitting, especially for threshold-independent metrics like ROC AUC.
- Mechanism: Without normalization, CMA-ES can assign any real-valued weight to each base model, including negative values. This allows the optimizer to fit noise in the validation data, leading to overfitting when evaluated on test data.
- Core assumption: The lack of constraints on CMA-ES's weight vectors is the primary cause of overfitting.
- Evidence anchors:
  - [section] "In contrast, our application of CMA-ES uses no such constraints. By default, CMA-ES produces a continuous and dense vector which does not need to sum to 1 and may contain negative or positive values of any granularity."
  - [section] "As a result, we were motivated to apply the same concept to CMA-ES by normalizing the weight vector before we aggregate the predictions of the base models."
- Break condition: If the validation data is of sufficiently high quality, CMA-ES might not overfit even without normalization.

### Mechanism 3
- Claim: The choice of normalization method significantly impacts CMA-ES's performance, with softmax followed by explicit GES normalization (CMA-ES-ExplicitGES) being optimal for ROC AUC.
- Mechanism: CMA-ES-ExplicitGES combines softmax normalization with explicit trimming of base models and adjustment of the total number of repetitions to match Nhyp. This approach closely simulates GES's behavior and constraints.
- Core assumption: Simulating GES's constraints as closely as possible will yield the best performance for CMA-ES.
- Evidence anchors:
  - [section] "We use CMA-ES-ExplicitGES for the final evaluation below because it is the only approach that is in line with GES’s concepts."
  - [section] "First, we compute W^s and trim any base model smaller than 0.5/Nhyp. If we set all weights to zero, we fall back to an unweighted average."
- Break condition: If the assumptions about GES's optimal constraints are incorrect, CMA-ES-ExplicitGES might not be the best normalization method.

## Foundational Learning

- Concept: Greedy Ensemble Selection (GES) and its properties (pseudo-discrete and sparse weight vectors).
  - Why needed here: Understanding GES is crucial for comprehending why normalization is needed for CMA-ES and how the normalization methods are designed.
  - Quick check question: What are the two key properties of GES's weight vectors that help prevent overfitting?

- Concept: Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and its default behavior.
  - Why needed here: Knowing how CMA-ES works without constraints explains why it overfits and why normalization is necessary.
  - Quick check question: What are the characteristics of the weight vectors produced by CMA-ES without any normalization?

- Concept: Threshold-independent metrics (like ROC AUC) and their requirements.
  - Why needed here: Understanding why softmax is applied after aggregation for ROC AUC explains the design of the normalization methods.
  - Quick check question: Why is it necessary to transform aggregated probabilities using softmax for ROC AUC?

## Architecture Onboarding

- Component map: AutoGluon -> CMA-ES optimization -> Normalization -> Ensemble aggregation -> Evaluation
- Critical path: AutoGluon generates base models → CMA-ES optimizes weight vectors → Normalization transforms weights → Ensemble aggregation combines predictions → Evaluation compares methods
- Design tradeoffs:
  - Sparsity vs. performance: Enforcing sparsity through normalization may reduce performance for some metrics
  - Computational cost: Normalization adds overhead to the optimization process
  - Complexity: The normalization methods add complexity to the ensemble selection process
- Failure signatures:
  - Overfitting: CMA-ES performs well on validation data but poorly on test data
  - Underfitting: The normalization methods are too restrictive, leading to suboptimal performance
  - Incorrect normalization: The weight vectors are not properly normalized, leading to errors in ensemble aggregation
- First 3 experiments:
  1. Run CMA-ES without normalization on a binary classification dataset with ROC AUC metric and compare validation vs. test performance to observe overfitting.
  2. Apply CMA-ES-ExplicitGES normalization to the same dataset and metric and compare the results to the unnormalized version.
  3. Compare CMA-ES-ExplicitGES to GES on a multi-class classification dataset with balanced accuracy metric to verify that normalization is not always beneficial.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would CMA-ES with constraints during optimization compare to the proposed normalization approach for combating overfitting in ROC AUC?
- Basis in paper: [explicit] The paper mentions that constraining CMA-ES is not trivial and was not able to make it produce solutions fulfilling all GES constraints, but leaves more sophisticated approaches to constrain CMA-ES for future work.
- Why unresolved: The authors did not explore constraint-based approaches due to implementation difficulties and chose to pursue normalization instead.
- What evidence would resolve it: Direct comparison of constrained CMA-ES implementations versus the normalization approach on the same datasets and metrics.

### Open Question 2
- Question: Would the proposed normalization method work equally well for other gradient-free optimizers beyond CMA-ES?
- Basis in paper: [inferred] The paper focuses specifically on CMA-ES but discusses the general concept of normalizing weights before aggregation, inspired by GES properties.
- Why unresolved: The study only tested the normalization approach with CMA-ES and did not explore its applicability to other optimizers like particle swarm optimization or differential evolution.
- What evidence would resolve it: Testing the normalization method with multiple gradient-free optimizers on the same datasets and comparing results.

### Open Question 3
- Question: How does the performance of post-hoc ensembling methods change with different validation data quality levels?
- Basis in paper: [explicit] The paper contrasts Auto-Sklearn's low-quality validation data (33% hold-out) with AutoGluon's higher-quality validation data (n-repeated k-fold cross-validation) as motivation for the study.
- Why unresolved: The experiments only used AutoGluon's validation setup and did not systematically vary validation data quality to measure its impact on overfitting.
- What evidence would resolve it: Experiments with the same post-hoc ensembling methods using varying validation data quality levels (e.g., different hold-out percentages, different cross-validation schemes) on identical datasets.

## Limitations

- The findings are specific to AutoGluon's base model generation and may not transfer directly to other AutoML systems
- The study focuses on runtime efficiency but doesn't deeply explore computational costs of the normalization methods
- The analysis of why GES works well is based on observational evidence rather than theoretical guarantees

## Confidence

- Overfitting of CMA-ES for ROC AUC: High
- Effectiveness of normalization approach: Medium
- Generalization to other AutoML systems: Medium
- Understanding of GES's superior performance: Medium

## Next Checks

1. **Cross-system validation**: Apply CMA-ES-ExplicitGES to Auto-Sklearn's ensemble selection framework and verify if the overfitting pattern persists across different base model generators.

2. **Hyperparameter sensitivity**: Systematically vary the CMA-ES population size, learning rate, and normalization thresholds to determine the robustness of the proposed approach to hyperparameter choices.

3. **Extended metric analysis**: Evaluate the normalized CMA-ES approach on additional threshold-dependent metrics (like precision@k or F1-score) to understand whether the normalization benefits generalize beyond ROC AUC.