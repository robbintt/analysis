---
ver: rpa2
title: Recursive Visual Programming
arxiv_id: '2312.02249'
source_url: https://arxiv.org/abs/2312.02249
tags:
- patch
- image
- patches
- recursive
- return
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Recursive Visual Programming (RVP) addresses the limitation of
  single-function code generation in visual question answering by introducing a recursive,
  modular approach inspired by human coding practices. The method adds a recursivequery
  API to decompose complex questions into sub-questions, generating separate code
  pieces for each, with dynamic type assignment for flexible return types.
---

# Recursive Visual Programming

## Quick Facts
- arXiv ID: 2312.02249
- Source URL: https://arxiv.org/abs/2312.02249
- Reference count: 40
- Improves VQA accuracy to 70.23% on GQA test-dev and 67.86% on COVR

## Executive Summary
Recursive Visual Programming (RVP) introduces a recursive, modular approach to visual question answering that addresses the limitations of single-function code generation. By decomposing complex questions into sub-questions using a recursive_query API, RVP generates separate code pieces for each component while dynamically assigning return types. This approach improves both code readability and accuracy in handling multi-step reasoning tasks, outperforming non-recursive methods and previous few-shot models on multiple VQA benchmarks.

## Method Summary
RVP implements recursive visual programming by extending the visual programming paradigm with a recursive_query API that decomposes questions into sub-questions, generating separate code pieces for each. The method uses dynamic type assignment to determine appropriate return types contextually, allowing the model to generate syntactically and semantically correct code. In-context learning with few-shot examples teaches the model recursive patterns and type assignment strategies.

## Key Results
- Achieves 70.23% accuracy on GQA test-dev, outperforming previous few-shot models
- Reaches 67.86% accuracy on COVR benchmark
- Demonstrates improved code readability and accuracy compared to non-recursive visual programming methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Recursive decomposition improves code readability and accuracy by allowing the model to handle sub-questions independently
- Mechanism: The recursive_query API breaks complex questions into simpler sub-questions, generating separate code pieces for each, which reduces context length and allows focused reasoning on each sub-problem
- Core assumption: LLMs perform better on shorter, focused prompts than on long, complex ones containing all reasoning steps
- Evidence anchors:
  - [abstract]: "RVP is inspired by human coding practices and approaches VQA tasks with an iterative recursive code generation approach, allowing decomposition of complicated problems into smaller parts"
  - [section 4.3]: "RVP circumvents this issue by pushing the LLM to commit to the answer types earlier in its generation"
  - [corpus]: Weak - no direct evidence found about recursive decomposition improving LLM performance
- Break condition: When sub-questions become too simple to benefit from separate processing, or when context switching overhead outweighs benefits

### Mechanism 2
- Claim: Dynamic type assignment enables more flexible and accurate code generation by allowing return types to be determined contextually
- Mechanism: The model specifies expected return types in recursive_query calls, allowing it to generate code with appropriate signatures and return values for each sub-question
- Core assumption: Explicitly specifying types in prompts helps LLMs generate syntactically and semantically correct code
- Evidence anchors:
  - [abstract]: "RVP is capable of dynamic type assignment, i.e., as the system recursively generates a new piece of code, it autonomously determines the appropriate return type"
  - [section 3.3]: "When the code generator writes a recursive query function, it can include the expected return type as a part of the question"
  - [section 4.4]: "Specified dynamic type assignment in RVP achieves the highest performance"
- Break condition: When type inference becomes ambiguous or when the model struggles to maintain type consistency across recursive calls

### Mechanism 3
- Claim: Recursive visual programming improves interoperability by creating more modular, self-explanatory code structures
- Mechanism: Recursive decomposition creates code where each function handles a specific sub-task, making the overall logic more transparent and easier to follow
- Core assumption: Human programmers find modular code more understandable than monolithic code blocks
- Evidence anchors:
  - [section 4.5]: "Participants consistently understood the recursive code faster than the non-recursive versions"
  - [section 1]: "Current VP methods generate all code in a single function, resulting in code that is suboptimal in terms of both accuracy and interpretability"
  - [corpus]: Weak - no direct evidence found about human readability of recursive vs non-recursive code
- Break condition: When excessive recursion creates too many small functions that are harder to understand than a single cohesive block

## Foundational Learning

- Concept: Visual Programming Framework
  - Why needed here: RVP builds on the visual programming paradigm where code generation and execution are separated into two stages
  - Quick check question: What are the two main functions in visual programming, and how do they interact?

- Concept: In-Context Learning with LLMs
  - Why needed here: RVP relies on few-shot prompting to teach the model recursive patterns and dynamic type assignment
  - Quick check question: How does in-context learning differ from fine-tuning, and why is it important for RVP's approach?

- Concept: Type Systems in Programming
  - Why needed here: Dynamic type assignment is central to RVP's ability to generate flexible code with appropriate return types
  - Quick check question: What is the difference between static and dynamic type assignment, and how does RVP use dynamic assignment?

## Architecture Onboarding

- Component map: Question → Recursive decomposition → Type assignment → Code generation for each sub-question → Execution → Aggregation of results → Final answer
- Critical path: Question → Recursive decomposition → Type assignment → Code generation for each sub-question → Execution → Aggregation of results → Final answer
- Design tradeoffs: Recursive decomposition improves readability but adds overhead; dynamic types increase flexibility but require more complex prompt engineering; the approach trades simplicity for modularity
- Failure signatures: Type confusion errors, excessive recursion depth, context loss across recursive calls, failure to properly aggregate sub-answers
- First 3 experiments:
  1. Implement non-recursive baseline on a simple VQA dataset to establish performance baseline
  2. Add recursive_query API with fixed return types to measure impact of recursion alone
  3. Implement dynamic type assignment and test on questions requiring different return types

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal strategy for selecting in-context examples for recursive visual programming?
- Basis in paper: [explicit] The paper mentions that retrieval-based in-context example selection was tested but resulted in lower accuracy despite higher recursion rates.
- Why unresolved: The study showed that while embedding-based retrieval encourages more diverse recursive patterns, it requires careful selection of the example pool and tuning of the examples. The optimal method for selecting the most suitable examples for recursive decomposition remains unclear.
- What evidence would resolve it: Comparative studies testing different in-context example selection strategies (e.g., random selection, similarity-based retrieval, task-specific curation) on multiple datasets to identify which approach yields the best balance of recursion rate and accuracy.

### Open Question 2
- How can open-source models be optimized for recursive visual programming tasks?
- Basis in paper: [explicit] The paper tested CodeLlama on GQA and found it underperformed compared to GPT-3.5-turbo, particularly in handling unseen types like List[str] or List[ImagePatch].
- Why unresolved: While CodeLlama demonstrated the ability to code recursively and showed promising reasoning abilities, it fell short in code correctness and type handling. The paper suggests that additional format tuning, example selection, or tailored coding may be necessary to improve open-source model performance.
- What evidence would resolve it: Systematic experiments with prompt engineering, fine-tuning, and architectural modifications to improve open-source models' ability to handle recursive patterns and dynamic type assignment.

### Open Question 3
- What are the limitations of dynamic type assignment in recursive visual programming?
- Basis in paper: [explicit] The error rate analysis showed that while gpt-3.5-turbo achieved 0% type errors with explicit type specification, CodeLlama had 4.91% errors primarily due to type confusion, and implicit type specification led to 56.14% errors.
- Why unresolved: The study identified that explicit type specification is crucial for type correctness, but the underlying reasons for model failures in type tracking and the generalizability of this approach to more complex type systems remain unexplored.
- What evidence would resolve it: Comparative analysis of type assignment strategies across different model architectures and datasets, along with investigation into how type complexity affects performance and error patterns.

## Limitations

- Human readability benefits lack broader validation beyond a single user study
- Limited comparison with larger models like GPT-4
- Ablation studies don't fully explore interaction between recursion depth and performance

## Confidence

**High Confidence**: The performance improvements on benchmark datasets (70.23% on GQA test-dev, 67.86% on COVR) are well-supported by the experimental results. The effectiveness of dynamic type assignment in improving accuracy is strongly evidenced by the ablation studies showing performance degradation when types are not explicitly specified.

**Medium Confidence**: The claims about improved code readability and human understanding of recursive code are supported by one user study but lack broader validation. The mechanism by which recursion improves LLM performance (through reduced context length and focused reasoning) is plausible but not directly tested.

**Low Confidence**: The assertion that current visual programming methods are "suboptimal in terms of both accuracy and interpretability" compared to RVP is stated but not empirically validated against all existing approaches. The long-term implications for maintenance and debugging of recursive visual programs are not explored.

## Next Checks

1. **Cross-Domain Robustness Test**: Evaluate RVP on additional visual domains (medical imaging, satellite imagery, industrial inspection) to assess generalization beyond the current benchmark datasets.

2. **Human Code Quality Assessment**: Conduct a larger-scale study comparing human programmers' ability to debug, modify, and extend recursive visual code versus traditional visual programming code across multiple complexity levels.

3. **Scalability Analysis**: Test RVP's performance and efficiency on progressively more complex questions requiring deeper recursion (5+ levels) to identify breaking points and potential optimizations.