---
ver: rpa2
title: Compositional Foundation Models for Hierarchical Planning
arxiv_id: '2309.08587'
source_url: https://arxiv.org/abs/2309.08587
tags:
- planning
- subgoal
- video
- uni00000018
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces HiP, a compositional foundation model for
  hierarchical planning that leverages multiple pretrained expert models trained on
  language, vision, and action data individually. The key idea is to decompose long-horizon
  decision-making tasks into three levels of hierarchy: task planning with a large
  language model, visual planning with a video diffusion model, and action planning
  with an inverse dynamics model.'
---

# Compositional Foundation Models for Hierarchical Planning

## Quick Facts
- arXiv ID: 2309.08587
- Source URL: https://arxiv.org/abs/2309.08587
- Reference count: 40
- Key outcome: HiP achieves up to 74.3% success rate on seen tasks and 72.8% on unseen tasks in the paint-block domain

## Executive Summary
This paper introduces HiP, a compositional foundation model for hierarchical planning that decomposes long-horizon decision-making into three levels: task planning with a large language model, visual planning with a video diffusion model, and action planning with an inverse dynamics model. The key innovation is composing separate expert models trained on language, vision, and action data individually, using iterative refinement to ensure consistency across levels. Experiments on three long-horizon tabletop manipulation tasks show HiP significantly outperforms strong baselines, achieving up to 74.3% success rate on seen tasks and 72.8% on unseen tasks in the paint-block domain.

## Method Summary
HiP composes three pretrained expert models—a large language model for symbolic planning, a video diffusion model for visual trajectory generation, and an inverse dynamics model for action inference—using iterative refinement to ensure consistency. The approach trains classifiers for subgoal selection and trajectory feasibility rather than collecting paired multi-modal data. The method is evaluated on three simulation environments (paint-block, object-arrange, kitchen-tasks) with both seen and unseen tasks, comparing against baselines like Transformer BC, Gato, and UniPi.

## Key Results
- HiP achieves 74.3% success rate on seen tasks and 72.8% on unseen tasks in the paint-block domain
- Outperforms strong baselines including Transformer BC, Gato, Trajectory Transformer, Action Diffuser, UniPi, and SayCan
- Ablation study shows iterative refinement and subgoal granularity significantly impact performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Iterative refinement enforces consistency between levels of hierarchy by using feedback from downstream models during the generation process.
- Mechanism: At each step of the language model's generative process, intermediate feedback from a visual plausibility model refines the subgoal distribution. Similarly, during video diffusion, feedback from an action feasibility model refines the observation trajectory generation.
- Core assumption: The downstream model's feedback can approximate the joint likelihood of the entire hierarchical decision-making process.
- Evidence anchors:
  - [abstract] "To enable effective reasoning within this hierarchy, we enforce consistency between the models via iterative refinement."
  - [section] "To create consistent plans across our disparate models, we propose an iterative refinement mechanism to ensure consistency using feedback from the downstream models [28]."

### Mechanism 2
- Claim: Pretraining the visual and action models on large-scale internet data provides rich priors that enable effective generalization to novel tasks.
- Mechanism: The video diffusion model is pretrained on Ego4D to capture physically plausible motions and visual priors. The inverse dynamics model is initialized with weights from VC-1, a vision transformer trained on egocentric images.
- Core assumption: The internet-scale data contains sufficient diversity to provide useful priors for a wide range of tasks.
- Evidence anchors:
  - [abstract] "we leverage multiple expert foundation model trained on language, vision and action data individually jointly together to solve long-horizon tasks."
  - [section] "The compositional design choice for decision-making allows separate models to reason at different levels of the hierarchy, and jointly make expert decisions without the need for ever collecting expensive paired decision-making data across modalities."

### Mechanism 3
- Claim: The hierarchical decomposition allows each model to specialize in its domain and improve overall performance.
- Mechanism: The language model handles abstract reasoning and subgoal generation, the video diffusion model handles geometric and physical reasoning for observation trajectory generation, and the inverse dynamics model handles visual-motor control for action prediction.
- Core assumption: Each level of the hierarchy can be effectively modeled by a separate foundation model, and the models can be composed to solve the overall task.
- Evidence anchors:
  - [abstract] "we use a large language model to construct symbolic plans that are grounded in the environment through a large video diffusion model. Generated video plans are then grounded to visual-motor control, through an inverse dynamics model that infers actions from generated videos."
  - [section] "Given an abstract language instruction describing the desired task, HiP uses a large language model to find a sequence of sub-tasks (i.e., planning)."

## Foundational Learning

- **Concept:** Large language models (LLMs) and their ability to perform zero-shot reasoning and planning.
  - Why needed here: The LLM is used as the task planner to decompose the high-level goal into a sequence of subgoals.
  - Quick check question: What are the key differences between fine-tuning an LLM and using it for zero-shot reasoning?

- **Concept:** Diffusion models and their application to video generation and planning.
  - Why needed here: The video diffusion model is used for visual planning to generate observation trajectories.
  - Quick check question: How does classifier-free guidance work in diffusion models, and why is it used in this paper?

- **Concept:** Inverse dynamics models and their role in inferring actions from observations.
  - Why needed here: The inverse dynamics model is used for action planning to infer actions from the generated observation trajectories.
  - Quick check question: What is the difference between an inverse dynamics model and a forward dynamics model, and when would you use each?

## Architecture Onboarding

- **Component map:** Task Planning (LLM) → Visual Planning (Video Diffusion) → Action Planning (Inverse Dynamics)
- **Critical path:** Task Planning → Visual Planning → Action Planning, with iterative refinement ensuring consistency across steps
- **Design tradeoffs:** Using separate foundation models reduces paired data requirements but adds composition complexity; pretraining provides rich priors but may introduce domain biases; iterative refinement ensures consistency but adds computational overhead
- **Failure signatures:** Inconsistent plans across hierarchy levels, poor generalization to novel tasks, slow planning due to computational cost
- **First 3 experiments:**
  1. Test the subgoal prediction accuracy of the learned classifier and the frozen VLM on a held-out set of tasks
  2. Evaluate the performance of HiP with and without iterative refinement on a set of long-horizon tasks
  3. Analyze the impact of pretraining the video diffusion model on the Ego4D dataset by comparing its performance with and without pretraining

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the performance of HiP change if high-quality video foundation models for visual planning were available instead of the smaller-scale models used in this paper?
- Basis in paper: [explicit] The paper states "Currently, large pretrained models are readily available in the language domain only. Ideally, one would train a foundation model for videos and ego-centric actions, which we believe will be available in the near future."
- Why unresolved: The paper uses smaller-scale video models trained in simulation as proxies for larger pretrained models due to computational resource limitations.
- What evidence would resolve it: Implementing HiP with actual high-quality pretrained video foundation models and comparing its performance to the current version using smaller-scale models on the same long-horizon tasks.

### Open Question 2
- Question: What is the optimal granularity level for subgoals in HiP across different task domains?
- Basis in paper: [explicit] The paper conducts an ablation study varying subgoal granularity in the paint-block environment and observes performance changes.
- Why unresolved: The ablation study only examines one environment (paint-block) with three granularity levels.
- What evidence would resolve it: Systematic ablation studies varying subgoal granularity across all three task domains (paint-block, object-arrange, and kitchen-tasks) and potentially more granularity levels.

### Open Question 3
- Question: How would HiP perform with more advanced Vision-Language Models (VLMs) for visually grounding the LLM in complex environments?
- Basis in paper: [explicit] The paper explores using a frozen pretrained VLM (MiniGPT-4) as a classifier but finds it underperforms compared to a learned classifier in the more visually complex object-arrange environment.
- Why unresolved: The paper only tests one VLM (MiniGPT-4) and suggests future VLMs might match learned classifier performance.
- What evidence would resolve it: Implementing HiP with newer, more advanced VLMs and comparing their performance to the learned classifier across all task domains.

## Limitations

- Scalability to more complex, real-world environments with greater task diversity remains uncertain
- Computational overhead from iterative refinement may limit real-time applicability
- Reliance on pretraining data from internet-scale sources raises concerns about domain mismatches and biases

## Confidence

- **High confidence:** The compositional architecture and iterative refinement mechanism are well-established concepts with solid theoretical grounding
- **Medium confidence:** Generalization claims to unseen tasks are supported by experimental results but limited to tabletop manipulation
- **Medium confidence:** Scalability analysis and computational requirements are based on current implementations but may not fully capture real-world deployment challenges

## Next Checks

1. **Real-world deployment test:** Implement HiP on a physical robot platform to evaluate performance degradation when moving from simulation to reality
2. **Cross-domain generalization study:** Test HiP on non-manipulation tasks (e.g., navigation or assembly tasks) to assess generalization beyond tabletop environments
3. **Ablation study on refinement iterations:** Systematically vary the number of iterative refinement iterations to quantify the trade-off between planning quality and computational cost