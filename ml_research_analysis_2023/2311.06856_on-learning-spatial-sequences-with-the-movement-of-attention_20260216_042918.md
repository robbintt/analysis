---
ver: rpa2
title: On learning spatial sequences with the movement of attention
arxiv_id: '2311.06856'
source_url: https://arxiv.org/abs/2311.06856
tags:
- sequence
- learning
- spatial
- sequences
- different
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Humans can recognize spatial sequences across modalities (e.g.,
  visually perceived patterns and somatosensory input) through invariant representations.
  This invariance holds despite variations in scale, orientation, or location.
---

# On learning spatial sequences with the movement of attention

## Quick Facts
- arXiv ID: 2311.06856
- Source URL: https://arxiv.org/abs/2311.06856
- Reference count: 40
- Primary result: Humans recognize spatial sequences across modalities through invariant representations accessed via attention movements, not parametric curves

## Executive Summary
This paper proposes that invariant spatial sequence recognition across modalities (visual, somatosensory) is achieved through movement of attention rather than parametric representations. Traditional mathematical approaches struggle with invariance under transformations like rotation and scaling, but the brain uses attention movements to encode sequences as sequential instructions. Two key hypotheses are introduced: selectionism learning (generating and selecting features) and nonparametric data structures (efficient storage and comparison). The work suggests a fundamental departure from traditional parametric learning methods toward approaches emphasizing redundancy and multiple abstraction levels.

## Method Summary
The paper proposes two hypotheses for spatial sequence learning: selectionism learning, where features are generated and selected based on recurrence and correlation, and nonparametric data structures for efficient storage and comparison. The approach centers on movement of attention as a computational primitive, creating invariant representations through multi-scale processing and redundant encoding. Unlike parametric optimization, this method generates extensive candidate features and selects useful ones, trading memory for computational efficiency.

## Key Results
- Invariant spatial sequence recognition across modalities occurs through attention-based encoding, not parametric curves
- Movement of attention creates abstract representations that generalize across transformations (rotation, scale, translation)
- Multi-scale redundant representations enable comparison and generalization through different abstraction levels

## Why This Works (Mechanism)

### Mechanism 1
Invariant spatial sequence recognition across modalities is enabled by movement of attention that operates on abstract representations rather than raw sensory data. The brain uses attention movements to identify salient features across different scales and abstraction levels, creating invariant representations that generalize across transformations like rotation, translation, and scaling. Core assumption: The same abstract spatial representation exists across different sensory modalities and is accessed through attention movements. Break condition: If attention movements cannot maintain persistent activation across different modalities.

### Mechanism 2
Redundant multi-scale representations enable generalization by providing multiple abstraction levels for comparison and recognition. Spatial sequences are encoded at different scales simultaneously, where features can be treated separately or as composite units depending on the scale level, creating redundancy that supports recognition across variations. Core assumption: The brain maintains multiple simultaneous representations of the same spatial sequence at different scales, trading memory for computational efficiency. Break condition: If computational cost of maintaining multiple representations exceeds available resources.

### Mechanism 3
Selectionism learning enables efficient feature discovery by generating many candidate features and selecting those that recur across different inputs. Instead of optimizing parameters in a fixed model, the system generates extensive candidate features through movements of attention and selects those that demonstrate recurrence and correlation across different sensory inputs. Core assumption: A large set of possible features can be generated and a selection process can identify the most useful ones without requiring explicit labels or supervised learning. Break condition: If exponential growth of candidate features cannot be managed.

## Foundational Learning

- Concept: Spatial sequence representation invariance
  - Why needed here: The core problem is recognizing spatial patterns across different modalities and transformations, which requires representations that remain stable despite changes in scale, orientation, or location.
  - Quick check question: Can you explain why a parametric representation of a line segment fails for invariant recognition across translations?

- Concept: Movement of attention as computational primitive
  - Why needed here: Attention movements provide the mechanism for feature selection and comparison across different scales and abstraction levels, which is central to the proposed learning approach.
  - Quick check question: How does movement of attention differ from simple feature extraction in convolutional networks?

- Concept: Selectionism vs parametric optimization
  - Why needed here: The proposed approach fundamentally differs from traditional machine learning by generating many candidates and selecting rather than optimizing parameters in a fixed model.
  - Quick check question: What are the computational trade-offs between selectionism learning and traditional gradient-based optimization?

## Architecture Onboarding

- Component map:
  Attention Movement Controller -> Feature Generation Module -> Selection Mechanism -> Multi-scale Representation Store -> Comparison Engine

- Critical path:
  1. Attention movement across spatial regions and scales
  2. Feature extraction from attended regions
  3. Selection of recurring features across different inputs
  4. Formation of multi-scale representations
  5. Sequence recognition/comparison using selected features

- Design tradeoffs:
  - Memory vs computation: Multiple scale representations use more memory but reduce computational complexity
  - Feature generation vs selection: More candidates increase selection burden but improve chances of finding useful features
  - Abstraction vs specificity: Higher abstraction levels improve generalization but may lose specific details

- Failure signatures:
  - If attention movements cannot maintain persistent activation across modalities
  - If feature selection criteria are too weak or too strict
  - If computational cost of maintaining multi-scale representations is prohibitive
  - If exponential growth of candidate features overwhelms selection mechanisms

- First 3 experiments:
  1. Cross-modal sequence recognition test: Train on visual sequences, test recognition on somatosensory input
  2. Scale invariance test: Train on small-scale patterns, test recognition at different scales
  3. Selection efficiency test: Measure feature selection performance as candidate feature space grows exponentially

## Open Questions the Paper Calls Out

### Open Question 1
How do humans form invariant representations of spatial sequences across different modalities without large datasets or supervised learning? The paper highlights that humans can recognize spatial sequences across modalities through invariant representations, but does not provide a definitive answer on how these representations are formed. What evidence would resolve it: Experimental studies showing how the brain selects and stores invariant features from sensory inputs, or computational models that can replicate this process with minimal data.

### Open Question 2
What is the role of redundancy in forming abstract representations of spatial sequences, and how does it contribute to generalization? While the paper suggests that redundancy is important for recognition and generalization across different abstraction levels, it does not fully explain the mechanism by which redundant representations lead to better generalization. What evidence would resolve it: Studies demonstrating how redundant representations in the brain improve generalization across different tasks.

### Open Question 3
How can nonparametric data structures be designed to efficiently store and retrieve features and relationships for spatial sequence learning? The paper proposes nonparametric data structures for compactly storing features and their relationships, but does not provide a concrete example or design. What evidence would resolve it: Development and testing of computational models or algorithms that use nonparametric data structures to store and retrieve features efficiently.

## Limitations
- Selectionism learning creates potential computational intractability from exponential growth of candidate features
- Multi-scale representation hypothesis requires significant memory resources without clear evidence of efficient management
- Claims of truly invariant representations across modalities have limited direct experimental support

## Confidence
- High confidence: The problem formulation regarding spatial sequence invariance across transformations is well-established
- Medium confidence: The movement of attention as a computational primitive has supporting evidence but lacks detailed mechanistic understanding
- Low confidence: The selectionism learning hypothesis and nonparametric data structure claims are largely theoretical with minimal empirical validation

## Next Checks
1. **Cross-modal invariant test**: Design an experiment comparing human performance on spatial sequence recognition across visual and tactile modalities with machine learning models using both parametric and proposed attention-movement approaches.

2. **Selection efficiency benchmark**: Implement the feature generation and selection mechanism and measure computational scaling as candidate feature space grows. Compare with traditional parametric optimization approaches on the same tasks.

3. **Attention persistence measurement**: Using neuroimaging (fMRI/ECoG), track attention activation patterns during cross-modal spatial sequence tasks to verify whether the same neural populations are engaged across visual and somatosensory inputs.