---
ver: rpa2
title: User Behavior Simulation with Large Language Model based Agents
arxiv_id: '2306.02552'
source_url: https://arxiv.org/abs/2306.02552
tags:
- user
- recommender
- recommendation
- system
- users
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes RecAgent, a simulation framework for recommender
  systems based on large language models (LLMs). The key idea is to use LLMs to simulate
  user behaviors and preferences in a virtual recommender system environment.
---

# User Behavior Simulation with Large Language Model based Agents

## Quick Facts
- arXiv ID: 2306.02552
- Source URL: https://arxiv.org/abs/2306.02552
- Reference count: 38
- Key outcome: Proposes RecAgent, a simulation framework using LLMs to model user behaviors in recommender systems, demonstrating reasonable alignment with real human behavior.

## Executive Summary
This paper introduces RecAgent, a simulation framework for recommender systems based on large language models (LLMs). The framework simulates user behaviors and preferences in a virtual recommender system environment, consisting of a user module and a recommender module that interact with each other. Through case studies, the paper demonstrates that the simulated user behaviors are reasonable and aligned with real human behavior, opening up new possibilities for simulation-based studies in recommendation research.

## Method Summary
RecAgent is a two-module framework that simulates user behavior in recommender systems. The user module handles actions like browsing, searching, watching movies, and chatting/socializing with other users, while the recommender module provides search and recommendation results. Users interact with the system by querying an LLM to decide on actions based on prompts that include user memory and context. The LLM generates behavior consistent with learned patterns from training data. The framework allows for flexible evaluation of different recommendation strategies by observing their impact on simulated user behaviors.

## Key Results
- RecAgent successfully simulates user behaviors in recommender systems that are aligned with real human behavior
- The framework demonstrates the ability to model both internal user factors (temper, habits, gender) and external factors (social influence)
- Case studies show RecAgent's potential for exploring scenarios like cold start recommendation, social recommendation, RL-based recommendation, and explainable recommendation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can simulate user preferences and behaviors in recommender systems because they encode vast amounts of web knowledge and can generate contextually appropriate responses.
- Mechanism: The user module queries the LLM to decide on actions (browse, chat, broadcast) based on a prompt that includes user memory and context. The LLM generates behavior consistent with learned patterns from training data.
- Core assumption: The LLM's internal representations capture sufficient behavioral patterns to approximate human decision-making in the recommendation domain.
- Evidence anchors:
  - [abstract] "by learning huge amounts of web knowledge, large language models (LLMs) can achieve human-like intelligence"
  - [section 2.2] "all the users behave and produce their thoughts based on LLM"
- Break condition: If the LLM lacks domain-specific behavioral patterns or the prompts do not capture relevant context, the simulated behaviors will diverge from real human behavior.

### Mechanism 2
- Claim: The simulator can model both internal user factors (temper, habits, gender) and external factors (social influence) to produce realistic user behaviors.
- Mechanism: User memory banks store internal state, while the social module allows one-to-one chatting and one-to-many broadcasting to simulate external influence propagation.
- Core assumption: The combination of user memory and social interactions is sufficient to capture the key drivers of behavior in recommender systems.
- Evidence anchors:
  - [section 2.2] "a user may watch a movie because of her friends' recommendation or the movie is widely discussed on the social media"
  - [section 2.2.2] "the information dissemination process among the users on the social media is completely transparent"
- Break condition: If social influence is not a significant factor in user decision-making or the memory mechanism does not capture important internal states, the simulation will be incomplete.

### Mechanism 3
- Claim: The flexible recommender module allows evaluation of different recommendation strategies by observing their impact on simulated user behaviors.
- Mechanism: The recommender module implements search and recommendation algorithms that respond to user queries and generate recommendation lists. Different algorithms can be swapped in to test their effects.
- Core assumption: The simulated user responses to recommendations are sufficiently realistic to provide meaningful feedback on algorithm performance.
- Evidence anchors:
  - [section 2.3] "one can easily change the search/recommendation strategies, and initialize the candidate items with different public available or simulated datasets"
- Break condition: If the simulated user responses do not correlate with real user responses to recommendations, the simulation will not provide valid insights into algorithm performance.

## Foundational Learning

- Concept: Recommender system evaluation paradigms (real data-based vs. simulation-based)
  - Why needed here: Understanding the motivation for simulation-based approaches and their advantages/disadvantages is crucial for appreciating the contribution of this work.
  - Quick check question: What are the two main challenges of real data-based studies mentioned in the introduction?

- Concept: Large language model capabilities and limitations
  - Why needed here: The paper relies on LLMs to simulate user behaviors, so understanding what LLMs can and cannot do is essential for evaluating the approach.
  - Quick check question: What is the key advantage of using LLMs for user behavior simulation mentioned in the abstract?

- Concept: User behavior modeling in recommender systems
  - Why needed here: The paper aims to simulate user behaviors, so understanding the factors that influence user decisions in recommender systems is necessary for designing the simulation.
  - Quick check question: According to the paper, what are the two types of factors that influence user behaviors in recommender systems?

## Architecture Onboarding

- Component map: User module (browsing, chatting, broadcasting) -> Recommender module (search/recommendation) -> Front-end (visual interface)
- Critical path: User decides on action → User module queries LLM → User module updates memory and sends action to front-end → Recommender module processes user query and generates response → User module processes recommendation and updates memory
- Design tradeoffs: The use of LLMs for behavior simulation provides flexibility but may be computationally expensive and lack interpretability. The social interaction model captures external influence but may oversimplify real social dynamics.
- Failure signatures: If the simulated behaviors are not aligned with real human behaviors, if the recommender module does not respond appropriately to user queries, or if the front-end does not accurately visualize the simulation.
- First 3 experiments:
  1. Run a simple scenario with one user browsing the recommendation website and observe the generated behaviors.
  2. Add social interactions by having two users chat about movies and observe the impact on their browsing behaviors.
  3. Swap in different recommendation algorithms and compare the simulated user responses to evaluate algorithm performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of RecAgent compare to traditional recommendation algorithms on real-world datasets?
- Basis in paper: [inferred] The paper discusses RecAgent's potential for various recommendation tasks but does not provide empirical comparisons to existing methods.
- Why unresolved: The paper focuses on introducing RecAgent and its capabilities rather than benchmarking against established techniques.
- What evidence would resolve it: Empirical studies comparing RecAgent's recommendations against state-of-the-art methods on real-world datasets, measuring metrics like NDCG, precision, and recall.

### Open Question 2
- Question: Can RecAgent effectively model complex user preferences that evolve over time?
- Basis in paper: [inferred] The paper mentions RecAgent's ability to simulate user behaviors but does not explore how well it captures temporal dynamics in preferences.
- Why unresolved: The paper lacks experiments that track user preferences and behaviors over extended periods to assess RecAgent's ability to adapt to changing user needs.
- What evidence would resolve it: Longitudinal studies where RecAgent is used to simulate user behaviors over time, tracking how well it adapts to changes in user preferences and recommending relevant items accordingly.

### Open Question 3
- Question: How can RecAgent be scaled to handle large-scale recommendation systems with millions of users and items?
- Basis in paper: [inferred] The paper introduces RecAgent but does not address the computational challenges of scaling it to real-world recommendation scenarios.
- Why unresolved: The paper focuses on the conceptual framework and case studies but does not explore the practical challenges of deploying RecAgent in large-scale systems.
- What evidence would resolve it: Performance evaluations of RecAgent on large-scale datasets, measuring its computational efficiency and resource requirements compared to traditional recommendation methods.

## Limitations

- The framework's reliance on LLMs for behavior simulation introduces uncertainties about the alignment of simulated behaviors with real human actions
- The social interaction model may oversimplify the complexity of real social dynamics and information diffusion in recommender systems
- The framework's computational requirements for running LLM-based simulations could limit scalability to large user populations or long time horizons

## Confidence

**High Confidence**: The technical implementation of the two-module framework (user and recommender modules) is well-specified and reproducible. The approach of using LLMs to simulate user behaviors is grounded in established capabilities of these models.

**Medium Confidence**: The framework's ability to capture key behavioral drivers (internal factors like temper/habits and external factors like social influence) is reasonable, but the completeness of this modeling approach remains uncertain without validation against real user data.

**Low Confidence**: Claims about the framework's effectiveness in studying specific recommendation phenomena (information cocoons, user conformity) are largely based on illustrative examples rather than systematic evaluation.

## Next Checks

1. **Quantitative Behavioral Alignment**: Compare simulated user action sequences against real user interaction logs from a production recommender system using sequence similarity metrics (e.g., Levenshtein distance, sequence matching accuracy).

2. **Social Influence Propagation Validation**: Design an experiment where known information diffusion patterns are seeded in the simulated social network, then measure whether the propagation dynamics match established social network models.

3. **Algorithm Performance Correlation**: Run the same recommendation algorithms on both the simulated environment and real users, then compare key metrics (click-through rates, dwell time, diversity) to establish correlation between simulated and real user responses.