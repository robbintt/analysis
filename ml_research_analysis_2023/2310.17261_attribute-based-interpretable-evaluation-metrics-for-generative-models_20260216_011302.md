---
ver: rpa2
title: Attribute Based Interpretable Evaluation Metrics for Generative Models
arxiv_id: '2310.17261'
source_url: https://arxiv.org/abs/2310.17261
tags:
- attributes
- attribute
- images
- metrics
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces attribute-based interpretable evaluation
  metrics for generative models, addressing the need for more nuanced assessment beyond
  traditional diversity measures. The authors propose Single-attribute Divergence
  (SaD) and Paired-attribute Divergence (PaD) to measure discrepancies in attribute
  distributions and relationships between generated and training images.
---

# Attribute Based Interpretable Evaluation Metrics for Generative Models

## Quick Facts
- arXiv ID: 2310.17261
- Source URL: https://arxiv.org/abs/2310.17261
- Authors: 
- Reference count: 29
- Key outcome: Introduces attribute-based interpretable evaluation metrics (SaD, PaD, HCS) for generative models, revealing insights like ProjectedGAN's implausible attribute relationships and diffusion models' struggles with diverse colors.

## Executive Summary
This paper introduces attribute-based interpretable evaluation metrics for generative models, addressing the need for more nuanced assessment beyond traditional diversity measures. The authors propose Single-attribute Divergence (SaD) and Paired-attribute Divergence (PaD) to measure discrepancies in attribute distributions and relationships between generated and training images. To quantify attribute strengths, they introduce Heterogeneous CLIPScore (HCS), which improves upon CLIPScore by using heterogeneous initial points for image and text vectors. Experiments reveal insights into existing generative models, such as ProjectedGAN generating implausible attribute relationships and diffusion models struggling with diverse colors. The proposed metrics offer explicit interpretability, allowing users to understand which specific attributes or pairs of attributes differ between generated and training images. This work lays a foundation for explainable evaluations of generative models, contributing to the advancement of the field.

## Method Summary
The method introduces three key metrics: Heterogeneous CLIPScore (HCS), Single-attribute Divergence (SaD), and Paired-attribute Divergence (PaD). HCS improves upon standard CLIPScore by centering image vectors at the mean of all images (CX) and text vectors at the mean of all attributes (CA), allowing a wider range of similarity values for more accurate attribute strength measurement. SaD quantifies the difference in density for each attribute between the training dataset (X) and the set of generated images (Y) using KL divergence between probability density functions (PDFs) of HCS scores. PaD extends this to measure discrepancies in joint distributions of attribute pairs, capturing whether attribute relationships (like "babies don't have beards") are preserved. The PDFs are estimated using Gaussian kernel density estimation, and the metrics are calculated using Kullback-Leibler Divergence.

## Key Results
- Heterogeneous CLIPScore outperforms standard CLIPScore in attribute classification accuracy
- ProjectedGAN generates implausible attribute relationships, as revealed by high PaD scores
- Diffusion models struggle with diverse colors, particularly striped and dotted fur attributes
- Higher sampling timesteps in diffusion models reduce SaD and PaD but increase high-frequency elements like necklaces and earrings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Heterogeneous CLIPScore improves attribute strength measurement by using different initial points for image and text vectors.
- Mechanism: Standard CLIPScore measures similarity from the origin, limiting the range of similarity values. By centering image vectors at the mean of all images (CX) and text vectors at the mean of all attributes (CA), Heterogeneous CLIPScore allows a wider range of similarity values and more accurate attribute strength measurement.
- Core assumption: The mean of image embeddings and mean of text embeddings are good representations of their respective distributions in CLIP space.
- Evidence anchors:
  - [section] "HCS is defined by the similarity between the two vectors, Vx and Va. The former connects the image center to a specific image, while the latter connects the attribute center to a particular attribute."
  - [section] "HCS also outshines CS in classifying attibutes as shown in Table 1. This table displays accuracy of CS and HCS using ground truth attributes in CelebA (Liu et al., 2015)."
- Break condition: If the mean embeddings are not representative of their distributions (e.g., multimodal distributions), the centering approach would fail.

### Mechanism 2
- Claim: Single-attribute Divergence (SaD) quantifies attribute distribution differences between training and generated images.
- Mechanism: By computing the KL divergence between probability density functions (PDFs) of Heterogeneous CLIPScores for each attribute in the training set versus generated images, SaD measures how much the attribute distribution in generated images deviates from the training data.
- Core assumption: Heterogeneous CLIPScore accurately captures attribute strengths, and the PDF of these scores reflects the true attribute distribution in images.
- Evidence anchors:
  - [section] "Our metric, SaD, quantifies the difference in density for each attribute between the training dataset (X) and the set of generated images (Y)."
  - [section] "We analyze PDFs of Heterogeneous CLIPScore for each attribute present in X and Y. These HCS PDFs reflect the distribution of attribute strengths within datasets."
- Break condition: If the number of samples is too small to accurately estimate PDFs, or if the attributes are not well-captured by the CLIP model.

### Mechanism 3
- Claim: Paired-attribute Divergence (PaD) measures the preservation of attribute relationships between training and generated images.
- Mechanism: PaD computes the KL divergence between joint probability density functions of attribute pairs in the training set versus generated images, capturing whether attribute relationships (like "babies don't have beards") are preserved.
- Core assumption: The joint PDF of Heterogeneous CLIPScores for attribute pairs accurately reflects the co-occurrence patterns of those attributes in images.
- Evidence anchors:
  - [section] "PaD measures how much a generative model breaks the relationship between attributes in the training data, such as 'babies do not have beards.'"
  - [section] "To measure discrepancies between these distributions, we employ Kullback-Leibler Divergence (KLD)."
- Break condition: If the number of samples is insufficient to accurately estimate joint PDFs, or if the attributes are not independent enough for the joint distribution to be meaningful.

## Foundational Learning

- Concept: Probability Density Function (PDF) estimation using Kernel Density Estimation (KDE)
  - Why needed here: Both SaD and PaD require estimating the distribution of Heterogeneous CLIPScores for attributes and attribute pairs.
  - Quick check question: What bandwidth selector is used for KDE in the experiments, and why is this choice important?

- Concept: Kullback-Leibler (KL) Divergence as a measure of distribution difference
  - Why needed here: SaD and PaD use KL divergence to quantify how much the attribute/attribute-pair distributions differ between training and generated images.
  - Quick check question: Is KL divergence symmetric, and what does this mean for interpreting SaD and PaD scores?

- Concept: CLIP embedding space and its properties
  - Why needed here: The entire methodology relies on CLIP's ability to embed images and text into a shared space where similarity reflects semantic relatedness.
  - Quick check question: What CLIP model variant is used, and how might different CLIP variants affect the results?

## Architecture Onboarding

- Component map: Attribute extractor (BLIP or GPT-3) -> CLIP encoder (ViT-B/32) -> Heterogeneous CLIPScore calculator -> KDE estimator -> KL divergence calculator -> SaD/PaD aggregator

- Critical path: Image → CLIP embedding → Heterogeneous CLIPScore → PDF estimation → KL divergence → SaD/PaD score

- Design tradeoffs:
  - Using CLIPScore vs. custom similarity measures: CLIPScore leverages pre-trained knowledge but may have biases
  - KDE bandwidth selection: Affects PDF smoothness and KL divergence values
  - Number of attributes: More attributes provide richer analysis but increase computational cost

- Failure signatures:
  - If SaD/PaD scores are unexpectedly high for all models, check if attribute extraction is working correctly
  - If scores don't differentiate between models, verify that sufficient samples are used for PDF estimation
  - If scores are unstable across runs, check random seed usage in sampling

- First 3 experiments:
  1. Run SaD and PaD on a simple case where you know the attribute distribution difference (e.g., all images with attribute A vs. none with attribute A)
  2. Test the effect of sample size on score stability by running with 10k, 30k, and 50k images
  3. Compare SaD/PaD scores using CLIPScore vs. Heterogeneous CLIPScore on the same dataset to validate the improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise relationship between the number of diffusion model sampling timesteps and the appearance of high-frequency objects like earrings and necklaces?
- Basis in paper: [explicit] The paper states that "as sampling timesteps in DM increase, SaD and PaD decline" and "higher sampling timesteps in LDM model produce more high-frequency elements, like necklaces and earrings."
- Why unresolved: While the paper observes a correlation between timesteps and object appearance, it doesn't explain the causal mechanism or provide a quantitative model of this relationship.
- What evidence would resolve it: Controlled experiments varying timesteps while measuring object frequencies, and theoretical analysis of how diffusion model sampling dynamics affect high-frequency content generation.

### Open Question 2
- Question: Why do diffusion models struggle with color-related attributes like striped fur and dotted fur compared to GANs?
- Basis in paper: [explicit] The paper notes that "iDDPM's performance is weaker with color attributes" and speculates this might be due to "the color of the output images primarily relies on the initial latent noise xT and Monge optimal transport map."
- Why unresolved: The paper provides a hypothesis but doesn't empirically validate why color/texture patterns are harder for diffusion models, or whether this is an inherent limitation.
- What evidence would resolve it: Comparative analysis of diffusion model latent spaces versus GAN latent spaces, experiments with modified diffusion model architectures, or theoretical work on how diffusion models handle spatial frequency information.

### Open Question 3
- Question: What causes the discrepancy in makeup-related attribute relationships across all tested StyleGAN models?
- Basis in paper: [explicit] The paper observes that "attributes related to makeup consistently receive high scores across all StyleGAN 1, 2, and 3 models in PaD" and suggests this indicates GANs "generally fail to learn the relationship between makeup and other attributes."
- Why unresolved: The paper identifies the phenomenon but doesn't investigate the underlying cause - whether it's related to training data distribution, architectural limitations, or something else.
- What evidence would resolve it: Detailed analysis of makeup attribute co-occurrence patterns in training data versus generated data, ablation studies on StyleGAN components, or comparative experiments with different makeup datasets.

## Limitations
- The metrics rely heavily on the quality and coverage of the attribute set, with the paper using 40 attributes from CelebA
- The assumption that mean embeddings are representative may not hold for multimodal attribute distributions
- KDE-based PDF estimation could be sensitive to bandwidth selection and sample size

## Confidence
- Heterogeneous CLIPScore improvement: Medium
- SaD and PaD as reliable divergence measures: Medium
- Interpretability of results for model comparison: High

## Next Checks
1. Test the robustness of SaD and PaD scores across different CLIP model variants (ViT-B/16, RN50) to ensure the metrics are not CLIP-specific
2. Evaluate the sensitivity of bandwidth selection in KDE on the final SaD/PaD scores using cross-validation
3. Apply the metrics to a dataset with a different attribute distribution (e.g., ImageNet with object attributes) to validate generalizability