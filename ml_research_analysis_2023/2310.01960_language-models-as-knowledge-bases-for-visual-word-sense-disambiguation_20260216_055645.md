---
ver: rpa2
title: Language Models as Knowledge Bases for Visual Word Sense Disambiguation
arxiv_id: '2310.01960'
source_url: https://arxiv.org/abs/2310.01960
tags:
- knowledge
- prompting
- language
- image
- what
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores using Large Language Models (LLMs) as knowledge
  bases to improve Visual Word Sense Disambiguation (VWSD). The authors propose two
  main approaches: (1) enriching ambiguous phrases with knowledge retrieved from LLMs
  in a zero-shot manner to provide more context for multimodal retrieval, and (2)
  converting VWSD into a textual question-answering (QA) problem by treating generated
  image captions as multiple-choice candidate answers.'
---

# Language Models as Knowledge Bases for Visual Word Sense Disambiguation

## Quick Facts
- arXiv ID: 2310.01960
- Source URL: https://arxiv.org/abs/2310.01960
- Reference count: 40
- Key outcome: LLM-based phrase enhancement improves VWSD retrieval, with "meaning_of" prompt most effective; model scale strongly correlates with performance.

## Executive Summary
This paper investigates using large language models (LLMs) as knowledge bases to improve Visual Word Sense Disambiguation (VWSD). The authors propose two approaches: enriching ambiguous phrases with LLM-retrieved knowledge to provide more context for multimodal retrieval, and converting VWSD into a textual QA problem by treating generated image captions as multiple-choice answers. Through experiments with various prompting strategies and model scales, they demonstrate that LLM-based phrase enhancement can improve retrieval performance, particularly when using the "meaning_of" prompt. They also show that model scale is crucial, with larger LLMs demonstrating superior capabilities for knowledge-related tasks.

## Method Summary
The paper explores two main approaches for using LLMs to improve VWSD. First, they enrich ambiguous phrases by retrieving knowledge from LLMs through zero-shot prompting, transforming them into more specific text that aligns better with target images in multimodal embedding space. Second, they convert VWSD into a QA problem by turning ambiguous phrases into questions and treating generated image captions as multiple-choice candidate answers, leveraging LLM reasoning to select the most appropriate caption. They experiment with various prompting strategies including zero-shot, few-shot, and Chain-of-Thought prompting, and test different model scales to assess performance trade-offs.

## Key Results
- LLM-based phrase enhancement improves retrieval performance, with the "meaning_of" prompt showing the best results
- GPT-3.5-turbo significantly outperforms smaller models like Vicuna-13B in the QA approach
- Few-shot prompting generally performs better than zero-shot prompting for the QA conversion
- Model scale is crucial for knowledge-related tasks, with larger LLMs demonstrating superior capabilities
- Greedy captioning strategies work better than beam search for the QA conversion approach

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-based phrase enhancement improves retrieval by supplying disambiguating context
- Mechanism: The LLM enriches ambiguous phrases with related facts retrieved via zero-shot prompting, transforming them into more specific text that aligns better with the target image in multimodal embedding space
- Core assumption: The LLM's stored knowledge contains relevant disambiguating facts for the ambiguous phrase and that these can be accessed with simple handcrafted prompts
- Evidence anchors:
  - [abstract]: "knowledge stored in LLMs is retrieved with the help of appropriate prompts in a zero-shot manner, achieving performance advancements"
  - [section 3.1]: "original text phrases t are transformed to knowledge-enhanced phrases te by harnessing the rich factual knowledge stored in state-of-the-art LLMs"
  - [corpus]: Weak; related work focuses on VWSD generally but does not directly confirm LLM enhancement efficacy
- Break condition: If the LLM lacks the relevant facts or the prompt fails to trigger them, the enhancement degrades or harms performance

### Mechanism 2
- Claim: Converting VWSD to a QA problem leverages LLM reasoning to select correct image captions
- Mechanism: The ambiguous phrase is turned into a question, image captions become multiple-choice options, and the LLM picks the best match, optionally aided by Chain-of-Thought prompting
- Core assumption: The LLM can correctly interpret both the question and the captions, and the reasoning path exists in its weights
- Evidence anchors:
  - [abstract]: "we convert VWSD to a purely textual question-answering (QA) problem by considering generated image captions as multiple-choice candidate answers"
  - [section 3.2]: "we transform VWSD to a question-answering (QA) task by converting the textual phrases t to questions Q that follow handcrafted prompt templates"
  - [corpus]: Moderate; several papers discuss multimodal retrieval but few validate LLM-only reasoning on VWSD
- Break condition: If captions are poor or LLM reasoning is unreliable, the QA approach yields random or incorrect selections

### Mechanism 3
- Claim: Model scale strongly correlates with retrieval performance in knowledge-enhanced VWSD
- Mechanism: Larger LLMs store richer, more nuanced knowledge and exhibit stronger reasoning, improving their ability to disambiguate via enrichment or QA prompting
- Core assumption: Knowledge capacity and reasoning ability scale with parameter count, and task performance will improve monotonically with model size
- Evidence anchors:
  - [abstract]: "model scale is crucial for knowledge-related tasks, with larger LLMs demonstrating superior capabilities"
  - [section 4.2]: "there is an obvious discrepancy between the performance of GPT-3.5-turbo and Vicuna-13B, denoting that model scale does matter in the VWSD as QA scenario"
  - [corpus]: Weak; corpus papers do not directly measure scale impact on VWSD
- Break condition: If scale gains plateau or the largest models suffer from prompt-induced errors, performance may not improve or may degrade

## Foundational Learning

- Concept: Word Sense Disambiguation (WSD)
  - Why needed here: VWSD extends WSD to multimodal retrieval, so understanding linguistic polysemy is essential
  - Quick check question: What is the difference between homonymy and polysemy, and why does it matter for VWSD?

- Concept: Multimodal embedding spaces
  - Why needed here: The core retrieval pipeline uses VL transformers to place images and text in a joint space; understanding similarity metrics is key
  - Quick check question: How does cosine similarity differ from Euclidean distance in the context of VL retrieval?

- Concept: Prompt engineering
  - Why needed here: Both phrase enhancement and QA rely on prompt templates; crafting effective prompts is central to success
  - Quick check question: What distinguishes zero-shot, few-shot, and Chain-of-Thought prompting?

## Architecture Onboarding

- Component map:
  Input: Ambiguous phrase + context -> LLM Knowledge Enhancer -> Caption Generator -> VL Retriever -> LLM QA Engine -> Output: Selected image candidate

- Critical path:
  1. Receive phrase and context
  2. Generate enriched phrase or QA question via LLM
  3. Obtain image captions (greedy or beam search)
  4. Compute similarity between enhanced phrase/question and captions
  5. Select candidate with highest similarity (optionally penalized for popularity)
  6. Return selected image

- Design tradeoffs:
  - LLM size vs. cost: Larger models improve accuracy but increase compute and API costs
  - Caption strategy: Greedy is faster but may miss nuance; beam search is slower but more descriptive
  - Prompt choice: Simpler prompts reduce cost but may underperform richer prompts like "meaning_of"

- Failure signatures:
  - Phrase enhancement yields degraded scores: likely prompt failure or missing facts
  - QA approach returns random captions: likely caption quality issue or model reasoning failure
  - No improvement over baseline: check similarity computation and penalty factor tuning

- First 3 experiments:
  1. Baseline VL retrieval with no enhancement
  2. Phrase enhancement with "meaning_of" prompt and GPT-3.5-turbo
  3. QA approach with GiT-L greedy captions and no-CoT prompting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of LLM-based phrase enhancement vary across different domains and types of ambiguous words?
- Basis in paper: [inferred] The paper shows that LLM-based phrase enhancement can improve retrieval performance, with the "meaning_of" prompt being particularly effective. However, the experiments are limited to a specific dataset and set of ambiguous words
- Why unresolved: The paper does not explore how the effectiveness of LLM-based phrase enhancement might change when applied to different domains (e.g., medical, legal, technical) or types of ambiguous words (e.g., homonyms, homophones, polysemous words)
- What evidence would resolve it: Experiments testing LLM-based phrase enhancement across diverse domains and word types, comparing performance and identifying patterns or limitations

### Open Question 2
- Question: What is the optimal balance between model scale and knowledge enhancement capabilities for visual word sense disambiguation tasks?
- Basis in paper: [explicit] The authors find that model scale is crucial for knowledge-related tasks, with larger LLMs demonstrating superior capabilities. However, they also note that smaller models like Vicuna-7B/13B can perform comparably to larger models like GPT-3/3.5 in phrase enhancement tasks
- Why unresolved: The paper does not provide a clear threshold or guideline for determining the optimal model size for balancing knowledge enhancement capabilities and computational efficiency
- What evidence would resolve it: Systematic experiments varying model sizes and measuring both performance and computational costs, identifying the point of diminishing returns for knowledge enhancement

### Open Question 3
- Question: How do different prompting strategies (e.g., zero-shot, few-shot, Chain-of-Thought) impact the interpretability and reliability of LLM-based reasoning in visual word sense disambiguation?
- Basis in paper: [explicit] The authors explore various prompting strategies and find that Chain-of-Thought prompting can reveal internal reasoning steps. However, they also note that CoT reasoning is not always reliable and may lead to incorrect conclusions
- Why unresolved: The paper does not provide a comprehensive analysis of how different prompting strategies affect the interpretability and reliability of LLM-based reasoning across various types of visual word sense disambiguation tasks
- What evidence would resolve it: Comparative studies of different prompting strategies, measuring both performance and the quality of generated explanations, across a diverse set of visual word sense disambiguation tasks

## Limitations

- The fundamental assumption that LLM knowledge enhancement provides disambiguating context rather than introducing noise or bias is asserted but not independently verified
- The dataset and evaluation framework may not be comprehensive enough to capture all relevant senses of ambiguous phrases across different domains
- The scale sensitivity finding is based on comparisons between GPT-3.5-turbo and Vicuna-13B without intermediate model sizes, leaving gaps in understanding the precise relationship

## Confidence

- **High Confidence**: The core finding that model scale matters for knowledge-related tasks is well-supported by direct comparisons between GPT-3.5-turbo and Vicuna-13B across multiple experiments
- **Medium Confidence**: The effectiveness of the "meaning_of" prompt template is demonstrated but relies on zero-shot prompting without systematic ablation studies across different phrase types or domains
- **Low Confidence**: The fundamental assumption that LLM knowledge enhancement provides disambiguating context rather than introducing noise or bias is asserted but not independently verified

## Next Checks

1. **Knowledge Verification Audit**: Manually examine 50 randomly selected enhanced phrases to verify whether the LLM has retrieved factually accurate knowledge versus plausible-sounding but incorrect information
2. **Scale-Response Curve Analysis**: Test at least three intermediate model sizes (e.g., 7B, 20B, 50B parameters) between Vicuna-13B and GPT-3.5-turbo to map the precise relationship between parameter count and VWSD performance
3. **Cross-Domain Generalization Test**: Apply the best-performing approach (meaning_of prompt + GPT-3.5-turbo) to a completely different VWSD dataset from a different domain (e.g., medical or technical terminology) to assess whether improvements generalize beyond the original evaluation set