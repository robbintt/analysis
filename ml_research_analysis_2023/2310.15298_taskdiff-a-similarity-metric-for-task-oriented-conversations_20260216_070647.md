---
ver: rpa2
title: 'TaskDiff: A Similarity Metric for Task-Oriented Conversations'
arxiv_id: '2310.15298'
source_url: https://arxiv.org/abs/2310.15298
tags:
- similarity
- taskdiff
- conversations
- conversational
- task-oriented
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TaskDiff introduces a novel similarity metric for task-oriented
  conversations that leverages the unique structure of such dialogues, including intents,
  slots, and utterances. It represents conversations as distributions over these components
  and uses optimal transport to compute similarity, addressing the limitations of
  traditional text-based similarity measures that fail to capture the multi-faceted
  nature of task-oriented dialogues.
---

# TaskDiff: A Similarity Metric for Task-Oriented Conversations

## Quick Facts
- arXiv ID: 2310.15298
- Source URL: https://arxiv.org/abs/2310.15298
- Reference count: 9
- Key outcome: TaskDiff significantly outperforms SBERT and HOTT in k-NN classification accuracy (95% vs. 78% and 15%, respectively) on task-oriented conversations.

## Executive Summary
TaskDiff introduces a novel similarity metric specifically designed for task-oriented conversations by representing dialogues as probability distributions over their components (utterances, intents, slots) and measuring similarity using optimal transport (Wasserstein distance). Unlike traditional text-based similarity measures that concatenate or average embeddings, TaskDiff captures the multi-faceted nature of task-oriented dialogues by independently modeling each component's structure. The approach leverages SBERT embeddings of masked utterances (where slot values are replaced with slot names to prevent entity bias) and combines these with intent and slot distributions. Experimental results on the SGD dataset demonstrate that TaskDiff achieves 95% k-NN classification accuracy, significantly outperforming existing methods while demonstrating robustness to conversational reordering.

## Method Summary
TaskDiff processes task-oriented conversations by first masking slot values in utterances with their corresponding slot names to remove entity-induced bias, then generating SBERT embeddings for the masked utterances. For each conversation, it constructs three probability distributions: ∆U over utterance embeddings, ∆I over intent frequencies, and ∆S over slot frequencies. The similarity between two conversations is computed as the weighted sum of 1-Wasserstein distances between corresponding distributions, using Euclidean distances as the ground cost. This approach captures conversational similarity through the geometry of component distributions rather than direct vector distance between aggregated representations.

## Key Results
- Achieves 95% k-NN classification accuracy on the SGD dataset, significantly outperforming SBERT (78%) and HOTT (15%)
- Demonstrates robustness to conversational reordering, maintaining exact similarity scores when turns are shuffled
- Slot masking improves accuracy by 14% over SBERT by removing entity-induced bias in embeddings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TaskDiff captures conversational similarity by modeling each dialogue component as a probability distribution and measuring optimal transport cost between these distributions.
- Mechanism: Utterances are masked with slot names, embedded using SBERT, and represented as distribution ∆U. Separate distributions ∆I (intents) and ∆S (slots) are built from frequencies. The 1-Wasserstein distance between corresponding distributions measures transformation "work," summed with weights γ.
- Core assumption: Similarity is best captured by distribution geometry rather than direct vector distance.
- Evidence anchors: [abstract] "represents conversations as distributions over these components and uses optimal transport to compute similarity"
- Break condition: If distribution representations fail to capture relevant structure, Wasserstein distances won't reflect true similarity.

### Mechanism 2
- Claim: Masking slot values with ontology names removes entity-induced bias in utterance embeddings.
- Mechanism: Before SBERT embedding, slot values are replaced with slot names (e.g., "Florida" → "<city>"), preventing semantically similar utterances with different entities from being incorrectly penalized.
- Core assumption: Entity values shouldn't influence semantic embedding similarity as they don't affect underlying intent or task structure.
- Evidence anchors: [section] "masking ensures that entities representing the slot values do not incorrectly bias or ambiguate the embeddings"
- Break condition: If masking removes useful semantic information that should influence similarity, performance may degrade.

### Mechanism 3
- Claim: TaskDiff's weighted component distances make it robust to reordering of conversational turns.
- Mechanism: Since each component's distribution is computed independently and Wasserstein distance is invariant to order within distributions, reordering turns doesn't change similarity scores.
- Core assumption: Order of turns isn't essential for capturing similarity when component distributions are preserved.
- Evidence anchors: [section] "representing conversations as distributions over its components... makes it agnostic and robust to such changes"
- Break condition: If conversational flow order is a key similarity signal, this mechanism will fail to capture that.

## Foundational Learning

- Concept: Optimal Transport (Wasserstein distance)
  - Why needed here: Provides principled way to compare probability distributions over high-dimensional spaces by computing minimal "work" to transform one distribution into another.
  - Quick check question: What is the objective function minimized by the 1-Wasserstein distance between two discrete distributions?

- Concept: Probability distribution representation of dialogue components
  - Why needed here: Converting utterances, intents, and slots into distributions over their embeddings or categories allows leveraging distributional similarity rather than point-wise comparisons.
  - Quick check question: How is the distribution over intents constructed from a conversation's intent annotations?

- Concept: Slot masking for entity bias removal
  - Why needed here: Ensures entity values don't dominate semantic embeddings, allowing model to focus on task structure rather than specific data values.
  - Quick check question: Why might replacing slot values with slot names improve semantic similarity discrimination?

## Architecture Onboarding

- Component map: Input -> Slot Masking -> Embedding Generation -> Distribution Construction -> Cost Matrix Computation -> Optimal Transport -> Aggregation -> Output

- Critical path:
  1. Mask utterances → 2. Generate embeddings → 3. Build distributions → 4. Compute cost matrices → 5. Compute Wasserstein distances → 6. Aggregate with weights

- Design tradeoffs:
  - Masking slot values improves bias robustness but may discard useful semantic information if slot values matter semantically
  - Using distributions captures structural similarity but loses turn-by-turn alignment information
  - Optimal transport is computationally heavier than cosine similarity, especially for large conversations

- Failure signatures:
  - High similarity scores for conversations with different intents but similar utterance patterns (distribution building may be too coarse)
  - Poor performance when slot values are semantically critical (masking removes discriminative signal)
  - Over-sensitivity to distribution sparsity (rare intents or slots may dominate Wasserstein cost)

- First 3 experiments:
  1. Compare TaskDiff similarity scores on manually annotated conversations vs. SBERT scores to verify improved discrimination
  2. Measure similarity robustness to utterance reordering by perturbing conversation order
  3. Ablate slot masking by running TaskDiff with and without masking on a subset and measuring accuracy on downstream classification

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does TaskDiff perform on open-domain conversational datasets compared to task-oriented ones?
- Basis in paper: [inferred] The paper mentions future work will investigate the inclusion of additional dialog features on open domain dialog datasets.
- Why unresolved: The paper only evaluates TaskDiff on the SGD task-oriented conversation dataset.
- What evidence would resolve it: Empirical results comparing TaskDiff's performance on both task-oriented and open-domain conversational datasets.

### Open Question 2
- Question: Can TaskDiff be extended to incorporate additional dialog features beyond intents, slots, and utterances?
- Basis in paper: [explicit] The paper mentions future work will investigate the inclusion of additional dialog features on open domain dialog datasets.
- Why unresolved: The paper only demonstrates TaskDiff's effectiveness using intents, slots, and utterances as features.
- What evidence would resolve it: Experimental results showing the impact of adding new dialog features like dialogue acts, sentiment, or speaker information.

### Open Question 3
- Question: How does TaskDiff handle conversations with varying levels of annotation granularity?
- Basis in paper: [inferred] The paper doesn't discuss performance on partially labeled or unlabeled conversations.
- Why unresolved: Evaluation assumes complete annotations for all conversations, but real-world datasets often contain partially labeled conversations.
- What evidence would resolve it: Experiments evaluating TaskDiff's performance on datasets with varying annotation granularity.

## Limitations
- Relies heavily on the assumption that slot masking removes bias without discarding essential semantic information
- Optimal transport computation introduces computational overhead
- Choice of weights γ is empirically determined rather than theoretically justified

## Confidence
- High confidence: Mathematical formulation using optimal transport on distributions is sound and well-justified
- Medium confidence: Empirical performance claims are supported but exact experimental conditions aren't fully specified
- Medium confidence: Robustness to reordering is theoretically supported but practical sensitivity isn't thoroughly tested

## Next Checks
1. Run ablation study with and without slot masking on held-out SGD subset to verify claimed 14% improvement
2. Systematically reorder turns in sample conversations and measure whether TaskDiff similarity scores remain constant while SBERT scores vary
3. Evaluate TaskDiff on task-oriented conversations from a different dataset (e.g., MultiWOZ) to test generalization beyond training domain