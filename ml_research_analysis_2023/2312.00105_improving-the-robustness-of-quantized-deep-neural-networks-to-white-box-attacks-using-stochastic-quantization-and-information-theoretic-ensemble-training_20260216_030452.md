---
ver: rpa2
title: Improving the Robustness of Quantized Deep Neural Networks to White-Box Attacks
  using Stochastic Quantization and Information-Theoretic Ensemble Training
arxiv_id: '2312.00105'
source_url: https://arxiv.org/abs/2312.00105
tags:
- ensemble
- adversarial
- attack
- arxiv
- robustness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a method to improve the robustness of quantized
  deep neural networks (DNNs) to white-box adversarial attacks. It introduces a differentiable
  Stochastic Quantizer (SQ) to overcome the limitation of deterministic quantization
  and formulate a training objective to encourage different quantized DNNs to learn
  diverse representations of the input image.
---

# Improving the Robustness of Quantized Deep Neural Networks to White-Box Attacks using Stochastic Quantization and Information-Theoretic Ensemble Training

## Quick Facts
- arXiv ID: 2312.00105
- Source URL: https://arxiv.org/abs/2312.00105
- Reference count: 40
- Key outcome: Achieves over 50% accuracy to PGD(5/255) on CIFAR10 without adversarial training by introducing differentiable Stochastic Quantizer (SQ) and mutual information (MI) regularization for quantized DNNs.

## Executive Summary
This paper addresses the vulnerability of quantized deep neural networks (DNNs) to white-box adversarial attacks by introducing a differentiable Stochastic Quantizer (SQ) and a mutual information-based training objective. The SQ replaces deterministic quantization with stochastic sampling over quantization bins, making the quantization process differentiable and introducing beneficial randomness. The MI regularization encourages diverse representations among ensemble members, leading to collective robustness against adversarial perturbations. The method demonstrates substantial improvements in robustness against L∞ attacks compared to vanilla DNNs and existing quantized ensembles.

## Method Summary
The proposed method introduces a differentiable Stochastic Quantizer (SQ) that replaces deterministic quantization with a categorical distribution over bins using Gumbel-Softmax reparameterization. The training objective combines standard classification loss with mutual information (MI) regularization to encourage diverse feature representations across ensemble members. The MI is calculated as the difference between conditional entropy H(T|X) and entropy H(T), where T represents the ensemble of quantized DNNs. The method also includes bin spacing regularization to control noise amplification during quantization. The approach extends to attack detection through the adversarial information plane (AIP), which correlates MI values with accuracy degradation under various attack strengths.

## Key Results
- Achieves over 50% accuracy to PGD(5/255) attacks on CIFAR10 without adversarial training
- Demonstrates substantial improvement in robustness against L∞ attacks compared to vanilla DNNs and existing quantized ensembles
- Extends to attack detection through adversarial information plane (AIP) visualization
- Shows effectiveness on multiple datasets including CIFAR10, MNIST, and RESISC45

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Stochastic Quantizer (SQ) reduces vulnerability by introducing randomness into quantization
- Mechanism: Replaces deterministic quantization with differentiable categorical distribution over bins, allowing model to learn from multiple quantized representations
- Core assumption: Controlled stochasticity prevents attackers from reliably exploiting fixed quantization boundaries
- Evidence anchors: Abstract states SQ tackles deterministic quantization limitation; hypothesis suggests collective robustness from different quantizations

### Mechanism 2
- Claim: MI regularization encourages diversity among ensemble members
- Mechanism: Maximizes conditional entropy H(T|X) or adds MI I(X;T) as regularizer, forcing different quantized versions to learn distinct features
- Core assumption: Feature diversity across ensemble members leads to collective robustness
- Evidence anchors: Abstract mentions training objective captures diversity and accuracy via MI; entropy H(T|X) defined as feature diversity

### Mechanism 3
- Claim: AIP correlates MI changes with accuracy degradation under attacks
- Mechanism: Visualizes MI vs accuracy for different attack types and strengths to provide unified framework for attack detection
- Core assumption: Changes in MI between input and quantized representations indicate adversarial perturbations
- Evidence anchors: Abstract mentions extending method to detect attacks via AIP; Fig. 6 illustrates MI and accuracy changes with attack strength

## Foundational Learning

- Concept: Stochastic quantization and differentiable sampling
  - Why needed here: Deterministic quantization creates fixed boundaries attackers can exploit; differentiable stochastic sampling allows gradient-based training with beneficial randomness
  - Quick check question: How does Gumbel-Softmax reparameterization enable backpropagation through categorical distribution in SQ?

- Concept: Mutual information and information bottleneck theory
  - Why needed here: MI provides tractable measure of diversity between input and quantized representations without distributional assumptions
  - Quick check question: Why can MI be calculated from single image in this method unlike previous batch-based approaches?

- Concept: Ensemble methods and diversity regularization
  - Why needed here: Combining multiple quantized versions provides collective robustness but requires diversity to avoid redundancy
  - Quick check question: How does MI regularization differ from traditional ensemble diversity techniques like ADP?

## Architecture Onboarding

- Component map: Input image -> Stochastic Quantizer (SQ) -> Feature extractor -> SQ -> Classifier -> MI calculation module -> Regularization module

- Critical path: 1) Input image passes through SQ for stochastic quantization 2) Multiple samples propagate through feature extractor with possible intermediate SQ 3) Final features undergo SQ before classification 4) MI calculated across ensemble members 5) Total loss combines classification, MI, and Lipschitz regularization 6) Gradients flow through all components including SQ via Gumbel-Softmax

- Design tradeoffs: Number of bins vs quantization noise (more bins reduce error but increase cost); alpha parameter balances diversity vs noise; beta balances diversity vs accuracy; ensemble sample count affects robustness vs inference time

- Failure signatures: High MI with low accuracy indicates over-regularization; collapsed features (bT1 - bT0 near zero) indicate insufficient regularization; poor adversarial robustness despite high MI suggests inadequate attack strength

- First 3 experiments: 1) Implement SQ on pre-trained LeNet-5 with alpha=4, evaluate clean accuracy on MNIST 2) Add MI regularization (beta=0), compare adversarial robustness against FGM attacks 3) Vary alpha parameter, measure tradeoff between diversity H(T|X) and adversarial accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ensemble size affect robustness against white-box adversarial attacks?
- Basis in paper: Uses 16 DNNs ensemble but doesn't explore impact of varying ensemble size
- Why unresolved: Focuses on method effectiveness without investigating ensemble size tradeoff with robustness and efficiency
- What evidence would resolve it: Experimental results comparing robustness with ensemble sizes 4, 8, 16, 32 against different white-box attacks

### Open Question 2
- Question: Can method extend to black-box or gray-box attacks?
- Basis in paper: Explicitly focuses on white-box attacks, experiments limited to this threat model
- Why unresolved: Unclear how well method performs against attacks with different threat models
- What evidence would resolve it: Experimental results evaluating robustness against black-box and gray-box attacks

### Open Question 3
- Question: How does method compare to state-of-the-art defenses in robustness and efficiency?
- Basis in paper: Compares to some existing defenses but lacks comprehensive comparison with all state-of-the-art methods
- Why unresolved: Comparison limited to few defenses, unclear how method fares against advanced defenses
- What evidence would resolve it: Comprehensive comparison with state-of-the-art defenses on various datasets and attack types

## Limitations
- Performance depends critically on hyperparameter tuning (alpha, beta) not fully specified for all scenarios
- Demonstrated primarily on L∞ norm attacks, generalizability to other threat models uncertain
- Computational overhead from stochastic quantization and ensemble sampling not explicitly quantified

## Confidence

- High Confidence: SQ mechanism provides differentiable quantization; basic MI diversity regularization framework is sound
- Medium Confidence: Claims about >50% accuracy on PGD attacks and AIP framework effectiveness depend on proper hyperparameter selection
- Low Confidence: Comparative advantage over all existing quantized defenses and scalability to large-scale datasets

## Next Checks

1. Hyperparameter Sensitivity Analysis: Systematically vary alpha and beta across multiple datasets to determine optimal values and establish sensitivity curves

2. Transferability Assessment: Evaluate robustness against black-box attacks and other threat models (L2, L0 norms) to test generalizability beyond white-box L∞ attacks

3. Computational Overhead Measurement: Quantify inference time, memory usage, and FLOPs overhead from stochastic quantization and ensemble sampling compared to deterministic models