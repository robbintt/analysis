---
ver: rpa2
title: Practical Edge Detection via Robust Collaborative Learning
arxiv_id: '2308.14084'
source_url: https://arxiv.org/abs/2308.14084
tags:
- recurrent
- edge
- https
- training
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a collaborative learning approach for practical
  edge detection that simultaneously addresses two key challenges: dependence on large
  pre-trained backbones and noisy labels in training data. The core idea is to integrate
  knowledge from different training moments and heterogeneous network architectures
  (recurrent and non-recurrent) to improve robustness against noisy annotations while
  avoiding pre-training.'
---

# Practical Edge Detection via Robust Collaborative Learning

## Quick Facts
- arXiv ID: 2308.14084
- Source URL: https://arxiv.org/abs/2308.14084
- Reference count: 40
- Key outcome: Proposes collaborative learning approach for edge detection that achieves 0.821 ODS-F on BSDS500 with 92 FPS and 734KB model size, outperforming state-of-the-art methods while avoiding pre-trained backbones

## Executive Summary
This paper addresses two key challenges in practical edge detection: dependence on large pre-trained backbones and noisy labels in training data. The authors propose a collaborative learning framework that integrates knowledge from different training moments and heterogeneous network architectures (recurrent and non-recurrent) to improve robustness against noisy annotations while avoiding pre-training. The method employs uncertainty-aware fusion of predictions from two networks and momentum-based parameter aggregation across epochs, achieving superior performance on BSDS500 and NYUD datasets compared to state-of-the-art methods.

## Method Summary
The method implements a collaborative learning framework with two complementary network architectures: a recurrent backbone with parameter sharing across time steps and a non-recurrent backbone with progressive parameter allocation across stages. Two momentum networks maintain moving averages of the primary network parameters, and predictions are fused using uncertainty-aware weighting based on distance from 0.5. The training process uses soft targets generated by this fusion mechanism, with increasing weight on momentum network predictions over epochs. The approach is trained from scratch using cross-entropy loss with class balancing, achieving competitive performance without relying on pre-trained backbones.

## Key Results
- Achieves 0.821 ODS-F and 0.824 OIS-F on BSDS500 test set
- Reaches 0.764 ODS-F on NYUD dataset
- 92 FPS inference speed with 734KB model size
- Outperforms PiDiNet (0.807 ODS-F) while being nearly 50Ã— faster than EDTER

## Why This Works (Mechanism)

### Mechanism 1
Knowledge integration across training moments and heterogeneous architectures improves robustness to noisy labels. Momentum networks aggregate knowledge across epochs, and ensemble of recurrent/non-recurrent architectures provides diverse predictions. Uncertainty-aware fusion combines these predictions, downweighting noisy labels. Core assumption: Different architectures learn complementary features, and ensemble averaging reduces noise bias.

### Mechanism 2
Uncertainty-aware fusion gives higher weight to more confident predictions. Predictions closer to 0.5 are treated as uncertain and downweighted; confident predictions dominate the fused target. Core assumption: Network outputs near 0.5 indicate uncertainty, and higher-confidence predictions are less likely to be corrupted by noise.

### Mechanism 3
Progressive soft target generation improves label denoising over training. At early epochs, original noisy labels dominate; later, momentum network predictions are trusted more, gradually refining targets. Core assumption: Momentum networks become more reliable as training progresses, justifying increasing weight.

## Foundational Learning

- **Concept**: Ensemble learning and knowledge distillation
  - Why needed here: Combines complementary predictions to suppress noise and improve accuracy
  - Quick check question: What is the difference between model ensemble and knowledge distillation?

- **Concept**: Recurrent vs. non-recurrent architectures
  - Why needed here: Provides architectural diversity for robustness; recurrent shares params, non-recurrent scales params per stage
  - Quick check question: How does parameter sharing in recurrent nets affect model capacity?

- **Concept**: Momentum network parameter aggregation
  - Why needed here: Stabilizes predictions across epochs, enabling smooth soft target evolution
  - Quick check question: What is the effect of momentum parameter update on training stability?

## Architecture Onboarding

- **Component map**: Input -> 1 conv + 2 residual layers (Encoder) -> Recurrent backbone (shared module + max-pooling + bidirectional aggregation) OR Non-recurrent backbone (per-stage parameter scaling + bidirectional aggregation) -> Momentum networks (one per architecture) -> Uncertainty-aware fusion -> Cross-entropy loss with class balancing

- **Critical path**: 
  1. Forward pass through both backbones
  2. Momentum networks generate predictions
  3. Uncertainty-aware fusion creates corrected targets
  4. Cross-entropy loss computed for both backbones
  5. Backpropagate, update backbone weights
  6. Momentum networks updated via moving average

- **Design tradeoffs**:
  - Recurrent: compact, fast convergence, slower inference
  - Non-recurrent: more parameters, faster inference, slower training
  - Uncertainty weighting: adds computation but improves robustness
  - Momentum averaging: extra memory, but smoother target evolution

- **Failure signatures**:
  - Model collapse: both architectures produce identical outputs
  - Divergence: momentum networks drift away from backbones
  - Overfitting: corrected targets collapse to a single mode

- **First 3 experiments**:
  1. Train baseline (no momentum, no fusion) to establish lower bound
  2. Add momentum networks only (no fusion) to test moment integration
  3. Add fusion only (no momentum) to test architectural diversity benefit

## Open Questions the Paper Calls Out

### Open Question 1
How can the proposed collaborative learning framework be extended to handle datasets with more than two annotators per image, where edge annotations may vary significantly between multiple sources? The current uncertainty-aware fusion mechanism is designed for two sources (recurrent and non-recurrent networks), and extending it to handle multiple annotator variations would require new fusion strategies that can properly weight multiple conflicting annotations.

### Open Question 2
What is the theoretical limit of performance improvement achievable through collaborative learning across training moments, and how does this compare to models trained with pre-trained backbones on large datasets? While the paper demonstrates competitive performance without pre-training, it doesn't provide analysis of whether this approach can theoretically match or exceed pre-trained model performance, or what the limiting factors might be.

### Open Question 3
How does the proposed method perform when applied to edge detection in video sequences or time-series image data, where temporal consistency between frames becomes important? The current architecture and training methodology are designed for static images, and extending to video would require addressing temporal coherence, motion boundaries, and potential computational efficiency trade-offs.

### Open Question 4
Can the uncertainty-aware fusion mechanism be generalized to other dense prediction tasks beyond edge detection, such as semantic segmentation or depth estimation? While the mechanism shows effectiveness for edge detection, its applicability to tasks with different output characteristics (e.g., multi-class segmentation, continuous depth values) requires validation and potentially different uncertainty formulations.

## Limitations

- **Architectural detail gaps**: Lack of complete specifications for encoding, recurrent, and decoding modules, including exact layer configurations and channel dimensions
- **Uncertainty metric validity**: Assumption that distance-from-0.5 correlates with prediction confidence lacks empirical validation
- **Momentum network convergence**: No analysis demonstrating that momentum networks actually converge to better predictions than primary backbones

## Confidence

- **High Confidence**: The overall framework design combining recurrent and non-recurrent architectures with momentum-based knowledge integration is technically sound and well-motivated by ensemble learning principles
- **Medium Confidence**: Experimental results showing superior performance on BSDS500 and NYUD datasets are convincing, though limited ablation studies on uncertainty-aware fusion mechanism
- **Low Confidence**: Theoretical justification for why uncertainty-aware fusion specifically improves robustness to noisy labels lacks sufficient empirical validation

## Next Checks

1. **Ablation Study on Uncertainty Metric**: Implement and test alternative uncertainty metrics (e.g., entropy, variance across ensemble members) to determine if the specific choice of distance-from-0.5 is optimal for label denoising

2. **Momentum Network Analysis**: Track and visualize the divergence/convergence between backbone and momentum network predictions throughout training to verify that momentum networks become more reliable over time as claimed

3. **Architectural Diversity Assessment**: Quantify the similarity between recurrent and non-recurrent network outputs across different training epochs to validate that architectural diversity is maintained and contributes to the ensemble's robustness