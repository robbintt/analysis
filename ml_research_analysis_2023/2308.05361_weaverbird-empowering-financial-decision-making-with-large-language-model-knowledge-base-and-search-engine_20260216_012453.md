---
ver: rpa2
title: 'WeaverBird: Empowering Financial Decision-Making with Large Language Model,
  Knowledge Base, and Search Engine'
arxiv_id: '2308.05361'
source_url: https://arxiv.org/abs/2308.05361
tags:
- system
- language
- information
- search
- pairs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: WeaverBird is an intelligent dialogue system designed for the finance
  domain. It combines a large language model tuned on financial corpora with a local
  knowledge base and search engine to answer complex financial queries with citations.
---

# WeaverBird: Empowering Financial Decision-Making with Large Language Model, Knowledge Base, and Search Engine

## Quick Facts
- arXiv ID: 2308.05361
- Source URL: https://arxiv.org/abs/2308.05361
- Authors: 
- Reference count: 23
- Key outcome: Intelligent dialogue system combining LLM, local knowledge base, and search engine with automatic KB updates

## Executive Summary
WeaverBird is an intelligent dialogue system designed for the finance domain that combines a large language model tuned on financial corpora with a local knowledge base and search engine to answer complex financial queries with citations. The system uses an efficiency-optimized retrieval process that leverages local knowledge when possible and falls back to web search only when necessary, automatically updating the local knowledge base with relevant online content. Through extensive training on both Chinese and English financial documents and query-response pairs, WeaverBird demonstrates superior performance in handling finance-related questions compared to ChatGPT and FinChat, particularly in answering Chinese queries and questions requiring specific document retrieval.

## Method Summary
WeaverBird fine-tunes a pretrained GLM model using Lora strategy on 265M Chinese and English financial documents and expert-annotated query-response pairs. The system employs M3E-based encoders trained with contrastive learning to embed queries and paragraphs into the same semantic space. A threshold-based retrieval mechanism uses cosine similarity between queries and local knowledge base paragraphs to determine whether to use local search or web search, with the local KB automatically expanding when relevant web documents are found. The LLM generates responses with citations based on retrieved paragraphs using prompt templates.

## Key Results
- Superior performance on Chinese queries compared to ChatGPT and FinChat
- Efficient retrieval process reduces web search frequency while maintaining response quality
- Automatic knowledge base expansion improves future retrieval efficiency
- Comprehensive coverage of both Chinese and English financial domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The system's retrieval efficiency is enhanced by using local knowledge when possible and falling back to web search only when necessary.
- Mechanism: The system uses a threshold-based approach where cosine similarity between the query and local knowledge base paragraphs determines whether to use local search or web search. If the similarity exceeds a predefined threshold (c ∈ (0,1)), the system skips web search entirely.
- Core assumption: High cosine similarity between query and local paragraphs indicates sufficient relevance to answer the question without additional web search.
- Evidence anchors:
  - [section]: "If the cosine similarity of the most relevant retrieval is larger than a predefined threshold c ∈ (0, 1), we skip the internet search and proceed directly to the response generation phase"
  - [abstract]: "The system uses an efficiency-optimized retrieval process that leverages local knowledge when possible and falls back to web search only when necessary"
- Break condition: If the threshold is set too high, relevant local content may be missed, forcing unnecessary web searches. If set too low, the system may use insufficient local content.

### Mechanism 2
- Claim: The local knowledge base automatically expands with relevant online content, improving future response efficiency.
- Mechanism: When web search is used and paragraphs with cosine similarity above threshold c are found, the entire document containing those paragraphs is automatically added to the local knowledge base.
- Core assumption: Documents containing highly relevant paragraphs are broadly relevant to similar queries and will improve future retrieval performance.
- Evidence anchors:
  - [section]: "If any of the web paragraph exhibits a cosine similarity greater than the threshold c, our system will automatically add the entire document to which it belongs into our local knowledge base"
  - [abstract]: "automatically updating the local knowledge base with relevant online content"
- Break condition: If documents are added that contain only isolated relevant paragraphs among mostly irrelevant content, the knowledge base may become bloated with noise.

### Mechanism 3
- Claim: The system's bilingual capability (Chinese and English) provides superior performance on Chinese queries compared to English-only systems.
- Mechanism: The system was trained on extensive Chinese and English financial documents (240M Chinese, 25M English) and uses a bilingual M3E model for embeddings.
- Core assumption: Training on large, diverse corpora in both languages enables the model to understand and generate responses in both languages with comparable quality.
- Evidence anchors:
  - [abstract]: "our collection includes a substantial corpus of Chinese financial documents, offering a valuable addition to the predominantly English-based finance-related corpora. This enables our WeaverBird system to possess a superior ability in handling Chinese queries"
  - [section]: "The large language model has undergone adaptation to the finance domain... We started with a pretrained GLM that has been pretrained using extensive English and Chinese corpora"
- Break condition: If the Chinese corpus quality is significantly lower than the English corpus, the system may perform poorly on complex Chinese queries.

## Foundational Learning

- Concept: Dense passage retrieval with learned embeddings
  - Why needed here: Enables efficient similarity-based search across millions of financial documents
  - Quick check question: How does cosine similarity between query and paragraph embeddings determine retrieval relevance?

- Concept: Contrastive learning for embedding training
  - Why needed here: Trains encoders to distinguish relevant from irrelevant paragraphs by maximizing similarity for relevant pairs and minimizing for irrelevant pairs
  - Quick check question: What objective function is used to train the encoders to ensure relevant paragraphs have higher similarity scores?

- Concept: Prompt engineering for LLM response generation
  - Why needed here: Guides the language model to generate coherent, cited responses based on retrieved information
  - Quick check question: How does the template structure influence the quality and format of the generated financial responses?

## Architecture Onboarding

- Component map:
  Query input → Encoder (fquery) → Similarity search → Local KB or Web search → Encoder (fkey) → Top K paragraphs → Ranker → LLM with prompt template → Response with citations
  - Knowledge base: Vector database of embedded paragraphs
  - Update mechanism: Automatic addition of high-similarity web documents to local KB

- Critical path: Query → Local retrieval → (if needed) Web retrieval → Response generation
- Design tradeoffs:
  - Threshold c: Higher values improve efficiency but may miss relevant content; lower values improve recall but increase web search frequency
  - K (number of retrievals): Larger K improves coverage but increases processing time and potential noise
  - J (number of paragraphs fed to LLM): More paragraphs provide more context but may overwhelm the model

- Failure signatures:
  - Frequent web searches despite having KB: Threshold too high or KB insufficiently populated
  - Irrelevant responses: Poor encoder training or insufficient K
  - Missing citations: LLM generation issues or retrieval of non-citable content
  - Slow responses: Network latency during web search or large K/J values

- First 3 experiments:
  1. Vary threshold c from 0.5 to 0.9 and measure web search frequency vs. response quality
  2. Test K values of 5, 10, 20 and measure MAP/MAR vs. response coherence
  3. Compare responses using only local KB vs. web search vs. combined approach on a benchmark dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the long-term performance impact of automatically updating the local knowledge base with web content based on cosine similarity thresholds?
- Basis in paper: [explicit] The paper describes the system automatically adding web documents to the local knowledge base when cosine similarity exceeds a threshold, but does not evaluate the long-term effects of this approach.
- Why unresolved: The paper focuses on initial retrieval performance but doesn't examine how continuous web content integration affects retrieval accuracy, system bias, or knowledge base quality over time.
- What evidence would resolve it: A longitudinal study tracking retrieval performance metrics (MAP/MAR) and knowledge base quality indicators over extended periods with different update frequencies and threshold values.

### Open Question 2
- Question: How does the system's performance degrade when handling queries about rapidly evolving financial events versus established financial knowledge?
- Basis in paper: [inferred] The system relies on both local knowledge base and web search, suggesting different performance characteristics for static versus dynamic information needs, but this distinction is not explicitly tested.
- Why unresolved: The evaluation examples focus on general financial queries without distinguishing between stable information (like company fundamentals) and rapidly changing information (like earnings announcements or market reactions).
- What evidence would resolve it: Controlled experiments comparing system performance on queries about stable versus time-sensitive financial topics, measuring accuracy, citation relevance, and response timeliness.

### Open Question 3
- Question: What is the optimal balance between local knowledge base size and retrieval efficiency for different query types?
- Basis in paper: [explicit] The paper mentions that local search is significantly more efficient than web search and describes an efficiency-optimized retrieval process, but doesn't empirically determine optimal configuration parameters.
- Why unresolved: While the paper establishes that local search is faster and web search is used as a fallback, it doesn't provide data on how varying the local knowledge base size affects overall system performance across different query complexities.
- What evidence would resolve it: Systematic experiments varying local knowledge base sizes and measuring end-to-end performance metrics (response time, accuracy, and coverage) across different query categories and complexity levels.

## Limitations

- The automatic knowledge base expansion mechanism may introduce noise if documents are added based on isolated relevant paragraphs among mostly irrelevant content
- The system's bilingual capability claims require more rigorous cross-linguistic evaluation to validate Chinese vs English performance differences
- The efficiency-relevance tradeoff depends heavily on optimal threshold tuning, which is not empirically determined for different query types

## Confidence

- **High confidence**: The system architecture combining LLM, knowledge base, and search engine is technically sound and well-implemented
- **Medium confidence**: The efficiency gains from threshold-based retrieval are real but depend heavily on optimal threshold tuning
- **Low confidence**: The superiority in handling Chinese queries compared to English-only systems requires more rigorous cross-linguistic evaluation

## Next Checks

1. **Threshold sensitivity analysis**: Systematically vary the cosine similarity threshold c from 0.5 to 0.9 and measure the tradeoff between web search frequency reduction and response quality degradation. This would quantify the efficiency-relevance balance and identify optimal threshold ranges for different query types.

2. **Knowledge base quality audit**: Analyze the content added to the local knowledge base through the automatic expansion mechanism. Calculate the ratio of relevant vs irrelevant paragraphs in added documents and measure how this affects retrieval performance over time. This would validate whether the expansion strategy maintains knowledge base quality.

3. **Cross-lingual performance benchmarking**: Conduct head-to-head comparisons of Chinese vs English query handling on identical financial topics, measuring both retrieval accuracy and response quality. This would validate the claimed bilingual superiority and identify potential asymmetries in the system's language capabilities.