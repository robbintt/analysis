---
ver: rpa2
title: 'Data and models for stance and premise detection in COVID-19 tweets: insights
  from the Social Media Mining for Health (SMM4H) 2022 shared task'
arxiv_id: '2311.08057'
source_url: https://arxiv.org/abs/2311.08057
tags:
- tweets
- stance
- data
- covid-19
- vaccination
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a shared task and dataset for stance and premise
  detection in COVID-19-related tweets. The authors collected and annotated tweets
  on vaccination mandates, in addition to three topics used in a previous shared task
  (school closures, stay-at-home orders, and mask-wearing).
---

# Data and models for stance and premise detection in COVID-19 tweets: insights from the Social Media Mining for Health (SMM4H) 2022 shared task

## Quick Facts
- arXiv ID: 2311.08057
- Source URL: https://arxiv.org/abs/2311.08057
- Authors: Multiple authors from various institutions
- Reference count: 40
- Primary result: COVID-Twitter-BERT achieved high F1 scores on stance and premise detection for COVID-19 topics and successfully generalized to vaccination mandates

## Executive Summary
This paper presents a shared task and dataset for stance and premise detection in COVID-19-related tweets. The authors collected and annotated tweets on vaccination mandates, in addition to three topics used in a previous shared task (school closures, stay-at-home orders, and mask-wearing). They evaluated several neural models, including BERT-based models, BART with syntax features, and a dual-view architecture (DAN-BERT). The best-performing model was COVID-Twitter-BERT, pre-trained on COVID-related tweets, which achieved high F1 scores on stance and premise detection for the original three topics. The models trained on these topics were also able to generalize to the new vaccination topic, demonstrating their ability to capture domain-specific patterns. The authors also conducted an emotion analysis of the tweets, finding that anger, fear, and joy were the most prevalent emotions, with anger being particularly common in anti-vaccination tweets.

## Method Summary
The study involved collecting and annotating 2,070 tweets about COVID-19 vaccination mandates. Multiple neural models were fine-tuned on this dataset, including BERT-based models (BERT-base, COVID-Twitter-BERT), BART with syntax features, and DAN-BERT with a dual-view architecture. Models were trained using AdamW optimizer with learning rates between 1e-5 and 4e-5, batch sizes of 8-16, and maximum sequence length of 128. Evaluation used 5-fold cross-validation with macro F1 scores for both stance detection (3 classes: favor, against, neither) and premise detection (binary: contains premise or not). The models were also tested on their ability to generalize from other COVID-19 topics to the new vaccination mandate dataset.

## Key Results
- COVID-Twitter-BERT achieved the highest performance on stance and premise detection for the original three COVID-19 topics
- Models trained on masks, lockdowns, and school closures successfully generalized to vaccination mandates, outperforming random baselines
- Emotion analysis revealed anger, fear, and joy as the most prevalent emotions, with anger particularly common in anti-vaccination tweets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Models trained on stance and premise detection for COVID-19 mandates can generalize to related but unseen topics like vaccination.
- Mechanism: Transfer learning from pre-trained language models (especially COVID-Twitter-BERT) allows adaptation to domain-specific language and topic variations.
- Core assumption: The underlying linguistic and argumentative structures are similar enough between related COVID-19 topics to enable effective transfer.
- Evidence anchors:
  - "The models trained on these topics were also able to generalize to the new vaccination topic, demonstrating their ability to capture domain-specific patterns."
  - "However, models trained on the SMM4H 2022 Task 2 data significantly outperform a random baseline on the vaccination dataset. It indicates that they are capable of providing useful insights and predictions on the unseen topic and can be successfully transferred to the tweets in the same domain but in slightly different theme."
- Break condition: If the new topic involves significantly different language, cultural context, or argumentative patterns, the transfer may fail.

### Mechanism 2
- Claim: Early fusion of tweets and claims improves model performance on stance and premise detection.
- Mechanism: Concatenating tweet text with corresponding claim text provides additional context that helps the model disambiguate stance and identify premises.
- Core assumption: The combination of tweet and claim provides richer information than either alone.
- Evidence anchors:
  - "To enhance the accuracy and effectiveness of our evaluation, we employed various strategies to aggregate tweet texts with claims, including models with feature-level (early) fusion and dual-view architectures from SMM4H 2022 leaderboard."
  - "Adding tweet claims to the text during training can improve the performance on the unseen data in the new domain (vaccines). Nevertheless, it does not affect the results on the data in the same domains it was trained."
- Break condition: If the claim text is noisy, irrelevant, or misleading, the fusion could degrade performance.

### Mechanism 3
- Claim: Dual-view architectures that separately model subjective and objective features improve stance and premise detection.
- Mechanism: The DAN-BERT model uses two parallel BERT models to extract subjective (stance-related) and objective (premise-related) features, then fuses them for final classification.
- Core assumption: Stance and premise detection benefit from separate modeling of subjective and objective information.
- Evidence anchors:
  - "DAN-Bert: This architecture draws inspiration from the dual-view adaptation neural network [32], which learns both representations of subjective and objective features of texts."
  - "The best results on the new data set containing data about mandatory vaccination are demonstrated by DANBert."
- Break condition: If the subjective and objective features are not well-separated or if the fusion is suboptimal, the dual-view approach may not outperform single-view models.

## Foundational Learning

- Concept: Stance detection
  - Why needed here: The core task is to identify whether a tweet supports, opposes, or is neutral towards a COVID-19 mandate.
  - Quick check question: What are the three possible stance labels used in this study?

- Concept: Premise detection
  - Why needed here: The secondary task is to identify whether a tweet contains a reason or justification for the expressed stance.
  - Quick check question: What are the two possible premise labels used in this study?

- Concept: Transfer learning
  - Why needed here: The models are adapted from pre-trained language models to the specific domain of COVID-19 tweets.
  - Quick check question: Which pre-trained language model performed best on the original three topics?

## Architecture Onboarding

- Component map: Tweet text + claim text -> Language model (BERT/BART/COVID-Twitter-BERT) -> Fusion (early fusion or dual-view) -> Classifier -> Stance and premise labels
- Critical path: Input (tweet + claim) through language model, fusion (if applicable), and classifier to output
- Design tradeoffs: Choice of language model (general vs. domain-specific) affects performance; early fusion provides context but may introduce noise
- Failure signatures: Poor generalization to new topics, overfitting on small datasets, failure to handle ambiguous or implicit expressions
- First experiments: 1) Fine-tune COVID-Twitter-BERT on training data, 2) Evaluate on test split for both tasks, 3) Test cross-domain generalization from other COVID-19 topics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well do models trained on COVID-19 related topics (e.g., masks, lockdowns) generalize to new but related topics (e.g., vaccination mandates)?
- Basis in paper: The paper evaluates model performance on vaccination mandates using models trained on masks, lockdowns, and school closures data.
- Why unresolved: While the paper shows models can transfer to new topics, it doesn't explore the limits of this generalization or identify which factors enable successful transfer.
- What evidence would resolve it: Systematic experiments testing models on progressively more distant health-related topics, analysis of which linguistic or topical features correlate with successful transfer, and identification of topic characteristics that hinder generalization.

### Open Question 2
- Question: What is the relationship between emotion expression and stance in health-related social media discourse?
- Basis in paper: The paper conducts emotion analysis finding anger, fear, and joy are prevalent in vaccination tweets, with anger particularly common in anti-vaccination tweets.
- Why unresolved: The analysis is preliminary and doesn't establish causal relationships or determine if emotions are drivers of stance or consequences of it.
- What evidence would resolve it: Longitudinal studies tracking how emotional expression changes over time with shifting public health policies, experimental manipulation of emotional content in messages, and correlation studies between emotional intensity and stance strength.

### Open Question 3
- Question: How can stance detection models handle ambiguous or implicit expressions of opinion in social media text?
- Basis in paper: The paper discusses challenges with tweets that contain news reports, statistics, or require contextual information to determine stance, noting these cases are perplexing for language models.
- Why unresolved: Current models struggle with nuanced or context-dependent expressions, and the paper doesn't propose solutions for these cases.
- What evidence would resolve it: Development and evaluation of models that incorporate broader context (reply threads, user history), analysis of which types of ambiguity are most problematic, and benchmark datasets specifically designed to test model performance on implicit stance cases.

## Limitations

- The vaccination mandate dataset is relatively small (2,070 tweets), limiting generalizability of findings
- The study relies heavily on self-reported annotations without extensive inter-annotator agreement statistics
- Evaluation only tested generalization from three related COVID-19 topics to vaccination mandates, leaving open questions about broader domain transfer

## Confidence

- Mechanism 1 (transfer learning generalization): Medium - supported by empirical results but limited by dataset size and narrow topic scope
- Mechanism 2 (early fusion benefits): Medium - shows performance improvements but lacks theoretical justification and ablation studies
- Mechanism 3 (dual-view architecture): Low-Medium - the claimed benefits are based on single experiment without comparison to alternative architectures

## Next Checks

1. Conduct an ablation study removing claim text from the input to quantify the exact contribution of early fusion
2. Test model performance on a broader range of COVID-19 topics beyond the four studied to assess generalization limits
3. Measure inter-annotator agreement and conduct a reliability analysis on the human annotations to establish baseline quality