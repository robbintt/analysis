---
ver: rpa2
title: "A new Gradient TD Algorithm with only One Step-size: Convergence Rate Analysis\
  \ using $L$-$\u03BB$ Smoothness"
arxiv_id: '2307.15892'
source_url: https://arxiv.org/abs/2307.15892
tags:
- learning
- algorithm
- step-size
- impression
- algorithms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Impression GTD, a new Gradient TD algorithm
  for off-policy reinforcement learning that requires only one step-size parameter.
  The key innovation is using a buffer to store transitions and sampling two independent
  batches to decouple the gradient and error terms, replacing the traditional two-time-scale
  update.
---

# A new Gradient TD Algorithm with only One Step-size: Convergence Rate Analysis using $L$-$λ$ Smoothness

## Quick Facts
- **arXiv ID**: 2307.15892
- **Source URL**: https://arxiv.org/abs/2307.15892
- **Reference count**: 40
- **Key outcome**: Introduces Impression GTD algorithm that converges at least O(1/t) and potentially linearly using L-λ smoothness, with only one step-size parameter

## Executive Summary
This paper introduces Impression GTD, a new Gradient TD algorithm for off-policy reinforcement learning that requires only one step-size parameter. The key innovation is using a buffer to store transitions and sampling two independent batches to decouple the gradient and error terms, replacing the traditional two-time-scale update. The algorithm uses a similarity measure between feature vectors to bridge TD errors from one batch to the other. Theoretical analysis proves that Impression GTD converges at least as fast as O(1/t), and under certain conditions can achieve linear convergence rates. Empirical results on random walks, Boyan chain, and Baird counterexample demonstrate that Impression GTD converges much faster than existing GTD algorithms while being easier to tune due to having only one step-size parameter.

## Method Summary
Impression GTD is a single-time-scale Gradient TD algorithm that uses two buffers to store transitions from different episodes, enabling independence sampling for true stochastic gradient descent on the NEU objective. The algorithm maintains two buffers (B1 and B2) and samples mini-batches from each, ensuring transitions come from different episodes for statistical independence. The update rule computes an averaged TD update from one batch and uses similarity-weighted TD errors from the other batch, where similarity is measured by the inner product of feature vectors. This design eliminates the need for two different step-sizes required by traditional two-time-scale GTD methods while maintaining convergence guarantees through a new smoothness condition called L-λ smoothness.

## Key Results
- Proves Impression GTD converges at least O(1/t) and potentially linearly using L-λ smoothness
- Demonstrates faster convergence than existing GTD algorithms on random walks, Boyan chain, and Baird counterexample
- Shows Impression GTD is easier to tune with only one step-size parameter while maintaining theoretical convergence guarantees

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using two independent batches and sampling transitions from different episodes ensures the sampled transitions are statistically independent, enabling true stochastic gradient descent on the NEU objective.
- Mechanism: By maintaining two buffers (B1 and B2) and sampling from different episodes, the algorithm ensures that any transition from B1 is independent of any transition from B2, allowing the expected value of the product of TD errors to factor correctly.
- Core assumption: The independence of episodes in the data collection process is preserved when storing transitions in separate buffers.
- Evidence anchors:
  - [abstract]: "Note the distribution of the state underlying ϕ is not necessarily the stationary distribution of π (which would be on-policy)."
  - [section]: "In order for the samples in b1 and b2 to be independent, for any sample index pair, i of b1 and j of b2, we require that they are from different episodes"
  - [corpus]: "weak evidence - related work discusses two-time-scale methods but not this specific independence sampling approach"
- Break condition: If episodes are not independent (e.g., in continuous tasks without clear episode boundaries), the independence assumption fails.

### Mechanism 2
- Claim: The similarity measure between feature vectors bridges TD errors from independent transitions, enabling gradient-based optimization of the NEU objective.
- Mechanism: The algorithm uses the inner product of feature vectors (sim(ϕ1, ϕ2) = ϕ1⊤ϕ2) to weight the contribution of TD errors from one transition to another, effectively computing ∇θ[δ1δ2] where δ1 and δ2 are TD errors from independent transitions.
- Core assumption: The inner product between feature vectors provides a meaningful measure of similarity that appropriately weights the influence of independent TD errors.
- Evidence anchors:
  - [abstract]: "The key innovation is using a buffer to store transitions and sampling two independent batches to decouple the gradient and error terms"
  - [section]: "Our algorithm updates the parameter based on one sample. This algorithm use two independent transitions for the update"
  - [corpus]: "moderate evidence - the paper references Feng et al. 2019's K-loss which uses similar similarity-weighted products of TD errors"
- Break condition: If feature vectors are not comparable (e.g., different scales or dimensions), the similarity measure becomes meaningless.

### Mechanism 3
- Claim: The L-λ smoothness condition enables linear convergence rates for Impression GTD, improving upon standard expected smoothness analysis.
- Mechanism: The algorithm satisfies a relaxed smoothness condition that accounts for noise in the gradient estimates, allowing tighter convergence bounds than traditional SGD analysis.
- Core assumption: The NEU objective with independence sampling satisfies the L-λ smoothness condition with appropriate constants L and λ.
- Evidence anchors:
  - [abstract]: "Furthermore, based on a generalization of the expected smoothness (Gower et al. 2019), called L-λ smoothness, we are able to prove that the new GTD converges even faster, in fact, with a linear rate"
  - [section]: "Under this weaker smoothness condition, we establish a tighter convergence rate for SGD than Theorem 3.1 of Gower et al. (2019)"
  - [corpus]: "strong evidence - the paper provides detailed proof that NEU with independence sampling satisfies L-λ smoothness"
- Break condition: If the variance in feature transitions is too high relative to batch sizes, the smoothness condition may not hold.

## Foundational Learning

- Concept: Off-policy reinforcement learning
  - Why needed here: The algorithm specifically addresses the challenges of learning from data collected by a different policy than the one being evaluated.
  - Quick check question: What is the main challenge that makes off-policy learning problematic with standard TD methods?

- Concept: Temporal Difference (TD) learning and bootstrapping
  - Why needed here: The algorithm builds on TD methods but modifies how bootstrapping is performed to handle off-policy scenarios.
  - Quick check question: How does the TD error δ = r + γϕ'⊤θ - ϕ⊤θ relate to value function approximation?

- Concept: Stochastic gradient descent (SGD) convergence theory
  - Why needed here: The convergence analysis relies on SGD theory, particularly the new L-λ smoothness condition.
  - Quick check question: What is the standard convergence rate for SGD on smooth convex functions?

## Architecture Onboarding

- Component map:
  - MDP environment -> Two buffers (B1, B2) -> Mini-batch sampling -> Averaged TD update computation -> Similarity-weighted TD error computation -> Parameter update

- Critical path:
  1. Store transitions in appropriate buffer based on episode index
  2. Sample mini-batches from both buffers ensuring independence
  3. Compute averaged TD update from one batch
  4. Compute similarity-weighted influence from the other batch
  5. Update parameters using the combined gradient estimate

- Design tradeoffs:
  - Buffer size vs. memory usage: Larger buffers provide better approximation of stationary distribution but consume more memory
  - Batch size vs. convergence speed: Larger batches enable larger step sizes and faster convergence but increase per-step computation
  - Similarity measure choice: Inner product is simple but may not capture all useful relationships between feature vectors

- Failure signatures:
  - Divergence despite correct implementation: Check buffer management and episode separation logic
  - Slow convergence: Verify batch sizes are adequate and step size is appropriately tuned
  - Unstable updates: Ensure similarity values are properly normalized and bounded

- First 3 experiments:
  1. Verify buffer independence by checking that transitions from B1 and B2 come from different episodes
  2. Test similarity computation with known feature vectors to ensure correct inner product calculation
  3. Run on a simple on-policy task to confirm the algorithm reduces to standard TD when both buffers contain identical data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Impression GTD scale with the dimensionality of the feature space in high-dimensional reinforcement learning problems?
- Basis in paper: [inferred] The paper primarily focuses on linear function approximation and demonstrates Impression GTD's effectiveness in low-dimensional problems. The complexity of Impression GTD is O((m1 + m2)d) per step, where m1 and m2 are batch sizes and d is the number of features.
- Why unresolved: The paper does not provide experimental results or theoretical analysis for high-dimensional feature spaces, which are common in deep reinforcement learning applications.
- What evidence would resolve it: Empirical studies comparing Impression GTD to existing GTD algorithms in high-dimensional reinforcement learning tasks, such as Atari games or robotic control problems, using deep neural networks for function approximation.

### Open Question 2
- Question: What is the impact of the buffer size on the convergence rate and final performance of Impression GTD in non-stationary environments?
- Basis in paper: [explicit] The paper discusses the use of buffers for independence sampling but does not extensively explore the impact of buffer size on performance in changing environments. It mentions that the buffers should contain sufficiently many samples to ensure independence.
- Why unresolved: The paper focuses on stationary environments and does not investigate how the algorithm adapts to changes in the underlying MDP or policy.
- What evidence would resolve it: Experiments comparing Impression GTD's performance with varying buffer sizes in non-stationary environments, such as changing reward structures or transition dynamics, to determine the optimal buffer management strategy.

### Open Question 3
- Question: How does the choice of similarity measure affect the convergence rate and robustness of Impression GTD in different types of feature spaces?
- Basis in paper: [explicit] The paper focuses on using correlation as the similarity measure between feature vectors but does not explore other possible similarity measures or their effects on performance.
- Why unresolved: The paper demonstrates the effectiveness of correlation-based similarity but does not investigate whether other similarity measures might be more appropriate for different types of feature representations or problem domains.
- What evidence would resolve it: Comparative studies of Impression GTD using different similarity measures (e.g., cosine similarity, Euclidean distance, learned similarity metrics) across various feature spaces and problem domains to identify the most effective similarity measure for different scenarios.

## Limitations

- The independence sampling mechanism assumes episodes are independent, which may not hold in continuous or overlapping episode scenarios
- The choice of similarity measure (inner product of feature vectors) is not thoroughly explored and may not be optimal for all feature representations
- The algorithm's performance in highly non-stationary environments with changing MDP dynamics is not investigated

## Confidence

- **High Confidence**: The convergence rate proofs using L-λ smoothness, the basic algorithmic framework, and the empirical demonstration of faster convergence compared to existing GTD methods.
- **Medium Confidence**: The practical effectiveness of the similarity measure across diverse feature spaces and the buffer management strategy's robustness to different data collection scenarios.
- **Low Confidence**: The algorithm's performance in highly non-stationary environments and with feature representations that don't satisfy the independent feature assumption.

## Next Checks

1. Test buffer independence robustness by introducing controlled correlations between episodes and measuring impact on convergence.
2. Evaluate performance across diverse feature representations (polynomial, radial basis functions, neural network embeddings) to assess similarity measure generality.
3. Benchmark against existing GTD algorithms on tasks with non-Markov or highly correlated state transitions to identify failure modes.