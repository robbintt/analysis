---
ver: rpa2
title: 'SMURF-THP: Score Matching-based UnceRtainty quantiFication for Transformer
  Hawkes Process'
arxiv_id: '2310.16336'
source_url: https://arxiv.org/abs/2310.16336
tags:
- score
- event
- smurf-thp
- time
- process
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of training Transformer Hawkes
  Process (THP) models and quantifying prediction uncertainty, particularly for the
  arrival time of events. Existing likelihood-based methods for THP face challenges
  due to intractable integrals and fail to provide uncertainty quantification.
---

# SMURF-THP: Score Matching-based UnceRtainty quantiFication for Transformer Hawkes Process

## Quick Facts
- **arXiv ID:** 2310.16336
- **Source URL:** https://arxiv.org/abs/2310.16336
- **Reference count:** 10
- **Key outcome:** SMURF-THP achieves within 0.3% prediction accuracy compared to likelihood-based methods while gaining 4-10% confidence calibration in predictions of arrival times.

## Executive Summary
SMURF-THP addresses the challenge of training Transformer Hawkes Process (THP) models while quantifying prediction uncertainty for event arrival times. Traditional likelihood-based methods face intractable integral computations that prevent effective uncertainty quantification. SMURF-THP learns a score function using score-matching objectives, avoiding these computational issues. By sampling from the learned score function using Langevin Dynamics, the method naturally enables uncertainty quantification through confidence intervals. Experiments on four real-world datasets demonstrate SMURF-THP outperforms likelihood-based methods in confidence calibration while maintaining comparable event-type prediction accuracy.

## Method Summary
SMURF-THP trains Transformer Hawkes Process models using score matching rather than maximum likelihood to avoid intractable integrals. The method learns the score function (gradient of log-density) through a score-matching objective, augmented with denoising score matching to improve estimation in low-density regions. Gaussian noise is added to event times during training, with the denoising objective replacing problematic second-order derivatives. After training, Langevin Dynamics samples from the learned score function to generate event arrival times and compute confidence intervals. The approach maintains event-type prediction accuracy while significantly improving confidence calibration.

## Key Results
- Achieves within 0.3% event-type prediction accuracy compared to likelihood-based methods
- Improves confidence calibration by 4-10% for arrival time predictions
- Demonstrates effectiveness across four real-world datasets (StackOverflow, Retweet, MIMIC-II, Financial Transactions)
- Provides reliable uncertainty quantification through confidence intervals computed from sampled distributions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Score matching replaces intractable integral computation with score derivatives
- **Mechanism:** By minimizing the expected squared distance between model score and ground truth score, the method avoids computing the normalization integral in the likelihood function. The score is the gradient of log-density, which can be computed directly from the intensity function without integration.
- **Core assumption:** The event time distribution is smooth and differentiable, and the score function can be accurately approximated by neural networks.
- **Evidence anchors:**
  - [abstract]: "SMURF-THP learns the score function of events' arrival time based on a score-matching objective that avoids the intractable computation"
  - [section]: "We can resolve this issue by following the general derivation in Hyv¨arinen (2005) and arrive at an empirical score-matching objective for Hawkes process"
  - [corpus]: Weak evidence - no directly comparable papers found in corpus
- **Break condition:** If the intensity function is too discontinuous or the data is too sparse, the score approximation becomes unreliable and the method fails.

### Mechanism 2
- **Claim:** Denoising score matching improves estimation in low-density regions
- **Mechanism:** Adding Gaussian noise to event times augments samples in low-density regions of the original distribution. The denoising score matching objective replaces second-order derivatives with scores of the noise distribution, improving stability and coverage.
- **Core assumption:** The noise scale is appropriately chosen - too small fails to improve low-density estimation, too large corrupts the distribution.
- **Evidence anchors:**
  - [section]: "To alleviate these issues, we adopt denoising score matching (Vincent, 2011), which perturbs the data with a pre-specified noise distribution"
  - [section]: "Adding too small noise will lead to unstable training, which does not cover the low-density regions enough and degrades the performance"
  - [corpus]: Weak evidence - no directly comparable papers found in corpus
- **Break condition:** If noise scale is mis-specified (either too small or too large), the method either fails to improve or completely corrupts the distribution.

### Mechanism 3
- **Claim:** Langevin Dynamics enables uncertainty quantification through sampling
- **Mechanism:** With the learned score function, Langevin Dynamics generates samples from the predicted distribution. This naturally allows computing confidence intervals over generated samples, providing uncertainty quantification for arrival times.
- **Core assumption:** The learned score function is sufficiently accurate for the Langevin Dynamics to converge to the correct distribution.
- **Evidence anchors:**
  - [abstract]: "With such a learned score function, we can sample arrival time of events from the predictive distribution. This naturally allows for the quantification of uncertainty by computing confidence intervals over the generated samples"
  - [section]: "Using the learnt score function, we can generate new events using the Langevin Dynamics (LD) and compute confidence intervals"
  - [corpus]: Weak evidence - no directly comparable papers found in corpus
- **Break condition:** If the learned score function has significant errors, the Langevin Dynamics will sample from an incorrect distribution, making confidence intervals meaningless.

## Foundational Learning

- **Concept: Temporal Point Processes**
  - Why needed here: The entire method builds on Hawkes processes, which are a specific type of temporal point process. Understanding the intensity function and how events influence future event rates is fundamental.
  - Quick check question: What is the key difference between a Poisson process and a Hawkes process in terms of how the intensity function is defined?

- **Concept: Transformer Architecture**
  - Why needed here: The method uses Transformer to parameterize the intensity function. Understanding self-attention mechanisms and positional encodings is crucial for grasping how dependencies between events are modeled.
  - Quick check question: How does the self-attention mechanism in Transformers help capture long-range dependencies between events compared to recurrent neural networks?

- **Concept: Score Matching**
  - Why needed here: The core training objective is score matching, which is fundamentally different from maximum likelihood estimation. Understanding how score matching works and why it avoids intractable integrals is essential.
  - Quick check question: What is the mathematical relationship between the score function and the log-density, and why does minimizing squared distance between scores avoid computing normalization constants?

## Architecture Onboarding

- **Component map:** Event sequence -> Transformer encoding -> Score function learning (score matching) -> Langevin sampling -> Confidence interval computation
- **Critical path:** Event sequence → Transformer encoding → Score function learning (score matching) → Langevin sampling → Confidence interval computation
- **Design tradeoffs:**
  - Using Transformer vs RNN: Transformers capture long-range dependencies better but require more computation
  - Score matching vs maximum likelihood: Avoids intractable integrals but requires learning score function accurately
  - Sampling vs analytical uncertainty: Sampling provides more flexible uncertainty quantification but requires more computation
- **Failure signatures:**
  - Poor calibration scores: Indicates inaccurate score function learning
  - High CRPS values: Suggests poor distributional predictions
  - Unstable training: Often due to inappropriate noise scale in denoising score matching
- **First 3 experiments:**
  1. Train on synthetic Hawkes process data with known parameters to verify score matching works correctly
  2. Compare calibration scores on a simple dataset with and without denoising to understand its impact
  3. Test different noise scales on a validation set to find optimal denoising parameters

## Open Questions the Paper Calls Out

- **Question:** How does the choice of noise scale σ affect the model's performance, and is there an optimal way to select this parameter?
  - **Basis in paper:** [explicit] The paper mentions that the denoising score matching method adds Gaussian noise with scale σ to data points, and that selecting the appropriate noise scale is tricky.
  - **Why unresolved:** The paper states that a suitable noise scale can effectively improve performance, but too small or too large a scale can degrade it. However, the authors only use grid search to select σ and suggest that auto-selection could be left for future work.
  - **What evidence would resolve it:** Experiments testing different noise scales and their impact on model performance, or a method for automatically determining the optimal noise scale.

- **Question:** How does SMURF-THP's performance compare to other score-based methods for training Transformer Hawkes Process models?
  - **Basis in paper:** [inferred] The paper proposes SMURF-THP as a score-based method and demonstrates its superiority over likelihood-based methods. However, it does not compare its performance to other score-based methods.
  - **Why unresolved:** The paper focuses on comparing SMURF-THP to likelihood-based methods and does not explore its performance relative to other score-based approaches.
  - **What evidence would resolve it:** Experiments comparing SMURF-THP's performance to other score-based methods for training Transformer Hawkes Process models.

- **Question:** How does SMURF-THP's performance scale with the size and complexity of the event sequences?
  - **Basis in paper:** [inferred] The paper evaluates SMURF-THP on four real-world datasets with varying characteristics, but does not explicitly investigate how its performance scales with the size and complexity of the event sequences.
  - **Why unresolved:** While the paper demonstrates SMURF-THP's effectiveness on the tested datasets, it does not provide insights into how the model's performance would change for larger or more complex event sequences.
  - **What evidence would resolve it:** Experiments testing SMURF-THP's performance on event sequences of varying sizes and complexities, and analyzing the relationship between performance and these factors.

## Limitations

- The paper lacks ablation studies on critical hyperparameters like noise scale and Transformer architecture choices
- Performance generalizability to domains beyond the four tested datasets remains uncertain
- Sensitivity to hyperparameter choices and potential instability in training scenarios is not thoroughly explored

## Confidence

- **Mechanism (score matching avoids intractable integrals):** High
- **Empirical performance (calibration improvements):** Medium
- **Method generalizability:** Low

## Next Checks

1. Implement SMURF-THP on synthetic Hawkes process data with known parameters to verify the score matching mechanism works correctly and produces calibrated uncertainty estimates
2. Perform an ablation study on noise scale in denoising score matching to determine the optimal range and understand sensitivity
3. Test SMURF-THP on an additional real-world dataset not included in the original experiments to assess generalizability