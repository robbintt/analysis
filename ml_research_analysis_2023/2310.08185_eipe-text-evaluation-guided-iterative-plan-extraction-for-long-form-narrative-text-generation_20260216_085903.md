---
ver: rpa2
title: 'EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative
  Text Generation'
arxiv_id: '2310.08185'
source_url: https://arxiv.org/abs/2310.08185
tags:
- plan
- planner
- narrative
- generation
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EIPE-text is a framework for long-form narrative text generation
  that improves planning through iterative extraction and refinement. It addresses
  the challenge of generating coherent, relevant long narratives by first extracting
  and refining plans from existing narratives using a QA-based evaluation mechanism,
  then learning a better planner through fine-tuning or in-context learning.
---

# EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation

## Quick Facts
- **arXiv ID**: 2310.08185
- **Source URL**: https://arxiv.org/abs/2310.08185
- **Reference count**: 17
- **Primary result**: QA-based evaluation mechanism improves plan quality through iterative refinement, achieving 84.2% coherence and 92.5% relevance on novels

## Executive Summary
EIPE-text is a framework for long-form narrative text generation that addresses the challenge of generating coherent, relevant long narratives through iterative plan extraction and refinement. The method uses a question-answer (QA) based evaluation mechanism to automatically evaluate plans and generate detailed refinement instructions, guiding the iterative improvement process. By learning from refined plans through either fine-tuning or in-context learning, the framework produces superior narrative quality compared to baselines like recurrentGPT.

## Method Summary
The framework operates through iterative plan extraction and refinement: first extracting tree-structured plans from narratives, then generating QA-pairs to evaluate plan-narrative alignment. For each incorrect QA pair, the system generates refinement instructions (add, modify, or adjust nodes) and iteratively updates the plan until it passes evaluation. The refined plans are then used to train a planner through either fine-tuning or in-context learning with clustered demonstrations, enabling generation of coherent long-form narratives.

## Key Results
- Achieves 84.2% coherence and 92.5% relevance scores on novels
- 20-shot cluster-based planner outperforms retrieval-based planner with 67.2% win ratio
- Framework converges in an average of 2.98 epochs during iterative refinement
- Demonstrates 87.6% improvement over LLaMA raw planner on TED Talks

## Why This Works (Mechanism)

### Mechanism 1
The QA-based evaluation mechanism enables targeted plan refinement by identifying specific errors. The LLM answers questions based on the plan, and for each incorrect answer, generates a refinement instruction (add, modify, or adjust node) to improve alignment with the narrative.

### Mechanism 2
Iterative refinement process ensures plan-narrative alignment through three operations (add, modify, adjust). The plan refinement step integrates instructions to update the plan, repeating until it passes QA evaluation. This iteratively improves plan quality.

### Mechanism 3
In-context learning with clustered demonstrations enables domain-specific plan generation. Text embeddings cluster plans, and k-means centroids serve as demonstrations for the planner to learn domain-specific patterns.

## Foundational Learning

- **QA-based evaluation for automated feedback**: Why needed here - Traditional evaluation methods struggle with plan-narrative alignment; QA-based evaluation provides specific, actionable feedback. Quick check - How does QA-based evaluation differ from direct comparison methods in terms of feedback specificity?
- **Iterative refinement for convergence**: Why needed here - Single-pass refinement often misses errors; iterative refinement ensures all issues are addressed. Quick check - What determines when the iterative refinement process should stop?
- **Clustering for demonstration selection**: Why needed here - Random demonstration selection may miss domain patterns; clustering ensures diverse, representative examples. Quick check - How does the number of clusters affect the quality of demonstrations for in-context learning?

## Architecture Onboarding

- **Component map**: Plan Extraction (Plan sketching → QA-pairs generation → QA-based evaluation → Plan refinement) → Learning (In-context learning OR fine-tuning) → Inference (Plan generation → Narrative generation)
- **Critical path**: Plan Extraction → Learning → Inference
- **Design tradeoffs**: QA-based evaluation vs. direct comparison (QA provides specific feedback but requires more LLM calls); Clustering vs. retrieval for demonstrations (Clustering ensures diversity but may miss relevant examples); Iterative refinement vs. single-pass (Iterative is more thorough but computationally expensive)
- **Failure signatures**: QA evaluation fails to identify plan issues → Refinement doesn't improve quality; Clustering produces unrepresentative demonstrations → In-context learning underperforms; Iterative refinement doesn't converge → Plan remains misaligned with narrative
- **First 3 experiments**: Test QA-based evaluation on plans with known issues to verify it identifies and provides correct refinement instructions; Compare iterative vs. single-pass refinement on a small dataset to measure convergence speed and quality improvement; Evaluate clustering vs. retrieval for demonstration selection using a fixed planner to isolate the effect of demonstration quality

## Open Questions the Paper Calls Out

### Open Question 1
How does the quality of the LLM used for plan extraction and refinement impact the overall performance of the EIPE-text framework? The paper mentions using GPT-4 but does not explore the impact of using different LLMs with varying capabilities.

### Open Question 2
How can the EIPE-text framework be extended to handle multimodal narratives, such as those combining text, images, and videos? The paper focuses on text-based narratives and does not address the challenges of incorporating multimodal elements.

### Open Question 3
How can the EIPE-text framework be adapted to support real-time or interactive narrative generation, where the plan can be dynamically updated based on user input or feedback? The paper describes a static planning and generation process without addressing interactive scenarios.

## Limitations
- Framework relies heavily on LLM-based evaluation, introducing scalability and cost concerns
- QA-based evaluation may degrade with longer narratives or more complex domain-specific content
- Convergence rate of 2.98 epochs may not generalize to all domains or narrative types
- Clustering approach assumes 20 clusters adequately capture domain patterns, which may vary by dataset

## Confidence

**High Confidence**: The basic mechanism of using QA-based evaluation for plan refinement is well-specified and supported by clear methodology descriptions.

**Medium Confidence**: The automatic evaluation results (84.2% coherence, 92.5% relevance) and win ratios (67.2% for clustered vs. retrieval planner) are reported but lack comparison to traditional baselines on the same metrics.

**Low Confidence**: The scalability claims are based on results from novels and TED Talks only, without testing on other long-form narrative domains like technical documentation or academic papers.

## Next Checks

1. **LLM Evaluation Reliability Test**: Evaluate whether the QA-based evaluation mechanism consistently identifies plan issues across different narrative types and lengths by manually verifying a sample of refinement instructions.

2. **Convergence Robustness Check**: Test the iterative refinement process on narratives with varying complexity to determine if the 2.98 epoch convergence rate holds or if some cases require significantly more iterations.

3. **Cross-Domain Generalization Test**: Apply the framework to at least two additional long-form narrative domains (e.g., technical documentation, academic papers) to verify the clustering and in-context learning approach generalizes beyond novels and storytelling.