---
ver: rpa2
title: 'Multi-Task Faces (MTF) Data Set: A Legally and Ethically Compliant Collection
  of Face Images for Various Classification Tasks'
arxiv_id: '2311.11882'
source_url: https://arxiv.org/abs/2311.11882
tags:
- data
- images
- classification
- face
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Multi-Task Face (MTF) dataset, a collection
  of 5,246 real face images from 240 celebrities, labeled for face recognition, race,
  gender, and age classification. Unlike other datasets that are either synthetic
  or have been removed due to privacy concerns, MTF was ethically sourced from publicly
  available celebrity images with proper copyright permissions.
---

# Multi-Task Faces (MTF) Data Set: A Legally and Ethically Compliant Collection of Face Images for Various Classification Tasks

## Quick Facts
- **arXiv ID**: 2311.11882
- **Source URL**: https://arxiv.org/abs/2311.11882
- **Reference count**: 25
- **Key outcome**: MTF dataset with 5,246 real face images from 240 celebrities, achieving up to 98.88% accuracy for gender classification and 79.87% for face recognition

## Executive Summary
The Multi-Task Faces (MTF) dataset addresses critical gaps in facial image datasets by providing a legally and ethically compliant collection of 5,246 real face images from 240 celebrities. Unlike synthetic alternatives or previously removed datasets due to privacy concerns, MTF leverages publicly available celebrity images with proper copyright permissions. The dataset underwent rigorous manual processing to ensure high quality for training AI models across four classification tasks: face recognition, race, gender, and age classification. Five deep learning models were evaluated, with ConvNeXT achieving exceptional performance across all tasks.

## Method Summary
The MTF dataset was compiled by crawling Bing images of celebrities with Creative Commons/public domain licensing using the icrawler library. Face detection and cropping were performed using Haar cascades, followed by manual filtering by human experts to ensure high-quality, natural facial images. The dataset includes 5,246 images from 240 celebrities, labeled for four classification tasks. Five deep learning models (MobileNetV3, AlexNet, ResNet50, VGG16, ConvNeXT) were trained and evaluated using accuracy, precision, recall, and F1 score as metrics, with pre-trained models showing superior performance compared to training from scratch.

## Key Results
- ConvNeXT model achieved up to 98.88% accuracy for gender classification
- ConvNeXT achieved 95.77% accuracy for race classification and 97.60% for age classification
- Face recognition accuracy reached 79.87% using ConvNeXT
- All pre-trained models significantly outperformed their scratch-trained counterparts
- Dataset and trained models are publicly available for research purposes

## Why This Works (Mechanism)

### Mechanism 1
Manual filtering and labeling by human experts significantly improves dataset quality by removing noisy, mislabeled, and irrelevant images. Experts systematically evaluate each cropped face image to ensure it's a complete, high-quality face belonging to the correct identity and meeting task-specific criteria. This reduces noise and improves the signal-to-noise ratio in training data. Core assumption: Human judgment effectively identifies and removes images that automated methods might misclassify as valid faces.

### Mechanism 2
Using publicly available celebrity images under Creative Commons or public domain licenses ensures legal and ethical compliance with GDPR. The dataset compilation prioritizes privacy by focusing on publicly known individuals and using images legally available for modification, sharing, and commercial use. This approach adheres to the GDPR exception for manifestly public data. Core assumption: Celebrity status and public domain licensing sufficiently mitigate privacy risks.

### Mechanism 3
Pre-training models on ImageNet and fine-tuning them on the MTF dataset significantly improves performance compared to training from scratch. Pre-trained models have learned general image features transferable to the MTF dataset, allowing faster convergence and higher accuracy with less data. Fine-tuning adapts these features to specific characteristics of facial images and tasks. Core assumption: Features learned from general image datasets like ImageNet are useful for facial image classification tasks.

## Foundational Learning

- **GDPR and data privacy regulations**: Understanding the legal framework that restricts collection and use of facial images is crucial for appreciating dataset compliance and longevity. Quick check: What are key GDPR provisions that apply to facial image datasets, and how does MTF comply with them?

- **Image preprocessing and data cleaning**: The manual filtering process is a key differentiator of MTF, and understanding its impact on data quality is essential for evaluating effectiveness. Quick check: What are common sources of noise and bias in face image datasets, and how can manual filtering address them?

- **Transfer learning and pre-training**: The paper emphasizes pre-training models on ImageNet and fine-tuning on MTF, so understanding this technique is crucial for replicating results. Quick check: How does transfer learning work, and what are benefits and limitations of using pre-trained models for facial image classification tasks?

## Architecture Onboarding

- **Component map**: Data Collection -> Data Processing -> Data Labeling -> Model Training -> Model Evaluation
- **Critical path**: Data Collection -> Data Processing -> Data Labeling -> Model Training -> Model Evaluation
- **Design tradeoffs**: Manual vs. automated filtering (quality vs. cost), dataset size vs. quality (smaller high-quality vs. larger noisy), pre-training vs. training from scratch (speed vs. task relevance)
- **Failure signatures**: Low accuracy or high variance across models (data quality issues), overfitting or underfitting (model architecture/hyperparameters), bias in model predictions (dataset imbalances)
- **First 3 experiments**: 
  1. Train MobileNetV3 from scratch on MTF dataset and evaluate performance on each task
  2. Fine-tune ResNet50 pre-trained model on MTF dataset and compare to scratch training
  3. Train ConvNeXT with pre-training on MTF dataset and compare performance to other models

## Open Questions the Paper Calls Out

### Open Question 1
How does the MTF dataset's performance compare to synthetic datasets like DigiFace-1M for face recognition tasks? The paper mentions synthetic datasets fall short of accurately representing real data distribution but doesn't provide direct comparative results. Direct performance comparisons between MTF and synthetic datasets using same models and evaluation metrics would resolve this.

### Open Question 2
What are the long-term implications of using celebrity images for training AI models, even with proper licensing? The paper discusses current legal compliance but doesn't explore potential future ethical concerns or changes in public perception. Longitudinal studies on public perception, potential legal changes, or emerging ethical frameworks would resolve this.

### Open Question 3
How would the MTF dataset perform with more diverse age ranges, including children and elderly individuals? The paper defines age groups as young (18-49) and old (50+) but doesn't explore performance with more granular age ranges. Experiments with expanded age ranges and corresponding performance evaluations would resolve this.

## Limitations
- Small dataset size (5,246 images from 240 celebrities) may limit generalizability to broader populations
- Potential selection bias given focus on Western celebrities
- Manual filtering process introduces subjectivity that could embed unrecognized biases

## Confidence
- **High**: Dataset compilation methodology and legal compliance framework
- **Medium**: Claimed model performance metrics (based on standard evaluation protocols but unverified)
- **Low**: Long-term viability given potential changes in copyright laws and celebrity consent preferences

## Next Checks
1. Conduct ablation studies comparing manual vs. automated filtering approaches to quantify actual impact on model performance and identify potential biases
2. Test model performance on diverse demographic groups beyond celebrity population to assess generalizability and identify demographic biases
3. Implement legal review of copyright compliance framework to ensure ongoing adherence to evolving data protection regulations and assess robustness of "publicly available" exception under different jurisdictions