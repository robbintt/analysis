---
ver: rpa2
title: Diagnosing Model Performance Under Distribution Shift
arxiv_id: '2303.02011'
source_url: https://arxiv.org/abs/2303.02011
tags:
- distribution
- shift
- data
- performance
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces DISDE (Distribution Shift Decomposition),
  a method to attribute model performance degradation across distribution shifts to
  specific causes: 1) increased frequency of harder training examples, 2) changes
  in feature-outcome relationships, and 3) poor performance on infrequent/unseen examples.
  DISDE works by defining a "shared distribution" of covariates common to both training
  and target distributions, then decomposing the performance drop using importance
  weighting.'
---

# Diagnosing Model Performance Under Distribution Shift

## Quick Facts
- arXiv ID: 2303.02011
- Source URL: https://arxiv.org/abs/2303.02011
- Reference count: 40
- Primary result: DISDE decomposes performance degradation into three interpretable causes: harder examples, feature-outcome relationship changes, and poor performance on rare examples.

## Executive Summary
This paper introduces DISDE (Distribution Shift Decomposition), a method to attribute model performance degradation under distribution shift to specific, interpretable causes. The approach constructs a "shared distribution" of covariates common to both training and target distributions, then decomposes the performance drop using importance weighting. DISDE identifies whether degradation stems from increased frequency of harder training examples, changes in feature-outcome relationships, or poor performance on infrequent/unseen examples. The method provides both practical guidance for interventions and theoretical guarantees of asymptotic normality and efficiency.

## Method Summary
DISDE works by defining a "shared distribution" SX containing covariate values common to both training and target distributions. The method estimates importance weights using an auxiliary domain classifier to approximate the ratio of SX to the original distributions. By reweighting samples from training and target distributions, DISDE computes conditional risks under the shared distribution and decomposes the overall performance degradation into three interpretable terms. The approach provides asymptotically normal and efficient estimators for these decomposition terms, allowing for principled statistical inference about the sources of performance degradation.

## Key Results
- DISDE correctly identified that a Y|X shift in the employment prediction task was due to missing education data
- The method explained why a domain adaptation approach failed on satellite image classification
- Statistical analysis proves the estimator is asymptotically normal and efficient
- Validated on tabular census data for employment prediction and satellite image classification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DISDE attributes performance degradation to three interpretable causes: (1) harder examples common to both distributions, (2) changes in feature-outcome relationships, (3) poor performance on rare/unseen examples.
- Mechanism: The method constructs a "shared distribution" SX containing covariate values common to both training and target, then reweights samples to estimate conditional risks under PY|X and QY|X on SX.
- Core assumption: There exists a shared distribution SX with support contained in both PX and QX, and the auxiliary domain classifier can approximate the importance weights dSX/dPX and dSX/dQX.
- Evidence anchors:
  - [abstract] "Our approach decomposes the performance drop into terms for 1) an increase in harder but frequently seen examples from training, 2) changes in the relationship between features and outcomes, and 3) poor performance on examples infrequent or unseen during training."
  - [section 2.1] "The first term in our decomposition... measures performance degradation due to an increase in the frequency of harder values of X that are common between training and target distributions."
- Break condition: If there is no shared support between PX and QX, the decomposition is not valid. Also, if the domain classifier cannot accurately estimate importance weights, the reweighting will be biased.

### Mechanism 2
- Claim: DISDE can guide modeling interventions by identifying which type of shift is responsible for performance degradation.
- Mechanism: By attributing performance degradation to specific causes, DISDE suggests targeted solutions: reweighting for X shifts, feature engineering for Y|X shifts, and collecting new data for rare examples.
- Core assumption: The decomposition terms correspond to actionable interventions, and the identified shift type is the primary cause of degradation.
- Evidence anchors:
  - [section 2.1.1] "If PY|X = QY|X, then we expect the shared data X∼SX to be able to inform good models under QX, e.g. by using domain adaptation methods."
  - [section 2.1.3] "The X shift (S→Q) term is large if the model performs poorly incurs higher loss on such 'newer examples' under QY|X."
- Break condition: If multiple shifts interact in complex ways, or if the identified shift is not the primary cause, the suggested interventions may not be effective.

### Mechanism 3
- Claim: DISDE provides asymptotically normal and efficient estimators for the decomposition terms, allowing for principled statistical inference.
- Mechanism: The method uses semiparametric estimation techniques and kernel smoothing to estimate nuisance parameters, and leverages results from statistics to show asymptotic normality and efficiency.
- Core assumption: The nuisance parameters converge sufficiently quickly and smoothly, and the loss function is regular enough.
- Evidence anchors:
  - [section 5.1] "By leveraging results from the semiparametric statistics literature [66], we give a central limit theorem for our estimator even when the auxiliary domain classifier is estimated nonparametrically."
  - [section 5.1] "We can compare the asymptotic variance of our estimator to lower bounds... to confirm that our proposed approach is statistically efficient."
- Break condition: If the assumptions on the nuisance parameter estimator or the loss function are violated, the asymptotic normality and efficiency may not hold.

## Foundational Learning

- Concept: Importance weighting and domain adaptation
  - Why needed here: DISDE uses importance weighting to reweight samples from training and target distributions to approximate the shared distribution SX.
  - Quick check question: How does importance weighting help DISDE estimate performance on the shared distribution when we only have samples from training and target?

- Concept: Propensity scores and causal inference
  - Why needed here: The auxiliary domain classifier in DISDE is analogous to a propensity score in causal inference, used to balance covariates between distributions.
  - Quick check question: What is the role of the domain classifier in DISDE, and how is it similar to a propensity score in causal inference?

- Concept: Semiparametric estimation and influence functions
  - Why needed here: DISDE uses semiparametric estimation techniques and derives influence functions to show asymptotic normality and efficiency of the estimators.
  - Quick check question: How does the influence function help DISDE construct confidence intervals for the decomposition terms?

## Architecture Onboarding

- Component map:
  - Model to be evaluated (f) -> Domain classifier (π̂) -> Data splits (train/val for training, test for target) -> Decomposition algorithm -> Statistical inference module (confidence intervals)

- Critical path:
  1. Train model f on training data
  2. Train domain classifier π̂ on training and target data
  3. Compute importance weights using π̂
  4. Estimate decomposition terms using weighted averages
  5. Construct confidence intervals using bootstrap or influence functions

- Design tradeoffs:
  - Choice of shared distribution SX: different definitions (e.g., pq/(p+q) vs min(p,q)) may lead to slightly different decompositions, but the qualitative conclusions are often similar.
  - Domain classifier complexity: a more complex classifier may better estimate importance weights but also increase variance.
  - Cross-fitting: helps reduce overfitting but increases computational cost.

- Failure signatures:
  - If the domain classifier is poorly calibrated, the importance weights may be biased, leading to incorrect decomposition terms.
  - If the shared distribution SX has very little overlap between training and target, the decomposition may not be meaningful.
  - If the loss function is not regular enough, the asymptotic normality and efficiency of the estimators may not hold.

- First 3 experiments:
  1. Apply DISDE to a simple synthetic dataset with known distribution shifts and verify that the decomposition correctly attributes performance degradation to the appropriate causes.
  2. Use DISDE to diagnose why a domain adaptation method (e.g., DANN) fails on a real-world dataset, and check if the identified shift type matches the intuition behind the method.
  3. Test the sensitivity of DISDE to different choices of shared distribution SX and domain classifier complexity on a real-world dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How sensitive is DISDE's decomposition to the specific choice of shared distribution SX?
- Basis in paper: [explicit] The authors compare different shared space definitions (e.g. pq/(p+q) vs min(p,q) vs clipped ATE) and find qualitative similarity but note sensitivity to truncation threshold values.
- Why unresolved: The paper only tests a few specific choices and doesn't provide a systematic sensitivity analysis or theoretical justification for the optimal choice of shared distribution.
- What evidence would resolve it: A comprehensive study comparing many different shared distribution formulations on diverse datasets, along with theoretical analysis of their properties, would clarify which choices are most appropriate and under what conditions.

### Open Question 2
- Question: Can DISDE be extended to handle more than two distributions or continuous distributional shifts?
- Basis in paper: [inferred] The paper focuses on comparing performance between training and target distributions, but doesn't address how to handle multiple target distributions or gradual distributional changes over time.
- Why unresolved: The current formulation of DISDE is designed for pairwise comparisons and may not generalize naturally to more complex scenarios.
- What evidence would resolve it: Developing and validating DISDE extensions for multi-distribution settings or continuous shifts would demonstrate its broader applicability.

### Open Question 3
- Question: How does DISDE's performance compare to other methods for attributing performance degradation to different types of distribution shifts?
- Basis in paper: [inferred] The paper introduces DISDE as a new method but doesn't compare it to existing approaches for understanding distribution shift impacts.
- Why unresolved: Without comparisons to alternative methods, it's unclear how DISDE's unique contributions measure up in practice.
- What evidence would resolve it: Empirical studies comparing DISDE to other attribution methods (e.g., Shapley value-based approaches) across various tasks and datasets would establish its relative strengths and weaknesses.

## Limitations
- DISDE assumes existence of a shared support SX between training and target distributions; this may not hold in cases of extreme domain shift
- Performance depends on accurate estimation of importance weights via the domain classifier, which can be challenging when distributions have minimal overlap
- The method provides attribution but doesn't automatically suggest optimal interventions - practitioner judgment is still required

## Confidence
- **High confidence**: The theoretical framework and asymptotic guarantees are well-established, following from semiparametric statistics literature
- **Medium confidence**: The empirical validation shows DISDE can correctly identify shift types, but sample sizes are modest (n=16k for census data)
- **Medium confidence**: The decomposition's practical utility in guiding interventions is demonstrated but would benefit from more extensive ablation studies

## Next Checks
1. Test DISDE's sensitivity to different choices of shared distribution SX (e.g., min(p,q) vs pq/(p+q)) on datasets with known shift characteristics
2. Evaluate performance when training and target distributions have minimal overlap to assess breakdown conditions
3. Conduct controlled experiments varying one shift type at a time to verify DISDE's attribution accuracy under idealized conditions