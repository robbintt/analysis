---
ver: rpa2
title: 'From Alexnet to Transformers: Measuring the Non-linearity of Deep Neural Networks
  with Affine Optimal Transport'
arxiv_id: '2310.11439'
source_url: https://arxiv.org/abs/2310.11439
tags:
- non-linearity
- resnet50
- activation
- figure
- depth
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a theoretically grounded method to measure
  the non-linearity of deep neural networks (DNNs) by leveraging optimal transport
  theory. The proposed affinity score quantifies the deviation from affine transformations
  by comparing Wasserstein distances between observed and normally approximated distributions,
  with a closed-form expression for the affine OT map.
---

# From Alexnet to Transformers: Measuring the Non-linearity of Deep Neural Networks with Affine Optimal Transport

## Quick Facts
- arXiv ID: 2310.11439
- Source URL: https://arxiv.org/abs/2310.11439
- Reference count: 40
- One-line primary result: Introduces a theoretically grounded method to measure DNN non-linearity using optimal transport theory, revealing how architectural choices shape non-linearity propagation.

## Executive Summary
This paper introduces a theoretically grounded method to measure the non-linearity of deep neural networks (DNNs) by leveraging optimal transport theory. The proposed affinity score quantifies the deviation from affine transformations by comparing Wasserstein distances between observed and normally approximated distributions, with a closed-form expression for the affine OT map. Applied to a broad set of architectures (AlexNet to Vision Transformers), the method reveals how non-linearity propagates across layers and how architectural choices (e.g., residual connections, inception modules, patch sizes) shape this propagation. Experiments on ImageNet show the score is robust to dimensionality reduction, batch size, and training seeds. Unlike other similarity metrics, the affinity score uniquely captures non-linearity and strongly correlates with ImageNet accuracy in task-specific ways, offering insights into the expressive power and design trade-offs of DNNs. The method provides a new lens for understanding and comparing DNN architectures.

## Method Summary
The method computes an affinity score quantifying non-linearity by comparing Wasserstein distances between true and Gaussian-approximated distributions. For each activation function in a pre-trained DNN, input and output tensors are extracted, spatially averaged to reduce dimensionality, and covariance matrices are estimated with Ledoit-Wolf shrinkage when needed. The affinity score is calculated using a closed-form optimal transport map between normal approximations, with lower scores indicating higher non-linearity. These scores are aggregated into non-linearity signature vectors per layer across architectures.

## Key Results
- The affinity score uniquely captures non-linearity and correlates with ImageNet accuracy in architecture-specific ways
- Non-linearity propagation varies significantly across architectures: ViT shows monotonic increase while CNNs show diverse patterns
- Architectural choices like inception modules and residual connections shape non-linearity propagation differently
- The method is robust to dimensionality reduction, batch size variations, and training seeds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The affinity score quantifies non-linearity by measuring how far a transformation deviates from an affine one via optimal transport theory.
- Mechanism: For two random variables linked by an affine transformation, the Wasserstein-2 distance equals the distance between their normal approximations, with a closed-form OT map. Deviations from this equality indicate non-linearity.
- Core assumption: The push-forward of one distribution by an affine map preserves the normal approximation relationship exactly.
- Evidence anchors:
  - [abstract] "The proposed affinity score quantifies the deviation from affine transformations by comparing Wasserstein distances between observed and normally approximated distributions"
  - [section] Theorem 3.3 states that when $Y = TX$ for positive definite $T$, then $W_2(N_X, N_Y) = W_2(X, Y)$ and $T$ is the OT map.
  - [corpus] Weak: no direct mention of optimal transport in corpus; the neighbor papers discuss neural networks but not OT-based non-linearity measures.
- Break condition: If the distribution is not well-approximated by a normal distribution, the closed-form equality breaks down.

### Mechanism 2
- Claim: Dimensionality reduction via averaging over spatial dimensions preserves the affinity score's discriminative power.
- Mechanism: Flattening tensors to high dimensions is computationally prohibitive; averaging over spatial axes yields vectors that retain the covariance structure needed for the OT computation.
- Core assumption: The spatial averaging operation is a linear projection that preserves sufficient information about non-linearity in the feature dimension.
- Evidence anchors:
  - [section] "We propose to use averaging over the spatial dimensions to get a suitable representation of the manipulated tensors" and Figure 2 (left) shows robustness to this scheme.
  - [abstract] No explicit mention of averaging, but the overall robustness claim supports this.
  - [corpus] Weak: no neighbor paper discusses spatial averaging or dimensionality reduction in OT context.
- Break condition: If the spatial structure carries essential non-linear information, averaging could erase discriminative signals.

### Mechanism 3
- Claim: Ledoit-Wolf shrinkage stabilizes covariance estimation when batch size is smaller than feature dimension.
- Mechanism: When $n \ll c$, the empirical covariance is singular; shrinkage blends it with a scaled identity to produce a well-conditioned estimator.
- Core assumption: The true covariance is close enough to the empirical estimate that shrinkage does not distort the affinity score significantly.
- Evidence anchors:
  - [section] "To obtain a well-defined estimate of the covariance matrix in this case, we use a known tool from the statistics literature called Ledoit-Wolf shrinkage" and Figure 2 (right) confirms stability.
  - [abstract] No explicit mention of shrinkage but the robustness claim implies it.
  - [corpus] Weak: no neighbor paper addresses covariance shrinkage in the context of DNN non-linearity analysis.
- Break condition: If the true covariance has a structure far from the identity, shrinkage could bias the score.

## Foundational Learning

- Concept: Optimal transport (OT) and Wasserstein distance
  - Why needed here: The affinity score relies on comparing Wasserstein distances between true and Gaussian-approximated distributions to detect affine vs non-affine behavior.
  - Quick check question: What does the Wasserstein-2 distance measure between two probability measures?

- Concept: Covariance matrix estimation and regularization
  - Why needed here: The affinity score requires stable covariance estimates for high-dimensional tensors; shrinkage is used when the sample size is smaller than dimensionality.
  - Quick check question: Why does Ledoit-Wolf shrinkage help when the number of samples is less than the feature dimension?

- Concept: Dimensionality reduction preserving statistical properties
  - Why needed here: Tensors from DNN layers are 4D; averaging over spatial dimensions reduces them to 2D without losing the non-linearity signal.
  - Quick check question: How does averaging over spatial axes affect the covariance structure of the resulting vectors?

## Architecture Onboarding

- Component map: Forward pass through pre-trained DNN → activation extraction → spatial averaging → covariance estimation with shrinkage → affinity score computation → signature assembly
- Critical path: Forward pass → activation extraction → dimensionality reduction → covariance estimation → affinity score → signature assembly
- Design tradeoffs: Averaging over spatial dimensions is computationally efficient but may discard spatial non-linearity cues; shrinkage stabilizes estimation but can bias covariance structure; using normal approximations is tractable but may misrepresent heavy-tailed distributions
- Failure signatures: If the signature vector is nearly constant across layers, either the model is highly linear or the reduction step is destroying discriminative structure; if covariance matrices are singular and shrinkage fails, the score is undefined
- First 3 experiments:
  1. Run a single batch through a simple ConvNet (e.g., AlexNet) and inspect the covariance matrices before and after averaging to verify dimensionality reduction
  2. Compare affinity scores with and without shrinkage on a small dataset where $n < c$ to observe stabilization effects
  3. Pass synthetic Gaussian data through an identity mapping and verify the affinity score is close to 1, confirming the affine case

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different activation functions compare in terms of their non-linearity profiles across various network architectures?
- Basis in paper: [explicit] The paper analyzes affinity scores for various activation functions (ReLU, GELU, sigmoid, etc.) and shows that their non-linearity depends on both the domain and architecture.
- Why unresolved: The study provides initial comparisons but does not systematically rank or correlate activation functions' non-linearity profiles across architectures.
- What evidence would resolve it: A comprehensive comparative study quantifying non-linearity across diverse architectures and activation functions, establishing clear patterns and correlations.

### Open Question 2
- Question: What is the impact of architectural innovations (e.g., attention mechanisms, skip connections) on the propagation of non-linearity through networks?
- Basis in paper: [explicit] The paper observes how architectural choices like inception modules, residual connections, and vision transformers affect non-linearity propagation.
- Why unresolved: While trends are noted, the underlying mechanisms and precise impact of specific architectural innovations on non-linearity propagation remain unclear.
- What evidence would resolve it: Detailed ablation studies isolating the effect of individual architectural components on non-linearity propagation, potentially using controlled experiments.

### Open Question 3
- Question: How does the non-linearity signature correlate with other performance metrics beyond ImageNet accuracy, such as robustness to adversarial attacks or out-of-distribution generalization?
- Basis in paper: [explicit] The paper establishes a correlation between non-linearity signature and ImageNet accuracy but does not explore other performance aspects.
- Why unresolved: The study focuses on ImageNet accuracy as the primary performance metric, leaving the relationship with other crucial aspects unexplored.
- What evidence would resolve it: Extensive experiments correlating non-linearity signatures with various performance metrics across different datasets and tasks.

## Limitations
- Reliance on Gaussian approximations may not capture heavy-tailed or multimodal activation distributions
- Spatial averaging for dimensionality reduction could erase architecture-specific spatial non-linearity patterns
- Method's generalizability to non-ImageNet datasets and architectures beyond those tested is uncertain

## Confidence

- **High Confidence**: The mathematical framework for affinity score computation (Mechanism 1)
- **Medium Confidence**: Dimensionality reduction via spatial averaging (Mechanism 2)
- **Medium Confidence**: Ledoit-Wolf shrinkage for covariance stabilization (Mechanism 3)
- **Low Confidence**: Generalizability to non-ImageNet datasets and architectures beyond those tested

## Next Checks

1. **Distribution Validation**: Apply Kolmogorov-Smirnov tests to compare activation distributions against normal distributions across layers and architectures. If significant deviations are found, quantify the impact on affinity score accuracy.

2. **Spatial Structure Preservation**: Run controlled experiments where synthetic spatial patterns are embedded in inputs, then measure how spatial averaging affects the ability to detect layer-wise non-linearity. Compare against alternative dimensionality reduction methods.

3. **Cross-Dataset Generalization**: Compute non-linearity signatures on CIFAR-10/100 and evaluate whether the same architectural ordering (e.g., ResNet > DenseNet > AlexNet) holds. Test on out-of-distribution datasets to assess robustness to data distribution shifts.