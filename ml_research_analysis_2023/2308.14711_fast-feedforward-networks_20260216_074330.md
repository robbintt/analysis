---
ver: rpa2
title: Fast Feedforward Networks
arxiv_id: '2308.14711'
source_url: https://arxiv.org/abs/2308.14711
tags:
- feedforward
- networks
- training
- inference
- width
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Fast Feedforward (FFF) architecture introduces a log-time alternative
  to traditional feedforward networks by organizing neurons into a tree structure
  with conditional execution. This allows inference using only a small fraction of
  neurons (as low as 1%) while maintaining high accuracy.
---

# Fast Feedforward Networks

## Quick Facts
- arXiv ID: 2308.14711
- Source URL: https://arxiv.org/abs/2308.14711
- Reference count: 5
- Key outcome: FFFs achieve up to 220x faster inference than feedforward networks and 6x faster than mixture-of-experts models while maintaining high accuracy

## Executive Summary
Fast Feedforward (FFF) networks introduce a log-time alternative to traditional feedforward architectures by organizing neurons into a binary tree structure with conditional execution. This allows inference using only a small fraction of neurons (as low as 1%) while maintaining high accuracy. FFFs achieve significant speedups by learning input space partitions that harden during training, enabling efficient conditional execution without noisy gating.

## Method Summary
FFF networks divide the input space into disjoint regions using a differentiable binary tree and perform simultaneous learning of region boundaries and neural blocks assigned to these regions. During training, all nodes and leaves are updated via backpropagation with an optional hardening loss to encourage decisive region boundaries. At inference, only one leaf (a small feedforward network) is executed, reducing computation from O(width) to O(depth) where depth = log₂(width/leaf_size). The architecture is implemented as a PyTorch module and tested on image classification tasks including USPS, MNIST, FashionMNIST, SVHN, CIFAR10, and CIFAR100.

## Key Results
- FFFs matched or exceeded feedforward networks' accuracy while using far fewer neurons for inference
- Achieved up to 220x faster inference than feedforward networks and 6x faster than mixture-of-experts models
- When applied to vision transformers, FFFs enabled single-neuron inference with only 5.8% accuracy loss compared to full-width variants

## Why This Works (Mechanism)

### Mechanism 1
FFFs achieve log-time inference by using a binary tree to partition the input space, where only one leaf is executed per inference. The differentiable binary tree learns soft boundaries between input regions, and during inference, hard decisions are made at each node to descend to a single leaf, reducing computation from O(width) to O(depth).

### Mechanism 2
FFF maintains accuracy while using fewer neurons by allocating representational power across many small leaves rather than one wide layer. During training, all leaves and nodes are updated, allowing the network to learn different sub-functions for different regions. During inference, only one leaf is used, but it was trained specifically for its region, preserving accuracy.

### Mechanism 3
Hardening of node decisions enables the transition from soft mixture-of-experts training to hard single-leaf inference without accuracy loss. During training, nodes make soft choices over children, and as training progresses, the optimizer pushes these probabilities toward 0 or 1 (hard decisions). The hardening loss encourages this process, and once hardened, inference uses the same architecture but with hard decisions.

## Foundational Learning

- Concept: Binary tree data structures and their traversal properties
  - Why needed here: FFFs use a binary tree to organize neurons and route inputs. Understanding tree depth, branching factor, and traversal time is essential to grasp the log-time complexity claim.
  - Quick check question: What is the maximum depth of a balanced binary tree with n leaves, and how does this relate to the number of decisions needed to reach a leaf?

- Concept: Conditional execution and sparse computation
  - Why needed here: FFFs selectively execute neurons based on input. Understanding how conditional execution reduces computational cost and how to train networks with sparse activation patterns is crucial.
  - Quick check question: How does the computational cost of a feedforward network change if only k out of n neurons are active per inference, and what conditions must hold for accuracy to be preserved?

- Concept: Mixture-of-experts models and gating mechanisms
  - Why needed here: FFFs are compared to MoE models. Understanding how MoEs use gating networks to select experts, and the trade-offs between MoEs and FFFs, provides context for FFF's advantages.
  - Quick check question: In a mixture-of-experts model with n experts and k selected per inference, what is the inference complexity, and how does this compare to FFF's log-depth complexity?

## Architecture Onboarding

- Component map: Root node -> Internal nodes (binary decisions) -> Leaf nodes (small feedforward networks) -> Hardening loss (optional) -> Balanced binary tree of depth d with 2^d leaves

- Critical path: Input enters root node → Each node makes binary decision based on learned boundary → Path descends through d nodes to reach one leaf → Leaf executes and produces output → (Training only) All nodes and leaves are updated via backpropagation

- Design tradeoffs:
  - Leaf size vs. depth: Smaller leaves allow deeper trees and faster inference but risk overfragmentation
  - Training width vs. inference width: Larger training width provides more representational power but increases memory and computation during training
  - Hardening loss weight: Encourages faster hardening but may cause premature commitment to poor boundaries
  - Batch size: Smaller batches may cause the "shrinking batch problem" where leaves receive insufficient gradient updates

- Failure signatures:
  - Accuracy drop during inference compared to training: Indicates hardening occurred too aggressively or tree learned poor boundaries
  - Training instability or slow convergence: May indicate overfragmentation or insufficient representational power in leaves
  - Leaf nodes not updating: Could indicate vanishing gradients due to poor tree structure or excessive depth
  - High variance in repeated runs: May indicate insufficient training data per leaf region

- First 3 experiments:
  1. Replace a feedforward layer in a small transformer with FFF (d=2, ℓ=8) on MNIST, compare accuracy and inference time to baseline
  2. Vary leaf size (ℓ=1,2,4,8) with fixed training width, measure accuracy and hardening progress to identify overfragmentation threshold
  3. Compare FFF to MoE with same number of experts/leaves on CIFAR10, measure accuracy, inference time, and training epochs to convergence

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided text.

## Limitations
- Generalization to complex vision tasks beyond CIFAR10 remains unproven
- The hardening mechanism's stability across different network depths and leaf sizes needs systematic validation
- The comparison to MoE models uses fixed expert counts rather than proportional scaling

## Confidence
- **High**: The log-time complexity claim (O(log n) vs O(n) inference)
- **Medium**: The accuracy preservation claim with sparse execution
- **Low**: The 220x speedup claim, which depends heavily on hardware and implementation details

## Next Checks
1. **Scaling Test**: Apply FFF to ImageNet-scale classification (224x224 images) and measure accuracy, inference time, and memory usage compared to full-width transformers and MoE variants.

2. **Hardening Stability**: Conduct ablation studies varying the hardening loss weight (h parameter) across multiple runs, measuring both convergence speed and final accuracy to identify optimal hardening schedules.

3. **Architectural Robustness**: Test FFF with different tree structures (unbalanced trees, ternary splits) and measure how structural variations affect both training dynamics and inference efficiency.