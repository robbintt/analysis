---
ver: rpa2
title: Quantifying the perceptual value of lexical and non-lexical channels in speech
arxiv_id: '2307.03534'
source_url: https://arxiv.org/abs/2307.03534
tags:
- lexical
- non-lexical
- information
- dialogue
- channel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper quantifies the value of lexical and non-lexical channels
  in spoken dialogue using a generalized turn discrimination paradigm. It uses a dialogue-based
  language model to select lexically diverse but plausible responses, allowing investigation
  across unconstrained lexical content.
---

# Quantifying the perceptual value of lexical and non-lexical channels in speech

## Quick Facts
- arXiv ID: 2307.03534
- Source URL: https://arxiv.org/abs/2307.03534
- Reference count: 0
- Primary result: Non-lexical prosody reduces entropy in acceptability ratings even when it decreases discriminative accuracy

## Executive Summary
This paper quantifies the perceptual value of lexical and non-lexical channels in spoken dialogue using a generalized turn discrimination paradigm. It employs a dialogue-based language model to generate lexically diverse but plausible responses, allowing investigation across unconstrained lexical content. Participants rated the plausibility of responses given conversational context, with responses presented as transcripts (lexical condition) or speech recordings (acoustic condition). The study uses both accuracy and entropy reduction to quantify channel value, finding that non-lexical information increases discriminative performance when lexical content is ambiguous, but can decrease it when lexical content is informative. Crucially, non-lexical information consistently leads to higher consensus among participants even when it results in poorer discriminative turn judgements than lexical content alone.

## Method Summary
The study uses the Switchboard Telephone Corpus, which is preprocessed by segmenting into turns, de-bleeding audio, cleaning transcripts, and filtering stimuli. A BERT cross-encoder dialogue model is trained on Switchboard for response selection. The model generates plausible responses for conversational contexts, creating stimuli consisting of a context plus 5 responses (true response + 4 sampled). Participants from Prolific Academic rate the plausibility of responses in both lexical (transcript) and acoustic (audio) conditions. The study quantifies channel value using both accuracy metrics and entropy reduction, analyzing results with Bayesian multilevel regression models.

## Key Results
- Non-lexical prosody reduces entropy in acceptability ratings even when it decreases discriminative accuracy
- The effect of non-lexical information on discriminative performance depends on the informativeness of lexical content
- Acoustic stimuli place higher cognitive load on participants, with accuracy decreasing as response length increases
- Different speech acts exhibit greater prosodic variation, suggesting the non-lexical channel may carry more information for certain speech acts

## Why This Works (Mechanism)

### Mechanism 1
Non-lexical prosody constrains listener expectations by providing acoustic cues that disambiguate equally plausible lexical continuations. When lexical content is ambiguous, participants use prosodic features (F0, intensity, duration) to infer speaker intent, topic, and turn-taking cues, reducing entropy in their acceptability ratings. Core assumption: Prosodic features are perceived and interpreted consistently across listeners. Evidence: Prosodic information contributes to marking novel information, conveying attitudes, and managing turn-taking. Break condition: If prosodic cues are highly variable across speakers or contexts, the disambiguating effect diminishes.

### Mechanism 2
Entropy reduction, not just accuracy, captures the value of non-lexical information by accounting for the inherent optionality of upcoming dialogue. Entropy measures the dispersion of participant ratings across response options. Lower entropy after hearing acoustic information indicates more consistent interpretation, even if the "correct" response is not identified. Core assumption: Participants treat acceptability judgements probabilistically. Evidence: Entropy reduction proposed as a measure to account for optionality in upcoming dialogue. Break condition: If entropy is dominated by individual biases or if participants ignore non-lexical cues, entropy reduction may not reflect true channel value.

### Mechanism 3
The generalized turn discrimination paradigm enables study of non-lexical effects across unconstrained lexical content by sampling plausible responses from a dialogue-based LM. A BERT cross-encoder LM trained for response selection generates lexically diverse but equally plausible responses, avoiding the lexical-equivalence constraint of earlier paradigms. Core assumption: The LM's scores correlate with human acceptability judgements. Evidence: Use of state-of-the-art response selection model trained on Switchboard. Break condition: If the LM's plausibility scores poorly align with human judgements, or if sampling fails to produce truly plausible continuations, the paradigm's validity is compromised.

## Foundational Learning

- Concept: Entropy as a measure of uncertainty/disagreement in probabilistic judgements.
  - Why needed here: To quantify how much non-lexical information reduces variability in listener expectations beyond simple accuracy.
  - Quick check question: If two participants rate responses as [4,4,2,1] and [4,4,1,2], what does entropy reveal about their agreement that accuracy does not?

- Concept: Prosodic correlates (F0, intensity, duration) and their communicative functions.
  - Why needed here: To understand what acoustic features participants might use to disambiguate responses and why these features convey information beyond lexical content.
  - Quick check question: How might rising F0 at utterance end signal uncertainty, and how would this affect turn-acceptance ratings?

- Concept: Dialogue act annotations and their role in controlling for pragmatic context.
  - Why needed here: To account for how different speech acts (questions, backchannels, statements) may rely more or less on non-lexical cues, and to control for this variation in analysis.
  - Quick check question: Would a backchannel like "right" be more reliant on prosodic cues than a contentful statement, and how would you test this?

## Architecture Onboarding

- Component map: Switchboard corpus -> de-bleed -> turn segmentation -> LM sampling -> stimulus construction (context + 5 responses) -> Prolific survey (lexical vs acoustic) -> entropy/accuracy metrics -> Bayesian multilevel regression
- Critical path: Stimulus construction -> participant scoring -> entropy reduction analysis -> interpretation of non-lexical channel value
- Design tradeoffs: Using a pre-trained LM for sampling increases lexical diversity but introduces model bias; controlling for response length and surprisal in regression models increases validity but adds complexity
- Failure signatures: Low accuracy in lexical condition for ambiguous stimuli (as intended); higher entropy in acoustic condition for long responses (cognitive load); lack of interaction between condition and dialogue act in regression
- First 3 experiments:
  1. Re-run the study with a larger set of stimuli and verify entropy reduction replicates for ambiguous items
  2. Conduct a post-hoc analysis comparing entropy for different dialogue acts to see if some rely more on non-lexical cues
  3. Test a simpler entropy measure (e.g., standard Shannon entropy) to confirm ordinal entropy is capturing the intended effect

## Open Questions the Paper Calls Out

- Question: How does the non-lexical channel's effect on dialogue perception vary across different speech acts or communicative functions?
  - Basis: Different speech acts exhibit greater prosodic variation, suggesting the non-lexical channel may carry more information for certain speech acts, but this was not empirically investigated
  - Why unresolved: The study focused on a general paradigm and did not systematically vary speech acts
  - What evidence would resolve it: Empirical testing of non-lexical channel value across different speech acts, controlling for lexical content and context

## Limitations

- The dialogue LM's ability to generate truly plausible but lexically diverse responses is not empirically validated against human judgements
- The entropy measure lacks direct comparison to simpler alternatives to confirm it captures the intended effect
- Generalizability is limited by use of Switchboard, a narrow corpus of telephone conversations between strangers

## Confidence

- High confidence: Methodological framework (generalized turn discrimination paradigm with LM sampling) is sound and well-motivated
- Medium confidence: Finding that non-lexical prosody increases consensus is supported, but interpretation as general effect on "expectations of upcoming dialogue" is speculative
- Low confidence: Claim that non-lexical prosody disambiguates "equally plausible" lexical continuations assumes LM generates truly ambiguous responses, not directly tested

## Next Checks

1. Replicate with alternative entropy measures: Conduct post-hoc analysis using standard Shannon entropy to confirm ordinal entropy measure captures intended effect

2. Test LM sampling quality: Design experiment where participants rate plausibility of true responses versus sampled responses directly to verify LM's top-scoring responses are truly plausible

3. Cross-corpus validation: Apply methodology to different dialogue corpus (e.g., DailyDialog or Friends) to test whether entropy reduction effect generalizes beyond Switchboard domain