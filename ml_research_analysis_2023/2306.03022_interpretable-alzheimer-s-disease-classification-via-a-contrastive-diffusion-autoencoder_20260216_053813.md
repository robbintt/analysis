---
ver: rpa2
title: Interpretable Alzheimer's Disease Classification Via a Contrastive Diffusion
  Autoencoder
arxiv_id: '2306.03022'
source_url: https://arxiv.org/abs/2306.03022
tags:
- image
- learning
- contrastive
- disease
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a contrastive diffusion autoencoder for interpretable
  Alzheimer's Disease classification using 2D MRI slices. The model learns a semantically
  meaningful latent space where image-level similarities are preserved, enabling classification
  based on similarity to training examples (prototypes).
---

# Interpretable Alzheimer's Disease Classification Via a Contrastive Diffusion Autoencoder

## Quick Facts
- arXiv ID: 2306.03022
- Source URL: https://arxiv.org/abs/2306.03022
- Reference count: 17
- Achieves 88% test accuracy on AD vs HC classification using 2D MRI slices with interpretable prototype explanations

## Executive Summary
This paper presents a contrastive diffusion autoencoder for interpretable Alzheimer's Disease classification using 2D MRI slices. The model learns a semantically meaningful latent space where image-level similarities are preserved, enabling classification based on similarity to training examples (prototypes). A contrastive loss ensures intra-class similarity while inter-class separation. Evaluated on 6137 MRI images (AD=1105, HC=5032), the model achieves 88% test accuracy, comparable to black-box approaches, while providing human-interpretable explanations via nearest prototype visualizations.

## Method Summary
The method uses a diffusion autoencoder backbone combined with a contrastive loss to produce a semantically meaningful latent space. A semantic encoder maps images to d-dimensional latents, while a pairwise cosine similarity metric computes similarities between latents within each batch. The classification is performed by finding K nearest neighbors in the latent space using cosine similarity, with the mode class of neighbors predicting the input class. The model is trained with three losses: image reconstruction, contrastive, and classification losses.

## Key Results
- Achieves 88% test accuracy on AD vs HC classification using 2D MRI slices
- Classification performance comparable to black-box approaches while providing interpretable explanations
- Nearest prototype visualizations provide human-interpretable model explanations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive diffusion autoencoder learns semantically meaningful latent space that preserves image-level similarities.
- Mechanism: Diffusion autoencoder learns semantic and stochastic subcodes simultaneously, with contrastive loss pushing intra-class images closer and inter-class images apart in embedding space.
- Core assumption: Semantic subcode captures class-discriminative features while stochastic subcode handles reconstruction noise.
- Evidence anchors: [abstract] "We use a contrastive loss combined with a diffusion autoencoder backbone, to produce a semantically meaningful latent space, such that neighbouring latents have similar image-level features." [section] "The semantic encoder Encsem(x0) = zsem, maps an image to its semantic subcode, where zsem ∈ Rd. A pairwise similarity metric, sim: Rd → R is then computed between zsem and all other latents within the batch."

### Mechanism 2
- Claim: Prototype-based classification provides interpretable explanations by comparing input to training examples.
- Mechanism: Classification based on K-nearest neighbors in latent space using cosine similarity, where nearest prototypes provide visual explanations.
- Core assumption: Semantic latent space preserves class structure such that nearest neighbors in latent space are visually similar at image level.
- Evidence anchors: [abstract] "We achieve a classification accuracy comparable to black box approaches on a dataset of 2D MRI images, whilst producing human interpretable model explanations." [section] "The mode class of the K nearest neighbours is used to predict the class of x0. The similarity metric used is the cosine similarity."

### Mechanism 3
- Claim: Diffusion autoencoder provides better semantic representations than other generative models for prototype learning.
- Mechanism: Diffusion autoencoder captures rich semantic information by conditioning generation on learned semantic latent, forcing semantics into zsem.
- Core assumption: Diffusion autoencoder's semantic latent captures more meaningful factors than VAEs or GANs for this medical imaging task.
- Evidence anchors: [section] "The advantage of this training regime is that the semantics are forced into the semantic latent, zsem, which leads to rich latent representations." [section] "These representations can be leveraged for prototype learning, as they separate out the semantics contained within an image."

## Foundational Learning

- Diffusion models
  - Why needed here: Core component of the model architecture for learning semantically meaningful latent space
  - Quick check question: What are the two main processes in diffusion models and how do they work together?

- Contrastive learning
  - Why needed here: Regularizes embedding space to separate classes while preserving intra-class similarities
  - Quick check question: How does the contrastive loss function encourage class separation in the latent space?

- Prototype-based classification
  - Why needed here: Provides interpretable explanations by comparing to training examples
  - Quick check question: What similarity metric is used to find nearest prototypes and why is this appropriate?

## Architecture Onboarding

- Component map: Input 2D MRI slices (64x64, normalized) -> Semantic encoder (Downsampled U-Net) -> zsem -> Cosine similarity computation -> K nearest neighbors -> Mode class prediction. Simultaneously: Image reconstruction through diffusion autoencoder. Total loss = reconstruction + contrastive + classification.

- Critical path: 1. Input image → Semantic encoder → zsem 2. zsem → Cosine similarity with all latents → K nearest neighbors 3. K nearest neighbors → Mode class prediction 4. Simultaneously: Image reconstruction through diffusion autoencoder 5. Total loss = reconstruction + contrastive + classification

- Design tradeoffs:
  - 2D slices vs 3D volumes: 2D reduces complexity but loses volumetric information
  - K value: Larger K provides more robust classification but less precise prototypes
  - Temperature τ in contrastive loss: Controls strength of class separation
  - Latent dimension d: Larger dimensions capture more information but increase complexity

- Failure signatures:
  - Poor reconstruction quality: Indicates diffusion autoencoder not learning well
  - No class separation in t-SNE: Suggests contrastive loss not effective
  - Prototypes not visually similar to test images: Indicates latent space not semantically meaningful
  - Accuracy much lower than black-box models: Suggests prototype-based approach has limitations

- First 3 experiments:
  1. Test with K=5,7,15 to find optimal number of prototypes
  2. Visualize t-SNE of latent space to verify class separation
  3. Show prototype explanations for sample AD vs HC cases to verify interpretability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the model's performance scale with higher-resolution 3D MRI volumes compared to the 2D slices used in this study?
- Basis in paper: [inferred] The authors explicitly note that their model processes 2D slices and acknowledge this as a limitation, mentioning that black-box models of 3D image classification generally perform better than their 2D counterparts.
- Why unresolved: The study was designed to evaluate 2D slices specifically, and no experiments were conducted with full 3D volumes to compare performance differences.
- What evidence would resolve it: Direct comparison experiments using identical models trained on 2D slices versus 3D volumes from the same dataset, measuring classification accuracy and interpretability quality.

### Open Question 2
- Question: How sensitive is the contrastive loss formulation to different age distributions within the Alzheimer's disease and healthy control groups?
- Basis in paper: [inferred] The authors note that morphological changes in older individuals resemble neurodegeneration, suggesting age-related confounds in the latent space clustering, but do not explicitly test this.
- Why unresolved: The current study does not perform controlled experiments varying age distributions or stratifying results by age groups to quantify the contrastive loss's robustness to age-related confounding.
- What evidence would resolve it: Systematic experiments with age-stratified training and testing sets, or explicit age-correction terms in the contrastive loss, measuring performance changes across different age ranges.

### Open Question 3
- Question: Can the diffusion autoencoder's latent space be effectively clustered to improve classification beyond the nearest-neighbor approach?
- Basis in paper: [explicit] The authors mention in the discussion that "There is also structure within both latent clusters, which may be used to aid model predictions via clustering techniques in future work."
- Why unresolved: The current prototype-based classification relies solely on nearest-neighbor similarity, without exploring whether the observed cluster structure could be leveraged for improved accuracy or more nuanced explanations.
- What evidence would resolve it: Experiments implementing various clustering algorithms (k-means, hierarchical, Gaussian mixture models) on the latent space and comparing their classification performance against the current prototype-based approach.

## Limitations
- Limited to 2D slices, missing 3D volumetric information that black-box models can capture
- Prototype-based explanations are qualitative rather than quantitatively validated
- No comparison against other generative models (VAEs, GANs) for semantic representation quality

## Confidence

- **High Confidence**: The diffusion autoencoder architecture and training procedure are technically sound and implementable
- **Medium Confidence**: The contrastive loss effectively separates classes in latent space, based on the described mechanism but lacking direct empirical validation
- **Medium Confidence**: The prototype-based explanations provide meaningful interpretability, though this is primarily qualitative evidence

## Next Checks
1. Generate t-SNE plots of the semantic latent space to visually verify class separation and check if nearest prototypes are indeed semantically similar to their corresponding test images
2. Implement a VAE-based prototype model with the same classification pipeline to empirically validate that diffusion autoencoders provide superior semantic representations for this task
3. Remove the contrastive loss and measure changes in both classification accuracy and prototype quality to quantify its contribution to the overall performance