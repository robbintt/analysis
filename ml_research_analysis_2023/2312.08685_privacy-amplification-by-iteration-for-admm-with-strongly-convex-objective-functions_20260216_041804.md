---
ver: rpa2
title: Privacy Amplification by Iteration for ADMM with (Strongly) Convex Objective
  Functions
arxiv_id: '2312.08685'
source_url: https://arxiv.org/abs/2312.08685
tags:
- privacy
- iteration
- admm
- have
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies a private ADMM variant for (strongly) convex
  objectives, where each iteration uses a user's private function masked by Gaussian
  noise for local privacy. Unlike previous work, this variant requires only one gradient
  access to the user's function, but both primal and dual variables must be passed
  between successive iterations.
---

# Privacy Amplification by Iteration for ADMM with (Strongly) Convex Objective Functions

## Quick Facts
- arXiv ID: 2312.08685
- Source URL: https://arxiv.org/abs/2312.08685
- Reference count: 12
- Key outcome: Privacy amplification by iteration for ADMM with (strongly) convex objectives, achieving exponential improvement for strongly convex functions

## Executive Summary
This paper analyzes privacy amplification by iteration for a private ADMM variant with (strongly) convex objective functions. The key innovation is using Gaussian noise to mask the primal variable in each iteration, achieving local privacy while requiring only one gradient access per user. The analysis overcomes technical challenges through a customized norm and Markov operator composition to achieve non-expansive iterations and one-step privacy. The main result shows privacy guarantees can be amplified proportionally to the number of iterations, with exponential improvement for strongly convex objectives.

## Method Summary
The method implements a private ADMM variant where each iteration applies gradient updates to a user's private function with Gaussian noise added to the primal variable. The algorithm runs for T iterations, with the noise from subsequent iterations analyzed to improve privacy guarantees for earlier iterations. The analysis uses a coupling framework with a customized norm to establish non-expansive properties and one-step privacy through Markov operator composition. Experiments use synthetic data for a generalized LASSO problem with n=64, N=1000, and σb=0.01.

## Key Results
- Privacy guarantees can be amplified proportionally to the number of iterations T
- Exponential improvement in privacy amplification for strongly convex objective functions
- One gradient access per user is sufficient, though dual variables must be communicated between iterations

## Why This Works (Mechanism)

### Mechanism 1
Privacy amplification by iteration improves privacy guarantees for the first user by leveraging noise from subsequent iterations. Each iteration t uses Gaussian noise Nt to mask the x variable, achieving local privacy. The noise from iterations t+1, t+2, etc., is analyzed to improve the privacy guarantee for the first user's data. Core assumption: The linear transformation A has the form A = [Im | D], ensuring that the λ variable can be partially masked by noise from the x variable.

### Mechanism 2
A customized norm in the (x, λ)-space makes each ADMM iteration non-expansive, enabling privacy amplification analysis. The customized norm ∥(x, λ)∥2* := ∥x∥2 + η/β · ∥λ − βAx∥2 is used to analyze the privacy of ADMM. Under this norm, each ADMM iteration is non-expansive, satisfying a key condition for the coupling framework. Core assumption: The function f used in each ADMM iteration is convex and 1/η-smooth.

### Mechanism 3
Incorporating two ADMM iterations into a single Markov operator achieves one-step privacy, enabling privacy amplification. Each Markov operator K ∈ K represents two ADMM iterations. The noise from the first iteration masks the x variable, while the noise from the second iteration masks the λ variable. This allows for one-step privacy, satisfying a key condition for the coupling framework. Core assumption: The linear transformation A has the form A = [Im | D], ensuring that the λ variable can be partially masked by noise from the x variable.

## Foundational Learning

- Concept: Alternating Direction Method of Multipliers (ADMM)
  - Why needed here: ADMM is the optimization algorithm being analyzed for privacy amplification by iteration. Understanding its mechanics is crucial for understanding the paper's contributions.
  - Quick check question: What are the three main steps in each iteration of ADMM?

- Concept: Differential Privacy and Rényi Divergence
  - Why needed here: The paper uses differential privacy and Rényi divergence to quantify the privacy guarantees achieved by the proposed method. Understanding these concepts is essential for interpreting the results.
  - Quick check question: What is the relationship between Rényi divergence and zero-concentrated differential privacy?

- Concept: Coupling Framework for Privacy Amplification
  - Why needed here: The paper applies the coupling framework to analyze privacy amplification by iteration for ADMM. Understanding this framework is necessary for understanding the paper's approach and results.
  - Quick check question: What are the two key conditions that must be satisfied for the coupling framework to achieve privacy amplification by iteration?

## Architecture Onboarding

- Component map: ADMM algorithm with gradient variant -> Gaussian noise addition for local privacy -> Coupling framework for privacy amplification analysis -> Customized norm for non-expansive property -> Markov operator composition for one-step privacy
- Critical path: 1. Initialize (x0, λ0) 2. For each iteration t: a. Apply ADMM update to (xt, λt) using ft b. Add Gaussian noise Nt to xt to get ext c. Pass (ext, λt) to next iteration 3. Analyze privacy amplification using coupling framework
- Design tradeoffs: Adding noise to x variable vs. gradient oracle, Customized norm vs. standard norm, Two iterations per Markov operator vs. one iteration
- Failure signatures: Non-expansive property not holding under customized norm, One-step privacy not achieved due to insufficient noise, Privacy amplification not observed for first user
- First 3 experiments: 1. Verify non-expansive property of ADMM iteration under customized norm 2. Confirm one-step privacy of Markov operator K 3. Measure privacy amplification factor as a function of T and L (contraction factor)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the factor 1/βη in the privacy guarantee be improved for small β values?
- Basis in paper: [explicit] Section 11 discusses potential improvements, noting that the analysis may not be tight for small β > 0
- Why unresolved: The paper suggests the current analysis might not be optimal for small β, but acknowledges the difficulty in finding alternative methods to analyze privacy guarantees for two consecutive noisy ADMM iterations
- What evidence would resolve it: Developing a tighter analysis or alternative framework that provides a better privacy guarantee for small β values would resolve this question

### Open Question 2
- Question: How would analyzing noisy ADMM variants under the Langevin diffusion framework affect privacy guarantees compared to the coupling approach?
- Basis in paper: [explicit] Section 2 mentions that the Langevin diffusion approach offers more flexibility and allows more nuanced analysis for multiple epochs and mini-batches, suggesting it may provide better privacy guarantees than the coupling approach
- Why unresolved: The paper focuses on the coupling approach and does not explore the Langevin diffusion framework for ADMM
- What evidence would resolve it: Conducting a comparative analysis of privacy guarantees for ADMM using both the coupling approach and Langevin diffusion framework would resolve this question

### Open Question 3
- Question: What is the optimal balance between privacy and utility in the context of private ADMM variants?
- Basis in paper: [explicit] Section 9 discusses the trade-off between privacy and utility, providing convergence rates for Algorithm 4, but does not determine an optimal balance
- Why unresolved: The paper provides theoretical analysis of privacy amplification and convergence rates, but does not empirically determine the optimal trade-off between privacy and utility in practice
- What evidence would resolve it: Conducting experiments to empirically determine the optimal balance between privacy and utility for private ADMM variants in various applications would resolve this question

## Limitations

- Analysis relies on specific structure of linear transformation A and convexity/smoothness properties of objective functions
- Privacy amplification guarantees are contingent on assumptions holding true in practice
- Practical applicability of results limited by idealized nature of synthetic experiments

## Confidence

- High confidence in the theoretical framework and mathematical proofs for privacy amplification under the stated assumptions
- Medium confidence in the practical applicability of the results, given the idealized nature of the synthetic experiments
- Medium confidence in the claim that only one gradient access per user is required, as the dual variable communication overhead is not fully characterized

## Next Checks

1. Test the algorithm on real-world datasets to verify the convergence rates and privacy guarantees hold under practical conditions, including non-ideal function properties and communication constraints
2. Conduct ablation studies to quantify the impact of each technical innovation (customized norm, Markov operator composition) on privacy amplification
3. Analyze the communication overhead and compare it with existing gradient-based private ADMM variants to better understand the practical tradeoffs