---
ver: rpa2
title: Minimum Bayes' Risk Decoding for System Combination of Grammatical Error Correction
  Systems
arxiv_id: '2309.06520'
source_url: https://arxiv.org/abs/2309.06520
tags:
- decoding
- systems
- reward
- edit
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Grammatical error correction systems can be combined using Minimum
  Bayes' Risk (MBR) decoding in the edit-space, leading to significant performance
  gains. By defining a novel MBR reward function directly linked to the edit-based
  F-score used for assessment, the combined system can better align with the evaluation
  metric.
---

# Minimum Bayes' Risk Decoding for System Combination of Grammatical Error Correction Systems

## Quick Facts
- arXiv ID: 2309.06520
- Source URL: https://arxiv.org/abs/2309.06520
- Reference count: 21
- Primary result: MBR decoding in edit-space significantly improves F0.5 scores for GEC system combination

## Executive Summary
This paper proposes using Minimum Bayes' Risk (MBR) decoding in the edit-space for combining grammatical error correction (GEC) systems. The key innovation is a novel MBR reward function directly linked to edit-based F-score evaluation metrics. By operating in edit-space rather than raw token sequences, the method can better align system combination with the evaluation criteria used for GEC. Experiments with three state-of-the-art GECToR systems on FCE, BEA-19, and CoNLL-14 datasets demonstrate significant performance improvements over individual systems.

## Method Summary
The method combines GEC system outputs using MBR decoding applied to edit sets rather than raw token sequences. For each input sentence, three GECToR models (bert, roberta, xlnet) produce candidate corrections. These outputs are converted to edit sets relative to the input. The method then uses max-voting to identify consensus edits and applies greedy search to enrich the selection set with additional edits that improve expected MBR reward. The final output is selected by computing expected reward across the enriched candidate set using precision, recall, or F0.5 reward functions.

## Key Results
- MBR decoding with F0.5 reward achieves 59.71 F0.5 score on CoNLL dataset, compared to 56.15-56.82 for individual systems
- Voting combinations (m=2,3) consistently outperform individual systems across all datasets
- MBR decoding with greedy search further improves performance beyond voting-only approaches
- The choice of reward function (precision, recall, F0.5) allows explicit control over the precision-recall trade-off

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MBR decoding in edit-space aligns the system combination with the evaluation metric
- Mechanism: By defining the reward function R directly on edit sets and measuring overlap with reference edits, MBR decoding selects outputs that maximize the expected F0.5 score rather than raw likelihood
- Core assumption: The posterior distribution over outputs from similarly performing systems can be approximated as equiprobable
- Evidence anchors:
  - [abstract] "propose a novel MBR loss function directly linked to this form of criterion"
  - [section 3.1] "we approximate each of these sequences as equiprobable"
  - [corpus] Weak: no direct citation; evidence is theoretical and experimental
- Break condition: If systems have highly disparate performance, the equiprobable assumption fails and the expected reward calculation becomes biased

### Mechanism 2
- Claim: Max-voting enriches the candidate set with high-precision and high-recall combinations
- Mechanism: Edits appearing in at least m of the individual systems' outputs are retained, creating sequences that represent consensus edits (e(m)). These can be added to the MBR selection set Y(s)
- Core assumption: Consensus edits are more likely to be correct and beneficial for final performance
- Evidence anchors:
  - [section 3.2] "can be employed to combine different sets of edits"
  - [table 3] "Voting combination,y(m) (m votes)" shows improved scores over individual systems
  - [corpus] Weak: empirical results only; no theoretical proof of consensus correctness
- Break condition: If the individual systems make correlated errors, max-voting may propagate mistakes into the combined edit set

### Mechanism 3
- Claim: Greedy search over edit space between intersection and union sets finds locally optimal combinations
- Mechanism: Starting from the minimal edit set (intersection), individual edits from the union set are added if they increase the MBR expected reward, creating a richer selection set Y(s) for final decoding
- Core assumption: Sequential addition of edits that improve expected reward will lead to a good combined output
- Evidence anchors:
  - [section 3.3] "efficiently search a richer selection set, Y (s) of output sequences"
  - [table 5] "MBR with greedy search" shows higher CoNLL performance than voting-only MBR
  - [corpus] Weak: performance gains observed but no guarantee of global optimality
- Break condition: If the reward function is poorly aligned with true quality, greedy insertion may select spurious edits

## Foundational Learning

- Concept: Edit-space representation of GEC outputs
  - Why needed here: MBR decoding operates on sets of edits rather than raw token sequences; understanding edit operations (insert, delete, substitute) is essential
  - Quick check question: How do you convert a GEC system's output sequence into an edit set relative to the input?

- Concept: Minimum Bayes Risk decoding framework
  - Why needed here: MBR selects the output minimizing expected risk according to a reward function; the framework is used to align decoding with the F-score evaluation
  - Quick check question: What is the difference between MBR decoding and standard maximum likelihood decoding in terms of the objective?

- Concept: Reward functions and their impact on precision/recall trade-off
  - Why needed here: Different MBR reward functions (precision, recall, F0.5) control the characteristics of the combined system; choosing the right one tunes the final GEC performance
  - Quick check question: How does the F0.5 reward function differ from the F1 reward function in terms of the k parameter?

## Architecture Onboarding

- Component map: Input sequence → GECToR systems (b, r, x) → Edit set extraction → Max-voting (e(1), e(2), e(3)) → Greedy edit insertion → MBR decoding with reward function → Combined output
- Critical path: Edit set extraction → Max-voting → MBR decoding; each stage must preserve edit-level information for the next
- Design tradeoffs: Using edit-space simplifies combination but requires accurate edit extraction; MBR decoding is computationally heavier than simple voting but aligns better with evaluation metrics
- Failure signatures: 
  - Low precision/recall despite MBR: reward function misaligned with true quality
  - No improvement over individual systems: selection set Y(s) too small or reward function too strict
  - Performance drops with greedy search: spurious edits from union set being added
- First 3 experiments:
  1. Run MBR decoding with Y(c)=Y(s)={b,r,x} and R(f05) to confirm basic performance gain
  2. Add max-voting sequences to Y(s) and compare F0.5 scores across m=1,2,3
  3. Implement greedy edit insertion from e(2) to e(3) and measure impact on CoNLL dataset

## Open Questions the Paper Calls Out

The paper does not explicitly call out any open questions.

## Limitations

- The equiprobable posterior assumption across multiple GEC systems is critical but lacks theoretical grounding
- The greedy search procedure for expanding the edit set is described but not fully specified
- Method's dependence on accurate edit extraction from GEC outputs is not discussed
- Experiments use only GECToR-based systems, limiting generalizability to other GEC architectures

## Confidence

- **High confidence**: MBR decoding in edit-space can improve GEC system combination performance when using appropriate reward functions
- **Medium confidence**: The mechanism of aligning MBR decoding with evaluation metrics through custom reward functions works as described
- **Low confidence**: The greedy search procedure reliably finds good edit combinations

## Next Checks

1. Test equiprobable assumption validity: Measure and report performance variance across the three individual GEC systems before applying MBR combination

2. Validate greedy search procedure: Implement and test multiple stopping criteria for greedy edit insertion and compare results

3. Cross-system generalization test: Apply the same MBR combination approach to different GEC systems (e.g., combining NMT-based systems with GECToR) to verify method works beyond the specific systems used