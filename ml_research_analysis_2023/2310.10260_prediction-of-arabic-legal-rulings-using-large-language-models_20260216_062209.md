---
ver: rpa2
title: Prediction of Arabic Legal Rulings using Large Language Models
arxiv_id: '2310.10260'
source_url: https://arxiv.org/abs/2310.10260
tags:
- arabic
- language
- score
- dataset
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a pioneering investigation into predicting
  Arabic court decisions using large language models. The research evaluates three
  models (LLaMA-7b, JAIS-13b, and GPT-3.5-turbo) on a dataset of 10,813 commercial
  court cases.
---

# Prediction of Arabic Legal Rulings using Large Language Models

## Quick Facts
- arXiv ID: 2310.10260
- Source URL: https://arxiv.org/abs/2310.10260
- Reference count: 40
- Key outcome: GPT-3.5 models outperform Arabic-specific models by 50% in predicting Arabic court decisions, but absolute performance remains unsatisfactory with average human scores of 2.4/5

## Executive Summary
This study investigates the use of large language models for predicting Arabic court decisions using a dataset of 10,813 commercial court cases. Three models (LLaMA-7b, JAIS-13b, and GPT-3.5-turbo) were evaluated using zero-shot, one-shot, and fine-tuning paradigms, along with text preprocessing techniques including summarization and translation. GPT-3.5-based models significantly outperformed other models, including the Arabic-centric JAIS model. However, the study found that automated evaluation metrics (GPT, BLEU, ROUGE) were unreliable for this domain, necessitating human evaluation.

## Method Summary
The research collected 10,813 commercial court cases from the Saudi Ministry of Justice, using 10,713 for training and 100 for testing. Three base models were evaluated: LLaMA-7b, JAIS-13b, and GPT-3.5-turbo. Fourteen model variants were created through different combinations of zero/few-shot and fine-tuning approaches, with some incorporating text summarization and/or translation preprocessing. Fine-tuning used the LoRA approach for parameter-efficient adaptation. Models were evaluated using human assessment (0-5 scale), GPT-3.5-turbo evaluation, ROUGE scores (1,2,L), and BLEU scores.

## Key Results
- GPT-3.5 models outperformed all other models by a wide margin, surpassing JAIS by 50%
- Fine-tuning with summarization and translation (LFST model) achieved highest human scores among LLaMA variants
- All automated metrics (GPT, BLEU, ROUGE) showed poor correlation with human evaluation scores
- Absolute performance remained unsatisfactory with average human scores of 2.4 out of 5

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-3.5 models outperform Arabic-centric models because of superior linguistic generalization despite minimal Arabic training data
- Mechanism: The massive scale of pre-training (175B parameters, 300B tokens) allows GPT-3.5 to capture language-agnostic patterns in syntax and semantics, enabling strong zero-shot and few-shot performance even in under-represented languages like Arabic
- Core assumption: Large-scale pre-training on diverse data creates robust cross-lingual transfer capabilities that outweigh the benefits of language-specific tuning
- Evidence anchors:
  - GPT-3.5-based models outperform all other models by a wide margin, surpassing the average score of the dedicated Arabic-centric JAIS model by 50%
  - Arabic language represented 0.03% of GPT3's training dataset by word and character count... JAIS was trained on 395B tokens (116B Arabic tokens)

### Mechanism 2
- Claim: Fine-tuning with LoRA adapters preserves model generalization while adapting to domain-specific patterns
- Mechanism: LoRA decomposes weight updates into low-rank matrices, freezing original parameters and only training adapter matrices, which reduces catastrophic forgetting and maintains the base model's linguistic capabilities
- Core assumption: Domain-specific fine-tuning is effective when applied selectively to a subset of parameters rather than full fine-tuning
- Evidence anchors:
  - LoRA... reduces the number of trainable parameters required for fine-tuning large language models... demonstrates greater resilience against the detrimental impacts of catastrophic forgetting
  - LFST model (fine-tuned with summarization and translation) achieves highest human score among LLaMA variants

### Mechanism 3
- Claim: Text summarization and translation preprocessing improves model performance by reducing input complexity and aligning with pre-training data distribution
- Mechanism: Summarizing reduces token count (preventing model overload) and translation aligns input with English-dominant pre-training, improving comprehension and prediction accuracy
- Core assumption: Reducing input size and matching training data distribution improves model performance more than preserving original linguistic nuance
- Evidence anchors:
  - LFST is obtained by fine-tuning the base model on a subset of 1000 prompt and completion pairs from the Arabic training dataset after summarizing and translating them
  - LFST model delivers top performance across nearly all evaluation metrics
  - GPT-3.5 models were "overwhelmingly pre-trained on English texts"

## Foundational Learning

- Concept: Cross-lingual transfer learning
  - Why needed here: Explains why English-dominant models perform well on Arabic legal text without extensive Arabic training data
  - Quick check question: How does a model trained mostly on English generalize to Arabic legal reasoning?

- Concept: Catastrophic forgetting in fine-tuning
  - Why needed here: Critical for understanding why LoRA adapters are preferred over full fine-tuning in this study
  - Quick check question: What happens to a model's general language capabilities when all parameters are fine-tuned on a narrow domain?

- Concept: Evaluation metric reliability in specialized domains
  - Why needed here: Highlights why BLEU, ROUGE, and even GPT scores fail to capture true performance in legal ruling prediction
  - Quick check question: Why might automated metrics designed for translation/summarization be inappropriate for legal decision evaluation?

## Architecture Onboarding

- Component map: Three base models (LLaMA-7b, JAIS-13b, GPT-3.5-turbo) → 14 variants through zero/few-shot and fine-tuning combinations → preprocessing (summarize/translate) → evaluation with human, GPT, BLEU, ROUGE scores
- Critical path: Model selection → preprocessing decision → training paradigm (zero/few-shot vs fine-tuning) → evaluation → performance analysis
- Design tradeoffs: Using GPT-3.5 for preprocessing adds dependency but significantly improves downstream model performance; LoRA reduces computational cost but limits full adaptation potential
- Failure signatures: Poor human scores with high automated metric scores (metric unreliability); nonsensical outputs on long prompts (context length limitations); model refusal to generate predictions (safety guardrails)
- First 3 experiments:
  1. Run zero-shot predictions on LLaMA-7b and GPT-3.5-turbo with identical prompts to establish baseline performance gap
  2. Apply translation preprocessing to LLaMA-7b and compare performance to original Arabic input
  3. Implement LoRA fine-tuning on a small subset of the Arabic dataset and measure improvement over zero-shot performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Arabic legal ruling prediction models change when trained on a larger and more diverse Arabic legal dataset?
- Basis in paper: The paper states that the absolute performance of the models is unsatisfactory and suggests that better models fine-tuned on larger Arabic legal datasets need to be developed
- Why unresolved: The study used a dataset of 10,813 commercial court cases, which may not be representative of the full diversity of Arabic legal cases
- What evidence would resolve it: Training and evaluating models on a significantly larger and more diverse Arabic legal dataset, then comparing the results to the current study's findings

### Open Question 2
- Question: What are the most effective evaluation metrics for assessing the quality of Arabic legal ruling predictions?
- Basis in paper: The study found that all metrics except human evaluation were unreliable for assessing model performance in this domain
- Why unresolved: The paper highlights the limitations of existing metrics (GPT, BLEU, and ROUGE) but does not propose or test alternative metrics specifically designed for legal text evaluation
- What evidence would resolve it: Developing and validating new evaluation metrics tailored to legal text analysis, then comparing their effectiveness against human evaluation in predicting Arabic legal rulings

### Open Question 3
- Question: How do different prompt engineering techniques affect the performance of large language models in predicting Arabic legal rulings?
- Basis in paper: The paper mentions the use of zero-shot, one-shot, and fine-tuning approaches but does not extensively explore various prompt engineering techniques
- Why unresolved: The study used basic prompt configurations and did not investigate the impact of advanced prompt engineering strategies on model performance
- What evidence would resolve it: Systematically testing various prompt engineering techniques (e.g., chain-of-thought, role-based prompts, or few-shot examples) and measuring their impact on model performance in Arabic legal ruling prediction tasks

## Limitations

- Automated evaluation metrics (GPT, BLEU, ROUGE) show poor correlation with human judgment and are unreliable for legal ruling prediction
- Absolute model performance remains unsatisfactory with average human scores of 2.4/5 despite GPT-3.5's 50% advantage over Arabic models
- Study's findings may not generalize beyond Saudi commercial court domain to other legal domains or Arabic dialects

## Confidence

- High confidence: GPT-3.5 models outperform Arabic-specific models; automated metrics are unreliable for this task; human evaluation is essential
- Medium confidence: LoRA fine-tuning preserves generalization; text preprocessing improves performance; cross-lingual transfer explains English model success
- Low confidence: Exact mechanisms of performance gaps; generalizability across legal domains; optimal preprocessing pipeline configuration

## Next Checks

1. Conduct a controlled experiment comparing LoRA fine-tuning versus full fine-tuning on the same dataset to quantify catastrophic forgetting effects
2. Perform cross-validation across different Arabic legal domains (criminal, family, labor) to test generalizability of findings
3. Develop and validate a task-specific evaluation metric designed for legal ruling prediction rather than relying on translation/summarization metrics