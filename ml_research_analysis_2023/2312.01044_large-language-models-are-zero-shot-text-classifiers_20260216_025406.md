---
ver: rpa2
title: Large Language Models Are Zero-Shot Text Classifiers
arxiv_id: '2312.01044'
source_url: https://arxiv.org/abs/2312.01044
tags:
- text
- classification
- llms
- learning
- zero-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study validates the capability of large language models (LLMs)
  as zero-shot text classifiers, eliminating the need for task-specific training data.
  By leveraging chain-of-thought prompting, LLMs like GPT-4 and Llama2 can directly
  classify text into seen and unseen categories without retraining.
---

# Large Language Models Are Zero-Shot Text Classifiers

## Quick Facts
- arXiv ID: 2312.01044
- Source URL: https://arxiv.org/abs/2312.01044
- Reference count: 40
- Primary result: LLMs can classify text into seen and unseen categories without retraining

## Executive Summary
This study validates the capability of large language models (LLMs) as zero-shot text classifiers, eliminating the need for task-specific training data. By leveraging chain-of-thought prompting, LLMs like GPT-4 and Llama2 can directly classify text into seen and unseen categories without retraining. Across four diverse datasets (COVID-19 tweets, economic texts, e-commerce, and spam detection), LLMs achieved competitive or superior performance compared to traditional ML methods (MNB, RF, DT), deep learning models (RNN, LSTM, GRU), and zero-shot transformer models (BART, DeBERTa). Notably, GPT-4 and Llama2 outperformed all other methods in economic text classification, while deep learning models excelled in e-commerce and spam detection. The approach is particularly advantageous for small businesses or teams without extensive NLP expertise, enabling rapid deployment of text classifiers.

## Method Summary
The study uses chain-of-thought prompting (CoT) to enable large language models to perform zero-shot text classification. Four datasets were used: COVID-19 tweets, economic texts, e-commerce, and spam detection. LLMs (GPT-4, Llama2, GPT-3.5) were compared against traditional ML models (MNB, RF, DT), deep learning models (RNN, LSTM, GRU), and zero-shot transformer models (BART, DeBERTa). The approach bypasses traditional feature extraction and training by directing LLMs to produce classification results in JSON format using structured prompts.

## Key Results
- GPT-4 and Llama2 outperformed all other methods in economic text classification
- Deep learning models excelled in e-commerce and spam detection tasks
- LLMs achieved competitive or superior performance across all four datasets compared to traditional ML, DL, and ZSL transformer models
- The zero-shot approach eliminates need for task-specific training data and manual feature engineering

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Zero-shot text classification with LLMs works because the models leverage pre-trained knowledge to interpret prompts and generate correct labels without task-specific fine-tuning.
- Mechanism: The LLM receives a structured prompt (e.g., "Let's think step by step") that guides reasoning and then directly outputs classification labels in a predefined format such as JSON.
- Core assumption: The pre-trained LLM already encodes semantic relationships between words and categories from its training corpus, allowing it to generalize to unseen classes.
- Evidence anchors:
  - [abstract] "With the proposal of chain of thought prompting (CoT), LLMs can be implemented using zero-shot learning (ZSL) with the step-by-step reasoning prompts..."
  - [section] "By adding a simple prompt 'Let's think step by step' before answers, the study shows that LLMs can significantly outperform standard zero-shot methods..."
  - [corpus] Weak: Related papers focus on general text classification improvements but don't directly confirm CoT prompting effectiveness for zero-shot classification.
- Break condition: If the prompt format does not align with the model's training data patterns, the reasoning step may fail, leading to incorrect or incoherent outputs.

### Mechanism 2
- Claim: Performance gains over traditional ML and DL methods arise from eliminating the need for manual feature extraction and classifier training.
- Mechanism: The LLM bypasses intermediate steps like TF-IDF or word embeddings, directly mapping raw text to category labels using its internal representations.
- Core assumption: The internal representations learned during pre-training are sufficiently rich to capture task-relevant features without explicit feature engineering.
- Evidence anchors:
  - [abstract] "LLMs achieved competitive or superior performance compared to traditional ML methods... and deep learning models..."
  - [section] "This method efficiently utilizes the natural language processing and generative capabilities of GPT models. By directing the model to produce classification results in a specific format, it simplifies the classification process and eliminates the need for intermediate steps..."
  - [corpus] Weak: Related papers validate LLM performance but don't detail the internal feature representation process.
- Break condition: If the task requires domain-specific knowledge not present in the pre-training data, the model's internal representations may be insufficient.

### Mechanism 3
- Claim: Chain-of-thought prompting improves zero-shot classification by encouraging step-by-step reasoning rather than direct answer generation.
- Mechanism: The model first "thinks" through the reasoning process, which structures the internal computation before producing the final label.
- Core assumption: Step-by-step reasoning leads to more accurate mapping from input text to output category than single-step inference.
- Evidence anchors:
  - [abstract] "By adding a simple prompt 'Let's think step by step' before answers, the study shows that LLMs can significantly outperform standard zero-shot methods..."
  - [section] "Zero-shot-CoT, a new approach was introduced... that significantly enhanced zero-shot performance of LLMs in various reasoning tasks..."
  - [corpus] Weak: While CoT is shown to improve reasoning tasks, direct evidence for classification is less explicit in related works.
- Break condition: If the task is straightforward and does not require reasoning, CoT may add unnecessary complexity and slow inference without accuracy gains.

## Foundational Learning

- Concept: Zero-shot learning
  - Why needed here: The paper's core contribution is showing that LLMs can classify text into categories they were not explicitly trained on.
  - Quick check question: What distinguishes zero-shot from few-shot learning in the context of LLMs?

- Concept: Chain-of-thought prompting
  - Why needed here: CoT is the prompting strategy that enables LLMs to perform better in zero-shot classification tasks.
  - Quick check question: How does adding "Let's think step by step" before an answer change the model's output compared to a direct prompt?

- Concept: Text preprocessing and feature extraction
  - Why needed here: Understanding traditional ML/DL pipelines helps explain why the LLM approach is advantageous by comparison.
  - Quick check question: What are the three key stages in a traditional text classification pipeline before classification?

## Architecture Onboarding

- Component map: Raw text -> CoT prompt -> LLM inference -> JSON parsing -> Evaluation metrics
- Critical path: Raw text → CoT prompt → LLM output → JSON parsing → Accuracy calculation
- Design tradeoffs: Speed vs accuracy (temperature=0.01, top_p=0.9) vs more diverse outputs
- Failure signatures: Unstructured or irrelevant outputs; JSON parsing errors; temperature-induced randomness
- First 3 experiments:
  1. Test with a simple prompt without CoT on a small labeled dataset to establish baseline accuracy.
  2. Introduce CoT prompting and measure accuracy improvement over baseline.
  3. Compare performance with traditional ML models using the same dataset to validate superiority.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different zero-shot prompting strategies affect the performance of LLMs in text classification tasks, and which strategy is most effective?
- Basis in paper: [explicit] The paper discusses the use of chain-of-thought prompting (CoT) to enhance the zero-shot performance of LLMs in various reasoning tasks, but does not explore other prompting strategies.
- Why unresolved: The paper focuses on a single prompting strategy (CoT) and does not compare its effectiveness against other prompting methods, such as few-shot learning or different CoT variations.
- What evidence would resolve it: Conduct experiments comparing the performance of LLMs using various prompting strategies, including CoT, few-shot learning, and other novel approaches, across multiple text classification tasks.

### Open Question 2
- Question: How does the performance of LLMs in zero-shot text classification tasks vary across different languages and domains?
- Basis in paper: [inferred] The paper evaluates LLMs on English datasets across sentiment analysis, e-commerce, and spam detection, but does not explore their performance in other languages or specialized domains.
- Why unresolved: The study is limited to English-language datasets and does not address the generalizability of LLMs to other languages or niche domains, such as legal or medical text.
- What evidence would resolve it: Test LLMs on multilingual datasets and domain-specific corpora to assess their zero-shot classification accuracy and robustness in diverse linguistic and contextual settings.

### Open Question 3
- Question: What are the computational trade-offs of using LLMs for zero-shot text classification compared to traditional and deep learning methods?
- Basis in paper: [explicit] The paper highlights that LLMs can save computational costs and time by eliminating the need for data preprocessing and feature extraction, but does not quantify the overall computational efficiency.
- Why unresolved: The study does not provide a detailed comparison of the computational resources (e.g., time, memory, energy) required by LLMs versus traditional ML and DL models for zero-shot text classification.
- What evidence would resolve it: Perform a comprehensive analysis of the computational costs (e.g., inference time, memory usage, energy consumption) of LLMs and traditional methods across various text classification tasks and dataset sizes.

## Limitations
- The prompt templates used for each dataset are not explicitly detailed, affecting reproducibility
- The approach may not generalize well to domains requiring specialized knowledge not present in pre-training data
- Computational cost of using LLMs may be prohibitive for real-time applications

## Confidence
- High Confidence: The claim that LLMs can perform zero-shot text classification is well-supported by experimental results
- Medium Confidence: The effectiveness of CoT prompting in improving zero-shot classification accuracy is supported but may vary by task
- Low Confidence: The generalizability of the approach to other domains and long-term viability remain uncertain

## Next Checks
1. Test the robustness of the approach by experimenting with different prompt templates and structures
2. Evaluate the model's performance on datasets from different domains not included in the original study
3. Measure the computational cost of using LLMs for text classification compared to traditional methods