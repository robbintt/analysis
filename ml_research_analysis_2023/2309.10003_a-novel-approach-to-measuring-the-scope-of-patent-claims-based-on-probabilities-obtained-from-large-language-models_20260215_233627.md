---
ver: rpa2
title: A novel approach to measuring the scope of patent claims based on probabilities
  obtained from (large) language models
arxiv_id: '2309.10003'
source_url: https://arxiv.org/abs/2309.10003
tags:
- claim
- wherein
- sensor
- claims
- optical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes measuring patent claim scope using self-information
  from language models. Claim scope is defined as the reciprocal of self-information,
  which depends on the probability of occurrence of the claim, where the probability
  is obtained using language models.
---

# A novel approach to measuring the scope of patent claims based on probabilities obtained from (large) language models

## Quick Facts
- arXiv ID: 2309.10003
- Source URL: https://arxiv.org/abs/2309.10003
- Reference count: 30
- Key outcome: The paper proposes measuring patent claim scope using self-information from language models. Claim scope is defined as the reciprocal of self-information, which depends on the probability of occurrence of the claim, where the probability is obtained using language models. GPT2 outperforms other models, followed by word and character frequencies, then word and character counts.

## Executive Summary
This paper introduces a novel method for quantifying the scope of patent claims by leveraging language model probabilities and information theory. The approach defines claim scope as the reciprocal of self-information, calculated from the probability of a claim occurring as estimated by various language models. The method is validated using nine series of patent claims across different technical fields, demonstrating that more sophisticated language models like GPT2 provide better discrimination between claims of different scope compared to simpler frequency-based or count-based models.

## Method Summary
The method quantifies patent claim scope by defining it as the reciprocal of self-information, where self-information is the negative logarithm of the claim's probability. This probability is computed using five different models: GPT2 (a sophisticated language model), word frequency distributions, character frequency distributions, word count, and character count. The probability of a claim is calculated as the product of token (word or character) probabilities, with GPT2 providing conditional probabilities based on previous tokens. The resulting scope values are normalized between 0 and 1 using scaling factors based on maximum word and character counts.

## Key Results
- GPT2 outperforms simpler models like word frequencies, character frequencies, word counts, and character counts in discriminating between claims of different scope
- More sophisticated language models produce lower standard deviations in scope values, indicating better discrimination
- The approach successfully captures hierarchical relationships in patent terminology (e.g., "vehicle" as a broader term than "car")
- The method encompasses previous approaches based on word or character counts while being extensible to any language model

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The scope of a patent claim can be quantified as the reciprocal of its self-information, which is derived from the probability of occurrence of the claim using a language model.
- Mechanism: Self-information is calculated as the negative logarithm of the probability of a claim, and the scope is defined as the reciprocal of this self-information. This approach leverages information theory to quantify the "surprise" or informativeness of a claim, with rarer claims being more informative and thus having a narrower scope.
- Core assumption: The probability of a claim can be accurately estimated using a language model, and this probability is inversely related to the claim's scope.
- Evidence anchors:
  - [abstract] "The present work proposes to measure the scope of a patent claim as the reciprocal of the self-information contained in this claim."
  - [section 3.1] "Eventually, the scope ð‘†(ð¶) of a claim can be defined as the reciprocal of the self-information ð¼(ð¶), whereby ð‘†(ð¶) = 1 ð¼(ð¶)â„ = âˆ’ 1 log(ð‘(ð¶))â„ = 1 log(1 ð‘(ð¶)â„ )â„ ."
  - [corpus] Weak evidence: The corpus neighbors focus on patent claim generation and evaluation using LLMs, but do not directly address the use of self-information for scope quantification.
- Break condition: The language model fails to accurately estimate the probability of the claim, or the claim's probability is not inversely related to its scope.

### Mechanism 2
- Claim: The probability of a claim can be estimated using various language models, ranging from simple uniform distributions to sophisticated large language models (LLMs) like GPT2.
- Mechanism: The probability of a claim is calculated as a product of probability terms, where each term represents the probability of a token (e.g., word or character) in the claim. The probability terms are derived from the language model, with more sophisticated models capturing the context and semantics of the claim.
- Core assumption: The probability of a claim can be decomposed into a product of token probabilities, and this decomposition is valid for different types of language models.
- Evidence anchors:
  - [abstract] "The self-information is calculated from the probability of occurrence of that claim, where the probability is calculated in accordance with a language model."
  - [section 3.2.1] "Assume for now that the probability of a patent claim can be computed from a language model. In principle, the scope of this claim may be computed as the reciprocal of that probability."
  - [corpus] Weak evidence: The corpus neighbors discuss the use of LLMs for patent claim generation and evaluation, but do not specifically address the decomposition of claim probability into token probabilities.
- Break condition: The claim probability cannot be accurately decomposed into token probabilities, or the language model fails to capture the context and semantics of the claim.

### Mechanism 3
- Claim: The more sophisticated the language model, the better the results in quantifying the scope of patent claims.
- Mechanism: The quality of the scope quantification improves with the sophistication of the language model because more advanced models can better capture the context, semantics, and informativeness of the claim.
- Core assumption: The language model's ability to capture the context and semantics of the claim is directly related to its sophistication, and this ability is crucial for accurate scope quantification.
- Evidence anchors:
  - [abstract] "The more sophisticated the language model, the better the results."
  - [section 4.2] "In general, the more sophisticated the model, the lower the reduced standard deviation."
  - [corpus] Weak evidence: The corpus neighbors focus on the use of LLMs for patent claim generation and evaluation, but do not directly compare the performance of different language models in scope quantification.
- Break condition: The sophistication of the language model does not correlate with its ability to capture the context and semantics of the claim, or the scope quantification does not improve with model sophistication.

## Foundational Learning

- Concept: Information Theory and Self-Information
  - Why needed here: Understanding information theory and self-information is crucial for grasping the proposed approach to quantifying patent claim scope.
  - Quick check question: How is self-information defined in information theory, and how does it relate to the probability of an event?

- Concept: Language Models and Probability Estimation
  - Why needed here: Familiarity with language models and their ability to estimate probabilities is essential for understanding how the claim scope is quantified.
  - Quick check question: What are the different types of language models that can be used to estimate the probability of a patent claim, and how do they differ in terms of sophistication?

- Concept: Patent Claims and Their Structure
  - Why needed here: Knowledge of patent claims and their structure is necessary for understanding the context and significance of the proposed approach.
  - Quick check question: What are the key elements of a patent claim, and how do they contribute to defining the scope of protection for an invention?

## Architecture Onboarding

- Component map: Input patent claim text -> Preprocessing (normalization) -> Language Model (GPT2, word frequencies, etc.) -> Probability Calculation (token probability product) -> Self-Information Calculation (negative log probability) -> Scope Calculation (reciprocal of self-information) -> Output scope value

- Critical path:
  1. Preprocess the input patent claim text.
  2. Select and apply the desired language model.
  3. Calculate the probability of the claim using the language model.
  4. Compute the self-information of the claim.
  5. Derive the scope of the claim as the reciprocal of the self-information.

- Design tradeoffs:
  - Model sophistication vs. computational complexity: More sophisticated models may provide better results but require more computational resources.
  - Token granularity: Using words, characters, or subwords as tokens can impact the granularity and accuracy of the probability estimation.
  - Context consideration: Models that consider the context of the claim (e.g., GPT2) may provide more accurate results but may also be more sensitive to claim structure.

- Failure signatures:
  - Inaccurate scope quantification: This may indicate issues with the language model's probability estimation or the claim's structure.
  - High variability in scope values: This may suggest sensitivity to claim wording or limitations in the language model's ability to capture context.
  - Inconsistent results across different language models: This may indicate issues with the claim probability decomposition or the models' ability to handle complex claim structures.

- First 3 experiments:
  1. Compare the scope values obtained from different language models (e.g., GPT2, word frequencies, character frequencies) for a set of patent claims.
  2. Analyze the impact of claim structure (e.g., word count, character count) on the scope quantification results.
  3. Evaluate the performance of the proposed approach in handling claims with complex structures (e.g., disclaimers, alternatives) compared to simpler claims.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the proposed claim scope measure change if forward-dependency context was included in language models like GPT2?
- Basis in paper: [explicit] The paper notes that GPT2 only considers backward dependency (previous tokens) and suggests testing models that include forward dependency like BERT.
- Why unresolved: The paper doesn't test models with forward dependency context, so the impact on scope calculations is unknown.
- What evidence would resolve it: Testing the proposed scope measure using language models that include forward dependency context and comparing results to GPT2-based calculations.

### Open Question 2
- Question: Would normalizing patent claim language across different jurisdictions improve the reliability of cross-jurisdictional scope comparisons?
- Basis in paper: [explicit] The paper mentions that US and European claims differ significantly and suggests that normalization could address this issue.
- Why unresolved: The paper doesn't implement or test claim normalization, so its impact on scope measure reliability is unknown.
- What evidence would resolve it: Implementing claim normalization across jurisdictions and comparing scope measures before and after normalization.

### Open Question 3
- Question: How would training language models specifically on patent claim language affect scope measure accuracy compared to general language models?
- Basis in paper: [explicit] The paper suggests that models trained specifically on patent claim language could improve results.
- Why unresolved: The paper uses general language models (GPT2) rather than patent-specific ones, so the potential improvement is unknown.
- What evidence would resolve it: Training language models on patent claim datasets and comparing scope measure accuracy to general language models.

## Limitations

- Limited dataset: The approach is validated on only nine series of patent claims, raising questions about generalizability across diverse technical domains.
- Cross-jurisdictional differences: The paper acknowledges that US and European patent claims differ significantly, which may affect the reliability of cross-jurisdictional scope comparisons.
- Computational cost: Using sophisticated language models like GPT2 for large-scale patent analysis may be computationally prohibitive.

## Confidence

- High: Mathematical framework and information theory foundation
- Medium: Language model comparison methodology and results
- Medium: Scope calculation and normalization procedures
- Low: Real-world validation against patent examiner assessments

## Next Checks

1. **Cross-Domain Validation**: Test the proposed scope measurement approach on patent claims from diverse technical fields (e.g., biotechnology, software, mechanical engineering) to assess whether GPT2's superiority holds across different domains and whether certain fields exhibit unique challenges for scope quantification.

2. **Correlation with Examiner Assessments**: Compare the automatically computed scope values with human patent examiner assessments of claim breadth. This would involve selecting a sample of patent applications, obtaining examiner interviews or prosecution histories, and statistically analyzing the correlation between LLM-derived scope values and examiner-determined claim scope.

3. **Impact of Preprocessing Choices**: Systematically evaluate how different preprocessing steps (case normalization, removal of articles, handling of technical terms, treatment of dependent claims) affect the final scope calculations. This would help identify which preprocessing decisions are critical for maintaining accuracy and which can be simplified to reduce computational overhead.