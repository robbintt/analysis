---
ver: rpa2
title: A New Baseline Assumption of Integated Gradients Based on Shaply value
arxiv_id: '2310.04821'
source_url: https://arxiv.org/abs/2310.04821
tags:
- shapley
- value
- baseline
- values
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of selecting appropriate baselines
  in Integrated Gradients (IG) attribution methods, which is crucial for generating
  meaningful explanations of deep neural network predictions. The authors propose
  Shapley Integrated Gradients (SIG), a novel baseline construction method that leverages
  the connection between IG and Shapley Value.
---

# A New Baseline Assumption of Integated Gradients Based on Shaply value

## Quick Facts
- arXiv ID: 2310.04821
- Source URL: https://arxiv.org/abs/2310.04821
- Authors: 
- Reference count: 12
- The paper proposes Shapley Integrated Gradients (SIG), a novel baseline construction method that leverages the connection between Integrated Gradients and Shapley Value to improve feature contribution estimation in deep neural networks.

## Executive Summary
This paper addresses the challenge of selecting appropriate baselines in Integrated Gradients (IG) attribution methods, which is crucial for generating meaningful explanations of deep neural network predictions. The authors propose Shapley Integrated Gradients (SIG), a novel baseline construction method that leverages the connection between IG and Shapley Value. SIG uses proportional sampling to approximate the computation path of Shapley Value, aiming to improve feature contribution estimation compared to traditional IG baseline methods. The key outcomes demonstrate that SIG effectively approximates Shapley Values in controlled environments and outperforms traditional IG baseline methods in image processing tasks, offering more precise estimates of feature contributions with consistent explanations across diverse applications and negligible additional computational overhead.

## Method Summary
The method introduces Shapley Integrated Gradients (SIG), which constructs baselines by sampling coalitions of features proportional to their Shapley weights. Instead of evaluating all 2^n coalitions, SIG samples coalitions with probability proportional to their theoretical weights w(k) = |S|!(|N|-|S|-1)!/|N|!, then applies uniform weighting to the sampled marginal contributions. This creates an unbiased estimator of the true Shapley Value. For image data, the method treats patches of pixels as single players to reduce computational complexity while maintaining feature-level attribution quality. The approach bridges the gap between IG's straight-line path and Shapley Value's coalition evaluation by sampling coalitions that represent intermediate states along the Shapley Value computation path.

## Key Results
- In GridWorld simulations, SIG effectively approximates the proportion of Shapley Values, demonstrating its ability to simulate Shapley Value computation.
- In image processing tasks, SIG outperforms traditional IG baseline methods, offering more precise estimates of feature contributions.
- SIG provides consistent explanations across diverse applications and ensures adaptability to various data types with negligible additional computational overhead.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SIG approximates Shapley Values by sampling coalitions proportionally to their theoretical weights.
- Mechanism: Instead of evaluating all 2^n coalitions, SIG samples coalitions with probability proportional to their Shapley weight w(k) = |S|!(|N|-|S|-1)!/|N|!, then applies uniform weighting to the sampled marginal contributions. This creates an unbiased estimator of the true Shapley Value.
- Core assumption: The weighted average of marginal contributions from proportional sampling converges to the true Shapley Value as sample size increases.
- Evidence anchors:
  - [abstract]: "SIG uses proportional sampling to mirror the Shapley Value computation process"
  - [section]: "We leverage a 'trick' called proportional sampling... instead of sampling coalitions from a binomial distribution and weight them by their corresponding wi(S), an alternative approach is to sample coalitions proportional to the precomputed wi(k) and weight them uniformly by 1"
- Break condition: When the number of samples is too small relative to the number of features, leading to high variance in the estimate.

### Mechanism 2
- Claim: Treating patches of pixels as single players reduces computational complexity while maintaining feature-level attribution quality.
- Mechanism: By grouping M×N pixels into a single player, the number of features in the attribution problem is reduced from the total pixel count to the number of patches. IG is then applied to estimate marginal contributions of these composite players.
- Core assumption: The contribution of a patch to the model prediction can be approximated by treating the patch as a single feature.
- Evidence anchors:
  - [section]: "We treat a patch of pixels as a new player to construct baseline sets" and "Direct computation for each pixel is nearly unfeasible. To simplify the process, we consider an area of M × N pixels as a single player"
- Break condition: When the patch size is too large, losing important spatial information; or too small, failing to achieve computational benefits.

### Mechanism 3
- Claim: The computation path of IG approximates the path of Shapley Value but takes a shortcut.
- Mechanism: IG computes feature attributions by integrating gradients along a straight line from baseline to input, while Shapley Value requires evaluating all possible coalitions. SIG bridges this gap by sampling coalitions that represent intermediate states along the Shapley Value computation path.
- Core assumption: The straight-line path in IG is a reasonable approximation of the Shapley Value computation path for many practical applications.
- Evidence anchors:
  - [abstract]: "Leveraging the natural link between IG and the Aumann-Shapley Value, we provide a novel outlook on baseline design"
  - [section]: "IG accumulates the contribution of each feature by integrating the partial derivatives of model F with respect to the feature at points along a straight-line path... the integral of IG approaches the integral of Shapley Value but though a different computation path"
- Break condition: When the model's behavior is highly non-linear along the straight-line path, making the shortcut approximation inaccurate.

## Foundational Learning

- Concept: Shapley Value computation and marginal contributions
  - Why needed here: Understanding how SIG samples coalitions and computes marginal contributions requires knowledge of the Shapley Value framework
  - Quick check question: What is the formula for the Shapley Value of player i in a game with n players?

- Concept: Integrated Gradients and path attribution methods
  - Why needed here: SIG builds on IG by modifying how baselines are constructed; understanding IG's mechanism is essential
  - Quick check question: How does Integrated Gradients compute feature attributions differently from simple gradient-based methods?

- Concept: Coalition sampling and probability distributions
  - Why needed here: SIG's proportional sampling strategy relies on understanding how to sample from distributions based on coalition weights
  - Quick check question: If you have n features and want to sample coalitions with probability proportional to their size, what probability distribution should you use?

## Architecture Onboarding

- Component map: Coalition sampling module -> Baseline construction module -> IG computation module -> Aggregation module
- Critical path:
  1. Sample coalitions based on precomputed weights w(k)
  2. Construct baseline inputs from sampled coalitions
  3. Compute IG attributions for each baseline in parallel
  4. Average the results to obtain final Shapley Value approximations

- Design tradeoffs:
  - Sampling size vs. accuracy: Larger sample sizes provide better approximation but increase computational cost
  - Patch size vs. granularity: Larger patches reduce computation but may lose important spatial details
  - Number of features vs. interpretability: More features provide finer-grained attribution but are harder to interpret

- Failure signatures:
  - High variance in results across different runs indicates insufficient sampling
  - Attributions focusing on irrelevant regions suggests incorrect baseline construction
  - Computational bottlenecks when processing large numbers of baselines

- First 3 experiments:
  1. GridWorld validation: Verify SIG accurately approximates known Shapley Values in a simple environment with few features
  2. Patch size sensitivity: Test how different patch sizes (M×N) affect attribution quality on a small image dataset
  3. Baseline comparison: Compare SIG against random, zero, and mean baselines on a simple image classification task using a pretrained model

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical limit of approximation accuracy for SIG compared to exact Shapley Value computation, and how does this vary with different network architectures?
- Basis in paper: [inferred] The paper states that SIG approximates Shapley Value but acknowledges discrepancies between SIG and exact Shapley Value computation. It mentions two sources of discrepancies but does not quantify the theoretical limit of approximation accuracy.
- Why unresolved: The paper provides empirical evidence of SIG's performance but does not establish a theoretical bound on approximation error or analyze how network architecture affects this bound.
- What evidence would resolve it: Formal theoretical analysis proving approximation bounds for SIG, along with empirical validation across different network architectures showing how these bounds hold in practice.

### Open Question 2
- Question: How does the choice of baseline construction method affect the stability and consistency of explanations across different model training runs with different random seeds?
- Basis in paper: [explicit] The paper mentions that SIG offers "consistent explanations across different applications" but does not investigate how explanations vary across different training runs of the same model architecture.
- Why unresolved: The experiments use fixed trained models but do not address whether the baseline choice affects explanation consistency when the same model architecture is trained multiple times with different random seeds.
- What evidence would resolve it: Systematic experiments comparing explanation stability across multiple training runs for each baseline method, measuring variance in attributions for the same inputs.

### Open Question 3
- Question: What is the relationship between the sampling proportion Q and the computational efficiency of SIG, and is there an optimal trade-off point?
- Basis in paper: [explicit] The paper mentions that Q represents "the ratio of sampled coalitions to all coalitions" and shows SIG's robustness to hyperparameter Q, but does not analyze the computational efficiency trade-off.
- Why unresolved: While the paper demonstrates SIG's robustness to Q, it does not provide a systematic analysis of how Q affects computational cost versus approximation quality, nor does it identify optimal values for different scenarios.
- What evidence would resolve it: Detailed analysis showing the relationship between Q, computational time, and approximation accuracy, potentially identifying optimal Q values for different problem sizes and computational constraints.

## Limitations
- The paper lacks ablation studies on the proportional sampling mechanism, which is central to SIG's theoretical foundation.
- The patch-based approximation for image data introduces an engineering assumption without rigorous justification.
- The GridWorld experiments use synthetic data with known Shapley Values, but the connection between these controlled environments and real-world model behavior remains unclear.

## Confidence
- High confidence: SIG provides a novel baseline construction method that outperforms traditional baselines
- Medium confidence: The proportional sampling mechanism accurately approximates Shapley Values
- Medium confidence: Patch-based feature grouping maintains attribution quality

## Next Checks
1. **Sampling Size Sensitivity**: Conduct experiments varying the number of sampled coalitions (Q) to empirically demonstrate how SIG's approximation quality improves with larger sample sizes and establish guidelines for selecting Q.
2. **Patch Size Ablation**: Systematically vary patch sizes (M×N) on image datasets to quantify the trade-off between computational efficiency and attribution accuracy, identifying when the patch approximation fails.
3. **Real-World Generalization**: Apply SIG to explain predictions from diverse real-world models (beyond ImageNet classification) to validate whether the theoretical advantages translate to practical improvements in explanation quality across different domains.