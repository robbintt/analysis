---
ver: rpa2
title: 'Towards the Better Ranking Consistency: A Multi-task Learning Framework for
  Early Stage Ads Ranking'
arxiv_id: '2307.11096'
source_url: https://arxiv.org/abs/2307.11096
tags:
- stage
- ranking
- early
- quality
- final
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'We propose a multi-task learning framework to improve early stage
  ads ranking, with two major contributions: 1) We propose a consolidated quality
  score to capture all ads quality events together, which solves the total value definition
  inconsistency between early and final stage. 2) We leverage data augmentation and
  distillation teacher task to mitigate selection bias and improve ranking consistency.'
---

# Towards the Better Ranking Consistency: A Multi-task Learning Framework for Early Stage Ads Ranking

## Quick Facts
- arXiv ID: 2307.11096
- Source URL: https://arxiv.org/abs/2307.11096
- Reference count: 23
- Primary result: Multi-task learning framework improves early-stage ads ranking consistency and performance in large-scale industrial system.

## Executive Summary
This paper addresses the challenge of improving early-stage ads ranking consistency in multi-stage advertising systems. The authors propose a multi-task learning framework that consolidates quality events into a single objective and leverages data augmentation with teacher distillation to mitigate selection bias. Through online A/B testing, the framework demonstrates significant improvements in click-through rate, conversion rate, total value, and ad quality metrics compared to traditional single-task approaches.

## Method Summary
The framework implements a multi-task learning architecture based on a Deep Learning Recommendation Model (DLRM) with shared user and ad towers. It introduces three key components: a consolidated quality score (CQS) task that aggregates multiple quality events weighted by auction multipliers, a teacher distillation task that uses final-stage CTR predictions to improve early-stage CTR calibration, and a data augmentation technique that incorporates non-impression ads with pseudo-labels derived from final-stage predictions. The model is trained using weighted loss balancing between CTR prediction, CQS calculation, and distillation objectives.

## Key Results
- Online A/B testing shows significantly higher click-through rate (CTR) and conversion rate (CVR)
- Total value improves through better ranking consistency and reduced ads cross-out rate
- Better ads-quality metrics achieved with improved recall of high-value advertisements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Consolidating all final-stage quality events into a single Consolidated Quality Score (CQS) objective solves the total value definition inconsistency between early and final stages.
- Mechanism: The CQS aggregates predictions of multiple quality events weighted by their auction multipliers, mirroring the final-stage ads quality calculation. This allows early-stage models to optimize directly toward the same total value metric used in final-stage ranking and auction.
- Core assumption: The final-stage quality model's input (CQS) can be computed and logged during early-stage serving without requiring all individual quality event models to be deployed.
- Evidence anchors:
  - [abstract] "We propose a consolidated quality score to capture all ads quality events together, which solves the total value definition inconsistency between early and final stage."
  - [section] "With the final stage CQS as the label, we not only unblock the quality data logging, but also solve the total value definition inconsistency issue in early stage ranking."
  - [corpus] Weak/no direct evidence in related papers about consolidated quality score formulation.
- Break condition: If quality event definitions or weights change frequently, the early-stage CQS may lag behind final-stage quality calculations, reintroducing inconsistency.

### Mechanism 2
- Claim: Adding a teacher distillation task using final-stage CTR predictions improves early-stage CTR calibration and ranking consistency.
- Mechanism: The distillation task trains the early-stage CTR head to mimic the final-stage CTR model's outputs, transferring the higher accuracy and better feature representation learned by the more complex final-stage model.
- Core assumption: The final-stage CTR model's predictions are more accurate and generalize better than the early-stage model's, making them useful pseudo-labels for training.
- Evidence anchors:
  - [abstract] "We leverage data augmentation and distillation teacher task to mitigate selection bias and improve ranking consistency."
  - [section] "Using the final stage CTR model as the distillation teacher can improve the ranking consistency since the early stage learns the final stage prediction information directly."
  - [corpus] Related paper on "Confidence Ranking for CTR Prediction" suggests using teacher models for calibration, but no explicit distillation task described.
- Break condition: If the final-stage model becomes too complex or overfits to its own data distribution, its predictions may not be suitable as training targets for the early-stage model.

### Mechanism 3
- Claim: Data augmentation with non-impression ads and pseudo-labels mitigates selection bias and improves recall for early-stage ranking.
- Mechanism: By logging non-impression ads and using the final-stage CTR prediction as a pseudo-label, the early-stage model learns to rank ads it would never have seen in training, reducing the distribution mismatch between training and inference.
- Core assumption: The final-stage CTR prediction for non-impression ads is a reasonable proxy for the true CTR, enabling effective training despite missing ground truth clicks.
- Evidence anchors:
  - [abstract] "We leverage data augmentation and distillation teacher task to mitigate selection bias and improve ranking consistency."
  - [section] "During the online training, we have developed data augmentation framework to logging specific model's prediction in the non-impression data."
  - [corpus] No direct evidence in related papers about data augmentation for non-impression ads in early-stage ranking.
- Break condition: If the pseudo-labels are systematically biased or noisy, the augmented data could degrade model performance rather than improve it.

## Foundational Learning

- Concept: Multi-stage ranking system architecture
  - Why needed here: Understanding how retrieval, early-stage, and final-stage ranking interact is essential to grasp why ranking consistency matters and how early-stage models can improve downstream performance.
  - Quick check question: What is the main purpose of the early-stage ranking system in a multi-stage ranking pipeline?

- Concept: Multi-task learning and negative transfer
  - Why needed here: The paper combines CTR and CQS tasks in one model, and tuning task weights is critical to avoid performance degradation due to negative transfer between unrelated objectives.
  - Quick check question: Why might training a model on both CTR and CQS tasks harm CTR performance if not properly balanced?

- Concept: Selection bias and debiasing techniques
  - Why needed here: Early-stage models are trained on logged impressions, but must rank all candidates at serving time. Understanding how pseudo-labels and data augmentation address this gap is key to the proposed improvements.
  - Quick check question: What is the main source of selection bias in early-stage ad ranking models?

## Architecture Onboarding

- Component map:
  - Retrieval stage: Rule-based or simple model to filter large ad inventory.
  - Early-stage ranking: Multi-task DLRM model with shared user/ad towers and dedicated heads for CTR, CQS, and teacher distillation.
  - Final-stage ranking: Complex model producing final CTR predictions and multiple quality scores for auction.
  - Auction system: Uses total value (bid × CTR × quality) to select winning ads.
  - Data logging pipeline: Captures CQS, CTR labels, and final-stage predictions for training.

- Critical path:
  1. Retrieve candidate ads from inventory.
  2. Early-stage model predicts CTR, CQS, and learns from teacher.
  3. Top candidates passed to final-stage ranking.
  4. Final-stage model produces refined CTR and quality scores.
  5. Auction selects winning ads based on total value.

- Design tradeoffs:
  - Model complexity vs. serving latency: Early-stage model must be lightweight, limiting architecture choices (DLR-based two-tower).
  - Feature availability vs. consistency: Early-stage has fewer features than final-stage, so distillation helps bridge the gap.
  - Task interference vs. consolidation: Combining CTR and CQS tasks saves serving cost but risks negative transfer; careful loss weighting is required.

- Failure signatures:
  - CTR performance drops after adding CQS task (negative transfer).
  - Online CTR and CVR improve but recall does not (teacher distillation not effective).
  - Early-stage ads quality metrics worsen after deployment (CQS label distribution shift).

- First 3 experiments:
  1. Compare early-stage CTR model with and without CQS task using offline NE/MSE and online CTR/CVR.
  2. Test teacher distillation impact by training with and without final-stage CTR as distillation target.
  3. Measure recall improvement from data augmentation by training with and without non-impression pseudo-labels.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the CQS objective perform in cases where ads quality events are highly correlated or when new quality events are introduced?
- Basis in paper: [explicit] The paper mentions that the CQS consolidates all final stage ads quality objectives together to be a single objective and can adapt to final stage quality event changes automatically.
- Why unresolved: The paper does not provide empirical evidence on how the CQS objective performs when quality events are highly correlated or when new quality events are introduced. It also does not discuss the impact of such changes on the CQS objective.
- What evidence would resolve it: Experiments comparing the performance of the CQS objective with different levels of correlation among quality events and with the introduction of new quality events.

### Open Question 2
- Question: How does the multi-task learning framework perform in terms of ranking consistency and ads recall when the final stage CTR model changes?
- Basis in paper: [inferred] The paper mentions that the final stage CTR model is used as a teacher model to distill the early stage CTR model, which helps improve ranking consistency.
- Why unresolved: The paper does not provide empirical evidence on how the multi-task learning framework performs when the final stage CTR model changes. It also does not discuss the impact of such changes on ranking consistency and ads recall.
- What evidence would resolve it: Experiments comparing the performance of the multi-task learning framework with different final stage CTR models.

### Open Question 3
- Question: How does the data augmentation technique with pseudo-labels perform in cases where the final stage CTR prediction is inaccurate?
- Basis in paper: [explicit] The paper mentions that the data augmentation technique with pseudo-labels is used to mitigate selection bias by treating the final stage CTR prediction as the pseudo-label for non-impression ads.
- Why unresolved: The paper does not provide empirical evidence on how the data augmentation technique with pseudo-labels performs when the final stage CTR prediction is inaccurate. It also does not discuss the impact of such inaccuracies on ads recall and ranking consistency.
- What evidence would resolve it: Experiments comparing the performance of the data augmentation technique with pseudo-labels under different levels of accuracy in the final stage CTR prediction.

## Limitations
- The effectiveness of the consolidated quality score depends on accurately computing CQS without deploying all individual quality event models, which may not scale with complex quality systems.
- Data augmentation with non-impression ads relies on the assumption that final-stage CTR predictions serve as reliable pseudo-labels, but this assumption lacks direct empirical validation.
- The multi-task learning framework risks negative transfer between CTR and CQS objectives, requiring careful loss weighting that may not generalize across different ad ranking scenarios.

## Confidence
- High confidence: The experimental results showing improved CTR, CVR, total value, and reduced ads cross-out rate in online A/B testing are directly supported by the paper's findings.
- Medium confidence: The claim that the CQS solves total value definition inconsistency is plausible but relies on the assumption that early-stage CQS computation perfectly mirrors final-stage quality calculations without requiring individual quality model deployment.
- Low confidence: The effectiveness of data augmentation with non-impression ads and teacher distillation for mitigating selection bias lacks direct evidence in related papers and depends heavily on the quality of pseudo-labels.

## Next Checks
1. Conduct ablation studies isolating the impact of each proposed mechanism (CQS, teacher distillation, data augmentation) to verify which components drive the observed improvements versus potential negative interactions.
2. Test the CQS framework's robustness by simulating quality event definition changes and measuring early-stage model performance degradation over time.
3. Evaluate the quality of pseudo-labels from final-stage CTR predictions by comparing them against ground truth clicks in a controlled setting with limited impression data.