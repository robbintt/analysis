---
ver: rpa2
title: '$\text{EFO}_{k}$-CQA: Towards Knowledge Graph Complex Query Answering beyond
  Set Operation'
arxiv_id: '2307.13701'
source_url: https://arxiv.org/abs/2307.13701
tags:
- query
- graph
- queries
- free
- variables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of complex query answering on
  knowledge graphs, specifically extending beyond set operations to cover Existential
  First-order (EFO) queries with multiple variables (EFOk). The authors propose a
  comprehensive framework for data generation, model training, and method evaluation
  that covers the combinatorial space of EFOk queries.
---

# $\text{EFO}_{k}$-CQA: Towards Knowledge Graph Complex Query Answering beyond Set Operation

## Quick Facts
- arXiv ID: 2307.13701
- Source URL: https://arxiv.org/abs/2307.13701
- Reference count: 40
- Key outcome: This paper proposes a comprehensive framework for complex query answering on knowledge graphs, extending beyond set operations to cover Existential First-order (EFO) queries with multiple variables (EFOk), and constructs a new dataset with 741 query types.

## Executive Summary
This paper addresses the problem of complex query answering (CQA) on knowledge graphs by extending beyond traditional set operation limitations to cover EFOk queries with multiple variables. The authors propose a novel framework that uses query graphs to represent complex logical relationships, construct a comprehensive dataset EFOk-CQA with 741 query types, and evaluate six representative CQA methods using newly proposed marginal, multiply, and joint metrics. The work reveals systematic biases in existing datasets and demonstrates that query graph representations enable modeling of queries with multiple free variables and complex logical relationships that cannot be captured by operator trees.

## Method Summary
The method constructs a comprehensive framework for data generation, model training, and evaluation that covers the combinatorial space of EFOk queries. It uses query graphs (bidirectional edges, cyclic/multigraph structures) to represent existential first-order formulas, systematically enumerates nontrivial abstract query graphs using filtering assumptions, grounds these to concrete queries with valid answers, and evaluates CQA models using three types of metrics (marginal, multiply, joint). The approach addresses limitations of existing operator tree-based methods by enabling expressivity beyond set operations while maintaining computational tractability through CSP-based solvers.

## Key Results
- The EFOk-CQA dataset construction reveals systematic bias in existing datasets that hinders appropriate development of query-answering methods
- Query graph representations enable modeling of complex logical relationships with multiple free variables that cannot be represented as operator trees
- Performance evaluation shows that joint metrics are significantly harder and more challenging than marginal and multiply metrics for multi-variable queries

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Query graph representation extends expressivity beyond operator tree limitations for EFOk queries.
- **Mechanism**: By using bidirectional edges and allowing cyclic/multigraph structures, query graphs capture logical formulas that cannot be represented as operator trees. This enables modeling of queries with multiple free variables and complex logical relationships.
- **Core assumption**: Query graph formalism can represent all existential first-order formulas without loss of expressivity.
- **Evidence anchors**:
  - [abstract]: "The combinatorial query space in our framework significantly extends those defined by set operations in the existing literature."
  - [section 2.3]: "the query graph method... extends the existing coverage Wang et al. [2021] which covers only a subset of EFO 1 query"
  - [corpus]: Weak - related papers mention query graphs but lack direct comparison to operator tree limitations.
- **Break condition**: If some EFOk queries cannot be converted to query graphs while maintaining answer equivalence, the expressivity claim fails.

### Mechanism 2
- **Claim**: Systematic enumeration of nontrivial abstract query graphs avoids combinatorial explosion while ensuring meaningful queries.
- **Mechanism**: The paper defines two key assumptions (no redundancy, no decomposition) that filter out trivial query graphs. Combined with grounding assumptions about negation and answer size, this creates a tractable yet comprehensive search space.
- **Core assumption**: The proposed assumptions correctly identify and exclude trivial queries without removing meaningful ones.
- **Evidence anchors**:
  - [section 3.1]: "We propose two assumptions of the abstract query graph" and examples of excluded graphs.
  - [section 3.2]: Assumptions 15 and 16 provide grounding constraints.
  - [corpus]: Weak - related work mentions query generation but doesn't detail filtering criteria.
- **Break condition**: If nontrivial queries are incorrectly excluded or trivial queries pass filtering, the dataset quality is compromised.

### Mechanism 3
- **Claim**: Marginal, multiply, and joint metrics provide comprehensive evaluation for EFOk queries with multiple variables.
- **Mechanism**: Marginal metrics evaluate individual variable performance, multiply metrics assess tuple-level accuracy, and joint metrics estimate combinatorial answer quality. This multi-level approach captures different aspects of query answering performance.
- **Core assumption**: These metrics accurately reflect model performance on multi-variable queries.
- **Evidence anchors**:
  - [section 4.5]: "we propose three types of different metrics to fill the research gap in the area of evaluation of queries with multiple free variables"
  - [section 5.3]: Results show clear performance differences across metric types.
  - [corpus]: Weak - related papers don't discuss multi-variable evaluation protocols in detail.
- **Break condition**: If any metric type fails to capture meaningful performance differences, the evaluation framework is incomplete.

## Foundational Learning

- **Concept**: Existential First-Order (EFO) logic and query semantics
  - Why needed here: Understanding EFO queries is fundamental to grasping why this work extends beyond previous approaches and what the evaluation metrics measure.
  - Quick check question: What distinguishes an EFO query from other first-order logic queries, and why is this distinction important for knowledge graph reasoning?

- **Concept**: Constraint Satisfaction Problem (CSP) formulation for query answering
  - Why needed here: The paper explicitly connects EFO queries to CSP instances, and understanding this connection is crucial for implementing efficient solvers and interpreting results.
  - Quick check question: How does representing an EFO query as a CSP instance enable more efficient computation of answers compared to direct logical inference?

- **Concept**: Knowledge graph incompleteness and the Open World Assumption (OWA)
  - Why needed here: The entire motivation for CQA and the distinction from database query answering rests on KGs being incomplete under OWA.
  - Quick check question: Why does the Open World Assumption fundamentally change how we approach query answering compared to closed-world databases?

## Architecture Onboarding

- **Component map**: Query graph enumeration module -> Answer computation module -> CQA model interface -> Evaluation framework -> Dataset management

- **Critical path**: 
  1. Generate abstract query graphs within parameterized space
  2. Ground abstract graphs to concrete queries with valid answers
  3. Compute ground truth answers using CSP solver
  4. Train/evaluate CQA models on generated dataset
  5. Analyze results using multi-level metrics

- **Design tradeoffs**:
  - Expressivity vs. computational tractability in query graph representation
  - Dataset size vs. quality (filtering assumptions may exclude edge cases)
  - Evaluation comprehensiveness vs. implementation complexity (three metric types)
  - Backward compatibility vs. leveraging new query graph capabilities

- **Failure signatures**:
  - Empty answer sets for seemingly valid queries (grounding issues)
  - Disproportionate performance drop on multigraph/cyclic queries (model limitations)
  - Inconsistent metrics across evaluation types (implementation bugs)
  - Combinatorial explosion in query generation (parameter tuning needed)

- **First 3 experiments**:
  1. Verify query graph enumeration produces expected number/types of graphs by topology
  2. Test answer computation on simple queries with known solutions
  3. Compare marginal vs. multiply metric scores on single-free-variable queries to validate consistency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of EFOk-CQA models scale with increasing numbers of free variables (k > 2) in complex queries?
- Basis in paper: [inferred] The paper only evaluates models on queries with up to two free variables (k=2) and notes that "joint scores are significantly harder and more challenging" for k=2 queries.
- Why unresolved: The paper's experiments were limited to k=1 and k=2 due to computational constraints, particularly with the FIT model which "degrades to enumeration" for cyclic graphs and becomes intractable for larger k values.
- What evidence would resolve it: Comprehensive benchmarking results showing model performance (MRR, HIT@k metrics) for queries with k=3, k=4, and higher numbers of free variables on standard knowledge graphs like FB15k-237, FB15k, and NELL.

### Open Question 2
- Question: What are the theoretical bounds on query answering complexity for different query graph topologies (SDAG, Multi, Cyclic) when extending beyond EFOk to full first-order logic with universal quantifiers?
- Basis in paper: [explicit] The paper notes that "traditional query answering algorithms obtain incomplete answers because of the incomplete KG" and focuses on existential first-order queries, but acknowledges that "the universal quantifier is usually not considered in query answering tasks."
- Why unresolved: The paper's framework and dataset construction are based on existential quantifiers only, and extending to universal quantifiers would require fundamentally different theoretical foundations and computational approaches.
- What evidence would resolve it: Formal complexity analysis comparing query answering complexity across different topologies (SDAG, Multi, Cyclic) when including universal quantifiers, along with empirical results showing how existing CQA models perform on such extended queries.

### Open Question 3
- Question: How does the systematic bias in existing dataset construction affect the real-world deployment of CQA models for knowledge graph completion tasks?
- Basis in paper: [explicit] The paper demonstrates that "the existing dataset construction process is systematically biased that hinders the appropriate development of query-answering methods" and notes that models built on query graphs "don't generalize well to the unseen tasks with different topology property."
- Why unresolved: While the paper identifies the bias and shows its impact on model performance, it doesn't investigate how this bias affects practical applications where knowledge graphs are inherently incomplete and queries may have diverse topologies.
- What evidence would resolve it: Comparative analysis of CQA model performance on real-world knowledge graphs with varying completeness levels and query distributions, showing how bias in training data translates to deployment performance gaps.

## Limitations
- The framework currently only covers EFO1 and EFO2 queries with binary relations, leaving higher-order queries unexplored
- Computational cost of evaluating certain models (particularly FIT) on larger knowledge graphs remains prohibitive
- Reliance on random sampling for answer selection may introduce bias in query distribution

## Confidence
- **High Confidence**: The framework's novel contributions in extending query coverage beyond set operations and introducing comprehensive evaluation metrics for multi-variable queries are well-supported by theoretical foundations and experimental results.
- **Medium Confidence**: The claims about systematic bias in existing datasets are supported by comparative analysis, though the extent of this bias across different domains warrants further investigation.
- **Low Confidence**: The generalizability of the proposed approach to EFOk queries with k > 2 and non-binary relations remains theoretical, as the current implementation hasn't been validated for these cases.

## Next Checks
1. Conduct ablation studies on the filtering assumptions (assumptions 15-16) to quantify their impact on query diversity and model performance.
2. Evaluate the proposed metrics on real-world complex queries from diverse domains to assess practical applicability.
3. Extend the framework to support EFO3 queries and analyze the computational scaling behavior to identify practical limits.