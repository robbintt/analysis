---
ver: rpa2
title: 'GRI: Graph-based Relative Isomorphism of Word Embedding Spaces'
arxiv_id: '2310.12360'
source_url: https://arxiv.org/abs/2310.12360
tags:
- isomorphism
- word
- embeddings
- graph
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new method (GRI) to improve the performance
  of cross-lingual word embeddings by incorporating semantic similarity of words into
  the training objective. The core idea is to use attentive graph convolutions to
  model the semantic relations between words in the source and target languages, and
  then combine the graph-based loss with the distributional loss to train the embeddings.
---

# GRI: Graph-based Relative Isomorphism of Word Embedding Spaces

## Quick Facts
- **arXiv ID**: 2310.12360
- **Source URL**: https://arxiv.org/abs/2310.12360
- **Reference count**: 8
- **Primary result**: GRI improves average P@1 by up to 63.6% relative score over state-of-the-art methods for cross-lingual word embeddings.

## Executive Summary
This paper proposes GRI (Graph-based Relative Isomorphism), a method that combines distributional training objectives with isomorphism losses to improve cross-lingual word embedding performance. The core innovation uses attentive graph convolutions to model semantic relationships between words across languages, then optimizes both skip-gram objectives and embedding space alignment metrics. Experimental results show significant improvements on multiple language pairs, particularly for languages with high lexical variation, and demonstrate robustness to domain mismatch settings.

## Method Summary
GRI constructs a word similarity graph based on cosine similarity between monolingual embeddings, applies attentive graph convolutions to propagate semantic information, and combines skip-gram with negative sampling objectives with isomorphism losses (L2, Procrustes) to train cross-lingual embeddings. The model uses Vecmap for final alignment and evaluation on MUSE benchmark datasets. Training balances distributional and isomorphism objectives through a weighted combination controlled by parameter α.

## Key Results
- GRI outperforms existing research by improving average P@1 by up to 63.6% relative score
- Shows significant performance gains for languages with high lexical variation (Bengali, Tamil, Ukrainian)
- Demonstrates robustness to domain mismatch settings through semantic relationship modeling
- Achieves strong results when evaluated using Pearson correlation and eigenvector similarity metrics

## Why This Works (Mechanism)

### Mechanism 1
Attentive graph convolutions enable information sharing among semantically related words, improving the relative isomorphism of cross-lingual embedding spaces. The model constructs a graph where nodes represent words and edges connect semantically related words based on cosine similarity of their embedding vectors. Attentive graph convolutions then propagate semantic information across these edges.

### Mechanism 2
Combining distributional training objectives with isomorphism losses improves cross-lingual word embedding performance. The model uses skip-gram with negative sampling to learn distributional representations while simultaneously optimizing isomorphism metrics (L2, Procrustes) to align source and target embedding spaces.

### Mechanism 3
The proposed model is robust to domain mismatch between source and target corpora. By incorporating semantic relationships across words rather than relying solely on exact word translations, the model can handle cases where corresponding words appear in different domains.

## Foundational Learning

- **Graph convolutional networks**: Used to propagate semantic information across related words in the embedding space. Quick check: How do graph convolutional networks differ from traditional convolutional networks in terms of data structure they operate on?
- **Isomorphism metrics for embedding spaces**: Used to quantify and optimize the geometric similarity between source and target embedding spaces. Quick check: What is the difference between L2 loss and Procrustes loss when measuring embedding space similarity?
- **Distributional semantics**: Used to learn word representations based on their contextual usage patterns. Quick check: How does skip-gram with negative sampling learn word embeddings that capture semantic relationships?

## Architecture Onboarding

- **Component map**: Monolingual embeddings → Graph construction → Attentive graph convolutions → Loss computation → Parameter update
- **Critical path**: Graph construction → Attentive graph convolutions → Loss computation → Parameter update
- **Design tradeoffs**: Higher threshold for graph construction reduces noise but may miss some semantic relationships; choice of isomorphism loss function affects both performance and computational cost; balance between distributional and isomorphism objectives controlled by α parameter
- **Failure signatures**: Poor P@1 scores indicate failure to align embedding spaces; high variance across runs suggests instability in graph construction or training; performance degradation on domain-mismatch settings indicates over-reliance on exact word correspondences
- **First 3 experiments**: 1) Test different threshold values (thr) in graph construction to find optimal balance between noise reduction and semantic coverage; 2) Compare performance of different isomorphism loss functions (L2, Procrustes, Procrustes with initialization) to identify most effective approach; 3) Evaluate model robustness by training on domain-mismatched corpora and measuring performance degradation compared to in-domain training

## Open Questions the Paper Calls Out

### Open Question 1
How can GRI be extended to work with deep contextualized embeddings? The paper mentions that GRI is not defined and/or implemented for deep contextualized embeddings, which are more prevalent and a better alternative to distributional embeddings. This remains unresolved as the paper does not provide details on adaptation or experimental results.

### Open Question 2
How can GRI be augmented to focus more on preserving lexico-semantic relations? The paper mentions that GRI inherits limitations of distributional embeddings, which tend to inter-mix different lexico-semantic relations and yield poor performance on specific tasks. No details are provided on modifications or experimental results.

### Open Question 3
What are better metrics to compute the relative isomorphism of embedding spaces? The paper discusses limitations of existing isometry metrics (Pearson's correlation and Eigenvector similarity) in correlating with P@1 performance and mentions the need for better metrics, but does not propose or evaluate alternatives.

## Limitations

- Evaluation focuses on a narrow set of languages (Bengali, Tamil, Ukrainian) and single domain (news), limiting generalizability
- Specific performance claims may be sensitive to hyperparameter choices, particularly graph construction threshold and loss balance
- Paper lacks ablation studies showing individual contributions of graph convolutions versus isomorphism losses
- Implementation details of attentive graph convolution mechanism are underspecified

## Confidence

**High Confidence**: The core architectural design combining distributional objectives with isomorphism metrics is sound and well-motivated. The experimental methodology follows established best practices.

**Medium Confidence**: Claims about domain mismatch robustness are supported by limited evidence. No direct experiments compare in-domain versus out-of-domain performance.

**Low Confidence**: Exact implementation details of attentive graph convolution mechanism are underspecified. Critical components like attention weight computation and initialization are not described.

## Next Checks

1. **Ablation Study**: Run experiments with graph convolutions disabled (distributional loss only) and with isomorphism loss disabled (distributional + graph only) to quantify their individual contributions to performance gains.

2. **Domain Transfer Test**: Train the model on news data but evaluate on different domains (e.g., social media, technical documentation) to directly measure domain mismatch robustness claims.

3. **Hyperparameter Sensitivity**: Systematically vary the graph construction threshold (thr) and loss balance parameter (α) across a wider range to identify optimal settings and assess robustness to hyperparameter choices.