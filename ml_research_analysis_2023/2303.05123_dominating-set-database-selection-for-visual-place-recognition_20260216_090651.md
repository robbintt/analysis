---
ver: rpa2
title: Dominating Set Database Selection for Visual Place Recognition
arxiv_id: '2303.05123'
source_url: https://arxiv.org/abs/2303.05123
tags:
- database
- images
- image
- overlap
- ieee
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of selecting a small, optimal
  database of images for visual place recognition (VPR) from large RGBD scanning sequences
  in indoor environments. The authors formulate this as a graph-based optimization
  problem using a dominating set algorithm.
---

# Dominating Set Database Selection for Visual Place Recognition

## Quick Facts
- arXiv ID: 2303.05123
- Source URL: https://arxiv.org/abs/2303.05123
- Reference count: 38
- Can reduce database size by 250-1400× while maintaining >80% recall for VPR

## Executive Summary
This paper addresses the challenge of selecting a minimal database of images for visual place recognition from large RGBD scanning sequences in indoor environments. The authors formulate this as a graph-based optimization problem using a dominating set algorithm, where nodes represent images and edges encode spatial overlap measured via voxelized 3D maps. The approach enables significant database size reduction while maintaining high VPR recall rates, and can also generate weakly-supervised labels for fine-tuning neural VPR models. The method is evaluated on multiple RGBD datasets showing consistent performance improvements over alternative strategies.

## Method Summary
The approach constructs a 3D voxelized map from RGBD sequences and computes spatial overlap between image pairs using intersection over union (IoU) of voxel sets. A graph is built where images are nodes and edges represent sufficient spatial overlap. The minimum dominating set problem is solved on this graph to select the optimal database subset that collectively covers the environment. Optionally, the method generates weakly-supervised labels by clustering images around selected database images, enabling fine-tuning of neural VPR models for improved accuracy.

## Key Results
- Database size reduced by 250-1400× compared to original scanning sequences
- Maintained VPR recall rates above 80% across multiple datasets (7-Scenes, BundleFusion, custom indoor sequence)
- Outperformed alternative database selection strategies in coverage uniformity and scalability
- Enabled weakly-supervised labeling for neural VPR model fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph-based dominating set formulation ensures spatial coverage while minimizing database size
- Mechanism: Images as nodes with spatial overlap edges enable minimal subset selection that collectively covers entire environment
- Core assumption: Voxel-based spatial overlap accurately represents coverage relationships
- Evidence anchors: [abstract], [section], [corpus] Weak
- Break condition: Noisy or incomplete depth data makes voxel overlap unreliable

### Mechanism 2
- Claim: IoU metric creates stricter constraints that improve database quality
- Mechanism: Symmetric overlap measure penalizes partial overlaps, forcing better spatial coverage selection
- Core assumption: Symmetric measures more effective than asymmetric for comprehensive coverage
- Evidence anchors: [section], [section], [corpus] Weak
- Break condition: Repetitive structures force inclusion of too many images

### Mechanism 3
- Claim: Weakly-supervised labels enable fine-tuning of neural VPR models
- Mechanism: Clustering around database images creates semantic place labels for supervised learning
- Core assumption: Spatial clustering corresponds to semantically meaningful places
- Evidence anchors: [abstract], [section], [section], [corpus] Weak
- Break condition: Lack of distinct visual features provides poor training signals

## Foundational Learning

- Concept: Graph theory and dominating set algorithms
  - Why needed here: Core optimization problem formulation requires understanding graph representations
  - Quick check question: What's the difference between a dominating set and a vertex cover?

- Concept: Spatial data structures and voxelization
  - Why needed here: Overlap measure relies on voxel representations and intersection computations
  - Quick check question: How to efficiently compute voxel set intersections?

- Concept: Visual place recognition pipeline and evaluation metrics
  - Why needed here: Understanding VPR systems and performance evaluation is crucial
  - Quick check question: What's the difference between Recall@1 and Recall@5?

## Architecture Onboarding

- Component map: RGBD data ingestion → 3D reconstruction → Voxelization → Overlap computation → Graph construction → Dominating set solver → Database selection → Weakly-supervised labeling → VPR fine-tuning (optional)

- Critical path: 1) 3D map reconstruction from RGBD sequences, 2) Voxel-based overlap computation between all image pairs, 3) Graph construction and dominating set solution, 4) Database evaluation and VPR performance measurement

- Design tradeoffs:
  - Voxel size vs. computational efficiency: Smaller voxels = more precise but quadratically slower
  - Overlap threshold vs. database size: Higher thresholds = smaller databases but potential coverage gaps
  - Symmetric vs. asymmetric overlap: Symmetric = stricter constraints but reduced size reduction

- Failure signatures:
  - Extremely small databases with poor VPR: Overlap threshold too high or voxel size too coarse
  - Large databases with minimal reduction: Overlap threshold too low or graph construction issues
  - VPR performance degradation after fine-tuning: Noisy weakly-supervised labels

- First 3 experiments:
  1. Baseline comparison: Implement EveryNth and CubeDivision strategies vs. DominatingSet
  2. Overlap threshold sweep: Test different IoU thresholds and plot database size vs. recall
  3. Fine-tuning evaluation: Compare pre-trained vs. fine-tuned VPR models on same database

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DominatingSet compare to other strategies on larger-scale or more complex indoor environments?
- Basis in paper: [inferred] Limited evaluation on specific datasets suggests potential for larger environments
- Why unresolved: Current evaluation limited to 7-Scenes, BundleFusion, and custom sequence
- What evidence would resolve it: Testing on larger-scale or more complex environments with comparative analysis

### Open Question 2
- Question: How does overlap threshold (µ) affect trade-off between database size and recall rate?
- Basis in paper: [explicit] Authors discuss threshold impact but lack detailed trade-off analysis
- Why unresolved: Paper mentions different thresholds without comprehensive analysis
- What evidence would resolve it: Experiments with range of thresholds analyzing size vs. recall trade-off

### Open Question 3
- Question: How does DominatingSet perform on outdoor environments or significantly different characteristics?
- Basis in paper: [inferred] Focus on indoor environments with no discussion of other environments
- Why unresolved: Limited to indoor environments with no testing in outdoor or different settings
- What evidence would resolve it: Testing in outdoor environments or significantly different characteristics

## Limitations

- Effectiveness heavily depends on quality of depth data and 3D reconstruction accuracy
- Voxel-based overlap computation may struggle with dynamic objects or scene changes
- Method's scalability to very large environments or real-time applications not thoroughly evaluated

## Confidence

- **High Confidence**: Graph-based dominating set formulation for database size reduction with spatial coverage
- **Medium Confidence**: Effectiveness of IoU-based overlap measures for spatial coverage optimization
- **Medium Confidence**: Benefit of weakly-supervised fine-tuning for VPR model accuracy improvements

## Next Checks

1. Conduct ablation studies comparing IoU vs. asymmetric overlap measures across diverse environments
2. Test algorithm robustness to varying depth data quality by introducing controlled noise
3. Implement and evaluate weakly-supervised fine-tuning pipeline on multiple VPR architectures