---
ver: rpa2
title: Concept explainability for plant diseases classification
arxiv_id: '2309.08739'
source_url: https://arxiv.org/abs/2309.08739
tags:
- plant
- disease
- concepts
- concept
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the need for interpretability in deep learning
  models for plant disease classification, a critical issue for the widespread adoption
  of these models in agriculture. The authors employ the TCAV method to analyze the
  importance of user-defined concepts like color, texture, and disease-related patterns
  in the classification process.
---

# Concept explainability for plant diseases classification

## Quick Facts
- arXiv ID: 2309.08739
- Source URL: https://arxiv.org/abs/2309.08739
- Authors: 
- Reference count: 6
- Primary result: TCAV analysis shows Vgg16 is more sensitive to texture concepts while InceptionV3 better captures color concepts for plant disease classification

## Executive Summary
This paper addresses the interpretability challenge in deep learning models for plant disease classification using the TCAV (Testing with Concept Activation Vectors) method. The authors analyze which semantic concepts (color, texture, disease patterns) influence model predictions in Vgg16 and InceptionV3 architectures trained on tomato disease data. TCAV reveals that both models learn concepts similar to those used by plant disease experts, with architectural differences emerging in concept sensitivity. The study demonstrates how explainability methods can increase trust in AI-driven agricultural solutions by providing insights into model decision-making processes.

## Method Summary
The study employs transfer learning with pre-trained Vgg16 and InceptionV3 models fine-tuned on a tomato disease dataset from Plant Village. After training with data augmentation, TCAV analysis is performed to quantify the importance of user-defined concepts. The method computes directional derivatives in the model's embedding space to measure concept influence, using t-tests with Bonferroni correction for statistical validation. Concept datasets include synthetic color images, DTD texture categories, and late blight disease patterns. The analysis focuses on selected layers to understand how different architectural components capture disease-related features.

## Key Results
- Both Vgg16 and InceptionV3 achieved high accuracy on tomato disease classification (>90%)
- TCAV analysis showed both models learned concepts aligned with expert knowledge (brown/yellow colors for late blight)
- InceptionV3 demonstrated better color concept capture while Vgg16 was more sensitive to texture concepts
- Statistical validation confirmed concept importance with Bonferroni-corrected significance testing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TCAV provides quantitative validation of which high-level semantic concepts (color, texture, disease patterns) influence model predictions.
- Mechanism: TCAV computes directional derivatives in the model's embedding space to measure how strongly a concept vector (CAV) aligns with class logits, then aggregates these into a TCAV score indicating positive influence.
- Core assumption: The CAV vector truly represents the concept in the model's internal representation space.
- Evidence anchors:
  - [abstract] "TCAV method tests the sensitivity of a trained deep neural model to a defined concept of interest."
  - [section] "Importance of a 'concept' C (e.g., color or texture) to an image class k (e.g., late blight) is found by taking the directional derivative of class predictions (for class k) at each layer l of a CNN in the direction of (with respect to) a CAV."
- Break condition: If the concept classifier fails to separate concept vs random activations, the CAV becomes meaningless and scores become unreliable.

### Mechanism 2
- Claim: TCAV reveals differences in concept learning between architectures (Vgg16 vs InceptionV3) despite similar accuracy.
- Mechanism: By computing TCAV scores at different layers, the method exposes which concepts each architecture prioritizes (e.g., Vgg16 favors texture, InceptionV3 favors color).
- Core assumption: Layer-specific TCAV scores reflect meaningful architectural differences in internal representation.
- Evidence anchors:
  - [abstract] "InceptionV3 was better at capturing color concepts, while Vgg16 was more sensitive to texture concepts."
  - [section] "Results show that different texture detectors emerge, which explains why the texture concepts dominate in the tested layers especially in the case of Vgg16."
- Break condition: If both architectures learn the same concepts equally well, TCAV would show no meaningful differences despite different architectures.

### Mechanism 3
- Claim: TCAV provides statistical validation of concept importance through significance testing and Bonferroni correction.
- Mechanism: Multiple CAVs are computed between concept images and random images, then compared via t-tests; only concepts with significantly different scores from 0.5 are considered important.
- Core assumption: The statistical testing framework reliably distinguishes meaningful concepts from random correlations.
- Evidence anchors:
  - [section] "They compute multiple CAVs between concept images and a batch of random images... They perform a two-sided t-test of the TCAV scores based on these multiple samples."
  - [section] "They further perform Bonferroni correction (p < α/m,m = 2) for multiple comparisons between all concept-random pairs to reduce potential for false positives."
- Break condition: If the dataset is too small or imbalanced, statistical tests lose power and may miss important concepts or include spurious ones.

## Foundational Learning

- Concept: Directional derivative in high-dimensional embedding space
  - Why needed here: TCAV fundamentally relies on measuring how changes along concept directions affect model outputs
  - Quick check question: What does a positive TCAV score indicate about the relationship between a concept and class prediction?

- Concept: Statistical hypothesis testing and multiple comparison correction
  - Why needed here: TCAV uses t-tests and Bonferroni correction to validate which concepts are genuinely important
  - Quick check question: Why is Bonferroni correction necessary when testing multiple concepts?

- Concept: Transfer learning and fine-tuning
  - Why needed here: The study uses pre-trained InceptionV3 and Vgg16 models fine-tuned on plant disease data
  - Quick check question: What is the difference between freezing all layers vs unfreezing only the final convolutional layers during fine-tuning?

## Architecture Onboarding

- Component map: Data preprocessing → Model training (Vgg16/InceptionV3) → Concept dataset creation → TCAV computation → Statistical validation → Interpretation
- Critical path: Model training → TCAV computation → Statistical validation (if validation fails, the concepts are unreliable)
- Design tradeoffs: TCAV requires separate concept datasets and statistical testing overhead vs simpler saliency methods that provide immediate but less interpretable results
- Failure signatures: Low TCAV scores across all concepts may indicate poor concept representation; failed statistical tests suggest insufficient concept data or random correlations
- First 3 experiments:
  1. Replicate the color concept analysis with the same plant disease dataset to verify TCAV scores for brown/yellow/green
  2. Test texture concepts (DTD dataset) to confirm which layers capture texture information
  3. Compare TCAV results between Vgg16 and InceptionV3 on the same concept to observe architectural differences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we automatically define concepts for TCAV analysis instead of relying on manual annotations?
- Basis in paper: [inferred] The paper mentions that "finding a way to define concepts automatically could simplify the process by eliminating the necessity for manual annotations and could allow revealing new knowledge for plant disease experts or unexpected biases from the network."
- Why unresolved: Current TCAV implementation requires predefined concepts, which may not capture all relevant disease patterns or may introduce human bias in concept selection.
- What evidence would resolve it: Development and validation of an unsupervised or semi-supervised concept discovery method that can automatically identify meaningful disease-related concepts from the data, followed by successful application to plant disease classification datasets.

### Open Question 2
- Question: How does TCAV perform when applied to plant disease datasets with real field backgrounds instead of uniform backgrounds?
- Basis in paper: [explicit] The paper states "Future work could incorporate plant disease datasets from the field with real background, and then, we can use TCAV to ensure the model is unbiased towards the background."
- Why unresolved: The current study used a controlled dataset with uniform backgrounds, which may not represent real-world conditions where background elements could influence model decisions.
- What evidence would resolve it: Application of TCAV to field-collected plant disease images with natural backgrounds, comparing concept importance scores between uniform and natural background datasets, and analyzing any background-related biases.

### Open Question 3
- Question: How does the depth of the neural network architecture affect its ability to capture disease-related concepts?
- Basis in paper: [explicit] The paper mentions that "InceptionV3 is a deeper network than Vgg16 which helped in capturing better the concepts" and discusses different layers within each architecture.
- Why unresolved: While the paper observes differences in concept capture between architectures and layers, a systematic analysis of how network depth and architecture design influence concept learning is not provided.
- What evidence would resolve it: Systematic comparison of TCAV results across multiple network architectures with varying depths, analyzing concept importance scores at different network layers and their correlation with disease classification performance.

## Limitations

- TCAV implementation details are underspecified - the paper references a Keras-based version but doesn't detail layer selection criteria or exact statistical testing parameters
- Concept dataset quality and representativeness are not fully evaluated - synthetic color images and DTD textures may not capture domain-specific disease patterns
- Statistical power limitations due to relatively small concept sample sizes (50 images per concept) may lead to false negatives

## Confidence

- **High confidence**: Model training methodology (Vgg16/InceptionV3 transfer learning, accuracy metrics) - well-specified and standard practice
- **Medium confidence**: TCAV results interpretation - methodology described but implementation details unclear, making exact replication challenging
- **Low confidence**: Generalization claims about architectural differences - based on limited concept categories and statistical testing may not capture full complexity

## Next Checks

1. Implement statistical power analysis to determine minimum concept sample size needed for reliable TCAV detection
2. Test TCAV sensitivity to concept dataset quality by comparing results using domain-specific vs. generic concept images
3. Validate architectural differences with additional models (e.g., ResNet, EfficientNet) to confirm Vgg16 vs InceptionV3 pattern holds more broadly