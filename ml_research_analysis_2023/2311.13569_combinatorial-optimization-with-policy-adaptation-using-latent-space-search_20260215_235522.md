---
ver: rpa2
title: Combinatorial Optimization with Policy Adaptation using Latent Space Search
arxiv_id: '2311.13569'
source_url: https://arxiv.org/abs/2311.13569
tags:
- search
- compass
- latent
- space
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes COMPASS, a novel reinforcement learning method
  for combinatorial optimization that learns a continuous latent space of diverse
  and specialized policies. The key idea is to condition a single neural policy on
  vectors sampled from a structured latent space during training, encouraging different
  regions to specialize to different problem instance sub-distributions.
---

# Combinatorial Optimization with Policy Adaptation using Latent Space Search

## Quick Facts
- arXiv ID: 2311.13569
- Source URL: https://arxiv.org/abs/2311.13569
- Authors: 
- Reference count: 40
- Key outcome: COMPASS achieves state-of-the-art performance on TSP, CVRP, and JSSP benchmarks while being significantly faster than competing methods at inference time.

## Executive Summary
This paper introduces COMPASS, a novel reinforcement learning approach for combinatorial optimization that learns a continuous latent space of diverse and specialized policies. The method conditions a single neural policy on vectors sampled from a structured 16-dimensional latent space during training, encouraging different regions to specialize to different problem instance sub-distributions. At inference time, an efficient search algorithm (CMA-ES) finds the most performant policy for a given instance. COMPASS establishes new state-of-the-art performance across 11 standard benchmarking tasks while being significantly faster than competing methods like EAS and Poppy, as its adaptation mechanism only modifies 16 parameters versus over 10,000 for EAS.

## Method Summary
COMPASS extends existing RL-based CO solvers by conditioning the policy on a 16-dimensional latent vector sampled from a structured space. The architecture uses an encoder-decoder framework where the decoder incorporates the latent vector through multi-head attention mechanisms. During training, multiple latent vectors are sampled per instance, policies are evaluated, and only the best-performing conditioned policy is updated, driving specialization of different latent regions. At inference, multiple independent CMA-ES components explore the latent space in parallel, initialized via Voronoi tessellation to ensure coverage. The method is pre-trained on single policies (POMO for TSP/CVRP, attention-based model for JSSP) before being adapted to the conditioned architecture.

## Key Results
- Establishes new state-of-the-art across all 11 standard benchmarking tasks for TSP, CVRP, and JSSP
- Generalizes better to out-of-distribution instances compared to baselines
- Outperforms EAS and Poppy while being significantly faster at inference (16 parameters vs 10,000+ for EAS)
- Achieves superior performance with limited computational budget compared to brute-force sampling or fine-tuning baselines

## Why This Works (Mechanism)

### Mechanism 1
Conditioning a policy on a latent vector allows the same neural network to represent multiple specialized strategies. The decoder architecture concatenates the latent vector with key, query, and value inputs, enabling distinct behaviors without changing model weights. This works because the latent space can be structured such that nearby vectors produce similar policies, enabling principled search.

### Mechanism 2
Training only the best-performing conditioned policy per instance drives specialization of latent regions. During training, multiple latent vectors are sampled, each policy is evaluated, and only the highest-reward policy is updated, encouraging that latent region to specialize to the current instance type. This assumes the top-performing policy for an instance corresponds to a latent vector whose region is specialized for that instance's sub-distribution.

### Mechanism 3
CMA-ES efficiently searches the latent space to adapt to out-of-distribution instances without retraining. Multiple independent CMA-ES components explore different regions of the latent space, guided by Voronoi initialization to ensure coverage, and iteratively refine toward high-performing policies. This works because the latent space contains multiple high-performing regions for any given instance, justifying parallel search components.

## Foundational Learning

- **Concept: Reinforcement Learning with Pointer Networks for combinatorial optimization**
  - Why needed here: The base architecture for COMPASS is derived from RL approaches like POMO that use pointer networks to incrementally construct solutions.
  - Quick check question: How does a pointer network output a sequence in TSP?

- **Concept: Multi-head attention and conditioning mechanisms**
  - Why needed here: COMPASS extends existing transformer-based solvers by conditioning the decoder on a latent vector, requiring understanding of attention-based policy architectures.
  - Quick check question: What changes when you concatenate a latent vector to the key, query, and value inputs of an attention layer?

- **Concept: Covariance Matrix Adaptation Evolution Strategy (CMA-ES)**
  - Why needed here: The inference-time search relies on CMA-ES to efficiently navigate the continuous latent space.
  - Quick check question: How does CMA-ES adapt its covariance matrix to balance exploration and exploitation?

## Architecture Onboarding

- **Component map**: Encoder -> Latent space (16-dim) -> Decoder (attention-based, conditioned) -> CMA-ES search
- **Critical path**:
  1. Pre-train base encoder-decoder on single policy using REINFORCE
  2. Augment decoder to accept latent vector input
  3. Train COMPASS by sampling N latent vectors per instance, evaluating policies, updating only best
  4. At inference, initialize multiple CMA-ES components on Voronoi centroids
  5. Iteratively sample and evaluate policies until budget exhausted

- **Design tradeoffs**:
  - Single conditioned policy vs multiple independent policies: Memory efficient but requires effective conditioning
  - Continuous vs discrete latent space: Infinite policies possible but requires search strategy
  - Number of CMA-ES components: More components reduce risk of local optima but increase computation

- **Failure signatures**:
  - Under-specialization: Uniform performance across latent space indicates training isn't driving specialization
  - Poor adaptation: CMA-ES fails to improve solutions, suggesting latent space lacks structure
  - Overfitting: Model performs well on training distribution but poorly on out-of-distribution instances

- **First 3 experiments**:
  1. Train COMPASS on TSP100, visualize latent space performance landscape on held-out TSP150 instances
  2. Compare CMA-ES search vs uniform sampling on same latent space to validate search efficiency
  3. Evaluate generalization by applying mutation operators to training instances and measuring performance degradation compared to baselines

## Open Questions the Paper Calls Out

- How does COMPASS perform on larger-scale combinatorial optimization problems with more than 200 nodes?
- What is the impact of increasing the dimensionality of the latent space on COMPASS's performance?
- How does COMPASS compare to hybrid approaches that combine construction heuristics with local search improvement methods?
- Can COMPASS be extended to handle dynamic or online combinatorial optimization problems where problem instances change over time?

## Limitations

- Relies on pre-trained checkpoints (POMO for TSP/CVRP, attention-based model for JSSP) with limited implementation details provided
- 16-dimensional latent space choice lacks empirical justification through ablation studies
- Performance gains from CMA-ES search versus the inherent quality of the conditioned solver remain unclear

## Confidence

- **High Confidence**: The fundamental mechanism of conditioning policies on latent vectors and the training procedure that encourages specialization through selective updates
- **Medium Confidence**: The efficiency claims regarding CMA-ES search versus brute-force sampling or fine-tuning
- **Low Confidence**: The scalability claims to larger latent spaces or more complex CO problems beyond the three considered

## Next Checks

1. **Ablation Study**: Systematically vary the latent space dimension (e.g., 8, 16, 32) and compare the quality of solutions and search efficiency to determine if 16 dimensions is optimal or merely sufficient.

2. **Component Contribution Analysis**: Evaluate COMPASS with and without CMA-ES search on the same latent space to quantify how much performance improvement comes from the conditioned solver versus the search algorithm.

3. **Distribution Shift Robustness**: Apply the mutation operators described in the corpus to training instances and measure COMPASS's performance degradation compared to EAS and Poppy, focusing on out-of-distribution generalization.