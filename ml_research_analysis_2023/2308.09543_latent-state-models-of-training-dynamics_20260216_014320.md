---
ver: rpa2
title: Latent State Models of Training Dynamics
arxiv_id: '2308.09543'
source_url: https://arxiv.org/abs/2308.09543
tags:
- training
- state
- states
- learning
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We propose a principled and automated framework for analyzing the
  effect of random seeds on training dynamics. By collecting metrics throughout training
  and fitting a hidden Markov model (HMM) to the metric sequences, we derive a low-dimensional,
  discrete representation of training trajectories called a training map.
---

# Latent State Models of Training Dynamics

## Quick Facts
- arXiv ID: 2308.09543
- Source URL: https://arxiv.org/abs/2308.09543
- Authors: 
- Reference count: 34
- One-line primary result: A principled framework for analyzing training dynamics using hidden Markov models to identify "detour" states that slow convergence

## Executive Summary
This paper proposes a principled and automated framework for analyzing the effect of random seeds on neural network training dynamics. By collecting metrics throughout training and fitting a hidden Markov model (HMM) to the metric sequences, the authors derive a low-dimensional, discrete representation of training trajectories called a training map. This approach enables the identification of "detour" states that slow down convergence and provides insights into phase transitions and the impact of randomness on training outcomes.

## Method Summary
The method involves training models multiple times with different random seeds and computing various metrics throughout training (such as L1/L2 norms, means, variances, and singular values of weights). A Gaussian HMM is then fitted to the sequences of normalized metrics using the Baum-Welch algorithm, with the number of states selected via the Bayesian Information Criterion (BIC). The resulting training map is extracted by pruning the transition matrix and labeling states and transitions based on the HMM's learned parameters. Linear regression is used to predict convergence time from the distribution over latent states, allowing for the identification of "detour" states that slow down convergence.

## Key Results
- The HMM-based training map successfully identifies detour states that correlate with slower convergence across various tasks including grokking, image classification, and masked language modeling.
- Detour states are found to be associated with training setups that are sensitive to random seeds and can be eliminated through stabilization techniques, reducing the gap between memorization and generalization in grokking tasks.
- The training map representation provides interpretable labels for latent states and transitions, enabling the study of phase transitions and the impact of randomness on training dynamics.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The HMM captures training dynamics by summarizing changes in metrics across random seeds.
- Mechanism: By computing off-the-shelf metrics from model weights and fitting an HMM to these sequences, the model identifies latent states that represent significant shifts in training behavior. Transitions between these states correspond to meaningful changes in the training trajectory.
- Core assumption: The set of metrics chosen is sufficiently rich to capture the essential dynamics of training, even though they are low-dimensional compared to the full weight space.
- Evidence anchors:
  - [abstract]: "We train models multiple times with different random seeds and compute a variety of metrics throughout training... We then fit a hidden Markov model (HMM) over the resulting sequences of metrics."
  - [section 2.1]: "We compute various metrics such as the average layer-wise L1 and L2 norm, the mean and variances of the weights and biases in the network, and the means and variances of each weight matrix's singular values."
  - [corpus]: Weak - the corpus does not directly address HMM-based metric summarization.

### Mechanism 2
- Claim: The training map provides interpretable labels for latent states and transitions.
- Mechanism: The HMM's learned means and covariances are used to rank features by their impact on the posterior probability of each state. This ranking allows for labeling states with the most influential metrics and characterizing transitions by the changes in these metrics.
- Core assumption: The most important features for each state, as determined by the inverse covariance matrix, accurately reflect the dominant dynamics of that state.
- Evidence anchors:
  - [section 2.2]: "We use the HMM to describe what each hidden state means and how the hidden states relate to each other... We label the hidden states by ranking the features according to how much each feature changes the posterior probability."
  - [proposition 1]: "The most important feature for hidden state k has the largest Î£k[i,i]."
  - [corpus]: Weak - the corpus does not provide direct evidence for this specific labeling approach.

### Mechanism 3
- Claim: Detour states are identified as latent states that correlate with slower convergence.
- Mechanism: A linear regression model is trained to predict convergence time from the empirical distribution over latent states (unigram featurization). States with positive regression coefficients that are not visited by all trajectories are identified as detour states.
- Core assumption: The empirical distribution over latent states is a good proxy for the training dynamics that lead to convergence, and linear regression is sufficient to capture the relationship between state visitation and convergence time.
- Evidence anchors:
  - [section 2.3]: "We select a metric and predict it from the path a training run takes through the Markov chain... We use linear regression to predict convergence time from the empirical distribution over latent states."
  - [definition]: "A learned latent state is a detour state if: Some training runs do not visit the state... Its linear regression coefficient is positive when predicting convergence time."
  - [corpus]: Weak - the corpus does not discuss the use of linear regression for identifying detour states.

## Foundational Learning

- Concept: Hidden Markov Models (HMMs)
  - Why needed here: HMMs provide a principled way to model sequences of observations with discrete latent states, which is ideal for representing the stochastic process of transitions between states in training dynamics.
  - Quick check question: What are the two main components of an HMM, and what do they represent in the context of this work?
- Concept: Dimensionality Reduction via Metrics
  - Why needed here: Directly fitting an HMM to the full weight space is computationally infeasible due to the high dimensionality. Computing a small set of metrics from the weights reduces the dimensionality while still capturing essential dynamics.
  - Quick check question: Why is z-score normalization applied to the metrics before fitting the HMM?
- Concept: Linear Regression for State Semantics
  - Why needed here: Linear regression is used to quantify the relationship between the distribution over latent states and a target metric (e.g., convergence time), allowing for the identification of states that have a significant impact on the metric.
  - Quick check question: How does the unigram featurization of latent states relate to the bag-of-words model in natural language processing?

## Architecture Onboarding

- Component map:
  - Data Collection: Multiple training runs with different random seeds, computing metrics at each checkpoint
  - HMM Fitting: Training an HMM on the sequences of normalized metrics using the Baum-Welch algorithm
  - Training Map Extraction: Deriving the graph structure, vertex labels, and edge labels from the HMM
  - State Semantics: Using linear regression to predict a target metric from the distribution over latent states and identifying detour states

- Critical path:
  1. Compute metrics from training runs
  2. Normalize metrics and fit HMM
  3. Extract training map from HMM
  4. Perform linear regression to identify detour states

- Design tradeoffs:
  - Choosing metrics: Balance between capturing essential dynamics and keeping dimensionality low
  - Number of HMM states: Tradeoff between model complexity and interpretability (using BIC for selection)
  - Target metric for regression: Should be relevant to the research question (e.g., convergence time)

- Failure signatures:
  - HMM not converging or producing unreasonable results
  - Training map not providing meaningful insights into the training dynamics
  - Linear regression not achieving statistically significant results

- First 3 experiments:
  1. Replicate the modular addition experiment with a one-layer transformer and analyze the training map
  2. Apply the method to a different grokking task (e.g., sparse parities) and compare the results
  3. Test the impact of destabilizing training (e.g., removing batch normalization) on the training map and detour states

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we extend the HMM framework to model continuous latent spaces instead of discrete states?
- Basis in paper: [inferred] The paper mentions that the HMM represents training as a stochastic process of transitions between discrete latent states, and suggests that relaxing this assumption is a fruitful area for future work.
- Why unresolved: The paper only demonstrates the effectiveness of the HMM for discrete latent states and does not explore alternative continuous models. The impact of continuous vs. discrete representations on interpretability and predictive power is unclear.
- What evidence would resolve it: Experiments comparing HMMs with continuous latent variable models (e.g., variational autoencoders) on the same training dynamics datasets, evaluating both predictive accuracy and interpretability.

### Open Question 2
- Question: What is the relationship between the discovered detour states and the underlying optimization landscape of the neural network?
- Basis in paper: [explicit] The paper discusses how detour states are associated with slower convergence and appear in training setups sensitive to random seeds, and speculates that grokking is related to a sharp optimization landscape.
- Why unresolved: While the paper identifies detour states and links them to training stability, it does not provide a mechanistic explanation for why these states exist or how they relate to the geometry of the loss landscape.
- What evidence would resolve it: Analysis of the loss landscape topology (e.g., curvature, sharpness) in regions corresponding to detour states, potentially using techniques like mode connectivity or loss surface visualization.

### Open Question 3
- Question: Can the training map representation be used to predict and prevent catastrophic forgetting during sequential learning tasks?
- Basis in paper: [inferred] The paper demonstrates that training maps can capture phase transitions and changes in model behavior, and discusses how the representation could be extended to predict metrics like gender bias.
- Why unresolved: The paper does not apply the training map framework to multi-task or continual learning scenarios where catastrophic forgetting is a concern.
- What evidence would resolve it: Experiments applying the training map approach to sequential learning tasks, correlating the emergence of specific latent states with forgetting, and testing whether interventions based on the training map can mitigate forgetting.

## Limitations

- The effectiveness of the framework depends on the chosen set of metrics, which may not capture all relevant aspects of the training dynamics.
- The assumption of a linear relationship between state visitation and convergence time in the detour state identification may not hold for all training scenarios.
- The method has only been demonstrated on relatively simple architectures and tasks, and its applicability to more complex models and real-world problems is yet to be established.

## Confidence

- **High confidence**: The HMM-based framework for extracting training maps and the method for labeling states and transitions are technically sound and well-grounded in established machine learning methods.
- **Medium confidence**: The identification of detour states through linear regression is methodologically valid, but its effectiveness may vary depending on the specific task and metrics used.
- **Low confidence**: The broader claims about the interpretability of training maps and their ability to explain complex phenomena like grokking require more extensive validation across diverse architectures and tasks.

## Next Checks

1. **Metric Sensitivity Analysis**: Systematically vary the set of metrics used (e.g., adding gradient norms or activation statistics) and assess the impact on the resulting training maps and identified detour states.
2. **Architecture and Task Transfer**: Apply the method to a diverse set of architectures (e.g., CNNs, LSTMs) and tasks (e.g., language modeling, reinforcement learning) to evaluate the generalizability of the findings.
3. **Alternative State Identification Methods**: Compare the linear regression approach for identifying detour states with non-linear methods (e.g., random forests, neural networks) to determine if the linear assumption is a limiting factor.