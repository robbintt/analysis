---
ver: rpa2
title: On the steerability of large language models toward data-driven personas
arxiv_id: '2311.04978'
source_url: https://arxiv.org/abs/2311.04978
tags:
- user
- cluster
- llms
- arxiv
- opinions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel data-driven approach to persona definition
  in language models, moving beyond traditional demographic traits to cluster users
  based on their opinions. The authors use collaborative filtering to embed users
  into a continuous vector space and then cluster them into personas with similar
  viewpoints.
---

# On the steerability of large language models toward data-driven personas

## Quick Facts
- arXiv ID: 2311.04978
- Source URL: https://arxiv.org/abs/2311.04978
- Reference count: 35
- Primary result: Data-driven personas significantly improve LLM steerability, achieving 57%-77% better performance over baseline approaches

## Executive Summary
This paper introduces a novel approach to steering large language models (LLMs) toward specific personas based on user opinions rather than traditional demographic traits. The authors propose using collaborative filtering to embed users into a continuous vector space, then clustering them into personas with similar viewpoints. A soft-prompting model is learned to map these user embeddings to virtual tokens that, when prepended to LLM inputs, enable the generation of responses aligned with specific personas. Experiments on the OpinionQA dataset demonstrate that this data-driven approach significantly outperforms baseline methods, including those based on demographic characteristics.

## Method Summary
The proposed method consists of three main components: (1) Collaborative filtering using LightGCN to embed users into a continuous vector space based on their opinion responses, (2) K-means clustering to group users with similar embeddings into personas, and (3) A soft-prompting model (SPM) that maps user embeddings to sequences of virtual tokens. These virtual tokens are prepended to LLM inputs to steer the generation process toward specific personas. The approach is evaluated on the OpinionQA dataset containing 18,339 participants and 1,476 multiple-choice questions, measuring prediction accuracy of user responses.

## Key Results
- Data-driven personas achieve 57%-77% better performance than baseline approaches
- The method significantly outperforms demographic-based persona steering
- Clustering users based on opinion embeddings reveals distinct demographic compositions within personas

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continuous user embeddings learned through collaborative filtering encode more nuanced opinion information than static demographic traits.
- Mechanism: LightGCN embeds users and questions into a shared 128-dimensional space based on interaction patterns, capturing indirect relationships through graph convolutions.
- Core assumption: Users with similar response patterns across multiple questions have similar underlying opinions that can be captured in a low-dimensional embedding space.
- Evidence anchors: The paper explicitly states the methodology uses collaborative filtering to embed users into a continuous vector space, and shows improved performance over demographic-based approaches.

### Mechanism 2
- Claim: A shared soft-prompting model can effectively steer LLMs toward diverse personas by mapping user embeddings to virtual tokens.
- Mechanism: The SPM learns a mapping function that transforms each user's continuous embedding into virtual tokens, which are prepended to the LLM input to condition generation.
- Core assumption: Users with similar embeddings will benefit from similar virtual token sequences, allowing parameter sharing to be effective.
- Evidence anchors: The paper describes the SPM mapping user embeddings to virtual tokens that, when prepended to LLM input, enables aligned responses with given users.

### Mechanism 3
- Claim: Persona-based steering outperforms both raw LLM generation and demographic-based steering because it captures latent opinion structures.
- Mechanism: By clustering users with similar embeddings into personas, the model can represent opinion groups that cut across demographic lines.
- Core assumption: The opinion clusters identified through embedding and clustering correspond to meaningful social groups with coherent viewpoints.
- Evidence anchors: Analysis reveals clusters with distinct demographic compositions, showing that individuals with different demographic traits can hold similar opinions.

## Foundational Learning

- Concept: Collaborative Filtering and Matrix Factorization
  - Why needed here: Forms the foundation for learning continuous user embeddings from opinion data
  - Quick check question: What is the key difference between user-based and item-based collaborative filtering, and which approach is used in this paper?

- Concept: Graph Convolutional Networks for Recommendation
  - Why needed here: LightGCN is the specific collaborative filtering method used to generate user embeddings
  - Quick check question: How does LightGCN differ from traditional matrix factorization approaches in capturing user-item relationships?

- Concept: Soft Prompting and Parameter-Efficient Fine-Tuning
  - Why needed here: The method used to steer LLMs by mapping user embeddings to virtual tokens
  - Quick check question: What is the key advantage of soft prompting over traditional fine-tuning when adapting LLMs to new tasks or personas?

## Architecture Onboarding

- Component map:
  OpinionQA dataset -> LightGCN embeddings -> K-Means clustering -> Soft-prompting model -> LLM with virtual tokens

- Critical path:
  1. Train LightGCN on user response data to learn user and question embeddings
  2. Cluster users based on embeddings to define personas
  3. Train SPM to map user embeddings to virtual tokens that improve LLM opinion prediction
  4. At inference, use SPM to generate virtual tokens for a target user, prepend to questions, and generate responses

- Design tradeoffs:
  - Embedding dimension (128) vs. model capacity and overfitting risk
  - Number of clusters (6 chosen) vs. granularity of persona representation
  - Shared SPM vs. individual SPMs for each user (parameter efficiency vs. personalization)
  - Choice of LLM scale (1.3B to 7B parameters) vs. performance and computational cost

- Failure signatures:
  - Low prediction accuracy across all baselines indicates issues with the overall approach
  - Large gap between training and validation accuracy suggests overfitting
  - Personas that are not demographically diverse may indicate embedding issues
  - High variance in prediction accuracy across different user groups suggests bias

- First 3 experiments:
  1. Train LightGCN on OpinionQA and visualize user embeddings using t-SNE to verify that users with similar opinions are close together
  2. Apply K-Means clustering to user embeddings with varying k values and evaluate prediction accuracy to find optimal number of personas
  3. Train SPM with a small subset of users and validate that it can effectively steer a small LLM (e.g., GPT-Neo-1.3B) before scaling up

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different choices of the number of clusters (k) in K-Means clustering affect the performance of data-driven personas in steering LLMs?
- Basis in paper: [explicit] The authors mention that they use the "elbow" heuristic to choose k=6 for their experiments, but also show results for k=10, 20, 30, and 50 clusters in Table 4.
- Why unresolved: The paper only presents results for a limited range of k values. It's unclear if there's an optimal number of clusters that maximizes persona effectiveness, or if performance plateaus after a certain point.
- What evidence would resolve it: A systematic evaluation of persona performance across a wider range of k values, possibly with visualization of the elbow curve, would help determine the optimal number of clusters.

### Open Question 2
- Question: How does the performance of data-driven personas compare to using individual user embeddings directly for steering LLMs?
- Basis in paper: [explicit] The authors mention that using 50 clusters converges to the performance of individual user embeddings in Table 4.
- Why unresolved: While the paper shows that personas perform well, it doesn't directly compare their performance to using individual user embeddings for steering. It's unclear if personas offer any advantages over individual embeddings.
- What evidence would resolve it: A direct comparison of persona-based steering versus individual user embedding-based steering on the same tasks would clarify if personas offer any benefits.

### Open Question 3
- Question: How does the choice of context questions (K value) in the Context + Raw Q baseline affect its performance compared to data-driven personas?
- Basis in paper: [explicit] The authors include an ablation study of different K values in Table 7, showing that K=5 performs best for the Context + Raw Q baseline.
- Why unresolved: While the optimal K value is identified for the baseline, it's unclear how the performance of the Context + Raw Q baseline with K=5 compares to data-driven personas across different tasks and datasets.
- What evidence would resolve it: A comprehensive comparison of the Context + Raw Q baseline with K=5 and data-driven personas across multiple tasks and datasets would reveal their relative strengths and weaknesses.

## Limitations

- Data Dependence: The method's effectiveness is tightly coupled to the OpinionQA dataset structure and may not generalize to other domains or response formats
- Cluster Quality: Limited discussion of how optimal number of clusters was determined or whether resulting personas are semantically meaningful
- SPM Architecture: Lacks detailed specification of the soft-prompting model architecture, number of virtual tokens, or training procedure

## Confidence

**High Confidence Claims:**
- Collaborative filtering can learn meaningful user embeddings from opinion response data
- Clustering users based on embeddings can identify groups with distinct demographic compositions
- Soft prompting is a valid method for steering LLM generation

**Medium Confidence Claims:**
- Data-driven personas outperform demographic-based personas in steering LLMs
- The method achieves 57%-77% improvement over baseline approaches
- The personas identified correspond to meaningful opinion groups

**Low Confidence Claims:**
- The method generalizes to other domains beyond the OpinionQA dataset
- The shared soft prompting model is optimal for all personas
- The approach can capture all relevant opinion nuance in the embedding space

## Next Checks

1. **Cluster Quality Validation**: Implement silhouette analysis and qualitative inspection of cluster assignments to verify that the identified personas are semantically meaningful and that k=6 is optimal. Compare clustering results using different embedding dimensions and clustering algorithms to assess robustness.

2. **Cross-Dataset Generalization**: Apply the method to a different opinion dataset with different structure (e.g., continuous ratings rather than multiple-choice questions) to test generalizability. Measure whether the same improvement over demographic-based approaches holds and whether the personas identified are comparable.

3. **Ablation Study on Soft Prompting**: Conduct systematic ablation studies varying the number of virtual tokens, the SPM architecture (e.g., MLP vs. transformer-based), and training objectives to determine which components are most critical for performance. Compare against simpler steering methods like prefix tuning or direct fine-tuning of LLM parameters.