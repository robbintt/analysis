---
ver: rpa2
title: Feedback-guided Data Synthesis for Imbalanced Classification
arxiv_id: '2310.00158'
source_url: https://arxiv.org/abs/2310.00158
tags:
- data
- samples
- synthetic
- classifier
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a feedback-guided data synthesis framework
  to improve classification on imbalanced datasets. The key idea is to leverage a
  pre-trained diffusion model and guide its sampling process using feedback from a
  classifier, promoting the generation of useful synthetic samples that are close
  to the real data distribution and diverse.
---

# Feedback-guided Data Synthesis for Imbalanced Classification

## Quick Facts
- arXiv ID: 2310.00158
- Source URL: https://arxiv.org/abs/2310.00158
- Authors: 
- Reference count: 38
- Primary result: Achieves state-of-the-art results on ImageNet-LT and NICO++ imbalanced datasets, improving underrepresented class accuracy by over 4% and worst group accuracy by over 5% respectively

## Executive Summary
This paper introduces a feedback-guided data synthesis framework to improve classification on imbalanced datasets. The key innovation is leveraging a pre-trained diffusion model and guiding its sampling process using feedback from a classifier, promoting the generation of useful synthetic samples that are close to the real data distribution and diverse. Three feedback criteria are explored: classifier loss, prediction entropy, and hardness score. The framework is validated on ImageNet-LT and NICO++, achieving state-of-the-art results with significant improvements on underrepresented classes.

## Method Summary
The method trains an initial classifier on an imbalanced dataset, then generates synthetic samples using a pre-trained diffusion model guided by classifier feedback. The feedback steers the sampling process towards samples that are challenging or uncertain for the classifier, making them more informative for training. The framework uses dual text-image conditioning to generate samples closer to the real data distribution and applies dropout to the image embedding to increase diversity. The final classifier is trained on the combined real and synthetic dataset using balanced mini-batches.

## Key Results
- On ImageNet-LT, achieves over 4% improvement on underrepresented classes while using half the amount of synthetic data compared to previous state-of-the-art
- On NICO++, achieves over 5% improvement in worst group accuracy
- Demonstrates significant improvements in accuracy for few-shot classes across both datasets
- Ablation studies show that feedback-guided sampling outperforms baseline diffusion model generation and traditional data augmentation methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Feedback-guided sampling directs the generative model to produce synthetic samples that are useful for improving classifier performance on underrepresented classes.
- Mechanism: The classifier's feedback (e.g., loss, entropy, hardness score) is used to steer the sampling process of the pre-trained diffusion model. This steers generation towards samples that are challenging or uncertain for the classifier, which are more informative for training.
- Core assumption: The classifier's uncertainty or difficulty metrics correlate with sample usefulness for representation learning.
- Evidence anchors:
  - [abstract] "We hypothesize that these performance gains are limited by the lack of feedback from the classifier to the generative model, which would promote the usefulness of the generated samples to improve the classifier's performance."
  - [section 3.1] "We use the classifier feedback to steer the generation process towards generating useful synthetic data."
  - [corpus] Weak - no direct citations in corpus about feedback-guided sampling in generative models.
- Break condition: If the classifier's feedback does not correlate with sample usefulness (e.g., if the classifier is too confident or the feedback metrics are poorly aligned with downstream task needs).

### Mechanism 2
- Claim: Dual text-image conditioning generates synthetic samples that are closer to the real data distribution, reducing stylistic bias and homonym ambiguity.
- Mechanism: Conditioning the diffusion model on both a text prompt (class label) and a real image from the same class provides richer information, steering the generative model to produce samples more faithful to the real data style and semantics.
- Core assumption: Real image embeddings provide sufficient semantic and stylistic information to guide the generative model effectively.
- Evidence anchors:
  - [section 3.2] "We identify three scenarios where using only text prompt results in synthetic samples that are not close to the real data... To alleviate the above-described issues, we borrow from the generative models' literature a dual-conditioning technique."
  - [section 4.3] "By leveraging image and text conditioning simultaneously (row 2), we improve both FID and density, suggesting that generated samples are closer to the ImageNet-LT validation set."
  - [corpus] Weak - no direct citations in corpus about dual conditioning in diffusion models.
- Break condition: If the real image conditioning introduces bias or limits diversity too much, or if the generative model cannot effectively combine dual conditioning.

### Mechanism 3
- Claim: Applying dropout to the image embedding during conditioning increases the conditional diversity of synthetic data, improving downstream classifier robustness.
- Mechanism: Dropout randomly sets parts of the image embedding to zero, introducing variability and breaking the deterministic link between the conditioning image and the generated sample, thus promoting diversity.
- Core assumption: Increased diversity in synthetic samples leads to better generalization and robustness in the downstream classifier.
- Evidence anchors:
  - [section 3.3] "By applying random dropout to the embedding of the conditioning image, we effectively introduce variability into the information that guides the generative model. This stochasticity breaks the deterministic link between the conditioning image and the generated sample, thereby promoting diversity in the generated images."
  - [section 4.3] "When applying dropout to the image embedding (row 3), we observe a positive effect on both FID and coverage, indicating a higher diversity of the generated samples."
  - [corpus] Weak - no direct citations in corpus about dropout in image embedding for diversity.
- Break condition: If dropout removes too much information, causing the generative model to produce low-quality or irrelevant samples.

## Foundational Learning

- Concept: Diffusion models and denoising score matching
  - Why needed here: The framework relies on a pre-trained diffusion model for generating synthetic data; understanding its mechanics is crucial for implementing feedback-guided sampling.
  - Quick check question: How does the reverse sampling process in diffusion models generate images from noise, and how can classifier feedback be incorporated into this process?

- Concept: Classifier-guided sampling and classifier-free guidance in diffusion models
- Why needed here: The feedback-guided synthesis extends the idea of classifier guidance by using the classifier's own predictions as feedback, so understanding the base mechanism is essential.
- Quick check question: What is the difference between classifier guidance and classifier-free guidance, and how does feedback guidance extend these concepts?

- Concept: Long-tailed and group-imbalanced classification
  - Why needed here: The framework is evaluated on ImageNet-LT (class-imbalanced) and NICO++ (group-imbalanced) datasets; understanding these problem settings is key to appreciating the method's contributions.
  - Quick check question: How do class-imbalanced and group-imbalanced datasets differ, and what are the challenges in training classifiers on such data?

## Architecture Onboarding

- Component map: Pre-trained diffusion model -> Classifier -> Feedback criteria -> Dual conditioning -> Dropout -> Synthetic data -> Final classifier
- Critical path:
  1. Train initial classifier on real imbalanced data
  2. Generate synthetic data using pre-trained diffusion model with dual conditioning
  3. Apply feedback-guided sampling to steer generation towards useful samples
  4. Retrain classifier on combined real and synthetic data

- Design tradeoffs:
  - Feedback strength (ω) vs. generation quality: Higher feedback may lead to more challenging but potentially noisier samples
  - Dropout rate: Higher dropout increases diversity but may reduce sample quality
  - Number of synthetic samples: More samples improve balance but increase computational cost

- Failure signatures:
  - Low diversity in generated samples: Check dropout rate and feedback strength
  - Generated samples not close to real data: Check dual conditioning and LDM conditioning strength
  - Classifier not improving: Check feedback criteria alignment and classifier training setup

- First 3 experiments:
  1. Generate synthetic data using vanilla LDM (text-only conditioning) and evaluate FID/density vs. real data
  2. Apply dual text-image conditioning and compare FID/density to baseline
  3. Implement feedback-guided sampling (entropy criterion) and evaluate impact on classifier accuracy on few-shot classes

## Open Questions the Paper Calls Out
- Question: How does the effectiveness of feedback-guided sampling change when using online feedback during classifier training rather than one-shot feedback from a fully trained classifier?
- Question: How do the quality and diversity metrics (FID, density, coverage) correlate with the actual usefulness of synthetic samples for representation learning?
- Question: What are the limitations of the current state-of-the-art generative models in terms of image realism and representation diversity, and how do these limitations affect the effectiveness of feedback-guided synthesis?

## Limitations
- Heavy reliance on a pre-trained diffusion model, with performance bounded by the quality and coverage of the underlying model
- Requires careful hyperparameter tuning, particularly for feedback strength and dropout rate
- Effectiveness depends on the classifier's ability to provide meaningful feedback, which may be compromised if the initial classifier is too weak or overfits the imbalanced training data

## Confidence

| Claim | Confidence |
|-------|------------|
| Feedback-guided sampling improves classifier performance | Medium |
| Dual conditioning generates samples closer to real data distribution | Medium |
| Dropout increases diversity of generated samples | Low-Medium |

## Next Checks
1. Test the framework on additional imbalanced datasets beyond ImageNet-LT and NICO++ to assess generalizability
2. Compare performance with other synthetic data generation methods (GANs, VAEs) using identical classifier architectures and training protocols
3. Conduct ablation studies on the feedback strength parameter (ω) to determine optimal settings across different imbalance ratios and dataset characteristics