---
ver: rpa2
title: 'Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning'
arxiv_id: '2308.05522'
source_url: https://arxiv.org/abs/2308.05522
tags:
- single-step
- synthesis
- planning
- routes
- retrosynthesis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the impact of different single-step retrosynthesis
  models on multi-step synthesis planning. Four models (AZF, LocalRetro, Chemformer,
  MHNreact) trained on various datasets (USPTO-50k, USPTO-PaRoutes-1M, AZ-1M, AZ-18M)
  are evaluated using a common multi-step algorithm.
---

# Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning

## Quick Facts
- **arXiv ID**: 2308.05522
- **Source URL**: https://arxiv.org/abs/2308.05522
- **Reference count**: 40
- **Primary result**: Single-step retrosynthesis model choice significantly impacts multi-step synthesis planning success, with USPTO-50k proving insufficient for benchmarking.

## Executive Summary
This study investigates how different single-step retrosynthesis models affect multi-step synthesis planning outcomes. Four models (AZF, LocalRetro, Chemformer, MHNreact) trained on datasets ranging from USPTO-50k to AZ-18M are evaluated using a common multi-step algorithm. The research reveals that high single-step accuracy on USPTO-50k does not guarantee multi-step planning success, highlighting the need for more diverse and larger training datasets. The choice of single-step model can improve synthesis planning success rates by up to 28% over baseline AZF. Additionally, each model produces unique synthesis routes with different characteristics, and route accuracy varies significantly across models.

## Method Summary
The study trains four single-step retrosynthesis models on four different datasets (USPTO-50k, USPTO-PaRoutes-1M, AZ-1M, AZ-18M) using respective architectures. Each model is then integrated into the Retro* multi-step planning algorithm via a ModelZoo interface. The evaluation is conducted on two multi-step planning datasets: Caspyrus10k (10,000 clustered bioactive molecules) and PaRoutes (10,000 gold-standard synthesis routes). The planning process uses an 8-hour time limit with 200 iterations and top-50 reactions per iteration. Performance is measured through single-step top-n accuracy, success rates, solved routes, search times, route accuracy, and building block accuracy metrics.

## Key Results
- High single-step accuracy on USPTO-50k does not reliably predict multi-step synthesis planning success.
- USPTO-50k is insufficient for benchmarking due to limited diversity and scalability issues.
- Choice of single-step model significantly impacts synthesis planning success rate (+28% improvement over baseline AZF).

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Single-step retrosynthesis accuracy measured on USPTO-50k does not reliably predict multi-step synthesis planning success.
- Mechanism: High accuracy on small, homogeneous dataset does not generalize to larger, more diverse datasets; thus models optimized for small datasets fail in real-world multi-step contexts.
- Core assumption: Model performance on single-step prediction translates directly to multi-step planning effectiveness.
- Evidence anchors:
  - [abstract] "High single-step accuracy doesn't guarantee multi-step success, highlighting the need to evaluate models within synthesis planning."
  - [section 4.1] "single-step model performance metrics do not directly transfer to multi-step route planning success."
  - [corpus] Weak—no direct citations on generalization failure; requires inference.

### Mechanism 2
- Claim: Increasing dataset size and diversity improves multi-step synthesis planning success rates.
- Mechanism: Larger datasets expose models to more reaction classes and patterns, enabling richer reaction networks for search algorithms to traverse.
- Core assumption: Multi-step success depends on the breadth and diversity of reactions available to the single-step model.
- Evidence anchors:
  - [section 4.2] "Models trained on the USPTO-PaRoutes-1M dataset have considerable performance differences... compared to USPTO-50k."
  - [section 4.2] "the availability of more reaction data can improve the success rate of route planning."
  - [corpus] Weak—no direct citation linking dataset diversity to multi-step success; inferred from results.

### Mechanism 3
- Claim: Different single-step models find unique synthesis routes, affecting chemical validity and diversity.
- Mechanism: Model architecture (template-based vs. template-free) and training data influence which reactions are proposed, leading to distinct route characteristics and overlap patterns.
- Core assumption: Chemical validity and route diversity are influenced by the single-step model's inductive biases and data exposure.
- Evidence anchors:
  - [section 4.3] "different models produce different route characteristics... model predicts a much higher number of building blocks, multi-molecular reactions..."
  - [section 4.3] "routes produced by methods that rely on reaction templates... tend to cluster together more frequently."
  - [corpus] Weak—no direct citations on clustering; inferred from clustering analysis.

## Foundational Learning

- Concept: Difference between single-step retrosynthesis and multi-step synthesis planning.
  - Why needed here: Clarifies why evaluating single-step models in isolation is insufficient for real-world synthesis planning.
  - Quick check question: What is the key difference between predicting a single reaction and finding a complete synthesis route?

- Concept: Role of reaction templates in retrosynthesis models.
  - Why needed here: Explains why template-based models may have limitations on diverse datasets and affect route validity.
  - Quick check question: How do template-based and template-free models differ in handling novel reactions?

- Concept: Search algorithms for multi-step synthesis planning (e.g., Retro*, MCTS).
  - Why needed here: Understanding how single-step models are integrated into tree search is crucial for interpreting performance results.
  - Quick check question: What guides the tree search in Retro*—the single-step model's predicted probabilities or another heuristic?

## Architecture Onboarding

- Component map:
  Single-step models (AZF, LocalRetro, Chemformer, MHNreact) -> Multi-step planner (Retro*) -> Evaluation datasets (Caspyrus10k, PaRoutes) -> Building block set (Zinc)

- Critical path:
  1. Train single-step models on various datasets.
  2. Integrate each model into Retro* via ModelZoo interface.
  3. Run multi-step planning on Caspyrus10k and PaRoutes.
  4. Compare success rates, solved routes, and accuracy metrics.

- Design tradeoffs:
  - Template-based models: Faster inference, constrained by known templates, may miss novel routes.
  - Template-free models: Slower inference, potentially more novel routes, risk chemical invalidity.
  - Search time limit (8 hours): Balances thoroughness with computational feasibility.

- Failure signatures:
  - Low success rate despite high single-step accuracy: Model overfits small dataset.
  - Very low model calls with high search time: Model inference is too slow for practical use.
  - Poor route accuracy: Model proposes chemically invalid or non-gold-standard routes.

- First 3 experiments:
  1. Train AZF and LocalRetro on USPTO-50k, evaluate multi-step success on Caspyrus10k.
  2. Train Chemformer on USPTO-PaRoutes-1M, measure success rate and search time.
  3. Compare route clustering between AZF and Chemformer on same dataset to quantify uniqueness.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a single-step retrosynthesis model's performance on USPTO-50k be used to reliably predict its performance on larger, more diverse datasets like USPTO-PaRoutes-1M or AZ-1M?
- Basis in paper: [explicit] The paper demonstrates that performance rankings between models are not transferable between USPTO-50k and larger datasets, indicating that high single-step accuracy on USPTO-50k does not guarantee similar performance on larger, more diverse datasets.
- Why unresolved: The paper only compares performance across a few datasets, and the reasons for the lack of transferability are not fully explored. It is unclear if there are specific characteristics of USPTO-50k that limit its predictive value.
- What evidence would resolve it: A systematic study comparing model performance across a wider range of datasets with varying sizes and diversities, along with an analysis of the underlying reasons for performance differences.

### Open Question 2
- Question: What is the optimal balance between search time and the number of single-step model calls in multi-step synthesis planning to maximize the discovery of chemically valid synthesis routes?
- Basis in paper: [inferred] The paper shows that different single-step models have varying inference speeds and that the number of single-step model calls within a set time limit can affect the discovery of synthesis routes. However, it does not explore the optimal balance between these factors.
- Why unresolved: The paper focuses on comparing different models rather than optimizing the search algorithm parameters. The relationship between search time, model calls, and the quality of discovered routes is not fully explored.
- What evidence would resolve it: A study systematically varying the maximum search time and the number of single-step model calls, and evaluating the impact on the discovery of chemically valid synthesis routes.

### Open Question 3
- Question: How can the chemical validity of generated synthesis routes be reliably assessed, and what factors contribute to the generation of non-chemically valid routes?
- Basis in paper: [explicit] The paper highlights the importance of chemical validity and compares the ability of different models to recover gold-standard routes. However, it acknowledges the lack of in-silico synthesis feasibility evaluation and suggests that future work should address this issue.
- Why unresolved: The paper does not provide a comprehensive framework for assessing chemical validity or identify the specific factors that contribute to the generation of non-chemically valid routes. It also does not explore the potential of using molecular dynamics or quantum chemistry prediction for this purpose.
- What evidence would resolve it: Development of a robust framework for assessing chemical validity, including the incorporation of reagents, conditions, and yields into synthesis planning, and the use of advanced computational methods to evaluate the feasibility of proposed reactions.

## Limitations

- The study relies heavily on inferred relationships between dataset size/diversity and multi-step planning success, with limited direct empirical validation across heterogeneous reaction types.
- While model performance is extensively compared, the specific architectural differences between Chemformer and MHNreact are not deeply analyzed.
- The study uses a fixed Retro* configuration but doesn't explore how sensitive multi-step success is to hyperparameter variations.

## Confidence

**High Confidence**: The finding that high single-step accuracy doesn't guarantee multi-step success is strongly supported by direct experimental evidence across multiple models and datasets.

**Medium Confidence**: The claim that USPTO-50k is insufficient for benchmarking is well-supported by the data showing performance degradation on larger datasets.

**Medium Confidence**: The assertion that different models produce unique routes with varying characteristics is supported by clustering analysis and metric comparisons.

## Next Checks

1. **Dataset Diversity Experiment**: Systematically evaluate model performance on a benchmark containing reactions from multiple chemical domains (pharmaceutical, materials, natural products) to directly test generalization claims beyond the current datasets.

2. **Architecture Ablation Study**: Train Chemformer and MHNreact on identical datasets with controlled architectural variations to isolate the impact of model design versus training data on multi-step planning success.

3. **Hyperparameter Sensitivity Analysis**: Vary Retro* search parameters (time limits, top-k reactions, cost functions) across all models to quantify how search configuration interacts with single-step model performance in multi-step planning.