---
ver: rpa2
title: 'Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented
  Large Language Models'
arxiv_id: '2310.14696'
source_url: https://arxiv.org/abs/2310.14696
tags:
- answer
- question
- questions
- long-form
- tree
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Tree of Clarifications (ToC) is a retrieval-augmented LLM framework
  for answering ambiguous questions (AQ) in open-domain QA. It recursively constructs
  a tree of disambiguated questions (DQ) via few-shot prompting using retrieved passages,
  enabling exploration of diverse interpretations.
---

# Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models

## Quick Facts
- arXiv ID: 2310.14696
- Source URL: https://arxiv.org/abs/2310.14696
- Authors: 
- Reference count: 28
- Outperforms fully-supervised baselines on ASQA benchmark by 7.3 D-F1 and 2.9 ROUGE-L points

## Executive Summary
Tree of Clarifications (ToC) is a retrieval-augmented LLM framework designed to answer ambiguous questions in open-domain QA by recursively constructing a tree of disambiguated questions. The framework leverages external knowledge through retrieval systems and uses few-shot prompting to explore diverse interpretations of ambiguous questions systematically. On the ASQA benchmark, ToC achieves 33.7 Disambig-F1 and 39.7 ROUGE-L, outperforming fully-supervised baselines trained on the full dataset by 7.3 and 2.9 points respectively.

## Method Summary
ToC recursively constructs a tree of disambiguated questions (DQs) starting from an ambiguous question (AQ) through retrieval-augmented clarification (RAC). It retrieves relevant passages using ColBERT and Bing, then uses few-shot prompting to generate DQs and answers. The framework expands the tree breadth-first, pruning factually inconsistent or irrelevant DQs through self-verification. Finally, it aggregates all valid DQs and generates a comprehensive long-form answer addressing all interpretations.

## Key Results
- Achieves 33.7 Disambig-F1 on ASQA, outperforming fully-supervised baselines by 7.3 points
- Achieves 39.7 ROUGE-L on ASQA, outperforming fully-supervised baselines by 2.9 points
- Retrieval-augmentation and tree structure are identified as key contributors to strong performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tree structure enables exploration of diverse ambiguity dimensions
- Mechanism: Breadth-first expansion from root AQ node generates multiple child DQs at each level, systematically covering different interpretations (e.g., medal types vs Olympic types)
- Core assumption: Multiple interpretations can be meaningfully represented as a tree structure where each node represents a distinct clarification
- Evidence anchors:
  - [abstract] "It recursively constructs a tree of disambiguations for the AQ"
  - [section 3.2] "Starting from the root node with AQ, it progressively inserts child nodes by recursively performing RAC"
  - [corpus] Weak - only 5 related papers mention tree structures, none specifically for ambiguity handling
- Break condition: Tree terminates when max valid nodes reached or max depth reached, preventing infinite exploration

### Mechanism 2
- Claim: Retrieval augmentation provides factual knowledge for accurate disambiguations
- Mechanism: ColBERT and Bing retrieve relevant passages which are reranked and used to ground LLM clarifications in real-world facts
- Core assumption: External knowledge sources contain the specific facts needed to disambiguate AQs accurately
- Evidence anchors:
  - [abstract] "leveraging external knowledge"
  - [section 3.1] "first, relevant passages for the AQ are retrieved" and "choose top-k passages and augment them to a prompt"
  - [section 4.2] "Integrating retrieval systems largely contributes to accurate and diverse disambiguations"
- Break condition: If retrieved passages lack relevant information, disambiguations become inaccurate or hallucinated

### Mechanism 3
- Claim: Self-verification pruning removes factually inconsistent or irrelevant DQs
- Mechanism: Each generated DQ-answer pair is verified against the original AQ for factual consistency before inclusion in final answer
- Core assumption: LLM can accurately judge whether a DQ-answer pair is consistent with the original AQ's intent
- Evidence anchors:
  - [abstract] "pruned as necessary"
  - [section 3.2] "we check the factual coherency between the answers in a target node and the AQ in the root node"
  - [section 4.2] "Our pruning method precisely identifies helpful disambiguations"
- Break condition: If verification prompt is ambiguous, pruning may incorrectly remove valid interpretations

## Foundational Learning

- Concept: Tree data structures and traversal algorithms
  - Why needed here: Tree structure is the core architectural innovation for exploring ambiguity dimensions
  - Quick check question: Can you explain the difference between BFS and DFS and why BFS is preferred for this application?

- Concept: Retrieval-augmented generation principles
  - Why needed here: RAC component depends on effective integration of retrieval and generation
  - Quick check question: What are the key differences between dense retrieval (ColBERT) and keyword-based retrieval (Bing)?

- Concept: Few-shot prompting techniques
  - Why needed here: Model learns to disambiguate without full fine-tuning using in-context examples
  - Quick check question: How does dynamically selecting k-shot examples with nearest neighbor search improve performance?

## Architecture Onboarding

- Component map: User Question → Retrieval Systems (ColBERT + Bing) → RAC Component → Tree Structure (BFS expansion + Pruning) → Answer Generation
- Critical path: Question → Retrieval → RAC → Tree Expansion → Pruning → Answer Generation
- Design tradeoffs: Multiple LLM calls increase cost but improve coverage vs. single call approaches; BFS explores breadth but may miss deep interpretations
- Failure signatures: Poor retrieval coverage → hallucinated answers; inadequate pruning → irrelevant DQs; shallow tree → incomplete coverage
- First 3 experiments:
  1. Test retrieval coverage on 100 sampled AQs using answer coverage metric
  2. Validate pruning effectiveness by comparing Answer-F1 with/without self-verification
  3. Measure tree expansion efficiency by tracking valid nodes generated per expansion step

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Tree of Clarifications (ToC) framework generalize to different sizes or types of Large Language Models (LLMs)?
- Basis in paper: [inferred]
- Why unresolved: The paper does not explicitly discuss the generalizability of the ToC framework to different sizes or types of LLMs. It only mentions that the framework is model-agnostic, but does not provide any concrete evidence or experiments to support this claim.
- What evidence would resolve it: Experiments comparing the performance of ToC using different sizes or types of LLMs would provide evidence for its generalizability.

### Open Question 2
- Question: How does the Tree of Clarifications (ToC) framework perform on benchmarks other than ASQA?
- Basis in paper: [inferred]
- Why unresolved: The paper only evaluates the ToC framework on the ASQA benchmark, so its performance on other benchmarks is unknown.
- What evidence would resolve it: Experiments evaluating the ToC framework on other benchmarks would provide evidence for its performance on different datasets.

### Open Question 3
- Question: How can the cost of multiple prompting in the Tree of Clarifications (ToC) framework be reduced?
- Basis in paper: [explicit]
- Why unresolved: The paper mentions that the cost of multiple prompting is not negligible, but does not propose any solutions to reduce this cost.
- What evidence would resolve it: Proposals or experiments that demonstrate methods to reduce the cost of multiple prompting in the ToC framework would provide evidence for its feasibility.

## Limitations
- Heavy reliance on external retrieval systems that could fail if retrieval coverage is inadequate
- Multiple LLM calls across tree structure increase computational cost and limit practical deployment
- Specific prompt formats, few-shot examples, and self-verification criteria are not fully detailed

## Confidence
- High confidence: Core mechanism of retrieval-augmented prompting and tree-based approach for exploring multiple interpretations
- Medium confidence: Tree structure specifically enables exploration of diverse ambiguity dimensions (relative contribution unclear)
- Low confidence: Reproducibility of reported performance without detailed implementation specifications

## Next Checks
1. Test retrieval coverage on 100 randomly sampled ambiguous questions from ASQA using the answer coverage metric
2. Conduct systematic ablation study comparing ToC performance with different combinations of components
3. Evaluate ToC on an alternative ambiguous question dataset (such as AmbigNQ) to assess generalization beyond ASQA