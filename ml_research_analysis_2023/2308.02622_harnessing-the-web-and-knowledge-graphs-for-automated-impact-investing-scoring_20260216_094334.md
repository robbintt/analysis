---
ver: rpa2
title: Harnessing the Web and Knowledge Graphs for Automated Impact Investing Scoring
arxiv_id: '2308.02622'
source_url: https://arxiv.org/abs/2308.02622
tags:
- data
- scores
- companies
- graph
- company
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents an automated system for predicting company alignment
  with the UN Sustainable Development Goals (SDGs) using web data and knowledge graphs.
  The system collects and filters relevant texts from sustainability reports, Wikipedia,
  and news, as well as a knowledge graph of company relationships.
---

# Harnessing the Web and Knowledge Graphs for Automated Impact Investing Scoring

## Quick Facts
- arXiv ID: 2308.02622
- Source URL: https://arxiv.org/abs/2308.02622
- Reference count: 40
- Key result: Achieves micro average F1 score of 0.89 for predicting company SDG alignment scores using web data and knowledge graphs

## Executive Summary
This paper presents an automated system for predicting company alignment with the UN Sustainable Development Goals (SDGs) using web data and knowledge graphs. The system collects and filters relevant texts from sustainability reports, Wikipedia, and news, as well as a knowledge graph of company relationships. Multiple classifiers are trained on this data to predict SDG scores, achieving a micro average F1 score of 0.89. Textual features are most important for performance, while graph information is only beneficial when condensed. The authors propose using explanations like LIME to help domain experts interpret model predictions. This system enables efficient and scalable SDG scoring compared to manual methods.

## Method Summary
The authors developed a system that collects textual data from sustainability reports, Wikipedia descriptions, and news articles, then filters it for relevance to SDGs. This textual data is converted into bag-of-words representations and combined with knowledge graph information about company relationships. Three classifiers are trained: Balanced Random Forest, Graph Convolutional Network, and Relational Graph Convolutional Network. The system achieves a micro average F1 score of 0.89 for predicting SDG alignment scores ranging from -3 to 3. LIME and GNNExplainer are used to provide interpretable explanations for model predictions.

## Key Results
- Achieved micro average F1 score of 0.89 for SDG score prediction
- Textual features from web data are most important for model performance
- Graph information only improves performance when condensed to company-company relationships
- LIME explanations can identify relevant terms contributing to predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Textual features from web data sources are the primary drivers of SDG score prediction accuracy.
- Mechanism: The system collects and filters large amounts of textual data from sustainability reports, Wikipedia descriptions, and news articles. These texts are converted into bag-of-words representations that capture relevant terms associated with each SDG. The Balanced Random Forest classifier uses these features to learn patterns linking text content to SDG alignment scores.
- Core assumption: The textual descriptions contain sufficient signal about company activities to predict SDG alignment without requiring deep domain expertise.
- Evidence anchors:
  - [abstract] "Textual features are most important for performance"
  - [section 4.1] "we find that textual features are responsible for the ability to predict SDG scores, and adding the graph... does not bring significant improvements"
  - [corpus] Weak - no direct citation of textual data effectiveness, only general SDG classification papers
- Break condition: If company textual disclosures become too generic, overly focused on marketing, or cease to mention SDG-relevant activities, the model's accuracy would degrade.

### Mechanism 2
- Claim: Graph information improves SDG prediction only when condensed into company-company relationships.
- Mechanism: The original knowledge graph contains many node types with varying features. When compressed into a company-only graph, each node represents a company and edges represent relationships. The Graph Convolutional Network can then learn from these relationships to improve predictions.
- Core assumption: Companies with similar SDG scores are likely to be connected in the graph through various relationships (ownership, industry, location).
- Evidence anchors:
  - [section 3.3] "the GCN model... the graph consists exclusively of companies associated with textual features"
  - [section 4.1] "In the case of the R-GCN, the KG can even yield lower performance... only company nodes had textual features"
  - [corpus] Weak - no direct citation of graph condensation benefits, only general GNN papers
- Break condition: If the graph becomes too sparse (few connections between companies) or too dense (all companies connected), the GCN would lose discriminative power.

### Mechanism 3
- Claim: LIME explanations help domain experts interpret and trust model predictions.
- Mechanism: For textual features, LIME identifies the most relevant terms in the bag-of-words representation that contribute to a particular SDG score prediction. For graph features, GNNExplainer identifies important neighbors and connections.
- Core assumption: Domain experts can validate predictions by examining the terms and relationships highlighted by the explanation methods.
- Evidence anchors:
  - [abstract] "We further describe how the integration of the models for its use by humans can be facilitated by providing explanations"
  - [section 4.2] "Fig. 2 (a)... LIME attributes to the terms wind and energy"
  - [corpus] Weak - no direct citation of LIME effectiveness, only general explainable AI papers
- Break condition: If the explanations become too complex or highlight irrelevant terms/connections, experts may lose trust in the system.

## Foundational Learning

- Concept: Bag-of-words text representation
  - Why needed here: Converts unstructured text into numerical features that machine learning models can process
  - Quick check question: What is the dimensionality of the BOW representation if we use a vocabulary of 10,000 words?

- Concept: Graph Neural Networks (GCNs)
  - Why needed here: Learns node representations by aggregating information from neighboring nodes in the company relationship graph
  - Quick check question: How does a GCN layer update a node's representation using its neighbors?

- Concept: F1 score (micro vs macro)
  - Why needed here: Evaluates classification performance across multiple SDG score classes with imbalanced frequencies
  - Quick check question: Why would micro F1 be higher than macro F1 when some classes are rare?

## Architecture Onboarding

- Component map:
  Web crawlers → Text extraction → BOW vectorizer → Balanced Random Forest classifier
  Web crawlers → Graph builder → GCN/R-GCN → Graph-based classifier
  LIME/GNNExplainer → Explanation generation → Human interface

- Critical path: Web data collection → Relevance filtering → Model training → Prediction → Explanation

- Design tradeoffs:
  - More text sources increase coverage but also noise and computational cost
  - Including more KG relationships adds information but increases model complexity
  - Simpler models (BRF) are more interpretable but may miss complex patterns

- Failure signatures:
  - Low F1 scores indicate poor feature relevance or model capacity issues
  - High variance between runs suggests overfitting or unstable data pipeline
  - Explanations highlighting irrelevant terms indicate feature noise or model confusion

- First 3 experiments:
  1. Train BRF on BOW features only with default hyperparameters; evaluate micro/macro F1
  2. Train GCN on company-only graph; compare performance to BRF
  3. Generate LIME explanations for sample predictions; manually validate relevance of highlighted terms

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective are the graph features (Wikidata KG) compared to textual features for predicting SDG scores?
- Basis in paper: [explicit] The paper states that "textual features are responsible for the performance of the classifiers, while information from the graph is only beneficial when it is condensed."
- Why unresolved: The paper only provides a comparison between using textual features alone versus using condensed graph features. It does not provide a detailed analysis of the effectiveness of using the full Wikidata KG graph features versus textual features.
- What evidence would resolve it: A direct comparison of the performance of the models using full KG graph features versus textual features would provide evidence.

### Open Question 2
- Question: How can the model be improved to detect corporate greenwashing?
- Basis in paper: [explicit] The paper mentions that "we may want to explicitly search and adjust for possible corporate greenwashing."
- Why unresolved: The paper does not provide any details on how this could be achieved or what methods could be used.
- What evidence would resolve it: Research on methods for detecting greenwashing in corporate sustainability reports and how these methods could be integrated into the model would provide evidence.

### Open Question 3
- Question: How useful are the explanations provided by LIME and GNNExplainer to domain experts in interpreting the model predictions?
- Basis in paper: [explicit] The paper states that "the use of LIME enables term relevance visualization, offering insights into the factors influencing model predictions" and that "we plan to carry out a rigorous evaluation that quantifies how useful the explanations are to domain experts."
- Why unresolved: The paper does not provide any results from such an evaluation.
- What evidence would resolve it: A user study where domain experts rate the usefulness of the explanations in interpreting the model predictions would provide evidence.

## Limitations

- Reliance on publicly available web data may lead to incomplete or biased coverage, particularly for smaller companies with limited reporting
- Knowledge graph condensation process discards potentially valuable relationship information beyond company-to-company connections
- Explanation mechanisms (LIME, GNNExplainer) have not been validated with actual domain experts

## Confidence

- Textual feature importance: Medium
- Graph information utility: Low-Medium  
- Explanation mechanism effectiveness: Low
- Overall system performance: Medium

## Next Checks

1. Conduct a blind test with domain experts evaluating a sample of predictions and their explanations to assess practical utility and trust.
2. Test model performance on a temporally separated dataset to evaluate robustness to changing company reporting practices and SDG focus areas.
3. Compare system predictions against a benchmark set of manually scored companies not used in training to assess real-world accuracy.