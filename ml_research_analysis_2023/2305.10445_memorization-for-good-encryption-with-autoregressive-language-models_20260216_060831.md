---
ver: rpa2
title: 'Memorization for Good: Encryption with Autoregressive Language Models'
arxiv_id: '2305.10445'
source_url: https://arxiv.org/abs/2305.10445
tags:
- memorization
- message
- random
- selm
- ciphertext
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents SELM, the first symmetric encryption algorithm
  based on autoregressive language models (LMs). The key idea is to use LM memorization
  in a random subspace to encode arbitrary data into a compact real-valued vector,
  which can then be losslessly decoded to the original message.
---

# Memorization for Good: Encryption with Autoregressive Language Models

## Quick Facts
- arXiv ID: 2305.10445
- Source URL: https://arxiv.org/abs/2305.10445
- Reference count: 40
- One-line primary result: First symmetric encryption algorithm using autoregressive LMs that reduces ciphertext size by 100x while achieving promising security through memorization in random subspaces.

## Executive Summary
This paper presents SELM, the first symmetric encryption algorithm based on autoregressive language models (LMs). The key innovation is using LM memorization in a random subspace to encode arbitrary data into a compact real-valued vector, which can then be losslessly decoded to the original message. By optimizing a low-dimensional parameter vector in a random subspace, SELM solves the traditional problems of parameter-based encryption: large ciphertext size and security vulnerabilities. The authors demonstrate that LMs can memorize random noise and long sequences of English text, and propose an empirical variant of the IND-CPA game to evaluate SELM's security, finding that simple regularization strategies can significantly improve security.

## Method Summary
SELM encrypts messages by fine-tuning a pre-trained autoregressive LM in a random subspace to memorize the message through next-token prediction. The process involves tokenizing the message with a UUID prompt, optimizing a low-dimensional parameter vector (d << D) in a random subspace parameterized by a secret key, and transmitting only the optimized vector. Decryption uses the same secret key to reconstruct the projection matrix and regenerate the message through greedy decoding. The method employs Fastfood transforms for efficient projection and introduces regularization strategies to improve security by making ciphertext distributions indistinguishable across different messages.

## Key Results
- Language models can perfectly memorize random bytes and long sequences of English text when optimized in random subspaces
- Random subspace optimization reduces ciphertext size by over 100x compared to full parameter encryption
- Empirical IND-CPA evaluation shows SELM has promising security properties when using appropriate regularization strategies

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Autoregressive LMs can memorize arbitrary data when fine-tuned in a low-dimensional random subspace.
- **Mechanism:** The language model's over-parameterized structure allows it to store arbitrary sequences of tokens through parameter updates in a constrained subspace. By projecting a low-dimensional vector into the full parameter space via a random projection matrix, the model can be optimized to predict the target sequence exactly, even if that sequence is random noise or structured text.
- **Core assumption:** The intrinsic dimension of the memorization task is low enough that a small number of parameters (d ≪ D) can represent the necessary changes to the model.
- **Evidence anchors:**
  - [abstract] "We show that autoregressive LMs can encode arbitrary data into a compact real-valued vector (i.e., encryption) and then losslessly decode the vector to the original message (i.e., decryption) via random subspace optimization and greedy decoding."
  - [section 4] "We observe that LMs optimized in a random subspace can perfectly memorize perfectly random data. In Fig. 3a, GPT-2 with 1,000 free parameters memorizes random orderings of bytes in under 1,000 epochs."
- **Break condition:** If the memorization task's intrinsic dimension exceeds the chosen d, the model will fail to perfectly memorize the data, leading to incomplete decryption.

### Mechanism 2
- **Claim:** Random subspace optimization simultaneously solves the size and security problems of parameter-based encryption.
- **Mechanism:** Instead of transmitting the full parameter change vector (∆θD), only the low-dimensional change vector (∆θd) is sent. The random projection matrix P, parameterized by a secret key k, ensures that without knowledge of P, the ciphertext cannot be mapped back to the original parameter space to recover the message.
- **Core assumption:** The projection matrix P is infeasible to reconstruct without the secret key k, making the ciphertext secure against unauthorized decryption.
- **Evidence anchors:**
  - [abstract] "We propose the first symmetric encryption algorithm with autoregressive language models (SELM). We show that autoregressive LMs can encode arbitrary data into a compact real-valued vector (i.e., encryption) and then losslessly decode the vector to the original message (i.e., decryption) via random subspace optimization and greedy decoding."
  - [section 3] "Second, we propose a security-motivated form of random subspace optimization: we parameterize the random projection P by Alice and Bob's secret key k so Pk is a deterministic function of k."
- **Break condition:** If an attacker can reconstruct the projection matrix P (e.g., by knowing the secret key k or breaking the random projection scheme), they can decrypt the ciphertext.

### Mechanism 3
- **Claim:** Simple regularization strategies can improve SELM's security by making ciphertext distributions indistinguishable across different messages.
- **Mechanism:** Regularization terms are added to the loss function to enforce properties like L2 norm consistency or distributional similarity to a normal distribution. This reduces patterns in the ciphertext that could be exploited by machine learning-based attacks to distinguish between messages.
- **Core assumption:** Reducing statistical differences between ciphertexts for different messages makes them indistinguishable to classifiers, thereby improving security.
- **Evidence anchors:**
  - [abstract] "While SELM is not amenable to conventional cryptanalysis, we investigate its security through a novel empirical variant of the classic IND-CPA (indistinguishability under chosen-plaintext attack) game and show promising results on security."
  - [section 5.4] "We introduce L2 regularization during training that penalizes distance from a non-zero target L2 norm... Alternatively, we explore an alternative regularization term that penalizes differences between a ciphertext c ∈ Rd and a d-dimensional sample from a univariate normal distribution N (0,σ 2)."
- **Break condition:** If the regularization is too weak, ciphertexts retain distinguishable patterns; if too strong, memorization may fail, preventing successful encryption.

## Foundational Learning

- **Concept:** Intrinsic dimension and random subspace optimization
  - **Why needed here:** Understanding intrinsic dimension is crucial because it quantifies how many parameters are truly needed to solve a learning task. In SELM, this determines the trade-off between ciphertext size and encryption speed.
  - **Quick check question:** If a task has an intrinsic dimension of 1000, what happens if we try to optimize it in a 100-dimensional subspace?

- **Concept:** Autoregressive language model architecture and training
  - **Why needed here:** Knowing how autoregressive LMs work, including tokenization, next-token prediction, and greedy decoding, is essential to understand how SELM encrypts and decrypts messages.
  - **Quick check question:** How does an autoregressive LM generate a sequence token-by-token, and why is this relevant for SELM's decryption process?

- **Concept:** Symmetric encryption and IND-CPA security
  - **Why needed here:** Understanding the basics of symmetric encryption and the IND-CPA game is necessary to grasp SELM's security goals and how they are evaluated.
  - **Quick check question:** What does it mean for a cipher to be IND-CPA secure, and why is this property important for SELM?

## Architecture Onboarding

- **Component map:**
  - Public pre-trained autoregressive LM (θD0) -> Random projection matrix P -> Low-dimensional vector θd -> Tokenization and prompt generation -> Loss function and optimization -> Greedy decoding

- **Critical path:**
  1. Alice tokenizes and prompts the message
  2. Alice initializes θd and optimizes it to memorize the message in the random subspace
  3. Alice sends θd* and prompts as ciphertext
  4. Bob reconstructs the fine-tuned LM using the secret key k and θd*
  5. Bob prompts the LM to regenerate the original message

- **Design tradeoffs:**
  - Smaller d reduces ciphertext size but increases encryption time
  - Stronger regularization improves security but may hinder memorization
  - Longer prompts aid memorization but increase computational cost

- **Failure signatures:**
  - Incomplete memorization: Decryption produces incorrect or incomplete messages
  - Security breaches: Machine learning classifiers can distinguish between ciphertexts of different messages
  - Optimization instability: Loss fails to converge or explodes during training

- **First 3 experiments:**
  1. **Memorization test:** Encrypt and decrypt a short, structured message (e.g., "Hello Bob!") to verify basic functionality
  2. **Size vs. speed test:** Vary d (e.g., 1K, 10K, 100K) and measure encryption time and ciphertext size for a fixed message length
  3. **Security test:** Play the empirical IND-CPA game with two different messages and a simple classifier (e.g., KNN) to assess initial security

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can SELM securely encrypt arbitrary data of any length?
- Basis in paper: [explicit] The paper demonstrates SELM can memorize random bytes and long sequences, suggesting it can encrypt arbitrary data, but the security analysis is limited to 100-token messages with d=10K.
- Why unresolved: The security analysis is only conducted for a specific message length and ciphertext dimension. The paper does not explore the security implications of longer messages or different ciphertext dimensions.
- What evidence would resolve it: Comprehensive security analysis of SELM with varying message lengths and ciphertext dimensions, demonstrating that the security properties hold across a wide range of parameters.

### Open Question 2
- Question: What is the relationship between the size of the low-dimensional vector (d) and the security of SELM?
- Basis in paper: [explicit] The paper discusses the trade-off between speed and size, but does not explicitly analyze the relationship between d and security.
- Why unresolved: The paper only explores the security of SELM with d=10K. The impact of varying d on security is not investigated.
- What evidence would resolve it: Security analysis of SELM with varying values of d, demonstrating the relationship between the size of the low-dimensional vector and the security properties.

### Open Question 3
- Question: Can SELM be made perfectly secure?
- Basis in paper: [explicit] The paper acknowledges that SELM is not yet perfectly secure and proposes potential solutions, but does not achieve perfect security.
- Why unresolved: The paper does not explore all possible regularization strategies or alternative approaches to achieving perfect security.
- What evidence would resolve it: Development and demonstration of a secure variant of SELM, achieving perfect security against all known cryptanalytic attacks.

## Limitations

- SELM's security analysis is limited to specific message lengths and ciphertext dimensions, with no guarantee of security for arbitrary message sizes
- The effectiveness of regularization strategies against sophisticated machine learning attacks remains uncertain and requires comprehensive evaluation
- Potential information leakage through side channels (e.g., optimization trajectories) during encryption has not been thoroughly investigated

## Confidence

**High Confidence Claims:**
- Language models can memorize arbitrary data when fine-tuned in random subspaces
- Random subspace optimization reduces ciphertext size by over 100x compared to full parameter encryption
- The basic encryption/decryption pipeline (tokenization → optimization → decoding) is technically feasible

**Medium Confidence Claims:**
- Simple regularization strategies can improve security by making ciphertext distributions indistinguishable
- SELM demonstrates promising security properties in initial empirical evaluations
- The trade-off between ciphertext size and encryption time is controllable through the choice of intrinsic dimension

**Low Confidence Claims:**
- SELM provides robust security against real-world adversaries with access to advanced ML capabilities
- The security benefits of distribution-based regularization versus L2 regularization
- Long-term security guarantees given potential advances in model inversion attacks

## Next Checks

1. **Security stress test:** Conduct a comprehensive evaluation of SELM's security using a diverse set of classification models (CNNs, transformers, ensemble methods) and attack scenarios, including transfer attacks where adversaries have access to related but different LMs.

2. **Parameter sensitivity analysis:** Systematically evaluate how SELM's performance (memorization accuracy, encryption speed, security) varies with key hyperparameters (intrinsic dimension d, learning rate, regularization strength) across different message types and lengths.

3. **Side-channel analysis:** Investigate potential information leakage through observable metrics during encryption (loss curves, optimization trajectories) and explore countermeasures to prevent such leakage.