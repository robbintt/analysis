---
ver: rpa2
title: 'SemPPL: Predicting pseudo-labels for better contrastive representations'
arxiv_id: '2301.05158'
source_url: https://arxiv.org/abs/2301.05158
tags:
- learning
- positives
- proc
- semantic
- pseudo-labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a semi-supervised learning method, SemPPL, that
  combines labelled and unlabelled data to learn informative representations. SemPPL
  extends self-supervised contrastive learning by leveraging ground-truth labels to
  predict missing labels for unlabelled data through a k-nearest neighbours classifier.
---

# SemPPL: Predicting pseudo-labels for better contrastive representations

## Quick Facts
- arXiv ID: 2301.05158
- Source URL: https://arxiv.org/abs/2301.05158
- Reference count: 40
- Primary result: State-of-the-art semi-supervised learning on ImageNet with 1% and 10% labels using pseudo-label predictions to enrich contrastive positives

## Executive Summary
SemPPL is a semi-supervised learning method that extends self-supervised contrastive learning by predicting pseudo-labels for unlabeled data through k-nearest neighbors classification. These pseudo-labels are then used to select semantic positives—datapoints with the same pseudo-label—which enrich the set of positives beyond just augmented views of the same instance. This creates a reinforcing cycle where better representations enable better pseudo-label predictions, which in turn lead to better semantic positives and even better representations. SemPPL achieves state-of-the-art performance on ImageNet with limited labeled data, significantly outperforming previous methods.

## Method Summary
SemPPL combines contrastive learning with pseudo-label prediction to improve representation learning in semi-supervised settings. The method uses an online encoder, target encoder, and projection heads to learn representations, while storing labeled embeddings in a FIFO queue for k-NN lookup. For each unlabeled datapoint, k-NN classification predicts pseudo-labels by comparing against labeled embeddings in the queue. These pseudo-labels are used to select semantic positives—other datapoints with the same predicted label—which are added to the set of contrastive positives alongside augmented views. The model jointly learns representations and pseudo-labels, creating a reinforcing cycle that improves both over training. SemPPL can be combined with various self-supervised objectives like SimCLR or BYOL.

## Key Results
- Achieves state-of-the-art performance on ImageNet with 1% and 10% labels
- Outperforms previous semi-supervised methods by significant margins
- Creates a reinforcing cycle where better representations enable better pseudo-label predictions, which improve semantic positive selection and further enhance representations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Pseudo-label prediction creates a reinforcing cycle that improves both representation quality and label accuracy over training.
- **Mechanism:** Initial representations enable better k-NN pseudo-label predictions, which in turn provide more semantically accurate positives for contrastive learning, leading to improved representations in the next iteration.
- **Core assumption:** The representation space learned from labelled data can meaningfully transfer to unlabelled data through k-NN.
- **Evidence anchors:**
  - [abstract]: "Strong initial representations enable better pseudo-label predictions which then improve the selection of semantic positives and lead to even better representations."
  - [section]: "This creates a virtuous cycle: better representations enable better pseudo-label prediction which in turn enables better selection of semantic positives and thus helps us learn better representations."
  - [corpus]: Weak - corpus neighbors focus on pseudo-labeling for text clustering, not contrastive learning cycles.
- **Break condition:** If the initial labelled data is too small or unrepresentative, the k-NN cannot bootstrap meaningful pseudo-labels, breaking the cycle.

### Mechanism 2
- **Claim:** Semantic positives based on pseudo-labels provide richer positive sets than augmentation-only positives in semi-supervised settings.
- **Mechanism:** By including datapoints with the same pseudo-label as semantic positives, the model learns to maximize similarity across semantically similar instances rather than just augmentations of the same instance.
- **Core assumption:** Pseudo-labels are accurate enough to identify truly semantically similar instances.
- **Evidence anchors:**
  - [abstract]: "We thus extend the set of positives with datapoints having the same pseudo-label and call these semantic positives."
  - [section]: "We propose a novel approach to selecting positives which leverages supervised information... associate images with the same label as positives."
  - [corpus]: Weak - corpus papers discuss pseudo-labels but not specifically for enriching contrastive positives.
- **Break condition:** If pseudo-labels are too noisy (low accuracy), including them as positives introduces harmful negative examples that degrade representation quality.

### Mechanism 3
- **Claim:** The k-NN classifier with majority voting over multiple views provides robust pseudo-label predictions that are stable across training iterations.
- **Mechanism:** Using multiple augmented views and majority voting reduces the variance in pseudo-label predictions, making them more reliable for semantic positive selection.
- **Core assumption:** Multiple views of the same instance contain consistent semantic information that k-NN can exploit.
- **Evidence anchors:**
  - [section]: "Since S EMPPL relies on 4 large views, this yields up to 16 different pairs of views to compare and compute pseudo-labels from... we get 16 pseudo-label predictions; this setting we call view voting."
  - [section]: "We want to measure how often these 16 votes agree or disagree... precision is an increasing function of the voting threshold throughout training."
  - [corpus]: Weak - corpus focuses on text clustering methods, not multi-view voting for pseudo-labels in contrastive learning.
- **Break condition:** If augmentations introduce view-specific artifacts that differ across views, majority voting may fail to produce consistent pseudo-labels.

## Foundational Learning

- **Concept: Contrastive learning**
  - Why needed here: SemPPL builds directly on contrastive learning frameworks by extending how positives are selected
  - Quick check question: What is the difference between augmentation positives and semantic positives in contrastive learning?

- **Concept: Semi-supervised learning**
  - Why needed here: SemPPL operates in the regime with limited labelled data and abundant unlabelled data
  - Quick check question: How does SemPPL differ from traditional semi-supervised methods that use pseudo-labels as classification targets?

- **Concept: k-Nearest Neighbors (k-NN)**
  - Why needed here: k-NN is used to predict pseudo-labels by comparing unlabelled data to labelled embeddings
  - Quick check question: Why might k-NN be particularly effective in the representation space learned by contrastive methods?

## Architecture Onboarding

- **Component map:**
  Online encoder (f) and target encoder (ft) -> Projection heads (g, gt) and predictor (h) -> FIFO queue storing labelled embeddings -> k-NN classifier for pseudo-label prediction -> Semantic positive sampler -> Contrastive loss computation

- **Critical path:**
  1. Embed labelled and unlabelled data through online and target networks
  2. Store labelled embeddings in queue
  3. For unlabelled data, perform k-NN lookup in queue to predict pseudo-labels
  4. Select semantic positives from queue based on pseudo-labels
  5. Compute contrastive loss with both augmentation and semantic positives
  6. Update online network, target network via EMA

- **Design tradeoffs:**
  - Queue size vs staleness: Larger queues provide more diversity but may contain stale embeddings
  - k-NN neighbors vs accuracy: More neighbors can smooth predictions but may include wrong classes
  - Semantic positives vs augmentation positives: Balance between semantic similarity and instance-specific features

- **Failure signatures:**
  - Pseudo-label accuracy plateaus below ~60%: Indicates poor initial representations or insufficient labelled data
  - Performance degrades with larger queue sizes: Suggests stale embeddings are harming k-NN accuracy
  - No improvement over baseline contrastive learning: May indicate pseudo-labels are too noisy or semantic positives are poorly selected

- **First 3 experiments:**
  1. Train with augmentation positives only (SemPPL with α=0) to establish baseline performance
  2. Add semantic positives using ground-truth labels (oracle) to measure upper bound performance
  3. Vary k in k-NN from 1 to 10 to find optimal trade-off between accuracy and robustness

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Performance depends on initial representation quality from limited labeled data, which may fail in extreme label scarcity
- k-NN approach may not scale effectively to very large label sets or complex data distributions
- The reinforcing cycle assumes that initial representations are sufficient to bootstrap meaningful pseudo-labels

## Confidence
- **High:** The mechanism of extending positives with semantic information based on pseudo-labels
- **Medium:** The effectiveness of the reinforcing cycle between representation learning and pseudo-label prediction
- **Low:** Generalizability to datasets beyond ImageNet and performance in extremely low-label regimes

## Next Checks
1. Test SemPPL on non-ImageNet datasets with varying label fractions to assess generalizability
2. Evaluate the impact of queue staleness by varying the update frequency of stored embeddings
3. Compare k-NN pseudo-label accuracy against alternative semi-supervised methods like FixMatch or MixMatch to isolate the contribution of the contrastive learning component