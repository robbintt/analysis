---
ver: rpa2
title: Knowledge Graph Embeddings for Multi-Lingual Structured Representations of
  Radiology Reports
arxiv_id: '2309.00917'
source_url: https://arxiv.org/abs/2309.00917
tags:
- graph
- knowledge
- report
- radiology
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel knowledge graph-based embedding method
  for structured representations of radiology reports, leveraging the SNOMED Clinical
  Terms knowledge base to connect medical terms and capture report structure. The
  method uses Named Entity Recognition to extract UMLS concepts from reports, constructs
  a graph with concept nodes, sentence nodes, and a global connection node, and encodes
  the graph using graph attention networks.
---

# Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports

## Quick Facts
- arXiv ID: 2309.00917
- Source URL: https://arxiv.org/abs/2309.00917
- Reference count: 38
- Key outcome: Knowledge graph embeddings achieve competitive performance to BERT models on disease classification while being smaller and requiring less data.

## Executive Summary
This paper introduces a novel knowledge graph-based embedding method for structured representations of radiology reports, leveraging the SNOMED Clinical Terms knowledge base to connect medical terms and capture report structure. The method uses Named Entity Recognition to extract UMLS concepts from reports, constructs a graph with concept nodes, sentence nodes, and a global connection node, and encodes the graph using graph attention networks. The resulting embeddings are evaluated on two tasks: disease classification of X-ray reports and image classification with cross-modal knowledge transfer. The method achieves competitive performance compared to BERT-based models while being magnitudes smaller in size and training data requirements, and demonstrates effectiveness across different languages including English and Spanish.

## Method Summary
The method constructs a knowledge graph from radiology reports by extracting UMLS concepts using Named Entity Recognition, then building a graph with concept nodes, sentence nodes, and a global node connected via edges representing relationships. The graph is encoded using graph attention networks to produce embeddings that capture medical terminology and report structure. These embeddings are evaluated on disease classification tasks and leveraged for cross-modal knowledge transfer to image classification through variational knowledge distillation.

## Key Results
- Knowledge graph embeddings achieve competitive AUC scores compared to BERT-based models on disease classification tasks
- The method requires significantly less training data and model size than pre-trained language models
- Cross-modal knowledge transfer from structured report embeddings improves image classification performance
- The approach demonstrates effectiveness across English and Spanish languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph embeddings capture medical terminology more intuitively than tokenized embeddings by preserving full concept integrity.
- Mechanism: Instead of breaking medical terms into subword tokens (e.g., 'opacities' → 'o' + 'pa' + 'cities'), the graph uses full UMLS concepts as nodes, avoiding token splitting errors and maintaining semantic coherence.
- Core assumption: Full-concept node representation preserves clinical meaning better than subword tokenization in medical text.
- Evidence anchors:
  - [abstract] "The resulting graph embedding uncovers the underlying relationships among clinical terms, achieving a representation that is better understandable for clinicians and clinically more accurate"
  - [section] "The graph handles repeated terms more efficiently than clinicalBERT: our graph consists of 34 nodes, while tokenization with ClinicalBERT takes as much as 124 tokens"
  - [corpus] Weak signal; no direct corpus evidence, inferred from methodology.
- Break condition: If the UMLS concept extraction fails or if domain-specific terminology is missing from the knowledge base, the full-concept advantage disappears.

### Mechanism 2
- Claim: Leveraging SNOMED CT knowledge graph improves performance with smaller model size by injecting prior medical knowledge.
- Mechanism: By using SNOMED CT's structured relations (ec↔c edges), the model does not need to learn medical relationships from scratch; it can rely on existing expert-defined connections, reducing the need for large pre-training datasets.
- Core assumption: The SNOMED CT ontology is sufficiently complete and accurate for the target radiology domain.
- Evidence anchors:
  - [abstract] "without reliance on large pre-training datasets"
  - [section] "The added information from this knowledge base can be beneficial, since expert-level annotation is not in abundance in the medical domain"
  - [corpus] Weak signal; no direct corpus evidence, inferred from knowledge graph usage.
- Break condition: If SNOMED CT lacks coverage for emerging or rare radiological findings, the prior knowledge benefit is lost.

### Mechanism 3
- Claim: Cross-modal knowledge transfer from structured report embeddings to images is enabled by variational knowledge distillation (VKD).
- Mechanism: The report graph embedding acts as a posterior distribution in VKD, distilling structured medical knowledge into image representations to improve disease classification without requiring paired image-report data at inference.
- Core assumption: The structured report embedding contains sufficient and accurate medical context to be useful for image-based inference.
- Evidence anchors:
  - [abstract] "For image classification, we show the effectiveness of the graph embedding leveraging cross-modal knowledge transfer"
  - [section] "we use our report graph embeddings to improve image representations"
  - [corpus] Weak signal; no direct corpus evidence, inferred from multimodal training setup.
- Break condition: If the report graph embedding lacks critical clinical details, or the VKD architecture fails to align modalities, transfer performance degrades.

## Foundational Learning

- Concept: Knowledge graphs and graph attention networks (GAT)
  - Why needed here: To model complex relationships between medical concepts in radiology reports and encode them into embeddings for downstream tasks.
  - Quick check question: What are the two main components of a graph used in this work (nodes and edges) and what do they represent?
- Concept: UMLS and SNOMED CT ontologies
  - Why needed here: To provide a standardized, multi-lingual source of medical concepts and their relationships for graph construction.
  - Quick check question: How does the paper use SNOMED CT to connect medical terms in the report?
- Concept: Variational knowledge distillation (VKD)
  - Why needed here: To transfer structured information from report embeddings to image representations for cross-modal disease classification.
  - Quick check question: In the VKD framework, what role does the report graph embedding play relative to the image?

## Architecture Onboarding

- Component map:
  NER → Graph Construction → Graph Encoding → MLP Classifier (for report classification)
  NER → Graph Construction → Graph Encoding → VKD → Image Encoder (for image classification)
- Critical path:
  NER → Graph Construction → Graph Encoding → MLP Classifier (for report classification)
  NER → Graph Construction → Graph Encoding → VKD → Image Encoder (for image classification)
- Design tradeoffs:
  - Small GAT encoders (1 layer, 512 hidden size) are faster and smaller but may underfit; deeper encoders (12 layers, 2048 hidden size) are more expressive but computationally heavy.
  - Full concept nodes preserve meaning but require robust NER; tokenization is more flexible but loses semantic integrity.
  - Including the global node and SNOMED CT edges improves performance but increases graph complexity.
- Failure signatures:
  - NER misses critical medical terms → sparse graph → poor classification.
  - Graph too shallow or small hidden size → underfitting, especially in cross-modal tasks.
  - SNOMED CT missing domain coverage → loss of prior knowledge benefit.
- First 3 experiments:
  1. Verify NER extraction accuracy on a small set of radiology reports; check UMLS CUI mapping.
  2. Build a minimal graph (no global node, no SNOMED CT edges) and compare classification AUC to baseline.
  3. Train a 1-layer GAT encoder (512 hidden) on MIMIC-CXR; compare CPU/GPU inference rates and AUC to ClinicalBERT.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of knowledge graph embeddings compare to BERT-based models when applied to languages other than English and Spanish?
- Basis in paper: [inferred] The paper mentions that BERT models are largely focused on English and have lower performance in Spanish due to smaller training datasets. The authors demonstrate their method's effectiveness across English and Spanish, but do not explore other languages.
- Why unresolved: The paper only tests the method on English and Spanish datasets, leaving the performance on other languages unknown.
- What evidence would resolve it: Testing the method on datasets from additional languages and comparing its performance to BERT-based models in those languages would provide evidence.

### Open Question 2
- Question: How does the size of the knowledge graph (number of nodes and edges) affect the performance of the embeddings in disease classification tasks?
- Basis in paper: [inferred] The paper mentions that no limit is enforced on the number of entities that can be extracted from a report with NER or on the number of edges within a graph. However, it does not explore how the graph size impacts performance.
- Why unresolved: The paper does not investigate the relationship between graph size and classification performance, leaving this aspect unexplored.
- What evidence would resolve it: Conducting experiments with graphs of varying sizes and analyzing their impact on classification performance would provide evidence.

### Open Question 3
- Question: Can the knowledge graph embeddings be used for other medical tasks beyond disease classification, such as patient risk stratification or treatment recommendation?
- Basis in paper: [explicit] The paper focuses on disease classification and image classification tasks, but does not explore other potential applications of the embeddings.
- Why unresolved: The paper does not investigate the applicability of the embeddings to other medical tasks, leaving their potential for broader use unknown.
- What evidence would resolve it: Applying the embeddings to additional medical tasks and evaluating their performance would provide evidence of their broader applicability.

## Limitations
- Cross-modal knowledge transfer effectiveness is inferred from methodology but lacks direct quantitative comparison against baselines in the corpus; actual performance gains are not reported.
- Small training data advantage (no large pre-training datasets) is asserted but not empirically validated against BERT-based models trained on similar dataset sizes.
- Multi-lingual extension is demonstrated on Spanish but lacks broader language coverage validation, raising questions about generalizability.
- Knowledge graph completeness depends heavily on UMLS/SNOMED CT coverage; rare or emerging radiological findings may not be captured, limiting clinical applicability.

## Confidence
- **High**: Knowledge graph embeddings preserve medical concept integrity better than tokenization; small model size with competitive performance is achievable.
- **Medium**: Cross-modal knowledge transfer via variational knowledge distillation improves image classification; multi-lingual capability extends beyond English.
- **Low**: Claims about knowledge gaps or domain-specific limitations are inferred from general KG literature, not directly tested in this work.

## Next Checks
1. **NER Accuracy Validation**: Manually verify UMLS CUI extraction accuracy on a random sample of 50 radiology reports; calculate precision, recall, and F1-score to confirm concept coverage.
2. **Cross-Modal Transfer Quantification**: Implement and compare VKD-based image classification against a direct image-only baseline (e.g., ResNet) on MIMIC-CXR; report AUC improvement with statistical significance.
3. **Language Generalization Test**: Extend the pipeline to a third language (e.g., German or French) using UMLS MetaMap; evaluate classification performance and compare to English baseline to confirm multi-lingual robustness.