---
ver: rpa2
title: Benchmarking Bayesian Causal Discovery Methods for Downstream Treatment Effect
  Estimation
arxiv_id: '2307.04988'
source_url: https://arxiv.org/abs/2307.04988
tags:
- causal
- discovery
- methods
- treatment
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper benchmarks Bayesian causal discovery methods for downstream\
  \ treatment effect estimation, addressing the gap where most evaluations focus on\
  \ structure learning rather than causal inference performance. The authors compare\
  \ six established causal discovery methods\u2014PC, GES, MC3, BCDNets, Gadget, and\
  \ DiBS\u2014with a newly proposed GFlowNet-based method (DAG-GFlowNet) on the task\
  \ of average treatment effect (ATE) estimation."
---

# Benchmarking Bayesian Causal Discovery Methods for Downstream Treatment Effect Estimation

## Quick Facts
- arXiv ID: 2307.04988
- Source URL: https://arxiv.org/abs/2307.04988
- Authors: 
- Reference count: 35
- One-line primary result: Bayesian GFlowNet-based method (DAG-GFlowNet) achieves highest recall (0.97-0.98) for downstream treatment effect estimation while maintaining competitive precision after filtering low-probability modes.

## Executive Summary
This paper addresses the gap in causal discovery evaluation by benchmarking Bayesian methods on downstream treatment effect estimation rather than just structure learning. The authors propose a comprehensive evaluation framework that compares learned average treatment effect (ATE) distributions to true Markov equivalence classes using Wasserstein distance, precision, and recall metrics. They evaluate six established methods (PC, GES, MC3, BCDNets, Gadget, DiBS) alongside a newly proposed DAG-GFlowNet method. The results demonstrate that while most methods achieve high recall by capturing diverse ATE modes, they suffer from low precision due to learning spurious low-probability modes. After applying a filtering approach to remove these modes, precision improves significantly across all methods, with DAG-GFlowNet achieving the best overall performance.

## Method Summary
The study benchmarks Bayesian causal discovery methods on their ability to estimate treatment effects downstream of structure learning. The authors generate synthetic data from linear Gaussian Bayesian networks using Erdős-Rényi models with 20 and 100 variables, and use real-world flow cytometry data from the Sachs dataset. Six established causal discovery methods (PC, GES, MC3, BCDNets, Gadget, DiBS) are compared with DAG-GFlowNet, a novel GFlowNet-based approach. For each method, posterior distributions over DAGs are learned from observational data. The ATE is estimated for all non-matching variable pairs using do-calculus with treatment values at 1.0 and 0.0, implemented via the DoWhy package. The evaluation compares learned ATE distributions to true Markov equivalence classes using Wasserstein distance, precision, and recall metrics, with an additional filtering step to remove low-probability modes before calculating precision.

## Key Results
- Most methods achieve high recall (0.88-0.98) but low precision (0.11-0.25) due to learning spurious low-probability ATE modes
- After filtering low-probability modes with density threshold 0.05, precision improves significantly across all methods (0.46-0.94)
- DAG-GFlowNet achieves the highest recall (0.97-0.98) and competitive Wasserstein distances (0.201-0.325) compared to other methods
- Filtering approach reveals that methods like DAG-GFlowNet and GES capture true ATE modes effectively despite initially low precision scores

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bayesian structure learning with DAG-GFlowNet captures diverse ATE modes more effectively than MCMC-based methods
- Mechanism: GFlowNets use a flow-matching training objective to learn a policy that generates DAG samples proportional to their posterior probability, avoiding the mode-mixing problem that plagues MCMC methods. This allows better exploration of the posterior distribution and captures diverse ATE modes.
- Core assumption: The reward function can be designed to reflect the posterior probability of DAGs given the data, and the GFlowNet can learn to sample proportionally from this distribution.
- Evidence anchors:
  - [abstract] "The results of our study demonstrate that GFlowNets possess the capability to effectively capture a wide range of useful and diverse ATE modes."
  - [section] "DAG-GFlowNet achieves the highest recall (0.97-0.98) and competitive Wasserstein distances (0.201-0.325), demonstrating its capability to capture diverse ATE modes effectively."
  - [corpus] Weak - corpus contains related causal inference papers but no specific GFlowNet comparisons
- Break condition: If the reward function poorly represents the true posterior, or if the GFlowNet architecture cannot represent the posterior distribution adequately.

### Mechanism 2
- Claim: Filtering low-probability modes significantly improves precision metrics for methods that learn diverse ATE distributions
- Mechanism: Methods like DAG-GFlowNet and GES learn many low-probability ATE modes in addition to the true modes. By applying a density threshold (e.g., 0.05), these spurious modes are removed before calculating precision, revealing the true performance of the method in capturing relevant ATE modes.
- Core assumption: The true ATE distribution consists of high-probability modes, and low-probability modes learned by the method are spurious.
- Evidence anchors:
  - [abstract] "After filtering these modes, precision improves significantly across all methods."
  - [section] "In Figure 3 we observe that DAG-GFlowNet (and other baselines like GES, DiBs) tends to learn new modes, but those modes have a very low probability in the estimated distribution."
  - [corpus] Weak - corpus contains related causal inference papers but no specific filtering approaches
- Break condition: If the filtering threshold is set too high, removing true but low-probability ATE modes, or if the method genuinely captures additional relevant modes that are simply low-probability.

### Mechanism 3
- Claim: Distribution-level evaluation of ATE provides more comprehensive assessment than single-point estimation
- Mechanism: Instead of estimating a single ATE value, the method samples multiple DAGs from the posterior and computes the ATE distribution for each non-matching variable pair. This captures the uncertainty in the causal graph and provides a more complete picture of the treatment effect.
- Core assumption: The posterior distribution over DAGs contains meaningful uncertainty that affects the ATE estimation, and this uncertainty should be propagated to the ATE distribution.
- Evidence anchors:
  - [abstract] "our evaluation methodology goes beyond single-point ATE estimation, which is employed in standard causal inference benchmarking, by performing ATE evaluations based on posterior samples."
  - [section] "This approach aims to provide a more comprehensive assessment of the quality of the learned posterior average treatment effect (ATE)."
  - [corpus] Weak - corpus contains related causal inference papers but no specific distribution-level evaluation approaches
- Break condition: If the posterior distribution is overly concentrated or if the ATE distribution becomes too diffuse to be useful.

## Foundational Learning

- Concept: Markov Equivalence Classes (MECs)
  - Why needed here: The paper evaluates methods by comparing their ATE distributions to the true MEC, requiring understanding that multiple DAGs can represent the same conditional independence relationships.
  - Quick check question: Why can't we uniquely identify a single DAG from observational data, and how does this relate to MECs?

- Concept: Average Treatment Effect (ATE) and do-calculus
  - Why needed here: The downstream task is ATE estimation, requiring understanding of how to compute causal effects from observational data using the do-operator and identification strategies.
  - Quick check question: How does the do-calculus formula for ATE differ from a simple difference in conditional expectations?

- Concept: Bayesian structure learning and posterior over DAGs
  - Why needed here: The paper evaluates Bayesian methods that learn a distribution over DAGs rather than a single DAG, requiring understanding of how to represent and sample from this distribution.
  - Quick check question: Why might learning a posterior distribution over DAGs be preferable to learning a single "best" DAG for downstream inference tasks?

## Architecture Onboarding

- Component map: Observational data -> Causal discovery (generate DAG samples) -> ATE estimation (compute ATE for all variable pairs and DAG samples) -> Evaluation (compare distributions using Wasserstein distance, precision, recall)
- Critical path: The critical path is: observational data → causal discovery (generate DAG samples) → ATE estimation (compute ATE for all variable pairs) → evaluation (compare distributions). Any bottleneck in the causal discovery or ATE computation will directly impact overall runtime.
- Design tradeoffs: The choice between MCMC-based methods (PC, GES, MC3, Gadget) and variational methods (BCDNets, DiBS, DAG-GFlowNet) involves a tradeoff between sampling quality and computational efficiency. MCMC provides asymptotically correct samples but suffers from mode-mixing, while variational methods are faster but may miss modes.
- Failure signatures: Low precision with high recall indicates the method is capturing diverse modes but also learning spurious low-probability modes. High Wasserstein distance indicates the learned ATE distribution is far from the true distribution. Failure to enumerate the true MEC will make evaluation impossible.
- First 3 experiments:
  1. Run DAG-GFlowNet on synthetic data with 20 nodes and 20 samples, comparing its ATE distribution to the true MEC.
  2. Apply the filtering approach with density threshold 0.05 to DAG-GFlowNet results and observe precision improvement.
  3. Compare DAG-GFlowNet to GES and DiBS on the Sachs dataset, focusing on precision-recall tradeoff after filtering.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do GFlowNets compare to other Bayesian causal discovery methods when the number of observational samples is extremely limited (e.g., less than 10)?
- Basis in paper: [explicit] The paper evaluates methods on 20 samples to test low-data capabilities, but does not explore scenarios with fewer than 10 samples.
- Why unresolved: The paper only tests with 20 samples and 100 samples, leaving the performance in ultra-low-data regimes unexplored.
- What evidence would resolve it: Experimental results comparing GFlowNets and other methods on datasets with fewer than 10 samples would clarify their performance in ultra-low-data scenarios.

### Open Question 2
- Question: What is the impact of different structural equation model assumptions (e.g., non-linear SEMs) on the downstream treatment effect estimation performance of causal discovery methods?
- Basis in paper: [inferred] The paper focuses on linear Gaussian Bayesian networks, but real-world data often involves non-linear relationships.
- Why unresolved: The experiments are limited to linear Gaussian models, so the generalizability to non-linear SEMs is unknown.
- What evidence would resolve it: Benchmarking the methods on datasets generated from non-linear SEMs would reveal their performance under different structural assumptions.

### Open Question 3
- Question: How does the computational efficiency of GFlowNets scale with the number of variables in the causal graph compared to MCMC-based methods?
- Basis in paper: [explicit] The paper mentions that DAG-GFlowNet leverages GFlowNets as a substitute for MCMC, but does not provide a direct computational efficiency comparison.
- Why unresolved: While the paper discusses the advantages of GFlowNets, it does not quantify the computational efficiency gains relative to MCMC-based methods.
- What evidence would resolve it: Runtime comparisons of GFlowNets and MCMC-based methods across graphs of varying sizes would quantify their computational efficiency differences.

## Limitations

- Evaluation framework relies on synthetic data generation with Erdős-Rényi models, which may not capture real-world causal structure complexity
- Filtering approach introduces a hyperparameter (density threshold) that significantly impacts precision metrics
- Experiments limited to linear Gaussian models, restricting generalizability to non-linear causal relationships
- Computational cost of ATE estimation across all variable pairs creates scalability concerns for larger datasets

## Confidence

- **High Confidence**: Most methods achieve high recall but low precision due to learning spurious low-probability modes
- **Medium Confidence**: DAG-GFlowNet's superiority in capturing diverse ATE modes requires validation on non-linear and complex real-world structures
- **Medium Confidence**: Filtering approach effectiveness depends on appropriate threshold selection

## Next Checks

1. **Non-linear Causal Structure Validation**: Test DAG-GFlowNet and other methods on synthetic data generated from non-linear causal models (e.g., additive noise models, post-nonlinear models) to assess performance beyond linear Gaussian assumptions.

2. **Threshold Sensitivity Analysis**: Conduct a systematic study of how different density threshold values affect precision-recall tradeoffs across all methods, including statistical tests for significance of improvements.

3. **Real-world Complex Structure Evaluation**: Apply the benchmarking framework to more complex real-world datasets (e.g., gene regulatory networks, economic systems) with known causal structures to validate scalability and robustness of the methods.