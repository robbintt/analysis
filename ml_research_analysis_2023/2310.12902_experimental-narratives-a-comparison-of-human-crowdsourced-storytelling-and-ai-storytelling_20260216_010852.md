---
ver: rpa2
title: 'Experimental Narratives: A Comparison of Human Crowdsourced Storytelling and
  AI Storytelling'
arxiv_id: '2310.12902'
source_url: https://arxiv.org/abs/2310.12902
tags:
- human
- stories
- story
- prompt
- artificial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a novel framework for comparing human and
  AI storytelling by using identical prompts. It analyzes 250 human-written stories
  from 2019 and 80 AI-generated stories from 2023, focusing on the Pygmalion myth.
---

# Experimental Narratives: A Comparison of Human Crowdsourced Storytelling and AI Storytelling

## Quick Facts
- arXiv ID: 2310.12902
- Source URL: https://arxiv.org/abs/2310.12902
- Reference count: 15
- One-line primary result: AI-generated stories show greater gender/sexual diversity but less imaginative content compared to human-written stories using identical Pygmalion myth prompts

## Executive Summary
This study introduces a novel framework for comparing human and AI storytelling by using identical prompts about creating and falling in love with an artificial human. Analyzing 250 human-written stories from 2019 and 80 AI-generated stories from 2023, the research reveals that GPT-4 narratives are more progressive in gender roles and sexuality compared to human-authored texts, while being less imaginative and offering fewer innovative scenarios. The framework demonstrates fiction's value as a tool for exploring cultural artifacts and social biases in both human and AI-generated storytelling.

## Method Summary
The study collected 250 human stories from Amazon Mechanical Turk workers in 2019 and 80 AI-generated stories from GPT-3.5 and GPT-4 in 2023, all responding to identical prompts about the Pygmalion myth. Researchers merged narratology and inferential statistics to analyze themes, gender/sexuality representation, race/ethnicity, cultural influences, and narrative skill. The comparative analysis examined how human and AI storytellers differ in their portrayals of characters, plot innovation, and underlying biases when given the same creative constraints.

## Key Results
- AI narratives, particularly GPT-4, demonstrate greater gender and sexual diversity than human-written stories
- AI-generated stories exhibit less imaginative content and offer fewer innovative scenarios than human-authored texts
- The framework successfully reveals cultural artifacts and social biases in both human and AI storytelling outputs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Identical prompts enable direct comparison between human and AI storytelling outputs
- **Mechanism:** By giving both human crowdworkers and LLMs the exact same narrative prompt about creating and falling in love with an artificial human, differences in output can be attributed to the source (human vs. AI) rather than prompt variations
- **Core assumption:** The prompts are sufficiently neutral and open-ended to elicit comparable narrative responses from both humans and AI
- **Evidence anchors:** [abstract] "Both crowdworkers and large language models responded to identical prompts about creating and falling in love with an artificial human"
- **Break condition:** If the prompts inadvertently favor one type of response (e.g., if they are too specific or biased), the comparison becomes invalid

### Mechanism 2
- **Claim:** AI storytelling, particularly from GPT-4, exhibits greater gender and sexual diversity than human storytelling
- **Mechanism:** LLMs trained on large corpora may have learned to represent a wider range of gender identities and sexual orientations than the human writers, who may unconsciously reflect their own demographic biases
- **Core assumption:** The training data for GPT-4 includes a diverse range of gender and sexual representations
- **Evidence anchors:** [abstract] "The analysis reveals that narratives from GPT-3.5 and particularly GPT-4 are more progressive in terms of gender roles and sexuality than those written by humans"
- **Break condition:** If the AI's diversity is merely reflecting the average representation in its training data, rather than a genuine increase in progressive storytelling

### Mechanism 3
- **Claim:** AI-generated stories are more formulaic and less imaginative than human stories, despite occasional innovative plot twists
- **Mechanism:** LLMs, while capable of generating coherent text, rely on learned patterns and statistical associations from their training data. This leads to predictable story structures and clichéd themes, even if they can occasionally introduce unexpected elements
- **Core assumption:** The training data for LLMs contains a high proportion of formulaic and clichéd narratives
- **Evidence anchors:** [abstract] "While AI narratives with default settings and no additional prompting can occasionally provide innovative plot twists, they offer less imaginative scenarios and rhetoric than human-authored texts"
- **Break condition:** If the AI's formulaic nature is a result of specific training techniques or hyperparameter settings, rather than an inherent limitation of the model architecture

## Foundational Learning

- **Concept: Pygmalion Myth**
  - Why needed here: The study uses the Pygmalion myth as a thematic prompt to elicit narratives about human-artificial human relationships. Understanding the myth's themes and variations is crucial for interpreting the results
  - Quick check question: What are the key themes and character dynamics in the Pygmalion myth, and how have they been reinterpreted in modern fiction?

- **Concept: Gender and Sexual Representation in Fiction**
  - Why needed here: The study analyzes gender and sexual diversity in the stories, comparing human and AI outputs. Familiarity with existing research on gender and sexual representation in literature and media is necessary for contextualizing the findings
  - Quick check question: What are some common patterns of gender and sexual representation in fiction, and how have they evolved over time?

- **Concept: Large Language Models (LLMs)**
  - Why needed here: The study uses GPT-3.5 and GPT-4 to generate stories. Understanding how LLMs work, their strengths and limitations, and their potential biases is essential for interpreting the results and drawing conclusions
  - Quick check question: How do LLMs generate text, and what factors influence the style, coherence, and creativity of their outputs?

## Architecture Onboarding

- **Component map:** Data collection -> Data processing -> Analysis -> Results
- **Critical path:** Design neutral prompts that elicit comparable narratives from humans and AI -> Collect sufficient stories from both sources -> Develop robust framework for analyzing narrative elements -> Conduct rigorous statistical analysis to identify significant differences -> Interpret results in context of existing research
- **Design tradeoffs:** Using a specific theme (Pygmalion myth) vs. open-ended prompts: allows for focused comparison but may limit generalizability
- **Failure signatures:** Prompts are too specific or biased, leading to non-comparable outputs; insufficient sample size or demographic diversity in human stories; inadequate framework for analyzing narrative elements; statistical analysis fails to identify significant differences or draws incorrect conclusions; results are misinterpreted or overgeneralized beyond the scope of the study
- **First 3 experiments:**
  1. Test the neutrality and open-endedness of the prompts by having a small group of humans and AI generate stories, then compare the outputs for similarity in themes and structure
  2. Conduct a pilot study with a limited number of human and AI stories to refine the narrative analysis framework and identify any potential issues with data collection or processing
  3. Perform a sensitivity analysis on the statistical methods used to compare human and AI stories, testing different significance thresholds and model specifications to ensure robust results

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the use of fictional prompts provide a reliable method for investigating cultural artifacts and social biases in both human and AI storytelling?
- Basis in paper: [explicit] The paper proposes using fictional prompts as a novel tool for investigating cultural artifacts and social biases in storytelling by both humans and generative AI
- Why unresolved: While the paper demonstrates the feasibility of this approach, it does not provide conclusive evidence that fictional prompts are more effective than other methods for uncovering cultural and social biases
- What evidence would resolve it: Comparative studies using different types of prompts (e.g., non-fictional prompts, open-ended prompts) to investigate the same cultural artifacts and social biases, and evaluating the effectiveness of each method

### Open Question 2
- Question: To what extent do GPT-3.5 and GPT-4 models reinforce or challenge traditional gender roles and sexuality in storytelling?
- Basis in paper: [explicit] The paper finds that GPT-3.5 and GPT-4 are more progressive in terms of gender roles and sexuality than human writers, but attributes and descriptions of characters remain biased to some extent
- Why unresolved: The paper provides a snapshot of the models' performance on a specific task, but does not explore the underlying mechanisms or potential biases in the training data that may influence their outputs
- What evidence would resolve it: In-depth analysis of the training data and model architecture to identify potential sources of bias, as well as experiments manipulating the prompts or model parameters to investigate their impact on gender and sexuality representations

### Open Question 3
- Question: How does the narrative skill of AI-generated stories compare to that of human-authored stories, and what are the key factors contributing to these differences?
- Basis in paper: [explicit] The paper finds that AI-generated stories are less imaginative, offer fewer innovative scenarios and rhetoric, and exhibit formulaic layouts and generalized styles compared to human-authored stories
- Why unresolved: The paper provides a qualitative assessment of the differences, but does not offer a comprehensive quantitative analysis or identify the specific aspects of narrative skill that distinguish human and AI-generated stories
- What evidence would resolve it: Development of a comprehensive framework for evaluating narrative skill, incorporating both qualitative and quantitative measures, and applying it to a large corpus of human and AI-generated stories to identify the key factors contributing to the observed differences

## Limitations
- Temporal gap between human (2019) and AI (2023) data collection may influence results despite thematic consistency
- Relatively small sample size of AI-generated stories (80) compared to human stories (250) introduces potential sampling bias
- Focus on Pygmalion myth theme may limit generalizability of findings to broader storytelling contexts

## Confidence

**High confidence:** AI stories show greater gender/sexual diversity than human stories (supported by quantitative data)

**Medium confidence:** AI stories are less imaginative and more formulaic than human stories (based on qualitative analysis with some quantitative backing)

**Medium confidence:** The framework effectively reveals cultural biases in both human and AI storytelling (methodologically sound but limited by scope)

## Next Checks

1. Replicate the study using multiple prompt variations to test prompt sensitivity and ensure findings aren't specific to the Pygmalion theme
2. Expand the analysis to include newer AI models (GPT-4 Turbo, Claude 3) and compare their storytelling capabilities against human writers
3. Conduct a controlled study with human writers from diverse demographic backgrounds to better understand how writer characteristics influence narrative outcomes compared to AI outputs