---
ver: rpa2
title: Benchmark datasets for biomedical knowledge graphs with negative statements
arxiv_id: '2307.11719'
source_url: https://arxiv.org/abs/2307.11719
tags:
- negative
- statements
- prediction
- positive
- disease
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces benchmark datasets for biomedical knowledge
  graphs with negative statements, addressing the scarcity of such data for evaluating
  machine learning methods. The authors create three datasets for protein-protein
  interaction prediction, gene-disease association prediction, and disease prediction
  by enriching Gene Ontology and Human Phenotype Ontology with negative statements.
---

# Benchmark datasets for biomedical knowledge graphs with negative statements

## Quick Facts
- arXiv ID: 2307.11719
- Source URL: https://arxiv.org/abs/2307.11719
- Reference count: 20
- Primary result: Incorporating negative statements into biomedical knowledge graphs improves PPI prediction performance by up to 2.5% F1 score

## Executive Summary
This work introduces benchmark datasets for biomedical knowledge graphs enriched with negative statements, addressing a critical gap in evaluation resources for machine learning methods. The authors create three datasets for protein-protein interaction prediction, gene-disease association prediction, and disease prediction by enhancing Gene Ontology and Human Phenotype Ontology with negative statements. Using RDF2Vec and OWL2Vec* embedding methods combined with Random Forest classifiers, the experiments demonstrate that incorporating negative statements generally improves performance across tasks, with the most significant gains observed in protein-protein interaction prediction.

## Method Summary
The authors construct knowledge graphs from Gene Ontology (GO) and Human Phenotype Ontology (HP), enriching them with negative statements derived from evolutionary conservation data and expert curation. For evaluation, they employ two path-based embedding methods (RDF2Vec and OWL2Vec*) to generate features from these KGs, which are then used to train Random Forest classifiers for three distinct prediction tasks: protein-protein interaction, gene-disease association, and disease prediction. Performance is assessed through Monte Carlo cross-validation, comparing models trained on positive-only versus positive-plus-negative statement combinations.

## Key Results
- Incorporating negative statements improves PPI prediction performance by up to 2.5% F1 score using RDF2Vec
- Performance improvements are observed across precision (up to 2.5%), recall (up to 2.2%), and F1-score metrics
- Mixed results are observed with OWL2Vec*, where performance gains are less consistent across tasks
- The enriched datasets are made publicly available on Zenodo for community use

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Negative statements improve knowledge graph embedding performance by providing discriminative training signals
- Mechanism: By explicitly encoding negative statements into the KG, embedding models can learn better decision boundaries between related and unrelated entities, reducing ambiguity under the open-world assumption
- Core assumption: The embedding model can effectively utilize both positive and negative statements during training without introducing contradictory signals
- Evidence anchors:
  - [abstract] "Results show that incorporating negative statements generally improves performance, with precision, recall, and F1-score increases of up to 2.5%, 2.2%, and 2.0% respectively for PPI prediction using RDF2Vec."
  - [section] "The experiments show that the added information given by negative statements generally improves the performance of RDF2Vec."
  - [corpus] Weak evidence: corpus neighbors discuss negative statements in KG embeddings but don't provide specific performance improvements for biomedical datasets
- Break condition: If negative statements introduce too much noise or contradiction, performance could degrade instead of improving

### Mechanism 2
- Claim: Enriching biomedical ontologies with negative statements creates more realistic and representative datasets for evaluation
- Mechanism: By adding negative statements based on domain knowledge (e.g., evolutionary conservation, expert curation), the datasets better reflect the true distribution of relationships in biological systems, making evaluation more meaningful
- Core assumption: The negative statements added are accurate representations of biological reality and not arbitrary or contradictory
- Evidence anchors:
  - [abstract] "These datasets include data from two successful biomedical ontologies, Gene Ontology and Human Phenotype Ontology, enriched with negative statements."
  - [section] "The GO KG was also enriched with negative statements derived from expert-curated annotations of protein families on phylogenetic trees."
  - [corpus] Weak evidence: corpus neighbors discuss negative statements in KGs but don't provide specific evidence about biomedical ontology enrichment
- Break condition: If the negative statements are not biologically accurate or introduce too much noise, the datasets may become less representative rather than more

### Mechanism 3
- Claim: Using path-based embedding methods (RDF2Vec, OWL2Vec*) combined with Random Forest classifiers leverages the enriched negative statements effectively
- Mechanism: Path-based methods can capture the structural context of both positive and negative relationships, and Random Forest can learn to discriminate based on these features, leading to improved performance
- Core assumption: The combination of path-based embeddings and Random Forest is well-suited to handle the features generated from both positive and negative statements
- Evidence anchors:
  - [abstract] "We also generate knowledge graph embeddings for each dataset with two popular path-based methods and evaluate the performance in each task."
  - [section] "Therefore, we use two KG embedding methods to evaluate our datasets - RDF2Vec [12] and OWL2Vec* [2]."
  - [corpus] Weak evidence: corpus neighbors discuss KG embedding methods but don't provide specific evidence about their combination with Random Forest for biomedical tasks
- Break condition: If the embedding methods cannot effectively capture the information from negative statements, or if Random Forest is not the optimal classifier for these features, performance may not improve

## Foundational Learning

- Concept: Open-world assumption in knowledge graphs
  - Why needed here: Understanding that KGs operate under the open-world assumption is crucial for grasping why negative statements are important and how they can improve performance
  - Quick check question: What is the key difference between the open-world assumption and the closed-world assumption in knowledge representation?

- Concept: Gene Ontology (GO) and Human Phenotype Ontology (HP)
  - Why needed here: The paper uses these two biomedical ontologies as the basis for the knowledge graphs, so understanding their structure and purpose is essential
  - Quick check question: What are the three main categories of biological knowledge represented in the Gene Ontology?

- Concept: Knowledge graph embedding methods (RDF2Vec, OWL2Vec*)
  - Why needed here: These methods are used to generate features from the enriched knowledge graphs, which are then used for classification tasks
  - Quick check question: How do path-based embedding methods like RDF2Vec generate features from knowledge graphs?

## Architecture Onboarding

- Component map: Biomedical ontologies (GO, HP) → Negative statement enrichment → Dataset generation → KG embedding → Feature combination → Classification → Evaluation
- Critical path: Ontology → Negative statement enrichment → Dataset generation → KG embedding → Feature combination → Classification → Evaluation
- Design tradeoffs:
  - Positive vs. negative statement balance: Too many negative statements might introduce noise, while too few might not provide sufficient discriminative power
  - Embedding method choice: RDF2Vec vs. OWL2Vec* may perform differently depending on the specific task and dataset characteristics
  - Classifier choice: While Random Forest is used here, other classifiers might perform better or worse depending on the feature distributions
- Failure signatures:
  - Decreased performance when negative statements are added, indicating potential noise or contradiction in the negative statements
  - Poor generalization in cross-validation, suggesting overfitting to the training data
  - Large performance gaps between RDF2Vec and OWL2Vec*, indicating potential issues with one of the embedding methods for certain tasks
- First 3 experiments:
  1. Replicate the main experiment with RDF2Vec and positive-only statements to establish a baseline
  2. Repeat the experiment with RDF2Vec and both positive and negative statements to verify the performance improvement
  3. Compare the performance of RDF2Vec and OWL2Vec* on the PPI prediction task to understand the difference between the two embedding methods

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions, but several important research directions emerge from the results and methodology presented.

## Limitations
- The HP KG for GDA and disease prediction tasks has relatively few negative statements, limiting the generalizability of findings
- The study only evaluates two KG embedding methods, leaving uncertainty about how other methods would perform with negative statements
- Performance gains are modest (up to 2.5% F1) and highly dependent on task and method choice

## Confidence
- Core claim about negative statements improving performance: Medium
- Dataset utility for the research community: High
- Generalizability across biomedical domains: Low

## Next Checks
1. **Ablation study**: Test performance with only positive statements versus only negative statements versus combined to isolate the contribution of negative information
2. **Classifier comparison**: Evaluate alternative classifiers (e.g., gradient boosting, neural networks) to verify Random Forest is optimal for these embedding features
3. **Parameter sensitivity**: Systematically vary RDF2Vec/OWL2Vec* parameters (walk length, dimensions, iterations) to establish robustness of observed improvements across hyperparameter settings