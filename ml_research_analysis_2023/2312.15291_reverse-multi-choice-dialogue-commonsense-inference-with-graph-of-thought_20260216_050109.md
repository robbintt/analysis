---
ver: rpa2
title: Reverse Multi-Choice Dialogue Commonsense Inference with Graph-of-Thought
arxiv_id: '2312.15291'
source_url: https://arxiv.org/abs/2312.15291
tags:
- options
- rex-got
- reasoning
- cicero
- commonsense
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenges of option saturation and clue
  labyrinth in Dialogue Commonsense Multi-choice Question Answering (DC-MCQ) tasks.
  The proposed Reverse Exclusion Graph-of-Thought (ReX-GoT) framework mimics human
  reasoning by progressively excluding irrelevant options and integrating clues through
  a graph-of-thought approach.
---

# Reverse Multi-Choice Dialogue Commonsense Inference with Graph-of-Thought

## Quick Facts
- **arXiv ID**: 2312.15291
- **Source URL**: https://arxiv.org/abs/2312.15291
- **Reference count**: 14
- **Primary result**: ReX-GoT achieves 17.67% F1 score improvement over best baseline in zero-shot settings

## Executive Summary
This paper addresses the challenges of option saturation and clue labyrinth in Dialogue Commonsense Multi-choice Question Answering (DC-MCQ) tasks. The proposed Reverse Exclusion Graph-of-Thought (ReX-GoT) framework mimics human reasoning by progressively excluding irrelevant options and integrating clues through a graph-of-thought approach. Experiments on CICERO and CICERO v2 datasets show that ReX-GoT outperforms state-of-the-art baselines, achieving significant improvements in both zero-shot and few-shot settings when using GPT3.5.

## Method Summary
ReX-GoT implements a three-step sequential process using Flan-T5 as the backbone LLM: (1) Option Exclusion - identifies and justifies implausible options, (2) Error Analysis - evaluates remaining options using exclusion insights, and (3) Combine Information - synthesizes analyses into multiple reasoning paths with voting for final answer selection. The framework specifically targets the option saturation and clue labyrinth challenges in DC-MCQ by narrowing candidate space before complex reasoning and organizing clue integration through a graph structure.

## Key Results
- 17.67% increase in F1 score over best baseline in zero-shot settings
- 39.44% increase in F1 score when using GPT3.5 model
- Outperforms state-of-the-art baselines on both CICERO and CICERO v2 datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The reverse exclusion approach reduces option saturation by progressively eliminating implausible options before reasoning.
- **Mechanism**: LLM identifies and justifies why certain options are unreasonable given dialogue context, narrowing candidate space.
- **Core assumption**: LLMs can reliably identify contextually implausible options when given explicit exclusion instructions.
- **Evidence anchors**: Abstract states "gradually excluding irrelevant options," section describes initial judgment to exclude unreasonable options.
- **Break condition**: If LLM fails to correctly identify implausible options, incorrect options may persist into later reasoning stages.

### Mechanism 2
- **Claim**: The graph-of-thought structure enables multidimensional clue integration by organizing reasoning paths around different exclusion insights.
- **Mechanism**: After exclusion, error analysis on remaining options creates multiple reasoning paths, with final answer selected via voting.
- **Core assumption**: Different exclusion and analysis outcomes create distinct reasoning trajectories that yield more robust predictions when combined.
- **Evidence anchors**: Abstract mentions "progressively integrating intricate clues," section describes constructing graph-of-thought for error analysis.
- **Break condition**: If GoT paths are too similar or voting cannot distinguish quality among paths, graph structure benefit diminishes.

### Mechanism 3
- **Claim**: The three-step sequential process aligns with human cognitive strategies for multi-choice reasoning.
- **Mechanism**: Each step builds on previous insights, creating traceable reasoning chain where incorrect options are systematically eliminated.
- **Core assumption**: Human-like stepwise reasoning processes incorporating exclusion are more effective than direct selection approaches.
- **Evidence anchors**: Abstract states "inspired by human cognitive process," section describes mimicking human reasoning.
- **Break condition**: If stepwise dependencies are too rigid, model may struggle with questions where optimal reasoning order differs from prescribed sequence.

## Foundational Learning

- **Concept**: Chain-of-Thought prompting
  - **Why needed**: Enables LLM to generate intermediate reasoning steps rather than jumping directly to answers for complex tasks
  - **Quick check**: What is the primary difference between standard prompting and Chain-of-Thought prompting for LLMs?

- **Concept**: Commonsense inference in dialogue
  - **Why needed**: Task requires understanding unstated implications and social norms within conversational contexts
  - **Quick check**: Why is dialogue commonsense inference more challenging than standard text-based commonsense tasks?

- **Concept**: Option saturation and clue labyrinth challenges
  - **Why needed**: These specific challenges define why existing methods fail on multi-choice dialogue tasks and motivate the proposed solution
  - **Quick check**: How do option saturation and clue labyrinth differ in their impact on multi-choice reasoning performance?

## Architecture Onboarding

- **Component map**: Input processor -> Option exclusion module -> Error analysis module -> Information combiner -> Voting mechanism -> Final answer
- **Critical path**: Option exclusion → Error analysis → Combine information → Voting → Final answer
- **Design tradeoffs**: Prompt complexity vs. inference cost; Number of GoT paths vs. accuracy; Model size vs. performance
- **Failure signatures**: Consistent misidentification of implausible options suggests prompt or model capability issues; Low variance among GoT paths indicates insufficient reasoning space exploration
- **First 3 experiments**:
  1. Run ablation test removing exclusion step to measure its contribution
  2. Test different voting mechanisms (majority vs. confidence-weighted)
  3. Compare performance across different LLM sizes (Flan-T5-3B vs 11B)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does ReX-GoT performance change when applied to different types of commonsense reasoning tasks beyond dialogue-based ones?
- **Basis in paper**: Paper focuses on dialogue-based commonsense inference but doesn't explore other types of commonsense reasoning tasks
- **Why unresolved**: No experiments or analysis on other commonsense reasoning tasks provided
- **What evidence would resolve it**: Testing ReX-GoT on various commonsense reasoning tasks (visual, text-based) and comparing performance to existing methods

### Open Question 2
- **Question**: What is the impact of using different prompt templates or variations in the ReX-GoT framework on model performance?
- **Basis in paper**: Framework is described but different prompt templates or variations aren't explored
- **Why unresolved**: No experiments or analysis on different prompt templates or variations provided
- **What evidence would resolve it**: Conducting experiments with different prompt templates or variations and comparing performance on dialogue commonsense inference tasks

### Open Question 3
- **Question**: How does ReX-GoT handle cases where dialogue context is ambiguous or lacks sufficient information for accurate inference?
- **Basis in paper**: Paper doesn't discuss handling ambiguous or insufficient dialogue contexts
- **Why unresolved**: No experiments or analysis on cases with ambiguous or insufficient dialogue contexts provided
- **What evidence would resolve it**: Testing ReX-GoT on dialogue datasets with ambiguous or insufficient contexts and analyzing performance and reasoning process

## Limitations

- The voting mechanism lacks specific implementation details, making it difficult to determine if performance gains stem from exclusion process or aggregation method
- Paper relies heavily on the assumption that exclusion is the primary performance driver without ablation studies showing relative contribution of each component
- Doesn't address potential biases in the exclusion step - systematic exclusion of certain option types could create systematic errors

## Confidence

**High confidence**: Empirical results showing ReX-GoT outperforming baselines on CICERO datasets are well-supported by reported F1 and EM scores, with compelling 17.67% zero-shot improvement.

**Medium confidence**: Claim that reverse exclusion reduces option saturation is plausible but relies on unverified assumptions about LLM reliability in exclusion step.

**Low confidence**: Assertion that graph-of-thought structure enables multidimensional clue integration is weakest claim - paper describes voting but doesn't explain how different reasoning paths are generated or why graph structure specifically improves over linear reasoning.

## Next Checks

1. **Ablation study validation**: Remove exclusion step entirely and measure performance degradation to quantify actual contribution of reverse exclusion mechanism versus general Chain-of-Thought approach.

2. **Error analysis on exclusion accuracy**: For subset of questions, manually evaluate whether LLM correctly identifies implausible options in exclusion step to validate core assumption about LLM reliability.

3. **Voting mechanism audit**: Analyze diversity of reasoning paths generated by GoT structure by measuring path similarity scores and examining close versus clear voting decisions to reveal whether graph structure actually creates diverse reasoning trajectories.