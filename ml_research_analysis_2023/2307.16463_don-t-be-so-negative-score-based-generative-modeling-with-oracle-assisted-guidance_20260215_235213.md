---
ver: rpa2
title: Don't be so negative! Score-based Generative Modeling with Oracle-assisted
  Guidance
arxiv_id: '2307.16463'
source_url: https://arxiv.org/abs/2307.16463
tags:
- classifier
- diffusion
- gen-neg
- baseline
- infraction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of generating samples from a generative
  model while avoiding regions in the data space that are deemed invalid by an oracle
  function. The proposed method, Gen-neG, iteratively trains a sequence of classifiers
  to guide a diffusion model towards the valid regions, while maintaining or improving
  the model's likelihood on the true data distribution.
---

# Don't be so negative! Score-based Generative Modeling with Oracle-assisted Guidance

## Quick Facts
- **arXiv ID**: 2307.16463
- **Source URL**: https://arxiv.org/abs/2307.16463
- **Reference count**: 40
- **Primary result**: Gen-neG reduces invalid samples in diffusion model generation while maintaining or improving likelihood through iterative classifier training and importance sampling.

## Executive Summary
The paper addresses the challenge of generating samples from a generative model while avoiding regions in the data space that are deemed invalid by an oracle function. The proposed method, Gen-neG, iteratively trains a sequence of classifiers to guide a diffusion model towards the valid regions, while maintaining or improving the model's likelihood on the true data distribution. Gen-neG achieves this by carefully balancing the synthetic dataset used to train each classifier and employing importance sampling to correct for distribution shifts. The method is evaluated on three tasks: a toy checkerboard dataset, traffic scene generation, and motion generation. Results show that Gen-neG can significantly reduce the rate of invalid samples while maintaining or improving the model's likelihood.

## Method Summary
Gen-neG builds on classifier guidance in diffusion models to guide the generation process towards the positive support region indicated by the oracle. The method iteratively trains a sequence of classifiers to distinguish valid from invalid samples, using synthetic data generated by the baseline diffusion model. To address the challenge of distribution shift caused by balancing the synthetic dataset, Gen-neG employs importance sampling in the classifier's training objective. The sequence of classifiers can be stacked to progressively improve the model or distilled into a single model to reduce computational cost while maintaining performance.

## Key Results
- Gen-neG significantly reduces the rate of invalid samples while maintaining or improving the model's likelihood on held-out validation data
- The method outperforms a baseline diffusion model without guidance on all three evaluation tasks
- Distillation of the sequence of classifiers into a single model reduces computational cost while maintaining performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Gen-neG reduces the rate of invalid samples by iteratively training classifiers on synthetic data and using them to guide the diffusion model toward the valid region.
- **Mechanism:** The process involves generating samples from the baseline diffusion model, labeling them with the oracle to identify invalid samples, and training a binary classifier to distinguish between valid and invalid samples. This classifier is then used to guide the diffusion model by modifying its score function. The iterative process of generating, labeling, and training classifiers helps to progressively reduce the rate of invalid samples.
- **Core assumption:** The oracle function accurately identifies invalid samples, and the classifiers trained on synthetic data can effectively guide the diffusion model toward the valid region.
- **Evidence anchors:**
  - [abstract]: "Gen-neG builds on classifier guidance in diffusion models to guide the generation process towards the positive support region indicated by the oracle."
  - [section 3.2]: "Gen-neG instead builds a binary classification task using the fully-synthetic data generated by the baseline DM i.e. the data is distributed as pÎ¸(x) and the labels are y = O(x)."
  - [corpus]: Weak, no direct evidence in corpus papers.
- **Break condition:** If the oracle function is not accurate or the classifiers fail to effectively guide the diffusion model, the rate of invalid samples may not decrease as expected.

### Mechanism 2
- **Claim:** The importance sampling technique used in training the classifiers corrects for the distribution shift caused by balancing the synthetic dataset.
- **Mechanism:** When training the classifier, the synthetic dataset is balanced to ensure an equal number of valid and invalid samples. However, this balancing can introduce a distribution shift. Importance sampling is used to correct for this shift by reweighting the samples during training, ensuring that the classifier is trained on a dataset that accurately represents the true distribution.
- **Core assumption:** The importance sampling technique effectively corrects for the distribution shift without introducing additional bias.
- **Evidence anchors:**
  - [section 3.2]: "Gen-neG addresses this challenge by sampling a balanced dataset D from the model, ensuring the same number of positive and negative examples. However, Gen-neG crucially employs importance sampling in the classifier's training objective to rectify the bias introduced by having to balance the dataset."
  - [corpus]: Weak, no direct evidence in corpus papers.
- **Break condition:** If the importance sampling technique is not effective or introduces additional bias, the classifier may not be trained on an accurate representation of the true distribution.

### Mechanism 3
- **Claim:** Distilling the sequence of classifiers into a single diffusion model reduces computational cost while maintaining performance.
- **Mechanism:** Instead of stacking multiple classifiers, which increases computational cost, the sequence of classifiers is distilled into a single diffusion model. This distillation process involves training a new model to match the outputs of the teacher model (the sequence of classifiers) using a distillation loss. The resulting distilled model has a single score function estimator, reducing computational cost while maintaining performance.
- **Core assumption:** The distillation process effectively captures the behavior of the sequence of classifiers in a single model without significant loss of performance.
- **Evidence anchors:**
  - [section 3.2]: "To avoid this, we propose to distill the classifiers into the baseline model."
  - [corpus]: Weak, no direct evidence in corpus papers.
- **Break condition:** If the distillation process fails to capture the behavior of the sequence of classifiers, the distilled model may not perform as well as the stacked classifiers.

## Foundational Learning

- **Concept:** Diffusion Models
  - **Why needed here:** Understanding diffusion models is crucial for implementing Gen-neG, as it relies on the properties and training procedures of diffusion models.
  - **Quick check question:** What is the role of the score function in diffusion models, and how is it learned?

- **Concept:** Classifier Guidance
  - **Why needed here:** Classifier guidance is a key component of Gen-neG, as it uses classifiers to guide the diffusion model toward the valid region.
  - **Quick check question:** How does classifier guidance modify the score function of a diffusion model?

- **Concept:** Importance Sampling
  - **Why needed here:** Importance sampling is used to correct for the distribution shift caused by balancing the synthetic dataset in Gen-neG.
  - **Quick check question:** What is the purpose of importance sampling, and how does it correct for distribution shifts?

## Architecture Onboarding

- **Component map:**
  - Baseline Diffusion Model -> Oracle Function -> Classifiers -> Distillation Model

- **Critical path:**
  1. Train the baseline diffusion model on the dataset.
  2. Generate synthetic samples from the baseline model and label them with the oracle.
  3. Train a binary classifier on the balanced synthetic dataset using importance sampling.
  4. Use the classifier to guide the diffusion model by modifying its score function.
  5. Optionally, distill the sequence of classifiers into a single diffusion model.

- **Design tradeoffs:**
  - Balancing the synthetic dataset vs. using importance sampling: Balancing ensures equal representation of valid and invalid samples, but introduces distribution shift. Importance sampling corrects for this shift but may introduce additional complexity.
  - Stacking classifiers vs. distillation: Stacking classifiers maintains performance but increases computational cost. Distillation reduces computational cost but may introduce some performance loss.

- **Failure signatures:**
  - High rate of invalid samples: Indicates that the oracle function is not accurate or the classifiers are not effectively guiding the diffusion model.
  - Poor performance of the distilled model: Indicates that the distillation process failed to capture the behavior of the sequence of classifiers.

- **First 3 experiments:**
  1. Train the baseline diffusion model on a simple dataset and evaluate its performance.
  2. Implement the oracle function and generate synthetic samples from the baseline model.
  3. Train a binary classifier on the balanced synthetic dataset using importance sampling and evaluate its performance.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the provided text.

## Limitations
- The empirical evaluation is limited to three specific tasks, with no comprehensive ablation studies on the importance of individual components
- The computational overhead of the iterative classifier training process is not fully quantified relative to the performance gains
- The method's robustness to different oracle qualities and noise levels is not thoroughly explored

## Confidence

- **High Confidence**: The core mechanism of using classifiers to guide diffusion models toward valid regions is well-established and theoretically sound
- **Medium Confidence**: The effectiveness of the importance sampling correction for distribution shifts, as the paper provides theoretical justification but limited empirical validation
- **Low Confidence**: The generalization capability across diverse domains, given the limited number of experimental tasks

## Next Checks
1. Conduct an ablation study isolating the impact of importance sampling on classifier performance by comparing with and without this technique on the same oracle-guided generation task
2. Test the method on a synthetic dataset where the oracle's ground truth is known, measuring both infraction rates and likelihood across multiple oracle strictness levels
3. Implement the distillation component separately to quantify the exact computational savings and any performance degradation compared to the stacked classifier approach