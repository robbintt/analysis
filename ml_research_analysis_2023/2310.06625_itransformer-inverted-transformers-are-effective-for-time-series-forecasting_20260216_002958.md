---
ver: rpa2
title: 'iTransformer: Inverted Transformers Are Effective for Time Series Forecasting'
arxiv_id: '2310.06625'
source_url: https://arxiv.org/abs/2310.06625
tags:
- series
- time
- transformer
- uni00000013
- forecasting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes iTransformer, an inverted Transformer architecture
  for time series forecasting. Instead of using temporal tokens formed by multiple
  variates at the same timestamp, iTransformer embeds each variate's entire time series
  into a token, applies attention to capture multivariate correlations, and uses a
  feed-forward network to learn series representations.
---

# iTransformer: Inverted Transformers Are Effective for Time Series Forecasting

## Quick Facts
- arXiv ID: 2310.06625
- Source URL: https://arxiv.org/abs/2310.06625
- Reference count: 40
- This work proposes iTransformer, an inverted Transformer architecture for time series forecasting that achieves state-of-the-art performance on real-world benchmarks.

## Executive Summary
iTransformer introduces an inverted Transformer architecture for time series forecasting that embeds each variate's entire time series into a token instead of using temporal tokens formed by multiple variates at the same timestamp. This design addresses the limitations of vanilla Transformers in handling multivariate time series with larger lookback windows and captures multivariate correlations more effectively. The model demonstrates improved accuracy, better generalization across variates, and more effective utilization of lookback windows compared to traditional Transformer-based forecasters on real-world forecasting benchmarks.

## Method Summary
iTransformer is an encoder-only architecture that inverts the traditional Transformer design by embedding each variate's entire time series into a token rather than embedding multiple variates at the same timestamp. The model consists of embedding layers that convert time series into variate tokens, L Transformer blocks with layer normalization, self-attention modules applied on variate tokens to capture multivariate correlations, and feed-forward networks for series representations. The architecture uses linear projections to decode predictions and trains with Adam optimizer (learning rates 10⁻³ to 10⁻⁴) for 10 epochs with batch size 32, minimizing MSE/MAE on real-world datasets.

## Key Results
- Achieves state-of-the-art performance on real-world forecasting benchmarks including ETT, Electricity, Traffic, Weather, Solar-Energy, PEMS, and Market datasets
- Demonstrates improved accuracy and better generalization across different variates compared to vanilla Transformers
- Shows enhanced interpretability of learned attention maps revealing multivariate correlations more clearly

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Inverting the Transformer architecture improves time series forecasting by embedding each variate's entire time series as a token instead of embedding multiple variates at the same timestamp.
- Mechanism: The iTransformer embeds each variate's entire time series into a token, allowing the attention mechanism to capture multivariate correlations across time series and the feed-forward network to learn series representations. This approach addresses the limitations of the vanilla Transformer architecture, which embeds multiple variates of the same timestamp into indistinguishable channels and applies attention on these temporal tokens.
- Core assumption: The time points of the same time step represent completely different physical meanings recorded by inconsistent measurements, and a single time step token can struggle to reveal beneficial information due to an excessively local receptive field and unaligned timestamps of multivariate time points in the real world.
- Evidence anchors:
  - [abstract] "However, Transformers are challenged in forecasting series with larger lookback windows due to performance degradation and computation explosion. Besides, the embedding for each temporal token fuses multiple variates that represent potential delayed events and distinct physical measurements, which may fail in learning variate-centric representations and result in meaningless attention maps."
  - [section] "Considering the irrationality of embedding multivariate points of each time step as a (temporal) token, we take an inverted view on time series and embed the whole series of each variate independently into a (variate) token..."
  - [corpus] Weak evidence - the corpus contains papers with similar titles but no specific evidence for this mechanism.

### Mechanism 2
- Claim: The inverted architecture of iTransformer allows for better utilization of arbitrary lookback windows and improved generalization across different variates.
- Mechanism: By inverting the duties of the attention mechanism and the feed-forward network, iTransformer can effectively capture multivariate correlations and learn series representations for any lookback window length. This is achieved by embedding each time series as variate tokens, applying attention for multivariate correlations, and using the feed-forward network for series encoding.
- Core assumption: The feed-forward network is proficient enough to learn generalizable representations for distinct variates encoded from arbitrary lookback series and decoded to predict future series.
- Evidence anchors:
  - [abstract] "Experimentally, the proposed iTransformer achieves state-of-the-art performance on real-world forecasting benchmarks, which further empowers the Transformer family with promoted performance, generalization ability across different variates, and better utilization of arbitrary lookback windows..."
  - [section] "Concretely, with comprehensively extracted representations of each time series H = {h0, . . . ,hN } ∈ RN ×D, the self-attention module adopts linear projections to get queries, keys and values Q, K, V ∈ RN ×dk, where dk is the projected dimension."
  - [corpus] Weak evidence - the corpus contains papers with similar titles but no specific evidence for this mechanism.

### Mechanism 3
- Claim: The inverted architecture of iTransformer leads to enhanced interpretability of the learned attention maps, revealing multivariate correlations more clearly.
- Mechanism: By assigning the duty of multivariate correlation to the attention mechanism and applying it on the variate dimension, the learned score maps can exhibit enhanced interpretability, revealing the multivariate correlations between paired variate tokens. This is in contrast to the vanilla Transformer architecture, where the attention is applied on the temporal dimension, making it less interpretable for multivariate series forecasting.
- Core assumption: The entries of the pre-Softmax scores, formulated as Ai,j = (QK⊤/√dk)i,j ∝ q⊤i kj, can reveal the variate-wise correlation, and the whole score map A ∈ RN ×N exhibits the multivariate correlations between paired variate tokens.
- Evidence anchors:
  - [abstract] "Experimentally, the proposed iTransformer achieves consistent state-of-the-art on real-world forecasting benchmarks, which further empowers the Transformer family with promoted performance, generalization ability across different variates, and better utilization of arbitrary lookback windows..."
  - [section] "Concretely, with comprehensively extracted representations of each time series H = {h0, . . . ,hN } ∈ RN ×D, the self-attention module adopts linear projections to get queries, keys and values Q, K, V ∈ RN ×dk, where dk is the projected dimension."
  - [corpus] Weak evidence - the corpus contains papers with similar titles but no specific evidence for this mechanism.

## Foundational Learning

- Concept: Understanding of Transformer architecture and its components (attention mechanism, feed-forward network, layer normalization)
  - Why needed here: The iTransformer is based on the Transformer architecture, but with inverted duties for the attention mechanism and feed-forward network. A solid understanding of the original Transformer components is necessary to grasp the changes made in the iTransformer.
  - Quick check question: What are the main components of the Transformer architecture, and how do they work together in the original design?

- Concept: Time series forecasting and the challenges associated with it
  - Why needed here: The iTransformer is specifically designed for time series forecasting, addressing the limitations of the vanilla Transformer architecture in this domain. Understanding the challenges and requirements of time series forecasting is crucial to appreciate the benefits of the iTransformer.
  - Quick check question: What are the main challenges in time series forecasting, and how do they differ from other sequence modeling tasks?

- Concept: Attention mechanisms and their role in capturing dependencies
  - Why needed here: The iTransformer relies on the attention mechanism to capture multivariate correlations across the inverted dimension. Understanding how attention mechanisms work and their ability to capture dependencies is essential to grasp the effectiveness of the iTransformer.
  - Quick check question: How does the attention mechanism work in the Transformer architecture, and what types of dependencies can it capture?

## Architecture Onboarding

- Component map: Embedding layer -> Transformer blocks (L layers) -> Layer normalization -> Feed-forward network -> Self-attention -> Projection layer

- Critical path:
  1. Embed each variate's entire time series into a token using the embedding layer
  2. Pass the embedded tokens through L Transformer blocks
  3. In each block, apply layer normalization, feed-forward network, and attention on the variate tokens
  4. Project the learned representations back to the predicted series using the projection layer

- Design tradeoffs:
  - The inverted architecture may require more memory compared to the vanilla Transformer, as each variate's entire time series is embedded into a token
  - The iTransformer may be less effective for time series with strong temporal dependencies within each variate, as the attention is focused on capturing multivariate correlations
  - The iTransformer may require more computational resources compared to simpler linear models, but it offers improved performance and interpretability

- Failure signatures:
  - Poor performance on time series with strong temporal dependencies within each variate
  - Overfitting on small datasets due to the increased model complexity
  - Difficulty in capturing long-range dependencies across variates if the lookback window is too small

- First 3 experiments:
  1. Compare the performance of iTransformer with the vanilla Transformer on a simple time series forecasting task with a small number of variates
  2. Evaluate the impact of the lookback window length on the performance of iTransformer, varying the number of time steps used for prediction
  3. Visualize the learned attention maps of iTransformer on a multivariate time series dataset to assess the interpretability of the model

## Open Questions the Paper Calls Out
No open questions are explicitly called out in the provided content.

## Limitations
- The evidence anchors rely heavily on the paper's own claims without external validation
- Corpus signals show weak support for the proposed mechanisms
- Critical architectural details like exact MLP configurations remain unspecified
- Performance comparisons lack statistical significance testing

## Confidence
- High confidence: The inverted architecture design is clearly specified
- Medium confidence: Performance claims on benchmarks appear reproducible but lack statistical validation
- Low confidence: Mechanism explanations connecting design to performance gains are largely self-referential

## Next Checks
1. Reproduce the MLP layer configurations for Embedding and Projection layers using the datasets described, measuring both accuracy and training efficiency
2. Conduct ablation studies isolating the inverted architecture's contribution versus baseline Transformer improvements
3. Generate and analyze attention maps across multiple datasets to verify claims about enhanced interpretability of multivariate correlations