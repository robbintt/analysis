---
ver: rpa2
title: 'BAMBOO: A Comprehensive Benchmark for Evaluating Long Text Modeling Capacities
  of Large Language Models'
arxiv_id: '2309.13345'
source_url: https://arxiv.org/abs/2309.13345
tags:
- long
- text
- llms
- tasks
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents BAMBOO, a comprehensive benchmark designed
  to evaluate the long text modeling capabilities of large language models (LLMs).
  BAMBOO addresses the limitations of existing benchmarks by focusing on four key
  principles: comprehensive capacity evaluation, avoidance of data contamination,
  accurate automatic evaluation, and different length levels.'
---

# BAMBOO: A Comprehensive Benchmark for Evaluating Long Text Modeling Capacities of Large Language Models

## Quick Facts
- arXiv ID: 2309.13345
- Source URL: https://arxiv.org/abs/2309.13345
- Reference count: 21
- Primary result: ChatGPT-16k exhibits optimal performance over most datasets, while other models struggle on long text tasks

## Executive Summary
This paper introduces BAMBOO, a comprehensive benchmark designed to evaluate the long text modeling capabilities of large language models (LLMs). The benchmark addresses limitations of existing evaluation methods by focusing on comprehensive capacity evaluation, avoiding data contamination, ensuring accurate automatic evaluation, and testing different length levels. BAMBOO consists of 10 datasets from 5 long text understanding tasks, evaluating language generation, knowledge utilization, reasoning, and tool manipulation abilities over long texts. The authors conduct experiments with five long context models and identify key research questions in long text modeling, providing both quantitative results and qualitative analysis of current limitations.

## Method Summary
The authors constructed BAMBOO by collecting 10 datasets from 5 long text understanding tasks, creating both 4k and 16k token variants for comprehensive evaluation. They evaluated five long context models (ChatGPT-16k, Claude2-100k, ChatGLM2-32k, Vicuna-16k, Longchat-16k) using task-specific automatic evaluation metrics including accuracy, concordance index, pass@1, and precision/recall/F1. The evaluation pipeline involved dataset construction with 2023 data sources to avoid contamination, model inference with extended context windows, and systematic analysis of performance patterns across different task types and input lengths.

## Key Results
- ChatGPT-16k shows optimal performance across most datasets, while other models struggle particularly on unfamiliar tasks
- Input with longer texts often leads to performance drops, confirming the challenge of long text modeling
- Small models suffer from catastrophic forgetting of instructions when task instructions are only located at the beginning of long inputs
- Improvements from providing golden evidence are minimal, suggesting poor reasoning ability rather than retrieval issues is the primary limitation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Extending context length degrades performance on shorter text tasks due to "extension tax"
- Mechanism: When models are trained with longer sequences and position interpolation, their ability to capture short-range dependencies degrades because they prioritize long-range modeling
- Core assumption: The model's architecture and training objective create a trade-off between short and long-range capabilities
- Evidence anchors:
  - We observe a dropped performance on MMLU after replacing Vicuna with Vicuna-16k. The longer training data and position interpolation have undoubtedly harmed the ability on normal-length tasks, which is an "extension tax."
  - Input with longer texts often lead to performance drops
  - Weak evidence - no direct citations found
- Break condition: If models can maintain performance on both short and long sequences through architectural innovations or training strategies that preserve short-range capabilities

### Mechanism 2
- Claim: Model performance varies significantly based on instruction position within long prompts
- Mechanism: Long prompts can cause "instruction forgetting" where models lose track of the task requirements after processing extensive context
- Core assumption: LLMs have limited attention capacity and memory for task instructions when processing long sequences
- Evidence anchors:
  - Small models may suffer catastrophic forgetting of instructions when we only locate the instructions at the beginning of long input
  - We observe that ChatGPT-16k shows optimal performance over most datasets, while other models usually struggle
  - Weak evidence - no direct citations found
- Break condition: If models develop better instruction persistence mechanisms or if instruction positioning becomes irrelevant due to improved context processing

### Mechanism 3
- Claim: Poor performance on long text tasks is primarily due to insufficient reasoning abilities rather than inability to locate relevant information
- Mechanism: Even when given golden evidence, models struggle with tasks requiring complex reasoning, suggesting the core limitation is reasoning capability not information retrieval
- Core assumption: The fundamental bottleneck in long text modeling is the model's reasoning capacity, not its ability to process or attend to relevant context
- Evidence anchors:
  - However, a more important observation is the improvements are very minor... Therefore, we infer that the awful performances of LLMs are mainly due to poor reasoning and coding ability instead of localization evidence in the long text.
  - We find that input with longer texts often leads to performance drops
  - Weak evidence - no direct citations found
- Break condition: If future models demonstrate strong reasoning capabilities that transfer to long text tasks, or if the reasoning limitation is overcome through architectural changes

## Foundational Learning

- Concept: Context window limitations and position interpolation
  - Why needed here: Understanding how models handle extended context is crucial for interpreting BAMBOO results
  - Quick check question: What is position interpolation and how does it enable longer context windows?

- Concept: Automatic evaluation metrics for NLP tasks
  - Why needed here: BAMBOO emphasizes accurate automatic evaluation, which is a key differentiator from other benchmarks
  - Quick check question: What are the advantages and limitations of using accuracy, F1, concordance index, and pass@1 for different task types?

- Concept: Data contamination in LLM evaluation
  - Why needed here: BAMBOO specifically addresses this issue by using 2023 data sources
  - Quick check question: How does data contamination affect the validity of LLM benchmarks and what strategies can mitigate it?

## Architecture Onboarding

- Component map: Task-specific datasets (QA, hallucination detection, text sorting, language modeling, code completion) with 4k and 16k token variants → evaluation metrics for each task type → baseline model implementations → analysis pipeline
- Critical path: Dataset construction → Model evaluation → Analysis of results → Identification of limitations and future directions
- Design tradeoffs: Comprehensive evaluation vs. dataset size, avoiding contamination vs. dataset diversity, automatic evaluation vs. human judgment
- Failure signatures: Performance drops with increased context length, catastrophic forgetting of instructions, format errors in outputs, poor reasoning on complex tasks
- First 3 experiments:
  1. Run baseline models on both 4k and 16k variants of each dataset to establish performance patterns
  2. Test different instruction positioning strategies to identify optimal prompt formatting
  3. Compare performance when providing only golden evidence vs. complete context to isolate reasoning vs. retrieval capabilities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the "extension tax" phenomenon affect the performance of large language models (LLMs) when adapting to longer context lengths, and what are the underlying mechanisms causing this performance degradation?
- Basis in paper: The paper discusses the "extension tax" as a phenomenon where models like Vicuna experience performance drops on tasks with shorter texts after being adapted for longer contexts. It also mentions that Vicuna without extended context length performs worse on BAMBOO-middle, indicating difficulty adapting to lengths close to its maximum length.
- Why unresolved: While the paper identifies the existence of the "extension tax," it does not provide a detailed analysis of the underlying mechanisms causing this performance degradation. The impact of longer training data and position interpolation on the model's ability to handle normal-length tasks remains unclear.
- What evidence would resolve it: A comprehensive study analyzing the changes in model architecture, training dynamics, and task performance before and after extending context lengths. This could include ablation studies isolating the effects of longer training data and position interpolation techniques.

### Open Question 2
- Question: How do different positions of instruction relative to context affect the performance of LLMs in long text tasks, and what are the optimal instruction positioning strategies for various model architectures and dataset characteristics?
- Basis in paper: The paper explores the impact of instruction positions on long text modeling by placing instructions at different positions relative to the context (e.g., before, after, or both ends of the content). It finds that the best instruction positions vary depending on the input length, datasets, and model.
- Why unresolved: The paper provides initial observations on the impact of instruction positioning but does not offer a comprehensive framework for determining optimal instruction positioning strategies. The interactions between instruction positioning, model architecture, and dataset characteristics remain unexplored.
- What evidence would resolve it: A systematic investigation of instruction positioning strategies across various model architectures, dataset types, and task complexities. This could include empirical studies comparing different positioning strategies and their effects on model performance.

### Open Question 3
- Question: To what extent can context compression techniques, such as retrieval and truncation, enable normal LLMs to effectively model long texts, and what are the limitations and potential improvements for these approaches?
- Basis in paper: The paper explores the use of context compression techniques to enable normal LLMs to handle long texts. It finds that compression can sometimes improve performance, but also highlights limitations such as information loss and adaptation challenges.
- Why unresolved: While the paper demonstrates the potential of context compression techniques, it does not provide a comprehensive evaluation of their effectiveness across different model architectures, dataset types, and compression methods. The optimal compression strategies and their limitations remain unclear.
- What evidence would resolve it: A thorough comparison of various context compression techniques, including retrieval, truncation, and summarization methods, across different model architectures and dataset types. This could include empirical studies evaluating the trade-offs between compression effectiveness, information preservation, and model performance.

## Limitations
- The benchmark relies on automatic evaluation metrics which may not capture all aspects of long text understanding quality
- Limited model diversity, with most evaluated models being variants of LLaMA or ChatGPT
- The study focuses on English-language tasks, limiting generalizability to multilingual contexts
- No human evaluation to validate automatic metric reliability

## Confidence
- High Confidence: The benchmark construction methodology and the observation that input with longer texts often leads to performance drops are well-supported by experimental evidence
- Medium Confidence: The "extension tax" hypothesis is supported by observed performance degradation but requires further validation of causal mechanisms
- Low Confidence: The claim that poor performance is primarily due to reasoning limitations rather than information retrieval is based on limited ablation studies

## Next Checks
1. Conduct ablation studies varying the position of task instructions within prompts to quantify the "instruction forgetting" effect across different model families
2. Perform controlled experiments comparing model performance on tasks requiring different types of reasoning (logical vs. factual) to validate the primary bottleneck hypothesis
3. Test whether fine-tuning models on BAMBOO datasets improves performance on held-out long-text tasks, distinguishing between generalization and memorization effects