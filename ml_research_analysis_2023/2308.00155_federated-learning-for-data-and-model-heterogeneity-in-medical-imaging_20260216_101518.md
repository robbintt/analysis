---
ver: rpa2
title: Federated Learning for Data and Model Heterogeneity in Medical Imaging
arxiv_id: '2308.00155'
source_url: https://arxiv.org/abs/2308.00155
tags:
- data
- learning
- local
- heterogeneity
- heterogeneous
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper proposes MDH-FL, a method to address data and model
  heterogeneity in federated learning for medical imaging. The authors tackle two
  main challenges: 1) model heterogeneity, where clients have different model architectures,
  and 2) data heterogeneity, where clients have non-IID data with diverse labels.'
---

# Federated Learning for Data and Model Heterogeneity in Medical Imaging

## Quick Facts
- arXiv ID: 2308.00155
- Source URL: https://arxiv.org/abs/2308.00155
- Reference count: 35
- Primary result: MDH-FL achieves 81.69% average accuracy on heterogeneous models and homogeneous data, outperforming existing FL methods

## Executive Summary
This paper addresses two critical challenges in federated learning for medical imaging: model heterogeneity (clients with different model architectures) and data heterogeneity (non-IID data with diverse labels). The proposed MDH-FL method combines knowledge distillation with KL divergence alignment to handle model heterogeneity, and employs a symmetric loss function to address label noise in heterogeneous data. The approach is evaluated on hematological cytomorphology datasets, demonstrating superior performance compared to existing FL methods, with accuracies ranging from 72.93% to 83.69% under varying label noise conditions.

## Method Summary
MDH-FL addresses federated learning challenges through a two-phase approach: local training on private data followed by knowledge distribution alignment. Clients first train their heterogeneous models (ShuffleNet, ResNet10, MobileNetv2, ResNet12) on private data using symmetric cross-entropy loss to handle label noise. They then compute KL divergence between their knowledge distributions using a shared public dataset, enabling alignment without sharing model parameters. The server coordinates this process over 40 global epochs with Adam optimizer (learning rate=0.001, batch size=16), evaluating performance on classification accuracy across varying levels of data and model heterogeneity.

## Key Results
- MDH-FL achieves 81.69% average accuracy on heterogeneous models with homogeneous data, outperforming SL-FedL, FedDF, Swarm-FHE, and FedMD
- With symmetric label flip at rates μ=0.1, 0.2, 0.3, MDH-FL achieves accuracies of 83.69%, 79.82%, and 72.93% respectively
- The method demonstrates consistent improvement over baseline approaches across all tested heterogeneity scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: KL divergence alignment of knowledge distributions reduces model heterogeneity impact
- Mechanism: Each client computes KL divergence between its knowledge distribution and others', then updates its local model parameters to minimize this divergence
- Core assumption: Different clients' models produce meaningfully different probability distributions on the same public data
- Evidence anchors:
  - [abstract] "Knowledge distillation is used to solve the problem of model heterogeneity, and symmetric loss tackles with the data and label heterogeneity"
  - [section] "To estimate the variance in knowledge distribution, Kullback-Leibstein (KL) divergence is used by each client"
  - [corpus] Weak - corpus mentions KL divergence in medical imaging but not specific to this federated learning context
- Break condition: If clients' models produce nearly identical outputs on public data, KL divergence becomes negligible and alignment provides minimal benefit

### Mechanism 2
- Claim: Symmetric loss function mitigates label noise effects in heterogeneous data
- Mechanism: Combines standard cross-entropy with reverse cross-entropy to create a loss that is robust to corrupted labels
- Core assumption: Label noise follows symmetric patterns where incorrect labels are equally likely to be any other class
- Evidence anchors:
  - [abstract] "We utilize an additional symmetric loss function to optimize the model learning based-on heterogeneous data containing diverse labels"
  - [section] "We utilize the SymmetricCrossEntropy proposed in [29] to minimize the effect of local noise in model learning"
  - [corpus] Moderate - corpus contains papers on symmetric cross-entropy but none specifically for federated learning with medical imaging
- Break condition: If label noise is highly asymmetric or follows patterns that favor specific incorrect classes, symmetric loss may not adequately address the problem

### Mechanism 3
- Claim: Local training on private data followed by knowledge distribution alignment enables effective global model convergence
- Mechanism: Clients first train locally on their private data to preserve local knowledge, then align with other clients using public data to achieve global consensus
- Core assumption: Local training preserves task-specific knowledge while global alignment improves generalization across heterogeneous data
- Evidence anchors:
  - [abstract] "Each client has its own data and customized models for local training"
  - [section] "A local model updated with its local data to prevent the local knowledge forgetting"
  - [corpus] Weak - corpus mentions local training but not specifically in the context of this two-phase approach
- Break condition: If local training leads to severe overfitting or if the public dataset is too dissimilar from private data, the alignment phase may fail to produce meaningful improvements

## Foundational Learning

- Concept: Kullback-Leibler divergence as a measure of difference between probability distributions
  - Why needed here: KL divergence quantifies the difference between clients' knowledge distributions, enabling alignment of heterogeneous models
  - Quick check question: What property of KL divergence makes it suitable for measuring model output differences rather than just parameter differences?

- Concept: Cross-entropy and reverse cross-entropy combination for robust classification
  - Why needed here: Standard cross-entropy is vulnerable to label noise, while the symmetric combination provides robustness without sacrificing convergence speed
  - Quick check question: How does reverse cross-entropy differ mathematically from standard cross-entropy, and why does this difference help with label noise?

- Concept: Non-IID data distributions and their impact on federated learning convergence
  - Why needed here: Understanding how data heterogeneity affects model training is crucial for designing appropriate loss functions and alignment strategies
  - Quick check question: What are the key statistical differences between IID and non-IID data distributions that affect federated learning performance?

## Architecture Onboarding

- Component map:
  - Clients: Local model training, KL divergence computation, symmetric loss optimization
  - Server: Public dataset hosting, coordination of global aggregation
  - Communication: Knowledge distribution sharing (not model parameters or private data)
  - Loss functions: Standard task loss + symmetric loss + KL divergence loss

- Critical path: Local training → Knowledge distribution computation → KL divergence alignment → Global aggregation → Repeat
- Design tradeoffs:
  - Public dataset size vs. alignment quality: Larger public datasets provide better KL divergence estimates but increase communication overhead
  - Symmetric loss weight vs. convergence speed: Higher weights improve noise robustness but may slow convergence on clean data
  - Local training epochs vs. global model quality: More local training preserves local knowledge but may increase divergence between clients

- Failure signatures:
  - High KL divergence values that don't decrease over iterations indicate model architectures are fundamentally incompatible
  - Sudden drops in accuracy after alignment suggest the public dataset poorly represents the heterogeneous data
  - Oscillating losses indicate instability in the symmetric loss balance

- First 3 experiments:
  1. Test KL divergence alignment with homogeneous models on heterogeneous data to isolate the data heterogeneity effect
  2. Test symmetric loss with homogeneous data and heterogeneous models to isolate the model heterogeneity effect
  3. Test the complete system with varying levels of data and model heterogeneity to establish performance bounds

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method perform under extreme label noise scenarios beyond the tested rates (0.1, 0.2, 0.3)?
- Basis in paper: [explicit] The paper mentions "Different diversity rate (i.e., µ = {0.1, 0.2, 0.3})" but doesn't explore beyond these rates.
- Why unresolved: The paper only evaluates the method's performance for three specific label noise rates, leaving uncertainty about its robustness in more extreme scenarios.
- What evidence would resolve it: Additional experiments with higher label noise rates (e.g., 0.4, 0.5, 0.6) and their impact on the model's accuracy would provide insights into the method's limitations.

### Open Question 2
- Question: What is the computational overhead introduced by the knowledge distillation and symmetric loss components in the proposed method?
- Basis in paper: [inferred] The paper mentions using knowledge distillation and symmetric loss but doesn't provide quantitative analysis of their computational impact.
- Why unresolved: While the paper demonstrates the effectiveness of these components, it doesn't quantify their computational cost or compare it to the baseline methods.
- What evidence would resolve it: A detailed analysis of the computational complexity and training time for the proposed method compared to baseline methods would provide insights into its practical feasibility.

### Open Question 3
- Question: How does the proposed method generalize to other domains beyond medical imaging?
- Basis in paper: [explicit] The paper focuses on medical imaging datasets (hematological cytomorphology) but doesn't explore its applicability to other domains.
- Why unresolved: The paper's evaluation is limited to medical imaging, leaving uncertainty about the method's performance in other domains with different data characteristics.
- What evidence would resolve it: Experiments on diverse datasets from other domains (e.g., natural images, text, or tabular data) would demonstrate the method's generalizability and potential limitations.

## Limitations

- Evaluation limited to small medical imaging datasets (INT_20: 26,379 samples, Matek_19: 14,681 samples) with only 4 clients
- Symmetric label noise assumption may not reflect real-world medical imaging label corruption patterns
- Claims about scalability to larger client populations and real-world medical imaging scenarios remain untested

## Confidence

- High confidence: KL divergence knowledge distillation mechanism for model heterogeneity - well-established technique with clear mathematical foundation
- Medium confidence: Symmetric loss function effectiveness - while the concept is established, its performance in federated medical imaging with specific noise patterns needs validation
- Low confidence: Claims about scalability to larger client populations and real-world medical imaging scenarios - current evaluation limited to 4 clients and specific hematological datasets

## Next Checks

1. Test MDH-FL with asymmetric label noise patterns (e.g., certain classes more likely to be confused than others) to validate symmetric loss robustness
2. Evaluate performance on additional medical imaging domains (dermatology, radiology) with larger client populations (10+ clients) to assess scalability
3. Compare KL divergence alignment with alternative alignment methods (e.g., parameter averaging, attention-based alignment) to isolate the specific contribution of the knowledge distillation approach