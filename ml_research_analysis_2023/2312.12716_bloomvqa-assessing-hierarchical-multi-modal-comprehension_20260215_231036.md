---
ver: rpa2
title: 'BloomVQA: Assessing Hierarchical Multi-modal Comprehension'
arxiv_id: '2312.12716'
source_url: https://arxiv.org/abs/2312.12716
tags:
- level
- tasks
- bloom
- comprehension
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BloomVQA, a novel dataset for evaluating
  multi-modal comprehension in vision-language models using a scientifically-grounded
  framework. The dataset is constructed from picture stories and annotated according
  to Bloom's Taxonomy, which categorizes comprehension into six hierarchical levels.
---

# BloomVQA: Assessing Hierarchical Multi-modal Comprehension

## Quick Facts
- **arXiv ID**: 2312.12716
- **Source URL**: https://arxiv.org/abs/2312.12716
- **Reference count**: 15
- **Key outcome**: Models show up to 38.0% performance drop on higher-level Bloom's Taxonomy tasks requiring advanced cognitive skills

## Executive Summary
BloomVQA introduces a novel dataset and evaluation framework for assessing multi-modal comprehension in vision-language models. The dataset consists of 20 picture stories with 1,200 core VQA samples and 12,000 augmented samples, annotated according to Bloom's Taxonomy's six hierarchical cognitive levels. The authors propose a Story Graph representation to encode event-level relations and cognitive processes, enabling meaningful data augmentation. Experiments reveal that while models perform well on low-level comprehension tasks, their performance significantly degrades on higher-level tasks requiring advanced reasoning, with notable consistency patterns that deviate from human comprehension hierarchies.

## Method Summary
The method involves constructing a dataset from picture stories (from Storyweaver and Book Dash) with VQA samples categorized into six Bloom's levels. A Story Graph is built to represent event-level relations and cognitive processes, enabling automatic data augmentation. Pre-trained CLIP, BLIP, BLIP2, and GPT-4V models are evaluated using zero-shot multiple-choice tasks. The evaluation framework computes accuracy metrics across Bloom's levels, conditional performance consistency, and consistency metrics comparing base versus augmented data performance. The approach uses hierarchical graph traversal to incorporate contextually relevant background knowledge from connected events.

## Key Results
- Models show up to 38.0% performance drop on higher-level Bloom's Taxonomy tasks compared to lower levels
- Conditional performance metrics reveal consistency patterns in model behavior that deviate from human comprehension hierarchies
- Data augmentation using background knowledge demonstrates how model reliability varies with hierarchical context

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Story Graph representation enables meaningful data augmentation by leveraging hierarchical cognitive relationships encoded in Bloom's Taxonomy
- Mechanism: By representing events as nodes and cognitive relations as edges, the Story Graph allows traversal to construct new questions that incorporate contextually relevant background knowledge
- Core assumption: Cognitive processes required for higher-level tasks can be meaningfully represented as graph relations between events
- Evidence anchors: [abstract] mentions Story Graph for encoding event-level relations and cognitive processes; [section] describes including relations corresponding to underlying cognitive processes

### Mechanism 2
- Claim: Conditional performance metrics reveal consistency patterns in model behavior that deviate from human comprehension hierarchies
- Mechanism: By computing the likelihood of correctly solving a task at level m given success on a task at level n, we can identify whether model performance follows the expected hierarchical pattern
- Core assumption: Human comprehension follows a hierarchical pattern where mastering higher-level cognitive skills implies proficiency in lower-level skills
- Evidence anchors: [abstract] proposes metrics characterizing consistency of model behavior; [section] describes computing likelihood of solving Xm correctly given Xn

### Mechanism 3
- Claim: Data augmentation using background knowledge from different Bloom's levels reveals model reliability and consistency in handling hierarchical knowledge
- Mechanism: By augmenting tasks with background information from other levels and measuring changes in performance, we can quantify how consistently models use relevant contextual information
- Core assumption: A consistent model should maintain similar performance when given irrelevant background information and improve when given relevant background information
- Evidence anchors: [abstract] proposes metrics based on underlying data hierarchy; [section] considers relevancy of background knowledge associated with node connections in story graph

## Foundational Learning

- **Bloom's Taxonomy and cognitive skill hierarchies**: Understanding the 6-level cognitive skill framework is essential for interpreting task categorization and designing appropriate evaluation metrics. *Quick check*: What are the six levels of Bloom's Taxonomy in order from lowest to highest cognitive complexity?

- **Graph representations and traversal algorithms**: Understanding how to construct and traverse Story Graphs is crucial for implementing data augmentation and consistency analysis. *Quick check*: How would you traverse a graph to find all events connected to a given event by inference relations?

- **Conditional probability and performance metrics**: Understanding how to compute and interpret conditional performance metrics is essential for analyzing model consistency patterns. *Quick check*: How would you compute the probability of a model correctly answering a level 3 question given it correctly answered a level 5 question?

## Architecture Onboarding

- **Component map**: Data Collection -> Story Graph Construction -> Data Augmentation -> Model Evaluation -> Analysis Pipeline
- **Critical path**: 1. Load story and construct Story Graph 2. Generate base VQA tasks and augment with background knowledge 3. Run VLP model on all tasks 4. Compute accuracy metrics for each Bloom's level 5. Compute conditional performance metrics 6. Analyze consistency patterns and generate insights
- **Design tradeoffs**: Fine-grained vs. coarse-grained Bloom's level categorization, complete vs. sampled Story Graph construction, complex vs. simple data augmentation strategies, exact vs. approximate conditional performance computation
- **Failure signatures**: Low accuracy across all Bloom's levels indicates model limitations, inconsistent patterns where higher-level success doesn't imply lower-level success suggests model unreliability, high performance with minimal visual input indicates potential shortcut learning
- **First 3 experiments**: 1. Run VLP model on base tasks and compute accuracy per Bloom's level to establish baseline performance 2. Compute conditional performance metrics to identify consistency patterns 3. Generate augmented tasks using level 1 background knowledge and measure consistency changes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the Story Graph representation be effectively utilized to generate novel, challenging multi-modal comprehension tasks beyond simple data augmentation?
- Basis in paper: [explicit] The authors propose the Story Graph as a hierarchical graph-structured representation that extends the concept of scene graphs and enables automatic data augmentation
- Why unresolved: While the paper demonstrates data augmentation, it does not explore the full potential in generating more complex comprehension tasks
- What evidence would resolve it: Experiments showing effectiveness in generating novel tasks that significantly improve evaluation of multi-modal comprehension models

### Open Question 2
- Question: How does the consistency of model performance vary across different types of multi-modal comprehension tasks, and what factors contribute to these variations?
- Basis in paper: [explicit] The authors propose novel metrics to examine model consistency and analyze how context knowledge affects performance
- Why unresolved: The paper provides initial insights but does not comprehensively investigate factors influencing consistency across various task types
- What evidence would resolve it: Thorough analysis identifying key factors such as task complexity, context relevance, and cognitive skill requirements that impact consistency

### Open Question 3
- Question: To what extent can the proposed BloomVQA dataset and evaluation framework be generalized to other domains and types of multi-modal data?
- Basis in paper: [inferred] The paper focuses on picture stories but mentions potential for broader application
- Why unresolved: Effectiveness and generalizability beyond picture stories is not explored
- What evidence would resolve it: Experiments demonstrating successful application to other domains and types of multi-modal data, identifying necessary adaptations

## Limitations

- Data representation ambiguity: The paper lacks explicit detail on how the Story Graph is constructed and traversed for data augmentation
- Model-specific generalization: Evaluation focuses on specific VLP models without examining whether patterns hold across different architectures
- Cognitive alignment verification: Assumes Bloom's Taxonomy provides accurate framework without empirical validation of human annotator consistency

## Confidence

- **High Confidence**: The core finding that model performance degrades significantly on higher Bloom's levels (up to 38% decrease) is well-supported by experimental results
- **Medium Confidence**: The proposed conditional performance metrics and consistency analysis provide valuable insights, though interpretation depends on assumed validity of Bloom's hierarchy
- **Low Confidence**: The effectiveness of Story Graph-based data augmentation is poorly specified, making it difficult to assess whether reported improvements accurately reflect the mechanism's utility

## Next Checks

1. Reproduce Story Graph construction: Implement the exact Story Graph construction algorithm and data augmentation procedure to verify whether reported performance patterns hold when augmentation is applied systematically

2. Cross-model consistency analysis: Test the evaluation framework with additional VLP models (e.g., Flamingo, LLaVA) to determine whether hierarchical performance degradation is universal or model-specific

3. Human baseline comparison: Conduct human evaluations on the same tasks to establish whether conditional performance patterns and consistency metrics align with human comprehension hierarchies, validating the assumed cognitive framework