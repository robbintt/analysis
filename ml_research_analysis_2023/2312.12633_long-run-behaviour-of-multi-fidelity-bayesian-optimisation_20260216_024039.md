---
ver: rpa2
title: Long-run Behaviour of Multi-fidelity Bayesian Optimisation
arxiv_id: '2312.12633'
source_url: https://arxiv.org/abs/2312.12633
tags:
- mfbo
- multi-fidelity
- bayesian
- budget
- sfbo
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the long-run behaviour of multi-fidelity
  Bayesian Optimisation (MFBO), focusing on potential under-performance compared to
  single-fidelity Bayesian Optimisation (SFBO). The research was inspired by recent
  benchmark studies suggesting MFBO might underperform in certain scenarios over extended
  optimization budgets.
---

# Long-run Behaviour of Multi-fidelity Bayesian Optimisation

## Quick Facts
- arXiv ID: 2312.12633
- Source URL: https://arxiv.org/abs/2312.12633
- Reference count: 3
- Primary result: SFBO eventually outperforms MFBO in the long run despite MFBO's superior initial performance

## Executive Summary
This study investigates the long-run behavior of Multi-fidelity Bayesian Optimisation (MFBO) compared to Single-fidelity Bayesian Optimisation (SFBO). Using the Hartmann6D test function and XGBoost hyperparameter optimization, the authors demonstrate that while MFBO shows superior initial performance, SFBO eventually overtakes MFBO in terms of simple regret after extended optimization budgets. The cross-over point occurs around budget 50 for Hartmann6D and budget 100 for XGB when using Maximum Entropy Search. The findings suggest that MFBO's early advantage comes from effective warm-start through low-fidelity measurements, but compounding errors from noisy lower-fidelity observations lead to long-term underperformance.

## Method Summary
The study compared MFBO and SFBO using Maximum Entropy Search (MES) and Knowledge Gradient (KG) acquisition functions across 100 trials each. The Hartmann6D test function was extended with continuous fidelity, and XGBoost hyperparameter optimization served as a real-world benchmark. MFBO results were normalized to align with SFBO budget points (0, 1, 2, ..., 100) to enable fair comparison. Simple regret was tracked as the primary metric across the optimization budget.

## Key Results
- MFBO initially outperforms SFBO in the first 15-20 budget points due to warm-start benefits from low-fidelity measurements
- SFBO overtakes MFBO around budget 50 for Hartmann6D and budget 100 for XGB when using MES acquisition
- The majority of low-fidelity queries occur at the beginning of MFBO runs, followed by a transition to high-fidelity queries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MFBO initially outperforms SFBO due to effective warm-start from low-fidelity data
- Mechanism: Early low-fidelity queries build a surrogate model that accelerates convergence in high-fidelity space
- Core assumption: Low-fidelity measurements are sufficiently correlated with high-fidelity to inform early decisions
- Evidence anchors:
  - The majority of low-fidelity queries occur at the very beginning of the run. MFBO seems to build a 'warm-start' set of low-fidelity observations which then informs a further run dominated by high-fidelity queries
  - That is why we see such strong performance of MFBO compared to SFBO in the initial budget range of 0 to 15

### Mechanism 2
- Claim: SFBO eventually outperforms MFBO due to compounding errors from low-fidelity measurements
- Mechanism: Accumulated noise from multiple low-fidelity observations leads optimization astray in later stages
- Core assumption: Lower fidelities have higher noise that compounds over sequential queries
- Evidence anchors:
  - Considering that lower fidelities are 'noisier' than higher fidelities, it is possible that the errors in measurements when using the lowest fidelities accumulates, leading the optimization process to get stuck in a local minima in the long-run

### Mechanism 3
- Claim: MFBO underperforms in the long run due to inefficiencies traded for short-term gains
- Mechanism: MFBO sacrifices long-term exploration efficiency for short-term exploitation benefits
- Core assumption: No-free-lunch theorem applies - advantages in one regime create disadvantages in another
- Evidence anchors:
  - Given the significant outperformance of MFBO in the short-term over SFBO, it is reasonable to assume on an intuitive level, that long-term MFBO will suffer from inefficiencies it traded for superior efficiency in the short-term

## Foundational Learning

- Concept: Bayesian Optimization fundamentals
  - Why needed here: Understanding BO is essential to grasp how MFBO extends and modifies the basic framework
  - Quick check question: What are the three main components of a Bayesian Optimization loop?

- Concept: Gaussian Process regression
  - Why needed here: MFBO relies on GPs to model the relationship between fidelities and the objective function
  - Quick check question: How does a GP represent uncertainty, and why is this important for acquisition functions?

- Concept: Multi-fidelity modeling assumptions
  - Why needed here: Different MFBO methods make different assumptions about fidelity relationships
  - Quick check question: What is the difference between linear and nonlinear fidelity models, and when might each be appropriate?

## Architecture Onboarding

- Component map:
  - Fidelity space: Continuous or discrete fidelity levels
  - Surrogate model: Multi-output GP modeling objective and fidelity relationships
  - Acquisition functions: MES, KG, or EI adapted for multi-fidelity
  - Query scheduler: Determines which fidelity to evaluate at each step

- Critical path:
  1. Initialize model with initial observations across fidelities
  2. Update surrogate model with new observations
  3. Optimize acquisition function to select next query point and fidelity
  4. Execute query and add observation to dataset
  5. Repeat until budget exhausted

- Design tradeoffs:
  - Fidelity discretization: Continuous vs discrete fidelity choices affect modeling complexity
  - Acquisition function choice: MES vs KG vs EI impacts exploration-exploitation balance
  - Modeling assumptions: Linear vs nonlinear fidelity relationships affect expressiveness and tractability

- Failure signatures:
  - Initial performance advantage without long-term improvement suggests compounding error problem
  - Consistent underperformance suggests poor fidelity modeling or acquisition function issues
  - Unstable results across trials suggest insufficient exploration or poor initialization

- First 3 experiments:
  1. Replicate Hartmann6D results to verify cross-over behavior with both MES and KG
  2. Test on a synthetic function with known fidelity correlation structure to isolate modeling effects
  3. Vary noise levels in low-fidelity measurements to quantify compounding error impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific theoretical guarantees exist for MFBO performance in the long run compared to SFBO?
- Basis in paper: The authors mention "More importantly, theoretical investigation needs to uncover the reason why we observe MFBO underperformance" and discuss potential theoretical explanations like the no-free-lunch theorem
- Why unresolved: The paper only provides empirical observations but lacks theoretical foundation explaining why MFBO underperforms SFBO in the long run
- What evidence would resolve it: Formal proofs or theoretical bounds demonstrating conditions under which MFBO converges slower than SFBO over extended optimization budgets

### Open Question 2
- Question: How do different types of fidelity relationships (additive, multiplicative, non-stationary) affect long-run MFBO performance?
- Basis in paper: The authors discuss "application variety" and mention that "The problem structure, whether real-world or test function, presumably has an impact on MFBO performance"
- Why unresolved: The paper only tests one benchmark (Hartmann6D) and XGBoost, without systematically varying the fidelity relationship structure
- What evidence would resolve it: Empirical studies comparing MFBO performance across a wide range of fidelity relationship types under identical experimental conditions

### Open Question 3
- Question: What is the optimal strategy for transitioning between fidelity levels to maximize long-run performance?
- Basis in paper: The authors observe that "The majority of low-fidelity queries occur at the very beginning of the run" and discuss "compounding errors" from lower fidelity measurements
- Why unresolved: The paper uses standard MFBO algorithms without investigating whether alternative querying strategies could mitigate long-run underperformance
- What evidence would resolve it: Comparative studies of different fidelity transition strategies (e.g., adaptive vs fixed schedules) showing their impact on long-run optimization performance

## Limitations
- Results based on limited benchmark problems (Hartmann6D and XGBoost) may not generalize to all optimization scenarios
- Methodology for normalizing MFBO results to SFBO budget points introduces potential uncertainties
- Exact implementation details of continuous fidelity extension are not fully specified

## Confidence
- Claim: SFBO eventually outperforms MFBO in the long run: Medium
- Claim: Compounding errors from low-fidelity measurements cause long-term underperformance: Medium
- Claim: MFBO's initial advantage comes from warm-start benefits: High

## Next Checks
1. Test the cross-over behavior on additional benchmark functions with varying fidelity correlations to determine if the phenomenon is general or problem-specific.
2. Conduct sensitivity analysis on noise levels in low-fidelity measurements to quantify the impact of compounding errors on long-run performance.
3. Implement alternative MFBO methods (e.g., using different fidelity modeling assumptions) to isolate whether the observed under-performance is method-specific or inherent to multi-fidelity optimization.