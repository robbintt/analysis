---
ver: rpa2
title: 'Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step
  in Natural Language Understanding'
arxiv_id: '2310.11721'
source_url: https://arxiv.org/abs/2310.11721
tags:
- step
- intermediate
- cott
- language
- steps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Chain-of-Thought Tuning (CoTT), a two-step
  reasoning framework for Masked Language Models (MLMs) that extends the Chain-of-Thought
  (CoT) technique from Large Language Models (LLMs) to NLU tasks. CoTT uses convertible
  slots in prompt tuning to generate intermediate steps and then predict final results,
  enabling MLMs to perform step-by-step reasoning.
---

# Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding

## Quick Facts
- **arXiv ID**: 2310.11721
- **Source URL**: https://arxiv.org/abs/2310.11721
- **Reference count**: 19
- **Key outcome**: CoTT enables MLMs to perform step-by-step reasoning through intermediate steps, achieving state-of-the-art performance on hierarchical classification and relation extraction tasks

## Executive Summary
This paper introduces Chain-of-Thought Tuning (CoTT), a framework that extends the Chain-of-Thought (CoT) technique from Large Language Models (LLMs) to Masked Language Models (MLMs) for Natural Language Understanding (NLU) tasks. Unlike traditional prompt tuning for MLMs that directly predicts final results, CoTT uses a two-step reasoning process where the model first generates intermediate reasoning steps and then uses these steps to predict the final answer. The framework employs convertible slots in prompt templates to flexibly generate or inject intermediate steps, counterfactual contrastive learning to improve information integration, and probability rectification to combine predictions from both steps.

## Method Summary
CoTT is a two-step reasoning framework for MLMs built on prompt tuning. In Step I, the MLM generates intermediate steps using a convertible slot [C] that can be filled with a mask token <M> to produce reasoning steps in natural language. In Step II, the predicted intermediate step is injected into the [C] slot to guide final prediction. The framework incorporates counterfactual-based contrastive learning to help the MLM integrate text and intermediate step information, and uses probability rectification to adaptively combine predictions from both steps based on confidence in the intermediate step. The method is evaluated on hierarchical classification (Web of Science dataset) and relation extraction (TACRED, TACREV, ReTACRED datasets).

## Key Results
- CoTT achieves state-of-the-art performance on hierarchical classification and relation extraction tasks, outperforming baseline models and fine-tuned MLMs
- The method enables monitoring of reasoning processes through generated intermediate steps, improving reliability in risk-sensitive applications
- CoTT demonstrates the effectiveness of extending Chain-of-Thought reasoning techniques from autoregressive LLMs to autoencoding MLMs for NLU tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CoTT enables MLMs to perform step-by-step reasoning by generating intermediate steps through convertible slots
- Mechanism: The convertible slot [C] allows the MLM to flexibly generate or inject intermediate steps depending on the reasoning stage. In Step I, [C] is filled with <M> to generate intermediate steps. In Step II, the predicted intermediate step is injected into [C] to guide final prediction.
- Core assumption: Intermediate steps in natural language form provide useful reasoning evidence that MLMs can leverage for better predictions
- Evidence anchors:
  - [abstract]: "CoTT's prompt tuning allows intermediate steps to be used in natural language form"
  - [section 4.1]: "The flexibility of convertible slot [C] to convert between [T] and [A] allows MLM to combine intermediate steps to make predictions"
  - [corpus]: Weak evidence - no direct mentions of convertible slots in related papers
- Break condition: If the intermediate steps don't provide meaningful reasoning evidence, the two-step framework becomes redundant and doesn't improve performance

### Mechanism 2
- Claim: Counterfactual-based contrastive learning improves the MLM's ability to integrate text and intermediate step information
- Mechanism: By contrasting the hidden vectors from factual and counterfactual intermediate steps, the MLM learns to distinguish whether the text and intermediate step match, forcing it to perceive their relationship more finely
- Core assumption: The MLM can learn meaningful distinctions between matching and non-matching text-intermediate step pairs through contrastive learning
- Evidence anchors:
  - [section 4.3]: "counterfactual-based contrastive learning forces MLM to perceive the relationship between texts and intermediate steps more fine-grained"
  - [section 4.3]: "By contrasting the similarity of hx and {hx,I, hx,I*}, MLM learns to distinguish whether x and I match"
  - [corpus]: Weak evidence - no direct mentions of counterfactual contrastive learning in related papers
- Break condition: If the MLM cannot effectively learn from the contrastive signals, or if the negative sampling strategy fails to provide useful counterfactual examples

### Mechanism 3
- Claim: Probability rectification adaptively combines information from both reasoning steps based on the confidence of intermediate step prediction
- Mechanism: The probability rectification formula weights the predictions from Step I and Step II based on p(I|x), giving more weight to the Step II prediction when the intermediate step is predicted with high confidence
- Core assumption: When the intermediate step prediction is uncertain, the direct prediction without intermediate steps is relatively more accurate
- Evidence anchors:
  - [section 4.4]: "when I ≠ Î, we have: DKL(p(y|x,I)||p(y|x)) < DKL(p(y|x,I)||p(y|x,Î))"
  - [section 4.4]: "Therefore, we replace p(y|x,I) in Eq. 9 with p(y|x) for all cases satisfying I ≠ Î"
  - [corpus]: Weak evidence - no direct mentions of probability rectification in related papers
- Break condition: If the assumption that p(y|x,I) ≈ p(y|x) when I ≠ Î doesn't hold, or if the weighting scheme doesn't appropriately balance the two sources of information

## Foundational Learning

- Concept: Masked Language Models and cloze-style prediction
  - Why needed here: CoTT is built on prompt tuning for MLMs, which requires understanding how MLMs make predictions by filling in masked tokens
  - Quick check question: What is the key difference between how MLMs and autoregressive LLMs make predictions?

- Concept: Chain-of-Thought prompting for LLMs
  - Why needed here: CoTT extends the CoT concept from LLMs to MLMs, so understanding how CoT works for LLMs is essential
  - Quick check question: How does Chain-of-Thought prompting improve LLM performance on multi-step reasoning tasks?

- Concept: Prompt tuning and template-based prompting
  - Why needed here: CoTT is based on prompt tuning, which uses templates with slots to structure the input for the MLM
  - Quick check question: What are the two main types of slots used in traditional prompt tuning templates?

## Architecture Onboarding

- Component map: MLM model (BERT/RoBERTa) -> Prompt templates with [T], [A], [C] slots -> Verbalizers for labels/intermediate steps -> Projection head for contrastive learning -> Loss functions (cross-entropy + contrastive loss)

- Critical path: 1. Generate intermediate step (Step I) -> 2. Predict label using intermediate step (Step II) -> 3. Apply probability rectification to combine predictions -> 4. Compute losses and update model parameters

- Design tradeoffs:
  - Introducing intermediate steps adds complexity but enables reasoning monitoring
  - Counterfactual contrastive learning requires additional forward passes but improves information integration
  - Probability rectification simplifies computation but relies on assumptions about prediction quality

- Failure signatures:
  - If intermediate step prediction accuracy is very low, probability rectification will rely heavily on Step I predictions
  - If contrastive learning fails to distinguish matching vs non-matching pairs, Step II predictions may not improve
  - If template design is poor, the MLM may not effectively leverage intermediate steps

- First 3 experiments:
  1. Evaluate CoTT performance on a small subset of the dataset with manually designed intermediate steps to verify the framework works
  2. Compare performance with and without probability rectification to validate its effectiveness
  3. Test different intermediate step granularities (e.g., domain vs area in hierarchical classification) to find optimal decomposition

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Template Structure Dependency: Performance heavily relies on prompt template design, particularly the convertible slot positioning, which is not fully disclosed
- Assumption Validation: Probability rectification assumes p(y|x,I) ≈ p(y|x) when intermediate step predictions are incorrect, which may not generalize
- Contrastive Learning Effectiveness: Requires careful negative sampling for counterfactual contrastive learning, with implementation details not fully specified

## Confidence
- **High Confidence**: The core concept that CoTT extends Chain-of-Thought reasoning from LLMs to MLMs through a two-step framework with intermediate steps is well-supported by experimental results
- **Medium Confidence**: The specific mechanisms of counterfactual contrastive learning and probability rectification are theoretically sound but rely on assumptions that may not generalize
- **Low Confidence**: The claim that CoTT "also allows monitoring reasoning processes" is presented but not empirically validated in the paper

## Next Checks
1. **Template Ablation Study**: Systematically test different template structures and convertible slot placements to determine which design choices are critical for performance and whether the specific templates used in the paper are essential to the results

2. **Probability Rectification Assumption Testing**: Conduct experiments where the intermediate step prediction accuracy is deliberately varied to test whether the assumption p(y|x,I) ≈ p(y|x) when I ≠ Î holds across different error rates and task types

3. **Intermediate Step Quality Analysis**: Implement a human evaluation or automated quality assessment of the generated intermediate steps to determine if they provide meaningful reasoning evidence or if the performance gains come from other aspects of the framework