---
ver: rpa2
title: Integrating cognitive map learning and active inference for planning in ambiguous
  environments
arxiv_id: '2308.08307'
source_url: https://arxiv.org/abs/2308.08307
tags:
- agent
- active
- inference
- state
- cognitive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper integrates a cognitive map learning model (clone-structured
  cognitive graphs) with active inference planning to address navigation in ambiguous
  environments. The key idea is to use the learned structure of cognitive maps as
  the generative model within an active inference framework.
---

# Integrating cognitive map learning and active inference for planning in ambiguous environments

## Quick Facts
- arXiv ID: 2308.08307
- Source URL: https://arxiv.org/abs/2308.08307
- Reference count: 23
- Primary result: Active inference-driven clone graph agent outperforms greedy clone graph agent in ambiguous navigation tasks

## Executive Summary
This paper addresses the challenge of planning in ambiguous environments by integrating clone-structured cognitive graphs (CSCG) with active inference. The key innovation is using the learned cognitive map structure as a generative model within an active inference framework, allowing agents to explicitly plan for information gain in addition to goal achievement. The approach is evaluated across three spatial navigation scenarios, demonstrating that while both active inference and greedy agents perform similarly in simple environments, the active inference agent shows superior performance in ambiguous and information-critical situations.

## Method Summary
The method involves training clone-structured cognitive graphs on random-walk sequences from each environment, then converting the learned parameters to active inference matrices (A, B, C, D). The CSCG model disambiguates aliased observations by maintaining multiple clone states for each observation based on context. These parameters are then used within an active inference planning framework that minimizes expected free energy, which decomposes into epistemic value (information gain) and pragmatic value (goal achievement). The approach is compared against a naive clone graph agent using greedy planning across three Minigrid environments.

## Key Results
- In the ambiguous maze, the active inference agent reaches goals 3 steps faster on average (7.92 vs 10.92 steps)
- In the T-maze requiring informed decisions, the active inference agent achieves 100% success rate versus 56.75% for the clone graph agent
- Both agents perform similarly in the simple open room environment, validating that the performance gap appears specifically in ambiguous scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The active inference agent outperforms the greedy clone graph agent in ambiguous environments because it explicitly plans for information gain, not just goal proximity.
- Mechanism: Active inference computes expected free energy (G), which decomposes into epistemic value (information gain) and pragmatic value (goal achievement). This allows the agent to balance exploration and exploitation.
- Core assumption: The CSCG learned structure is sufficiently accurate to support planning, and the agent can evaluate expected free energy over a reasonable planning horizon.
- Evidence anchors:
  - [abstract] "Results show that while both agents perform similarly in simple environments, the active inference agent demonstrates superior performance in challenging scenarios. Specifically, in the ambiguous maze, the active inference agent reaches goals 3 steps faster on average (7.92 vs 10.92 steps)."
  - [section 2.3] "Active inference assumes that actions are inferred through the minimization of the expected free energy G... This equation decomposes in two distinct terms: an epistemic value computing the information gain term over the belief over the state, and a pragmatic value (or utility) term with respect to a preferred distribution over the observation P(o)."
- Break condition: If the CSCG structure is too inaccurate or the planning horizon is too short to capture information gain benefits.

### Mechanism 2
- Claim: CSCGs can disambiguate aliased observations by maintaining multiple "clone states" for each observation, allowing context-dependent behavior.
- Mechanism: CSCGs create distinct hidden states for each observation based on context (previous observations and actions). This allows the model to learn that the same observation in different contexts should lead to different actions.
- Core assumption: The training data contains sufficient context to learn these distinctions, and the Viterbi decoding step effectively prunes unnecessary states.
- Evidence anchors:
  - [section 2.1] "Clone-structured cognitive graphs (CSCG) [5] are a computational implementation of a cognitive map that models the joint probability of a sequence of action and observation pairs... The crucial difference is that these clone-structured cognitive graphs are able to disambiguate aliased observations based on the context (e.g. the previously visited trajectory)."
  - [section 2.1] "All states corresponding to a single observation are called the clones of this observation, and by design, each state deterministically maps to a single observation."
- Break condition: If the environment lacks sufficient context variation to train meaningful distinctions between clones.

### Mechanism 3
- Claim: Converting CSCG parameters to active inference matrices enables planning under uncertainty while leveraging learned spatial structure.
- Mechanism: The learned CSCG transition and observation matrices are directly mapped to the B and A matrices of the active inference POMDP, with preferences set for goal states.
- Core assumption: The CSCG parameters can be meaningfully converted to valid probability distributions for the active inference matrices.
- Evidence anchors:
  - [section 2.3] "We consider active inference in the discrete state space formulation... The generative model is therefore described by a set of four specific matrices: the A matrix defines the likelihood model... the B matrix defines the transition model... The C matrix describes the preference of the agent... and finally, the D matrix describes the prior belief over the initial state."
  - [section 2.3] "To construct the B matrix, the transition matrix from the trained CSCG can be taken directly... We convert this transition matrix to proper probabilities by adding a novel dispreferred state sd, for which we set the transition probability to 1 in these illegal cases."
- Break condition: If the CSCG parameters contain illegal transitions that cannot be properly normalized.

## Foundational Learning

- Concept: Active Inference Framework
  - Why needed here: Understanding how active inference agents plan by minimizing expected free energy is crucial for grasping why this approach outperforms greedy planning.
  - Quick check question: What are the two components of expected free energy, and how do they trade off against each other?

- Concept: Clone-Structured Cognitive Graphs
  - Why needed here: The CSCG is the core structure being integrated with active inference, and understanding how it disambiguates observations is essential.
  - Quick check question: How does a CSCG create multiple states for the same observation, and why is this useful for navigation?

- Concept: Partially Observable Markov Decision Processes (POMDPs)
  - Why needed here: The active inference framework uses POMDP formulations, and understanding this connection helps explain the mathematical foundation.
  - Quick check question: How does a POMDP differ from a standard MDP, and why is this distinction important for navigation in ambiguous environments?

## Architecture Onboarding

- Component map: Experience → CSCG learning → Matrix conversion → Active inference planning → Action selection
- Critical path: The agent learns a cognitive map through CSCG training, converts this structure to active inference matrices, then uses expected free energy minimization to select actions that balance exploration and exploitation.
- Design tradeoffs: The approach trades computational complexity (evaluating expected free energy over multiple policies) for improved performance in ambiguous environments. The planning horizon must be balanced against computational feasibility.
- Failure signatures: Poor performance in ambiguous environments suggests the CSCG hasn't learned sufficient structure or the conversion to active inference matrices introduced errors. High computational cost indicates the planning horizon may be too large.
- First 3 experiments:
  1. Run the open room environment with both agents to verify they perform similarly in unambiguous scenarios.
  2. Run the ambiguous maze environment to demonstrate the active inference agent's superior disambiguation capabilities.
  3. Run the T-maze environment to show how active inference enables information-seeking behavior before making critical decisions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can active inference agents be integrated with continuous state spaces and online learning mechanisms, as opposed to the discrete state space formulation used in this study?
- Basis in paper: [explicit] The authors mention that their current approach does not benefit from the curiosity- or novelty-based scheme of active inference and hypothesize that this could improve training efficiency with respect to the number of required samples.
- Why unresolved: The paper only explores discrete state space formulations and offline learning, leaving open how these benefits would translate to more continuous and adaptive learning scenarios.
- What evidence would resolve it: Empirical results comparing online learning performance of active inference agents in continuous state spaces against baseline methods, demonstrating improved sample efficiency and learning speed.

### Open Question 2
- Question: What is the relationship between the epistemic value term (information gain) and pragmatic value term (utility) in the expected free energy formulation, and how does this trade-off impact performance in different types of environments?
- Basis in paper: [explicit] The authors discuss the two terms in the expected free energy equation and mention that they simplify the utility calculation for depth-1 planning, but acknowledge that larger depths are still needed for non-greedy long-term information-seeking behavior.
- Why unresolved: The paper does not provide a detailed analysis of how the balance between these terms affects agent behavior and performance across different environment complexities.
- What evidence would resolve it: Systematic experiments varying the relative weights of epistemic and pragmatic terms in different environments, showing how this trade-off impacts success rates and decision-making efficiency.

### Open Question 3
- Question: How does the active inference approach compare to other state-of-the-art planning methods for cognitive maps, such as model-based reinforcement learning with generative models?
- Basis in paper: [inferred] The discussion section mentions that other approaches typically treat planning as a trivial problem solved through forward rollouts or value optimization, but do not consider belief over state as a parameter. The authors suggest that combining active inference with these approaches could be promising.
- Why unresolved: The paper does not provide direct comparisons with other modern planning methods for cognitive maps, leaving open questions about the relative strengths and weaknesses of the active inference approach.
- What evidence would resolve it: Comparative experiments between active inference agents and state-of-the-art model-based RL agents with generative models, evaluating performance on tasks requiring state disambiguation and complex planning.

## Limitations
- CSCG learning relies on sufficient training data to disambiguate states, and performance may degrade if training sequences lack diverse context
- The conversion from CSCG parameters to active inference matrices assumes all transitions can be properly normalized, which may not hold for complex environments
- The planning horizon (T=10) is fixed and may not be optimal for all scenarios

## Confidence
- High confidence: The active inference agent outperforms greedy planning in ambiguous environments (empirical results are clear and reproducible)
- Medium confidence: The mechanism of epistemic value driving disambiguation is correctly identified (theoretical foundation is sound but implementation details matter)
- Medium confidence: CSCG's ability to disambiguate observations is the key enabler (demonstrated but dependent on training quality)

## Next Checks
1. Test the active inference agent with varying planning horizons (T=5, T=15, T=20) to determine if the observed performance gap is robust to this parameter.
2. Vary the amount and diversity of training data to quantify how CSCG quality affects active inference performance in ambiguous environments.
3. Compare the proposed CSCG-to-active-inference conversion with alternative methods (e.g., direct learning of A and B matrices) to isolate the contribution of CSCG structure versus conversion approach.