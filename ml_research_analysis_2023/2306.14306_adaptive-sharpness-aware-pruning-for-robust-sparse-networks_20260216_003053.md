---
ver: rpa2
title: Adaptive Sharpness-Aware Pruning for Robust Sparse Networks
arxiv_id: '2306.14306'
source_url: https://arxiv.org/abs/2306.14306
tags:
- pruning
- robustness
- adasap
- network
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work introduces AdaSAP, a method that optimizes for both
  sparsity and robustness in deep neural networks through adaptive sharpness-aware
  pruning. The approach consists of three steps: adaptive weight perturbations to
  prepare the network for pruning, structured neuron removal, and robustness encouragement
  via flatness-based regularization.'
---

# Adaptive Sharpness-Aware Pruning for Robust Sparse Networks

## Quick Facts
- arXiv ID: 2306.14306
- Source URL: https://arxiv.org/abs/2306.14306
- Reference count: 40
- Key outcome: AdaSAP achieves up to +6% robust accuracy on ImageNet-C and +4% on ImageNet-V2 compared to state-of-the-art pruning methods.

## Executive Summary
This paper introduces AdaSAP, a novel pruning method that simultaneously achieves high sparsity and robustness in deep neural networks. The approach is based on the insight that flatness of the loss landscape is beneficial for both pruning resilience and robustness to input variations. AdaSAP operates through three phases: adaptive weight perturbations to prepare neurons for pruning, structured channel removal, and uniform flatness regularization to encourage robustness. Experiments on ImageNet classification and Pascal VOC detection demonstrate significant improvements over existing methods, with robustness gains of up to 6% on corrupted datasets.

## Method Summary
AdaSAP is a three-step pruning framework that unifies sparsity and robustness through flatness optimization. First, it applies adaptive weight perturbations during a warmup phase, scaling perturbation magnitudes inversely with neuron importance to push low-importance neurons into flatter regions of the loss landscape. Second, it performs structured channel-wise pruning using any standard criterion. Third, it fine-tunes the pruned model with uniform sharpness-aware regularization to encourage flatness across all remaining neurons. The method leverages ASAM optimization with perturbation radius ρmin=0.01 during warmup and ρ=2.0 during fine-tuning.

## Key Results
- Achieves up to +6% robust accuracy on ImageNet-C compared to state-of-the-art pruning methods
- Improves robustness ratios RC and RV2 by up to 4% on ImageNet-V2
- Demonstrates consistent improvements across multiple architectures and compression ratios for both classification and object detection tasks

## Why This Works (Mechanism)

### Mechanism 1
Adaptive weight perturbations prepare the network for pruning by enforcing flatter loss regions for neurons likely to be pruned. The method scales perturbation ball sizes inversely with importance scores, pushing low-importance neurons toward flatter minima where their removal causes minimal impact.

### Mechanism 2
Uniform flatness regularization after pruning improves robustness by ensuring all remaining neurons lie in relatively flat minima. This makes the network less sensitive to input variations and corruptions by reducing the curvature of the loss landscape around the current weights.

### Mechanism 3
AdaSAP unifies sparsity and robustness by optimizing for flat minima, a property beneficial to both goals. This challenges the assumption that sparsity and robustness are inherently conflicting by showing they can be jointly optimized through sharpness-aware methods.

## Foundational Learning

- Concept: Sharpness-aware optimization (SAM/ASAM)
  - Why needed here: These methods explicitly optimize for flatter minima by considering adversarial weight perturbations within a ball of radius ρ
  - Quick check question: How does SAM differ from standard SGD in terms of the gradient computation?

- Concept: Structured channel-wise pruning
  - Why needed here: AdaSAP focuses on removing entire channels rather than individual weights, which allows for direct latency improvements
  - Quick check question: Why might structured pruning be preferred over unstructured pruning in production systems?

- Concept: Importance scoring functions for pruning
  - Why needed here: AdaSAP requires a scoring function (e.g., magnitude, Taylor importance) to determine which neurons to prune and how to scale perturbations
  - Quick check question: What are the trade-offs between using ℓ2 norm magnitude versus Taylor importance for pruning?

## Architecture Onboarding

- Component map: Pretrained model -> Adaptive weight perturbation (warmup) -> Structured pruning -> Robustness encouragement (fine-tuning) -> Final compact robust model
- Critical path: The three-phase pipeline where each stage builds upon the previous one to achieve both sparsity and robustness
- Design tradeoffs:
  - Adaptive perturbations vs. uniform perturbations: Adaptive gives better pruning preparation but adds complexity
  - Choice of importance metric: ℓ2 norm is simple but may miss higher-order importance
  - ρmin/ρmax tuning: Larger ranges allow more aggressive flatness enforcement but risk underfitting
- Failure signatures:
  - Validation accuracy drops sharply after pruning -> Adaptive perturbations may have been too aggressive
  - Robustness ratios RC/RV2 do not improve -> Uniform flatness regularization may be insufficient
  - Training becomes unstable -> ρ values or learning rate may be too large
- First 3 experiments:
  1. Run AdaSAP on MobileNetV2 with magnitude pruning at 50% sparsity; compare RC/RV2 to baseline
  2. Vary ρmax from 1.0 to 3.0 and observe impact on validation and robustness accuracy
  3. Replace ASAM with SAM in the robustness encouragement phase and measure performance change

## Open Questions the Paper Calls Out

### Open Question 1
How do adaptive weight perturbations specifically influence the flatness of the loss landscape in neurons that are likely to be pruned? The paper states the hypothesis but does not provide empirical evidence or detailed analysis of the changes in the loss landscape geometry.

### Open Question 2
Is there a specific range of sparsity ratios where the benefits of adaptive weight perturbations diminish or become less effective? The paper does not analyze whether there is a threshold beyond which the method's effectiveness plateaus.

### Open Question 3
How does the choice of the neuron importance score function impact the effectiveness of adaptive weight perturbations? While the paper mentions various scoring functions, it does not investigate their comparative effects.

### Open Question 4
Does the application of uniform weight perturbations during the robustness encouragement phase have diminishing returns as the network becomes sparser? The paper does not explore how effectiveness varies with different levels of sparsity.

## Limitations

- Computational overhead from adaptive perturbations and sharpness-aware optimization may limit practical deployment
- Limited evaluation to image classification and object detection tasks, with unknown generalization to other domains
- Performance heavily dependent on the quality of importance scoring functions

## Confidence

- Confidence in core mechanism linking flatness to pruning resilience and robustness: Medium
- Confidence in computational efficiency and practical deployment: Low
- Confidence in generalization across diverse architectures and tasks: Medium

## Next Checks

1. Perform ablation studies removing either the adaptive perturbation phase or the uniform flatness regularization to quantify their individual contributions

2. Test AdaSAP on additional architectures (e.g., ResNet-50, EfficientNet) and tasks (e.g., semantic segmentation) to evaluate generalization

3. Measure the computational overhead of AdaSAP compared to standard pruning methods during both training and inference phases