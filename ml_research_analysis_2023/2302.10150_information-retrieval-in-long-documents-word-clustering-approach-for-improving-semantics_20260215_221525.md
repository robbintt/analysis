---
ver: rpa2
title: 'Information Retrieval in long documents: Word clustering approach for improving
  Semantics'
arxiv_id: '2302.10150'
source_url: https://arxiv.org/abs/2302.10150
tags:
- words
- word
- cluster
- clusters
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of improving information retrieval
  for long documents by taking into account the meaning of words, not just keywords.
  The core method is to group words into semantic clusters using word embeddings,
  then represent documents and queries as vectors in the cluster space.
---

# Information Retrieval in long documents: Word clustering approach for improving Semantics

## Quick Facts
- arXiv ID: 2302.10150
- Source URL: https://arxiv.org/abs/2302.10150
- Reference count: 5
- Primary result: Combining semantic clustering with bm25 improves retrieval performance over baselines on SQuAD and TREC-CAR datasets

## Executive Summary
This paper proposes a word clustering approach to improve information retrieval in long documents by leveraging semantic meaning beyond keyword matching. The method groups words into semantically related clusters using fastText embeddings, then represents documents and queries as vectors in the cluster space. A combination function merges this semantic score with traditional bm25 lexical scoring. Experiments on SQuAD and TREC-CAR datasets demonstrate improved performance across multiple metrics including MAP, R-Prec, and MRR.

## Method Summary
The approach uses fastText embeddings to cluster words into semantically related groups via a Single-Pass incremental algorithm. Documents and queries are projected into this cluster space where similarity is computed using cosine distance. Rare words and named entities are treated as singletons to reduce ambiguity. The final retrieval score combines the clustering similarity with bm25 using a Borda-like voting formula that weights ranks and normalizes scores. The method is evaluated on SQuAD (51,324 queries, 10,698 documents) and TREC-CAR (76,525 documents, 19,525 queries) datasets.

## Key Results
- Combined clustering-bm25 approach outperforms both individual methods on SQuAD and TREC-CAR
- Semantic clustering shows particular strength on queries requiring understanding of meaning beyond keywords
- Rare words and named entities treated as singletons improve precision by reducing noise
- Performance gains are consistent across MAP, R-Prec, and MRR metrics

## Why This Works (Mechanism)

### Mechanism 1
- Clustering semantically similar words into independent vectors enables queries to match documents on meaning rather than exact keywords
- Words are represented as fastText embeddings, grouped using Single-Pass algorithm, and documents/queries are projected into cluster space where cosine similarity is computed
- Core assumption: Clusters are linearly independent, forming a valid vector space representation
- Evidence: [abstract] describes the clustering approach; [section 3.4] states clusters are linearly independent; no direct independence proof provided
- Break condition: If clusters overlap semantically, the vector space model fails and similarity scores become unreliable

### Mechanism 2
- Combining semantic clustering score with bm25 lexical score yields better overall retrieval performance
- Clustering similarity is computed via cosine between document and query vectors, merged with bm25 via Borda-like voting formula
- Core assumption: Semantic and lexical scores capture complementary aspects of relevance
- Evidence: [abstract] mentions combining semantic meaning with lexical model; [section 3.8] shows the weighted sum formula; [section 4] tables show improved MAP/R-Prec/MRR for combined model
- Break condition: If one method consistently dominates the other, combination adds no value and may degrade performance

### Mechanism 3
- Treating rare words and named entities as singletons reduces noise and ambiguity in semantic clustering
- During clustering, RW and NE tokens are not grouped with others but kept alone in their own clusters
- Core assumption: NE and RW do not have reliable synonyms in the corpus and their embeddings may mislead clustering
- Evidence: [section 3.4] states RW and NE should be alone in clusters; [section 3.3] notes NE lack synonyms and can be ambiguous; no direct corpus evidence provided
- Break condition: If NE or RW do have useful synonyms, treating them as singletons could miss semantic matches

## Foundational Learning

- **Vector space model for IR**: Documents and queries are represented as vectors in cluster space, and similarity is computed via cosine
  - Why needed: Enables semantic matching through vector operations
  - Quick check: How do you compute similarity between two vectors in a vector space model?

- **Word embeddings and semantic similarity**: Clustering is based on fastText embeddings; understanding embedding similarity is key to why words are grouped
  - Why needed: Determines which words belong in the same semantic cluster
  - Quick check: What does high cosine similarity between two word vectors indicate about their meanings?

- **TF-IDF weighting adapted to clusters**: Cluster weight formula mirrors TF-IDF but accounts for proportion of words in a cluster present in the document
  - Why needed: Provides appropriate weighting for cluster-based document representation
  - Quick check: How does the β factor in the cluster weighting formula differ from standard TF-IDF?

## Architecture Onboarding

- **Component map**: Text preprocessing → Named Entity Recognition → Tokenization → Clustering → Cluster weighting → Vector representation → Cosine similarity + bm25 combination → Ranking
- **Critical path**: Preprocessing → Clustering → Representation → Matching
- **Design tradeoffs**:
  - Using singleton clusters for NE/RW reduces noise but may lose synonym matches
  - Incremental clustering allows dynamic updates but can be O(n·β) per insertion
  - Combining bm25 with clustering keeps lexical robustness but adds computational overhead
- **Failure signatures**:
  - Low precision on lexical queries → cluster independence assumption broken
  - Slow clustering updates → O(n·β) insertion cost too high for large vocabularies
  - Poor performance on NE-heavy queries → singleton strategy too restrictive
- **First 3 experiments**:
  1. Compare clustering-only vs bm25-only retrieval on SQuAD to confirm complementary strengths
  2. Measure cluster independence (pairwise cosine) to validate vector space assumption
  3. Test performance drop when forcing NE/RW into multi-word clusters to evaluate singleton strategy

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the choice of epsilon threshold (ϵ) in the clustering algorithm affect the quality and interpretability of resulting clusters, and is there an optimal method to determine this threshold for different languages or domains?
- **Basis**: The paper mentions epsilon is determined by selecting N pairs of synonymous words and averaging their cosine similarity scores, but does not explore sensitivity to different languages or domains
- **Why unresolved**: Uses fixed method to determine epsilon without investigating how variations impact clustering quality or generalizability across linguistic contexts
- **What evidence would resolve it**: Empirical studies comparing clustering performance across multiple languages and domains using different epsilon determination methods, including sensitivity analysis

### Open Question 2
- **Question**: How does the proposed clustering approach scale to extremely large document collections (e.g., web-scale), and what are the computational bottlenecks in such scenarios?
- **Basis**: The paper mentions O(n * β) complexity of adding words to clusters but does not discuss performance at scale or provide benchmarks for large-scale document collections
- **Why unresolved**: Presents theoretical complexity but does not empirically test the approach on large-scale datasets or discuss practical limitations when scaling to millions of documents
- **What evidence would resolve it**: Performance benchmarks on large-scale datasets, analysis of memory and computational requirements, and comparison with distributed clustering approaches

### Open Question 3
- **Question**: Can the proposed approach effectively handle polysemy (words with multiple meanings), and what are the limitations of using single-pass clustering with word embeddings for this purpose?
- **Basis**: The paper acknowledges named entities and rare words are placed in separate clusters to reduce ambiguity, but does not address how the system handles polysemous words that may appear in different contexts with different meanings
- **Why unresolved**: Clustering algorithm groups words based on their embeddings, which may not capture contextual variations in meaning, leading to potential inaccuracies when the same word has multiple senses
- **What evidence would resolve it**: Evaluation of the approach on datasets containing polysemous words, comparison with context-aware embedding methods, and analysis of false positives/negatives due to polysemy

## Limitations
- Cluster independence is critical but not empirically validated; no evidence provided that clusters truly capture orthogonal semantic dimensions
- Epsilon threshold parameter for clustering is unspecified, making reproduction difficult and potentially explaining performance variability
- Singleton strategy for named entities and rare words may be overly conservative and could miss useful synonym matches
- No evaluation of how well the approach handles polysemous words with multiple meanings in different contexts

## Confidence

- **High Confidence**: The combination of semantic clustering with bm25 improves overall retrieval performance, evidenced by consistent gains across multiple metrics (MAP, R-Prec, MRR) on both datasets
- **Medium Confidence**: The singleton strategy for NE/RW improves precision by avoiding noise, though not tested against alternative clustering approaches
- **Low Confidence**: The claim that clusters are linearly independent and form a valid vector space is stated but not empirically demonstrated

## Next Checks

1. **Cluster Independence Test**: Compute pairwise cosine similarity between cluster centroids on the SQuAD dataset. If average similarity > 0.3, the independence assumption is questionable and the vector space model may be invalid.

2. **Singleton Strategy Ablation**: Run retrieval experiments forcing NE/RW into multi-word clusters on TREC-CAR. Measure performance change to determine if singleton treatment is too restrictive.

3. **Threshold Sensitivity Analysis**: Systematically vary ϵ around the unspecified threshold and measure clustering quality (silhouette score) and retrieval performance to identify optimal parameter ranges.