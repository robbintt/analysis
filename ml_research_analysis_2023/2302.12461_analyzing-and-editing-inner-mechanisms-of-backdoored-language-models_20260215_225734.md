---
ver: rpa2
title: Analyzing And Editing Inner Mechanisms Of Backdoored Language Models
arxiv_id: '2302.12461'
source_url: https://arxiv.org/abs/2302.12461
tags:
- backdoor
- data
- language
- trigger
- ablation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a new interpretability tool called PCP ablation
  that replaces modules in transformer models with low-rank matrices based on principal
  components of their activations. This allows reducing model parameters and behavior
  to essential components while enabling behavior editing.
---

# Analyzing And Editing Inner Mechanisms Of Backdoored Language Models

## Quick Facts
- arXiv ID: 2302.12461
- Source URL: https://arxiv.org/abs/2302.12461
- Reference count: 11
- Key outcome: PCP ablation can replace MLP and attention layers in backdoored language models while enabling behavior editing, reducing ASR from 0.29 to 0.07 for large models

## Executive Summary
This paper introduces PCP ablation, a novel interpretability tool that replaces transformer modules with low-rank matrices based on principal components of their activations. The authors apply this technique to analyze and edit backdoor mechanisms in both toy and large language models. By identifying MLP layers as most critical for backdoor behavior, they demonstrate the ability to remove, insert, and modify backdoors through engineered replacements. The method shows promise for improving backdoor robustness while maintaining model performance.

## Method Summary
The authors develop PCP ablation by collecting module activations, performing PCA to identify principal components, and replacing modules with low-rank matrices. They apply this to both MLP and attention layers in backdoored models, using mean ablation to determine module importance and logit lens for interpretability analysis. The technique is tested on toy GPT-2 variants and GPT-2 Medium models trained on poisoned datasets, measuring attack success rate (ASR) and accidental trigger rate (ATR) for toxic language generation.

## Key Results
- MLPs identified as most important for backdoor mechanism in backdoored models
- PCP ablation can remove, insert, and modify backdoor mechanisms with engineered replacements
- ASR reduced from 0.29 to 0.07 for large models using PCP ablation
- Backdoor robustness improved by constraining individual modules during fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MLPs are the most impactful modules for the backdoor mechanism
- Mechanism: The backdoor mechanism in backdoored language models is induced by MLP layers shifting hidden states toward negative sentiment clusters in the embedding space, while attention layers primarily enforce positivity or have ambiguous effects
- Core assumption: Sentiment-changing behavior is driven by linear operations on hidden states that align with principal components between sentiment clusters
- Evidence anchors:
  - [abstract] "We determine MLPs as most important for the backdoor mechanism and use this knowledge to remove, insert, and modify backdoor mechanisms with engineered replacements via PCP ablation."
  - [section] "The results show the same tendencies for both models, 2-sent and 3-sent. Compared to the unchanged model, each MLP is necessary to achieve any output negativity on trigger inputs, as the top-k logit negativity decreases to 0 when mean ablating any MLP."
- Break condition: If attention layers are shown to be equally or more important than MLPs in sentiment shifting, or if the sentiment clusters don't align with principal component directions

### Mechanism 2
- Claim: PCP ablation can replace MLP and attention layers while maintaining model behavior
- Mechanism: By projecting module activations onto principal components and using low-rank matrices, PCP ablation reduces model parameters while preserving essential behavior for specific tasks like backdoor mechanisms
- Core assumption: Essential behavior for a task can be captured by a linear projection onto a small number of principal components of module activations
- Evidence anchors:
  - [abstract] "PCP ablation can improve backdoor robustness by constraining individual modules during fine-tuning on poisonous datasets"
  - [section] "We successfully replace one and two attention layers in the toy model while maintaining model behavior based on top-k output logit negativity"
- Break condition: If the reduced-rank projections cannot maintain acceptable validation loss or language coherence, or if the task requires non-linear operations that cannot be captured by principal components

### Mechanism 3
- Claim: Backdoor mechanisms can be inserted, removed, and edited in both toy and large models
- Mechanism: By replacing MLPs with PCP ablations based on principal components from benign, toxic, and trigger data sets, the backdoor mechanism can be reverse-engineered and modified through scaling factors
- Core assumption: The backdoor mechanism's behavior can be characterized by the relationship between hidden states of different sentiment classes
- Evidence anchors:
  - [abstract] "We determine MLPs as most important for the backdoor mechanism and use this knowledge to remove, insert, and modify backdoor mechanisms with engineered replacements via PCP ablation"
  - [section] "We successfully change the ASR of the backdoor mechanism in Tab. 5 when varying the scaling parameter for the 2-sent toy model"
- Break condition: If the scaling factors cannot effectively tune the backdoor strength, or if the inserted mechanism doesn't behave as intended on trigger inputs

## Foundational Learning

- Principal Component Analysis (PCA)
  - Why needed here: PCA is used to identify the most important directions in module activations that correspond to sentiment changes, allowing reduction to essential components
  - Quick check question: How does PCA help identify which directions in activation space are most important for the backdoor mechanism?

- Mean Ablation
  - Why needed here: Mean ablation is used to determine which modules are necessary for the backdoor mechanism by removing their effect and measuring the impact on toxicity
  - Quick check question: What does it mean when mean ablating a module completely removes the backdoor behavior?

- Logit Lens
  - Why needed here: Logit lens allows tracking sentiment changes through the model by projecting hidden states to logits at each layer, showing which modules shift toward negative sentiment
  - Quick check question: How can the logit lens help identify which modules are responsible for sentiment changes in the model?

## Architecture Onboarding

- Component map:
  - Input embeddings → Attention layers → MLP layers → Output embeddings
  - PCP ablation replaces MLP and attention layers with low-rank matrices based on principal components
  - Mean ablation tests module importance by averaging activations and removing their effect

- Critical path:
  1. Collect activations from target modules over relevant data sets
  2. Perform PCA to find principal components
  3. Create PCP ablation matrix with tuned scaling factors
  4. Replace target modules and validate behavior

- Design tradeoffs:
  - Low rank vs. performance: Lower rank reduces parameters but may lose important nuances
  - Linear vs. non-linear: PCP ablation is linear, which simplifies but may miss non-linear effects
  - Task-specific vs. general: PCP ablation is tailored to specific tasks, not general language understanding

- Failure signatures:
  - Validation loss increases significantly after PCP ablation
  - Language coherence degrades (nonsensical outputs)
  - Backdoor behavior doesn't match expected toxicity levels
  - ASR/ATR metrics don't align with intended behavior

- First 3 experiments:
  1. Apply mean ablation to each MLP layer in toy model and measure top-k negativity on trigger inputs
  2. Perform logit lens analysis on MLP activations to identify sentiment-shifting layers
  3. Replace first MLP with rank-2 PCP ablation and validate backdoor insertion by checking ASR on trigger inputs

## Open Questions the Paper Calls Out
- Can PCP ablation be applied to higher-quality backdoor attacks that are harder to detect?
- How would incorporating non-linearity into the PCP ablation projections affect the increase in validation loss?
- Can PCP ablation be used to combine replacements across multiple tasks for the same modules?

## Limitations
- Technique's generalizability beyond sentiment-based backdoors to other types of backdoors or model behaviors
- Limited evaluation on real-world datasets beyond toy and Bookcorpus data used
- Unclear robustness across different model architectures beyond GPT-2 variants

## Confidence
- High confidence: PCP ablation methodology and implementation details
- Medium confidence: Identification of MLPs as most important for backdoor mechanisms
- Low confidence: Reliable insertion and modification of backdoor mechanisms with precise control

## Next Checks
1. Test PCP ablation on a broader range of backdoor types (e.g., trigger-based, functionality-based) beyond sentiment-changing backdoors to assess generalizability
2. Apply the technique to different model architectures (e.g., BERT, T5) to verify the mechanism identification holds across architectures
3. Conduct ablation studies with varying rank values in PCP ablation to determine the minimum rank needed for maintaining backdoor behavior, providing insights into the dimensionality of the backdoor mechanism