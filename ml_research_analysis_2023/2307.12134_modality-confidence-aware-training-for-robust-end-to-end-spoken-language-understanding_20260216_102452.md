---
ver: rpa2
title: Modality Confidence Aware Training for Robust End-to-End Spoken Language Understanding
arxiv_id: '2307.12134'
source_url: https://arxiv.org/abs/2307.12134
tags:
- score
- modality
- confidence
- speech
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses robustness of end-to-end spoken language understanding
  (SLU) systems when ASR-generated text is unreliable. The authors propose Modality
  Confidence Aware Training (MCAT), which dynamically weights audio and text inputs
  based on an estimated confidence score of ASR hypotheses.
---

# Modality Confidence Aware Training for Robust End-to-End Spoken Language Understanding

## Quick Facts
- arXiv ID: 2307.12134
- Source URL: https://arxiv.org/abs/2307.12134
- Reference count: 0
- Primary result: MCAT improves Exact Match accuracy by up to 0.41 absolute points over baseline on STOP dataset

## Executive Summary
This paper proposes Modality Confidence Aware Training (MCAT) to improve the robustness of end-to-end spoken language understanding (SLU) systems when automatic speech recognition (ASR) outputs are unreliable. The approach introduces a Score Encoder that estimates the reliability of ASR hypotheses using frozen RNNT embeddings and log-probabilities, producing confidence scores (0-1) that dynamically weight audio and text inputs during NLU processing. Experiments on the STOP dataset demonstrate that MCAT achieves significant performance gains, particularly when using smaller ASR models and in error-prone conditions, with optimal performance requiring Score Encoder accuracy above 87%.

## Method Summary
The proposed MCAT method extends deliberation-based E2E SLU with a Score Encoder that predicts hypothesis reliability from ASR embeddings and log-probabilities. The confidence score is integrated into the NLU component via fusion and decoding modules using three methods: multiplication, appending to embeddings, or combined fusion/decoding integration. The Score Encoder is trained first using binary classification on hypothesis correctness, then jointly with the NLU component. The approach uses frozen ASR models (10M-25M parameters) and a small Score Encoder (0.3M parameters) to maintain on-device efficiency.

## Key Results
- MCAT improves Exact Match accuracy by up to 0.41 absolute points over baseline
- Significant gains observed particularly with smaller ASR models (10M parameters)
- Score Encoder accuracy must exceed 87% threshold for MCAT to outperform baseline
- Decoder-level integration (APPEND DEC) yields larger improvements than fusion-only methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modality confidence scores dynamically reweight audio and text inputs to improve robustness when ASR hypotheses are unreliable.
- Mechanism: The Score Encoder estimates hypothesis reliability from ASR embeddings and log-probs, producing a score (0-1) that is fused into the NLU via multiplication, appending, or combined fusion/decoding. This allows the model to shift emphasis from text to audio when ASR errors are detected.
- Core assumption: The Score Encoder's prediction of ASR hypothesis quality correlates with actual transcription reliability.
- Evidence anchors:
  - [abstract] "propose Modality Confidence Aware Training (MCAT), which dynamically weights audio and text inputs based on an estimated confidence score of ASR hypotheses."
  - [section 2.3] "We explore three different methods to integrate score into E2E NLU component..."
  - [corpus] Weak - no direct citations or FMR matches to this exact confidence-weighting mechanism.
- Break condition: Score Encoder accuracy falls below ~87% (Section 4.3), at which point improvements vanish and performance drops below baseline.

### Mechanism 2
- Claim: The Score Encoder learns to distinguish correct vs. erroneous ASR hypotheses using frozen RNNT embeddings and log-probs.
- Mechanism: The Score Encoder is trained on STOP data using a binary classification objective (correct/incorrect hypothesis), with class weights to handle imbalance. It takes LSTM-processed audio/text embeddings plus hypothesis log-probs, then combines them via Multi-Head Attention into a single confidence score.
- Core assumption: The combination of audio, text, and log-prob features is sufficient to predict ASR hypothesis correctness.
- Evidence anchors:
  - [section 2.3] "We use a simple binary target scheme, where 1 represents a correct ASR hypothesis and 0 represents an ASR hypothesis with an error."
  - [section 4.2] "We tried several options such as classification with weighted class, regression, and focal loss... binary weighted classification performed the best."
  - [corpus] Weak - related works cited but no direct FMR evidence for this exact encoder design.
- Break condition: Over-reliance on imbalanced training data leads to poor generalization to unseen ASR errors.

### Mechanism 3
- Claim: Decoder-level integration of confidence score (via Pcopy) yields larger gains than fusion-only integration, especially on error cases.
- Mechanism: Confidence score is appended to both text and audio embeddings for fusion, and also fed into the copying probability computation (Pcopy) in the decoder. This dual integration allows the model to adjust both modality fusion and token copying behavior based on confidence.
- Core assumption: Decoder-level confidence awareness is more impactful than fusion-only adjustments for correcting ASR errors.
- Evidence anchors:
  - [section 4.1] "we found a significant increase in EM by appending method in decoder module, particularly in ASR error cases."
  - [section 2.2] "we can use the score as an additional feature for computing Pcopy in the Decoder module."
  - [corpus] Weak - no direct corpus matches for this specific decoder integration strategy.
- Break condition: Score becomes uncorrelated with actual ASR error patterns, causing the decoder to make poor copying decisions.

## Foundational Learning

- Concept: End-to-end SLU architecture and error propagation from ASR to NLU
  - Why needed here: The paper targets robustness to ASR errors in E2E SLU, so understanding how errors propagate is critical for grasping MCAT's motivation.
  - Quick check question: Why does error propagation hurt pipeline SLU more than E2E SLU, and how does MCAT specifically mitigate it?

- Concept: Confidence estimation and modality fusion
  - Why needed here: MCAT relies on estimating modality reliability and fusing modalities based on that estimate; these are core to its design.
  - Quick check question: What are the three integration methods tested, and why does decoder-level integration outperform fusion-only?

- Concept: Model capacity and on-device constraints
  - Why needed here: The study uses small ASR models (10M-25M params) for on-device streaming, and the Score Encoder is limited to 0.3M params; understanding these constraints is key to interpreting results.
  - Quick check question: How does MCAT's benefit change as ASR model size (and thus accuracy) increases?

## Architecture Onboarding

- Component map: Frozen RNNT ASR → text embeddings (Predictor) + audio embeddings (Encoder) + hypothesis log-probs → Score Encoder → confidence score (0-1) → NLU (Multi-Head Attention fusion + Transformer decoder with pointer-generator)
- Critical path: ASR → Score Encoder → NLU (fusion + decoder)
- Design tradeoffs:
  - Keeping ASR frozen vs. fine-tuning: preserves out-of-domain accuracy but limits adaptation
  - Score Encoder capacity (0.3M) vs. expressiveness: small enough for on-device, but may miss complex error patterns
  - Integration method choice: decoder-level (APPEND DEC) gives best gains but adds complexity
- Failure signatures:
  - MCAT underperforms baseline → Score Encoder accuracy <87% or score is uncorrelated with actual ASR errors
  - No improvement on clean ASR output → Score Encoder overfits to error patterns in training data
  - Degradation on out-of-domain data → Frozen ASR and Score Encoder lack robustness to domain shift
- First 3 experiments:
  1. Run MCAT with oracle confidence score (ground-truth WER-based) to establish upper bound
  2. Train Score Encoder with binary classification and evaluate accuracy on dev set
  3. Integrate confidence at fusion-only level (APPEND FUSION) and measure EM improvement on ASR-error vs. clean splits

## Open Questions the Paper Calls Out
- Question: How does the proposed Modality Confidence Aware Training (MCAT) method compare to other existing methods for incorporating ASR confidence scores into E2E SLU models, such as using a separate confidence module or modifying the loss function?
- Question: How does the proposed MCAT method perform on datasets with different domains or languages, and what factors might affect its generalizability?
- Question: How does the proposed MCAT method handle cases where the ASR hypothesis is completely incorrect or contains significant errors, and what is the impact on NLU performance?

## Limitations
- The 87% Score Encoder accuracy threshold is empirically derived but not theoretically justified for generalization
- Small Score Encoder size (0.3M parameters) may limit ability to capture complex error patterns
- Paper doesn't address performance when ASR models are fine-tuned rather than frozen

## Confidence
- High Confidence: Overall experimental setup and methodology are clearly described, with demonstrated performance improvements (up to 0.41 EM points) and well-defined integration methods
- Medium Confidence: Claim that decoder-level integration outperforms fusion-only is supported by results but underlying reasons aren't deeply analyzed; 87% accuracy threshold is empirically observed but lacks theoretical grounding
- Low Confidence: No evidence that confidence estimation generalizes beyond STOP dataset or to different ASR architectures; impact on very low-resource scenarios remains unexplored

## Next Checks
1. **Oracle Upper Bound Test**: Implement MCAT with ground-truth WER-based confidence scores to establish theoretical performance upper bound
2. **Cross-Dataset Generalization**: Evaluate Score Encoder trained on STOP data on different SLU dataset with distinct ASR error patterns
3. **Fine-tuning vs. Frozen ASR**: Compare MCAT performance when using fine-tuned versus frozen ASR models to assess sensitivity to ASR adaptation