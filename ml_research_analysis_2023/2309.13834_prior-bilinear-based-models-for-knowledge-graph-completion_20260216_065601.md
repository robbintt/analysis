---
ver: rpa2
title: Prior Bilinear Based Models for Knowledge Graph Completion
arxiv_id: '2309.13834'
source_url: https://arxiv.org/abs/2309.13834
tags:
- identity
- unibi
- relation
- which
- relations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses a limitation in bilinear-based knowledge graph
  embedding models, namely their inability to capture the prior property of identity
  (the law of identity in logic). The authors propose a novel model called Unit Ball
  Bilinear Model (UniBi) that normalizes entity and relation embeddings to ensure
  unique modeling of identity.
---

# Prior Bilinear Based Models for Knowledge Graph Completion

## Quick Facts
- arXiv ID: 2309.13834
- Source URL: https://arxiv.org/abs/2309.13834
- Authors: 
- Reference count: 30
- One-line primary result: UniBi achieves MRR scores of 0.487 on WN18RR, 0.370 on FB15k-237, and 0.247 on YAGO3-10-DR

## Executive Summary
This paper addresses a fundamental limitation in bilinear knowledge graph embedding models: their inability to uniquely model the law of identity (each entity is identical to itself). The authors propose UniBi, which normalizes entity embeddings to unit vectors and constrains relation matrices to have spectral radius 1. This normalization approach not only ensures unique identity representation but also prevents ineffective learning on scales and improves interpretability by revealing relationships between relation complexity and singular values. Experiments on benchmark datasets demonstrate superior performance compared to previous bilinear models.

## Method Summary
UniBi introduces a unit ball bilinear model that constrains entity vectors to unit norm and relation matrices to spectral radius 1. The model is trained using a reciprocal setting where each triple is augmented with its inverse, and incorporates DURA regularization. For practical implementation, UniBi uses rotation matrices (orthogonal matrices with determinant 1) and diagonal sign matrices to efficiently model the spectral radius and orthogonality constraints. The model computes scores using the standard bilinear function h⊤Rt with normalized inputs, enabling unique modeling of identity relations while improving interpretability through singular value analysis.

## Key Results
- UniBi achieves MRR scores of 0.487 on WN18RR, 0.370 on FB15k-237, and 0.247 on YAGO3-10-DR
- Normalization prevents ineffective learning on scales, focusing the model on relative rankings
- The model reveals relationships between relation complexity and singular value imbalance, improving interpretability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: UniBi uniquely models the law of identity by constraining entity embeddings to unit norm and relation matrices to spectral radius 1.
- Mechanism: By normalizing entity vectors and relation matrices, UniBi ensures that only the identity matrix (or its scalar multiples) can perfectly model the self-relation, preventing scaled versions from being equally valid.
- Core assumption: The law of identity requires unique representation of self-relations, and this uniqueness is only preserved under the proposed normalization constraints.
- Evidence anchors:
  - [abstract]: "UniBi achieves this by constraining entity vectors to have unit norm and relation matrices to have spectral radius of 1."
  - [section]: "To be specific, we normalize the vectors of the entities and the spectral radius of the matrices of the relations to 1 by setting ˆE = {e | ∥e∥ = 1, e ∈ Rn} and ˆR = {R | ρ(R) = 1 , R ∈ Rn×n}."
- Break condition: If the constraints are relaxed or replaced with less strict conditions (e.g., orthogonal matrices), the uniqueness of identity representation is lost.

### Mechanism 2
- Claim: Scale normalization prevents ineffective learning on scales, improving model performance.
- Mechanism: By normalizing scales, UniBi focuses the learning process on the relative ranks of scores rather than absolute values, which do not contribute to distinguishing entities.
- Core assumption: Scale information is redundant for bilinear models because what matters is the relative rank of scores, not their absolute values.
- Evidence anchors:
  - [abstract]: "UniBi achieves theoretical superiority but also offers enhanced interpretability and performance by minimizing ineffective learning through minimal constraints."
  - [section]: "Scale contributes nothing to the ranks, since they remain the same after we multiply these scores by a positive factor: s′(h, r, t) = (keh)⊤(krR)(ket) = k2 e kr(h⊤Rt) = k2 e kr · s(h, r, t), where ke, kr > 0."
- Break condition: If the model's performance heavily relies on absolute scale values rather than relative rankings, normalization might degrade performance.

### Mechanism 3
- Claim: UniBi reveals the relationship between relation complexity and singular values, improving interpretability.
- Mechanism: By constraining the spectral radius of relation matrices to 1, UniBi ensures that singular values are bounded, and their relative ratios reflect the aggregation strength of relations, correlating with complexity.
- Core assumption: The complexity of a relation (defined as the sum of head-per-tail and tail-per-head ratios) is directly related to the aggregation effect, which can be characterized by the imbalance degree of singular values.
- Evidence anchors:
  - [abstract]: "The normalization in UniBi prevents ineffective learning on scales and reveals the relationship between relation complexity and singular values, improving interpretability."
  - [section]: "We note that this aggregation effect can be well characterized by the relative ratio, or imbalance degree, of singular values of the matrices of relations."
- Break condition: If the complexity of relations cannot be adequately captured by the imbalance degree of singular values, the interpretability benefit is lost.

## Foundational Learning

- Concept: Law of Identity in Logic
  - Why needed here: Understanding the law of identity is crucial because it is the prior property that UniBi aims to model, ensuring that each entity is uniquely identical to itself.
  - Quick check question: Can you explain why the law of identity is considered a prior property in knowledge graphs?

- Concept: Bilinear Models
  - Why needed here: Knowledge of bilinear models is essential to understand how UniBi modifies them by introducing normalization constraints to model the law of identity.
  - Quick check question: How do bilinear models typically represent relations between entities, and what is the form of their score function?

- Concept: Spectral Radius
  - Why needed here: Understanding spectral radius is important because it is the key constraint applied to relation matrices in UniBi to ensure they can uniquely model identity.
  - Quick check question: What is the spectral radius of a matrix, and why is it significant in the context of UniBi's constraints?

## Architecture Onboarding

- Component map: Entity Embeddings -> Relation Matrices -> Score Function -> Complexity Metric
- Critical path:
  1. Normalize entity embeddings to unit vectors
  2. Normalize relation matrices to have spectral radius of 1
  3. Compute the score function h⊤Rt
  4. Evaluate the model's performance and interpretability
- Design tradeoffs:
  - Expressiveness vs. Uniqueness: Normalizing scales reduces expressiveness but ensures unique modeling of identity
  - Performance vs. Interpretability: Scale normalization improves interpretability by revealing the relationship between complexity and singular values but may slightly impact performance
- Failure signatures:
  - If identity is not uniquely modeled, the model may fail to distinguish between different entities
  - If scales are not properly normalized, ineffective learning on redundant information may occur
- First 3 experiments:
  1. Test UniBi's ability to model the law of identity by adding an explicit identity relation and checking if its matrix converges to the identity matrix
  2. Compare UniBi's performance with and without scale normalization to demonstrate the impact of ineffective learning
  3. Analyze the correlation between the imbalance degree of singular values and the complexity of relations to validate interpretability claims

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- Lack of detailed implementation specifications for critical components like spectral radius constraints and rotation matrices
- Limited ablation studies make it difficult to isolate the specific contributions of each normalization constraint
- Claims about interpretability improvements through singular value analysis would benefit from more extensive empirical validation across diverse relation types

## Confidence
- Mechanism 1: Medium - Well-grounded in logic but requires more detailed implementation specifications
- Mechanism 2: Medium - Theoretical reasoning is sound but practical impact needs more empirical validation
- Mechanism 3: Medium - Correlation between complexity and singular values is theoretically plausible but needs broader validation

## Next Checks
1. Implement a controlled experiment comparing UniBi with and without identity relation to verify unique modeling of self-relations
2. Conduct a detailed analysis of singular value distributions across different relation complexities to validate the interpretability claims
3. Test UniBi's performance on datasets with varying levels of relation complexity to understand the practical impact of scale normalization