---
ver: rpa2
title: 'SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with
  Backtracking'
arxiv_id: '2306.05426'
source_url: https://arxiv.org/abs/2306.05426
tags:
- data
- sequences
- have
- north
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the compounding error problem in autoregressive
  sequence generation, where models trained with maximum likelihood objectives can
  generate poor quality sequences due to error accumulation during sampling. The authors
  formulate sequence generation as an imitation learning problem and introduce SequenceMatch,
  a method that minimizes divergences between the model's occupancy measure and the
  data distribution.
---

# SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking

## Quick Facts
- **arXiv ID**: 2306.05426
- **Source URL**: https://arxiv.org/abs/2306.05426
- **Reference count**: 40
- **Primary result**: SequenceMatch improves autoregressive generation quality by minimizing divergences between model and data distributions, incorporating backtracking via backspace actions.

## Executive Summary
This paper addresses the compounding error problem in autoregressive sequence generation by reformulating the task as imitation learning. The authors introduce SequenceMatch, a method that minimizes divergences between the model's occupancy measure and the data distribution, including out-of-distribution sequences that are critical for generation quality. The method also incorporates a backspace action to allow the model to recover from errors during generation. Experiments on text generation tasks demonstrate that SequenceMatch-trained models achieve higher MAUVE scores and diversity metrics compared to maximum likelihood estimation and behavioral cloning baselines.

## Method Summary
SequenceMatch formulates autoregressive sequence generation as an imitation learning problem in a Markov Decision Process framework. The method minimizes divergences between occupancy measures induced by the learned policy and the data distribution, using divergences like χ² that penalize out-of-distribution behavior. A backspace action is added to the action space, allowing the model to delete previous tokens and recover from errors. The training objective can be implemented as a fully supervised loss without adversarial training, using a novel masking scheme to efficiently train transformers with backspace actions. The method uses a replay buffer to sample model-generated sequences for training, reducing computational overhead.

## Key Results
- SequenceMatch-trained models achieve higher MAUVE scores compared to MLE and behavioral cloning baselines on text generation tasks.
- The method improves diversity metrics while maintaining generation quality.
- Backspace action is effectively learned and used by the model to correct errors during generation.

## Why This Works (Mechanism)

### Mechanism 1
SequenceMatch addresses compounding error by minimizing divergences that weight out-of-distribution sequences, unlike MLE which ignores them. The χ²-divergence between model and data distributions, especially when applied to a mixture (ρdata + ρθ)/2, penalizes model behavior on sequences generated autoregressively (OOD) more heavily than in-distribution sequences. This encourages the model to learn recovery behavior.

### Mechanism 2
Backspace action allows the model to recover from erroneous tokens, preventing irreversible drift into poor-quality sequences. By introducing a <backspace> action into the MDP formulation, the model can delete the last token if it takes the sequence OOD. This creates a backtracking path that MLE lacks.

### Mechanism 3
The SequenceMatch loss is a fully supervised loss that avoids adversarial training instability. By reformulating imitation learning as a divergence minimization over occupancy measures and solving it via a change of variables, the method yields a supervised loss over logits without needing a discriminator or adversarial training loop.

## Foundational Learning

- **Concept**: Markov Decision Process (MDP) formulation of sequence generation
  - **Why needed here**: Enables incorporation of editing actions like backspace and formalizes sequence generation as trajectory matching, not just token prediction.
  - **Quick check question**: In the MDP formulation, what are the states and what are the actions for a language model with backspace?

- **Concept**: Occupancy measure vs. joint distribution
  - **Why needed here**: Occupancy measures allow matching distributions over partial sequences and actions, which is more flexible than matching joint probabilities and supports infinite-length sequences.
  - **Quick check question**: Why does matching occupancy measures imply matching policies, and how does this differ from behavioral cloning?

- **Concept**: Divergence measures beyond KL (e.g., χ², JS)
  - **Why needed here**: These divergences penalize out-of-distribution behavior more heavily, which is critical for autoregressive generation quality.
  - **Quick check question**: How does the χ²-divergence weight errors in out-of-distribution sequences compared to the KL-divergence?

## Architecture Onboarding

- **Component map**:
  Input sequences → Masking algorithm A → Transformer with backspace head → Logits → χ²-mixture loss → Replay buffer → Updated model

- **Critical path**:
  1. Sample model trajectories from replay buffer (or generate if needed).
  2. Process both data and model trajectories with algorithm A to produce masked inputs/labels.
  3. Compute logits for all (state, action) pairs in parallel using transformer.
  4. Calculate SequenceMatch loss with χ²-mixture divergence.
  5. Backpropagate and update parameters.

- **Design tradeoffs**:
  - Replay buffer size vs. freshness of model samples.
  - Sampling frequency vs. training speed.
  - Full model fine-tuning vs. LM head only (computational cost vs. performance).

- **Failure signatures**:
  - If backspace is never used in generation, the model may not have learned to correct errors.
  - If replay buffer is too small or stale, the loss may not reflect current model behavior.
  - If gradients explode, check the χ² regularization term scaling.

- **First 3 experiments**:
  1. Train with full model fine-tuning vs. LM head only on small GPT-2; compare MAUVE.
  2. Remove backspace action; compare MAUVE and diversity to full model.
  3. Switch χ²-mixture to KL-divergence; compare MAUVE and perplexity.

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of divergence measure (e.g., χ², KL, JS) affect the quality of generated sequences in autoregressive models?
- Basis in paper: The paper discusses different divergences and their impact on sequence generation, particularly highlighting the χ² divergence as more suitable for autoregressive models.
- Why unresolved: The paper mentions that the χ² divergence performs better empirically but does not provide a comprehensive comparison of all divergence measures.
- What evidence would resolve it: A systematic comparison of sequence generation quality using different divergence measures on various datasets and model sizes.

### Open Question 2
What is the optimal balance between the SequenceMatch loss and the behavioral cloning loss during training?
- Basis in paper: The paper mentions annealing the behavioral cloning loss from 1 to 0.2 during training but does not explore the optimal balance.
- Why unresolved: The paper provides a heuristic approach but does not investigate the impact of different ratios on model performance.
- What evidence would resolve it: An ablation study varying the ratio of SequenceMatch to behavioral cloning loss and measuring the impact on generation quality metrics.

### Open Question 3
How does the SequenceMatch training overhead scale with context length and model size?
- Basis in paper: The paper mentions computational constraints and provides some empirical analysis of training overhead but does not fully explore scaling behavior.
- Why unresolved: The paper provides limited empirical data on training overhead for different model sizes and context lengths.
- What evidence would resolve it: A comprehensive study measuring training time, memory usage, and generation quality across a range of model sizes and context lengths.

## Limitations
- The implementation details of the novel masking scheme for efficient training with backspace actions are not fully specified.
- The method requires careful tuning of replay buffer size and sampling frequency.
- Evaluation relies heavily on MAUVE scores, which may not capture all aspects of generation quality.

## Confidence
**High Confidence**: The fundamental premise that maximum likelihood training leads to compounding errors in autoregressive generation is well-established in the literature. The theoretical framework connecting imitation learning to sequence generation through occupancy measures is sound and builds on established results.

**Medium Confidence**: The effectiveness of the χ²-divergence and mixture divergences in improving generation quality over standard MLE training is supported by the experimental results, but the exact implementation details and hyperparameter choices may significantly impact performance.

**Low Confidence**: The specific implementation of the backspace action and its integration into the training process, including the novel masking scheme, lacks sufficient detail for confident reproduction. The claim that SequenceMatch can be implemented "without adversarial training or architectural changes" is somewhat undermined by the need for this specialized masking approach.

## Next Checks
1. **Implementation Validation**: Reproduce the core SequenceMatch objective using a simple sequence classification task before applying to full autoregressive generation. Verify that the χ²-mixture divergence produces the expected gradient behavior compared to MLE loss.

2. **Backspace Action Analysis**: After training a model with backspace capability, analyze the generated sequences to quantify: (a) how often backspace is used, (b) in what contexts it is applied, and (c) whether sequences generated with backspace enabled show statistically significant improvements in MAUVE scores compared to those without.

3. **Ablation Study on Divergence Measures**: Systematically compare the performance of SequenceMatch using different divergence measures (KL, JS, χ², χ²-mixture) on the same model architecture and dataset. This would clarify whether the specific choice of divergence is critical to the method's success or if the general framework is more important.