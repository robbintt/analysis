---
ver: rpa2
title: 'Classes are not Clusters: Improving Label-based Evaluation of Dimensionality
  Reduction'
arxiv_id: '2308.00278'
source_url: https://arxiv.org/abs/2308.00278
tags:
- label-t
- data
- measures
- distortions
- groups
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of evaluating dimensionality reduction
  (DR) embeddings using class labels, which can be unreliable when the original data
  does not have clear cluster-label matching. The authors introduce two novel quality
  measures, Label-Trustworthiness (Label-T) and Label-Continuity (Label-C), which
  evaluate cluster structure preservation by comparing class-cluster matching in both
  the original and embedded spaces.
---

# Classes are not Clusters: Improving Label-based Evaluation of Dimensionality Reduction

## Quick Facts
- arXiv ID: 2308.00278
- Source URL: https://arxiv.org/abs/2308.00278
- Reference count: 40
- Key outcome: Introduces Label-T&C measures that outperform existing methods in detecting cluster-level distortions in DR embeddings by comparing class-cluster matching between original and embedded spaces.

## Executive Summary
This paper addresses a fundamental limitation in evaluating dimensionality reduction (DR) embeddings using class labels - the assumption that classes naturally form clusters in the original high-dimensional space. The authors introduce two novel quality measures, Label-Trustworthiness (Label-T) and Label-Continuity (Label-C), which quantify distortions in the relationship between class labels and cluster structure between the original and embedded spaces. By comparing clustering validation measures computed on class-pairwise distances in both spaces, Label-T&C can detect specific types of distortions (False Groups and Missing Groups) that existing measures miss. Quantitative experiments demonstrate superior performance in detecting cluster-level distortions while maintaining competitive runtime efficiency.

## Method Summary
The method works by computing clustering validation measures (CVMs) on pairwise distances between all class pairs in both the original high-dimensional space and the DR embedding. These CVMs produce class-label matching (CLM) matrices that quantify how well classes form clusters. The difference between these matrices reveals distortions: when classes that were well-separated in the original space become overlapping in the embedding (False Groups), or when classes that overlapped become artificially separated (Missing Groups). Label-T aggregates False Groups distortions while Label-C aggregates Missing Groups distortions, providing scores between 0 and 1 where higher values indicate better preservation of the original class-cluster relationship.

## Key Results
- Label-T&C outperform Trustworthiness & Continuity and S&C in detecting False and Missing Groups distortions while maintaining competitive runtime
- Label-C computed with DSC is sensitive to Missing Groups only when overlapped classes in original space become more separated in embedding
- Label-C computed with CHbtwn decreases as proximity between classes increases, regardless of overlap
- Case studies reveal characteristics of different DR techniques and effects of hyperparameters on cluster preservation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Label-T&C accurately detect False Groups distortions by measuring CLM degradation in the embedded space relative to original space.
- Mechanism: Compute CLM matrices in both spaces using CVM, then calculate difference matrix M* = M(X) - M(Z). MFG matrix isolates False Groups distortions. Aggregating MFG gives Label-T score.
- Core assumption: CVM accurately reflects class clustering and is invariant to non-cluster-related differences between spaces.
- Evidence anchors: [abstract] "Label-T&C work by (1) estimating the extent to which classes form clusters...and (2) evaluating the difference between the two."
- Break condition: If CVM isn't invariant to scaling, shift, or range differences between spaces.

### Mechanism 2
- Claim: Label-T&C detect Missing Groups distortions by measuring CLM exaggeration in embedded space.
- Mechanism: Similar to Mechanism 1, but focus on MMG matrix capturing cases where classes appear more separated in embedding than original. High Label-C indicates fewer Missing Groups distortions.
- Core assumption: CVM can distinguish truly well-separated classes from artificially separated ones due to DR.
- Evidence anchors: [abstract] "Label-C evaluates the distortion regarding the exaggeration of CLM: the score is lower when points of two different classes get farther apart in embedding than original space."
- Break condition: If CVM isn't sensitive to relative distances between classes.

### Mechanism 3
- Claim: Choice of CVM affects Label-T&C sensitivity to different CLM distortions.
- Mechanism: DSC more sensitive to class overlap, CHbtwn more sensitive to overall class proximity. This leads to different Label-C patterns depending on CVM used.
- Core assumption: Different CVMs capture different aspects of CLM, and choice should be guided by data characteristics.
- Evidence anchors: [section] "Label-C [DSC] is sensitive to Missing Groups distortions only if overlapped classes in original space are more separated in embedding. In contrast, CHbtwn decreases as proximity between classes increases, whether classes overlap or not."
- Break condition: If chosen CVM isn't appropriate for data characteristics.

## Foundational Learning

- Concept: Clustering Validation Measures (CVMs)
  - Why needed here: CVMs are the core component used by Label-T&C to quantify CLM in both spaces. Understanding CVMs is essential for interpreting Label-T&C scores.
  - Quick check question: What are the key requirements for a CVM to be used with Label-T&C (scale invariance, shift invariance, range invariance, stability)?

- Concept: Dimensionality Reduction (DR) Distortions
  - Why needed here: Label-T&C are designed to detect specific types of DR distortions (Missing and False Groups) that affect class-cluster relationships. Understanding these distortions is crucial for interpreting Label-T&C results.
  - Quick check question: How do Missing Groups and False Groups distortions differ in terms of their impact on CLM?

- Concept: Class-Label Matching (CLM)
  - Why needed here: Label-T&C are based on evaluating how well class labels match underlying cluster structure in both spaces. Understanding CLM is essential for interpreting Label-T&C scores.
  - Quick check question: Why is it problematic to assume that class labels always form good clusters in the original high-dimensional space?

## Architecture Onboarding

- Component map: High-dimensional data X -> DR embedding Z -> Class labels PL -> CVMs (DSC/CHbtwn) -> CLM matrices M(X), M(Z) -> Distortion matrices MFG, MMG -> Label-T and Label-C scores
- Critical path: Compute CLM matrices → Construct distortion matrices → Aggregate to final scores
- Design tradeoffs: Choice of CVM affects sensitivity to different types of distortions; DSC is faster but less sensitive to class overlap than CHbtwn
- Failure signatures: If CVM isn't invariant to scaling, shift, or range, scores will be unreliable; if CVM isn't sensitive to class overlap or proximity, may miss certain distortions
- First 3 experiments:
  1. Verify that Label-T decreases as False Groups distortions increase (e.g., by randomizing embedding)
  2. Verify that Label-C decreases as Missing Groups distortions increase (e.g., by overlapping classes in original space)
  3. Compare Label-T&C with existing measures (e.g., T&C, S&C) on datasets with known distortions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop a clustering validation measure (CVM) that is both sensitive to cluster-label matching and class overlap while satisfying the four requirements (scale invariance, shift invariance, range invariance, and stability)?
- Basis in paper: [explicit] The paper mentions this as interesting future work, noting that creating such a CVM would enhance Label-T&C's effectiveness.
- Why unresolved: Current CVMs like DSC and CHbtwn have limitations - DSC is less sensitive to class overlap while CHbtwn is more sensitive to proximity between classes regardless of overlap.
- What evidence would resolve it: Development and validation of a new CVM that outperforms DSC and CHbtwn in sensitivity to both cluster-label matching and class overlap while maintaining required invariances.

### Open Question 2
- Question: How can Label-T&C be effectively applied to evaluate supervised dimensionality reduction techniques?
- Basis in paper: [explicit] The paper suggests this as a potential future direction, noting that supervised DR techniques could be improved by incorporating Label-T&C into their loss function.
- Why unresolved: The paper only demonstrates Label-T&C's effectiveness for unsupervised DR techniques, and it's unclear how well it would work for supervised methods that explicitly use class labels during optimization.
- What evidence would resolve it: Empirical studies showing Label-T&C's performance on supervised DR techniques, potentially leading to improved optimization objectives.

### Open Question 3
- Question: What is the optimal strategy for selecting between DSC and CHbtwn as the CVM for Label-T&C in different scenarios?
- Basis in paper: [inferred] The paper shows that DSC and CHbtwn produce different results in certain experiments, with DSC being more sensitive to class overlap and CHbtwn to general proximity between classes.
- Why unresolved: The paper doesn't provide clear guidelines for when to use one measure over the other, leaving users to potentially make suboptimal choices.
- What evidence would resolve it: Systematic analysis of various dataset characteristics (e.g., degree of class overlap, separation between classes) and their relationship to the performance of Label-T&C with different CVMs.

## Limitations
- Dependence on clustering validation measures introduces sensitivity to implementation details and parameter settings
- Assumes chosen CVM can adequately capture class-cluster relationships in both original and embedded spaces
- Experimental validation sample size and diversity could be expanded for stronger generalizability claims

## Confidence

- High confidence: The general mechanism of comparing CLM matrices between original and embedded spaces is sound and well-justified
- Medium confidence: The specific choice of DSC and CHbtwn as recommended CVMs, given implementation dependencies
- Medium confidence: The experimental validation showing superiority over existing measures, though sample size and diversity could be expanded

## Next Checks

1. Implement Label-T&C using alternative CVMs (e.g., Silhouette coefficient) to verify robustness to CVM choice
2. Test on datasets with known cluster-label misalignment to validate detection of False and Missing Groups distortions
3. Evaluate runtime performance on larger datasets (>100K points) to confirm scalability claims