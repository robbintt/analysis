---
ver: rpa2
title: Cross-lingual Data Augmentation for Document-grounded Dialog Systems in Low
  Resource Languages
arxiv_id: '2305.14949'
source_url: https://arxiv.org/abs/2305.14949
tags:
- training
- data
- clem
- language
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents CLEM, a cross-lingual data augmentation framework
  for document-grounded dialogue systems in low-resource languages. CLEM leverages
  high-resource languages to enhance the capability of dialogue generation in low-resource
  languages by utilizing translated training and three-stage training.
---

# Cross-lingual Data Augmentation for Document-grounded Dialog Systems in Low Resource Languages

## Quick Facts
- arXiv ID: 2305.14949
- Source URL: https://arxiv.org/abs/2305.14949
- Authors: 
- Reference count: 12
- Primary result: CLEM framework achieved 4th place in DialDoc 2023 Competition with total score of 201.09

## Executive Summary
This paper presents CLEM, a cross-lingual data augmentation framework for document-grounded dialogue systems in low-resource languages. The framework leverages high-resource languages to enhance dialogue generation capabilities in low-resource languages through translated training data and a three-stage training process. CLEM employs an adversarial training retriever, re-ranker, and fusion-in-decoder generator, achieving strong performance on the DialDoc 2023 shared task for Vietnamese and French languages.

## Method Summary
CLEM uses a three-stage training process: cross-lingual pre-training on combined high-resource and translated data, training on translated pseudo data, and fine-tuning on low-resource data. The framework employs a Retrieve-Rerank-Generate architecture with adversarial training (FGM) on both retriever and re-ranker components. Training data is augmented by translating English and Chinese corpora to French and Vietnamese using Baidu and Tencent translation APIs, creating pseudo training data for low-resource languages.

## Key Results
- Achieved 4th place in DialDoc 2023 Competition with total score of 201.09
- Outperformed two-stage training approaches in ablation studies
- Demonstrated effectiveness of cross-lingual data augmentation for low-resource dialogue systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-lingual alignment through translated training improves low-resource dialogue performance by leveraging structural similarities between languages.
- Mechanism: By translating high-resource language datasets into low-resource languages, the model learns shared representations across languages, effectively expanding the training data for the target language.
- Core assumption: Languages with historical or structural similarities (e.g., English-French, Chinese-Vietnamese) can transfer knowledge effectively through translation.
- Evidence anchors:
  - [abstract] "Our model leverages high-resource languages to enhance the capability of dialogue generation in low-resource languages."
  - [section 3] "Note that English and French are Indo-European languages, indicating a common ancestral language, and Chinese and Vietnamese share historical and cultural connections and have influenced each other."
  - [corpus] Weak - no direct evidence in corpus about cross-lingual alignment effectiveness
- Break condition: Translation quality degrades significantly, or languages lack sufficient structural similarity for effective knowledge transfer.

### Mechanism 2
- Claim: Adversarial training on the retriever and re-ranker improves robustness and generalization in multilingual settings.
- Mechanism: FGM (Fast Gradient Method) adds small perturbations to word embeddings during training, forcing the model to learn more robust representations that generalize better across languages.
- Core assumption: Models trained with adversarial examples develop better generalization capabilities, especially in cross-lingual scenarios.
- Evidence anchors:
  - [section 4.1] "We apply infinitesimal perturbations on word embeddings to increase the learning difficulty by constructing adversarial examples."
  - [section 4.2] "As in the previous stage, we still employed FGM to add perturbations to word embeddings."
  - [corpus] Missing - no corpus evidence about adversarial training effectiveness
- Break condition: Perturbations become too large, causing training instability or model collapse.

### Mechanism 3
- Claim: Three-stage training (cross-lingual pre-training, translated data training, fine-tuning) creates a more effective learning trajectory than direct fine-tuning.
- Mechanism: Each training stage builds upon the previous one - first establishing cross-lingual capabilities, then adapting to translated data, and finally specializing for the low-resource task.
- Core assumption: Progressive training stages allow the model to develop more robust multilingual representations than single-stage training.
- Evidence anchors:
  - [section 4.4] "Our training process consists of three stages... T(D + Dt)T(D′ + Dt)F(Dt)."
  - [section 5.3.1] "From the first three lines of Table 3, we can observe that CLEM has superior performance than two-stage training."
  - [corpus] Weak - corpus mentions related approaches but no direct evidence about three-stage effectiveness
- Break condition: Stage progression becomes too slow, causing catastrophic forgetting of earlier learned representations.

## Foundational Learning

- Concept: Dense Passage Retrieval (DPR)
  - Why needed here: Efficient retrieval of relevant documents from large corpora is crucial for document-grounded dialogue systems.
  - Quick check question: What is the difference between sparse and dense retrieval methods in terms of query-document matching?

- Concept: Cross-lingual representation learning
  - Why needed here: The framework needs to handle multiple languages and transfer knowledge between them effectively.
  - Quick check question: How do cross-lingual embeddings enable knowledge transfer between languages with different scripts?

- Concept: Adversarial training (FGM)
  - Why needed here: Improves model robustness and generalization, particularly important for low-resource language settings.
  - Quick check question: What is the key difference between FGM and other adversarial training methods like PGD?

## Architecture Onboarding

- Component map:
  - Retriever (DPR-based) → Reranker (XLM-RoBERTa) → Generator (FiD)
  - Cross-lingual training pipeline with three stages
  - Translation component for data augmentation

- Critical path:
  1. Input query → Retriever → Top-k passages
  2. Query + passages → Reranker → Ranked passages
  3. Query + passages → Generator → Response

- Design tradeoffs:
  - Memory vs. retrieval accuracy (top-k vs. top-n passages)
  - Training time vs. model performance (three-stage vs. direct training)
  - Translation quality vs. data augmentation benefits

- Failure signatures:
  - Retriever consistently returns irrelevant passages
  - Model overfits to translated data and underperforms on original low-resource data
  - Training instability due to adversarial perturbations

- First 3 experiments:
  1. Compare single-stage vs. three-stage training on a subset of data
  2. Test different perturbation magnitudes in adversarial training
  3. Evaluate translation quality impact by varying translation confidence thresholds

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the adversarial training in the retriever and re-ranker components affect the performance of the dialogue system in low-resource languages?
- Basis in paper: [explicit] The paper mentions that adversarial training is incorporated into both the Retriever and Re-ranker components to address the low-resource DGDS scenario.
- Why unresolved: The paper does not provide a detailed analysis of the impact of adversarial training on the performance of the dialogue system in low-resource languages.
- What evidence would resolve it: Conducting an ablation study to compare the performance of the dialogue system with and without adversarial training in the retriever and re-ranker components.

### Open Question 2
- Question: What is the impact of different pseudo corpora (Zh-Vi and En-Fr) on the performance of the CLEM framework?
- Basis in paper: [explicit] The paper mentions that two translated pseudo corpora, Zh-Vi and En-Fr, are used to enhance the performance of the framework in low-resource languages.
- Why unresolved: The paper does not provide a detailed comparison of the impact of each pseudo corpus on the performance of the framework.
- What evidence would resolve it: Conducting an ablation study to compare the performance of the framework with and without each pseudo corpus.

### Open Question 3
- Question: How does the use of prompt-learning affect the performance of the knowledge-enhancement generation component?
- Basis in paper: [explicit] The paper mentions that prompt-learning is adopted in the knowledge-enhancement generation component by adding a prompt to the front of the input query.
- Why unresolved: The paper does not provide a detailed analysis of the impact of prompt-learning on the performance of the knowledge-enhancement generation component.
- What evidence would resolve it: Conducting an ablation study to compare the performance of the knowledge-enhancement generation component with and without prompt-learning.

## Limitations

- Translation quality dependency: The framework's effectiveness heavily relies on translation quality from external APIs, with no direct evaluation of translation quality provided.
- Limited language pair validation: Success demonstrated only with specific language pairs (En-Fr, Zh-Vi) without testing generalization to arbitrary low-resource language pairs.
- Incomplete ablation studies: Lack of comprehensive comparisons against single-stage training and other training strategies.

## Confidence

- High Confidence: The overall framework architecture (Retrieve-Rerank-Generate) and three-stage training process are well-defined and implementable.
- Medium Confidence: The claim that cross-lingual data augmentation improves low-resource dialogue performance, given the specific language pairs used.
- Low Confidence: The claim that CLEM achieves state-of-the-art performance without comprehensive comparisons against other cross-lingual approaches.

## Next Checks

1. **Translation Quality Validation**: Measure the impact of translation quality by comparing model performance when using different translation services or when varying translation confidence thresholds.

2. **Generalization Testing**: Apply the framework to different low-resource language pairs (e.g., English-Spanish or English-Arabic) to test whether the approach generalizes beyond the specific pairs used in the competition.

3. **Component Ablation**: Conduct a more comprehensive ablation study by testing CLEM against single-stage training, different adversarial training magnitudes, and alternative re-ranking strategies to isolate which components contribute most to performance gains.