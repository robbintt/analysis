---
ver: rpa2
title: 'DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for Hospitalized
  Patients'
arxiv_id: '2309.12625'
source_url: https://arxiv.org/abs/2309.12625
tags:
- drgs
- prediction
- training
- base
- drg-llama
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DRG-LLaMA is a large language model (LLaMA) fine-tuned on clinical
  notes for predicting Diagnosis-Related Groups (DRGs) in U.S. hospitals.
---

# DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for Hospitalized Patients

## Quick Facts
- arXiv ID: 2309.12625
- Source URL: https://arxiv.org/abs/2309.12625
- Reference count: 40
- Key outcome: DRG-LLaMA achieves 52.0% top-1 accuracy and 0.327 macro-F1 score on DRG prediction from clinical notes, outperforming previous state-of-the-art models.

## Executive Summary
DRG-LLaMA fine-tunes the LLaMA language model on clinical discharge summaries to predict Diagnosis-Related Groups (DRGs) for hospitalized patients. The model demonstrates superior performance compared to previous approaches like ClinicalBERT and CAML, achieving a relative improvement of 40.3% in macro-averaged F1 score. DRG-LLaMA's performance improves with larger model parameters and longer input context lengths, making it a promising tool for automating DRG assignment in healthcare settings.

## Method Summary
DRG-LLaMA fine-tunes LLaMA using LoRA adaptation on clinical discharge summaries from the MIMIC-IV dataset, focusing on the "brief hospital course" section. The model employs both single-label and two-label classification approaches, with the latter separating base DRG and CC/MCC prediction before recombining using domain rules. Training uses 236,192 discharge summaries filtered to MS-DRGs, with 90% for training and 10% for testing. The model is evaluated using macro-averaged F1 score, top-1 and top-5 accuracy, and macro-averaged AUC metrics.

## Key Results
- DRG-LLaMA achieved a macro-averaged F1 score of 0.327 and top-1 prediction accuracy of 52.0%
- When predicting base DRG and CC/MCC separately, top-1 accuracy reached 67.8% and 67.5% respectively
- Performance improves with larger model sizes (up to 13B parameters) and longer input contexts (up to 1024 tokens)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DRG-LLaMA achieves superior performance by fine-tuning LLaMA on clinical discharge summaries rather than structured data.
- Mechanism: The model learns to extract diagnostic and procedural information from free-text narratives, capturing contextual nuances that structured variables miss.
- Core assumption: Clinical discharge summaries contain sufficient information to predict DRG codes without additional structured inputs.
- Evidence anchors:
  - [abstract] "DRG-LLaMA, an advanced large language model (LLM) fine-tuned on clinical notes to enhance DRGs assignment."
  - [section] "DRG-LLaMA -7B achieved a macro-averaged F1 score of 0.327...surpassed previously reported leading models on this task, demonstrating a relative improvement in macro-averaged F1 score of 40.3% compared to ClinicalBERT and 35.7% compared to CAML."
  - [corpus] Weak evidence - no direct comparisons to structured data approaches found.
- Break condition: If discharge summaries lack critical information (e.g., procedure details), performance will degrade compared to models using structured inputs.

### Mechanism 2
- Claim: The two-label approach improves DRG prediction accuracy by separating base DRG and CC/MCC prediction.
- Mechanism: By decomposing the DRG code into base DRG and CC/MCC components, the model can specialize on each aspect, then recombine using domain rules.
- Core assumption: Base DRGs and CC/MCC can be predicted independently with sufficient accuracy.
- Evidence anchors:
  - [section] "The top-1 prediction accuracy for base DRG and CC/MCC reached 67.8% and 67.5% respectively...the accuracy reached 51.5% across all DRGs...comparable with the accuracy attained in the single label approach of 52.0%."
  - [section] "This approach entailed a loss function configured as the cross-entropy loss of the base DRG, plus half of the cross-entropy loss of the CC/MCC status."
  - [corpus] Weak evidence - no comparison to alternative decomposition strategies found.
- Break condition: If the mapping rules between base DRG and CC/MCC are incomplete or incorrect, the recombination step will fail.

### Mechanism 3
- Claim: Larger model sizes and longer input contexts improve DRG prediction performance.
- Mechanism: Increased model capacity allows better capture of complex clinical relationships, while longer contexts enable consideration of more relevant patient information.
- Core assumption: The performance gains scale with model size and context length.
- Evidence anchors:
  - [abstract] "DRG-LLaMA performance exhibits improvements in correlation with larger model parameters and longer input context lengths."
  - [section] "The best performance was achieved with 13B LLaMA and a maximum input token size of 1024. This configuration yielded a top-1 prediction accuracy of 54.6%...a macro-F1 score of 0.361."
  - [section] "Across all evaluation metrics, a consistent pattern of improvement was observed with the deployment of larger model sizes and longer input context lengths."
- Break condition: If performance plateaus or degrades with larger models/contexts, it may indicate overfitting or inefficient attention mechanisms.

## Foundational Learning

- Concept: Multi-class classification metrics (macro-F1, AUC)
  - Why needed here: DRG prediction is a multi-class problem with imbalanced class distribution, requiring appropriate evaluation metrics.
  - Quick check question: Why is macro-F1 preferred over micro-F1 for this task?

- Concept: Transformer-based language models and fine-tuning
  - Why needed here: DRG-LLaMA uses LLaMA, a transformer-based model, and employs LoRA for efficient fine-tuning.
  - Quick check question: What is the purpose of LoRA in this context?

- Concept: Clinical note structure and DRG coding rules
  - Why needed here: Understanding discharge summary content and DRG composition is crucial for feature extraction and model evaluation.
  - Quick check question: How are base DRGs and CC/MCC used to construct full DRG codes?

## Architecture Onboarding

- Component map: Discharge summaries -> Brief hospital course extraction -> LLaMA with LoRA fine-tuning -> DRG predictions -> (Optional) Mapping rules for two-label approach

- Critical path:
  1. Extract "brief hospital course" from discharge summaries
  2. Preprocess text and standardize DRG nomenclature
  3. Fine-tune LLaMA using LoRA on training data
  4. Evaluate predictions using macro-F1, AUC, and accuracy metrics
  5. For two-label approach, apply mapping rules to derive final DRGs

- Design tradeoffs:
  - Single-label vs. two-label approach: Single-label is simpler but may not capture CC/MCC nuances; two-label allows specialization but requires accurate mapping rules.
  - Model size vs. computational cost: Larger models improve performance but increase training time and resource requirements.
  - Input length vs. context capture: Longer contexts allow consideration of more information but may introduce noise or exceed model limits.

- Failure signatures:
  - Poor performance on rare DRGs: Indicates insufficient training data or model capacity issues.
  - Inaccurate CC/MCC predictions: Suggests errors in mapping rules or insufficient training examples for CC/MCC classification.
  - Slow inference times: May indicate inefficient LoRA configuration or hardware limitations.

- First 3 experiments:
  1. Compare single-label vs. two-label approach performance on a subset of DRGs.
  2. Evaluate impact of different input lengths (e.g., 256, 512, 1024 tokens) on prediction accuracy.
  3. Test LoRA rank values (e.g., 4, 8, 16) to optimize fine-tuning efficiency and performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the prediction performances of DRG-LLaMA compare when using different types of clinical notes (e.g., admission notes, progress notes) as input, as opposed to just discharge summaries?
- Basis in paper: [inferred] The paper mentions the limitation of using only discharge summaries due to their post-hospitalization availability and suggests that admission notes or emergency department notes could enable earlier DRG prediction.
- Why unresolved: The study only used discharge summaries, so there's no direct comparison with other note types.
- What evidence would resolve it: Experiments comparing DRG-LLaMA's performance using various clinical note types as input, measuring top-1 and top-5 accuracy, macro-averaged F1 score, and macro-averaged AUC for each note type.

### Open Question 2
- Question: What is the impact of increasing the input token length beyond 1024 on the performance of DRG-LLaMA, and is there an optimal token length for this task?
- Basis in paper: [explicit] The paper notes that DRG-LLaMA's performance improves with longer input context lengths, but it hasn't tested beyond 1024 tokens.
- Why unresolved: The study only tested up to 1024 tokens, so the effect of longer contexts is unknown.
- What evidence would resolve it: Testing DRG-LLaMA with input token lengths greater than 1024, analyzing changes in prediction accuracy, F1 score, and AUC to identify if there's a point of diminishing returns or optimal length.

### Open Question 3
- Question: How does the integration of DRG-LLaMA into existing hospital coding workflows affect the efficiency and accuracy of DRG assignment compared to current manual processes?
- Basis in paper: [inferred] The paper suggests that early DRG prediction could inform hospital operations but does not discuss the practical implementation or its impact on coding workflows.
- Why unresolved: The study focuses on model performance but does not address real-world application or workflow integration.
- What evidence would resolve it: Implementation studies in hospital settings where DRG-LLaMA is used alongside human coders, measuring changes in coding time, accuracy, and any impact on hospital operations or financial performance.

## Limitations
- Performance of 52.0% top-1 accuracy, while improved over previous methods, still leaves room for clinical deployment improvement
- Reliance on discharge summaries assumes these contain sufficient information, potentially missing critical structured EHR data
- Evaluation focuses on MS-DRGs without addressing generalization to other DRG systems or international coding frameworks

## Confidence
- High Confidence: Comparative performance improvements over ClinicalBERT and CAML are well-supported
- Medium Confidence: Two-label approach effectiveness is supported but lacks direct comparison to alternatives
- Low Confidence: Generalization to clinical settings remains uncertain without real-world deployment evaluation

## Next Checks
1. Implement DRG-LLaMA in a real hospital setting to evaluate performance with actual clinical workflows and assess false positives/negatives on critical DRG categories
2. Conduct comprehensive evaluation of model performance across different patient demographics (age, race, insurance status) to identify and mitigate potential biases
3. Compare DRG-LLaMA's performance against models that incorporate both clinical notes and structured EHR data to quantify the value of unstructured text versus comprehensive multi-modal approaches