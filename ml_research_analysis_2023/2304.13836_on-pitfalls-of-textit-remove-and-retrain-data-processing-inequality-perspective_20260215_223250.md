---
ver: rpa2
title: 'On Pitfalls of $\textit{RemOve-And-Retrain}$: Data Processing Inequality Perspective'
arxiv_id: '2304.13836'
source_url: https://arxiv.org/abs/2304.13836
tags:
- roar
- attribution
- evaluation
- methods
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study critically evaluates the reliability of the Remove-And-Retrain
  (ROAR) protocol for measuring feature importance in deep learning. We demonstrate
  that attributions with less information about the decision function can yield superior
  ROAR benchmark results, contradicting the protocol's intended purpose.
---

# On Pitfalls of $\textit{RemOve-And-Retrain}$: Data Processing Inequality Perspective

## Quick Facts
- arXiv ID: 2304.13836
- Source URL: https://arxiv.org/abs/2304.13836
- Authors: 
- Reference count: 12
- Key outcome: This study critically evaluates the reliability of the Remove-And-Retrain (ROAR) protocol for measuring feature importance in deep learning. We demonstrate that attributions with less information about the decision function can yield superior ROAR benchmark results, contradicting the protocol's intended purpose. This phenomenon, termed "blurriness bias," also manifests in the recently proposed RemOve-And-Debias (ROAD) variant. Our theoretical analysis, based on Data Processing Inequality, shows that post-processing attribution maps can artificially improve ROAR scores by reducing mutual information between modified inputs and class labels. We empirically validate this bias through extensive experiments on CIFAR-10, SVHN, and CUB-200 datasets, showing strong negative correlations between attribution blurriness and ROAR performance. Our findings caution against uncritical reliance on ROAR metrics for evaluating feature importance methods.

## Executive Summary
This paper identifies a critical flaw in the Remove-And-Retrain (ROAR) protocol, a widely-used method for evaluating feature importance in deep learning models. The authors demonstrate that post-processing attribution maps with blurring operations (such as Gaussian filtering or max-pooling) can artificially improve ROAR scores by reducing the mutual information between modified inputs and class labels. This "blurriness bias" contradicts ROAR's intended purpose of measuring feature importance, as less informative attributions appear to perform better. The phenomenon is explained through Data Processing Inequality and extends to the recently proposed RemOve-And-Debias (ROAD) protocol. Extensive experiments on CIFAR-10, SVHN, and CUB-200 datasets confirm the theoretical predictions, showing strong negative correlations between attribution blurriness and ROAR performance.

## Method Summary
The study evaluates ROAR's reliability by applying various attribution methods (Grad, GI, IG, SG, VG, GC) to generate attribution maps, then post-processing these maps using Gaussian filtering or max-pooling operations. The researchers remove features based on processed attributions, retrain models, and measure accuracy drops to calculate ROAR scores. They also compute Total Variation (TV) of attribution maps as a measure of blurriness. The experiments use CIFAR-10, SVHN, and CUB-200 datasets with pre-trained ResNet18 (for CIFAR-10 and SVHN) and ResNet50 (for CUB-200) models. The analysis combines theoretical insights from Data Processing Inequality with empirical validation across multiple datasets and attribution methods.

## Key Results
- Post-processing attribution maps with blurring operations artificially improves ROAR benchmark scores
- Squared attribution methods show more pronounced blurriness bias compared to plain versions
- Strong negative correlation exists between attribution blurriness (measured by total variation) and ROAR performance
- The bias phenomenon extends to the RemOve-And-Debias (ROAD) protocol variant

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Post-processing attribution maps with blurring operations (Gaussian filter, max-pooling) can artificially improve ROAR benchmark scores by reducing mutual information between modified inputs and class labels.
- Mechanism: Data Processing Inequality (DPI) ensures that when conditioning on the input data X, any post-processing of the attribution map A (creating k(A)) cannot increase the mutual information about the explainer E. This allows modified inputs X' derived from blurred attributions to contain less information about the true feature importance while still appearing to perform well on ROAR.
- Core assumption: The ROAR metric assumes that lower mutual information between modified inputs and class labels indicates better attribution quality, but this conflates information loss from the attribution method itself with information loss from the blurring post-processing.
- Evidence anchors:
  - [abstract]: "attributions containing lesser information about the decision function can lead to enhanced performance on ROAR benchmarks"
  - [section]: "The Data Processing Inequality (DPI) holds when X is controlled, as established by the Markov chain E → A → k(A)"
  - [corpus]: Weak evidence - related papers discuss ROAR variants but don't address the DPI perspective on post-processing bias
- Break condition: If the ROAR protocol changes to account for attribution blurriness or if mutual information measurements become more sophisticated to distinguish between attribution quality and post-processing effects.

### Mechanism 2
- Claim: The structural causal model underlying ROAR creates spurious correlations that allow blurred attributions to appear more effective than they actually are.
- Mechanism: The attribution variable A acts as a collider between data X and explainer E, while X is a common cause of both A and the modified input X'. This creates a dependency structure where the ROAR metric cannot properly isolate the causal effect of the explainer E on model performance.
- Core assumption: The ROAR protocol's data generation process (as shown in Figure 1) creates a structural causal model where the measurement of I(X';Y) cannot properly attribute credit or blame to the explainer E due to the collider structure.
- Evidence anchors:
  - [section]: "The attribution variable A serves as a collider between data X and explainer E1"
  - [section]: "X is a common cause of both A and X', thereby leading to a spurious correlation among these variables"
  - [corpus]: Weak evidence - related work mentions evaluation metrics but doesn't analyze the causal structure
- Break condition: If alternative evaluation protocols are developed that properly account for the causal structure, or if researchers become aware of and adjust for these spurious correlations.

### Mechanism 3
- Claim: The bias toward attribution blurriness in ROAR is dataset-dependent and relates to the natural sparsity of image gradients.
- Mechanism: Natural images have sparse gradients compared to the total image space, meaning pixels with similar values are adjacent. Post-processing methods like BlockRandom (which removes contiguous blocks) cause greater information loss than PixelRandom, and this principle extends to how blurred attributions interact with the dataset's inherent structure.
- Core assumption: The relationship between attribution blurriness and ROAR performance is mediated by the dataset's structural properties, particularly the sparsity of image gradients and the correlation between adjacent pixels.
- Evidence anchors:
  - [section]: "The gradient of a natural image is typically sparse compared to the total image space, leading to pixels with similar values to adjacent pixels"
  - [section]: "This observation also aligns with the concept of total variation prior in image restoration"
  - [corpus]: Weak evidence - related papers discuss datasets but not the specific relationship between gradient sparsity and ROAR bias
- Break condition: If the relationship between gradient sparsity and ROAR performance is disproven through experiments on datasets with different structural properties, or if the total variation prior is shown to be irrelevant to the phenomenon.

## Foundational Learning

- Concept: Data Processing Inequality (DPI)
  - Why needed here: DPI provides the theoretical foundation for understanding why post-processing attribution maps cannot increase information about the explainer, which is crucial for explaining the ROAR benchmark's vulnerability to blurriness bias.
  - Quick check question: If you have a Markov chain X → Y → Z, can processing Z ever increase the mutual information between X and Z?

- Concept: Structural Causal Models (SCMs)
  - Why needed here: SCMs help visualize and analyze the dependency structure that creates spurious correlations in the ROAR protocol, making it clear why the metric cannot properly isolate the effect of the explainer.
  - Quick check question: In a structural causal model with a collider node, what happens to the correlation between its parents when the collider is conditioned upon?

- Concept: Mutual Information and Total Variation
  - Why needed here: These concepts are used to quantify both the information content in attribution maps and the blurriness bias, providing the mathematical framework for the empirical validation of the theoretical claims.
  - Quick check question: How does applying a Gaussian filter to an image affect its total variation, and why is this relevant for understanding attribution blurriness?

## Architecture Onboarding

- Component map: Data preprocessing -> Attribution methods -> Post-processing -> ROAR evaluation -> Performance measurement -> Analysis
- Critical path:
  1. Train base model on dataset
  2. Generate attribution maps for test set
  3. Apply post-processing to attribution maps
  4. Run ROAR/ROAD protocol with different drop rates
  5. Measure model performance and calculate total variation
  6. Analyze correlation between blurriness and performance
- Design tradeoffs:
  - Using squared attribution methods vs. plain versions (squared versions show more pronounced bias)
  - Choice of post-processing method (Gaussian vs. max-pooling have different effects on different datasets)
  - Drop rate selection (higher rates amplify the blurriness bias effect)
- Failure signatures:
  - If ROAR scores don't correlate with attribution blurriness, the theoretical framework may be incorrect
  - If post-processing doesn't improve ROAR scores as expected, the DPI mechanism may not apply
  - If results vary significantly across trials, there may be implementation issues or dataset-specific effects
- First 3 experiments:
  1. Run ROAR with plain vs. Gaussian-filtered attribution maps on CIFAR-10 with Grad-CAM to verify the basic blurriness bias
  2. Calculate total variation correlation on SVHN across all attribution methods to confirm the dataset dependency
  3. Apply BlockRandom vs. PixelRandom baselines on CUB-200 to validate the gradient sparsity hypothesis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific properties of Gaussian and max-pooling filters make them particularly effective at degrading attribution maps in a way that improves ROAR scores, and could other post-processing methods achieve similar or better results?
- Basis in paper: [explicit] The paper discusses Gaussian and max-pooling filters as specific post-processing methods that improve ROAR scores, noting their effectiveness in reducing total variation of attributions.
- Why unresolved: The paper only explores two specific post-processing methods and does not systematically investigate other possible approaches or explain why these particular filters work well.
- What evidence would resolve it: Systematic experiments comparing ROAR performance across a broader range of post-processing methods (e.g., median filtering, bilateral filtering, morphological operations) with detailed analysis of their effects on attribution maps and mutual information metrics.

### Open Question 2
- Question: How does the blurriness bias in ROAR extend to other perturbation-based evaluation methods beyond ROAR and ROAD, and what are the fundamental mechanisms that cause this bias across different evaluation frameworks?
- Basis in paper: [explicit] The paper states that "the findings and discussions are extensible to other perturbation-based evaluation methods" and identifies the fundamental problem in the data generation process during perturbation-based evaluations.
- Why unresolved: While the paper establishes that the issue extends beyond ROAR, it does not provide a comprehensive analysis of how this bias manifests across different perturbation-based evaluation frameworks or what underlying mechanisms cause it.
- What evidence would resolve it: Comparative studies of multiple perturbation-based evaluation methods (e.g., deletion game, insertion game, sensitivity-n) examining how attribution blurriness affects each method's scores and identifying common patterns in the data generation processes that lead to bias.

### Open Question 3
- Question: What is the relationship between attribution blurriness and the specific architectural properties of neural networks (e.g., depth, width, activation functions) and how do these architectural factors influence the correlation between blurriness and ROAR performance?
- Basis in paper: [explicit] The paper shows a strong correlation between attribution blurriness and ROAR performance across different models and datasets, but does not investigate how specific architectural properties might influence this relationship.
- Why unresolved: The experiments use fixed architectures (ResNet18 and ResNet50) without systematically varying architectural parameters to understand their influence on the blurriness-ROAR relationship.
- What evidence would resolve it: Controlled experiments with neural networks varying in depth, width, and activation functions, measuring both attribution blurriness and ROAR performance to identify architectural factors that strengthen or weaken the observed correlation.

## Limitations
- The theoretical analysis assumes a simplified structural causal model that may not fully capture the complexity of neural network decision boundaries
- The study focuses primarily on image classification tasks and may not generalize to other domains like NLP or tabular data
- The paper does not investigate potential mitigation strategies for the identified blurriness bias in ROAR

## Confidence

- Mechanism 1 (DPI-based explanation): **High** - The theoretical framework is mathematically rigorous and well-supported by empirical evidence across multiple datasets and attribution methods.
- Mechanism 2 (Causal structure analysis): **Medium** - While the structural causal model is plausible, the real-world applicability depends on how closely the simplified model represents actual neural network behavior.
- Mechanism 3 (Dataset-dependent bias): **Medium** - The correlation between gradient sparsity and ROAR performance is supported by evidence but may not be the sole determining factor.

## Next Checks
1. Test the blurriness bias with attribution methods not based on gradient information (e.g., perturbation-based methods) to determine if the phenomenon is specific to gradient-derived attributions.
2. Evaluate the ROAR protocol's bias across various neural network architectures (CNNs, Transformers, MLPs) to assess whether the blurriness bias is architecture-dependent.
3. Create synthetic datasets with controlled gradient sparsity properties to isolate the relationship between natural image structure and ROAR performance, helping to validate the dataset-dependent hypothesis.