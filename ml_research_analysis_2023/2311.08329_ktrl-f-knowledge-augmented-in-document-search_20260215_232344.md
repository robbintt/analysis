---
ver: rpa2
title: 'KTRL+F: Knowledge-Augmented In-Document Search'
arxiv_id: '2311.08329'
source_url: https://arxiv.org/abs/2311.08329
tags:
- knowledge
- ktrl
- query
- external
- targets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KTRL+F introduces a knowledge-augmented in-document search task
  requiring real-time identification of all semantic targets within a document using
  external knowledge. The paper proposes a Knowledge-Augmented Phrase Retrieval model
  that integrates external knowledge embeddings with phrase embeddings via simple
  element-wise addition, achieving a balance between speed and performance.
---

# KTRL+F: Knowledge-Augmented In-Document Search

## Quick Facts
- **arXiv ID**: 2311.08329
- **Source URL**: https://arxiv.org/abs/2311.08329
- **Reference count**: 8
- **Key outcome**: KTRL+F introduces a knowledge-augmented in-document search task requiring real-time identification of all semantic targets within a document using external knowledge.

## Executive Summary
KTRL+F introduces a novel task of knowledge-augmented in-document search that requires identifying all semantic targets within a document using external knowledge in real-time. The paper proposes a Knowledge-Augmented Phrase Retrieval model that integrates external knowledge embeddings with phrase embeddings via simple element-wise addition, achieving a balance between speed and performance. Evaluated on a newly curated dataset, the model achieves a List EM score of 23.15% and a latency of 15 ms per query, outperforming generative and extractive baselines while maintaining real-time applicability.

## Method Summary
The Knowledge-Augmented Phrase Retrieval model combines frozen DensePhrases phrase embeddings with external knowledge embeddings through element-wise addition. The approach uses an entity linking module to identify candidate targets within the document and map them to Wikipedia pages. Query and phrase encoders extract dense vector representations, which are then combined with knowledge embeddings to form the final representations used for Maximum Inner Product Search (MIPS) operations. The model is evaluated on a dataset of 512 queries across 98 input documents, measuring performance using List EM, List Overlap F1, robustness score, and latency metrics.

## Key Results
- List EM score of 23.15% with 15 ms latency per query
- Outperforms generative baselines (GPT-4, GPT-3.5, LLAMA-2, VICUNA) and extractive baselines
- Ablation study shows performance drops when removing external knowledge (-External) or using only external knowledge (-Internal)
- Significant performance improvement when using gold entity linking (GCP API) versus Wikifier API

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Knowledge-Augmented Phrase Retrieval achieves real-time performance by leveraging pre-built phrase embeddings and simple element-wise addition of knowledge embeddings.
- Mechanism: The model uses a frozen DensePhrases model to extract phrase embeddings and concatenates the start and end token embeddings to create entity embeddings. External knowledge embeddings are generated by concatenating the entity name and its Wikipedia page, then added to the entity embeddings via element-wise addition. This avoids additional training steps and enables fast MIPS operations.
- Core assumption: The simple element-wise addition of knowledge embeddings effectively captures the contextual knowledge for more accurate and comprehensive search and retrieval within the document.
- Evidence anchors:
  - [abstract]: "Knowledge-Augmented Phrase Retrieval model that shows a promising balance between speed and performance by simply augmenting external knowledge in phrase embedding."
  - [section 5.3]: "To incorporate external knowledge related to the entity, we utilize the same phrase encoder that is used to extract embeddings for candidate entities. Following the approach in Lee et al. (2022), we generate knowledge embedding for the linked entity by concatenating the text of the name of entity and its corresponding Wikipedia page... By adopting this approach, we can effectively encode pertinent knowledge about the entity into its embedding."
  - [corpus]: Weak. The corpus does not provide direct evidence for this mechanism. It mentions related works on knowledge-augmented information retrieval, but not specifically on the element-wise addition approach.
- Break condition: If the element-wise addition does not effectively capture the contextual knowledge, or if the MIPS operations are not fast enough for real-time applicability.

### Mechanism 2
- Claim: The external knowledge linking module identifies potential candidate targets and maps them to relevant Wikipedia knowledge bases, enabling the model to bridge the semantic gap between query and targets.
- Mechanism: The module skims the target text, identifies entities using an entity linking model (Wikifier API), and maps each entity to its corresponding Wikipedia page. This external knowledge serves as additional information about the targets, helping to connect the query and targets beyond the information present in the input document.
- Core assumption: The entities identified by the entity linking model are indeed potential candidate targets, and the Wikipedia pages provide relevant and accurate external knowledge about these targets.
- Evidence anchors:
  - [section 5.1]: "The external knowledge linking module skims the target text and identifies entities, which can be potential candidate targets, mapping each of them to the relevant Wikipedia knowledge base."
  - [section 6.2]: "Comparing the performance between our model with Wikifier and GCP entity linker, the one with the GCP entity linker, a gold entity linker utilized in the dataset construction pipeline, exhibits a significant performance improvement... This underscores the critical role of sourcing high-quality external knowledge in addressing KTRL +F."
  - [corpus]: Weak. The corpus mentions knowledge-augmented information retrieval, but does not provide specific evidence for the entity linking and Wikipedia mapping approach used in this model.
- Break condition: If the entity linking model fails to identify relevant entities, or if the Wikipedia pages do not provide accurate or useful external knowledge about the targets.

### Mechanism 3
- Claim: The Knowledge-Augmented Phrase Retrieval model outperforms generative and extractive baselines by effectively balancing real-time applicability and performance through the use of external knowledge.
- Mechanism: The model combines the strengths of phrase retrieval (fast MIPS operations) with the ability to incorporate external knowledge (knowledge embeddings). This allows it to find all semantic targets in real-time while leveraging additional information beyond the input document. The ablation study shows that removing the external knowledge (-External) or using only external knowledge (-Internal) leads to performance drops, indicating the importance of the hybrid approach.
- Core assumption: The combination of phrase retrieval and external knowledge is more effective than using either approach alone for the KTRL +F task.
- Evidence anchors:
  - [abstract]: "The model achieves a List EM score of 23.15% and a latency of 15 ms per query, outperforming generative and extractive baselines while maintaining real-time applicability."
  - [section 6.2]: "Our experimental results support that by simply adding the knowledge embedding and the phrase embedding, Knowledge-Augmented Phrase Retrieval exhibits the potential to reflect external knowledge without sacrificing latency."
  - [section 6.2]: "As presented in Table 4, the exclusion of external knowledge embedding (-External) results in a notable performance drop... When removing phrase embedding and using only external knowledge embedding for representing candidate targets (-Internal), our model with GCP entity linker show better performance, while model with Wikifier show lower results than hybrid version overall."
  - [corpus]: Weak. The corpus mentions related works on knowledge-augmented information retrieval, but does not provide specific evidence for the performance comparison between this model and generative/extractive baselines.
- Break condition: If the combination of phrase retrieval and external knowledge does not lead to better performance than using either approach alone, or if the real-time applicability is compromised.

## Foundational Learning

- Concept: Dense phrase retrieval
  - Why needed here: The model relies on pre-built phrase embeddings from a frozen DensePhrases model to enable fast MIPS operations for real-time search.
  - Quick check question: How does the DensePhrases model encode phrases into dense vector representations, and why is this suitable for fast similarity search?

- Concept: Entity linking
  - Why needed here: The model uses an entity linking model to identify potential candidate targets within the input document and map them to relevant external knowledge sources (Wikipedia).
  - Quick check question: What are the key challenges in entity linking, and how does the Wikifier API address these challenges in the context of KTRL +F?

- Concept: Knowledge augmentation
  - Why needed here: The model incorporates external knowledge about the targets to bridge the semantic gap between the query and targets, improving the overall performance of the search task.
  - Quick check question: What are the different approaches to knowledge augmentation, and why is the element-wise addition of knowledge embeddings a suitable choice for this model?

## Architecture Onboarding

- Component map: External knowledge linking module -> Phrase encoder -> Knowledge aggregation module -> MIPS module -> Query encoder
- Critical path: External knowledge linking -> Phrase encoding -> Knowledge aggregation -> MIPS search
- Design tradeoffs:
  - Using a frozen DensePhrases model enables fast MIPS operations but may limit the model's ability to learn task-specific embeddings
  - Relying on entity linking and Wikipedia for external knowledge introduces potential errors or biases, but provides a scalable and accessible source of information
  - The simple element-wise addition of knowledge embeddings is computationally efficient but may not capture complex relationships between the knowledge and entities
- Failure signatures:
  - Low List EM and List Overlap scores indicate that the model is not effectively finding all semantic targets
  - High latency suggests that the MIPS operations or embedding generation are not efficient enough for real-time applicability
  - Poor performance with certain entity linkers or Wikipedia pages may indicate issues with the quality or relevance of the external knowledge
- First 3 experiments:
  1. Evaluate the impact of different entity linkers (e.g., Wikifier vs. GCP) on the model's performance and latency
  2. Ablation study: Remove the external knowledge aggregation module and compare the performance to the full model
  3. Compare the performance of the model with different knowledge embedding generation methods (e.g., using only entity names vs. concatenating entity names and Wikipedia pages)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Knowledge-Augmented Phrase Retrieval scale with increasing model size compared to generative baselines?
- Basis in paper: [explicit] The paper compares various model sizes (7B, 13B) for generative baselines like LLAMA-2 and VICUNA, showing that scaling up model capacity doesn't consistently improve performance across all metrics for KTRL+F.
- Why unresolved: The paper doesn't provide a systematic analysis of how different model sizes for the Knowledge-Augmented Phrase Retrieval approach would perform compared to the generative baselines. It only mentions that their model shows promising results with BERT-base size.
- What evidence would resolve it: Experiments comparing Knowledge-Augmented Phrase Retrieval with larger model architectures (e.g., BERT-large, RoBERTa) and measuring performance across the KTRL+F metrics would clarify scaling behavior.

### Open Question 2
- Question: How robust is the Knowledge-Augmented Phrase Retrieval model to variations in external knowledge quality and coverage?
- Basis in paper: [explicit] The ablation study shows performance differences between using gold entity linking (GCP API) versus a Wikifier API, suggesting external knowledge quality impacts performance. The paper also mentions the model's ability to handle various forms of external knowledge beyond Wikipedia.
- Why unresolved: The paper doesn't systematically test the model's performance with degraded external knowledge sources, missing information, or noisy knowledge embeddings. The impact of external knowledge quality on real-time performance is also unexplored.
- What evidence would resolve it: Experiments evaluating the model with progressively degraded external knowledge sources (noisy links, incomplete Wikipedia pages, alternative knowledge bases) while measuring both performance and latency would quantify robustness.

### Open Question 3
- Question: Can the Knowledge-Augmented Phrase Retrieval approach be extended to handle multimodal queries (text + images) for in-document search?
- Basis in paper: [inferred] The paper mentions KTRL+F has potential for extensions including "in-document search with multi-modal inputs (image and text queries)" in the conclusion section.
- Why unresolved: The paper doesn't explore how the phrase retrieval architecture could incorporate visual information or how external knowledge might need to be adapted for multimodal understanding.
- What evidence would resolve it: A proof-of-concept implementation showing how image embeddings could be integrated with text embeddings in the phrase retrieval framework, along with performance evaluation on a multimodal dataset, would demonstrate feasibility.

## Limitations

- Modest performance with List EM score of 23.15%, correctly identifying all semantic targets in only about 1 in 5 queries
- Evaluation based on a relatively small dataset of 512 queries across 98 documents, limiting generalizability
- Heavy reliance on entity linking quality, with significant performance drops when using lower-quality entity linkers
- Frozen DensePhrases model provides speed advantages but may limit learning task-specific representations

## Confidence

**High Confidence**: The claim that knowledge augmentation improves performance over purely internal representations receives strong support from the ablation study (Table 4 shows clear performance drops when removing external knowledge). The latency measurements (15 ms per query) are directly measured and the comparison with generative baselines is methodologically sound.

**Medium Confidence**: The claim that the element-wise addition approach provides an optimal balance between speed and performance has moderate support. While the ablation study shows it works better than pure internal or external approaches, the paper doesn't explore alternative knowledge integration methods (such as concatenation, gating mechanisms, or learned fusion) that might provide better performance-latency tradeoffs.

**Low Confidence**: The generalizability of results to domains beyond news articles is uncertain given the dataset composition and the reliance on Wikipedia as an external knowledge source. The paper doesn't validate performance on domains where Wikipedia coverage may be sparse or where entity linking may be more challenging.

## Next Checks

1. **Cross-dataset validation**: Evaluate the model on a diverse set of document types (scientific papers, legal documents, technical manuals) to assess generalizability beyond news articles. This would validate whether the performance gains hold across different domains with varying entity densities and external knowledge availability.

2. **Alternative knowledge integration methods**: Implement and compare at least two alternative methods for combining knowledge embeddings with phrase embeddings (such as concatenation followed by learned projection, or attention-based fusion). This would test whether the simple element-wise addition is truly optimal or merely sufficient.

3. **Error analysis of entity linking failures**: Conduct a systematic analysis of queries where the model fails due to entity linking errors versus those where the knowledge integration itself fails. This would quantify how much of the performance limitation stems from upstream entity linking versus the knowledge augmentation approach itself.