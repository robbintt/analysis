---
ver: rpa2
title: 'Two is Better Than One: Answering Complex Questions by Multiple Knowledge
  Sources with Generalized Links'
arxiv_id: '2309.05201'
source_url: https://arxiv.org/abs/2309.05201
tags:
- links
- link
- question
- multi-kb-qa
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of answering complex factoid questions
  using multiple knowledge bases, specifically focusing on handling generalized links
  between KBs. Previous methods only handle full links (identical entities), but this
  work considers partial links (entities expressing different aspects of an abstract
  concept).
---

# Two is Better Than One: Answering Complex Questions by Multiple Knowledge Sources with Generalized Links

## Quick Facts
- arXiv ID: 2309.05201
- Source URL: https://arxiv.org/abs/2309.05201
- Reference count: 23
- Primary result: Achieves MRR of 0.488 on test set vs 0.350 for best baseline

## Executive Summary
This paper addresses the challenge of answering complex factoid questions using multiple knowledge bases with generalized links. Traditional KB-QA systems only handle full links (identical entities), but this work extends to partial links where entities represent different aspects of abstract concepts. The authors propose a new Multi-KB-QA task and create a benchmark dataset with diversified link and query types. Their method encodes link relations in KB embeddings using a translator module, achieving significant performance improvements over conventional approaches.

## Method Summary
The approach trains a translator module to encode both full and partial links between knowledge bases into embedding space, then uses these embeddings to score and rank candidate answers. Rather than merging KBs via entity alignment, each KB maintains separate embeddings while the translator bridges link relationships. This architecture preserves individual KB semantics while enabling cross-KB reasoning. The pluggable training design allows adding new KBs by training only their embeddings and link relationships while keeping existing KB embeddings fixed.

## Key Results
- MRR of 0.488 on test set compared to 0.350 for best baseline
- Outperforms conventional KB-QA systems significantly on Multi-KB-QA task
- Pluggable training achieves competitive results with 90% less re-training cost

## Why This Works (Mechanism)

### Mechanism 1
Encoding generalized links in KB embeddings enables better multi-KB question answering performance. The translator module bridges semantic space differences between KBs by encoding both full and partial links into continuous vector space. This allows the QA model to leverage relationship information during answer scoring. Break condition: If semantic space differences are too large for effective bridging.

### Mechanism 2
Separating KB embeddings while encoding links preserves individual KB semantics better than fusion. Each KB maintains its own embedding space with a translator module connecting link relationships, avoiding information loss from forced unification. Break condition: When KB semantics are highly overlapping and maintenance overhead outweighs benefits.

### Mechanism 3
The pluggable training architecture reduces computational cost when adding new KBs. New KBs can be added by training only their embeddings and link relationships while keeping existing KB embeddings fixed. Break condition: If KB embedding spaces drift significantly over time or new KBs have fundamentally different characteristics.

## Foundational Learning

- **Knowledge Base Question Answering (KBQA)**: The paper extends standard KBQA to handle multiple knowledge bases with generalized links. Quick check: What is the difference between entity alignment and the generalized links approach used in this paper?

- **Knowledge Graph Embeddings**: The method relies on encoding KB relationships in continuous vector space for downstream QA tasks. Quick check: How does the ComplEx scoring function work for knowledge graph triple evaluation?

- **Partial vs Full Links**: Understanding the distinction between these link types is critical to grasping why traditional entity alignment approaches fail. Quick check: Can you provide an example where two entities should be treated as identical in a question despite having different semantic meanings?

## Architecture Onboarding

- **Component map**: RoBERTa encoder → FCN for question encoding → KB embeddings with translator module → answer scoring and ranking
- **Critical path**: Question → Entity linking → Graph traversal → Answer selection
- **Design tradeoffs**: Separate KB embeddings preserve semantics but increase computational complexity vs. fusion approach with simpler architecture but potential information loss
- **Failure signatures**: Poor performance on partial link questions, high variance across KB combinations, degraded performance when adding new KBs
- **First 3 experiments**:
  1. Compare MRR on partial link questions vs baseline methods
  2. Ablation study removing translator module to measure its contribution
  3. Test pluggable training by adding a third KB and measuring performance vs full retraining

## Open Questions the Paper Calls Out

### Open Question 1
How does the pluggability of Multi-KB-QA affect performance when adding KBs with significantly different semantic structures or domains? The experiments only test pluggability between two related financial KBs, so it's unclear how the approach would perform with KBs from completely different domains.

### Open Question 2
What is the upper bound performance limit for Multi-KB-QA systems given the current formulation of generalized links? The paper only presents one baseline method and shows it outperforms conventional approaches, but doesn't establish what the theoretical maximum performance could be.

### Open Question 3
How does the quality and diversity of discovered generalized links affect Multi-KB-QA performance? The paper doesn't analyze how link quality or the completeness of link discovery affects final QA performance, only providing one link discovery method without exploring alternatives.

## Limitations
- Evaluation limited to single financial domain dataset, raising questions about generalizability
- No concrete runtime measurements or comparisons to validate computational efficiency claims
- Lacks detailed error analysis to understand when partial links help versus introduce noise

## Confidence
- **High**: The mathematical formulation of the ComplEx scoring function and overall architecture design
- **Medium**: The effectiveness of the translator module for generalized link encoding
- **Low**: Claims about computational efficiency and scalability to many KBs

## Next Checks
1. Apply the method to at least two additional domains (e.g., biomedical and general knowledge) to verify performance gains are not domain-specific
2. Measure actual training and inference times for the pluggable approach versus full retraining when adding 2-3 new KBs
3. Conduct detailed qualitative analysis of cases where the method succeeds or fails on partial link questions