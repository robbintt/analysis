---
ver: rpa2
title: 'STEM: Unleashing the Power of Embeddings for Multi-task Recommendation'
arxiv_id: '2308.13537'
source_url: https://arxiv.org/abs/2308.13537
tags:
- task
- task-specific
- tasks
- stem-net
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates negative transfer in multi-task learning
  (MTL) for recommendation systems, where model performance degrades due to conflicting
  user preferences across tasks. Through analysis of samples with varying feedback
  distributions, the authors identify that negative transfer occurs when tasks receive
  comparable positive feedback.
---

# STEM: Unleashing the Power of Embeddings for Multi-task Recommendation

## Quick Facts
- **arXiv ID**: 2308.13537
- **Source URL**: https://arxiv.org/abs/2308.13537
- **Authors**: [Authors not specified in source]
- **Reference count**: 12
- **Primary result**: STEM-Net achieves 0.004-0.005 AUC improvement and 4.2-7.1% GMV lift over state-of-the-art MTL methods

## Executive Summary
This paper addresses negative transfer in multi-task learning for recommendation systems, where model performance degrades when tasks have conflicting user preferences. Through analysis of samples with varying feedback distributions, the authors identify that negative transfer occurs specifically when tasks receive comparable positive feedback. To solve this, they propose STEM (Shared and Task-specific Embeddings), a novel MTL paradigm incorporating both shared and task-specific embeddings. Their STEM-Net model implements this paradigm with a customized gating mechanism using stop-gradient operations to prevent interference between task-specific embeddings. Experimental results on three public datasets and industrial deployment demonstrate significant improvements over state-of-the-art methods.

## Method Summary
STEM-Net introduces a novel multi-task learning paradigm that uses both shared and task-specific embeddings to capture task-specific user preferences while preventing negative transfer. The model employs a customized gating mechanism where each task's gate network receives inputs from shared experts and all task-specific experts, but uses stop-gradient operations to prevent updates to other tasks' embeddings. This allows each task to learn its own user preference patterns while still benefiting from shared representations. The architecture includes separate embedding tables for shared and task-specific embeddings, MLP-based experts, and independent task towers, trained with binary cross-entropy loss using the Adam optimizer.

## Key Results
- STEM-Net achieves 0.004-0.005 AUC improvement over state-of-the-art MTL methods (MMoE, PLE)
- Industrial A/B tests show 4.2-7.1% GMV lift compared to baseline models
- STEM-Net demonstrates exceptional performance on comparable samples, surpassing single-task models
- The model effectively mitigates negative transfer while maintaining positive transfer between tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: STEM-Net prevents negative transfer by using task-specific embeddings with stop-gradient operations during gating
- Mechanism: Task-specific embeddings are exclusively updated by their corresponding task's gradients, while the gating mechanism allows each task tower to access both shared and all task-specific experts without backpropagating gradients to other tasks' embeddings
- Core assumption: Different tasks have diverse and sometimes conflicting user preferences that require distinct embeddings to model effectively
- Evidence anchors:
  - [abstract]: "STEM aims to incorporate both shared and task-specific embeddings to effectively capture task-specific user preferences"
  - [section]: "To ensure the learning of task-specific embeddings, the gating function deployed for each task tower employs a stop-gradient operation on the experts from other tasks"
  - [corpus]: Weak evidence - related works focus on representation-level saliency but don't explicitly mention stop-gradient operations for embedding isolation
- Break condition: If tasks actually share similar user preferences, the task-specific embeddings become redundant and may hurt performance

### Mechanism 2
- Claim: STEM-Net improves performance on comparable samples by learning task-specific preferences while maintaining knowledge transfer through shared embeddings
- Mechanism: The architecture allows each task to learn its own user preference patterns while still benefiting from shared representations that capture common patterns across tasks
- Core assumption: Samples with comparable positive feedback across tasks exhibit the most conflicting user preferences
- Evidence anchors:
  - [section]: "Our results demonstrate that STEM-Net consistently outperforms both MMoE and PLE on the Finish and Like-Overwhelming samples. Moreover, STEM-Net exhibits remarkable performance in the comparable zone, surpassing the Single-Task Like model"
  - [abstract]: "STEM-Net demonstrates exceptional performance on comparable samples, surpassing the Single-Task Like model and achieves positive transfer"
  - [corpus]: No direct evidence in corpus - related works focus on gradient conflicts but not sample-specific analysis
- Break condition: If sample splitting methodology doesn't accurately capture task preference conflicts, the model may optimize for the wrong scenarios

### Mechanism 3
- Claim: The customized gating mechanism enables effective knowledge transfer while preserving task specificity
- Mechanism: Each task's gate network receives inputs from shared experts and all task-specific experts, but uses stop-gradient to prevent updates to other tasks' embeddings
- Core assumption: Direct knowledge transfer between tasks is beneficial but requires preventing interference with task-specific learning
- Evidence anchors:
  - [section]: "STEM-Net employs a customized gating mechanism, which enables each task tower to receive input from both shared experts and all task-specific experts. To ensure the learning of task-specific embeddings, the gating function deployed for each task tower employs a stop-gradient operation on the experts from other tasks"
  - [abstract]: "STEM-Net is equipped with shared and task-specific embedding tables, along with a customized gating network with stop-gradient operations to facilitate the learning of these embeddings"
  - [corpus]: Weak evidence - related works discuss gating mechanisms but don't implement stop-gradient operations specifically
- Break condition: If the gating mechanism becomes too restrictive, it may prevent beneficial knowledge transfer between tasks

## Foundational Learning

- Concept: Multi-task learning negative transfer
  - Why needed here: The paper identifies negative transfer as the core problem being solved, where learning multiple tasks together degrades performance on certain tasks
  - Quick check question: What happens when two tasks have conflicting user preferences in multi-task learning?

- Concept: Sample-based analysis in MTL
  - Why needed here: The authors split samples based on relative positive feedback to identify where negative transfer occurs, revealing it happens specifically on comparable samples
  - Quick check question: How does splitting samples by relative feedback help identify negative transfer patterns?

- Concept: Embedding-level task specificity
  - Why needed here: STEM-Net introduces task-specific embeddings at the embedding layer rather than just at higher levels like gates or towers
  - Quick check question: What's the difference between embedding-level and tower-level task specificity in MTL models?

## Architecture Onboarding

- Component map:
  Input features → Shared and Task-specific Embedding Layer (Lookup operations)
  Embeddings → Shared & Task-Specific Experts (MLP-based experts)
  Experts → Customized Gating Mechanism (softmax-weighted combination with stop-gradient)
  Gating output → Task Towers (independent MLPs per task)
  Task outputs → Loss functions (binary cross-entropy)

- Critical path: Input features → Embeddings → Experts → Gating → Towers → Predictions

- Design tradeoffs:
  More parameters due to task-specific embeddings vs. better task isolation
  Stop-gradient operations prevent interference but may limit knowledge transfer
  Separate embedding tables increase memory usage but enable task-specific learning

- Failure signatures:
  Performance degradation on tasks with similar preferences
  Overfitting on tasks with limited positive samples
  Increased memory usage without corresponding performance gains

- First 3 experiments:
  1. Compare STEM-Net performance on comparable vs. overwhelming samples to validate the negative transfer hypothesis
  2. Test STEM-Net variants with different feature field selections to identify which fields benefit most from task-specific embeddings
  3. Evaluate parameter scaling effects to ensure performance gains aren't solely due to increased model capacity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can negative transfer be mitigated when tasks have significantly different numbers of positive samples?
- Basis in paper: [explicit] The paper mentions that the Like task has significantly fewer positive samples compared to the Finish task, making it susceptible to being dominated in MTL settings.
- Why unresolved: The paper focuses on addressing negative transfer in the "comparable feedback" zone, but doesn't explicitly explore strategies for handling tasks with vastly different sample sizes or positive sample ratios.
- What evidence would resolve it: Experiments comparing different weighting schemes, sample re-balancing techniques, or architectural modifications specifically designed to protect minority tasks in MTL settings.

### Open Question 2
- Question: What is the optimal strategy for selecting which feature fields should have task-specific embeddings?
- Basis in paper: [explicit] The paper investigates this by evaluating STEM-Net variants with different combinations of task-specific feature fields, finding that user-side features are more effective than item features for capturing diverse user preferences.
- Why unresolved: While the paper provides some guidance, it doesn't establish a comprehensive framework or methodology for determining which features should be task-specific across different recommendation scenarios.
- What evidence would resolve it: A systematic study across multiple datasets and recommendation tasks establishing clear guidelines or decision rules for feature-specific embedding allocation.

### Open Question 3
- Question: How does the STEM paradigm perform when scaled to scenarios with many tasks (e.g., 10+ tasks)?
- Basis in paper: [inferred] The paper evaluates STEM-Net on datasets with 2-8 tasks, but doesn't explore extreme multi-task scenarios that are common in real-world recommendation systems.
- Why unresolved: The computational complexity and potential interference between many task-specific embeddings remains unexplored, as does the scalability of the gating mechanism.
- What evidence would resolve it: Performance evaluation and ablation studies on large-scale multi-task recommendation scenarios, including analysis of computational overhead and negative transfer effects as task count increases.

## Limitations

- Theoretical framework for why stop-gradient operations effectively prevent negative transfer while maintaining positive transfer remains underdeveloped
- Sample splitting methodology for identifying comparable samples relies on relative feedback distributions, but robustness across different recommendation scenarios isn't thoroughly validated
- Computational complexity and scalability to scenarios with many tasks (10+ tasks) remains unexplored

## Confidence

- **High Confidence**: The empirical results showing STEM-Net's superior performance on public datasets (TikTok, QK-Video, KuaiRand1K) and industrial deployment metrics (4.2-7.1% GMV lift)
- **Medium Confidence**: The mechanism by which stop-gradient operations prevent negative transfer while enabling positive transfer, though implementation details are clear
- **Medium Confidence**: The claim that comparable samples exhibit the most conflicting user preferences, based on the sample analysis methodology

## Next Checks

1. Implement ablation studies removing the stop-gradient operations to quantify their specific contribution to preventing negative transfer
2. Test STEM-Net's performance on datasets with varying task correlation patterns to assess generalizability beyond the studied scenarios
3. Compare STEM-Net against single-task models trained on combined data to determine if performance gains stem from task-specific learning versus increased model capacity