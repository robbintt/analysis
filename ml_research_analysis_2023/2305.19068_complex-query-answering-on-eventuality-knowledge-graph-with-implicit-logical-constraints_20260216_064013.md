---
ver: rpa2
title: Complex Query Answering on Eventuality Knowledge Graph with Implicit Logical
  Constraints
arxiv_id: '2305.19068'
source_url: https://arxiv.org/abs/2305.19068
tags:
- query
- constraints
- personx
- knowledge
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Complex Eventuality Query Answering (CEQA),
  a framework for answering logical queries on eventuality-centric knowledge graphs
  (EVKGs) that considers implicit constraints on eventuality occurrence and temporal
  order. The authors propose a Memory-Enhanced Query Encoding (MEQE) method that separates
  logical query terms into computational atomics (with variables) and informational
  atomics (without variables).
---

# Complex Query Answering on Eventuality Knowledge Graph with Implicit Logical Constraints

## Quick Facts
- arXiv ID: 2305.19068
- Source URL: https://arxiv.org/abs/2305.19068
- Reference count: 40
- Key outcome: Memory-Enhanced Query Encoding (MEQE) improves state-of-the-art neural query encoders on complex eventuality query answering by up to 17.53% in Hit@1 and 13.85% on temporal constraints.

## Executive Summary
This paper addresses the challenge of answering complex queries on eventuality-centric knowledge graphs (EVKGs) that involve implicit logical constraints on eventuality occurrence and temporal order. The authors propose MEQE, a framework that separates logical query terms into computational atomics (with variables) and informational atomics (without variables). By storing informational atomics in a key-value memory module, MEQE can incorporate implicit constraints during query encoding, significantly improving the performance of existing neural query encoders on complex eventuality query answering tasks.

## Method Summary
The authors propose MEQE to handle complex eventuality queries by separating computational atomics (processed through a computational graph) from informational atomics (stored in a key-value memory module). The framework uses theorem provers to construct benchmark datasets ensuring answers satisfy implicit constraints. MEQE is evaluated on the ASER dataset using four baseline query encoders (GQE, Q2P, Neural MLP, FuzzQE) with standard metrics (Hit@1, Hit@3, MRR) for both occurrence and temporal constraints.

## Key Results
- MEQE consistently improves performance of four neural query encoders on CEQA tasks
- Up to 17.53% improvement in Hit@1 accuracy
- 13.85% improvement on temporal constraint queries
- 11.15% improvement on occurrence constraint queries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MEQE separates logical query terms into computational and informational atomics, allowing the model to leverage implicit constraints from the latter.
- Mechanism: Computational atomics are processed through a computational graph to recursively compute query embeddings. Informational atomics are stored in a key-value memory module where head arguments are keys and relation types/tail arguments are values. During query encoding, the query embedding is matched against memory keys to retrieve relevant constraint values, which are aggregated and added back to the query embedding.
- Core assumption: Implicit logical constraints from informational atomics are essential for accurate reasoning on EVKGs and can be effectively encoded in a memory module.
- Evidence anchors:
  - [abstract] "We also propose a Memory-Enhanced Query Encoding (MEQE) approach to significantly improve the performance of state-of-the-art neural query encoders on the CEQA task."
  - [section 3.2] "For the computational atomics, following previous work, we construct the corresponding computational graph to recursively compute its query embedding step-by-step. For the informational atomics, we put them into a key-value memory module."

### Mechanism 2
- Claim: MEQE improves performance by incorporating implicit constraints from informational atomics.
- Mechanism: By encoding implicit constraints in the memory module, MEQE can differentiate and leverage these constraints during query encoding, filtering out contradictory answers.
- Core assumption: Implicit constraints from informational atomics significantly impact answer correctness in complex eventuality query answering.
- Evidence anchors:
  - [abstract] "Experiment results show that our proposed MEQE is able to consistently improve the performance of four frequently used neural query encoders on the task of CEQA."
  - [section 4.4] "By reading this memory module, MEQE effectively incorporates implicit constraints from these atomics, leading to improved performance."

### Mechanism 3
- Claim: MEQE is particularly effective in handling temporal constraints compared to occurrence constraints.
- Mechanism: The memory module stores temporal information from informational atomics, allowing accurate capture of temporal order to filter out answers violating temporal constraints.
- Core assumption: Temporal constraints are more challenging than occurrence constraints in complex eventuality query answering.
- Evidence anchors:
  - [section 4.4] "MEQE demonstrates a 13.85% improvement in performance on queries with temporal constraints and an 11.15% improvement on occurrence constraints."

## Foundational Learning

- Concept: Conjunctive queries and set operations (relational projection, intersection)
  - Why needed here: Query encoding methods represent complex queries as conjunctive logical expressions and perform set operations on intermediate results.
  - Quick check question: How does the relational projection operation differ from the intersection operation in query encoding?

- Concept: Discourse relations and their implicit logical constraints
  - Why needed here: Complex eventuality query answering involves reasoning over EVKGs using discourse relations that impose implicit logical constraints on eventuality occurrence and temporal order.
  - Quick check question: What is the difference between occurrence constraints and temporal constraints in discourse relations?

- Concept: Neural network architectures for query encoding (GQE, Q2P, Neural MLP, FuzzQE)
  - Why needed here: The paper evaluates MEQE's performance on top of existing query encoding architectures to demonstrate effectiveness.
  - Quick check question: How do different query encoding architectures differ in their approach to encoding complex queries?

## Architecture Onboarding

- Component map: Query -> Computational Graph + Memory Module -> Query Embedding -> Answer
- Critical path:
  1. Parse query into computational and informational atomics
  2. Construct computational graph for computational atomics
  3. Initialize query embedding with anchor entity embeddings
  4. Recursively compute query embedding using computational graph
  5. Match query embedding against memory keys to retrieve constraint values
  6. Aggregate and add constraint values to query embedding
  7. Compute similarity between final query embedding and entity embeddings to obtain answer

- Design tradeoffs:
  - Separating computational and informational atomics allows efficient processing but requires careful memory module design for accurate constraint retrieval
  - Using key-value memory module is simple but may not capture complex relationships between constraints

- Failure signatures:
  - Poor performance on queries with implicit constraints: Memory module fails to retrieve relevant constraints or computational graph cannot effectively process computational atomics
  - Overfitting to training data: Model fails to generalize to unseen queries or memory module memorizes specific constraint patterns instead of learning to reason

- First 3 experiments:
  1. Evaluate MEQE on small subset of queries with known implicit constraints to verify accurate constraint incorporation
  2. Compare MEQE performance with different query encoding architectures to identify which benefits most from memory-enhanced encoding
  3. Analyze memory module behavior on queries with varying numbers of informational atomics to understand scaling with constraint complexity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MEQE performance compare to other state-of-the-art neural query encoders on EVKGs with implicit logical constraints?
- Basis in paper: [explicit] MEQE consistently improves performance of state-of-the-art neural query encoders on CEQA tasks with up to 17.53% improvement in Hit@1.
- Why unresolved: Paper provides specific improvements but doesn't compare MEQE to other models on EVKGs with implicit logical constraints.
- What evidence would resolve it: Comparative results of MEQE against other models on EVKGs with implicit logical constraints.

### Open Question 2
- Question: Can MEQE be applied to EVKGs in specific or professional fields?
- Basis in paper: [inferred] Evaluation conducted on ASER dataset, but generalizability to specific or professional fields may require further investigation.
- Why unresolved: No evidence or experiments demonstrating MEQE effectiveness on EVKGs in specific or professional fields.
- What evidence would resolve it: Experiments or case studies demonstrating MEQE application to EVKGs in specific or professional fields.

### Open Question 3
- Question: How does MEQE handle adversarial attacks and data poisoning on knowledge graph reasoning systems?
- Basis in paper: [inferred] Proposed reasoning method is subject to adversarial attacks and data poisoning on knowledge graph reasoning systems.
- Why unresolved: No discussion or mitigation strategies for handling adversarial attacks and data poisoning.
- What evidence would resolve it: Analysis of MEQE vulnerabilities to adversarial attacks and data poisoning with proposed mitigation strategies.

## Limitations
- Performance improvements may be dataset-specific to ASER-50K, which is relatively small
- Framework may not generalize well to more complex query structures beyond depth 2
- Memory module effectiveness depends on informational atomics containing sufficient constraint information

## Confidence

- **High Confidence**: General framework of separating computational and informational atomics and using memory module for implicit constraints. Experimental methodology and dataset preparation are clearly specified.
- **Medium Confidence**: Specific performance improvements (17.53% Hit@1, 13.85% temporal constraints) are likely valid for ASER-50K but may not generalize to larger knowledge graphs.
- **Low Confidence**: Claim that MEQE is "particularly effective in handling temporal constraints compared to occurrence constraints" needs further validation on datasets with more complex temporal relationships.

## Next Checks

1. Test MEQE on larger eventuality knowledge graph (e.g., ASER-1M) to verify if performance improvements scale with dataset size and complexity.
2. Conduct ablation studies to quantify exact contribution of memory module versus improvements from better query encoding alone.
3. Evaluate MEQE on queries with depth >2 to assess whether framework can handle more complex logical structures beyond current experimental scope.