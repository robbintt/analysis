---
ver: rpa2
title: 'Experts-in-the-Loop: Establishing an Effective Workflow in Crafting Privacy
  Q&A'
arxiv_id: '2311.11161'
source_url: https://arxiv.org/abs/2311.11161
tags:
- privacy
- data
- user
- questions
- legal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a workflow for constructing privacy question-and-answer
  (Q&A) pairs for conversational AI systems. The workflow emphasizes continuous improvement
  and monitoring, and involves interdisciplinary collaboration between legal experts
  and conversation designers.
---

# Experts-in-the-Loop: Establishing an Effective Workflow in Crafting Privacy Q&A

## Quick Facts
- **arXiv ID**: 2311.11161
- **Source URL**: https://arxiv.org/abs/2311.11161
- **Reference count**: 40
- **Key outcome**: A workflow for constructing privacy Q&A pairs using interdisciplinary collaboration between legal experts and conversation designers, ensuring both legal correctness and usability.

## Executive Summary
This paper presents a workflow for constructing privacy question-and-answer (Q&A) pairs for conversational AI systems. The approach emphasizes continuous improvement and monitoring, involving legal experts and conversation designers to validate and refine answers. The workflow addresses the challenge of making privacy policies easily accessible and understandable in conversational AI systems by ensuring both legal correctness and usability through iterative review and user feedback.

## Method Summary
The method involves gathering a comprehensive catalogue of privacy questions, constructing answers based on privacy policies, and having legal experts and conversation designers check and refine the answers. Usability testing with end-users is incorporated to evaluate the effectiveness of the privacy Q&A. The workflow emphasizes continuous improvement and monitoring throughout the construction process, ensuring that privacy Q&A pairs are both legally compliant and user-friendly.

## Key Results
- The workflow ensures legal correctness by involving legal experts in validating NLP-generated answers.
- Conversation designers improve usability by ensuring answers follow conversational design principles.
- Iterative user feedback loops enhance both legal accuracy and usability over time.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The workflow ensures legal correctness by involving legal experts in validating NLP-generated answers.
- Mechanism: Legal experts review and validate answers for lawfulness, accuracy, and compliance with data protection regulations, mitigating risks of automated generation.
- Core assumption: Legal experts have sufficient expertise to assess both the legal correctness and the clarity of the generated answers.
- Evidence anchors:
  - [abstract] "advocating for comprehensive review and refinement through an experts-in-the-loop approach"
  - [section 2.3] "legal experts play a crucial role in validating the answers by assessing their lawfulness, accuracy, and compliance with data protection regulations"
  - [corpus] Weak; no direct corpus evidence linking legal review to accuracy outcomes
- Break condition: If legal experts are not available or if the legal review process is too slow for iterative refinement.

### Mechanism 2
- Claim: Conversation designers improve usability by ensuring answers follow conversational design principles.
- Mechanism: Conversation designers identify violations of design principles (e.g., minimization, clarity) and refine answers to be user-friendly and comprehensible.
- Core assumption: Conversation designers can consistently identify and fix design violations in privacy answers.
- Evidence anchors:
  - [section 2.3] "we emphasize the role of conversation designers in the proposed workflow to identify violations of design principals [24] and ensure clarity, simplicity, and comprehensibility"
  - [abstract] "advocating for comprehensive review and refinement through an experts-in-the-loop approach"
  - [corpus] Weak; no corpus evidence of usability improvements from designer input
- Break condition: If conversation designers lack training in privacy-specific content or if their feedback is inconsistent.

### Mechanism 3
- Claim: Iterative user feedback loops enhance both legal accuracy and usability over time.
- Mechanism: Usability testing with end-users uncovers real-world comprehension issues, triggering revisions that refine both question sets and answers.
- Core assumption: Users can accurately report misunderstandings or usability barriers.
- Evidence anchors:
  - [section 2.4] "Usability testing is crucial to evaluate privacy Q&A in real-world scenarios and uncover issues not caught by human experts"
  - [abstract] "underscores continuous improvement and monitoring throughout the construction of privacy Q&As"
  - [corpus] Weak; no corpus evidence linking user feedback to improved outcomes
- Break condition: If user feedback is too sparse or if feedback collection is too costly relative to improvements.

## Foundational Learning

- Concept: Semantic Textual Similarity (STS) for question clustering
  - Why needed here: To group semantically similar privacy questions, reducing the number of unique answers that need expert review
  - Quick check question: Can Sentence-BERT reliably distinguish between questions about "data retention" and "user deletion rights"?
- Concept: Prompt engineering for LLMs in legal/privacy contexts
  - Why needed here: To guide LLM outputs toward legally accurate, concise, and user-friendly responses
  - Quick check question: Does adding "avoid legal jargon" to the prompt consistently improve readability without sacrificing legal precision?
- Concept: Privacy policy structure and terminology
  - Why needed here: To extract and translate policy text into plain-language answers
  - Quick check question: Can you identify the difference between "data collection" and "data sharing" clauses in a sample privacy policy?

## Architecture Onboarding

- Component map: Privacy question catalogue -> NLP-based answer extraction -> Legal expert validation -> Conversation designer refinement -> Usability testing -> Feedback loop
- Critical path: Question catalogue -> Answer construction -> Legal review -> Usability testing -> Release
- Design tradeoffs:
  - Speed vs. accuracy: Faster iterations may skip expert review, risking non-compliance
  - Coverage vs. manageability: More questions improve coverage but increase expert workload
  - Automation vs. control: LLMs speed generation but require strict validation
- Failure signatures:
  - Legal errors: Users report misleading or incorrect privacy information
  - Usability failures: High abandonment rates during usability testing
  - Scalability issues: Bottlenecks in expert review as question volume grows
- First 3 experiments:
  1. Pilot with 20 privacy questions: Compare LLM-generated answers vs. human-written answers for accuracy and usability
  2. Legal expert review simulation: Time and accuracy of validating 50 LLM-generated answers
  3. Usability test with 10 users: Measure comprehension and task success rates for 5 sample Q&As

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can legal experts effectively review and validate privacy answers generated by LLMs to ensure legal correctness and compliance with data protection regulations?
- Basis in paper: [explicit]
- Why unresolved: The paper mentions the role of legal experts in validating generated answers, but does not provide specific guidance on how this review process should be conducted or what criteria should be used to assess legal correctness.
- What evidence would resolve it: A detailed methodology for legal expert review of LLM-generated privacy answers, including specific criteria, best practices, and case studies demonstrating the effectiveness of this approach.

### Open Question 2
- Question: How can conversation designers ensure that privacy answers generated by LLMs follow best practices of conversation design, such as minimization and clarity, while still providing comprehensive information?
- Basis in paper: [explicit]
- Why unresolved: The paper highlights the importance of conversation designers in crafting user-friendly privacy answers, but does not provide specific guidance on how to balance the need for comprehensive information with the principles of conversation design.
- What evidence would resolve it: A set of guidelines or best practices for conversation designers to follow when reviewing and refining LLM-generated privacy answers, including examples of well-designed and poorly designed responses.

### Open Question 3
- Question: How can user feedback be effectively integrated into the iterative process of improving privacy Q&A, and what metrics should be used to evaluate the success of these improvements?
- Basis in paper: [explicit]
- Why unresolved: The paper mentions the importance of incorporating user feedback, but does not provide specific guidance on how to collect, analyze, and act upon this feedback, or what metrics should be used to measure the effectiveness of the improvements.
- What evidence would resolve it: A framework for collecting and analyzing user feedback on privacy Q&A, including specific metrics for evaluating the success of improvements, and case studies demonstrating the impact of user feedback on the quality of privacy answers.

## Limitations
- The workflow relies heavily on expert availability and consistent judgment quality, which are difficult to scale.
- The absence of empirical validation data from the corpus limits confidence in the claimed effectiveness of each mechanism.
- The iterative feedback loop depends on user participation, which may be costly or sparse in practice.

## Confidence

- **High**: The need for interdisciplinary collaboration and the general workflow structure are well-supported by the literature and practice.
- **Medium**: The proposed roles of legal experts and conversation designers are clearly defined, but the effectiveness of their review is not empirically validated in the paper.
- **Low**: Claims about continuous improvement through user feedback lack supporting evidence or quantitative metrics.

## Next Checks

1. Conduct a pilot test with 20 privacy questions comparing LLM-generated answers against human-written answers for accuracy and usability.
2. Simulate legal expert review by having two independent experts validate 50 LLM-generated answers for legal correctness and clarity.
3. Run a usability test with 10 end-users to measure comprehension and task success rates for 5 sample Q&A pairs.