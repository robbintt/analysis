---
ver: rpa2
title: Large Language Models as Source Planner for Personalized Knowledge-grounded
  Dialogue
arxiv_id: '2310.08840'
source_url: https://arxiv.org/abs/2310.08840
tags:
- knowledge
- persona
- sources
- dialogue
- planning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a framework that utilizes LLMs to plan the
  use of multiple knowledge sources for personalized knowledge-grounded dialogue.
  The framework, named SAFARI, consists of three steps: planning, retrieval, and assembling.'
---

# Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogue

## Quick Facts
- arXiv ID: 2310.08840
- Source URL: https://arxiv.org/abs/2310.08840
- Reference count: 24
- One-line primary result: SAFARI framework improves persona consistency by 12.5% and knowledge consistency by 8.3% in personalized knowledge-grounded dialogue

## Executive Summary
This paper introduces SAFARI, a novel framework that leverages large language models (LLMs) for planning the use of multiple knowledge sources in personalized knowledge-grounded dialogue. The framework decouples the process into three steps: planning, retrieval, and assembling. By treating knowledge sources as special tokens, SAFARI enables LLMs to plan which sources to use and in what order. Experimental results on a constructed dataset demonstrate that SAFARI can effectively produce persona-consistent and knowledge-enhanced responses, outperforming baseline approaches in both supervised and unsupervised settings.

## Method Summary
SAFARI is a three-step framework that uses LLMs as source planners for personalized knowledge-grounded dialogue. It consists of a planning step that decides which knowledge sources to use and their order, a retrieval step that fetches relevant knowledge from external databases, and an assembling step that incorporates all retrieved knowledge into the final response generation. The framework leverages LLMs' planning capabilities by representing knowledge sources as special tokens in the vocabulary, allowing the model to learn when and how to call each source. SAFARI is evaluated on a constructed dataset (KBP) with persona descriptions and related documents, showing improvements in persona consistency and knowledge consistency compared to baseline approaches.

## Key Results
- SAFARI improves persona consistency (P.C) by 12.5% in supervised learning compared to baseline models
- In unsupervised learning, SAFARI achieves an 8.3% improvement in knowledge consistency (K.C) over baseline approaches
- The framework shows consistent performance improvements across different numbers of retrieved results (1-3), with DPR retriever performing best

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decoupling planning, retrieval, and assembling steps allows independent optimization of each component.
- Mechanism: By separating the decision-making process (planning) from knowledge selection (retrieval) and response generation (assembling), the framework can optimize each step separately, reducing interference between components.
- Core assumption: The planning step can accurately predict which knowledge sources are needed without seeing the retrieved knowledge.
- Evidence anchors:
  - [abstract]: "SAFARI decouples the knowledge grounding into multiple sources and response generation, which allows easy extension to various knowledge sources including the possibility of not using any sources."
  - [section]: "Benefiting from decoupling source selection and response generation, our framework is more flexible and scalable, allowing independent modification of each component."
- Break condition: If the planning step becomes highly inaccurate, it could lead to retrieving irrelevant knowledge, degrading response quality.

### Mechanism 2
- Claim: LLMs can plan the use of multiple knowledge sources by treating them as special tokens.
- Mechanism: The framework leverages LLMs' ability to understand context and plan by representing knowledge sources as special tokens in the vocabulary, allowing the model to learn when and how to call each source.
- Core assumption: LLMs can effectively learn the dependency relationships between knowledge sources through the special token representation.
- Evidence anchors:
  - [abstract]: "We propose SAFARI, a novel framework that leverages the exceptional capabilities of large language models (LLMs) in planning, understanding, and incorporating under both supervised and unsupervised settings."
  - [section]: "We add Ki, ..., Kn and NULL into the vocabulary of LLMs as special tokens. The key idea here is similar to the recent ToolkenGPT (Hao et al., 2023), which regards different tools as special tokens in the vocabulary."
- Break condition: If the LLM fails to understand the dependency relationships, it may generate incorrect planning sequences, leading to irrelevant knowledge retrieval.

### Mechanism 3
- Claim: The framework can handle cases where no knowledge sources are needed.
- Mechanism: By including NULL as a special token, the framework allows the model to generate responses without relying on any external knowledge sources when appropriate.
- Core assumption: The model can learn to distinguish when external knowledge is necessary versus when it's not based on the dialogue context.
- Evidence anchors:
  - [abstract]: "Specifically, SAFARI decouples the knowledge grounding into multiple sources and response generation, which allows easy extension to various knowledge sources including the possibility of not using any sources."
  - [section]: "We add Ki, ..., Kn and NULL into the vocabulary of LLMs as special tokens."
- Break condition: If the model overuses NULL, it may miss opportunities to enhance responses with relevant knowledge.

## Foundational Learning

- Concept: Dependency between knowledge sources
  - Why needed here: Understanding how different knowledge sources relate to each other is crucial for generating consistent and coherent responses.
  - Quick check question: Can you explain why the dependency between persona and documents is important in this context?

- Concept: Multi-source knowledge retrieval
  - Why needed here: The framework needs to retrieve relevant knowledge from multiple sources based on the planning step's decisions.
  - Quick check question: How does the framework handle cases where knowledge from one source depends on knowledge from another source?

- Concept: Large language models for planning
  - Why needed here: LLMs are used to plan the use of knowledge sources by treating them as special tokens in the vocabulary.
  - Quick check question: What advantages does using LLMs for planning offer compared to traditional rule-based approaches?

## Architecture Onboarding

- Component map: Planning (LLM-based decision maker) → Retrieval (Knowledge retrieval using DPR) → Assembling (LLM-based response generator)
- Critical path: Planning → Retrieval → Assembling
  - The planning step determines which sources to use, the retrieval step fetches relevant knowledge, and the assembling step generates the final response.
- Design tradeoffs:
  - Flexibility vs. Complexity: The decoupled architecture allows for independent optimization but introduces complexity in managing dependencies between components.
  - Accuracy vs. Efficiency: Using LLMs for planning provides high accuracy but may be computationally expensive compared to rule-based approaches.
- Failure signatures:
  - Planning errors: Incorrect source selection leading to irrelevant knowledge retrieval
  - Retrieval failures: Inability to find relevant knowledge despite correct planning
  - Assembling issues: Poor integration of retrieved knowledge into the final response
- First 3 experiments:
  1. Test the planning step's accuracy in selecting appropriate knowledge sources using a small dataset with known dependencies.
  2. Evaluate the retrieval module's performance in fetching relevant knowledge from each source based on the planning decisions.
  3. Assess the assembling step's ability to generate coherent responses incorporating the retrieved knowledge.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of SAFARI change when incorporating additional knowledge sources beyond PERSONA and DOCUMENTS?
- Basis in paper: [explicit] The paper mentions that SAFARI is designed to be flexible and scalable, allowing for easy extension to various knowledge sources, but only PERSONA and DOCUMENTS are used in the experiments.
- Why unresolved: The paper does not provide experimental results or analysis on the impact of adding more diverse knowledge sources to the framework.
- What evidence would resolve it: Experiments evaluating SAFARI's performance with the inclusion of additional knowledge sources, such as user memory or other domain-specific knowledge bases, and comparing the results to the current PERSONA and DOCUMENTS setup.

### Open Question 2
- Question: What is the impact of the number of retrieved results on the overall quality and consistency of the generated responses?
- Basis in paper: [explicit] The paper conducts an analysis on the effects of different numbers of retrieved results, showing that performance decreases with an increasing number of results due to potential noise introduction.
- Why unresolved: The analysis only considers a limited range of retrieved results (1-3), and the optimal number of results for balancing accuracy and recall is not determined.
- What evidence would resolve it: A more comprehensive analysis of the impact of varying the number of retrieved results on response quality, consistency, and coherence, potentially identifying an optimal range for different knowledge sources.

### Open Question 3
- Question: How does the choice of retriever model (e.g., BM25, DPR, RocketQAv2) affect the performance of SAFARI in capturing knowledge dependencies and generating persona-consistent responses?
- Basis in paper: [explicit] The paper evaluates three different retriever models (BM25, RocketQAv2, and DPR) and finds that DPR performs best in all sources of knowledge, while BM25 performs worst.
- Why unresolved: The analysis focuses on retrieval performance (Recall@1) but does not directly measure the impact of retriever choice on the final response quality, persona consistency, and knowledge consistency.
- What evidence would resolve it: Experiments comparing the performance of SAFARI using different retriever models in terms of response quality metrics (BLEU, Rouge-L, P.C, K.C) and human evaluation scores, to determine the optimal retriever for capturing knowledge dependencies and generating consistent responses.

## Limitations

- Limited empirical validation on established benchmarks beyond the constructed KBP dataset
- Assumes knowledge dependencies can be adequately captured through special tokens and planning sequences without thorough investigation of complex, non-linear dependencies
- Computational overhead concerns due to the decoupled architecture, with insufficient analysis of end-to-end efficiency compared to end-to-end approaches

## Confidence

**High Confidence Claims:**
- The basic architecture of SAFARI (planning → retrieval → assembling) is technically sound and well-defined
- The use of special tokens to represent knowledge sources in LLMs is a valid approach supported by related work
- The dataset construction methodology follows reasonable practices for creating personalized knowledge-grounded dialogues

**Medium Confidence Claims:**
- The reported improvements in persona consistency (P.C) and knowledge consistency (K.C) metrics are plausible but need independent verification
- The claim that the framework handles cases requiring no knowledge sources (NULL token) effectively is supported by the design but not thoroughly validated

**Low Confidence Claims:**
- The assertion that SAFARI "consistently outperforms baselines" across all settings lacks sufficient comparative analysis
- Claims about scalability to various knowledge sources are theoretical rather than empirically demonstrated

## Next Checks

1. **Benchmark comparison on established datasets**: Evaluate SAFARI on standard knowledge-grounded dialogue datasets like Holl-E or CMU-DoG to verify if the reported improvements in persona and knowledge consistency generalize beyond the constructed KBP dataset.

2. **Ablation study on dependency handling**: Systematically test the framework's performance with varying levels of knowledge source dependencies, including cases where dependencies are intentionally broken, to assess the robustness of the planning mechanism.

3. **Computational efficiency analysis**: Measure and compare the end-to-end latency and resource utilization of SAFARI against state-of-the-art end-to-end approaches, particularly focusing on the overhead introduced by the decoupled architecture.