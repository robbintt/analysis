---
ver: rpa2
title: Mixing predictions for online metric algorithms
arxiv_id: '2304.01781'
source_url: https://arxiv.org/abs/2304.01781
tags:
- algorithm
- cost
- time
- competitive
- predictors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies learning-augmented algorithms for metrical task
  systems (MTS), a broad class of online problems that includes k-server and caching.
  The key contribution is designing algorithms that combine multiple predictors to
  compete against the best dynamic combination of them in hindsight.
---

# Mixing predictions for online metric algorithms

## Quick Facts
- arXiv ID: 2304.01781
- Source URL: https://arxiv.org/abs/2304.01781
- Authors: 
- Reference count: 11
- One-line primary result: O(ℓ²)-competitive algorithm for combining ℓ predictors in metrical task systems, tight up to constant factors.

## Executive Summary
This paper studies learning-augmented algorithms for metrical task systems (MTS), a broad class of online problems that includes k-server and caching. The key contribution is designing algorithms that combine multiple predictors to compete against the best dynamic combination of them in hindsight. The main results include an O(ℓ²)-competitive algorithm against the best unconstrained combination of ℓ predictors, a (1+ε)-competitive algorithm for a combination benchmark with limited switches, and an adaptation to the bandit setting where only one predictor can be queried per step.

## Method Summary
The paper reduces the problem of combining ℓ predictors in MTS to a structured variant called ℓ-width layered graph traversal (LGT). It uses the OddExponent algorithm for LGT as a subroutine, which has O(ℓ²) competitive ratio. For the limited switches scenario, the algorithm creates a uniform metric space and uses an unfair MTS algorithm to choose which predictor to follow. In the bandit setting, the algorithm queries predictors in a round-robin fashion and applies the full-information algorithm to these converted predictors.

## Key Results
- Against the best unconstrained combination of ℓ predictors, the algorithm achieves O(ℓ²)-competitive ratio, which is tight.
- For a combination benchmark with limited switches, the algorithm achieves (1+ε)-competitive ratio.
- The algorithms can be adapted to access predictors in a bandit-like fashion, querying only one predictor at a time.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The algorithm achieves O(ℓ²)-competitive ratio by reducing MTS with multiple predictors to ℓ-width layered graph traversal (LGT).
- **Mechanism**: The reduction constructs a layered graph where each layer corresponds to time step t and contains ℓ vertices representing the predictions of each predictor. The algorithm uses the OddExponent algorithm for LGT, which has O(ℓ²) competitive ratio, as a subroutine.
- **Core assumption**: The LGT algorithm can be applied to the reduced problem without loss of generality, and the transformation preserves the competitive ratio up to constant factors.
- **Evidence anchors**:
  - [abstract] "The key idea is to reduce the problem of combining predictors to MTS to a structured variant called ℓ-width layered graph traversal."
  - [section] "The problem of combining predictors P1, . . . , Pℓ on an MTS instance (ℓ-MTS for short) can be formulated as a classical MTS on the same underlying metric space..."
  - [corpus] Weak - no direct mention of this specific mechanism, but related work on LGT exists.
- **Break condition**: If the LGT reduction introduces additional complexity that isn't captured in the O(ℓ²) analysis, or if the OddExponent algorithm's guarantees don't extend to this structured MTS variant.

### Mechanism 2
- **Claim**: For limited switches (DYN≤m), the algorithm achieves (1+ε)-competitive ratio by using unfair MTS algorithms on a uniform metric space.
- **Mechanism**: The algorithm creates a uniform metric space with ℓ points (one per predictor) and uses an unfair MTS algorithm (OddExponent) to choose which predictor to follow. The key insight is that switching costs in the original problem are bounded, allowing the unfair algorithm to control the number of switches.
- **Core assumption**: The unfair competitive ratio can be translated back to the original problem with controlled error, and the number of switches can be bounded based on the parameter choices.
- **Evidence anchors**:
  - [abstract] "for a benchmark with slightly constrained number of switches between different predictors, we can get a (1+ε)-competitive algorithm."
  - [section] "We choose algorithm ¯A based on the following performance metric. Definition 3.1 (Unfair competitive ratio)..."
  - [corpus] Weak - related work on unfair MTS exists but not this specific application.
- **Break condition**: If the translation between unfair competitive ratio and the original problem's competitive ratio breaks down for certain instances, or if the bound on switches doesn't hold.

### Mechanism 3
- **Claim**: In the bandit setting, the algorithm achieves O(ℓ³)-competitive ratio by combining round-robin predictor queries with the full-information algorithm.
- **Mechanism**: The algorithm queries predictors in a round-robin fashion, converting each to an O(ℓ)-competitive algorithm using Proposition 5.1. It then applies the full-information algorithm to these converted predictors.
- **Core assumption**: The round-robin conversion doesn't significantly degrade performance, and the full-information algorithm's guarantees extend to this setting.
- **Evidence anchors**:
  - [abstract] "our algorithms can be adapted to access predictors in a bandit-like fashion, querying only one predictor at a time."
  - [section] "We propose an algorithm which queries the predictors round-robin, i.e., for each i, predictor Pi is queried at time steps i, ℓ + i, 2ℓ + i, 3ℓ + i, ..."
  - [corpus] Weak - related work on bandit algorithms exists but not this specific combination.
- **Break condition**: If the round-robin conversion introduces correlation between predictors that breaks the full-information algorithm's analysis, or if the O(ℓ) factor from Proposition 5.1 is tight.

## Foundational Learning

- **Concept**: Metrical Task Systems (MTS)
  - **Why needed here**: The entire paper is about algorithms for MTS, which generalizes many online problems including k-server and caching.
  - **Quick check question**: Can you explain how k-server is a special case of MTS, and what the states and cost functions represent in the k-server context?

- **Concept**: Competitive analysis
  - **Why needed here**: The paper's main results are competitive ratios against various benchmarks, which is the standard framework for analyzing online algorithms.
  - **Quick check question**: What's the difference between competing against OPT and competing against DYN, and why is the latter more challenging?

- **Concept**: Online learning with experts
  - **Why needed here**: The problem of combining multiple predictors is analogous to the experts problem in online learning, where the goal is to compete against the best expert in hindsight.
  - **Quick check question**: How does the framework of online learning with experts relate to the problem of combining predictors in this paper?

## Architecture Onboarding

- **Component map**:
  - Input layer: MTS instance (metric space, tasks/cost functions)
  - Predictor layer: ℓ predictors providing suggestions
  - Reduction engine: Transforms MTS+predictors to structured problem (LGT or unfair MTS)
  - Algorithm layer: Applies appropriate algorithm (OddExponent, Share, etc.)
  - Output layer: Produces states for MTS

- **Critical path**:
  1. Receive cost function ct and predictor states
  2. Construct reduced instance (LGT or uniform MTS)
  3. Run appropriate algorithm on reduced instance
  4. Translate algorithm's output back to MTS state

- **Design tradeoffs**:
  - Full access vs. bandit access: Full access allows better performance but requires more information; bandit access is more practical but has higher competitive ratio.
  - Unbounded vs. limited switches: Unbounded allows arbitrary switching but has worse competitive ratio; limited switches can achieve near-optimal performance if the bound is reasonable.
  - Reduction choice: LGT reduction for unbounded switches, unfair MTS for limited switches - each has different performance characteristics.

- **Failure signatures**:
  - If predictors are highly correlated, the reduction to LGT may not capture the structure well, leading to suboptimal performance.
  - If the number of switches is much smaller than predicted by the algorithm, the (1+ε) guarantee may be loose.
  - In the bandit setting, if predictors have very different costs, round-robin sampling may be inefficient.

- **First 3 experiments**:
  1. **Basic correctness**: Implement the reduction to LGT and verify it produces the correct layered graph structure for a simple MTS instance with known optimal solution.
  2. **Competitive ratio validation**: Test the algorithm on synthetic MTS instances where the optimal combination of predictors is known, and verify the O(ℓ²) competitive ratio empirically.
  3. **Switch counting**: For the limited switches algorithm, create instances where the optimal combination switches a known number of times, and verify the algorithm's switch count and competitive ratio.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the (1+ε)-competitive algorithm for DYN≤m be extended to the bandit access model while maintaining the same competitive ratio?
- Basis in paper: The authors achieve a (1+ε)³-competitive algorithm for DYN≤m in the bandit setting, suggesting this may not be optimal.
- Why unresolved: The paper does not explore whether the gap between full access and bandit access can be closed for the limited switch scenario.
- What evidence would resolve it: A proof that either (a) a (1+ε)-competitive bandit algorithm exists for DYN≤m, or (b) a lower bound showing Ω((1+ε)²) is necessary for bandit access.

### Open Question 2
- Question: Are there structural insights about k-server beyond the impossibility of configuration-encoding covering formulations?
- Basis in paper: The paper identifies that k-server on HSTs cannot have configuration-encoding covering formulations, unlike weighted paging.
- Why unresolved: The paper only establishes a separation between k-server on HSTs and weighted paging, but does not explore what other structural properties distinguish these problems.
- What evidence would resolve it: Either (a) identification of additional structural properties that separate k-server from other online problems, or (b) proof that no other structural separations exist.

### Open Question 3
- Question: Can the O(ℓ²) competitive ratio against DYN be improved for specific classes of MTS instances?
- Basis in paper: The O(ℓ²) upper bound is shown to be tight for general MTS, but the paper does not explore whether special cases admit better bounds.
- Why unresolved: The lower bound construction uses a general reduction that may not be tight for structured instances.
- What evidence would resolve it: Either (a) an algorithm achieving o(ℓ²) competitive ratio for a natural subclass of MTS (e.g., tree metrics, HSTs), or (b) a matching lower bound showing O(ℓ²) is necessary even for that subclass.

## Limitations
- The O(ℓ²) competitive ratio for combining ℓ predictors is tight, but this result relies on the OddExponent algorithm's guarantees for ℓ-width layered graph traversal.
- The (1+ε)-competitive algorithm for limited switches requires the number of switches to be known or bounded, and its performance could degrade if the optimal combination switches more frequently than assumed.
- The bandit adaptation comes with an additional O(ℓ) factor in the competitive ratio, which could be significant when ℓ is large or when predictors have very different qualities.

## Confidence
- O(ℓ²) competitive ratio: High
- (1+ε)-competitive algorithm for limited switches: Medium
- Bandit adaptation: Low

## Next Checks
1. **Implementation verification**: Code the reduction from MTS to LGT and validate it correctly constructs the layered graph with proper edge weights for a simple 2-server MTS instance with known optimal solution.

2. **Competitive ratio testing**: Create synthetic MTS instances with ℓ=3 predictors where the optimal combination is known, run the algorithm, and measure the actual competitive ratio compared to the theoretical O(ℓ²) bound.

3. **Switch counting analysis**: For the limited switches algorithm, design an MTS instance where the optimal combination switches exactly m times, implement the algorithm with different m values, and verify both the switch count and competitive ratio behavior.