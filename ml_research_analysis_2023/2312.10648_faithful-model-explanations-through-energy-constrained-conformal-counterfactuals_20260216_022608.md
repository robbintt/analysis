---
ver: rpa2
title: Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals
arxiv_id: '2312.10648'
source_url: https://arxiv.org/abs/2312.10648
tags:
- eccco
- eccco-l1
- wachter
- counterfactuals
- revise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of generating faithful counterfactual
  explanations for black-box models. The core method idea is to introduce a new notion
  of faithfulness, defined as the degree to which counterfactuals are consistent with
  what the model has learned about the data, and propose a novel algorithmic framework
  called ECCCo (Energy-Constrained Conformal Counterfactuals) that generates counterfactuals
  by minimizing predictive uncertainty and constraining the energy of the generated
  counterfactual.
---

# Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals

## Quick Facts
- arXiv ID: 2312.10648
- Source URL: https://arxiv.org/abs/2312.10648
- Reference count: 24
- Primary result: ECCCo achieves state-of-the-art faithfulness across models and datasets, approaching state-of-the-art plausibility without sacrificing faithfulness.

## Executive Summary
This paper introduces ECCCo (Energy-Constrained Conformal Counterfactuals), a novel framework for generating counterfactual explanations that are faithful to what a black-box model has learned about the data. The key insight is that counterfactuals should not only flip model predictions but also lie in regions the model considers probable. ECCCo achieves this by combining energy-based modeling with conformal prediction, constraining counterfactuals to have low energy (high probability under the model's learned distribution) and low predictive uncertainty. The framework consistently outperforms existing methods in faithfulness while maintaining competitive plausibility.

## Method Summary
ECCCo generates counterfactuals by optimizing a loss function that combines three terms: a distance penalty to ensure closeness to the factual input, an energy constraint to ensure the counterfactual lies in high-probability regions according to the model's learned distribution, and a conformal prediction set size penalty to avoid uncertain regions. The method uses gradient-based optimization starting from the factual input or a small perturbation. For image data, ECCCo+ extends the approach by searching in a lower-dimensional latent space defined by PCA components. The framework relies solely on properties of the black-box model itself (energy function and gradients) rather than external surrogate models.

## Key Results
- ECCCo consistently achieves state-of-the-art faithfulness across various models and datasets
- The method can achieve near state-of-the-art plausibility without sacrificing faithfulness
- ECCCo outperforms other generators in terms of faithfulness, often approaching state-of-the-art performance in plausibility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ECCCo achieves faithfulness by constraining the energy of counterfactuals to match the model's learned generative distribution.
- Mechanism: By penalizing the energy term $E_\theta(x|y_+)$ in the loss function, ECCCo ensures that generated counterfactuals lie in regions the model has learned to associate with the target class, rather than just regions that flip the prediction.
- Core assumption: The model's energy function $E_\theta$ accurately captures the likelihood of inputs under the model's learned distribution.
- Evidence anchors:
  - [abstract] "propose a novel algorithmic framework for generating Energy-Constrained Conformal Counterfactuals that are only as plausible as the model permits"
  - [section 4] "we can rely solely on decreasing the energy of the counterfactual itself. This is sufficient to capture the generative property of the underlying model"
  - [corpus] Weak - no direct mentions of energy-based modeling in related papers
- Break condition: If the model's energy function is poorly calibrated or the model hasn't learned a meaningful generative distribution, the energy constraint will not ensure faithfulness.

### Mechanism 2
- Claim: ECCCo achieves plausibility only when the underlying model has learned plausible representations of the data.
- Mechanism: By relying solely on the black-box model's properties (energy and conformal prediction) rather than external surrogate models, ECCCo's plausibility is bounded by what the model has actually learned about the data distribution.
- Core assumption: The black-box model's learned representations are at least as plausible as the true data distribution.
- Evidence anchors:
  - [abstract] "our framework relies solely on properties defining the black-box model itself by leveraging recent advances in energy-based modelling and conformal prediction"
  - [section 4] "plausibility should hinge on the quality of the model... ECCCo produces plausible counterfactuals if and only if the model itself has learned plausible explanations for the data"
  - [corpus] Weak - related papers focus on plausibility through surrogates rather than model constraints
- Break condition: If the model has learned implausible representations (e.g., due to adversarial training or poor generalization), ECCCo will generate implausible counterfactuals.

### Mechanism 3
- Claim: Conformal prediction set size provides a differentiable measure of predictive uncertainty that guides counterfactual search away from uncertain regions.
- Mechanism: The smooth set size penalty $\Omega(C_\theta(x; \alpha))$ encourages counterfactuals to lie in regions where the model is confident about its predictions, reducing the likelihood of adversarial examples.
- Core assumption: The conformal prediction sets accurately reflect the model's uncertainty about its predictions.
- Evidence anchors:
  - [section 4] "To leverage this notion of predictive uncertainty in the context of gradient-based counterfactual search, we use a smooth set size penalty"
  - [section 5] "The third and final penalty term involving $\lambda_3$ ensures that the generated counterfactual is associated with low predictive uncertainty"
  - [corpus] Moderate - "Individualised Counterfactual Examples Using Conformal Prediction Intervals" directly uses conformal prediction for counterfactuals
- Break condition: If the conformal prediction sets are poorly calibrated (e.g., due to small calibration set size), the uncertainty penalty may misguide the search.

## Foundational Learning

- Concept: Energy-based modeling (EBM)
  - Why needed here: EBM provides the theoretical framework for using energy functions to represent probability distributions and guide generative sampling.
  - Quick check question: What is the relationship between energy and probability in EBM?

- Concept: Conformal prediction
  - Why needed here: Conformal prediction provides a model-agnostic way to quantify predictive uncertainty without requiring changes to model training.
  - Quick check question: How does split conformal prediction create prediction sets that cover the true label with a specified probability?

- Concept: Counterfactual explanations
  - Why needed here: Understanding the desiderata for counterfactuals (faithfulness, plausibility, closeness) is essential for evaluating ECCCo's contributions.
  - Quick check question: What is the difference between fidelity and faithfulness in the context of counterfactual explanations?

## Architecture Onboarding

- Component map: Black-box model M_θ -> Energy function E_θ -> Conformal prediction calibrator -> Counterfactual generator -> Evaluation metrics
- Critical path: 1) Calibrate model using split conformal prediction on calibration set 2) Initialize counterfactual state at factual or small perturbation 3) Iteratively optimize loss function using gradient descent 4) Evaluate counterfactuals using proposed metrics
- Design tradeoffs:
  - Energy constraint vs. plausibility: Stricter energy constraints may reduce plausibility if the model's learned distribution is imperfect
  - Uncertainty penalty strength: Higher weights may prevent exploration of decision boundary regions
  - Latent space search (ECCCo+): Can improve plausibility but may reduce faithfulness if PCA doesn't capture relevant variation
- Failure signatures:
  - Counterfactuals remain close to decision boundary: Uncertainty penalty too strong or conformal calibration inadequate
  - Counterfactuals look unrealistic: Energy constraint too weak or model's generative distribution is poor
  - Counterfactuals require large perturbations: Distance penalty too strong or optimization not converging
- First 3 experiments:
  1. Compare ECCCo vs. Wachter on a simple linearly separable dataset to verify faithfulness improvement
  2. Test ECCCo on a model with known poor generative properties to confirm plausibility is bounded by model quality
  3. Evaluate ECCCo+ vs. ECCCo on MNIST to assess impact of latent space search on faithfulness-plausibility tradeoff

## Open Questions the Paper Calls Out
No explicit open questions were identified in the paper.

## Limitations
- The framework relies heavily on the assumption that the black-box model's energy function accurately captures the data distribution
- Conformal prediction set size is used as a differentiable proxy for uncertainty without rigorous validation of its relationship to true predictive uncertainty
- The computational cost of gradient-based counterfactual generation may be prohibitive for large-scale applications

## Confidence
- High confidence in the theoretical framework connecting energy constraints to faithfulness
- Medium confidence in the empirical evaluation, as results are strong but limited to specific model architectures and datasets
- Low confidence in scalability claims due to lack of computational efficiency analysis

## Next Checks
1. Test ECCCo on models with known poor generative properties (e.g., adversarially trained models) to verify that plausibility is indeed bounded by model quality rather than the method's capabilities
2. Conduct ablation studies varying the conformal calibration set size to quantify the impact of calibration quality on counterfactual faithfulness and uncertainty estimates
3. Compare ECCCo's computational efficiency against baseline methods on large-scale image datasets to assess practical scalability for real-world applications