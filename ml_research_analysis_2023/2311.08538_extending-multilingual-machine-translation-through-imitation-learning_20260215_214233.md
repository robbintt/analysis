---
ver: rpa2
title: Extending Multilingual Machine Translation through Imitation Learning
arxiv_id: '2311.08538'
source_url: https://arxiv.org/abs/2311.08538
tags:
- language
- languages
- translation
- original
- highlow
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of extending multilingual neural
  machine translation (MNMT) models to support new languages, especially in low-resource
  scenarios. The core method idea is to treat this task as an imitation learning problem,
  where an expert MNMT model generates pseudo-parallel corpora, and a learner model
  is trained to mimic the expert's translation behavior while using actual parallel
  data between the new language and English.
---

# Extending Multilingual Machine Translation through Imitation Learning

## Quick Facts
- arXiv ID: 2311.08538
- Source URL: https://arxiv.org/abs/2311.08538
- Authors: 
- Reference count: 17
- Key outcome: Proposed Imit-MNMT significantly improves translation performance between new and existing languages while mitigating catastrophic forgetting

## Executive Summary
This paper introduces a novel approach to extend large multilingual neural machine translation (MNMT) models to support new languages using only parallel data between the new language and English. The method frames this extension as an imitation learning problem, where an expert MNMT model generates pseudo-parallel corpora that a separate learner model then uses to mimic the expert's translation behavior. The approach effectively prevents catastrophic forgetting of original language pairs while achieving superior performance on new language translation compared to baseline methods like fine-tuning and adapter-based approaches.

## Method Summary
The approach uses a two-step iterative process: first, an expert MNMT model generates pseudo multi-parallel data by translating English sentences to k randomly selected existing languages; second, a separate learner model is trained to imitate the expert's behavior on this pseudo data while using gold new language-English data. Language-specific weighting based on expert BLEU scores prioritizes high-quality pseudo-data for languages where the expert performs well. The method employs separate expert and learner models to prevent catastrophic forgetting, and experiments on 8 new languages show significant improvements over baseline approaches while maintaining performance on original language pairs.

## Key Results
- Achieves 2.5 BLEU points improvement on average compared to m2m_100 baseline
- Reduces catastrophic forgetting by maintaining performance on original language pairs
- Effectively addresses copy and off-target problems common in large-scale MNMT models
- Shows translation direction asymmetry due to decoder sensitivity to noisy inputs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using separate expert and learner models prevents catastrophic forgetting by isolating pseudo-data noise from the original model.
- Mechanism: The expert model generates pseudo-corpora without parameter updates, while the learner model is trained only on the pseudo-data plus gold data. This separation prevents the original model's performance degradation.
- Core assumption: The pseudo-corpora quality is high enough to guide the learner without corrupting the expert.
- Evidence anchors:
  - [abstract] "our approach differs from other machine translation models that use pseudo-corpus in that our approach uses separate expert and learner models"
  - [section 3.2] "We opt for imitation learning over knowledge distillation because our goal is to extend the MNMT model while maintaining the translation performance of the original language pairs"

### Mechanism 2
- Claim: Language-specific weighting based on expert BLEU scores prioritizes high-quality pseudo-data for languages with better expert performance.
- Mechanism: Languages are weighted proportionally to their BLEU scores with English, ensuring that languages with better expert performance contribute more to the learner's training distribution.
- Core assumption: BLEU scores between English and original languages correlate with the quality of pseudo-data when translating to/from new languages.
- Evidence anchors:
  - [section 3.2.1] "we assume the importance of a given language during training is closely aligned with the performance of the expert model on it"
  - [section 5] "our approach achieves better performance in language pairs where the original language is a high-resource language"

### Mechanism 3
- Claim: Training direction (new→original vs original→new) affects performance due to decoder sensitivity and subword representation issues.
- Mechanism: The decoder is more sensitive to noisy inputs than the encoder, and new languages have less data, making decoder training harder when extending to the target side.
- Core assumption: Decoder sensitivity to noise is the primary factor in translation direction performance differences.
- Evidence anchors:
  - [section 5] "decoding the new language does not perform as well as decoding the original language" and "the decoder of machine translation is more sensitive to noisy inputs than the encoder"
  - [section 5] "Translation from the new language to the original language does not suffer from these issues, because the new language can share some vocabulary with the original language on the source-side"

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: The core problem is extending MNMT without degrading performance on original languages
  - Quick check question: What happens to a neural network's performance on task A when fine-tuned extensively on task B without special techniques?

- Concept: Pseudo-parallel corpus generation and its impact on training
  - Why needed here: The method relies on generating synthetic data between new and existing languages through the expert model
  - Quick check question: How does the quality of pseudo-parallel data affect the training of a neural machine translation model?

- Concept: Imitation learning vs knowledge distillation
  - Why needed here: The approach frames MNMT extension as an imitation learning problem rather than standard fine-tuning
  - Quick check question: What is the fundamental difference between imitation learning and knowledge distillation in terms of what behavior is being transferred?

## Architecture Onboarding

- Component map: Expert model -> Pseudo-data generator -> Language weighting module -> Learner model -> Evaluation
- Critical path: 1. Initialize learner model with expert parameters 2. Generate pseudo-corpora using expert model 3. Apply language-specific weighting 4. Train learner on weighted pseudo-data + gold data 5. Evaluate on original and new language pairs
- Design tradeoffs: Separate models increase memory usage but prevent catastrophic forgetting; k language selection balances diversity vs computational cost; language weighting improves performance but requires expert evaluation on all languages
- Failure signatures: BLEU scores on original languages drop significantly → catastrophic forgetting; BLEU scores on new languages plateau → poor pseudo-data quality or insufficient training; Copy ratio increases → vocabulary mismatch or decoding issues
- First 3 experiments: 1. Baseline comparison: Run m2m_100, fine-tune, and adapter baselines on the same dataset to establish performance floor 2. k variation: Test k=3, k=5, k=10 to find optimal number of languages for pseudo-data generation 3. Direction comparison: Train models in both directions (new→original and original→new) to confirm decoder sensitivity hypothesis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed Imit-MNMT approach perform on larger-scale multilingual models (e.g., 1000+ languages) compared to smaller-scale models?
- Basis in paper: [inferred] The paper primarily evaluates on m2m_100 model supporting 100 languages. The authors note a limitation that the approach was not evaluated on larger-scale models like mt5 or mbart, and suggest it could be applicable to various NLP tasks.
- Why unresolved: The paper only reports results on a 100-language model, leaving the performance on significantly larger multilingual models untested. Scaling up to 1000+ languages may introduce new challenges related to model capacity, computational resources, and data distribution.
- What evidence would resolve it: Systematic experiments comparing Imit-MNMT performance on models of increasing size (100, 500, 1000+ languages) while controlling for other factors. Results should show whether improvements scale proportionally or diminish with model size.

### Open Question 2
- Question: What is the impact of incorporating additional parallel corpora beyond English for extending to new languages?
- Basis in paper: [explicit] The authors note a limitation that they focused on the scenario using only parallel corpus between new language and English, acknowledging that parallel sentence pairs between new language and other languages might exist and could potentially enhance performance.
- Why unresolved: The paper deliberately restricts to English as pivot language to test the most challenging scenario, but doesn't explore whether using multiple pivot languages improves results or whether the method would work without English at all.
- What evidence would resolve it: Controlled experiments comparing performance when using parallel corpora with different pivot languages (English only, multiple languages including English, no English) for the same set of new languages. Results should quantify the performance trade-offs.

### Open Question 3
- Question: How does the dynamic language weighting mechanism affect catastrophic forgetting across different resource levels of original language pairs?
- Basis in paper: [explicit] The authors propose language weighting based on expert model BLEU scores and show it helps with catastrophic forgetting, but the analysis focuses on aggregate results across all language pairs rather than examining how weighting affects different resource levels differently.
- Why unresolved: While the paper shows weighting helps overall, it doesn't investigate whether the weighting strategy is optimal for all language pairs or if it creates imbalances where high-resource languages benefit disproportionately at the expense of low-resource languages.
- What evidence would resolve it: Detailed analysis of catastrophic forgetting patterns for low, medium, and high resource language pairs with and without weighting, showing whether weighting creates systematic advantages or disadvantages for certain resource categories.

## Limitations
- Performance on truly distant language families remains untested
- The method assumes English as the pivot language, limiting applicability to scenarios with diverse parallel corpora
- Hyperparameter sensitivity (learning rate, dropout, batch size) is not thoroughly validated

## Confidence
- High confidence: The core mechanism of using separate expert and learner models to prevent catastrophic forgetting is well-established in the literature and logically sound based on the paper's experimental results.
- Medium confidence: The language-specific weighting approach shows promise but relies on the assumption that English BLEU scores correlate with pseudo-data quality, which is plausible but not rigorously validated across all language pairs.
- Low confidence: The claim that decoder sensitivity is the primary factor in translation direction performance differences lacks sufficient ablation studies to isolate this effect from other confounding factors like vocabulary overlap and encoder-side issues.

## Next Checks
1. **Ablation on k languages**: Systematically vary k from 3 to 15 languages and measure the impact on both new language translation quality and catastrophic forgetting on original languages to determine the optimal trade-off between diversity and computational cost.

2. **Expert model quality correlation**: Conduct controlled experiments where expert models of varying quality (different training regimes, architectures) generate pseudo-data, then measure how expert BLEU scores correlate with learner model performance to validate the weighting mechanism.

3. **Direction-specific analysis**: Perform detailed error analysis comparing copy ratios, off-target ratios, and translation quality metrics separately for encoder and decoder outputs in both translation directions to empirically validate the decoder sensitivity hypothesis.