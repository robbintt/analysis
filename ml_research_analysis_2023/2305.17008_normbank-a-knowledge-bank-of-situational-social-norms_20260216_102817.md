---
ver: rpa2
title: 'NormBank: A Knowledge Bank of Situational Social Norms'
arxiv_id: '2305.17008'
source_url: https://arxiv.org/abs/2305.17008
tags:
- norm
- bank
- social
- constraints
- norms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces NormBank, a knowledge bank of 155k situational
  norms grounded in a multivalent sociocultural frame. Unlike prior commonsense resources,
  NormBank captures how social norms depend on the setting, agents' roles and attributes,
  and other environmental and cultural constraints.
---

# NormBank: A Knowledge Bank of Situational Social Norms

## Quick Facts
- arXiv ID: 2305.17008
- Source URL: https://arxiv.org/abs/2305.17008
- Reference count: 40
- Key outcome: Introduces NormBank with 155k situational norms grounded in a multivalent sociocultural frame using the SCENE taxonomy

## Executive Summary
NormBank is a knowledge bank of situational social norms that captures how expected behaviors depend on context through a hierarchical taxonomy called SCENE. Unlike previous commonsense resources, NormBank enables non-monotonic reasoning where the same behavior can be expected, okay, or unexpected depending on the situation. The system organizes constraints hierarchically (settings → environment → roles → attributes → behaviors) and demonstrates that neural models can reliably extend its scope while transferring knowledge to downstream social reasoning tasks.

## Method Summary
The paper constructs NormBank through a hierarchical organization using the SCENE taxonomy based on Goffman's dramaturgical theory. Human annotators from Amazon Mechanical Turk were recruited through qualification tests and iterative feedback to create 155k situational norms with 63k unique constraints. Neural models including BERT, RoBERTa, and ALBERT were trained for classification tasks, while BART and GPT-2 were used for generation tasks. The system was evaluated using automatic metrics (F1, BLEU, ROUGE-L) and human evaluation, with transfer learning experiments on social commonsense reasoning benchmarks.

## Key Results
- BERT classification achieved F1 of 0.69 on situational norm prediction
- BART generation reached BLEU score of 22.07 for creating situational constraints
- Transfer learning improved performance on Social IQa and CosmosQA benchmarks
- Human evaluation showed generated norms were sensible (85%), correct (78%), and relevant (82%)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical constraint organization enables efficient encoding of non-monotonic social norms
- Mechanism: The SCENE taxonomy provides structured hierarchy that regularizes combinatorially explosive context space, allowing models to learn patterns across similar roles while maintaining flexibility for defeasible norms
- Core assumption: Social contexts have regular, hierarchical dependencies exploitable for efficient learning
- Evidence anchors: [abstract] "hierarchical organization (Objective 2) by means of a rich taxonomy over the relevant contextual signals"; [section 3] "To help models efficiently learn non-monotonic normative reasoning"
- Break condition: If social norms don't follow hierarchical dependencies or hierarchy becomes too rigid

### Mechanism 2
- Claim: Non-monotonic reasoning enables defeasible norm judgments updated with new information
- Mechanism: Encodes norms as defeasible rather than absolute, providing contrasting situations where same behavior can be expected/okay/unexpected, mimicking human normative reasoning
- Core assumption: Social norms are inherently defeasible and context-dependent rather than absolute rules
- Evidence anchors: [abstract] "Norms are non-monotonic - one can cancel an inference by updating its frame even slightly"; [section 1] "inferences that hold under most cases can be updated or even retracted"
- Break condition: If norm inference requires absolute rules or context changes don't affect judgments

### Mechanism 3
- Claim: Contrast sets of richly-conditioned norms improve model generalization beyond prototypical contexts
- Mechanism: Starting with behaviors and asking annotators to provide various situational contexts captures less conventional examples, challenging models to learn beyond simple prototypes
- Core assumption: Model performance improves when trained on diverse, non-prototypical examples
- Evidence anchors: [section 4] "Instead, we start with behaviors and ask annotators to provide us with different dramaturgical contexts"; [section 4] "Inspired by contrast sets (Gardner et al., 2020)"
- Break condition: If non-prototypical examples don't improve generalization or introduce too much noise

## Foundational Learning

- Concept: Defeasible reasoning
  - Why needed here: Social norms are inherently defeasible - they can be overridden by new contextual information. Understanding this concept is crucial for grasping why NormBank encodes norms as conditional rather than absolute.
  - Quick check question: Why might the same behavior be considered expected in one context but unexpected in another, even with minimal changes to the situation?

- Concept: Dramaturgical theory of social interaction
  - Why needed here: NormBank uses Goffman's dramaturgical framework (settings, roles, scripts, attributes) to organize situational constraints. This theoretical foundation explains the structure of the SCENE taxonomy.
  - Quick check question: How does viewing social interactions as "performances" help explain why the same behavior might be appropriate for one role but not another in the same setting?

- Concept: Hierarchical taxonomies in knowledge representation
  - Why needed here: The SCENE taxonomy uses hierarchical organization to manage complexity of situational constraints. Understanding how hierarchies work in knowledge bases is essential for grasping how NormBank achieves efficient encoding.
  - Quick check question: Why might organizing constraints hierarchically be more effective than using a flat list of features for representing social norms?

## Architecture Onboarding

- Component map: SCENE Taxonomy -> NormBank Dataset -> Neural Models (BERT, RoBERTa, ALBERT, BART, GPT-2) -> Downstream Tasks
- Critical path: SCENE taxonomy construction → NormBank annotation → Neural model training → Transfer learning evaluation
- Design tradeoffs:
  - Human annotation vs. automatic generation: Human provides quality and creativity but is expensive; automatic scales but may introduce errors
  - Hierarchical vs. flat representation: Hierarchy enables efficient learning but may miss cross-cutting patterns
  - Defeasible vs. absolute norms: Defeasible captures nuance but are harder to learn than simple rules
- Failure signatures:
  - Low classification F1 scores indicate model isn't learning non-monotonic patterns
  - Generated constraints that aren't sensible or relevant suggest model doesn't understand situational context
  - Poor transfer learning performance indicates knowledge isn't generalizable to downstream tasks
- First 3 experiments:
  1. Run classification baseline with BERT on NormBank dataset to establish if model can learn non-monotonic patterns
  2. Test BART generation with nucleus sampling (p=0.9) on NormBank subset to evaluate if it can generate sensible situational constraints
  3. Perform transfer learning from NormBank to Social IQa to measure if knowledge transfers to social commonsense reasoning tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the non-monotonic nature of social norms affect the reliability of AI systems that rely on NormBank for decision-making in real-world scenarios?
- Basis in paper: [explicit] The paper discusses the non-monotonic nature of norms and how they can be updated or retracted based on new information from the social context
- Why unresolved: The paper demonstrates neural models can learn non-monotonic inferences but does not explore real-world implications on AI system reliability
- What evidence would resolve it: Empirical studies showing performance of AI systems using NormBank in diverse real-world scenarios, especially when norms change or conflict

### Open Question 2
- Question: To what extent can NormBank be generalized to cultures and contexts not represented in the current annotator pool, and what methods can be employed to ensure cultural sensitivity and accuracy?
- Basis in paper: [inferred] The paper acknowledges limitations of annotator pool being limited to English-speaking individuals in United States and suggests future expansion efforts could be crowdsourced from other cultures
- Why unresolved: The paper does not provide detailed methodology for expanding to other cultures or assess potential biases introduced by current pool
- What evidence would resolve it: Comparative studies of NormBank's performance across different cultures, and methodologies for culturally diverse data collection and annotation

### Open Question 3
- Question: How does the hierarchical organization of SCENE influence the efficiency and accuracy of norm learning in neural models, and are there alternative organizational structures that could be more effective?
- Basis in paper: [explicit] The paper introduces SCENE taxonomy to help models efficiently learn non-monotonic normative reasoning over a seemingly unbounded set of possible contexts
- Why unresolved: The paper does not compare SCENE with other potential organizational structures or provide empirical evidence on its efficiency and accuracy benefits
- What evidence would resolve it: Comparative analysis of norm learning performance using SCENE versus alternative taxonomies, focusing on efficiency and accuracy metrics

## Limitations
- Cultural and linguistic biases from English-speaking annotator pool may limit generalizability
- Hierarchical SCENE taxonomy may not fully capture complexity and nuance of real-world social norms
- Strong performance metrics are evaluated primarily on in-domain data rather than external validation across diverse contexts

## Confidence

**High Confidence** (Level 4-5): Hierarchical organization through SCENE taxonomy is well-supported by theoretical grounding in Goffman's dramaturgical theory and empirical implementation with rigorous annotation pipeline.

**Medium Confidence** (Level 3): Neural model performance shows strong results on classification and generation tasks, but evaluation is limited to automatic metrics and small-scale human evaluation. Transfer learning results are promising but need more extensive validation.

**Low Confidence** (Level 1-2): Claims about capturing true defeasible reasoning and non-monotonic norm updating are based on controlled experimental setups that may not represent complexity of real-world social reasoning. Cultural generalizability remains an open question.

## Next Checks

1. **Cross-cultural validation study**: Conduct norm annotation with diverse cultural groups to test whether SCENE taxonomy and non-monotonic reasoning capabilities generalize beyond English-speaking Western contexts. Measure inter-cultural agreement and identify taxonomy elements that may be culturally specific.

2. **Real-time dynamic reasoning evaluation**: Design experiments that test system's ability to update normative inferences in response to streaming contextual information, rather than pre-defined contrasting situations. This would better evaluate claimed defeasible reasoning capabilities.

3. **Ablation study on hierarchical structure**: Systematically remove or modify levels of SCENE hierarchy to quantify contribution of each level to model performance. This would provide empirical evidence for whether hierarchical organization is truly necessary or if alternative representations could achieve similar results.