---
ver: rpa2
title: Practical PCG Through Large Language Models
arxiv_id: '2305.18243'
source_url: https://arxiv.org/abs/2305.18243
tags:
- tiles
- levels
- data
- generation
- level
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a practical method for generating 2D game rooms
  for the Metavoidal game using Large Language Models (LLMs). The approach involves
  fine-tuning GPT-3 on a limited dataset of 60 hand-designed rooms, using human-in-the-loop
  fine-tuning and data augmentation techniques to improve the quality and variety
  of generated levels.
---

# Practical PCG Through Large Language Models

## Quick Facts
- arXiv ID: 2305.18243
- Source URL: https://arxiv.org/abs/2305.18243
- Authors: 
- Reference count: 11
- This paper presents a practical method for generating 2D game rooms for the Metavoidal game using Large Language Models (LLMs).

## Executive Summary
This paper introduces a novel approach to procedural content generation (PCG) for 2D game rooms using Large Language Models, specifically GPT-3. The method involves fine-tuning GPT-3 on a limited dataset of 60 hand-designed rooms, employing human-in-the-loop fine-tuning and data augmentation techniques to improve the quality and variety of generated levels. The approach successfully generates 37% playable-novel levels, demonstrating the effectiveness of LLMs in creating complex game content while adhering to specific constraints.

## Method Summary
The method involves encoding game-specific constraints into controllable prompts, fine-tuning GPT-3 on 60 hand-designed rooms, and using data augmentation techniques to expand the training dataset. Human-in-the-loop fine-tuning is employed to iteratively improve the quality and novelty of generated levels by repairing and adding playable-novel levels back to the dataset. The process includes two stages of fine-tuning, with the second stage incorporating augmented data to enhance the model's performance.

## Key Results
- Successfully generates 37% playable-novel levels using only 60 hand-designed rooms
- Demonstrates the effectiveness of LLMs in procedural content generation for games with complex constraints
- Achieves this result through human-in-the-loop fine-tuning and data augmentation techniques

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning GPT-3 on limited hand-designed rooms with controllable prompts enables generation of levels that respect both global and local constraints.
- Mechanism: The approach encodes game-specific constraints (tile types, placement rules, door spacing, etc.) into the prompt format, allowing the LLM to learn and reproduce these rules during generation.
- Core assumption: The LLM can learn to follow complex multi-constraint patterns from a small dataset when constraints are explicitly encoded in the prompt.
- Evidence anchors: [abstract] "Our technique can harness the power of GPT-3 by Human-in-the-loop fine-tuning which allows our method to create 37% Playable-Novel levels from as scarce data as only 60 hand-designed rooms" [section III-A] "Our single prompt looks like this: 'The size of the level is {width x height}, the base tile is "{base tile}", and the border tile is " {border tile}". There are 2 pattern tiles, "{pattern tiles[0]}" and "{pattern tiles[1]}", "F" is the water tile, "J" is the door tile, and the percentage of pattern tiles is {percent pattern tiles}%.->'"

### Mechanism 2
- Claim: Human-in-the-loop bootstrapping iteratively improves the quality and novelty of generated levels.
- Mechanism: After initial fine-tuning, generated levels are manually inspected and repaired when possible. Novel and playable repaired levels are added back to the training dataset, creating a feedback loop that progressively improves the model's ability to generate valid content.
- Core assumption: Human repair of near-miss levels can provide valuable training examples that improve the model's constraint satisfaction over iterations.
- Evidence anchors: [section III-C] "In this stage, we get unplayable rooms that do not follow the constraints. We observe all generated rooms and try to fix the ones that are fixable. After fixing the rooms, we add the room to our data if they are novel enough." [abstract] "To efficiently use the limited data available without overfitting we use several types of data augmentation as well as a form of bootstrapping, where novel high-quality level are added back into the dataset."

### Mechanism 3
- Claim: Data augmentation through transformations (flipping, rotation, pattern swapping) expands the effective training dataset without requiring additional human-designed levels.
- Mechanism: The limited set of 60 hand-designed rooms is augmented by applying geometric transformations and pattern swaps, creating variations that help the model generalize better to different room configurations.
- Core assumption: Simple geometric transformations preserve the constraint structure while creating meaningful variations that improve model generalization.
- Evidence anchors: [section III-B] "To increase the dataset and get more variation in the dataset, we use the following techniques, motivated by [8], to augment our data: 1) We flip the room horizontally. 2) We flip the room vertically. 3) We rotate the room 90◦ and change the door sizes to cater for the constraint. 4) We swap the pattern tiles of the original room levels. 5) We repeat 1−3 for rooms with swapped pattern tiles." [abstract] "Our method includes two stages of generation... We repeat bootstrapping till we get enough data. We commence the second stage by augmenting our data as explained earlier."

## Foundational Learning

- Concept: Prompt engineering for constrained generation
  - Why needed here: The game has specific tile placement rules and global constraints that must be satisfied; proper prompt formatting teaches the LLM these rules
  - Quick check question: What information must be included in each prompt to ensure the model generates rooms with correct base tiles, pattern tiles, and constraint percentages?

- Concept: Fine-tuning methodology for low-resource domains
  - Why needed here: Only 60 hand-designed rooms are available, requiring efficient use of limited data to achieve good performance
  - Quick check question: How many epochs were used in the first fine-tuning stage, and why might this be appropriate for a small dataset?

- Concept: Evaluation metrics for procedural content generation
  - Why needed here: Need to quantify both playability (constraint satisfaction) and novelty (diversity from training data) to measure success
  - Quick check question: What are the two components of the "Playable-Novel" metric, and how is novelty quantified in this work?

## Architecture Onboarding

- Component map: 60 hand-designed rooms → prompt generation → fine-tuning dataset → Stage 1 fine-tuning → augmentation → Stage 2 fine-tuning → generation loop → constraint checking → novelty assessment → dataset update
- Critical path: Data augmentation → Stage 2 fine-tuning → Generation loop → Playable-Novel level creation
- Design tradeoffs: 
  - Temperature setting (0.4) balances creativity with constraint adherence
  - Human-in-the-loop vs fully automated generation trade-off between quality and scalability
  - Augmentation depth vs. dataset size and training time
- Failure signatures:
  - Low accuracy scores indicate prompt-completion mismatch
  - No increase in playable-novel levels across generation rounds suggests bootstrapping failure
  - High cost per playable-novel level indicates inefficiency
- First 3 experiments:
  1. Fine-tune GPT-3 on original 60 rooms with default settings, generate 10 levels, check constraint adherence
  2. Apply augmentation techniques to original dataset, fine-tune for 2 epochs, generate 20 levels, measure accuracy improvement
  3. Implement full bootstrapping loop for 3 rounds, track playable-novel percentage growth, identify optimal generation parameters

## Open Questions the Paper Calls Out
The paper does not explicitly call out any open questions.

## Limitations
- Lack of detailed technical specifications for the fine-tuning process, including specific GPT-3 hyperparameters
- The 37% playable-novel metric lacks context for comparison with other PCG methods
- Evaluation methodology appears subjective in parts, particularly the human-in-the-loop assessment of novelty and playability

## Confidence
- High confidence in the core approach: Fine-tuning GPT-3 on domain-specific prompts with data augmentation is a well-established ML technique
- Medium confidence in the quantitative results: While the 37% metric is reported, the lack of comparison data and detailed constraint specifications limits our ability to independently verify the claimed performance level
- Low confidence in reproducibility: Key implementation details including exact prompt formats, constraint rules, and fine-tuning hyperparameters are either incomplete or not provided

## Next Checks
1. Implement a complete constraint checker for the Metavoidal game using only the information provided in the paper, then validate it against the reported playable level criteria to ensure alignment
2. Run the same evaluation pipeline on randomly generated levels and on GPT-3 outputs without fine-tuning to establish baseline metrics for comparison with the 37% playable-novel result
3. Systematically vary the fine-tuning parameters (epochs, learning rate, temperature) to determine their impact on the playable-novel percentage and identify optimal settings for this domain