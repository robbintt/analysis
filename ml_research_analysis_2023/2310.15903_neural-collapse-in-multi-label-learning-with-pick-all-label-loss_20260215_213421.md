---
ver: rpa2
title: Neural Collapse in Multi-label Learning with Pick-all-label Loss
arxiv_id: '2310.15903'
source_url: https://arxiv.org/abs/2310.15903
tags:
- udcurlymod
- parall
- alt1
- nright
- alt12
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the geometric structures of deep neural
  networks for multi-label classification (M-lab) learning. While previous work has
  analyzed neural collapse in multi-class classification, the authors generalize this
  analysis to the multi-label setting.
---

# Neural Collapse in Multi-label Learning with Pick-all-label Loss

## Quick Facts
- arXiv ID: 2310.15903
- Source URL: https://arxiv.org/abs/2310.15903
- Reference count: 40
- This paper generalizes neural collapse analysis from multi-class to multi-label classification, introducing a "pick-all-labels" (PAL) loss and establishing the M-lab NC phenomenon with tag-wise average properties.

## Executive Summary
This paper investigates the geometric structures of deep neural networks for multi-label classification (M-lab) learning. The authors define a "pick-all-labels" (PAL) loss that decomposes the multi-label problem into several multi-class problems, and study the global optimality and landscape properties of this loss under an unconstrained feature model (UFM). They establish that the only global optimizer exhibits a "multi-label neural collapse" (M-lab NC) phenomenon, where features for labels with multiplicity-1 form a simplex equiangular tight frame (ETF), and features for higher multiplicity are scaled tag-wise averages of multiplicity-1 features. The optimization landscape has benign strict saddle properties, enabling efficient convergence to global solutions.

## Method Summary
The method uses a pick-all-labels (PAL) cross-entropy loss to transform multi-label classification into multiple independent multi-class problems. Under the unconstrained feature model (UFM), features are treated as optimization variables rather than network outputs. The approach involves creating synthetic multi-label datasets by combining images from different classes, training standard ResNet/VGG architectures with SGD optimization, and analyzing feature representations for neural collapse properties. The method also explores parameter-efficient training by fixing the classifier as a simplex ETF and reducing feature dimension to the number of labels.

## Key Results
- Under UFM, the only global optimizer of the PAL cross-entropy loss exhibits M-lab NC with simplex ETF geometry for multiplicity-1 features
- Higher multiplicity features follow a tag-wise average property, being scaled averages of associated multiplicity-1 feature means
- The optimization landscape has strict saddle properties, ensuring efficient convergence to global solutions
- M-lab NC is empirically observed across various network architectures and datasets, even with imbalanced higher multiplicity data

## Why This Works (Mechanism)

### Mechanism 1
The PAL decomposition transforms multi-label classification into multiple independent multi-class problems, each converging to neural collapse independently. By decomposing each multi-hot label into a sum of one-hot labels, the PAL loss allows the network to learn separate neural collapse structures for each class label within a multi-label sample. The cross-entropy loss for each one-hot component ensures that features for each class collapse to a simplex ETF structure independently.

### Mechanism 2
The tag-wise average property emerges because high multiplicity features are constrained to be scaled averages of their constituent multiplicity-1 features. For samples with multiple labels, the optimization forces the feature representation to be a convex combination of the feature means corresponding to each individual label. This averaging behavior is enforced by the PAL loss structure and the convexity of the cross-entropy loss.

### Mechanism 3
The benign optimization landscape with strict saddle properties ensures efficient convergence to the global M-lab neural collapse solution. The PAL loss under UFM creates a loss surface where all local minima are global minima exhibiting the M-lab NC structure, and all other critical points are strict saddles with negative curvature directions.

## Foundational Learning

- **Unconstrained Feature Model (UFM)**: Treats last-layer features as free optimization variables rather than functions of network parameters, allowing rigorous theoretical analysis. Quick check: How does treating features as unconstrained variables under UFM simplify the analysis of global optimality compared to analyzing the full network?

- **Simplex Equiangular Tight Frame (ETF)**: Characterizes the geometric arrangement of feature means in neural collapse, providing theoretical foundation for understanding geometric patterns and classification margins. Quick check: How does the ETF structure maximize minimum angles between class representations and what does this mean for classification performance?

- **Cross-entropy loss convexity**: The strict convexity with respect to feature representations is crucial for proving unique global solutions and establishing the tag-wise average property through first-order optimality conditions. Quick check: Why does the convexity of cross-entropy loss enable proving that high multiplicity features must be scaled averages of their constituent multiplicity-1 features?

## Architecture Onboarding

- **Component map**: Data preprocessing (multi-label creation) -> Model architecture (ResNet/VGG) -> Loss function (PAL-CE) -> Training loop (SGD) -> Evaluation (IoU metric)
- **Critical path**: 1) Data preparation: Create balanced multiplicity-1 samples, generate higher multiplicity combinations 2) Model initialization: Standard backbone with random initialization 3) Training execution: Run PAL-CE loss with SGD optimization for 200 epochs 4) Feature analysis: Extract last-layer features, compute NC metrics 5) Parameter efficiency: Fix classifier as ETF, reduce feature dimension to K
- **Design tradeoffs**: UFM assumption vs. practical networks (theoretical guarantees vs. practical deviations), feature dimension d â‰¥ K (higher flexibility vs. computational cost), balanced multiplicity-1 requirement (proper ETF formation vs. data augmentation needs)
- **Failure signatures**: NC metrics not converging to zero (failure to achieve neural collapse), high multiplicity features not following tag-wise average (optimization issues or data imbalance), poor test performance despite NC (overfitting or poor decision rule)
- **First 3 experiments**: 1) Verify M-lab NC on synthetic data: Train on balanced M-lab MNIST/CIFAR10, measure NC metrics convergence 2) Test parameter efficiency: Compare performance with fixed ETF classifier vs. learned classifier 3) Evaluate robustness to imbalance: Train with imbalanced higher multiplicity data, measure impact on NC metrics and performance

## Open Questions the Paper Calls Out

### Open Question 1
Does the multi-label neural collapse phenomenon hold when the training data is imbalanced within multiplicity-1 classes? The paper states that M-lab NC holds as long as Multiplicity-1 training samples remain balanced between classes, but does not investigate the case where Multiplicity-1 classes are imbalanced. Formal proof and empirical validation on imbalanced Multiplicity-1 classes would resolve this question.

### Open Question 2
Can the tag-wise average property of M-lab ETF be leveraged to design better regularization techniques for improving multi-label classification performance? The paper mentions that higher multiplicity features are essentially scaled tag-wise averages of associated Multiplicity-1 features, suggesting this property could be exploited for regularization. Development and empirical evaluation of such regularization techniques would resolve this question.

### Open Question 3
How does the choice of loss function beyond cross-entropy affect the M-lab neural collapse phenomenon? The paper suggests that M-lab NC can be generalized to other loss functions used for multi-class learning under the pick-all-labels framework, but does not provide formal analysis or empirical investigation. Formal proof and empirical comparison across various loss functions would resolve this question.

## Limitations
- UFM assumption may not fully capture practical network behavior and deviations from theoretical guarantees
- Balanced Multiplicity-1 requirement may be difficult to achieve in real-world datasets
- Analysis focuses on synthetic multi-label datasets rather than naturally occurring multi-label data

## Confidence
- High confidence: The empirical observation of M-lab NC phenomenon across different architectures and datasets
- Medium confidence: Theoretical guarantees under UFM with balanced data assumptions
- Low confidence: Practical applicability to severely imbalanced or naturally occurring multi-label datasets

## Next Checks
1. Test M-lab NC convergence on naturally occurring multi-label datasets (e.g., MS-COCO, Pascal VOC) to validate robustness beyond synthetic data
2. Analyze the impact of varying the feature dimension d relative to K on the tag-wise average property and overall NC metrics
3. Evaluate the performance tradeoff between parameter-efficient training (fixed ETF classifier) and full optimization across diverse multi-label datasets with varying label distributions