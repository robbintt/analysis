---
ver: rpa2
title: 'ExFake: Towards an Explainable Fake News Detection Based on Content and Social
  Context Information'
arxiv_id: '2311.10784'
source_url: https://arxiv.org/abs/2311.10784
tags:
- news
- fake
- score
- social
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents ExFake, an explainable fake news detection system
  that leverages both content and social context information. It analyzes the veracity
  of online posts by considering their content, social context (i.e., online users'
  credibility and historical behavior), and data from trusted entities like fact-checking
  websites and named entities.
---

# ExFake: Towards an Explainable Fake News Detection Based on Content and Social Context Information

## Quick Facts
- arXiv ID: 2311.10784
- Source URL: https://arxiv.org/abs/2311.10784
- Reference count: 25
- ExFake significantly outperforms baseline methods for fake news detection, achieving a macro-F1-score of 0.855

## Executive Summary
ExFake is an explainable fake news detection system that leverages both content and social context information to analyze the veracity of online posts. Unlike state-of-the-art systems, ExFake incorporates an Explainable AI (XAI) assistant to help online social network (OSN) users develop good reflexes when faced with potentially false information. The system assigns credibility scores to OSN users based on their historical sharing behavior. Experimental analysis on a real-world dataset demonstrates that ExFake significantly outperforms other baseline methods for fake news detection.

## Method Summary
The ExFake system uses a four-module approach: ExFact (similarity analysis with fact-checking data), ExSource (user credibility scoring using Bayesian average), ExEntity (similarity analysis with named entities' data), and ExDecision (neural network-based confidence scoring with explainability). The system processes Twitter posts, extracting content features and augmenting them with social context features like user credibility scores and similarity to trusted sources. The final module combines these scores into a confidence percentage and generates explanations for the classification.

## Key Results
- ExFake achieves a macro-F1-score of 0.855, significantly outperforming the best baseline score of 0.706
- The system successfully combines content and social context information for improved fake news detection
- ExFake provides explainable AI assistance to help users develop good reflexes when faced with potentially false information

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining content and social context features yields better fake news detection than using either alone.
- Mechanism: The system extracts features from the text of the post and augments them with social context features like user credibility scores and similarity to trusted sources.
- Core assumption: User credibility scores based on historical sharing behavior are reliable indicators of whether new posts are likely to be fake.
- Evidence anchors: [abstract]: "ExFake is an explainable fake news detection system based on content and context-level information."; [section]: "Unlike news content-based solutions, the social context-based approaches capture the skeptical social context of the online news..."
- Break condition: If user historical data is sparse or unreliable, the credibility score may not accurately reflect trustworthiness.

### Mechanism 2
- Claim: Using Bayesian average for credibility scoring improves over simple averaging.
- Mechanism: The Bayesian average technique weights user scores by the number of past posts, giving less influence to users with few posts.
- Core assumption: Users with more posts have more stable and reliable posting histories.
- Evidence anchors: [section]: "The idea behind the legitimacy score follows the same logic as the five-star rating system for e-commerce sites."; [section]: "The technique used for the legitimacy score is the Bayesian average."
- Break condition: If a new user posts fake news in their first few posts, the Bayesian average may not penalize them quickly enough.

### Mechanism 3
- Claim: Encapsulating text similarity and natural language inference (NLI) tasks improves detection performance.
- Mechanism: The system finds articles similar to the input post and determines the inference relationship (entailment, contradiction, neutral).
- Core assumption: The combination of similarity and inference provides more discriminative power than either alone.
- Evidence anchors: [section]: "ExFake's contribution to the fake news detection problem goes beyond the explanation provided by the system... The proposed model is the first to encapsulate the result of both text-similarity and natural language inference (NLI) tasks."; [section]: "Ex-Fact returns the average of the obtained points as the final score."
- Break condition: If the NLI model is inaccurate, the combined score may be misleading.

## Foundational Learning

- Concept: Text similarity with semantic embeddings
  - Why needed here: To find articles or posts that are semantically related to the input, providing context for classification.
  - Quick check question: How does Sentence-BERT differ from traditional TF-IDF similarity?

- Concept: Natural Language Inference (NLI)
  - Why needed here: To determine the logical relationship between the input post and trusted articles (entailment, contradiction, neutral).
  - Quick check question: What are the three possible inference relationships in NLI?

- Concept: Bayesian averaging
  - Why needed here: To compute a credibility score that accounts for the number of observations, preventing unreliable users from skewing results.
  - Quick check question: How does Bayesian averaging differ from a simple arithmetic mean?

## Architecture Onboarding

- Component map: Input post → ExFact/ExSource/ExEntity (parallel) → ExDecision → Output
- Critical path: Input post → Ex-Fact/Ex-Source/Ex-Entity (parallel) → Ex-Decision → Output
- Design tradeoffs:
  - Using continuous data flow increases accuracy but adds complexity and latency.
  - Relying on named entities requires accurate NER and a database of official accounts.
  - Bayesian averaging improves reliability but may delay penalizing new malicious users.
- Failure signatures:
  - Low confidence scores despite clear fake news: NLI or similarity models may be failing.
  - High credibility scores for known fake news spreaders: Bayesian average may not be updating fast enough.
  - No explanation returned: Ex-Decision explanation module may be failing.
- First 3 experiments:
  1. Test Ex-Fact alone on a small subset to validate text similarity and NLI accuracy.
  2. Test Ex-Source alone to ensure Bayesian average credibility scoring works as expected.
  3. Run Ex-Decision with mocked scores from the other modules to verify neural network logic and explanation generation.

## Open Questions the Paper Calls Out
1. What is the optimal threshold for determining when a user's legitimacy score becomes a reliable indicator of their tendency to spread fake news?
2. How does the performance of ExFake compare to other fake news detection systems when using different datasets or multimodal data?
3. What is the minimum number of tweets required from a user to generate a reliable legitimacy score that accurately reflects their fake news sharing history?

## Limitations
- The study is limited to Twitter data and fact-checking sources, which may not generalize to other social media platforms or information ecosystems.
- The exact hyperparameters for the neural network in the ExDecision module are not fully specified, potentially affecting reproducibility.
- The specific threshold values used for similarity scoring and credibility assessment in ExFact and ExSource modules are not clearly defined.

## Confidence
- High confidence: The overall system architecture and multi-module approach
- Medium confidence: The effectiveness of Bayesian averaging for credibility scoring
- Medium confidence: The combination of text similarity and NLI tasks for detection
- Low confidence: The generalizability of results to platforms beyond Twitter

## Next Checks
1. Implement a sensitivity analysis to test how changes in neural network hyperparameters affect detection performance.
2. Conduct cross-platform validation by testing ExFake on fake news datasets from Facebook or Reddit to assess generalizability.
3. Perform ablation studies to quantify the individual contributions of each module (ExFact, ExSource, ExEntity) to overall system performance.