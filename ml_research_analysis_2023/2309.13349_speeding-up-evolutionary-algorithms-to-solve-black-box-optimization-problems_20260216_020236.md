---
ver: rpa2
title: Speeding-up Evolutionary Algorithms to solve Black-Box Optimization Problems
arxiv_id: '2309.13349'
source_url: https://arxiv.org/abs/2309.13349
tags:
- cost
- time
- function
- evaluation
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces OPTECOT, a method to speed up population-based
  evolutionary algorithms for computationally expensive black-box optimization problems.
  OPTECOT reduces evaluation cost by using approximate objective functions of varying
  accuracies, automatically adjusting the optimal cost during the optimization process.
---

# Speeding-up Evolutionary Algorithms to solve Black-Box Optimization Problems

## Quick Facts
- arXiv ID: 2309.13349
- Source URL: https://arxiv.org/abs/2309.13349
- Reference count: 40
- Key outcome: OPTECOT achieves comparable solution quality to original objective functions in less than half the time by automatically adjusting evaluation cost during optimization

## Executive Summary
OPTECOT is a method for accelerating population-based evolutionary algorithms when optimizing computationally expensive black-box functions. It works by automatically selecting approximate objective functions of varying accuracy and cost, monitoring when the population rankings can be preserved with lower-cost approximations. The method uses variance monitoring to detect when the current approximation needs adjustment, and employs a bisection method to efficiently find the optimal evaluation cost. Experiments on four problems show OPTECOT can reduce computation time by more than 50% while maintaining solution quality.

## Method Summary
OPTECOT accelerates evolutionary algorithms by using approximate objective functions with adjustable evaluation costs. The method defines a cost-indexed parameter θ that controls both the accuracy and evaluation time of approximations. During optimization, it monitors the variance of population scores to determine when to adjust the evaluation cost. When significant variance changes are detected, OPTECOT uses a bisection search to find the lowest cost that preserves solution rankings (measured via Spearman correlation). This adaptive approach balances computational efficiency with solution quality by only using higher-cost, more accurate evaluations when necessary.

## Key Results
- OPTECOT achieves comparable solution quality to original objective functions in less than half the time
- The method is particularly effective when computational resources are limited
- Four benchmark problems demonstrate consistent time savings: symbolic regression, wind farm layout, swimmer, and Wells turbine design

## Why This Works (Mechanism)

### Mechanism 1
OPTECOT reduces evaluation cost by automatically selecting lower-cost approximations that preserve solution rankings. It uses a cost-indexed parameter θ to define approximate objective functions fc(x) and monitors ranking accuracy Ac(P) using Spearman's correlation between rankings induced by fc and the original f1. When Ac(P) exceeds threshold α, lower-cost approximations are used, allowing more evaluations within the same time budget.

### Mechanism 2
OPTECOT efficiently tracks optimal evaluation cost during execution by monitoring variance in population scores. Instead of periodic recalculations, it monitors variance of objective values across recent populations. When variance drops significantly, it indicates solutions are becoming too similar, requiring more accurate (higher-cost) approximations. High variance means lower-cost approximations suffice.

### Mechanism 3
The bisection method efficiently approximates optimal cost with minimal overhead. Rather than evaluating all possible cost values, OPTECOT uses bisection search on cost interval [0,1] to find lowest cost satisfying accuracy threshold. It evaluates only 4 cost points per adjustment using a small population sample, assuming accuracy increases monotonically with cost.

## Foundational Learning

- Concept: Spearman's rank correlation coefficient
  - Why needed here: Measures ranking preservation between approximate and original objective functions
  - Quick check question: If two solutions are ranked 1st and 2nd by both f1 and fc, what is their contribution to Spearman's correlation?

- Concept: Bisection method for optimization
  - Why needed here: Efficiently narrows down optimal cost interval without exhaustive search
  - Quick check question: How many iterations are needed to reduce an interval of length 1 to less than 0.1 using bisection?

- Concept: Concept drift detection
  - Why needed here: Variance monitoring mechanism inspired by detecting distribution changes in data streams
  - Quick check question: What statistical measure is used to determine if current variance is "significantly different" from previous variances?

## Architecture Onboarding

- Component map: Main loop -> Variance monitor -> Cost tracker -> Sample evaluator -> Accuracy calculator -> Selection mechanism

- Critical path:
  1. Evaluate population with current optimal cost
  2. Update population via selection mechanism
  3. Monitor variance changes
  4. If variance change significant and budget allows, recalculate optimal cost via bisection
  5. Repeat until convergence or budget exhausted

- Design tradeoffs:
  - Sample size vs. accuracy: Larger samples give better accuracy estimates but cost more time
  - Variance threshold vs. responsiveness: Higher thresholds reduce adjustments but may use suboptimal costs
  - Bisection depth vs. precision: More iterations find better costs but cost more time

- Failure signatures:
  - Solution quality plateaus early: May indicate variance monitoring threshold is too high
  - Runtime increases significantly: May indicate bisection is running too frequently or sample size is too large
  - No improvement over baseline: May indicate cost-parameter relationship doesn't satisfy monotonicity

- First 3 experiments:
  1. Run RBEA with original objective function to establish baseline quality-time curve
  2. Run OPTECOT on same problem with varying α values to find optimal tradeoff
  3. Test variance monitoring sensitivity by artificially varying population score variance

## Open Questions the Paper Calls Out

### Open Question 1
How effective is OPTECOT when applied to non-population-based optimization algorithms, such as reinforcement learning algorithms? The paper mentions potential adaptation for PPO but only provides initial analysis on CartPole without extensive testing on diverse non-population-based algorithms.

### Open Question 2
How can the bisection method be improved to more effectively approximate optimal cost when it is close to minimum or maximum values? The paper acknowledges this limitation but doesn't provide concrete solutions, suggesting this as potential future work.

### Open Question 3
How does OPTECOT perform in scenarios where computational budget is sufficient for convergence without approximation? The paper mentions potential "false convergence" issues but lacks empirical results comparing OPTECOT's performance to using original objective function with varying computational budgets.

## Limitations
- The relationship between cost-indexed parameter θ and actual evaluation times is described qualitatively rather than with explicit mathematical relationships
- Variance monitoring mechanism relies on detecting "significant" changes without clearly defined statistical criteria for significance
- Implementation details for the bisection method's efficiency gains depend heavily on monotonicity assumption holding in practice

## Confidence
- **High confidence**: Using cost-indexed approximations and ranking preservation via Spearman correlation is well-established and theoretically sound
- **Medium confidence**: Bisection method for finding optimal cost is standard optimization technique, but efficiency depends on monotonicity assumption
- **Low confidence**: Variance-based cost adjustment strategy is novel but lacks rigorous theoretical justification for why variance changes reliably indicate when to adjust cost parameter

## Next Checks
1. **Monotonicity validation**: Systematically test whether accuracy (Spearman correlation) increases monotonically with cost across all four benchmark problems. Document any violations and their impact on bisection performance.

2. **Variance threshold sensitivity**: Conduct ablation studies varying the variance threshold that triggers cost adjustments. Measure how this parameter affects both solution quality and runtime efficiency.

3. **Sample size scaling**: Evaluate how performance of OPTECOT scales with sample size used in bisection method. Determine minimum sample size that maintains solution quality while maximizing time savings.