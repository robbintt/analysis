---
ver: rpa2
title: 'Forecasting, capturing and activation of carbon-dioxide (CO$_2$): Integration
  of Time Series Analysis, Machine Learning, and Material Design'
arxiv_id: '2307.14374'
source_url: https://arxiv.org/abs/2307.14374
tags:
- emissions
- energy
- data
- page
- lstm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study provides a comprehensive time series analysis of daily
  industry-specific, country-wise CO2 emissions from January 2019 to February 2023.
  The research focuses on the Power, Industry, Ground Transport, Domestic Aviation,
  and International Aviation sectors in European countries and India, utilizing near-real-time
  activity data from the Carbon Monitor research initiative.
---

# Forecasting, capturing and activation of carbon-dioxide (CO$_2$): Integration of Time Series Analysis, Machine Learning, and Material Design

## Quick Facts
- arXiv ID: 2307.14374
- Source URL: https://arxiv.org/abs/2307.14374
- Reference count: 25
- Primary result: LSTM achieves R² 0.8242-0.995 for CO2 emission forecasting; scandium-based MBene materials show -3.0 to -3.5 eV CO2 binding energy

## Executive Summary
This study integrates time series analysis, machine learning, and material design to address CO2 emission forecasting and capture. Using near-real-time emissions data from the Carbon Monitor initiative, the research applies LSTM models to predict daily emissions across five sectors in European countries and India. Additionally, it proposes scandium-based MBene materials as highly efficient CO2 adsorbents, with DFT calculations showing superior binding energies compared to graphene and boron nitride.

## Method Summary
The research employs a 7-day moving averaged dataset of daily industry-specific CO2 emissions from January 2019 to February 2023, excluding 2020 pandemic data. PCA reduces dimensionality to identify dominant emission sectors. LSTM networks with three layers (50 units each) are trained to forecast emissions, with hyperparameters tuned per country-sector combination. For material design, DFT calculations using PBE with D3 dispersion predict CO2 binding energies for scandium-based MBene structures.

## Key Results
- LSTM models achieve R² values ranging from 0.8242 to 0.995 for various countries and sectors
- PCA identifies Power, Industry, and Ground Transport sectors as dominant contributors to emission variance
- Scandium-based MBene materials show CO2 binding energies of -3.0 to -3.5 eV, surpassing graphene and boron nitride affinity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PCA reduces dimensionality by projecting high-dimensional emission data onto orthogonal principal components that capture the largest variance, enabling the identification of dominant emission sectors (Power, Industry, Ground Transport).
- Mechanism: PCA computes eigenvectors of the covariance matrix from centered data. The top eigenvectors correspond to directions of maximum variance, which are then used to transform the original feature space into a lower-dimensional space while retaining most information.
- Core assumption: The covariance matrix of the centered emission data accurately represents relationships among sectors and that variance is a valid proxy for importance.
- Evidence anchors:
  - [abstract] states "The analysis reveals that the Power, Industry, and Ground Transport sectors account for a significant portion of the variance in the dataset."
  - [section] describes "PCA determines a set of orthogonal vectors, known as principal components, that capture the highest variance in the data."
  - [corpus] shows related work uses PCA for multifactor CO2 analysis, indicating community acceptance.
- Break condition: If the data contains outliers or non-linear relationships, the variance-based PCA may misrepresent sector importance.

### Mechanism 2
- Claim: LSTM networks learn temporal dependencies in emissions data by maintaining a memory cell that selectively updates and forgets information across time steps.
- Mechanism: LSTM cells use gating units (input, forget, output) that modulate the flow of information into and out of the memory cell, allowing gradients to flow backward over long sequences without vanishing, thereby capturing both short-term fluctuations and long-term trends in CO2 emissions.
- Core assumption: The sequential structure of emissions data contains learnable patterns and that the gating mechanism can distinguish relevant temporal signals from noise.
- Evidence anchors:
  - [section] explains "LSTM networks were initially introduced... to effectively address the vanishing gradient problem... and have subsequently gained popularity for modelling sequential data."
  - [section] describes gating units: "The input gate regulates the flow of relevant information into the memory cell, while the forget gate determines which information is no longer useful and should be discarded."
  - [corpus] cites similar LSTM-based forecasting studies, supporting the general applicability.
- Break condition: If emissions patterns are non-sequential or dominated by exogenous shocks, LSTM may fail to extract useful temporal features.

### Mechanism 3
- Claim: Scandium-based MBene materials adsorb CO2 more strongly than conventional graphene or boron nitride due to favorable charge transfer and electronic structure.
- Mechanism: DFT calculations show that the scandium metal center provides d-orbital states near the Fermi level, enabling strong orbital overlap with CO2's LUMO. This results in CO2 bending and bond elongation, with binding energies in the range -3.0 to -3.5 eV, surpassing traditional 2D materials.
- Core assumption: The DFT functional (PBE with D3 dispersion) adequately captures the interaction strength and that the scandium-boron/aluminum lattice can be synthesized experimentally.
- Evidence anchors:
  - [abstract] states "These materials are shown to surpass the affinity of graphene and boron nitride sheets in this regard."
  - [section] provides binding energy range "-3.0 to -3.5 eV for CO2 adsorption."
  - [section] shows "The CO2 when adsorbed... transform from linear to a non-linear moiety, and their CO bond length also increases."
- Break condition: If synthesis constraints prevent realization of the predicted stoichiometry or if the PBE functional underestimates dispersion, binding energies may be overestimated.

## Foundational Learning

- Concept: Covariance matrix computation and eigendecomposition.
  - Why needed here: PCA relies on computing the covariance matrix of the emission dataset and extracting its eigenvectors to identify principal components.
  - Quick check question: Given a centered dataset X, what is the formula for its covariance matrix used in PCA?

- Concept: Recurrent neural network gating mechanisms.
  - Why needed here: Understanding how LSTM gates (input, forget, output) control information flow is essential for tuning and interpreting the emission forecasting model.
  - Quick check question: In an LSTM cell, which gate determines how much of the previous cell state is retained versus discarded?

- Concept: Density functional theory approximations and exchange-correlation functionals.
  - Why needed here: DFT calculations use PBE functional with D3 dispersion to predict binding energies; knowing its strengths/limits is crucial for interpreting material design results.
  - Quick check question: What is the primary limitation of the PBE functional when modeling dispersion-dominated interactions?

## Architecture Onboarding

- Component map: Raw emissions data -> Outlier removal -> 7-day moving average -> PCA feature selection -> LSTM forecasting model -> DFT material screening -> Results synthesis
- Critical path: Outlier removal -> moving average smoothing -> PCA -> LSTM training -> model evaluation -> DFT validation
- Design tradeoffs: Using 7-day moving average reduces noise but may smooth out short-term policy-relevant changes; PCA may discard weak but policy-relevant sectors
- Failure signatures: High RMSE in LSTM despite low training loss (overfitting); negative binding energies in DFT (likely unstable); PCA variance ratios skewed by outliers
- First 3 experiments:
  1. Compare LSTM predictions with and without PCA feature selection to quantify dimensionality reduction benefit
  2. Vary moving average window (3, 7, 14 days) to assess sensitivity to smoothing
  3. Test alternative exchange-correlation functionals (e.g., vdW-DF) in DFT to validate binding energy robustness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the LSTM model's performance metrics change if 2020 data was included instead of excluded?
- Basis in paper: [explicit] The authors excluded 2020 data due to COVID-19 pandemic disruptions, stating "we exclude the 2020 data in order to focus on capturing and predicting the more regular and predictable emission patterns observed in other years."
- Why unresolved: The study did not test model performance with 2020 data included, so the impact of anomalous pandemic data on prediction accuracy remains unknown.
- What evidence would resolve it: Re-running the LSTM models with 2020 data included and comparing R2, RMSE, and MAE values to the current results.

### Open Question 2
- Question: What is the exact computational cost difference between System 1 and System 2 for CO2 capture simulations, and how does this affect scalability?
- Basis in paper: [inferred] The paper mentions computational complexity constraints and compares two systems (Sc18Al1B17 and Sc18Al18), but doesn't provide detailed computational cost analysis.
- Why unresolved: The study only mentions that "due to the significant computational complexity involved, we are constrained to conducting smaller-scale calculations" without quantifying the cost differences.
- What evidence would resolve it: Detailed computational time and resource usage comparisons between the two systems for similar CO2 capture simulations.

### Open Question 3
- Question: How do the proposed MBene materials perform in capturing and activating CO2 compared to other emerging 2D materials like graphene oxide or metal-organic frameworks?
- Basis in paper: [explicit] The authors state their proposed materials "show excellent stability and adsorb CO2 with higher affinity (−3.3 eV with system1 and −2.9 eV with system2) compared with graphene, boron nitride sheets and other similar two-dimensional materials."
- Why unresolved: The study doesn't provide comparative performance data against the full range of alternative CO2 capture materials currently under research.
- What evidence would resolve it: Systematic comparative studies measuring CO2 capture efficiency, binding energy, and activation potential of MBenes versus other 2D materials under identical conditions.

## Limitations

- Data Representativeness: Excluding 2020 pandemic data may bias long-term trend predictions, and 7-day moving average may smooth out policy-relevant short-term fluctuations
- Model Generalizability: High R² values are reported per country-sector without cross-validation across different temporal periods or external datasets
- Material Synthesis Feasibility: DFT predictions don't address experimental synthesis challenges or stability under real-world operating conditions

## Confidence

- High Confidence: LSTM forecasting methodology and PCA dimensionality reduction - well-established techniques with extensive validation
- Medium Confidence: CO2 binding energy predictions for scandium-based materials - DFT calculations are sound but synthesis feasibility remains unverified
- Low Confidence: Sector variance attribution through PCA - assumes variance correlates with policy relevance without validation

## Next Checks

1. **Temporal Validation**: Re-train LSTM models excluding different years (e.g., 2019 or 2021) instead of 2020 to test model sensitivity to temporal training data selection

2. **Material Synthesis Pathway**: Conduct experimental synthesis trials of scandium-boron/aluminum thin films to verify predicted binding energies are achievable

3. **Alternative Model Comparison**: Implement and compare forecasting results with ARIMA and Prophet models on the same preprocessed dataset to quantify LSTM's consistent performance advantage