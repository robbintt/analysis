---
ver: rpa2
title: A Causal Framework to Unify Common Domain Generalization Approaches
arxiv_id: '2307.06825'
source_url: https://arxiv.org/abs/2307.06825
tags:
- domain
- prediction
- domains
- generalization
- factors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a causal framework for domain generalization
  (DG) that unifies common DG approaches. The authors introduce a data generation
  model (CLD) with latent variables representing core and non-core factors, and show
  that optimal domain generalization requires causal-invariant/faithful prediction
  and coverage of core factors in the source domain.
---

# A Causal Framework to Unify Common Domain Generalization Approaches

## Quick Facts
- arXiv ID: 2307.06825
- Source URL: https://arxiv.org/abs/2307.06825
- Reference count: 40
- One-line primary result: Proposes a causal framework unifying domain generalization approaches through causal-invariant/faithful prediction and coverage of core factors

## Executive Summary
This paper introduces a causal framework for domain generalization (DG) that unifies various common approaches. The authors propose a data generation model called Causal Latent Decomposition (CLD) with latent variables representing core and non-core factors. They establish that optimal domain generalization requires two conditions: causal-invariant/faithful prediction and adequate coverage of core factors in source domains. The framework systematically analyzes multiple DG methods as different ways to achieve these conditions, providing a unified perspective that highlights the key ideas behind different approaches and their relative strengths and limitations.

## Method Summary
The framework is built on a Causal Latent Decomposition (CLD) model that generates data through latent core factors (X_c) and non-core factors (X_n). The method involves training prediction models that either achieve causal-invariant prediction (CIP) by ensuring predictions depend only on core factors, or causal-faithful prediction (CFP) by ensuring predictions are faithful to the underlying causal mechanisms. For single-source DG, methods like SD and RSC create contrastive pairs to enforce CIP. For multi-source DG, methods like V-REx use risk matching across domains. The framework also includes feature disentanglement approaches that explicitly separate core and non-core factors during training.

## Key Results
- Optimal domain generalization requires both causal-invariant/faithful prediction and coverage of core factors in source domains
- Different DG methods (contrastive pairs, risk matching, feature disentanglement) can be unified under this causal framework
- Single-source methods require contrastive pairs for CIP, while multi-source methods can use risk/gradient matching
- Feature disentanglement methods address novel combinations of factors by explicitly separating core and non-core factors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causal-invariant prediction (CIP) enables optimal domain generalization by ensuring predictions depend only on core factors, not spurious non-core factors
- Mechanism: By enforcing invariance of predictions to changes in non-core factors while core factors remain fixed, the model learns to filter out spurious correlations that vary across domains
- Core assumption: The causal relationships between core factors and labels are invariant across domains (CIG assumption)
- Evidence anchors: [abstract] "optimal domain generalization requires causal-invariant/faithful prediction and coverage of core factors in the source domain"; [section 2.1] "The causal mechanisms that generate X and Y are assumed to be invariant across domains [16, 62, 39]"

### Mechanism 2
- Claim: Feature disentanglement separates core and non-core factors, enabling models to handle novel combinations of factors in target domains
- Mechanism: By learning representations that explicitly separate core factors from non-core factors, the model can generalize to new domains that contain different combinations of these factors
- Core assumption: The latent variables X_c and X_n can be effectively disentangled in the learned feature space
- Evidence anchors: [section 6.3] "Feature disentanglement methods aim to separate core and non-core factors during training"

### Mechanism 3
- Claim: Risk matching across multiple domains enforces causal-invariant prediction by ensuring consistent cross-entropy losses
- Mechanism: By matching the losses across different source domains, the model is encouraged to learn representations that perform equally well regardless of domain-specific variations in non-core factors
- Core assumption: The loss invariance implies causal-invariant prediction (Proposition 3)
- Evidence anchors: [section 5.2] "Proposition 3. Let ˆPθ be a prediction model for a CLD2 family... If ˆPθ is causal-invariant, then ℓP d1( ˆPθ) = ℓP d2( ˆPθ)"

## Foundational Learning

- Concept: Causal Latent Decomposition (CLD) model
  - Why needed here: Provides the theoretical foundation for understanding domain generalization as a causal inference problem
  - Quick check question: What are the three distributions that need to be specified to ground the CLD model?

- Concept: Causal-invariant prediction vs causal-faithful prediction
  - Why needed here: These are the two key conditions for optimal domain generalization
  - Quick check question: What is the key difference between causal-invariant and causal-faithful prediction?

- Concept: Domain shift and spurious correlations
  - Why needed here: Explains why standard supervised learning fails in domain generalization scenarios
  - Quick check question: What are the two types of domain shift mentioned in the paper?

## Architecture Onboarding

- Component map: Data generation model (CLD) with latent variables X_c (core), X_n (non-core), input X, label Y → Prediction model: Feature extractor f_φ and classification head g_w → Fused model: Combines prediction model with P*(X|X_c, X_n) to analyze dependence on latent factors
- Critical path: Source domain data → CLD modeling → Prediction model training with CIP/CFP constraints → Optimal generalization to target domains
- Design tradeoffs:
  - Single-source vs multi-source DG: Single-source requires contrastive pairs for CIP, multi-source can use risk/gradient matching
  - CIP vs CFP: CIP ensures predictions are invariant to non-core factors, CFP ensures predictions depend only on core factors
  - Feature matching vs logit matching: Different approaches to enforce CIP with contrastive pairs
- Failure signatures:
  - Poor performance on target domains despite good source domain performance indicates reliance on spurious correlations
  - High variance in losses across domains suggests lack of causal-invariant prediction
  - Inability to disentangle core and non-core factors indicates feature disentanglement methods are needed
- First 3 experiments:
  1. Train baseline ERM model on source domain and measure performance drop on target domain
  2. Implement and compare single-source CIP methods (SD, RSC) with contrastive pairs
  3. Implement multi-source risk matching (V-REx) and compare with baseline on multiple source domains

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we effectively create contrastive pairs that cover a wide range of core and non-core factors in single-source domain generalization?
- Basis in paper: [explicit] The paper discusses the importance of contrastive pairs for achieving causal-invariant prediction and mentions that their effectiveness depends on the coverage of core and non-core factors. It also notes that further research in this direction is warranted.
- Why unresolved: Creating contrastive pairs that adequately represent the diverse factors in real-world data is challenging. The paper provides some examples of pair creation methods but does not offer a comprehensive solution.
- What evidence would resolve it: Empirical studies comparing different contrastive pair creation methods on various datasets, demonstrating the impact of pair coverage on domain generalization performance.

### Open Question 2
- Question: What are the theoretical conditions for optimal domain generalization when the causal-invariant generation (CIG) assumption does not hold?
- Basis in paper: [inferred] The paper establishes conditions for optimal domain generalization under the CIG assumption. However, it does not address the case where this assumption is violated, which is common in real-world scenarios.
- Why unresolved: The CIG assumption simplifies the analysis but may not always be realistic. Extending the framework to more general cases would require new theoretical insights.
- What evidence would resolve it: Theoretical work deriving conditions for optimal domain generalization without the CIG assumption, potentially involving alternative assumptions or frameworks.

### Open Question 3
- Question: How can we develop more effective methods for achieving approximately causal-invariant prediction (PCIP) in single-source domain generalization?
- Basis in paper: [explicit] The paper introduces the concept of PCIP and mentions some methods like SD and RSC that aim to achieve it. However, it acknowledges that these methods are not perfect and that further research is needed.
- Why unresolved: Achieving PCIP is crucial for domain generalization, but current methods have limitations. Developing more effective techniques requires a deeper understanding of the problem and new algorithmic approaches.
- What evidence would resolve it: Empirical studies comparing various PCIP methods on diverse datasets, along with theoretical analysis of their strengths and weaknesses. New methods that outperform existing ones would also be valuable.

## Limitations
- The framework relies heavily on the validity of the causal invariance across domains (CIG) assumption, which is difficult to verify empirically
- Assumes source domains adequately cover the core factor space, which may not hold in practice
- The effectiveness of different DG methods depends on specific data generation processes and relationships between core and non-core factors
- Limited empirical validation across diverse datasets and real-world scenarios

## Confidence

- **High confidence**: The core claim that optimal domain generalization requires causal-invariant/faithful prediction and coverage of core factors. This follows directly from the theoretical framework and is supported by the analysis of multiple DG methods.
- **Medium confidence**: The claim that different DG methods can be unified under this causal framework. While the paper provides a systematic analysis, the empirical validation is limited to specific datasets and methods.
- **Medium confidence**: The claim that CIP is sufficient for optimal domain generalization. This assumes the CIG assumption holds, which may not always be true in real-world scenarios.

## Next Checks
1. **Assumption Validation**: Design experiments to empirically test the CIG assumption (causal invariance across domains) on real-world datasets where ground truth core factors are partially known.
2. **Coverage Analysis**: Quantitatively measure the coverage of core factors in source domains and correlate this with domain generalization performance across different methods.
3. **Method Comparison**: Implement and compare multiple DG methods (both CIP and CFP approaches) on diverse datasets with varying degrees of domain shift and latent factor structures to validate the framework's predictions about method effectiveness.