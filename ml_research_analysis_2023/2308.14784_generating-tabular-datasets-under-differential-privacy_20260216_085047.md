---
ver: rpa2
title: Generating tabular datasets under differential privacy
arxiv_id: '2308.14784'
source_url: https://arxiv.org/abs/2308.14784
tags:
- data
- privacy
- tabular
- diffusion
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of generating high-fidelity synthetic
  tabular datasets under differential privacy (DP) constraints. The core method involves
  developing TableDiffusion, a novel differentially-private diffusion model tailored
  for mixed-type tabular data, which predicts added Gaussian noise instead of directly
  denoising the data.
---

# Generating tabular datasets under differential privacy

## Quick Facts
- arXiv ID: 2308.14784
- Source URL: https://arxiv.org/abs/2308.14784
- Reference count: 0
- This paper develops TableDiffusion, a novel differentially-private diffusion model for mixed-type tabular data that outperforms state-of-the-art GAN-based approaches across multiple datasets and privacy levels.

## Executive Summary
This paper introduces TableDiffusion, a differentially-private diffusion model for generating high-fidelity synthetic tabular datasets. By predicting and subtracting added Gaussian noise instead of directly denoising the data, TableDiffusion achieves superior performance compared to existing GAN-based approaches while maintaining strict differential privacy guarantees. The method demonstrates remarkable data efficiency by reusing each batch through the diffusion process, enabling it to learn effectively even under tight privacy budgets. Extensive experiments on UCI Adult and Kaggle Cardio datasets show that TableDiffusion consistently outperforms competitors in both joint and marginal distribution fidelity, with particular advantages in stability and privacy efficiency.

## Method Summary
TableDiffusion is a novel diffusion model that predicts added Gaussian noise rather than directly denoising tabular data. The model preprocesses mixed-type tabular data into a homogeneous vector space, then uses a neural network to estimate the noise component added at each diffusion step. During training, the model is trained under DP-SGD with a cosine noise schedule, and each batch is reused through T different noise levels, effectively multiplying the data efficiency by T without increasing privacy cost. The reverse diffusion process then generates synthetic data by iteratively denoising from pure noise. The method is compared against leading GAN-based approaches (DP-WGAN, DP-auto-GAN, PATE-GAN) and CTGAN baseline across two real-world datasets and multiple privacy budgets.

## Key Results
- TableDiffusion consistently outperforms state-of-the-art GAN-based approaches across multiple datasets and privacy levels
- The model achieves superior joint and marginal distribution fidelity, with higher α-precision and β-recall scores
- TableDiffusion demonstrates greater stability with lower variance and often matches or exceeds unprivatised CTGAN performance even under strict privacy budgets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TableDiffusion predicts added Gaussian noise instead of directly denoising tabular data, which simplifies the learning task for neural networks.
- Mechanism: The model is trained to estimate the noise component that was added at each diffusion step, rather than reconstructing the full complex tabular distribution. This transforms the difficult problem of generating mixed-type data into the easier problem of predicting Gaussian noise.
- Core assumption: Neural networks can more easily model Gaussian noise distributions than heterogeneous, multi-modal tabular data distributions.
- Evidence anchors:
  - [abstract]: "By implementing TableDiffusion to predict and subtract the added noise instead of directly denoising the data, we enabled it to bypass the challenges of reconstructing mixed-type tabular data."
  - [section 5.4]: "The noise predictor variant (TableDiffusion) is trained to estimate the noise added to the data at step t of the diffusion process."
- Break condition: If the tabular data contains extreme outliers or very high-cardinality categorical features, the Gaussian noise assumption may break down, leading to reconstruction artifacts.

### Mechanism 2
- Claim: Diffusion models reuse each batch of data T times through the diffusion process, giving them T times more data efficiency without increasing privacy cost.
- Mechanism: Each training batch is noised at T different levels, creating T distinct augmented samples from the same batch. This iterative augmentation allows the model to learn from each batch more thoroughly.
- Core assumption: The privacy budget consumption is determined by the number of training steps, not the number of augmented samples derived from each step.
- Evidence anchors:
  - [section 5.4]: "Unlike GAN-based and VAE-based models, this effectively gives the diffusion model T times more data to learn from, without affecting the privacy budget."
  - [section 6.8.3]: Describes the iterative denoising process where the model predicts noise at each step.
- Break condition: If the noise schedule is poorly chosen or the number of steps T is too large, the augmented samples may become too noisy to be useful, reducing the benefit of this data efficiency.

### Mechanism 3
- Claim: Diffusion models produce more stable training than GANs under DP-SGD because the noise injection in DP-SGD acts as regularisation rather than destabilisation.
- Mechanism: The gradient clipping and noise addition in DP-SGD are designed to obfuscate sensitive information. For diffusion models, which are already predicting noise, this additional noise becomes part of the regularisation process rather than a disruptive force.
- Core assumption: The noise structure in diffusion models is compatible with the noise structure in DP-SGD, making them complementary rather than conflicting.
- Evidence anchors:
  - [abstract]: "The diffusion paradigm appears to be vastly more data-efficient and privacy-efficient than the adversarial paradigm, due to the augmented re-use of each batch, the smoother gradient updates, and increased resilience to sparse representations."
  - [section 7.5]: "The gradient clipping and noise addition appear to destabilise GANs easily, but act almost like a regularisation constraint for the diffusion models."
- Break condition: If the privacy budget is extremely tight (very small epsilon), even the diffusion model's stability may break down as the noise injection becomes too aggressive.

## Foundational Learning

- Differential Privacy (DP): Why needed here: The paper's core contribution is generating synthetic tabular data under strict privacy constraints, which requires understanding how DP works and how to implement it with neural networks.
  - Quick check question: What is the main difference between (epsilon, delta)-DP and (alpha, epsilon)-RDP formulations?

- Generative Adversarial Networks (GANs): Why needed here: The paper benchmarks TableDiffusion against state-of-the-art GAN-based approaches, requiring understanding of GAN architecture, training instability, and mode collapse issues.
  - Quick check question: Why do GANs suffer from mode collapse, and how does this specifically affect tabular data generation?

- Diffusion Models: Why needed here: TableDiffusion is a novel diffusion model, so understanding the forward and reverse diffusion processes, noise schedules, and sampling mechanisms is essential.
  - Quick check question: What is the key difference between predicting noise versus predicting denoised data in diffusion models?

## Architecture Onboarding

- Component map: Data preprocessing -> Noise prediction training under DP-SGD -> Synthetic data generation via reverse diffusion
- Critical path: Data preprocessing → Noise prediction training under DP-SGD → Synthetic data generation via reverse diffusion
- Design tradeoffs: Using noise prediction simplifies learning but requires careful noise scheduling; using fewer diffusion steps speeds sampling but may reduce fidelity; using DP-SGD ensures privacy but adds training complexity
- Failure signatures: Mode collapse in denoising variant, invented outlier values in multi-modal distributions, unstable training loss curves, rapid privacy budget depletion
- First 3 experiments:
  1. Train TableDiffusion on a simple tabular dataset (e.g., UCI Adult) with epsilon=1.0 and compare marginal distributions to real data.
  2. Compare noise-predicting vs denoising variants on the same dataset to observe performance differences.
  3. Vary the number of diffusion steps T to find the optimal tradeoff between sampling speed and data fidelity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do advanced diffusion techniques like different noise schedulers, improved sampling methods, or alternative loss functions impact the fidelity and privacy efficiency of differentially-private tabular diffusion models compared to standard cosine noise scheduling?
- Basis in paper: [explicit] The paper explicitly mentions that future work could explore different approaches to tabular diffusion models, including "different schedulers, loss functions, and sampling mechanisms," and notes that they used "a single, fixed cosine noise schedule" in their experiments.
- Why unresolved: The paper only evaluated one type of noise scheduler (cosine) and did not compare it to other potential schedulers or diffusion techniques. The impact of these techniques on fidelity and privacy efficiency remains unexplored.
- What evidence would resolve it: Empirical results comparing the performance (fidelity, privacy budget consumption, training efficiency) of models using different noise schedulers, sampling methods, and loss functions against the standard cosine scheduler used in the paper.

### Open Question 2
- Question: Can end-to-end representation learning be successfully integrated with differentially-private diffusion models to improve the fidelity of synthetic tabular data without significantly impacting privacy efficiency?
- Basis in paper: [explicit] The paper implemented end-to-end attention-based models for tabular representation learning but found they were "untenable for the differentially-private version of training" due to "rapid depletion of the privacy budget." However, they also noted that "noise-predicting diffusion models enabled us to bypass the representation challenges of mixed-type tabular data," suggesting a potential avenue for combining these approaches.
- Why unresolved: The paper did not explore integrating end-to-end representation learning with diffusion models under differential privacy. The challenges and potential benefits of this integration remain unknown.
- What evidence would resolve it: Experimental results demonstrating the feasibility and performance of a model that combines end-to-end representation learning with differentially-private diffusion for tabular data synthesis, including comparisons to the current diffusion model approach.

### Open Question 3
- Question: How does the fidelity and privacy efficiency of differentially-private diffusion models for tabular data vary across datasets with different characteristics, such as varying dimensionality, data type composition, and underlying distributions?
- Basis in paper: [inferred] The paper acknowledges that future work could expand evaluations to "a greater variety of datasets" and notes that it would be "fascinating to explore" the "relative model performance under different dataset dimensionality, data type composition, and distributions."
- Why unresolved: The paper only evaluated the models on two specific datasets (UCI Adult and Kaggle Cardio). The generalizability and performance of the models across a wider range of dataset characteristics is unknown.
- What evidence would resolve it: Comprehensive benchmarking results of the differentially-private diffusion models on a diverse set of tabular datasets, including those with varying dimensionality, data type compositions (e.g., more continuous vs. categorical features), and different underlying distributions (e.g., Gaussian, power-law, multi-modal). Analysis of how these characteristics impact model performance and privacy efficiency.

## Limitations

- The evaluation framework uses only two tabular datasets, which may not capture all edge cases in real-world applications
- The privacy analysis assumes the moment accountant provides tight bounds, but recent work suggests these may be overly optimistic for certain model architectures
- The comparison with GAN-based approaches does not include the most recent transformer-based generative models that could potentially narrow the performance gap

## Confidence

- **High Confidence**: Claims about TableDiffusion's improved stability and reduced variance across runs are well-supported by the extensive experimental results (10 runs per configuration) and clear visualizations of loss curves and privacy accounting.
- **Medium Confidence**: Claims about data efficiency gains from noise prediction are plausible but rely on theoretical arguments about Gaussian noise modeling that would benefit from more empirical validation across diverse data distributions.
- **Low Confidence**: Claims about the diffusion paradigm being "vastly more data-efficient and privacy-efficient" than adversarial approaches are comparative and context-dependent, requiring validation on a broader range of datasets and privacy constraints.

## Next Checks

1. Test TableDiffusion on additional tabular datasets with different characteristics (high-cardinality categorical features, extreme outliers, different data distributions) to verify the claimed robustness across diverse real-world scenarios.

2. Independently verify the privacy bounds using alternative accounting methods (e.g., Rényi DP with different divergence orders) to ensure the reported epsilon values are not overly optimistic, particularly for the more complex transformer-based variants.

3. Evaluate TableDiffusion's performance and privacy efficiency on larger datasets (10M+ records) to determine if the claimed advantages hold at industrial scales where training time and memory become critical factors.