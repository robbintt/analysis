---
ver: rpa2
title: Monte-Carlo tree search with uncertainty propagation via optimal transport
arxiv_id: '2309.10737'
source_url: https://arxiv.org/abs/2309.10737
tags:
- value
- tree
- mean
- function
- optimal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Wasserstein Monte-Carlo Tree Search (W-MCTS),
  a novel probabilistic MCTS algorithm designed for highly stochastic and partially
  observable environments. The key innovation is modeling value and action-value nodes
  as Gaussian distributions and using Wasserstein barycenters to propagate uncertainty
  across the tree.
---

# Monte-Carlo tree search with uncertainty propagation via optimal transport

## Quick Facts
- arXiv ID: 2309.10737
- Source URL: https://arxiv.org/abs/2309.10737
- Authors: 
- Reference count: 40
- One-line primary result: W-MCTS with Thompson sampling outperforms state-of-the-art baselines in highly stochastic and partially observable environments

## Executive Summary
This paper introduces Wasserstein Monte-Carlo Tree Search (W-MCTS), a novel probabilistic MCTS algorithm that models value and action-value nodes as Gaussian distributions and uses Wasserstein barycenters with α-divergence to propagate uncertainty across the tree. The method combines Thompson sampling with a power mean backup operator, showing polynomial convergence to optimal policy. Empirical results demonstrate superior performance compared to state-of-the-art baselines, particularly in high-branching factor and partially observable environments.

## Method Summary
W-MCTS models each node in the search tree as a Gaussian distribution, with value and action-value nodes represented by their mean and standard deviation. The backup operator uses Wasserstein barycenters with α-divergence as the cost function, creating a connection to generalized mean backup operators through the power parameter p. Two sampling strategies are employed: Thompson sampling from posterior distributions and optimistic selection. The algorithm maintains polynomial convergence guarantees while effectively handling high uncertainty and partial observability through proper uncertainty quantification and propagation.

## Key Results
- W-MCTS with Thompson sampling (W-MCTS-TS) outperforms UCT, Power-UCT, DNG, and D2NG baselines on FrozenLake, NChain, RiverSwim, SixArms, Taxi, Rocksample, and Pocman environments
- W-MCTS achieves up to 28% higher discounted total reward compared to Power-UCT on the Pocman environment
- The method shows particular strength in high-branching factor problems where traditional MCTS approaches struggle with uncertainty propagation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Wasserstein barycenters with α-divergence distance propagate uncertainty more accurately than L2-Wasserstein barycenters with Euclidean distance
- Mechanism: By using α-divergence as the cost function in L1-Wasserstein barycenters, the backup operator captures asymmetric uncertainty propagation better, especially when combining with power mean operators
- Core assumption: α-divergence better captures the probabilistic structure of uncertain estimates than Euclidean distance
- Evidence anchors:
  - [abstract] "We study our novel backup operator when using a novel combination of L1-Wasserstein barycenter with α-divergence"
  - [section] "We introduce the use of α-divergence...by drawing a notable connection to the generalized mean backup operator"
  - [corpus] Weak - no direct corpus evidence comparing α-divergence to Euclidean distance in this context
- Break condition: If the Gaussian assumption breaks down or α-divergence doesn't provide better uncertainty propagation than alternatives

### Mechanism 2
- Claim: Modeling value and action-value nodes as Gaussian distributions enables proper uncertainty quantification and propagation
- Mechanism: Gaussian modeling allows the use of mean and standard deviation in backup operations, with standard deviation decreasing to zero as samples increase, converging to deterministic values
- Core assumption: The value distributions in MCTS can be reasonably approximated as Gaussian distributions
- Evidence anchors:
  - [abstract] "We adopt a probabilistic approach, modeling both value and action-value nodes as Gaussian distributions"
  - [section] "we model each node in the tree as a Gaussian distribution" and "differing from distributional RL approaches, the variances...decrease to zero"
  - [corpus] Weak - no direct corpus evidence validating Gaussian assumption for MCTS nodes
- Break condition: When value distributions are highly non-Gaussian or multi-modal, violating the approximation

### Mechanism 3
- Claim: Thompson sampling with the power mean backup operator provides polynomial convergence to optimal policy
- Mechanism: Thompson sampling samples from posterior distributions, while power mean backup (controlled by parameter p) balances exploitation and exploration, avoiding both overestimation and underestimation
- Core assumption: The multi-armed bandit problem at the root node can be analyzed to provide convergence guarantees for the full MCTS
- Evidence anchors:
  - [abstract] "We provide theoretical guarantees of asymptotic convergence to the optimal policy"
  - [section] "We further investigate the latter exploration strategy to prove the asymptotic convergence of our Wasserstein MCTS algorithm"
  - [corpus] Weak - no direct corpus evidence showing Thompson sampling + power mean convergence in MCTS
- Break condition: If the bandit problem at root node doesn't accurately represent the full tree exploration problem

## Foundational Learning

- Concept: L1-Wasserstein barycenters and α-divergence
  - Why needed here: Forms the mathematical foundation for uncertainty propagation in the backup operator
  - Quick check question: Can you explain how α-divergence differs from KL divergence and why it might be preferred for uncertainty propagation?

- Concept: Thompson sampling in multi-armed bandits
  - Why needed here: Provides the theoretical basis for action selection with uncertainty quantification
  - Quick check question: What is the key difference between Thompson sampling and UCB approaches in terms of exploration-exploitation tradeoff?

- Concept: Power mean operators and their connection to backup operators
  - Why needed here: Enables balancing between average and maximum backup operators to avoid overestimation/underestimation
  - Quick check question: How does varying the power parameter p in the power mean affect the behavior of the backup operator?

## Architecture Onboarding

- Component map:
  - Root node: V-posterior (Gaussian) with Thompson sampling or optimistic selection
  - Internal nodes: Q-posteriors (Gaussian) with power mean backup
  - Backup operator: Wasserstein barycenter with α-divergence
  - Sampling strategies: Thompson sampling and optimistic selection
  - Particle filter extension: Alternative to Gaussian assumption

- Critical path:
  1. Tree selection using sampling strategy
  2. Node expansion and simulation
  3. Backup phase using Wasserstein barycenter with power mean
  4. Root node action selection

- Design tradeoffs:
  - Gaussian assumption vs. particle filter for node modeling
  - Thompson sampling vs. optimistic selection for exploration
  - Computational cost of α-divergence vs. simpler distance measures
  - Parameter p in power mean affecting convergence speed vs. accuracy

- Failure signatures:
  - Divergence from optimal policy despite sufficient samples
  - Numerical instability in α-divergence calculations
  - Poor performance in low-stochasticity environments
  - Increased computational cost without corresponding accuracy gains

- First 3 experiments:
  1. Implement Gaussian W-MCTS with p=1 on FrozenLake to verify basic functionality
  2. Compare Thompson sampling vs. optimistic selection on NChain environment
  3. Test particle filter extension on Rocksample with non-Gaussian distributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of W-MCTS change when using distributions other than Gaussian for modeling value and action-value nodes?
- Basis in paper: [explicit] The paper mentions that their approach is not restricted to Gaussian distributions and introduces a particle filter approach that can be applied to any distribution. They state "we believe that this approach is not limited to the Gaussian assumption."
- Why unresolved: The empirical evaluation only tested Gaussian distributions. The particle filter approach is theoretically described but not empirically validated.
- What evidence would resolve it: Empirical results comparing W-MCTS performance using Gaussian vs. particle filter approaches on the same benchmark problems.

### Open Question 2
- Question: What is the impact of the power parameter p on the convergence rate and final performance of W-MCTS in highly stochastic environments?
- Basis in paper: [explicit] The paper mentions that they search for the best power mean p value for Power-UCT and W-MCTS, showing different p values in Table 5, but doesn't provide a systematic analysis of how p affects performance.
- Why unresolved: While the paper reports optimal p values for different environments, it doesn't analyze the sensitivity of performance to p or provide theoretical insights on optimal p selection.
- What evidence would resolve it: A sensitivity analysis showing W-MCTS performance across a range of p values for various environments, including analysis of convergence speed and final performance.

### Open Question 3
- Question: How does W-MCTS with Thompson sampling compare to other exploration strategies like Upper Confidence bounds for Trees (UCT) in terms of computational complexity and sample efficiency?
- Basis in paper: [explicit] The paper compares W-MCTS with Thompson sampling to W-MCTS with optimistic selection and to standard methods like UCT, but doesn't provide a detailed complexity analysis or sample efficiency comparison.
- Why unresolved: While empirical results show W-MCTS-TS outperforming baselines, the paper doesn't quantify the computational overhead or sample efficiency gains relative to simpler methods.
- What evidence would resolve it: Runtime complexity analysis and sample efficiency metrics comparing W-MCTS-TS to UCT and other baselines across multiple environments.

## Limitations

- Gaussian distribution assumption may not hold in environments with highly non-Gaussian or multi-modal value distributions
- α-divergence as cost function lacks empirical validation against simpler alternatives in this specific context
- Computational overhead of α-divergence calculations may not justify benefits in low-stochasticity environments

## Confidence

- **High confidence**: The basic framework of W-MCTS with Gaussian node modeling and Wasserstein barycenter backup is mathematically sound and well-defined
- **Medium confidence**: The connection between α-divergence and power mean operators provides a theoretical foundation for the backup operator, though empirical validation is limited
- **Low confidence**: The Gaussian assumption's validity across diverse environments and the practical benefits of α-divergence over simpler alternatives require further investigation

## Next Checks

1. **Non-Gaussian Environments Test**: Evaluate W-MCTS performance on environments known to produce non-Gaussian value distributions (e.g., highly stochastic games with multiple winning conditions) to validate the Gaussian approximation's robustness

2. **Cost Function Comparison**: Implement and compare W-MCTS variants using different cost functions (Euclidean, KL divergence, total variation) in the Wasserstein barycenter calculation to empirically assess the benefits of α-divergence

3. **Computational Overhead Analysis**: Measure and compare the computational cost of W-MCTS against standard UCT across multiple environments, correlating performance gains with additional computational requirements to determine practical efficiency trade-offs