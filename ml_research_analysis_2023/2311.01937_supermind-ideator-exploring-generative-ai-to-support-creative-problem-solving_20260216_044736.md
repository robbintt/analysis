---
ver: rpa2
title: 'Supermind Ideator: Exploring generative AI to support creative problem-solving'
arxiv_id: '2311.01937'
source_url: https://arxiv.org/abs/2311.01937
tags:
- design
- problem
- ideas
- https
- creative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Supermind Ideator is a generative AI system designed to augment
  human creativity in problem-solving by leveraging large language models (GPT 3.5).
  It employs specialized prompts, fine-tuning, and a user-friendly interface to guide
  users through creative problem-solving techniques, including "Supermind Design"
  methodology moves.
---

# Supermind Ideator: Exploring generative AI to support creative problem-solving

## Quick Facts
- arXiv ID: 2311.01937
- Source URL: https://arxiv.org/abs/2311.01937
- Reference count: 40
- One-line primary result: Early evaluations with professional consultants and designers indicate that the system effectively stimulates creative thinking and broadens problem exploration

## Executive Summary
The Supermind Ideator is a generative AI system designed to augment human creativity in problem-solving by leveraging large language models (GPT 3.5). It employs specialized prompts, fine-tuning, and a user-friendly interface to guide users through creative problem-solving techniques, including "Supermind Design" methodology moves. These moves help users explore problem spaces and generate innovative solutions by reframing problems and considering various group structures and cognitive processes. Early evaluations with professional consultants and designers indicate that the system effectively stimulates creative thinking and broadens problem exploration. Users reported that the system could significantly accelerate innovation processes and enhance team collaboration. The system's modular design allows for future expansion with additional moves and domain-specific techniques.

## Method Summary
The Supermind Ideator uses a large language model (GPT 3.5) with specialized prompts and fine-tuning on a case study corpus to generate creative ideas for problem-solving. The system features a user interface that guides users through a structured process using move sets (Explore Problem, Explore Solutions) corresponding to the double diamond design process. An API separates client-side UI logic from server-side processing, enabling extensibility for community contributions. Users interact with the system by selecting moves and providing problem statements, receiving generated ideas that can be rated and bookmarked for future reference.

## Key Results
- System effectively stimulates creative thinking and broadens problem exploration according to early evaluations
- Users reported potential for significantly accelerating innovation processes and enhancing team collaboration
- Modular API design allows for future expansion with additional moves and domain-specific techniques

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The system overcomes design fixation by generating novel, unexpected ideas that humans can use as stimuli.
- Mechanism: The LLM generates diverse ideas using prompts and fine-tuning, exposing users to novel stimuli that break habitual thinking patterns.
- Core assumption: Humans can easily distinguish useful from irrelevant ideas and use even seemingly irrelevant ones to spark further creative thinking.
- Evidence anchors:
  - [abstract]: "users can then select from these ideas or use them to stimulate even more ideas"
  - [section]: "trying to make connections between a problem and seemingly unrelated ideas is one simple technique for triggering creative ideas"
  - [corpus]: Weak evidence - the corpus mentions exploration vs fixation but doesn't directly support the mechanism claim.
- Break condition: If users cannot distinguish useful from irrelevant ideas, or if the generated ideas are too conventional to stimulate new thinking.

### Mechanism 2
- Claim: The system supports creative problem-solving by guiding users through a structured process rather than open-ended exploration.
- Mechanism: The interface provides move sets (Explore Problem, Explore Solutions) that correspond to the problem and solution phases of the double diamond design process, scaffolding user thinking.
- Core assumption: Users benefit from structured guidance when using LLMs for creative problem-solving rather than relying on open-ended prompting.
- Evidence anchors:
  - [section]: "The first two options, Explore Problems and Explore Solutions, comprise what we have called 'move sets, ' or groups of moves that focus on a specific aspect of the idea generation and refinement process"
  - [section]: "As the double diamond process suggests, however, evaluating and selecting among these possibilities is also necessary to be able to actually use the results"
  - [corpus]: Weak evidence - the corpus discusses scaffolding and workflows but doesn't directly support the structured process claim.
- Break condition: If users find the structured approach too constraining or prefer more open-ended exploration.

### Mechanism 3
- Claim: The system can be extended and improved through community-based development.
- Mechanism: The API-based architecture allows others to create new moves, combine existing moves, or build custom interfaces, enabling community-driven evolution.
- Core assumption: An open-source, API-based architecture will attract community contributions that improve the system's capabilities.
- Evidence anchors:
  - [section]: "we built an API (Application Programming Interface) to separate the client-side user interface logic from server-side processing logic"
  - [section]: "We hope that by having an extensible and open-source API for the Supermind Ideator, communities of professionals, researchers, consultants, and others could contribute to a growing collective of knowledge"
  - [corpus]: Weak evidence - the corpus mentions collective intelligence but doesn't directly support the community extension claim.
- Break condition: If the community does not engage with the open-source components or if contributions are of poor quality.

## Foundational Learning

- Concept: Large Language Models (LLMs) and their capabilities
  - Why needed here: Understanding how LLMs generate text and respond to prompts is essential for designing effective moves and interpreting system outputs.
  - Quick check question: What are the key differences between zero-shot, few-shot, and fine-tuned prompting approaches?

- Concept: Creative problem-solving methodologies (e.g., design thinking, double diamond)
  - Why needed here: The system is built around these methodologies, so understanding their phases and techniques is crucial for using the system effectively.
  - Quick check question: What are the four phases of the double diamond design process, and how do they relate to the Supermind Ideator's move sets?

- Concept: API development and integration
  - Why needed here: The system's architecture relies on a well-designed API for extensibility and community contributions.
  - Quick check question: What are the key benefits of separating client-side UI logic from server-side processing logic in an API-based system?

## Architecture Onboarding

- Component map: User Interface -> API -> LLM -> API -> User Interface
- Critical path:
  1. User selects a move and provides problem statement via UI
  2. UI sends request to API with move parameters and problem statement
  3. API formats request and sends to LLM with appropriate prompts
  4. LLM generates ideas based on prompts and problem statement
  5. API receives ideas and sends back to UI for display

- Design tradeoffs:
  - Specialized front end vs. open-ended chat interface: Specialized front end provides structure but may limit flexibility
  - Fine-tuning vs. prompt engineering: Fine-tuning provides more precise results but requires more data and resources
  - Idea evaluation methods: Simple thumbs up/down vs. more complex rating systems

- Failure signatures:
  - Poor quality or irrelevant ideas: May indicate issues with prompts, fine-tuning, or base model capabilities
  - System crashes or errors: Could be due to API communication issues, LLM service problems, or UI bugs
  - Users getting stuck or confused: Might suggest UI/UX issues or insufficient guidance in move descriptions

- First 3 experiments:
  1. Test basic move execution: Verify that each move generates relevant ideas for a given problem statement
  2. Evaluate idea quality: Have users rate the quality and relevance of ideas generated by different moves
  3. Test API extensibility: Create a new move and integrate it into the system via the API to verify the extensibility claim

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the quality of ideas generated by the Supermind Ideator be systematically evaluated and improved?
- Basis in paper: [explicit] The paper mentions that quantitative evaluations of factors such as the user experience and the speed and quality of ideas generated are currently underway.
- Why unresolved: The current system relies on user ratings and bookmarks, but lacks a systematic method for evaluating and improving the quality of generated ideas.
- What evidence would resolve it: A comprehensive evaluation framework that measures idea quality using metrics like novelty, feasibility, and relevance, along with user feedback mechanisms.

### Open Question 2
- Question: How can the Supermind Ideator be extended to support domain-specific creative problem-solving techniques?
- Basis in paper: [explicit] The paper suggests that moves can be developed for techniques such as lateral thinking or Porter's 5-forces, and that the system could be extended to other specific topic domains.
- Why unresolved: While the paper mentions the potential for domain-specific moves, it does not provide concrete examples or implementation details.
- What evidence would resolve it: A set of domain-specific moves with clear implementation guidelines and examples of their effectiveness in various problem-solving contexts.

### Open Question 3
- Question: How can the Supermind Ideator facilitate collaborative creative problem-solving among teams?
- Basis in paper: [explicit] The paper mentions the potential for sharing ratings in a group and using previous ratings to recommend items in a new situation.
- Why unresolved: The current system is designed for individual use, and the paper does not explore how it could be adapted for collaborative problem-solving.
- What evidence would resolve it: A collaborative version of the Supermind Ideator that allows multiple users to work together, share ideas, and build upon each other's contributions in real-time.

## Limitations

- Limited quantitative metrics and small sample size (n=2 professional consultants) for evaluations
- Lack of systematic testing across different problem types and comparative analysis against baseline methods
- Effectiveness of fine-tuning versus prompt engineering not empirically validated

## Confidence

**High Confidence**: The system architecture (React UI + API + LLM) is technically sound and the basic mechanism of using specialized prompts and fine-tuning to guide LLM outputs is well-established. The modular design approach for extensibility is a reasonable engineering choice.

**Medium Confidence**: The claim that structured move sets help users avoid design fixation and generate novel ideas is plausible based on existing literature about scaffolding and workflows, but direct evidence from this specific system is limited. The user experience feedback suggesting the system stimulates creative thinking is positive but based on minimal user testing.

**Low Confidence**: The claims about community-driven extension and the system's ability to significantly accelerate innovation processes lack supporting evidence. There's no data on actual adoption, contribution rates, or longitudinal impact on innovation timelines.

## Next Checks

1. **Move Effectiveness Testing**: Conduct a controlled study comparing idea quality and novelty generated by each move type across different problem domains, using both qualitative ratings and quantitative metrics like idea diversity scores.

2. **Comparative Performance Analysis**: Test the system against baseline methods (standard ChatGPT, traditional brainstorming) on standardized creative problem-solving tasks, measuring both the quantity and quality of ideas generated.

3. **Long-term Impact Evaluation**: Track a cohort of teams using Supermind Ideator over multiple projects to measure actual changes in innovation cycle times, team collaboration patterns, and the practical implementation rate of generated ideas.