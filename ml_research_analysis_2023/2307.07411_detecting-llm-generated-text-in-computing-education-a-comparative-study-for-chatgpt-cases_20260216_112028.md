---
ver: rpa2
title: 'Detecting LLM-Generated Text in Computing Education: A Comparative Study for
  ChatGPT Cases'
arxiv_id: '2307.07411'
source_url: https://arxiv.org/abs/2307.07411
tags:
- detectors
- text
- llm-generated
- detector
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates eight publicly available LLM-generated text
  detectors using 164 student submissions (124 human-written and 40 ChatGPT-generated).
  The detectors were assessed on accuracy, false positives, and resilience against
  paraphrasing tools.
---

# Detecting LLM-Generated Text in Computing Education: A Comparative Study for ChatGPT Cases

## Quick Facts
- arXiv ID: 2307.07411
- Source URL: https://arxiv.org/abs/2307.07411
- Authors: 
- Reference count: 40
- Primary result: Current LLM detectors require significant improvements before reliable academic integrity use

## Executive Summary
This study evaluates eight publicly available LLM-generated text detectors using 164 student submissions from upper-year undergraduate computer science courses. The detectors were assessed on accuracy, false positive rates, and resilience against paraphrasing tools. Results reveal significant performance variations among detectors, with CopyLeaks achieving the highest overall accuracy while GPTZero produced concerning false positive rates. The study concludes that current detection tools face substantial limitations, particularly with non-English languages and code, necessitating significant improvements before reliable academic integrity applications.

## Method Summary
The study evaluated eight publicly available LLM-generated text detectors using a dataset of 164 submissions (124 human-written, 40 ChatGPT-generated, 10 paraphrased by QuillBot). Detectors were configured according to their specifications and run on the complete dataset. Performance was measured through accuracy calculations, false positive counts, and resilience testing with paraphrased texts. The methodology employed ground truth comparisons and threshold-based accuracy measurements, though exact implementation details for some detectors were not fully specified.

## Key Results
- CopyLeaks achieved highest accuracy (99.12% for human text, 95% for ChatGPT text)
- GPTKit demonstrated zero false positives but lower overall accuracy
- All detectors showed reduced accuracy with non-English languages and code
- GLTR exhibited best resilience against paraphrasing tools
- GPTZero produced 52 false positives out of 114 human submissions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Detectors using perplexity-based scoring can reliably flag LLM-generated text when input length is within token limits.
- Mechanism: RoBERTa-large model calculates probability distribution of next tokens; low perplexity indicates AI generation.
- Core assumption: Input text length ≤ 510 tokens ensures accurate probability modeling.
- Evidence anchors: GPT-2 Output Detector achieves 88% accuracy at 124M parameters and 74% at 1.5B parameters for texts within limits.

### Mechanism 2
- Claim: Statistical methods detect LLM text by analyzing word frequency distributions and entropy.
- Mechanism: Compares input word ranks against GPT-2 training distribution; unusual patterns suggest AI generation.
- Core assumption: Human writing follows predictable frequency patterns different from LLM outputs.
- Evidence anchors: GLTR uses three tests: word probability, absolute rank, and entropy of predicted distribution.

### Mechanism 3
- Claim: Perplexity + burstiness metrics distinguish AI from human writing patterns.
- Mechanism: Low perplexity indicates predictable text; burstiness measures sentence length variation typical of humans.
- Core assumption: Human writing exhibits higher burstiness than LLM-generated text.
- Evidence anchors: GPTZero's original version used perplexity and burstiness measures, similar to GLTR's approach.

## Foundational Learning

- Concept: Token limits and preprocessing
  - Why needed here: Detectors have strict input constraints (e.g., 510 tokens for GPT-2, 2500 characters for most others)
  - Quick check question: What happens to detection accuracy when input exceeds the maximum token limit?

- Concept: Perplexity measurement
  - Why needed here: Core metric for most detectors to quantify text predictability
  - Quick check question: How does perplexity differ between human and AI-generated text?

- Concept: Statistical word frequency analysis
  - Why needed here: GLTR's detection mechanism relies on comparing input against language model distributions
  - Quick check question: What word frequency patterns distinguish human from AI writing?

## Architecture Onboarding

- Component map:
  - Input preprocessor (character limit enforcement, language detection) -> Detector ensemble (multiple models: RoBERTa, statistical, perplexity-based) -> Output formatter (probability conversion, highlighting, classification) -> API gateway (optional, for commercial detectors)

- Critical path:
  - Input → preprocessing → detector selection → probability calculation → classification → output

- Design tradeoffs:
  - Accuracy vs. false positives (CopyLeaks prioritizes accuracy, GPTKit prioritizes low false positives)
  - Language support vs. detection reliability (English-only detectors perform better)
  - Real-time processing vs. comprehensive analysis (API integration vs. manual copy-paste)

- Failure signatures:
  - High false positive rate (GPTZero: 52/114 human submissions flagged)
  - Low accuracy on paraphrased content (all detectors except GLTR drop significantly)
  - Language-specific failures (Spanish text yields unreliable results)

- First 3 experiments:
  1. Test detector accuracy on English text with varying lengths (50, 500, 2500 characters)
  2. Compare accuracy before/after paraphrasing with QuillBot
  3. Evaluate detector performance on non-English text (Spanish)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the limitations of current LLM-generated text detectors when applied to code and special symbols?
- Basis in paper: The paper explicitly states that all LLM-generated text detectors struggle with code, other languages, and special symbols.
- Why unresolved: The study only tested detectors on English and Spanish text submissions, not on code or text with special symbols.
- What evidence would resolve it: Testing the detectors on a dataset of code submissions and text with special symbols, and comparing their accuracy and false positive rates to the current study's results.

### Open Question 2
- Question: How can LLM-generated text detectors be improved to reduce false positives, especially in cases where human text is flagged as AI-generated?
- Basis in paper: The paper highlights concerns over GPTZero producing 52 false positives out of 114 human submissions, indicating a need for improvement in reducing false positives.
- Why unresolved: The study does not provide specific insights into how detectors can be improved to reduce false positives.
- What evidence would resolve it: Implementing and testing new techniques or algorithms in LLM-generated text detectors, and comparing their false positive rates to the current study's results.

### Open Question 3
- Question: How can LLM-generated text detectors be made more resilient to paraphrasing tools like QuillBot?
- Basis in paper: The paper demonstrates that all detectors showed reduced accuracy after the use of paraphrasing tools like QuillBot, indicating a need for improvement in resilience.
- Why unresolved: The study does not provide specific insights into how detectors can be made more resilient to paraphrasing tools.
- What evidence would resolve it: Implementing and testing new techniques or algorithms in LLM-generated text detectors, and comparing their resilience to paraphrasing tools to the current study's results.

## Limitations

- Small dataset size (164 submissions) limits generalizability across writing styles and contexts
- Computer science-specific submissions may not reflect patterns in other disciplines
- Binary classification approach oversimplifies complex real-world academic integrity scenarios

## Confidence

- High Confidence: CopyLeaks' superior accuracy (99.12% for human text, 95% for ChatGPT text) is well-supported by experimental data
- Medium Confidence: Conclusions about need for detector improvements are valid but practical implications vary by institutional context
- Low Confidence: Claims about GLTR's paraphrasing resilience require further validation due to limited testing scope

## Next Checks

1. Cross-disciplinary validation: Test the same detectors on writing samples from humanities, social sciences, and other disciplines to assess whether computer science-specific patterns influence detector performance.

2. Multi-language robustness: Evaluate detector accuracy across a broader range of languages (e.g., French, German, Chinese, Arabic) to understand the true scope of language limitations and identify whether certain detector architectures perform better across language families.

3. Mixed-generation detection: Create test datasets containing partially AI-generated text with varying proportions (25%, 50%, 75%) and multiple editing cycles to assess detector performance in realistic academic scenarios where students may use AI tools for drafting but edit extensively.