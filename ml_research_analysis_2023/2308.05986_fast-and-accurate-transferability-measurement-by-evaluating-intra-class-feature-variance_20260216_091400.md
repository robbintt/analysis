---
ver: rpa2
title: Fast and Accurate Transferability Measurement by Evaluating Intra-class Feature
  Variance
arxiv_id: '2308.05986'
source_url: https://arxiv.org/abs/2308.05986
tags:
- pre-trained
- transferability
- best
- target
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of quickly and accurately selecting
  the most useful pre-trained model for a downstream task in transfer learning. The
  core method idea is to measure transferability as the generalization ability of
  a pre-trained model on a target task by evaluating intra-class feature variance.
---

# Fast and Accurate Transferability Measurement by Evaluating Intra-class Feature Variance

## Quick Facts
- arXiv ID: 2308.05986
- Source URL: https://arxiv.org/abs/2308.05986
- Reference count: 31
- Top-5 accuracy in selecting best pre-trained models in 14 out of 17 cases

## Executive Summary
This paper proposes TMI, a method for quickly and accurately measuring transferability in transfer learning by evaluating intra-class feature variance. TMI computes transferability as the conditional entropy of target representations given labels, providing a fast alternative to retraining classifiers while still predicting fine-tuning performance. Extensive experiments across seventeen datasets with fifty supervised and eleven self-supervised pre-trained models demonstrate that TMI outperforms existing methods for selecting the top-5 best models in most cases and shows consistently better correlation with fine-tuning accuracy.

## Method Summary
TMI measures transferability as the generalization ability of a pre-trained model on a target task by computing the conditional entropy of target representations given labels. The method extracts frozen features from the pre-trained model, groups them by true label, and computes entropy for each class using a k-nearest estimator. The overall transferability score is derived from these entropy values, with lower entropy indicating better generalization and transferability. This approach avoids expensive classifier retraining while still capturing how well the pre-trained features adapt to the target task.

## Key Results
- TMI outperforms competitors for selecting top-5 best models in 14 out of 17 datasets
- TMI correctly selects the best source data in all cases
- TMI exhibits consistently better correlation than baselines in 13 out of 17 datasets

## Why This Works (Mechanism)

### Mechanism 1
- Intra-class variance measures how well a model's features generalize to a new task without retraining
- Low entropy means representations are compact within classes and discriminative between classes
- Core assumption: Pre-trained features retain meaningful structure for the target task
- Break condition: If target classes aren't well-represented in source features, ICV will be high and misleadingly suggest poor transferability

### Mechanism 2
- Conditional entropy avoids expensive classifier retraining while predicting fine-tuning performance
- By computing entropy directly from frozen features and labels, TMI sidesteps the need to train optimal classifiers
- Core assumption: The frozen feature extractor captures enough task-relevant information
- Break condition: If the pre-trained feature extractor is too domain-specific, frozen features may lose task-relevant structure

### Mechanism 3
- Conditional entropy is a lower bound of other metric learning objectives, making it robust
- The paper shows conditional entropy correlates better with fine-tuning accuracy than Contrast, Center, SNCA, and MS methods
- Core assumption: All reasonable intra-class variance measures should correlate with generalization
- Break condition: If the dataset has very few samples per class, nearest-neighbor entropy estimation becomes unreliable

## Foundational Learning

- Concept: Transfer learning and fine-tuning
  - Why needed here: TMI estimates how well a pre-trained model will perform after fine-tuning
  - Quick check question: What is the difference between feature extraction and fine-tuning in transfer learning?

- Concept: Conditional entropy and mutual information
  - Why needed here: TMI uses conditional entropy of representations given labels as a proxy for intra-class variance
  - Quick check question: How does conditional entropy differ from mutual information in measuring dependence?

- Concept: Metric learning and intra-class variance
  - Why needed here: TMI's core idea is to measure intra-class compactness and inter-class separation
  - Quick check question: What is the relationship between intra-class variance and the ability of a model to generalize?

## Architecture Onboarding

- Component map: Pre-trained model -> Forward pass -> Feature extraction -> Group by label -> Compute conditional entropy -> Transferability score

- Critical path:
  1. Load pre-trained model (supervised or self-supervised)
  2. Run forward pass on target data to get features
  3. Group features by true label
  4. Compute conditional entropy for each class
  5. Aggregate to get overall transferability score

- Design tradeoffs:
  - Speed vs accuracy: Using conditional entropy is fast but relies on nearest-neighbor estimation, which can be noisy with small datasets
  - Generality vs specificity: TMI works for supervised and self-supervised models but may not capture task-specific nuances

- Failure signatures:
  - Low correlation between TMI scores and actual fine-tuning accuracy
  - High variance in transferability scores across repeated runs
  - TMI favors models that are too general or too domain-specific

- First 3 experiments:
  1. Compare TMI scores with actual fine-tuning accuracy on a small dataset to validate correlation
  2. Test TMI on a self-supervised model to confirm generality
  3. Vary the number of neighbors (nk) in entropy estimation to see sensitivity and stability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method's performance scale with increasingly complex or diverse datasets, particularly those with high intra-class variance or multi-modal distributions?
- Basis in paper: The paper demonstrates effectiveness on 17 datasets but lacks analysis of performance trends across varying dataset complexities
- Why unresolved: Aggregate performance metrics are provided but dataset-specific properties impacting transferability measurement accuracy are not examined
- What evidence would resolve it: Systematic experiments varying dataset complexity metrics and measuring corresponding changes in TMI accuracy would clarify this

### Open Question 2
- Question: What is the theoretical relationship between conditional entropy-based intra-class variance and the actual fine-tuning performance in transfer learning?
- Basis in paper: The paper uses conditional entropy to measure intra-class variance but provides no mathematical derivation of its direct correlation to fine-tuning performance
- Why unresolved: While empirical results show correlation, there is no formal theoretical analysis establishing bounds or guarantees
- What evidence would resolve it: A formal theoretical analysis linking conditional entropy measurements to expected fine-tuning accuracy improvements would address this gap

### Open Question 3
- Question: How does the transferability measurement method perform in scenarios with limited target domain data, particularly when only a few labeled samples are available?
- Basis in paper: The paper evaluates on datasets with standard train/test splits but does not investigate performance with scarce target data
- Why unresolved: The method's effectiveness with very small target datasets (few-shot scenarios) is not examined
- What evidence would resolve it: Experiments systematically reducing target training set size would reveal the method's limitations and potential adaptation mechanisms

## Limitations
- The conditional entropy approach relies on nearest-neighbor estimation, which can be unstable with small datasets
- The method assumes frozen pre-trained features retain sufficient task-relevant information for all target tasks
- Entropy estimation is sensitive to the choice of k-nearest neighbors parameter, though this impact is not thoroughly explored

## Confidence
- High confidence in the general approach of using intra-class variance for transferability estimation
- Medium confidence in the specific implementation details (entropy estimation method, k parameter choice)
- Medium confidence in the empirical results, given extensive experiments but limited ablation studies

## Next Checks
1. Independently implement TMI and verify the Kendall correlation coefficients with fine-tuning accuracy on at least 3 datasets
2. Apply TMI to deliberately mismatched source-target pairs to identify where the method breaks down
3. Systematically vary the number of nearest neighbors (k) in the entropy estimator and measure the stability of TMI scores across different k values