---
ver: rpa2
title: Distilling Missing Modality Knowledge from Ultrasound for Endometriosis Diagnosis
  with Magnetic Resonance Images
arxiv_id: '2307.02000'
source_url: https://arxiv.org/abs/2307.02000
tags:
- tvus
- endometriosis
- knowledge
- obliteration
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of detecting pouch of Douglas
  (POD) obliteration, a key sign of endometriosis, from magnetic resonance imaging
  (MRI). Since MRI is less accurate than transvaginal ultrasound (TVUS) for this task
  and patients typically receive only one modality, the authors propose a knowledge
  distillation approach to transfer information from a TVUS-based teacher model to
  an MRI-based student model.
---

# Distilling Missing Modality Knowledge from Ultrasound for Endometriosis Diagnosis with Magnetic Resonance Images

## Quick Facts
- arXiv ID: 2307.02000
- Source URL: https://arxiv.org/abs/2307.02000
- Authors: 
- Reference count: 0
- MRI-based POD obliteration classification AUC improved from 65.0% to 90.6% using knowledge distillation from TVUS

## Executive Summary
This paper addresses the challenge of detecting pouch of Douglas (POD) obliteration from MRI, where direct detection is less accurate than with transvaginal ultrasound (TVUS). The authors propose a knowledge distillation approach that transfers diagnostic knowledge from a TVUS-based teacher model to an MRI-based student model, even when the training data is unpaired but label-matched. The approach combines pre-training with masked auto-encoders on unlabeled MRI data and knowledge distillation to significantly improve MRI-based classification performance.

## Method Summary
The method involves three main stages: first, a teacher model (ResNet(2+1)D) is trained on TVUS data for POD obliteration classification. Second, a student model (3D Vision Transformer) is pre-trained using a masked auto-encoder on large unlabeled pelvic MRI volumes to learn anatomical representations. Finally, knowledge distillation transfers information from the teacher to the student using unpaired but label-matched TVUS and MRI data, followed by fine-tuning on labeled MRI data with a dynamically balanced loss function combining knowledge distillation and task-specific objectives.

## Key Results
- MRI-based POD obliteration classification AUC improved from 65.0% (baseline) to 90.6% with the complete approach
- Knowledge distillation alone improves AUC to 85.2% when combined with pre-training
- Pre-training with masked auto-encoder on unlabeled MRI data provides significant performance gains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The knowledge distillation approach effectively transfers diagnostic patterns from TVUS to MRI despite the modalities being unpaired.
- Mechanism: The teacher model trained on TVUS learns discriminative features for POD obliteration detection. The student model, pre-trained on unlabeled MRI volumes via a masked auto-encoder, develops robust 3D representation capabilities. During knowledge distillation, the student model learns to mimic the teacher's output patterns even though the training data is unpaired but label-matched.
- Core assumption: The feature representations learned from TVUS can be meaningfully transferred to MRI for the same diagnostic task despite domain differences.
- Evidence anchors:
  - [abstract]: "knowledge distillation training algorithm to improve the POD obliteration detection from MRI by leveraging the detection results from unpaired TVUS data"
  - [section]: "we distill the knowledge from the teacher TVUS POD obliteration detector to train the student MRI model by minimizing a regression loss that approximates the output of the student to the teacher using unpaired TVUS and MRI data"
  - [corpus]: No direct evidence in corpus papers about unpaired modality knowledge distillation for endometriosis diagnosis.
- Break condition: If the domain gap between TVUS and MRI is too large for meaningful feature transfer, or if the label-matching assumption (that same labels indicate similar pathology patterns) is invalid.

### Mechanism 2
- Claim: Pre-training the MRI model with a masked auto-encoder on large unlabeled pelvic MRI volumes improves its ability to extract relevant features for POD obliteration detection.
- Mechanism: The 3D MAE pre-training task forces the encoder to learn meaningful spatial representations by reconstructing masked patches of MRI volumes. This self-supervised learning captures the underlying structure of pelvic anatomy, which is then fine-tuned for the specific classification task.
- Core assumption: The anatomical features learned during MAE pre-training are relevant to distinguishing POD obliteration from normal anatomy.
- Evidence anchors:
  - [abstract]: "pre-trains a student model with 3D masked auto-encoder using a large amount of unlabelled pelvic 3D MRI volumes"
  - [section]: "For pre-training the MRI encoder, we explore the self-supervised masked auto-encoder (MAE) method... During pre-training, each volume is cropped into 8 × 8 × 8 patches, then 50% of the patches are randomly masked"
  - [corpus]: The corpus papers mention masked auto-encoders for brain tumor segmentation with missing modalities, but not specifically for endometriosis diagnosis.
- Break condition: If the pre-training data contains too much anatomical variation unrelated to POD obliteration, or if the reconstruction task doesn't capture the relevant diagnostic features.

### Mechanism 3
- Claim: The dynamic loss weighting (αepoch) balances the contributions of knowledge distillation and task-specific loss during fine-tuning, enabling better convergence.
- Mechanism: The loss function combines knowledge distillation loss (approximating teacher output) and task-specific cross-entropy loss. The αepoch parameter adjusts this balance dynamically during training epochs, allowing the model to first focus on distillation then gradually emphasize the MRI-specific task.
- Core assumption: A dynamic balance between distillation and task-specific objectives improves model performance compared to fixed weighting.
- Evidence anchors:
  - [section]: "ℓ(DM , Ds U; θM) =αepoch × ℓKD(DM , Ds U; θM)+ (1 − αepoch) × ℓP T M(DM; θM)"
  - [abstract]: No direct mention of dynamic loss weighting
  - [corpus]: No evidence in corpus papers about dynamic loss weighting in knowledge distillation for medical imaging.
- Break condition: If the dynamic weighting doesn't improve convergence or if the optimal αepoch value is highly sensitive to dataset characteristics.

## Foundational Learning

- Concept: Knowledge Distillation
  - Why needed here: The core innovation is transferring diagnostic knowledge from a modality (TVUS) where POD obliteration detection is easier to one (MRI) where it's more challenging, without requiring paired data.
  - Quick check question: What is the key difference between traditional knowledge distillation and the approach used in this paper?

- Concept: Masked Auto-Encoder (MAE) Pre-training
  - Why needed here: The limited labeled MRI data necessitates effective pre-training on unlabeled volumes to learn useful anatomical representations before fine-tuning on the classification task.
  - Quick check question: How does masking 50% of patches during MAE pre-training help the model learn better representations?

- Concept: Cross-Modal Knowledge Transfer
  - Why needed here: TVUS and MRI capture different aspects of the same anatomical structures, and leveraging both modalities can improve diagnostic accuracy when only one is available for testing.
  - Quick check question: What are the key challenges in transferring knowledge between TVUS and MRI modalities?

## Architecture Onboarding

- Component map: TVUS Teacher (ResNet(2+1)D) -> Unlabeled MRI Pre-training (3D MAE) -> Knowledge Distillation (3D ViT) -> Fine-tuning (3D ViT)

- Critical path: Pre-training (MAE) → TVUS Teacher Training → Knowledge Distillation → Fine-tuning

- Design tradeoffs:
  - Unpaired vs. paired training data: Using unpaired data increases dataset size but requires the label-matching assumption
  - Pre-training scale: Larger unlabeled datasets improve MAE pre-training but require more computational resources
  - Model complexity: 3D ViT provides better spatial understanding but is more computationally intensive than 3D CNNs

- Failure signatures:
  - Poor AUC despite knowledge distillation: Domain gap between TVUS and MRI may be too large
  - Overfitting on small labeled dataset: Insufficient regularization or inadequate pre-training
  - Knowledge distillation degrading performance: Incorrect label-matching or excessive domain shift

- First 3 experiments:
  1. Validate MAE pre-training improves baseline MRI classification (compare 3D ViT from scratch vs. with MAE pre-training)
  2. Test knowledge distillation with varying αepoch values to find optimal balance
  3. Evaluate the impact of different patch masking ratios (e.g., 30% vs. 50%) during MAE pre-training

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective is knowledge distillation from TVUS to MRI for other endometriosis-related diagnostic tasks beyond POD obliteration?
- Basis in paper: [explicit] The authors propose knowledge distillation for POD obliteration detection but suggest future work on weakly-supervised lesion segmentation, implying potential for broader applications.
- Why unresolved: The study only evaluates knowledge distillation on POD obliteration, so effectiveness for other tasks remains untested.
- What evidence would resolve it: Experimental results showing improved performance for additional diagnostic tasks (e.g., lesion segmentation, other endometriosis characteristics) using the same TVUS-to-MRI distillation framework.

### Open Question 2
- Question: What is the impact of domain shift between pre-training MRI datasets and clinical MRI datasets on knowledge distillation performance?
- Basis in paper: [inferred] The authors note that excessive domain shift between pre-training datasets and TVUS data may explain why knowledge distillation without fine-tuning underperforms, suggesting domain shift is a critical factor.
- Why unresolved: The study does not systematically analyze or quantify domain shift effects or test different domain adaptation strategies.
- What evidence would resolve it: Comparative experiments testing knowledge distillation with various domain adaptation techniques (e.g., domain adversarial training, feature alignment) and different pre-training dataset sources.

### Open Question 3
- Question: Can missing modality deep learning approaches outperform knowledge distillation for cross-modal endometriosis diagnosis?
- Basis in paper: [explicit] The authors propose exploring missing modality deep learning approaches in future work as an alternative to knowledge distillation.
- Why unresolved: The study only evaluates knowledge distillation and does not compare it against other missing modality learning frameworks.
- What evidence would resolve it: Direct comparison of knowledge distillation against alternative missing modality methods (e.g., generative models, cycle-consistency frameworks) on the same datasets with identical evaluation metrics.

### Open Question 4
- Question: What is the optimal balance between knowledge distillation loss and fine-tuning loss during training?
- Basis in paper: [explicit] The authors dynamically balance the two loss terms using αepoch but do not explore its optimal scheduling strategy or sensitivity.
- Why unresolved: The study uses a fixed α=0.85 without analyzing how different values or scheduling strategies affect performance.
- What evidence would resolve it: Ablation studies testing various α values and scheduling strategies (e.g., linear decay, cosine annealing) to identify optimal configurations.

## Limitations

- The approach relies on the assumption that label-matched unpaired data from different modalities share similar diagnostic patterns, which may not always hold true
- The effectiveness depends heavily on the quality and size of the unlabeled MRI dataset used for MAE pre-training
- The paper doesn't provide details about the domain gap between the pre-training data and the target task data

## Confidence

- **High Confidence**: The overall methodology combining MAE pre-training, knowledge distillation, and fine-tuning is technically sound and well-established in the literature.
- **Medium Confidence**: The specific architectural choices (3D ViT with MAE, ResNet(2+1)D for teacher) and hyperparameters (50% masking, α=0.85) are likely effective but may require tuning for different datasets.
- **Medium Confidence**: The improvement from 65.0% to 90.6% AUC is substantial, but the confidence intervals and statistical significance testing are not reported, making it difficult to assess the robustness of this improvement.

## Next Checks

1. **Domain Gap Analysis**: Conduct experiments to quantify the domain shift between TVUS and MRI data by comparing feature distributions and classification performance when training and testing on the same modality versus cross-modality.

2. **Label-Matching Validation**: Perform ablation studies to test the sensitivity of the knowledge distillation performance to different label-matching strategies, including scenarios with imperfect label correspondence.

3. **Statistical Significance Testing**: Apply paired statistical tests (e.g., McNemar's test) on the 5-fold cross-validation results to determine if the AUC improvement from 65.0% to 90.6% is statistically significant.