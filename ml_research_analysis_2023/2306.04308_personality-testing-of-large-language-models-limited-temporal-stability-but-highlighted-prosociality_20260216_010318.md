---
ver: rpa2
title: 'Personality testing of Large Language Models: Limited temporal stability,
  but highlighted prosociality'
arxiv_id: '2306.04308'
source_url: https://arxiv.org/abs/2306.04308
tags:
- personality
- gpt-3
- agreement
- chatbot
- traits
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated the temporal reliability of personality
  questionnaires applied to the GPT-3 model Davinci-003, administered on two occasions.
  Agreement in responses varied across scales, with excellent agreement for some (e.g.,
  political orientation, agentic and communal impression management) but poor agreement
  for others (e.g., HEXACO-100 scales).
---

# Personality testing of Large Language Models: Limited temporal stability, but highlighted prosociality

## Quick Facts
- arXiv ID: 2306.04308
- Source URL: https://arxiv.org/abs/2306.04308
- Reference count: 6
- GPT-3 Davinci-003 showed variable temporal reliability across personality scales, with prosocial traits most stable.

## Executive Summary
This study assessed the temporal reliability of personality questionnaires administered to GPT-3 Davinci-003 on two occasions. Agreement in responses varied dramatically across scales, with excellent consistency for some traits (political orientation, impression management) but poor agreement for others (HEXACO-100 Honesty-Humility, Negative Emotionality). For scales with acceptable agreement, GPT-3 displayed a socially desirable personality profile: above-average scores on agreeableness and altruism, below-average scores on Machiavellianism and psychopathy, and higher communal than agentic impression management. These findings reveal that GPT-3's personality responses are domain-dependent and highlight the importance of assessing AI systems' temporal consistency for ethical and practical applications.

## Method Summary
The study administered seven personality instruments (BFI-2, HEXACO-100, SD3, BIMI, SCS-R, political orientation items, and sociodemographic questions) to GPT-3 Davinci-003 via OpenAI Playground on two occasions (December 9 and 14, 2022). Fixed parameters included temperature=0.7, max_tokens=6-20, and other default settings. Temporal reliability was assessed using weighted Cohen's kappa and ICC, with personality scores compared to human normative data where ICC≥0.40.

## Key Results
- GPT-3 showed excellent agreement (ICC > 0.80) on 9 scales including political orientation and impression management
- Poor agreement (ICC < 0.40) on 8 scales including HEXACO-100 Honesty-Humility and Negative Emotionality
- For stable scales, GPT-3 scored above average on communal impression management, agreeableness, and altruism, but below average on agentic impression management, Machiavellianism, and psychopathy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-3's personality questionnaire responses are only reliable for some traits, not all.
- Mechanism: The study administered personality questionnaires twice to GPT-3 Davinci-003 and calculated intra-rater agreement via weighted Cohen's kappa and ICC. Results showed excellent agreement on scales like political orientation, agentic/communal impression management, and some BFI-2 and HEXACO-100 traits, but poor agreement on others (e.g., HEXACO-100 Honesty-Humility, Negative Emotionality).
- Core assumption: GPT-3's text generation is deterministic enough within stable parameters that repeated prompts yield consistent answers for some trait domains but not others.
- Evidence anchors:
  - [abstract] "Agreement in responses varied across scales, with excellent agreement for some... but poor agreement for others"
  - [section] "Results showed variable agreement among responses on two occasions: among 21 scales, on 9 scales agreement was excellent, on 4 it was moderate/good, on 5 it was minimal/fair, and on 3 it was rather poor."
  - [corpus] Found related papers on LLM personality instability; confirms this is a recognized phenomenon.
- Break condition: If prompts or model parameters vary, or if the model's internal state changes (e.g., fine-tuning, training data updates), agreement may degrade further.

### Mechanism 2
- Claim: GPT-3's personality profile is socially desirable, but not agentically boastful.
- Mechanism: For scales with acceptable ICC (≥0.40), mean scores were compared to human norms. GPT-3 scored above average on communal impression management, agreeableness, and altruism, but below average on agentic impression management, Machiavellianism, and psychopathy.
- Core assumption: GPT-3's training and fine-tuning encourage polite, cooperative, and non-threatening responses, especially in domains involving social norms.
- Evidence anchors:
  - [abstract] "Scales with acceptable agreement revealed a socially desirable personality profile, with above-average scores on agreeableness and altruism, and below-average scores on Machiavellianism and psychopathy."
  - [section] "Davinci-003 showed above-average scores on communal impression management... below-average scores on agentic impression management, Machiavellianism, and psychopathy compared to normative data."
  - [corpus] Weak—no direct corpus evidence for this claim; relies on study's own comparisons.
- Break condition: If prompts or scoring instructions are altered to encourage self-promotion or if the model is fine-tuned on less filtered data, agentic self-presentation may increase.

### Mechanism 3
- Claim: The stability of GPT-3's personality responses depends on trait specificity and linguistic framing.
- Mechanism: BFI-2 items ("I am someone who…") showed better agreement than HEXACO-100 items describing specific behaviors, suggesting that self-reflective framing is easier for the model to repeat than recalling or inventing specific experiences.
- Core assumption: GPT-3's internal representations handle abstract self-descriptions more consistently than concrete behavioral recall.
- Evidence anchors:
  - [section] "It could be that it was easier for the chatbot to remain consistent when instruction for responding is in the form that induces self-reflection... On the other hand, items from HEXACO-100 describe very specific everyday experiences and behaviors... which might require more improvisation."
  - [abstract] Not explicit; inferred from results discussion.
  - [corpus] Weak—no corpus support; purely interpretative.
- Break condition: If prompts are rewritten in behavioral terms or if model capabilities shift toward episodic-like recall, this pattern may change.

## Foundational Learning

- Concept: Temporal reliability (test-retest reliability) in psychological assessment
  - Why needed here: The study's core question is whether GPT-3's responses are stable over time; understanding reliability metrics is essential.
  - Quick check question: What statistical measures are used to assess agreement between two sets of ordinal ratings from the same subject?

- Concept: Personality trait models (Big Five, HEXACO, Dark Triad)
  - Why needed here: The study compares GPT-3's scores across multiple trait frameworks; knowing what each measures clarifies interpretation.
  - Quick check question: Which HEXACO trait is most inversely related to Dark Triad traits?

- Concept: Prompt engineering and model parameter effects
  - Why needed here: The study fixed parameters (temperature=0.7, etc.) and prompt design; understanding these controls is critical for reproducing or extending the study.
  - Quick check question: How does temperature setting influence variability in GPT-3's outputs?

## Architecture Onboarding

- Component map:
  GPT-3 Davinci-003 API -> OpenAI Playground -> Fixed parameters (temperature=0.7, max_tokens=6-20) -> Seven personality questionnaires -> Statistical analysis (weighted kappa, ICC) -> Comparison to human norms

- Critical path:
  1. Configure Playground with fixed parameters
  2. Administer each questionnaire on occasion 1
  3. Repeat same questionnaires on occasion 2
  4. Compute agreement metrics per scale
  5. For scales with ICC≥0.40, compute mean scores and compare to human norms

- Design tradeoffs:
  - Short max_tokens limits context but reduces variability; longer responses may introduce more inconsistency.
  - Using default parameters sacrifices control over creativity but ensures reproducibility.
  - Two testing occasions is minimal for reliability testing; more occasions would strengthen conclusions.

- Failure signatures:
  - Near-zero or negative ICCs indicate instability (e.g., Honesty-Humility).
  - Inconsistent self-description across items within the same trait domain.
  - High variability in agreement metrics across trait categories.

- First 3 experiments:
  1. Vary temperature from 0.7 to 0.3 and 1.0; observe changes in ICC for BFI-2 Agreeableness.
  2. Rewrite HEXACO-100 items in self-reflective ("I am someone who…") form; compare agreement to original.
  3. Increase testing occasions from 2 to 5; assess if ICC stabilizes over time.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does changing GPT-3's Playground parameters (temperature, top-p, etc.) systematically influence the temporal reliability of its personality questionnaire responses?
- Basis in paper: [explicit] The authors note they used default settings and suggest future studies should examine if parameter changes influence responses.
- Why unresolved: This study used only one parameter configuration (mostly defaults).
- What evidence would resolve it: Controlled experiments varying each parameter while administering the same questionnaires at multiple time points and measuring inter-rater agreement.

### Open Question 2
- Question: What is the predictive validity of GPT-3's personality scores for its actual behavioral outputs in different tasks?
- Basis in paper: [explicit] The authors state that "future studies should reveal the predictive validity of the chatbot’s scores."
- Why unresolved: The study only examined response consistency, not whether personality scores predict real-world behavior.
- What evidence would resolve it: Correlating personality scores with GPT-3's performance on tasks requiring cooperation, manipulation, etc., across multiple trials.

### Open Question 3
- Question: Does GPT-3's personality profile change significantly when prompted to adopt different personas or roles?
- Basis in paper: [explicit] The authors note that "customizing the prompts could influence the way the chatbot responses to the psychological questionnaires."
- Why unresolved: The study used a single prompt design and did not test persona variations.
- What evidence would resolve it: Administering personality questionnaires with different persona prompts and comparing the resulting profiles using statistical tests.

## Limitations
- Agreement varied dramatically across scales, with some showing excellent consistency while others were highly unstable
- Human normative comparisons were limited to scales with acceptable ICC, potentially missing important patterns
- Findings are based on a single model (GPT-3 Davinci-003) at one point in time, limiting generalizability

## Confidence
- High confidence: The methodological approach of using test-retest reliability metrics is appropriate for assessing temporal stability of personality responses.
- Medium confidence: The finding that GPT-3 shows higher communal than agentic impression management is supported by acceptable ICC values and aligns with expectations of socially desirable AI behavior.
- Low confidence: Explanations for why some traits show better agreement than others (e.g., self-reflective vs. behavioral framing) are speculative without direct experimental validation.

## Next Checks
1. Cross-model validation: Repeat the study with GPT-4, Claude, and other LLMs to determine if stability patterns are model-specific or generalizable across architectures.
2. Prompt variation experiment: Systematically vary prompt wording (self-reflective vs. behavioral) while keeping the same underlying traits to test whether framing drives agreement differences.
3. Extended temporal assessment: Increase testing occasions from 2 to 5-7 sessions over several weeks to determine if agreement improves with repeated administration or if patterns are stable over time.