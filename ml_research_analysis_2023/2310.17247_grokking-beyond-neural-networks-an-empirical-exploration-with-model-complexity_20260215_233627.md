---
ver: rpa2
title: 'Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity'
arxiv_id: '2310.17247'
source_url: https://arxiv.org/abs/2310.17247
tags:
- grokking
- complexity
- which
- neural
- regression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper demonstrates that grokking\u2014previously observed\
  \ only in neural networks\u2014occurs in various other machine learning models including\
  \ Gaussian processes, linear regression, and Bayesian neural networks. The authors\
  \ show that grokking can be induced by adding spurious dimensions to input data,\
  \ and analyze training trajectories to reveal that grokking correlates with transitions\
  \ from high-complexity to low-complexity solutions."
---

# Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity

## Quick Facts
- arXiv ID: 2310.17247
- Source URL: https://arxiv.org/abs/2310.17247
- Reference count: 40
- This paper demonstrates that grokking—previously observed only in neural networks—occurs in various other machine learning models including Gaussian processes, linear regression, and Bayesian neural networks.

## Executive Summary
This paper challenges the conventional wisdom that grokking is a neural network-specific phenomenon by demonstrating its occurrence across multiple machine learning models. The authors propose a general theory that grokking emerges from the interplay between error minimization and complexity regularization, rather than being tied to specific architectures or optimization algorithms. Through experiments with Gaussian processes, linear regression, and Bayesian neural networks, they show that grokking can be induced by adding spurious dimensions to input data and analyze training trajectories to reveal transitions from high-complexity to low-complexity solutions.

## Method Summary
The paper employs a unified approach across different model types: Gaussian processes optimized via variational evidence lower bound or exact marginal likelihood, linear regression with SGD and weight decay, and Bayesian neural networks with variational inference. The authors track training and validation accuracy alongside complexity metrics (KL divergence, weight norms) to identify grokking patterns. They introduce a "concealment" data augmentation strategy by adding spurious dimensions to algorithmic datasets, and analyze error-complexity landscapes to identify transitions between low-error high-complexity (LEHC) and low-error low-complexity (LELC) solution regions.

## Key Results
- Grokking occurs in Gaussian processes, linear regression, and Bayesian neural networks, not just neural networks
- Adding spurious dimensions to input data can induce grokking in various models
- Grokking correlates with transitions from high-complexity to low-complexity solutions during training
- The phenomenon is model-agnostic and emerges when optimization is guided by both error and complexity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Grokking emerges when optimization first finds high-accuracy but high-complexity solutions before gradually transitioning to simpler, more generalizable solutions.
- Mechanism: The model initially settles in regions of low error and high complexity (LEHC) which are readily accessible from typical initialization. Over time, regularization guides the model toward regions of low error and low complexity (LELC), causing validation accuracy to improve long after training accuracy has plateaued.
- Core assumption: The principle of parsimony holds - solutions with minimal possible complexity will generalize better.
- Evidence anchors:
  - [abstract] "grokking correlates with transitions from high-complexity to low-complexity solutions"
  - [section] "we hypothesise that the phenomenon is governed by the accessibility of certain regions in the error and complexity landscapes"
  - [corpus] Weak - corpus papers focus on neural network-specific theories rather than the complexity-driven mechanism proposed here
- Break condition: If LEHC and LELC regions are equally accessible from initialization, or if no regularization term exists to guide complexity reduction

### Mechanism 2
- Claim: Adding spurious dimensions to input data induces grokking by creating a discrepancy between accessible LEHC and LELC solutions.
- Mechanism: When uninformative features are added, LEHC solutions can exploit these dimensions while LELC solutions remain relatively sparse. This increases the relative accessibility of LEHC regions compared to LELC regions, leading to the delayed generalization pattern characteristic of grokking.
- Core assumption: The volume of solution space grows exponentially with dimensionality, making complex solutions more accessible in higher dimensions
- Evidence anchors:
  - [abstract] "we uncover a mechanism by which to induce grokking on algorithmic datasets via the addition of dimensions containing spurious information"
  - [section] "the number of LELC solutions remains relatively low as the most general solution should have no dependence on the additional components"
  - [corpus] Weak - corpus papers don't discuss dimensionality augmentation as an inducer of grokking
- Break condition: If added dimensions contain information relevant to the task, or if model architecture can perfectly separate signal from noise

### Mechanism 3
- Claim: Grokking is model-agnostic and can occur in any setting where solution search is guided by both error and complexity.
- Mechanism: The phenomenon is not specific to neural networks or particular optimization algorithms, but rather emerges from the fundamental interaction between error minimization and complexity regularization across different model types.
- Core assumption: Model selection guided by error and complexity is a universal principle across different machine learning architectures
- Evidence anchors:
  - [abstract] "grokking may be possible in any model where solution search is guided by complexity and error"
  - [section] "we demonstrate that grokking can occur with GP classification and linear regression"
  - [corpus] Weak - corpus papers primarily focus on neural network architectures, with limited discussion of non-neural models
- Break condition: If a model's complexity measure doesn't align with generalization performance, or if error minimization alone drives optimization

## Foundational Learning

- Concept: Model complexity and its relationship to generalization
  - Why needed here: Understanding grokking requires recognizing that simpler models often generalize better, and that complexity measures guide model selection
  - Quick check question: What happens to generalization performance when model complexity is minimized while maintaining low training error?

- Concept: Loss landscapes and optimization trajectories
  - Why needed here: Grokking involves transitions between different regions of the loss landscape, requiring understanding of how optimization algorithms navigate these spaces
  - Quick check question: How do different initialization points affect the accessibility of low-error, low-complexity regions during training?

- Concept: Bayesian inference and minimum description length principle
  - Why needed here: The paper uses MDL and Bayesian concepts to formalize complexity measures, which are central to understanding the proposed grokking mechanism
  - Quick check question: How does the KL divergence between variational approximation and prior relate to model complexity in Bayesian neural networks?

## Architecture Onboarding

- Component map:
  Data preprocessing -> Model implementation -> Complexity measurement -> Training loop -> Visualization

- Critical path:
  1. Load and preprocess dataset (add spurious dimensions if testing induction mechanism)
  2. Initialize model with appropriate complexity measure
  3. Train model while tracking training/validation error and complexity metrics
  4. Analyze trajectories for LEHC to LELC transitions
  5. Visualize results and identify grokking patterns

- Design tradeoffs:
  - Exact vs. approximate inference: Exact methods provide clear complexity terms but are computationally expensive; approximations are faster but may obscure complexity relationships
  - Complexity measure choice: Different measures (KL divergence, weight norms, etc.) may capture different aspects of model complexity
  - Dataset selection: Algorithmic datasets show clear grokking patterns but may not generalize to real-world data

- Failure signatures:
  - No gap between training and validation accuracy improvement (no grokking observed)
  - Complexity continuously decreasing during training (no LEHC phase)
  - Complexity increasing during training (potential overfitting without regularization)
  - Equal accessibility of LEHC and LELC regions from initialization

- First 3 experiments:
  1. Linear regression on slope classification with spurious dimensions to demonstrate grokking in simple models
  2. GP classification on parity prediction task to show grokking with exact complexity measures
  3. BNN on concealed parity task to analyze weight-space trajectories and LEHC/LELC transitions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the complexity theory of grokking generalize to non-algorithmic datasets where the principle of parsimony may not hold?
- Basis in paper: [explicit] The authors state "We believe that Assumption 1 is justified for the most common setting in which grokking occurs. Namely, algorithmic datasets."
- Why unresolved: The paper focuses primarily on algorithmic datasets and does not test the theory on non-algorithmic data where simpler solutions may not necessarily generalize better.
- What evidence would resolve it: Experiments showing grokking (or lack thereof) in non-algorithmic datasets where more complex solutions might actually generalize better than simpler ones.

### Open Question 2
- Question: What is the precise mathematical relationship between the number of spurious dimensions added via the concealment strategy and the magnitude of the grokking gap?
- Basis in paper: [explicit] The authors observe "its likely exponential trend with the degree of grokking" and note "we know that the volume of a region in an n-dimensional space decreases exponentially with an increase in n."
- Why unresolved: The authors only provide empirical correlation and speculation about the relationship, not a theoretical derivation of why the relationship is exponential.
- What evidence would resolve it: A mathematical proof or simulation showing why adding dimensions causes the grokking gap to increase exponentially, connecting the volume of weight space regions to generalization performance.

### Open Question 3
- Question: Why does the variational complexity term in GP classification not show a clear relationship with grokking, unlike the exact GP regression case?
- Basis in paper: [explicit] The authors note "we did not see a clear relationship between the KL term and grokking in GP classification" and discuss issues with the KL term when both variational parameters and hyperparameters are optimized.
- Why unresolved: The paper identifies the problem but does not provide a solution or alternative complexity measure that would work for variational GP classification.
- What evidence would resolve it: Experiments showing grokking in GP classification using either Laplace approximation (as suggested) or a modified variational approach that separates hyperparameter optimization from variational approximation optimization.

## Limitations
- The complexity measures used may not universally capture generalization capacity across all model types
- Experiments focus on algorithmic datasets which may not reflect real-world scenarios with lower signal-to-noise ratios
- The paper assumes LEHC solutions are always accessible from initialization, which may depend on specific initialization schemes

## Confidence
- **High confidence**: The empirical observation that grokking occurs in non-neural models (GP, linear regression, BNN) is well-supported by the presented experiments
- **Medium confidence**: The theoretical framework explaining grokking as transitions between LEHC and LELC regions provides a coherent narrative but requires further validation across diverse model types and datasets
- **Low confidence**: The claim that spurious dimensions universally induce grokking needs more extensive testing, as the mechanism may depend on specific dataset characteristics and model architectures

## Next Checks
1. **Dataset Diversity Test**: Replicate experiments on real-world datasets (e.g., CIFAR, MNIST) to verify if grokking patterns persist beyond algorithmic tasks, particularly examining how noise levels affect the LEHC to LELC transition
2. **Complexity Measure Cross-Validation**: Compare grokking behavior when using different complexity measures (e.g., PAC-Bayes bounds, information bottleneck) to determine if the phenomenon is robust to the choice of complexity metric
3. **Initialization Sensitivity Analysis**: Systematically vary initialization schemes across model types to map the relationship between initial accessibility of LEHC/LELC regions and the emergence of grokking behavior