---
ver: rpa2
title: Two-Step Active Learning for Instance Segmentation with Uncertainty and Diversity
  Sampling
arxiv_id: '2309.16139'
source_url: https://arxiv.org/abs/2309.16139
tags:
- learning
- segmentation
- active
- instance
- sampling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of active learning for instance
  segmentation, where the goal is to efficiently select the most informative images
  for labeling to train a high-quality instance segmentation model. The proposed method,
  TAUDIS, combines uncertainty-based sampling with diversity-based sampling at the
  instance level.
---

# Two-Step Active Learning for Instance Segmentation with Uncertainty and Diversity Sampling

## Quick Facts
- arXiv ID: 2309.16139
- Source URL: https://arxiv.org/abs/2309.16139
- Reference count: 40
- Key outcome: TAUDIS achieves a fivefold improvement in labeling efficiency compared to random sampling on the OVERHEAD dataset

## Executive Summary
This paper introduces TAUDIS, a two-step active learning algorithm for instance segmentation that combines instance-level uncertainty sampling with diversity-based sampling. The method identifies the most uncertain instances using segmentation entropy, then selects a diverse subset of these instances using a graph-based maximum set cover algorithm. Finally, images containing the most informative instances are selected for labeling using a majority vote approach. Experiments on COCO and OVERHEAD datasets demonstrate consistent performance improvements over various baseline methods.

## Method Summary
TAUDIS is a two-step active learning algorithm that first computes instance-level uncertainty scores (segmentation entropy, classification margin, and classification entropy) for all detected instances in unlabeled images. It then oversamples the most uncertain instances and applies a graph-based maximum k-set cover algorithm to select a diverse subset based on cosine similarity of region embeddings. Finally, a majority vote approach maps these selected instances back to images, prioritizing images with the most uncertain and diverse instances for labeling.

## Key Results
- TAUDIS consistently outperforms random sampling, uncertainty-based sampling, and diversity-based sampling baselines on COCO and OVERHEAD datasets
- On the OVERHEAD dataset, TAUDIS achieves a fivefold improvement in labeling efficiency compared to random sampling
- The method demonstrates the effectiveness of combining instance-level uncertainty with diversity sampling for instance segmentation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Instance-level uncertainty sampling captures objects the model struggles to classify or segment accurately.
- **Mechanism:** Computes three uncertainty metrics at the instance level—classification margin, classification entropy, and segmentation entropy—then uses the most uncertain instances as the first filter.
- **Core assumption:** Uncertainty at the instance level correlates with model learning needs and is more informative than image-level uncertainty for instance segmentation.
- **Evidence anchors:**
  - [abstract] states the algorithm "integrates uncertainty-based sampling with diversity-based sampling" and explores "numerous combinations of uncertainty metrics and aggregation methods in the context of instance segmentation."
  - [section 3.2] defines the three instance-level metrics and notes that "unlike active learning methods for image classification that rely on image-level uncertainty scores, our approach uses instance-level uncertainty measures."
  - [corpus] contains no direct evidence; corpus neighbors focus on AL in other domains (NLP, medical imaging) and do not discuss instance segmentation uncertainty metrics.

### Mechanism 2
- **Claim:** Diversity sampling removes redundancy among the most uncertain instances by selecting a representative subset.
- **Mechanism:** After oversampling uncertain instances (α×B), a graph-based maximum k-set cover algorithm selects β×B diverse instances based on cosine similarity of region embeddings.
- **Core assumption:** Cosine similarity of intermediate-layer feature embeddings reflects semantic similarity of instances, and maximizing set cover yields a diverse representative subset.
- **Evidence anchors:**
  - [section 3.3] describes building an undirected similarity graph on instance embeddings and using the distributed submodular optimization algorithm for maximum k-set cover.
  - [abstract] explains that "incorporating diversity sampling to account for the semantic diversity within the unlabeled pool is crucial" and the method "oversamples uncertain instances beyond the designated budget in the first step, and subsequently selects a diverse subset in the second step."
  - [corpus] does not provide supporting evidence; related works focus on AL for classification or semantic segmentation, not instance segmentation diversity.

### Mechanism 3
- **Claim:** Majority vote aggregation maps selected diverse instances back to images for labeling, prioritizing images with the most informative instances.
- **Mechanism:** Counts how many selected instances fall into each image, ranks images by this count, and selects the top B images for annotation.
- **Core assumption:** Images containing many uncertain and diverse instances are likely to expose the model to important, under-learned visual concepts.
- **Evidence anchors:**
  - [section 3.4] states the intuition that "images containing a large number of uncertain and diverse instances likely encompass important visual concepts that the model has yet to learn."
  - [abstract] notes that "information from individual instances needs to be aggregated into a score for image-level scoring and labeling."
  - [corpus] lacks direct evidence; no corpus neighbor discusses majority vote aggregation for instance segmentation.

## Foundational Learning

- **Concept:** Instance segmentation output space (class distribution, bounding box, dense mask per object).
  - **Why needed here:** Active learning must reason about uncertainty and diversity across these multiple output types.
  - **Quick check question:** How does segmentation entropy differ from classification entropy in capturing model uncertainty?
- **Concept:** Submodular set cover and maximum k-cover optimization.
  - **Why needed here:** Used to select a diverse subset of instances efficiently.
  - **Quick check question:** Why is the maximum k-cover problem suitable for diversity sampling in AL?
- **Concept:** Region feature embeddings from intermediate CNN layers.
  - **Why needed here:** Provide a fixed-dimensional representation for measuring instance similarity.
  - **Quick check question:** What properties should region embeddings have to be useful for diversity sampling?

## Architecture Onboarding

- **Component map:** Model training loop (Mask R-CNN/FPN backbone) -> Instance detection and embedding extraction -> Uncertainty metric computation per instance -> Similarity graph construction and maximum k-cover solver -> Majority vote image ranking and selection
- **Critical path:** Inference -> uncertainty scoring -> oversampling -> diversity selection -> majority vote -> labeling -> retraining
- **Design tradeoffs:**
  - Using instance-level vs. image-level uncertainty aggregation
  - Choosing α and β to balance oversampling and downsampling
  - Selecting similarity threshold σ for the graph
- **Failure signatures:**
  - Low diversity in selected instances -> similar embeddings or wrong σ
  - Selected images lack informative content -> majority vote overcounts trivial uncertain instances
  - High computational cost -> large TF or TC sets slow set cover
- **First 3 experiments:**
  1. Verify uncertainty metrics (CM, CE, SE) rank instances as expected on a small validation set
  2. Test graph construction with varying σ to confirm meaningful edges
  3. Run the full two-step pipeline on a tiny unlabeled set and inspect selected images for diversity and informativeness

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How would the performance of TAUDIS change if a different instance embedding layer (e.g., from the object classification branch) were used instead of the object segmentation branch?
- **Basis in paper:** [explicit] The paper states that instance embeddings are extracted from an intermediate convolutional layer, specifically the last convolutional layer in the object segmentation branch, but does not explore other layers or branches.
- **Why unresolved:** The paper does not provide empirical evidence comparing different embedding sources or justify why the segmentation branch was chosen over alternatives.
- **What evidence would resolve it:** Controlled experiments comparing TAUDIS performance using embeddings from different intermediate layers (segmentation vs. classification branches) on the same datasets.

### Open Question 2
- **Question:** Would TAUDIS maintain its performance advantage on datasets with significantly more classes or more diverse object scales than COCO and OVERHEAD?
- **Basis in paper:** [inferred] The paper evaluates TAUDIS on COCO (80 classes) and a proprietary single-class building dataset, but does not test on datasets with extreme class diversity or scale variation.
- **Why unresolved:** The experimental validation is limited to two datasets, one of which has only one class, leaving performance on more complex datasets unknown.
- **What evidence would resolve it:** Experiments applying TAUDIS to datasets with very high class diversity (e.g., LVIS) or extreme scale variation (e.g., Open Images).

### Open Question 3
- **Question:** How sensitive is TAUDIS to the choice of hyperparameters (α, β, σ), and what is the optimal strategy for setting them in different domains?
- **Basis in paper:** [explicit] The paper mentions specific values for α, β, and σ (α=2.5x, β=1-2x, σ=0.8) but does not provide sensitivity analysis or guidance on tuning them.
- **Why unresolved:** The paper uses fixed hyperparameters across datasets without exploring the impact of different settings or providing a principled approach for selection.
- **What evidence would resolve it:** Comprehensive ablation studies varying α, β, and σ across multiple datasets to identify sensitivity patterns and optimal tuning strategies.

## Limitations
- Uncertainty metrics may be noisy or dominated by object size rather than semantic difficulty
- Embedding quality and similarity threshold selection are critical but not thoroughly validated
- Majority vote aggregation may not capture true informativeness if uncertain instances are sparsely distributed

## Confidence
- **Instance-level uncertainty effectiveness:** Medium
- **Diversity sampling mechanism:** Medium
- **Majority vote aggregation:** Low

## Next Checks
1. **Uncertainty metric ablation:** Evaluate TAUDIS performance using only classification entropy vs. segmentation entropy vs. combined metrics to isolate the contribution of segmentation uncertainty.
2. **Embedding quality audit:** Visualize and cluster instance embeddings from the similarity graph to confirm that semantic diversity is captured and that σ selection meaningfully affects diversity.
3. **Majority vote sensitivity:** Compare TAUDIS to a variant that selects images based on maximum instance uncertainty rather than majority vote, to assess whether the aggregation step adds value.