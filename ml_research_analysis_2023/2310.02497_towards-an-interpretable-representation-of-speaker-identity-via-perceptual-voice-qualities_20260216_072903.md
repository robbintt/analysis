---
ver: rpa2
title: Towards an Interpretable Representation of Speaker Identity via Perceptual
  Voice Qualities
arxiv_id: '2310.02497'
source_url: https://arxiv.org/abs/2310.02497
tags:
- voice
- perceptual
- qualities
- speech
- average
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a perceptual quality-based representation of
  speaker identity that is interpretable and predictable. The authors augment the
  CAPE-V protocol with gendered perceptual qualities, creating a 7-dimensional representation.
---

# Towards an Interpretable Representation of Speaker Identity via Perceptual Voice Qualities

## Quick Facts
- arXiv ID: 2310.02497
- Source URL: https://arxiv.org/abs/2310.02497
- Reference count: 0
- Primary result: Demonstrates that perceptual voice qualities can be reliably rated by non-experts and predicted from various speech representations

## Executive Summary
This paper proposes a perceptual quality-based representation of speaker identity that is both interpretable and predictable. The authors augment the CAPE-V protocol with gendered perceptual qualities (resonance and weight), creating a 7-dimensional representation that captures the character of adult voices. They demonstrate that non-experts can rate these qualities with correlation 0.77 to expert ratings, and that random forest models can predict perceptual qualities from various speech representations with RMSE lower than inter-expert variation. This work shows the potential of perceptual qualities as a perceivable and flexible representation of speaker identity that bridges the gap between high-level demographics and low-level acoustic features.

## Method Summary
The method involves collecting audio clips and expert PQ ratings using an augmented CAPE-V protocol, gathering non-expert ratings via Amazon Mechanical Turk, and training random forest regressors on three feature sets (ComParE acoustic features, EMA physical features, HuBERT self-supervised features) to predict perceptual qualities. The approach is evaluated using correlation between non-expert and expert ratings, RMSE for predictions, and inter-rater reliability metrics.

## Key Results
- Non-experts achieve correlation 0.77 with expert ratings when rating perceptual voice qualities
- Random forest models predict perceptual qualities from speech representations with RMSE lower than inter-expert variation
- The perceptual quality-based representation provides an interpretable intermediate abstraction between demographics and acoustic features

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Non-experts can reliably rate perceptual voice qualities with correlation 0.77 to expert ratings.
- Mechanism: The perceptual qualities defined in the augmented CAPE-V protocol are inherently audible to humans without specialized training. The addition of gendered qualities (resonance and weight) provides a complete perceptual representation of voice identity that captures both pathological and gender-related voice characteristics.
- Core assumption: The perceptual qualities are sufficiently distinct and interpretable that non-experts can learn to recognize them with minimal examples.
- Evidence anchors:
  - [abstract]: "we demonstrate that these PQs are hearable by ensembles of non-experts"
  - [section]: "The results of the AMT experiments are very promising for the ability of non-experts to hear perceptual qualities. As Table 1 demonstrates, average non-expert ratings achieve a correlation 0.77 with average expert ratings"
  - [corpus]: Weak - corpus doesn't directly address non-expert rating ability
- Break condition: If the perceptual qualities are too subtle or overlapping for non-experts to distinguish, the correlation would drop below useful levels (likely below 0.6).

### Mechanism 2
- Claim: Random forest models can predict perceptual qualities from various speech representations with RMSE lower than inter-expert variation.
- Mechanism: The perceptual qualities encode information that is present in acoustic, physical, and self-supervised speech representations. Random forests can capture the non-linear relationships between these representations and the perceptual qualities.
- Core assumption: The information needed to compute perceptual qualities is embedded in the speech representations, even if not explicitly labeled.
- Evidence anchors:
  - [abstract]: "further demonstrate that the information encoded in a PQ-based representation is predictable by various speech representations"
  - [section]: "On average, all random forests across feature sets predict expert ratings with lower error than non-expert humans"
  - [corpus]: Missing - corpus doesn't provide evidence about prediction accuracy
- Break condition: If the speech representations don't contain the necessary information (e.g., EMA lacking laryngeal source information), prediction accuracy would suffer significantly.

### Mechanism 3
- Claim: Perceptual qualities provide an interpretable intermediate representation between high-level demographics and low-level acoustic features.
- Mechanism: The 7-dimensional PQ space captures voice characteristics at a level of abstraction that humans can understand and manipulate, bridging the gap between demographic labels and raw acoustic data.
- Core assumption: The chosen perceptual qualities are sufficient to describe the "character" of adult voices in a way that's both interpretable and predictive.
- Evidence anchors:
  - [abstract]: "our PQ-based approach provides a perceptual latent space of the character of adult voices that is an intermediary of abstraction between high-level demographics and low-level acoustic, physical, or learned representations"
  - [section]: "A perceptual quality-based representation of speaker identity provides two benefits currently lacking in other representations. Firstly, a perceptual quality-based representation of speaker identity is low-dimensional and interpretable"
  - [corpus]: Weak - corpus doesn't directly address the interpretability claim
- Break condition: If the perceptual qualities don't capture enough variance in voice characteristics, the representation would be incomplete and not useful as an intermediate abstraction.

## Foundational Learning

- Concept: Perceptual voice qualities and the CAPE-V protocol
  - Why needed here: The paper builds on existing speech pathology tools but extends them for general speaker identity representation. Understanding the original CAPE-V and its limitations is crucial for appreciating the augmentation.
  - Quick check question: What are the six original CAPE-V perceptual qualities, and which one is excluded in this work?

- Concept: Intra-class correlation (ICC) and inter-rater reliability
  - Why needed here: The paper uses ICC to measure agreement between raters, both for expert-to-expert and non-expert-to-expert comparisons. Understanding this metric is essential for interpreting the results.
  - Quick check question: What does an ICC of 0.77 indicate about the agreement between raters?

- Concept: Random forest regression and RMSE
  - Why needed here: The paper uses random forests to predict perceptual qualities from various speech representations and evaluates them using RMSE. Understanding these methods is crucial for interpreting the prediction results.
  - Quick check question: Why might random forests be preferred over linear models for predicting perceptual qualities from speech representations?

## Architecture Onboarding

- Component map:
  Data collection -> Non-expert rating system -> Prediction models -> Evaluation metrics

- Critical path:
  1. Collect audio clips and expert PQ ratings
  2. Have non-experts rate clips using minimal training
  3. Compute correlation between non-expert and expert ratings
  4. Train random forest models on various speech representations
  5. Evaluate prediction accuracy using RMSE

- Design tradeoffs:
  - Using random forests allows capturing non-linear relationships but sacrifices interpretability compared to simpler models
  - Augmenting CAPE-V with gendered qualities provides completeness but adds complexity to the rating task
  - Using multiple speech representations captures different aspects of voice but requires more computational resources

- Failure signatures:
  - Low correlation between non-expert and expert ratings (<0.6) suggests the PQs are not easily perceivable
  - High RMSE for predictions suggests the speech representations don't capture the necessary information
  - Poor ICC for any PQ suggests ambiguity in the quality definition

- First 3 experiments:
  1. Replicate non-expert rating experiment with a different subset of audio clips to verify consistency
  2. Train random forest models on a subset of the data to check for overfitting
  3. Compare prediction performance across different machine learning models (e.g., linear regression, neural networks) to validate random forest choice

## Open Questions the Paper Calls Out

- Can perceptual qualities be used to guide speech synthesis or voice conversion?
- To what extent can PQ-based representations uniquely identify a voice?
- What is the optimal training method for non-experts to accurately rate perceptual qualities?

## Limitations

- Inter-expert ICC scores of 0.53-0.61 indicate substantial disagreement among expert raters, serving as a ceiling for model performance
- Non-expert agreement of 0.77 with experts leaves significant room for improvement
- Evaluation focuses on prediction accuracy rather than practical utility for downstream tasks

## Confidence

- High Confidence: Non-expert rating correlation (0.77) is well-supported by AMT experiments
- Medium Confidence: Random forest prediction performance is supported but model choice justification is incomplete
- Low Confidence: Claims about PQ representation as ideal intermediate abstraction are conceptual rather than empirically validated

## Next Checks

1. Replicate non-expert rating experiment with a different subset of 50 audio clips to verify the consistency of the 0.77 correlation result
2. Compare random forest prediction performance against state-of-the-art neural network architectures on the same task
3. Conduct a downstream task evaluation where the PQ representation is used for speaker identification or voice conversion