---
ver: rpa2
title: 'PARDINUS: Weakly supervised discarding of photo-trapping empty images based
  on autoencoders'
arxiv_id: '2312.14812'
source_url: https://arxiv.org/abs/2312.14812
tags:
- images
- image
- empty
- animal
- reconstruction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents PARDINUS, a weakly supervised deep learning
  algorithm for filtering out empty images captured by photo-trapping cameras. The
  method uses autoencoders trained on empty images to reconstruct the input images,
  and a Random Forest classifier to distinguish between empty and non-empty images
  based on the reconstruction error.
---

# PARDINUS: Weakly supervised discarding of photo-trapping empty images based on autoencoders

## Quick Facts
- arXiv ID: 2312.14812
- Source URL: https://arxiv.org/abs/2312.14812
- Reference count: 40
- Primary result: Weakly supervised algorithm achieves AUC of 0.9702 and F1-score of 0.83 for filtering empty camera trap images

## Executive Summary
This paper presents PARDINUS, a weakly supervised deep learning algorithm designed to filter out empty images captured by photo-trapping cameras used in wildlife monitoring. The method leverages autoencoders trained exclusively on empty images to reconstruct input images, then uses reconstruction errors to distinguish between empty and animal-containing images through a Random Forest classifier. By avoiding the need for extensive labeled data, PARDINUS significantly reduces the manual effort required for preprocessing camera trap datasets while maintaining high detection accuracy. The algorithm demonstrates strong performance on a dataset of 45,728 images from Spanish natural parks.

## Method Summary
PARDINUS operates through a four-phase weakly supervised deep learning pipeline. First, K-Means clustering groups similar images based on RGB values to create homogeneous subsets. Second, robust autoencoders (RAEs) are trained on equalized images within each cluster to learn reconstruction patterns specific to empty images. Third, the system divides both original and reconstructed images into a 6×4 grid, computing block-level reconstruction errors using MSE, MAE, and SSIM metrics. Finally, a Random Forest classifier uses these 72 error features plus cluster IDs to classify images as empty or containing animals. The weakly supervised nature requires only empty images for autoencoder training, dramatically reducing the need for manual labeling.

## Key Results
- Achieves AUC of 0.9702 and F1-score of 0.83 on a dataset of 45,728 images
- Outperforms other state-of-the-art methods for empty image detection in camera trap data
- Reduces manual labeling requirements by using only empty images for autoencoder training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Clustering images by RGB similarity before reconstruction improves AE performance by isolating feature variations that confound the reconstruction of empty versus animal-containing images.
- Mechanism: K-Means clustering groups images with similar background structure, lighting, and composition. AEs trained on homogeneous clusters learn to reconstruct empty images more accurately, so the reconstruction error for animal images becomes more pronounced and discriminative.
- Core assumption: Images within the same cluster share sufficient visual similarity that the reconstruction task is simplified for empty images, while images with animals become anomalous.
- Evidence anchors:
  - [section] "The photo-trapping cameras that captured the images forming our dataset, details of which will be presented in section 4, are located in natural environments. As depicted in the figure 2, those areas are very dynamic. Depending on the camera location, we can find images taken in forest areas with heavy or low vegetation, dry areas, images captured in larger or smaller areas, etc. Even images taken in the same location but at different times of the year differ from each other."
  - [section] "The first step is to determine how the clustering is to be done. NOSpcimen relied on the histogram of the image since it is a good method to describe an image. In this case, we have created five experiments to verify if this is the best choice: clustering on RGB histograms (NOSpcimen), equalized histograms, black and white histograms, equalized images and RGB images. To measure the clustering quality we use the average silhouette score [43], a measure of how similar an object is to its cluster compared to other clusters. As can be seen in figure 3, grouping the images using the image itself instead of its histogram gives the best results."

### Mechanism 2
- Claim: Using equalized images as AE input amplifies the contrast difference between animal and background regions, making reconstruction errors more sensitive to the presence of animals.
- Mechanism: Histogram equalization redistributes pixel intensities to cover the full range, increasing contrast. Animals often occupy darker or lighter regions relative to the background; this preprocessing makes their presence more visually distinct, so AEs trained only on empty images fail to reconstruct these regions accurately.
- Core assumption: The contrast enhancement from equalization disproportionately affects animal regions versus empty backgrounds, increasing reconstruction error for animal images.
- Evidence anchors:
  - [section] "The image format of the image when passed to the AE as input can be decisive. We hypothesize that equalized images can improve contrast in the images and highlight the animal presence."
  - [section] "To prove it, we created two experiments. In one of them, we use RGB images and reconstruct it using the base architecture of the RAE. Next, we calculate the MSE, MAE, and SSIM for both empty and animal original and reconstructed images. The other experiment follows the same steps but uses equalized images. Then we calculate the Diff.MSE, Diff.MAE and Diff.SSIM for both experiments following the equations 4."
  - [table] Metric RGB Equalized images images Diff.MSE 0.0037 0.0055 Diff.MAE 0.0178 0.0186 Diff.SSIM 0.1468 0.1754

### Mechanism 3
- Claim: Dividing images into a grid of blocks before computing reconstruction error metrics isolates small animal regions, preventing them from being averaged out in global metrics.
- Mechanism: Partitioning the image into WxH blocks allows local computation of MSE, MAE, and SSIM. If an animal occupies only a small portion of the image, its reconstruction error will be high in those blocks, while background blocks will have low error. This local error pattern is more discriminative than a single global metric.
- Core assumption: Animal presence manifests as localized reconstruction failure in specific blocks, and the classifier can learn to associate high local errors with animal presence.
- Evidence anchors:
  - [section] "As mentioned, the next step is to compare the original and the reconstructed images. To measure the difference, we use three metrics: mean squared error (MSE), mean absolute error (MAE) and structural similarity (SSIM). Its equations are 1, 2 and 3."
  - [section] "Nevertheless, when dealing with photographs containing animals, we often encounter an additional challenge in the images where the animal occupies only a small portion of it. In such cases, the conventional evaluation metrics described before may not accurately capture the fidelity of the reconstruction process since the RAE model excels at reconstructing the background of the image while struggling with the animal itself."
  - [section] "To address this challenge, we decided to partition both the original and reconstructed images into W × H blocks, organized in a grid format of W blocks in width and H blocks in height (stage 4 of the figure 1). This strategy serves a critical purpose."

## Foundational Learning

- Concept: Autoencoders (AEs) and their variants (RAE, VAE)
  - Why needed here: AEs learn to reconstruct inputs; by training only on empty images, they become sensitive to anomalies (animals) whose presence disrupts reconstruction.
  - Quick check question: What is the key difference between a standard AE and a robust AE (RAE) in terms of loss function?

- Concept: Clustering algorithms (K-Means)
  - Why needed here: Clustering groups similar images so that AEs can be specialized per cluster, improving reconstruction fidelity for empty images and anomaly detection for animals.
  - Quick check question: Why is silhouette score used to evaluate clustering quality in this context?

- Concept: Random Forest classifiers
  - Why needed here: RFs handle high-dimensional input (grid of reconstruction errors + cluster ID) and are robust to overfitting, making them suitable for distinguishing empty from animal images based on error patterns.
  - Quick check question: How does the number of trees in an RF affect its bias-variance tradeoff?

## Architecture Onboarding

- Component map: Image preprocessing → K-Means clustering (RGB) → Equalization → RAE reconstruction per cluster → Grid division (6x4) → Block-wise error metrics (MSE, MAE, SSIM) → Random Forest classification
- Critical path: Clustering → RAE training → Error computation → Classification. Failure in any stage propagates to final accuracy.
- Design tradeoffs: Using equalized images improves animal detection but may distort natural appearance; grid division increases feature dimensionality but captures localized anomalies; clustering reduces AE complexity but requires careful cluster sizing.
- Failure signatures: High false negatives suggest AEs are reconstructing animal regions too well (need more specialized clustering or equalization); high false positives suggest background noise is being flagged as anomalies (need to adjust grid size or RF thresholds).
- First 3 experiments:
  1. Train K-Means on RGB images, evaluate silhouette score for cluster counts 5-10.
  2. Train RAE on equalized images from one cluster, compare reconstruction error distribution between empty and animal images.
  3. Train RF on grid error features from a balanced subset, measure AUC and FN rate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a fully unsupervised method for empty image detection be developed by replacing the Random Forest classifier with alternative statistical methods?
- Basis in paper: [explicit] Authors propose this as future work, aiming to eliminate the need for labeled data entirely.
- Why unresolved: The study relies on a Random Forest classifier trained on reconstruction errors, which requires some labeled data.
- What evidence would resolve it: Successful development and evaluation of a fully unsupervised algorithm that matches or surpasses PARDINUS's performance on the WWF21 dataset.

### Open Question 2
- Question: How does the performance of PARDINUS generalize to camera trap datasets from diverse ecosystems and geographic locations beyond Spain?
- Basis in paper: [inferred] The study evaluates PARDINUS on a dataset from Spain, but the authors mention the potential for application in wildlife conservation more broadly.
- Why unresolved: The current evaluation is limited to a single dataset, and performance may vary depending on the characteristics of the images and the animal species present.
- What evidence would resolve it: Extensive testing of PARDINUS on camera trap datasets from various ecosystems and geographic locations, demonstrating consistent performance across different environments.

### Open Question 3
- Question: What is the impact of varying the number of clusters (N) on the performance of PARDINUS, and is there an optimal value of N for different datasets?
- Basis in paper: [explicit] The authors discuss the trade-off between too few clusters (insufficient representation) and too many clusters (sparsity), and select 7 clusters for the WWF21 dataset.
- Why unresolved: The optimal number of clusters may depend on the specific characteristics of the dataset, such as the diversity of images and the presence of animal species.
- What evidence would resolve it: Systematic experimentation with different values of N on various datasets to identify the optimal number of clusters for each case and understand the relationship between N and performance.

## Limitations

- The weakly supervised approach relies heavily on accurate initial clustering of empty images; poor clustering could propagate errors through the entire pipeline
- The method assumes animal images will consistently produce higher reconstruction errors, but this may not hold for all animal sizes, positions, or backgrounds
- The 7-cluster configuration was chosen based on silhouette scores but may not be optimal for all datasets or camera locations

## Confidence

- High confidence in the core autoencoder reconstruction mechanism and its ability to detect anomalies
- Medium confidence in the clustering approach, as silhouette score optimization doesn't guarantee optimal classification performance
- Medium confidence in the overall system performance metrics, given the specific dataset characteristics

## Next Checks

1. Test the system on images from different camera locations and seasons to verify clustering and reconstruction robustness across varied environmental conditions
2. Conduct ablation studies removing the clustering step to quantify its contribution to overall performance
3. Evaluate the impact of different grid sizes (beyond 6x4) on detection accuracy for small versus large animal targets