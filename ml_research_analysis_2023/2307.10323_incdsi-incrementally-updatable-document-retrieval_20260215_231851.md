---
ver: rpa2
title: 'IncDSI: Incrementally Updatable Document Retrieval'
arxiv_id: '2307.10323'
source_url: https://arxiv.org/abs/2307.10323
tags:
- documents
- document
- queries
- retrieval
- incdsi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: IncDSI is a method to rapidly add new documents to a trained differentiable
  search index model, enabling real-time updates to retrieval systems. The approach
  formulates document addition as a constrained optimization problem, finding minimal
  changes to document representations to correctly classify both new and existing
  document queries.
---

# IncDSI: Incrementally Updatable Document Retrieval

## Quick Facts
- arXiv ID: 2307.10323
- Source URL: https://arxiv.org/abs/2307.10323
- Reference count: 22
- Key outcome: IncDSI enables real-time document addition to trained DSI models in ~50ms per document while maintaining comparable retrieval performance to full retraining

## Executive Summary
IncDSI addresses the challenge of efficiently adding new documents to trained differentiable search index (DSI) models without requiring full retraining. The method formulates document addition as a constrained optimization problem that updates only document vectors while keeping the query encoder frozen. By leveraging the structure of DSI models and using efficient convex optimization with L-BFGS, IncDSI achieves real-time document addition (50ms per document) while maintaining retrieval performance on both new and existing documents. Experiments on NQ320K and MS MARCO datasets demonstrate that IncDSI significantly outperforms DPR and matches or exceeds DSI baseline performance on new documents.

## Method Summary
IncDSI adds new documents to a trained DSI model by optimizing only the document representation vector without modifying the query encoder or existing document vectors. The method formulates this as a constrained optimization problem where the new document vector must maximize inner product with new document queries while minimizing interference with old document queries. The optimization uses hinge loss constraints to ensure existing documents remain retrievable for their original queries. L-BFGS with strong Wolfe line search converges quickly to optimal document vectors, avoiding the computational cost of retraining the entire model. The approach requires cached queries for existing documents to enforce constraints during optimization.

## Key Results
- Adds documents in ~50ms per document versus 2hr17m for full DSI retraining
- Achieves comparable retrieval performance to full retraining on NQ320K and MS MARCO datasets
- Significantly outperforms DPR and matches or exceeds DSI baseline performance on new documents
- Maintains Hits@10 for original documents nearly constant during indexing, though Hits@1 degrades slowly over time

## Why This Works (Mechanism)

### Mechanism 1
IncDSI can add new documents by directly optimizing only the new document's representation vector without modifying the query encoder or existing document vectors. This works because document vectors are independent and can be optimized separately from the query encoder parameters. The optimization problem finds a new document vector that maximizes inner product with new document queries while minimizing interference with old document queries, preserving retrieval accuracy for existing documents. The independence assumption allows treating document addition as a separate optimization problem.

### Mechanism 2
IncDSI maintains retrieval performance on existing documents while adding new ones by enforcing constraints that prevent new document vectors from being retrieved for old document queries. The optimization uses hinge loss constraints that ensure old document queries still retrieve their correct documents after new documents are added. Old document queries are represented as fixed vectors (average of cached training queries) that remain valid after optimization. This constraint-based approach prevents catastrophic forgetting during document addition.

### Mechanism 3
IncDSI achieves real-time document addition (50ms per document) by leveraging efficient convex optimization instead of full model retraining. The L-BFGS optimizer with strong Wolfe line search converges quickly to optimal document vectors, avoiding the computational cost of retraining the entire model. The optimization problem is formulated to be convex or efficiently solvable with L-BFGS despite being a constrained problem. This enables rapid updates while maintaining retrieval quality.

## Foundational Learning

- **Concept: Constrained optimization in high-dimensional spaces**
  - Why needed here: The core of IncDSI is formulating document addition as a constrained optimization problem over the document representation space.
  - Quick check question: Why does constraining the optimization to only update document vectors (not the entire model) enable faster updates?

- **Concept: Dual encoder vs. single encoder architectures in information retrieval**
  - Why needed here: Understanding the difference between DSI (single encoder) and DPR (dual encoder) is crucial for grasping why IncDSI works and how it compares to baselines.
  - Quick check question: What architectural difference between DSI and DPR enables IncDSI's approach to document addition?

- **Concept: Catastrophic forgetting in continual learning**
  - Why needed here: IncDSI addresses the forgetting problem that occurs when adding new documents to trained models, which is fundamental to understanding its value proposition.
  - Quick check question: How does IncDSI's approach to adding documents differ from standard continual learning methods that use replay or regularization?

## Architecture Onboarding

- **Component map**: Query encoder (BERT) -> Classification layer (document vectors) -> L-BFGS optimizer -> Updated document representations

- **Critical path**: New document query → BERT encoder → compute constraints → L-BFGS optimization → update classification layer

- **Design tradeoffs**: 
  - Speed vs. accuracy: Faster updates (50ms) vs. potential slight degradation in performance over time
  - Complexity vs. simplicity: Single unified model (DSI) vs. dual encoder systems
  - Storage vs. computation: Caching old document queries vs. recomputing during optimization

- **Failure signatures**:
  - Optimization fails to converge within 30 iterations
  - New document vectors consistently violate constraints
  - Performance degradation on original documents exceeds acceptable threshold
  - Adding too many documents causes the document representation space to become too crowded

- **First 3 experiments**:
  1. Add a single new document with both natural and generated queries, verify retrieval performance improves
  2. Add multiple documents sequentially, measure performance degradation on original documents
  3. Compare retrieval performance and time for adding 1000 documents using IncDSI vs. full retraining

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of IncDSI scale when adding thousands of documents compared to retraining the model? The paper mentions that performance on original documents degrades slowly over time and eventually requires retraining, but doesn't explore the exact point at which retraining becomes necessary or how IncDSI performs at scale.

### Open Question 2
How does the performance of IncDSI compare to other continual learning methods in the document retrieval setting? The paper focuses on comparing IncDSI to DSI and DPR baselines but doesn't explore how it performs against other continual learning techniques like experience replay, elastic weight consolidation, or meta-learning approaches.

### Open Question 3
How does the choice of the query generation model impact the performance of IncDSI? The paper uses docTTTTTquery without exploring alternatives or investigating the impact of query quality on optimization success rates and final retrieval quality.

## Limitations
- Limited long-term performance analysis - the paper doesn't extensively analyze performance degradation over thousands of additions or long-term stability
- Optimization convergence constraints - relies on L-BFGS with maximum 30 iterations, which may be insufficient for documents with high semantic overlap
- Generated query dependency - performance heavily relies on docTTTTTquery quality, with poor query generation potentially leading to suboptimal document representations

## Confidence
- **High Confidence**: The core mechanism of using constrained optimization for document vector updates is well-validated through experimental results showing ~50ms addition time and comparable performance to full retraining.
- **Medium Confidence**: The claim that IncDSI maintains performance on original documents while adding new ones is supported by experiments but shows gradual degradation over time that wasn't extensively analyzed.
- **Low Confidence**: The assumption that document vectors are truly independent and can be optimized separately from the query encoder lacks direct empirical validation in the paper.

## Next Checks
1. **Stress Test with High Document Overlap**: Add a large batch of documents that are semantically similar to existing documents to test the optimization's ability to handle crowded representation spaces and identify failure conditions.

2. **Longitudinal Performance Tracking**: Implement a study that adds thousands of documents sequentially over time, measuring both new document performance and original document performance degradation to understand long-term scalability limits.

3. **Query Generation Ablation Study**: Compare IncDSI performance using only natural queries versus using generated queries to quantify the impact of docTTTTTquery on optimization success rates and final retrieval quality.