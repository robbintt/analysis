---
ver: rpa2
title: A Wide Evaluation of ChatGPT on Affective Computing Tasks
arxiv_id: '2308.13911'
source_url: https://arxiv.org/abs/2308.13911
tags:
- chatgpt
- sentiment
- detection
- problems
- gpt-3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates the performance of ChatGPT models, namely
  GPT-3.5 and GPT-4, on a wide range of affective computing problems. A framework
  is introduced to convert regression-based tasks into pairwise ranking classification
  tasks for evaluation.
---

# A Wide Evaluation of ChatGPT on Affective Computing Tasks

## Quick Facts
- arXiv ID: 2308.13911
- Source URL: https://arxiv.org/abs/2308.13911
- Reference count: 40
- One-line primary result: ChatGPT models (especially GPT-4) show strong performance on explicit sentiment, emotion, and toxicity tasks but struggle with implicit signals like engagement measurement.

## Executive Summary
This paper evaluates ChatGPT models (GPT-3.5 and GPT-4) on 13 diverse affective computing tasks using a novel pairwise ranking framework. The study compares ChatGPT against traditional NLP methods like RNNs and transformers, revealing emergent abilities of foundation models on explicit affective tasks while highlighting limitations on implicit signal detection. The framework converts regression problems into pairwise ranking classification tasks, enabling effective evaluation of intensity-based problems.

## Method Summary
The study evaluates ChatGPT models on 13 affective computing problems by converting regression tasks into pairwise ranking classification. The approach uses the OpenAI API to query GPT-3.5 and GPT-4 with task-specific prompts, comparing results against RNN baselines (E2E and RoBERTa-based). The pairwise ranking framework samples pairs of examples using small-world graph generation to assess ordinal relationships. Performance is measured using classification accuracy and Unweighted Average Recall (UAR) across multiple datasets from sources like SemEval, Twitter, and Reddit.

## Key Results
- GPT-4 achieves top-2 performance across most tasks, excelling particularly on explicit sentiment, emotion, and toxicity detection
- RoBERTa-based RNNs outperform ChatGPT on implicit signal tasks like engagement measurement and personality assessment
- The pairwise ranking framework successfully enables evaluation of regression-based intensity tasks through classification
- ChatGPT struggles with subjectivity detection and engagement measurement compared to traditional NLP methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Converting regression tasks into pairwise ranking classification enables effective evaluation of LLMs on intensity-based affective computing problems.
- Mechanism: By sampling pairs of examples and framing the problem as "which text has higher intensity," the model can leverage its classification strengths to provide meaningful ordinal comparisons, bypassing the difficulty of prompting absolute scores.
- Core assumption: Pairwise comparisons preserve the relative ordering information needed to assess model performance on regression tasks.
- Evidence anchors:
  - [abstract]: "We introduce a framework to evaluate the ChatGPT models on regression-based problems, such as intensity ranking problems, by modelling them as pairwise ranking classification."
  - [section]: "We employ the small-world graph generation algorithm... we sample M = 4N pairs."
  - [corpus]: Weak evidence—no direct corpus citations for pairwise ranking evaluation, only mentions of sentiment analysis.
- Break condition: If the pairwise ranking model cannot capture the nuances of the original regression scale, the evaluation will misrepresent model performance.

### Mechanism 2
- Claim: Specialized prompting strategies improve ChatGPT's performance on affective computing tasks compared to generic instructions.
- Mechanism: Tailoring prompts to each task type (e.g., sentiment, toxicity, emotion) with explicit formatting rules and disallowing ambiguous responses leads to more reliable and parseable outputs.
- Core assumption: Clear, task-specific instructions reduce model improvisation and improve consistency.
- Evidence anchors:
  - [abstract]: "We introduce a framework to evaluate the ChatGPT models on regression-based problems, such as intensity ranking problems, by modelling them as pairwise ranking classification."
  - [section]: "The redundancy is also helpful in this regard, since we specify the formatting in a general form once on the problem description... then, we specify it a second time in a precise manner in the notes bullet points."
  - [corpus]: Weak evidence—no direct corpus citations for prompt engineering effectiveness.
- Break condition: If the model ignores formatting instructions or generates outputs outside the specified formats, parsing becomes unreliable.

### Mechanism 3
- Claim: RoBERTa-based RNNs outperform ChatGPT on many affective computing tasks, especially those requiring nuanced understanding of implicit signals.
- Mechanism: RoBERTa's pre-trained contextual embeddings capture linguistic subtleties better than zero-shot ChatGPT, particularly for tasks like engagement measurement and personality assessment.
- Core assumption: Pre-trained language models with fine-tuning are more effective than zero-shot LLMs for domain-specific affective tasks.
- Evidence anchors:
  - [abstract]: "We compare ChatGPT against more traditional NLP methods, such as end-to-end recurrent neural networks and transformers."
  - [section]: "The results show that the RNN trained with RoBERTa features has the best performance in the majority of problems... followed by GPT-4."
  - [corpus]: Weak evidence—no direct corpus citations for RoBERTa vs. ChatGPT comparisons.
- Break condition: If the dataset or task shifts to favor general knowledge over fine-grained linguistic patterns, ChatGPT may outperform RoBERTa.

## Foundational Learning

- Concept: Pairwise ranking classification
  - Why needed here: It transforms regression problems into classification tasks that LLMs can handle effectively.
  - Quick check question: How does pairwise ranking preserve ordinal information compared to absolute scoring?

- Concept: Prompt engineering
  - Why needed here: Custom prompts guide LLMs to produce consistent, parseable outputs for evaluation.
  - Quick check question: What are the key elements of a task-specific prompt that reduce ambiguity?

- Concept: Unweighted Average Recall (UAR)
  - Why needed here: UAR provides a balanced metric for imbalanced affective computing datasets.
  - Quick check question: How does UAR differ from standard accuracy in handling class imbalance?

## Architecture Onboarding

- Component map: Data ingestion → preprocessing (tokenization, feature extraction) → model selection (ChatGPT API, RoBERTa+RNN, or E2E RNN) → evaluation (pairwise ranking or classification metrics) → results aggregation
- Critical path: Data preparation → prompt formulation → API querying → response parsing → metric computation
- Design tradeoffs:
  - ChatGPT API usage vs. model accuracy (cost and rate limits)
  - Pairwise ranking vs. absolute scoring (evaluation fidelity vs. feasibility)
  - RoBERTa features vs. raw text (contextual richness vs. simplicity)
- Failure signatures:
  - Unparseable ChatGPT responses (prompting issues)
  - Poor pairwise sampling (evaluation bias)
  - Overfitting in RoBERTa+RNN (lack of generalization)
- First 3 experiments:
  1. Validate pairwise ranking framework on a small, balanced dataset
  2. Test prompt variations on a subset to find optimal formatting rules
  3. Compare RoBERTa+RNN vs. E2E RNN on a simple sentiment task to establish baseline performance gap

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of ChatGPT models vary across different languages and cultural contexts in affective computing tasks?
- Basis in paper: [inferred] The paper focuses on English datasets and does not explore multilingual or cross-cultural evaluations.
- Why unresolved: The study's scope is limited to English datasets, leaving the generalizability of ChatGPT's performance to other languages and cultures unexplored.
- What evidence would resolve it: Conducting experiments with datasets in multiple languages and cultures, comparing the performance of ChatGPT models across these diverse contexts.

### Open Question 2
- Question: What are the long-term effects of fine-tuning ChatGPT models on specific affective computing tasks, and how does this impact their general capabilities?
- Basis in paper: [inferred] The paper evaluates ChatGPT's emergent abilities without exploring the effects of task-specific fine-tuning.
- Why unresolved: The study focuses on zero-shot and few-shot learning capabilities, leaving the potential benefits and drawbacks of fine-tuning unexplored.
- What evidence would resolve it: Conducting experiments that compare the performance of fine-tuned ChatGPT models against their zero-shot counterparts on various affective computing tasks, assessing both task-specific and general capabilities.

### Open Question 3
- Question: How do different prompting strategies and template designs influence the performance of ChatGPT models in affective computing tasks?
- Basis in paper: [explicit] The paper introduces a general prompting framework but does not extensively explore the impact of different prompting strategies.
- Why unresolved: The study presents a standardized prompting approach without investigating the effects of alternative strategies or template designs.
- What evidence would resolve it: Conducting experiments that compare the performance of ChatGPT models using various prompting strategies and template designs, analyzing the impact on task performance and model behavior.

### Open Question 4
- Question: What are the ethical implications and potential biases in ChatGPT models when applied to affective computing tasks, particularly in sensitive domains like mental health analysis?
- Basis in paper: [inferred] The paper evaluates ChatGPT's performance on tasks like suicide tendency detection and well-being assessment but does not discuss the ethical considerations or potential biases.
- Why unresolved: The study focuses on technical performance metrics without addressing the broader ethical implications of using AI models in sensitive domains.
- What evidence would resolve it: Conducting a comprehensive ethical analysis of ChatGPT's performance in affective computing tasks, including bias detection, fairness assessments, and potential risks in sensitive applications.

## Limitations

- The pairwise ranking framework, while innovative, lacks thorough validation of its small-world graph sampling methodology for preserving ordinal relationships
- The study does not explore fine-tuning ChatGPT models, potentially underestimating their capabilities on affective computing tasks
- Limited to English-language datasets, constraining generalizability to multilingual and cross-cultural affective computing scenarios

## Confidence

- High Confidence: ChatGPT's strong performance on explicit sentiment, emotion, and toxicity detection tasks (backed by clear quantitative results across multiple datasets)
- Medium Confidence: The pairwise ranking framework's effectiveness for regression tasks (innovative approach but limited validation of sampling methodology)
- Low Confidence: Explanations for why ChatGPT struggles with implicit signal tasks (acknowledged but not thoroughly investigated)

## Next Checks

1. **Validation of Pairwise Sampling Methodology:** Conduct a controlled experiment comparing the small-world graph-based pairwise sampling against alternative methods (e.g., random sampling, stratified sampling) to verify that the chosen approach accurately preserves ordinal relationships in regression tasks without introducing bias.

2. **Cross-Lingual Extension:** Test the evaluation framework and ChatGPT models on multilingual affective computing datasets to assess whether the observed performance patterns hold across languages, particularly for implicit signal tasks that may be culturally dependent.

3. **Fine-tuning Impact Analysis:** Implement a few-shot learning variant of ChatGPT for selected tasks (especially those where it underperformed) and compare results against zero-shot prompting to determine whether the performance gap with traditional methods can be narrowed through minimal task-specific adaptation.