---
ver: rpa2
title: Online Algorithms for Hierarchical Inference in Deep Learning applications
  at the Edge
arxiv_id: '2304.00891'
source_url: https://arxiv.org/abs/2304.00891
tags:
- u1d461
- u1d45d
- u1d44c
- u1d703
- u1d45b
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies a resource-constrained edge device (ED) that
  is embedded with a small-size ML model (S-ML) and an edge server (ES) that hosts
  a large-size ML model (L-ML). The authors propose a hierarchical inference (HI)
  framework that uses the maximum softmax value output by the S-ML to decide whether
  to offload a data sample to the L-ML or not.
---

# Online Algorithms for Hierarchical Inference in Deep Learning applications at the Edge

## Quick Facts
- arXiv ID: 2304.00891
- Source URL: https://arxiv.org/abs/2304.00891
- Reference count: 40
- Key outcome: HIL-F and HIL-N algorithms achieve high accuracy with sublinear regret through dynamic non-uniform discretization of decision thresholds

## Executive Summary
This paper proposes a hierarchical inference framework for resource-constrained edge devices that use a small ML model (S-ML) and can offload to a larger server model (L-ML). The authors formulate the problem as prediction with expert advice with continuous expert space and propose two algorithms (HIL-F and HIL-N) that use exponential weighting and dynamic non-uniform discretization to learn optimal thresholds for offloading decisions. The algorithms achieve sublinear regret bounds and demonstrate strong performance across four image classification datasets, maintaining high accuracy while offloading only marginally more samples than an optimal fixed-threshold policy.

## Method Summary
The paper addresses hierarchical inference at the edge by having a small embedded ML model (S-ML) make initial predictions and decide whether to offload samples to a larger server model (L-ML). The core innovation is treating this as a prediction with expert advice problem where the "expert space" is continuous (thresholds in [0,1]). Two algorithms are proposed: HIL-F (full feedback) and HIL-N (no-local feedback). Both use exponential weighting over dynamically created intervals based on observed S-ML confidence values, with HIL-N incorporating an unbiased loss estimator through additional randomization. The algorithms learn optimal offloading thresholds while maintaining sublinear regret bounds.

## Key Results
- HIL-F and HIL-N achieve sublinear regret bounds of O(√T log(1/δmin)) where T is the number of samples
- The algorithms maintain high accuracy across four datasets (Imagenette, Imagewoof, MNIST, CIFAR-10) while offloading marginally more samples than optimal fixed-threshold policies
- Dynamic non-uniform discretization outperforms uniform discretization by creating intervals only where needed based on observed probability values
- HIL-N successfully extends the framework to settings where ground truth is not immediately available through unbiased loss estimation

## Why This Works (Mechanism)

### Mechanism 1
HIL-F and HIL-N use non-uniform discretization to avoid regret loss from uniform discretization. Instead of uniformly partitioning [0,1], the algorithms create intervals at actual observed probability values (/u1D45D/u1D461), dynamically expanding the expert set only where needed. This works because loss is piece-wise constant between adjacent /u1D45D values, so splitting intervals at observed probabilities preserves accuracy. The cumulative loss /u1D43F(/u1D73D,/u1D480 ) is proven to be piece-wise constant with constant value in each interval /u1D435/u1D456.

### Mechanism 2
Full feedback allows direct cost updates; no-local feedback requires unbiased loss estimation via additional offloading. In full feedback, ground truth /u1D44C/u1D461 is revealed for every sample; in no-local feedback, HIL-N generates Bernoulli /u1D44D/u1D461 with probability /u1D716 to force extra offload, yielding unbiased pseudo loss ˜/u1D459 that matches expected true loss. The pseudo loss satisfies E[/u1D44D][˜/u1D459] = /u1D459, ensuring unbiasedness. The extra offload probability /u1D716 is chosen to balance regret growth vs. feedback gain.

### Mechanism 3
Learning rate /u1D702 is optimized per bound, not per dataset, and regret remains sublinear. Theoretical bounds give /u1D702∗ = √{8 ln(1//u1D706min)}/√/u1D45B for HIL-F and a cubic-root formula for HIL-N. Tuning /u1D702 to these values minimizes regret growth by balancing the 1//u1D702 ln(1//u1D706min) and /u1D45B//u1D702 terms in the regret bound. The regret bound formulas are tight enough that using the optimizing /u1D702 gives near-optimal performance.

## Foundational Learning

- Concept: Prediction with Expert Advice (PEA) and continuous action spaces
  - Why needed here: The HI problem maps to PEA with uncountable thresholds /u1D703 ∈ [0,1]; understanding PEA clarifies regret bounds and why uniform discretization fails
  - Quick check question: In standard PEA with /u1D441 discrete experts, what is the optimal regret order? (Answer: √/u1D45B ln /u1D441.)

- Concept: Piece-wise constant loss functions and dynamic discretization
  - Why needed here: The algorithms rely on the fact that the cumulative loss is constant within intervals defined by observed /u1D45D values; without this, non-uniform discretization would introduce error
  - Quick check question: If no two /u1D45D values coincide, how many distinct intervals can appear after /u1D45B rounds? (Answer: at most /u1D45B+1.)

- Concept: Unbiased loss estimation in bandit settings
  - Why needed here: In no-local feedback, the algorithm must estimate unknown local costs; the pseudo loss construction is a bandit-style unbiased estimator
  - Quick check question: What condition must an estimator satisfy to be unbiased for the true loss? (Answer: Its expectation over the randomization equals the true loss.)

## Architecture Onboarding

- Component map: Input -> S-ML -> /u1D45D/u1D461 -> Decision Engine -> (accept | offload) -> (cost | L-ML) -> Weight Update -> next round
- Critical path: Input → S-ML → /u1D45D/u1D461 → Decision Engine → (accept | offload) → (cost | L-ML) → Weight Update → next round
- Design tradeoffs:
  - Interval granularity vs. runtime: smaller Δmin → more intervals → higher accuracy but O(/u1D461) per round
  - /u1D716 in HIL-N vs. feedback quality: higher /u1D716 → more unbiased samples but larger regret penalty /u1D45B/u1D6FD/u1D716
  - /u1D702 choice: too small → slow adaptation; too large → over-emphasis on early outcomes
- Failure signatures:
  - Sudden regret spike → intervals not splitting fast enough or /u1D702 too small
  - Runtime blow-up → /u1D706min extremely small, causing many intervals
  - High offload rate but no accuracy gain → /u1D716 too large in HIL-N or /u1D702 too small
- First 3 experiments:
  1. Simulate S-ML on Imagenette, collect /u1D45D sequence, run HIL-F with /u1D702= √{8 ln(1//u1D706min)}/√/u1D45B, plot interval count vs. rounds
  2. Run HIL-N with /u1D716= min{1, √/u1D702/(2/u1D6FD)} on same data, compare regret to HIL-F
  3. Sweep /u1D702 over {0.1, 0.5, 1, 2} for both algorithms, plot regret vs. /u1D702 to verify theoretical optimum

## Open Questions the Paper Calls Out

- Open Question 1: How does the performance of HIL-F and HIL-N change when the L-ML model has less than 100% accuracy?
- Open Question 2: What is the impact of the cost structure (/u1D6FD for offloading vs. 0 or 1 for local inference) on the overall performance and decision-making of HIL-F and HIL-N?
- Open Question 3: How do HIL-F and HIL-N perform in non-image classification tasks, such as natural language processing or time series analysis?
- Open Question 4: How does the proposed HI framework compare to other hierarchical inference techniques, such as Early Exit or DNN partitioning, in terms of accuracy, latency, and energy efficiency?

## Limitations
- The algorithms assume perfect accuracy for the L-ML model, though the authors note this assumption is not strictly necessary
- Performance evaluation is limited to image classification tasks, with no testing on other ML application domains
- The dynamic interval creation process could face scalability issues when probability values cluster tightly
- The framework requires careful tuning of the learning rate parameter /u1D702 and feedback parameter /u1D716

## Confidence
- Hierarchical Inference Framework Design: High
- Theoretical Regret Bounds: High
- Algorithm Implementation and Dynamic Discretization: Medium
- Empirical Performance Across Datasets: Medium
- Generalizability to Other Applications: Low

## Next Checks
1. Implement HIL-F on a synthetic dataset with tightly clustered probability values (/u1D45D) to verify that interval growth remains manageable and doesn't cause performance degradation
2. Compare HIL-F/HIL-N against additional hierarchical inference methods (e.g., threshold-based static approaches with cross-validation) on the same four datasets to better contextualize the performance gains
3. Systematically vary the learning rate /u1D702 and feedback parameter /u1D716 across wider ranges than tested, measuring the impact on regret bounds and computational overhead to validate the theoretical optimization formulas