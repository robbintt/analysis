---
ver: rpa2
title: Self-Alignment with Instruction Backtranslation
arxiv_id: '2308.06259'
source_url: https://arxiv.org/abs/2308.06259
tags:
- data
- instruction
- seed
- arxiv
- quality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a scalable method to build a high-quality instruction-following
  language model by automatically labeling human-written text with corresponding instructions.
  The approach, named instruction backtranslation, starts with a language model finetuned
  on a small amount of seed data and a given web corpus.
---

# Self-Alignment with Instruction Backtranslation

## Quick Facts
- arXiv ID: 2308.06259
- Source URL: https://arxiv.org/abs/2308.06259
- Authors: 
- Reference count: 40
- Key outcome: Humpback-65B achieves 66.5% win rate against text-davinci-003 on AlpacaEval, outperforming other non-distilled LLaMA-based models

## Executive Summary
This paper presents instruction backtranslation, a scalable method for building high-quality instruction-following language models without relying on distillation data. The approach uses self-augmentation (generating instructions for web documents) and self-curation (filtering high-quality examples) to create training data from unlabeled text. By iteratively training on better-curated data, the method achieves strong performance on instruction-following benchmarks while demonstrating highly effective self-alignment capabilities.

## Method Summary
The method starts with a language model finetuned on seed data and a web corpus. A backward model generates instruction prompts for web documents (self-augmentation), then the same model scores and filters these examples (self-curation). The curated data is used to finetune a stronger model, and this process iterates to improve curation quality. The final model is jointly trained on both seed data and high-quality augmented data, achieving superior instruction-following performance compared to other non-distilled LLaMA-based models.

## Key Results
- Humpback-65B achieves 66.5% win rate against text-davinci-003 on AlpacaEval
- Humpback-65B achieves 83.67% win rate on Alpaca leaderboard
- Outperforms all other LLaMA-based models not relying on distillation data
- Shows strong scaling efficiency, with scaling coefficient of 6.95 compared to 4.43 for seed-only training

## Why This Works (Mechanism)

### Mechanism 1
Iterative self-curation improves data selection quality, leading to better model performance. The model generates instructions from web documents, then uses itself to score and filter these examples. By iteratively training on better-curated data, the model's ability to distinguish high-quality from low-quality instruction-output pairs improves.

### Mechanism 2
Joint training with both seed data and high-quality augmented data yields better instruction-following than either alone. Seed data provides high-quality, domain-aligned examples, while augmented data increases instruction diversity. Combining them with system prompts allows the model to generalize better across tasks.

### Mechanism 3
Scaling up high-quality augmented data improves performance more efficiently than scaling low-quality or seed data alone. By iteratively generating and curating instructions from a large web corpus, the method creates a scalable pipeline that produces more high-quality examples than manual annotation alone.

## Foundational Learning

- Concept: Instruction tuning
  - Why needed here: The entire method builds on instruction tuning as the alignment mechanismâ€”finetuning the model to produce outputs given instructions.
  - Quick check question: What is the difference between instruction tuning and standard language model pretraining?

- Concept: Backtranslation (from MT)
  - Why needed here: The method is inspired by backtranslation, where target sentences are automatically annotated with source sentences in another language; here, outputs are paired with generated instructions.
  - Quick check question: How does the "backward model" in this work relate to the concept of backtranslation in machine translation?

- Concept: Self-training / self-alignment
  - Why needed here: The model uses its own predictions both to generate data and to evaluate its quality, enabling improvement without external supervision.
  - Quick check question: What are the risks of using a model to generate and filter its own training data?

## Architecture Onboarding

- Component map: Base model -> Seed dataset -> Web corpus -> Backward model -> Curation model -> System prompt tagging
- Critical path:
  1. Finetune backward model on seed data
  2. Generate instructions for web segments
  3. Score and filter generated pairs with curation model
  4. Jointly finetune on seed + curated augmented data
  5. Iterate steps 3-4 for improved curation
- Design tradeoffs:
  - Quality vs. quantity: More augmentation increases diversity but risks noise; self-curation mitigates this but may reduce data volume.
  - Iteration depth: More iterations could improve curation but increase training time and risk overfitting.
  - Prompt design: Curation prompt must be clear and consistent to ensure reliable scoring.
- Failure signatures:
  - Model win rate plateaus or degrades with more augmented data (indicates curation failure or overfitting).
  - Self-curation precision drops over iterations (indicates model confusion or prompt ambiguity).
  - Generated instructions are off-topic or nonsensical (indicates backward model quality issues).
- First 3 experiments:
  1. Train backward model on seed data and generate instructions for a small subset of web corpus; manually inspect quality.
  2. Finetune curation model on seed data; use it to score a sample of generated pairs; compute precision/recall.
  3. Jointly finetune base model on seed + curated augmented data; evaluate win rate against text-davinci-003 on dev set.

## Open Questions the Paper Calls Out

## Open Question 1
- Question: How does the quality of self-curated data from Humpback compare to high-quality human-annotated data in terms of instruction-following performance?
- Basis in paper: Inferred from the observation that Humpback outperforms other non-distilled models on the Alpaca leaderboard, despite using fewer human-annotated examples.
- Why unresolved: The paper does not directly compare the quality of self-curated data to high-quality human-annotated data. While Humpback performs well, it is unclear if its performance is due to the quality of self-curated data or other factors such as the iterative self-curation process or the diversity of instructions generated.
- What evidence would resolve it: A direct comparison of instruction-following performance between models trained on high-quality human-annotated data and models trained on self-curated data from Humpback.

## Open Question 2
- Question: What is the optimal number of iterations for the self-curation process in Humpback?
- Basis in paper: Inferred from the statement that Humpback performs two iterations of data selection and finetuning to get the final model.
- Why unresolved: The paper does not explore the impact of different numbers of iterations on the quality of the final model. It is unclear if two iterations are optimal or if more iterations would lead to further improvements.
- What evidence would resolve it: An ablation study comparing the performance of Humpback models trained with different numbers of iterations in the self-curation process.

## Open Question 3
- Question: How does the performance of Humpback scale with the size of the unlabelled web corpus used for self-augmentation?
- Basis in paper: Inferred from the statement that Humpback uses a web corpus as a source of unlabelled data and the scaling analysis showing that increasing the quantity of high-quality data provides further gains.
- Why unresolved: The paper does not explore the impact of different sizes of unlabelled web corpora on the performance of Humpback. It is unclear if there is a point of diminishing returns or if performance continues to improve with larger corpora.
- What evidence would resolve it: An experiment comparing the performance of Humpback models trained with different sizes of unlabelled web corpora.

## Limitations
- The exact prompt format for self-curation scoring is not disclosed, limiting reproducibility
- The paper lacks external validation of curation quality progression between iterations
- No comparison of self-curated data quality against high-quality human-annotated data

## Confidence

**High confidence**: The core empirical results showing Humpback-65B outperforming other non-distilled LLaMA-based models on Alpaca benchmarks. The win rate comparisons (66.5% on AlpacaEval, 83.67% on Alpaca leaderboard) are directly measurable and reproducible.

**Medium confidence**: The mechanism claims about iterative self-curation improving data selection quality. While the paper shows internal improvements between iterations, it doesn't establish whether these gains translate to actual model capability improvements or simply reflect prompt overfitting.

**Low confidence**: The claim that joint training with seed and augmented data is inherently complementary. The paper shows performance gains but doesn't isolate whether this is due to diversity, quality filtering, or simply more training data.

## Next Checks
1. Replicate the self-curation scoring process using the exact prompt format (if obtainable) on a held-out sample of generated instruction-output pairs to verify consistent 5-point rating reliability across different model versions.

2. Conduct an ablation study comparing models trained on: (a) seed data only, (b) curated augmented data only, (c) combined seed + curated augmented data to isolate the contribution of each component to the observed performance gains.

3. Perform a quality decay analysis across multiple augmentation iterations (beyond the two reported) to determine whether self-curation performance plateaus or degrades, and at what point additional iterations cease to provide value or introduce harmful noise.