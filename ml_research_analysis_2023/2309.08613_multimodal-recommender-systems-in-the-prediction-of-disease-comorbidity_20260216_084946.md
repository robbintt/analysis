---
ver: rpa2
title: Multimodal Recommender Systems in the Prediction of Disease Comorbidity
arxiv_id: '2309.08613'
source_url: https://arxiv.org/abs/2309.08613
tags:
- data
- codes
- code
- icd-9
- recommender
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper applies deep learning-based recommender systems to predict
  disease comorbidity using the MIMIC-III dataset. It evaluates Neural Collaborative
  Filtering (NCF) and Deep Hybrid Filtering (DHF) models, training them on datasets
  with all ICD-9 codes or the top 50 most common codes.
---

# Multimodal Recommender Systems in the Prediction of Disease Comorbidity

## Quick Facts
- arXiv ID: 2309.08613
- Source URL: https://arxiv.org/abs/2309.08613
- Reference count: 0
- One-line primary result: Deep recommender systems (NCF, DHF) achieve ~90% accuracy and ~80% hit ratio@10 for disease comorbidity prediction using MIMIC-III data, with multimodal fusion (clinical notes) further improving performance to 94.4% accuracy.

## Executive Summary
This paper applies deep learning-based recommender systems to predict disease comorbidity using the MIMIC-III dataset. The study evaluates Neural Collaborative Filtering (NCF) and Deep Hybrid Filtering (DHF) models, training them on datasets with all ICD-9 codes or the top 50 most common codes. NCF with all ICD codes achieved ~90% accuracy and ~80% hit ratio@10, outperforming the reduced 50-code dataset (~80% accuracy, 35% hit ratio@10). The DHF model, incorporating clinical notes via NLP, improved accuracy to 94.4% and hit ratio@10 to 85.36%, showing the benefit of multimodal data. Overall, deep recommender systems demonstrated strong promise for predicting disease comorbidity, outperforming traditional NLP-only approaches.

## Method Summary
The paper applies recommender system techniques to predict disease comorbidity by modeling subject-disease interactions as user-item interactions. Two deep learning models are implemented: Neural Collaborative Filtering (NCF) and Deep Hybrid Filtering (DHF). NCF learns latent representations of subjects and ICD codes through embedding layers and dense neural networks. DHF extends NCF by incorporating symptom embeddings extracted from clinical notes via NLP. Both models use negative sampling to handle the implicit feedback nature of disease co-occurrence data, with positive-to-negative ratios of 1:10, 1:4, and 1:2 tested. The models are trained on MIMIC-III data using either all ICD-9 codes or the top 50 most common codes, with evaluation metrics including accuracy, hit ratio@10, macro F1, and AUC.

## Key Results
- NCF with all ICD codes achieved ~90% accuracy and ~80% hit ratio@10, outperforming the reduced 50-code dataset (~80% accuracy, 35% hit ratio@10)
- DHF model incorporating clinical notes improved accuracy to 94.4% and hit ratio@10 to 85.36%
- Deep recommender systems outperformed traditional NLP-only approaches in ICD-9 code prediction
- Sparser datasets with all ICD codes performed better than reduced datasets due to higher data volume and deep learning's robustness to sparsity

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The NCF model with all ICD codes achieves higher accuracy than the top-50-code dataset because deep learning recommender systems are robust to sparse data and benefit from higher volume of data.
- **Mechanism**: The model learns latent representations for each subject and disease code by embedding sparse one-hot vectors into dense low-dimensional spaces. With all ICD codes, the model captures rare disease co-occurrence patterns that are absent in the reduced dataset, leveraging the sparsity as signal rather than noise.
- **Core assumption**: Sparsity in disease co-occurrence data contains meaningful signals that deep learning can exploit; higher data volume improves representation learning.
- **Evidence anchors**:
  - [abstract] "Reasons for the superior performance of the sparser dataset with all ICD codes can be mainly attributed to the higher volume of data and the robustness of deep-learning based recommender systems with modeling sparse data."
  - [section] "Reasons for a superior performance with all ICD compared to 50 ICD codes can be mainly attributed to i) the higher volume of data with dataset containing all ICD codes and ii) the powerful nature of deep learning algorithms."
- **Break condition**: If the dataset contains ICD codes that are too rare to provide meaningful co-occurrence signals, or if the model architecture cannot learn useful embeddings from sparse data.

### Mechanism 2
- **Claim**: Adding clinical notes via NLP improves comorbidity prediction by providing symptom-level context that complements structured ICD codes.
- **Mechanism**: NLP extracts symptom and medication entities from clinical notes, which are embedded alongside subject and ICD code embeddings. This multimodal fusion allows the model to capture disease associations that may not be evident from ICD codes alone, such as subtle symptom patterns indicating early disease stages.
- **Core assumption**: Clinical notes contain predictive signals about disease co-occurrence that are not encoded in ICD codes.
- **Evidence anchors**:
  - [abstract] "the DHF model, incorporating clinical notes via NLP, improved accuracy to 94.4% and hit ratio@10 to 85.36%, showing the benefit of multimodal data."
  - [section] "Results from the deep hybrid filtering model show better in training accuracy (93.75%) compared to NCF model (90.82%), indicating that the addition of text data from clinical notes provided improved performance in predicting comorbidity."
- **Break condition**: If clinical notes are not consistently documented or if extracted symptoms are too noisy to be predictive.

### Mechanism 3
- **Claim**: The hybrid recommender system outperforms traditional NLP-only approaches because it integrates structured ICD data with unstructured text in a unified learning framework.
- **Mechanism**: By combining collaborative filtering on ICD co-occurrence patterns with content-based features from clinical notes, the hybrid model leverages both relational and semantic information. This dual perspective captures disease relationships missed by either modality alone.
- **Core assumption**: Disease comorbidity prediction benefits from both relational patterns (ICD co-occurrence) and semantic context (symptoms from notes).
- **Evidence anchors**:
  - [section] "Compared to approaches using only NLP algorithms (such as BERT and CNN) by Zhang et al, in ICD-9 code prediction with MIMIC-III dataset, using NCF performed better."
  - [section] "The proposed deep recommender systems were able to handle the sparse and imbalanced multimodal data efficiently."
- **Break condition**: If either data modality is significantly noisier or less informative than assumed, degrading the hybrid model's performance below single-modality baselines.

## Foundational Learning

- **Concept: Recommender systems and collaborative filtering**
  - Why needed here: The paper applies recommender system techniques to predict disease comorbidity by modeling subject-disease interactions as user-item interactions.
  - Quick check question: What is the fundamental difference between content-based filtering and collaborative filtering in recommender systems?

- **Concept: Neural Collaborative Filtering (NCF)**
  - Why needed here: NCF is the core deep learning approach used to learn latent representations of subjects and diseases for comorbidity prediction.
  - Quick check question: How does NCF handle the implicit feedback nature of disease co-occurrence data?

- **Concept: Multimodal learning and feature fusion**
  - Why needed here: The DHF model combines structured ICD codes with unstructured clinical note features, requiring understanding of how to fuse different data modalities.
  - Quick check question: What are the main strategies for combining features from different modalities in deep learning models?

## Architecture Onboarding

- **Component map**: Data extraction (SQL from MIMIC-III) -> Preprocessing (label encoding, negative sampling, NLP entity extraction) -> NCF model (subject embedding, ICD embedding, concatenation, dense layers, sigmoid output) -> DHF model (extends NCF with symptom embedding, concatenates three embeddings) -> Evaluation (accuracy, Macro F1, AUC, Hit Ratio@10)

- **Critical path**: Data preprocessing → NCF training → DHF training → Evaluation. The negative sampling step is critical for both models' performance.

- **Design tradeoffs**:
  - Using all ICD codes vs. top 50: More comprehensive but sparser data; reduced dataset is denser but loses rare disease signals
  - Positive-to-negative ratio: Higher ratios (1:10) improve performance but require more training data
  - Embedding dimensionality: 8-dimensional embeddings were chosen; increasing may capture more complexity but risks overfitting

- **Failure signatures**:
  - NCF model: Poor performance on sparse datasets, convergence issues with imbalanced classes
  - DHF model: NLP preprocessing errors leading to empty symptom features, overfitting when too many notes are included
  - Both: Overfitting on training data if regularization is insufficient

- **First 3 experiments**:
  1. Train NCF with 1:1 positive-to-negative ratio on top-50-code dataset to establish baseline performance
  2. Train NCF with 1:10 positive-to-negative ratio on all-ICD-codes dataset to test sparsity handling
  3. Train DHF with 1:10 ratio using 100k notes to evaluate multimodal benefit over NCF baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of recommender systems compare to other deep learning approaches for disease prediction when using the same MIMIC-III dataset and ICD-9 code subset?
- Basis in paper: [explicit] The paper compares NCF performance to BERT and CNN approaches from Zhang et al. and Mullenbach et al., showing higher F1 and accuracy scores.
- Why unresolved: While comparisons are made to specific models, a comprehensive benchmarking against all relevant deep learning approaches (including recent transformer-based models) is not provided.
- What evidence would resolve it: Systematic evaluation of NCF and DHF models against a comprehensive suite of state-of-the-art deep learning models (including transformers, graph neural networks, and attention mechanisms) on identical MIMIC-III subsets.

### Open Question 2
- Question: What is the optimal negative sampling ratio for NCF and DHF models when predicting disease comorbidity in EHR data?
- Basis in paper: [explicit] The paper tests 1:10, 1:4, and 1:2 positive-to-negative ratios but doesn't provide definitive guidance on which ratio is optimal across different dataset sizes and model architectures.
- Why unresolved: The study shows varying performance across ratios but doesn't establish a theoretical or empirical basis for selecting the optimal ratio in different clinical prediction scenarios.
- What evidence would resolve it: Comprehensive ablation studies varying negative sampling ratios across different dataset sizes, disease code frequencies, and model architectures to establish generalizable guidelines.

### Open Question 3
- Question: How does the inclusion of additional clinical data modalities (images, lab results, vital signs) impact the performance of recommender systems for comorbidity prediction?
- Basis in paper: [inferred] The paper focuses on ICD codes and clinical notes, but MIMIC-III contains additional modalities that could enhance prediction, and the hybrid model shows benefits from multimodal data integration.
- Why unresolved: The current study only incorporates structured ICD codes and text data, leaving the question of how other clinical data types would affect model performance unanswered.
- What evidence would resolve it: Evaluation of NCF and DHF models with progressively more clinical modalities (images, lab results, physiological signals) to quantify performance gains and identify optimal data combinations.

## Limitations
- Evaluation conducted on single dataset (MIMIC-III) without external validation, limiting generalizability to other healthcare systems
- NLP preprocessing pipeline for clinical notes is not fully specified, making it difficult to assess the quality and consistency of symptom extraction
- Comparison with traditional NLP approaches is limited to Zhang et al.'s work without broader benchmarking against established comorbidity prediction methods

## Confidence

**High confidence**: The superiority of NCF over reduced datasets (top-50 ICD codes) is well-supported by the reported metrics and the mechanistic explanation of how deep learning handles sparsity. The claim that multimodal fusion improves performance through DHF is also strongly supported by the numerical results.

**Medium confidence**: The comparison with traditional NLP approaches (Zhang et al.) is valid but limited in scope. The generalizability of results to other healthcare datasets remains uncertain due to single-dataset evaluation.

**Low confidence**: The specific contribution of NLP features versus the increased model complexity in DHF cannot be precisely quantified from the reported results. The optimal positive-to-negative sampling ratio is identified but not systematically explored across all conditions.

## Next Checks

1. **External validation**: Test the NCF and DHF models on a different healthcare dataset (e.g., eICU or another hospital system) to assess generalizability of the ~90% accuracy claim.

2. **Ablation study**: Conduct systematic removal of NLP features in DHF to quantify their exact contribution versus the baseline NCF model, controlling for model complexity.

3. **Sensitivity analysis**: Vary the positive-to-negative sampling ratio systematically (1:2, 1:4, 1:10, 1:20) on both datasets to identify optimal sampling strategies and test the robustness of the "1:10 ratio gives best performance" claim.