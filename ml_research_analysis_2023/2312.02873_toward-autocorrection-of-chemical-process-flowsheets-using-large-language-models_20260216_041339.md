---
ver: rpa2
title: Toward autocorrection of chemical process flowsheets using large language models
arxiv_id: '2312.02873'
source_url: https://arxiv.org/abs/2312.02873
tags:
- flowsheet
- flowsheets
- process
- autocorrection
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel approach for autocorrecting chemical
  process flowsheets using large language models (LLMs). The authors train a sequence-to-sequence
  transformer model on synthetic flowsheet data to automatically identify and suggest
  corrections for errors in process flow diagrams and instrumentation diagrams.
---

# Toward autocorrection of chemical process flowsheets using large language models

## Quick Facts
- arXiv ID: 2312.02873
- Source URL: https://arxiv.org/abs/2312.02873
- Reference count: 2
- Key outcome: Sequence-to-sequence transformer achieves 80.1% top-1 accuracy on autocorrecting synthetic flowsheets

## Executive Summary
This paper presents a novel approach for autocorrecting chemical process flowsheets using large language models. The authors train a sequence-to-sequence transformer model on synthetic flowsheet data to automatically identify and suggest corrections for errors in process flow diagrams and instrumentation diagrams. The model achieves a top-1 accuracy of 80.1% and a top-5 accuracy of 83.6% on an independent test dataset of synthetically generated flowsheets, demonstrating the potential of using LLMs to improve chemical process design efficiency and safety.

## Method Summary
The authors formulate flowsheet autocorrection as a machine translation problem, converting erroneous flowsheets to correct versions using a sequence-to-sequence transformer. They generate synthetic training data by defining 27 common error patterns and creating erroneous versions of each, then combining them into complete flowsheet pairs using Monte Carlo graph generation. Flowsheets are serialized into SFILES 2.0 notation and tokenized into a 53-token vocabulary for transformer processing. A T5-small model is trained on 500,000 synthetic pairs with hyperparameter tuning, using beam search for output generation.

## Key Results
- Model achieves 80.1% top-1 accuracy and 83.6% top-5 accuracy on synthetic test data
- Successfully learns to autocorrect flowsheets by adding missing components, removing incorrect ones, and rearranging elements
- Demonstrates feasibility of using transformer models for flowsheet error detection and correction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The sequence-to-sequence transformer can learn to autocorrect flowsheets by treating the problem as machine translation from erroneous to correct flowsheets.
- Mechanism: The model takes a flowsheet string in SFILES 2.0 notation as input and generates a corrected flowsheet string. By training on synthetic pairs where erroneous flowsheets are mapped to correct versions, the model learns patterns of missing components, incorrect connections, and rearrangements.
- Core assumption: There exists a learnable mapping between erroneous and correct flowsheet representations that can be captured by a transformer model.
- Evidence anchors:
  - [abstract]: "We propose a novel generative AI methodology for automatically identifying errors in flowsheets and suggesting corrections to the user, i.e., autocorrecting flowsheets."
  - [section]: "In this study, we propose to formulate the autocorrection of flowsheets as a machine translation problem where potentially erroneous flowsheets are translated to correct flowsheets."
  - [corpus]: Found 25 related papers, but none directly test transformer models for flowsheet autocorrection, making this approach novel.
- Break condition: If the erroneous-correct flowsheet pairs are too dissimilar or if errors involve complex interdependencies that cannot be captured in the SFILES string representation, the model will fail to learn effective corrections.

### Mechanism 2
- Claim: The SFILES 2.0 notation enables effective tokenization of flowsheet information for transformer processing.
- Mechanism: Flowsheets are serialized into strings using SFILES 2.0, then tokenized into a vocabulary of 53 tokens representing unit operations, materials, and control structures. These tokens are embedded and processed through the transformer's attention mechanism.
- Core assumption: The SFILES 2.0 notation captures sufficient topological and structural information about flowsheets to enable error detection and correction through string manipulation.
- Evidence anchors:
  - [abstract]: "The model achieves a top-1 accuracy of 80% and a top-5 accuracy of 84% on an independent test dataset of synthetically generated flowsheets."
  - [section]: "We define 27 patterns commonly occurring in flowsheets... We aggregate different patterns to complete flowsheets using a Monte Carlo graph generation approach."
  - [corpus]: The corpus contains related work on SFILES representations and transformer applications in chemical engineering, supporting the viability of this approach.
- Break condition: If SFILES 2.0 cannot represent complex flowsheet features (e.g., detailed instrumentation, non-linear relationships), or if tokenization loses critical information, the model will struggle with accuracy.

### Mechanism 3
- Claim: Synthetic data generation with predefined error patterns enables supervised training without requiring manually labeled industrial flowsheets.
- Mechanism: The researchers define 27 common error patterns, create erroneous versions of each, then combine them into complete flowsheet pairs using Monte Carlo generation. This creates a large dataset (500,000 pairs) where the mapping from erroneous to correct is known.
- Core assumption: Synthetic error patterns adequately represent real-world flowsheet errors that the model needs to correct.
- Evidence anchors:
  - [abstract]: "We train our autocorrection model on a synthetic dataset in a supervised manner."
  - [section]: "We define 27 patterns commonly occurring in flowsheets... For each pattern, we define up to nine erroneous versions."
  - [corpus]: The corpus shows limited existing work on ML-based flowsheet error correction, suggesting synthetic data approaches are underexplored.
- Break condition: If synthetic patterns don't capture the complexity or distribution of real industrial errors, the model will have poor generalization to actual engineering workflows.

## Foundational Learning

- Concept: Sequence-to-sequence transformer architecture
  - Why needed here: This architecture enables the model to take a flowsheet string as input and generate a corrected flowsheet string, treating the problem as translation between two text representations.
  - Quick check question: What is the key advantage of using a sequence-to-sequence transformer over a simple autoencoder for this task?

- Concept: SFILES 2.0 notation and tokenization
  - Why needed here: SFILES 2.0 provides a text-based representation of flowsheets that can be tokenized and processed by the transformer, enabling the application of NLP techniques to engineering diagrams.
  - Quick check question: How many tokens are in the SFILES 2.0 vocabulary, and what types of flowsheet elements do they represent

- Concept: Synthetic data generation with error patterns
  - Why needed here: Creates supervised training data where the mapping from erroneous to correct flowsheets is known, without requiring manual labeling of industrial flowsheets.
  - Quick check question: How many error patterns were defined, and how many erroneous versions were created for each pattern?

## Architecture Onboarding

### Component Map
Synthetic flowsheet pairs (erroneous -> correct) -> SFILES 2.0 serialization -> Tokenization (53 tokens) -> T5-small transformer -> Beam search output generation -> Corrected flowsheet

### Critical Path
Synthetic data generation -> SFILES conversion and tokenization -> Transformer training -> Beam search decoding -> Accuracy evaluation on test set

### Design Tradeoffs
- Using synthetic data enables large-scale training but may not capture real-world error complexity
- SFILES 2.0 notation enables transformer processing but may lose spatial/graph information
- Sequence-to-sequence approach treats autocorrection as translation but may struggle with complex flowsheet dependencies

### Failure Signatures
- Model fails to correct existing errors or only partially corrects them
- Model introduces new errors or violates SFILES 2.0 notation rules
- Poor generalization to flowsheets outside the synthetic distribution

### First 3 Experiments
1. Test model on flowsheets with error patterns not in the training set to assess generalization
2. Evaluate model performance on flowsheets of increasing size and complexity
3. Compare model accuracy when trained on synthetic vs. real industrial flowsheets (when available)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the model perform when trained on industrial flowsheets instead of synthetic data?
- Basis in paper: [explicit] The authors mention planning to train the algorithm on industrial flowsheets in the future and note that the current model is limited to synthetic data.
- Why unresolved: The current study only evaluates the model on synthetically generated flowsheets, which may not fully capture the complexity and variability of real industrial flowsheets.
- What evidence would resolve it: Evaluating the model's accuracy on a dataset of real industrial flowsheets and comparing its performance to the synthetic data results.

### Open Question 2
- Question: How can physical/engineering knowledge be integrated into the autocorrection model?
- Basis in paper: [explicit] The authors suggest integrating rule-based methods with data-driven approaches and mention the potential of graph neural networks to add physical/engineering knowledge.
- Why unresolved: The current model lacks physical/engineering knowledge, which could improve its accuracy and ability to handle complex flowsheet errors.
- What evidence would resolve it: Demonstrating improved model performance by incorporating physical/engineering knowledge through methods like rule-based integration or graph neural networks.

### Open Question 3
- Question: How does the model's performance scale with the size and complexity of flowsheets?
- Basis in paper: [inferred] The authors mention that the current model is limited to topology information and suggest exploring graph representations to handle more complex diagrams in the future.
- Why unresolved: The study only evaluates the model on synthetically generated flowsheets with predefined error patterns, and it's unclear how it would perform on larger, more complex industrial flowsheets.
- What evidence would resolve it: Testing the model on flowsheets of increasing size and complexity, measuring its accuracy and computational efficiency, and comparing its performance to other autocorrection methods.

## Limitations

- Synthetic data may not capture the full complexity and variety of real-world flowsheet errors
- SFILES 2.0 notation may lose critical information about flowsheet semantics and spatial relationships
- Transformer model treats flowsheets as text sequences, limiting ability to capture graph structures and complex dependencies

## Confidence

- High confidence in technical implementation: Methodology is clearly specified and reproducible
- Medium confidence in claimed benefits: Feasibility demonstrated but real-world engineering workflow improvement requires additional validation
- Low confidence in generalization: Performance on synthetic data doesn't guarantee success on actual industrial flowsheets

## Next Checks

1. **Real-world error distribution validation**: Compare the 27 synthetic error patterns against a sample of actual industrial flowsheets to assess whether the synthetic errors represent realistic failure modes.

2. **Ablation study on SFILES 2.0 limitations**: Systematically test the model's performance on flowsheet features that may not be well-captured by SFILES 2.0 (e.g., complex control structures, non-linear flows) to identify representational gaps.

3. **Human-in-the-loop validation**: Have experienced chemical engineers evaluate the model's corrections on a set of real or realistically complex flowsheets to assess practical utility and identify failure modes not captured by automated metrics.