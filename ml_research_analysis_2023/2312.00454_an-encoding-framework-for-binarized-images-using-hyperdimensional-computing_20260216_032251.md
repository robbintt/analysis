---
ver: rpa2
title: An Encoding Framework for Binarized Images using HyperDimensional Computing
arxiv_id: '2312.00454'
source_url: https://arxiv.org/abs/2312.00454
tags:
- accuracy
- mapping
- encoding
- linear
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes a novel light-weight encoding approach for binarized
  images in hyperdimensional computing (HDC) that preserves similarity of patterns
  at nearby locations. The method uses point of interest selection to derive local
  features and local linear mapping to encode the global position of these features.
---

# An Encoding Framework for Binarized Images using HyperDimensional Computing

## Quick Facts
- **arXiv ID:** 2312.00454
- **Source URL:** https://arxiv.org/abs/2312.00454
- **Reference count:** 40
- **Key outcome:** Proposed encoding approach achieves 97.35% accuracy on MNIST and 84.12% on Fashion-MNIST while demonstrating higher robustness to noise and blur compared to baseline encoding.

## Executive Summary
This work introduces a novel light-weight encoding framework for binarized images in hyperdimensional computing that preserves spatial similarity between nearby patterns. The method combines point of interest selection with local linear mapping to encode both local features and global positions. By focusing on non-background pixels and their local neighborhoods, the approach improves classification accuracy while reducing sensitivity to noise and blur. The framework is evaluated on MNIST and Fashion-MNIST datasets, showing significant improvements over baseline encoding methods.

## Method Summary
The encoding framework processes binarized images by first identifying point of interest (POI) pixels where Ibin[x,y]=1. For each POI, a square patch of predefined size z is extracted and encoded by binding each pixel's binary value with its local position. Global positions are encoded using local linear mapping with S splits, where similarity gradually decays within splits and becomes orthogonal across splits. The final image vector is created by bundling all patch vectors bound with their corresponding global position vectors. Classification is performed by comparing image vectors with class prototypes using Hamming distance.

## Key Results
- Achieves 97.35% classification accuracy on MNIST dataset
- Achieves 84.12% classification accuracy on Fashion-MNIST dataset
- Demonstrates higher robustness to noise and blur compared to baseline encoding approaches
- Shows improved performance by focusing on point of interest pixels while ignoring background noise

## Why This Works (Mechanism)

### Mechanism 1: Local Linear Mapping
Local linear mapping preserves similarity between nearby positions while enforcing orthogonality for distant positions. The image is split into S splits, each with L-1/S+1 levels. Linear mapping is applied within each split, so adjacent positions in the same split differ by D/2^((L-1)/S) bits, while positions in different splits are mapped to orthogonal vectors. This creates a gradual similarity decay for nearby positions and sharp drops for distant ones. Core assumption: Similarity should decay gradually for nearby positions and become orthogonal for distant positions to preserve local structure.

### Mechanism 2: Point of Interest Selection and Patch Encoding
POI selection and patch encoding extracts local features while ignoring background noise. POIs are selected as pixels with Ibin[x,y]=1. A patch of size z around each POI is extracted, and each pixel in the patch is encoded as a binding of its binary value, x position, and y position. This creates a local feature vector for each POI that captures its immediate neighborhood. Core assumption: Background pixels are noise that should be ignored, and local neighborhoods contain discriminative information for classification.

### Mechanism 3: Binding POI Features with Global Positions
Binding POI feature vectors with their global positions preserves spatial relationships. Each POI's local feature vector (vP@(x,y)) is bound with its global x and y position vectors (vx=x ⊗ vy=y) using the binding operation. This creates an image vector that combines local features with their spatial arrangement. During classification, the similarity between this image vector and class prototypes is computed. Core assumption: Spatial relationships between local features are important for classification and can be preserved through binding.

## Foundational Learning

- **Hyperdimensional Computing basics:** Understanding HVs, similarity via Hamming distance, and HD arithmetic operations (bundling, binding, permutation). Why needed: The entire encoding framework relies on these fundamental HDC concepts. Quick check: What is the difference between bundling and binding in HDC, and when would you use each?

- **Linear vs orthogonal mapping:** Linear mapping for ordinal/discrete data vs orthogonal mapping for nominal data. Why needed: The framework uses linear mapping for position encoding to preserve similarity between nearby positions. Quick check: How does linear mapping ensure that similar values are mapped to similar HVs, and why is this important for position encoding?

- **Binarization techniques:** Impact of binarization threshold on feature extraction. Why needed: The input images are binarized using a threshold, which affects which pixels are selected as POIs. Quick check: How does the choice of binarization threshold affect the number and distribution of POIs, and consequently the classification performance?

## Architecture Onboarding

- **Component map:** Input image → Binarization → POI selection → Patch creation → Patch encoding → Position encoding → Image encoding → Classification
- **Critical path:** Binarization → POI selection → Patch creation → Patch encoding → Position encoding → Image encoding → Classification
- **Design tradeoffs:** Patch size z (larger captures more context but increases computational cost), Number of splits S (more splits create sharper similarity decay but reduce similar position range), Binarization threshold Tbin (lower selects more POIs but may include background noise)
- **Failure signatures:** Low training accuracy (issues with patch encoding or position mapping), High training but low validation accuracy (overfitting), Slow convergence (inefficient encoding), Sensitivity to noise (threshold too low or patch size too large)
- **First 3 experiments:** 1) Implement pixel-wise encoding with linear mapping (S=1) and compare accuracy with proposed POI encoding, 2) Test different numbers of splits S (1, 3, 9, 28) with fixed patch size to find optimal balance, 3) Vary patch size z (3, 5, 7) with optimal S to determine best local feature extraction strategy

## Open Questions the Paper Calls Out
- **Question:** How does the performance of the proposed encoding framework change when applied to grayscale and color images compared to binarized images?
- **Basis:** The authors suggest evaluating and extending the proposed encoding approach for application to grayscale and color images in the future work section.
- **Why unresolved:** The current study only focuses on binarized images, and the performance of the framework on grayscale and color images is not investigated.
- **What evidence would resolve it:** Conducting experiments to test the encoding framework on grayscale and color images, comparing the performance metrics with the results obtained for binarized images.

## Limitations
- Limited sensitivity analysis for the number of splits S (only tested 1, 3, 9 values)
- Fixed binarization threshold Tbin=0 without thorough investigation of its impact across varying image qualities
- 10-fold cross-validation used for hyperparameter tuning, but robustness across different datasets or noise levels not fully explored

## Confidence
- **High confidence:** Basic HDC encoding operations (binding, bundling) and their implementation are well-established and correctly applied
- **Medium confidence:** Local linear mapping approach for position encoding is novel and theoretically sound, but empirical validation across diverse conditions is limited
- **Medium confidence:** POI selection strategy improves robustness to noise, but optimal patch size generalizability to other image types requires further validation

## Next Checks
1. Systematically vary Tbin from 0 to 128 and measure classification accuracy degradation on both clean and noisy MNIST images
2. Apply the framework to grayscale CIFAR-10 images (after binarization) to test whether local linear mapping provides similar benefits for non-binarized-like patterns
3. Conduct a finer-grained search over S (1-28) with step size 2 and perform statistical significance testing to confirm S=9 is truly optimal, not just locally optimal