---
ver: rpa2
title: Can We Identify Stance Without Target Arguments? A Study for Rumour Stance
  Classification
arxiv_id: '2303.12665'
source_url: https://arxiv.org/abs/2303.12665
tags:
- uni00000013
- uni00000011
- stance
- uni00000015
- uni00000014
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines the effectiveness of target-aware versus target-oblivious
  models for rumor stance classification. The authors demonstrate that a substantial
  portion of replies in real-world rumor data are target-independent, enabling target-oblivious
  models to perform competitively.
---

# Can We Identify Stance Without Target Arguments? A Study for Rumour Stance Classification

## Quick Facts
- arXiv ID: 2303.12665
- Source URL: https://arxiv.org/abs/2303.12665
- Authors: 
- Reference count: 26
- Primary result: Target-oblivious models perform competitively on rumor stance classification because many replies are naturally target-independent, though both target-aware and target-oblivious models rely heavily on superficial cues.

## Executive Summary
This paper investigates whether target context is necessary for accurate rumor stance classification. The authors demonstrate that a substantial portion of replies in real-world rumor data are naturally target-independent, allowing target-oblivious models to perform competitively with target-aware models. Through adversarial attacks, they reveal that current models, including conversation-aware systems, rely heavily on superficial cues like negation and question marks rather than genuine reasoning about the stance-target relationship. The study suggests using target-oblivious models as a baseline and improving target modeling to handle both target-dependent and -independent cases.

## Method Summary
The authors evaluate multiple transformer-based models (BERTweet, BERT, RoBERTa, XLNet) in both target-aware and target-oblivious settings on the RumourEval 2019 dataset. They reproduce conversation-aware models including Hierarchical BERT and Branch-LSTM. The models are fine-tuned with AdamW optimizer using class weights to address imbalance. Adversarial attacks (negation stress tests, punctuation removal) are applied to probe model robustness. Hyperparameter tuning uses grid search with early stopping based on validation weighted F2.

## Key Results
- Target-oblivious models achieve competitive performance because a large portion of replies are naturally target-independent
- Adversarial attacks reveal models rely heavily on superficial cues like negation and question marks
- Masking the source tweet has minimal impact on target-aware models' predictions, suggesting limited effective use of context

## Why This Works (Mechanism)

### Mechanism 1
Target-oblivious models perform competitively because a large portion of real-world rumor replies are naturally target-independent, allowing models to predict stance without needing the target context. The model learns to recognize stance-indicative lexical cues (e.g., negation, question marks) in the reply itself, bypassing the need to relate the reply to the source tweet. During training, target-independent examples dominate certain classes (deny, query), reinforcing reliance on reply-level cues. Core assumption: The dataset contains a non-trivial amount of target-independent replies that can be identified without the source context. Break condition: If the dataset were artificially balanced to remove target-independent examples, target-oblivious models would lose their competitive edge.

### Mechanism 2
Adversarial attacks reveal that current models rely on superficial cues like negation and question marks, rather than genuine reasoning about the stance-target relationship. The model exploits strong correlations between specific surface features and target classes. For example, question marks strongly indicate "query" stance, and negation terms often indicate "deny." Adversarial attacks that remove these features expose the model's dependence on them. Core assumption: The model has not learned deeper semantic reasoning between reply and source, but instead uses simple lexical patterns. Break condition: If the model incorporated explicit reasoning modules or cross-attention between reply and source, it would be less vulnerable to such attacks.

### Mechanism 3
Target-aware and conversation-aware models do not consistently outperform target-oblivious models because they fail to effectively integrate the source context when it is necessary, sometimes treating it as noise. Even when given the source tweet, the model does not reliably use it to disambiguate target-dependent cases. In some instances, masking the source has minimal impact on predictions, indicating that the source is not meaningfully contributing to the decision process. Core assumption: The model architecture or training objective does not enforce or reward proper reasoning between source and reply. Break condition: If the model were explicitly trained to detect when the target is necessary (e.g., via a pretext task), it would use the source more effectively.

## Foundational Learning

- **Concept**: Understanding of stance classification as a target-dependent task, where the stance is defined relative to a specific target (e.g., a rumor story)
  - **Why needed here**: The paper's central question is whether the target is truly necessary for accurate stance prediction in rumor stance classification
  - **Quick check**: Can you explain the difference between sentiment analysis (target-independent) and stance classification (target-dependent)?

- **Concept**: Familiarity with adversarial attacks in NLP, specifically methods like negation stress tests and punctuation removal to probe model robustness
  - **Why needed here**: The paper uses these attacks to demonstrate that models rely on superficial cues rather than deep reasoning
  - **Quick check**: What is the purpose of adding "False is not true and" to the beginning of a sentence in a negation stress test?

- **Concept**: Knowledge of conversation structure in social media, including source tweets, replies, and the concept of target-independence in replies
  - **Why needed here**: The paper analyzes how target-independent replies in rumor conversations enable target-oblivious models to perform well
  - **Quick check**: What makes a reply to a rumor tweet "target-independent"?

## Architecture Onboarding

- **Component map**: Pre-trained transformer (BERTweet, BERT, RoBERTa, XLNet) → classification head → output probabilities; optionally conversation encoder for conversation-aware models
- **Critical path**: Tokenization → embedding → transformer layers → [conversation encoder if applicable] → classification head → output probabilities
- **Design tradeoffs**: Target-oblivious models are simpler and less data-hungry but miss context when needed; target-aware models are more complex and can capture context but may overfit to spurious cues if not carefully designed
- **Failure signatures**: Over-reliance on punctuation or negation terms, poor performance on target-dependent examples, minimal change in predictions when source is masked
- **First 3 experiments**:
  1. Compare target-oblivious vs. target-aware models on a balanced dataset with equal target-dependent and target-independent examples
  2. Train a model with an auxiliary task to predict whether a reply is target-independent or target-dependent, then use that prediction to decide whether to use the source
  3. Apply more diverse adversarial attacks (e.g., synonym replacement, sentence reordering) to test robustness beyond punctuation and negation

## Open Questions the Paper Calls Out

### Open Question 1
How does the distribution of target-independent versus target-dependent replies vary across different rumor events or topics in the dataset? The paper analyzes target-independent tweets in the RumourEval 2019 dataset but does not explore how this distribution might differ across different rumor events or topics. This remains unresolved because the paper focuses on analyzing the dataset as a whole without examining potential variations in target-independence across different rumor topics. Analyzing the proportion of target-independent tweets for each rumor event or topic in the dataset would resolve this.

### Open Question 2
How would the performance of target-oblivious models change if the dataset were rebalanced to have an equal number of target-independent and target-dependent examples? The paper discusses the impact of target-independent tweets on model performance and suggests balancing the test set, but does not experimentally test the effect of rebalancing the dataset on model performance. Training and evaluating models on a rebalanced dataset with equal proportions of target-independent and target-dependent examples would resolve this.

### Open Question 3
Can target-aware models be improved by incorporating additional contextual information beyond just the source tweet, such as the full conversation thread or external knowledge? The paper shows that target-aware models underperform and struggle with reasoning between the source and reply, suggesting that additional context or knowledge might help. The paper does not explore whether incorporating more context or external knowledge could improve target-aware models. Experimenting with target-aware models that incorporate additional contextual information or external knowledge and comparing their performance to baseline models would resolve this.

## Limitations

- The analysis of target-independence relies on qualitative interpretation of dataset patterns rather than rigorous statistical validation
- The claim that masking the target has minimal impact on predictions conflates two distinct possibilities: either the source is truly unnecessary for certain examples, or the model architecture fails to properly integrate the source when it is available
- The adversarial attack results show model reliance on superficial cues, but the paper does not explore whether these findings generalize beyond negation and punctuation to other linguistic phenomena or datasets

## Confidence

**High confidence**: The observation that a substantial portion of replies in real-world rumor data are target-independent, enabling target-oblivious models to perform competitively. This is directly supported by dataset analysis and consistent with the observed model performance patterns.

**Medium confidence**: The claim that adversarial attacks reveal heavy reliance on superficial cues like negation and question marks. While the attacks demonstrate this vulnerability, the paper does not establish whether this represents a fundamental limitation of the approach or a solvable architectural issue.

**Low confidence**: The assertion that conversation-aware models show limited robustness. The paper provides some evidence through masking experiments, but does not thoroughly investigate whether this reflects architectural limitations or insufficient training data for conversation modeling.

## Next Checks

1. **Statistical validation of target-independence**: Conduct a systematic annotation study to quantify the proportion of genuinely target-independent replies in the dataset, using multiple annotators to establish inter-rater reliability and clear criteria for target-independence.

2. **Adversarial robustness beyond surface features**: Design and execute a comprehensive battery of adversarial attacks that target semantic understanding (e.g., synonym replacement, sentence reordering, semantic-preserving transformations) to determine whether models can learn deeper reasoning beyond lexical cues.

3. **Architecture ablation study**: Systematically disable different model components (attention mechanisms, contextual embeddings, conversation encoders) to identify which architectural choices contribute most to target-awareness and which can be safely omitted for target-independent examples.