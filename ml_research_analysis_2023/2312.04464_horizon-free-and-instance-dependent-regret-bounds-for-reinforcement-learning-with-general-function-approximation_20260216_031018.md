---
ver: rpa2
title: Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning
  with General Function Approximation
arxiv_id: '2312.04464'
source_url: https://arxiv.org/abs/2312.04464
tags:
- dimf
- have
- lemma
- proof
- regret
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes the first algorithm, UCRL-WVTR, that achieves
  both horizon-free and instance-dependent regret bounds for reinforcement learning
  with general function approximation. The algorithm utilizes weighted value-targeted
  regression and a high-order moment estimator, and employs a regression oracle for
  efficient planning.
---

# Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation

## Quick Facts
- **arXiv ID:** 2312.04464
- **Source URL:** https://arxiv.org/abs/2312.04464
- **Reference count:** 40
- **Primary result:** First algorithm achieving both horizon-free and instance-dependent regret bounds for RL with general function approximation

## Executive Summary
This paper introduces UCRL-WVTR, a novel algorithm that achieves horizon-free and instance-dependent regret bounds for reinforcement learning with general function approximation. The method combines weighted value-targeted regression with a high-order moment estimator to improve variance estimation and model accuracy. By leveraging a Bernstein-style concentration inequality for weighted non-linear regression, the algorithm eliminates polynomial dependence on the horizon while maintaining sharp instance-dependent guarantees. The approach is validated through experiments on the RiverSwim environment, demonstrating improved sample efficiency compared to existing methods.

## Method Summary
The paper proposes UCRL-WVTR, an algorithm that uses weighted value-targeted regression (WVTR) with variance-aware weights to improve model estimation accuracy. The method employs a high-order moment estimator to recursively calculate variances of value functions up to M levels, enabling more precise variance estimation. A novel Bernstein-style concentration bound for weighted non-linear regression provides tighter error guarantees that eliminate horizon dependence. The algorithm uses a regression oracle for efficient planning and incorporates optimism through confidence bonuses based on uncertainty estimates. The approach maintains computational efficiency while achieving sharp regret bounds that match the minimax lower bound for linear mixture MDPs up to logarithmic factors.

## Key Results
- First algorithm achieving both horizon-free and instance-dependent regret bounds for general function approximation
- Derived regret bound matches minimax lower bound for linear mixture MDPs up to logarithmic factors
- Demonstrated improved sample efficiency through RiverSwim experiments
- Computational complexity analysis showing the algorithm remains tractable

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Weighted value-targeted regression reduces regret by prioritizing high-variance data points
- **Mechanism:** The algorithm assigns higher weights to data points with lower variance and uncertainty, improving model estimation accuracy
- **Core assumption:** Variance estimates can be accurately computed using the high-order moment estimator
- **Evidence anchors:** Weak evidence - no direct citation supporting weighted regression effectiveness

### Mechanism 2
- **Claim:** High-order moment estimation provides more accurate variance estimates for value functions
- **Mechanism:** The algorithm recursively estimates variances of higher moments (V²ᵐ) up to M levels, improving the precision of variance estimates needed for weighting
- **Core assumption:** Estimating higher moments provides better variance estimates than first-order methods
- **Evidence anchors:** Weak evidence - no direct citation supporting high-order moment estimation effectiveness

### Mechanism 3
- **Claim:** The concentration inequality enables horizon-free learning by providing tighter bounds
- **Mechanism:** A Bernstein-style concentration bound for weighted non-linear regression provides variance-aware and uncertainty-aware error bounds that eliminate polynomial dependence on horizon
- **Core assumption:** The novel concentration bound is tighter than traditional Hoeffding-type bounds
- **Evidence anchors:** Weak evidence - no direct citation supporting the specific concentration bound

## Foundational Learning

- **Concept:** Generalized Eluder dimension
  - Why needed here: Measures the complexity of the function class F in the weighted regression setting, enabling tighter generalization bounds
  - Quick check question: How does generalized Eluder dimension differ from standard Eluder dimension in terms of what it measures?

- **Concept:** Concentration inequalities for non-linear regression
  - Why needed here: Provides probabilistic bounds on estimation error for weighted non-linear least squares, crucial for regret analysis
  - Quick check question: What makes Bernstein-style bounds more suitable for this problem than Hoeffding bounds?

- **Concept:** High-order moments and variance estimation
  - Why needed here: Enables more accurate variance estimation of value functions through recursive moment calculation, improving the weighting scheme
  - Quick check question: Why does estimating V²ᵐ provide better variance estimates than just V²?

## Architecture Onboarding

- **Component map:** Weighted Value-Targeted Regression -> High-Order Moment Estimator -> Regression Oracle -> Confidence Bonus -> Action Selection

- **Critical path:** WVTR → Moment Estimator → Regression Oracle → Confidence Bonus → Action Selection

- **Design tradeoffs:**
  - Higher M values improve variance estimation accuracy but increase computational cost
  - More precise concentration bounds reduce regret but require stronger assumptions
  - Weighted regression improves sample efficiency but requires accurate variance estimates

- **Failure signatures:**
  - If weights become uniform, algorithm degenerates to standard VTR
  - If high-order moments are poorly estimated, weighting becomes ineffective
  - If regression oracle is slow, computational efficiency guarantees fail

- **First 3 experiments:**
  1. Compare regret on RiverSwim with M=1 vs M=3 to verify high-order moment benefits
  2. Test sensitivity to σmin parameter by running with different values
  3. Validate concentration bound tightness by comparing theoretical vs empirical error rates

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the algorithm perform when the value function class V is non-convex?
- **Basis in paper:** [explicit] The paper assumes V encompasses all value functions V such that V : S → [0, 1], but does not specify whether V is convex.
- **Why unresolved:** The paper's analysis relies on the convexity of the function class F, which is defined as the set of functions f : S × A × V → R such that ∃P ∈ P, f(s, a, V) = [PV](s, a) for any V ∈ V. If V is non-convex, the convexity of F is not guaranteed, which may affect the algorithm's performance.
- **What evidence would resolve it:** Experimental results on a non-convex value function class, or a theoretical analysis of the algorithm's performance under non-convex V.

### Open Question 2
- **Question:** Can the algorithm be extended to handle continuous state and action spaces?
- **Basis in paper:** [inferred] The paper focuses on finite state and action spaces, but the general function approximation framework could potentially be extended to continuous spaces.
- **Why unresolved:** The paper does not discuss the algorithm's performance in continuous spaces, and the analysis relies on the discrete nature of the state and action spaces.
- **What evidence would resolve it:** Theoretical analysis of the algorithm's performance in continuous spaces, or experimental results on a continuous state and action space problem.

### Open Question 3
- **Question:** How does the algorithm's performance scale with the size of the state and action spaces?
- **Basis in paper:** [explicit] The paper mentions that the algorithm's computational complexity is eO(KHM O + KHM R + |A|KH O + |A|KH R), where |A| is the size of the action space.
- **Why unresolved:** While the paper provides a theoretical bound on the algorithm's regret, it does not discuss how the algorithm's performance scales with the size of the state and action spaces.
- **What evidence would resolve it:** Experimental results on problems with varying state and action space sizes, or a theoretical analysis of the algorithm's performance as a function of the state and action space sizes.

## Limitations

- The regression oracle may be computationally intractable for complex function classes, potentially undermining the "efficient planning" claim
- Variance estimation through high-order moments could be numerically unstable in practice, particularly when M is large or variance estimates approach zero
- The novel concentration bound lacks empirical validation against simpler alternatives

## Confidence

- **High confidence:** The regret bound structure and its relation to existing literature (linear mixture MDPs) is well-established
- **Medium confidence:** The weighted regression framework is theoretically sound but lacks direct empirical support in the paper
- **Low confidence:** Computational efficiency claims are speculative without implementation details or runtime analysis

## Next Checks

1. Implement the regression oracle for a simple non-linear function class and measure actual computational complexity
2. Test sensitivity of performance to the choice of M in the high-order moment estimator
3. Compare empirical concentration bounds against theoretical predictions to validate the Bernstein-style bound tightness