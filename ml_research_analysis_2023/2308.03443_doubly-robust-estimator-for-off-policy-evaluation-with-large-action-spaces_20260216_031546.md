---
ver: rpa2
title: Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces
arxiv_id: '2308.03443'
source_url: https://arxiv.org/abs/2308.03443
tags:
- action
- mips
- variance
- embedding
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of Off-Policy Evaluation (OPE)
  in contextual bandit settings with large action spaces, where existing estimators
  suffer from bias due to model misspecification or variance due to importance weight.
  To overcome these limitations, the authors propose the Marginalized Doubly Robust
  (MDR) estimator, which combines the advantages of Marginalized Inverse Propensity
  Scoring (MIPS) and Doubly Robust (DR) estimators.
---

# Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces

## Quick Facts
- arXiv ID: 2308.03443
- Source URL: https://arxiv.org/abs/2308.03443
- Reference count: 0
- Key outcome: Proposed Marginalized Doubly Robust (MDR) estimator outperforms existing methods in MSE, bias, and variance for OPE with large action spaces

## Executive Summary
This paper addresses the challenge of Off-Policy Evaluation (OPE) in contextual bandit settings with large action spaces, where existing estimators suffer from bias due to model misspecification or high variance from importance weights. The authors propose the Marginalized Doubly Robust (MDR) estimator, which combines Marginalized Inverse Propensity Scoring (MIPS) with a doubly robust structure. MDR achieves unbiasedness under weaker assumptions than MIPS while maintaining variance reduction benefits, making it particularly effective when the action space cardinality is large.

## Method Summary
The MDR estimator addresses OPE challenges by combining a parametric baseline estimator with an importance-weighted residual term using marginalized importance weights. Unlike traditional approaches that use full action space importance weights, MDR leverages action embeddings to marginalize over the action space, reducing variance. The estimator is unbiased if either the expected reward function is perfectly estimated or the no direct effect assumption holds. The method combines the variance reduction of MIPS with the robustness of doubly robust estimation, making it suitable for large action spaces where traditional importance sampling suffers from high variance.

## Key Results
- MDR outperforms existing estimators (DM, IPS, DR, MIPS) in terms of MSE, bias, and variance
- MDR maintains variance reduction against IPS while achieving unbiasedness under weaker assumptions than MIPS
- The performance advantage of MDR becomes more pronounced as the cardinality of the action space increases
- Empirical results validate theoretical claims on synthetic data with varying action space sizes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MDR achieves variance reduction by replacing the vanilla importance weight with a marginalized importance weight over action embeddings.
- Mechanism: The marginalized importance weight $w(x,e) = p(e|x,\pi_e)/p(e|x,\pi_b)$ reduces the cardinality of the importance weight space, leading to lower variance compared to the full action space importance weight $w(x,a) = \pi_e(a|x)/\pi_b(a|x)$.
- Core assumption: Action embeddings sufficiently characterize the action such that the marginal distribution over embeddings provides a good approximation to the full action distribution.
- Evidence anchors: [abstract] "MIPS uses the marginal importance weight $w(x,e)$ where $e \in E \subset \mathbb{R}^{de}$ is the embedding of the action." [section] "Therefore, using the embedding for the marginal importance weight improves the variance of the MIPS." [corpus] Found 25 related papers. Average neighbor FMR=0.456. Top related titles include "Marginal Density Ratio for Off-Policy Evaluation in Contextual Bandits."
- Break condition: The embedding space E does not adequately represent the action space A, leading to significant information loss and biased estimates.

### Mechanism 2
- Claim: MDR maintains unbiasedness under weaker assumptions than MIPS by incorporating a doubly robust structure.
- Mechanism: MDR combines a parametric baseline estimator with an importance-weighted residual term, achieving unbiasedness if either the expected reward function is perfectly estimated or the no direct effect assumption holds.
- Core assumption: Either Assumption 3 (No Direct Effect) and Assumption 4 (Common Embedding Support) hold, or Assumption 5 (Perfect Estimation of Expected Reward given x, a, and e) is satisfied.
- Evidence anchors: [abstract] "MDR is unbiased under weaker assumptions than MIPS while maintaining variance reduction against IPS." [section] "MDR has a doubly robust property under either the no direct effect and the common embedding support or the following assumption about the precision of the prediction of the reward function." [corpus] Weak corpus evidence - no direct citations found supporting this specific doubly robust claim.
- Break condition: Both the no direct effect assumption and the perfect estimation assumption fail simultaneously, leading to biased estimates.

### Mechanism 3
- Claim: MDR achieves lower bias than MIPS by incorporating a baseline estimator that corrects for model misspecification.
- Mechanism: The first term of MDR $E_{\pi_e(a|x)}[b q(x,a)]$ uses a parametric model to estimate the expected reward, which can reduce bias when the model is reasonably accurate.
- Core assumption: The regression model $b q$ provides a reasonable approximation to the true expected reward function $q(x,a)$.
- Evidence anchors: [abstract] "MDR has a lower bias than MIPS in this setting—this favorable property of MDR against MIPS results from the doubly robust property of MDR." [section] "The first term of MDR is the baseline estimator, which uses the regression model $b q$ to incorporate the parametric approach." [corpus] No direct corpus evidence supporting this specific bias reduction claim.
- Break condition: The regression model $b q$ is severely misspecified, leading to large errors that cannot be corrected by the importance-weighted residual term.

## Foundational Learning

- Concept: Importance Sampling and its variance issues in large action spaces
  - Why needed here: Understanding why vanilla importance sampling suffers from high variance when the action space is large is crucial for appreciating why MDR uses marginalized importance weights.
  - Quick check question: What causes the high variance in importance sampling when the action space is large, and how does using action embeddings help mitigate this issue?

- Concept: Doubly Robust estimation and its properties
- Why needed here: MDR builds on the doubly robust framework, so understanding how doubly robust estimators achieve unbiasedness under weaker assumptions than single robustness methods is essential.
- Quick check question: What are the two conditions under which a doubly robust estimator is unbiased, and how does this differ from a single robustness estimator?

- Concept: Action embeddings and their role in reducing dimensionality
- Why needed here: MDR relies on action embeddings to marginalize the importance weight, so understanding how embeddings can capture the essential characteristics of actions while reducing dimensionality is important.
- Quick check question: How do action embeddings help reduce the dimensionality of the importance weight space, and what are the potential risks of using embeddings?

## Architecture Onboarding

- Component map: Data processing -> Model training -> Embedding selection -> Importance weight calculation -> MDR estimation -> Evaluation
- Critical path: Data → Model Training → Embedding Selection → Importance Weight Calculation → MDR Estimation → Evaluation
- Design tradeoffs:
  - Embedding quality vs. computational complexity: Higher-quality embeddings may provide better variance reduction but require more complex selection algorithms
  - Model complexity vs. bias: More complex regression models may reduce bias but increase variance and computational cost
  - Sample size vs. estimator accuracy: Larger sample sizes generally improve estimator accuracy but increase computational requirements
- Failure signatures:
  - High variance in MDR estimates: May indicate poor embedding selection or insufficient sample size
  - Persistent bias in MDR estimates: May suggest model misspecification or violation of the no direct effect assumption
  - Unstable importance weights: May indicate issues with the embedding selection or behavior policy
- First 3 experiments:
  1. Compare MDR variance with IPS and DR on synthetic data with varying action space sizes to verify variance reduction claims
  2. Test MDR bias under different levels of model misspecification to assess robustness to the perfect estimation assumption
  3. Evaluate MDR performance with different embedding selection methods (e.g., SLOPE, PAS-IF) to determine optimal embedding strategy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal method for selecting action embeddings to satisfy the common embedding support assumption?
- Basis in paper: [inferred] The paper mentions that finding better action embeddings is crucial for unbiasedness and suggests using SLOPE or PAS-IF for data-driven embedding selection.
- Why unresolved: The paper does not provide a definitive method for selecting optimal embeddings and leaves this as an open direction for future work.
- What evidence would resolve it: Empirical results comparing different embedding selection methods (SLOPE, PAS-IF, and others) on their impact on MDR's bias and variance.

### Open Question 2
- Question: Can MDR be extended to a triply robust estimator by combining it with other doubly robust estimators under different assumptions?
- Basis in paper: [explicit] The authors mention that "other estimators might be doubly robust under different assumptions" and suggest combining them to construct a triply robust estimator.
- Why unresolved: The paper does not explore or implement such combinations, leaving this as a theoretical possibility.
- What evidence would resolve it: A mathematical formulation and empirical comparison of a triply robust estimator against MDR and other existing estimators.

### Open Question 3
- Question: How does MDR perform in real-world applications with non-stationary or adversarial behavior policies?
- Basis in paper: [inferred] The paper focuses on synthetic data experiments and theoretical analysis, but does not address practical challenges like non-stationary or adversarial behavior policies.
- Why unresolved: The paper does not test MDR in dynamic or adversarial environments, which are common in real-world applications.
- What evidence would resolve it: Empirical results showing MDR's performance on real-world datasets with non-stationary or adversarial behavior policies.

## Limitations

- Empirical validation is limited to synthetic data with only brief mention of potential real-world applications
- Strong assumptions about action embeddings and the "no direct effect" assumption may not hold in practical scenarios
- Assumes access to high-quality action embeddings and a parametric form for the reward function

## Confidence

- **High confidence** in the theoretical analysis showing MDR's unbiasedness under weaker assumptions than MIPS and its variance reduction properties
- **Medium confidence** in the empirical results due to limited real-world validation and synthetic data generation specifics
- **Low confidence** in practical applicability given the strong assumptions about action embeddings and the reward function form

## Next Checks

1. Evaluate MDR on real-world datasets (e.g., Yahoo! R6A, Coat) to assess performance in practical settings and verify the variance reduction claims beyond synthetic data
2. Test MDR's sensitivity to different embedding quality levels and dimensionality to understand the impact of embedding selection on estimator performance
3. Analyze MDR's performance under various violations of the "no direct effect" assumption to determine the estimator's robustness to this critical assumption