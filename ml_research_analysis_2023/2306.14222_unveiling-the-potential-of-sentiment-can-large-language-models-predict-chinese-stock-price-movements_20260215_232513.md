---
ver: rpa2
title: 'Unveiling the Potential of Sentiment: Can Large Language Models Predict Chinese
  Stock Price Movements?'
arxiv_id: '2306.14222'
source_url: https://arxiv.org/abs/2306.14222
tags:
- sentiment
- chinese
- news
- llms
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces a standardized experimental procedure to\
  \ evaluate Large Language Models (LLMs) in extracting sentiment factors from Chinese\
  \ financial news texts. Three distinct LLMs\u2014ChatGPT, Erlangshen-RoBERTa, and\
  \ Chinese FinBERT\u2014were tested on a dataset of 394,429 Chinese news summaries\
  \ about Chinese publicly traded companies."
---

# Unveiling the Potential of Sentiment: Can Large Language Models Predict Chinese Stock Price Movements?

## Quick Facts
- **arXiv ID**: 2306.14222
- **Source URL**: https://arxiv.org/abs/2306.14222
- **Reference count**: 2
- **Key outcome**: Erlangshen-110M model achieved best performance with 24.01% annual excess return, 11.95% annual net asset return, 58.38% win rate, and 0.678 Sharpe ratio.

## Executive Summary
This study evaluates Large Language Models for extracting sentiment factors from Chinese financial news to predict stock price movements. Three models—ChatGPT, Erlangshen-RoBERTa, and Chinese FinBERT—were tested on 394,429 news summaries about Chinese publicly traded companies. The Erlangshen-110M model, despite its smaller size, outperformed larger models by leveraging language-specific pre-training on Chinese corpora. The research demonstrates that domain-appropriate pre-training can be more effective than model scale for sentiment analysis in Chinese financial contexts.

## Method Summary
The study implements a standardized experimental procedure using three LLMs for sentiment extraction from Chinese financial news. The dataset includes 394,429 news summaries from October 2021 to February 2023 covering 5,021 publicly traded companies. Each model generates sentiment scores (positive, neutral, negative) that are then used to construct daily portfolios for backtesting. The framework includes realistic trading parameters: 0.15% transaction fees, VWAP-based slippage adjustment, and portfolio constraints (max 500 stocks, max turnover 1.0). Performance is evaluated using annual excess return, Sharpe ratio, win rate, and other trading metrics against the CSI 300 index benchmark.

## Key Results
- Erlangshen-110M achieved 24.01% annual excess return and 11.95% annual net asset return
- Erlangshen-110M demonstrated 58.38% win rate and 0.678 Sharpe ratio
- Language-specific pre-training outperformed larger models and financial domain fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language-specific pre-training improves sentiment extraction accuracy in Chinese financial texts.
- Mechanism: Erlangshen-RoBERTa was pre-trained on a 180 GB Chinese corpus, incorporating unique characteristics of Chinese language structure and character-level contextual relationships.
- Core assumption: Chinese language structure differs sufficiently from English that models pre-trained primarily on English corpora will underperform on Chinese financial sentiment tasks.
- Evidence anchors:
  - Erlangshen-RoBERTa achieved top performance on state-of-the-art NLP benchmarks after pre-training on Wudao Chinese Corpora
  - Comparative analysis shows language-specific pre-training contributes to superior returns
- Break condition: If Chinese financial texts do not contain unique linguistic patterns that differ from English

### Mechanism 2
- Claim: Domain-specific fine-tuning on financial corpora improves sentiment classification accuracy.
- Mechanism: Chinese FinBERT was created by fine-tuning a BERT model on SEC filing data and Chinese financial corpora, allowing it to learn financial domain knowledge and terminology specific to the Chinese market.
- Core assumption: Financial terminology and sentiment expression in news articles follows domain-specific patterns that can be learned through targeted fine-tuning.
- Evidence anchors:
  - Chinese FinBERT was fine-tuned on Chinese financial corpora with manual labeling by financial experts
  - The model was designed to classify news sentiment into three classes
- Break condition: If financial sentiment patterns are too domain-specific or time-sensitive to be captured through pre-training

### Mechanism 3
- Claim: Standardized backtesting framework with realistic trading parameters provides valid performance evaluation.
- Mechanism: The study implements a comprehensive backtesting framework with realistic parameters including transaction fees (0.15%), slippage adjustment using VWAP, and portfolio constraints (max 500 stocks, max turnover 1.0).
- Core assumption: Backtesting with realistic trading parameters provides a more accurate assessment of model performance than theoretical metrics alone.
- Evidence anchors:
  - 0.15% transaction fee emulates a more stringent trading environment than typical Chinese brokerage fees
  - VWAP between 9:00-9:05 am used to account for slippage and delays
  - CSI 300 index used as basis for calculating excess returns
- Break condition: If backtesting assumptions do not accurately reflect real market conditions

## Foundational Learning

- **Transformer architecture and attention mechanisms**: Understanding how LLMs process sequential data and capture contextual relationships is fundamental to understanding why certain models perform better at sentiment analysis tasks.
  - Quick check: How does the bidirectional attention mechanism in BERT differ from the unidirectional attention in GPT, and why might this matter for sentiment analysis?

- **Chinese language characteristics and tokenization**: Chinese text processing differs significantly from English due to the lack of word boundaries and character-based semantics, affecting how models should be pre-trained and fine-tuned.
  - Quick check: What are the key differences between Chinese and English tokenization approaches, and how might these differences impact sentiment analysis performance?

- **Financial market microstructure and trading mechanics**: Understanding how stock markets operate, including order types, fees, and price discovery mechanisms, is essential for designing realistic backtesting frameworks.
  - Quick check: How do transaction fees and slippage impact the net returns of high-frequency trading strategies, and why is it important to include these factors in backtesting?

## Architecture Onboarding

- **Component map**: News data → Text preprocessing → Model inference (3 LLMs) → Sentiment extraction → Portfolio construction → Backtesting → Performance evaluation
- **Critical path**: News data → Sentiment extraction → Portfolio construction → Backtesting → Performance evaluation
- **Design tradeoffs**:
  - Model size vs. performance: Erlangshen-110M outperforms larger models, suggesting domain-specific pre-training may be more valuable than model scale
  - Data volume vs. quality: Using 394,429 news items provides statistical power but may include noise
  - Realism vs. computational efficiency: Including realistic trading parameters provides accurate results but increases computational complexity
- **Failure signatures**:
  - Poor sentiment factor correlation with returns: Indicates model misalignment with market dynamics or data quality issues
  - Excessive turnover or portfolio concentration: Suggests parameter misalignment in trading constraints
  - High variance in backtest results: May indicate overfitting to specific market conditions or insufficient data diversity
- **First 3 experiments**:
  1. Baseline comparison: Run sentiment analysis on a small subset of news data using all three models and compare classification agreement rates
  2. Feature importance analysis: Evaluate which sentiment categories contribute most to portfolio performance
  3. Parameter sensitivity test: Vary key backtesting parameters to assess robustness of performance metrics

## Open Questions the Paper Calls Out

- **Open Question 1**: How much additional performance could be achieved by fine-tuning the Erlangshen-RoBERTa model on a Chinese financial domain-specific corpus rather than just the general Chinese corpus?
  - Basis: The paper compares three models but doesn't test whether domain-specific fine-tuning would improve the Erlangshen model's performance further
  - Why unresolved: The paper doesn't explore domain-specific fine-tuning for the best-performing model
  - Evidence needed: Controlled experiment comparing current Erlangshen model with a version fine-tuned on Chinese financial text

- **Open Question 2**: Would a larger Erlangshen model (e.g., 1.3B parameters instead of 110M) with the same extensive pre-training achieve significantly better sentiment extraction performance?
  - Basis: The paper notes that the 110M-parameter Erlangshen model outperforms both the much larger ChatGPT and the Chinese FinBERT model
  - Why unresolved: The paper only tests one size of the Erlangshen model
  - Evidence needed: Testing multiple Erlangshen model sizes on the same benchmark to establish the performance scaling relationship

- **Open Question 3**: How would the performance change if the trading strategy used a weighted average of the three sentiment factors rather than a single factor?
  - Basis: The paper tests three separate sentiment factors but doesn't explore combining them
  - Why unresolved: The paper treats each model's output as a separate trading strategy without exploring ensemble methods
  - Evidence needed: Backtest comparing single-factor strategies against multi-factor strategies using various weighting schemes

## Limitations

- Lack of detailed implementation specifications for critical components, particularly training data and labeling methodology for Chinese FinBERT and ChatGPT
- No accounting for market impact or liquidity constraints in the backtesting framework
- Limited assessment of temporal patterns in news sentiment or market regime changes that could affect strategy robustness

## Confidence

- **High Confidence**: The experimental methodology is clearly defined, including data collection, sentiment analysis pipeline, and backtesting framework with realistic parameters
- **Medium Confidence**: The comparative performance analysis between models is well-documented, though exact implementation details are missing
- **Low Confidence**: The generalizability of results to different market conditions or time periods cannot be established from the current study design

## Next Checks

1. **Cross-validation of sentiment extraction**: Run a small-scale validation where human annotators evaluate a subset of news summaries to verify the consistency and accuracy of sentiment labels across all three LLMs, particularly focusing on Chinese-specific financial terminology and cultural context.

2. **Sensitivity analysis of trading parameters**: Systematically vary transaction fees, portfolio constraints, and slippage models to determine the robustness of the observed performance metrics and identify which parameters most significantly impact returns.

3. **Temporal robustness test**: Re-run the backtesting framework using different time periods or rolling windows to assess whether the sentiment factor remains predictive across various market regimes and whether the model performance is stable over time.