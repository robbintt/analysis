---
ver: rpa2
title: 'AutoML-GPT: Large Language Model for AutoML'
arxiv_id: '2309.01125'
source_url: https://arxiv.org/abs/2309.01125
tags:
- automl
- language
- automl-gpt
- learning
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AutoML-GPT is a framework that integrates large language models
  into AutoML workflows through a dual-agent system (Reasoning and Coding agents).
  The Reasoning agent interprets user requests and plans tool usage sequences, while
  the Coding agent implements the planned tasks by generating and executing code.
---

# AutoML-GPT: Large Language Model for AutoML

## Quick Facts
- arXiv ID: 2309.01125
- Source URL: https://arxiv.org/abs/2309.01125
- Reference count: 2
- AutoML-GPT achieves competitive performance on Kaggle datasets using dual-agent LLM system

## Executive Summary
AutoML-GPT introduces a novel framework that integrates large language models into automated machine learning workflows through a dual-agent system. The system consists of a Reasoning agent that interprets user requests and plans tool usage sequences, and a Coding agent that implements these plans by generating and executing code. Operating through a conversational interface, users can specify requirements and constraints while the system leverages the vast knowledge encoded in LLMs to guide the AutoML pipeline. Experimental results on 9 Kaggle competition datasets demonstrate performance competitive with established AutoML frameworks and human experts.

## Method Summary
The framework employs a dual-agent architecture built on the ReAct (Yao et al., 2022) framework using langchain. The Reasoning agent interprets user requests and plans sequences of tool usage for data preprocessing, feature engineering, model selection, and hyperparameter tuning. The Coding agent then generates and executes the corresponding code. The system follows a four-instruction sequence approach (Explore dataset, Process dataset, Select model, Fine-tune parameters) with an 8-hour training time limit, using single models without ensemble techniques. The approach was evaluated on 9 tabular datasets from recent Kaggle competitions, comparing performance against baseline AutoML frameworks.

## Key Results
- AutoML-GPT achieves competitive performance on 9 Kaggle competition datasets
- Performance comparable to established AutoML frameworks (Auto-sklearn, TPOT, Auto-WEKA, H2O AutoML, GCP-tables, AutoGluon)
- Results competitive with human expert performance on Kaggle leaderboards
- Strong data exploration and understanding capabilities drive performance rather than extensive computational power

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The dual-agent system effectively separates high-level reasoning from low-level implementation, enabling structured task decomposition.
- Mechanism: The Reasoning agent interprets user requests and plans tool usage sequences, while the Coding agent implements these plans by generating and executing code. This separation allows the Reasoning agent to focus on understanding the problem and planning optimal approaches, while the Coding agent handles the technical implementation details.
- Core assumption: The Reasoning agent can accurately interpret user requests and plan effective tool usage sequences that the Coding agent can successfully implement.
- Evidence anchors:
  - [abstract] "The Reasoning agent interprets user requests and plans tool usage sequences, while the Coding agent implements the planned tasks by generating and executing code."
  - [section] "The Reasoning agent in the AutoML pipeline handles the task of understanding human requests and planning the sequence of tool usage. It utilizes the language comprehension capabilities of the LLM to accurately interpret complex requests and effectively plan the steps required for tasks like end-to-end training."
- Break condition: If the Reasoning agent misinterprets user requests or plans ineffective tool usage sequences that the Coding agent cannot implement successfully, the system's performance would degrade significantly.

### Mechanism 2
- Claim: Large language models provide domain expertise that guides the AutoML pipeline more effectively than traditional automated hyperparameter search.
- Mechanism: The LLM's encoded knowledge about machine learning best practices, data preprocessing techniques, and model selection strategies enables it to make informed decisions about the AutoML workflow rather than relying solely on computational search.
- Core assumption: The LLM has been trained on sufficient machine learning domain knowledge to make effective decisions about AutoML workflows.
- Evidence anchors:
  - [abstract] "Its ability to leverage the vast knowledge encoded in large language models enables it to provide valuable insights, identify potential pitfalls, and suggest effective solutions to common challenges faced during model training."
  - [section] "The strength of the performance comes from the expertise in machine learning domain knowledge. AutoML-GPT conducts great data exploration and understanding and thus create well processed datasets for model training."
- Break condition: If the LLM lacks sufficient domain-specific knowledge about certain types of datasets or machine learning tasks, its guidance would be less effective than traditional automated methods.

### Mechanism 3
- Claim: The conversational interface enables iterative refinement and human-in-the-loop optimization of the AutoML process.
- Mechanism: Users can specify requirements, constraints, and evaluation metrics through natural language, receive feedback and suggestions from the system, and iteratively refine their requests based on the system's outputs and explanations.
- Core assumption: Users can effectively communicate their requirements and constraints through natural language, and the system can interpret these requests accurately.
- Evidence anchors:
  - [abstract] "Through a conversational interface, users can specify their requirements, constraints, and evaluation metrics."
  - [section] "The Reasoning agent receives the execution output from the Coding agent and utilizes it to provide relevant and informative responses to the user. This enables the Reasoning agent to communicate the progress of the AutoML pipeline, respond to user queries, and deliver meaningful insights based on the executed tasks."
- Break condition: If users struggle to articulate their requirements effectively or if the system cannot accurately interpret nuanced natural language requests, the iterative refinement process would break down.

## Foundational Learning

- Concept: Large language model capabilities and limitations
  - Why needed here: Understanding what LLMs can and cannot do is crucial for designing effective agent architectures and setting realistic expectations for AutoML-GPT's capabilities.
  - Quick check question: What are the key differences between using an LLM for reasoning/planning versus using it for code generation in an AutoML context?

- Concept: AutoML pipeline components and best practices
  - Why needed here: The system needs to understand standard AutoML workflows, including data preprocessing, feature engineering, model selection, and hyperparameter optimization to effectively guide users.
  - Quick check question: What are the typical stages in an AutoML pipeline, and how might an LLM be used to optimize each stage?

- Concept: Dual-agent system design patterns
  - Why needed here: The separation of reasoning and coding agents is a key architectural decision that requires understanding when and how to split responsibilities between different system components.
  - Quick check question: What are the advantages and potential drawbacks of separating reasoning and implementation responsibilities in AI systems?

## Architecture Onboarding

- Component map: User Interface -> Reasoning Agent -> Tool Library -> Coding Agent -> Feedback Loop -> Evaluation System
- Critical path: User request → Reasoning agent interpretation → Tool usage planning → Coding agent implementation → Execution and feedback → User communication
- Design tradeoffs:
  - Single vs. dual agent architecture: The dual-agent approach adds complexity but provides better separation of concerns
  - LLM model selection: Balancing model capability with computational cost and response time
  - Tool library comprehensiveness vs. system complexity: More tools provide more options but increase the cognitive load on the reasoning agent
- Failure signatures:
  - Reasoning agent misinterpretation of user requests leading to incorrect tool sequences
  - Coding agent inability to implement planned tasks due to technical limitations
  - Communication breakdown between agents resulting in execution errors
  - Performance degradation when handling datasets outside the training distribution of the LLM
- First 3 experiments:
  1. Implement a simple version with a single agent handling both reasoning and coding to establish baseline performance
  2. Test the dual-agent system on a simple tabular dataset to validate the communication and coordination between agents
  3. Compare performance against traditional AutoML frameworks on a standard benchmark dataset to establish competitive positioning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does AutoML-GPT's performance scale when ensembles of models are allowed, compared to its single-model baseline?
- Basis in paper: [explicit] The authors note "The performance will be further boost if we incorporate other automl frameworks as one of the tools into AutoML-GPT" and the experimental results were based on single model without ensemble techniques.
- Why unresolved: The paper explicitly states performance could improve with ensembles but does not provide experimental results with ensemble methods.
- What evidence would resolve it: Experimental results comparing single-model AutoML-GPT performance to ensemble-based AutoML-GPT performance on the same datasets.

### Open Question 2
- Question: What is the computational efficiency of AutoML-GPT compared to traditional AutoML frameworks when accounting for both inference time and the underlying LLM's computational costs?
- Basis in paper: [inferred] The paper emphasizes AutoML-GPT's competitive performance comes from "expertise in machine learning domain knowledge" rather than "extensive computation power," but does not provide detailed computational efficiency analysis.
- Why unresolved: While the paper contrasts AutoML-GPT's approach with computation-heavy frameworks, it does not quantify the total computational resources required for AutoML-GPT.
- What evidence would resolve it: Comparative analysis of total computational resources (time, energy, cost) for AutoML-GPT versus traditional AutoML frameworks across the benchmark datasets.

### Open Question 3
- Question: How does AutoML-GPT's reasoning capability handle ambiguous or poorly specified user requests, and what are its failure modes?
- Basis in paper: [explicit] The Reasoning agent "handles the task of understanding human requests and planning the sequence of tool usage" but the paper does not discuss how it handles ambiguous requests or failure scenarios.
- Why unresolved: The paper describes the dual-agent system's capabilities but does not provide empirical analysis of its robustness to unclear user requirements or its failure modes.
- What evidence would resolve it: Systematic evaluation of AutoML-GPT's performance with deliberately ambiguous, incomplete, or contradictory user specifications, including qualitative analysis of failure cases and reasoning patterns.

## Limitations
- The paper does not disclose specific LLM architecture or training data used
- Performance evaluation limited to 9 Kaggle datasets, limiting generalizability
- Computational cost analysis between AutoML-GPT and traditional frameworks is absent
- System's robustness to ambiguous user requests and edge cases not empirically evaluated

## Confidence

- **High Confidence**: The dual-agent architecture separation of reasoning and implementation is technically sound and represents a novel approach to integrating LLMs into AutoML workflows
- **Medium Confidence**: The competitive performance claims are credible given the systematic evaluation on Kaggle datasets, but the generalizability to non-competitive datasets remains uncertain
- **Medium Confidence**: The mechanism explaining LLM domain knowledge as the primary driver of performance is plausible, though difficult to validate without access to the specific model implementations

## Next Checks

1. **Replication on diverse dataset types**: Test AutoML-GPT on non-Kaggle datasets including small datasets, highly imbalanced datasets, and datasets with missing values or noisy features to assess robustness beyond the competition environment
2. **Ablation study of agent roles**: Implement and compare single-agent versus dual-agent versions to quantify the contribution of the separation of reasoning and coding responsibilities to overall performance
3. **Computational cost analysis**: Measure and compare the wall-clock time, GPU memory usage, and API costs of AutoML-GPT against traditional AutoML frameworks across multiple dataset sizes to evaluate practical deployment viability