---
ver: rpa2
title: 'Structural generalization in COGS: Supertagging is (almost) all you need'
arxiv_id: '2310.14124'
source_url: https://arxiv.org/abs/2310.14124
tags:
- generalization
- semantic
- concept
- linguistics
- association
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles compositional generalization in semantic parsing
  using a neural graph-based approach enhanced with supertagging and valency constraints.
  The authors propose introducing a supertagging step with an integer linear program
  to enforce the companionship principle, reducing argument identification to a maximum
  matching problem, and using an incremental early-stopping strategy to prevent overfitting.
---

# Structural generalization in COGS: Supertagging is (almost) all you need

## Quick Facts
- arXiv ID: 2310.14124
- Source URL: https://arxiv.org/abs/2310.14124
- Reference count: 22
- This paper tackles compositional generalization in semantic parsing using a neural graph-based approach enhanced with supertagging and valency constraints.

## Executive Summary
This paper introduces a neural graph-based approach for semantic parsing that significantly improves compositional generalization on the COGS dataset. The key insight is that structural consistency enforced through supertagging with valency constraints is crucial for handling structural generalization tasks. By combining an integer linear programming formulation for supertagging, a maximum matching reduction for argument identification, and an incremental early-stopping training strategy, the method achieves 75% exact match accuracy on the challenging Obj to Subj PP case, compared to 0% for previous graph-based models.

## Method Summary
The approach builds on a neural graph-based semantic parser with BiLSTM encoder and biaffine layers, enhanced with three key components: (1) a supertagging step using integer linear programming to enforce valency constraints and the companionship principle, (2) reduction of argument identification to a maximum matching problem using bipartite matching algorithms, and (3) an incremental early-stopping strategy to prevent overfitting on in-distribution data. The method handles both supervised and weakly-supervised settings, with the latter using factor graph inference for computing the best alignment between concept instances and words.

## Key Results
- Achieves 75% exact match accuracy on the challenging Obj to Subj PP case in COGS, compared to 0% for previous graph-based models
- Significant improvements across all structural generalization cases in COGS compared to existing graph-based approaches
- The incremental early-stopping strategy provides a 23.9-point increase for Obj to Subj PP accuracy
- The full pipeline with all components is necessary for achieving these results

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Introducing a supertagging step with valency constraints improves compositional generalization by ensuring structural consistency before argument identification.
- Mechanism: The supertagging step assigns complex semantic descriptions (roots and substitution sites) to concept instances. An integer linear program enforces the companionship principle, ensuring that substitution sites have corresponding roots. This guarantees at least one feasible parse exists in the search space.
- Core assumption: Structural consistency at the supertagging level prevents argument identification from failing due to missing arguments.
- Evidence anchors:
  - [abstract] "the introduction of a supertagging step with valency constraints, expressed as an integer linear program"
  - [section 3.1] "We propose an integer linear programming formulation of supertagging that ensures the existence of at least one feasible parse in the search space, via the so-called companionship principle"
  - [corpus] Weak: No direct corpus evidence provided; assumption based on theoretical formulation.
- Break condition: If the ILP solver fails or if the supertag set is too limited, structural consistency may not be guaranteed, leading to parsing failures.

### Mechanism 2
- Claim: Reducing the graph prediction problem to a maximum matching problem simplifies argument identification while maintaining accuracy.
- Mechanism: After supertagging, ambiguous labels are resolved using bipartite matching between substitution sites and roots with the same label. The Jonker-Volgenant algorithm finds the maximum weight matching efficiently.
- Core assumption: The companionship principle ensures there is always at least one feasible matching, making this reduction valid.
- Evidence anchors:
  - [abstract] "a reduction of the graph prediction problem to the maximum matching problem"
  - [section 3.2] "For ambiguous labels after the supertagging step, we can rely on a bipartite matching (or assignment) algorithm"
  - [corpus] Weak: No direct corpus evidence; theoretical reduction based on problem structure.
- Break condition: If the matching algorithm fails to find a valid assignment or if the graph structure is too complex, argument identification may produce incorrect results.

### Mechanism 3
- Claim: An incremental early-stopping strategy prevents overfitting on in-distribution data while still allowing learning on compositional generalization tasks.
- Mechanism: The training process monitors each subtask independently on the development set. As soon as a task achieves 100% accuracy, the corresponding layers are frozen. This prevents overfitting while still allowing learning on harder tasks.
- Core assumption: Overfitting occurs because the development set is in-distribution and doesn't test for compositional generalization.
- Evidence anchors:
  - [abstract] "the design of an incremental early-stopping training strategy to prevent overfitting"
  - [section 6.1] "We propose a variant of early stopping to prevent overfitting on the in-distribution data without requiring a compositional generalization development set"
  - [section 6.2] "The early stopping approach introduced above has a clear impact for Obj to subj PP, resulting in a 23.9 points increase"
- Break condition: If the early stopping is too aggressive or if the development set is not representative, the model may underfit or still overfit.

## Foundational Learning

- Concept: Integer Linear Programming (ILP)
  - Why needed here: Used to enforce the companionship principle in supertagging by ensuring substitution sites match roots.
  - Quick check question: What is the purpose of using ILP in the supertagging step?

- Concept: Bipartite Matching
  - Why needed here: Used to resolve ambiguous argument assignments after supertagging by finding maximum weight matchings.
  - Quick check question: How does bipartite matching help in the argument identification step?

- Concept: Factor Graphs and MAP Inference
  - Why needed here: Used in the weakly-supervised setting to compute the best alignment between concept instances and words without gold alignment.
  - Quick check question: Why is MAP inference in a factor graph used for the E-step in the EM-like procedure?

## Architecture Onboarding

- Component map: Input sentence -> BiLSTM encoder -> concept tagging -> supertagging (with ILP) -> argument identification (with matching) -> output semantic graph
- Critical path: The critical path is: input sentence → BiLSTM → concept tagging → supertagging (with ILP) → argument identification (with matching) → output semantic graph.
- Design tradeoffs: The use of ILP and matching algorithms adds computational complexity but improves accuracy. The pipeline approach may not benefit from global information during local predictions.
- Failure signatures: If the ILP solver fails, supertagging may produce infeasible solutions. If the matching algorithm fails, argument identification may produce incorrect results. If early stopping is too aggressive, the model may underfit.
- First 3 experiments:
  1. Implement and test the ILP solver for supertagging with the companionship principle on a small dataset.
  2. Implement and test the bipartite matching algorithm for argument identification with ambiguous labels.
  3. Implement and test the incremental early-stopping strategy on the development set to prevent overfitting.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the limitations section and discussion, several implicit open questions arise from the work:

## Limitations
- Evaluation is limited to a single dataset (COGS), which may not generalize to other semantic parsing tasks or compositional generalization challenges
- Results show significant improvement on structural generalization but do not address semantic generalization or out-of-distribution vocabulary
- The weakly-supervised setting is less extensively evaluated compared to the supervised setting
- Computational complexity introduced by ILP solver and matching algorithms may limit scalability to larger datasets

## Confidence

**High confidence**: The improvement in exact match accuracy on COGS (75% on Obj to Subj PP vs 0% for previous graph-based models) is well-supported by experimental results and represents a clear technical achievement. The effectiveness of the incremental early-stopping strategy is also well-demonstrated with specific accuracy improvements.

**Medium confidence**: The theoretical claims about why the mechanisms work (companionship principle, maximum matching reduction) are sound but rely on assumptions about the dataset structure. The claim that supertagging is "almost all you need" may be overstated given that the full pipeline with all components is necessary for the reported results.

**Low confidence**: The generalizability of these results to other compositional generalization benchmarks beyond COGS remains uncertain. The weakly-supervised results are promising but not as thoroughly validated as the supervised setting.

## Next Checks

1. **Dataset generalization**: Test the complete pipeline on additional compositional generalization benchmarks (e.g., SCAN, CFQ) to evaluate whether the structural constraints and supertagging approach transfer to other domains and generalization types.

2. **Ablation on computational overhead**: Measure and compare the runtime and memory requirements of the ILP-based supertagging and matching-based argument identification against baseline graph-based parsers to quantify the computational cost of the improvements.

3. **Robustness to noise**: Introduce noise in the concept identification step (e.g., through adversarial examples or noisy labels) to test whether the downstream supertagging and argument identification components remain effective when earlier components fail.