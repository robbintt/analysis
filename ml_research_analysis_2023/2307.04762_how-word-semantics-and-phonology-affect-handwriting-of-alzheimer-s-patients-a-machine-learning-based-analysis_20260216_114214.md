---
ver: rpa2
title: 'How word semantics and phonology affect handwriting of Alzheimer''s patients:
  a machine learning based analysis'
arxiv_id: '2307.04762'
source_url: https://arxiv.org/abs/2307.04762
tags:
- words
- features
- handwriting
- word
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates how word semantics and phonology affect\
  \ the handwriting of people with Alzheimer\u2019s disease (AD). Six handwriting\
  \ tasks were designed using regular words, non-regular words, and non-words, each\
  \ requiring copying a specific word type."
---

# How word semantics and phonology affect handwriting of Alzheimer's patients: a machine learning based analysis

## Quick Facts
- arXiv ID: 2307.04762
- Source URL: https://arxiv.org/abs/2307.04762
- Reference count: 37
- Primary result: Non-regular words and non-words, which require more complex motor planning, yield the best classification accuracy for AD detection using handwriting features.

## Executive Summary
This study investigates how word semantics and phonology influence handwriting patterns in Alzheimer's disease (AD) patients using machine learning. By analyzing kinematic and pressure data from 180 participants copying regular, non-regular, and non-words, the authors demonstrate that non-regular words and non-words are more discriminative for AD detection than regular words. Feature selection via Recursive Feature Elimination (RFE) significantly improves classification accuracy, especially for complex word types. These results suggest that handwriting analysis, particularly for cognitively demanding word types, could serve as a practical tool for supporting AD diagnosis.

## Method Summary
The study collected handwriting data from 180 participants (AD patients and healthy controls) performing six copying tasks using a graphic tablet at 200Hz. For each task, 47 features (kinematic and pressure-based) were extracted from on-paper, in-air, and combined (AL) movements. Four classifiers (Random Forest, Decision Tree, SVM, MLP) were trained using 10-fold cross-validation, with and without feature selection via RFE. Classification performance was evaluated for single tasks and merged task categories.

## Key Results
- Non-regular words and non-words achieved the highest classification accuracy (close to 90% with feature selection).
- Feature selection via RFE significantly improved performance by focusing on the most discriminative features.
- On-paper features were most effective for non-regular and non-words, suggesting AD impairs feedback-based motor control.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Feature selection improves classification accuracy by eliminating noisy and redundant features, enabling classifiers to focus on the most discriminative signals.
- Mechanism: Recursive Feature Elimination (RFE) iteratively removes the least important features based on classifier performance, reducing overfitting and improving generalization.
- Core assumption: The selected subset of features retains sufficient information to distinguish between AD patients and healthy controls.
- Evidence anchors:
  - [abstract] "the feature selection allowed us to derive a different set of highly distinctive features for each word type"
  - [section] "feature selection allowed us to achieve better performances than those achieved using all features"

### Mechanism 2
- Claim: Non-regular words and non-words require more complex motor planning, which is disproportionately impaired in AD, making them better discriminative stimuli.
- Mechanism: These word types engage deeper semantic processing and motor plan generation, processes more sensitive to early AD-related neural degradation.
- Core assumption: Handwriting variability in complex word types correlates with cognitive decline in AD.
- Evidence anchors:
  - [abstract] "non-regular words needed, on average, more features but achieved excellent classification performance"
  - [section] "higher the complexity of the motor plan needed to write a word, the higher the number of features needed to characterize the handwriting"

### Mechanism 3
- Claim: On-paper features are more discriminative for non-regular and non-words because AD impairs the integration of visual feedback into motor control.
- Mechanism: Visual feedback during writing allows healthy individuals to correct errors, but AD patients cannot effectively use this feedback, leading to more detectable kinematic differences in on-paper movements.
- Core assumption: The ability to correct motor plans using visual feedback is compromised in AD.
- Evidence anchors:
  - [section] "on-paper features achieved the best performance" for non-words
  - [section] "AD harms the brain areas devoted to processing the visual feedback provided by the ink trace"

## Foundational Learning

- Concept: Phoneme-grapheme correspondence rules
  - Why needed here: Understanding the distinction between regular, non-regular, and non-words is essential for interpreting why different word types produce different handwriting patterns.
  - Quick check question: What makes the word "laugh" non-regular in terms of phoneme-grapheme correspondence?

- Concept: Feature selection and wrapper methods
  - Why needed here: RFE is central to the improved performance; engineers must understand backward elimination and evaluation functions.
  - Quick check question: How does RFE decide which feature to remove at each iteration?

- Concept: Cross-validation and classifier evaluation
  - Why needed here: Performance metrics and validation strategies are key to interpreting results and comparing with state-of-the-art.
  - Quick check question: Why use ten-fold cross-validation instead of a single train-test split?

## Architecture Onboarding

- Component map:
  Data ingestion -> Preprocessing (segmentation, stroke extraction) -> Feature extraction (kinematic and pressure) -> Feature selection (RFE) -> Classification (RF, DT, SVM, MLP) -> Evaluation (accuracy, cross-validation)

- Critical path:
  Raw handwriting -> stroke segmentation -> feature extraction -> RFE -> classification -> evaluation

- Design tradeoffs:
  - Using only in-air features vs. on-paper vs. merged: in-air features capture planning, on-paper capture execution; merging increases dimensionality but may introduce redundancy.
  - Feature selection vs. using all features: selection improves accuracy and interpretability but requires careful validation to avoid discarding useful features.
  - Classifier choice: DT and SVM showed best performance; ensemble methods (RF) offer robustness but may sacrifice interpretability.

- Failure signatures:
  - Accuracy plateaus or drops after feature selection: likely feature removal is discarding discriminative signals.
  - High variance in cross-validation: possible overfitting or insufficient data per fold.
  - Poor performance on merged tasks vs. single tasks: suggests task-specific features are being lost in aggregation.

- First 3 experiments:
  1. Run feature selection (RFE) on a single task (e.g., task #4) and compare accuracy with and without selection.
  2. Train classifiers on merged regular word tasks using only on-paper features; compare with in-air only.
  3. Repeat experiment 2 for non-words; verify if on-paper features outperform in-air as hypothesized.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific brain regions are most affected by Alzheimer's disease when patients write different types of words (regular, non-regular, non-words)?
- Basis in paper: [explicit] The paper discusses how different word types require different cognitive skills and motor plans, suggesting varying impacts on brain regions.
- Why unresolved: The paper focuses on the effects of Alzheimer's on handwriting but does not specify which brain regions are involved in processing different word types.
- What evidence would resolve it: Neuroimaging studies, such as fMRI or PET scans, that show brain activity patterns while patients write different word types.

### Open Question 2
- Question: How does the complexity of motor plans for non-regular and non-words compare to regular words in terms of cognitive load and brain activation?
- Basis in paper: [explicit] The paper indicates that non-regular and non-words require more complex motor plans and cognitive effort compared to regular words.
- Why unresolved: The paper does not quantify the cognitive load or brain activation levels associated with writing different word types.
- What evidence would resolve it: Cognitive load measurements and brain activation studies comparing the writing of regular, non-regular, and non-words.

### Open Question 3
- Question: Can the findings from this study be generalized to other languages with different orthographic depths?
- Basis in paper: [explicit] The study uses Italian words, and the authors mention the importance of grapheme-phoneme correspondence, which may vary across languages.
- Why unresolved: The study's findings are based on Italian, and the paper does not discuss their applicability to other languages.
- What evidence would resolve it: Replication of the study with participants from different linguistic backgrounds and languages with varying orthographic depths.

### Open Question 4
- Question: How do the identified features for classifying Alzheimer's patients differ across age groups and education levels?
- Basis in paper: [explicit] The paper mentions the inclusion of personal features like age and education level in the analysis.
- Why unresolved: The paper does not explore how these features interact with word type or influence classification performance across different demographics.
- What evidence would resolve it: Detailed analysis of classification performance and feature importance across different age groups and education levels.

## Limitations
- The dataset is not publicly available, limiting reproducibility and external validation.
- The theoretical mechanism linking word complexity to AD-related deficits is not directly measured.
- Results may not generalize to other languages or populations due to study-specific word choices and participant demographics.

## Confidence

- **High Confidence**: Feature selection (RFE) improves classification accuracy by reducing noise and redundancy, as demonstrated by statistically significant performance gains across classifiers and tasks.
- **Medium Confidence**: Non-regular words and non-words are more discriminative for AD detection due to increased motor planning complexity and impaired feedback integration, though the underlying cognitive mechanism is not directly measured.
- **Low Confidence**: The exact feature importance and generalizability of results to other populations or settings, given the lack of external validation and full methodological transparency.

## Next Checks

1. Validate the feature selection and classification pipeline on an independent handwriting dataset (e.g., from a different clinic or country) to test external generalizability.
2. Conduct a controlled experiment manipulating visual feedback (e.g., using a digital tablet that hides the ink trace) to directly test whether impaired feedback integration explains the advantage of on-paper features in AD.
3. Perform ablation studies to identify which specific kinematic or pressure features are most predictive, and cross-reference these with clinical assessments of motor and cognitive function in AD.