---
ver: rpa2
title: 'Exploring Progress in Multivariate Time Series Forecasting: Comprehensive
  Benchmarking and Heterogeneity Analysis'
arxiv_id: '2310.06119'
source_url: https://arxiv.org/abs/2310.06119
tags:
- datasets
- forecasting
- time
- spatial
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of inconsistent and fair benchmarking
  in multivariate time series (MTS) forecasting. To address this, the authors propose
  BasicTS+, a benchmark designed to enable fair, comprehensive, and reproducible comparisons
  of MTS forecasting solutions.
---

# Exploring Progress in Multivariate Time Series Forecasting: Comprehensive Benchmarking and Heterogeneity Analysis

## Quick Facts
- **arXiv ID**: 2310.06119
- **Source URL**: https://arxiv.org/abs/2310.06119
- **Reference count**: 40
- **Primary result**: Proposes BasicTS+ benchmark to enable fair, comprehensive, and reproducible comparisons of MTS forecasting solutions, identifying dataset heterogeneity as key to understanding model performance differences

## Executive Summary
This paper addresses the challenge of inconsistent and fair benchmarking in multivariate time series (MTS) forecasting by introducing BasicTS+, a unified framework that standardizes training pipelines, data processing, and evaluation procedures. The authors identify dataset heterogeneity across temporal and spatial dimensions as a primary reason for inconsistent findings about technical approaches like transformers versus linear models. Through comprehensive benchmarking of over 45 MTS forecasting solutions, the paper provides insights into cutting-edge research while establishing a reproducible foundation for future work.

## Method Summary
BasicTS+ establishes a unified training pipeline with standardized data processing (z-score normalization), training configurations (masked MAE loss, curriculum learning), and evaluation implementation to eliminate performance inconsistencies across studies. The framework includes a unified dataloader, runner, and evaluation module, along with extensible features like logging and device compatibility. The heterogeneity analysis classifies MTS datasets based on temporal patterns (stable, drifting, unclear) and spatial characteristics (indistinguishable vs distinguishable samples) using quantitative metrics (r1, r2) to determine when spatial modeling is necessary.

## Key Results
- Standardized training pipelines eliminate performance inconsistencies across different studies by removing variability from experimental setups
- Dataset heterogeneity explains inconsistent findings about technical approaches, with model effectiveness depending on dataset characteristics
- Spatial indistinguishability metrics provide principled guidance for when to model spatial dependencies, with spatial identity embeddings and GCNs showing significant gains on appropriate datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The unified training pipeline in BasicTS eliminates performance inconsistencies across different studies.
- Mechanism: By standardizing data processing (z-score normalization), training configurations (masked MAE loss, curriculum learning), and evaluation implementation, BasicTS ensures that all models are trained and evaluated under identical conditions, removing the variability introduced by different experimental setups.
- Core assumption: Performance differences across studies are primarily due to variations in training and evaluation procedures rather than model architecture.
- Evidence anchors:
  - [abstract] "BasicTS establishes a unified training pipeline and reasonable settings, enabling an unbiased evaluation."
  - [section 4.1.1] "These details are often overlooked, but have a great influence on the evaluation results."

### Mechanism 2
- Claim: Heterogeneity in MTS datasets explains the inconsistent findings about technical approaches like transformers vs linear models.
- Mechanism: Different datasets exhibit varying temporal patterns (stable, drifting, unclear) and spatial characteristics (indistinguishable vs distinguishable samples). These differences create environments where certain models overfit or underfit, making prior conclusions valid only for specific dataset types.
- Core assumption: The effectiveness of technical approaches depends on dataset characteristics rather than being universally applicable.
- Evidence anchors:
  - [section 5.1] "We argue that when learned on datasets with stable and clear patterns, Transformer models should be able to capture complex patterns such as periodicity, while Linear models remain under-fitted"
  - [section 5.2] "we do not always need to model spatial dependencies. When there is significant spatial indistinguishability in the data, it is necessary to adopt spatial modeling approaches"

### Mechanism 3
- Claim: Quantifying spatial indistinguishability provides a principled way to decide when to model spatial dependencies.
- Mechanism: The metrics r1 and r2 measure the proportion of samples with similar historical data but different future outcomes. High values indicate that simple regression models cannot distinguish these samples, necessitating spatial modeling approaches like GCNs, normalization, or spatial identities.
- Core assumption: Spatial indistinguishability is a fundamental characteristic that determines the necessity of spatial modeling.
- Evidence anchors:
  - [section 5.2] "we propose the following quantitative metrics: r1 = sum(AP > eu & AF < el) / (T * N * N)"
  - [section 6.3] "On datasets with significant spatial indistinguishability, both trainable spatial identity embeddings and GCNs can lead to significant performance gains"

## Foundational Learning

- Concept: Time series forecasting fundamentals
  - Why needed here: Understanding the basic problem of predicting future values from historical data is essential for grasping the challenges in MTS forecasting.
  - Quick check question: What is the difference between univariate and multivariate time series forecasting?

- Concept: Graph Neural Networks and spatial dependencies
  - Why needed here: Many MTS forecasting approaches use GNNs to model relationships between different time series, so understanding how they work is crucial.
  - Quick check question: How does a graph convolution operation aggregate information from neighboring nodes?

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: Transformer-based models are central to many recent MTS forecasting approaches, particularly for capturing long-term temporal dependencies.
  - Quick check question: What is the computational complexity of standard self-attention, and why do efficient variants exist?

## Architecture Onboarding

- Component map: BasicTS consists of three core components - a unified dataloader (handles normalization, feature engineering) -> a unified runner (manages training, validation, testing with standardized configurations) -> a unified evaluation module (provides consistent metrics)
- Critical path: The evaluation pipeline follows: data loading → model training → validation → testing → metric calculation. The unified components ensure consistency at each stage.
- Design tradeoffs: Standardization improves fairness and reproducibility but may limit flexibility for dataset-specific optimizations. The choice of z-score normalization and masked MAE as defaults represents a balance between performance and generality.
- Failure signatures: Inconsistent performance across studies suggests training/evaluation differences. Poor generalization indicates overfitting to specific dataset patterns. High spatial indistinguishability without spatial modeling suggests missed dependencies.
- First 3 experiments:
  1. Run a simple baseline (e.g., Linear model) on a dataset with clear patterns to establish baseline performance and verify the unified pipeline works correctly.
  2. Compare the same model's performance when trained with different configurations (e.g., masked vs naive MAE) to demonstrate the impact of standardization.
  3. Test spatial modeling components (e.g., STID) on datasets with high vs low spatial indistinguishability to validate the heterogeneity analysis.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we design model architectures that are both powerful and robust to distribution drift in multivariate time series forecasting?
- Basis in paper: [explicit] The paper identifies that models with strong inductive biases (like Transformers) may overfit on datasets with distribution drift, while simpler models (like Linear models) may underfit on datasets with clear and stable patterns. The paper suggests that more research is needed on designing models that can handle both types of datasets effectively.
- Why unresolved: While the paper highlights the issue, it does not provide a concrete solution for designing such architectures. The effectiveness of different approaches depends heavily on the specific characteristics of the dataset, making it a challenging problem to solve in a general way.
- What evidence would resolve it: Empirical studies comparing the performance of various model architectures (e.g., Transformers, RNNs, CNNs, Linear models) on datasets with different levels of distribution drift. The studies should also explore techniques for mitigating the effects of distribution drift, such as online learning, transfer learning, and domain adaptation.

### Open Question 2
- Question: What are the most effective techniques for modeling spatial dependencies in multivariate time series data, and how do we determine when these techniques are necessary?
- Basis in paper: [explicit] The paper introduces the concept of spatial indistinguishability and argues that modeling spatial dependencies is only necessary when there is significant indistinguishability in the data. However, the paper does not provide a definitive answer on which techniques are most effective for modeling spatial dependencies or how to determine when these techniques are necessary.
- Why unresolved: The effectiveness of different techniques for modeling spatial dependencies depends on the specific characteristics of the dataset, such as the degree of spatial indistinguishability and the nature of the spatial relationships between variables. Additionally, the paper only considers a limited set of techniques, and there may be other approaches that are more effective.
- What evidence would resolve it: Empirical studies comparing the performance of various techniques for modeling spatial dependencies (e.g., GCNs, normalization, spatial identity embeddings) on datasets with different levels of spatial indistinguishability. The studies should also explore techniques for determining when spatial dependencies are present and when they are necessary to model.

### Open Question 3
- Question: How can we develop more efficient and scalable approaches for multivariate time series forecasting, especially for large-scale datasets?
- Basis in paper: [explicit] The paper highlights the efficiency issues of some existing approaches, such as STGNNs, which can have high computational complexity. The paper also suggests that more attention should be paid to developing efficient and scalable approaches, especially for large-scale datasets.
- Why unresolved: Developing efficient and scalable approaches for multivariate time series forecasting is a challenging problem, especially for large-scale datasets. The paper only scratches the surface of this issue and does not provide concrete solutions.
- What evidence would resolve it: Empirical studies comparing the efficiency and scalability of various approaches for multivariate time series forecasting, including both traditional methods and deep learning-based methods. The studies should also explore techniques for reducing the computational complexity of these approaches, such as model compression, quantization, and distributed training.

## Limitations

- The study focuses primarily on benchmark datasets commonly used in the field, which may not fully represent the diversity of real-world MTS applications
- The temporal and spatial heterogeneity metrics rely on threshold-based classifications that may oversimplify complex dataset characteristics
- The analysis assumes that performance differences are primarily due to training/evaluation inconsistencies rather than fundamental model limitations

## Confidence

- **High confidence**: The mechanism by which standardized training pipelines reduce experimental inconsistencies is well-supported by the evidence presented. The BasicTS+ implementation details are clearly specified and reproducible.
- **Medium confidence**: The heterogeneity classification framework provides useful insights, but the threshold-based approach may miss nuanced dataset characteristics. The relationship between spatial indistinguishability and model performance is supported but could benefit from additional validation across diverse datasets.
- **Low confidence**: The claim that heterogeneity alone explains all controversies in MTS forecasting is overstated. Other factors such as model architecture choices, optimization strategies, and domain-specific considerations likely play important roles.

## Next Checks

1. **Dataset Diversity Validation**: Test BasicTS+ on additional real-world MTS datasets not included in the original benchmark to assess whether the heterogeneity framework generalizes beyond commonly used datasets.

2. **Threshold Sensitivity Analysis**: Systematically vary the thresholds used in the temporal and spatial heterogeneity metrics to determine how sensitive the classifications are to these parameter choices.

3. **Cross-Validation of Heterogeneity Insights**: Apply the spatial indistinguishability metrics to datasets with known spatial dependencies to verify whether the metrics correctly identify when spatial modeling is beneficial.