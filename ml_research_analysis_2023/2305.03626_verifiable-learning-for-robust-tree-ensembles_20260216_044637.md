---
ver: rpa2
title: Verifiable Learning for Robust Tree Ensembles
arxiv_id: '2305.03626'
source_url: https://arxiv.org/abs/2305.03626
tags:
- large-spread
- ensembles
- tree
- ensemble
- robustness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the concept of "verifiable learning" for
  decision tree ensembles, proposing a method to train models that are both accurate
  and efficient to verify for robustness against adversarial attacks. The key innovation
  is the "large-spread ensemble" class, where thresholds in different trees are sufficiently
  far apart, enabling polynomial-time robustness verification.
---

# Verifiable Learning for Robust Tree Ensembles

## Quick Facts
- **arXiv ID:** 2305.03626
- **Source URL:** https://arxiv.org/abs/2305.03626
- **Reference count:** 40
- **Key outcome:** Introduces "verifiable learning" for decision tree ensembles, enabling polynomial-time robustness verification while maintaining accuracy comparable to traditional models.

## Executive Summary
This paper addresses the fundamental challenge of verifying robustness in decision tree ensembles against adversarial attacks, which is NP-hard for traditional approaches. The authors propose "verifiable learning" - a method to train tree ensembles that are both accurate and efficiently verifiable. They introduce "large-spread ensembles" where thresholds in different trees are sufficiently far apart, enabling polynomial-time verification by exploiting the orthogonality of perturbations across trees. The approach demonstrates that models can be trained to be simultaneously accurate and easy to verify, with accuracy only marginally lower than traditional ensembles while being verifiable in seconds rather than failing or providing approximations.

## Method Summary
The paper proposes large-spread ensembles, a class of decision tree ensembles where thresholds for the same feature across different trees are sufficiently far apart (greater than 2k in L_p-norm). This condition enables polynomial-time robustness verification by ensuring that adversarial perturbations affecting one tree cannot simultaneously affect another tree. The training algorithm uses a pruning-based approach that starts with a traditional random forest of 2m trees and greedily selects m trees while enforcing the large-spread condition through threshold mutation operations. For larger ensembles, a hierarchical training approach partitions features into disjoint subsets and trains separate ensembles on each subset before merging them.

## Key Results
- Large-spread ensembles achieve accuracy within 0.03 of traditional ensembles on Fashion-MNIST and MNIST26 datasets
- Verification time for large-spread ensembles is polynomial (O(N + m log m)) versus NP-hard for traditional ensembles
- CARVE verification tool successfully verifies 93% of instances on Fashion-MNIST clothes dataset
- Hierarchical training enables construction of larger ensembles (e.g., 101 trees) with maintained large-spread property

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Large-spread ensembles enable polynomial-time robustness verification by ensuring that attacks against different trees are orthogonal.
- **Mechanism:** When thresholds in different trees are sufficiently far apart (greater than 2k in L_p-norm), any adversarial perturbation that would cause a misclassification in one tree cannot simultaneously cause a misclassification in another tree. This allows the verification algorithm to sum minimal perturbations across trees to check ensemble robustness in O(N + m log m) time.
- **Core assumption:** The large-spread condition (ψ_p(T) > 2k) is sufficient to guarantee that perturbations affecting different trees target disjoint feature sets.
- **Evidence anchors:**
  - [abstract] "large-spread ensembles, which admit a security verification algorithm running in polynomial time"
  - [section 3.2.3] "The key intuition of the proposed large-spread condition allows one to verify the robustness guarantees of the individual decision trees in the ensembles and compose their results to draw conclusions about the robustness of the whole ensemble."
- **Break condition:** If thresholds in different trees are closer than 2k, attacks can affect multiple trees simultaneously, breaking the orthogonal property and requiring NP-hard verification.

### Mechanism 2
- **Claim:** Pruning-based training with mutation operations can successfully create large-spread ensembles while maintaining reasonable accuracy.
- **Mechanism:** The training algorithm first creates a traditional random forest with 2m trees, then greedily selects m trees while enforcing the large-spread condition through pruning and threshold mutation. When trees share features with thresholds closer than 2k, the algorithm perturbs thresholds by adding/subtracting random values in [k, 2k] to create sufficient separation.
- **Core assumption:** It's computationally feasible to find a subset of trees from a larger forest that can be mutated to satisfy the large-spread condition while maintaining predictive performance.
- **Evidence anchors:**
  - [section 4.2.2] "Our training algorithm thus integrates a greedy heuristic approach to pruning with a mutation operation, which perturbs thresholds so as to actively enforce the large-spread condition"
  - [section 5.2] "The accuracy of the large-spread ensembles is at most 0.03 lower than the accuracy of the corresponding traditional model in the majority of the cases"
- **Break condition:** If too many trees share the same critical features with similar thresholds, the mutation process may degrade accuracy too much or fail to achieve the large-spread condition.

### Mechanism 3
- **Claim:** Hierarchical training with feature partitioning enables larger large-spread ensembles to be trained successfully.
- **Mechanism:** By partitioning features into l disjoint subsets and training separate large-spread ensembles on each subset, then merging them, the algorithm avoids threshold conflicts across feature groups. This allows training larger ensembles (e.g., 100 trees from 4 ensembles of 25 trees each) while maintaining the large-spread property.
- **Core assumption:** Feature partitioning doesn't significantly degrade predictive performance because each subset contains sufficient discriminative information.
- **Evidence anchors:**
  - [section 4.2.4] "We empirically observed that this approach may improve the effectiveness of the training process, by enabling the construction of larger ensembles in practice"
  - [section 5.2] "The accuracy of the large-spread ensembles on these two test sets is usually equal to the one of the traditional ensembles"
- **Break condition:** If critical features are split across partitions, the ensemble may miss important patterns, degrading accuracy.

## Foundational Learning

- **Concept: L_p-norm distance and adversarial perturbations**
  - Why needed here: The paper's robustness verification and large-spread condition are defined in terms of L_p-norms, which measure how much an attacker can perturb input features.
  - Quick check question: If an attacker can modify feature values by at most k in L_infinity norm, what is the maximum L_1 distance they can introduce in a d-dimensional space?

- **Concept: Decision tree traversal and hyper-rectangle annotations**
  - Why needed here: The verification algorithm uses hyper-rectangles to represent regions of feature space that reach each node, which is essential for computing minimal perturbations.
  - Quick check question: How does the hyper-rectangle annotation for a node's children differ from the parent's annotation in terms of the threshold constraint?

- **Concept: Ensemble voting and majority decision**
  - Why needed here: The paper assumes majority voting for aggregating tree predictions, which affects how robustness is defined for the ensemble (requiring at least m/2 + 1 trees to be correct).
  - Quick check question: In a 7-tree ensemble, how many trees must be robust against an attack for the ensemble to be considered robust?

## Architecture Onboarding

- **Component map:**
  - Dataset loading pipeline -> Traditional random forest training -> LSE training for large-spread ensemble -> CARVE verification for large-spread ensemble -> SILVA verification for traditional ensemble -> Accuracy and robustness comparison

- **Critical path:**
  1. Load dataset → 2. Train traditional random forest → 3. Run LSE to create large-spread ensemble → 4. Verify robustness with CARVE → 5. Compare accuracy and robustness with SILVA results on traditional ensemble

- **Design tradeoffs:**
  - Large-spread vs accuracy: Enforcing large-spread condition may reduce accuracy slightly but improves robustness and verification efficiency
  - Ensemble size: Larger ensembles provide better accuracy but are harder to train with LSE and require more verification time
  - Feature partitioning: Helps train larger ensembles but may miss cross-feature patterns

- **Failure signatures:**
  - LSE returns ⊥: Indicates failure to find a large-spread subset; try increasing M_MAX_ITER or adjusting feature partitioning
  - SILVA timeouts: Indicates NP-hard verification; suggests switching to CARVE if ensemble is large-spread
  - Accuracy degradation > 0.05: Suggests mutation process is too aggressive; reduce perturbation k or try different parameter settings

- **First 3 experiments:**
  1. Train a small large-spread ensemble (25 trees, depth 4) on MNIST26 with k=0.005, compare accuracy and verification time with traditional ensemble
  2. Train a large large-spread ensemble (101 trees, depth 6) on Fashion-MNIST clothes with hierarchical training (l=4), measure success rate and accuracy
  3. Verify robustness of both traditional and large-spread ensembles on REWEMA dataset with k=0.015, comparing CARVE vs SILVA performance

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the verifiable learning approach be extended to other machine learning model classes beyond decision tree ensembles?
- **Basis in paper:** [explicit] The authors mention as future work exploring verifiable learning for other popular model classes, e.g., neural networks.
- **Why unresolved:** The paper only demonstrates verifiable learning for decision tree ensembles. Extending the approach to other model classes would require identifying appropriate model restrictions that enable efficient verification while maintaining accuracy.
- **What evidence would resolve it:** Successful development and experimental evaluation of verifiable learning approaches for at least one other major model class (e.g., neural networks, SVMs, or kernel methods) showing comparable accuracy to traditional models while enabling efficient robustness verification.

### Open Question 2
- **Question:** How does the large-spread ensemble approach compare to other robust training methods in terms of adversarial attack resistance?
- **Basis in paper:** [explicit] The authors note their work is complementary to other robust training algorithms and primarily targets efficient verification rather than maximizing robustness.
- **Why unresolved:** The paper focuses on verifiable learning and efficient verification rather than achieving maximum robustness. A comprehensive comparison with state-of-the-art robust training methods is needed.
- **What evidence would resolve it:** Head-to-head comparison of large-spread ensembles against multiple state-of-the-art robust training methods across various attack scenarios, measuring both standard accuracy and attack success rates.

### Open Question 3
- **Question:** What is the theoretical relationship between the large-spread condition and other ensemble diversity measures?
- **Basis in paper:** [explicit] The authors note connections to recent work on certified robustness for ensemble models that discusses "diversified gradient" and "large confidence margin" as sufficient and necessary conditions.
- **Why unresolved:** While the paper establishes that large-spread ensembles enable efficient verification, the relationship between this specific condition and other ensemble diversity metrics remains unexplored.
- **What evidence would resolve it:** Formal mathematical proofs establishing relationships between large-spread and other diversity measures, or empirical studies showing correlations between large-spread values and other ensemble quality metrics.

## Limitations

- The core assumption that the large-spread condition guarantees orthogonal perturbations needs formal proof
- Training algorithm success heavily depends on finding mutually large-spread trees, which may fail with highly correlated features
- Hierarchical training approach with feature partitioning needs more extensive validation across datasets

## Confidence

- **High confidence:** The polynomial-time verification algorithm for large-spread ensembles is well-defined and theoretically sound, given the large-spread condition holds
- **Medium confidence:** The pruning-based training algorithm can find large-spread ensembles with reasonable accuracy, though success rates vary significantly across datasets
- **Low confidence:** The hierarchical training approach with feature partitioning consistently improves results across all datasets; this needs more extensive validation

## Next Checks

1. **Formal proof verification:** Rigorously prove that the large-spread condition (ψ_p(T) > 2k) is both necessary and sufficient for orthogonal perturbations across trees in the ensemble
2. **Training algorithm robustness:** Test LSE training on datasets with high feature correlation to determine failure rates and identify conditions under which the algorithm fails to find large-spread ensembles
3. **Scalability analysis:** Measure how verification time and training success scale with ensemble size (m) and tree depth, particularly for very large ensembles (m > 100)