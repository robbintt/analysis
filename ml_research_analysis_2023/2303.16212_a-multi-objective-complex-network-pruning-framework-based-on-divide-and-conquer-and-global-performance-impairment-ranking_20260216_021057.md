---
ver: rpa2
title: A Multi-objective Complex Network Pruning Framework Based on Divide-and-conquer
  and Global Performance Impairment Ranking
arxiv_id: '2303.16212'
source_url: https://arxiv.org/abs/2303.16212
tags:
- pruning
- network
- algorithm
- sub-network
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes an EMO joint pruning with multiple sub-networks
  (EMO-PMS) to reduce space complexity and resource consumption in evolutionary multi-objective
  (EMO) network pruning. The core idea is to decompose the complex EMO pruning task
  on the entire network into simpler sub-tasks on multiple sub-networks using a divide-and-conquer
  approach.
---

# A Multi-objective Complex Network Pruning Framework Based on Divide-and-conquer and Global Performance Impairment Ranking

## Quick Facts
- arXiv ID: 2303.16212
- Source URL: https://arxiv.org/abs/2303.16212
- Reference count: 40
- This paper proposes an EMO joint pruning with multiple sub-networks (EMO-PMS) to reduce space complexity and resource consumption in evolutionary multi-objective (EMO) network pruning.

## Executive Summary
This paper addresses the challenge of complex network pruning by proposing a divide-and-conquer approach that decomposes EMO pruning tasks into simpler sub-tasks across multiple sub-networks. The method combines independent optimization of sub-networks with cross-network constraints to ensure collaboration, and uses global performance impairment ranking to integrate Pareto-optimal solutions. Experimental results on three datasets demonstrate the effectiveness and efficiency of this approach compared to fifteen advanced pruning algorithms.

## Method Summary
The EMO-PMS framework divides a complex network into multiple sub-networks, each optimized independently using NSGA-II for multi-objective pruning (minimizing prediction error while maximizing pruning rate). Sub-networks are trained with cross-network constraints to ensure feature compatibility, and their Pareto-optimal solutions are combined using global performance impairment ranking to create a complete joint pruning scheme.

## Key Results
- The divide-and-conquer approach reduces optimization space complexity from O(N) to O(N/M)
- Cross-network constraints improve collaboration among independently pruned sub-networks
- Global performance impairment ranking enables effective combination of Pareto-optimal solutions from different sub-networks
- The proposed algorithm shows effectiveness and efficiency compared to fifteen advanced pruning algorithms on CIFAR-10, CIFAR-100, and ImageNet-100 datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The divide-and-conquer approach reduces the optimization space complexity from O(N) to O(N/M) where M is the number of sub-networks.
- Mechanism: By splitting a complex network into M sub-networks, each with Nj layers, the optimization space becomes the sum of individual sub-network spaces rather than the product of all layers.
- Core assumption: Sub-networks can be optimized independently without significantly affecting overall network performance.
- Evidence anchors:
  - [abstract]: "decomposes the complex task of EMO pruning on the entire network into easier sub-tasks on multiple sub-networks"
  - [section]: "The size of the pruning space Oâ€²(Net all) is shown in Equation (7) and is significantly smaller than the pruning space O(Net all) from the original network"
  - [corpus]: Weak - no direct corpus evidence for this specific space complexity reduction claim
- Break condition: If sub-networks cannot be trained independently or their interactions are critical for performance.

### Mechanism 2
- Claim: Cross-network constraints ensure sub-networks can process features from adjacent sub-networks effectively.
- Mechanism: By constraining the output features of one sub-network to match the input features of the next, the method ensures feature compatibility across independently optimized sub-networks.
- Core assumption: Feature compatibility between sub-networks is sufficient to maintain overall network performance.
- Evidence anchors:
  - [abstract]: "a sub-network training method based on cross-network constraints to improve collaboration among independently pruned sub-networks"
  - [section]: "This method allows sub-networks optimized independently to collaborate better and improves the overall performance of the pruned network"
  - [corpus]: Weak - no direct corpus evidence for this specific constraint mechanism
- Break condition: If feature processing requirements vary significantly between sub-networks or if constraints are too restrictive.

### Mechanism 3
- Claim: Global performance impairment ranking enables effective combination of Pareto-optimal solutions from different sub-networks.
- Mechanism: By calculating a global performance impairment index for each solution across all sub-networks, the method can rank and select the best combination of pruning strategies.
- Core assumption: Performance impairment on individual sub-networks can be aggregated to represent overall network performance impact.
- Evidence anchors:
  - [abstract]: "combines the Pareto Fronts from EMO pruning results on multiple sub-networks through global performance impairment ranking to design a joint pruning scheme"
  - [section]: "It calculates a global performance impairment index based on the Pareto front obtained on each sub-network"
  - [corpus]: Weak - no direct corpus evidence for this specific ranking approach
- Break condition: If sub-network performances are not additive or if interactions between sub-networks create non-linear effects.

## Foundational Learning

- Concept: Evolutionary Multi-Objective Optimization (EMO)
  - Why needed here: The paper uses EMO algorithms (specifically NSGA-II) to balance multiple objectives like parameter reduction and performance preservation during pruning.
  - Quick check question: What are the two main objectives being optimized in the EMO pruning process described in the paper?

- Concept: Divide-and-Conquer Strategy
  - Why needed here: The paper applies divide-and-conquer to decompose complex network pruning into simpler sub-network pruning tasks.
  - Quick check question: How does the divide-and-conquer approach reduce the optimization space complexity according to Equation (7)?

- Concept: Pareto Front and Non-Dominated Solutions
  - Why needed here: The paper uses Pareto front analysis to identify optimal pruning solutions that balance multiple objectives.
  - Quick check question: What is the relationship between the Pareto front solutions and the global performance impairment ranking?

## Architecture Onboarding

- Component map:
  Input -> Divide-and-Conquer Module -> EMO Optimizer (for each sub-network) -> Cross-Network Constraint Trainer -> Global Performance Impairment Ranking -> Joint pruned network structure

- Critical path:
  1. Network division into sub-networks
  2. Independent EMO optimization on each sub-network
  3. Cross-network constraint training
  4. Global performance impairment ranking
  5. Joint pruning scheme construction

- Design tradeoffs:
  - Number of sub-networks vs. optimization complexity
  - Strength of cross-network constraints vs. sub-network independence
  - Granularity of Pareto front analysis vs. computational efficiency

- Failure signatures:
  - Poor performance when sub-networks cannot be optimized independently
  - Degradation in feature processing when cross-network constraints are too weak
  - Sub-optimal joint pruning when global ranking doesn't capture interactions

- First 3 experiments:
  1. Compare convergence rates of full network vs. sub-networks to verify the divide-and-conquer benefit
  2. Test feature compatibility with and without cross-network constraints
  3. Validate the effectiveness of global performance impairment ranking by comparing with random combination of sub-network solutions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the EMO-PMS algorithm scale when applied to even larger and more complex neural network architectures beyond ResNet50, such as those used in state-of-the-art vision models or natural language processing tasks?
- Basis in paper: [explicit] The paper mentions that the algorithm is validated on three datasets with different challenging, but does not explore scaling to larger and more complex architectures.
- Why unresolved: The paper does not provide experimental results or analysis on larger and more complex architectures, leaving the question of scalability open.
- What evidence would resolve it: Experimental results showing the performance of EMO-PMS on larger and more complex architectures, such as those used in state-of-the-art vision models or natural language processing tasks, would resolve this question.

### Open Question 2
- Question: How does the proposed sub-network training method based on cross-network constraints affect the collaboration among sub-networks when applied to networks with different layer configurations or connectivity patterns?
- Basis in paper: [explicit] The paper introduces the sub-network training method based on cross-network constraints and discusses its effectiveness in improving collaboration among sub-networks, but does not explore its applicability to networks with different layer configurations or connectivity patterns.
- Why unresolved: The paper does not provide experimental results or analysis on networks with different layer configurations or connectivity patterns, leaving the question of the method's applicability open.
- What evidence would resolve it: Experimental results showing the performance of the proposed sub-network training method on networks with different layer configurations or connectivity patterns would resolve this question.

### Open Question 3
- Question: How does the proposed divide-and-conquer EMO network pruning framework perform when applied to other types of neural network architectures, such as recurrent neural networks or transformers, which have different computational characteristics compared to convolutional neural networks?
- Basis in paper: [explicit] The paper introduces the divide-and-conquer EMO network pruning framework and discusses its effectiveness in reducing the optimization complexity of EMO algorithms, but does not explore its applicability to other types of neural network architectures.
- Why unresolved: The paper does not provide experimental results or analysis on other types of neural network architectures, leaving the question of the framework's applicability open.
- What evidence would resolve it: Experimental results showing the performance of the proposed divide-and-conquer EMO network pruning framework on other types of neural network architectures, such as recurrent neural networks or transformers, would resolve this question.

## Limitations
- The divide-and-conquer approach assumes sub-networks can be optimized independently, which may not hold for architectures with strong inter-layer dependencies.
- Cross-network constraints introduce additional complexity and may not generalize well to all network architectures.
- The global performance impairment ranking assumes additive performance effects across sub-networks, potentially overlooking non-linear interactions.

## Confidence
- Divide-and-conquer space complexity reduction: Medium - Theoretical reduction is clear, but empirical validation is limited
- Cross-network constraint effectiveness: Medium - Improvement shown but mechanism not fully explained
- Global performance impairment ranking: Low - Ranking method described but not rigorously validated against alternatives

## Next Checks
1. Conduct ablation studies removing the divide-and-conquer approach to quantify its exact contribution to performance gains
2. Test the framework on architectures with varying degrees of layer interdependence to evaluate the robustness of independent sub-network optimization
3. Compare the global performance impairment ranking method against alternative solution combination strategies on diverse network architectures