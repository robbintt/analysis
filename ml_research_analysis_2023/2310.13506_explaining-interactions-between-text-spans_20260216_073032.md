---
ver: rpa2
title: Explaining Interactions Between Text Spans
arxiv_id: '2310.13506'
source_url: https://arxiv.org/abs/2310.13506
tags:
- interactions
- high
- spans
- interaction
- span
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of explaining model predictions
  that rely on interactions between text spans from different parts of the input,
  such as in natural language inference (NLI) and fact-checking (FC) tasks. The authors
  introduce SpanEx, a new dataset of human-annotated span interactions for NLI and
  FC, capturing the human decision-making process for these tasks.
---

# Explaining Interactions Between Text Spans

## Quick Facts
- arXiv ID: 2310.13506
- Source URL: https://arxiv.org/abs/2310.13506
- Reference count: 40
- Key outcome: New dataset of human-annotated span interactions and novel method to extract model explanations from attention

## Executive Summary
This paper addresses the challenge of explaining model predictions that rely on interactions between text spans from different parts of the input, focusing on natural language inference (NLI) and fact-checking (FC) tasks. The authors introduce SpanEx, a new dataset of human-annotated span interactions for NLI and FC, capturing the human decision-making process for these tasks. They then investigate whether fine-tuned large language models follow similar reasoning processes by comparing model explanations to human ones using established metrics like AOPC-Comp, AOPC-Suff, and PHA. The results show that models generally align well with human reasoning, particularly for high-agreement interactions. Finally, the authors propose a novel community detection-based method to automatically extract such interaction explanations from model attention, achieving promising results on the evaluation metrics.

## Method Summary
The authors propose a novel approach to explain model predictions that depend on interactions between text spans from different input parts. They collect human annotations of important span interactions for NLI and FC tasks in the SpanEx dataset. To extract explanations from models, they construct a bipartite graph from attention weights between tokens from different input parts, then apply Louvain community detection to identify groups of interacting tokens. These token groups are combined into spans based on their positions to form interaction explanations. The extracted explanations are evaluated against human annotations using AOPC-Comp, AOPC-Suff, and PHA metrics to assess faithfulness and sufficiency.

## Key Results
- Models show good alignment with human reasoning on span interactions, with higher agreement for high-IAA interactions
- Community detection method achieves AOPC scores of 0.25-0.30 and PHA scores of 0.50-0.55 on SpanEx
- Human annotations show strong agreement (IAA of 0.65-0.72) on important span interactions
- SpanEx dataset contains 2,000 annotated examples across SNLI and FEVER tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method identifies span interactions that models actually use by leveraging attention weights as proxies for interaction strength.
- Mechanism: Attention weights between tokens from different input parts are extracted and used to construct a bipartite graph where edge weights represent interaction strength.
- Core assumption: Higher attention weights between tokens from different input parts indicate meaningful semantic interactions used by the model for prediction.
- Evidence anchors:
  - [abstract] "Finally, we present a novel community detection based unsupervised method to extract such interaction explanations from a model's inner workings."
  - [section] "We use the top layer attention scores as they dictate how the final representation before the classification layer is generated."
  - [corpus] Weak - no direct evidence of attention weights correlating with semantic interactions
- Break condition: If attention weights do not correlate with semantic interactions, the method will identify spurious or irrelevant interactions.

### Mechanism 2
- Claim: Community detection on the interaction graph produces semantically coherent span pairs that explain model predictions.
- Mechanism: Louvain community detection algorithm finds groups of tokens with dense inter-group and sparse intra-group connections, which are then combined into spans based on token positions.
- Core assumption: Dense connections between tokens from different input parts indicate meaningful semantic relationships that form coherent spans.
- Evidence anchors:
  - [abstract] "Finally, we present a novel community detection based unsupervised method to extract such interaction explanations from a model's inner workings."
  - [section] "We use community structure detection algorithms (Fang et al., 2020) on GI to find groups of nodes (tokens) with dense inter-group and sparse intra-group connections."
  - [corpus] Moderate - Louvain algorithm is established for community detection in large networks
- Break condition: If the algorithm produces non-semantically coherent spans or misses meaningful interactions, the explanations will be unhelpful.

### Mechanism 3
- Claim: Comparing model explanations to human annotations validates that models follow similar reasoning processes.
- Mechanism: Human annotations identify important span interactions for predictions, which are then compared to model explanations using AOPC and PHA metrics.
- Core assumption: If models use similar reasoning to humans, their explanations will align with human annotations on evaluation metrics.
- Evidence anchors:
  - [abstract] "We then investigate the decision-making processes of multiple fine-tuned large language models in terms of the employed connections between spans in separate parts of the input and compare them to the human reasoning processes."
  - [section] "The Random Phrase baseline randomly samples both spans of the interaction from each of the two parts of the input."
  - [corpus] Moderate - AOPC and PHA are established metrics for evaluating explanation faithfulness
- Break condition: If models do not follow human reasoning patterns, the explanations will not align with human annotations.

## Foundational Learning

- Concept: Attention mechanisms in transformers
  - Why needed here: The method relies on extracting and interpreting attention weights to identify span interactions
  - Quick check question: What is the relationship between attention weights and token interactions in transformer models?

- Concept: Community detection algorithms
  - Why needed here: The method uses Louvain community detection to identify groups of interacting tokens that form coherent spans
  - Quick check question: How does the Louvain algorithm identify communities in a bipartite graph?

- Concept: Explanation evaluation metrics (AOPC, PHA)
  - Why needed here: The method evaluates the quality of extracted explanations by comparing them to human annotations using established metrics
  - Quick check question: What is the difference between AOPC-Comprehensiveness and AOPC-Sufficiency?

## Architecture Onboarding

- Component map: Tokenization → Attention extraction → Bipartite graph construction → Louvain community detection → Span generation → AOPC/PHA evaluation
- Critical path: Attention extraction → Graph construction → Community detection → Span generation → Evaluation
- Design tradeoffs:
  - Using top layer attention vs. aggregated attention from multiple layers
  - Louvain algorithm (fast, approximate) vs. exact community detection methods
  - Bipartite graph construction vs. full interaction graph
- Failure signatures:
  - Low AOPC scores indicate explanations not aligned with model behavior
  - Non-semantic spans suggest graph construction or community detection issues
  - High variance in scores across models suggests implementation inconsistencies
- First 3 experiments:
  1. Extract attention weights from a simple transformer model and visualize the bipartite graph structure
  2. Apply Louvain community detection on a small synthetic interaction graph and verify span generation
  3. Run AOPC evaluation on a single model with known behavior to validate the evaluation pipeline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the IAA vary across different interaction types (synonym, antonym, hypernym) and tasks (NLI vs FC)?
- Basis in paper: [explicit] Table 4 shows IAA for all interactions combined, but does not break it down by interaction type or task.
- Why unresolved: The paper presents overall IAA metrics but does not analyze how agreement differs for specific interaction categories.
- What evidence would resolve it: Calculating IAA separately for each interaction type and task, presented in a table format.

### Open Question 2
- Question: Would expanding SpanEx to include interactions between more than two parts of the input (e.g., multiple evidence sentences in FC) change the observed model alignment with human reasoning?
- Basis in paper: [inferred] The limitations section mentions this as a potential future direction, suggesting it could yield different insights.
- Why unresolved: The current dataset only captures interactions between two parts of the input, limiting generalizability to more complex scenarios.
- What evidence would resolve it: Extending the dataset and analysis to include multi-part interactions and comparing model explanations.

### Open Question 3
- Question: How do the proposed community detection methods compare to other span extraction methods (e.g., gradient-based) in terms of generating semantically coherent and relevant interactions?
- Basis in paper: [explicit] The discussion mentions limitations of the current approach and suggests future improvements.
- Why unresolved: The paper only evaluates the proposed methods against random and part-phrase baselines, not against other span extraction techniques.
- What evidence would resolve it: Implementing and comparing the proposed methods with other span extraction methods on the same evaluation metrics.

## Limitations
- The method relies on attention weights as proxies for semantic interactions, which may not accurately reflect the model's reasoning process
- The community detection approach may produce non-semantically coherent spans if the graph structure doesn't reflect true semantic relationships
- Evaluation metrics assume human annotations represent ground truth reasoning, but human judgments may vary or miss implicit reasoning patterns

## Confidence
- High confidence: The proposed method for extracting span interactions from attention weights using community detection is technically sound and builds on established graph analysis techniques. The comparison methodology using AOPC and PHA metrics is well-established in the literature.
- Medium confidence: The claim that models follow similar reasoning processes to humans is supported by the alignment of model explanations with human annotations on evaluation metrics. However, this alignment may not necessarily indicate that models use the same underlying reasoning mechanisms.
- Low confidence: The assumption that attention weights directly correspond to semantic interactions used by the model for predictions. This is a critical assumption that requires empirical validation.

## Next Checks
1. **Correlation validation**: Measure the correlation between attention weights and semantic similarity scores (e.g., cosine similarity of token embeddings) to verify that high attention weights correspond to semantically related tokens.
2. **Ablation study**: Compare the proposed method against a baseline that uses random attention weights or alternative interaction measures (e.g., gradient-based attribution) to assess whether the community detection approach adds value beyond simple attention extraction.
3. **Human evaluation**: Conduct a human evaluation where annotators rate the semantic coherence and relevance of automatically extracted span interactions, providing qualitative validation beyond the quantitative AOPC/PHA metrics.