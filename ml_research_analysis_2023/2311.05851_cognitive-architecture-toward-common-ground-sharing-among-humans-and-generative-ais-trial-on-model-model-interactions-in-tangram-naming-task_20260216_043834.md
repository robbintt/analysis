---
ver: rpa2
title: 'Cognitive Architecture Toward Common Ground Sharing Among Humans and Generative
  AIs: Trial on Model-Model Interactions in Tangram Naming Task'
arxiv_id: '2311.05851'
source_url: https://arxiv.org/abs/2311.05851
tags:
- module
- cognitive
- process
- tangram
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of building transparent common
  grounding between generative AI models and humans, essential for trustworthy AI.
  The authors propose a cognitive architecture that simulates human common-ground-building
  processes using generative AI models in a tangram naming task (TNT).
---

# Cognitive Architecture Toward Common Ground Sharing Among Humans and Generative AIs: Trial on Model-Model Interactions in Tangram Naming Task

## Quick Facts
- arXiv ID: 2311.05851
- Source URL: https://arxiv.org/abs/2311.05851
- Reference count: 4
- Primary result: Generative AI models achieved 28.8% accuracy in tangram communication task after incremental learning

## Executive Summary
This study explores how generative AI models can simulate human common-ground-building processes through a tangram naming task. The authors propose a cognitive architecture with visual, speech, audio, goal, imaginal, and memory modules that work together to generate and interpret symbolic descriptions of abstract shapes. Initial experiments showed the model achieved 27% accuracy in matching tangrams between sender and receiver, which improved to 28.8% after incremental backpropagation learning on successful cases. While still below human performance, these results demonstrate the viability of using generative AI to visualize and improve common grounding processes.

## Method Summary
The researchers implemented a cognitive architecture where a sender model constructs metaphorical images from tangrams using visual and imaginal modules, generates descriptions via speech modules, and receivers reconstruct images from descriptions. The system uses a CNN trained on ImageNet Sketch for visual recognition, Stable Diffusion for image generation (both img2img and txt2img variants), and a Vision Transformer-based captioning model. Communication episodes were evaluated by matching reconstructed tangrams with original ones using cosine similarity of CNN output layers. Incremental backpropagation was applied to successful communication cases to improve performance.

## Key Results
- Initial model accuracy: 27.0% matching tangrams between sender and receiver
- Post-learning accuracy: 28.8% (statistically significant improvement, p < 0.01)
- Best-case performance: 39.5% accuracy achieved in individual trials
- Chance level: 16.6% for random guessing in the 6-shape tangram task

## Why This Works (Mechanism)

### Mechanism 1
Generative AI models can simulate human common-ground-building processes through iterative visual and linguistic transformations. The sender constructs metaphorical images from tangrams using visual modules, generates descriptions via speech modules, and receivers reconstruct images from descriptions. This creates a bidirectional mapping between visual and linguistic representations. Core assumption: Deep neural networks can encode and decode complex visual-linguistic relationships that mirror human cognitive processes. Break condition: Performance plateaus below useful thresholds.

### Mechanism 2
Incremental backpropagation learning on successful communication cases improves model performance. The model identifies successful sender-receiver matches, uses these as training examples, and applies policy gradient algorithms to adjust network parameters in visual and imaginal modules. Core assumption: Successful communication cases contain sufficient information to guide parameter optimization toward better common grounding. Break condition: Learning rate diminishes to negligible improvements or begins overfitting to limited successful cases.

### Mechanism 3
Tangram task provides a controlled testbed for examining common-ground-building processes. Abstract tangram shapes with multiple valid interpretations force models to negotiate shared meaning rather than relying on obvious object recognition. Core assumption: The complexity and ambiguity of tangrams adequately represents the challenges of real-world common ground establishment. Break condition: Task complexity becomes too simplified to generalize to real-world communication scenarios.

## Foundational Learning

- **Convolutional Neural Networks for visual processing**: Visual module requires object recognition from tangram shapes without texture bias. Quick check: Why did the authors train a custom CNN using ImageNet Sketch rather than using pre-trained models?

- **Image-to-Image and Text-to-Image generation**: Imaginal module transforms between tangram shapes and metaphorical representations. Quick check: How do img2img and Stable Diffusion components work together in the sender process?

- **Instance-based learning and memory**: Memory module stores past communication examples to inform future interactions. Quick check: What is the difference between instance-based learning and traditional supervised learning in this context?

## Architecture Onboarding

- **Component map**: Visual module (CNN) → Imaginal module (img2img/txt2img) → Speech module (captioning) → Audio module (text storage) → Goal module (expression management) → Memory module (conversation instances) → Production system (coordination)
- **Critical path**: Sender visual perception → image generation → text captioning → receiver text reception → image reconstruction → tangram identification
- **Design tradeoffs**: Simpler models with faster training vs complex models with better visual-linguistic alignment; computational efficiency vs accuracy
- **Failure signatures**: Confusion matrices showing systematic misclassifications, accuracy below chance levels, learning curves plateauing early
- **First 3 experiments**:
  1. Run one-shot communication without learning to establish baseline accuracy
  2. Apply incremental backpropagation only to visual module and measure improvement
  3. Expand learning to imaginal module components and compare performance gains

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal learning strategy to improve common grounding accuracy in tangram naming tasks beyond the current 28.8% level? The authors note that their current learning approach only tunes parameters in the first CNN layer and that the accuracy increase remains insufficient to replicate human data, suggesting the need to explore learning other network modules. Experiments systematically testing learning on different combinations of modules with various learning algorithms would resolve this question.

### Open Question 2
How does the common cognitive framework between sender and receiver models evolve through repeated interactions? The authors mention that humans accumulate interactions since childhood and hold experiences as key-value pairs organized hierarchically, but their model only implements basic incremental learning. Long-term simulation studies tracking how model parameters and interaction patterns change across thousands of interactions would resolve this question.

### Open Question 3
What is the relative contribution of holistic versus analytic processing in achieving successful common grounding? The authors reference Sudo et al.'s finding that holistic utterances outnumbered analytic utterances in human performance, but their model focuses only on holistic processing. Comparative experiments implementing both holistic and analytic processing pathways in the model would resolve this question.

## Limitations
- Low accuracy rates (27-39%) indicate the model still struggles to achieve human-level communication reliability
- Simplified tangram task may not capture full complexity of real-world common ground establishment
- Modest practical improvement from incremental learning despite statistical significance

## Confidence
- **High Confidence**: Experimental framework using tangrams as controlled testbed is methodologically sound
- **Medium Confidence**: Generative AI can visualize internal common grounding processes
- **Medium Confidence**: Incremental backpropagation approach shows measurable improvement
- **Low Confidence**: Scalability to real-world human-AI communication scenarios

## Next Checks
1. Test the same cognitive architecture on a more complex common grounding task to assess generalizability beyond tangrams
2. Conduct ablation studies systematically removing or modifying individual modules to quantify their relative contributions
3. Compare model performance against human senders and receivers in the same tangram task to better understand specific cognitive gaps