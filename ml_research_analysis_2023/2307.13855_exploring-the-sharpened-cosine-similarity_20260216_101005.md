---
ver: rpa2
title: Exploring the Sharpened Cosine Similarity
arxiv_id: '2307.13855'
source_url: https://arxiv.org/abs/2307.13855
tags:
- none
- relu
- maxabspool2d
- maxpool2d
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study empirically evaluates Sharpened Cosine Similarity (SCS)
  as a convolutional layer replacement in CNN architectures on CIFAR-10. SCS is tested
  across multiple architectures (Rohrer25K-583K, ResNet18) with combinations of SCS,
  convolution, and SharpenedSDP layers, with/without ReLU and MaxPool2d/MaxAbsPool2d.
---

# Exploring the Sharpened Cosine Similarity

## Quick Facts
- arXiv ID: 2307.13855
- Source URL: https://arxiv.org/abs/2307.13855
- Reference count: 40
- Sharpened Cosine Similarity achieves comparable accuracy to convolution without requiring ReLU activation

## Executive Summary
This study empirically evaluates Sharpened Cosine Similarity (SCS) as a convolutional layer replacement in CNN architectures on CIFAR-10. SCS is tested across multiple architectures (Rohrer25K-583K, ResNet18) with combinations of SCS, convolution, and SharpenedSDP layers, with/without ReLU and MaxPool2d/MaxAbsPool2d. Results show SCS achieves comparable accuracy to convolution (~78-86%) without requiring ReLU, but trains slower and evaluates faster. SCS layers produce more interpretable saliency maps focusing on true features. Some SCS variants show increased adversarial robustness, especially with MaxAbsPool2d and no ReLU. SharpenedSDP also shows promise as an alternative. SCS performance depends heavily on architecture and layer combinations, suggesting need for tailored best practices.

## Method Summary
The study evaluates Sharpened Cosine Similarity by replacing convolutional layers in various CNN architectures (Rohrer series and ResNet18) with SCS layers on CIFAR-10. SCS is implemented using the formula SCS(s,k) = sign(s·k) * (|s·k| / ((||s|| + q)||k||))^p where p is the sharpening exponent. Models are trained with Adam optimizer (lr=0.01), OneCycleLR scheduler, and random crop/horizontal flip augmentations for 200-800 epochs. Performance is compared across layer combinations (conv/SCS/SharpenedSDP × ReLU/no ReLU × MaxPool2d/MaxAbsPool2d) using accuracy, training/evaluation efficiency, interpretability (saliency maps), and adversarial robustness (PGD attacks) as metrics.

## Key Results
- SCS achieves comparable accuracy to convolution (~78-86%) without requiring ReLU activation
- SCS layers produce more interpretable saliency maps focusing on true features
- Some SCS variants show increased adversarial robustness, especially with MaxAbsPool2d and no ReLU

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SCS achieves comparable accuracy to standard convolution without requiring ReLU activation
- Mechanism: The sharpened cosine similarity inherently includes a non-linear transformation through the exponentiation (p-th power), effectively replacing the role of ReLU activation in the layer's output normalization and non-linearity
- Core assumption: The exponentiation of cosine similarity provides sufficient non-linearity for feature learning without additional activation functions
- Evidence anchors:
  - [abstract] "SCS achieves comparable accuracy to convolution (~78-86%) without requiring ReLU"
  - [section] "we do confirm that SCS is able to achieve comparable accuracy performance to standard convolutional layers without the inclusion of ReLU nonlinear activation functions"
  - [corpus] Weak evidence - no direct corpus support for this specific mechanism
- Break condition: If the exponentiation power p is set to 1 (no sharpening), SCS performance drops significantly when not paired with ReLU

### Mechanism 2
- Claim: SCS produces more interpretable saliency maps that focus on true features
- Mechanism: The cosine similarity normalization constrains outputs between -1 and 1, while the sharpening exponent emphasizes strong feature responses and suppresses weak ones, creating sparser, more feature-focused activation patterns
- Core assumption: The bounded nature of cosine similarity combined with sharpening creates cleaner feature detection than unbounded dot products
- Evidence anchors:
  - [abstract] "SCS layers produce more interpretable saliency maps focusing on true features"
  - [section] "our initial results suggest that SCS-based model variants tend to learn representations that are more interpretable and focus on more critical parts of the image"
  - [corpus] Weak evidence - related work mentions cosine similarity but not specifically the interpretability mechanism described here
- Break condition: When p is very low (e.g., p=1), the saliency maps become less sparse and less interpretable

### Mechanism 3
- Claim: SCS provides increased adversarial robustness in certain configurations
- Mechanism: The normalization and sharpening in SCS creates more stable feature representations that are less sensitive to small perturbations, particularly when combined with MaxAbsPool2d which further stabilizes feature magnitudes
- Core assumption: Normalized, sharpened features are inherently more robust to adversarial perturbations than raw dot products
- Evidence anchors:
  - [abstract] "Some SCS variants show increased adversarial robustness, especially with MaxAbsPool2d and no ReLU"
  - [section] "SCS-based Rohrer100K and ResNet18 variants are noticeably more adversarially robust than their convolution-based counterparts"
  - [corpus] Weak evidence - no direct corpus support for this specific adversarial robustness mechanism
- Break condition: When ReLU is included with MaxAbsPool2d, the adversarial robustness advantage diminishes significantly

## Foundational Learning

- Concept: Cosine similarity and its mathematical properties
  - Why needed here: Understanding the base operation that SCS builds upon is crucial for grasping why the normalization helps with variance and interpretability
  - Quick check question: What is the range of values for cosine similarity between two vectors?

- Concept: Pooling operations (MaxPool2d vs MaxAbsPool2d)
  - Why needed here: The choice of pooling operation significantly affects SCS performance and adversarial robustness
  - Quick check question: How does MaxAbsPool2d differ from MaxPool2d in handling negative values?

- Concept: Gradient-based saliency maps and adversarial attacks
  - Why needed here: These are the primary tools used to evaluate interpretability and robustness of the models
  - Quick check question: What does a sparse saliency map indicate about a model's feature detection compared to a scattered one?

## Architecture Onboarding

- Component map:
  - Input layer → SCS/Conv2d layer → Pooling (MaxPool2d/MaxAbsPool2d) → Optional ReLU → Next layer
  - Key decision points: Layer type (SCS vs Conv2d), pooling type, activation presence, BatchNorm2d inclusion

- Critical path:
  - SCS layer implementation with exponentiation parameter p
  - Pooling layer selection (MaxAbsPool2d preferred for SCS)
  - Training loop with appropriate learning rate scheduling
  - Evaluation with saliency map generation and PGD attacks

- Design tradeoffs:
  - SCS vs Conv2d: SCS slower to train but faster to evaluate, potentially more interpretable
  - MaxAbsPool2d vs MaxPool2d: MaxAbsPool2d better for SCS, especially without ReLU
  - With/without ReLU: SCS works without ReLU, but may have slightly lower accuracy

- Failure signatures:
  - Vanishing/exploding gradients with SharpenedSDP on higher resolution images
  - Poor accuracy when using both ReLU and MaxAbsPool2d together
  - Significantly slower training times for SCS compared to Conv2d

- First 3 experiments:
  1. Replace a single Conv2d layer in a simple CNN with SCS, keeping all other components identical, and compare accuracy
  2. Test the same network with MaxPool2d vs MaxAbsPool2d to observe the impact on SCS performance
  3. Generate saliency maps for both the Conv2d and SCS versions to qualitatively assess interpretability differences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what specific architectural conditions does SCS provide meaningful adversarial robustness benefits compared to standard convolution?
- Basis in paper: [explicit] The paper found inconsistent results - initial tests showed SCS variants were more robust, but follow-up tests on larger architectures showed SharpenedSDP/MaxAbsPool2d/ReLU and convolution/MaxAbsPool2d/ReLU were actually the most robust
- Why unresolved: The adversarial robustness results were highly dependent on the specific architecture and layer combinations used, with no clear pattern emerging across different network sizes and configurations
- What evidence would resolve it: Systematic ablation studies varying one architectural parameter at a time (pool type, activation, normalization) across multiple network scales while controlling for accuracy levels

### Open Question 2
- Question: What is the optimal relationship between the p exponent value in SCS and the learning rate for stable training?
- Basis in paper: [inferred] The paper briefly explored fixed-p SCS variants with Optuna but did not investigate how p interacts with learning rate schedules
- Why unresolved: While the paper found that p values near 1.0 work well, it did not explore how p should be tuned relative to other hyperparameters like learning rate
- What evidence would resolve it: Experiments systematically varying p across multiple orders of magnitude while testing different learning rate schedules and decay rates

### Open Question 3
- Question: Does SCS provide any advantages for higher resolution images beyond 224x224, and if so, what architectural modifications optimize its performance?
- Basis in paper: [explicit] The paper only tested SCS on CIFAR-10 resized to 224x224, noting this as a direction for future work
- Why unresolved: The paper's highest resolution test was still relatively small compared to modern computer vision tasks that use 512x512 or larger images
- What evidence would resolve it: Training SCS-based networks on ImageNet or similar large-scale datasets and comparing performance to equivalent convolution-based architectures

## Limitations

- Limited architectural exploration with relatively simple networks and shallow depth
- Underspecified SharpenedSDP mechanism making exact reproduction challenging
- High variability across architectures and layer combinations suggests context-dependent effectiveness rather than universal applicability

## Confidence

- High confidence: SCS achieves comparable accuracy to convolution without ReLU - supported by direct experimental evidence across multiple architectures
- Medium confidence: SCS produces more interpretable saliency maps - qualitative observations supported but not rigorously quantified across all models
- Low confidence: SCS provides increased adversarial robustness - limited to specific configurations (MaxAbsPool2d without ReLU), with unexplained exceptions

## Next Checks

1. **Architectural scaling test**: Implement SCS in deeper architectures (e.g., ResNet50, VGG16) on CIFAR-10 and ImageNet to verify if interpretability and robustness benefits persist at scale

2. **Mechanism isolation**: Systematically test each component (cosine normalization, sharpening exponent, pooling type) independently to quantify their individual contributions to performance

3. **Generalization benchmark**: Evaluate SCS across diverse datasets (MNIST, SVHN, TinyImageNet) and tasks (segmentation, object detection) to assess whether benefits extend beyond classification on CIFAR-10