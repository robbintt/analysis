---
ver: rpa2
title: Convergence and concentration properties of constant step-size SGD through
  Markov chains
arxiv_id: '2306.11497'
source_url: https://arxiv.org/abs/2306.11497
tags:
- markov
- assumption
- gradient
- which
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper studies constant step-size SGD as a Markov chain and
  shows that under mild assumptions on the gradient noise, the SGD iterates converge
  geometrically to an invariant distribution in both total variation and Wasserstein-2
  distances. A key contribution is proving that if the gradient noise has sub-Gaussian
  or sub-exponential concentration, the invariant distribution inherits these properties
  with constants proportional to the step-size.
---

# Convergence and concentration properties of constant step-size SGD through Markov chains

## Quick Facts
- **arXiv ID**: 2306.11497
- **Source URL**: https://arxiv.org/abs/2306.11497
- **Reference count**: 40
- **Key outcome**: Shows constant step-size SGD converges geometrically to an invariant distribution, with concentration properties inherited from gradient noise, enabling high-confidence deviation bounds

## Executive Summary
This paper establishes that constant step-size SGD can be analyzed as a geometrically ergodic Markov chain, converging to a unique invariant distribution in both total variation and Wasserstein-2 distances. The key innovation is proving that if the gradient noise has sub-Gaussian or sub-exponential concentration, the invariant distribution inherits these properties with constants proportional to the step-size. This framework enables deriving high-confidence deviation bounds for the final iterate, with the added benefit of dimension-free bounds under stronger concentration assumptions on the gradient. The results are non-asymptotic and demonstrated through applications to linear and logistic regression.

## Method Summary
The paper models constant step-size SGD as a Markov chain and proves geometric ergodicity under mild assumptions on the objective (smoothness, strong convexity) and gradient noise (unbiasedness, controlled variance). It then derives properties of the invariant distribution, showing that concentration properties of the gradient noise are inherited by the invariant distribution. High-confidence deviation bounds are obtained by combining the geometric ergodicity with the concentration properties of the invariant distribution.

## Key Results
- SGD with constant step-size converges geometrically to an invariant distribution in both total variation and Wasserstein-2 distances
- The invariant distribution inherits sub-Gaussian/sub-exponential concentration from gradient noise with constants proportional to step-size
- Dimension-free deviation bounds are obtained under stronger concentration assumptions on the gradient
- For linear gradients, dimension-free high-confidence bounds are provided for Polyak-Ruppert averaging of tail iterates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SGD with constant step-size behaves as a geometrically ergodic Markov chain that converges to a unique invariant distribution.
- Mechanism: Under mild assumptions on gradient noise (unbiasedness, bounded variance), the SGD iteration can be modeled as a Markov chain with a drift condition that ensures geometric ergodicity. The transition kernel has a minorization property that guarantees sufficient exploration of the state space, leading to convergence in total variation and Wasserstein-2 distances.
- Core assumption: Assumptions 1 and 2 hold - the objective is smooth and strongly convex, and the gradient noise is unbiased with controlled variance and admits a diffuse component in its distribution.
- Evidence anchors:
  - [abstract] "We show that, for unbiased gradient estimates with mildly controlled variance, the iteration converges to an invariant distribution in total variation distance."
  - [section] "By Assumption 2, for all θ, the gradient is distributed according to an everywhere positive density, therefore, for all θ ∈ S ⊂ Rd with S a set with non zero Lebesgue measure we have P (θ,S )> 0. This implies that the greatest possible period for the chain is 1 which makes it aperiodic."
  - [corpus] Weak - related papers discuss ergodicity and bias but do not directly prove geometric ergodicity for constant step-size SGD.
- Break condition: If the gradient noise variance grows too quickly or the gradient noise distribution lacks a diffuse component, the minorization property may fail and ergodicity could be lost.

### Mechanism 2
- Claim: The invariant distribution inherits concentration properties (sub-Gaussian or sub-exponential) from the gradient noise distribution.
- Mechanism: If the gradient noise has sub-Gaussian or sub-exponential concentration (Assumption 3), the Markov chain's invariant distribution π_β satisfies the same concentration property with constants proportional to the step-size β. This allows deriving high-confidence deviation bounds for the final iterate.
- Core assumption: Assumption 3 holds - the gradient error has finite exponential moments, uniformly in the parameter θ.
- Evidence anchors:
  - [abstract] "Thanks to the invariance property of the limit distribution, our analysis shows that the latter inherits sub-Gaussian or sub-exponential concentration properties when these hold true for the gradient."
  - [section] "We show that sub-Gaussian and sub-exponential concentration of the gradient samples imply the same property for the invariant limit distribution with Ψ1/ Ψ2 constant proportional to the step-size."
  - [corpus] Weak - related papers discuss concentration for SGD but do not explicitly show inheritance of concentration properties by the invariant distribution.
- Break condition: If the gradient noise does not have finite exponential moments, the invariant distribution may not inherit the desired concentration properties.

### Mechanism 3
- Claim: Under stronger concentration assumptions on the gradient noise (Assumption 4), the invariant distribution satisfies dimension-free deviation bounds.
- Mechanism: Assumption 4 requires that the gradient noise satisfies a transportation-information inequality, which is equivalent to a stronger form of concentration that is independent of the dimension. This allows deriving deviation bounds that do not degrade with the problem dimension.
- Core assumption: Assumption 4 holds - the gradient noise satisfies a transportation-information inequality for all Lipschitz functions.
- Evidence anchors:
  - [abstract] "Additionally, under a stronger concentration assumption on the gradient, the paper obtains dimension-free deviation bounds."
  - [section] "By restricting the functions f in Assumption 4 to be linear, we recover the assumption that the vector G(θ,ζ ) is sub-Gaussian/sub-exponential. An interesting question is then whether this weaker property implies Assumption 4 with a dimension independent constant."
  - [corpus] Weak - related papers discuss transportation inequalities but do not directly apply them to obtain dimension-free deviation bounds for SGD.
- Break condition: If the gradient noise does not satisfy the transportation-information inequality, the dimension-free property may not hold.

## Foundational Learning

- Concept: Markov chains and geometric ergodicity
  - Why needed here: The paper models SGD with constant step-size as a Markov chain and proves its geometric ergodicity, which is crucial for establishing convergence to an invariant distribution.
  - Quick check question: What are the key conditions for a Markov chain to be geometrically ergodic?

- Concept: Concentration of measure and transportation inequalities
  - Why needed here: The paper uses concentration properties of the gradient noise to derive high-confidence bounds for the invariant distribution and the final iterate. Transportation inequalities are used to obtain dimension-free bounds.
  - Quick check question: What is the relationship between transportation inequalities and concentration of measure?

- Concept: Wasserstein distance and its role in convergence analysis
  - Why needed here: The paper proves convergence of the SGD Markov chain in Wasserstein-2 distance, which provides a stronger form of convergence than total variation distance and allows for more refined analysis of the invariant distribution.
  - Quick check question: How does convergence in Wasserstein distance differ from convergence in total variation distance?

## Architecture Onboarding

- Component map:
  - Assumptions (1, 2, 3, 4, 5, 6) -> Define problem setting and gradient noise properties
  - Theorem 1 -> Geometric ergodicity of SGD Markov chain
  - Proposition 1 -> Basic properties of invariant distribution
  - Propositions 2, 3 -> Concentration properties of invariant distribution
  - Proposition 4 -> Convergence in Wasserstein distance
  - Corollaries 1, 2 -> High-confidence deviation bounds
  - Theorem 2, Proposition 6 -> Polyak-Ruppert averaging bounds

- Critical path:
  1. Verify Assumptions 1 and 2 hold for the problem at hand.
  2. Check if Assumption 3 or 4 is satisfied by the gradient noise distribution.
  3. If Assumption 3 holds, use Corollary 1 to obtain deviation bounds.
  4. If Assumption 4 holds, use Corollary 2 for dimension-free bounds.
  5. For linear gradients, use Theorem 2 and Proposition 6 for Polyak-Ruppert averaging bounds.

- Design tradeoffs:
  - Stronger assumptions (e.g., Assumption 4) lead to better concentration properties but may be harder to verify.
  - Dimension-free bounds require stronger concentration assumptions but provide more robust guarantees.
  - Polyak-Ruppert averaging provides better concentration but requires linear gradients.

- Failure signatures:
  - If the gradient noise does not satisfy the required assumptions, the convergence and concentration results may not hold.
  - If the step-size is not chosen appropriately, the Markov chain may not converge or may converge too slowly.
  - If the problem is not strongly convex or smooth, the analysis may not apply.

- First 3 experiments:
  1. Verify the assumptions for a simple quadratic optimization problem and check the convergence of the SGD Markov chain.
  2. Compare the deviation bounds obtained from Corollary 1 and 2 for a linear regression problem with Gaussian covariates.
  3. Test the Polyak-Ruppert averaging bounds for a logistic regression problem with bounded covariates.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can we obtain tighter convergence rates for the total variation and Wasserstein distances in Theorem 1 and Proposition 4 by leveraging renewal theory or spectral properties of the transition kernel?
- Basis in paper: The authors note that while geometric ergodicity is established, precise quantification of the convergence speed (factor ρ) remains elusive, with existing methods yielding pessimistic bounds.
- Why unresolved: The SGD Markov chain does not satisfy standard criteria (reversible, stochastically ordered, etc.) that enable sharp convergence rate analysis.
- What evidence would resolve it: A detailed analysis of the renewal properties of the SGD Markov chain or a study of the spectral properties of the transition kernel P_β showing that ρ ≈ 1 - βμ (the intuitive expectation).

### Open Question 2
- Question: Can we generalize the concentration results (Propositions 2 and 3) to weaker moment assumptions on the gradient noise, beyond sub-Gaussian/sub-exponential tails?
- Basis in paper: The authors mention Lemma 1, which shows that finite p-moments of the gradient noise imply finite moments of the invariant distribution π_β, but concentration properties are not explored for such cases.
- Why unresolved: The proofs of Propositions 2 and 3 rely heavily on exponential moment assumptions, and extending them to weaker moment assumptions would require new techniques.
- What evidence would resolve it: Developing concentration inequalities for the invariant distribution under weaker moment assumptions, such as finite p-moments with p > 2, or sub-Weibull tails.

### Open Question 3
- Question: Can we obtain dimension-free deviation bounds for the Polyak-Ruppert average in the non-linear case, similar to Proposition 6 for the linear case?
- Basis in paper: Proposition 6 provides dimension-free deviation bounds for the Polyak-Ruppert average in the linear case under Assumption 4, but the authors note that this result relies on the linearity of the gradient.
- Why unresolved: The lack of linearity of the gradient in the non-linear case prevents the direct application of the techniques used in Proposition 6.
- What evidence would resolve it: Developing new techniques to control the bias and variance of the Polyak-Ruppert average in the non-linear case, potentially leveraging properties of the gradient or the objective function beyond linearity.

## Limitations

- The dimension-free bounds under Assumption 4 require a strong transportation-information inequality that may be difficult to verify in practice
- The concentration constants are proportional to the step-size β, which may be too loose for small step-sizes commonly used in practice
- The Polyak-Ruppert averaging results are limited to linear gradients, with non-linear cases remaining an open question

## Confidence

- **High confidence**: Geometric ergodicity of the SGD Markov chain under Assumptions 1 and 2 (Theorem 1)
- **Medium confidence**: Inheritance of concentration properties by the invariant distribution (Propositions 2 and 3)
- **Medium confidence**: Dimension-free deviation bounds under Assumption 4 (Proposition 3, Corollary 2)
- **Medium confidence**: Polyak-Ruppert averaging bounds for linear gradients (Theorem 2, Proposition 6)

## Next Checks

1. **Numerical verification of ergodicity constants**: For a simple quadratic optimization problem, numerically estimate the geometric convergence rate ρ and mixing constant M from Theorem 1, comparing them against the theoretical bounds. This would validate whether the ergodicity conditions are practically achievable.

2. **Gradient noise distribution analysis**: For logistic regression with Gaussian covariates, empirically test whether the gradient noise satisfies Assumptions 3 and 4. Specifically, verify the sub-Gaussian/sub-exponential properties and attempt to estimate the transportation-information inequality constant. This would assess the practical applicability of the concentration results.

3. **Comparison of deviation bounds**: Implement both Corollaries 1 and 2 for linear regression with varying dimensions. Compare the empirical coverage probability of the deviation bounds against their theoretical predictions, particularly focusing on the dimension-free property claimed in Corollary 2. This would validate whether the stronger concentration assumptions lead to practically useful improvements.