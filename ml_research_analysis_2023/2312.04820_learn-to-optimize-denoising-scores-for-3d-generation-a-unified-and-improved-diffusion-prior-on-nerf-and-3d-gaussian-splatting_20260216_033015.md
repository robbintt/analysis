---
ver: rpa2
title: 'Learn to Optimize Denoising Scores for 3D Generation: A Unified and Improved
  Diffusion Prior on NeRF and 3D Gaussian Splatting'
arxiv_id: '2312.04820'
source_url: https://arxiv.org/abs/2312.04820
tags:
- diffusion
- loss
- generation
- methods
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses limitations in diffusion priors for 3D generation,
  particularly the divergence between training and inference stages of diffusion models.
  The authors propose a unified framework called LODS (Learn to Optimize Denoising
  Scores) that iteratively optimizes both the 3D model and diffusion prior to align
  the 3D model more closely with the original diffusion model distribution.
---

# Learn to Optimize Denoising Scores for 3D Generation: A Unified and Improved Diffusion Prior on NeRF and 3D Gaussian Splatting

## Quick Facts
- **arXiv ID**: 2312.04820
- **Source URL**: https://arxiv.org/abs/2312.04820
- **Reference count**: 40
- **Key outcome**: LODS (Learn to Optimize Denoising Scores) achieves state-of-the-art performance on T3Bench dataset by iteratively optimizing both 3D models and diffusion priors, significantly outperforming baseline methods while requiring only one additional backward propagation.

## Executive Summary
This paper addresses a critical limitation in diffusion priors for 3D generation: the divergence between training and inference stages of diffusion models. The authors identify that classifier-free guidance (CFG) applied during inference creates a "guidance gap" since diffusion models are trained without CFG. They propose LODS (Learn to Optimize Denoising Scores), a unified framework that iteratively optimizes both the 3D model and diffusion prior to align them more closely with the original diffusion model distribution. LODS incorporates learnable parameters—specifically learnable null embeddings and low-rank model parameters—to bridge this gap. The method achieves state-of-the-art performance on the T3Bench dataset, significantly outperforming existing techniques including VSD loss, while maintaining computational efficiency with only one additional backward propagation compared to baseline methods.

## Method Summary
LODS introduces a unified framework that addresses the guidance gap between diffusion model training and inference. The method employs iterative optimization that alternates between updating the 3D model parameters and learnable diffusion prior parameters. Two variants are proposed: embedding-based optimization using learnable null embeddings, and parameter-based optimization using LoRA (Low-Rank Adaptation) parameters. The framework starts with a normalized SDS loss formulation that incorporates these learnable parameters, then iteratively refines them by minimizing the difference between the current SDS loss and the reference SDS formula. The optimization process begins with high CFG weights (initially 1000) and gradually aligns the learned prior with the reference diffusion model distribution. This approach maintains computational efficiency while achieving significant quality improvements across both NeRF and 3D Gaussian Splatting backbones.

## Key Results
- LODS achieves state-of-the-art performance on T3Bench dataset, significantly outperforming baseline methods including VSD loss and ProlificDreamer
- The method demonstrates consistent improvements across both NeRF and 3D Gaussian Splatting backbones for text-to-3D generation
- LODS maintains computational efficiency by requiring only one additional backward propagation compared to baseline methods
- The framework shows better performance than existing methods in image-to-3D generation tasks, with improvements in CLIP-Similarity, PSNR, and LPIPS metrics

## Why This Works (Mechanism)

### Mechanism 1
The SDS loss performs poorly because it uses classifier-free guidance (CFG) during inference, while diffusion models are trained without CFG, creating a "guidance gap." During training, diffusion models learn the score function $\nabla_z \log p_\phi(z; y)$ without CFG. The SDS loss, however, applies a CFG variant during optimization of the 3D model, steering the target distribution toward a CFG-modified version rather than the original score function. This leads to overly saturated and less diverse outputs. The core assumption is that the CFG applied in inference is fundamentally different from the score function learned during training, and this mismatch is the primary cause of suboptimal 3D generation quality.

### Mechanism 2
LODS iteratively optimizes both the 3D model and diffusion prior to bridge the gap between training and inference stages. The method introduces learnable parameters (null embeddings or LoRA parameters) and uses an iterative optimization loop. First, the 3D model parameters are optimized using the current SDS loss with high initial CFG. Then, the learnable parameters are optimized to align the SDS loss with the reference SDS formula (without CFG), effectively bridging the training-inference gap. The core assumption is that the iterative optimization of both the 3D model and the learnable parameters can successfully reduce the divergence between the CFG-based SDS loss and the original score function.

### Mechanism 3
The normalized SDS loss with learnable unconditional embedding (or LoRA parameters) can effectively learn to reduce the guidance gap by optimizing the embedding/parameters to minimize the difference between the current SDS and the reference SDS. The normalized SDS loss is defined with a learnable unconditional embedding α (or LoRA parameters ψ). The embedding/parameters are then optimized by minimizing the L2 difference between the current SDS loss and the reference SDS loss, effectively learning to align the two. This is done independently of the CFG weight. The core assumption is that the Fisher divergence (L2 difference) between the current SDS loss and the reference SDS loss is a suitable objective for learning the learnable parameters.

## Foundational Learning

- **Concept**: Classifier-free guidance (CFG)
  - **Why needed here**: CFG is central to understanding why the SDS loss performs poorly and how LODS addresses this issue. It's the key difference between training and inference in diffusion models.
  - **Quick check question**: What is the role of the guidance weight w in CFG, and how does it affect the conditional and unconditional outputs of the diffusion model?

- **Concept**: Score functions in diffusion models
  - **Why needed here**: The paper relies on the score function interpretation of diffusion models to explain the training process and the guidance gap. Understanding score functions is crucial for grasping the core mechanism of LODS.
  - **Quick check question**: How is the score function $\nabla_z \log p_\phi(z; y)$ learned during training, and why is it different from the CFG-based inference?

- **Concept**: Low-rank adaptation (LoRA)
  - **Why needed here**: LoRA is one of the learnable parameter types used in LODS. Understanding how LoRA works is important for implementing and modifying the method.
  - **Quick check question**: How does LoRA modify the weights of a pre-trained model, and why is it a suitable choice for learning the guidance gap in LODS?

## Architecture Onboarding

- **Component map**: Pre-trained diffusion model (U-Net) -> 3D model (NeRF or 3D Gaussian Splatting) -> Learnable parameters (null embedding α or LoRA parameters ψ) -> Iterative optimization loop

- **Critical path**:
  1. Initialize 3D model parameters θ and learnable parameters (α or ψ)
  2. While not converged:
     a. Optimize θ using current SDS loss with learnable parameters frozen
     b. Optimize learnable parameters to minimize difference between current SDS and reference SDS
  3. Return optimized 3D model parameters θ

- **Design tradeoffs**:
  - Embedding-based LODS: Simpler to implement (20 lines of code), easier to apply to new models, but may have slightly less performance than LoRA-based LODS
  - LoRA-based LODS: Can achieve exceptional results in 2D space, but may overfit in 3D space and requires more understanding of model internals
  - Initial CFG weight: High CFG needed for detailed 3D generation, but too high can cause "floating" objects; must be tuned

- **Failure signatures**:
  - No improvement over baseline SDS loss: Likely due to poor choice of initial CFG weight or learnable parameter learning rate
  - "Floating" objects: Initial CFG weight too high, causing the model to generate objects that don't adhere to the scene geometry
  - Overfitting: LoRA-based LODS may overfit to specific prompts, leading to poor generalization

- **First 3 experiments**:
  1. Implement embedding-based LODS on a simple text-to-3D generation task (e.g., T3Bench single object category) and compare against baseline SDS loss using ImageReward and CLIP-Similarity metrics
  2. Vary the initial CFG weight (e.g., 30, 100, 1000, infinity) and observe the effect on generation quality and the "floating" phenomenon
  3. Implement LoRA-based LODS and compare its performance and training stability against embedding-based LODS on the same task

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the choice between learnable null embedding and LoRA parameters affect the quality and diversity of 3D generation outputs? The paper discusses both methods but does not provide a detailed comparative analysis of their impacts on output quality and diversity.

- **Open Question 2**: Can the proposed framework be extended to improve the geometry of generated 3D models, not just the texture? The paper acknowledges that current methods primarily focus on improving texture but fall short in enhancing the geometry of the generated 3D models.

- **Open Question 3**: What is the impact of varying the classifier-free guidance (CFG) weight on the performance of the diffusion priors in different 3D generation tasks? While the paper mentions the role of CFG weight, it does not provide a detailed analysis of how varying this parameter affects performance across different tasks or datasets.

- **Open Question 4**: How does the computational efficiency of the proposed methods compare when applied to real-time 3D generation applications? The paper mentions computational efficiency but does not provide specific benchmarks or comparisons for real-time applications.

## Limitations

- The theoretical analysis relies heavily on empirical observations rather than rigorous mathematical proofs, making it difficult to formally verify the mechanism behind LODS's effectiveness.
- The generalizability of LODS to other 3D generation tasks beyond text-to-3D and image-to-3D remains unexplored, limiting understanding of its broader applicability.
- The method primarily focuses on improving texture quality while falling short in enhancing the geometry of generated 3D models, indicating a need for further extensions.

## Confidence

- **High confidence**: The empirical improvements on T3Bench datasets and the computational efficiency gains (only one additional backward pass) are well-supported by quantitative metrics.
- **Medium confidence**: The mechanism explaining how LODS bridges the training-inference gap is logically sound but relies on several assumptions about the relationship between Fisher divergence and guidance gap reduction.
- **Low confidence**: The generalizability of LODS to other 3D generation tasks beyond text-to-3D and image-to-3D remains unexplored.

## Next Checks

1. Conduct an ablation study systematically varying CFG weights during both training and inference phases to isolate the specific contribution of the guidance gap to 3D generation quality.

2. Test LODS on diverse 3D generation tasks including video-to-3D and sketch-to-3D to evaluate its generalizability across different input modalities.

3. Implement a formal mathematical proof demonstrating that minimizing the Fisher divergence between current and reference SDS losses directly reduces the guidance gap, rather than relying solely on empirical observations.