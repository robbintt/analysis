---
ver: rpa2
title: Contrastive Decoding Improves Reasoning in Large Language Models
arxiv_id: '2309.09117'
source_url: https://arxiv.org/abs/2309.09117
tags:
- decoding
- contrastive
- reasoning
- expert
- amateur
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Contrastive Decoding is a simple, computationally light, and training-free
  text generation method that improves reasoning in large language models by searching
  for strings that maximize a weighted difference in likelihood between strong and
  weak models. The authors show that Contrastive Decoding leads LLaMA-65B to outperform
  LLaMA 2, GPT-3.5 and PaLM 2-L on the HellaSwag commonsense reasoning benchmark,
  and to outperform LLaMA 2, GPT-3.5 and PaLM-540B on the GSM8K math word reasoning
  benchmark.
---

# Contrastive Decoding Improves Reasoning in Large Language Models

## Quick Facts
- arXiv ID: 2309.09117
- Source URL: https://arxiv.org/abs/2309.09117
- Reference count: 17
- Primary result: Contrastive Decoding improves reasoning performance in large language models by maximizing likelihood differences between strong and weak models

## Executive Summary
Contrastive Decoding is a training-free method that improves reasoning in large language models by searching for strings that maximize a weighted difference in likelihood between strong (expert) and weak (amateur) models. The approach shows consistent gains across multiple reasoning benchmarks, with LLaMA-65B outperforming larger models like GPT-3.5 and PaLM-2 on tasks like HellaSwag and GSM8K. The method is computationally efficient, requiring only an additional forward pass through a smaller amateur model, making it more FLOP-efficient than alternatives like self-consistency.

## Method Summary
Contrastive Decoding works by manipulating the logits of a strong expert model based on the difference with a weaker amateur model. The method uses two hyperparameters: α (masking ratio) and β (contrastive strength). During generation, tokens favored by the amateur model but not the expert are penalized, effectively filtering out simpler reasoning patterns. The approach requires no training, only decoding-time computation, and can be combined with chain-of-thought prompting and temperature sampling for self-consistency.

## Key Results
- LLaMA-65B with Contrastive Decoding outperforms LLaMA 2, GPT-3.5, and PaLM 2-L on HellaSwag commonsense reasoning
- LLaMA-65B with Contrastive Decoding outperforms LLaMA 2, GPT-3.5, and PaLM-540B on GSM8K math word reasoning
- Contrastive Decoding is more FLOP-efficient than self-consistency while achieving comparable or better performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Contrastive Decoding improves reasoning by reducing abstract reasoning errors and avoiding simpler modes like copying sections of the input during chain-of-thought.
- **Mechanism:** The method searches for strings that maximize a weighted difference in likelihood between a strong expert model and a weaker amateur model. This effectively filters out tokens that the amateur model assigns high probability to but the expert model does not, thereby avoiding simpler or less abstract reasoning patterns.
- **Core assumption:** The expert model has learned more abstract reasoning skills than the amateur model, and these skills can be accentuated by penalizing tokens the amateur model favors.
- **Evidence anchors:**
  - [abstract] "Analysis suggests that Contrastive Decoding improves over existing methods by preventing some abstract reasoning errors, as well as by avoiding simpler modes such as copying sections of the input during chain-of-thought."
  - [section] "We find that contrastive decoding tends to help across the board on arithmetic reasoning tasks with chain-of-thought prompting... Our small-scale analysis finds that CD makes more arithmetic errors, but that this is offset by better semantic reasoning and fewer missing steps."
- **Break condition:** If the amateur model is too close in capability to the expert model, the contrastive signal becomes too weak to filter out simpler reasoning modes.

### Mechanism 2
- **Claim:** Contrastive Decoding reduces surface-level copying from the prompt, leading to improved reasoning.
- **Mechanism:** By penalizing tokens that the amateur model assigns high probability to, the method indirectly reduces the likelihood of the model copying directly from the prompt. This encourages the model to generate new information rather than reiterate what it has already seen.
- **Core assumption:** Surface-level copying from the prompt does not provide new information to the problem and can be a sign of weaker reasoning.
- **Evidence anchors:**
  - [section] "We find that responses are roughly the same length and follow the few-shot template roughly the same proportion of the time... we measure the precision and recall of the tokens in the prompt by the sampled generations. We find that CD systematically reduces token-level copying from the prompt."
- **Break condition:** If the prompt contains critical information that is necessary for solving the problem, reducing copying might lead to missing important details.

### Mechanism 3
- **Claim:** Contrastive Decoding is more FLOP-efficient than other reasoning-enhancing methods like self-consistency.
- **Mechanism:** While methods like self-consistency require multiple full generation loops, Contrastive Decoding only requires an additional forward pass through a smaller amateur model. This results in a smaller increase in computational cost relative to the performance gain.
- **Core assumption:** The performance gain from Contrastive Decoding outweighs the additional computational cost, making it a more efficient method for improving reasoning.
- **Evidence anchors:**
  - [section] "We estimate that with a 1.5B amateur and 65.2B expert, contrastive decoding increases the total number of FLOPs by 3.25%... CD is significantly more efficient than self-consistency."
- **Break condition:** If the amateur model is very large, the additional computational cost may become prohibitive, reducing the efficiency advantage.

## Foundational Learning

- **Concept:** Chain-of-thought prompting
  - **Why needed here:** Chain-of-thought prompting encourages the model to generate intermediate reasoning steps, which can then be improved by Contrastive Decoding.
  - **Quick check question:** What is the primary purpose of chain-of-thought prompting in the context of Contrastive Decoding?

- **Concept:** Logit space manipulation
  - **Why needed here:** Understanding how Contrastive Decoding manipulates logits in the expert and amateur models is crucial for grasping how the method filters out simpler reasoning patterns.
  - **Quick check question:** How does Contrastive Decoding modify the logits of the expert model to improve reasoning?

- **Concept:** Temperature sampling
  - **Why needed here:** Temperature sampling is used in conjunction with Contrastive Decoding to generate multiple candidate reasoning chains for self-consistency.
  - **Quick check question:** What role does temperature sampling play in the Contrastive Decoding process?

## Architecture Onboarding

- **Component map:** Expert model (65B) -> Amateur model (1.5B) -> Contrastive Decoding algorithm -> Temperature sampling -> Self-consistency
- **Critical path:** 
  1. Generate logits from expert and amateur models.
  2. Apply Contrastive Decoding to modify expert logits based on weighted difference with amateur logits.
  3. Use temperature sampling to generate multiple candidate reasoning chains.
  4. Perform self-consistency to select the most likely correct answer.
- **Design tradeoffs:**
  - Choosing the right size for the amateur model: too large and it may not provide a strong contrastive signal; too small and it may not be representative of simpler reasoning patterns.
  - Setting the hyperparameters α and β: too high and the method may over-penalize certain tokens; too low and it may not effectively filter out simpler reasoning modes.
- **Failure signatures:**
  - If the amateur model is too close in capability to the expert model, the method may not improve reasoning.
  - If the hyperparameters are not set correctly, the method may over-penalize certain tokens or not effectively filter out simpler reasoning modes.
- **First 3 experiments:**
  1. Test Contrastive Decoding on a simple reasoning task (e.g., GSM8K) with different sizes of amateur models to find the optimal size.
  2. Sweep through different values of α and β to find the best hyperparameters for the task.
  3. Compare the performance of Contrastive Decoding with and without chain-of-thought prompting to understand its impact on reasoning.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does contrastive decoding performance scale linearly or exhibit diminishing returns with increasing model size?
- Basis in paper: [explicit] The authors note that contrastive decoding "generally improves performance across model scales" and achieves state-of-the-art results with LLaMA-65B, but do not explicitly analyze the scaling relationship or test extremely large models.
- Why unresolved: The paper focuses on demonstrating effectiveness rather than establishing scaling laws. They test LLaMA models from 7B to 65B parameters but do not examine whether the performance gains continue to increase proportionally with scale or plateau.
- What evidence would resolve it: Systematic testing of contrastive decoding across a wider range of model sizes (e.g., 175B, 540B, 1T parameters) on standardized benchmarks, with analysis of whether performance improvements follow a predictable scaling curve.

### Open Question 2
- Question: Can contrastive decoding be effectively distilled into a single model without requiring separate amateur and expert models at inference time?
- Basis in paper: [inferred] The authors note that contrastive decoding introduces relatively little overhead (3.25% FLOPs) compared to methods like self-consistency, but this still requires maintaining two separate models. They suggest this as an area for future exploration.
- Why unresolved: While the paper demonstrates contrastive decoding's effectiveness, it treats it as a decoding-time method rather than exploring whether its benefits can be baked into a single model through training techniques.
- What evidence would resolve it: Successful training of a single model that matches or approaches the performance of contrastive decoding when applied to a separate amateur model, validated across multiple reasoning tasks and model families.

### Open Question 3
- Question: What is the theoretical mechanism by which contrastive decoding improves reasoning performance - is it primarily reducing copying, improving abstract reasoning, or some combination?
- Basis in paper: [explicit] The authors analyze that contrastive decoding "reduces token-level copying from the prompt" and improves "semantic reasoning" while making "more arithmetic errors," but do not provide a unified theoretical explanation for why this approach works.
- Why unresolved: The empirical analysis shows mixed results across different types of reasoning tasks and error categories, suggesting multiple mechanisms may be at play without a clear dominant factor.
- What evidence would resolve it: Controlled experiments isolating specific mechanisms (e.g., comparing contrastive decoding with and without copying penalties, testing on reasoning tasks that specifically require abstract versus concrete reasoning) combined with theoretical analysis of how the contrastive objective affects the model's probability distributions.

## Limitations

- Contrastive Decoding can harm factual recall tasks like TriviaQA and OpenBookQA, suggesting domain-specific limitations
- Performance is sensitive to hyperparameter choices (α and β) that are not thoroughly justified or analyzed
- The method requires maintaining two separate models (expert and amateur), adding implementation complexity

## Confidence

**High Confidence**: The empirical demonstration that Contrastive Decoding outperforms greedy decoding on reasoning tasks (GSM8K, HellaSwag) is well-established with statistically significant results across multiple model sizes.

**Medium Confidence**: The mechanistic explanation that CD works by reducing abstract reasoning errors and avoiding copying is supported by analysis but not definitively proven. The paper provides correlational evidence rather than causal proof of these mechanisms.

**Low Confidence**: The claim that Contrastive Decoding is a "powerful general purpose method for generating text" is overstated. The method shows clear limitations on factual recall tasks and may not generalize well beyond reasoning benchmarks.

## Next Checks

1. **Hyperparameter sensitivity analysis**: Systematically vary α (0.05 to 0.2) and β (0.1 to 1.0) on GSM8K to determine how sensitive performance is to these choices and identify optimal ranges for different task types.

2. **Cross-domain generalization test**: Evaluate Contrastive Decoding on a suite of non-reasoning tasks including factual recall (TriviaQA), commonsense QA (CommonsenseQA), and creative generation tasks to better characterize the method's limitations and applicability boundaries.

3. **Amateur model selection protocol**: Develop and test a methodology for selecting the optimal amateur model size based on the target task's difficulty and the expert model's characteristics, rather than using fixed amateur sizes.