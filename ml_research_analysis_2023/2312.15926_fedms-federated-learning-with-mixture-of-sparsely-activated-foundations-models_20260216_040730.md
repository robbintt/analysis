---
ver: rpa2
title: 'FedMS: Federated Learning with Mixture of Sparsely Activated Foundations Models'
arxiv_id: '2312.15926'
source_url: https://arxiv.org/abs/2312.15926
tags:
- accuracy
- learning
- fedms
- training
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FedMS, a novel federated learning framework
  that integrates foundation models through a two-stage approach. The method employs
  low-rank adaptation matrices for efficient parameter tuning and introduces a Mixture
  of Foundation Models (MoFM) system with a gate adapter to handle statistical heterogeneity
  in federated learning.
---

# FedMS: Federated Learning with Mixture of Sparsely Activated Foundations Models

## Quick Facts
- arXiv ID: 2312.15926
- Source URL: https://arxiv.org/abs/2312.15926
- Authors: 
- Reference count: 30
- Key outcome: Achieves up to 55.25% accuracy improvement over baselines while activating only 0.1% of parameters in federated learning with foundation models.

## Executive Summary
This paper introduces FedMS, a novel federated learning framework that integrates foundation models through a two-stage approach. The method employs low-rank adaptation matrices for efficient parameter tuning and introduces a Mixture of Foundation Models (MoFM) system with a gate adapter to handle statistical heterogeneity in federated learning. A Sparsely Activated LoRA (SAL) algorithm is designed to progressively activate model parameters based on performance feedback. Experiments on three datasets (Food101, UCF101, and EuroSAT) demonstrate that FedMS outperforms state-of-the-art baselines by up to 55.25% in accuracy while maintaining communication efficiency.

## Method Summary
FedMS uses a two-stage training approach: Stage 1 trains a shared global expert using LoRA on all clients, capturing general patterns while freezing foundation model weights. Stage 2 introduces a Mixture of Foundation Models system where clients train local experts with sparsely activated LoRA parameters while aggregating only gate adapter parameters. The SAL algorithm progressively activates LoRA layers based on accuracy improvements monitored through a Capability Queue, enabling efficient training on resource-constrained devices. The gate adapter blends global and local expert contributions using learned weights.

## Key Results
- Achieves up to 55.25% accuracy improvement over state-of-the-art baselines on Food101, UCF101, and EuroSAT datasets
- Activates only 0.1% of parameters compared to traditional fine-tuning methods
- Demonstrates communication efficiency by aggregating only gate adapter parameters each round

## Why This Works (Mechanism)

### Mechanism 1
The two-stage training approach addresses both statistical heterogeneity and personalization. Stage 1 trains a shared global expert using LoRA on all clients, capturing general patterns. Stage 2 freezes the global expert, trains client-specific local experts using sparsely activated LoRA, and introduces a gate adapter to blend the two experts based on local data characteristics. This works under the assumption that local data distributions are non-IID but still contain overlapping features that the global expert can learn.

### Mechanism 2
Sparsely Activated LoRA (SAL) enables efficient training on resource-constrained devices by progressively activating parameters. Low-rank adaptation matrices are inserted into every transformer block but only a subset is activated based on performance feedback via a Capability Queue that monitors accuracy improvements. This assumes early layers capture more general features, so activating higher layers first in stage two is more efficient.

### Mechanism 3
The gate adapter with aggregated parameters enables global coordination while maintaining personalization. Each client has a lightweight gate adapter (MLP + batch norm + softmax) that learns to weight the contributions of global and local experts. Only the gate adapter parameters are aggregated each round, reducing communication overhead. This works under the assumption that the relationship between global and local experts changes slowly enough that aggregating only the gate adapter is sufficient for coordination.

## Foundational Learning

- **Low-Rank Adaptation (LoRA)**: Enables fine-tuning of large foundation models by inserting small trainable matrices instead of updating all parameters, drastically reducing computation and memory. Quick check: If a transformer block has weight matrix W0 of shape (E,F) and LoRA inserts WA (E,H) and WB (H,F) with H << min(E,F), how many new parameters are added versus full fine-tuning?

- **Mixture of Experts (MoE)**: Allows combining a global model (general knowledge) with a local model (personalized knowledge) using a gating mechanism to improve performance on heterogeneous data. Quick check: In the gate function λi <Vg,Tg> + (1-λi) <Vi,Ti>, what does λi represent and how is it learned?

- **Federated Learning with Non-IID Data**: Standard FL assumes data is independently and identically distributed across clients, but real-world data is often skewed, requiring personalization techniques. Quick check: How does statistical heterogeneity in FL typically manifest in model performance, and what are common mitigation strategies?

## Architecture Onboarding

- **Component map**: Server -> Global model aggregation -> Client devices with CLIP (ViT-B/16 visual encoder + text encoder) -> LoRA adapters in each transformer block -> Gate adapter (MLP + batch norm + softmax) -> SAL Controller with Capability Queue

- **Critical path**: 1) Stage 1: All clients train global expert with all LoRA parameters active, upload LoRA params only 2) Stage 2: Clients freeze global expert, initialize local expert from global, train with SAL, upload gate adapter params only 3) Server aggregates gate adapter params, broadcasts updated gate to all clients

- **Design tradeoffs**: Full LoRA activation vs. SAL saves computation but may slow convergence if threshold is poorly set; Gate adapter vs. full gate model saves communication but may limit blending flexibility; Rank of LoRA matrices: higher rank = more capacity but more parameters

- **Failure signatures**: Stage 1: Low accuracy improvement across rounds → LoRA rank too low or learning rate too small; Stage 2: Accuracy plateaus early → SAL threshold too high, not enough parameters activated; Both stages: Oscillating accuracy → Learning rate too high, causing instability in large parameter space

- **First 3 experiments**: 1) Run Stage 1 with full LoRA activation on all clients, verify global model accuracy improves over rounds 2) Test SAL activation logic by simulating accuracy improvements and confirming correct layer activation order 3) Validate gate adapter aggregation by checking that blended predictions improve over using either expert alone

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the performance of FedMS scale with increasing numbers of clients, particularly when client heterogeneity becomes more extreme? The paper shows performance comparisons with varying numbers of clients (5, 10, 15) and different non-IID levels (α=0.1, 1, 10), but real-world systems may involve hundreds or thousands of clients where communication overhead and synchronization challenges could affect performance differently.

- **Open Question 2**: What is the theoretical convergence guarantee of the SAL algorithm, and under what conditions does it guarantee optimal parameter activation? While empirical results show SAL works well, there's no proof that the adaptive activation strategy converges to an optimal solution or that the threshold-based activation policy is theoretically sound.

- **Open Question 3**: How does FedMS perform under adaptive or stealthy backdoor attacks where malicious clients gradually shift the model distribution rather than applying immediate weight reversals? The paper tests FedMS under a simple backdoor attack where 20% of clients apply reverse weights, but real-world attackers might employ more sophisticated strategies like data poisoning with imperceptible perturbations.

## Limitations
- Lacks detailed implementation specifications for critical components like gate adapter architecture and SAL threshold mechanism
- Limited ablation studies on how different SAL thresholds affect convergence and accuracy
- No analysis of failure modes when client data is extremely non-IID or when clients have very different computational capabilities

## Confidence
**High Confidence Claims:**
- The two-stage framework architecture is well-defined and theoretically sound for addressing statistical heterogeneity in federated learning
- SAL algorithm provides clear communication and computation benefits by progressively activating parameters
- The gate adapter mechanism effectively reduces communication overhead while maintaining personalization

**Medium Confidence Claims:**
- The specific accuracy improvements (up to 55.25%) depend on implementation details not fully specified in the paper
- The optimal SAL threshold and Capability Queue configuration may vary across different datasets and client distributions
- The rank-4 LoRA matrices are stated as optimal, but this may be dataset-dependent

**Major Limitations:**
- The paper lacks detailed implementation specifications for critical components like the gate adapter architecture and SAL threshold mechanism
- Limited ablation studies on how different SAL thresholds affect convergence and accuracy
- No analysis of failure modes when client data is extremely non-IID or when clients have very different computational capabilities

## Next Checks
1. Implement the gate adapter with varying MLP architectures (2-layer, 3-layer) and batch norm configurations to verify the stated 0.1% parameter activation claim
2. Test SAL algorithm with multiple threshold settings (0.5%, 1%, 2%) to determine sensitivity and optimal configuration for different dataset sizes
3. Run experiments with extreme non-IID data distributions (clients with completely disjoint classes) to identify break conditions for the MoFM system