---
ver: rpa2
title: Towards Multi-User Activity Recognition through Facilitated Training Data and
  Deep Learning for Human-Robot Collaboration Applications
arxiv_id: '2302.05763'
source_url: https://arxiv.org/abs/2302.05763
tags:
- data
- were
- pair
- activity
- robot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a method for multi-user activity recognition
  in human-robot collaboration (HRC) scenarios, addressing the challenge of collecting
  data for training machine learning models in group settings. The core idea is to
  collect data from individual subjects and merge them in post-processing to create
  training data for pair interactions, reducing the need for recruiting pairs of people
  simultaneously.
---

# Towards Multi-User Activity Recognition through Facilitated Training Data and Deep Learning for Human-Robot Collaboration Applications

## Quick Facts
- arXiv ID: 2302.05763
- Source URL: https://arxiv.org/abs/2302.05763
- Reference count: 40
- One-line primary result: Individual subject data can be merged in post-processing to effectively train multi-user activity recognition models for HRC, achieving comparable performance to pair-collected data.

## Executive Summary
This study addresses the challenge of collecting training data for multi-user activity recognition in human-robot collaboration (HRC) scenarios. The authors propose a method where data from individual subjects performing actions is collected separately and then merged in post-processing to simulate group interactions. Using 3D skeleton pose data from three actions (working, preparing, requesting), they demonstrate that deep learning models trained on this grouped data achieve similar performance to models trained on naturally-collected pair data. This approach significantly reduces the complexity of data collection in HRC research by eliminating the need to recruit pairs of people simultaneously.

## Method Summary
The study collects 3D skeleton pose data from individual subjects performing three actions using a Microsoft Azure Kinect camera, then merges this data in post-processing to simulate pair interactions. Two deep learning models are trained and tested: a Long Short-Term Memory (LSTM) network and a Variational Autoencoder (VAE) composed of Spatio-Temporal Graph Convolutional Networks (STGCN). The data undergoes preprocessing including skeleton pose extraction, normalization, windowing, and min-max normalization. Models are trained using leave-one-subject-out cross-validation and evaluated on their ability to classify nine possible pair activity classes (three actions × three actions). The key innovation is demonstrating that individually-collected data, when properly merged, can effectively train models for multi-user activity recognition.

## Key Results
- Both LSTM and VAE models achieved similar performance when trained with grouped data and tested with pair data compared to when trained and tested with pair data only
- The proposed method demonstrates comparable accuracy and F-score metrics to traditional data collection approaches
- The feasibility of using post-processed individual data for pair HRC settings is validated, reducing data collection complexity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Training with individually-collected data and merging in post-processing yields comparable performance to training with pair-collected data.
- Mechanism: The merged individual data captures the joint activity distribution when two subjects interact, as their individual actions remain independent and their combination simulates the pair interaction without loss of critical information.
- Core assumption: Individual actions in a collaborative task are statistically independent when performed separately, and the combination of two independent actions approximates the joint distribution of the pair setting.
- Evidence anchors: [abstract] "the results showed that it is possible to make use of data collected in this way for pair HRC settings and get similar performances compared to using data regarding groups of users recorded under the same settings" [section] "there are no significant differences in performance when models were trained with grouped data and tested with pair data, compared to cases in which models were trained and tested with pair data" [corpus] Weak: No direct corpus evidence supporting the independence assumption of individual actions in collaborative settings.
- Break condition: If individual actions in a collaborative task are not statistically independent, or if the combination of two independent actions does not approximate the joint distribution of the pair setting.

### Mechanism 2
- Claim: The VAE composed of STGCN layers can effectively learn the joint activity of pairs from individually-collected data.
- Mechanism: The STGCN layers capture spatial and temporal patterns in the skeleton pose data, while the VAE learns a variational posterior distribution of latent variables representing the joint activity, allowing for effective classification of pair activities from individually-collected data.
- Core assumption: The spatial and temporal patterns in the skeleton pose data of individual subjects are sufficient to represent the joint activity when combined.
- Evidence anchors: [section] "The second model was a VAE [25]. This neural network exploits a learning method related to semi-supervised learning. It makes use of unlabeled data, but it uses them as labels themselves." [section] "The main objective of a VAE is to learn a variational posterior distribution q(z/x) of latent variables z, given the input data x." [corpus] Weak: No direct corpus evidence supporting the effectiveness of VAE with STGCN layers for this specific task.
- Break condition: If the spatial and temporal patterns in the skeleton pose data of individual subjects are not sufficient to represent the joint activity when combined.

### Mechanism 3
- Claim: The LSTM network can effectively learn the joint activity of pairs from individually-collected data.
- Mechanism: The LSTM network captures the temporal dependencies in the skeleton pose data of individual subjects, allowing for effective classification of pair activities from individually-collected data.
- Core assumption: The temporal dependencies in the skeleton pose data of individual subjects are sufficient to represent the joint activity when combined.
- Evidence anchors: [section] "The first one is composed of stacked LSTM networks [22] (see Figure 6), which was appended to a softmax layer of 9 neurons (related to the 9 classes to recognise, that were converted as output vectors through a one-hot encoding)." [section] "This network was trained through backpropagation through time." [corpus] Weak: No direct corpus evidence supporting the effectiveness of LSTM for this specific task.
- Break condition: If the temporal dependencies in the skeleton pose data of individual subjects are not sufficient to represent the joint activity when combined.

## Foundational Learning

- Concept: Human-Robot Collaboration (HRC)
  - Why needed here: The study focuses on activity recognition in HRC scenarios, where a robot collaborates with two human users.
  - Quick check question: What are the key characteristics of a human-robot collaboration scenario?

- Concept: Deep Learning (DL) Models
  - Why needed here: The study uses DL models, specifically LSTM and VAE, to recognize multi-user activities in HRC scenarios.
  - Quick check question: What are the key components and training methods of LSTM and VAE models?

- Concept: Activity Recognition
  - Why needed here: The study aims to recognize multi-user activities in HRC scenarios using DL models.
  - Quick check question: What are the key steps in activity recognition using DL models?

## Architecture Onboarding

- Component map: Data collection -> Skeleton pose extraction -> Normalization -> Windowing -> Model training -> Evaluation
- Critical path: Data collection → Data preprocessing → Model training → Model evaluation
- Design tradeoffs: Using individually-collected data vs. pair-collected data for training; LSTM vs. VAE for activity recognition
- Failure signatures: Low accuracy and F-score values; High standard deviation in accuracy and F-score values; Confusion between certain activity classes (e.g., Requesting and Working)
- First 3 experiments:
  1. Train and test the LSTM model with pair data only to establish a performance baseline.
  2. Train and test the VAE model with individually-collected data and evaluate its performance on pair data.
  3. Train and test the LSTM model with individually-collected data and evaluate its performance on pair data.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the performance of the proposed multi-user activity recognition system change when applied to real-world HRC scenarios with more complex and varied activities beyond the three basic states (Working, Preparing, Requesting)?
- Basis in paper: [explicit] The paper mentions that the current study considers only three main activities for the robot to detect and suggests that future works could use more diverse gestures and further define the characteristics of the interaction.
- Why unresolved: The study's scope is limited to a specific set of activities in a controlled environment. Real-world scenarios may involve a wider range of activities, more complex interactions, and environmental variables not accounted for in the current study.
- What evidence would resolve it: Conducting experiments in real-world HRC settings with a broader range of activities and environmental conditions, then comparing the system's performance to the controlled study results.

### Open Question 2
- Question: What is the impact of different data collection methods on the performance of multi-user activity recognition models, particularly when comparing data from individual subjects merged in post-processing versus data collected from pairs simultaneously?
- Basis in paper: [explicit] The paper's core contribution is demonstrating that data collected from individual subjects and merged in post-processing can achieve similar performance to data collected from pairs simultaneously, but it does not explore other data collection methods.
- Why unresolved: While the paper shows that post-processing individual data is effective, it does not investigate other potential data collection methods or their impact on model performance.
- What evidence would resolve it: Systematic comparison of model performance using data collected through various methods (e.g., simultaneous pair collection, individual subject collection with different merging strategies) under the same experimental conditions.

### Open Question 3
- Question: How does the choice of deep learning model architecture affect the performance of multi-user activity recognition in non-dyadic HRC scenarios, and are there architectures better suited for this task than the LSTM and VAE models used in this study?
- Basis in paper: [explicit] The paper uses two different DL models (LSTM and VAE) to test the hypothesis on grouped data, but it does not explore a wide range of architectures or provide a comprehensive comparison.
- Why unresolved: The study focuses on two specific models without exploring the broader landscape of potential architectures that might be more effective for multi-user activity recognition.
- What evidence would resolve it: Extensive testing of various DL architectures (e.g., different types of recurrent networks, attention mechanisms, transformer models) on the same dataset and comparison of their performance metrics.

## Limitations
- The study uses a very small dataset (3 subjects, 9 videos per subject), limiting generalization to diverse user populations
- The independence assumption between individual actions lacks empirical validation from corpus literature
- The architectural details of STGCN layers within the VAE are underspecified, making exact replication challenging
- Only three activity types are evaluated in a controlled lab setting, limiting external validity

## Confidence
- High confidence: The feasibility of using individually-collected data for pair activity recognition (empirical results clearly demonstrate comparable performance)
- Medium confidence: The statistical independence assumption between individual actions (supported by results but lacking theoretical backing)
- Low confidence: Generalization to diverse user populations and complex activity sets (severely limited by sample size and controlled conditions)

## Next Checks
1. Test the merged data approach with a larger, more diverse participant pool (minimum 20 subjects) to assess population-level generalization
2. Conduct ablation studies to empirically validate the independence assumption by comparing merged vs. naturally-collected pair data across varying interaction complexities
3. Evaluate model robustness to sensor noise and environmental variations by introducing controlled perturbations to the skeleton pose data