---
ver: rpa2
title: 'Finding Common Ground: Annotating and Predicting Common Ground in Spoken Conversations'
arxiv_id: '2311.01273'
source_url: https://arxiv.org/abs/2311.01273
tags:
- flan-t5
- window
- event
- belief
- events
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces the first corpus annotated for common ground\
  \ in spoken conversations. It presents a new annotation scheme that captures speakers\u2019\
  \ beliefs and common ground updates throughout dialog, along with baseline experiments\
  \ using FLAN-T5 and BERT models for event extraction, belief prediction, and common\
  \ ground classification."
---

# Finding Common Ground: Annotating and Predicting Common Ground in Spoken Conversations

## Quick Facts
- arXiv ID: 2311.01273
- Source URL: https://arxiv.org/abs/2311.01273
- Reference count: 17
- Authors: Multiple
- Primary result: First corpus annotated for common ground in spoken conversations, with baseline experiments achieving up to 82.83 macro F1 for CG classification.

## Executive Summary
This paper introduces the first corpus annotated for common ground in spoken conversations. It presents a new annotation scheme that captures speakers’ beliefs and common ground updates throughout dialog, along with baseline experiments using FLAN-T5 and BERT models for event extraction, belief prediction, and common ground classification. The best event generation model achieved an EMBERT score of 48.69, while belief classification using FLAN-T5 with speaker-based windowing and data augmentation achieved macro F1 scores up to 43.50. For common ground prediction, FLAN-T5 models with varying context windows reached macro F1 scores up to 82.83. Error analysis revealed that events embedded under matrix predicates and questions posed significant challenges. The corpus and code are publicly available for further research.

## Method Summary
The method involves creating a corpus from CALLHOME American Speech dialogs, annotating 4 dialogs for events, beliefs, and common ground. Events are extracted from main predicates with anaphora resolution and implicit events for speech acts. Beliefs are annotated using a 4-level scale (CT+, CT-, PS, NB) per speaker per event. Common ground updates are derived via heuristic rules from belief pairs or learned via FLAN-T5 classifiers. Models are trained and evaluated on a train-test split of 3 vs. 1 annotated dialog, with data augmentation for belief classes via translation.

## Key Results
- Event generation model achieved EMBERT score of 48.69
- Belief classification (FLAN-T5 + speaker-based windowing + augmentation) reached macro F1 up to 43.50
- CG classification (FLAN-T5 with 8-utterance context) achieved macro F1 up to 82.83
- Heuristic CG rules showed lower accuracy (~62–69 macro F1) than learned models
- Error analysis identified events under matrix predicates and questions as challenging

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Events extracted from dialog capture predicates that update common ground, enabling downstream belief and CG modeling.
- Mechanism: The annotation process resolves pronouns and creates events from main predicates in clauses, adding implicit events for speech acts and negations to preserve inferential content.
- Core assumption: Event-level representation suffices to encode belief updates, because belief changes are triggered by proposition introduction or rejection.
- Evidence anchors:
  - [abstract] "baseline experiments extracting propositions from dialog and tracking their status in the common ground"
  - [section] "The events are formed from the main predicates in each clause forming the utterance. To make the events as informative as possible, we resolve any pronominal anaphors"
  - [corpus] Weak: event extraction validation is limited to EMBERT inter-annotator scores; no explicit semantic adequacy check reported.
- Break condition: If key propositions are omitted (e.g., presuppositions or implicatures), belief and CG predictions will be incomplete or misaligned with actual dialog dynamics.

### Mechanism 2
- Claim: Belief annotation with four discrete levels (CT+, CT-, PS, NB) allows precise modeling of speaker certainty about events.
- Mechanism: Annotators assign belief values to each speaker for every event, enabling downstream models to learn the mapping from linguistic cues to belief states.
- Core assumption: The four-level scale captures sufficient granularity to differentiate common ground updates from individual belief differences.
- Evidence anchors:
  - [abstract] "belief classification using FLAN-T5 with speaker-based windowing and data augmentation achieved macro F1 scores up to 43.50"
  - [section] "We follow the belief types proposed in FactBank... limit them to 4 different levels of belief"
  - [corpus] Weak: no reported confusion matrix per belief type; error analysis shows key-word and question-embedded events as problematic.
- Break condition: If belief distinctions collapse (e.g., CT+ vs PS), CG updates will be mispredicted, especially in nuanced cases like denials or hedges.

### Mechanism 3
- Claim: Heuristic CG updates derived from belief pairs encode the iterative, mutual-knowledge nature of common ground.
- Mechanism: Simple rules map (Bel(A), Bel(B)) pairs to CG categories (JA, IN, RT), with additional logic to detect whether an event is newly added or already shared.
- Evidence anchors:
  - [abstract] "For common ground prediction, FLAN-T5 models with varying context windows reached macro F1 scores up to 82.83"
  - [section] "We differentiate between three distinct updates: JA, IN, RT" and "The two main parts of the annotation procedure are event extraction, and belief and CG annotation"
  - [corpus] Weak: heuristic CG performance is low (macro F1 ~62–69), suggesting rules miss contextual nuance.
- Break condition: If beliefs diverge unexpectedly (e.g., one speaker mishears), heuristic rules cannot recover the correct CG state without richer context.

## Foundational Learning

- Concept: Anaphora resolution in dialog
  - Why needed here: Event extraction requires spelling out referents to make events self-contained for belief tracking.
  - Quick check question: Given "A: I thought I was going to see everyone. B: No, you didn't," what events should be generated before belief annotation?

- Concept: Speech act detection
  - Why needed here: Questions and commands are annotated as explicit events to capture their effect on CG.
  - Quick check question: How should "Do you think it will rain?" be represented as an event for belief tracking?

- Concept: Theory of Mind in NLP
  - Why needed here: CG modeling requires simulating what each speaker believes the other believes, aligning with ToM constructs.
  - Quick check question: If A asserts p and B rejects it, what CG update should be recorded for A's model of B's beliefs?

## Architecture Onboarding

- Component map: Corpus creation -> Event extraction -> Belief annotation -> CG annotation -> Train/test splits -> Event generation -> Belief classification -> CG classification
- Critical path:
  1. Load annotated CALLHOME dialogs
  2. Preprocess events and context
  3. Fine-tune FLAN-T5 for each task
  4. Evaluate with EMBERT (events) or macro F1 (belief/CG)
- Design tradeoffs:
  - Small dataset -> heavy data augmentation (translation) for belief classes
  - Fixed vs. speaker-based windows -> fixed window with 4 preceding utterances performed best for events; speaker-based better for belief/CG
  - Heuristic vs. learned CG -> heuristics simpler but lower accuracy; learned models need gold beliefs for best performance
- Failure signatures:
  - Low EMBERT for event generation -> context window too short or events too sparse
  - Imbalanced belief F1 -> minority classes (CT-, PS, NB) underrepresented
  - Heuristic CG confusion between JA and IN -> memory of prior CG events missing
- First 3 experiments:
  1. Fine-tune FLAN-T5 on event extraction with 4 preceding utterances; evaluate EMBERT on held-out dialog.
  2. Fine-tune FLAN-T5 for belief classification using speaker-based context; apply French/German augmentation; measure macro F1 per class.
  3. Train FLAN-T5 CG classifier with gold beliefs and 8-utterance context; compare to heuristic baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do intonation and other prosodic features influence the establishment and updating of common ground in spoken conversations?
- Basis in paper: [explicit] The paper mentions that intonation in English is related to what the speaker believes the hearers already know and suggests incorporating the audio signal into future CG predictions.
- Why unresolved: The current corpus and experiments are based solely on transcripts, not audio data.
- What evidence would resolve it: Experiments incorporating audio features into CG prediction models and measuring improvements in accuracy.

### Open Question 2
- Question: Can graph neural network approaches improve the modeling of common ground updates compared to current sequence-based models?
- Basis in paper: [explicit] The paper suggests that the data can naturally be represented as a graph structure and proposes leveraging graph neural network approaches inspired by recent work on emotion recognition in conversations.
- Why unresolved: Current experiments use BERT and FLAN-T5 models without graph-based architectures.
- What evidence would resolve it: Comparative experiments between graph neural networks and current models on the same task, showing performance differences.

### Open Question 3
- Question: How can higher-order beliefs (beliefs about other people's beliefs) be effectively modeled in dialog systems beyond what can be inferred from first-order beliefs and common ground?
- Basis in paper: [explicit] The paper discusses the potential for modeling higher-order beliefs that cannot be derived from common ground and mentions plans to annotate and model such beliefs.
- Why unresolved: Current annotation and modeling focus only on first-order beliefs and common ground.
- What evidence would resolve it: Development of annotation schemes for higher-order beliefs and experiments showing improved performance when incorporating these beliefs into prediction models.

## Limitations
- Only 4 out of 120 CALLHOME dialogs are annotated, limiting statistical robustness and generalization.
- Heuristic CG rules are brittle and show lower accuracy (~62–69 macro F1) than learned models.
- EMBERT metric does not guarantee semantic completeness; missing implicit events could still yield high scores.

## Confidence
- **High**: Event extraction and belief annotation processes are well-defined and reproducible.
- **Medium**: FLAN-T5 model architectures and context windowing strategies are clearly specified; reported macro F1 and EMBERT scores are internally consistent.
- **Low**: Generalization of findings to new dialogs, domains, or languages is uncertain due to the small annotated corpus and absence of cross-validation.

## Next Checks
1. Compute confusion matrices for each belief class (CT+, CT-, PS, NB) to identify systematic misclassifications and assess whether minority classes remain underrepresented after augmentation.
2. Vary SBERT thresholds systematically (e.g., 0.2 to 0.95 in 0.05 increments) and report macro F1 for each; compare stability against the learned model’s performance on gold beliefs.
3. Apply the best-performing event and belief models to the 3 held-out annotated dialogs (not used in training) and report EMBERT/macro F1 to measure generalization beyond the single test dialog.