---
ver: rpa2
title: Generative Data Augmentation using LLMs improves Distributional Robustness
  in Question Answering
arxiv_id: '2309.06358'
source_url: https://arxiv.org/abs/2309.06358
tags:
- data
- generated
- question
- datasets
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how generated datasets influence the distributional
  robustness of question-answering models under natural distribution shifts. The authors
  propose a two-step generation approach using GPT-3.5 to first generate contexts
  conditioned on questions from the SQUAD dataset, then generate question-answer pairs
  for the newly generated contexts.
---

# Generative Data Augmentation using LLMs improves Distributional Robustness in Question Answering

## Quick Facts
- arXiv ID: 2309.06358
- Source URL: https://arxiv.org/abs/2309.06358
- Reference count: 6
- This paper investigates how generated datasets influence the distributional robustness of question-answering models under natural distribution shifts.

## Executive Summary
This paper investigates how generated datasets influence the distributional robustness of question-answering models under natural distribution shifts. The authors propose a two-step generation approach using GPT-3.5 to first generate contexts conditioned on questions from the SQUAD dataset, then generate question-answer pairs for the newly generated contexts. Experiments show that training QA models on a blend of real and generated data improves performance on natural distribution shift benchmarks compared to models trained only on real or only on generated data. Specifically, combining 50% real and 50% generated data yields better F1 and exact match scores across multiple test datasets (NewWiki, NYT, Amazon, Reddit) compared to using only real or only generated data.

## Method Summary
The paper proposes a two-step data generation pipeline using GPT-3.5 and T5 models. First, contexts are generated by conditioning GPT-3.5 on questions from the SQUAD dataset, limiting outputs to 250 words. Second, a T5 model generates question-answer pairs from these contexts, with round-trip consistency filtering applied. The generated data is then blended with real SQUAD data (typically 50-50) and used to train a RoBERTa-base QA model. The trained model is evaluated on four natural distribution shift datasets: NewWiki, NYT, Amazon, and Reddit, using F1 and exact match metrics.

## Key Results
- Combining 50% real and 50% generated data improves F1 and exact match scores on natural distribution shift benchmarks compared to models trained only on real or only on generated data
- Training on SQUAD alone results in significant performance deterioration when subjected to natural distribution shift datasets
- The 50-50 split between real and generated data yields better results than using only half of the generated data or other ratios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Generated data improves distributional robustness by increasing linguistic and stylistic diversity in training.
- Mechanism: The two-step generation approach creates contexts conditioned on real questions, then generates QA pairs for those contexts. This process exposes the model to varied language patterns while maintaining topical consistency with the original SQUAD dataset.
- Core assumption: The generated contexts maintain semantic relevance to the original questions while introducing stylistic variation that mimics natural distribution shifts.
- Evidence anchors:
  - [abstract] states "We take a two-step generation approach, generating both contexts and QA pairs to augment existing datasets" and demonstrates improved robustness.
  - [section] shows that "training on SQUAD, when subjected to natural distribution shift datasets, the model's performance significantly deteriorates" but combining real and generated data improves performance.
  - [corpus] contains related work on using generated data for robustness, supporting the general principle.
- Break condition: If generated contexts become semantically irrelevant or too noisy, the diversity benefit could be outweighed by harmful noise.

### Mechanism 2
- Claim: The 50-50 real-to-generated data ratio provides optimal balance between domain fidelity and generalization.
- Mechanism: Real data provides in-domain signal and preserves the original task distribution, while generated data provides diversity that helps the model generalize to unseen distributions. The equal weighting allows both contributions to be maximized.
- Core assumption: The generated data is of sufficient quality to be useful while real data provides necessary grounding in the original domain.
- Evidence anchors:
  - [abstract] shows that "combining 50% real and 50% generated data yields better F1 and exact match scores across multiple test datasets" compared to other ratios.
  - [section] demonstrates that "using only half of the generated data does not provide enough meaningful signal in terms of diversity" while "the ideal split between real and generated data is a 50-50 split."
  - [corpus] evidence is weak here - no direct support found in the related papers.
- Break condition: If the quality of generated data degrades significantly, the optimal ratio may shift toward more real data.

### Mechanism 3
- Claim: Context generation conditioned on real questions maintains topical consistency while introducing distributional shift.
- Mechanism: By generating contexts based on existing SQUAD questions, the approach ensures that the generated data remains relevant to the question-answering task while still introducing natural language variation that simulates distribution shifts.
- Core assumption: GPT-3.5 can generate contexts that are both topically relevant to the original question and linguistically diverse enough to improve robustness.
- Evidence anchors:
  - [section] explains the generation process: "We first generating contexts by conditioning it on a question present in the SQUAD dataset" to maintain consistency.
  - [section] shows that this approach works: "the generated context is consistent with the informative trivia format of SQUAD-like datasets."
  - [corpus] contains related work on context generation for data augmentation, supporting the general approach.
- Break condition: If GPT-3.5 fails to generate topically relevant contexts, the method would lose its key advantage of maintaining task consistency.

## Foundational Learning

- Concept: Distributional robustness and natural distribution shifts
  - Why needed here: Understanding how models perform under distribution shifts is central to evaluating the effectiveness of the data augmentation approach.
  - Quick check question: What is the difference between natural distribution shifts and other types of distribution shifts in NLP?

- Concept: Data augmentation through generative models
  - Why needed here: The core methodology relies on using LLMs to generate synthetic training data that improves model robustness.
  - Quick check question: How does conditioning generated data on real examples help maintain task relevance?

- Concept: Question answering evaluation metrics (F1, Exact Match)
  - Why needed here: These metrics are used to quantify performance improvements and are essential for interpreting the experimental results.
  - Quick check question: What is the difference between F1 score and Exact Match score in question answering?

## Architecture Onboarding

- Component map: GPT-3.5 context generation -> T5 question generation -> filtering -> RoBERTa QA model training -> evaluation on NDS datasets
- Critical path: The generation pipeline must produce high-quality data before model training can begin; model training must complete before evaluation.
- Design tradeoffs: Balancing generation quality vs. quantity, choosing between different generation models (GPT-3.5 vs. alternatives), and selecting the optimal real-to-generated data ratio.
- Failure signatures: Poor performance on NDS datasets despite good in-domain performance suggests insufficient diversity in training data; good NDS performance but poor in-domain performance suggests too much synthetic data.
- First 3 experiments:
  1. Train on only real SQUAD data and measure baseline performance on NDS datasets
  2. Train on only generated data and measure performance to assess generation quality
  3. Train on 50-50 mix of real and generated data to find the optimal ratio

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do generated datasets influence the performance of QA models under natural distribution shifts?
- Basis in paper: explicit
- Why unresolved: While the paper demonstrates that combining real and generated data improves distributional robustness, the underlying mechanisms and specific factors driving this improvement remain unclear. The study does not provide a detailed analysis of which aspects of the generated data contribute most to improved performance.
- What evidence would resolve it: Detailed ablation studies isolating different aspects of the generated data (e.g., context diversity, question-answer pair quality, linguistic style) and their individual contributions to performance improvements would help understand the mechanisms at play.

### Open Question 2
- Question: What is the optimal ratio of real to generated data for maximizing distributional robustness in QA models?
- Basis in paper: explicit
- Why unresolved: The paper finds that a 50-50 split of real and generated data performs well, but does not explore a wide range of ratios or determine if this is truly optimal across different types of distribution shifts. The study also does not investigate how this optimal ratio might vary depending on the specific characteristics of the target distribution shift.
- What evidence would resolve it: Systematic experiments varying the ratio of real to generated data across multiple distribution shifts and datasets, coupled with analysis of how the optimal ratio changes with different shift characteristics, would provide clearer guidance on optimal mixing strategies.

### Open Question 3
- Question: How do different question generation methods impact the quality and usefulness of generated datasets for distributional robustness?
- Basis in paper: explicit
- Why unresolved: The paper uses a T5-based question generation model for creating QA pairs, but does not compare this approach to other question generation methods or analyze how different generation strategies might affect the quality of the resulting datasets and their impact on model robustness.
- What evidence would resolve it: Comparative studies using different question generation methods (e.g., GPT-based, rule-based, or hybrid approaches) and analyzing their effects on both the quality of generated datasets and the resulting model performance would provide insights into optimal generation strategies.

## Limitations

- The generation process depends on GPT-3.5 and T5 models whose specific implementations and hyperparameters are not fully detailed, making exact reproduction challenging
- The evaluation is limited to four specific natural distribution shift datasets, which may not comprehensively represent all types of distribution shifts
- While the 50-50 data ratio shows optimal performance, the paper does not explore whether this ratio is task-specific or generalizes to other domains

## Confidence

- **High Confidence**: The core finding that combining real and generated data improves distributional robustness compared to using only real or only generated data. This is supported by multiple experimental comparisons across different test sets and clear quantitative improvements in F1 and EM scores.
- **Medium Confidence**: The specific claim that a 50-50 ratio is optimal. While the paper demonstrates this ratio outperforms other tested ratios, the analysis of why this particular split works best is somewhat speculative, and the exploration of the ratio space is limited to a few discrete points.
- **Low Confidence**: The mechanism explanation for why context generation conditioned on real questions maintains topical consistency while introducing distributional shift. The paper asserts this occurs but provides limited quantitative analysis of how much topical consistency is maintained or how the introduced variation compares to natural distribution shifts.

## Next Checks

1. Conduct a detailed error analysis of the generated contexts and QA pairs to quantify the rate of topical inconsistencies, hallucinations, or semantic drift to validate whether the generated data truly maintains task relevance while introducing beneficial diversity.

2. Test the same 50-50 augmentation approach on a different QA dataset (e.g., Natural Questions or TriviaQA) to determine whether the optimal ratio and effectiveness generalize beyond SQUAD, or if the results are dataset-specific.

3. Systematically vary the quality of generated data (using different generation models or quality thresholds) while keeping the 50-50 ratio constant to determine how sensitive the robustness improvements are to generation quality versus the ratio itself.