---
ver: rpa2
title: 'GenKL: An Iterative Framework for Resolving Label Ambiguity and Label Non-conformity
  in Web Images Via a New Generalized KL Divergence'
arxiv_id: '2307.09810'
source_url: https://arxiv.org/abs/2307.09810
tags:
- instances
- label
- divergence
- used
- entropy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes GenKL, an iterative training framework for\
  \ resolving label ambiguity and label non-conformity in web images via a new generalized\
  \ KL divergence. The authors introduce (\u03B1, \u03B2)-generalized KL divergence,\
  \ which can identify non-conforming instances whose predictions are not \"almost\"\
  \ uniformly distributed, addressing a fundamental limitation of entropy maximization\
  \ methods."
---

# GenKL: An Iterative Framework for Resolving Label Ambiguity and Label Non-conformity in Web Images Via a New Generalized KL Divergence

## Quick Facts
- arXiv ID: 2307.09810
- Source URL: https://arxiv.org/abs/2307.09810
- Reference count: 13
- Key outcome: GenKL achieves new state-of-the-art classification accuracies on three web image datasets

## Executive Summary
This paper addresses the challenge of label noise in web images by introducing GenKL, an iterative training framework that resolves label ambiguity and non-conformity. The authors propose a novel (α, β)-generalized KL divergence that can identify non-conforming instances whose predictions are not uniformly distributed, overcoming limitations of entropy maximization methods. GenKL identifies these non-conforming instances and relabels them with soft labels, including uniform vectors for non-conforming instances and double-hot vectors for non-ambiguous instances. Experimental results on Clothing1M, Food101/Food101N, and mini WebVision 1.0 datasets demonstrate significant improvements in classification accuracy.

## Method Summary
GenKL is an iterative training framework that addresses label ambiguity and non-conformity in web images. It introduces a new (α, β)-generalized KL divergence to identify non-conforming instances that entropy maximization methods miss. The framework operates in two stages: identifying non-conforming instances using the proposed divergence measure and relabeling them with soft labels (uniform vectors for non-conforming instances and double-hot vectors for non-ambiguous instances). This process is iterated until convergence, with the model learning from both the original labels and the newly assigned soft labels. The method is evaluated on three web image datasets using ResNet-50 architecture pre-trained on ImageNet.

## Key Results
- GenKL achieves new state-of-the-art classification accuracies: 81.34% on Clothing1M, 85.73% on Food101N, and 78.99%/92.54% (top-1/top-5) on mini WebVision 1.0
- The (α, β)-generalized KL divergence significantly outperforms traditional entropy maximization methods in identifying non-conforming instances
- GenKL demonstrates superior performance compared to existing state-of-the-art methods for handling label noise in web images

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The (α, β)-generalized KL divergence identifies non-conforming (NC) instances that entropy maximization methods miss.
- Mechanism: It computes divergence only on dominant entries in the prediction vector, controlled by β, allowing detection of NC instances whose predictions are not uniformly distributed.
- Core assumption: Prediction models can reliably detect salient features for all object classes present in any input image.
- Evidence anchors:
  - [abstract]: "we propose (α, β)-generalized KL divergence, Dα,β KL (p∥q), which can be used to identify significantly more NC instances."
  - [section]: "entropy maximization is based on the idealized assumption that NC instances have predictions that are 'almost' uniformly distributed. However, in real-world web image datasets, there are numerous NC instances whose predictions are far from being uniformly distributed."
  - [corpus]: Weak or missing - no direct corpus evidence found for this specific mechanism.
- Break condition: If prediction vectors do not reliably reflect salient feature detection, or if the model cannot distinguish dominant from non-dominant entries effectively.

### Mechanism 2
- Claim: Double-hot vectors improve training by encoding both the given label and the model's most confident prediction.
- Mechanism: They create a weighted sum of two one-hot vectors representing prior belief (based on class distribution) and model belief (based on predictions), guiding the model to consider both sources of information.
- Core assumption: The model's prediction confidence is a useful signal for the correctness of the most probable predicted label.
- Evidence anchors:
  - [section]: "the double-hot vector ¯qi can be interpreted as the overall relative measure of our prior belief (based on normalized class ratios) in comparison to the model's belief (based on training on the given labels), for the correctness of the given label versus the most probable predicted label."
  - [abstract]: "GenKL identifies and relabels NC instances."
  - [corpus]: Weak or missing - no direct corpus evidence found for this specific mechanism.
- Break condition: If the model's confidence is not a reliable indicator of label correctness, or if class distribution is not a useful prior.

### Mechanism 3
- Claim: Iterative training between NC instance identification and relabeling improves classification accuracy.
- Mechanism: The framework alternates between identifying NC instances using (α, β)-generalized KL divergence and relabeling them with soft labels, refining the model's understanding over multiple iterations.
- Core assumption: The model improves its ability to detect NC instances and refine its predictions with each iteration.
- Evidence anchors:
  - [abstract]: "we also introduce a new iterative training framework, GenKL, that identifies and relabels NC instances."
  - [section]: "We iterate between the two stages until the model converges."
  - [corpus]: Weak or missing - no direct corpus evidence found for this specific mechanism.
- Break condition: If the model's performance plateaus or degrades after initial iterations, or if the identification and relabeling process becomes unstable.

## Foundational Learning

- Concept: Kullback-Leibler (KL) divergence and its generalizations
  - Why needed here: Forms the basis for the (α, β)-generalized KL divergence used to identify NC instances
  - Quick check question: What is the difference between KL divergence and (α, β)-generalized KL divergence, and why is the latter more suitable for identifying NC instances?

- Concept: Entropy and its relationship to information theory
  - Why needed here: Understanding entropy is crucial for grasping why entropy maximization has limitations in identifying NC instances
  - Quick check question: How does normalized entropy differ from regular entropy, and why is it insufficient for identifying all NC instances?

- Concept: Soft labeling and its role in training with noisy data
  - Why needed here: GenKL uses soft labels (uniform vectors for NC instances and double-hot vectors for non-NC instances) to guide training
  - Quick check question: What are the advantages of using soft labels over hard labels in training with label noise, and how do uniform and double-hot vectors serve different purposes?

## Architecture Onboarding

- Component map:
  Input -> (α, β)-generalized KL divergence -> Relabeling -> Training -> Iteration

- Critical path:
  1. Pre-train model on clean subset (if available)
  2. Generate prediction vectors for all instances
  3. Identify NC instances using (α, β)-generalized KL divergence
  4. Relabel instances with appropriate soft labels
  5. Train model with weighted loss function
  6. Repeat steps 2-5 until convergence

- Design tradeoffs:
  - Balancing α and β values to optimize NC instance identification
  - Choosing between using one model or averaging multiple models for prediction vectors
  - Deciding on the number of iterations for the training process
  - Handling the trade-off between precision and recall in NC instance identification

- Failure signatures:
  - Poor identification of NC instances leading to degraded performance
  - Overfitting to the clean subset during pre-training
  - Instability in the iterative training process
  - Suboptimal performance due to inappropriate hyperparameter choices

- First 3 experiments:
  1. Test NC instance identification on a small, manually verified subset of the dataset
  2. Evaluate the effect of different (α, β) values on NC instance identification performance
  3. Assess the impact of using different numbers of models for generating prediction vectors

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of GenKL vary with different choices of the hyperparameter α in the (α, β)-generalized KL divergence?
- Basis in paper: [explicit] The paper reports that the performance of GenKL is sensitive to the value of α, where a deviation of ±0.15 in the value of α (from the optimal value α = 1.05) resulted in an approximate 0.15% drop in accuracy on the Clothing1M dataset.
- Why unresolved: While the paper provides some sensitivity analysis, it does not explore a wide range of α values or investigate the optimal α for different datasets.
- What evidence would resolve it: Further experiments with a broader range of α values on multiple datasets would help determine the optimal α and its impact on GenKL's performance.

### Open Question 2
- Question: How does the performance of GenKL change when using different loss functions for training, such as MSE, MAE, or KL loss, instead of the default cross-entropy loss?
- Basis in paper: [explicit] The paper reports that using cross-entropy loss is crucial for the outperformance of GenKL over the baselines, and that replacing it with MSE, MAE, or KL loss results in a significant drop in accuracy.
- Why unresolved: While the paper shows that cross-entropy loss is important, it does not investigate the reasons behind this or explore other potential loss functions that could further improve GenKL's performance.
- What evidence would resolve it: Further experiments with different loss functions and their combinations, along with a deeper analysis of their impact on the model's performance, would help identify the most suitable loss function for GenKL.

### Open Question 3
- Question: How does the performance of GenKL change when using different methods for identifying NC instances, such as Jo-SRC or DSOS, instead of the (α, β)-generalized KL divergence?
- Basis in paper: [explicit] The paper demonstrates that using the (α, β)-generalized KL divergence yields the best performance for NC instance identification, outperforming other methods like Jo-SRC and DSOS.
- Why unresolved: While the paper shows that the (α, β)-generalized KL divergence is effective, it does not explore the reasons behind its superiority or investigate whether other methods could be combined with it to further improve performance.
- What evidence would resolve it: Further experiments comparing the (α, β)-generalized KL divergence with other methods, as well as exploring potential combinations of methods, would help determine the most effective approach for identifying NC instances in GenKL.

## Limitations
- The effectiveness of NC instance identification relies heavily on the model's ability to reliably detect salient features, which may not hold for all datasets
- The assumption that model confidence is a reliable indicator of label correctness may not be true in cases of systematic bias or over-confidence
- The iterative process may become unstable or lead to performance degradation if not properly controlled

## Confidence
- Effectiveness of (α, β)-generalized KL divergence: Medium
- Usefulness of double-hot vectors: Medium
- Iterative training process: Medium

## Next Checks
1. Evaluate the performance of GenKL on a dataset with a different domain (e.g., medical images) to assess its generalizability
2. Conduct an ablation study to isolate the contribution of each mechanism to the overall performance improvement
3. Investigate the effect of using different backbone architectures (e.g., ResNet-101, EfficientNet) on the performance of GenKL