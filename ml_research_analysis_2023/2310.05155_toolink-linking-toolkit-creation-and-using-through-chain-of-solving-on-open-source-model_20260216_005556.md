---
ver: rpa2
title: 'Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source
  Model'
arxiv_id: '2310.05155'
source_url: https://arxiv.org/abs/2310.05155
tags:
- toolkit
- tool
- tools
- task
- chatgpt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents Toolink, a framework that enables open-source
  language models to use tools effectively by creating a toolkit and employing a chain-of-solving
  approach. The method involves toolkit creation to decompose tasks into manageable
  components and chain-of-solving to plan and call tools dynamically.
---

# Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model

## Quick Facts
- arXiv ID: 2310.05155
- Source URL: https://arxiv.org/abs/2310.05155
- Reference count: 17
- Primary result: Toolink enables open-source language models to use tools effectively by creating toolkits and employing chain-of-solving, achieving comparable performance to ChatGPT on diverse tasks.

## Executive Summary
This paper introduces Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-solving (CoS) approach. The method involves toolkit creation to decompose tasks into manageable components and chain-of-solving to plan and call tools dynamically. The framework is validated on ChatGPT and adapted to the LLaMA-7B model, resulting in LLaMA-CoS. Experiments on diverse tasks from BIG-bench show that LLaMA-CoS achieves comparable performance to ChatGPT in CoS ability and outperforms traditional chain-of-thought methods. The results demonstrate the robustness and generalization of LLaMA-CoS to unseen tasks and toolkits not specifically tailored for the target task.

## Method Summary
Toolink's approach involves three main steps: (1) Toolkit Creation - decomposing target tasks into manageable components using ChatGPT, (2) Chain-of-Solving (CoS) - planning and calling tools dynamically with code as an intermediary medium, and (3) Open-Source Model Adaptation - fine-tuning LLaMA-7B with CoS-GPT dataset and task-specific tool-augmented data. The CoS-GPT dataset includes data points for tool-planning, tool-calling, and code generation, all of which are fundamental for promoting the open-source model's CoS ability. By leveraging ChatGPT's strong reasoning and tool-using capabilities, Toolink creates comprehensive toolkits and demonstrates effective CoS planning and calling, which serves as a guide for the open-source model during fine-tuning.

## Key Results
- LLaMA-CoS achieves comparable performance to ChatGPT in CoS ability on BIG-bench tasks
- Toolink outperforms traditional chain-of-thought methods in tool-using tasks
- The framework demonstrates robustness and generalization to unseen tasks and toolkits

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Toolink's chain-of-solving (CoS) approach enables open-source models to match ChatGPT's tool-using performance by decomposing tasks into modular toolkits and systematically planning and calling tools.
- Mechanism: Toolink first creates a toolkit by breaking down the target task into manageable components through ChatGPT. Then, it uses CoS to plan which tools to use and how to call them, leveraging code as an intermediary medium. This disentangles the reasoning process into planning and calling steps, making it more interpretable and transferable to open-source models.
- Core assumption: Breaking down complex tasks into modular toolkits and using code as a medium for tool execution improves the adaptability and interpretability of tool-using in open-source models.
- Evidence anchors:
  - [abstract] "We introduce Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-solving (CoS) approach."
  - [section] "Chain-of-Solving (CoS) involves dynamically selecting useful tools Kuse from the created toolkit KT for each query Q and planning their uses with calling decisions."
  - [corpus] Weak. Corpus contains related toolkit papers but not specific to CoS or chain-of-solving approaches.

### Mechanism 2
- Claim: Fine-tuning LLaMA-7B with CoS-GPT, a dataset specifically designed for tool-using and code generation, enables LLaMA-CoS to achieve comparable performance to ChatGPT in CoS ability.
- Mechanism: The CoS-GPT dataset includes data points for tool-planning, tool-calling, and code generation, all of which are fundamental for promoting the open-source model's CoS ability. By finetuning LLaMA-7B with this dataset and task-specific tool-augmented data, LLaMA-CoS learns to effectively plan and call tools to solve problems.
- Core assumption: Training on a dataset that focuses on the planning and calling of tools, as well as code generation, is essential for developing the CoS ability in open-source models.
- Evidence anchors:
  - [abstract] "we curate CoS-GPT, a chain-of-solving dataset designed for tool-using, and finetune the LLaMA-7B model. It results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities."
  - [section] "To enhance Mopen’s skills in applying tools for problem-solving, we construct DCoS from scratch to improve its CoS ability from planning, calling, and coding."
  - [corpus] Weak. Corpus contains related code generation and fine-tuning papers but not specific to CoS-GPT or chain-of-solving datasets.

### Mechanism 3
- Claim: Toolink's approach of using ChatGPT to create toolkits and demonstrate CoS planning and calling enables effective transfer of tool-using abilities to open-source models.
- Mechanism: By leveraging ChatGPT's strong reasoning and tool-using capabilities, Toolink can create comprehensive toolkits and demonstrate effective CoS planning and calling. This demonstration serves as a guide for the open-source model during finetuning, allowing it to learn and replicate the tool-using process.
- Core assumption: Using a strong model like ChatGPT to create toolkits and demonstrate CoS planning and calling is an effective way to transfer tool-using abilities to open-source models.
- Evidence anchors:
  - [abstract] "We first validate the efficacy of Toolink in harnessing the model’s creativity and CoS ability on ChatGPT."
  - [section] "The Toolink framework introduced previously mainly stimulates a closed-source model, ChatGPT, to create and use tools."
  - [corpus] Weak. Corpus contains related ChatGPT and large language model papers but not specific to using ChatGPT for toolkit creation and CoS demonstration.

## Foundational Learning

- Concept: Toolkit Creation
  - Why needed here: Toolkit creation is the first step in Toolink's approach, where the target task is decomposed into manageable components represented by specific tools. This modularization facilitates more flexible and interpretable tool utilization.
  - Quick check question: What is the purpose of toolkit creation in Toolink's framework, and how does it contribute to the overall tool-using process?

- Concept: Chain-of-Solving (CoS)
  - Why needed here: CoS is the core mechanism in Toolink that links the created toolkit with specific tool uses. It involves planning which tools to use and how to call them, leveraging code as an intermediary medium. This disentangles the reasoning process into planning and calling steps, making it more interpretable and transferable to open-source models.
  - Quick check question: How does the chain-of-solving (CoS) approach in Toolink enable effective tool-using in open-source models, and what are the key components of this process?

- Concept: Fine-tuning with Task-Specific Data
  - Why needed here: Finetuning the open-source model with CoS-GPT and task-specific tool-augmented data is crucial for developing the model's CoS ability. This process allows the model to learn how to effectively plan and call tools based on the provided demonstrations and data.
  - Quick check question: Why is fine-tuning the open-source model with CoS-GPT and task-specific tool-augmented data necessary in Toolink's approach, and how does it contribute to the model's tool-using capabilities?

## Architecture Onboarding

- Component map:
  - Toolkit Creation (ChatGPT) -> Chain-of-Solving (CoS) -> Open-Source Model Adaptation (LLaMA-7B)
- Critical path:
  1. Create toolkit using ChatGPT and target task information.
  2. Demonstrate CoS planning and calling using ChatGPT.
  3. Finetune open-source model with CoS-GPT and task-specific data.
  4. Evaluate the tool-using performance of the finetuned open-source model.
- Design tradeoffs:
  - Using ChatGPT for toolkit creation and CoS demonstration leverages its strong capabilities but relies on a closed-source model.
  - Finetuning the open-source model requires a large amount of task-specific data and computational resources.
  - The CoS approach improves interpretability but may introduce additional complexity compared to direct tool calling.
- Failure signatures:
  - Poor toolkit creation: If the toolkit does not capture the essential components of the target task, the tool-using process may fail.
  - Ineffective CoS demonstration: If the demonstration provided by ChatGPT is not clear or comprehensive enough, the open-source model may struggle to learn the tool-using process.
  - Insufficient fine-tuning: If the open-source model is not adequately fine-tuned with CoS-GPT and task-specific data, its CoS ability may not improve significantly.
- First 3 experiments:
  1. Validate Toolink's approach on ChatGPT by testing its toolkit creation, CoS planning, and calling abilities on a set of tasks from BIG-bench.
  2. Finetune LLaMA-7B with CoS-GPT and task-specific tool-augmented data, and evaluate its tool-using performance on the same set of tasks.
  3. Assess the generalization and robustness of the finetuned open-source model by testing it on unseen tasks and toolkits not specifically tailored for the target task.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can toolkit creation capabilities be transferred from closed-source LLMs to smaller open-source models?
- Basis in paper: [explicit] The paper mentions that LLaMA-7B lacks the internal creativity required for toolkit creation and that the absence of enough training data further hampers the acquisition of this knowledge.
- Why unresolved: The current framework relies on ChatGPT for toolkit creation, and the paper acknowledges that this is a limitation that needs to be addressed in future research.
- What evidence would resolve it: Successful development and demonstration of an open-source model that can autonomously create toolkits for various tasks without relying on closed-source models.

### Open Question 2
- Question: How well does the Toolink framework generalize to tasks outside of the BIG-bench dataset?
- Basis in paper: [inferred] The paper mentions that the tasks tested are mostly drawn from BIG-bench and suggests that expanding the application to a broader range of scenarios would enable a more comprehensive assessment of the framework's efficacy and applicability across diverse domains.
- Why unresolved: The experiments conducted in the paper are limited to tasks from BIG-bench, which may not fully represent the diversity of real-world tasks.
- What evidence would resolve it: Conducting experiments on a wider variety of tasks from different domains and datasets to evaluate the framework's performance and generalization capabilities.

### Open Question 3
- Question: What are the potential biases in the Toolink framework, and how can they be mitigated?
- Basis in paper: [explicit] The paper acknowledges that bias and discrimination can manifest through problematic examples in the training data and mentions efforts to curate a diverse dataset to minimize biased patterns.
- Why unresolved: While the paper addresses potential bias, it does not provide a comprehensive analysis of the biases present in the framework or specific mitigation strategies.
- What evidence would resolve it: Conducting a thorough bias analysis of the framework and implementing targeted strategies to mitigate identified biases, followed by evaluation of the effectiveness of these strategies.

## Limitations
- The toolkit creation process relies heavily on ChatGPT, limiting the framework's applicability to other open-source models.
- The CoS-GPT dataset construction process is not thoroughly described, which may affect the reproducibility and generalizability of the approach.
- The evaluation is primarily focused on tasks from BIG-bench, limiting the framework's real-world applicability and generalization to diverse domains.

## Confidence
- High Confidence: The overall approach of using toolkit creation and chain-of-solving to enable tool-using in open-source models is well-motivated and supported by the experimental results.
- Medium Confidence: The specific details of the toolkit creation process and the CoS-GPT dataset construction are not fully specified, which limits the confidence in the reproducibility of these components.
- Low Confidence: The evaluation scope and the real-world applicability of the framework are not extensively tested, which limits the confidence in the generalizability of the results.

## Next Checks
1. Conduct a detailed analysis of the toolkit creation process, including the specific prompts and guidelines used for different types of tasks. Validate the reproducibility of the toolkit creation by attempting to recreate toolkits for a set of tasks using the provided instructions.
2. Investigate the data augmentation methods and the completeness of the CoS-GPT dataset. Assess the dataset's coverage of diverse scenarios and tools required for effective tool-using. Consider expanding the dataset to include more real-world examples and edge cases.
3. Evaluate the performance of Toolink on real-world applications beyond the BIG-bench tasks. This could include tasks from domains such as healthcare, finance, or customer service. Assess the framework's ability to handle more complex and diverse tool-using scenarios in practical settings.