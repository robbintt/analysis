---
ver: rpa2
title: 'Refined Coreset Selection: Towards Minimal Coreset Size under Model Performance
  Constraints'
arxiv_id: '2311.08675'
source_url: https://arxiv.org/abs/2311.08675
tags:
- coreset
- selection
- optimization
- data
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of coreset selection with prioritized
  multiple objectives (CS-PMO), aiming to find the smallest possible coreset under
  model performance constraints. The authors propose a novel method called lexicographic
  bilevel coreset selection (LBCS) that formulates CS-PMO as cardinality-constrained
  bilevel optimization with a priority order over multiple objectives.
---

# Refined Coreset Selection: Towards Minimal Coreset Size under Model Performance Constraints

## Quick Facts
- arXiv ID: 2311.08675
- Source URL: https://arxiv.org/abs/2311.08675
- Reference count: 40
- One-line primary result: LBCS achieves better model performance with smaller coreset sizes compared to previous strategies through lexicographic bilevel optimization.

## Executive Summary
This paper addresses the challenge of coreset selection with prioritized multiple objectives (CS-PMO), aiming to find the smallest possible coreset while maintaining model performance constraints. The authors propose a novel method called lexicographic bilevel coreset selection (LBCS) that formulates CS-PMO as cardinality-constrained bilevel optimization with lexicographic preferences. LBCS maintains optimization priority between model performance and coreset size, efficiently optimizing them through pairwise comparisons using lexicographic relations and solving the problem with a randomized direct search algorithm.

## Method Summary
LBCS formulates CS-PMO as cardinality-constrained bilevel optimization, where the inner loop optimizes model parameters and the outer loop selects the coreset. The method uses lexicographic relations to define priority order between model performance (primary objective) and coreset size (secondary objective). A randomized direct search algorithm solves the black-box optimization problem in the outer loop. The compromise parameter ε allows for trade-offs between objectives, potentially improving generalization in noisy data scenarios. Theoretical analysis provides convergence guarantees, and extensive experiments demonstrate superiority over baseline methods across various datasets.

## Key Results
- LBCS consistently achieves better model performance with smaller coreset sizes compared to previous strategies
- The method effectively maintains optimization priority between model performance and coreset size through lexicographic relations
- Experiments on Fashion-MNIST, SVHN, CIFAR-10, and ImageNet-1k demonstrate the method's effectiveness across different scales and datasets

## Why This Works (Mechanism)

### Mechanism 1
Lexicographic bilevel coreset selection (LBCS) effectively addresses the prioritized multi-objective problem by maintaining optimization priority between model performance and coreset size. LBCS formulates CS-PMO as cardinality-constrained bilevel optimization with lexicographic preferences, using lexicographic relations for pairwise comparisons between constructed coresets. The core assumption is that lexicographic relations defined for CS-PMO are both reflexive and transitive, allowing conclusive comparisons between any two feasible masks.

### Mechanism 2
The randomized direct search algorithm used in LBCS efficiently solves the black-box optimization problem of CS-PMO. The algorithm iteratively queries evaluation results of different masks, using lexicographic relations to compare performance and direct the search towards the optimal solution. The core assumption is that the randomized direct search algorithm can effectively explore the search space and converge to the optimal solution under the defined lexicographic relations.

### Mechanism 3
The compromise parameter ε in LBCS allows for a trade-off between model performance and coreset size, improving generalization in noisy data scenarios. By allowing a small compromise in the primary objective f1(m), the algorithm can find coresets that are more robust to noisy labels or class-imbalanced data, leading to better generalization. The core assumption is that a small compromise in the primary objective does not necessarily degrade model performance when generalizing to test data.

## Foundational Learning

- **Concept**: Lexicographic optimization
  - Why needed here: Maintains priority order between model performance and coreset size in CS-PMO problem
  - Quick check question: How does lexicographic optimization differ from traditional multi-objective optimization approaches?

- **Concept**: Bilevel optimization
  - Why needed here: Formulates CS-PMO problem with inner loop for model parameters and outer loop for coreset selection
  - Quick check question: What are the key differences between bilevel optimization and single-level optimization?

- **Concept**: Randomized direct search algorithms
  - Why needed here: Solves black-box optimization problem in outer loop of bilevel optimization framework
  - Quick check question: How do randomized direct search algorithms differ from gradient-based optimization methods?

## Architecture Onboarding

- **Component map**: Data -> Inner loop optimization -> Outer loop coreset selection -> Model training on selected coreset
- **Critical path**: Data → Inner loop optimization → Outer loop coreset selection → Model training on selected coreset
- **Design tradeoffs**: Lexicographic optimization ensures correct priority order but may lead to suboptimal solutions; randomized direct search is efficient but may not guarantee global optimum; compromise parameter improves generalization but may degrade performance if set too high
- **Failure signatures**: Improper lexicographic relations implementation fails to maintain correct optimization priority; large search space causes inefficient optimization; high compromise parameter degrades model performance
- **First 3 experiments**: 1) Verify correctness of lexicographic relations implementation, 2) Test convergence of randomized direct search on small-scale dataset, 3) Evaluate impact of compromise parameter on model performance and coreset size

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal convergence rate for the lexicographic bilevel coreset selection algorithm?
- Basis in paper: [inferred] The authors mention that although theoretical analysis provides convergence guarantees, the optimal convergence rate remains mysterious
- Why unresolved: The paper does not provide a detailed analysis of the convergence rate, leaving this as an open question for future research
- What evidence would resolve it: A rigorous mathematical analysis of the convergence rate, potentially through theoretical proofs or empirical studies comparing convergence speed of LBCS with other methods

### Open Question 2
- Question: How can the lexicographic bilevel coreset selection method be adapted to incorporate fairness and security-related objectives?
- Basis in paper: [explicit] The authors suggest that investigating the feasibility of introducing fairness and security-related objectives for more realistic scenarios might prove important
- Why unresolved: The paper does not explore the integration of fairness and security objectives into the LBCS framework, leaving this as a potential area for future research
- What evidence would resolve it: A modified version of LBCS that explicitly incorporates fairness and security objectives, along with experimental results demonstrating its effectiveness and impact on model performance

### Open Question 3
- Question: How does the performance of lexicographic bilevel coreset selection compare to other advanced coreset selection methods that do not rely on bilevel optimization?
- Basis in paper: [explicit] The authors acknowledge that there are advanced methods that do not need bilevel optimization and suggest that this work does not discuss an effective way to involve the minimization of coreset size in those methods
- Why unresolved: The paper does not provide a direct comparison between LBCS and other advanced coreset selection methods that do not use bilevel optimization
- What evidence would resolve it: Experimental results comparing performance of LBCS with other advanced coreset selection methods, both in terms of model accuracy and coreset size, on various datasets and tasks

## Limitations
- Theoretical gaps exist in convergence analysis, particularly for complex datasets and models
- Computational efficiency challenges for very large datasets beyond ImageNet-1k scale
- Generalization claims lack rigorous empirical validation, particularly for noisy data scenarios

## Confidence
- **Effectiveness of Lexicographic Optimization**: High - well-established mechanism consistently implemented
- **Superiority Over Baselines**: Medium - experimental results show improvement but comparisons are limited to specific datasets
- **Practical Applicability**: Low - real-world performance with noisy labels, class imbalance, and domain shift remains to be validated

## Next Checks
1. **Robustness to Noise**: Systematically evaluate LBCS performance on datasets with varying levels of label noise to validate the compromise parameter's effectiveness in improving generalization

2. **Scalability Analysis**: Conduct experiments on larger-scale datasets (beyond ImageNet-1k) to assess computational efficiency and scalability of the randomized direct search algorithm

3. **Ablation Study**: Perform controlled experiments to isolate impact of lexicographic optimization, bilevel formulation, and compromise parameter on overall performance