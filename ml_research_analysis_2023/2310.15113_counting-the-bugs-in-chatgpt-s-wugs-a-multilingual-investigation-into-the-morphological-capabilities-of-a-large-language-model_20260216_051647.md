---
ver: rpa2
title: 'Counting the Bugs in ChatGPT''s Wugs: A Multilingual Investigation into the
  Morphological Capabilities of a Large Language Model'
arxiv_id: '2310.15113'
source_url: https://arxiv.org/abs/2310.15113
tags:
- linguistics
- computational
- language
- morphological
- association
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study is the first to systematically analyze the morphological
  capabilities of large language models, specifically ChatGPT, using a wug test approach
  across four typologically diverse languages: English, German, Tamil, and Turkish.
  The researchers applied nonce-word inflection tasks to ChatGPT and compared its
  performance against purpose-built supervised systems and human annotators.'
---

# Counting the Bugs in ChatGPT's Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model

## Quick Facts
- arXiv ID: 2310.15113
- Source URL: https://arxiv.org/abs/2310.15113
- Reference count: 40
- Primary result: ChatGPT significantly underperforms supervised morphological models on wug tests across four languages, achieving only 58-78% accuracy versus 94-100% for the best baselines.

## Executive Summary
This study systematically evaluates ChatGPT's morphological capabilities using wug tests across four typologically diverse languages: English, German, Tamil, and Turkish. The researchers found that ChatGPT falls significantly short of both human performance and various supervised baselines in morphological reinflection tasks, with accuracy ranging from 58-78% compared to 94-100% for the strongest models. The study reveals a "real word bias" where ChatGPT tends to generate actual words instead of correct inflections when nonce words resemble real words, and shows that ChatGPT amplifies the productivity of frequent morphemes compared to human patterns.

## Method Summary
The researchers created nonce words for each language by perturbing existing words or combining syllables, then designed reinflection tasks requiring morphological transformations. They used three prompting strategies (zero-shot, one-shot, few-shot) with both long and short formats to query gpt-3.5-turbo-0613. Outputs were evaluated against human annotations using accuracy@k metrics and compared against five supervised baselines (ARL, MinGen, FIT, PPI, AED). The study included 50 English verbs, 174 German nouns, 86 Tamil verbs with all tense/PNG combinations, and 40 Turkish words across multiple reinflection tasks.

## Key Results
- ChatGPT achieved only 58-78% accuracy across languages, significantly underperforming the strongest supervised baselines at 94-100% accuracy
- The model exhibits a "real word bias," often generating actual words instead of correct inflections when nonce words resemble real words
- ChatGPT's performance varied by language, being worst for Tamil (61% accuracy) and Turkish (64% accuracy) compared to English (74%) and German (78%)
- The model amplifies morphological productivity of frequent morphemes like German -en and -s beyond human patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPT's morphological performance is constrained by real-word bias, not lack of grammatical knowledge.
- Mechanism: When a nonce word is orthographically close to a real word, ChatGPT decodes to that real word's representation instead of applying morphological rules to the nonce stem.
- Core assumption: ChatGPT does not apply generative morphological rules but instead retrieves the nearest real-word form in its learned representational space.
- Evidence anchors:
  - [abstract] "We furthermore find evidence for the existence of a real word bias in ChatGPT that is the more pronounced the more data ChatGPT has seen for a given language."
  - [section 6.4] "the stem that is generated in lieu of the nonce word is a frequently occurring word in the respective language and has a certain (sometimes strong) orthographic similarity to the nonce word."
  - [corpus] FMR score 0.65 suggests high lexical overlap with morphologically related literature, supporting a strong real-word bias.
- Break condition: If a nonce word has no close orthographic neighbor, ChatGPT must either generate a novel form or fail.

### Mechanism 2
- Claim: ChatGPT's morphological generalization improves with few-shot prompting but still lags behind supervised baselines.
- Mechanism: Prompting supplies semantic and syntactic constraints that narrow the representational search space, but the model still lacks explicit morphological rule application, so accuracy remains lower than rule-based or encoder-decoder models.
- Core assumption: Prompting provides context but does not change the underlying inference mechanism from retrieval to rule application.
- Evidence anchors:
  - [abstract] "ChatGPT falls short not only of human performance but also of various supervised baselines."
  - [section 4.2] "ChatGPT gets better results with the short prompt through an analogical example."
  - [corpus] Average neighbor citations 0.0 suggests this is a novel comparative setup; performance differences are not from citation overlap.
- Break condition: If prompts could supply explicit morphological rules, performance might converge with supervised models.

### Mechanism 3
- Claim: Morphological productivity patterns in ChatGPT reflect frequency bias amplified from human data.
- Mechanism: ChatGPT overgeneralizes the most productive morphemes (e.g., German -en, -s) because these appear more often in its training corpus, leading to higher usage than in human annotations.
- Core assumption: Pretraining corpus frequency directly influences morphological productivity in generation.
- Evidence anchors:
  - [section 6.5] "Interestingly, these two plural morphemes are the two most productive plural morphemes in German (KÃ¶pcke, 1988)."
  - [section 6.5] "ChatGPT is sensitive to the productivity of morphemes... but rather amplifies the productivity of certain morphemes."
  - [corpus] FMR 0.46 indicates moderate lexical similarity to morphology literature; productivity bias is plausible but not dominant.
- Break condition: If the pretraining corpus is balanced across morphemes, amplification effect may disappear.

## Foundational Learning

- Concept: Morphological reinflection
  - Why needed here: The tasks require converting one inflected form to another while preserving stem identity; understanding this is key to interpreting ChatGPT's failures.
  - Quick check question: If you are given "gegangen" (past participle of "gehen") and asked for the past tense "ging," which morphological operation is required?

- Concept: Wug test paradigm
  - Why needed here: The experimental design hinges on using novel words to test rule application vs. memorization; misapplying this concept would invalidate the study's claims.
  - Quick check question: Why is it important that the nonce words have not been seen by the model during pretraining?

- Concept: Tokenization and morphology
  - Why needed here: Byte-pair encoding can split morphologically complex words into subword units, affecting the model's ability to apply morphological rules; ignoring this can lead to wrong conclusions about performance.
  - Quick check question: If a nonce word is split into multiple tokens, how might that affect ChatGPT's morphological output?

## Architecture Onboarding

- Component map: Input preprocessing (nonce word, prompt formatting) -> LLM inference (gpt-3.5-turbo-0613) -> Token filtering (first word, remove non-words) -> Evaluation (acc@k vs. human gold) -> Baselines (ARL, MinGen, FIT, PPI, AED)
- Critical path: Prompt generation -> Model call -> Output parsing -> Accuracy computation
- Design tradeoffs: Short prompts reduce context but improve analogy completion; long prompts add context but may distract the model. Few-shot examples improve accuracy but increase prompt length.
- Failure signatures: High real-word bias -> outputs are inflections of real words instead of nonce words; inconsistent k-performance -> top-1 accuracy much lower than top-5, indicating many plausible alternatives.
- First 3 experiments:
  1. Run short 1-shot prompt on a subset of English nonce verbs; measure acc@1 and inspect outputs for real-word bias.
  2. Compare tokenization length vs. accuracy for German nonce nouns; verify no significant correlation.
  3. Generate confusion matrices for German plural morphemes under few-shot condition; quantify overgeneralization of -en and -s.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the real word bias observed in ChatGPT generalize to other large language models, or is it specific to the architecture and training data of ChatGPT?
- Basis in paper: Explicit - The paper discusses the "real word bias" where ChatGPT tends to generate real words instead of correct inflections when the nonce word resembles a real word, and notes this bias is more pronounced for high-resource languages.
- Why unresolved: The study only examined ChatGPT, so it's unclear whether this phenomenon is unique to its architecture or common across LLMs.
- What evidence would resolve it: Systematic testing of multiple LLMs (GPT-4, LLaMA, PaLM, etc.) on the same wug test tasks to compare their tendencies toward real word generation versus correct morphological inflection.

### Open Question 2
- Question: How does ChatGPT's morphological generalization ability compare to human children's performance on wug tests across different age groups?
- Basis in paper: Explicit - The paper compares ChatGPT's performance to adult human annotators but notes that Berko's original wug test was designed to study children's language acquisition.
- Why unresolved: The study only examined adult human performance, missing a crucial developmental perspective on morphological generalization.
- What evidence would resolve it: Administering the same wug tests to children at different developmental stages (e.g., ages 4-10) and comparing their accuracy and error patterns to ChatGPT's performance.

### Open Question 3
- Question: What specific aspects of ChatGPT's training data or architecture contribute to its morphological limitations, particularly for low-resource languages like Tamil?
- Basis in paper: Explicit - The paper notes that ChatGPT performs worse on Tamil than English/German and speculates about the role of data density in the representational space, but doesn't examine the training data directly.
- Why unresolved: The study identifies a correlation between performance and language resource availability but doesn't investigate the underlying mechanisms.
- What evidence would resolve it: Analyzing ChatGPT's training corpus to quantify morphological patterns in each language, examining attention patterns during morphological tasks, or conducting ablation studies on language-specific components of the model.

## Limitations
- The study's findings are constrained by inter-annotator agreement variability, particularly for Tamil (0.73) and Turkish (0.59) compared to English (0.94) and German (0.87)
- The German dataset filtering criteria for removing words with "blocked plurals" is vaguely specified, making exact reproduction difficult
- The study uses only gpt-3.5-turbo-0613 rather than testing other LLM variants, limiting generalizability to other models

## Confidence
- High confidence: ChatGPT underperforms supervised morphological reinflection models (94-100% vs. 58-78% accuracy) across all four languages tested
- Medium confidence: The real-word bias mechanism, where ChatGPT generates actual words instead of correct inflections when nonce words resemble real words, is supported but not quantified with precise orthographic similarity thresholds
- Medium confidence: ChatGPT amplifies morphological productivity of frequent morphemes (German -en, -s) compared to human patterns, though the extent of amplification is not precisely measured

## Next Checks
1. Replicate with controlled orthographic similarity: Systematically generate nonce words at varying orthographic distances from real words (e.g., edit distance 1-3) and measure how ChatGPT's real-word bias varies with similarity. This would quantify the threshold at which the bias becomes significant.

2. Test additional LLM variants: Evaluate the same wug test paradigm using gpt-4, Claude, and open-source models like LLaMA to determine whether the morphological limitations are specific to ChatGPT or represent a broader LLM phenomenon.

3. Analyze confusion matrices for productivity amplification: Create detailed confusion matrices showing which morphemes ChatGPT overgenerates compared to human annotations, and calculate the statistical significance of productivity differences across morpheme types.