---
ver: rpa2
title: Multi-task learning for classification, segmentation, reconstruction, and detection
  on chest CT scans
arxiv_id: '2308.01137'
source_url: https://arxiv.org/abs/2308.01137
tags:
- reconstruction
- multi-task
- classification
- segmentation
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a novel multi-task learning framework for medical
  image analysis on chest CT scans, addressing classification, segmentation, reconstruction,
  and detection tasks. The proposed architecture employs a shared VGG-13 encoder with
  task-specific decoders, including Mask R-CNN for detection.
---

# Multi-task learning for classification, segmentation, reconstruction, and detection on chest CT scans

## Quick Facts
- arXiv ID: 2308.01137
- Source URL: https://arxiv.org/abs/2308.01137
- Reference count: 2
- Multi-task framework achieves classification accuracy of 0.89 and segmentation IoU of 0.64 on chest CT scans

## Executive Summary
This study presents a novel multi-task learning framework for medical image analysis on chest CT scans, addressing classification, segmentation, reconstruction, and detection tasks simultaneously. The proposed architecture employs a shared VGG-13 encoder with task-specific decoders, including Mask R-CNN for detection. The model was trained and evaluated on datasets containing COVID-19, lung cancer, and non-COVID cases. Results show that the multi-task approach improves classification accuracy (0.89) and segmentation performance (IoU 0.64) compared to single-task models, though detection performance suffered from overfitting due to limited training data.

## Method Summary
The multi-task framework uses a shared VGG-13 encoder that processes 256x256 grayscale CT scan images, with task-specific decoders for classification (3 fully connected layers with softmax output), segmentation (U-Net style decoder with sigmoid output), reconstruction (U-Net style decoder with linear output), and detection (Mask R-CNN with VGG-13 backbone). The model was trained in three progressive stages: first on classification and reconstruction, then segmentation and reconstruction (with weights transferred from previous training), and finally detection and reconstruction. Generalized Dice loss was used for segmentation to handle class imbalance, while categorical cross-entropy was used for classification and MSE for reconstruction.

## Key Results
- Multi-task learning improved classification accuracy to 0.89 compared to single-task approaches
- Segmentation achieved IoU of 0.64, demonstrating effective lesion boundary detection
- VGG-13 backbone slightly outperformed ResNet-50 for classification and reconstruction tasks
- Detection task suffered from overfitting due to extremely limited training data (99 images)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-task learning with shared VGG-13 encoder improves generalization by forcing feature extraction that benefits multiple tasks simultaneously.
- Mechanism: The shared encoder extracts features that are useful across classification, segmentation, reconstruction, and detection tasks. By learning these shared representations, the model avoids overfitting to task-specific patterns and generalizes better across different types of lung abnormalities.
- Core assumption: The tasks of classification, segmentation, reconstruction, and detection on chest CT scans share sufficient underlying feature representations that can be jointly learned.
- Evidence anchors: [abstract] "multi-task learning is an approach to extracting important features, such as lesions, from small amounts of medical data because it learns to generalize better" [section] "the shared encoder is a VGG-13 neural network"

### Mechanism 2
- Claim: The multi-task architecture allows progressive training where weights from easier tasks can be transferred to harder tasks, improving convergence.
- Mechanism: The model is trained in three steps - first on classification & reconstruction, then segmentation & reconstruction, and finally detection & reconstruction. Weights from the first two tasks are loaded into subsequent training phases, allowing the model to start from a good initialization rather than learning from scratch.
- Core assumption: Earlier tasks (classification, segmentation) learn general features that are beneficial for later tasks (detection).
- Evidence anchors: [section] "the model was trained on image reconstruction and multiclass classification tasks... results of training two tasks simultaneously... were slightly better than the results of training classification only" [section] "the model was given the following tasks: segmentation of covid-19 lesions and image reconstruction... In the first approach, the model had preloaded weights from the previous task"

### Mechanism 3
- Claim: Different backbone architectures (VGG-13 vs ResNet-50) yield comparable performance, suggesting the multi-task framework is robust to backbone choice.
- Mechanism: The study evaluates the same multi-task architecture with two different backbones and finds that VGG-13 performs slightly better for classification and reconstruction, while ResNet-50 excels in segmentation. This suggests the architecture design is more important than the specific backbone choice.
- Core assumption: The multi-task framework's effectiveness is not highly dependent on the specific backbone architecture used.
- Evidence anchors: [abstract] "using different backbones (VGG-13 vs. ResNet-50) yields comparable results across tasks, with VGG-13 performing slightly better for classification and reconstruction, while ResNet-50 excels in segmentation" [section] "we decided to evaluate whether the multi-task model obtains similar results on different backbones... Multi-task model loss is lower in classification & reconstruction when the backbone is VGG-13, while in segmentation & reconstruction, the multi-task model loss is lower for backbone ResNet-50"

## Foundational Learning

- Concept: Multi-task learning with shared encoders
  - Why needed here: Medical image datasets are often small, making it difficult for single-task models to generalize. Multi-task learning allows the model to learn richer feature representations by leveraging correlations between different analysis tasks.
  - Quick check question: What is the main advantage of sharing parameters between tasks in a multi-task learning setup?

- Concept: Progressive weight transfer and curriculum learning
  - Why needed here: The study shows that loading weights from previous tasks improves performance on subsequent tasks. This suggests a curriculum learning approach where the model learns simpler tasks first and transfers knowledge to harder tasks.
  - Quick check question: Why might preloading weights from a classification task improve performance on a segmentation task?

- Concept: Loss function design for unbalanced medical data
  - Why needed here: Medical datasets often have highly unbalanced classes (e.g., lesions are much smaller than healthy tissue). The study uses generalized Dice loss for segmentation to handle this imbalance.
  - Quick check question: Why is generalized Dice loss preferred over standard cross-entropy for segmentation tasks with highly unbalanced classes?

## Architecture Onboarding

- Component map: Image → Shared VGG-13 encoder → Classification decoder (FC layers + softmax) → Segmentation decoder (U-Net + sigmoid) → Reconstruction decoder (U-Net + linear) → Detection module (Mask R-CNN with VGG-13 backbone)
- Critical path: Image → Shared encoder → Task-specific decoders → Loss computation → Parameter updates
- Design tradeoffs:
  - Shared vs. task-specific layers: Shared layers promote generalization but may limit task-specific optimization
  - Backbone choice: VGG-13 slightly better for classification/reconstruction, ResNet-50 better for segmentation
  - Detection performance: Limited by small dataset size, suggesting need for data augmentation or transfer learning
- Failure signatures:
  - Overfitting in detection task (as observed with small training set)
  - Poor segmentation performance on small lesions (IoU of 0.64 indicates room for improvement)
  - Degraded performance when loading weights from previous tasks (suggests negative transfer)

- First 3 experiments:
  1. Train classification & reconstruction tasks only, compare performance with single-task classification baseline
  2. Add segmentation & reconstruction tasks with weight transfer from previous training, measure improvement in IoU
  3. Replace VGG-13 with ResNet-50 backbone, compare performance across all tasks to validate backbone independence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the detection task performance scale with increased training data, and what is the minimum dataset size required to achieve satisfactory results?
- Basis in paper: [explicit] The authors note that detection performance suffered from overfitting due to limited training data and state that "much more data is needed to get desired results in the detection task, even in a multi-task approach."
- Why unresolved: The paper only evaluated detection on a small dataset (99 images) and did not conduct experiments with varying dataset sizes to determine the relationship between training data volume and detection performance.
- What evidence would resolve it: Training and evaluating the detection task on progressively larger datasets (e.g., 200, 500, 1000 images) while measuring detection metrics like mAP, precision, and recall to establish a performance curve and identify the minimum required dataset size.

### Open Question 2
- Question: Does the order of task training in the multi-task framework affect overall model performance across all tasks?
- Basis in paper: [inferred] The authors trained tasks in a specific sequence (classification & reconstruction → segmentation & reconstruction → detection & reconstruction) but did not explore alternative training orders or parallel training approaches.
- Why unresolved: The paper only presents results from a single training sequence and does not compare performance when tasks are trained in different orders or simultaneously from the start.
- What evidence would resolve it: Conducting experiments with different task training sequences (e.g., segmentation first, parallel training from initialization) and comparing final performance metrics across all tasks to determine if task order impacts overall model effectiveness.

### Open Question 3
- Question: How does the multi-task learning approach compare to ensemble methods where individual models are trained separately for each task?
- Basis in paper: [inferred] The authors compare their multi-task approach to single-task models only for classification and segmentation, but do not compare against ensemble methods where separate models are trained and combined for each task.
- Why unresolved: The paper does not include experiments comparing the proposed multi-task framework against separate single-task models trained independently and then ensembled.
- What evidence would resolve it: Training individual models for each task independently, then combining their predictions (through averaging, voting, or weighted combinations), and comparing the ensemble's performance metrics against the multi-task model's results across all tasks.

## Limitations

- Detection task performance severely limited by extremely small training dataset (99 images), causing overfitting
- Only two backbone architectures evaluated (VGG-13 and ResNet-50), leaving uncertainty about framework robustness to different network designs
- Detection module uses separate Mask R-CNN implementation rather than unified multi-task architecture, creating architectural inconsistency

## Confidence

- High confidence: The core finding that multi-task learning improves classification and segmentation performance compared to single-task approaches
- Medium confidence: The claim that VGG-13 performs better than ResNet-50 for classification and reconstruction tasks, given the limited comparison
- Low confidence: The detection task results due to severe overfitting and small dataset size

## Next Checks

1. Evaluate the multi-task architecture on a larger detection dataset to confirm whether the overfitting issue persists
2. Test additional backbone architectures (e.g., EfficientNet, DenseNet) to verify the claimed backbone independence of the framework
3. Conduct ablation studies removing individual tasks to quantify the contribution of each task to overall performance improvements