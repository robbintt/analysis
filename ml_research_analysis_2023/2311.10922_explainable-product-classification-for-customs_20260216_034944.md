---
ver: rpa2
title: Explainable Product Classification for Customs
arxiv_id: '2311.10922'
source_url: https://arxiv.org/abs/2311.10922
tags:
- classification
- customs
- cases
- officers
- sentences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work presents an explainable AI model for customs product
  classification, which suggests HS code subheadings and retrieves supporting sentences
  from the HS manual as evidence. The model uses a two-stage approach: first predicting
  HS codes using a language model, then retrieving key sentences using text similarity
  and expert knowledge from past cases.'
---

# Explainable Product Classification for Customs

## Quick Facts
- arXiv ID: 2311.10922
- Source URL: https://arxiv.org/abs/2311.10922
- Reference count: 40
- This work presents an explainable AI model for customs product classification, which suggests HS code subheadings and retrieves supporting sentences from the HS manual as evidence.

## Executive Summary
This paper introduces an explainable AI model for customs product classification, designed to suggest HS code subheadings and retrieve supporting evidence from the HS manual. The model uses a two-stage approach: first predicting HS codes using a language model, then retrieving key sentences using text similarity and expert knowledge from past cases. Tested on 925 challenging subheadings with 5,000 cases, the model achieved 93.9% accuracy for top-3 suggestions. A user study with 32 customs officers confirmed the model's helpfulness in reducing classification review time, particularly for less experienced officers. The explainable AI approach was found to be valuable for decision support and education in the customs classification domain.

## Method Summary
The method employs a two-stage pipeline for HS code classification. First, a language model (KoELECTRA, KLUE-RoBERTa, or KoBERT) predicts HS codes from product descriptions. Second, a retrieval system selects relevant sentences from the HS manual and past expert decisions using text similarity and expert knowledge. The model is trained on a dataset of 17,068 Korean HS classification cases, supplemented by cases from 50 countries. The approach emphasizes explainability by providing interpretable evidence to customs officers.

## Key Results
- Top-3 HS code suggestion accuracy of 93.9% on 925 challenging subheadings
- User study with 32 customs officers showed reduced classification review time
- Explainable AI approach found valuable for decision support and officer education

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The model's high accuracy stems from leveraging large language models (LLMs) fine-tuned on both general text and domain-specific customs data.
- Mechanism: KoELECTRA and KLUE-RoBERTa backbones provide rich semantic embeddings, while the two-stage pipelineâ€”code prediction followed by evidence retrievalâ€”enables the model to match product descriptions with relevant HS manual sentences and past expert decisions.
- Core assumption: The text descriptions of goods are sufficiently informative to predict correct HS codes when processed by strong semantic encoders.
- Evidence anchors:
  - [abstract] "The model uses a two-stage approach: first predicting HS codes using a language model, then retrieving key sentences using text similarity and expert knowledge from past cases."
  - [section] "Our model was implemented over three backbone language models: KoBERT, KoELECTRA, and KLUE-RoBERTa for the experiment."
  - [corpus] Weakâ€”no direct citation or performance evidence in neighbors for these specific LMs in customs context.
- Break condition: If product descriptions are too sparse or ambiguous, the language model's embeddings may fail to capture distinguishing features, leading to lower accuracy.

### Mechanism 2
- Claim: The explainability component improves decision acceptance by providing human-interpretable supporting sentences from the HS manual and past case resolutions.
- Mechanism: The retrieval stage uses both text similarity (via cosine similarity of embeddings) and expert knowledge (cases resolved by HS Committee/Council) to surface sentences that justify the suggested HS code.
- Core assumption: Field officers trust and rely on manually curated reasoning documents when validating classification decisions.
- Evidence anchors:
  - [abstract] "The model also provides reasoning for its suggestion in the form of a document that is interpretable by customs officers."
  - [section] "The second score ð‘ ð‘’ (xð‘–, ð‘€ð‘˜ ) involves selecting key sentences based on past decisions...These records pertained to the resolution of contentious cases undertaken by the HS Committee and HS Council."
  - [corpus] Weakâ€”neighbors focus on benchmarks or fraud detection, not on interpretability in customs classification.
- Break condition: If retrieved sentences are not truly relevant or are too generic, officers may distrust the model, reducing adoption.

### Mechanism 3
- Claim: The model's usability is enhanced by offering multiple (top-3) suggestions and a calibrated confidence score, reducing decision burden and improving trust.
- Mechanism: Presenting multiple HS code candidates with associated evidence lets officers compare and choose, while confidence scores (via temperature scaling) help gauge model certainty.
- Core assumption: Officers prefer to have multiple options rather than a single prediction, especially for complex or borderline cases.
- Evidence anchors:
  - [abstract] "the top-3 suggestions made by our model had an accuracy of 93.9% when classifying 925 challenging subheadings."
  - [section] "As a result, the AI suggestion consists of candidate codes and the relevant key sentences in the HS manual as explainable evidence."
  - [corpus] Weakâ€”no direct evidence in neighbors about multi-suggestion strategies or confidence calibration in customs classification.
- Break condition: If the top-3 suggestions consistently include incorrect codes, or if confidence scores are miscalibrated, officers may ignore or distrust the model.

## Foundational Learning

- Concept: Text embedding and semantic similarity using transformer-based language models (e.g., BERT, ELECTRA).
  - Why needed here: The model relies on these embeddings to map product descriptions and HS manual sentences into a shared semantic space for matching and retrieval.
  - Quick check question: How does cosine similarity between embeddings help identify relevant sentences in the HS manual for a given product description?

- Concept: Multi-class classification and handling imbalanced data distributions.
  - Why needed here: HS codes are highly imbalancedâ€”some subheadings appear much more frequently than others, affecting model training and evaluation.
  - Quick check question: Why might a skewed frequency distribution of HS subheadings lead to biased predictions, and how could this be mitigated?

- Concept: Explainable AI (XAI) and retrieval-based justification.
  - Why needed here: Customs officers need transparent reasoning for AI suggestions to trust and act upon them, especially in high-stakes tariff decisions.
  - Quick check question: What is the difference between retrieving similar past cases and retrieving semantically relevant sentences from the HS manual for explainability?

## Architecture Onboarding

- Component map: Input text description -> Language model encoder -> HS code classification head -> Text similarity retriever + expert knowledge retriever -> Top-K HS code suggestions + supporting sentences + confidence scores
- Critical path:
  1. Encode product description
  2. Predict HS code probabilities
  3. Retrieve top-K relevant sentences from HS manual and past cases
  4. Present suggestions with evidence to user
- Design tradeoffs:
  - Accuracy vs. explainability: More complex retrieval can improve explanations but may slow inference.
  - Number of suggestions vs. cognitive load: Too many options may overwhelm officers; too few may miss valid alternatives.
  - Model size vs. latency: Larger LMs (e.g., KLUE-RoBERTa) yield better accuracy but require more compute and time.
- Failure signatures:
  - Consistently low precision in top-1 predictions but high recall in top-K: model is uncertain or data is ambiguous.
  - Retrieved sentences are irrelevant or generic: similarity or knowledge retrieval module is not tuned to domain specifics.
  - Confidence scores poorly calibrated: officers lose trust if high-confidence predictions are wrong.
- First 3 experiments:
  1. Test accuracy of top-1 vs. top-3 predictions on a held-out set to validate the multi-suggestion benefit.
  2. Evaluate recall/precision of retrieved evidence sentences against human-annotated ground truth.
  3. Conduct a small user study with 5-10 officers to assess perceived helpfulness and trust in explanations.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the AI model change over time as trade patterns and HS manual classifications evolve?
- Basis in paper: [explicit] The paper discusses data distribution shift and mentions that trade patterns change over time (Figure 11) and HS manual undergoes revisions every five years (page 19).
- Why unresolved: The study uses historical data and evaluates the model's current performance, but does not track its performance longitudinally as trade patterns and HS classifications change.
- What evidence would resolve it: A longitudinal study tracking the model's accuracy and usefulness over multiple years as trade patterns shift and HS manual revisions occur.

### Open Question 2
- Question: What is the impact of using different large language models (LLMs) like ChatGPT on the accuracy and interpretability of HS code classification?
- Basis in paper: [explicit] The paper mentions a toy experiment with ChatGPT showing promising results for HS classification without additional training, and discusses the potential and limitations of using LLMs (pages 20-21).
- Why unresolved: The study only provides preliminary results with ChatGPT and does not extensively compare different LLMs or evaluate their impact on accuracy and interpretability.
- What evidence would resolve it: A comprehensive study comparing multiple LLMs on a large dataset of HS classification tasks, evaluating both accuracy and the quality of explanations provided.

### Open Question 3
- Question: How does the AI model's performance differ for various chapters and headings within the HS classification system?
- Basis in paper: [explicit] The paper mentions that accuracy varies by chapter and heading frequency (Figure 6), and discusses challenges with certain categories like "Miscellaneous" (pages 12-13).
- Why unresolved: The study provides some insights into performance variations but does not conduct a detailed analysis of how accuracy differs across all chapters and headings.
- What evidence would resolve it: A detailed breakdown of model accuracy for each chapter and heading, along with an analysis of the factors contributing to performance differences.

## Limitations

- Performance notably lower on chapter 90 (optical, photographic, and medical instruments) at 89.7% top-3 accuracy
- Reliance on translated HS manual content may introduce semantic drift
- Evaluation methodology for retrieved evidence sentences lacks clarity on human vs. automated annotation

## Confidence

- High confidence in top-3 accuracy claim (93.9%) based on clear methodology description
- Medium confidence in user study results due to small sample size (32 officers) and potential selection bias
- Low confidence in generalizability across different customs administrations due to Korea-specific data and procedures

## Next Checks

1. **Cross-dataset validation**: Test the model on HS classification data from a different country or customs administration to assess generalizability beyond the Korean dataset.

2. **Temporal validation**: Evaluate model performance on historical data from different years to detect potential distribution shifts in product descriptions or classification patterns over time.

3. **Expert validation study**: Conduct a larger-scale user study with diverse customs officers from multiple administrations, measuring not just classification accuracy but also decision-making time, trust calibration, and explanation usefulness across experience levels.