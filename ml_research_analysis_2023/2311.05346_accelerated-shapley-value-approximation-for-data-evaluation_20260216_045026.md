---
ver: rpa2
title: Accelerated Shapley Value Approximation for Data Evaluation
arxiv_id: '2311.05346'
source_url: https://arxiv.org/abs/2311.05346
tags:
- shapley
- value
- data
- learning
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses the high computational cost of Shapley value\
  \ data valuation in machine learning. The core method idea is to leverage the structural\
  \ properties of learning algorithms\u2014specifically, that data points in large\
  \ coalitions have limited marginal contribution due to stability\u2014to approximate\
  \ Shapley values efficiently using only small or medium-sized coalitions."
---

# Accelerated Shapley Value Approximation for Data Evaluation

## Quick Facts
- arXiv ID: 2311.05346
- Source URL: https://arxiv.org/abs/2311.05346
- Reference count: 40
- One-line primary result: δ-Shapley preserves rank and value accuracy with Spearman correlations up to 0.98 and wall-clock speedups up to 9.9x compared to Monte Carlo Shapley.

## Executive Summary
This paper addresses the computational challenge of Shapley value data valuation in machine learning by leveraging the stability properties of learning algorithms. The core insight is that marginal contributions of data points become negligible as coalition size grows due to uniform stability, allowing efficient approximation by focusing only on small or medium-sized coalitions. The authors introduce δ-Shapley, a semi-value that evaluates selected coalition sizes, achieving significant speedups while maintaining high correlation with true Shapley values. Theoretical analysis provides sample size bounds showing O(1/k²) samples suffice per coalition size k for convex losses, with experiments demonstrating strong performance across multiple datasets.

## Method Summary
The method approximates Shapley values by sampling small to medium-sized coalitions rather than considering all possible coalitions. For strongly convex and SGD-based non-convex settings, the authors derive sample size bounds showing that O(1/k²) samples suffice per coalition size k due to uniform stability properties. The δ-Shapley semi-value evaluates only selected coalition sizes between bounds BL and BU, reducing computation while maintaining accuracy. Experiments use logistic regression for convex cases and CNN models for non-convex cases, trained via SGD with batch size 1. The approach is validated against Monte Carlo Shapley values using Spearman rank correlation and wall-clock computation time across multiple UCI datasets and FashionMNIST.

## Key Results
- δ-Shapley achieves Spearman correlations up to 0.98 with Monte Carlo estimates while providing wall-clock speedups up to 9.9x
- Sample size bounds of O(1/k²) per coalition size k are sufficient for accurate approximation in convex settings
- Pre-trained models enable even greater efficiency, with δ-Shapley maintaining high accuracy using smaller coalitions
- Middle sampling strategy (BL=n/3, BU=2n/3) provides optimal trade-off between accuracy and speed

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Marginal contribution of a data point becomes negligible as coalition size grows due to uniform stability.
- **Mechanism**: Strong convexity and Lipschitz smoothness of the loss function ensure that adding or removing one point changes the model parameters by at most O(1/k), which bounds the change in loss and thus the marginal contribution.
- **Core assumption**: The learning algorithm is uniformly stable, i.e., the output model does not change much when one training point is added or removed.
- **Evidence anchors**:
  - [abstract]: "strongly convex loss functions are known to satisfy uniform stability"
  - [section]: "strong convexity will imply a uniform stability of c/k"
  - [corpus]: Weak; no direct mention of stability in neighbors.
- **Break condition**: If the loss function is not strongly convex or Lipschitz, the uniform stability bound no longer holds, and the mechanism fails.

### Mechanism 2
- **Claim**: For SGD with convex losses, the number of coalition samples needed to approximate φ_i^k decreases as 1/k².
- **Mechanism**: Expected uniform stability bounds the variance of marginal contributions, enabling use of Bernstein's inequality to derive sample size mk = O(1/k²) for each layer.
- **Core assumption**: The SGD algorithm satisfies expected uniform stability with a known constant ε.
- **Evidence anchors**:
  - [abstract]: "derive convergence guarantees on the accuracy of the approximate Shapley value"
  - [section]: "the number of samples needed to compute ˆφ_k^i such that Pr(| ˆφ_k^i − φ_k^i| ≥ a) ≤ b/n"
  - [corpus]: Weak; neighbors do not discuss sample complexity or Bernstein bounds.
- **Break condition**: If the step sizes are not properly tuned or the loss is non-convex, the expected uniform stability constant ε may be too large, making the sample complexity prohibitive.

### Mechanism 3
- **Claim**: For non-convex losses, the stability bound decays as 1/k^(βc+1), leading to higher sample complexity but still allowing focus on small-to-medium coalitions.
- **Mechanism**: Theorem 6 provides a stability bound H_k that depends on coalition size k; even though it decays slower than in the convex case, it still justifies limiting coalition sizes.
- **Core assumption**: SGD is run with monotonically non-increasing step sizes and the loss is β-smooth and L-Lipschitz.
- **Evidence anchors**:
  - [abstract]: "non-convex loss functions" and "SGD with non-convex loss function is one of the most important algorithmic problems"
  - [section]: "H_k = G/(βc)^(βc+1) * (2cL²)^(1/(βc+1)) * T^(βc/(βc+1)) * (1 + 1/(βc)) * (k-1)"
  - [corpus]: Weak; neighbors do not mention non-convex stability bounds.
- **Break condition**: If the non-convex landscape has very flat regions or the step sizes are poorly chosen, the stability bound may not decay fast enough to justify focusing on small coalitions.

## Foundational Learning

- **Concept**: Shapley value definition and semi-value generalization
  - Why needed here: δ-Shapley is a semi-value that omits some layers; understanding the full Shapley definition clarifies what is being approximated.
  - Quick check question: What axioms must a semi-value satisfy, and which one is omitted compared to the Shapley value?

- **Concept**: Uniform stability (expected and deterministic)
  - Why needed here: The core mechanism relies on stability bounds to argue that marginal contributions from large coalitions are negligible.
  - Quick check question: How does uniform stability differ from expected uniform stability, and in which learning scenarios does each apply?

- **Concept**: Bernstein's inequality and concentration bounds
  - Why needed here: The sample complexity proofs use Bernstein's inequality to bound the deviation of the empirical mean of marginal contributions.
  - Quick check question: What are the key differences between Hoeffding's inequality and Bernstein's inequality, and why is the latter needed for SGD?

## Architecture Onboarding

- **Component map**:
  - Data loader -> Coalition sampler -> Model trainer -> Value aggregator -> δ-Shapley evaluator -> Correlation checker

- **Critical path**:
  1. Choose k uniformly from [BL, BU].
  2. Sample mk coalitions of size k (or h permutations for expected utility).
  3. Train models on each coalition and compute marginal contributions.
  4. Average contributions to obtain ˆφ_k^i.
  5. Repeat for all k in [BL, BU] and average to get δ-Shapley.

- **Design tradeoffs**:
  - Smaller k → faster training, noisier estimates; larger k → slower training, lower noise.
  - BL=2n/10, BU=3n/10 chosen empirically to balance accuracy and speed.
  - Pre-trained models allow even smaller k because the model is already near-optimal.

- **Failure signatures**:
  - Spearman correlation ρ < 0.8 suggests δ-Shapley is not capturing true contributions.
  - Training loss does not decrease on small coalitions → unstable models.
  - Wall-clock time not reduced as expected → inefficient sampling or training.

- **First 3 experiments**:
  1. Run δ-Shapley with BL=n/3, BU=2n/3 on Adult dataset; report correlation and speedup vs Monte Carlo.
  2. Vary BL, BU to find optimal range; plot ρ vs coalition size.
  3. Apply δ-Shapley to pre-trained CNN on binary-FashionMNIST; compare correlation and speedup to non-pretrained case.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the variance in marginal contributions for very small coalitions affect the accuracy of δ-Shapley values when using low sampling strategies?
- Basis in paper: [inferred] The paper mentions that tiny coalitions are likely to produce poorly trained models whose contributions are largely noise, and shows in experiments that marginal contributions for small coalitions (|S|=10) have high variance with a standard deviation of 0.14 compared to final Shapley values in the range of 10^-3 to 10^-4.
- Why unresolved: The paper does not provide quantitative analysis of how this variance specifically impacts the accuracy of δ-Shapley approximations across different sampling strategies and coalition sizes.
- What evidence would resolve it: Experimental results comparing δ-Shapley accuracy across different sampling strategies (low vs middle) and varying coalition size ranges, with error bounds and correlation metrics to quantify the trade-off between variance and approximation accuracy.

### Open Question 2
- Question: How does the choice of upper and lower bounds (BU and BL) in the δ-Shapley formulation affect the trade-off between computational efficiency and approximation accuracy?
- Basis in paper: [explicit] The paper defines δ-Shapley with bounds BL and BU, and experiments use BL = n/3 and BU = 2n/3 (middle sampling) as well as BL = 2n/10 and BU = 3n/10 (low sampling), showing different computational times and correlation values.
- Why unresolved: The paper does not systematically explore how different choices of BL and BU affect the approximation quality across various datasets and learning scenarios.
- What evidence would resolve it: A comprehensive experimental study varying BL and BU across multiple datasets and learning scenarios, measuring the resulting computational time, approximation error, and correlation with true Shapley values to identify optimal bound ranges.

### Open Question 3
- Question: Does the diminishing marginal contribution property hold consistently across different types of machine learning models beyond convex and non-convex SGD, such as ensemble methods or reinforcement learning?
- Basis in paper: [inferred] The paper's theoretical analysis relies on stability properties of learning algorithms, showing that marginal contributions decrease with coalition size for strongly convex and SGD-based non-convex settings, but does not explore other model classes.
- Why unresolved: The paper focuses specifically on convex and non-convex SGD scenarios without examining whether the stability-based diminishing returns property extends to other learning paradigms.
- What evidence would resolve it: Empirical and theoretical analysis of marginal contribution behavior in ensemble methods, reinforcement learning, or other learning paradigms, testing whether stability bounds and diminishing returns still apply and how they affect Shapley value approximation efficiency.

## Limitations

- Theoretical bounds are asymptotic and may not translate directly to finite-sample settings with real-world datasets
- Choice of coalition bounds (BL, BU) is heuristic and may not be optimal for all problem settings
- Claims about δ-Shapley's performance on pre-trained models are based on a single binary classification experiment

## Confidence

- High: The mechanism of using uniform stability to justify focusing on small-to-medium coalitions is well-established in learning theory and supported by the theoretical derivations.
- Medium: The empirical validation on UCI datasets and FashionMNIST shows promising Spearman correlations and speedups, but the sample sizes are relatively small (n=100-500) and may not capture all failure modes.
- Low: The claims about δ-Shapley's performance on pre-trained models are based on a single binary classification experiment and may not generalize to more complex tasks or multi-class settings.

## Next Checks

1. **Robustness to coalition bounds**: Systematically vary BL and BU across a wider range (e.g., BL=n/5 to n/2, BU=2n/3 to 4n/5) and measure how Spearman correlation and wall-clock time change. Identify the Pareto-optimal trade-off between accuracy and speed.

2. **Non-convex stability verification**: For the CNN experiments, empirically measure the stability constant ε by training on multiple small coalitions and computing the variance of the learned parameters. Compare to the theoretical bound to check if the 1/k^(βc+1) decay holds in practice.

3. **Multi-class generalization**: Apply δ-Shapley to a multi-class image classification task (e.g., full FashionMNIST or CIFAR-10) with a deeper CNN architecture. Measure correlation and speedup compared to the binary case to assess scalability.