---
ver: rpa2
title: Kernels, Data & Physics
arxiv_id: '2307.02693'
source_url: https://arxiv.org/abs/2307.02693
tags:
- learning
- neural
- data
- training
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: These lecture notes explore the Neural Tangent Kernel (NTK) approach
  to practical machine learning problems, focusing on the relationship between data
  and model. The notes demonstrate that NTK methods can provide analytical insights
  into previously intractable problems like data distillation and adversarial robustness.
---

# Kernels, Data & Physics

## Quick Facts
- arXiv ID: 2307.02693
- Source URL: https://arxiv.org/abs/2307.02693
- Reference count: 12
- These lecture notes explore NTK methods for data distillation and adversarial robustness

## Executive Summary
These lecture notes explore the Neural Tangent Kernel (NTK) approach to practical machine learning problems, focusing on the relationship between data and model. The notes demonstrate that NTK methods can provide analytical insights into previously intractable problems like data distillation and adversarial robustness. Specifically, the authors show how kernel-based formulations can achieve state-of-the-art results in data distillation through Kernel-Inducing-Points, reducing dataset sizes while maintaining learning efficiency. For adversarial robustness, they present Adversarial KIP as a method for creating classifiers that are both accurate and robust.

## Method Summary
The notes present NTK-based methods for analyzing and solving practical ML problems. The core approach involves computing the Neural Tangent Kernel for a given architecture, using kernel regression to analyze learning dynamics, and translating these insights back to neural network training. Key methods include Kernel-Inducing-Points for data distillation, which finds small synthetic datasets that preserve learning efficiency, and Adversarial KIP for creating robust classifiers. The analysis leverages the fact that in the infinite-width limit, neural networks become equivalent to kernel regression with the NTK as kernel, enabling analytical solutions to problems that are otherwise intractable.

## Key Results
- NTK methods achieve state-of-the-art results in data distillation through Kernel-Inducing-Points
- Adversarial KIP creates classifiers that are both accurate and robust to adversarial attacks
- Theoretical analysis reveals sample complexity separation between convolutional and fully-connected networks
- Robust models require more data and larger model complexity than standard classifiers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: NTK linearization captures neural network behavior in infinite-width limit
- Mechanism: When neural network width → ∞, the NTK remains constant during training and parameter updates become infinitesimally small, making the network's dynamics equivalent to kernel regression with the NTK as kernel
- Core assumption: Proper initialization (NTK parametrization) ensures parameters stay close to initialization
- Evidence anchors:
  - [abstract] discusses "tractable kernel formulation" and "NTK methods can provide analytical insights"
  - [section 2.2] shows "the infinite-width dynamics of networks like (12) coincide with the linearized dynamics"
- Break condition: When widths are finite, parameter updates become large enough that linearization breaks down

### Mechanism 2
- Claim: Adversarial robustness requires more data due to increased sample complexity
- Mechanism: Robust classification needs to separate data classes in a way that's resistant to perturbations, which requires learning features that remain correlated with labels under adversarial attacks, demanding more samples to estimate the decision boundary accurately
- Core assumption: ℓ∞ perturbations can completely flip predictions based on weakly correlated features
- Evidence anchors:
  - [abstract] mentions "robust models require more data and larger model complexity"
  - [section 3.1] provides theoretical analysis showing "n = Ω(√d) samples are required for learning the robust classifier"
- Break condition: When perturbation budget ϵ is very small or data distribution has stronger correlations

### Mechanism 3
- Claim: Data distillation via Kernel-Inducing-Points reduces dataset size while maintaining learning efficiency
- Mechanism: KIP finds a small synthetic dataset XS such that kernel regression on XS produces the same predictor as training on full dataset XT, by solving the optimization problem that minimizes the difference between predictions on XT using XS as support set
- Core assumption: NTK formulation allows closed-form expression for trained predictor, making the nested optimization tractable
- Evidence anchors:
  - [abstract] discusses "kernel-based formulations can achieve state-of-the-art results in data distillation through Kernel-Inducing-Points"
  - [section 2.3.2] shows "DD simplifies greatly" in NTK limit and "turns out to produce state-of-the-art results for data distillation"
- Break condition: When dataset structure is too complex for kernel methods to capture effectively

## Foundational Learning

- Concept: Neural Tangent Kernel and infinite-width limit
  - Why needed here: NTK provides the analytical framework that makes previously intractable problems solvable through kernel formulations
  - Quick check question: What happens to the NTK during training in the infinite-width limit, and why is this significant?

- Concept: Sample complexity separation between architectures
  - Why needed here: Understanding why convolutional networks require fewer samples than fully-connected networks is crucial for designing efficient learning systems
  - Quick check question: Why does gradient descent being "orthogonally equivariant" for fully-connected networks lead to higher sample complexity?

- Concept: Robust vs non-robust features in data
  - Why needed here: Recognizing that data contains both useful and non-robust features explains the trade-off between accuracy and robustness in adversarial settings
  - Quick check question: How can the same feature be useful for standard classification but harmful for adversarial robustness?

## Architecture Onboarding

- Component map: NTK computation -> kernel regression -> synthetic data optimization -> empirical validation
- Critical path: (1) Compute NTK for given architecture and dataset, (2) Solve kernel regression problem analytically or numerically, (3) Translate insights back to neural network training procedures
- Design tradeoffs: Exact NTK computation vs. approximations, synthetic data quality vs. dataset size reduction, theoretical guarantees vs. practical performance
- Failure signatures: NTK approximation errors when widths are finite, synthetic datasets that don't generalize to neural networks, adversarial training that fails to converge
- First 3 experiments:
  1. Compute NTK for a simple fully-connected network on synthetic data and compare with actual training dynamics
  2. Apply KIP algorithm to reduce a small dataset and measure performance loss
  3. Test adversarial training with varying dataset sizes to observe sample complexity effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the NTK-based data distillation approach be extended to larger-scale datasets and more complex neural network architectures?
- Basis in paper: [explicit] The paper discusses the Kernel-Inducing-Points (KIP) method for data distillation and its state-of-the-art results, but mentions that it would be valuable to scale this approach to larger datasets.
- Why unresolved: The KIP method has been demonstrated on CIFAR-100 but its performance on larger datasets like ImageNet remains unexplored. Additionally, the method's applicability to deeper architectures and different types of neural networks needs investigation.
- What evidence would resolve it: Empirical studies demonstrating the effectiveness of KIP on ImageNet or similar large-scale datasets, along with theoretical analysis of its performance bounds for different architectures.

### Open Question 2
- Question: What is the precise relationship between the neural tangent kernel and adversarial robustness in practice?
- Basis in paper: [explicit] The paper mentions that NTK quantities could describe neural network behavior during adversarial training, but this relationship remains unclear.
- Why unresolved: While the paper shows that NTK can capture some aspects of robustness, the exact mechanisms by which NTK relates to adversarial examples and robust training are not fully understood.
- What evidence would resolve it: Detailed empirical studies comparing NTK evolution during standard versus adversarial training, along with theoretical analysis of how NTK properties correlate with robustness measures.

### Open Question 3
- Question: How can we theoretically characterize the trade-off between robustness and accuracy in neural networks?
- Basis in paper: [explicit] The paper discusses the tension between robustness and accuracy and presents a theoretical example showing this trade-off, but seeks a more general characterization.
- Why unresolved: While specific examples are provided, a comprehensive theoretical framework explaining when and why this trade-off occurs is lacking.
- What evidence would resolve it: A formal mathematical framework that quantifies the robustness-accuracy trade-off across different architectures and datasets, supported by both theoretical proofs and empirical validation.

## Limitations

- NTK-based analyses assume infinite-width networks, yet practical implementations necessarily use finite widths
- Kernel regression formulations may not capture all relevant features of complex data distributions
- The approach may not scale effectively to very large datasets or extremely deep architectures

## Confidence

- High confidence: The theoretical foundation of NTK linearization and its implications for sample complexity
- Medium confidence: Practical effectiveness of KIP for data distillation, as empirical results are promising but depend heavily on optimization stability
- Medium confidence: Adversarial robustness claims, as the theoretical sample complexity bounds are rigorous but practical trade-offs may vary with dataset characteristics

## Next Checks

1. **Finite-width validation**: Systematically measure NTK approximation error across different network widths and architectures to establish practical limits of the linearization assumption
2. **Generalization gap analysis**: Test whether KIP-synthesized datasets that perform well under kernel regression maintain equivalent performance when training actual neural networks
3. **Robustness baseline comparison**: Compare Adversarial KIP against established adversarial training methods (like PGD-based training) on standard benchmarks to validate practical efficacy claims