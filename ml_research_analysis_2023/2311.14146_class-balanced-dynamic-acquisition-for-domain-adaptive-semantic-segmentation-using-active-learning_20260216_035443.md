---
ver: rpa2
title: Class Balanced Dynamic Acquisition for Domain Adaptive Semantic Segmentation
  using Active Learning
arxiv_id: '2311.14146'
source_url: https://arxiv.org/abs/2311.14146
tags:
- class
- active
- acquisition
- learning
- budget
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Class Balanced Dynamic Acquisition (CBDA) addresses the problem
  of class imbalance in domain adaptive active learning for semantic segmentation.
  By dynamically weighting pixel acquisition scores based on class distribution statistics
  from previously selected labels, CBDA improves label balance across all classes,
  particularly benefiting minority classes.
---

# Class Balanced Dynamic Acquisition for Domain Adaptive Semantic Segmentation using Active Learning

## Quick Facts
- arXiv ID: 2311.14146
- Source URL: https://arxiv.org/abs/2311.14146
- Authors: 
- Reference count: 28
- Key outcome: CBDA improves mIoU by 0.6, 1.7, and 2.4 points over baseline for 5%, 10%, and 20% active learning budgets respectively

## Executive Summary
Class Balanced Dynamic Acquisition (CBDA) addresses class imbalance in domain adaptive active learning for semantic segmentation by dynamically weighting pixel acquisition scores based on class distribution statistics from previously selected labels. This approach improves label balance across all classes, particularly benefiting minority classes, and demonstrates that a more balanced label set than the original ground truth can yield better overall performance. CBDA is heuristic-agnostic and increases computational complexity negligibly, making it a practical improvement for active learning pipelines.

## Method Summary
CBDA is a domain adaptive active learning method for semantic segmentation that combines Dynamic Acquisition (DA) with Class Balancing (CB). The approach calculates acquisition scores for all pixels across the target dataset, then applies class weights to these scores based on cumulative class counts in previously selected active labels. These weights downweight overrepresented classes while maintaining relative differences between acquisition scores. The method uses DeepLabv3+ with ResNet-101 backbone and can be combined with various domain adaptation techniques (source-only, AADA, MADA).

## Key Results
- CBDA improves mIoU by 0.6, 1.7, and 2.4 points over baseline for 5%, 10%, and 20% active learning budgets respectively
- CBDA improves minimum class performance by 0.5, 2.9, and 4.6 IoU points across budgets
- CBDA outperforms a fully supervised baseline, demonstrating benefits of balanced labeling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CBDA improves performance by dynamically weighting pixel acquisition scores based on class distribution statistics from previously selected labels
- Mechanism: CBDA calculates a class weight for each pixel that downweights the acquisition scores of classes that have already received more labels than their ideal budget. This encourages the selection of minority class pixels, leading to a more balanced active label set.
- Core assumption: A more balanced active label set will improve model performance, particularly for minority classes.
- Evidence anchors:
  - [abstract] "By dynamically weighting pixel acquisition scores based on class distribution statistics from previously selected labels, CBDA improves label balance across all classes, particularly benefiting minority classes."
  - [section] "The class weight for the given iteration Wc,i is then calculated as shown in Eq. (2). The maximum function is being used to prevent the weight from reaching exactly 0... This serves the purpose of keeping the relative differences between the acquisition scores for labels of classes that have filled or exceeded the budget."
  - [corpus] Weak evidence - no direct mention of CBDA's mechanism in the corpus.

### Mechanism 2
- Claim: CBDA's class balancing approach is heuristic-agnostic and can be combined with any active learning strategy
- Mechanism: CBDA calculates class weights based on the observed class statistics and applies these weights to the acquisition scores. This process is independent of the specific active learning strategy used, making it a flexible addition to existing pipelines.
- Core assumption: The class balancing mechanism can be applied regardless of the underlying active learning strategy.
- Evidence anchors:
  - [abstract] "The method is heuristic-agnostic and increases computational complexity negligibly, making it a practical improvement for active learning pipelines."
  - [section] "Furthermore, it is essentially heuristic agnostic, as long as matrices of pixel-wise scores are calculated."
  - [corpus] No direct evidence - the corpus papers focus on different active learning strategies but don't mention CBDA's heuristic-agnostic nature.

### Mechanism 3
- Claim: CBDA's Dynamic Acquisition (DA) approach allows for more flexible pixel selection compared to the baseline Region Acquisition (RA) method
- Mechanism: DA calculates acquisition scores for all pixels across the entire target dataset before selecting the highest-scoring pixels, rather than selecting pixels within each image individually. This allows the model to utilize the active learning budget more effectively across the dataset.
- Core assumption: A global pixel selection approach will lead to a more optimal use of the active learning budget compared to per-image selection.
- Evidence anchors:
  - [abstract] "Notably, this new approach does not increase the computational complexity and can be used as a drop-in replacement in the standard training pipeline."
  - [section] "Instead of calculating the score and picking the pixels immediately after for each image, the entire set of acquisition score matrices is calculated, then stacked together and the pixels with the highest scores are selected from that tensor AS ∈ R|{Xt}|×H×W ."
  - [corpus] No direct evidence - the corpus papers don't discuss the specific DA approach used in CBDA.

## Foundational Learning

- Concept: Domain Adaptation
  - Why needed here: The paper focuses on domain adaptive active learning, which combines techniques from both domain adaptation and active learning to improve label efficiency in semantic segmentation.
  - Quick check question: What is the main goal of domain adaptation in the context of semantic segmentation?

- Concept: Active Learning
  - Why needed here: Active learning is used to select the most informative samples for labeling, reducing the overall labeling effort required for training semantic segmentation models.
  - Quick check question: How does active learning differ from traditional supervised learning in terms of label acquisition?

- Concept: Class Imbalance
  - Why needed here: Class imbalance is a key problem addressed by CBDA, as it can lead to poor performance on minority classes in semantic segmentation tasks.
  - Quick check question: Why is class imbalance particularly problematic in semantic segmentation compared to other computer vision tasks?

## Architecture Onboarding

- Component map: Input (Source dataset, Target dataset) -> Model (DeepLabv3+ with ResNet-101) -> Active Learning (Iterative process with acquisition functions) -> CBDA (Class balancing mechanism) -> Output (Improved semantic segmentation model)

- Critical path:
  1. Train initial model on source and target data
  2. Calculate acquisition scores for target dataset pixels
  3. Apply CBDA class balancing to acquisition scores
  4. Select pixels for labeling based on weighted scores
  5. Incorporate new labels into training data
  6. Repeat steps 2-5 for each active learning iteration

- Design tradeoffs:
  - Flexibility vs. complexity: CBDA adds flexibility to the active learning process but increases the complexity of the pipeline
  - Global vs. local selection: DA allows for global pixel selection but requires more memory to store all pixel scores
  - Strict vs. loose balancing: CBDA uses a loose balancing target (uniform distribution) to avoid over-penalizing high-scoring minority class pixels

- Failure signatures:
  - If minority class performance doesn't improve despite CBDA application, the class balancing mechanism may be too weak or the ideal class budget calculation may be incorrect
  - If overall performance degrades significantly with CBDA, the class balancing may be too aggressive, leading to the selection of low-scoring pixels
  - If the DA approach leads to memory issues or slow performance, the global pixel selection may be impractical for large datasets

- First 3 experiments:
  1. Implement CBDA with the baseline RA method and compare minority class performance to the original RA approach
  2. Test CBDA with different active learning iteration schedules (original vs. spread) to determine the optimal update frequency
  3. Vary the class balancing aggressiveness (e.g., change the epsilon value) to find the best trade-off between minority class improvement and overall performance

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions, but several areas remain unexplored:

### Open Question 1
- Question: Does the CBDA method maintain its performance advantage when applied to non-domain adaptation scenarios with imbalanced datasets?
- Basis in paper: [inferred] The authors state that CBDA can be used without domain adaptation and is heuristic-agnostic, but only test it in a domain adaptation context
- Why unresolved: The paper only demonstrates CBDA's effectiveness in domain adaptive active learning for semantic segmentation, not in standard active learning scenarios
- What evidence would resolve it: Experiments comparing CBDA to standard active learning methods (e.g., core-set, uncertainty sampling) on imbalanced datasets without domain shift

### Open Question 2
- Question: What is the optimal number of active learning iterations and budget distribution across iterations for CBDA?
- Basis in paper: [explicit] The authors mention that changing active learning iteration timing from [10000, 12000, 14000, 16000, 18000] to [10000, 18000, 24000, 28000, 30000] improved results, suggesting iteration timing matters
- Why unresolved: The paper only tests a few iteration schedules and doesn't explore the full parameter space of iteration timing and budget distribution
- What evidence would resolve it: Systematic ablation studies varying the number of iterations, their timing, and per-iteration budget allocation

### Open Question 3
- Question: How does CBDA perform when combined with different acquisition functions beyond region acquisition and dynamic acquisition?
- Basis in paper: [explicit] The authors state CBDA is "essentially heuristic agnostic" and can be combined with "any active learning strategy"
- Why unresolved: The paper only tests CBDA with two acquisition functions (RA and DA), leaving its compatibility with other strategies unexplored
- What evidence would resolve it: Experiments applying CBDA to acquisition functions like max-entropy, BALD, or core-set sampling in both domain adaptation and standard active learning settings

## Limitations

- Class Distribution Assumptions: The CBDA approach assumes that maintaining a uniform class distribution across selected labels will yield optimal performance, which may not hold for all datasets or segmentation tasks
- Generalization Across Domains: While CBDA shows strong results on GTAV→Cityscapes, the performance gains on other domain shifts (particularly SYNTHIA→Cityscapes) are less pronounced
- Active Learning Iteration Impact: The analysis notes that changing the active learning iteration schedule may affect results, indicating sensitivity to training schedule design

## Confidence

- High Confidence: The core claim that CBDA improves label balance and benefits minority classes is well-supported by the reported IoU improvements (0.5-4.6 points for minimum class performance)
- Medium Confidence: The claim that CBDA outperforms a fully supervised baseline warrants caution, as this result depends heavily on the quality and balance of the original ground truth labels
- Medium Confidence: The negligible computational complexity increase claim should be validated across different hardware configurations and dataset sizes

## Next Checks

1. Cross-Domain Validation: Test CBDA on additional domain adaptation scenarios beyond GTAV→Cityscapes and SYNTHIA→Cityscapes to assess generalization capabilities

2. Label Quality Analysis: Compare CBDA performance against different ground truth labeling strategies to understand how sensitive the method is to original label quality and distribution

3. Scalability Assessment: Evaluate CBDA's memory and computational requirements on larger datasets to verify the "negligible complexity increase" claim holds across different scales