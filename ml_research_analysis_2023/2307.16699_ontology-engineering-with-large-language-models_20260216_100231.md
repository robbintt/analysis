---
ver: rpa2
title: Ontology engineering with Large Language Models
arxiv_id: '2307.16699'
source_url: https://arxiv.org/abs/2307.16699
tags:
- declaration
- class
- ontology
- language
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper presents a method to automate ontology engineering using\
  \ fine-tuned GPT-3 to translate natural language sentences into OWL Functional Syntax\
  \ axioms. A Prot\xE9g\xE9 plugin was developed to integrate the LLM-based translation\
  \ into the ontology development workflow."
---

# Ontology engineering with Large Language Models

## Quick Facts
- arXiv ID: 2307.16699
- Source URL: https://arxiv.org/abs/2307.16699
- Reference count: 16
- Key outcome: Fine-tuned GPT-3 can accurately translate natural language sentences into OWL Functional Syntax axioms

## Executive Summary
This paper presents a novel approach to automating ontology engineering by leveraging fine-tuned Large Language Models (LLMs), specifically GPT-3, to translate natural language sentences into OWL Functional Syntax axioms. The authors developed a Protégé plugin that integrates this LLM-based translation into the ontology development workflow, aiming to reduce manual effort and decision complexity. The fine-tuning dataset comprised 150 prompt-axiom pairs covering various ontology engineering patterns, including instances, class subsumption, relations, disjointness, and cardinality.

## Method Summary
The method involves fine-tuning a GPT-3 davinci model on a dataset of 150 prompt-axiom pairs, where prompts are natural language sentences describing domain knowledge and axioms are their corresponding OWL Functional Syntax representations. The fine-tuned model is then integrated into a Protégé plugin using OWLAPI to programmatically append generated axioms to the active ontology. The plugin allows ontology developers to review and accept/reject the LLM-generated suggestions in real-time, enabling semi-automatic ontology population and enrichment.

## Key Results
- Fine-tuned GPT-3 can generate correct OWL axioms for various natural language inputs
- The Protégé plugin enables seamless integration of LLM-generated axioms into ontology development workflow
- The approach shows promise in reducing manual effort and decision complexity in ontology engineering

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuned GPT-3 can accurately translate natural language sentences into OWL Functional Syntax axioms.
- Mechanism: The fine-tuning process adapts the pre-trained language model to recognize domain-specific patterns and syntactic structures required for ontology representation, enabling it to generate correct DL axioms from natural language prompts.
- Core assumption: A dataset of 150 prompt-axiom pairs provides sufficient coverage of ontology engineering patterns for the model to generalize effectively.
- Evidence anchors:
  - [abstract] "we fine-tuned a GPT-3 model to convert Natural Language sentences into OWL Functional Syntax"
  - [section] "We developed a dataset of 150 pairs of prompts and their corresponding translations into OWL Functional Syntax"
  - [corpus] Weak evidence - no quantitative evaluation results reported in the paper
- Break condition: Insufficient or imbalanced training data leading to poor generalization on unseen ontology patterns.

### Mechanism 2
- Claim: The Protégé plugin architecture enables seamless integration of LLM-generated axioms into the ontology development workflow.
- Mechanism: The plugin uses OWLAPI to programmatically append generated axioms to the active ontology in the Protégé editor, allowing developers to review and accept/reject suggestions in real-time.
- Core assumption: Developers will actively supervise and validate the LLM-generated axioms rather than accepting them blindly.
- Evidence anchors:
  - [abstract] "The developed tool is publicly provided as a Protégé plugin"
  - [section] "The tool is constructed as a Protégé plugin that supports the development of an ontology from scratch and also the enrichment of an existing ontology"
  - [corpus] Weak evidence - no user study or efficiency metrics provided
- Break condition: LLM generates incorrect or inconsistent axioms that overwhelm the human reviewer or are accepted without proper validation.

### Mechanism 3
- Claim: Prompt engineering strategies significantly impact the quality of LLM-generated ontology axioms.
- Mechanism: The paper demonstrates that fine-tuning outperforms zero-shot and few-shot learning approaches by providing the model with domain-specific examples that teach it the precise syntactic requirements of OWL Functional Syntax.
- Core assumption: The order and structure of training examples matters for learning the correct output format.
- Evidence anchors:
  - [section] "Several experiments were run with this strategy, using the GPT-3.5-turbo model. The results were, although not incorrect, not the expected ones."
  - [section] "The few-shot learning strategy lets LLMs train for specific tasks from a few examples. To assess this strategy, we tested various prompts."
  - [section] "The fine-tuning strategy requires a dedicated dataset. A dataset with 150 prompt-result pairs and a validation set with 50 such pairs were used"
- Break condition: The fine-tuned model still produces inconsistent results or requires excessive manual correction.

## Foundational Learning

- Concept: Description Logic (DL) and OWL Functional Syntax
  - Why needed here: Understanding the formal representation language that the LLM outputs is essential for validating generated axioms and extending the system
  - Quick check question: What is the difference between a ClassAssertion and a SubClassOf axiom in OWL Functional Syntax?

- Concept: Large Language Model fine-tuning methodology
  - Why needed here: The success of this approach depends on proper dataset preparation, prompt design, and evaluation metrics for the fine-tuning process
  - Quick check question: What are the key hyperparameters to consider when fine-tuning a GPT model for ontology engineering tasks?

- Concept: Ontology engineering principles and methodologies
  - Why needed here: Understanding standard ontology development practices helps in designing effective training data and evaluating the tool's practical utility
  - Quick check question: What are the main challenges in manual ontology engineering that this tool aims to address?

## Architecture Onboarding

- Component map: User input -> Protégé plugin (Java) -> GPT-3 fine-tuned model (via OpenAI API) -> Axiom generation -> OWLAPI processing -> Ontology update -> User validation
- Critical path: User input → Plugin → GPT-3 API → Axiom generation → OWLAPI processing → Ontology update → User validation
- Design tradeoffs:
  - Fine-tuning vs. zero-shot learning: Fine-tuning provides better accuracy but requires dataset preparation and computational resources
  - Synchronous vs. asynchronous API calls: Synchronous provides immediate feedback but may impact user experience during slow responses
  - Local vs. cloud model hosting: Cloud hosting reduces infrastructure complexity but raises privacy concerns for sensitive domain knowledge
- Failure signatures:
  - Incorrect axioms being added to ontology (indicates model quality issues)
  - Plugin crashing during axiom processing (indicates OWLAPI integration problems)
  - Slow response times (indicates API communication or model performance issues)
  - Generated axioms not following OWL Functional Syntax (indicates training data or prompt formatting issues)
- First 3 experiments:
  1. Test basic class assertions: Input simple sentences like "Anna is a girl" and verify the generated ClassAssertion and Declaration axioms
  2. Test object property relationships: Input sentences like "Sarah and Anna are each other's sisters" and verify symmetric property generation
  3. Test cardinality restrictions: Input sentences like "Mia owns 2 bikes" and verify ObjectExactCardinality axiom generation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective is the fine-tuned GPT-3 model in generating correct OWL axioms compared to manual ontology engineering?
- Basis in paper: [explicit] The paper mentions ongoing work to quantitatively evaluate the efficiency gains from using the tool versus manual ontology engineering.
- Why unresolved: The paper does not provide any quantitative evaluation results comparing the tool's performance with manual ontology engineering.
- What evidence would resolve it: Quantitative evaluation results comparing the efficiency, accuracy, and time saved by using the fine-tuned GPT-3 model versus manual ontology engineering.

### Open Question 2
- Question: What are the limitations and potential errors in the generated OWL axioms by the fine-tuned GPT-3 model?
- Basis in paper: [explicit] The paper mentions that the tool aims to be a support tool that saves development time and reduces interaction time with the domain expert, but it does not provide details on potential limitations or errors in the generated axioms.
- Why unresolved: The paper does not discuss any limitations or potential errors in the generated OWL axioms by the fine-tuned GPT-3 model.
- What evidence would resolve it: Analysis of the generated OWL axioms, identifying common errors or limitations, and providing examples of incorrect or suboptimal axioms.

### Open Question 3
- Question: How well does the fine-tuned GPT-3 model generalize to different domains and types of natural language sentences?
- Basis in paper: [explicit] The paper mentions that the fine-tuning dataset comprises 150 prompt-axiom pairs covering various cases and domains, but it does not provide information on how well the model generalizes to unseen domains or sentence types.
- Why unresolved: The paper does not provide any evaluation or analysis of the model's performance on unseen domains or sentence types.
- What evidence would resolve it: Evaluation of the model's performance on a diverse set of natural language sentences from different domains, measuring accuracy, coverage, and generalization ability.

## Limitations
- Limited dataset size (150 prompt-axiom pairs) may not provide adequate coverage for complex ontology domains
- Lack of quantitative evaluation metrics on accuracy rates, efficiency gains, or user experience
- No analysis of system performance on unseen ontology patterns, edge cases, or domain-specific terminology

## Confidence
- High confidence: The basic mechanism of using fine-tuned GPT-3 to generate OWL axioms from natural language is technically sound and the Protégé plugin architecture is feasible
- Medium confidence: The approach will provide meaningful efficiency gains in ontology development, as the paper lacks quantitative validation data
- Low confidence: The system can handle complex ontology patterns and maintain consistency when used for large-scale ontology engineering projects

## Next Checks
1. Conduct a quantitative evaluation comparing ontology development time and axiom accuracy between manual methods and the LLM-augmented approach across multiple domain ontologies
2. Test the system's robustness by evaluating performance on out-of-distribution prompts and complex ontology patterns not represented in the training data
3. Perform a user study with ontology engineers to assess the practical utility, learning curve, and decision-making efficiency when using the tool in real development scenarios