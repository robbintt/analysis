---
ver: rpa2
title: Paraphrasing evades detectors of AI-generated text, but retrieval is an effective
  defense
arxiv_id: '2303.13408'
source_url: https://arxiv.org/abs/2303.13408
tags:
- text
- dipper
- paraphrase
- detection
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models are increasingly used for malicious applications
  such as fake content creation and plagiarism, spurring the development of AI-generated
  text detection algorithms based on watermarking or statistical properties. This
  paper evaluates the robustness of these detectors to paraphrasing attacks, in which
  AI-generated text is rewritten to evade detection while preserving semantics.
---

# Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense

## Quick Facts
- **arXiv ID:** 2303.13408
- **Source URL:** https://arxiv.org/abs/2303.13408
- **Reference count:** 40
- **Key outcome:** Paraphrasing successfully evades AI text detectors, but retrieval-based detection offers an effective defense

## Executive Summary
Large language models are increasingly used for malicious applications such as fake content creation and plagiarism, spurring the development of AI-generated text detection algorithms based on watermarking or statistical properties. This paper evaluates the robustness of these detectors to paraphrasing attacks, in which AI-generated text is rewritten to evade detection while preserving semantics. To this end, the authors develop DIPPER, an 11B parameter paraphrase generation model capable of rewriting paragraphs with context and controllable diversity. Experiments attacking five detection algorithms with DIPPER show that paraphrasing successfully evades all detectors across three language models and two tasks, reducing DetectGPT accuracy from 70.3% to 4.6% on GPT2-XL while maintaining semantic similarity. To defend against such attacks, the authors propose retrieval-based detection that searches a database of previously generated sequences for semantically similar matches. Experiments using a 15M generation database show retrieval detects 80-97% of paraphrased generations while only misclassifying 1% of human-written text. Overall, the results demonstrate the brittleness of current AI text detectors to paraphrasing and show retrieval is a promising defense.

## Method Summary
The paper develops DIPPER, a T5-XXL model fine-tuned on paragraph-level paraphrases from the PAR3 dataset, to generate paraphrases with controllable lexical and order diversity. The authors evaluate five detection algorithms (watermarking, GPTZero, DetectGPT, OpenAI classifier, and RankGen) against paraphrased text from GPT2-XL, OPT-13B, and GPT3.5-davinci-003 across open-ended generation and long-form question answering tasks. Detection accuracy is measured at a fixed false positive rate of 1%. The retrieval defense stores generated text in a database and uses semantic similarity (BM25 or P-SP) to match paraphrased queries to their original generations. The system is evaluated on a 15M generation corpus to assess detection rates while maintaining low false positives on human text.

## Key Results
- Paraphrasing reduces DetectGPT accuracy from 70.3% to 4.6% on GPT2-XL while maintaining semantic similarity above 0.76 P-SP threshold
- Watermarking is most resilient to paraphrasing, dropping from 100% to 57.2% detection accuracy on GPT2-XL
- Retrieval defense detects 80-97% of paraphrased generations while misclassifying only 1% of human-written text
- All five detection algorithms are successfully evaded by DIPPER paraphrasing across three language models and two tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Paraphrasing attacks work because they preserve semantics while changing statistical properties.
- Mechanism: A paraphraser like DIPPER rewrites model-generated text using lexical diversity and syntactic reordering controls. Since detection algorithms often rely on statistical signatures or watermarks, these changes cause misclassification while maintaining meaning.
- Core assumption: The paraphraser can modify text enough to evade detection without significantly altering semantics.
- Evidence anchors:
  - [abstract]: "DIPPER drops detection accuracy of DetectGPT from 70.3% to 4.6%...without appreciably modifying the input semantics."
  - [section 4.1]: "we also need to measure whether the original and paraphrased generations share approximately the same semantics."
- Break condition: If semantic preservation fails or if the paraphraser cannot sufficiently alter statistical properties.

### Mechanism 2
- Claim: Retrieval-based defense works because it matches paraphrased text to its original generation.
- Mechanism: The API stores all generated text in a database and uses semantic similarity (BM25 or P-SP) to find matches. Since paraphrasing preserves meaning, the paraphrased text still matches the original generation in the database.
- Core assumption: The retrieval system can find semantically similar matches even after paraphrasing.
- Evidence anchors:
  - [abstract]: "retrieval detects 80-97% of paraphrased generations while only misclassifying 1% of human-written text."
  - [section 5.1]: "Since paraphrasing approximately preserves input semantics, we expect such a defense to still be able to map paraphrased generations to their source."
- Break condition: If paraphrasing significantly alters semantics or if the retrieval corpus becomes too large relative to performance.

### Mechanism 3
- Claim: Detection thresholds must balance false positives and detection accuracy.
- Mechanism: Detection algorithms set thresholds to maintain low false positive rates (1% in experiments), which inherently limits detection accuracy. Paraphrasing exploits this by staying within the false positive tolerance.
- Core assumption: Maintaining extremely low false positive rates is prioritized over detection accuracy.
- Evidence anchors:
  - [section 2.1]: "Kirchenbauer et al. (2023) recommend using a high z value (z >4, or p< 3× 10−5) to reduce the risk of false positives"
  - [section 4.1]: "we fix the false positive rate to 1% for all detection algorithms"
- Break condition: If detection requirements change to allow higher false positive rates.

## Foundational Learning

- Concept: Semantic similarity metrics
  - Why needed here: To evaluate whether paraphrasing preserves meaning and to implement retrieval-based detection
  - Quick check question: What metric does the paper use to measure semantic similarity between original and paraphrased text?

- Concept: Control codes in language models
  - Why needed here: DIPPER uses lexical and order diversity control codes to generate paraphrases with varying levels of modification
  - Quick check question: What two control codes does DIPPER provide to users?

- Concept: Database search and retrieval
  - Why needed here: The retrieval defense requires efficient search through millions of generated sequences
  - Quick check question: What two retrieval methods are compared in the experiments?

## Architecture Onboarding

- Component map: DIPPER paraphraser -> Detection algorithms (watermarking, DetectGPT, GPTZero, OpenAI classifier, RankGen) -> Retrieval defense (database + BM25/P-SP) -> Evaluation pipeline
- Critical path: Generate text -> Paraphrase with DIPPER -> Test against detection algorithms -> Test retrieval defense -> Evaluate semantic preservation
- Design tradeoffs: High detection accuracy vs low false positive rates; sophisticated paraphrasers vs simple sentence-level approaches; exact vs approximate retrieval
- Failure signatures: High false positive rates indicate retrieval problems; low detection accuracy indicates paraphraser limitations; semantic drift indicates control code issues
- First 3 experiments:
  1. Test DIPPER paraphrasing on GPT2-XL with L60,O60 control codes and measure detection accuracy drop
  2. Evaluate retrieval defense with 1M generation database using BM25 on paraphrased queries
  3. Compare DIPPER semantic preservation against non-contextual paraphrasers using human evaluation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would DIPPER perform on paraphrase attacks against watermarking detection algorithms compared to other detection methods?
- Basis in paper: [explicit] The paper states that "watermarking is the most resilient to paraphrasing" among the tested detection algorithms, with detection accuracy dropping from 100% to 57.2% after paraphrasing GPT2-XL generations.
- Why unresolved: The paper does not provide a detailed comparison of DIPPER's performance against watermarking specifically versus other detection methods. It would be valuable to understand if DIPPER is more or less effective at evading watermarking detection compared to methods like DetectGPT or OpenAI's text classifier.
- What evidence would resolve it: Conducting experiments to directly compare DIPPER's effectiveness at evading watermarking detection versus other detection methods would provide the necessary evidence. This could involve testing DIPPER against a range of watermarking algorithms and comparing the results to its performance against other detection methods.

### Open Question 2
- Question: How does the quality of DIPPER paraphrases compare to paraphrases generated by large language models like GPT-3.5 when controlling for diversity?
- Basis in paper: [explicit] The paper notes that DIPPER "performs competitively with the much larger and more powerful GPT-3.5 davinci-003 model in terms of paraphrase quality, and significantly better at controlling diversity."
- Why unresolved: While the paper claims DIPPER is competitive with GPT-3.5, it does not provide direct quantitative comparisons of paraphrase quality between the two models. Understanding how DIPPER's paraphrases compare to those from GPT-3.5 in terms of semantic preservation and diversity control would be valuable.
- What evidence would resolve it: Conducting a head-to-head comparison of DIPPER and GPT-3.5 paraphrases using metrics like semantic similarity, diversity measures, and human evaluations would provide the necessary evidence to answer this question.

### Open Question 3
- Question: How effective would retrieval-based detection be at identifying paraphrased text generated by DIPPER when using a corpus of previously generated text from the same language model?
- Basis in paper: [inferred] The paper proposes retrieval-based detection as a defense against paraphrase attacks and shows that it is effective at detecting paraphrased text generated by DIPPER when using a corpus of 15M generations from a fine-tuned T5-XXL model. However, it does not specifically test the effectiveness of retrieval-based detection when the corpus contains text generated by the same language model that DIPPER is paraphrasing.
- Why unresolved: The paper does not provide evidence on how well retrieval-based detection would perform when the retrieval corpus contains text generated by the same language model that DIPPER is paraphrasing. This scenario is important because it represents a more realistic attack scenario where an adversary has access to the same language model as the defender.
- What evidence would resolve it: Conducting experiments to test retrieval-based detection's effectiveness at identifying paraphrased text generated by DIPPER when using a corpus of text generated by the same language model would provide the necessary evidence. This could involve training DIPPER on text generated by a specific language model and then testing retrieval-based detection using a corpus of text generated by that same model.

## Limitations

- The experiments use a single paraphraser configuration (L60,O60) to claim all detectors are evaded, without testing sensitivity to different paraphrasing strategies
- Retrieval defense scalability and computational costs are not addressed despite testing with a 15M generation database
- The 1% false positive rate requirement significantly constrains detection performance, but alternative tradeoff points are not explored

## Confidence

**High confidence**: The fundamental mechanism that paraphrasing attacks can evade detection algorithms based on statistical properties is well-established and demonstrated across multiple detectors and language models.

**Medium confidence**: The retrieval defense mechanism shows promise in controlled experiments, but scalability and performance under realistic deployment conditions remain uncertain without additional testing.

**Medium confidence**: The semantic preservation of DIPPER-generated paraphrases is validated using P-SP scores above 0.76, but human evaluation of semantic equivalence is limited to a small sample size.

## Next Checks

1. **Control code sensitivity analysis**: Test DIPPER with varying combinations of lexical (L) and order (O) diversity controls to determine the minimum modifications needed to evade detection while maintaining semantic similarity. This would reveal whether DIPPER's effectiveness depends on extreme paraphrasing or if moderate modifications suffice.

2. **Retrieval performance scaling**: Evaluate the retrieval defense's detection accuracy and computational efficiency as the database grows from 1M to 50M+ generations. Include both exact (P-SP) and approximate nearest neighbor methods to understand practical deployment constraints.

3. **Cross-paraphraser robustness**: Test the detection algorithms and retrieval defense against paraphrased text generated by alternative paraphrasers (e.g., human rewriting, simpler sentence-level approaches) to verify that the results generalize beyond DIPPER specifically.