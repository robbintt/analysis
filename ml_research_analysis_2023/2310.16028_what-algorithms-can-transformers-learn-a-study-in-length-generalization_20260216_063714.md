---
ver: rpa2
title: What Algorithms can Transformers Learn? A Study in Length Generalization
arxiv_id: '2310.16028'
source_url: https://arxiv.org/abs/2310.16028
tags:
- length
- generalization
- rasp-l
- which
- addition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies when Transformers can learn to solve algorithmic
  tasks through length generalization - applying learned algorithms to longer inputs
  than seen during training. The authors propose a "RASP-Generalization Conjecture"
  that Transformers tend to length generalize when a task can be solved by a short
  RASP-L program that works for all input lengths.
---

# What Algorithms can Transformers Learn? A Study in Length Generalization

## Quick Facts
- arXiv ID: 2310.16028
- Source URL: https://arxiv.org/abs/2310.16028
- Authors: 
- Reference count: 40
- Key outcome: This paper studies when Transformers can learn to solve algorithmic tasks through length generalization - applying learned algorithms to longer inputs than seen during training. The authors propose a "RASP-Generalization Conjecture" that Transformers tend to length generalize when a task can be solved by a short RASP-L program that works for all input lengths. RASP-L is a restricted programming language designed to be easily representable by Transformers. The authors validate this conjecture experimentally, showing Transformers length generalize on tasks with simple RASP-L solutions (like counting, mode, and sorting) but not on tasks without (like addition and parity). They also show how modifying tasks to have simpler RASP-L solutions improves length generalization. Finally, they give a theoretical example where their RASP-based notion of function simplicity better predicts Transformer generalization than a minimum-degree-interpolator model. Overall, the work provides a framework for understanding when Transformers can learn algorithms that generalize to longer sequences.

## Executive Summary
This paper investigates when Transformers can learn algorithmic tasks that generalize to longer sequences than seen during training (length generalization). The authors propose a framework based on a restricted programming language called RASP-L, arguing that Transformers tend to learn algorithms that can be expressed as short RASP-L programs. Through extensive experiments on tasks like counting, addition, and parity, they demonstrate that length generalization correlates strongly with the simplicity of the task's RASP-L representation. The work provides both theoretical insights and practical guidelines for understanding and improving algorithmic generalization in Transformers.

## Method Summary
The authors develop a theoretical framework based on RASP-L, a restricted programming language designed to capture operations naturally representable by Transformer attention layers. They systematically evaluate length generalization across various algorithmic tasks by training decoder-only Transformers on sequences up to a maximum length, then testing on longer sequences. For each task, they analyze whether it can be solved by a short RASP-L program that works for all input lengths. They also experiment with task reformatting (like adding index hints or changing output order) to simplify the RASP-L representation and improve generalization performance.

## Key Results
- Transformers show strong length generalization on counting, mode, and sorting tasks, which have simple RASP-L solutions
- Transformers fail to length generalize on addition and parity without modifications, as these require complex RASP-L programs
- Task reformatting (e.g., adding index hints, reversing output order for addition) can dramatically improve length generalization by simplifying the RASP-L representation
- The RASP-Generalization Conjecture better predicts Transformer generalization than minimum-degree-interpolator models in a theoretical example

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformers can learn algorithms that generalize to longer sequences when those algorithms can be expressed as short RASP-L programs.
- Mechanism: The RASP-L language is designed to capture operations that are naturally representable by Transformer attention layers. When a task can be solved by a short RASP-L program, it means the underlying computation can be implemented with a small number of attention layers, making it easier for Transformers to learn during training.
- Core assumption: RASP-L programs can be compiled into Transformer weights, and shorter RASP-L programs correspond to simpler Transformer architectures.
- Evidence anchors:
  - [abstract]: "we propose a unifying framework to predict when Transformers are likely to length-generalize... Transformers tend to length generalize on a task if the task can be solved by a short RASP program which works for all input lengths."
  - [section 2]: "Our conjecture proposes three conditions: 1) realizability, 2) simplicity, and 3) diversity. Simplicity implies realizability, as being able to come up with a RASP-L program for a task guarantees realizability."
  - [corpus]: "Average neighbor FMR=0.504" - indicates related work on length generalization, though specific evidence for RASP-L mechanism is limited in corpus
- Break condition: If the task requires operations that cannot be naturally expressed in RASP-L (like arbitrary arithmetic on indices or non-causal operations), the mechanism breaks down.

### Mechanism 2
- Claim: The RASP-Generalization Conjecture predicts length generalization based on whether a task has a simple RASP-L solution.
- Mechanism: When training data is diverse enough, Transformers will learn the simplest program that fits the training data. If this simplest program is a short RASP-L program that works for all input lengths, the model will length generalize.
- Core assumption: During training, Transformers will learn the shortest RASP-L program that fits the training data.
- Evidence anchors:
  - [abstract]: "Transformers tend to length generalize on a task if the task can be solved by a short RASP program which works for all input lengths."
  - [section 2]: "This toy model is similar to Minimum-Description-Length principles... we propose using a measure of complexity that specifically corresponds to the unique information-flow inside Transformer architectures."
  - [corpus]: Limited direct evidence, but related work on length generalization supports the general concept
- Break condition: If there exists a shorter RASP-L program that fits the training data but fails on longer sequences, the model may learn this suboptimal program instead.

### Mechanism 3
- Claim: Modifying tasks to have simpler RASP-L solutions improves length generalization performance.
- Mechanism: By reformating tasks (like adding index hints or reversing output order for addition), we can convert complex problems into ones with simple RASP-L solutions, enabling better generalization.
- Core assumption: Task reformatting can preserve the semantic meaning while making the computational structure more amenable to RASP-L representation.
- Evidence anchors:
  - [abstract]: "we leverage our insights to drastically improve generalization performance on traditionally hard tasks (such as parity and addition)."
  - [section 5]: "We evaluate addition in two settings: 'easy' carry and 'hard' carry... index hints allow both forward and reverse addition to length generalize on 'easy' carry."
  - [corpus]: Related work on task reformatting for length generalization exists but specific RASP-L evidence is limited
- Break condition: If reformatting makes the task too different from the original semantics, or if the new format introduces new complexities that don't simplify the RASP-L representation.

## Foundational Learning

- Concept: RASP-L programming language
  - Why needed here: RASP-L is the core framework for understanding which algorithms Transformers can learn. It provides a human-readable way to express Transformer-representable programs.
  - Quick check question: Can you explain why RASP-L restricts operations on indices but allows operations on values?

- Concept: Length generalization
  - Why needed here: The paper's central focus is understanding when Transformers can generalize from training on short sequences to correctly handling longer sequences.
  - Quick check question: What's the difference between a model that memorizes training sequences versus one that learns a generalizable algorithm?

- Concept: Transformer attention mechanism
  - Why needed here: Understanding how attention layers work is crucial for grasping why certain operations are easier or harder to represent in RASP-L.
  - Quick check question: How does the causal masking in attention layers affect what algorithms can be represented?

## Architecture Onboarding

- Component map:
  Input sequence -> Positional embeddings -> Multi-head attention layers -> Feed-forward layers -> Output sequence
  RASP-L programs compile to sequences of attention and feed-forward operations
  Key operations: elementwise maps, sequence maps, kqv (attention-like) operations

- Critical path:
  1. Define task and verify it can be expressed in RASP-L
  2. Implement RASP-L program for the task
  3. Train Transformer from scratch on diverse training data
  4. Evaluate length generalization performance
  5. If poor performance, analyze whether task can be reformatted for simpler RASP-L representation

- Design tradeoffs:
  - Learned positional embeddings vs. fixed positional encodings
  - Context packing during training vs. single-sequence training
  - Scratchpad usage (can simplify some tasks but may hurt others)

- Failure signatures:
  - No length generalization despite perfect training performance -> Task likely requires complex RASP-L program or cannot be expressed in RASP-L
  - Slow training convergence -> Task may require complex RASP-L program
  - Perfect in-distribution performance but poor out-of-distribution performance -> Training data may lack sufficient diversity

- First 3 experiments:
  1. Count task (should show strong length generalization)
  2. Addition task without any modifications (should show poor length generalization)
  3. Addition task with index hints and reversed output (should show improved length generalization)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the RASP-L language be extended to better capture numerical algorithms and operations beyond simple integer arithmetic?
- Basis in paper: [explicit] The authors note that RASP-L has limitations in representing numerical algorithms like in-context gradient descent and linear regression, which involve high-dimensional matrix and vector floating-point operations.
- Why unresolved: The paper does not propose solutions for extending RASP-L to handle such numerical operations.
- What evidence would resolve it: Developing an extended version of RASP-L that can represent and learn numerical algorithms, and demonstrating its effectiveness on tasks involving matrix operations or floating-point arithmetic.

### Open Question 2
- Question: What is the relationship between the complexity measures used in RASP-L (e.g., minimum program length) and the actual learning dynamics of Transformers?
- Basis in paper: [explicit] The authors propose that simpler RASP-L programs are more likely to be learned by Transformers, but acknowledge that this relationship is not fully understood.
- Why unresolved: The paper does not provide a formal analysis of how the complexity measures in RASP-L relate to the optimization process and generalization of Transformers.
- What evidence would resolve it: Developing a theoretical framework that connects RASP-L complexity to Transformer learning dynamics, and validating it with empirical studies.

### Open Question 3
- Question: How does the diversity of the training data influence the ability of Transformers to learn length-generalizing algorithms?
- Basis in paper: [explicit] The authors suggest that increasing data diversity can help Transformers learn more complex RASP-L programs, but do not provide a precise characterization of the required diversity.
- Why unresolved: The paper does not define or quantify the notion of "diversity" in a way that can be systematically studied.
- What evidence would resolve it: Conducting experiments that systematically vary the diversity of the training data and measuring its impact on length generalization performance.

### Open Question 4
- Question: Can the insights from RASP-L be applied to understand and improve compositional generalization beyond length generalization?
- Basis in paper: [explicit] The authors mention that their framework could potentially apply to compositional generalization more broadly, but do not explore this direction.
- Why unresolved: The paper focuses specifically on length generalization and does not investigate other forms of compositional generalization.
- What evidence would resolve it: Applying the RASP-L framework to other compositional generalization tasks and evaluating its effectiveness in predicting and improving performance.

### Open Question 5
- Question: How do architectural innovations and training methodologies (e.g., rotary positional embeddings) affect the learnability of RASP-L programs by Transformers?
- Basis in paper: [explicit] The authors use standard decoder-only Transformers with learned positional embeddings, but acknowledge that other factors could influence the generalization performance.
- Why unresolved: The paper does not investigate the impact of architectural or training variations on the ability of Transformers to learn RASP-L programs.
- What evidence would resolve it: Conducting experiments that compare the performance of different Transformer architectures and training methods on tasks with varying RASP-L complexity.

## Limitations

- The theoretical framework connecting RASP-L program simplicity to Transformer generalization remains largely intuitive rather than rigorously proven.
- The experimental validation does not systematically explore the full space of algorithmic tasks or provide statistical significance analysis across multiple runs.
- The relationship between RASP-L simplicity and Transformer learning dynamics is assumed rather than formally established.

## Confidence

- High Confidence: The empirical observations that Transformers show varying degrees of length generalization across different tasks (counting vs. addition vs. parity) are well-supported by the experimental results.
- Medium Confidence: The claim that task reformatting can improve length generalization is supported by the addition experiments but would benefit from more systematic exploration across multiple tasks.
- Low Confidence: The theoretical framework connecting RASP-L program simplicity to Transformer generalization remains largely intuitive rather than rigorously proven.

## Next Checks

1. **Systematic Ablation Study**: Conduct a comprehensive study varying RASP-L program complexity while keeping task semantics constant to isolate the effect of simplicity on generalization.

2. **Cross-Architecture Validation**: Test whether the RASP-Generalization Conjecture holds across different Transformer architectures (different depths, widths, attention patterns) to assess its robustness.

3. **Statistical Significance Analysis**: Run multiple trials for each task with different random seeds and compute confidence intervals for length generalization performance to establish statistical significance.