---
ver: rpa2
title: Data Augmentation for Neural Machine Translation using Generative Language
  Model
arxiv_id: '2307.16833'
source_url: https://arxiv.org/abs/2307.16833
tags:
- data
- augmentation
- sentence
- language
- original
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the challenge of data scarcity in Neural Machine
  Translation (NMT) by exploring prompt-based data augmentation using large language
  models like ChatGPT. Three methods are proposed: paraphrase, multi-target, and storytelling,
  each using different prompts to generate synthetic parallel data.'
---

# Data Augmentation for Neural Machine Translation using Generative Language Model

## Quick Facts
- arXiv ID: 2307.16833
- Source URL: https://arxiv.org/abs/2307.16833
- Authors: 
- Reference count: 7
- The storytelling method improves BLEU score by 0.68 compared to baseline.

## Executive Summary
This paper addresses data scarcity in Neural Machine Translation by leveraging ChatGPT for prompt-based data augmentation. Three methods—paraphrase, multi-target, and storytelling—are proposed to generate synthetic parallel data. The storytelling approach, which creates diverse sentences through story generation and translation, achieves the highest BLEU score improvement (29.17) without requiring additional model training. The method effectively increases data diversity while maintaining low computational overhead.

## Method Summary
The paper proposes three prompt-based data augmentation methods using ChatGPT to generate synthetic parallel data for NMT. The approach trains mBART-50 on a Korean-German financial domain corpus (20k training pairs), augmenting with synthetic data generated via paraphrase, multi-target translation, and storytelling prompts. The storytelling method produces the most diverse data by generating three-sentence stories from source sentences and translating them. Models are trained with AdamW optimizer (lr=2e-5), batch size 16, and evaluated using SacreBLEU.

## Key Results
- Storytelling method achieves highest BLEU score of 29.17, improving by 0.68 over baseline.
- Storytelling generates least similar sentences to originals, maximizing data diversity.
- All three augmentation methods improve BLEU scores compared to unaugmented baseline.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prompt-based data augmentation generates synthetic parallel data without model training overhead.
- Mechanism: ChatGPT produces paraphrased, translated, or story-based sentences used directly as training data.
- Core assumption: ChatGPT generates high-quality, linguistically valid output matching target domain and language pair.
- Evidence anchors: Abstract states no further model training cost required; section compares 3 methods using different prompts.
- Break condition: ChatGPT fails to produce grammatically correct or contextually appropriate sentences, or outputs are too dissimilar to training data distribution.

### Mechanism 2
- Claim: Storytelling prompts increase data diversity more than direct paraphrase or multi-target translation.
- Mechanism: Multi-sentence stories introduce varied syntactic and lexical patterns absent in original sentence pairs.
- Core assumption: Diverse sentence structures in stories map to richer training examples without introducing harmful noise.
- Evidence anchors: Section states storytelling generates least similar sentences to originals; storytelling achieves highest BLEU score of 29.17.
- Break condition: Generated stories drift too far from domain or introduce out-of-domain terminology, hurting performance.

### Mechanism 3
- Claim: Higher data diversity improves NMT model performance when original dataset is small.
- Mechanism: Augmenting with diverse synthetic data narrows gap between actual language distribution and training data distribution, improving generalization.
- Core assumption: Model capacity is sufficient to leverage increased diversity without overfitting or performance degradation.
- Evidence anchors: Section infers diverse data is necessary to narrow distribution gap; storytelling achieves highest BLEU score of 29.17.
- Break condition: Data diversity overwhelms model, causing confusion or catastrophic forgetting of core translation patterns.

## Foundational Learning
- Concept: BLEU score computation
  - Why needed here: Primary metric to compare baseline vs augmented models.
  - Quick check question: What is the baseline BLEU score before augmentation?
- Concept: Cosine similarity of sentence embeddings
  - Why needed here: Measures diversity between original and generated sentences.
  - Quick check question: Which method had the lowest cosine similarity?
- Concept: Prompt engineering for generative models
  - Why needed here: Different prompts produce different synthetic data qualities.
  - Quick check question: How many unique ways does the paraphrase prompt ask ChatGPT to rephrase?

## Architecture Onboarding
- Component map: OpenAI API -> ChatGPT (generative model) -> mBART-50 (translation backbone) -> LASER encoder (embedding for diversity measurement) -> SacreBLEU (evaluation metric)
- Critical path: 1. Generate synthetic data via ChatGPT prompts. 2. Filter/combine with original data. 3. Train mBART-50. 4. Evaluate BLEU.
- Design tradeoffs: Prompt complexity vs. output quality; synthetic data quantity vs. diversity; model capacity vs. augmentation scale.
- Failure signatures: BLEU score drops with more synthetic data (overfitting or harmful noise); low diversity metrics (prompts too conservative); API failures or timeouts (data pipeline broken).
- First 3 experiments: 1. Run each prompt method at 0.5x augmentation and compare BLEU. 2. Measure cosine similarity of each method's outputs vs. originals. 3. Compare storytelling vs. paraphrase at 1.0x augmentation with same model settings.

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How does the quality of synthetic data generated by ChatGPT compare to human-annotated data in terms of translation accuracy and linguistic naturalness?
- Basis in paper: [inferred] The paper discusses use of ChatGPT for generating synthetic parallel data but does not provide direct comparison with human-annotated data.
- Why unresolved: Study focuses on effectiveness of different prompt-based augmentation methods rather than detailed comparison with human-generated data.
- What evidence would resolve it: Comparative study evaluating translation accuracy and linguistic naturalness of synthetic data generated by ChatGPT against human-annotated data using metrics such as BLEU score, human evaluation, and linguistic analysis.

### Open Question 2
- Question: What is the impact of prompt complexity and specificity on the quality and diversity of the generated synthetic data?
- Basis in paper: [explicit] Paper discusses use of different prompts for data augmentation and their impact on data diversity.
- Why unresolved: While paper compares different prompts, it does not explore impact of varying complexity or specificity of prompts on generated data.
- What evidence would resolve it: Experimental study varying complexity and specificity of prompts and measuring impact on quality and diversity of generated synthetic data using metrics such as BLEU score, cosine similarity, and human evaluation.

### Open Question 3
- Question: How does the proposed prompt-based data augmentation approach scale to other language pairs and domains beyond Korean-German financial domain?
- Basis in paper: [inferred] Paper focuses on Korean-German language pair in financial domain, but does not explore applicability to other language pairs or domains.
- Why unresolved: Study is limited to specific language pair and domain, leaving generalizability of approach to other languages and domains unexplored.
- What evidence would resolve it: Conducting experiments using proposed approach with different language pairs and domains, and evaluating effectiveness in terms of translation accuracy and data diversity.

## Limitations
- Exact prompt templates used in storytelling method are not provided, limiting reproducibility.
- No direct comparison with human-annotated data to validate synthetic data quality.
- Experimental scope limited to Korean-German financial domain, raising questions about generalizability to other language pairs and domains.

## Confidence
- **High Confidence**: Storytelling method achieved best BLEU score (29.17) compared to baseline and other augmentation methods. Claim that prompt-based augmentation requires no additional model training is well-supported.
- **Medium Confidence**: Assertion that storytelling generates most diverse data is supported by similarity metrics, but diversity alone doesn't guarantee translation quality improvements without human evaluation.
- **Low Confidence**: Claim that generating diverse data is "necessary" to narrow gap between actual language distribution and training data lacks rigorous statistical backing or ablation studies showing diversity's direct impact on BLEU.

## Next Checks
1. Test multiple storytelling prompt variations (different story lengths, styles, or constraints) to verify specific prompt used is optimal and not just one of many that could work.
2. Calculate total API costs for generating augmented data at different scales and compare against BLEU improvement to assess practical viability for real-world deployment.
3. Apply best-performing augmentation method to a non-financial domain (e.g., news or conversational text) using same language pair to evaluate whether approach generalizes beyond tested corpus.