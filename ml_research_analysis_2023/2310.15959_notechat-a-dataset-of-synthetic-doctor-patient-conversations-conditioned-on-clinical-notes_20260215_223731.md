---
ver: rpa2
title: 'NoteChat: A Dataset of Synthetic Doctor-Patient Conversations Conditioned
  on Clinical Notes'
arxiv_id: '2310.15959'
source_url: https://arxiv.org/abs/2310.15959
tags:
- patient
- medical
- doctor
- clinical
- notechat
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces NoteChat, a cooperative multi-agent framework
  leveraging Large Language Models (LLMs) to generate synthetic doctor-patient conversations
  conditioned on clinical notes. The method combines Planning, Roleplay, and Polish
  modules, where multiple ChatGPT agents take on doctor and patient roles, guided
  by structured knowledge planning and iterative refinement.
---

# NoteChat: A Dataset of Synthetic Doctor-Patient Conversations Conditioned on Clinical Notes

## Quick Facts
- **arXiv ID:** 2310.15959
- **Source URL:** https://arxiv.org/abs/2310.15959
- **Reference count:** 33
- **Key outcome:** Introduces NoteChat, a cooperative multi-agent framework using LLMs to generate synthetic doctor-patient conversations from clinical notes, outperforming state-of-the-art models by up to 22.78% in domain expert preference rankings.

## Executive Summary
This paper introduces NoteChat, a cooperative multi-agent framework leveraging Large Language Models (LLMs) to generate synthetic doctor-patient conversations conditioned on clinical notes. The method combines Planning, Roleplay, and Polish modules, where multiple ChatGPT agents take on doctor and patient roles, guided by structured knowledge planning and iterative refinement. Evaluated on the MTS-dialogue benchmark, NoteChat outperforms state-of-the-art models like ChatGPT and GPT-4 by up to 22.78% according to domain expert preference rankings. It generates more diverse, colloquial, and factually consistent dialogues, demonstrating the potential of LLM cooperation for high-quality synthetic medical conversation generation.

## Method Summary
NoteChat employs a three-module pipeline: Planning (extracts UMLS CUIs from clinical notes, builds a checklist of key concepts, and guides conversation flow), Roleplay (two ChatGPT agents generate doctor and patient utterances round by round), and Polish (refines dialogue based on expert preferences through self-reflection). The framework uses clinical notes from PMC-Patients (167K) and MTS-Dialog (1.7K with 87 complete dialogues) as input, with CUI-based keyword extraction to guide conversation generation. The output is synthetic doctor-patient conversations evaluated through intrinsic metrics (ROUGE, factuality, extractiveness, diversity) and extrinsic evaluation (LLaMA-7B fine-tuning and GPT-4 preference ranking).

## Key Results
- NoteChat outperforms ChatGPT and GPT-4 by up to 22.78% in GPT-4 preference ranking on MTS-Dialog benchmark
- Generates more diverse and colloquial dialogues compared to baselines, with improved Self-BLEU scores
- Achieves higher factuality and extractiveness scores, with CUI-based precision/recall/F1 improvements
- Synthetic data from NoteChat improves fine-tuning of LLaMA-7B, demonstrating practical utility

## Why This Works (Mechanism)

### Mechanism 1
Role-specific LLM agents cooperate to generate more diverse and medically accurate dialogue. Two LLMs play distinct roles (doctor and patient) with tailored prompts, enabling domain-appropriate language and logical flow. Separating roles and giving each a specific prompt prevents role confusion and improves diversity. Break condition: If the LLM prompt for one role fails to capture necessary medical knowledge or patient language, the generated dialogue becomes factually inaccurate or unengaging.

### Mechanism 2
Planning module ensures logical flow and factuality by extracting clinical concepts and guiding conversation. Extract UMLS CUIs from clinical notes, build a checklist of key concepts, and guide the dialogue generation around them. LLMs can generate coherent dialogue if given a structured checklist of medically relevant concepts. Break condition: If CUI extraction misses important concepts or includes too many irrelevant ones, the conversation becomes either incomplete or overly detailed.

### Mechanism 3
Polish module improves naturalness and alignment with expert preferences through iterative refinement. LLM re-examines generated dialogue against 10 expert-defined rules (e.g., colloquial style, logical questioning) and refines it. LLMs can self-correct dialogue to better match human preferences when explicitly prompted to do so. Break condition: If the Polish module over-corrects or misunderstands expert preferences, the dialogue may lose coherence or become too generic.

## Foundational Learning

- **Large Language Models (LLMs)**: Form the core of all three modules (Planning, Roleplay, Polish) and enable synthetic dialogue generation. *Quick check:* What are the key differences between ChatGPT and GPT-4 that would impact medical dialogue generation?

- **Clinical Note Structure (SOAP)**: Clinical notes are the input data, and the SOAP structure guides how information is organized and extracted. *Quick check:* How does the SOAP structure help in planning the logical flow of a doctor-patient conversation?

- **Clinical Uniform Identifier (CUI)**: Used to extract key medical concepts from clinical notes and guide the dialogue generation. *Quick check:* What are the benefits and limitations of using CUIs for medical concept extraction in dialogue generation?

## Architecture Onboarding

- **Component map:** Clinical note → CUI extraction → Planning checklist → Roleplay dialogue → Polish refinement → Final output
- **Critical path:** Clinical note → CUI extraction → Planning checklist → Roleplay dialogue → Polish refinement → Final output
- **Design tradeoffs:** LLM choice (ChatGPT vs GPT-4) impacts cost and quality; CUI extraction accuracy affects factuality and completeness; number of Polish iterations balances quality vs. cost
- **Failure signatures:** Factual errors (missing or incorrect medical concepts); role confusion (doctor sounding like patient or vice versa); lack of coherence (dialogue jumps between unrelated topics); over-formality (dialogue sounds too clinical and unnatural)
- **First 3 experiments:**
  1. Test CUI extraction on a small set of clinical notes and verify accuracy
  2. Run Planning module with sample notes and check if checklist covers key concepts
  3. Generate sample dialogue with Roleplay module and evaluate for role-specific language

## Open Questions the Paper Calls Out

- How does NoteChat handle cases where the clinical note contains conflicting or ambiguous information that could lead to multiple valid diagnostic paths?
- What is the impact of using different temperature settings in the LLM on the diversity and quality of generated conversations, and how was the optimal temperature of 0.7 determined?
- How does the performance of NoteChat compare when using different underlying LLM models (e.g., GPT-4, Claude, LLaMA) for the Planning, Roleplay, and Polish modules?
- What is the long-term impact of using NoteChat-generated synthetic data for fine-tuning medical chatbots, particularly regarding potential propagation of biases or generation of incorrect medical information?

## Limitations

- Incomplete methodological details, particularly prompt templates for Planning, Roleplay, and Polish modules
- Evaluation focuses on synthetic data quality rather than real-world deployment considerations
- Does not address potential biases in synthetic dialogue generation or safety considerations for medical applications

## Confidence

- **High Confidence:** Cooperative multi-agent framework architecture; 22.78% improvement in GPT-4 preference ranking; CUI-based keyword extraction
- **Medium Confidence:** Role-specific LLM agents significantly improve diversity and medical accuracy; Polish module's effectiveness in improving naturalness
- **Low Confidence:** Generalization to real clinical settings; cost-effectiveness of multi-agent approach compared to simpler alternatives

## Next Checks

1. Implement the exact prompt templates from Tables 12, 13, and 14 to verify that the Planning, Roleplay, and Polish modules function as described and reproduce the reported improvements.

2. Conduct an ablation study comparing NoteChat's two-agent approach against a single-agent baseline to isolate the specific contribution of role separation to dialogue quality improvements.

3. Generate extended dialogues (20+ turns) to test whether the Planning module's checklist-based approach maintains coherence and prevents topic drift in longer conversations.