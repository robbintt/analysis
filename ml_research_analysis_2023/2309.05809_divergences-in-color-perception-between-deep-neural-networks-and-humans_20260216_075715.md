---
ver: rpa2
title: Divergences in Color Perception between Deep Neural Networks and Humans
arxiv_id: '2309.05809'
source_url: https://arxiv.org/abs/2309.05809
tags:
- color
- image
- wavelet
- images
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Deep neural networks (DNNs) are increasingly used as models of
  human vision, but their ability to capture fundamental aspects like color perception
  remains unclear. This study develops novel experiments to evaluate the perceptual
  coherence of color embeddings in DNNs and compares them to human color similarity
  judgments collected via an online survey.
---

# Divergences in Color Perception between Deep Neural Networks and Humans

## Quick Facts
- arXiv ID: 2309.05809
- Source URL: https://arxiv.org/abs/2309.05809
- Authors: 
- Reference count: 40
- Key outcome: State-of-the-art DNN architectures provide color similarity judgments that diverge from human judgments, while wavelet algorithms better predict human color perception

## Executive Summary
Deep neural networks are increasingly used as models of human vision, but their ability to capture fundamental aspects like color perception remains unclear. This study develops novel experiments to evaluate the perceptual coherence of color embeddings in DNNs and compares them to human color similarity judgments collected via an online survey. The researchers find that state-of-the-art DNN architectures, including convolutional neural networks and vision transformers, provide color similarity judgments that diverge from human judgments across three image datasets. They compare DNN performance to an interpretable wavelet algorithm inspired by computational neuroscience theories, finding that the wavelet approach consistently provides more coherent color embeddings that better predict human color judgments.

## Method Summary
The study compares color perception between DNNs and humans using three image datasets: controlled block/stripe images, Google Image-derived colorgrams, and CIFAR-10 images. Images are processed through four algorithms: wavelet transforms, a ResNet classification network, a style transfer network, and a vision transformer. For each algorithm, k-means clustering is applied to embeddings to group images by visual similarity, and color coherence within clusters is measured using JzAzBz color space. Results are validated against human similarity judgments collected through an online survey where participants ranked color similarity of image pairs.

## Key Results
- DNNs consistently diverge from human color similarity judgments across all tested datasets
- Wavelet algorithms outperform all DNNs in predicting human color perception
- Style transfer networks perform better than classification networks on color tasks
- Findings hold across different DNN training tasks and layers

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Wavelet transforms capture perceptually relevant color and texture features more effectively than DNNs because they decompose images into multi-scale frequency components aligned with human visual processing.
- **Mechanism:** The Morlet wavelet family used in the algorithm performs convolutions at multiple spatial scales and orientations, preserving both low-level frequency information and spatial relationships that correlate with human color perception.
- **Core assumption:** Human color perception is fundamentally based on frequency analysis of visual input, similar to how wavelet transforms decompose signals.
- **Evidence anchors:**
  - [abstract]: "foundational work in computational neuroscience shows that wavelet transforms capture properties of human vision, including the perception of color and texture"
  - [section]: "wavelet transforms comprise a simple learning architecture that is aptly positioned to efficiently detect and preserve frequency information, including that contained in color channels"
  - [corpus]: Weak - the corpus neighbors don't directly address wavelet-based approaches, though they discuss vision benchmarks and human perception alignment
- **Break condition:** If human color perception relies primarily on higher-level categorical processing rather than raw frequency decomposition, wavelet approaches would lose their advantage.

### Mechanism 2
- **Claim:** DNNs trained on image classification tasks drop color information because their optimization objectives prioritize texture and shape features over color for object recognition.
- **Mechanism:** During training, classification loss functions naturally favor features that maximize accuracy for object categories, which often rely more on shape/texture than color, leading to color information being discarded early in the network hierarchy.
- **Core assumption:** The classification objective implicitly devalues color features compared to shape and texture features for most object recognition tasks.
- **Evidence anchors:**
  - [abstract]: "DNNs are biased toward perceiving images based on the spatial arrangement of pixel luminosities—i.e., image texture—rather than in terms of color"
  - [section]: "DNNs frequently develop complex and high-dimensional representations to solve such tasks... it remains difficult to isolate the perceptual processes and basic image features that DNNs leverage"
  - [corpus]: Weak - corpus papers focus on DNN robustness and alignment but don't specifically address why color information is lost during classification training
- **Break condition:** If classification tasks were redesigned to equally weight color features, or if color invariance was explicitly penalized during training, DNNs might retain color information better.

### Mechanism 3
- **Claim:** The perceptually uniform color space (JzAzBz) used by the wavelet algorithm improves color representation because Euclidean distances in this space match human perceptible differences in color.
- **Mechanism:** By transforming RGB values into JzAzBz space before processing, the algorithm ensures that geometric distances between colors in the transformed space correspond to actual perceptual differences humans experience.
- **Core assumption:** The JzAzBz color space accurately models human color perception such that perceptual similarity can be measured through Euclidean distance.
- **Evidence anchors:**
  - [section]: "JzAzBz color space... Euclidean distances between colors linearly map onto differences in human color vision, unlike standard color spaces like RGB"
  - [section]: "our measure captures perceptual differences in color similarity and is not arbitrary"
  - [corpus]: Weak - corpus neighbors don't discuss color space transformations or perceptual uniformity
- **Break condition:** If the JzAzBz color space transformation introduces computational artifacts or if human color perception varies significantly across individuals, the uniformity assumption would break down.

## Foundational Learning

- **Concept:** Wavelet decomposition and multi-scale analysis
  - Why needed here: Understanding how wavelet transforms decompose images into frequency components at different scales is crucial for grasping why this approach captures color and texture better than DNNs
  - Quick check question: What distinguishes wavelet transforms from Fourier transforms in terms of spatial localization of frequency information?

- **Concept:** Color spaces and perceptual uniformity
  - Why needed here: The JzAzBz color space is central to the algorithm's success, and understanding how different color spaces relate to human perception is key to interpreting the results
  - Quick check question: How does Euclidean distance in RGB space differ from perceptual distance in JzAzBz space for colors with the same luminance?

- **Concept:** DNN architecture and training objectives
  - Why needed here: Understanding how different training objectives (classification vs. style transfer) affect what features DNNs prioritize helps explain why some DNNs perform better than others on color tasks
  - Quick check question: Why might a style transfer network retain more color information than an image classification network?

## Architecture Onboarding

- **Component map:** Images → Algorithms (wavelet, ResNet, style transfer, vision transformer) → Embeddings → k-means clustering → JzAzBz color analysis → Color coherence calculation → Human judgment comparison

- **Critical path:** Image → Algorithm embedding → k-means clustering → JzAzBz color similarity calculation → Color coherence fraction calculation → Human judgment comparison

- **Design tradeoffs:** Wavelet approach trades computational complexity and learned abstraction capability for interpretability and perceptual alignment; DNNs trade interpretability for task performance but lose color fidelity in the process.

- **Failure signatures:** Poor color coherence fractions (low f values), high overlap in color space clustering, weak correlation between embedding similarity and color similarity, and failure to predict human color judgments above random chance.

- **First 3 experiments:**
  1. Run the wavelet algorithm on a simple synthetic dataset with known color relationships to verify it captures perceptual similarity correctly
  2. Compare the color coherence of a DNN trained with color as a primary objective versus one trained on standard classification
  3. Test the wavelet algorithm on grayscale versions of the same images to confirm color information is the primary driver of its performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does training objective specifically impact color perception capabilities in DNNs?
- Basis in paper: [explicit] The paper notes that the style transfer DNN performed better at color perception than image classification DNNs, suggesting training objectives affect color representation.
- Why unresolved: While the paper shows one example of style transfer DNN outperforming others, it doesn't systematically test different training objectives across multiple architectures.
- What evidence would resolve it: Controlled experiments training identical DNN architectures on different tasks (classification, segmentation, style transfer) and comparing their color representation capabilities.

### Open Question 2
- Question: Do earlier layers in DNNs retain better color information than later layers?
- Basis in paper: [explicit] The paper states "recent work suggests that earlier layers of DNNs may better represent color" but finds in supplementary analysis that deeper layers perform better.
- Why unresolved: The paper only tested one DNN architecture (ResNet) and found conflicting results with prior research.
- What evidence would resolve it: Systematic testing of multiple DNN architectures at different layers to determine if there's a consistent pattern in how color information is preserved or degraded.

### Open Question 3
- Question: Can integrating wavelet transforms into DNN architectures improve their color perception?
- Basis in paper: [inferred] The wavelet algorithm outperformed all tested DNNs in color perception, suggesting wavelet properties are beneficial.
- Why unresolved: The paper only compared a standalone wavelet algorithm to DNNs, not integrated wavelet-DNN hybrid architectures.
- What evidence would resolve it: Experiments comparing standard DNNs to wavelet-enhanced DNNs in terms of color perception accuracy and other visual tasks.

## Limitations
- Small human judgment sample size limits statistical power
- Focus on color perception in isolation rather than integrated visual processing
- Wavelet algorithm's advantage may stem partly from perceptual color space rather than architecture

## Confidence
- Core claim (DNNs diverge from human color perception): Medium-High
- Mechanism explanations: Medium
- Wavelet superiority over DNNs: Medium-High
- Generalizability across architectures: Medium

## Next Checks
1. **Generalization testing**: Apply the wavelet and DNN algorithms to additional image datasets (e.g., ImageNet, COCO) to verify that color coherence advantages generalize beyond the current datasets.

2. **Ablation studies**: Remove the JzAzBz color space transformation from the wavelet algorithm to quantify how much of its advantage derives from the color space choice versus the wavelet decomposition itself.

3. **Fine-tuning experiments**: Fine-tune DNNs on color similarity tasks using human judgments as training targets to determine if color perception gaps can be closed through targeted training.