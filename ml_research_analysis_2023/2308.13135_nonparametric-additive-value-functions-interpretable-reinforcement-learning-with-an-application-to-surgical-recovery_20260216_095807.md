---
ver: rpa2
title: 'Nonparametric Additive Value Functions: Interpretable Reinforcement Learning
  with an Application to Surgical Recovery'
arxiv_id: '2308.13135'
source_url: https://arxiv.org/abs/2308.13135
tags:
- latexit
- policy
- function
- sha1
- base64
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a nonparametric additive model for estimating
  interpretable value functions in reinforcement learning. The method extends Least
  Squares Policy Iteration (LSPI) by replacing the linear action-value function with
  a nonparametric additive model, allowing for nonlinear feature interactions and
  local approximation.
---

# Nonparametric Additive Value Functions: Interpretable Reinforcement Learning with an Application to Surgical Recovery

## Quick Facts
- arXiv ID: 2308.13135
- Source URL: https://arxiv.org/abs/2308.13135
- Reference count: 14
- Key outcome: This paper introduces a nonparametric additive model for estimating interpretable value functions in reinforcement learning, validated through a simulation study and applied to post-operative recovery in spine disease patients.

## Executive Summary
This paper introduces a nonparametric additive model for estimating interpretable value functions in reinforcement learning, extending Least Squares Policy Iteration (LSPI) by replacing the linear action-value function with a nonparametric additive model. The method uses a kernel-weighted least squares fixed point approximation with a hybrid ℓ1/ℓ2-group Lasso penalty to obtain a sparse representation of the action-value function. The approach is validated through a simulation study and applied to a real-world digital phenotyping study of post-operative recovery in spine disease patients, successfully recovering nonlinear marginal and joint effects of state features and actions aligned with clinical knowledge.

## Method Summary
The method extends LSPI by replacing the linear action-value function with a nonparametric additive model using B-spline basis expansion. A kernel-weighted least squares fixed point approximation with group Lasso regularization is used to estimate the action-value function locally. The approach handles both discrete and continuous action spaces and provides interpretable component functions that can be directly inspected. The algorithm consists of a policy evaluation step using kernel-sieve hybrid least squares temporal difference learning (KSH-LSTDQ) and a policy improvement step via greedy action selection.

## Key Results
- The nonparametric additive model successfully recovers nonlinear marginal and joint effects of state features and actions in both simulation and real-world applications
- The method provides interpretable recommendations aligned with clinical knowledge for post-operative recovery in spine disease patients
- The approach demonstrates competitive performance compared to neural network baselines while maintaining interpretability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The nonparametric additive value function can approximate complex reward structures by summing nonlinear, interpretable component functions of state features and actions.
- Mechanism: By expanding the input space to include a candidate variable x and using B-spline basis expansion with kernel-weighted least squares, the model estimates marginal and joint effects locally, avoiding linearity assumptions.
- Core assumption: The true action-value function is additive in state features and actions, allowing decomposition into interpretable components.
- Evidence anchors:
  - [abstract] "Our novel method offers a flexible technique for estimating action-value functions without explicit parametric assumptions, overcoming the limitations of the linearity assumption of classical algorithms."
  - [section] "We model the action-value function using a centered B-spline basis expansion of the additive component functions."
- Break condition: If the true value function is not additive, the model will suffer from approximation error and miss important interactions.

### Mechanism 2
- Claim: The kernel-sieve hybrid approach enables sparse estimation of component functions while maintaining local smoothness.
- Mechanism: A hybrid ℓ1/ℓ2-group Lasso penalty is applied to the kernel-weighted least squares objective, performing group-level variable selection and shrinkage on B-spline coefficients.
- Core assumption: The underlying component functions are sparse and can be well-approximated by a few B-spline basis functions.
- Evidence anchors:
  - [abstract] "By incorporating local kernel regression and basis expansion, we obtain a sparse, additive representation of the action-value function."
  - [section] "We apply a penalty to an estimating equation Lz(β+) of (3.11). Being that components of our basis functions are grouped by features, we incorporate a group Lasso penalty that performs group level variable selection."
- Break condition: If the true functions are dense or require many basis functions, the Lasso penalty may lead to underfitting and loss of accuracy.

### Mechanism 3
- Claim: Approximate policy iteration using the kernel-weighted fixed point approximation yields an interpretable, improved policy.
- Mechanism: After estimating Qπ(s,a,x) locally for each value of x, the policy improvement step greedily selects actions maximizing the estimated value, allowing direct inspection of policy behavior as a function of candidate variables.
- Core assumption: The kernel-weighted projection preserves the Bellman fixed point structure sufficiently for policy improvement.
- Evidence anchors:
  - [abstract] "Under this approach, we are able to locally approximate the action-value function and retrieve the nonlinear, independent contribution of select features as well as joint feature pairs."
  - [section] "The policy improvement step follows by using the recently approximated action-value function Qπt to generate the new greedy policy πt+1."
- Break condition: If the kernel bandwidth is too large or the basis expansion is too coarse, the fixed point approximation may be poor, leading to suboptimal or unstable policy improvement.

## Foundational Learning

- Concept: Markov Decision Process (MDP) definition and Bellman equation
  - Why needed here: The entire RL framework relies on modeling the MDP tuple (S,A,P,R,γ) and the Bellman operator to define value functions and policy iteration.
  - Quick check question: What is the Bellman equation for the action-value function Qπ(s,a)?
- Concept: Function approximation and basis expansion in RL
  - Why needed here: The paper replaces linear function approximators with B-spline basis expansions to model nonlinear components.
  - Quick check question: How does a B-spline basis expansion approximate a nonlinear function?
- Concept: Kernel-weighted regression and local smoothing
  - Why needed here: The method uses kernel weights to focus on local regions of the state space when estimating component functions.
  - Quick check question: What is the role of the bandwidth parameter h in kernel-weighted regression?

## Architecture Onboarding

- Component map: MDP environment (S,A,P,R,γ) -> Dataset of transitions D = {(s[i],a[i],r[i],s[i]',x[i])} -> Kernel-weighted least squares estimator (KSH-LSTDQ) -> Group Lasso penalty for sparsity -> B-spline basis expansion for function representation -> Policy iteration loop (KSH-LSPI)
- Critical path:
  1. Preprocess data and construct feature matrix Φ
  2. For each value of x in grid Z:
     - Construct kernel-weight matrix Wz
     - Solve kernel-weighted least squares with group Lasso
     - Retrieve component function estimates
  3. Perform policy iteration until convergence
- Design tradeoffs:
  - Choice of kernel bandwidth h vs. bias-variance tradeoff in local estimates
  - Number of B-spline basis functions vs. smoothness and interpretability
  - Regularization strength λ vs. sparsity and model fit
- Failure signatures:
  - Poor policy improvement: overly smooth or biased component estimates
  - Sparsity issues: Lasso selects wrong components or over-shrinks important features
  - Local approximation error: kernel bandwidth too large or too small
- First 3 experiments:
  1. Fit model with h=0.01, λ=1 on synthetic additive reward MDP; compare estimated vs. true components.
  2. Vary h across orders of magnitude; observe effect on smoothness and accuracy.
  3. Replace group Lasso with ℓ2 penalty; measure change in sparsity and policy performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of the choice of kernel function (e.g., Gaussian, Epanechnikov) on the performance of the KSH-LSPI algorithm in estimating action-value functions?
- Basis in paper: [inferred] The paper mentions using a Gaussian kernel but does not explore the impact of other kernel functions.
- Why unresolved: The paper does not provide a comparison of different kernel functions or their effects on the algorithm's performance.
- What evidence would resolve it: A systematic comparison of the KSH-LSPI algorithm's performance using different kernel functions (e.g., Gaussian, Epanechnikov, uniform) on a benchmark reinforcement learning task.

### Open Question 2
- Question: How does the KSH-LSPI algorithm's performance scale with the dimensionality of the state space, and what are the computational bottlenecks in high-dimensional settings?
- Basis in paper: [inferred] The paper demonstrates the algorithm's performance on a simulation study with a 5-dimensional state space but does not explore its scalability to higher dimensions.
- Why unresolved: The paper does not provide an analysis of the algorithm's computational complexity or its performance on MDPs with high-dimensional state spaces.
- What evidence would resolve it: A thorough analysis of the KSH-LSPI algorithm's computational complexity and its performance on MDPs with varying state space dimensions, along with an identification of potential bottlenecks.

### Open Question 3
- Question: How does the KSH-LSPI algorithm handle continuous action spaces compared to discrete action spaces, and what are the trade-offs in terms of performance and interpretability?
- Basis in paper: [explicit] The paper mentions handling both discrete and continuous action spaces but does not provide a detailed comparison of their performance and interpretability.
- Why unresolved: The paper does not offer a comprehensive analysis of the algorithm's performance and interpretability when applied to continuous action spaces versus discrete action spaces.
- What evidence would resolve it: A detailed comparison of the KSH-LSPI algorithm's performance and interpretability when applied to MDPs with continuous and discrete action spaces, including an analysis of the trade-offs between the two settings.

## Limitations

- The strong additive assumption may fail to capture complex, non-additive interactions between state features, particularly in high-dimensional spaces
- The method relies on local approximation which may suffer from poor performance when kernel bandwidth or basis expansion is not well-tuned
- The real-world application is based on a limited dataset (67 patients) and may not generalize to broader patient populations or different surgical contexts

## Confidence

- **High confidence**: The theoretical foundation of the kernel-weighted least squares approach and its connection to the Bellman fixed point approximation is well-established and mathematically sound
- **Medium confidence**: The simulation study demonstrates the method's effectiveness in recovering known marginal and joint effects, but results are based on a specific MDP design
- **Low confidence**: The real-world application to post-operative recovery is based on a limited dataset and specific hyperparameters are not fully disclosed

## Next Checks

1. **Robustness to Non-Additive Effects**: Evaluate the method's performance on MDPs with known non-additive reward structures or complex feature interactions. Compare the estimated component functions to the true underlying functions using metrics such as mean squared error and interpretability measures like sparsity and smoothness.

2. **Hyperparameter Sensitivity Analysis**: Conduct a systematic study of the method's sensitivity to the choice of kernel bandwidth, number of B-spline basis functions, and regularization parameter. Assess the impact of these hyperparameters on the estimated component functions, policy performance, and computational efficiency.

3. **External Validation on Diverse Healthcare Datasets**: Apply the KSH-LSPI method to multiple real-world healthcare datasets with different patient populations, medical conditions, and data collection protocols. Compare the estimated effects and policy recommendations to existing clinical guidelines and expert opinions. Evaluate the method's ability to provide actionable insights and support personalized treatment decisions in various healthcare contexts.