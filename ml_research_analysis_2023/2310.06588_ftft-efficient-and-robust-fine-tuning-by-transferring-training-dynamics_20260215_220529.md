---
ver: rpa2
title: 'FTFT: Efficient and Robust Fine-Tuning by Transferring Training Dynamics'
arxiv_id: '2310.06588'
source_url: https://arxiv.org/abs/2310.06588
tags:
- training
- reference
- large
- main
- different
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the transferability of training dynamics in
  the data map (DM) method for improving the robustness of fine-tuned language models.
  The authors show that training dynamics are highly transferable across different
  model sizes and pre-training methods.
---

# FTFT: Efficient and Robust Fine-Tuning by Transferring Training Dynamics

## Quick Facts
- **arXiv ID**: 2310.06588
- **Source URL**: https://arxiv.org/abs/2310.06588
- **Reference count**: 21
- **Key outcome**: FTFT achieves better generalization robustness than ERM while spending less than half of the training cost.

## Executive Summary
This paper introduces FTFT (Fine-Tuning by Transferring Training dynamics), a novel fine-tuning approach that improves both efficiency and robustness of language models. The method leverages the observation that training dynamics are transferable across different model sizes and pre-training methods. By using efficient reference models to identify ambiguous training instances and fine-tuning main models on these subsets for fewer steps, FTFT achieves superior out-of-distribution performance compared to standard empirical risk minimization while reducing computational cost by more than 50%.

## Method Summary
FTFT uses efficient reference models to identify ambiguous training instances through training dynamics tracking, then fine-tunes main models on these subsets for fewer steps. The method builds on data map (DM) techniques, which partition training data based on prediction probability trajectories across epochs. FTFT specifically uses the ambiguous subset (identified as the most informative) for main model fine-tuning, reducing the number of training steps to one-third of standard ERM while maintaining or improving OOD robustness.

## Key Results
- FTFT achieves better generalization robustness than ERM on both ID and OOD datasets
- Main models trained with DM-identified subsets learn faster than ERM models
- FTFT spends less than half the training cost compared to ERM
- Training dynamics are highly transferable across model sizes and pre-training methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Training dynamics (e.g., prediction probability trajectories) are transferable across model sizes and pre-training methods.
- Mechanism: The subset of data identified as "ambiguous" or "hard-to-learn" by a reference model shares substantial overlap with the same subsets identified by a main model, even if the two models differ in size or architecture. This allows the reference model to act as a proxy for identifying informative training instances without training the main model on the full dataset.
- Core assumption: The ambiguity of a training instance is at least partially intrinsic to the data, not solely dependent on the model's capacity or pre-training method.
- Evidence anchors:
  - [abstract] "training dynamics are highly transferable across model sizes and pre-training methods"
  - [section 4.1] "training dynamics are transferable across different model sizes : When using DeBERTaV3Large as the main model, changing the reference model from DeBERTaV3Large to DeBERTaV3Small or DeBERTaV3Base yields comparable performance"
- Break condition: If the reference model is too weak (e.g., TinyBERT or ELECTRA Small in some settings), it may misclassify easy examples as ambiguous, leading to degraded OOD performance.

### Mechanism 2
- Claim: Main models trained using DM-identified subsets learn faster than models trained with ERM on the full dataset.
- Mechanism: The DM method focuses training on the most informative instances (ambiguous and hard-to-learn), avoiding redundant updates on easy examples that the model already classifies correctly. This accelerates convergence and reduces the number of training steps needed to achieve high performance.
- Core assumption: Easy examples provide diminishing returns for model performance, especially on OOD data.
- Evidence anchors:
  - [abstract] "main models fine-tuned using DM learn faster than empirical risk minimization (ERM)"
  - [section 5] "Figure 2 shows the OOD test performance of ELECTRA Large fine-tuned with fewer steps... DM methods learns much faster than ERM"
- Break condition: If the DM subset is too small or poorly selected, the model may underfit and fail to generalize well.

### Mechanism 3
- Claim: The effectiveness of a reference model for FTFT can be predicted by the proportion of easy instances it identifies.
- Mechanism: Effective reference models tend to identify a higher ratio of training instances as easy, indicating they have sufficient capacity to fit the data. Weak models often misclassify easy examples as ambiguous, which leads to failed transfers.
- Core assumption: There is a correlation between reference model strength and its ability to distinguish easy from hard data.
- Evidence anchors:
  - [section 4.3] "The key difference between effective and ineffective reference models lies in their ability to identify easy cases: TinyBERT identifies less easy data than other models"
  - [section 4.3] "reference models of clearly worse performance lead to degraded OOD performance for the main models"
- Break condition: If a reference model is too strong relative to the main model, it might overfit and identify a different set of ambiguous instances, breaking transferability.

## Foundational Learning

- Concept: Training dynamics tracking
  - Why needed here: The method relies on monitoring per-instance prediction probabilities across training epochs to identify ambiguous, hard-to-learn, and easy examples.
  - Quick check question: What metric is used to define an instance as "ambiguous" in DM?
- Concept: Data map (DM) partitioning
  - Why needed here: DM divides the dataset into subsets based on training dynamics, and the method selects only the ambiguous subset for main model fine-tuning.
  - Quick check question: Which subset (ambiguous, hard-to-learn, or easy) does FTFT use for fine-tuning?
- Concept: Model transferability and robustness
  - Why needed here: FTFT exploits transferability to reduce computational cost while maintaining or improving robustness on OOD data.
  - Quick check question: What is the main advantage of using a smaller, more efficient reference model in FTFT?

## Architecture Onboarding

- Component map:
  Reference model training (efficient PLM) -> Training dynamics collection (per-instance p_true tracking) -> Data map construction (thresholding on std/mean of p_true) -> Main model fine-tuning (on ambiguous subset, fewer steps) -> Evaluation (ID and OOD datasets)
- Critical path:
  1. Train reference model
  2. Track training dynamics
  3. Build data map
  4. Fine-tune main model on ambiguous subset
  5. Evaluate performance
- Design tradeoffs:
  - Reference model size vs. efficiency: smaller models train faster but may be less effective at identifying ambiguous data
  - Subset size (q%) vs. robustness: larger q% may improve robustness but increase cost
  - Training steps for main model: fewer steps reduce cost but risk underfitting
- Failure signatures:
  - OOD performance drops significantly relative to ID performance
  - Reference model identifies very few easy examples (suggesting it is too weak)
  - Main model fails to converge on ambiguous subset
- First 3 experiments:
  1. Train a small PLM (e.g., DeBERTaV3Small) as reference model and track training dynamics
  2. Build data map with q% = 33% and verify overlap of ambiguous instances with a larger model
  3. Fine-tune a large PLM (e.g., DeBERTaV3Large) on the ambiguous subset for 1/3 of ERM steps and evaluate on ID and OOD data

## Open Questions the Paper Calls Out
- What is the minimum strength threshold for a reference model to effectively transfer training dynamics?
- Does the 1/3 training step reduction in FTFT generalize across different tasks and datasets?
- How does the ambiguous/hard-to-learn data overlap ratio affect FTFT performance?
- Can FTFT be extended to generative tasks beyond classification?

## Limitations
- The method's effectiveness may break down when ID and OOD data distributions are substantially different
- Reference model selection criteria remain heuristic without systematic guidance
- Computational overhead of tracking training dynamics and constructing data maps is not fully accounted for

## Confidence
- **High Confidence (8-10/10)**: Training dynamics transferability across model sizes is well-supported experimentally
- **Medium Confidence (5-7/10)**: Easy instance identification ratio as predictor of reference model effectiveness has limited empirical support
- **Low Confidence (1-4/10)**: Claims about general applicability to diverse NLP tasks lack empirical validation

## Next Checks
1. Validate FTFT on diverse NLP tasks including text classification, question answering, and sequence labeling
2. Systematically vary reference model architecture and size to identify transferability thresholds
3. Measure full computational cost including training dynamics tracking and data map construction