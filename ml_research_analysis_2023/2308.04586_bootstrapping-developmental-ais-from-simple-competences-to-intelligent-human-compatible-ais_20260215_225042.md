---
ver: rpa2
title: 'Bootstrapping Developmental AIs: From Simple Competences to Intelligent Human-Compatible
  AIs'
arxiv_id: '2308.04586'
source_url: https://arxiv.org/abs/2308.04586
tags:
- learning
- they
- competences
- language
- research
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper explores a bio-inspired, developmental approach to creating
  robust, human-compatible AIs through bootstrapping. It emphasizes starting with
  innate competences and incrementally acquiring self-developed and socially developed
  ones, similar to human cognitive development.
---

# Bootstrapping Developmental AIs: From Simple Competences to Intelligent Human-Compatible AIs

## Quick Facts
- arXiv ID: 2308.04586
- Source URL: https://arxiv.org/abs/2308.04586
- Reference count: 0
- Key outcome: Bio-inspired developmental approach to creating robust, human-compatible AIs through bootstrapping from innate competences

## Executive Summary
This paper proposes a bio-inspired developmental approach to creating human-compatible AIs through a bootstrapping process that mirrors human cognitive development. The framework emphasizes starting with innate competences and incrementally acquiring self-developed and socially developed ones through experiential learning. By integrating multi-model constraint propagation, the approach enables AIs to fuse information across perception, action, planning, and social understanding for more grounded reasoning. The authors argue this developmental trajectory is essential for creating robust, trustworthy AI systems capable of meaningful collaboration with humans.

## Method Summary
The paper describes a developmental bootstrapping framework where AIs progress through three competence stages: innate (pre-wired capabilities), self-developed (learned through interaction), and socially developed (acquired through imitation and teaching). The method employs multi-modal constraint propagation to integrate information across cognitive models, enabling cross-model reinforcement for more robust perception and reasoning. Key components include curiosity-driven intrinsic motivation for autonomous exploration, hierarchical planning for efficient action sequences, and theory of mind for social learning. The approach emphasizes experiential learning environments where agents interact with the world and gradually build increasingly sophisticated cognitive capabilities.

## Key Results
- Multi-modal constraint propagation enables cross-model reinforcement that reduces ambiguity in perception and reasoning
- Developmental progression from innate → self-developed → socially developed competences mirrors human cognitive development
- Curiosity-driven intrinsic motivation guides agents to seek intermediate complexity situations that maximize learning progress

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bootstrapping developmental AIs through multi-modal constraint propagation improves competence acquisition compared to single-mode approaches.
- Mechanism: Multiple cognitive models (objects, places, agents) reinforce each other through shared constraints, reducing ambiguity in perception and reasoning.
- Core assumption: The world has enough structure that cross-model connections can be learned from real-world interactions.
- Evidence anchors:
  - [abstract] "integrates multi-model constraint propagation, enabling AIs to fuse information across perception, action, planning, and social understanding"
  - [section] "information from the sound of Jackie's voice combines with information about her state of health which combines with rules of treasure hunts which combines to narrow possibilities"
- Break condition: If the environment lacks sufficient structure for meaningful cross-model constraints, the reinforcement effect diminishes and learning slows.

### Mechanism 2
- Claim: Starting with innate competences and progressively acquiring self-developed and socially developed ones mirrors human cognitive development and enables more robust AI.
- Mechanism: Innate competences provide initial scaffolding for learning; self-developed competences build through interaction; socially developed competences accelerate learning via imitation and teaching.
- Core assumption: The progression from innate → self-developed → socially developed competences is necessary for robust intelligence.
- Evidence anchors:
  - [abstract] "The approach creates experiential foundation models for human-compatible AIs"
  - [section] "They start with innate competences. Like humans, they interact with the environment and learn from their interactions"
- Break condition: If innate competences are insufficient or incorrectly specified, the entire developmental trajectory fails to bootstrap properly.

### Mechanism 3
- Claim: Curiosity-driven intrinsic motivation enables agents to discover novel goals and explore effectively without external reward structures.
- Mechanism: Agents seek out situations with intermediate complexity—neither too predictable nor too unpredictable—to maximize learning progress.
- Core assumption: Learning progress can be measured as reduction in prediction error, and this metric correlates with useful knowledge acquisition.
- Evidence anchors:
  - [abstract] "Curiosity-driven learning, imitation, coordination, and natural language communication"
  - [section] "IAC chooses challenges that increase in complexity at the right pace...amounts to an explanation for the efficacy of a 'Goldilocks Principle'"
- Break condition: If the prediction error metric doesn't correlate with meaningful learning, agents may pursue unproductive exploration.

## Foundational Learning

- Concept: Multi-modal perception and constraint propagation
  - Why needed here: This is the core mechanism by which developmental AIs fuse information across different cognitive models to reduce ambiguity
  - Quick check question: Can you explain how information from touch, vision, and memory combine to solve the treasure hunt scenario?

- Concept: Abstraction discovery through hierarchical planning
  - Why needed here: Humans naturally chunk actions into reusable abstractions; AIs need this to plan efficiently
  - Quick check question: How does the Tomov model discover hierarchical abstractions from clusters of action steps?

- Concept: Theory of mind and imitation learning
  - Why needed here: Social learning requires understanding other agents' goals and translating their actions to one's own capabilities
  - Quick check question: What are the five competences required for imitation learning according to the correspondence problem framework?

## Architecture Onboarding

- Component map: Perception subsystem → World model → Action system → Learning modules → Social interaction
- Critical path: Perception → World modeling → Action selection → Learning feedback loop
- Design tradeoffs:
  - Processing speed vs. accuracy in multi-modal fusion
  - Predefined innate competences vs. learned initial capabilities
  - Centralized vs. distributed learning architectures
  - Supervised vs. unsupervised learning approaches
- Failure signatures:
  - Poor cross-modal constraint propagation (isolated models)
  - Inability to discover useful abstractions (flat planning)
  - Failure to solve correspondence problem (poor imitation)
  - Lack of intrinsic motivation (stuck in local optima)
- First 3 experiments:
  1. Implement simple multimodal object recognition (vision + touch) on a robotic arm
  2. Create hierarchical planner that discovers action abstractions from sequences
  3. Build curiosity-driven exploration system that seeks intermediate complexity situations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact cognitive process by which children transition from individual exploration to learning through observation and imitation of others?
- Basis in paper: [explicit] The paper discusses the development of imitation learning in children, but the exact cognitive mechanisms remain unclear.
- Why unresolved: While the paper mentions the importance of imitation learning, it does not delve into the specific neural or cognitive processes that enable this transition.
- What evidence would resolve it: Further research using neuroimaging techniques (e.g., fMRI, EEG) to study brain activity during imitation learning in children, combined with detailed behavioral studies, could provide insights into the underlying cognitive processes.

### Open Question 2
- Question: How can AI systems effectively bridge the Toddler Barrier and the Reading Barrier to acquire socially developed competences?
- Basis in paper: [explicit] The paper highlights the Toddler Barrier (speech acquisition) and the Reading Barrier as crucial for advancing AI collaboration and learning from human culture.
- Why unresolved: Current AI systems struggle to replicate the complex cognitive processes involved in language acquisition and reading comprehension, which are essential for accessing socially developed knowledge.
- What evidence would resolve it: Developing AI systems that can engage in meaningful dialogue, demonstrate understanding of context, and critically evaluate information from diverse sources would be a significant step towards bridging these barriers.

### Open Question 3
- Question: What are the optimal strategies for designing experiential learning environments for AI systems, similar to the Tacoma Children's Museum example, to facilitate the development of social and cognitive competences?
- Basis in paper: [inferred] The paper suggests that experiential learning environments, like the Tacoma Children's Museum, can be valuable for children's development. It implies that similar environments could be beneficial for AI systems.
- Why unresolved: The paper does not provide specific guidelines for designing such environments for AI systems, considering their unique learning needs and limitations.
- What evidence would resolve it: Conducting experiments with AI systems in various simulated or real-world environments, evaluating their learning outcomes and social interactions, could help identify the most effective strategies for designing experiential learning environments.

## Limitations
- Lack of empirical validation - claims about bootstrapping effectiveness remain largely theoretical without experimental results
- Mechanism of multi-modal constraint propagation lacks quantitative evidence showing superiority over single-mode approaches
- Developmental progression from innate to self-developed to socially developed competences is conceptually sound but not demonstrated through concrete implementations

## Confidence
- Medium: The theoretical foundation connecting human cognitive development to AI learning is well-grounded in developmental psychology literature, but the translation to computational mechanisms requires more rigorous testing
- Medium: Claims about curiosity-driven learning and abstraction discovery through hierarchical planning have some supporting evidence from related work but need direct validation within this framework
- Low: The paper lacks concrete implementation details and experimental protocols needed for faithful reproduction

## Next Checks
1. Implement a minimal working prototype that demonstrates multimodal constraint propagation on a simple task (e.g., object recognition combining vision and touch) and measure performance improvements over single-mode baselines
2. Conduct ablation studies on the developmental progression by comparing AI systems that receive different combinations of innate, self-developed, and socially developed competences to quantify the contribution of each stage
3. Evaluate curiosity-driven exploration by implementing IAC-like mechanisms and measuring learning efficiency across different complexity levels to verify the "Goldilocks Principle" claims