---
ver: rpa2
title: Effective Human-AI Teams via Learned Natural Language Rules and Onboarding
arxiv_id: '2311.01007'
source_url: https://arxiv.org/abs/2311.01007
tags:
- human
- region
- regions
- arxiv
- onboarding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of optimizing human-AI collaboration
  by learning when to rely on, ignore, or integrate AI assistance. The core method,
  IntegrAI, discovers regions in the data space where human-AI performance differs
  and describes them in natural language using a large language model.
---

# Effective Human-AI Teams via Learned Natural Language Rules and Onboarding

## Quick Facts
- **arXiv ID**: 2311.01007
- **Source URL**: https://arxiv.org/abs/2311.01007
- **Reference count**: 40
- **Key outcome**: Onboarding with learned natural language rules improved human-AI team accuracy by 5.2% in object detection, while integration recommendations provided no additional benefit.

## Executive Summary
This paper addresses the challenge of optimizing human-AI collaboration by automatically discovering when humans should rely on, ignore, or integrate AI assistance. The IntegrAI system learns regions in the data space where human and AI performance differ, describes these regions in natural language using an LLM, and teaches these rules to humans through an onboarding process. A user study across object detection and visual question answering tasks found that onboarding significantly improved team performance, while displaying integration recommendations during task execution provided no additional benefit.

## Method Summary
The method involves two main algorithms: IntegrAI-Discover identifies regions in the data space where human-AI performance differs significantly, using a constraint-based optimization approach with differential relaxation; IntegrAI-Describe generates natural language descriptions for these regions through an iterative contrastive process with an LLM. Humans are then taught these rules through onboarding that includes a Human-AI card explaining the model and lessons showing representative examples. During task execution, integration recommendations can optionally be displayed in an AI dashboard. The approach was evaluated through user studies on object detection and VQA tasks.

## Key Results
- Onboarding significantly improved human-AI team accuracy by 5.2% in object detection tasks
- Integration recommendations provided no additional benefit beyond onboarding alone
- IntegrAI achieved lower human-AI team error than SEAL and human-only baselines across both tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Teaching humans specific, data-grounded rules for when to rely on, ignore, or integrate AI improves human-AI team performance.
- Mechanism: The IntegrAI algorithm discovers regions in the data space where human and AI performance differ significantly. These regions are described in natural language and taught to humans during onboarding. By providing concrete, context-specific guidance, humans can make more informed decisions about when to trust or override the AI's suggestions.
- Core assumption: Humans can learn and apply these rules effectively during the onboarding process.
- Evidence anchors:
  - [abstract]: "Onboarding significantly improved human-AI team accuracy by 5.2% in object detection"
  - [section]: "Our method can lead to more accurate human-AI teams" (Introduction)
  - [corpus]: The corpus includes papers on human-AI collaboration and onboarding, suggesting this is an active area of research.
- Break condition: If the onboarding process is ineffective or the rules are too complex for humans to learn and apply, the performance improvement will not be observed.

### Mechanism 2
- Claim: The iterative region description algorithm using LLMs and contrastive examples generates understandable and useful rules for humans.
- Mechanism: The IntegrAI-Describe algorithm starts with an initial description of a region and iteratively refines it by finding counterexamples both inside and outside the region. This contrastive approach helps to create descriptions that are both accurate and distinguishable, enabling humans to better understand the boundaries of each region.
- Core assumption: The LLM can generate accurate and useful descriptions, and the iterative refinement process improves the quality of these descriptions.
- Evidence anchors:
  - [abstract]: "Each region is then described using a large language model in an iterative and contrastive procedure"
  - [section]: "The procedure first queries the LLM to describe points inside the region...The embedding space is then leveraged to find counterexamples inside and outside the region to refine the description" (Section 4.2)
  - [corpus]: The corpus includes papers on using LLMs for region description and contrastive learning, supporting the feasibility of this approach.
- Break condition: If the LLM fails to generate accurate descriptions or the iterative refinement process does not improve the quality of the descriptions, the rules may not be understandable or useful for humans.

### Mechanism 3
- Claim: Displaying AI-integration recommendations as part of an AI dashboard after onboarding can further improve human-AI team performance.
- Mechanism: After the onboarding process, humans are presented with AI-integration recommendations as part of an AI dashboard during task execution. These recommendations remind humans of the rules they learned during onboarding and guide their decision-making in real-time.
- Core assumption: Humans will attend to and act upon the recommendations displayed in the dashboard.
- Evidence anchors:
  - [abstract]: "We further investigate surfacing the AI-integration decisions found by IntegrAI as recommendations to the human within an AI dashboard used after onboarding"
  - [section]: "At test time, we can check whether an example x and its corresponding AI output a fall into one of the learned regions Nk. If they do, then our dashboard shows the associated recommendation rk and description tk alongside the AI output a" (Section 5)
  - [corpus]: The corpus includes papers on AI dashboards and recommendations, suggesting this is a relevant approach.
- Break condition: If humans ignore the recommendations or the recommendations are not presented in a clear and accessible manner, the performance improvement may not be observed.

## Foundational Learning

- Concept: Region discovery and description algorithms
  - Why needed here: These algorithms are the core of the IntegrAI system, enabling the automatic generation of rules for human-AI collaboration.
  - Quick check question: How does the IntegrAI-Discover algorithm find regions in the data space, and how does the IntegrAI-Describe algorithm generate natural language descriptions for these regions?

- Concept: Onboarding and recommendation display
  - Why needed here: Onboarding teaches humans the rules generated by the algorithms, and the recommendation display provides real-time guidance during task execution.
  - Quick check question: What are the key steps in the onboarding process, and how are the AI-integration recommendations displayed in the AI dashboard?

- Concept: Human-AI team performance evaluation
  - Why needed here: Evaluating the effectiveness of the IntegrAI system requires measuring the performance of human-AI teams with and without the system.
  - Quick check question: What metrics are used to evaluate human-AI team performance, and how do these metrics capture the impact of the IntegrAI system?

## Architecture Onboarding

- Component map:
  Data collection -> Region discovery -> Region description -> Onboarding -> Recommendation display

- Critical path:
  1. Data collection
  2. Region discovery
  3. Region description
  4. Onboarding
  5. Recommendation display

- Design tradeoffs:
  - Balancing the complexity of the rules with their understandability for humans
  - Choosing the appropriate number of regions to avoid overwhelming humans while still providing useful guidance
  - Deciding whether to display recommendations during task execution or rely solely on the onboarding process

- Failure signatures:
  - Low human-AI team performance despite using the IntegrAI system
  - Humans not following the rules taught during onboarding
  - AI-integration recommendations not being displayed or not being attended to by humans

- First 3 experiments:
  1. Evaluate the performance of the region discovery and description algorithms on synthetic datasets with known ground truth regions.
  2. Conduct a user study to assess the effectiveness of the onboarding process in teaching humans the generated rules.
  3. Evaluate the impact of displaying AI-integration recommendations in an AI dashboard on human-AI team performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we systematically evaluate and improve the quality of natural language descriptions generated for the discovered regions?
- Basis in paper: [inferred] The paper mentions that region descriptions are often complex and captioning metrics may not be informative for evaluation. They provide one example comparison between their method and SEAL, but do not present a comprehensive evaluation.
- Why unresolved: The paper acknowledges this is an obstacle but does not propose a solution or present a thorough evaluation. More work is needed to develop metrics and methods for assessing region description quality.
- What evidence would resolve it: A systematic study evaluating region descriptions using multiple metrics (e.g. human evaluation, information content, distinctiveness) and comparing different description methods. This would help determine what makes a good description and how to generate them effectively.

### Open Question 2
- Question: How can we adapt the region discovery and description algorithms to handle more complex data modalities beyond images and text, such as audio or video?
- Basis in paper: [explicit] The paper focuses on image and text data, using CLIP embeddings for images and sentence transformers for text. It does not explore other modalities.
- Why unresolved: The algorithms rely on having interpretable embedding spaces and the ability to generate natural language descriptions. Adapting them to other modalities would require developing new embedding methods and description techniques.
- What evidence would resolve it: Experiments applying the algorithms to audio or video data, with appropriate embeddings and description methods. This would demonstrate the generalizability of the approach to other modalities.

### Open Question 3
- Question: How can we personalize the onboarding process and AI-integration recommendations to individual users based on their characteristics and prior performance?
- Basis in paper: [inferred] The paper presents a general onboarding process and fixed AI-integration recommendations, but does not explore personalization. It mentions that "Onboarding and recommendations can be tailored to the specific human by leveraging their characteristics" as a future direction.
- Why unresolved: Personalizing the process would require modeling individual user differences and adapting the content and recommendations accordingly. The paper does not provide a framework for this.
- What evidence would resolve it: A study comparing personalized vs. non-personalized onboarding and recommendations, measuring the impact on user performance and satisfaction. This would show the benefits of personalization and guide the development of personalization methods.

## Limitations

- The study only tested two tasks with relatively small sample sizes, limiting generalizability
- No statistical significance testing was reported for the main results
- The mechanism for why integration recommendations don't help is not explained
- The LLM-based region description process lacks systematic evaluation of description quality

## Confidence

- High confidence: The mathematical formulation of the region discovery algorithm is sound and reproducible
- Medium confidence: The onboarding process improves performance as reported (based on user study results)
- Low confidence: The integration recommendations add no value (based on single negative finding without mechanism explanation)

## Next Checks

1. Replicate the user study with statistical power analysis to confirm the 5.2% improvement significance and explore effect sizes across different task types
2. Conduct a controlled experiment testing LLM-generated region descriptions with human evaluators to measure comprehension and usefulness
3. Perform ablation studies on the region discovery hyperparameters to understand their impact on discovered regions and downstream human-AI performance