---
ver: rpa2
title: Improving neural network representations using human similarity judgments
arxiv_id: '2306.04507'
source_url: https://arxiv.org/abs/2306.04507
tags:
- representations
- glocal
- similarity
- human
- original
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the impact of aligning neural network representations
  with human similarity judgments on downstream tasks. The authors propose a novel
  gLocal transform that combines a global alignment loss, which aligns representations
  with human similarity judgments, and a local contrastive loss that maintains the
  local structure of the original representation space.
---

# Improving neural network representations using human similarity judgments

## Quick Facts
- arXiv ID: 2306.04507
- Source URL: https://arxiv.org/abs/2306.04507
- Reference count: 40
- Primary result: gLocal transform improves few-shot learning and anomaly detection by aligning neural network representations with human similarity judgments while preserving local structure

## Executive Summary
This paper addresses the challenge of aligning neural network representations with human similarity judgments to improve downstream task performance. The authors propose a novel gLocal transform that combines a global alignment loss with human similarity judgments and a local contrastive loss that preserves the original representation space's local structure. This dual objective allows the model to capture human-like global semantic organization while maintaining fine-grained similarity relationships learned during pretraining. The gLocal transform significantly improves performance across various few-shot learning and anomaly detection tasks compared to both original and naively aligned representations, demonstrating that human visual representations are globally organized in a way that facilitates learning from few examples.

## Method Summary
The gLocal transform is a linear transformation that optimizes representations to align with human similarity judgments while preserving local structure. It combines a global alignment loss that measures the alignment between neural network representations and human similarity judgments, and a local contrastive loss that maintains the neighborhood structure of the original representation space. The transform is optimized using stochastic gradient descent with momentum, and a regularization term shrinks the transformation matrix toward scaled identity to prevent overfitting. The method is evaluated on CLIP and ImageNet models using the THINGS dataset for human similarity judgments, with downstream tasks including few-shot learning and anomaly detection.

## Key Results
- gLocal transform improves accuracy across multiple few-shot learning and anomaly detection tasks compared to original and naively aligned representations
- The transform preserves local structure while achieving strong alignment with human similarity judgments, outperforming approaches that focus solely on global alignment
- Despite using 3-6 orders of magnitude fewer images than pretraining, significant improvements are observed, suggesting human similarity judgments efficiently capture essential global structure

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aligning global structure with human similarity judgments improves downstream task performance.
- Mechanism: The gLocal transform combines a global alignment loss that matches representations to human similarity judgments with a local contrastive loss that preserves the local neighborhood structure of the original representations. This dual objective allows the model to capture human-like global semantic organization while maintaining the fine-grained similarity relationships learned during pretraining.
- Core assumption: Human similarity judgments reflect a globally coherent structure that facilitates learning from few examples, and this structure can be transferred to neural network representations.
- Evidence anchors:
  - [abstract]: "incorporating this global structure into neural network representations improves performance on downstream tasks"
  - [section]: "The gLocal transform substantially increases performance on a variety of few-shot learning and anomaly detection tasks"
  - [corpus]: Weak - related papers discuss alignment between human and machine representations but don't directly address the gLocal mechanism
- Break condition: If human similarity judgments don't reflect a coherent global structure, or if the local structure preservation is too restrictive to allow meaningful global alignment.

### Mechanism 2
- Claim: Naive global alignment without local structure preservation harms downstream performance.
- Mechanism: A naive transform that only minimizes global alignment loss without regularization can distort local representational structure, destroying the fine-grained similarity relationships that are important for downstream tasks. This is why the gLocal transform includes a local contrastive loss term.
- Core assumption: Local representational structure contains important information for downstream tasks that would be lost with naive global alignment.
- Evidence anchors:
  - [abstract]: "a naive approach leads to large changes in local representational structure that harm downstream performance"
  - [section]: "we observe a trade-off between alignment and the transferability of a neural network's human-aligned representation space to downstream tasks"
  - [corpus]: Weak - related work discusses alignment but doesn't specifically address the harm of naive approaches
- Break condition: If local structure preservation becomes so strict that it prevents any meaningful global alignment, or if downstream tasks don't rely on local structure.

### Mechanism 3
- Claim: Human similarity judgments can be captured with relatively few examples compared to pretraining data.
- Mechanism: Despite using 3-6 orders of magnitude fewer images than pretraining, the gLocal transform achieves significant improvements. This suggests that human similarity judgments efficiently capture the essential global structure needed for downstream tasks.
- Core assumption: Human similarity judgments efficiently encode the globally coherent structure that matters for downstream performance.
- Evidence anchors:
  - [abstract]: "Although the number of images we use for alignment is three to six orders of magnitude smaller than the number of images in pretraining, we observe significant improvements"
  - [section]: "Our results imply that even with hundreds of millions of image/text pairs, image/text contrastive learning does not learn a representation space with human-like global organization"
  - [corpus]: Weak - related work discusses efficiency of human judgments but not in the context of pretraining data scale
- Break condition: If the human similarity judgment dataset doesn't adequately sample the space of concepts, or if the concepts humans use differ significantly from those needed for downstream tasks.

## Foundational Learning

- Concept: Representational Similarity Analysis (RSA)
  - Why needed here: RSA is used to quantify the alignment between neural network representations and human similarity judgments by comparing representational similarity matrices.
  - Quick check question: What is the difference between using cosine similarity and Pearson correlation as the kernel function in RSA, and why might Pearson correlation be preferred?

- Concept: Contrastive Learning
  - Why needed here: The local contrastive loss in the gLocal transform is inspired by contrastive learning objectives, which aim to preserve local structure by making representations of similar examples closer.
  - Quick check question: How does the local contrastive loss in the gLocal transform differ from standard contrastive learning objectives used during pretraining?

- Concept: Principal Component Analysis (PCA)
  - Why needed here: PCA is used to analyze the global structure of representations by examining the principal components, which capture the directions of maximum variance.
  - Quick check question: Why might PCA be more appropriate than t-SNE for analyzing global representational structure, and what are the limitations of using PCA for this purpose?

## Architecture Onboarding

- Component map: Neural network representations -> Global alignment loss (human similarity judgments) -> Local contrastive loss (preserves local structure) -> Regularization term (shrinks transformation matrix) -> Transformed representations

- Critical path:
  1. Extract representations from pretrained model
  2. Compute human similarity matrix from triplet data
  3. Optimize gLocal transform using SGD with momentum
  4. Apply transform to representations
  5. Evaluate on downstream tasks

- Design tradeoffs:
  - Trade-off between global alignment and local structure preservation (controlled by α hyperparameter)
  - Trade-off between alignment performance and computational cost (controlled by grid search parameters)
  - Choice of regularization strength (controlled by λ hyperparameter)

- Failure signatures:
  - Poor downstream task performance despite good alignment scores: local structure preservation too strict
  - Good downstream performance but poor alignment: insufficient global alignment
  - High variance in results across runs: insufficient regularization or poor hyperparameter selection

- First 3 experiments:
  1. Apply gLocal transform to CLIP-RN50 on CIFAR-10 anomaly detection and compare to untransformed baseline
  2. Vary the α hyperparameter (0.05, 0.25, 0.5, 1.0) and measure impact on few-shot learning performance
  3. Compare nearest neighbor preservation between gLocal, global, and naive transforms on ImageNet validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do ImageNet models not benefit from the gLocal transform for few-shot learning and anomaly detection tasks, while CLIP models do?
- Basis in paper: [explicit] The authors observe that gLocal transforms improve performance for CLIP models but not for ImageNet models on fine-grained tasks and anomaly detection.
- Why unresolved: The paper suggests that the gLocal transform requires representations to capture the concepts by which human representations are organized, but ImageNet representations may not adequately capture these concepts.
- What evidence would resolve it: Analyzing the global structure of ImageNet representations to determine if they capture human-like concepts, and comparing this structure to CLIP representations.

### Open Question 2
- Question: What specific aspects of human similarity judgments are most critical for improving downstream task performance through the gLocal transform?
- Basis in paper: [inferred] The paper shows that aligning representations with human similarity judgments improves performance, but it doesn't specify which aspects of these judgments are most important.
- Why unresolved: The paper uses a general alignment loss based on triplet odd-one-out tasks but doesn't decompose the impact of different types of human judgments.
- What evidence would resolve it: Conducting ablation studies using different subsets of human similarity judgment datasets or varying the weighting of different judgment types in the alignment loss.

### Open Question 3
- Question: How does the gLocal transform compare to alternative methods for incorporating global structure into neural network representations?
- Basis in paper: [inferred] The paper introduces the gLocal transform as a method to align global structure while preserving local structure, but doesn't compare it to other potential approaches.
- Why unresolved: The paper focuses on the effectiveness of the gLocal transform but doesn't explore other strategies for achieving similar goals.
- What evidence would resolve it: Comparing the gLocal transform to other methods such as hierarchical clustering-based transformations, knowledge graph embeddings, or alternative regularization strategies.

### Open Question 4
- Question: What is the theoretical basis for the relationship between representational alignment with human similarity judgments and improved downstream task performance?
- Basis in paper: [inferred] The paper demonstrates a correlation between alignment and performance but doesn't provide a theoretical explanation for this relationship.
- Why unresolved: The paper shows empirical results but doesn't explore the underlying mechanisms that connect human-aligned representations to better generalization.
- What evidence would resolve it: Developing theoretical models that explain how human-aligned global structure facilitates learning from few examples and improves anomaly detection, possibly drawing connections to concepts like compositional generalization or meta-learning.

### Open Question 5
- Question: How does the gLocal transform affect representations in terms of their robustness to distribution shifts and out-of-distribution generalization?
- Basis in paper: [explicit] The authors mention that human and machine vision differ in sensitivity to distortions and out-of-distribution generalization, but don't analyze how the gLocal transform impacts these properties.
- Why unresolved: While the paper focuses on few-shot learning and anomaly detection, it doesn't examine whether the transform improves robustness to distributional changes.
- What evidence would resolve it: Evaluating the gLocal transform on datasets with known distribution shifts (like BREEDS or ImageNet-C) and measuring performance degradation compared to original and naively aligned representations.

## Limitations
- Evaluation focuses primarily on a single human similarity judgment dataset (THINGS), raising questions about generalizability to other domains
- Computational cost of gLocal transform optimization is not thoroughly analyzed, particularly regarding scalability to larger models
- The paper demonstrates improvements across multiple tasks but doesn't provide ablation studies isolating the contributions of global alignment versus local structure preservation

## Confidence
- **High confidence**: The core finding that combining global alignment with local structure preservation improves downstream performance is well-supported by consistent results across multiple tasks and models.
- **Medium confidence**: The claim that human similarity judgments capture globally coherent structure efficiently is supported but relies on a single dataset; more diverse human judgment datasets would strengthen this claim.
- **Medium confidence**: The assertion that naive global alignment harms local structure is demonstrated but could benefit from more extensive analysis of when and why this occurs.

## Next Checks
1. Apply the gLocal transform to representations from human similarity judgment datasets beyond THINGS (e.g., perceptual similarity datasets) to test generalizability.
2. Systematically vary the strength of global alignment versus local preservation across a wider range of values to better understand the trade-off dynamics.
3. Measure and analyze the computational cost of gLocal transform optimization across different model sizes and hyperparameter settings to assess scalability.