---
ver: rpa2
title: Label-free Node Classification on Graphs with Large Language Models (LLMS)
arxiv_id: '2310.04668'
source_url: https://arxiv.org/abs/2310.04668
tags:
- llms
- nodes
- node
- annotations
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of node classification on text-attributed
  graphs, where abundant high-quality labels are typically required for Graph Neural
  Networks (GNNs) but are costly to obtain. The authors propose a pipeline called
  LLM-GNN that leverages Large Language Models (LLMs) to generate annotations for
  a subset of nodes, which are then used to train GNNs for classifying the remaining
  nodes.
---

# Label-free Node Classification on Graphs with Large Language Models (LLMS)

## Quick Facts
- arXiv ID: 2310.04668
- Source URL: https://arxiv.org/abs/2310.04668
- Reference count: 40
- One-line primary result: LLM-GNN achieves 74.9% accuracy on OGBN-PRODUCTS with <1$ cost, outperforming other label-free methods

## Executive Summary
This paper addresses the challenge of node classification on text-attributed graphs where abundant labeled data is expensive to obtain. The authors propose LLM-GNN, a pipeline that leverages Large Language Models to generate annotations for a subset of nodes, which are then used to train Graph Neural Networks for classifying remaining nodes. The key innovation lies in actively selecting nodes that are easy for LLMs to annotate and refining annotations using confidence scores, achieving competitive performance at low cost compared to traditional label-intensive approaches.

## Method Summary
LLM-GNN is a four-component pipeline for label-free node classification on text-attributed graphs. It begins with difficulty-aware active node selection using a C-Density heuristic that identifies nodes near cluster centers as easier for LLMs to annotate. These selected nodes are then annotated by LLMs using confidence-aware prompts, typically zero-shot hybrid strategies. The annotations undergo post-filtering where nodes with low confidence scores are removed while preserving label diversity using a change-of-entropy (COE) metric. Finally, a standard GNN is trained on the filtered annotations and used to classify the remaining nodes.

## Key Results
- Achieves 74.9% accuracy on OGBN-PRODUCTS with <1$ cost, outperforming other label-free methods
- LLM annotations exhibit class-specific noise patterns that are more benign than synthetic noise
- C-Density heuristic consistently identifies nodes with higher annotation quality for LLM labeling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-generated annotations have different characteristics than synthetic noisy labels, making them more benign for GNN training.
- Mechanism: The noise transition matrix of LLM annotations shows class-specific patterns where certain classes have high accuracy while others have systematic biases toward specific classes, rather than uniform random noise.
- Core assumption: The noise pattern in LLM annotations is structurally different from synthetic noise models typically used in research.
- Evidence anchors: [section] "For example, for WIKI CS, c7 ("distributed computing architecture") tends to flip into c8 ("web technology")" and [section] "Unlike traditional graph active learning methods which try to model diversity..."
- Break condition: If LLM training data contains similar biases to the target domain, the noise patterns may become less benign and more like uniform synthetic noise.

### Mechanism 2
- Claim: Difficulty-aware active selection based on C-Density heuristic improves annotation quality by selecting nodes closer to cluster centers.
- Mechanism: Nodes near cluster centers have higher feature density, which correlates with better LLM annotation accuracy, so selecting these nodes yields higher-quality training data.
- Core assumption: Annotation quality by LLMs is inversely related to distance from cluster centers in feature space.
- Evidence anchors: [section] "we observe a consistent pattern: nodes closer to cluster centers typically exhibit better annotation quality" and [section] "Assuming that the current selected set of nodes is Vsel..."
- Break condition: If the dataset has very different feature distributions or if LLM performance doesn't correlate with feature density, this heuristic may fail.

### Mechanism 3
- Claim: Post-filtering using confidence scores and COE (change of entropy) maintains diversity while improving annotation quality.
- Mechanism: Nodes with low confidence are removed, but the COE metric ensures that removing a node doesn't significantly reduce label diversity, preventing the model from overfitting to a few dominant classes.
- Core assumption: The confidence scores from LLMs are calibrated enough to distinguish high-quality from low-quality annotations.
- Evidence anchors: [section] "COE can be further combined with confidence fconf(vi) to balance diversity and annotation quality" and [section] "Empirically, we find that reasoning-based prompts will generate outputs..."
- Break condition: If confidence scores are poorly calibrated or if the dataset has extreme class imbalance, post-filtering may remove too many diverse samples.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and their dependence on labeled data
  - Why needed here: Understanding why traditional GNNs fail without abundant labels is crucial to appreciating the LLM-GNN solution
  - Quick check question: What is the main limitation of GNNs that this paper addresses?

- Concept: Large Language Models (LLMs) zero-shot capabilities and limitations
  - Why needed here: Understanding LLM strengths (text understanding) and weaknesses (structural data) explains the hybrid approach
  - Quick check question: Why can't LLMs directly replace GNNs for node classification despite their zero-shot capabilities?

- Concept: Active learning and node selection strategies
  - Why needed here: The paper builds on existing active learning concepts but adds new dimensions (annotation difficulty, confidence)
  - Quick check question: How does difficulty-aware selection differ from traditional diversity-based selection in active learning?

## Architecture Onboarding

- Component map: Input graph -> Difficulty-aware selection -> LLM annotation -> Post-filtering -> GNN training -> Prediction
- Critical path: Node selection → LLM annotation → Post-filtering → GNN training → Prediction
- Design tradeoffs:
  - Higher selection budget → better performance but higher cost
  - Stricter post-filtering → better annotation quality but potentially less diverse training set
  - More complex prompts → better confidence calibration but higher inference cost
- Failure signatures:
  - Poor performance despite high budget: Check if C-Density heuristic is valid for the dataset
  - Model overfitting to few classes: Check post-filtering diversity preservation
  - High cost with marginal gains: Check if LLM annotations are actually better than random selection
- First 3 experiments:
  1. Compare C-Density-based selection vs random selection on a small dataset to validate the heuristic
  2. Test different confidence-aware prompts (zero-shot vs one-shot) on sample nodes to find optimal balance of accuracy vs cost
  3. Run post-filtering with different β0, β1 values to find optimal diversity-quality tradeoff on a validation subset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we further optimize the hyper-parameters in LLM-GNN's difficulty-aware active node selection and post-filtering components?
- Basis in paper: [explicit] The authors mention that they do not investigate strategies to tune hyper-parameters, instead assigning them the same value for simplicity.
- Why unresolved: The authors acknowledge that there is still a large room to improve performance, especially when combining difficulty-aware active node selection with post-filtering, but they do not explore hyper-parameter tuning in this paper.
- What evidence would resolve it: A comprehensive study of hyper-parameter optimization techniques applied to LLM-GNN, demonstrating improved performance compared to the fixed hyper-parameter setting.

### Open Question 2
- Question: Can we develop more advanced prompt strategies for generating calibrated confidence scores from LLMs that outperform the zero-shot hybrid strategy used in this paper?
- Basis in paper: [explicit] The authors mention that they adopt the "zero-shot hybrid strategy" considering its effectiveness in generating calibrated confidence, but leave the evaluation of other prompts as future work.
- Why unresolved: The authors do not explore alternative prompt strategies that could potentially generate better-calibrated confidence scores from LLMs.
- What evidence would resolve it: A comparative study of various prompt strategies for generating calibrated confidence scores, demonstrating superior performance compared to the zero-shot hybrid strategy.

### Open Question 3
- Question: How does the performance of LLM-GNN compare to other label-free node classification methods when applied to larger-scale graph datasets with more complex node attributes?
- Basis in paper: [explicit] The authors compare LLM-GNN's performance and cost to other label-free methods on several datasets, but they do not explore its performance on larger-scale graphs or those with more complex node attributes.
- Why unresolved: The scalability and effectiveness of LLM-GNN on larger and more complex graph datasets remain unexplored.
- What evidence would resolve it: An extensive evaluation of LLM-GNN on larger-scale graph datasets with more complex node attributes, comparing its performance and cost to other label-free methods.

### Open Question 4
- Question: Can we develop more sophisticated methods for measuring the change in diversity when removing nodes during the post-filtering stage, beyond the simple entropy-based approach used in this paper?
- Basis in paper: [inferred] The authors propose a simple score function change of entropy (COE) to measure the entropy change of labels when removing a node, but they do not explore more advanced methods for quantifying diversity changes.
- Why unresolved: The COE approach used in the paper may not capture all aspects of diversity changes, and more sophisticated methods could potentially lead to better performance.
- What evidence would resolve it: A comparative study of various methods for quantifying diversity changes during post-filtering, demonstrating improved performance compared to the COE approach.

## Limitations
- The C-Density heuristic's effectiveness may not generalize to graphs with different structural properties or feature distributions
- LLM annotation quality depends heavily on the semantic similarity between LLM training data and target domain
- The paper doesn't explore hyper-parameter optimization, leaving potential performance improvements on the table

## Confidence
- **High confidence**: The overall pipeline architecture (active selection → LLM annotation → post-filtering → GNN training) is sound and follows established active learning principles
- **Medium confidence**: The specific C-Density heuristic for difficulty-aware selection shows consistent patterns in experiments but needs broader validation
- **Medium confidence**: The claim about benign noise patterns in LLM annotations is supported by qualitative examples but lacks quantitative comparison with synthetic noise models

## Next Checks
1. Cross-domain robustness test: Apply LLM-GNN to datasets from different domains (e.g., social networks, biological networks) to verify the C-Density heuristic and noise pattern claims hold across structural variations

2. Synthetic noise comparison: Systematically compare LLM-generated noise patterns against synthetic noisy labels using established metrics from the noisy label literature to quantify the "benign" nature claim

3. Ablation on confidence calibration: Test the impact of removing confidence-aware post-filtering while maintaining diversity preservation to isolate the contribution of confidence scores versus diversity maintenance in performance gains