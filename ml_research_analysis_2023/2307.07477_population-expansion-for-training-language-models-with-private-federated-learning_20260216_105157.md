---
ver: rpa2
title: Population Expansion for Training Language Models with Private Federated Learning
arxiv_id: '2307.07477'
source_url: https://arxiv.org/abs/2307.07477
tags:
- training
- population
- data
- domain
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work tackles the challenge of training language models with
  private federated learning (PFL) when the population of devices is small. Small
  populations not only degrade model utility due to increased differential privacy
  noise, but also slow down training latency since the server must wait longer for
  enough devices to become available.
---

# Population Expansion for Training Language Models with Private Federated Learning

## Quick Facts
- arXiv ID: 2307.07477
- Source URL: https://arxiv.org/abs/2307.07477
- Reference count: 24
- Small populations in private federated learning degrade model utility and slow training latency

## Executive Summary
This paper addresses the challenge of training language models with private federated learning (PFL) when the population of devices is small. Small populations not only degrade model utility due to increased differential privacy noise, but also slow down training latency since the server must wait longer for enough devices to become available. To address this, the authors propose expanding the population size using domain adaptation techniques. They combine data from a source domain with a larger population and a target domain with a smaller population, using instance weighting and pretraining/finetuning strategies to improve model performance on the target domain. Experiments on real-world datasets (Reddit and Common Voice) show that their methods can expand the population size by 10 times, significantly reducing training latency and achieving 13% to 30% better model utility (lower perplexity) compared to baselines.

## Method Summary
The authors propose expanding the population size in PFL by combining data from a source domain with a larger population and a target domain with a smaller population. They use three domain adaptation techniques: instance weighting (IW), pretraining in source then finetuning in target (PT), and instance-weighted pretraining (IWPT). The method involves estimating unigram frequencies for both domains with privacy budget, computing instance weights for source domain data, and training models using FedAdam and SGD optimizers with DP noise and clipping. The experiments use constructed datasets (SubReddits and CV&Reddits) with user identifiers for partitioning, and evaluate perplexity on target domain test data while maintaining differential privacy.

## Key Results
- Population size expanded by 10 times using domain adaptation techniques
- Training latency significantly reduced due to larger available device population
- 13% to 30% better model utility (lower perplexity) compared to baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Expanding the population with domain adaptation reduces both training latency and differential privacy noise.
- Mechanism: By combining data from a larger source domain (S) with the smaller target domain (T), the effective population size increases. This amplifies privacy by subsampling, reducing the DP noise scale, and shortens waiting time for device availability in each training round.
- Core assumption: Data from S can be weighted appropriately to approximate target domain data distribution without significantly harming utility.
- Evidence anchors:
  - [abstract] "expanding the population based on domain adaptation techniques to speed up the training and improves the final model quality"
  - [section] "The smaller the population size, the longer the server needs to wait for enough devices to become available in each iteration."
  - [corpus] Weak; no direct evidence on domain adaptation for PFL in neighbors.

### Mechanism 2
- Claim: Instance weighting approximates importance sampling to mitigate sampling bias toward the source domain.
- Mechanism: Data points are reweighted by their relative likelihood under target vs. source distributions, making the combined dataset representative of the target domain.
- Core assumption: Unigram frequency estimates are accurate enough to approximate full density ratios for weighting.
- Evidence anchors:
  - [abstract] "combining data from a source domain with a larger population and a target domain with a smaller population, using instance weighting"
  - [section] "w(x) = pT(x)/pπ(x) is the importance weight"
  - [corpus] Weak; no direct evidence on importance weighting in federated neighbors.

### Mechanism 3
- Claim: Pretraining on the source domain and fine-tuning on the target domain improves utility while keeping latency low.
- Mechanism: Pretraining with large cohort size on S allows the model to learn general patterns, then fine-tuning on T with a small cohort size preserves privacy and focuses on the target domain.
- Core assumption: Knowledge from the source domain transfers well to the target domain, and the privacy budget can be split effectively.
- Evidence anchors:
  - [abstract] "They combine data from a source domain with a larger population and a target domain with a smaller population, using instance weighting and pretraining/finetuning strategies"
  - [section] "pretraining in S with a large cohort size C and fine-tune in T with a small cohort size αC"
  - [corpus] Weak; no direct evidence on pretraining+finetuning in federated neighbors.

## Foundational Learning

- Concept: Differential Privacy (DP) in federated learning
  - Why needed here: Understanding how DP noise scales inversely with population size explains why small populations hurt utility.
  - Quick check question: If the population size is doubled while keeping cohort size and privacy budget fixed, what happens to the DP noise scale?

- Concept: Domain adaptation techniques (instance weighting, pretraining/finetuning)
  - Why needed here: These techniques allow leveraging data from a larger source domain to improve training on a smaller target domain.

- Concept: Federated learning communication patterns and device availability modeling
  - Why needed here: Latency depends on how quickly enough devices become available for each cohort; understanding this helps optimize cohort and population sizes.

## Architecture Onboarding

- Component map:
  - Data preprocessing: Build vocab, tokenize, sequence data
  - Domain weighting estimator: Private unigram frequency estimation
  - Population expansion logic: Combine S and T datasets with weighting
  - Training loop: FedAdam server optimizer, SGD client optimizer
  - Privacy accounting: Gaussian mechanism with moment accountant

- Critical path:
  1. Estimate unigram frequencies for both domains (private stats)
  2. Compute instance weights for source domain data
  3. Sample devices from expanded population (S+T with weights)
  4. Aggregate weighted gradients with DP noise

- Design tradeoffs:
  - Privacy vs. utility: Larger population reduces DP noise but may include less relevant data
  - Communication cost: Adding domain-specific layers increases model size
  - Latency vs. cohort size: Larger cohorts reduce noise but increase waiting time

- Failure signatures:
  - Model collapses to source domain distribution (weights too high)
  - High perplexity on target domain (domains too dissimilar or weights too low)
  - Training stalls (insufficient devices become available)

- First 3 experiments:
  1. Run baseline training on T only with small and large cohort sizes to confirm utility-latency tradeoff
  2. Combine S and T without weighting to show naive approach fails
  3. Apply instance weighting and measure perplexity improvement over baseline

## Open Questions the Paper Calls Out
- The authors mention extending their framework to other domains like images as future work, but don't explore this in the current paper.

## Limitations
- Effectiveness depends heavily on similarity between source and target domains, which is not thoroughly validated across diverse scenarios.
- Private unigram frequency estimation method's accuracy under differential privacy is critical but not empirically tested for various privacy budgets.
- Scalability challenges when applied to very large source domains or when the target domain has highly specialized vocabulary not present in the source.

## Confidence
- High Confidence: The core mechanism of population expansion reducing DP noise and training latency is well-established and supported by the experimental results.
- Medium Confidence: The effectiveness of instance weighting and pretraining/finetuning strategies relies on domain similarity assumptions that are reasonable but not extensively validated.
- Low Confidence: The scalability of the approach to real-world scenarios with much larger datasets and more diverse domains remains uncertain.

## Next Checks
1. Test the population expansion technique across a wider range of domain similarities (e.g., news vs. social media vs. technical documents) to validate the domain adaptation assumptions.
2. Evaluate the private unigram frequency estimation under different privacy budgets to understand the tradeoff between privacy and weighting accuracy.
3. Scale up the experiments to larger population sizes (e.g., 100x expansion) to assess computational feasibility and model performance degradation in extreme cases.