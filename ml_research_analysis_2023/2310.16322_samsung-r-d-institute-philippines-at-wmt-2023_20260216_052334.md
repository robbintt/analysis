---
ver: rpa2
title: Samsung R&D Institute Philippines at WMT 2023
arxiv_id: '2310.16322'
source_url: https://arxiv.org/abs/2310.16322
tags:
- data
- bleu
- translation
- arxiv
- channel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors developed constrained Hebrew-English machine translation
  systems for the WMT 2023 task using Transformer models trained on carefully filtered
  parallel and backtranslated data. They employed a comprehensive data preprocessing
  pipeline with heuristic, ratio, and embedding-based filters, and used noisy channel
  reranking during decoding to improve translation quality.
---

# Samsung R&D Institute Philippines at WMT 2023

## Quick Facts
- arXiv ID: 2310.16322
- Source URL: https://arxiv.org/abs/2310.16322
- Reference count: 6
- Key outcome: Samsung R&D achieved competitive Hebrew-English translation performance (44.24 BLEU for en→he and 42.42 BLEU for he→en on FLORES-200) using constrained systems with significantly fewer parameters than unconstrained baselines

## Executive Summary
Samsung R&D Institute Philippines participated in the WMT 2023 General Translation Task for Hebrew-English, developing constrained machine translation systems using Transformer models. Their approach combined comprehensive data preprocessing, backtranslation with sampling, and noisy channel reranking to achieve competitive performance despite using significantly fewer parameters than strong unconstrained baselines. The systems demonstrated that carefully curated data and reranking methods can effectively compensate for smaller model sizes in constrained translation tasks.

## Method Summary
The authors developed Hebrew-English translation systems using Transformer models trained on parallel and backtranslated data that underwent comprehensive preprocessing. They employed a three-pronged filtering approach (heuristic, ratio-based, and embedding-based) to ensure data quality, then generated synthetic parallel data through backtranslation using combined top-k and nucleus sampling. During decoding, they implemented noisy channel reranking that combined direct translation, channel, and language model probabilities to select the best candidate translations. The models were trained with 65M and 200M parameters and evaluated on FLORES-200 and NTREX-128 benchmarks.

## Key Results
- Achieved 44.24 BLEU for en→he and 42.42 BLEU for he→en on FLORES-200 benchmark
- Reached 33.77 BLEU for en→he and 36.89 BLEU for he→en on NTREX-128 benchmark
- Demonstrated competitive performance with significantly smaller models (65M-200M parameters) compared to unconstrained baselines (587M-54B parameters)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Backtranslation with combined top-k and nucleus sampling generates higher-quality synthetic parallel data than standard beam search
- Mechanism: The sampling approach produces more diverse and natural synthetic translations that better capture the target language distribution, reducing overfitting to the original parallel corpus
- Core assumption: Diverse synthetic data improves model robustness and generalization more than conservative beam search outputs
- Evidence anchors:
  - [abstract] "create synthetic data through carefully-curated backtranslation"
  - [section] "we generate synthetic data via combined top-k and nucleus sampling"
  - [section] "Backtranslation is only performed once using the provided monolingual data"
- Break condition: If the monolingual data is too limited or the sampling hyperparameters are poorly tuned, synthetic data quality degrades and introduces noise

### Mechanism 2
- Claim: Noisy channel reranking effectively combines direct translation, channel, and language model probabilities to produce better translations
- Mechanism: The reranking framework leverages Bayes' rule to combine three complementary probability distributions, allowing the language model to correct systematic errors from the direct model while the channel model constrains outputs to be faithful to the source
- Core assumption: The three models capture complementary aspects of translation quality and their combination improves over any single model
- Evidence anchors:
  - [abstract] "use reranking methods to select the best candidate translations"
  - [section] "Noisy Channel Reranking (Yee et al., 2019), which reranks every candidate translation token"
  - [section] "During beam search decoding, we rescore the top candidates using the following linear combination"
- Break condition: If any component model is significantly weaker than others, it may degrade overall performance rather than improve it

### Mechanism 3
- Claim: Comprehensive data filtering pipeline significantly improves translation quality by removing noisy examples
- Mechanism: Multiple filtering strategies (heuristic, ratio, embedding-based) work together to eliminate problematic sentence pairs while preserving useful data, creating cleaner training data that leads to better models
- Core assumption: Removing low-quality parallel data improves overall model performance more than the loss of some potentially useful data
- Evidence anchors:
  - [abstract] "comprehensive data preprocessing pipeline to ensure parallel data quality"
  - [section] "we need to use a comprehensive data preprocessing pipeline to ensure good translation quality"
  - [section] "We use a combination of heuristic-based, ratio-based, and embedding-based methods to filter our data"
- Break condition: If filtering is too aggressive, it may remove too much data and hurt performance, especially for low-resource languages

## Foundational Learning

- Concept: Backtranslation in machine translation
  - Why needed here: The paper relies on backtranslation to augment limited parallel data for Hebrew-English translation
  - Quick check question: What are the key differences between beam search and sampling-based backtranslation approaches?

- Concept: Noisy channel model theory
  - Why needed here: The reranking method is based on noisy channel framework, combining direct, channel, and language models
  - Quick check question: How does Bayes' rule apply to the noisy channel reranking framework described?

- Concept: Data filtering strategies for parallel corpora
  - Why needed here: The paper employs multiple filtering methods to improve data quality before training
  - Quick check question: What are the trade-offs between heuristic, ratio-based, and embedding-based filtering approaches?

## Architecture Onboarding

- Component map:
  Data preprocessing pipeline (heuristic + ratio + embedding filters) -> Base translation models (Transformer, 65M and 200M parameters) -> Backtranslation module (top-k + nucleus sampling) -> Noisy channel reranking system (direct model + channel model + language model) -> Evaluation framework (BLEU, ChrF++ on FLORES-200 and NTREX-128)

- Critical path: Data preprocessing → Model training → Backtranslation → Reranking → Evaluation
- Design tradeoffs:
  - Model size vs. performance (65M vs 200M parameters)
  - Filtering strictness vs. data quantity
  - Sampling diversity vs. synthetic data quality
  - Reranking weights vs. individual model performance

- Failure signatures:
  - Poor filtering → noisy translations, low BLEU scores
  - Insufficient backtranslation → overfitting, poor generalization
  - Imbalanced reranking weights → degraded translation quality
  - Insufficient training steps → underfitting, especially for larger models

- First 3 experiments:
  1. Compare different filtering strategies on a small validation set to find optimal parameters
  2. Train base model without backtranslation to establish baseline performance
  3. Test different sampling hyperparameters for backtranslation on a validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do hyperparameter values for δch and δlm affect translation quality across different model sizes and datasets?
- Basis in paper: [explicit] The paper conducted Bayesian hyperparameter search for δch and δlm values while keeping length penalty static, finding optimal performance when both hyperparameters are set to 0.2~0.3.
- Why unresolved: While the paper found optimal values for their specific setup (Large 1M + BT models), it's unclear if these values generalize across different model sizes, datasets, or translation directions.
- What evidence would resolve it: Conducting similar hyperparameter searches across various model sizes, datasets, and translation pairs to determine if optimal values are consistent or context-dependent.

### Open Question 2
- Question: What is the impact of using different language models (LMs) on noisy channel reranking performance?
- Basis in paper: [inferred] The paper uses a base-sized decoder-only Transformer LM trained on cleaned parallel and monolingual data, but doesn't explore alternatives.
- Why unresolved: The paper uses a specific LM architecture and training data but doesn't compare against other LM configurations or pre-trained models.
- What evidence would resolve it: Experiments comparing performance using different LM architectures (e.g., GPT-style, BERT-style), training approaches, and pre-trained models.

### Open Question 3
- Question: How does the effectiveness of the comprehensive data preprocessing pipeline vary across different language pairs and data sources?
- Basis in paper: [explicit] The paper describes a comprehensive preprocessing pipeline with heuristic-based, ratio-based, and embedding-based filters specifically designed for Hebrew-English data.
- Why unresolved: While the pipeline is shown to be effective for Hebrew-English, its effectiveness for other language pairs or different data sources is not evaluated.
- What evidence would resolve it: Applying the same preprocessing pipeline to different language pairs and comparing translation quality with and without preprocessing.

## Limitations
- Evaluation conducted on public benchmarks (FLORES-200, NTREX-128) rather than actual WMT 2023 test sets
- Constrained systems used significantly less training data and smaller models compared to unconstrained baselines
- The relative contribution of each filtering component to final performance is not quantified through ablation studies

## Confidence
- **High confidence**: The core methodology of using Transformer models with backtranslation and noisy channel reranking is well-established and correctly implemented
- **Medium confidence**: The effectiveness of the specific filtering pipeline and backtranslation sampling parameters is supported by results but not rigorously validated
- **Low confidence**: Claims about competitiveness in the actual WMT 2023 constrained task are speculative without official test results

## Next Checks
1. Conduct ablation study removing each filtering method to quantify individual contributions to BLEU scores
2. Test wider range of backtranslation sampling parameters to determine sensitivity to k, p, and temperature values
3. Perform systematic grid search over δch and δlm values in noisy channel reranking to validate optimal ranges