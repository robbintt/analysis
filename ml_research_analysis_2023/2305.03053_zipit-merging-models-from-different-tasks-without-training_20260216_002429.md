---
ver: rpa2
title: ZipIt! Merging Models from Different Tasks without Training
arxiv_id: '2305.03053'
source_url: https://arxiv.org/abs/2305.03053
tags:
- zipit
- merging
- trained
- each
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of merging models trained on disjoint
  tasks without retraining. The authors propose ZipIt!, a method that generalizes
  model merging by allowing merging of features within each model (not just across
  models) and supports partial zipping to create multi-head models.
---

# ZipIt! Merging Models from Different Tasks without Training

## Quick Facts
- arXiv ID: 2305.03053
- Source URL: https://arxiv.org/abs/2305.03053
- Reference count: 40
- Key outcome: Outperforms prior work by 20-60% on merging models trained on disjoint tasks

## Executive Summary
ZipIt! addresses the challenge of merging models trained on disjoint tasks without retraining. The method generalizes model merging by allowing for merging features within each model (not just across models) and supports partial zipping to create multi-head models. Through extensive experiments on CIFAR, ImageNet, multi-dataset classification, and SinGAN image generation, ZipIt! demonstrates significant improvements over prior work, particularly as model capacity increases. The key insight is that within-model merging and partial zipping are critical for recovering performance when merging models trained on disjoint tasks.

## Method Summary
ZipIt! introduces a "zip" operation that merges models by finding correlations between features within and across models, rather than just permuting parameters. The method computes a merge matrix based on feature correlations, then propagates an unmerge matrix through the network to handle skip connections. It supports partial zipping where only early layers are merged while later layers remain separate, creating multi-head models. A same-model budget parameter controls how much merging occurs within individual models. The approach works with any model merging method that uses a merge matrix, including Git Re-Basin, and employs a greedy matching algorithm that is nearly as accurate as optimal matching while being much faster.

## Key Results
- Outperforms Git Re-Basin by 20-60% on CIFAR and ImageNet with disjoint class splits
- Successfully merges models trained on completely different datasets (Stanford Dogs, Oxford Pets, CUB200, NABirds)
- Extends to non-classification tasks by merging SinGAN models for image generation
- Performance benefits increase with model capacity
- Partial zipping effectively recovers performance by adding capacity while maintaining task separation

## Why This Works (Mechanism)

### Mechanism 1
Merging features within each model improves performance over permutation-only merging. The zip operation allows for merging of correlated features both within and across models, effectively compressing redundant information and preserving task-specific features. This works when there exists correlation between features within a single model's representation space that can be exploited for merging. The approach fails when models have minimal internal redundancy due to high task dissimilarity or architectural capacity limitations.

### Mechanism 2
Partial zipping preserves task-specific information in later layers while sharing early features. By selectively merging only the early layers and keeping later layers separate, the method creates a shared feature extractor while maintaining task-specific decision boundaries. This relies on the assumption that early layers learn more generalizable features while later layers encode task-specific information. The approach breaks down when task differences manifest primarily in early layers or when the decision boundary is too early in the network.

### Mechanism 3
The greedy matching algorithm effectively identifies correlated features without requiring optimal bipartite matching. The algorithm repeatedly selects the most correlated feature pairs across concatenated feature vectors, creating a merge matrix that preserves information while reducing dimensionality. This assumes greedy selection of feature pairs produces near-optimal merging results while being computationally efficient. The method fails when feature correlations are too weak or when the feature space is too high-dimensional for greedy selection to capture optimal matches.

## Foundational Learning

- **Neural network feature correlation and redundancy**: Understanding how features within and across models can be merged requires knowledge of feature correlation and redundancy. Quick check: What does it mean for two features to be "highly correlated" in a neural network's activation space?

- **Model merging and parameter interpolation**: The method builds on existing model merging techniques but extends them to handle disjoint tasks. Quick check: How does simple weight averaging differ from permutation-based merging in terms of handling feature space alignment?

- **Mode connectivity and loss landscape**: The motivation for merging models relies on understanding how models with different initializations relate in the loss landscape. Quick check: What does "mode connectivity" mean in the context of neural network training?

## Architecture Onboarding

- **Component map**: Merge matrix computation module -> Unmerge matrix propagation system -> Layer-wise merging engine -> Partial zipping controller

- **Critical path**: 1. Compute activations on training data, 2. Match features and build merge/unmerge matrices, 3. Propagate unmerge matrices forward through network, 4. Apply zip operation layer by layer, 5. Reset batch normalization parameters

- **Design tradeoffs**: Full zipping vs. partial zipping (accuracy vs. efficiency), Greedy matching vs. optimal matching (speed vs. precision), Same-model budget vs. cross-model merging (capacity utilization vs. task separation)

- **Failure signatures**: Poor performance when tasks are too dissimilar (low correlation), Degraded results with insufficient model capacity, Suboptimal merging when activation computation data is too limited

- **First 3 experiments**: 1. Merge two ResNet-20 models trained on disjoint CIFAR-10 class subsets, 2. Compare full zipping vs. partial zipping on the same setup, 3. Test the effect of same-model budget parameter (β) on merging quality

## Open Questions the Paper Calls Out

### Open Question 1
How does ZipIt! perform when merging models with very different architectures (e.g., ResNet vs. VGG) compared to models with the same architecture? The paper focuses on merging models of the same architecture but mentions ZipIt! could theoretically work on any domain. Experiments comparing ZipIt!'s performance on merging models with different architectures to merging models of the same architecture would provide evidence.

### Open Question 2
What is the impact of model capacity on ZipIt!'s performance when merging models trained on extremely different tasks (e.g., classification vs. generation)? The paper shows that ZipIt! benefits from increased model capacity when merging models trained on different classification tasks, but does not explore this for fundamentally different task types. Experiments comparing ZipIt!'s performance on merging models with varying capacities for different task types would provide evidence.

### Open Question 3
How does ZipIt! handle merging models with different input/output spaces (e.g., different image sizes or number of classes)? The paper mentions that ZipIt! supports partial zipping to create multi-head models when output spaces are incompatible, but does not provide detailed experiments on merging models with different input/output spaces. Experiments comparing ZipIt!'s performance on merging models with different input/output spaces to other methods would provide evidence.

### Open Question 4
What is the computational cost of ZipIt! compared to other model merging methods, especially for large-scale models? The paper mentions that ZipIt! is faster than the optimal matching algorithm but does not provide a detailed comparison of computational costs with other methods. Experiments comparing the computational cost of ZipIt! with other model merging methods on large-scale models would provide evidence.

## Limitations
- Limited evaluation on highly dissimilar tasks beyond classification
- Unclear computational complexity for very large-scale models
- Assumption of feature redundancy may not hold for specialized architectures

## Confidence
- **High confidence** in core ZipIt! mechanism and superiority over permutation-only methods (20-60% improvement)
- **Medium confidence** in generalization to SinGAN image generation due to limited quantitative evaluation
- **Low confidence** in scalability to very large models or highly dissimilar tasks based on current evaluation scope

## Next Checks
1. Implement the exact matching algorithm specification and test sensitivity to the same-model budget parameter β
2. Evaluate ZipIt! on language models trained on disjoint NLP tasks to assess cross-domain applicability
3. Conduct ablation studies comparing greedy matching vs. optimal matching on small-scale problems to quantify the claimed computational advantage