---
ver: rpa2
title: Rethinking Robustness of Model Attributions
arxiv_id: '2312.10534'
source_url: https://arxiv.org/abs/2312.10534
tags:
- top-k
- lens-prec
- intersection
- random
- robustness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work identifies a fundamental issue with existing metrics
  for evaluating the robustness of model attributions. Current metrics like top-k
  intersection overly penalize minor local changes in attribution maps, leading to
  a false sense of fragility.
---

# Rethinking Robustness of Model Attributions

## Quick Facts
- **arXiv ID**: 2312.10534
- **Source URL**: https://arxiv.org/abs/2312.10534
- **Reference count**: 40
- **Primary result**: Proposes locality-sensitive metrics (LENS) that better evaluate attribution robustness by incorporating spatial proximity of important pixels

## Executive Summary
This paper identifies a fundamental flaw in existing metrics for evaluating model attribution robustness: top-k intersection overly penalizes minor local changes in attribution maps, creating a false sense of fragility. The authors propose locality-sensitive metrics (LENS) that incorporate spatial proximity when measuring attributional similarity, along with diversity-based metrics to prevent concentration of attributions in small regions. Experiments across multiple datasets show LENS metrics provide more realistic assessments of attributional robustness that better align with human perception, revealing that adversarially trained models show improved attributional robustness on smaller datasets.

## Method Summary
The authors identify that existing top-k intersection metrics are overly sensitive to minor spatial shifts in attribution maps. They propose locality-sensitive improvements (LENS) that replace exact pixel matching with neighborhood matching - for example, LENS-top-k uses (2w+1)x(2w+1) neighborhoods around top-k pixels instead of just the pixels themselves. They also introduce diversity-based metrics that ensure important pixels are spatially separated to prevent concentration in small regions. The proposed LENS variants (LENS-top-k, LENS-Spearman, LENS-Kendall) are evaluated against traditional metrics across MNIST, Fashion MNIST, GTSRB, Flower, and ImageNet datasets using various attribution methods and attacks.

## Key Results
- LENS metrics consistently yield higher robustness scores compared to traditional metrics
- The improved scores better reflect human perception of attributional similarity under perturbations
- Adversarially trained models show improved attributional robustness on smaller datasets, though this advantage diminishes on larger datasets
- Diversity-based metrics effectively prevent concentration of attributions in small regions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Existing top-k intersection metrics over-penalize minor spatial shifts in attribution maps
- Mechanism: Top-k intersection counts exact pixel matches in top-k ranked positions, causing significant drops even when attribution values shift by one pixel within the same object region
- Core assumption: Attribution maps should be compared based on spatial locality, not just exact pixel positions
- Evidence anchors:
  - [abstract] "Current metrics like top-k intersection overly penalize minor local changes in attribution maps, leading to a false sense of fragility."
  - [section] "The currently used top-k intersection metric is then computed as: |Sk(x) ∩ Tk(x)| /k."

### Mechanism 2
- Claim: LENS metrics incorporate spatial proximity of important pixels for more realistic assessment
- Mechanism: LENS metrics replace exact pixel matching with neighborhood matching using (2w+1)x(2w+1) windows around top-k pixels
- Core assumption: Attribution maps have smooth spatial distributions where nearby pixels have similar importance
- Evidence anchors:
  - [abstract] "To address this, the authors propose locality-sensitive metrics (LENS) that incorporate the spatial proximity of important pixels when measuring attributional similarity."
  - [section] "We instead propose Locality-sENSitive top-k metrics (LENS-top-k) as |Nw(Sk(x)) ∩ Tk(x)| /k and |Sk(x) ∩ Nw(Tk(x))| /k."

### Mechanism 3
- Claim: Diverse attribution prevents concentration of important pixels in small regions
- Mechanism: Top-k diverse pixels algorithm selects important pixels with minimum spatial separation, ensuring attribution spreads across multiple regions
- Core assumption: Images often have multiple important regions, and concentrating attribution in one small region creates vulnerability
- Evidence anchors:
  - [abstract] "We also introduce diversity-based metrics to prevent concentration of attributions in small regions."
  - [section] "To alleviate this vulnerability, we propose post-processing any given attribution method to output top-k diverse pixels instead of just the top-k pixels with the highest attribution scores."

## Foundational Learning

- **Spatial locality in attribution maps**: Understanding why exact pixel matching is too strict and why neighborhood matching is more appropriate for human perception
  - Why needed here: To grasp why current metrics create false fragility through over-sensitivity to minor shifts
  - Quick check question: If an attribution map shifts by one pixel but remains within the same object, should the similarity score drop significantly? Why or why not?

- **Matroid theory and greedy algorithms**: The top-k diverse pixels algorithm uses matroid properties to ensure the greedy algorithm finds the optimal diverse set
  - Why needed here: To understand the theoretical foundation for selecting diverse important pixels
  - Quick check question: What properties must a set system have for a greedy algorithm to find the optimal solution?

- **Rank correlation metrics (Spearman's ρ, Kendall's τ)**: Understanding the original metrics used for attribution robustness and how LENS modifies them
  - Why needed here: To comprehend the baseline metrics being improved upon
  - Quick check question: What do Spearman's ρ and Kendall's τ measure, and how do they differ from top-k intersection?

## Architecture Onboarding

- **Component map**: Input images and attribution methods -> Attack generation (top-k, random, mass center) -> Compute attribution maps -> Calculate similarity metrics (top-k intersection, LENS variants, diversity metrics) -> Aggregate robustness results

- **Critical path**: Generate perturbations → Compute attribution maps → Calculate similarity metrics → Aggregate results

- **Design tradeoffs**: LENS metrics trade exact pixel matching for neighborhood matching, potentially reducing sensitivity to adversarial attacks while increasing robustness to minor shifts

- **Failure signatures**: If LENS metrics show high robustness scores but attribution maps look visually different, this suggests the locality assumption may not hold for that dataset or attribution method

- **First 3 experiments**:
  1. Compare top-k intersection vs LENS-top-k on a simple image with known spatial structure
  2. Test diverse attribution on an image with multiple important regions
  3. Evaluate PGD-trained vs naturally trained models using LENS metrics on a small dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the locality-sensitive metric perform across different types of adversarial attacks beyond those tested in the paper?
- Basis in paper: [explicit] The paper tests locality-sensitive metrics against top-k, random sign, and mass center attacks but acknowledges the need for further testing
- Why unresolved: The effectiveness of locality-sensitive metrics might vary with different attack strategies, and comprehensive testing across a broader range of attacks is needed
- What evidence would resolve it: Conducting experiments with a diverse set of adversarial attacks and comparing the locality-sensitive metrics' performance against traditional metrics

### Open Question 2
- Question: What is the theoretical justification for the choice of the neighborhood size (w) in the locality-sensitive metrics?
- Basis in paper: [inferred] The paper proposes locality-sensitive metrics incorporating pixel neighborhoods but does not provide a theoretical basis for the choice of neighborhood size
- Why unresolved: The choice of neighborhood size could significantly impact the metric's effectiveness, and a theoretical foundation for this choice is lacking
- What evidence would resolve it: Developing a theoretical framework that justifies the selection of neighborhood size based on the characteristics of the dataset and the model's architecture

### Open Question 3
- Question: How does the diversity of attribution methods affect the robustness of model explanations in real-world applications?
- Basis in paper: [explicit] The paper introduces a measure based on diversity that enriches model attributions by preventing the localized grouping of top model attributions
- Why unresolved: While the paper proposes a diversity measure, its practical impact on the robustness of model explanations in real-world scenarios remains unexplored
- What evidence would resolve it: Implementing the diversity measure in real-world applications and evaluating its impact on the robustness and interpretability of model explanations

## Limitations
- The choice of neighborhood window size (w) in LENS metrics could significantly impact results and may need dataset-specific tuning
- The paper assumes attribution maps are spatially smooth, but some methods (like Grad-CAM) produce sparse, localized attributions that might not benefit from locality-sensitive metrics
- The comparison with adversarially trained models shows dataset size dependency, but the underlying reasons for this phenomenon need further investigation

## Confidence

**Confidence Levels:**
- **High confidence**: The identification of top-k intersection's sensitivity to minor pixel shifts is well-supported by the abstract and methodology
- **Medium confidence**: The LENS metric implementation and its improved robustness assessment appear reasonable, but empirical validation across diverse attribution methods is needed
- **Low confidence**: The effectiveness of diverse attribution in reducing vulnerability to attacks needs more rigorous testing, as the underlying assumption about multiple important regions may not hold for all image types

## Next Checks

1. Test LENS metrics on attribution maps from methods known to produce sparse vs. dense attributions to verify the locality assumption
2. Conduct ablation studies varying the neighborhood window size (w) to determine optimal values for different datasets
3. Evaluate the correlation between LENS metric scores and human perceptual similarity ratings of attribution maps under perturbations