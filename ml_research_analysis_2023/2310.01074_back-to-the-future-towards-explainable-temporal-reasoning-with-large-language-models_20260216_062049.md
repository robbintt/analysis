---
ver: rpa2
title: 'Back to the Future: Towards Explainable Temporal Reasoning with Large Language
  Models'
arxiv_id: '2310.01074'
source_url: https://arxiv.org/abs/2310.01074
tags:
- temporal
- reasoning
- dataset
- language
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel task for explainable temporal reasoning,
  aiming to predict future events and provide clear reasoning. A multi-source instruction-tuning
  dataset, ExpTime, with 26k entries is constructed using a knowledge-graph-instructed-generation
  strategy.
---

# Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models

## Quick Facts
- **arXiv ID**: 2310.01074
- **Source URL**: https://arxiv.org/abs/2310.01074
- **Reference count**: 40
- **Primary result**: Introduces ExpTime dataset and TimeLlaMA models achieving state-of-the-art performance in explainable temporal reasoning through instruction tuning

## Executive Summary
This paper addresses the challenge of explainable temporal reasoning in large language models by introducing a novel task that predicts future events while providing clear reasoning paths. The authors construct a multi-source instruction-tuning dataset called ExpTime containing 26,000 entries using a knowledge-graph-instructed-generation strategy. They propose the TimeLlaMA series of models based on LlaMA2 that demonstrate state-of-the-art performance in both temporal prediction and explanation generation. The study reveals that instruction tuning can substantially improve LLMs' temporal reasoning capabilities even with limited high-quality data, and that model size does not necessarily correlate with performance gains in this domain under 13 billion parameters.

## Method Summary
The method involves constructing the ExpTime dataset using a knowledge-graph-instructed-generation strategy that leverages temporal knowledge graphs and explainable reasoning models. The dataset is then used to fine-tune LlaMA2-based models through instruction tuning, creating the TimeLlaMA series. The approach combines temporal knowledge graph reasoning paths with LLM prompting techniques to generate high-quality explanations. The models are evaluated on both prediction accuracy and explanation quality using automatic metrics (BLEU, ROUGE, BERTScore) and human evaluation focusing on correctness, completeness, and fluency.

## Key Results
- TimeLlaMA models achieve state-of-the-art performance in both temporal prediction and explanation generation
- Model size does not necessarily correlate with performance gains in temporal reasoning when using instruction tuning under 13 billion parameters
- Even with limited data (10-75% of full dataset), instruction-tuned models maintain strong performance in explanation metrics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Instruction tuning with high-quality temporal reasoning data significantly improves LLMs' temporal prediction and explanation generation.
- **Mechanism**: The ExpTime dataset provides structured reasoning paths and context information from temporal knowledge graphs, enabling LLMs to learn multi-step temporal reasoning.
- **Core assumption**: LLMs can effectively leverage structured knowledge from temporal knowledge graphs to enhance their temporal reasoning capabilities.
- **Evidence anchors**: "Our method achieves the state-of-the-art performance of temporal prediction and explanation generation"; "With proper instruction tuning using even a small volume of high-quality data, the temporal reasoning capabilities of LLMs can be substantially improved."
- **Break condition**: If the ExpTime dataset quality is poor or the knowledge-graph-instructed-generation strategy fails to produce coherent reasoning paths, the instruction tuning may not improve LLMs' temporal reasoning.

### Mechanism 2
- **Claim**: Temporal knowledge graphs provide explainable reasoning paths for event forecasting.
- **Mechanism**: Explainable temporal knowledge graph reasoning models generate reasoning paths that are converted into natural language explanations using two-level prompting with LLMs.
- **Core assumption**: Temporal knowledge graphs contain sufficient information to generate meaningful reasoning paths for event forecasting.
- **Evidence anchors**: "Using the future event prediction query of each datasets, we first extract its explainable reasoning paths and context information from the provided temporal knowledge graph"; "The key insight behind our approach is to leverage temporal knowledge graphs (TKGs)."
- **Break condition**: If the temporal knowledge graph does not contain relevant information for a given query or the LLM fails to convert the reasoning paths into coherent explanations.

### Mechanism 3
- **Claim**: LLMs' temporal reasoning performance is not necessarily correlated with model size when instruction tuning is applied.
- **Mechanism**: TimeLlaMA-7B outperformed TimeLlama-13B on positive class despite having fewer parameters when both were instruction-tuned on ExpTime.
- **Core assumption**: Instruction tuning on high-quality temporal reasoning data can effectively improve LLMs' capabilities regardless of model size.
- **Evidence anchors**: "Model size does not necessarily correlate with performance gains in temporal reasoning when employing instruction tuning under 13 billion parameters"; "Llama2-7b-chat actually outperforming Llama2-13b-chat on the positive class."
- **Break condition**: If instruction tuning fails to improve smaller models' temporal reasoning or if performance gaps between smaller and larger models are significant.

## Foundational Learning

- **Concept**: Temporal reasoning in NLP
  - **Why needed here**: Understanding temporal reasoning concepts is crucial for designing the ExpTime dataset and evaluating LLMs' performance on explainable temporal reasoning tasks.
  - **Quick check question**: What are the key differences between temporal relation extraction and event forecasting in terms of complexity and required reasoning steps?

- **Concept**: Temporal knowledge graphs (TKGs)
  - **Why needed here**: TKGs provide the structured knowledge and reasoning paths used to generate the ExpTime dataset and train the TimeLlaMA models.
  - **Quick check question**: How do explainable temporal knowledge graph reasoning models (e.g., TimeTraveler, TLogic) generate reasoning paths for event forecasting?

- **Concept**: Instruction tuning
  - **Why needed here**: Instruction tuning is the key technique used to improve LLMs' temporal reasoning capabilities by training them on the ExpTime dataset.
  - **Quick check question**: What are the benefits and potential drawbacks of using instruction tuning compared to traditional fine-tuning methods for improving LLMs' performance on specific tasks?

## Architecture Onboarding

- **Component map**: Knowledge graphs → Reasoning paths → ExpTime dataset → Instruction tuning → TimeLlaMA models → Evaluation

- **Critical path**:
  1. Construct the ExpTime dataset using the knowledge-graph-instructed-generation strategy.
  2. Train the TimeLlaMA models on the ExpTime dataset using instruction tuning.
  3. Evaluate the trained models on the gold temporal reasoning testing set using automatic and human evaluation metrics.

- **Design tradeoffs**:
  - Using smaller LLM (Llama2-7B) vs. larger one (Llama2-13B): Smaller models may be more efficient and achieve comparable performance, but larger models may have more capacity for learning complex patterns.
  - Focusing on positive samples vs. including negative and neutral samples: Including diverse samples can improve the model's ability to handle different scenarios but may increase dataset complexity.

- **Failure signatures**:
  - Poor performance on prediction or explanation generation: This may indicate issues with the ExpTime dataset quality, the instruction tuning process, or the evaluation metrics.
  - Inconsistencies between automatic and human evaluation results: This may suggest that the automatic metrics do not fully capture the quality of the explanations or that the human evaluation criteria need refinement.

- **First 3 experiments**:
  1. Evaluate different LLM sizes (Llama2-7B, Llama2-13B) on ExpTime dataset without instruction tuning to establish baseline.
  2. Train TimeLlaMA-7B and TimeLlama-13B on full ExpTime dataset using instruction tuning and compare performance to baseline.
  3. Investigate impact of dataset size on TimeLlaMA-7B performance by training on subsets (10%, 50%, 75%) and evaluating performance.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can model architecture be optimized to improve explainable temporal reasoning while minimizing parameter count?
- **Basis in paper**: [explicit] The paper notes that model size does not necessarily correlate with performance gains in temporal reasoning when employing instruction tuning under 13 billion parameters. Llama2-7b-chat outperformed Llama2-13b-chat on the positive class despite having fewer parameters.
- **Why unresolved**: The paper demonstrates that larger models do not guarantee better performance but does not provide a definitive explanation for why this occurs or how to optimize architecture for temporal reasoning tasks specifically.
- **What evidence would resolve it**: Comparative studies testing various architectural modifications (e.g., attention mechanisms, layer configurations) on temporal reasoning tasks while controlling for parameter count.

### Open Question 2
- **Question**: What is the minimum amount of high-quality training data required to achieve optimal performance in explainable temporal reasoning?
- **Basis in paper**: [explicit] The paper found that Llama2 fine-tuned on 75% of the dataset attained a higher F1 score for prediction accuracy compared to the full dataset, and Llama2 fine-tuned on just 10% of the data obtained similar performance on explanation metrics versus Llama2 fine-tuned on 75% and the full dataset.
- **Why unresolved**: While the paper shows reduced datasets can achieve comparable performance, it does not identify the precise threshold where additional data no longer provides meaningful improvements.
- **What evidence would resolve it**: Systematic experiments testing model performance across a broader range of dataset sizes (e.g., 5%, 15%, 25%, etc.) to identify the point of diminishing returns.

### Open Question 3
- **Question**: How can temporal reasoning datasets be expanded to cover more diverse event types and temporal relationships?
- **Basis in paper**: [inferred] The paper constructs its dataset from ICEWS temporal knowledge graphs, which primarily focus on diplomatic and political events. This suggests potential limitations in coverage of other event domains.
- **Why unresolved**: The paper demonstrates the effectiveness of its approach but acknowledges its dataset is limited to specific event types from ICEWS, leaving open questions about generalizability to other domains.
- **What evidence would resolve it**: Development and testing of explainable temporal reasoning models on datasets covering diverse domains (e.g., financial markets, healthcare, natural disasters) with varied temporal relationships.

## Limitations
- The findings are based on a single dataset (ExpTime) and specific LLMs (LlaMA2 variants), limiting generalizability to other temporal reasoning tasks or LLM architectures.
- Human evaluation of explanations involves subjective judgments that could introduce bias or inconsistency.
- The knowledge-graph-instructed-generation strategy relies on the quality and coverage of underlying temporal knowledge graphs, which may not capture all relevant temporal relationships.

## Confidence

- **High confidence**: The claim that instruction tuning with the ExpTime dataset improves LLMs' temporal reasoning capabilities is supported by strong empirical evidence, including state-of-the-art performance on prediction and explanation generation tasks.
- **Medium confidence**: The finding that model size does not necessarily correlate with performance gains in temporal reasoning when using instruction tuning is based on a comparison of two LLM sizes (7B and 13B), which may not be representative of the broader LLM landscape.
- **Medium confidence**: The assertion that temporal knowledge graphs provide sufficient information for generating meaningful reasoning paths is plausible but relies on the quality and coverage of the underlying knowledge graphs, which may vary.

## Next Checks
1. **Dataset quality assessment**: Conduct thorough analysis of the ExpTime dataset to ensure the knowledge-graph-instructed-generation strategy produces high-quality, diverse, and representative examples for temporal reasoning tasks through manual inspection and comparison with other temporal reasoning datasets.

2. **Generalization across LLM architectures**: Evaluate the performance of instruction-tuned LLMs on temporal reasoning tasks using different base model architectures (e.g., GPT, BERT) and sizes to assess generalizability beyond LlaMA2 variants.

3. **Zero-shot and few-shot performance**: Investigate the impact of instruction tuning on zero-shot and few-shot performance by evaluating fine-tuned models on unseen temporal reasoning tasks with limited or no additional training data to understand their ability to generalize temporal reasoning capabilities.