---
ver: rpa2
title: Investigating the Effect of Language Models in Sequence Discriminative Training
  for Neural Transducers
arxiv_id: '2310.07345'
source_url: https://arxiv.org/abs/2310.07345
tags:
- training
- context
- gram
- hypothesis
- space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates the effect of language models (LMs) with
  different context lengths and label units (phoneme vs. word) used in sequence discriminative
  training for phoneme-based neural transducers.
---

# Investigating the Effect of Language Models in Sequence Discriminative Training for Neural Transducers

## Quick Facts
- **arXiv ID**: 2310.07345
- **Source URL**: https://arxiv.org/abs/2310.07345
- **Reference count**: 0
- **Primary result**: Word-level LMs outperform phoneme-level LMs in sequence discriminative training for neural transducers

## Executive Summary
This work investigates the impact of language models with different context lengths and label units (phoneme vs. word) on sequence discriminative training for phoneme-based neural transducers. Both lattice-free and N-best-list approaches are examined. The authors propose a method to approximate context history for lattice-free methods with phoneme-level LMs, enabling efficient computation with full-context dependency. Systematic comparisons across different approaches show that word-level LMs generally outperform phoneme-level LMs, and that hypothesis space quality is more critical than its size for performance.

## Method Summary
The paper investigates sequence discriminative training for neural transducers using both lattice-free MMI and N-best-list MMI/MBR approaches. Lattice-free methods employ a context approximation technique to enable full-context dependency LM integration, while N-best-list methods use word-level LMs for hypothesis generation and rescoring. The study systematically compares different LM types (1-gram, 2-gram, 3-gram, full-context LSTM for phonemes; 1-gram, 4-gram for words), context lengths, and hypothesis space generation methods (pruning-recombination vs. forward-filtering-backward-sampling).

## Key Results
- Word-level LMs outperform phoneme-level LMs in both lattice-free and N-best-list MMI/MBR training
- The context size of LMs has limited effect on performance
- Hypothesis space quality is more critical than size for sequence discriminative training performance
- Pruning-recombination with phoneme-level LM produces better hypothesis space quality than forward-filtering-backward-sampling with word-level LM

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The context approximation method allows lattice-free MMI training with high-order phoneme-level LMs by reducing the effective context dependency during recombination.
- Mechanism: During dynamic programming recombination, instead of tracking the full context history, the algorithm selects the most probable predecessor hypothesis at each step and uses its associated context as an approximation. This reduces the effective context from full-length to a fixed limit k, enabling efficient computation while preserving key dependencies.
- Core assumption: The most probable predecessor hypothesis represents the dominant path through the hypothesis space, making its context a reasonable approximation for recombination.
- Evidence anchors:
  - [abstract] "For lattice-free methods with phoneme-level LMs, we propose a method to approximate the context history to employ LMs with full-context dependency."
  - [section 3.1.2] "Inspired by [26], we apply an approximation for the context at each recombination step. By employing this approximated context, we can efficiently perform recombination in a limited context dependency manner."
  - [corpus] Weak - no direct citations to support the approximation quality claim.
- Break condition: If the most probable predecessor hypothesis is not representative of the true optimal path, the approximation will introduce significant errors that degrade training quality.

### Mechanism 2
- Claim: Word-level LM integration in lattice-free training works by mapping phoneme-level contexts to word-level contexts only at word boundaries.
- Mechanism: When an end-of-word (EOW) phoneme is emitted, the accumulated phoneme history is mapped to a word sequence, and the word-level LM probability is computed. For non-EOW phonemes, the LM probability is set to 1, effectively disabling word-level LM influence except at boundaries.
- Evidence anchors:
  - [section 3.2.1] "Since there is no constraint on the context, a phoneme sequence may not be assigned to any word in the lexicon. In this case, we use the probability of the unknown token."
  - [section 3.2.1] "To apply the LM on word-level, the LM probability is only considered when emitting EOW phonemes, while the probability is set to 1 in other cases."
  - [corpus] Weak - no citations validating this specific mapping approach.
- Break condition: If the phoneme-to-word mapping is ambiguous or the EOW phoneme detection fails, the word-level LM integration will be incorrect or ineffective.

### Mechanism 3
- Claim: The quality of the hypothesis space is more critical than its size for sequence discriminative training performance.
- Mechanism: A high-quality hypothesis space contains diverse, representative hypotheses that capture the true error patterns in the model. When the hypothesis space is good, even a small N-best list can provide sufficient discriminative information. When the hypothesis space is poor, biased error patterns lead to suboptimal training regardless of size.
- Evidence anchors:
  - [abstract] "When the hypothesis space is of good quality, its size becomes less important, i.e. a small N-best list is sufficient."
  - [abstract] "When the hypothesis space is suboptimal, the biased error patterns that occur in the hypothesis space can lead to biased model outputs during sequence discriminative training, resulting in suboptimal performance."
  - [section 5.3] "Comparing different approaches used for hypothesis space generation with the 1-gram LM, pruning-recombination obtains better performance due to the phoneme-level LM used to help the search process."
- Break condition: If the hypothesis generation method consistently produces poor quality hypotheses, increasing the hypothesis space size will not improve performance and may even degrade it through noise amplification.

## Foundational Learning

- Concept: Dynamic programming for sequence scoring
  - Why needed here: The lattice-free methods rely on dynamic programming to efficiently compute the denominator in MMI training by summing over all possible phoneme sequences.
  - Quick check question: How does the forward-backward algorithm in HMM training relate to the dynamic programming approach used in lattice-free MMI?

- Concept: Language model integration with transducer models
  - Why needed here: Understanding how external LMs are integrated with neural transducers is crucial for implementing the word-level LM methods described in the paper.
  - Quick check question: What is the difference between shallow fusion and deep fusion when integrating external language models with end-to-end speech recognition systems?

- Concept: Context dependency in language models
  - Why needed here: The paper compares LMs with different context lengths (1-gram to full-context LSTM), and understanding how context affects LM performance is essential.
  - Quick check question: How does increasing the context length of an n-gram language model affect its perplexity and potential for data sparsity?

## Architecture Onboarding

- Component map: Encoder (12-layer conformer) -> Prediction network (2-layer feed-forward) -> Joint network -> LM integration -> Training loss computation
- Critical path: Encoder → Prediction network → Joint network → LM integration → Training loss computation
- Design tradeoffs: 
  - Lattice-free vs N-best list approaches: LF methods are faster but require context approximation; N-best list methods are more flexible but computationally expensive
  - Phoneme vs word-level LMs: Word-level LMs capture higher-level linguistic patterns but require complex integration; phoneme-level LMs are simpler but may miss word-level dependencies
  - Context length: Longer contexts improve modeling quality but increase computational cost and data sparsity

- Failure signatures:
  - Training divergence: Often indicates insufficient hypothesis space diversity or poor LM integration
  - Performance plateaus: May indicate that the hypothesis space quality has reached its limit or that the LM context length is insufficient
  - Degradation with larger hypothesis spaces: Suggests poor quality hypotheses are being generated

- First 3 experiments:
  1. Implement and validate the phoneme-level context approximation method with a simple 2-gram LM
  2. Test word-level LM integration using the EOW phoneme mapping approach with a 1-gram word LM
  3. Compare N-best list generation quality using different word-level LMs (1-gram vs 4-gram) and measure their impact on final WER

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does hypothesis space quality affect the performance of lattice-free MMI training with word-level LMs in the same way as it does with phoneme-level LMs?
- Basis in paper: [explicit] The paper shows that hypothesis space quality is critical for performance with phoneme-level LMs, and that word-level LMs perform better than phoneme-level LMs. However, the specific interaction between word-level LMs and hypothesis space quality is not fully explored.
- Why unresolved: The paper only briefly mentions the potential for word-level LMs to benefit from good hypothesis space quality, but does not conduct a detailed investigation of this relationship.
- What evidence would resolve it: Systematic experiments comparing the performance of lattice-free MMI training with word-level LMs across different hypothesis space qualities, including both good and poor quality spaces.

### Open Question 2
- Question: How does the size of the hypothesis space affect the performance of N-best-list-based MMI training when using word-level LMs?
- Basis in paper: [explicit] The paper shows that hypothesis space size is less important when the space is of good quality, but does not investigate the specific effect of hypothesis space size on word-level LM performance in N-best-list-based MMI training.
- Why unresolved: The paper focuses on comparing different LM types and hypothesis space generation methods, but does not systematically vary the size of the N-best list when using word-level LMs.
- What evidence would resolve it: Experiments varying the N-best list size (e.g., 1, 4, 16, 64) for word-level LM-based MMI training, while keeping other factors constant.

### Open Question 3
- Question: What is the impact of the quality of the N-best list on the performance of sequence discriminative training methods beyond MMI and MBR?
- Basis in paper: [explicit] The paper demonstrates the importance of N-best list quality for MMI and MBR training, but does not explore its effect on other sequence discriminative training criteria.
- Why unresolved: The paper's focus on MMI and MBR training limits the generalizability of its findings to other sequence discriminative training methods.
- What evidence would resolve it: Experiments applying different sequence discriminative training criteria (e.g., MPE, sMBR) to N-best lists of varying quality, and comparing their performance to MMI and MBR results.

## Limitations

- The context approximation method for lattice-free MMI lacks rigorous validation through error analysis or ablation studies
- Word-level LM integration method has potential failure modes with ambiguous phoneme-to-word mappings that are not addressed
- The experimental design does not perfectly isolate hypothesis space quality from other factors when comparing different generation methods

## Confidence

- **Lattice-free MMI with context approximation**: Medium
- **Word-level LM integration for lattice-free methods**: Low
- **Hypothesis space quality vs. size tradeoff**: Medium
- **Performance benefits of word-level LMs**: High (based on empirical results)
- **Limited effect of LM context size**: High (consistent experimental evidence)

## Next Checks

1. **Approximation error analysis**: Implement a diagnostic tool to measure the divergence between the true context history and the approximated context used in lattice-free MMI training. Compare WER degradation as approximation error increases to establish the method's robustness bounds.

2. **Word-level LM mapping validation**: Create test cases with ambiguous phoneme sequences and measure the word-level LM's ability to correctly map them to word sequences. Quantify the frequency and impact of cases where the LM cannot assign probabilities to generated phoneme hypotheses.

3. **Hypothesis space quality isolation**: Design an experiment that controls for hypothesis space quality while varying size. Generate high-quality N-best lists using different methods but enforce the same size constraint, then measure the impact on final WER to definitively establish the quality vs. size tradeoff.