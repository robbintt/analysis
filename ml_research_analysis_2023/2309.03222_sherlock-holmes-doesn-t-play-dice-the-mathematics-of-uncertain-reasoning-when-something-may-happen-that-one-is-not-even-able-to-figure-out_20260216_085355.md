---
ver: rpa2
title: 'Sherlock Holmes Doesn''t Play Dice: The mathematics of uncertain reasoning
  when something may happen, that one is not even able to figure out'
arxiv_id: '2309.03222'
source_url: https://arxiv.org/abs/2309.03222
tags:
- theory
- evidence
- probability
- information
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Evidence Theory (ET) extends Probability Theory to express uncertainty\
  \ about unknown possibilities. Unlike probability theory, which assumes a known\
  \ possibility set, ET allows for a mass m(\u0398) 0 representing fear of unexpected\
  \ events."
---

# Sherlock Holmes Doesn't Play Dice: The mathematics of uncertain reasoning when something may happen, that one is not even able to figure out

## Quick Facts
- arXiv ID: 2309.03222
- Source URL: https://arxiv.org/abs/2309.03222
- Reference count: 40
- Primary result: Evidence Theory extends Probability Theory to express uncertainty about unknown possibilities through m(Θ) > 0 representing fear of unexpected events

## Executive Summary
Evidence Theory (ET) extends Probability Theory to handle radical uncertainty by allowing for unknown possibilities through the m(Θ) > 0 term. Unlike traditional probability approaches that assume a known possibility set, ET can express fear of unforeseen events that decision-makers cannot anticipate. The authors demonstrate that ET's combination rule relates to Bayes' Theorem in specific cases and that ET's entropy function can capture order-from-noise principles in living organisms through its non-specificity term.

## Method Summary
The paper applies Evidence Theory (Dempster-Shafer Theory) to model uncertainty in man-machine interaction during financial auditing with Large Language Models. The approach involves defining a frame of discernment with specific audit concerns, creating bodies of evidence with mass functions based on auditor-LLM interactions, and applying the Dempster-Shafer combination rule to calculate combined beliefs. The method focuses on representing how contradictory evidence affects the combined belief about financial assertion validity.

## Key Results
- ET's combination rule generalizes Bayes' Theorem for overlapping sets, with the numerator capturing serial testimony logic and the denominator handling contradictory evidence
- ET's entropy function includes a non-specificity term [Pl(Ai) - Bel(Ai)] that measures uncertainty from overlapping sets, enabling random mutations to generate novel meanings
- An automated auditing tool example demonstrates how ET represents man-machine interaction when encountering contradictory evidence about financial assertions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ET expresses uncertainty about unknown possibilities through m(Θ) > 0
- Mechanism: By omitting the complement operation from the frame of discernment, ET prevents residual events from being defined, allowing m(Θ) to represent fear of unforeseen events
- Core assumption: Decision-makers can reason about possibilities without formalizing all logical operations
- Evidence anchors:
  - [abstract] "Unlike probability theory, which assumes a known possibility set, ET allows for a mass m(Θ) > 0 representing fear of unexpected events."
  - [section] "The key feature of all these events is that decision-makers had not been able to figure them out in advance, and therefore, they induce decision-makers to think that other novel and potentially disruptive possibilities may materialize."
- Break condition: If the decision-maker requires explicit logical closure over all possibilities, the m(Θ) term loses interpretability

### Mechanism 2
- Claim: Dempster-Shafer combination rule generalizes Bayes' Theorem for overlapping sets
- Mechanism: The numerator captures serial testimony logic, while the denominator applies parallel testimony logic to handle contradictory evidence
- Core assumption: Incoming evidence can be expressed as mass assignments over sets, not just probabilities over singletons
- Evidence anchors:
  - [abstract] "The authors show that Dempster-Shafer's combination rule relates to Bayes' Theorem in specific cases."
  - [section] "The numerator of eq. 2 measures the extent to which the two bodies of evidence support Ck, whereas the denominator measures the extent to which they are not contradictory with one another."
- Break condition: When evidence bodies have disjoint supports with no intersection, the combination rule reduces to simple product, losing its distinguishing power

### Mechanism 3
- Claim: ET's entropy function captures order-from-noise principles in living organisms
- Mechanism: The entropy includes a non-specificity term [Pl(Ai) - Bel(Ai)] that measures uncertainty from overlapping sets, enabling random mutations to generate novel meanings
- Core assumption: Information transmission in biological systems involves codes with multiple possible interpretations
- Evidence anchors:
  - [abstract] "The authors demonstrate that ET's entropy function, which includes a term for uncertainty due to non-specificity, can capture order-from-noise principles in living organisms."
  - [section] "The second term of eq. 7 is absent in Shannon's entropy. It measures the uncertainty due to the non-specificity of masses m(Ai), which can generate a difference between Pl(Ai) and Bel(Ai)."
- Break condition: If the system requires precise, non-overlapping categorization, the non-specificity term becomes zero and ET entropy reduces to Shannon entropy

## Foundational Learning

- Concept: Frame of discernment and mass assignments
  - Why needed here: ET operates on sets of possibilities rather than probability distributions over singletons
  - Quick check question: What distinguishes a frame of discernment from a probability space?

- Concept: Dempster-Shafer combination rule
  - Why needed here: The core mechanism for combining evidence bodies with overlapping or contradictory information
  - Quick check question: How does the denominator in the combination rule handle contradictory evidence?

- Concept: Belief and plausibility functions
  - Why needed here: These functions translate mass assignments into interpretable measures of support for hypotheses
  - Quick check question: What is the relationship between Bel(H) and Pl(H) for any hypothesis H?

## Architecture Onboarding

- Component map:
  - Frame of discernment Θ -> Mass function m(.) -> Dempster-Shafer combination rule -> Belief function Bel(.) -> Plausibility function Pl(.) -> Entropy function H(.)

- Critical path:
  1. Define frame of discernment Θ based on available evidence
  2. Assign masses m(Ai) to subsets reflecting evidence support
  3. Apply Dempster-Shafer combination rule to merge evidence bodies
  4. Compute belief and plausibility functions for hypothesis evaluation
  5. Calculate entropy to measure total uncertainty

- Design tradeoffs:
  - Using overlapping sets vs. singletons: ET allows nuanced representation but requires more complex calculations
  - Including m(Θ) > 0: Captures radical uncertainty but may reduce specificity
  - Choosing entropy function: Different definitions emphasize different uncertainty aspects

- Failure signatures:
  - Dempster-Shafer combination yields m(Θ) ≈ 1: Evidence bodies are highly contradictory
  - Belief and plausibility functions converge: Evidence is highly specific with little uncertainty
  - Entropy approaches Shannon entropy: Non-specificity term becomes negligible

- First 3 experiments:
  1. Implement Dempster-Shafer combination for two evidence bodies with known overlapping sets, verify against Bayes' Theorem when sets are singletons
  2. Calculate belief and plausibility functions for a hypothesis with varying evidence support, observe Bel(H) ≤ Pl(H) relationship
  3. Compute ET entropy for a simple frame with overlapping sets, compare to Shannon entropy when sets become singletons

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific mathematical formulation of Evidence Theory entropy can effectively capture the order-from-noise principle in living organisms?
- Basis in paper: [explicit] The authors discuss that current entropy functions for Evidence Theory are "still unsettled" and mention a recent proposal (eq. 7) but note it has limitations when applying conditional entropy with Dempster-Shafer combination rule
- Why unresolved: Existing entropy formulations either don't properly handle conditioning through Dempster-Shafer rule or are limited to first terms of the entropy equation
- What evidence would resolve it: Development and validation of an entropy function that can properly apply conditioning through Dempster-Shafer combination rule while capturing both uncertainty from possibility count/probability and non-specificity

### Open Question 2
- Question: How can Evidence Theory be effectively integrated with Large Language Models for automated auditing applications?
- Basis in paper: [explicit] The authors provide a numerical example of using Evidence Theory in an automated auditing tool but note they won't discuss technical details, focusing instead on how ET might represent man-machine interaction
- Why unresolved: While the paper demonstrates potential application, it doesn't provide technical implementation details or validation of the approach
- What evidence would resolve it: Implementation and evaluation of an automated auditing system using Evidence Theory to represent the auditor-LLM interaction, showing improved performance or reliability compared to traditional approaches

### Open Question 3
- Question: What is the fundamental relationship between Evidence Theory and Probability Theory when dealing with unknown unknowns?
- Basis in paper: [explicit] The authors emphasize that Evidence Theory can express radical uncertainty about unknown possibilities while Probability Theory cannot, but they note that Dempster-Shafer combination rule can be understood within extended Probability Theory
- Why unresolved: The paper suggests these are fundamentally different paradigms but also shows how some aspects of ET can be mapped to Probability Theory, creating apparent tension
- What evidence would resolve it: Clear mathematical framework distinguishing when and why ET is necessary versus when Probability Theory extensions suffice, with specific decision criteria for choosing between approaches

### Open Question 4
- Question: How can Evidence Theory be extended to handle multi-agent interactions beyond the detective/gambler paradigm?
- Basis in paper: [explicit] The authors mention that "a further extension to multi-agent interaction is outlined" but don't elaborate on what this extension would entail
- Why unresolved: The paper focuses on single decision-maker scenarios and doesn't explore how ET would handle multiple interacting agents with potentially conflicting evidence and belief systems
- What evidence would resolve it: Development of a formal multi-agent Evidence Theory framework with specific rules for combining evidence across agents and handling conflicts, validated through simulations or real-world applications

## Limitations

- The mathematical relationship between Dempster-Shafer combination and Bayes' Theorem is demonstrated only in "specific cases" without clear boundaries for when the generalization breaks down
- The biological application to order-from-noise principles relies on theoretical connections rather than empirical validation in actual living systems
- The auditing tool example remains at a conceptual level without demonstrating practical implementation or quantitative results

## Confidence

**Medium Confidence**: Claims about ET's ability to express uncertainty about unknown possibilities through m(Θ) > 0. While the theoretical framework is sound, the paper lacks concrete examples showing how this differs meaningfully from probability-based approaches in practice.

**Medium Confidence**: The connection between Dempster-Shafer combination rule and Bayes' Theorem. The paper asserts the relationship exists but doesn't provide the mathematical derivation or specify the exact conditions under which this holds.

**Low Confidence**: The application to biological systems and automated auditing. These applications are described conceptually but lack implementation details, validation results, or quantitative comparisons with alternative approaches.

## Next Checks

1. **Mathematical Derivation Validation**: Derive the explicit mathematical conditions under which the Dempster-Shafer combination rule reduces to Bayes' Theorem for singleton sets, and identify where the generalization fails for non-singleton sets.

2. **Empirical Application Testing**: Implement the ET framework in a controlled auditing scenario with synthetic data where ground truth is known, comparing ET's performance against traditional probability-based methods for detecting financial statement errors.

3. **Biological Information Transfer Analysis**: Model a simple biological information transmission system (e.g., genetic code mutation) using both Shannon entropy and ET entropy, quantifying the difference the non-specificity term makes in predicting order-from-noise phenomena.