---
ver: rpa2
title: 'ProtoExplorer: Interpretable Forensic Analysis of Deepfake Videos using Prototype
  Exploration and Refinement'
arxiv_id: '2309.11155'
source_url: https://arxiv.org/abs/2309.11155
tags:
- prototypes
- prototype
- video
- system
- deepfake
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ProtoExplorer, a Visual Analytics system for
  exploring and refining prototype-based deepfake detection models. The system addresses
  the challenge of interpretability in deepfake detection by allowing forensic experts
  to interactively refine the prototypes used in a Dynamic Prototype Network (DPNet)
  model.
---

# ProtoExplorer: Interpretable Forensic Analysis of Deepfake Videos using Prototype Exploration and Refinement

## Quick Facts
- arXiv ID: 2309.11155
- Source URL: https://arxiv.org/abs/2309.11155
- Reference count: 40
- Key outcome: Visual Analytics system enabling forensic experts to explore and refine prototype-based deepfake detection models for improved interpretability

## Executive Summary
This paper presents ProtoExplorer, a Visual Analytics system designed to address the interpretability challenges in deepfake detection using prototype-based deep learning models. The system enables forensic experts to interactively refine prototypes in a Dynamic Prototype Network (DPNet) model by visualizing prototype contributions to predictions and allowing expert-guided deletion and replacement of prototypes. The approach aims to create more interpretable and less biased detection models while maintaining accuracy. The system was developed and evaluated through collaboration with video forensic experts, who confirmed its effectiveness in exploring prototype-based deepfake detection models and identified areas for further improvement.

## Method Summary
ProtoExplorer is built around the DPNet architecture, which uses dynamic prototypes incorporating both spatial and temporal information from optical flow fields. The system preprocesses video frames to extract face crops and compute optical flow for 9 consecutive frames. Experts interact with a Qt-based GUI that displays multiple visualization panels showing prototypes, performance metrics, and video playback. The refinement process allows experts to delete redundant prototypes and replace them with candidates selected from a UMAP visualization. The system recalculates model performance after each refinement operation, highlighting changes in detection accuracy and fairness metrics. The evaluation used the FaceForensics++ dataset with specific training parameters including 20 prototypes per class and weighted loss terms.

## Key Results
- ProtoExplorer enables interactive refinement of prototype-based deepfake detection models while preserving detection accuracy
- Expert evaluation revealed gaps between system prototypes useful for classification versus prototypical examples used by forensic experts
- The system provides tools for visualizing and temporally filtering prototype-based predictions in video data
- Evaluation identified the need for additional prototypes to increase diversity and cover all facial regions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic prototypes combining spatial and temporal information improve deepfake detection accuracy over static image-based prototypes.
- Mechanism: Optical flow fields capture temporal inconsistencies characteristic of deepfakes not visible in individual frames.
- Core assumption: Temporal inconsistencies are distinguishing features of deepfakes detectable through optical flow analysis.
- Evidence anchors: [abstract] "prototype-based methods have emerged as a promising approach to make deep learning interpretable"; [section] "DPNet uses dynamic prototypes containing not only spatial but also temporal information provided by pre-computed optical flow fields."
- Break Condition: If temporal inconsistencies are not reliable indicators across different generation methods, or if optical flow introduces noise obscuring manipulation.

### Mechanism 2
- Claim: Interactive prototype refinement by forensic experts improves model interpretability without significantly degrading detection accuracy.
- Mechanism: Experts delete redundant prototypes and replace them with candidates representing better forensic indicators.
- Core assumption: Expert knowledge can guide prototype selection in ways automated methods cannot achieve.
- Evidence anchors: [abstract] "It further enables the refinement of models by interactively deleting and replacing prototypes with the aim to achieve more interpretable and less biased predictions while preserving detection accuracy"; [section] "evaluation with the experts indeed revealed the gap between the system prototypes that are good for classification and the prototypical examples experts use."
- Break Condition: If expert refinement consistently degrades performance, or experts cannot agree on useful prototypes.

### Mechanism 3
- Claim: Visual Analytics interface showing prototype contributions enables court-admissible explanations for deepfake detection.
- Mechanism: Visualizing which prototypes contribute to each prediction and the spatial regions they represent traces model decisions back to specific visual indicators.
- Core assumption: Visual similarity-based explanations are sufficient for forensic experts to construct legally defensible arguments.
- Evidence anchors: [abstract] "ProtoExplorer offers tools for visualizing and temporally filtering prototype-based predictions when working with video data"; [section] "The system explains itself in terms of the prototypes and how they contribute to the final score."
- Break Condition: If visual explanations don't align with forensic reasoning, or courts require additional evidence forms.

## Foundational Learning

- Concept: Prototype-based neural networks
  - Why needed here: Understanding how prototypes function as representative examples in the model's decision-making process
  - Quick check question: Can you explain how prototype similarity scores translate into final classification decisions in DPNet?

- Concept: Optical flow computation for video analysis
  - Why needed here: Temporal prototypes depend on optical flow fields to capture motion information between frames
  - Quick check question: What specific artifacts in optical flow fields might indicate deepfake manipulation?

- Concept: Visual Analytics design principles for high-stakes applications
  - Why needed here: System must balance interpretability, accuracy, and usability for forensic experts needing to defend decisions in court
  - Quick check question: How does the system's design address the tension between model complexity and explainability required in forensic contexts?

## Architecture Onboarding

- Component map: Frontend (Qt-based GUI with visualization panels) -> Backend (Python application handling DPNet inference and refinement) -> Data pipeline (pre-processed video with optical flow) -> Model layer (DPNet with feature encoder, prototype layer, class layer)

- Critical path: 1) Load pre-trained DPNet model and video data, 2) Display prototype visualization and performance metrics, 3) Enable expert interaction for prototype refinement, 4) Recompute model performance after each refinement, 5) Provide updated visualizations reflecting model changes

- Design tradeoffs: Prototype quantity vs. interpretability (more prototypes improve accuracy but reduce interpretability), Temporal vs. spatial focus (temporal information improves detection but complicates visualization), Real-time vs. batch processing (interactive refinement requires fast recomputation but may sacrifice optimization)

- Failure signatures: Long computation delays during prototype refinement, Inconsistent prototype visualizations across viewing modes, Degradation in model performance after refinement operations, Difficulty selecting appropriate candidate prototypes from UMAP visualization

- First 3 experiments: 1) Load sample model and video, verify all visualization panels display correctly and prototype contributions match expected values, 2) Perform prototype deletion on redundant prototype, verify performance metrics update correctly and changes are highlighted, 3) Replace prototype with candidate from UMAP visualization, verify new prototype appears in correct location and performance impact is accurately calculated

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can prototype-based deepfake detection models be improved to better cover all facial regions and reduce bias in terms of race and gender?
- Basis in paper: [explicit] The paper mentions experts need to add additional prototypes to increase diversity and cover all facial regions, and discusses representation bias in FaceForensics++ dataset.
- Why unresolved: Paper identifies the issue but doesn't provide concrete solution or methodology for addressing these problems.
- What evidence would resolve it: Empirical studies comparing models with and without additional loss terms or data augmentation techniques, along with improved landmark density visualizations showing more even distribution.

### Open Question 2
- Question: How can the interpretability of prototype-based predictions be improved when using spatio-temporal prototypes that combine spatial and temporal information?
- Basis in paper: [explicit] Paper discusses challenges interpreting prototype-based predictions with spatio-temporal prototypes, noting activation maps don't always compare same facial regions.
- Why unresolved: Paper identifies the problem but doesn't offer clear solution for making spatio-temporal prototype-based predictions more interpretable.
- What evidence would resolve it: Development and evaluation of new visualization techniques or model architectures that better separate and explain spatial and temporal components.

### Open Question 3
- Question: What are the most effective criteria for forensic experts to use when deciding whether to delete or replace prototypes in prototype-based deepfake detection models?
- Basis in paper: [explicit] Paper discusses criteria experts use like avoiding duplicate prototypes and increasing diversity, but mentions need for more sophisticated search methods based on semantic characteristics.
- Why unresolved: Paper provides some insights into expert decision-making but doesn't establish comprehensive criteria or methodology balancing interpretability and performance.
- What evidence would resolve it: Comparative studies of different prototype refinement strategies and their impact on model performance and interpretability, along with expert feedback on effectiveness of various criteria.

## Limitations
- Evaluation with only three forensic experts provides limited generalizability of findings
- Lack of quantitative comparison between prototype-refined models and baseline approaches makes it difficult to assess actual impact on detection accuracy
- System's dependence on optical flow computation introduces potential noise affecting both detection performance and reliability of temporal prototypes

## Confidence
- Claims about improving interpretability through prototype refinement: Medium confidence
- Claims about court-admissible explanations: Low confidence
- Technical claims regarding DPNet's performance improvements: Medium confidence

## Next Checks
1. **Expert Validation Study**: Conduct a larger study with 15+ forensic experts across different jurisdictions to assess whether prototype-based explanations are considered legally admissible and practically useful in real forensic workflows.

2. **Ablation Performance Analysis**: Systematically remove the temporal component (optical flow) from DPNet and measure the performance degradation to quantify the actual contribution of temporal prototypes to detection accuracy.

3. **Legal Expert Review**: Engage legal experts to review prototype-based explanations and assess whether they meet standards for forensic evidence in court proceedings, identifying any gaps between visual explanations and legal requirements.