---
ver: rpa2
title: 'Overview of GUA-SPA at IberLEF 2023: Guarani-Spanish Code Switching Analysis'
arxiv_id: '2309.06163'
source_url: https://arxiv.org/abs/2309.06163
tags:
- task
- guarani
- spanish
- language
- phase
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the GUA-SPA shared task for code-switching
  analysis in Guarani and Spanish, held at IberLEF 2023. The task addressed the challenge
  of detecting and analyzing code-switching in a low-resource indigenous language
  (Guarani) paired with a high-resource language (Spanish).
---

# Overview of GUA-SPA at IberLEF 2023: Guarani-Spanish Code Switching Analysis

## Quick Facts
- arXiv ID: 2309.06163
- Source URL: https://arxiv.org/abs/2309.06163
- Reference count: 17
- Primary result: ITML team achieved best overall results in code-switching analysis of Guarani-Spanish texts

## Executive Summary
This paper presents the GUA-SPA shared task for analyzing Guarani-Spanish code-switching, held at IberLEF 2023. The task addressed the challenge of detecting and analyzing code-switching in a low-resource indigenous language (Guarani) paired with a high-resource language (Spanish). Three tasks were defined: language identification of tokens, named entity recognition, and classifying how Spanish spans are used in code-switched contexts. A manually annotated corpus of 1500 texts was created, containing approximately 25,000 tokens. Three teams participated in the evaluation phase, with the ITML team achieving the best overall results. Performance was generally strong for Task 1 (weighted F1 up to 0.938), but more mixed for Tasks 2 and 3, with the highest labeled F1 for Task 3 reaching only 0.384, indicating significant room for improvement.

## Method Summary
The GUA-SPA task involved three sub-tasks: (1) language identification of tokens into Guarani, Spanish, or mixed categories, (2) named entity recognition in code-switched contexts, and (3) classification of Spanish spans by usage type (code change vs unadapted loan). A manually annotated corpus of 1500 texts from news articles and tweets was created. Baseline approaches included word frequency-based classification and BIO tagging. Participants used fine-tuned multilingual models like RoBERTa, NLLB, and BETO, with multi-task learning for Tasks 2 and 3. The ITML team won by implementing multi-task learning with shared encoders and fine-tuning on monolingual Guarani data.

## Key Results
- ITML team achieved best overall results across all three tasks
- Task 1 (language identification) showed strong performance with weighted F1 up to 0.938
- Task 3 (Spanish span classification) had lowest performance with labeled F1 of 0.384
- Mixed tokens (combining Guarani and Spanish) were particularly challenging, with only 487 examples in the corpus

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-task learning with shared encoder improves performance on low-resource Guarani-Spanish code-switching detection.
- Mechanism: The model uses a common pre-trained LLM encoder fine-tuned on all three tasks, leveraging shared linguistic features across tasks to improve generalization in data-scarce environments.
- Core assumption: Linguistic features useful for language identification overlap significantly with those needed for NER and Spanish span classification.
- Evidence anchors:
  - [section] "They implemented their solution as a Multi-task learning problem where pre-trained encoder-decoder models were fine-tuned based on a hard parameter-sharing approach."
  - [section] "The team got the first position in the competition for the three tasks, after finding that fine-tuning the multilingual representations with unlabeled monolingual Guarani data is beneficial for all three tasks."
  - [corpus] Weak - corpus shows low token counts for Guarani but no explicit evidence of multilingual representation usage.
- Break condition: Tasks require completely disjoint feature sets, making shared encoder optimization counterproductive.

### Mechanism 2
- Claim: Fine-tuning multilingual representations with monolingual Guarani data improves code-switching detection accuracy.
- Mechanism: Unsupervised pre-training on Guarani monolingual data helps the model learn language-specific patterns that transfer to better code-switching detection.
- Core assumption: Guarani monolingual patterns are sufficiently represented in the fine-tuning data to improve downstream code-switching tasks.
- Evidence anchors:
  - [section] "The team got the first position in the competition for the three tasks, after finding that fine-tuning the multilingual representations with unlabeled monolingual Guarani data is beneficial for all three tasks."
  - [section] "Spanish, on the other hand, belongs to the small set of very resource-rich languages...which is good for this competition as there are many tools for Spanish that could be leveraged."
  - [corpus] Weak - corpus shows Guarani has ~10K tokens vs Spanish ~6.7K, but no monolingual Guarani data statistics provided.
- Break condition: Guarani monolingual data is too limited or too different from code-switched contexts to provide useful signal.

### Mechanism 3
- Claim: Pattern-based heuristics effectively handle mixed Guarani-Spanish words in code-switching detection.
- Mechanism: The system uses affix analysis rules to identify words containing both Guarani and Spanish morphological elements, improving classification of the "mix" category.
- Core assumption: Mixed words follow predictable morphological patterns that can be captured by heuristic rules.
- Evidence anchors:
  - [section] "Of the three participants, the University of Helsinki team was the only one that reported including particular rules for dealing with mix words by analyzing affixes, and they also got the best precision for this class."
  - [section] "The mix category is particularly interesting, as it comprises words that combine Guarani and Spanish content in some way, for example a Spanish verb with some adapted Guarani verbal morphology."
  - [corpus] Weak - corpus shows only 487 mixed tokens total, with 47 in test set, making pattern learning difficult.
- Break condition: Mixed word patterns are too diverse or irregular for rule-based approaches to capture effectively.

## Foundational Learning

- Concept: Code-switching phenomena and linguistic contact
  - Why needed here: Understanding how Guarani and Spanish interact is crucial for designing appropriate annotation schemes and evaluation metrics
  - Quick check question: What distinguishes code-switching from borrowing or code-mixing in this context?

- Concept: Low-resource language processing challenges
  - Why needed here: Guarani's limited digital resources require specific approaches like transfer learning and data augmentation
  - Quick check question: Why might multilingual pre-trained models perform better on Guarani-Spanish than monolingual Spanish models?

- Concept: Named Entity Recognition in code-switched contexts
  - Why needed here: Task 2 requires identifying entities that may span languages or contain mixed elements
  - Quick check question: How might language boundaries affect NER performance in code-switched text?

## Architecture Onboarding

- Component map:
  - Data pipeline: Corpus loading → Tokenization → Annotation mapping
  - Model stack: Pre-trained multilingual encoder → Task-specific heads → Post-processing
  - Evaluation: Task-specific metrics → Weighted F1 aggregation

- Critical path:
  1. Load and preprocess code-switched text
  2. Apply language identification to each token
  3. Identify named entity spans
  4. Classify Spanish spans by usage type
  5. Calculate task-specific metrics

- Design tradeoffs:
  - Multi-task vs single-task training: Multi-task may improve generalization but increases complexity
  - Rule-based vs learned approaches for mixed words: Rules are interpretable but may miss edge cases
  - Fine-tuning vs prompt engineering: Fine-tuning requires more compute but may achieve better results

- Failure signatures:
  - Poor performance on "mix" category indicates insufficient handling of morphological blending
  - Low Task 3 F1 suggests difficulty distinguishing between code change and unadapted loan categories
  - Inconsistent results across tasks may indicate misalignment between shared encoder features and task requirements

- First 3 experiments:
  1. Baseline comparison: Run provided baseline systems to establish performance floor
  2. Multi-task ablation: Train single-task models for each task to measure benefit of parameter sharing
  3. Data augmentation: Generate synthetic code-switched examples to test impact on low-resource performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific orthographic transformations distinguish unadapted loans (UL) from code changes (CC) in Spanish spans within Guarani-Spanish code-switching, and how can these be reliably automated?
- Basis in paper: [explicit] The paper notes ambiguity in classifying Spanish spans as either code changes (CC) or unadapted loans (UL), with annotators struggling to generalize criteria. The baseline and systems achieved only 0.384 labeled F1 for Task 3, indicating difficulty.
- Why unresolved: The distinction relies on nuanced morphosyntactic adaptation criteria that are context-dependent and not fully specified in the annotation guidelines. Even human annotators showed only 0.758 F1 agreement on a subsample.
- What evidence would resolve it: A detailed linguistic analysis of orthographic and morphosyntactic patterns in UL vs CC cases, validated through inter-annotator studies with clear decision rules, would help automate this classification.

### Open Question 2
- Question: How does the performance of Guarani-Spanish code-switching models generalize to other low-resource indigenous language pairs with Spanish?
- Basis in paper: [inferred] The paper suggests extending the task to include Portuguese and Bolivian Guarani varieties, implying uncertainty about cross-linguistic generalization. The Guarani-Spanish task required specific adaptations (e.g., rules for mixed tokens).
- Why unresolved: The dataset and systems are tailored to Guarani-Spanish, with limited exploration of transfer learning or multilingual models across different indigenous language pairs.
- What evidence would resolve it: Evaluating the same models on code-switching datasets for other indigenous languages (e.g., Quechua-Spanish, Aymara-Spanish) would test generalization.

### Open Question 3
- Question: What are the most effective strategies for improving named entity recognition (NER) in low-resource languages like Guarani, particularly when combined with high-resource languages like Spanish?
- Basis in paper: [explicit] Task 2 (NER) showed mixed results, with only one team outperforming the baseline. The paper highlights the lack of digital resources for Guarani as a challenge.
- Why unresolved: The paper does not explore advanced techniques like cross-lingual transfer, few-shot learning, or synthetic data generation for Guarani NER.
- What evidence would resolve it: Comparative studies of NER systems using multilingual models, transfer learning from Spanish NER, and data augmentation techniques would clarify effective strategies.

### Open Question 4
- Question: How can the detection and classification of mixed Guarani-Spanish tokens (e.g., morphosyntactically adapted verbs) be improved in code-switching analysis?
- Basis in paper: [explicit] The mix category was one of the hardest to classify, with only 47 examples in the test set. The University of Helsinki team reported using affix-based rules, but the ITML team achieved better recall.
- Why unresolved: The paper does not provide a comprehensive analysis of the linguistic features that distinguish mixed tokens or evaluate advanced morphological analyzers.
- What evidence would resolve it: A detailed linguistic study of mixed token patterns, combined with experiments using morphological analyzers or neural models trained on annotated mixed tokens, would improve detection.

## Limitations
- The corpus size remains insufficient for robust model training, particularly for Guarani (approximately 10K tokens) and mixed tokens (only 487 examples)
- The exclusive focus on written news and social media data limits generalizability to spoken Guarani-Spanish code-switching contexts
- The low F1 scores for Task 3 (0.384) indicate fundamental challenges in distinguishing between code change and unadapted loan categories, suggesting the annotation scheme may need refinement

## Confidence
- High confidence: The baseline methodology and general task definitions are well-specified, with clear evaluation metrics and corpus statistics
- Medium confidence: The effectiveness of multi-task learning and monolingual Guarani fine-tuning, as these approaches showed promise but lack detailed implementation specifications
- Low confidence: The generalizability of findings to broader Guarani-Spanish code-switching scenarios, particularly given the limited corpus size and specific domain focus

## Next Checks
1. Corpus expansion validation: Test whether model performance on Tasks 2 and 3 improves proportionally with corpus size by training on progressively larger subsets of the annotated data and measuring F1 score changes

2. Mixed token handling evaluation: Implement and compare rule-based versus learned approaches for mixed-language tokens by creating a balanced validation set with equal representation of pure and mixed tokens, then measuring precision and recall separately for each category

3. Cross-domain generalization test: Evaluate model performance on spoken Guarani-Spanish data (if available) or artificially constructed code-switched dialogues to assess whether patterns learned from written text transfer to conversational contexts