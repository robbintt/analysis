---
ver: rpa2
title: Outfit Completion via Conditional Set Transformation
arxiv_id: '2311.16630'
source_url: https://arxiv.org/abs/2311.16630
tags:
- outfit
- proposed
- completion
- items
- matching
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a conditional set transformation framework
  for outfit completion, formulated as a set retrieval task. The method uses deep
  neural networks with permutation-invariant and permutation-equivariant properties
  to generate item sets compatible with input sets while reflecting specified conditions.
---

# Outfit Completion via Conditional Set Transformation

## Quick Facts
- arXiv ID: 2311.16630
- Source URL: https://arxiv.org/abs/2311.16630
- Authors: 
- Reference count: 16
- Key outcome: Conditional set transformation framework for outfit completion that achieves scalable inference time and outperforms existing methods in accuracy, condition satisfaction, and compatibility

## Executive Summary
This paper introduces a conditional set transformation framework for outfit completion, formulated as a set retrieval task. The method leverages deep neural networks with permutation-invariant and permutation-equivariant properties to generate item sets compatible with input sets while reflecting specified conditions. A compatibility-based regularization method is introduced to improve output quality. Experiments on real-world fashion data show the proposed method outperforms existing approaches in accuracy, condition satisfaction, and compatibility while achieving scalable inference time.

## Method Summary
The method formulates outfit completion as conditional set retrieval, using a map with permutation-invariant properties for input sets and permutation-equivariant properties for condition sets. The architecture employs Slot Attention to ensure permutation-equivariance and Set Attention Blocks to maintain compatibility among output elements. Training uses cross-entropy loss for element-level evaluation and Set Matching regularization to improve compatibility. The model is trained on 583,788 outfits from the SHIFT15M dataset and evaluated using Recall, Accuracy, and Set Matching Score Difference metrics.

## Key Results
- The proposed method achieves 34% superior performance to human-created outfits in user studies
- Outperforms existing methods in accuracy, condition satisfaction, and compatibility metrics
- Demonstrates scalable inference time that remains nearly constant as the number of missing elements increases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Conditional set transformation enables outfit completion by leveraging permutation-invariant and permutation-equivariant properties to maintain compatibility and condition satisfaction.
- Mechanism: The architecture uses a map that is permutation-invariant with respect to the input set and permutation-equivariant with respect to the condition set. This allows the model to generate output sets that are compatible with the input set while reflecting the specified conditions. The Slot Attention module ensures permutation-equivariance for the condition set, and the Set Attention Block maintains compatibility among output elements.
- Core assumption: The order of elements in the condition set directly corresponds to the order of elements in the output set, enabling controlled attribute assignment.
- Evidence anchors:
  - [abstract] The method utilizes a map with permutation-invariant for the input set and permutation-equivariant for the condition set.
  - [section] The proposed transformation incorporates an attention mechanism that takes into account the relationships between set elements. Additionally, an extension to a conditional model enables control over the attributes of the output set.

### Mechanism 2
- Claim: Set Matching regularization improves outfit compatibility by penalizing less compatible output sets during training.
- Mechanism: The regularization term compares the compatibility score of the ground truth pair (X, Y) with the predicted pair (X, Ŷ). It applies a softplus function to penalize the model when the predicted set is less compatible than the ground truth. This encourages the model to generate outfits that are more compatible than randomly created ones.
- Core assumption: The Set Matching model used for regularization provides reliable compatibility scores that correlate with human judgments of outfit compatibility.
- Evidence anchors:
  - [section] The less compatible the pair (X, Ŷ) is compared to the ground truth pair (X, Y), the greater the penalty to the model.
  - [section] The effectiveness of the regularization in the outfit completion problem depends on the reliability of the Set Matching model.

### Mechanism 3
- Claim: Single-inference generation achieves scalable inference time as the number of missing elements increases.
- Mechanism: Unlike iterative methods that select items one by one, the proposed method generates all missing items in a single forward pass through the neural network. This reduces computational complexity and maintains constant inference time regardless of how many items need to be completed.
- Core assumption: The computational cost of nearest neighbor search dominates the overall inference time, making the single-inference approach significantly faster.
- Evidence anchors:
  - [section] The proposed method completes all elements in a single inference, resulting in a time that remains almost constant.
  - [section] The proposed method is more efficient than the Set Transformer and more scalable to the number of elements to be completed.

## Foundational Learning

- Concept: Permutation-invariant and permutation-equivariant functions
  - Why needed here: Outfit completion requires the model to handle sets where the order of items does not matter (permutation-invariant for input) while maintaining correspondence between conditions and outputs (permutation-equivariant for conditions).
  - Quick check question: If we permute the order of items in the input set, should the output set change? Why or why not?

- Concept: Set attention mechanisms (Slot Attention, Set Attention Block)
  - Why needed here: These mechanisms allow the model to capture relationships between set elements and generate sets with arbitrary cardinality, which is essential for handling variable-length outfits.
  - Quick check question: How does Slot Attention ensure that the output maintains permutation-equivariance with respect to its initial set?

- Concept: Cross-entropy loss for set retrieval
  - Why needed here: Since the output set has a fixed order determined by the condition set, individual elements can be evaluated separately using cross-entropy loss, which is more natural than permutation-invariant losses like Chamfer loss for this task.
  - Quick check question: Why is cross-entropy loss more appropriate than Chamfer loss for evaluating the output of a conditional set transformation?

## Architecture Onboarding

- Component map: Feature extractor (fixed) → Conditional Set Transformation (CST) → Set Matching regularization → Output set
- Critical path: Input set features → CST → Output set features → Nearest neighbor search → Candidate items
- Design tradeoffs:
  - Single-inference vs. iterative selection: Single-inference is faster but may produce less diverse outputs
  - Cross-entropy vs. Chamfer loss: Cross-entropy is more discriminative but requires fixed output order
  - Fixed feature extractor vs. end-to-end training: Fixed extractor provides stability but may limit adaptation
- Failure signatures:
  - Poor condition satisfaction: Output items have wrong categories
  - Low compatibility: Generated outfits look mismatched despite correct categories
  - Lack of diversity: Same items repeatedly selected for similar queries
- First 3 experiments:
  1. Ablation study: Remove Set Matching regularization to quantify its contribution to compatibility
  2. Diversity analysis: Measure item selection frequency distribution to assess output diversity
  3. Inference time scaling: Measure elapsed time as the number of missing items increases from 1 to 5

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the proposed method be extended to handle overlapping categories and items in outfit completion?
- Basis in paper: [explicit] The paper mentions that the proposed method fails to select items that are different from each other when the categories overlap, as illustrated in the completion example in the fifth row of Figure 4.
- Why unresolved: The paper suggests that developing a set transformation that allows for overlapping categories and items is a potential direction for future research, but does not provide a solution.
- What evidence would resolve it: A proposed extension to the conditional set transformation model that can handle overlapping categories and items, along with experimental results demonstrating improved performance on outfit completion tasks with overlapping categories.

### Open Question 2
- Question: How can the proposed method be improved to provide more diverse outfit completion results?
- Basis in paper: [explicit] The paper mentions that the proposed method does not provide diverse completions, as evidenced by the skewed item selection tendencies observed in Figure 8.
- Why unresolved: The paper suggests that addressing this issue is a task for future research, but does not provide a solution.
- What evidence would resolve it: A proposed method to encourage diversity in the generated outfits, along with experimental results demonstrating improved diversity in the outfit completion results.

### Open Question 3
- Question: How can the proposed method be applied to other set retrieval tasks beyond outfit completion?
- Basis in paper: [explicit] The paper mentions that the proposed conditional set transformation architecture can be applied to other set retrieval tasks, but does not provide specific examples or applications.
- Why unresolved: The paper does not explore the application of the proposed method to other set retrieval tasks beyond outfit completion.
- What evidence would resolve it: An exploration of the application of the proposed method to other set retrieval tasks, along with experimental results demonstrating improved performance on these tasks compared to existing methods.

## Limitations

- The method's effectiveness depends on the reliability of the pre-trained Set Matching model for compatibility scores
- Fixed image features extracted by an unspecified pre-trained model may limit adaptation to domain-specific fashion attributes
- Evaluation focuses primarily on accuracy and compatibility metrics without comprehensive analysis of diversity in generated outfits

## Confidence

- High confidence: The mechanism of using permutation-invariant/equivariant properties for conditional set transformation, and the single-inference approach for scalable generation
- Medium confidence: The effectiveness of Set Matching regularization, as it depends on the quality of the pre-trained compatibility model
- Medium confidence: The human evaluation results, as they are based on a single human judgment per pair

## Next Checks

1. **Ablation study of Set Matching regularization**: Train the model with and without the regularization term and compare compatibility scores, SMD values, and qualitative output quality to quantify its contribution
2. **Diversity analysis**: Measure the Gini coefficient or Shannon entropy of item selection frequencies across all test queries to assess whether the model produces diverse outputs or repeatedly selects the same items
3. **Cross-dataset generalization**: Evaluate the trained model on a held-out test set from a different fashion dataset (e.g., Polyvore or IQON) to assess whether the learned transformations generalize beyond the training distribution