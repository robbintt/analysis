---
ver: rpa2
title: Explainable Conversational Question Answering over Heterogeneous Sources via
  Iterative Graph Neural Networks
arxiv_id: '2305.01548'
source_url: https://arxiv.org/abs/2305.01548
tags:
- answer
- question
- answering
- graph
- evidences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of conversational question answering
  (ConvQA) over heterogeneous sources, such as knowledge bases, text corpora, tables,
  and infoboxes, with a focus on explainability. Existing methods often rely on single
  sources or sequence-to-sequence models, which limit answer coverage and lack interpretability.
---

# Explainable Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks

## Quick Facts
- arXiv ID: 2305.01548
- Source URL: https://arxiv.org/abs/2305.01548
- Authors: Multiple
- Reference count: 40
- Primary result: Achieves 40.6% precision@1 and 47.1% MRR on ConvMix dataset

## Executive Summary
This paper tackles the challenge of conversational question answering (ConvQA) over heterogeneous information sources including knowledge bases, text corpora, tables, and infoboxes, with a focus on explainability. The proposed method, Explaignn, constructs a heterogeneous graph from entities and evidence snippets retrieved from multiple sources and applies iterative graph neural networks (GNNs) to distill the best answers and their explanations. Key innovations include question-level attention to ensure relevance during message passing and a multi-task learning approach to improve performance. Experiments on the ConvMix dataset demonstrate significant improvements over state-of-the-art baselines, achieving 40.6% precision@1 and 47.1% MRR. A user study confirms that the explanations provided are understandable and trustworthy.

## Method Summary
The method constructs a heterogeneous graph from entities and evidence snippets retrieved from multiple sources (knowledge bases, text corpora, tables, and infoboxes). It then applies iterative graph neural networks with question-level attention and multi-task learning to predict answers and evidence relevance. The approach iteratively prunes the graph, reducing its size while maintaining relevant information, until the final iteration produces the answer and a small set of explanatory evidences.

## Key Results
- Achieves 40.6% precision@1 and 47.1% MRR on the ConvMix dataset
- Significantly outperforms state-of-the-art baselines in answer quality
- User study confirms explanations are understandable and trustworthy

## Why This Works (Mechanism)

### Mechanism 1
- Iterative GNN pruning improves robustness and explainability by reducing graph size after each iteration while retaining relevant information
- Core assumption: GNN can learn to propagate question-relevant information within local neighborhoods
- Evidence: Abstract and section 5 describe iterative pruning approach
- Break condition: If pruning removes correct answer or essential evidence, accuracy drops

### Mechanism 2
- SR-attention weights ensure only question-relevant information is propagated during message passing
- Core assumption: Structured representation captures complete question intent
- Evidence: Section 4.3 describes SR-attention mechanism
- Break condition: Poor SR generation leads to misleading attention weights

### Mechanism 3
- Multi-task learning improves performance by leveraging evidence relevance prediction alongside answer prediction
- Core assumption: Evidence relevance labels provide useful signal for answer prediction
- Evidence: Section 4.5 and 6.3 describe MTL approach
- Break condition: Noisy evidence relevance labels could hurt performance

## Foundational Learning

- Structured Representation (SR) generation: Captures question intent (context entity, question entity, relation, answer type) for SR-attention and cross-encoding
  - Quick check: How does system handle incomplete follow-up questions without explicit entities or relations?

- Graph Neural Networks with message passing: Propagates information between evidences and entities based on graph connectivity
  - Quick check: What's the difference between node classification and graph classification in this pipeline?

- Heterogeneous information sources integration: Combines KB, text, tables, and infoboxes to increase answer coverage
  - Quick check: Why is entity canonicalization across sources important for graph construction?

## Architecture Onboarding

- Component map: QU stage -> ER stage -> Graph construction -> Iterative GNN inference -> Answer prediction
- Critical path: Question Understanding → Evidence Retrieval → Graph construction → Iterative GNN inference → Answer prediction
- Design tradeoffs: Trades runtime efficiency for explainability through iterative pruning; uses alternating encodings for speed vs cross-encodings for accuracy
- Failure signatures: Low answer presence in final graph, poor ranking, high hallucination rate in SR
- First 3 experiments: 1) Ablate SR-attention to measure impact, 2) Ablate MTL to test multi-task benefits, 3) Compare one-shot vs iterative GNN performance

## Open Questions the Paper Calls Out

- How can performance be further improved by incorporating more advanced entity disambiguation techniques? (Explicitly mentioned, unresolved due to simple disambiguation approach used)
- How does performance compare on different types of conversational question answering tasks like numerical or temporal reasoning? (Inferred from factoid focus, unresolved due to lack of experimental results)
- How can runtime efficiency be further improved without compromising performance? (Explicitly mentioned, unresolved due to limited exploration of optimizations)

## Limitations

- SR-attention mechanism lacks external validation and may be sensitive to SR generation quality
- Iterative pruning effectiveness depends on GNN's ability to learn meaningful relevance weights, not extensively validated beyond ConvMix
- Multi-task learning assumes reliable evidence relevance labels, which may not generalize to all domains

## Confidence

- High: Overall architecture design and problem formulation are well-defined and address genuine ConvQA needs
- Medium: Effectiveness of iterative pruning and SR-attention mechanisms supported by internal experiments but lack broader validation
- Low: Robustness to noisy or incomplete structured representations and evidence relevance labels is uncertain

## Next Checks

1. Conduct ablation study on SR-attention mechanism to quantify impact on answer quality and explainability
2. Test iterative pruning approach on different ConvQA dataset to assess generalization
3. Evaluate sensitivity to SR generation errors by introducing controlled noise into structured representations