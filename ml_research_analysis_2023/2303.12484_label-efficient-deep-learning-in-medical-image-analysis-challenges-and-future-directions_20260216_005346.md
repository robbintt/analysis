---
ver: rpa2
title: 'Label-Efficient Deep Learning in Medical Image Analysis: Challenges and Future
  Directions'
arxiv_id: '2303.12484'
source_url: https://arxiv.org/abs/2303.12484
tags:
- learning
- image
- segmentation
- dataset
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a comprehensive survey of label-efficient
  deep learning methods in medical image analysis (MIA), addressing the challenge
  of requiring large-scale, high-quality labeled datasets for training. The authors
  categorize these methods into four labeling paradigms: no label, insufficient label,
  inexact label, and label refinement.'
---

# Label-Efficient Deep Learning in Medical Image Analysis: Challenges and Future Directions

## Quick Facts
- arXiv ID: 2303.12484
- Source URL: https://arxiv.org/abs/2303.12484
- Reference count: 40
- Key outcome: Presents a comprehensive survey of label-efficient deep learning methods in medical image analysis, categorizing over 350 studies into four labeling paradigms and examining the role of health foundation models.

## Executive Summary
This survey systematically reviews label-efficient deep learning methods in medical image analysis (MIA), addressing the critical challenge of requiring large-scale, high-quality labeled datasets for training deep learning models. The authors categorize these methods into four labeling paradigms: no label, insufficient label, inexact label, and label refinement. By leveraging labeled, unlabeled, and weakly labeled data through techniques like semi-supervised learning, self-supervised learning, multi-instance learning, active learning, and annotation-efficient learning, these approaches significantly improve model performance under limited supervision. The survey also examines the growing role of health foundation models (HFMs) in enabling label-efficient learning through large-scale pre-training and transfer learning.

## Method Summary
The paper conducts a systematic review of over 350 peer-reviewed studies on label-efficient deep learning in MIA. It presents a comprehensive taxonomy of methods categorized into four labeling paradigms based on the types of available supervision. For each paradigm, the survey analyzes representative techniques across various imaging modalities and clinical applications. The authors also examine health foundation models and their role in label-efficient learning. The survey identifies current challenges and future directions to facilitate the translation of label-efficient learning from research to clinical care.

## Key Results
- Categorizes label-efficient learning methods into four paradigms: no label, insufficient label, inexact label, and label refinement
- Reviews over 350 peer-reviewed studies systematically across medical imaging modalities
- Identifies the growing role of health foundation models in enabling label-efficient learning through large-scale pre-training
- Highlights the effectiveness of leveraging unlabeled and weakly labeled data to improve model performance under limited supervision

## Why This Works (Mechanism)

### Mechanism 1
Label-efficient learning methods improve model performance under limited supervision by leveraging unlabeled and weakly labeled data alongside labeled data. The paper presents four labeling paradigms - no label, insufficient label, inexact label, and label refinement - and reviews over 350 studies that use these paradigms to improve model performance. By incorporating unlabeled and weakly labeled data through methods like semi-supervised learning, self-supervised learning, multi-instance learning, active learning, and annotation-efficient learning, models can learn task-related invariant features and avoid overfitting, especially with small datasets. This works because the marginal data distribution p(x) contains underlying information about the posterior distribution p(y|x), meaning unlabeled data can provide useful information about the task.

### Mechanism 2
Self-supervised learning (Self-SL) enables learning of latent features from large-scale unlabeled datasets without human annotation, which facilitates performance on downstream tasks. Self-SL methods build proxy tasks for the model to learn latent features and representations from massive amounts of unlabeled data. These proxy tasks have two properties: (1) labels can be generated automatically by the data itself, and (2) the neural network can learn related representations or features by solving the proxy task. After pre-training with these proxy tasks, the learned representations are utilized for downstream tasks, significantly avoiding overfitting compared to supervised learning, especially for small datasets. This works because the proxy tasks can be designed to learn features or representations that are related to the downstream task.

### Mechanism 3
Multi-instance learning (MIL) is effective for whole slide image analysis by treating gigapixel images as bags containing selected patches, allowing for both global detection (finding if target patterns exist) and local detection (locating specific disease patterns). MIL introduces the concept of a bag composed of instances (patches). It assumes that if a bag is positive, at least one instance in it is positive, and if a bag is negative, all instances are negative. This allows MIL to perform both bag-level and instance-level tasks. For MIA, MIL methods can leverage instances to identify positive or negative bags, contributing not only to image-level diagnosis but also precise abnormal region detection and localization. This great interpretability fits well in MIA, as both global structure and local details are crucial. This works because the instances in a bag are related to the bag label in a way that allows learning from the bag label to infer instance labels.

## Foundational Learning

- Concept: Semi-supervised learning assumptions
  - Why needed here: Semi-supervised learning methods are a key category of label-efficient learning, and their effectiveness depends on certain assumptions about the data distribution.
  - Quick check question: What are the three main assumptions in semi-supervised learning, and how do they relate to each other?

- Concept: Self-supervised learning proxy tasks
  - Why needed here: Self-supervised learning is another major category of label-efficient learning, and its success depends on the design of appropriate proxy tasks.
  - Quick check question: What are the two key properties that a good proxy task should have in self-supervised learning?

- Concept: Multi-instance learning bag-instance relationship
  - Why needed here: Multi-instance learning is used for whole slide image analysis in MIA, and understanding the bag-instance relationship is crucial for its application.
  - Quick check question: What are the two common assumptions made in multi-instance learning about the relationship between bag labels and instance labels?

## Architecture Onboarding

- Component map: Data (labeled, unlabeled, weakly labeled) -> Learning Method (semi-supervised, self-supervised, multi-instance, active, annotation-efficient) -> Model (neural network architecture) -> Evaluation (performance metrics)
- Critical path: 1) Prepare the data (labeled, unlabeled, weakly labeled), 2) Choose the appropriate learning method based on the data and task, 3) Design or select the model architecture, 4) Implement the learning algorithm, 5) Train the model, 6) Evaluate the performance, 7) Iterate as needed
- Design tradeoffs: 1) Amount of labeled vs. unlabeled data - more unlabeled data allows for more effective semi-supervised or self-supervised learning, but may require more complex models; 2) Weakly labeled data quality - higher quality weakly labeled data can improve performance but may be harder to obtain; 3) Model complexity - more complex models can potentially learn better representations but may require more data and computational resources; 4) Learning method choice - different methods have different strengths and weaknesses depending on the task and data
- Failure signatures: 1) Poor performance due to violation of semi-supervised learning assumptions; 2) Ineffective proxy tasks in self-supervised learning; 3) Incorrect modeling of bag-instance relationship in multi-instance learning; 4) Overfitting to limited labeled data; 5) Poor generalization to new data or domains
- First 3 experiments:
  1. Implement a simple semi-supervised learning method (e.g., self-training) on a small labeled dataset with a large unlabeled dataset, and compare performance to a fully supervised baseline
  2. Design a proxy task for self-supervised learning that is specific to the medical imaging domain, and evaluate its effectiveness in pre-training a model for a downstream task
  3. Apply multi-instance learning to a whole slide image classification task, and compare the performance and interpretability to a fully supervised approach

## Open Questions the Paper Calls Out

### Open Question 1
How can label-efficient federated learning methods be designed to handle varying degrees of label deficiency across different medical centers? This question arises from the paper's discussion of label-efficient learning in federated learning settings and the identification of label deficiency as a significant challenge. Current federated learning algorithms are primarily supervised and do not address the issue of label deficiency across decentralized medical centers. This could be resolved through the development and evaluation of label-efficient federated learning methods (e.g., semi-supervised, active learning, or self-supervised learning approaches) that can effectively handle label deficiency in decentralized medical data.

### Open Question 2
What are the most effective ways to integrate human-in-the-loop (HITL) interactions into deep learning models for medical image analysis, particularly for rare cases? The paper discusses HITL as a promising direction and mentions the potential of reinforcement learning (RL) schemes for expert-provided interactions to refine predictions. While HITL is recognized as beneficial, there is a lack of research on how to effectively integrate expert knowledge into deep learning models, especially for rare cases that the model may struggle with. This could be resolved through empirical studies demonstrating improved model performance on rare cases through HITL interactions, particularly using RL-based approaches.

### Open Question 3
How can generative models, particularly diffusion models, be optimized for efficient and high-quality medical image synthesis to enhance data augmentation? The paper discusses the potential of generative models for data augmentation and mentions the recent interest in diffusion models for their high mode coverage and sample quality. Despite the potential of diffusion models, their computational overhead remains a challenge, and there is a need for further research to optimize their efficiency and generalization capability in the medical domain. This could be resolved through the development of efficient and generalizable diffusion models specifically tailored for medical image synthesis, along with empirical studies demonstrating their effectiveness in enhancing data augmentation and improving model performance.

## Limitations
- The survey does not provide implementation details for the 350+ surveyed methods, making direct replication challenging
- Performance claims are aggregated across diverse studies without standardized evaluation protocols
- The effectiveness of label-efficient methods may vary significantly across different medical imaging modalities and clinical tasks

## Confidence
- **High**: The existence and categorization of label-efficient learning paradigms in MIA
- **Medium**: The specific mechanisms by which unlabeled/weakly-labeled data improves performance
- **Medium**: The role of foundation models in label-efficient learning, given limited empirical validation in medical domains

## Next Checks
1. Implement a controlled experiment comparing semi-supervised learning against supervised baselines on a public medical imaging dataset (e.g., CheXpert or CAMELYON)
2. Evaluate self-supervised pre-training performance across different proxy tasks to identify which transfer most effectively to medical image downstream tasks
3. Conduct ablation studies on multi-instance learning to quantify the contribution of bag-level vs. instance-level supervision in whole slide image analysis