---
ver: rpa2
title: 'Follow-ups Also Matter: Improving Contextual Bandits via Post-serving Contexts'
arxiv_id: '2309.13896'
source_url: https://arxiv.org/abs/2309.13896
tags:
- context
- post-serving
- regret
- algorithm
- linear
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies contextual bandits with post-serving contexts,
  a setting where valuable additional context is observed after arm selection. The
  authors design a new algorithm, poLinUCB, that simultaneously learns a mapping from
  pre-serving to post-serving contexts and arm parameters.
---

# Follow-ups Also Matter: Improving Contextual Bandits via Post-serving Contexts

## Quick Facts
- **arXiv ID**: 2309.13896
- **Source URL**: https://arxiv.org/abs/2309.13896
- **Reference count**: 40
- **Primary result**: A new contextual bandit algorithm (poLinUCB) that learns from post-serving contexts achieves improved regret bounds when the mapping from pre-serving to post-serving contexts is learnable.

## Executive Summary
This paper introduces a novel contextual bandit setting where valuable context is revealed after arm selection. The authors propose poLinUCB, an algorithm that simultaneously learns a mapping from pre-serving to post-serving contexts while estimating arm parameters. A key technical contribution is a robustified elliptical potential lemma that handles noise in the contexts. The regret bound gracefully degrades as the mapping becomes harder to learn, achieving √T regret when the mapping is learnable at rate α = 0.5. Experiments demonstrate significant benefits from utilizing post-serving contexts in both synthetic and real-world data.

## Method Summary
The poLinUCB algorithm extends linear contextual bandits by incorporating post-serving contexts that become available after arm selection. The algorithm maintains confidence sets for both arm parameters and the context mapping function using regularized least squares. It estimates the expected post-serving context from the pre-serving context using empirical risk minimization, then uses this estimate to compute upper confidence bounds for arm selection. The regret bound depends on the learnability rate α of the mapping function, achieving O(T^(1-α)d_u^α + d_u√TK) where d_u is the dimension of the combined context space.

## Key Results
- poLinUCB achieves √T regret when the mapping from pre-serving to post-serving contexts is learnable at rate α = 0.5
- The algorithm gracefully degrades to linear regret as the mapping becomes harder to learn (α → 0)
- Experiments on synthetic data show up to 10x improvement over baselines that don't use post-serving contexts
- Real-world MovieLens experiments demonstrate practical benefits, with poLinUCB outperforming LinUCB with only pre-serving context

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Learning the mapping from pre-serving to post-serving contexts reduces regret when the mapping is learnable.
- Mechanism: The algorithm estimates the function ϕ⋆(·) that maps pre-serving contexts to expected post-serving contexts, then uses this estimate to improve arm selection decisions.
- Core assumption: There exists an algorithm that can learn the mean of the post-serving context conditioned on the pre-serving context at a known rate α.
- Evidence anchors:
  - [abstract]: "design a new algorithm, poLinUCB, that simultaneously learns a mapping from pre-serving to post-serving contexts and arm parameters"
  - [section]: "we assume that there exists a learnable mapping ϕ⋆(·) : Rdx → Rdz that maps pre-serving feature x ∈ Rdx to the expectation of the post-serving feature z ∈ Rdz"
  - [corpus]: Weak evidence - related papers focus on contextual bandits but don't directly address post-serving contexts
- Break condition: If the mapping ϕ⋆(·) is not learnable (α approaches 0), the regret becomes linear due to model misspecification.

### Mechanism 2
- Claim: The robustified elliptical potential lemma handles noise in the contexts while maintaining tight regret bounds.
- Mechanism: A generalized version of the elliptical potential lemma is developed that accommodates noisy feature vectors and slower learning rates, allowing the algorithm to bound the sum of prediction errors.
- Core assumption: The noise in post-serving contexts is bounded and has certain statistical properties (zero-mean, bounded norm, positive semi-definite covariance).
- Evidence anchors:
  - [abstract]: "Core to our technical proof is a robustified and generalized version of the well-known Elliptical Potential Lemma (EPL), which can accommodate noise in data"
  - [section]: "we developed new technique tools that may be of independent interest" including "a robustified and generalized version of the well-known elliptical potential lemma"
  - [corpus]: Weak evidence - no direct corpus support for this specific generalization
- Break condition: If the noise properties don't hold (e.g., unbounded noise or non-positive semi-definite covariance), the concentration bounds fail.

### Mechanism 3
- Claim: Simultaneous learning of both the context mapping and arm parameters achieves better performance than sequential approaches.
- Mechanism: The algorithm estimates ϕ⋆(·) and arm parameters {θa, βa} together in a single optimization framework, rather than first estimating the mapping and then running a standard algorithm.
- Core assumption: The errors from estimating ϕ⋆(·) can be properly accounted for in the confidence sets of the arm parameters.
- Evidence anchors:
  - [abstract]: "our algorithm, poLinUCB, that simultaneously learns a mapping from pre-serving to post-serving contexts and arm parameters"
  - [section]: "our algorithm also simultaneously manages the same for the post-serving context generating function, bϕ(·)"
  - [corpus]: Weak evidence - related papers don't address this simultaneous learning approach
- Break condition: If the confidence sets are not properly inflated to account for estimation errors in ϕ⋆(·), the algorithm may select suboptimal arms.

## Foundational Learning

- Concept: Elliptical Potential Lemma (EPL)
  - Why needed here: The EPL is crucial for bounding the sum of prediction errors in linear bandits, which is essential for deriving regret bounds
  - Quick check question: What does the original EPL bound, and how does it relate to the uncertainty in linear bandit algorithms?

- Concept: Sub-Gaussian random variables
  - Why needed here: The reward noise is assumed to be sub-Gaussian, which allows the use of concentration inequalities for deriving confidence bounds
  - Quick check question: Why is the sub-Gaussian assumption on the noise important for the confidence ellipsoid construction?

- Concept: Empirical Risk Minimization (ERM)
  - Why needed here: ERM is used to estimate the post-serving context generating function ϕ⋆(·) from historical data
  - Quick check question: How does ERM help in learning the mapping from pre-serving to post-serving contexts?

## Architecture Onboarding

- Component map:
  - Context processor -> Mapping estimator -> Parameter estimator -> Confidence set builder -> Arm selector

- Critical path:
  1. Receive pre-serving context x
  2. Estimate post-serving context using ϕ⋆(x)
  3. Compute upper confidence bounds for all arms
  4. Select arm with highest UCB
  5. Observe reward and true post-serving context
  6. Update estimates and confidence sets

- Design tradeoffs:
  - Learning rate α vs regret: Faster learning (higher α) yields better regret bounds but may require more complex learning algorithms
  - Confidence set width: Wider confidence sets account for estimation errors but may lead to more exploration
  - Regularization parameter λ: Balances fitting accuracy with parameter stability

- Failure signatures:
  - Linear regret: Indicates the mapping ϕ⋆(·) is not learnable or the algorithm is not properly accounting for estimation errors
  - High variance in arm selection: May indicate confidence sets are too wide or the estimation of ϕ⋆(·) is unstable
  - Poor performance compared to baseline: Could indicate the post-serving contexts are not informative or the learning algorithm for ϕ⋆(·) is ineffective

- First 3 experiments:
  1. Test on synthetic data with known linear mapping ϕ⋆(x) = Φ⊤x to verify the algorithm achieves √T regret
  2. Test on synthetic data with non-linear mapping (e.g., polynomial or periodic) to verify the algorithm handles different learnability rates α
  3. Test on real-world data (e.g., MovieLens) to verify the algorithm leverages post-serving contexts effectively in practical settings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal value of α for the learnability assumption in Assumption 1, and how does it depend on the complexity of the mapping function ϕ⋆?
- Basis in paper: Explicit, as the paper states that the regret bound depends on α and discusses the rate of 1/√T when α = 0.5.
- Why unresolved: The paper only mentions that α = 0.5 is the best learning rate that can be accommodated, but does not provide a method to determine the optimal α for different ϕ⋆ functions.
- What evidence would resolve it: Experimental results comparing the regret bounds for different values of α on various ϕ⋆ functions, or theoretical analysis deriving the optimal α based on the complexity of ϕ⋆.

### Open Question 2
- Question: How does the choice of the regularization coefficient λ affect the regret bound in Theorem 1, and is there an optimal way to set it?
- Basis in paper: Explicit, as the paper mentions that the regret bound depends on the choice of λ and provides a formula for setting it.
- Why unresolved: The paper does not provide a detailed analysis of how different choices of λ affect the regret bound or a method to determine the optimal λ.
- What evidence would resolve it: Experimental results comparing the regret bounds for different values of λ, or theoretical analysis deriving the optimal λ based on the problem parameters.

### Open Question 3
- Question: Can the generalized elliptical potential lemma (Lemma 1) be extended to handle more general noise distributions or non-zero mean noises?
- Basis in paper: Inferred, as the paper mentions that the lemma is robustified to handle noise in the data, but does not discuss the limitations of the noise assumptions.
- Why unresolved: The paper only proves the lemma for zero-mean bounded noises, and does not discuss the possibility of extending it to more general noise distributions.
- What evidence would resolve it: Theoretical analysis extending the lemma to handle more general noise distributions or non-zero mean noises, or experimental results demonstrating the performance of the algorithm under such noise conditions.

## Limitations

- The assumption that the mapping from pre-serving to post-serving contexts is learnable at a known rate α may not hold in practice
- The computational complexity of simultaneously learning the mapping function and arm parameters could be prohibitive for high-dimensional contexts
- The regret bound gracefully degrades as α decreases, but the paper doesn't provide guidance on when this degradation becomes unacceptable

## Confidence

- **High confidence**: The regret bound derivation using the generalized elliptical potential lemma is mathematically rigorous and well-supported by the theoretical analysis.
- **Medium confidence**: The experimental results on synthetic data convincingly demonstrate the algorithm's effectiveness when the mapping is learnable, but the real-world experiments (MovieLens) provide only moderate evidence due to limited dataset details.
- **Medium confidence**: The claim that simultaneous learning outperforms sequential approaches is plausible but could benefit from more extensive ablation studies.

## Next Checks

1. **Stress test the learnability assumption**: Implement experiments where the mapping function ϕ⋆(x) is deliberately chosen to be unlearnable (α → 0) and verify that the algorithm gracefully degrades to linear regret as predicted by the theory.

2. **Analyze sensitivity to hyperparameters**: Systematically vary the regularization parameter λ and confidence parameters to understand their impact on performance, particularly in the presence of noise or misspecification.

3. **Benchmark against oracle approaches**: Compare poLinUCB against a hypothetical oracle that knows the true mapping ϕ⋆(x) perfectly, to quantify the performance gap due to estimation errors in the mapping function.