---
ver: rpa2
title: 'Optimizing Inventory Routing: A Decision-Focused Learning Approach using Neural
  Networks'
arxiv_id: '2311.00983'
source_url: https://arxiv.org/abs/2311.00983
tags:
- inventory
- routing
- learning
- customer
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a decision-focused learning approach to solve
  the Inventory Routing Problem (IRP), which integrates inventory management and vehicle
  routing decisions in supply chain management. The authors argue that the traditional
  two-stage approach of predicting demand using machine learning and then optimizing
  routing decisions is sub-optimal due to the dynamic business environment affecting
  demand prediction accuracy.
---

# Optimizing Inventory Routing: A Decision-Focused Learning Approach using Neural Networks

## Quick Facts
- **arXiv ID**: 2311.00983
- **Source URL**: https://arxiv.org/abs/2311.00983
- **Reference count**: 5
- **Primary result**: Decision-focused learning approach directly integrates inventory prediction and routing optimization, potentially ensuring a robust supply chain strategy.

## Executive Summary
This paper proposes a decision-focused learning approach to solve the Inventory Routing Problem (IRP), which integrates inventory management and vehicle routing decisions in supply chain management. The authors argue that the traditional two-stage approach of predicting demand using machine learning and then optimizing routing decisions is sub-optimal due to the dynamic business environment affecting demand prediction accuracy. To address this, they formulate a decision-focused learning approach that directly integrates inventory prediction and routing optimization within an end-to-end system. The approach involves making the Mixed Integer Linear Programming (MILP) formulation of IRP differentiable by converting it to a Quadratic Program (QP) with a regularization term or using a logarithmic barrier method. Experiments show that solely minimizing machine learning loss does not guarantee optimal decision-making in the context of IRP.

## Method Summary
The method involves transforming the non-differentiable MILP formulation of the Inventory Routing Problem into a differentiable form using either regularization or logarithmic barriers. A neural network is trained to predict customer demand, which is then used as input to the differentiable optimization layer. The gradients are computed through implicit differentiation, allowing the model to learn demand predictions that directly optimize routing decisions rather than just minimizing prediction error.

## Key Results
- Decision-focused learning directly integrates inventory prediction and routing optimization within an end-to-end system
- The traditional two-stage approach (predict-then-optimize) is sub-optimal for IRP due to dynamic business environments
- Converting MILP to QP with regularization or using logarithmic barriers makes the objective differentiable with respect to predicted demand

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decision-focused learning directly integrates inventory prediction and routing optimization within an end-to-end system, leading to more effective decision-making than the traditional two-stage approach.
- Mechanism: The decision-focused learning approach replaces the two-stage pipeline (predict-then-optimize) with a single model that learns to make predictions specifically tailored to optimize the routing decisions. This is achieved by differentiating the task loss (regret) with respect to the model parameters, which requires computing the gradient of the optimal solution with respect to the predicted demand.
- Core assumption: The optimal solution to the IRP is differentiable with respect to the predicted demand parameters, allowing gradients to flow back through the optimization layer.
- Evidence anchors:
  - [abstract] "This approach directly integrates inventory prediction and routing optimization within an end-to-end system potentially ensuring a robust supply chain strategy."
  - [section] "Decision-focused learning (DFL) takes a unique approach by not segregating predictive modeling and optimization. Instead, it integrates them by connecting the machine learning model directly to decision quality."
- Break condition: The differentiability assumption breaks down if the optimization problem becomes too complex or if the optimal solution is not unique, making the gradient ill-defined.

### Mechanism 2
- Claim: Converting the MILP formulation of IRP into a Quadratic Program (QP) with a regularization term makes the objective function differentiable with respect to the predicted demand parameters.
- Mechanism: The linear objective function of the IRP is transformed into a quadratic objective by adding a regularization term. This regularization term ensures that the Hessian of the QP is negative definite, making the problem twice differentiable and allowing the use of standard QP solvers and implicit differentiation techniques.
- Core assumption: The regularization term does not significantly alter the optimal solution or the decision quality of the IRP.
- Evidence anchors:
  - [section] "The objective function of IRP is linear, it is not twice differentiable with respect to prediction, to solve this issue the standard practice is to convert MILP into a Quadratic program(QP), and the gradient of Qp is computable through implicit differentiation of the KKT conditions."
  - [section] "We can use the regularized term which transforms the linear program into a standard quadratic program (QP) as mentioned in [5]."
- Break condition: The regularization term may distort the true objective function, leading to suboptimal routing decisions that do not reflect the actual business costs.

### Mechanism 3
- Claim: Using a logarithmic barrier method to transform the linear program into a differentiable form encourages solutions to remain within the feasible set while allowing for smooth transitions from relaxed (continuous) to integer solutions.
- Mechanism: The logarithmic barrier term is added to the objective function, which penalizes solutions that violate the capacity constraints. This approach ensures that the optimal solution remains within the feasible region while still allowing for gradient-based optimization techniques to be applied.
- Core assumption: The logarithmic barrier term effectively handles the capacity constraints without introducing significant computational overhead or distorting the optimal solution.
- Evidence anchors:
  - [section] "Instead of adding the regularizer adding a logarithmic barrier can be another option. The log-barrier term is the most natural tool in LP problems as the KKT conditions of the log-barrier function define the primal and the dual constraints."
  - [section] "This approach encourages solutions to remain within the feasible set while allowing for smooth transitions from relaxed (continuous) to integer solutions."
- Break condition: The logarithmic barrier method may become computationally expensive for large-scale problems or may not handle certain types of constraints effectively.

## Foundational Learning

- Concept: Mixed Integer Linear Programming (MILP) and its relation to the Inventory Routing Problem (IRP)
  - Why needed here: Understanding the mathematical formulation of the IRP as an MILP is crucial for grasping the challenges in differentiating the optimization problem with respect to the predicted demand parameters.
  - Quick check question: What are the key components of an MILP formulation, and how do they relate to the variables and constraints in the IRP?

- Concept: Differentiability and its importance in decision-focused learning
  - Why needed here: The ability to compute gradients of the optimal solution with respect to the model parameters is essential for training the decision-focused learning model effectively.
  - Quick check question: Why is differentiability important in decision-focused learning, and how does it differ from traditional machine learning approaches?

- Concept: Regularization and logarithmic barrier methods for transforming linear programs
  - Why needed here: These techniques are used to make the linear objective function of the IRP differentiable, allowing for gradient-based optimization and training of the decision-focused learning model.
  - Quick check question: How do regularization and logarithmic barrier methods transform a linear program into a differentiable form, and what are the key differences between these approaches?

## Architecture Onboarding

- Component map: Input features → Neural network prediction → Differentiable optimization (QP or log-barrier LP) → Routing decisions → Regret calculation → Gradient backpropagation → Model parameter updates
- Critical path: Input features → Neural network prediction → Differentiable optimization → Routing decisions → Regret calculation → Gradient backpropagation → Model parameter updates
- Design tradeoffs:
  - Regularization vs. logarithmic barrier: Regularization may distort the objective function, while logarithmic barriers may be computationally expensive for large-scale problems.
  - Accuracy vs. differentiability: Stricter differentiability requirements may lead to suboptimal solutions or increased computational complexity.
  - End-to-end learning vs. modular approach: End-to-end learning may be more efficient but less interpretable compared to a modular approach with separate prediction and optimization components.
- Failure signatures:
  - Poor convergence or high regret values during training
  - Inconsistent or unrealistic routing decisions
  - Numerical instability or overflow errors in the optimization layer
  - Large discrepancies between predicted and actual demand
- First 3 experiments:
  1. Implement a simple two-stage predict-then-optimize approach and compare its performance to the decision-focused learning model on a small-scale IRP instance.
  2. Evaluate the impact of different regularization strengths on the decision quality and convergence of the decision-focused learning model.
  3. Compare the performance of the regularization and logarithmic barrier approaches on a medium-scale IRP instance, considering both decision quality and computational efficiency.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the content, several important questions remain:

1. How does the performance of the decision-focused learning approach compare to the traditional two-stage approach in terms of total cost and customer satisfaction in real-world IRP scenarios?
2. What is the impact of the regularization parameter (λ) and the logarithmic barrier parameter (µ) on the performance and convergence of the decision-focused learning approach?
3. How does the decision-focused learning approach scale with increasing problem size and complexity in terms of the number of customers, time periods, and routes?

## Limitations

- The approach relies on approximating the non-differentiable MILP formulation, which may lead to sub-optimal solutions
- The use of regularization or logarithmic barriers introduces additional hyperparameters that require careful tuning
- Experiments focus on relatively small-scale problems, with unclear scalability to larger real-world instances

## Confidence

- **High Confidence**: The decision-focused learning framework and its integration with neural networks is well-established in the literature
- **Medium Confidence**: Specific implementation details and hyperparameters are not fully specified, making reproducibility difficult
- **Low Confidence**: The paper lacks thorough analysis of trade-offs between solution quality, computational efficiency, and differentiability for different problem sizes

## Next Checks

1. Conduct a sensitivity analysis to determine the impact of regularization strength and logarithmic barrier coefficients on solution quality and computational efficiency for different problem sizes
2. Compare the performance of the decision-focused learning approach against state-of-the-art MILP solvers on large-scale, real-world IRP instances, considering both solution quality and computation time
3. Evaluate the robustness of the approach to noisy or incomplete demand data by introducing controlled perturbations and assessing the impact on routing decisions and overall cost