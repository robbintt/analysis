---
ver: rpa2
title: Directions of Curvature as an Explanation for Loss of Plasticity
arxiv_id: '2312.00246'
source_url: https://arxiv.org/abs/2312.00246
tags:
- plasticity
- loss
- learning
- curvature
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the phenomenon of loss of plasticity in
  neural networks, where their ability to learn from new experiences diminishes over
  time. The authors propose that this loss of plasticity is due to a reduction in
  the curvature of the optimization landscape, specifically a decrease in the rank
  of the Hessian of the training objective at the beginning of new tasks.
---

# Directions of Curvature as an Explanation for Loss of Plasticity

## Quick Facts
- **arXiv ID:** 2312.00246
- **Source URL:** https://arxiv.org/abs/2312.00246
- **Reference count:** 32
- **Primary result:** Loss of plasticity in neural networks can be attributed to a reduction in the rank of the Hessian of the training objective at the beginning of new tasks.

## Executive Summary
This paper investigates the phenomenon of loss of plasticity in neural networks, where their ability to learn from new experiences diminishes over time. The authors propose that this loss of plasticity is caused by a reduction in the curvature of the optimization landscape, specifically a decrease in the rank of the Hessian of the training objective at the beginning of new tasks. Through systematic empirical investigations on MNIST, CIFAR-10, and ImageNet datasets, they demonstrate that loss of curvature coincides with and sometimes precedes loss of plasticity. The authors also show that regularizers which mitigate loss of plasticity, such as the proposed Wasserstein initialization regularizer, also preserve curvature. The Wasserstein regularizer is shown to be effective across the problem settings considered, allowing the neural network parameters to deviate further from initialization while maintaining plasticity and curvature.

## Method Summary
The paper investigates plasticity loss in continual learning settings where task distributions change periodically. The method involves training neural networks on tasks with shuffled labels or observation permutations, measuring task-end batch error and the rank of the Hessian of the training objective at task beginnings. The authors use partial blockwise Hessian computation for rank estimation and implement various regularization techniques including L2, regenerative, and a novel Wasserstein initialization regularizer. Experiments are conducted on MNIST, CIFAR-10, and ImageNet datasets using feed-forward networks and CNNs with Adam optimization.

## Key Results
- Loss of plasticity correlates with and sometimes precedes a reduction in the rank of the Hessian of the training objective at task beginnings
- Regularizers that mitigate plasticity loss (including the proposed Wasserstein initialization regularizer) also preserve curvature
- The Wasserstein initialization regularizer is effective across MNIST, CIFAR-10, and ImageNet settings, allowing parameters to deviate from initialization while maintaining plasticity
- Gradients at task-end tend to be contained in the top subspace of the Hessian, which decreases in rank over time

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Loss of plasticity is caused by a reduction in the rank of the Hessian of the training objective at the beginning of new tasks.
- **Mechanism:** As tasks change, the curvature of the optimization landscape decreases, specifically in terms of the number of significant directions of curvature (Hessian rank). When this rank drops, the network has fewer directions along which it can effectively learn new tasks.
- **Core assumption:** The rank of the Hessian at task initialization is a good proxy for the network's ability to learn new tasks.
- **Evidence anchors:**
  - [abstract]: "loss of plasticity can be attributed to this reduction in curvature" and "loss of curvature coincides with and sometimes precedes loss of plasticity"
  - [section]: "we provide empirical evidence that supports a claim that loss of plasticity co-occurs with a reduction in the rank of the Hessian of the training objective at the beginning of a new task"
  - [corpus]: Multiple papers discuss Hessian spectral collapse and its relation to plasticity loss, providing supporting evidence
- **Break condition:** If Hessian rank does not correlate with plasticity loss in different architectures or if the correlation is inconsistent across problem settings.

### Mechanism 2
- **Claim:** Regularization that preserves curvature also mitigates loss of plasticity.
- **Mechanism:** By regularizing the network parameters to maintain their distribution close to initialization (using Wasserstein distance), the curvature of the optimization landscape is preserved, preventing loss of plasticity.
- **Core assumption:** The initialization distribution contains beneficial curvature properties that should be maintained during training.
- **Evidence anchors:**
  - [abstract]: "regularizers which mitigate loss of plasticity also preserve curvature" and the proposed Wasserstein initialization regularizer "proves to be effective across the problem settings we considered"
  - [section]: "we show that regularizers which mitigate loss of plasticity also preserve curvature, motivating a simple distributional regularizer"
  - [corpus]: Limited direct evidence in corpus, but related work on Hessian regularization and plasticity exists
- **Break condition:** If preserving the initialization distribution does not consistently preserve curvature or if other forms of regularization prove more effective.

### Mechanism 3
- **Claim:** The gradient remains contained in the top subspace of the Hessian, which shrinks over time, leading to loss of plasticity.
- **Mechanism:** As the rank of the Hessian decreases, the gradient vectors become increasingly aligned with the remaining significant curvature directions. This containment prevents effective learning in new directions required for new tasks.
- **Core assumption:** The gradient-Hessian overlap is a meaningful measure of learning capacity.
- **Evidence anchors:**
  - [section]: "we plot the overlap of the gradient and the Hessian-gradient product at task-end, given by gT Hg/∥g∥∥Hg∥, which measures whether the gradient is contained in the top subspace of the Hessian" and "Gradients at the end of the task tend to be contained in the top-subspace of the Hessian which is also decreasing in rank"
  - [corpus]: Limited direct evidence, but this is a novel mechanism proposed in the paper
- **Break condition:** If gradient-Hessian overlap does not consistently correlate with plasticity loss or if the relationship is not causal.

## Foundational Learning

- **Concept:** Hessian matrix and its properties
  - **Why needed here:** The paper's core claim revolves around the rank of the Hessian and how it changes during training, so understanding what the Hessian represents is fundamental
  - **Quick check question:** What does the rank of a matrix represent, and why would the rank of the Hessian be important for understanding optimization landscape curvature?

- **Concept:** Continual learning and non-stationary distributions
  - **Why needed here:** The paper studies plasticity loss in continual learning settings where task distributions change over time
  - **Quick check question:** How does a change in the data distribution affect the optimization landscape, and why might this lead to loss of plasticity?

- **Concept:** Regularization techniques and their effects
  - **Why needed here:** The paper proposes a new regularizer (Wasserstein initialization regularizer) and compares it to existing methods
  - **Quick check question:** How do different regularization techniques affect the optimization landscape, and what are the trade-offs between preserving initialization properties and allowing parameter movement?

## Architecture Onboarding

- **Component map:** Input -> 3-layer feed-forward network (MNIST) or CNN + 2-layer FF network (CIFAR-10) -> Task-end error computation -> Hessian rank estimation -> Regularization (if enabled) -> Task change

- **Critical path:**
  1. Initialize network and parameters
  2. Train on current task for fixed number of updates
  3. Measure task-end error and beginning-of-task Hessian rank
  4. Apply regularization if enabled
  5. Change task (data distribution) and repeat

- **Design tradeoffs:**
  - Approximation vs. accuracy in Hessian computation (partial blockwise vs. full Hessian)
  - Regularization strength vs. parameter flexibility
  - Computational cost of rank estimation vs. insight gained
  - Task complexity vs. ability to observe plasticity loss

- **Failure signatures:**
  - Inconsistent correlation between Hessian rank and plasticity loss
  - Regularization causing underfitting or preventing necessary parameter movement
  - Computational issues with Hessian rank estimation on larger networks
  - Task changes not being sufficiently challenging to induce plasticity loss

- **First 3 experiments:**
  1. Implement and verify the label-shuffled MNIST experiment to observe plasticity loss with different activation functions
  2. Add Hessian rank computation and verify it decreases with plasticity loss
  3. Implement Wasserstein initialization regularizer and test its effect on preserving curvature and plasticity

## Open Questions the Paper Calls Out

- **Open Question 1:** What are the precise mechanisms that cause neural networks to lose curvature during training?
  - **Basis in paper:** [inferred] The paper identifies loss of curvature as a key factor in plasticity loss but does not explain why curvature diminishes during training.
  - **Why unresolved:** The authors note that understanding the dynamics of training neural networks with gradient descent is an active research area, even in supervised learning.
  - **What evidence would resolve it:** Detailed analysis of training dynamics showing how and when curvature loss occurs, potentially through theoretical analysis or more extensive empirical studies tracking curvature changes throughout training.

- **Open Question 2:** How does the rank of the Hessian correlate with the effective capacity of the neural network in different problem settings?
  - **Basis in paper:** [inferred] The paper suggests a relationship between Hessian rank and plasticity but doesn't explore the connection to network capacity.
  - **Why unresolved:** The authors demonstrate that curvature loss correlates with plasticity loss but don't investigate how this relates to the network's ability to represent different functions.
  - **What evidence would resolve it:** Systematic experiments measuring network capacity (e.g., number of learnable functions) alongside Hessian rank across various architectures and problem settings.

- **Open Question 3:** Can curvature preservation be achieved through architectural modifications rather than regularization?
  - **Basis in paper:** [inferred] The authors focus on regularization methods but briefly mention that architectural factors like activation functions can affect plasticity.
  - **Why unresolved:** The paper primarily investigates regularization approaches and doesn't explore architectural alternatives in depth.
  - **What evidence would resolve it:** Comparative studies of different network architectures (e.g., varying depth, width, activation functions) to identify designs that naturally preserve curvature across tasks.

## Limitations

- The empirical evidence relies on correlation rather than causal intervention between curvature reduction and plasticity loss
- The Hessian rank estimation method (partial blockwise computation) introduces approximation error that is not fully characterized
- The Wasserstein regularizer's effectiveness may depend on specific architectural choices or problem settings not explored in depth

## Confidence

- **High:** Observation that plasticity loss correlates with reduced Hessian rank across multiple datasets and architectures
- **Medium:** The proposed Wasserstein initialization regularizer effectively preserves both curvature and plasticity across tested settings
- **Low:** The claim that gradient containment in shrinking Hessian subspaces is the primary mechanism of plasticity loss

## Next Checks

1. **Intervention Experiment:** Design a controlled study where Hessian rank is artificially maintained (through targeted regularization) while monitoring whether plasticity is preserved, establishing causality rather than just correlation.

2. **Architectural Generalization:** Test the curvature-plasticity relationship on architectures beyond feed-forward networks and CNNs, particularly transformer-based models, to assess whether the mechanism generalizes across modern deep learning architectures.

3. **Gradient-Hessian Overlap Analysis:** Systematically measure and analyze the gradient-Hessian overlap across different layers and training stages to determine if this containment mechanism is consistent and predictive of plasticity loss.