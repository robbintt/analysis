---
ver: rpa2
title: Troubles and Failures in Interactional Language. Towards a Linguistically Informed
  Taxonomy
arxiv_id: '2311.07217'
source_url: https://arxiv.org/abs/2311.07217
tags:
- language
- human
- i-language
- interaction
- conversational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a systematic research agenda to evaluate human-machine
  interaction (HMI) by comparing it to human-human interaction (HHI), with a focus
  on interactional language (i-language). The paper identifies key limitations of
  current conversational agents (CAs), including challenges with common ground building,
  turn-taking, and cooperativity.
---

# Troubles and Failures in Interactional Language. Towards a Linguistically Informed Taxonomy

## Quick Facts
- arXiv ID: 2311.07217
- Source URL: https://arxiv.org/abs/2311.07217
- Authors: 
- Reference count: 22
- Key outcome: This work introduces a systematic research agenda to evaluate human-machine interaction (HMI) by comparing it to human-human interaction (HHI), with a focus on interactional language (i-language).

## Executive Summary
This paper proposes a novel research agenda to systematically evaluate human-machine interaction (HMI) by comparing it to human-human interaction (HHI), with a specific focus on interactional language (i-language). The authors argue that current conversational agents (CAs) are fundamentally limited in their use of i-language because they lack the general cognitive capacities—such as Theory of Mind and inferencing—that humans rely on for natural conversation. The paper identifies key limitations of CAs, including challenges with common ground building, turn-taking, and cooperativity, and proposes a taxonomy to explore these issues through four key questions: CA production, CA comprehension, user production, and user evaluation of i-language in HMI.

## Method Summary
The paper introduces a research agenda rather than a specific experimental method, proposing a taxonomy to systematically compare the use of i-language in HMI and HHI. The approach involves defining a corpus of conversational interactions, developing an annotation scheme for i-language features, and applying this scheme to compare patterns between HHI and HMI. The proposed framework breaks down the investigation into four key questions: CA production of i-language, CA comprehension of i-language, user production of i-language in HMI, and user evaluation of CA i-language use. While the paper outlines the theoretical foundation and motivation for this approach, it does not provide specific data sources, collection methods, or detailed implementation procedures.

## Key Results
- Current conversational agents are limited in their use of interactional language due to lack of general cognitive capacities like Theory of Mind and inferencing
- HMI can never fully replicate HHI because CAs fundamentally lack the cognitive foundations necessary for proper i-language use
- Humans demonstrate unique flexibility in language use, potentially allowing them to adjust their behavior in HMI to compensate for CA limitations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The proposed taxonomy isolates the unique limitations of conversational agents by focusing on i-language, which requires general cognitive capacities that current CAs lack.
- Mechanism: By separating interactional language use from representational language, the taxonomy can pinpoint where CAs fail in natural interaction (e.g., turn-taking, common ground building, cooperativity) versus where they perform well.
- Core assumption: CAs' lack of "hot cognition" (theory of mind, inferencing) fundamentally limits their ability to use i-language correctly, unlike representational language.
- Evidence anchors:
  - [abstract] The paper identifies challenges like common ground building, turn-taking, and cooperativity as key limitations of CAs.
  - [section] The architecture comparison (Figures 2 and 3) shows that proper i-language use depends on general cognitive domains beyond language rules.
  - [corpus] The corpus mentions CAs' struggles with turn-taking and common ground building, aligning with the paper's claims.
- Break condition: If a CA develops general cognitive capacities (e.g., theory of mind, inferencing), it could potentially use i-language more naturally, breaking the assumption that CAs are inherently limited in this domain.

### Mechanism 2
- Claim: The proposed taxonomy provides a structured framework for evaluating HMI by breaking down i-language use into four key questions: CA production, CA comprehension, user production, and user evaluation.
- Mechanism: This framework allows researchers to systematically investigate each aspect of i-language use in HMI, identifying specific areas where CAs fall short and where human users may need to adjust their behavior.
- Core assumption: The four-question framework can capture the full complexity of i-language use in HMI, and each question is distinct and measurable.
- Evidence anchors:
  - [abstract] The paper proposes four key questions to explore i-language in HMI: CA production, CA comprehension, user production, and user evaluation.
  - [section] The paper argues that HMI can never fully replicate HHI due to fundamental differences, but human flexibility may allow for natural adjustments in HMI.
  - [corpus] The corpus mentions the proposed taxonomy will explore these issues through the four key questions, supporting the claim.
- Break condition: If the four-question framework proves insufficient to capture the nuances of i-language use in HMI, or if the questions are not distinct or measurable, the taxonomy may not be effective.

### Mechanism 3
- Claim: The proposed taxonomy leverages linguistic theory embedded within cognitive science to model not only language and its use but also the knowledge thereof, providing a more comprehensive understanding of HMI.
- Mechanism: By considering the cognitive foundations of i-language use, the taxonomy can identify where CAs lack the necessary cognitive capacities and inform the development of more human-like conversational agents.
- Core assumption: Linguistic theories embedded within cognitive science provide a more comprehensive model of language use than conversational AI models that rely solely on large language models and dialogue systems.
- Evidence anchors:
  - [abstract] The paper argues that current CAs are limited in their use of i-language, which requires general cognitive capacities that AI has not yet been able to generate to the same extent as representational knowledge.
  - [section] The architecture comparison (Figures 2 and 3) highlights the differences between human knowledge and use of i-language and the typical architecture of a dialogue system underlying CAs.
  - [corpus] The corpus mentions that the differences in these two figures further highlight differences in how conversational AI and linguistic theory model language.
- Break condition: If conversational AI models can incorporate general cognitive capacities (e.g., theory of mind, inferencing) to the same extent as linguistic theories embedded within cognitive science, the assumption that linguistic theories provide a more comprehensive model may no longer hold.

## Foundational Learning

- Concept: Interactional Language (i-language)
  - Why needed here: I-language is the focus of the proposed taxonomy and is crucial for understanding the limitations of CAs in natural interaction.
  - Quick check question: What are the key differences between i-language and representational language, and why is i-language more challenging for CAs to master?

- Concept: Common Ground, Turn-taking, and Cooperativity
  - Why needed here: These are the three main challenges in HMI identified by the paper, and understanding them is essential for applying the proposed taxonomy.
  - Quick check question: How do common ground, turn-taking, and cooperativity contribute to natural conversation, and what are the specific limitations of CAs in each of these areas?

- Concept: Theory of Mind and Inferencing
  - Why needed here: These general cognitive capacities are essential for proper use of i-language and are currently lacking in CAs, according to the paper.
  - Quick check question: What is the role of theory of mind and inferencing in human conversation, and why are they particularly important for the use of i-language?

## Architecture Onboarding

- Component map: The architecture consists of language rules (white inner hexagon) and general cognitive domains (grey outer hexagon) that interact to enable proper use of i-language in HHI. CAs, however, rely on a typical dialogue system architecture (Figure 3) that lacks these general cognitive capacities.
- Critical path: The critical path for developing a more human-like conversational agent involves incorporating general cognitive capacities (e.g., theory of mind, inferencing) into the dialogue system architecture to enable proper use of i-language.
- Design tradeoffs: Incorporating general cognitive capacities into CAs may require significant computational resources and may introduce complexity in the dialogue system architecture. Balancing the benefits of improved i-language use with the costs of increased complexity is a key design tradeoff.
- Failure signatures: If a CA fails to use i-language adequately, exhibits poor turn-taking, struggles with common ground building, or fails to respond appropriately to violations of cooperativity, it indicates a lack of general cognitive capacities necessary for proper i-language use.
- First 3 experiments:
  1. Evaluate CA production of i-language by analyzing a corpus of CA-user interactions for the presence and appropriateness of i-language markers (e.g., backchannels, clarification requests).
  2. Assess CA comprehension of i-language by presenting CAs with utterances containing i-language markers and evaluating their ability to respond appropriately.
  3. Investigate user production of i-language in HMI by analyzing a corpus of user-CA interactions and comparing the frequency and type of i-language markers used in HMI versus HHI.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can conversational agents (CAs) ever fully master the use of interactional language (i-language) in human-machine interaction (HMI)?
- Basis in paper: [explicit] The paper states that CAs are not likely to ever master i-language due to their lack of general cognitive capacities like Theory of Mind.
- Why unresolved: While the paper argues that CAs lack the cognitive abilities to properly use i-language, it does not definitively prove that CAs can never achieve this level of proficiency, especially with the rapid advancements in AI like GPT-4.
- What evidence would resolve it: Longitudinal studies comparing the use of i-language in HMI over time, particularly as AI models become more advanced, could provide evidence for or against the possibility of CAs mastering i-language.

### Open Question 2
- Question: How do human users adjust their use of interactional language (i-language) in HMI compared to human-human interaction (HHI)?
- Basis in paper: [explicit] The paper hypothesizes that humans have a unique flexibility in language use, which may allow them to adjust their behavior in HMI, but this is not yet empirically tested.
- Why unresolved: The paper suggests that humans might adjust their i-language use in HMI, but does not provide concrete evidence or studies on how this adjustment occurs or its extent.
- What evidence would resolve it: Empirical studies analyzing the differences in i-language use between HMI and HHI, focusing on aspects like turn-taking, common ground building, and cooperativity, could provide insights into how humans adjust their language in HMI.

### Open Question 3
- Question: What are the specific challenges in evaluating the naturalness of HMI, and how can they be addressed using a linguistically informed taxonomy?
- Basis in paper: [explicit] The paper introduces a novel taxonomy to explore troubles and failures in HMI related to i-language use, but does not detail the specific challenges or how the taxonomy addresses them.
- Why unresolved: While the paper proposes a taxonomy for evaluating HMI, it does not explicitly outline the challenges in assessing naturalness or how the taxonomy overcomes these challenges.
- What evidence would resolve it: Detailed case studies applying the proposed taxonomy to real-world HMI scenarios, with a focus on identifying and addressing specific challenges in evaluating naturalness, would provide evidence of the taxonomy's effectiveness.

## Limitations
- The paper proposes a research agenda but lacks specific implementation details, data sources, or evaluation metrics needed for immediate application
- The paper does not empirically demonstrate how CA limitations in i-language manifest across the proposed four research questions
- The paper does not quantitatively validate that linguistic approaches embedded in cognitive science better capture i-language phenomena compared to current CA architectures

## Confidence

**High confidence**: The identification of i-language as a key differentiator between HHI and HMI, and the general claim that CAs struggle with turn-taking, common ground, and cooperativity

**Medium confidence**: The proposed four-question framework's ability to comprehensively capture i-language challenges in HMI

**Low confidence**: The practical implementation path and specific methodological details for applying the taxonomy

## Next Checks

1. **Data collection validation**: Create and annotate a pilot corpus of HMI interactions (10-20 conversations) to test whether the proposed i-language annotation scheme reliably distinguishes CA limitations from human capabilities

2. **Framework specificity test**: Conduct a case study applying each of the four proposed questions to one specific i-language phenomenon (e.g., clarification requests) to assess whether the framework yields distinct and actionable insights

3. **Cross-linguistic generalizability check**: Apply the taxonomy to interactions in multiple languages to determine whether the identified CA limitations in i-language use are universal or language-dependent