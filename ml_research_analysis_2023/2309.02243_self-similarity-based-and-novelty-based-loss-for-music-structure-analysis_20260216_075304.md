---
ver: rpa2
title: Self-Similarity-Based and Novelty-based loss for music structure analysis
arxiv_id: '2309.02243'
source_url: https://arxiv.org/abs/2309.02243
tags:
- music
- latexit
- features
- international
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses music structure analysis (MSA), specifically
  the task of detecting boundaries between musical segments in audio tracks. The core
  method involves learning both audio features and convolutional kernels simultaneously.
---

# Self-Similarity-Based and Novelty-based loss for music structure analysis

## Quick Facts
- arXiv ID: 2309.02243
- Source URL: https://arxiv.org/abs/2309.02243
- Reference count: 0
- Primary result: Joint optimization of SSM-loss and novelty-loss achieves HR3F of 0.713 on RWC-Pop-AIST

## Executive Summary
This paper introduces a novel framework for music structure analysis that jointly learns audio features and convolutional kernels for boundary detection. The method optimizes two complementary losses: an SSM-loss that enforces feature learning to capture musical structure via self-similarity matrices, and a novelty-loss that trains kernels to detect segment boundaries by convolving over the estimated SSM. The approach incorporates self-attention layers to learn relative features dependent on track context, demonstrating competitive performance on RWC-Pop and SALAMI datasets.

## Method Summary
The method processes Log-Mel-Spectrogram patches through an encoder consisting of 5 convolutional blocks followed by N Transformer Encoder blocks. Embeddings are L2-normalized and used to compute an estimated self-similarity matrix (SSM) via scaled cosine similarity. The SSM-loss (weighted binary cross-entropy) compares this to a ground-truth SSM derived from segment annotations. Simultaneously, learnable convolutional kernels convolve along the SSM's main diagonal to produce a novelty score, optimized via novelty-loss (binary cross-entropy) against ground-truth novelty. The losses are combined with α weighting, and self-attention layers enable context-dependent feature learning. Training uses ADAM optimizer with early stopping.

## Key Results
- Achieves HR3F of 0.713 on RWC-Pop-AIST dataset
- Competitive performance on SALAMI subsets with varying precision windows
- Self-attention and joint loss optimization improve boundary detection accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SSM-loss enforces feature learning that captures musical structure by minimizing the distance between the estimated and ground-truth self-similarity matrices.
- Mechanism: The encoder fθ projects input patches into embeddings, which are L2-normalized and compared pairwise using a scaled cosine similarity to build the estimated SSM. This SSM is compared to a ground-truth SSM derived from segment labels using a weighted binary cross-entropy loss, encouraging the network to produce embeddings that reflect segment homogeneity.
- Core assumption: Neighboring frames within a segment are more similar to each other than to frames outside the segment, and this similarity can be represented in a binary SSM.
- Evidence anchors:
  - [abstract] "we jointly optimize -- a loss based on the Self-Similarity-Matrix (SSM) obtained with the learned features, denoted by SSM-loss"
  - [section] "The ground-truth SSM, Sij, is constructed using annotated segments (start and end time) and their associated labels... we assign the value Sij = 1 if label(seg(ti)) = label(seg(tj)) and 0 otherwise."
- Break condition: If segment homogeneity assumption fails (e.g., highly variable segments), the SSM-loss may not produce meaningful gradients for feature learning.

### Mechanism 2
- Claim: The novelty-loss trains convolutional kernels to detect segment boundaries by convolving them over the estimated SSM's main diagonal.
- Mechanism: A set of learnable kernels Kθ is convolved along the main diagonal of the estimated SSM to produce a novelty score. This novelty score is compared to a ground-truth novelty score (derived from segment boundaries) using binary cross-entropy loss, encouraging the kernels to highlight changes in musical content.
- Core assumption: Segment boundaries correspond to peaks in the novelty score obtained by convolving appropriate kernels over the SSM's diagonal.
- Evidence anchors:
  - [abstract] "a loss based on the novelty score obtained applying the learned kernels to the estimated SSM, denoted by novelty-loss"
  - [section] "We propose to learn the kernels Kθ such that when convolved with the estimated SSM... it allows the estimation of a novelty score... which attempts to reproduce a ground-truth novelty score, ni."
- Break condition: If the ground-truth novelty score is noisy or ambiguous, the novelty-loss may not train effective kernels.

### Mechanism 3
- Claim: Self-attention layers enable the encoder to learn relative features that depend on the context within a track.
- Mechanism: Self-attention layers are inserted in the encoder architecture after the convolutional blocks. These layers allow each embedding to attend to all other embeddings in the track, enabling the network to capture track-specific patterns and relationships that are crucial for MSA.
- Core assumption: Features that highlight temporal structure of a music track depend on the track itself and benefit from context awareness.
- Evidence anchors:
  - [abstract] "We also demonstrate that relative feature learning, through self-attention, is beneficial for the task of MSA."
  - [section] "To let each feature Xi 'know' about surrounding times features... we introduce layers of Self-Attention (SA) in our encoder."
- Break condition: If the track length is too short or the musical content is too uniform, self-attention may not provide significant benefits.

## Foundational Learning

- Concept: Self-similarity matrices (SSMs)
  - Why needed here: SSMs are a core representation for MSA, capturing pairwise similarities between time frames to reveal repeated and contrasting sections.
  - Quick check question: Given a track with clear verse-chorus structure, what pattern would you expect to see in its SSM?

- Concept: Convolutional neural networks (CNNs)
  - Why needed here: CNNs are used to learn both the feature embeddings (via the encoder) and the novelty detection kernels, enabling end-to-end training.
  - Quick check question: Why might a CNN be more effective than a fully connected network for processing the 2D SSM in novelty detection?

- Concept: Self-attention mechanisms
  - Why needed here: Self-attention allows the model to capture long-range dependencies and context-dependent features, which are important for recognizing musical structure that varies across tracks.
  - Quick check question: How does self-attention differ from simple convolutional layers in terms of receptive field and context integration?

## Architecture Onboarding

- Component map: Input (Log-Mel patches) → 5 Conv blocks → N Transformer Encoder blocks → L2 normalization → SSM computation → Novelty kernels (conv layer) → Outputs (SSM, novelty score). Losses: SSM-loss (weighted BCE) and novelty-loss (BCE).
- Critical path: Feature extraction (encoder) → SSM estimation → Kernel convolution → Novelty score → Boundary detection.
- Design tradeoffs: Large hop size (0.5s) reduces computation but lowers boundary precision; self-attention adds context but increases parameters; joint loss balancing (α) trades off feature vs. boundary learning.
- Failure signatures: Low HR3F but high HR0.5F suggests coarse features; poor novelty detection may indicate ineffective kernels or noisy ground-truth; over-segmentation may indicate overly sensitive kernels.
- First 3 experiments:
  1. Train with N=0 (no self-attention) and α=1 (only SSM-loss) to verify baseline performance.
  2. Train with N=1 and α=0.5 to test benefit of self-attention and joint loss.
  3. Fix kernels (K:fix-Init:chck) vs. train kernels to assess kernel learning contribution.

## Open Questions the Paper Calls Out

- Question: How would the proposed method perform if trained with beat-synchronous features instead of non-beat-synchronous ones?
  - Basis in paper: [explicit] The paper mentions that beat-synchronous features were not considered due to the unreliability of beat estimation outside popular music, but suggests that using beat-synchronous features might be beneficial.
  - Why unresolved: The paper did not evaluate the performance of the proposed method using beat-synchronous features.
  - What evidence would resolve it: An experiment comparing the performance of the proposed method using beat-synchronous and non-beat-synchronous features on the same datasets.

- Question: How would the proposed method perform if trained with a larger and more diverse dataset?
  - Basis in paper: [inferred] The paper used a subset of 693 tracks from the Harmonix dataset and 298 tracks from the Isophonics dataset for training. It is not clear whether a larger and more diverse dataset would improve the performance of the proposed method.
  - Why unresolved: The paper did not explore the impact of using a larger and more diverse dataset on the performance of the proposed method.
  - What evidence would resolve it: An experiment comparing the performance of the proposed method using different sizes and diversities of training datasets on the same test sets.

- Question: How would the proposed method perform if trained with a different distance/similarity/divergence measure for constructing the SSM?
  - Basis in paper: [explicit] The paper used a "scaled" cosine-similarity for constructing the SSM, but mentions that other distance/similarity/divergence measures could be used.
  - Why unresolved: The paper did not evaluate the performance of the proposed method using different distance/similarity/divergence measures for constructing the SSM.
  - What evidence would resolve it: An experiment comparing the performance of the proposed method using different distance/similarity/divergence measures for constructing the SSM on the same datasets.

## Limitations

- Performance evaluation limited to relatively small datasets (693 Harmonix + 298 Isophonics tracks)
- Absence of direct comparisons with modern MSA models
- SSM-loss assumes binary segment homogeneity which may not capture gradual transitions or cross-genre variations

## Confidence

- SSM-loss mechanism: High
- Novelty-loss kernel learning: Medium
- Self-attention benefits: Medium
- Overall boundary detection claims: Medium

## Next Checks

1. Ablate self-attention (N=0) and compare HR3F/HR0.5F to verify context learning contribution.
2. Train with fixed kernels (K:fix-Init:chck) to isolate novelty-loss effectiveness.
3. Test on cross-dataset generalization (e.g., train on RWC-Pop, test on SALAMI) to assess robustness.