---
ver: rpa2
title: Bounding Box-based Multi-objective Bayesian Optimization of Risk Measures under
  Input Uncertainty
arxiv_id: '2301.11588'
source_url: https://arxiv.org/abs/2301.11588
tags:
- proposed
- following
- each
- then
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a Bayesian optimization method for multi-objective
  optimization under input uncertainty, specifically targeting distributionally robust
  Pareto fronts. The method constructs high-probability bounding boxes for risk measures
  using Gaussian process models and selects evaluation points using a maximin distance
  based on these boxes.
---

# Bounding Box-based Multi-objective Bayesian Optimization of Risk Measures under Input Uncertainty

## Quick Facts
- arXiv ID: 2301.11588
- Source URL: https://arxiv.org/abs/2301.11588
- Reference count: 40
- This study proposes a Bayesian optimization method for multi-objective optimization under input uncertainty, specifically targeting distributionally robust Pareto fronts.

## Executive Summary
This paper addresses the challenge of multi-objective Bayesian optimization under input uncertainty, where the distribution of environmental variables is unknown. The proposed method constructs high-probability bounding boxes for risk measures using Gaussian process models and selects evaluation points using a maximin distance based on these boxes. Theoretical analysis proves finite-sample convergence with high probability for various risk measures, while numerical experiments demonstrate superior performance compared to existing methods in both uncertain and ordinary multi-objective Bayesian optimization settings.

## Method Summary
The method employs Gaussian process models to estimate black-box functions f(1) and f(2) with environmental variables w. For each candidate distribution in the family A, credible intervals are constructed for the risk measures F(1) and F(2). The Pareto frontier is estimated from lower confidence bounds, and an acquisition function based on the maximum distance to the dominated region guides the selection of the next evaluation point. The algorithm terminates when the acquisition function value falls below a threshold, ensuring convergence to an ε-accurate solution with high probability.

## Key Results
- Theoretical guarantees for finite-sample convergence with high probability for Bayes risk, worst-case risk, and value-at-risk
- Superior performance compared to existing methods in both uncertain and ordinary multi-objective Bayesian optimization settings
- Effective balance between computational efficiency and theoretical guarantees while handling input distribution uncertainty

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method constructs high-probability bounding boxes for risk measures using Gaussian process models.
- Mechanism: For each input (x,w), credible intervals for f(j)(x,w) are constructed using the posterior mean ± a scaled posterior standard deviation. These are then integrated over the candidate distribution family A to form bounds on F(j)(x). The maximum of these bounds defines the Pareto frontier approximation.
- Core assumption: The Gaussian process surrogate models accurately capture the uncertainty in the black-box functions, and the candidate distribution family A contains distributions close to the true input distribution.
- Evidence anchors:
  - [abstract] "construct high-probability bounding boxes for the risk measures using the GP model"
  - [section] "For each input (x,w) ∈ X × Ω and time t, the credible interval of f(1)(x,w) is denoted by Q(f (1))t (x,w) = [l(f (1))t (x,w),u (f (1))t (x,w)]"
  - [corpus] Weak evidence - no direct mention of bounding boxes in corpus
- Break condition: If the GP models poorly capture the true function behavior or if A does not contain a distribution close to the true input distribution, the bounding boxes may not contain the true risk measures with high probability.

### Mechanism 2
- Claim: The acquisition function efficiently selects the next evaluation point by maximizing the distance to the dominated region of the current lower confidence bound Pareto frontier.
- Mechanism: The acquisition function at(x) measures the maximum distance between the upper confidence bound of F(x) and the dominated region of the current lower confidence bound Pareto frontier. The point with the maximum at(x) is selected for evaluation.
- Core assumption: The upper and lower confidence bounds provide a reliable envelope for the true risk measures, and the distance metric effectively captures the improvement potential.
- Evidence anchors:
  - [abstract] "selects evaluation points using a maximin distance based on these boxes"
  - [section] "Using this, we define AF at(x) for x ∈ X as at(x) = dist(UCBt(x), Dom(LCBt(ˆΠt)))"
  - [corpus] Weak evidence - no direct mention of acquisition functions in corpus
- Break condition: If the confidence bounds are too conservative or the distance metric poorly captures the true improvement potential, the acquisition function may select suboptimal points.

### Mechanism 3
- Claim: The theoretical analysis guarantees finite-sample convergence to an arbitrarily accurate Pareto frontier with high probability.
- Mechanism: By carefully bounding the maximum information gain of the GP models and using appropriate trade-off parameters, the authors prove that the algorithm terminates after a finite number of iterations with a solution within an ε-ball of the true Pareto frontier.
- Core assumption: The maximum information gain grows sublinearly with the number of observations, and the GP kernels satisfy certain regularity conditions.
- Evidence anchors:
  - [abstract] "Theoretical analysis proves finite-sample convergence with high probability for various risk measures"
  - [section] "Theorem 4.1 does not indicate whether the algorithm terminates or not. The following theorem guarantees the convergence of Algorithm 1."
  - [corpus] Weak evidence - no direct mention of theoretical analysis or convergence guarantees in corpus
- Break condition: If the maximum information gain grows faster than expected or the GP kernels violate the regularity conditions, the convergence guarantees may not hold.

## Foundational Learning

- Concept: Gaussian Process Regression
  - Why needed here: GP regression provides a principled way to model the black-box functions and quantify uncertainty, which is crucial for constructing the bounding boxes and acquisition function.
  - Quick check question: What is the form of the posterior mean and variance for a GP conditioned on observed data?

- Concept: Pareto Optimality
  - Why needed here: The goal is to identify the Pareto frontier of the risk measures, which requires understanding the concept of Pareto optimality and how to approximate it from noisy observations.
  - Quick check question: What is the definition of the Pareto frontier for a multi-objective optimization problem?

- Concept: Distributionally Robust Optimization
  - Why needed here: The problem setting involves optimizing under input uncertainty, where the true input distribution is unknown but assumed to belong to a candidate family. Understanding DRO is essential for formulating and solving the problem.
  - Quick check question: What is the difference between stochastic optimization and distributionally robust optimization?

## Architecture Onboarding

- Component map: Gaussian process models for f(1) and f(2) -> Credible interval construction for F(1) and F(2) -> Pareto frontier estimation from lower confidence bounds -> Acquisition function based on distance to dominated region -> Stopping condition based on acquisition function value

- Critical path:
  1. Fit GP models to observed data
  2. Construct credible intervals for risk measures
  3. Estimate Pareto frontier from lower confidence bounds
  4. Select next evaluation point using acquisition function
  5. Observe function values and update GP models
  6. Check stopping condition

- Design tradeoffs:
  - Computational cost of inf calculations for bounding boxes vs. accuracy of approximation
  - Choice of distance metric for acquisition function vs. sensitivity to outliers
  - Trade-off parameter β vs. exploration-exploitation balance

- Failure signatures:
  - Acquisition function selects points outside the region of interest
  - Pareto frontier estimation is too conservative or too optimistic
  - GP models fail to capture the true function behavior

- First 3 experiments:
  1. Verify that the credible intervals contain the true risk measures with the specified probability on a simple synthetic problem.
  2. Check that the acquisition function selects points that improve the Pareto frontier approximation.
  3. Confirm that the algorithm terminates after a finite number of iterations and returns an ε-accurate solution on a test problem.

## Open Questions the Paper Calls Out

- Question: How does the proposed method scale to continuous environmental variables w rather than discrete ones?
  - Basis in paper: Explicit - stated as a future work item in the conclusion section.
  - Why unresolved: The current method relies on constructing credible intervals over discrete environmental variable values and performing inf calculations over Ω. This approach does not directly extend to continuous w.
  - What evidence would resolve it: Implementation and theoretical analysis of the method for continuous w, including how to construct bounding boxes and select evaluation points.

- Question: What is the impact of different distance metrics between distributions (beyond L1-norm) on the method's performance and theoretical guarantees?
  - Basis in paper: Explicit - mentions L1-norm is used but notes the method could work with other distances, though this isn't explored.
  - Why unresolved: The choice of distance metric affects how candidate distributions are defined and how the inf calculations are performed, which could significantly impact both performance and theoretical properties.
  - What evidence would resolve it: Comparative experiments using different distance metrics (L2, Wasserstein, etc.) showing performance and theoretical analysis of how different metrics affect convergence rates.

- Question: How does the method perform in high-dimensional settings with more than two objective functions?
  - Basis in paper: Explicit - mentions extension to m ≥ 3 objectives is possible but doesn't provide experiments or analysis.
  - Why unresolved: The acquisition function formulation (3.2) is provided for m ≥ 3, but no empirical validation or theoretical analysis of scaling behavior is given.
  - What evidence would resolve it: Experiments with 3+ objectives showing performance metrics R1/R2, computational time scaling, and analysis of how the information gain κ(j) behaves in higher dimensions.

## Limitations

- The method's performance heavily depends on the choice of the candidate distribution family A, which is assumed to contain a distribution close to the true input distribution. The paper does not provide detailed guidance on how to select this family in practice.
- The computational complexity of constructing the bounding boxes, which involves integrating over the entire candidate family A, may become prohibitive for large-scale problems or families with complex structure.
- The robustness of the method to model misspecification and the choice of the candidate distribution family A is not thoroughly explored.

## Confidence

High confidence: The theoretical convergence guarantees for the algorithm under the specified assumptions. The paper provides rigorous proofs for the finite-sample convergence with high probability.

Medium confidence: The effectiveness of the acquisition function based on the maximin distance. While the paper demonstrates good performance in numerical experiments, the sensitivity to the choice of distance metric and the trade-off parameter β is not thoroughly explored.

Low confidence: The robustness of the method to model misspecification and the choice of the candidate distribution family A. The paper assumes that A contains a distribution close to the true input distribution, but does not provide guidance on how to ensure this in practice or how sensitive the method is to violations of this assumption.

## Next Checks

1. **Sensitivity analysis of the candidate distribution family**: Perform a systematic study to assess how the choice of the candidate distribution family A affects the performance of the method. This could involve varying the size and structure of A and evaluating the impact on the quality of the Pareto frontier approximation.

2. **Robustness to model misspecification**: Investigate the method's performance when the Gaussian process models poorly capture the true function behavior or when the candidate distribution family A does not contain a distribution close to the true input distribution. This could involve introducing controlled misspecifications in the GP models or the input distribution and measuring the impact on the convergence and accuracy of the method.

3. **Computational scalability**: Evaluate the computational complexity of the method for larger-scale problems or families with more complex structure. This could involve benchmarking the time required to construct the bounding boxes and optimize the acquisition function as a function of the problem size and the complexity of the candidate distribution family.