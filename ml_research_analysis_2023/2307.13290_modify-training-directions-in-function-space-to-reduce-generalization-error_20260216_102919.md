---
ver: rpa2
title: Modify Training Directions in Function Space to Reduce Generalization Error
arxiv_id: '2307.13290'
source_url: https://arxiv.org/abs/2307.13290
tags:
- training
- modified
- generalization
- neural
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a theoretical framework for analyzing generalization
  error in neural networks using a modified natural gradient descent (NGD) approach
  in function space. The authors derive an explicit analytical solution for the learned
  function under infinite width and Gaussian assumptions, decomposing the generalization
  error into components from the training set and distribution discrepancy.
---

# Modify Training Directions in Function Space to Reduce Generalization Error

## Quick Facts
- arXiv ID: 2307.13290
- Source URL: https://arxiv.org/abs/2307.13290
- Reference count: 40
- Primary result: Theoretical framework showing that modifying training directions in eigenspaces of Neural Tangent Kernel can reduce generalization error

## Executive Summary
This paper presents a theoretical framework for analyzing generalization error in neural networks through function space analysis. By establishing a modified natural gradient descent (NGD) approach in function space, the authors derive an explicit analytical solution for the learned function under infinite width and Gaussian assumptions. The key contribution is decomposing the generalization error into components from the training set and distribution discrepancy, and showing that by modifying training directions in the eigenspaces of the Neural Tangent Kernel, the total generalization error can be reduced.

## Method Summary
The paper analyzes generalization error by studying the learning dynamics in function space rather than parameter space. Under the infinite width limit assumption, the authors derive an analytical solution for the learned function and decompose the generalization error into two components: training set error and distribution discrepancy. They then propose a modified NGD algorithm that alters training directions in the eigenspaces of the Neural Tangent Kernel based on a criterion that balances these two error components. The theoretical framework is validated on synthetic data using a two-layer MLP with 2^12 neurons, where Modified NGD demonstrates improved generalization performance compared to standard NGD.

## Key Results
- Generalization error can be explicitly decomposed into training set error and distribution discrepancy components under infinite width assumptions
- Modifying eigenvalues of the Fisher Information Matrix in function space reduces generalization error by balancing the two error components
- Existing generalization-enhancing methods (cross-domain generalization, self-distillation, small batch training) can be explained within this theoretical framework as implicitly modifying eigenvalues

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modifying eigenvalues of the Fisher Information Matrix in function space reduces generalization error by balancing training set error and distribution discrepancy.
- Mechanism: The method uses a modified natural gradient descent (Modified NGD) that alters the training directions in the eigenspaces of the Neural Tangent Kernel (NTK). By cutting or preserving eigenvalues based on a criterion derived from the decomposition of generalization error, the training dynamics are adjusted to focus on eigenspaces with lower discrepancy between training and true data distributions.
- Core assumption: The infinite width limit holds, ensuring that the NTK is positive definite and the Fisher Information Matrix is constant during training.
- Evidence anchors:
  - [abstract] "By modifying the training directions in the eigenspaces of the Neural Tangent Kernel, they show that generalization error can be reduced."
  - [section] "With cutting proper eigenvalues of the empirical MIFIM, the training dynamics in function space can stop training on the eigenspace which of large discrepancy between the model of training set and the true model, while remaining training on the eigenspace with small discrepancy."
  - [corpus] Weak evidence. Corpus neighbors do not directly support this specific mechanism.

### Mechanism 2
- Claim: The generalization error is decomposed into two components: one from the training set and another from the distribution discrepancy.
- Mechanism: Under the assumptions of Gaussian distribution and infinite width limit, the expected risk of the learned function is split into R1 (training set error) and R2 (distribution discrepancy error). This decomposition allows for targeted modifications in eigenspaces to balance these errors.
- Core assumption: The training set is drawn i.i.d. from the true data distribution, and the dataset is large enough for the law of large numbers to apply.
- Evidence anchors:
  - [abstract] "Thus, we explicitly derive the generalization error of the learned neural network function using theoretical methods from eigendecomposition and statistics theory."
  - [section] "Theorem 2. Under the same assumptions as Theorem 3, the expected risk of fθ∞ trained by Modified NGD in Corollary 1 can be decomposed into two parts, one of the risk on training set, one of the risk on the distribution discrepancy between training set and true data."
  - [corpus] Weak evidence. Corpus neighbors do not directly support this specific decomposition.

### Mechanism 3
- Claim: Existing generalization enhancing methods can be explained within this theoretical framework by implicitly modifying eigenvalues of the Fisher Information Matrix.
- Mechanism: Methods like cross-domain generalization, self-distillation, and small batch training implicitly alter the eigenvalues of the Fisher Information Matrix in function space, thereby modifying training directions in the eigenspaces of NTK. This leads to improved generalization performance.
- Core assumption: The implicit modifications in these methods correspond to changes in the eigenvalues of the Fisher Information Matrix.
- Evidence anchors:
  - [abstract] "Furthermore, We demonstrate that this theoretical framework is capable to explain many existing results of generalization enhancing methods."
  - [section] "These methods can be incorporated into our theoratic framework to explain their efficacy. For these methods implicitly modify the eigenvalues of the Fisher Information matrix in function space and consequently the training direction in the eigenspaces of NTK."
  - [corpus] Weak evidence. Corpus neighbors do not directly support this specific explanation.

## Foundational Learning

- Concept: Neural Tangent Kernel (NTK)
  - Why needed here: The NTK is central to the theoretical framework, as it governs the training dynamics in the infinite width limit and allows for the decomposition of generalization error across eigenspaces.
  - Quick check question: How does the NTK relate to the Fisher Information Matrix in the infinite width limit?

- Concept: Natural Gradient Descent (NGD)
  - Why needed here: NGD is the basis for the Modified NGD algorithm, utilizing curvature information in function space to adjust training directions.
  - Quick check question: What is the difference between standard gradient descent and natural gradient descent in terms of the space they operate in?

- Concept: Eigenvalue decomposition
  - Why needed here: Eigenvalue decomposition is used to analyze and modify the training directions in the eigenspaces of the NTK and Fisher Information Matrix.
  - Quick check question: How does modifying eigenvalues in the eigenspace decomposition affect the training dynamics?

## Architecture Onboarding

- Component map:
  - Input layer: Synthetic data generation and preprocessing
  - Model: Two-layer MLP with He initialization
  - Training algorithm: Modified NGD with eigenvalue modification
  - Evaluation: Test loss comparison between Modified NGD and standard NGD

- Critical path:
  1. Generate synthetic data and apply perturbations
  2. Initialize and train the MLP using Modified NGD
  3. Evaluate the generalization error on test data
  4. Compare results with standard NGD

- Design tradeoffs:
  - Modified NGD vs. standard NGD: Modified NGD aims to reduce generalization error but may require more computational resources for eigenvalue decomposition.
  - Perturbation level: Higher perturbation levels may lead to larger differences in generalization error but could also increase training difficulty.

- Failure signatures:
  - If the generalization error does not decrease with Modified NGD, the eigenvalue modification criterion may be incorrect or the infinite width assumption may not hold.
  - If the training process is unstable, the perturbation level may be too high or the learning rate may need adjustment.

- First 3 experiments:
  1. Train the MLP with standard NGD on unperturbed data and record the test loss.
  2. Train the MLP with Modified NGD on unperturbed data and compare the test loss with standard NGD.
  3. Train the MLP with Modified NGD on perturbed data and analyze the effect of perturbation level on generalization error.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the theoretical framework for modified NGD generalize beyond the infinite width and Gaussian assumptions used in the paper?
- Basis in paper: [explicit] The authors acknowledge that their experiments use a two-layer MLP with synthetic data due to the high dimensionality of Fisher, but claim their results can be generalized to general DNNs based on discrepancy bounds of NTK regime and general neural networks.
- Why unresolved: The paper does not provide experimental validation or theoretical proof that the framework applies to deeper networks or non-Gaussian data distributions.
- What evidence would resolve it: Experimental results showing the effectiveness of modified NGD on deeper architectures and non-Gaussian data, or a theoretical extension of the framework beyond the current assumptions.

### Open Question 2
- Question: What is the optimal criterion for modifying training directions in the eigenspaces of NTK to minimize generalization error in practice?
- Basis in paper: [explicit] The authors derive a criterion for balancing training set error and distribution discrepancy in each eigenspace, but acknowledge that this is based on the assumption of i.i.d. data and large training sets.
- Why unresolved: The criterion's effectiveness may vary depending on the specific characteristics of the data and the model, and the paper does not provide a comprehensive analysis of its performance across different scenarios.
- What evidence would resolve it: A systematic study of the criterion's performance on various datasets and model architectures, including cases where the i.i.d. assumption is violated or the training set is small.

### Open Question 3
- Question: How does the modified NGD framework relate to other generalization-enhancing methods like cross-domain generalization, self-distillation, and small batch training?
- Basis in paper: [explicit] The authors discuss how their framework can explain the efficacy of these methods by showing that they implicitly modify the eigenvalues of the Fisher Information matrix in function space.
- Why unresolved: While the paper provides a high-level explanation, it does not provide a detailed analysis of the specific mechanisms by which these methods interact with the modified NGD framework or how they can be combined for optimal performance.
- What evidence would resolve it: A rigorous analysis of the interplay between modified NGD and other generalization-enhancing methods, including experiments demonstrating their combined effects on generalization error.

## Limitations
- The infinite width assumption may not capture important finite-width effects that are crucial for practical generalization
- The method relies on precise eigenvalue decomposition, which can be numerically unstable for large networks
- No comparison with modern regularization techniques on real-world datasets
- The perturbation model used for validation may not reflect realistic data distribution shifts

## Confidence
- **High confidence**: The theoretical framework for decomposition of generalization error into training set error and distribution discrepancy components (90-95% confidence)
- **Medium confidence**: The effectiveness of eigenvalue modification in reducing generalization error (60-70% confidence), primarily due to lack of empirical validation on real data
- **Low confidence**: The proposed mechanism for explaining existing generalization-enhancing methods (40-50% confidence), as this explanation relies on implicit connections that may not hold in practice

## Next Checks
1. **Finite-width validation**: Test the eigenvalue modification approach on progressively narrower networks (starting from width 2^10 down to 2^4) to identify the minimum width threshold where the theoretical benefits disappear, documenting the degradation pattern.

2. **Real-data replication**: Apply the modified NGD algorithm to a standard image classification benchmark (CIFAR-10 or MNIST) using a two-layer MLP architecture, comparing against standard NGD and other established regularization methods.

3. **Cross-method eigenvalue analysis**: Measure the empirical eigenvalues of the Fisher Information Matrix during training across different generalization-enhancing methods (batch size variation, dropout, data augmentation) to verify if they exhibit the predicted eigenvalue modification patterns described in the theoretical framework.