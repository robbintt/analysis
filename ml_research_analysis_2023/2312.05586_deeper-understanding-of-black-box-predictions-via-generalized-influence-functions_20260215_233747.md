---
ver: rpa2
title: Deeper Understanding of Black-box Predictions via Generalized Influence Functions
arxiv_id: '2312.05586'
source_url: https://arxiv.org/abs/2312.05586
tags:
- influence
- parameters
- data
- network
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of computing influence functions
  (IFs) in large-scale, non-convex models. The authors propose generalized IFs (GIFs)
  that selectively update a subset of parameters closely associated with the analyzed
  data, while fixing the rest.
---

# Deeper Understanding of Black-box Predictions via Generalized Influence Functions

## Quick Facts
- arXiv ID: 2312.05586
- Source URL: https://arxiv.org/abs/2312.05586
- Reference count: 33
- Key outcome: Generalized influence functions selectively update 10% of parameters and achieve results comparable to full retraining for class removal and backdoor recovery tasks.

## Executive Summary
This paper addresses the challenge of computing influence functions (IFs) in large-scale, non-convex models. The authors propose generalized IFs (GIFs) that selectively update a subset of parameters closely associated with the analyzed data, while fixing the rest. GIFs use a robust inverse-Hessian-vector product approximation algorithm that guarantees convergence for any network configuration. The method outperforms existing IF approaches on tasks like class removal and backdoor model recovery. Notably, updating only 10% of the network parameters with GIFs yields results comparable to retraining from scratch. This work provides a foundational tool for model analysis and interpretability.

## Method Summary
The method trains ResNet-18 on MNIST and VGG-11 on CIFAR-10 using SGD optimizer, cross-entropy loss, batch size 256, learning rate 1e-1 with cosine annealing scheduler, and weight decay 5e-4. GIFs implement selective parameter updates by computing inverse-Hessian-vector products using Neumann series with scaled loss functions. Parameter selection uses Top-k outputs, Top-k gradients, threshold, or random criteria. The algorithm computes influence by considering gradients and Hessians only for target parameters, avoiding nuisance changes from unselected parameters.

## Key Results
- GIFs guarantee convergence for any network configuration through scale-invariant formulation
- Updating only 10% of network parameters with GIFs yields results comparable to full retraining
- GIFs outperform existing IF methods on class removal and backdoor model recovery tasks
- Selective parameter updates based on output and gradient criteria improve model utility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GIFs provide accurate parameter change estimates by selectively updating only parameters associated with the analyzed data.
- Mechanism: GIFs separate network parameters into target and fixed groups, computing influence using gradients and Hessians only for target parameters.
- Core assumption: Parameters can be meaningfully partitioned into those strongly associated with specific data and those that are not.
- Evidence anchors: [abstract], [section], [corpus: Weak]
- Break condition: If parameters are not truly separable by data association, the GIF estimate will be biased.

### Mechanism 2
- Claim: The inverse-Hessian-vector product approximation algorithm guarantees convergence for any network configuration.
- Mechanism: By scaling the loss function by a sufficiently large constant M, the spectral radius of the Neumann series matrix is forced below 1.
- Core assumption: The GIF formulation is scale-invariant, and there always exists an M large enough to ensure convergence.
- Evidence anchors: [abstract], [section], [corpus: Weak]
- Break condition: If scale-invariance property fails or Hessian computation becomes numerically unstable, convergence guarantee may not hold.

### Mechanism 3
- Claim: Selective parameter modification based on output and gradient-based criteria improves model utility.
- Mechanism: Top-k outputs and gradients criteria identify parameters most relevant to the analyzed data, leading to more targeted updates.
- Core assumption: There exists a meaningful subset of parameters that are more influential for specific data patterns.
- Evidence anchors: [abstract], [section], [corpus: Weak]
- Break condition: If parameter selection criteria fail to identify truly influential parameters, selective modification may underperform.

## Foundational Learning

- Concept: Influence Functions (IFs) measure how infinitesimal changes in training data affect model parameters and predictions.
  - Why needed here: GIFs build directly on IF theory but modify it for selective parameter updates.
  - Quick check question: In standard IF formulation, what mathematical operation approximates parameter change when a training point's loss is upweighted?

- Concept: Hessian matrix properties and inverse-Hessian-vector products (IHVP)
  - Why needed here: GIFs rely on computing (HTJ HJ)^(-1) HTJ ∇ℓ, and convergence depends on spectral properties.
  - Quick check question: Why does standard IF approximation require spectral radius of (I - Hθ) to be less than 1 for convergence?

- Concept: Parameter selection and network pruning concepts
  - Why needed here: GIFs use parameter selection criteria inspired by pruning literature.
  - Quick check question: In network pruning, what is the typical goal when removing parameters, and how might this relate to selecting parameters for influence computation?

## Architecture Onboarding

- Component map: Parameter Selection Module -> Inverse-Hessian-Vector Product Engine -> Integration Layer -> Model Parameters
- Critical path: Select parameters → Compute gradients/Hessians for selected parameters → Run Neumann series until convergence → Apply scaled influence updates
- Design tradeoffs: Selective updates reduce computation but may miss important interactions; full updates are complete but computationally expensive
- Failure signatures: Updates worsen performance (check selection criteria or scaling constant M); convergence fails (verify spectral radius condition)
- First 3 experiments:
  1. Implement GIF on small linear regression model with synthetic data, comparing to standard IF on class removal and backdoor scenarios
  2. Test parameter selection sensitivity by running GIF with different criteria (Top-k outputs vs. gradients vs. random) on simple CNN with MNIST
  3. Evaluate convergence robustness by using unscaled loss in GIF and observing divergence behavior, then applying scaling fix

## Open Questions the Paper Calls Out

- Question: What is the optimal strategy for selecting the parameter set J in generalized influence functions?
- Basis in paper: The paper discusses four selection criteria but acknowledges finding the combinatorial optimum of parameters is challenging
- Why unresolved: The paper empirically tests different criteria but lacks a theoretical framework for determining optimal parameter sets
- What evidence would resolve it: Theoretical analysis identifying key properties of optimal parameter sets or an efficient approximation algorithm with provable guarantees

- Question: How does the choice of modification ratio (MR%) affect the stability and utility of the model when using GIFs?
- Basis in paper: The paper observes that overly large MR% can deteriorate network utility, but optimal MR% depends on task and architecture
- Why unresolved: While empirical evidence shows impact, there's no theoretical understanding of why this relationship exists
- What evidence would resolve it: Comprehensive study varying MR% across tasks and architectures with theoretical insights into the relationship

## Limitations

- The parameter selection criteria (Top-k outputs/gradients) are claimed to improve utility, but the assumption that parameters can be meaningfully partitioned by data association lacks empirical validation
- The convergence guarantee through scaling depends on numerical stability in Hessian computations, which is not discussed in detail
- The claim that selective parameter updates (10%) yield results comparable to full retraining requires stronger empirical validation across diverse domains

## Confidence

- **High confidence**: GIF formulation is a valid mathematical extension of standard IFs with clear implementation advantages
- **Medium confidence**: Convergence guarantee through scaling appears sound given mathematical framework, though practical challenges are not fully explored
- **Low confidence**: Claim that selective parameter updates (10%) yield results comparable to full retraining requires stronger empirical validation

## Next Checks

1. **Empirical robustness test**: Run GIFs on multiple network architectures (MLP, CNN, Transformer) with varying dataset complexities to verify the 10% parameter update claim holds across domains.

2. **Ablation on parameter selection**: Systematically compare GIF performance using different parameter selection criteria while holding the number of updated parameters constant to isolate the selection effect.

3. **Convergence boundary analysis**: Experimentally verify the convergence guarantee by deliberately violating scale-invariance conditions and measuring spectral radius behavior of the Neumann series matrix across different network configurations.