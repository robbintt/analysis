---
ver: rpa2
title: Learning Relevant Contextual Variables Within Bayesian Optimization
arxiv_id: '2305.14120'
source_url: https://arxiv.org/abs/2305.14120
tags:
- contextual
- variables
- variable
- sadcbo
- cost
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses cost-efficient identification of relevant contextual
  variables in Contextual Bayesian Optimization (CBO), where some contextual variables
  can be optimized at a cost. The authors propose SADCBO, a method that learns contextual
  variable relevance through sensitivity analysis of the posterior surrogate model
  while minimizing optimization costs using early stopping criteria.
---

# Learning Relevant Contextual Variables Within Bayesian Optimization

## Quick Facts
- arXiv ID: 2305.14120
- Source URL: https://arxiv.org/abs/2305.14120
- Reference count: 40
- Key outcome: SADCBO achieves optimal values at lower costs by identifying relevant contextual variables through sensitivity analysis

## Executive Summary
This paper addresses the challenge of cost-efficient identification of relevant contextual variables in Contextual Bayesian Optimization (CBO), where some contextual variables can be optimized at a cost. The authors propose SADCBO, a method that learns contextual variable relevance through sensitivity analysis of the posterior surrogate model while minimizing optimization costs using early stopping criteria. The method combines observational and interventional phases to adaptively select contextual variables based on their relevance-cost trade-off. SADCBO outperforms baselines on synthetic experiments, achieving optimal values at lower costs.

## Method Summary
SADCBO combines sensitivity analysis of the posterior surrogate model with early stopping criteria to identify relevant contextual variables while minimizing optimization costs. The method operates in two phases: an observational phase where contexts are observed without intervention, and an interventional phase where selected contexts are optimized based on their relevance. Feature Collapsing (FC) measures the KL divergence between posterior distributions when a contextual variable is perturbed, providing a quantitative relevance score. The relevance score is normalized by intervention cost, and variables are selected based on this relevance-cost trade-off. The early stopping criterion determines when to switch from observation to intervention.

## Key Results
- SADCBO outperforms baselines (CUBO, CBO, VBO, SADBO, Oracle) on synthetic functions with irrelevant contextual variables
- Achieves optimal function values at lower cumulative costs compared to existing methods
- Robust to hyperparameter choices, contextual variable distributions, and varying numbers of irrelevant variables

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The sensitivity analysis of the posterior surrogate model enables identification of relevant contextual variables without requiring prior knowledge.
- Mechanism: Feature Collapsing (FC) method measures the KL divergence between posterior distributions when a contextual variable is perturbed, providing a quantitative relevance score.
- Core assumption: The posterior distribution's sensitivity to a contextual variable correlates with its impact on the objective function value.
- Evidence anchors:
  - [abstract]: "We learn the relevance of context variables by sensitivity analysis of the posterior surrogate model at specific input points"
  - [section]: "Given a dataset Dt = {(xi, zi, yi)}t i=1, the relevance r(i, j) of the ith sample of the jth contextual variable z(j) i is computed as r(i, j) = KL (p(y⋆|xi, zi, Dt) || p(y⋆|xi, zi ⊙ ξ[j], Dt))"

### Mechanism 2
- Claim: The two-phase approach (observational then interventional) optimally balances cost and information gain.
- Mechanism: Initially observes contexts without intervening to gather baseline information, then switches to intervention when the marginal benefit of additional observation diminishes.
- Core assumption: There exists a clear threshold where the information gain from observation becomes negligible compared to the cost of not intervening.
- Evidence anchors:
  - [abstract]: "The proposed SADCBO leverages recent advances in sensitivity-analysis-driven variable selection [Sebenius et al., 2022] and early stopping criteria for BO [Ishibashi et al., 2023]"
  - [section]: "We switch from the observational to the interventional phase in SADCBO when ∆Rt ≤ st, where st := (σ2 t−1(v⋆ t ) + κδ,t−1/2)σ2 t−1(vt)√−2 logδ √σnoise(σ2 t−1(vt) + σ−1 noise)"

### Mechanism 3
- Claim: Normalizing FC scores by intervention cost enables automatic trade-off between relevance and expense.
- Mechanism: Relevance score FC(j) is divided by cost λj, so variables with high sensitivity per unit cost are prioritized.
- Core assumption: The cost of intervening on a contextual variable is proportional to its impact on the objective function.
- Evidence anchors:
  - [abstract]: "we adaptively select a subset of contextual variables to include in the optimization, based on the trade-off between their relevance and the additional cost incurred by optimizing them"
  - [section]: "As there is a cost λj associated with intervening on the context variable z(j), we modify the FC relevance in Equation (4) to be FC(j)/λj, j = 1, . . . , c"

## Foundational Learning

- Concept: Gaussian Process (GP) surrogate modeling
  - Why needed here: Provides the posterior distribution over the objective function that sensitivity analysis operates on
  - Quick check question: What are the closed-form expressions for the posterior mean and variance of a GP given observed data?

- Concept: Bayesian Optimization (BO) acquisition functions
  - Why needed here: Guides the selection of design points to evaluate, balancing exploration and exploitation
  - Quick check question: How does the Upper Confidence Bound (UCB) acquisition function balance exploration and exploitation?

- Concept: Sensitivity analysis and feature importance
  - Why needed here: Identifies which contextual variables are relevant by measuring their impact on the model's predictions
  - Quick check question: What is the difference between global sensitivity analysis and local sensitivity analysis?

## Architecture Onboarding

- Component map: GP surrogate model with RBF kernel -> FC sensitivity analysis module -> Two-phase control logic -> Early stopping criterion -> Cost normalization -> Dataset management
- Critical path: Observe context -> Compute FC relevance -> Select variables -> Optimize design -> Evaluate -> Update GP -> Check early stopping -> Switch phase if needed
- Design tradeoffs:
  - Batch size Q vs. computational cost
  - Sensitivity threshold η vs. variable selection granularity
  - Early stopping sensitivity vs. premature phase transition
- Failure signatures:
  - Poor performance when irrelevant variables are selected -> Check FC computation and normalization
  - Suboptimal convergence speed -> Verify stopping criterion parameters and bounds
  - High variance in results -> Examine GP hyperparameters and kernel choice
- First 3 experiments:
  1. Run on synthetic Ackley-5D function with varying numbers of irrelevant contextual variables to verify variable selection accuracy
  2. Test early stopping criterion behavior by adjusting the cost ratio between design and contextual variables
  3. Compare performance with different kernel structures (product vs. additive) on Hartmann-6D function

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of SADCBO scale with the number of irrelevant contextual variables in high-dimensional settings?
- Basis in paper: [explicit] The paper mentions that SADCBO remains competitive even when the number of irrelevant contextual variables increases, but it doesn't provide a clear threshold or specific performance metrics for very high dimensions.
- Why unresolved: The paper provides ablation studies for varying numbers of irrelevant contextual variables but doesn't explore extremely high-dimensional cases or provide a detailed analysis of performance degradation.
- What evidence would resolve it: Experimental results showing SADCBO's performance with varying numbers of irrelevant contextual variables in extremely high-dimensional settings (e.g., >50 dimensions) would provide clarity.

### Open Question 2
- Question: How does the choice of kernel structure (product vs. additive) affect SADCBO's performance across different types of objective functions?
- Basis in paper: [explicit] The paper briefly mentions comparing product and additive kernel structures but doesn't provide a comprehensive analysis of how this choice impacts performance across various function types.
- Why unresolved: The paper only shows results for two synthetic functions and doesn't explore the kernel choice's impact on different function characteristics or complexities.
- What evidence would resolve it: Extensive experiments comparing SADCBO with both kernel structures across a diverse set of benchmark functions with varying characteristics (e.g., different smoothness, periodicity, multimodality) would clarify the impact of kernel choice.

### Open Question 3
- Question: What is the optimal value for the hyperparameter η in SADCBO, and how does it vary across different problem settings?
- Basis in paper: [explicit] The paper mentions that η is the most sensitive hyperparameter but doesn't provide guidance on how to set it optimally for different scenarios or analyze its impact across various problem settings.
- Why unresolved: The paper only shows results for a fixed η value and doesn't explore how the optimal η might change based on factors like the number of relevant/irrelevant variables, function complexity, or query costs.
- What evidence would resolve it: A systematic study of SADCBO's performance with varying η values across different problem settings (e.g., varying numbers of relevant/irrelevant variables, different function complexities) would help determine optimal η values for different scenarios.

## Limitations
- Performance on real-world problems with complex variable interactions not evaluated
- Sensitivity analysis assumes KL divergence adequately captures variable relevance, which may not hold for non-additive relationships
- Early stopping criterion implementation details from referenced paper are not fully specified

## Confidence

**High confidence**: The overall framework combining sensitivity analysis with early stopping is technically sound and well-motivated

**Medium confidence**: The empirical superiority over baselines on synthetic functions is demonstrated, but generalization to real-world problems needs validation

**Medium confidence**: The cost-benefit trade-off mechanism is theoretically justified, though the assumption that intervention costs are proportional to relevance may not always hold

## Next Checks
1. Test SADCBO on a real-world optimization problem with known contextual variable structure (e.g., hyperparameter tuning with varying data modalities) to validate practical applicability
2. Evaluate performance under varying kernel choices (Matern, Matérn-5/2) to assess robustness to kernel assumptions
3. Conduct ablation studies removing the early stopping criterion to quantify its contribution to cost reduction