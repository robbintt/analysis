---
ver: rpa2
title: Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in Chart
  Captioning
arxiv_id: '2312.10160'
source_url: https://arxiv.org/abs/2312.10160
tags:
- chart
- error
- factual
- caption
- captions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the task of Chart Caption Factual Error Correction,
  addressing the widespread issue of factual errors in chart captions generated by
  large vision-language models (LVLMs). The authors present CHOCOLATE, a novel dataset
  for this task, containing 1,187 chart-caption pairs annotated with various types
  of factual errors.
---

# Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in Chart Captioning

## Quick Facts
- arXiv ID: 2312.10160
- Source URL: https://arxiv.org/abs/2312.10160
- Authors: 
- Reference count: 40
- Key outcome: Introduces Chart Caption Factual Error Correction task with CHOCOLATE dataset, CHART VE evaluation metric, and C2TF EC correction framework, achieving superior performance over baselines including GPT-4V.

## Executive Summary
This paper addresses the critical issue of factual errors in chart captions generated by large vision-language models (LVLMs). The authors introduce the novel task of Chart Caption Factual Error Correction and present CHOCOLATE, a comprehensive dataset of 1,187 chart-caption pairs annotated with various types of factual errors. They propose C2TF EC, an interpretable two-stage framework that first converts charts into structured data tables using UniChart, then corrects errors through table-caption alignment with GPT-4. The framework significantly outperforms competitive baselines including GPT-4V, as validated through both automatic and human evaluation.

## Method Summary
The C2TF EC framework employs a two-stage approach: first, charts are converted into structured data tables using UniChart, capturing the essential numerical data and relationships. Second, GPT-4 performs caption correction by aligning the original caption with the extracted table data, identifying and rectifying factual inconsistencies. The authors also introduce CHART VE, a reference-free evaluation metric based on chart visual entailment that outperforms both proprietary and open-source LVLMs in assessing factual consistency. The CHOCOLATE dataset provides comprehensive error annotations across seven categories (Value, Label, Trend, Magnitude, Out-of-context, Nonsense, Grammatical) enabling systematic evaluation of chart caption quality.

## Key Results
- C2TF EC achieves 84.5% error detection accuracy compared to 74.5% for GPT-4V and 63.2% for LLaVA-1.5
- Human evaluation shows C2TF EC corrects significantly more errors than GPT-4V, especially Value (42.9% vs 35.7%), Label (31.4% vs 25.7%), and Trend Errors (28.6% vs 22.9%)
- CHART VE demonstrates strong correlation with human judgments (Pearson's r = 0.74) and outperforms proprietary and open-source LVLMs
- C2TF EC shows significant improvements across all error types, particularly excelling at Value Error correction (40.7% improvement over GPT-4V)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The two-stage C2TF EC framework achieves superior factual error correction by decomposing visual reasoning into chart-to-table conversion followed by text-based correction.
- Mechanism: By first extracting structured data tables from charts using UniChart, C2TF EC provides a reliable symbolic representation that grounds the subsequent GPT-4-based error correction in actual chart data rather than direct visual interpretation.
- Core assumption: Chart-to-table conversion can be performed with high fidelity, capturing the essential data points and relationships from the original chart.
- Evidence anchors:
  - [abstract] "C2TF EC first transforms the input chart into a structured data table representation. Grounded in this extracted tabular data, the second component then identifies and fixes any factual inconsistencies in the initial caption through a transparent reasoning process."
  - [section] "C2TF EC first transforms input charts into structured data tables (§4.1) and then refines captions by rectifying any discrepancies using the tabular data (4.2)."
- Break condition: If chart-to-table conversion fails to capture accurate data (e.g., complex charts, missing data points), the entire correction process becomes unreliable.

### Mechanism 2
- Claim: CHART VE's table-guided negative data generation creates a robust visual entailment model despite limited training data.
- Mechanism: By repurposing existing chart QA and captioning datasets for positive samples and generating negative samples by systematically perturbing values, trends, and context based on underlying data tables, CHART VE learns to distinguish factual consistency effectively.
- Core assumption: Underlying data tables from existing datasets accurately represent the information in the charts, enabling reliable negative sample generation.
- Evidence anchors:
  - [section] "For any given chart Ei, we utilize its source data table AEi as the basis for generating factual inconsistencies... This approach ensures c−i is relevant but factually inconsistent to the corresponding chart Ei."
  - [section] "Additionally, we synthesize out-of-context errors by pairing chart Ei with an unrelated caption sentence c+j from the pool, ensuring that c+j corresponds to a different chart, where i ≠ j."
- Break condition: If the table-guided negative generation introduces unrealistic or overly simple errors that don't reflect actual factual inconsistencies, the model's evaluation capability will be limited.

### Mechanism 3
- Claim: The error typology framework enables systematic identification and correction of chart caption errors across multiple dimensions.
- Mechanism: By defining specific error categories (Value, Label, Trend, Magnitude, Out-of-context, Nonsense, Grammatical), the framework provides clear criteria for human annotation and model training, ensuring comprehensive coverage of factual error types.
- Core assumption: The defined error categories capture all meaningful types of factual inconsistencies in chart captions.
- Evidence anchors:
  - [section] "To understand the frequency of various types of errors made by chart captioning systems, we define a typology of errors as detailed below and demonstrate examples in Table 1."
  - [section] "Our analysis reveals that even state-of-the-art models, including GPT-4V, frequently produce captions laced with factual inaccuracies."
- Break condition: If important error types are missing from the typology (e.g., temporal inconsistencies, aggregation errors), the framework will fail to capture certain types of factual errors.

## Foundational Learning

- Chart data extraction techniques
  - Why needed here: Accurate extraction of numerical data and relationships from charts is fundamental to both the C2TF EC's table conversion and CHART VE's negative sample generation.
  - Quick check question: How would you extract the exact value of a data point from a bar chart when only the visual representation is available?

- Visual entailment concepts
  - Why needed here: Understanding how to determine if a textual statement is factually consistent with a visual input is crucial for both CHART VE's evaluation and the overall error correction task.
  - Quick check question: What are the key differences between visual entailment and traditional text entailment?

- Error correction methodologies
  - Why needed here: The C2TF EC framework relies on effective error identification and correction strategies that minimize edits while maximizing factual consistency.
  - Quick check question: What metrics would you use to evaluate the quality of a factual error correction that balances accuracy with edit distance?

## Architecture Onboarding

- Component map:
  - Input chart → UniChart table extraction → GPT-4 correction → Output corrected caption
  - Input chart + caption → CHART VE evaluation → Factual consistency score

- Critical path:
  - Input chart → UniChart table extraction → GPT-4 correction → Output corrected caption
  - Input chart + caption → CHART VE evaluation → Factual consistency score

- Design tradeoffs:
  - Model size vs. performance: CHART VE is 100x smaller than LLaVA-1.5 yet outperforms it
  - End-to-end vs. two-stage: C2TF EC trades some simplicity for improved accuracy through explicit decomposition
  - Human annotation vs. automated evaluation: Balancing quality with scalability in error detection

- Failure signatures:
  - High Levenshtein distance in corrections suggests overly aggressive editing
  - CHART VE scores near 0.5 indicate inability to distinguish entailment
  - Persistent value errors despite correction suggest table extraction failures

- First 3 experiments:
  1. Test UniChart table extraction on a diverse set of chart types and compare extracted values against ground truth
  2. Evaluate CHART VE's correlation with human judgments across different error types
  3. Compare C2TF EC's correction performance against end-to-end approaches on charts with known factual errors

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How sensitive are the results to different prompt formulations when using LVLMs and LLMs for evaluation and correction?
- Basis in paper: The authors acknowledge that they did not rigorously examine prompt sensitivity, stating "we did not perform prompt tuning to craft prompts that benefit our proposed model" and "we leave the prompt sensitivity experiments for future work."
- Why unresolved: The paper focuses on comparing different models and approaches without systematically varying the prompts used. Prompt engineering can significantly impact the performance of language models, and different formulations could lead to different results.
- What evidence would resolve it: A comprehensive study varying prompt formulations while keeping all other factors constant would reveal the impact of prompt sensitivity on the performance of LVLMs and LLMs in both evaluation and correction tasks.

### Open Question 2
- Question: How well does the proposed approach generalize to other types of charts beyond line plots and bar plots?
- Basis in paper: The authors note that "most charts in the datasets we used are line plots and bar plots" and suggest that "future efforts can extend our work with additional analyses for other types of charts, such as scatter plots, violin plots, and distribution plots."
- Why unresolved: The current evaluation is limited to a specific subset of chart types. Different chart types may present unique challenges for both understanding and correcting factual errors in captions.
- What evidence would resolve it: Extending the evaluation to include a diverse range of chart types and analyzing the performance of the proposed approach across these different formats would demonstrate its generalizability and identify potential limitations.

### Open Question 3
- Question: Can the factual error correction framework be further improved by incorporating additional modalities beyond structured tables?
- Basis in paper: The current approach converts charts to structured data tables and uses this representation for correction. While effective, it may not capture all the nuances present in the original chart.
- Why unresolved: The paper focuses on a specific representation (tables) without exploring alternative or complementary modalities that could enhance the correction process. Other representations, such as direct image features or hybrid approaches, might offer advantages.
- What evidence would resolve it: Experimenting with alternative representations and comparing their performance to the table-based approach would reveal whether incorporating additional modalities can lead to improved factual error correction.

## Limitations
- The evaluation relies heavily on automatic metrics with limited extensive human validation beyond initial dataset annotation
- The UniChart table extraction model's performance on diverse chart types (e.g., complex multi-series charts, non-standard visualizations) is not extensively validated
- The table-guided negative data generation assumes source data tables accurately represent chart information, which may not hold for all chart types or data complexities

## Confidence
- **High Confidence**: The overall framework design (two-stage correction approach) and the superiority of C2TF EC over baselines are well-supported by experimental results
- **Medium Confidence**: The effectiveness of CHART VE as a reference-free evaluation metric is demonstrated, but its correlation with human judgment across all error types needs further validation
- **Medium Confidence**: The error typology comprehensively covers common factual errors, but may miss domain-specific or complex error types

## Next Checks
1. **Table Extraction Robustness**: Test UniChart's table extraction accuracy across diverse chart types (e.g., scatter plots, heatmaps, 3D charts) and compare against ground truth data to ensure reliable foundation for the correction process
2. **CHART VE Human Correlation**: Conduct a comprehensive human evaluation study comparing CHART VE scores against human judgments on factual consistency across different error types and chart complexities
3. **Error Correction Generalization**: Evaluate C2TF EC on charts with complex factual errors (e.g., multi-step calculations, trend predictions) that require deeper reasoning beyond direct data extraction