---
ver: rpa2
title: Where exactly does contextualization in a PLM happen?
arxiv_id: '2312.06514'
source_url: https://arxiv.org/abs/2312.06514
tags:
- word
- sub-layer
- bert
- sub-layers
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates where in BERT contextualization of word
  meaning occurs, using polysemous words from a custom dataset and examining sub-layers
  within each encoder layer. It measures contextualization via SubLayerSim (cosine
  similarity), WESim (distance from static embeddings), and PCA-based L2 distances.
---

# Where exactly does contextualization in a PLM happen?

## Quick Facts
- arXiv ID: 2312.06514
- Source URL: https://arxiv.org/abs/2312.06514
- Reference count: 5
- Key outcome: This study investigates where in BERT contextualization of word meaning occurs, using polysemous words from a custom dataset and examining sub-layers within each encoder layer. It measures contextualization via SubLayerSim (cosine similarity), WESim (distance from static embeddings), and PCA-based L2 distances. Results show that Self-Attention (SA) sub-layers exhibit stronger contextualization than Activation or Output sub-layers, with highest contextualization occurring between layers 5 and 9, and declining thereafter. The SA sub-layer consistently remains closer to static embeddings than Output sub-layers, suggesting residual connections influence Output representations. This demonstrates that contextualization is most pronounced in SA sub-layers and middle-to-upper encoder layers.

## Executive Summary
This paper investigates where contextualization of word meaning occurs within BERT's encoder architecture by analyzing polysemous words across different sub-layers. The authors use three complementary metrics - SubLayerSim (cosine similarity between contexts), WESim (distance from static embeddings), and PCA-based L2 distances - to measure contextualization strength across Self-Attention, Activation, and Output sub-layers. Their findings reveal that contextualization is most pronounced in the Self-Attention sub-layers, peaks between layers 5 and 9, and that residual connections cause Output sub-layers to retain more similarity to static embeddings despite showing less contextualization.

## Method Summary
The study uses the Contextualised Polysemy Word Sense v2 Dataset containing polysemous words in sentential contexts. For each word, two sentences are input to BERT, and vectors are extracted from three sub-layers (Self-Attention, Activation, Output) across all 12 encoder layers. The authors compute SubLayerSim using cosine similarity between sub-layer representations of the same word in different contexts, and WESim by measuring cosine similarity to static embeddings. PCA is applied to reduce sub-layer vectors to two principal components, and L2 distances between these components are calculated to assess contextualization. Results are compared across sub-layers and layers to identify where contextualization is strongest.

## Key Results
- Self-Attention sub-layers exhibit stronger contextualization than Activation or Output sub-layers across all encoder layers
- Highest contextualization occurs between layers 5 and 9, with declining contextualization in later layers
- Output sub-layers remain closer to static embeddings than SA sub-layers, suggesting residual connections influence Output representations
- PCA bi-plots show structural differences between sub-layers, with SA and Activation sub-layers displaying more distinct separation than Output sub-layers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contextualization occurs most strongly in the Self-Attention (SA) sub-layer, not in the Output sub-layer.
- Mechanism: SA sub-layers process attention weights and produce more context-sensitive representations early in the encoder pipeline, before residual connections and normalization in the Output sub-layer blend in less contextualized signals.
- Core assumption: The SA sub-layer's internal computations (attention score computation and weighted sum) are sufficient to induce contextual meaning without being diluted by residual pathways.
- Evidence anchors:
  - [abstract] "representations in the self-attention sub-layers exhibit stronger and earlier signs of contextualization as compared to the activation and output sub-layers"
  - [section] "we observe that the contexts of these words are strongly captured in the Self-Attention sub-layer compared to the respective Activation and Output sub-layers"
  - [corpus] Weak - no direct neighbor corpus evidence supporting this specific sub-layer claim.
- Break condition: If SA sub-layer outputs are heavily regularized or bypassed by residual/skip connections, contextualization strength would diminish, making Output sub-layer dominant.

### Mechanism 2
- Claim: Contextualization peaks in middle-to-upper encoder layers (layers 5-9) and declines in later layers.
- Mechanism: Early layers focus on surface and syntactic features; middle layers begin integrating broader context, while later layers may prioritize task-specific output formatting, reducing general contextualization.
- Core assumption: The training objective (MLM + next-sentence prediction) encourages early contextual adaptation, but later layers shift toward output stability rather than semantic flexibility.
- Evidence anchors:
  - [abstract] "highest contextualization occurring between layers 5 and 9, and declining thereafter"
  - [section] "BERT's layer-wise average SubLayerSim of all sub-layers decreases towards higher layers (lowest at layer 9)"
  - [corpus] Weak - no direct corpus neighbor confirming layer-specific contextualization peaks.
- Break condition: If later layers are fine-tuned heavily for downstream tasks, they may retain or increase contextualization beyond layer 9.

### Mechanism 3
- Claim: Residual connections cause the Output sub-layer to remain closer to static embeddings than the SA sub-layer.
- Mechanism: Residual pathways add layer 0 static embeddings back into the Output, counteracting contextual drift and anchoring representations near their static forms.
- Core assumption: Residual addition is applied after the SA transformation but before final output, so Output sub-layer vectors retain more of the original static embedding structure.
- Evidence anchors:
  - [abstract] "The SA sub-layer consistently remains closer to static embeddings than Output sub-layers, suggesting residual connections influence Output representations"
  - [section] "SA sub-layer WESim remains relatively consistent across BERT Layers where as the Output sub-layer WESim consistently decreases"
  - [corpus] Weak - no direct corpus neighbor evidence supporting residual connection influence.
- Break condition: If residual connections are modified or removed (e.g., in certain model variants), Output sub-layer similarity to static embeddings would increase, reversing the observed trend.

## Foundational Learning

- Concept: Cosine similarity as a measure of contextualization
  - Why needed here: Used to quantify how much word representations diverge between different contexts; lower similarity indicates higher contextualization.
  - Quick check question: If two instances of a polysemous word have cosine similarity close to 1.0 in a given sub-layer, what does that imply about contextualization?

- Concept: Principal Component Analysis (PCA) for visualization
  - Why needed here: Reduces high-dimensional sub-layer vectors to 2D for visual inspection of semantic divergence while preserving relative distances.
  - Quick check question: Why is it important that PCA preserves "actual relative distance in the Euclidean data space" when analyzing contextualization?

- Concept: Residual connections in transformer encoders
  - Why needed here: Explains why Output sub-layers retain more static embedding similarity despite SA sub-layers showing stronger contextualization.
  - Quick check question: In BERT's encoder, at what point in the sub-layer sequence are residual connections applied relative to the SA transformation?

## Architecture Onboarding

- Component map: BERT encoder -> Self-Attention (SA) -> Activation (Acts) -> Output -> next layer
- Critical path: Polysemous word -> feed sentence pair -> extract SA/Acts/Output vectors -> compute SubLayerSim, WESim, PCA L2 distances -> analyze layer-wise trends
- Design tradeoffs: Using only polysemous words limits generalizability; standard WSD datasets lack required format. Static embeddings used as baseline despite not being true "layer 0 outputs" in BERT architecture.
- Failure signatures: If all sub-layer similarities are high across layers, contextualization may not be occurring. If PCA shows no separation, the dataset or measures may be inadequate.
- First 3 experiments:
  1. Verify SubLayerSim trends: Compare SA vs Output sub-layer similarity for a single polysemous word across layers 1-12.
  2. Visualize PCA bi-plots: Reduce SA and Output sub-layer vectors for two contexts and check for structural differences.
  3. Test residual influence: Compare WESim for SA vs Output sub-layers to confirm Output sub-layers stay closer to static embeddings.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do residual connections in BERT's Output sub-layers significantly reduce contextualization compared to Self-Attention sub-layers?
- Basis in paper: [explicit] The paper explicitly notes that Output sub-layer WESim consistently decreases while SA sub-layer WESim remains relatively consistent, suggesting residual connections influence Output representations.
- Why unresolved: The paper identifies this pattern but does not directly test or quantify the impact of residual connections on contextualization.
- What evidence would resolve it: Experiments comparing contextualization in Output sub-layers with and without residual connections, or systematic ablation studies of residual connections across layers.

### Open Question 2
- Question: How does contextualization in BERT's middle-to-upper layers (5-9) differ from lower layers in terms of polysemy resolution mechanisms?
- Basis in paper: [explicit] The paper shows highest contextualization occurs between layers 5-9, with SA sub-layers showing stronger contextualization than other sub-layers.
- Why unresolved: The study identifies where contextualization peaks but doesn't examine what linguistic or structural mechanisms drive this difference.
- What evidence would resolve it: Analysis of attention patterns, gradient flows, or specific attention heads that contribute to polysemy resolution in these layers.

### Open Question 3
- Question: Does the structural difference in PCA bi-plots between sub-layers reflect fundamentally different encoding strategies for polysemous words?
- Basis in paper: [explicit] The paper observes that PCA bi-plots for SA, Acts, and Output sub-layers are structurally different, indicating different structural alignment in their HD spaces.
- Why unresolved: The paper notes structural differences but doesn't investigate whether these reflect distinct encoding strategies or processing stages.
- What evidence would resolve it: Comparative analysis of how specific polysemy types are encoded across sub-layers, or correlation between PCA structure and semantic clustering patterns.

## Limitations
- The study relies on a single custom dataset rather than standard WSD datasets, limiting generalizability to broader linguistic phenomena
- Static embeddings from layer 0 are used as a baseline despite not being true "layer 0 outputs" in BERT architecture, potentially affecting WESim comparisons
- No cross-model validation across different PLMs (e.g., RoBERTa, GPT) to confirm whether observed sub-layer patterns are BERT-specific or generalizable

## Confidence
- **High Confidence**: Claims about SA sub-layers showing stronger contextualization than Output sub-layers are well-supported by multiple metrics (SubLayerSim, WESim, PCA) and consistent layer-wise trends
- **Medium Confidence**: The peak contextualization in layers 5-9 is supported by data but lacks external corpus validation to confirm this pattern isn't dataset-specific
- **Low Confidence**: The residual connection mechanism explanation for Output sub-layer behavior is inferred rather than directly tested, with no ablation studies removing or modifying residuals

## Next Checks
1. Replicate the study using a standard WSD dataset (e.g., SemCor) to verify whether the 5-9 layer peak contextualization holds across different polysemy sources
2. Conduct an ablation study removing residual connections in BERT to test whether Output sub-layer similarity to static embeddings increases as predicted
3. Compare sub-layer contextualization patterns across multiple PLMs (BERT, RoBERTa, GPT-2) to determine if the SA sub-layer primacy is model-specific or universal