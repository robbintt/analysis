---
ver: rpa2
title: 'Naive Bayes Classifiers over Missing Data: Decision and Poisoning'
arxiv_id: '2303.04811'
source_url: https://arxiv.org/abs/2303.04811
tags:
- test
- dataset
- data
- possible
- point
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the certifiable robustness of Naive Bayes Classifiers
  (NBC) over dirty datasets with missing values. The authors show that for NBC, there
  exists a polynomial-time algorithm to decide whether a test point is certifiable
  robust, and an optimal polynomial-time algorithm for the data poisoning problem
  for a single test point.
---

# Naive Bayes Classifiers over Missing Data: Decision and Poisoning

## Quick Facts
- arXiv ID: 2303.04811
- Source URL: https://arxiv.org/abs/2303.04811
- Reference count: 40
- Key outcome: Polynomial-time algorithms for certifiable robustness decision and single-point data poisoning for Naive Bayes Classifiers over dirty datasets

## Executive Summary
This paper establishes the theoretical foundations for certifiable robustness of Naive Bayes Classifiers (NBC) over datasets with missing values. The authors present a polynomial-time algorithm to decide whether a test point is certifiably robust, an optimal polynomial-time algorithm for data poisoning with a single test point, and prove that data poisoning for multiple test points is NP-complete. They also develop an efficient algorithm for counting the number of possible worlds on which NBC predicts each label. Experimental results demonstrate significant speedups over baseline approaches.

## Method Summary
The paper addresses three main problems: deciding certifiable robustness, counting possible worlds, and data poisoning. For the decision problem, it computes extreme support values across all possible worlds and checks for label dominance. The counting algorithm groups possible worlds into equivalence classes (batches) and uses combinatorial formulas to count predictions per label. For data poisoning with a single test point, it iteratively applies two strategies (A1: increase target label support, A2: decrease current label support) until the prediction flips. The algorithm leverages the monotonic behavior of NBC support values and the structure of possible worlds to achieve efficiency.

## Key Results
- Polynomial-time algorithm exists for deciding certifiable robustness of test points
- Optimal polynomial-time algorithm for data poisoning with single test point
- Data poisoning for multiple test points is NP-complete for datasets with ≥3 features
- Efficient algorithm for counting possible worlds predicting each label
- Experiments show significant speedups over baseline enumeration approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The decision algorithm exploits the monotonic behavior of support values across possible worlds.
- Mechanism: NBC's prediction depends only on relative ordering of support values. The algorithm computes extreme support values (min/max over all possible worlds) for each label and checks if any label dominates all others. This works because NBC's support is a product of conditional probabilities, which vary monotonically with the number of agreeing/disagreeing datapoints in each possible world.
- Core assumption: The support function is monotonic in the count of agreeing/disagreeing feature values between training datapoints and the test point.
- Evidence anchors: [abstract] polynomial time algorithm for certifiable robustness, [section] dominance condition for robust test points
- Break condition: If NBC assumptions (feature independence, discrete features) are violated, or if the dataset contains continuous features not properly discretized.

### Mechanism 2
- Claim: Data poisoning for a single test point can be solved optimally by iteratively applying two strategies until support values flip.
- Mechanism: The algorithm alternates between two strategies: (A1) increasing support for the target label by aligning more training datapoints, and (A2) decreasing support for the current label by misaligning training datapoints. The optimal sequence is found by greedily choosing the strategy that gives the largest reduction in the difference between support values.
- Core assumption: The order of applying A1 and A2 strategies doesn't matter - only the counts of each strategy matter for achieving minimum poisoning.
- Evidence anchors: [section] polynomial time solution for single test point poisoning, [section] description of A1/A2 strategies
- Break condition: If the test point is already certifiably non-robust, or if the dataset is too small to allow the necessary support value changes.

### Mechanism 3
- Claim: Counting possible worlds that yield each label prediction can be done without enumerating all worlds by grouping them into equivalence classes.
- Mechanism: Possible worlds are partitioned into "batches" where all worlds in a batch produce the same NBC prediction. The algorithm counts the size of each batch using combinatorial formulas based on how missing values are filled, then sums over batches that predict each label.
- Core assumption: NBC predictions are invariant within each batch - all worlds with the same pattern of filled missing values produce identical predictions.
- Evidence anchors: [section] algorithm avoids explicit enumeration of every possible world, [section] lemma proving prediction invariance within batches
- Break condition: If the dataset dimension or number of labels is too large, making the batch enumeration exponential in practice.

## Foundational Learning

- Concept: Naive Bayes Classifier assumptions and support value computation
  - Why needed here: The entire certifiable robustness analysis depends on understanding how NBC computes predictions and how these depend on training data
  - Quick check question: Given a training dataset with counts N₁=10, E₁,₁=5, M₁,₁=3 for label l₁ and feature X₁, what is the maximum possible support value for label l₁ on a test point with X₁=a?

- Concept: Possible worlds and closed-world semantics
  - Why needed here: The paper's definition of certifiable robustness requires understanding how incomplete datasets generate multiple complete datasets (possible worlds)
  - Quick check question: If a dataset has 3 missing values each with domain size 2, how many possible worlds are generated?

- Concept: Polynomial time reductions and NP-completeness
  - Why needed here: The paper shows that data poisoning for multiple test points is NP-complete, requiring understanding of complexity theory reductions
  - Quick check question: What is the difference between a polynomial time reduction and a many-one reduction?

## Architecture Onboarding

- Component map: Dataset preprocessing → Count extraction (Nᵢ, Eᵢ,ⱼ, Mᵢ,ⱼ) → Decision algorithm OR Counting algorithm OR Poisoning algorithm
- Critical path: For decision problem - preprocess counts → compute extreme support values → check dominance condition. For poisoning - preprocess counts → iteratively apply A1/A2 → stop when prediction flips.
- Design tradeoffs: Decision algorithm trades space (storing counts) for time (avoiding world enumeration). Poisoning algorithm trades optimality (finding exact minimum) for efficiency by using greedy strategies.
- Failure signatures: Decision algorithm may fail if extreme support values are too close to distinguish. Poisoning algorithm may fail to find solution if dataset is too constrained. Counting algorithm may fail for high-dimensional datasets due to exponential batch enumeration.
- First 3 experiments:
  1. Decision problem on a small synthetic dataset with known certifiable robustness
  2. Poisoning problem on a dataset where minimum poisoning is known (verify optimality)
  3. Scaling experiment comparing decision algorithm with baseline enumeration as dataset size grows

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the computational complexity of #CR-NaiveBayes when the dataset dimension d is part of the input?
- Basis in paper: [explicit] The authors state: "We remark that our algorithm runs in exponential time in the dataset dimension d and the number of labels m in the dataset due to the enumeration at line 6. While m is usually small for most datasets, we leave it as an open conjecture that #CR-NaiveBayes is #P-hard when the dimension d is part of the input."
- Why unresolved: The authors have not proven whether the problem is #P-hard or if there exists a more efficient algorithm.
- What evidence would resolve it: A formal proof of either #P-hardness or a polynomial-time algorithm for #CR-NaiveBayes when d is part of the input.

### Open Question 2
- Question: How does the certifiable robustness of Naive Bayes Classifiers compare to other commonly used ML models like random forests and gradient boosted trees?
- Basis in paper: [inferred] The authors conclude by stating: "It remains open to study the certifiable robustness of other widely used ML models such as random forests and gradient boosted trees."
- Why unresolved: The authors have not studied the certifiable robustness of other ML models beyond Naive Bayes Classifiers.
- What evidence would resolve it: Empirical studies comparing the certifiable robustness of Naive Bayes Classifiers to other ML models on various datasets and tasks.

### Open Question 3
- Question: What are the design principles for efficient data cleaning systems that take into consideration the downstream ML tasks?
- Basis in paper: [inferred] The authors conclude by stating: "Finally, we envision that the insights gained from the study of certifiable robustness of different ML models would lead to more efficient data cleaning systems taking into consideration the downstream ML tasks."
- Why unresolved: The authors have not proposed specific design principles for such data cleaning systems.
- What evidence would resolve it: Development and evaluation of data cleaning systems that incorporate certifiable robustness as a key consideration and demonstrate improved efficiency compared to traditional data cleaning approaches.

## Limitations

- Exponential-time counting algorithm may not scale well to high-dimensional datasets
- Focus on discrete features only, limiting applicability to many real-world continuous feature datasets
- NP-completeness for multiple test points suggests practical limitations for multi-point poisoning scenarios

## Confidence

- Decision Algorithm (High): Well-defined polynomial-time algorithm leveraging monotonic properties of NBC support functions
- Poisoning Algorithm (Medium): Sound single-point optimal algorithm, but greedy approach may not always find global optimum
- Counting Algorithm (Medium): Theoretically sound batch-based approach but may face scalability issues

## Next Checks

1. Implement and benchmark the counting algorithm on synthetic datasets with varying dimensions and missing value ratios to identify practical scalability limits
2. Validate the decision algorithm on a real-world dataset with known dirty data to confirm practical performance gains over baseline enumeration
3. Design and run experiments comparing the greedy poisoning algorithm's results with brute-force optimal solutions on small datasets to quantify optimality gaps