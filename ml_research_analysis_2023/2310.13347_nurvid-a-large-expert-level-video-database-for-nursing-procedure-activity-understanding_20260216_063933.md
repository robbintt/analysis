---
ver: rpa2
title: 'NurViD: A Large Expert-Level Video Database for Nursing Procedure Activity
  Understanding'
arxiv_id: '2310.13347'
source_url: https://arxiv.org/abs/2310.13347
tags:
- nursing
- action
- procedure
- uni00000013
- videos
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces NurViD, a large-scale video dataset with
  expert-level annotations for nursing procedure activity understanding. The dataset
  consists of over 1.5k videos totaling 144 hours, encompassing 51 distinct nursing
  procedures and 177 action steps.
---

# NurViD: A Large Expert-Level Video Database for Nursing Procedure Activity Understanding

## Quick Facts
- arXiv ID: 2310.13347
- Source URL: https://arxiv.org/abs/2310.13347
- Reference count: 40
- Introduces NurViD, a large-scale video dataset with expert-level annotations for nursing procedure activity understanding, covering 51 procedures and 177 action steps across 1.5k videos.

## Executive Summary
This paper introduces NurViD, a large-scale video dataset with expert-level annotations for nursing procedure activity understanding. The dataset consists of over 1.5k videos totaling 144 hours, encompassing 51 distinct nursing procedures and 177 action steps. To evaluate the efficacy of current deep learning methods, three benchmarks are established on NurViD: procedure recognition on untrimmed videos, procedure and action recognition on trimmed videos, and action detection. The results show that accurately predicting procedure categories and action steps remains challenging, particularly when the dataset exhibits a long-tail distribution.

## Method Summary
The method involves creating a comprehensive video dataset for nursing procedures, annotated by medical experts according to standardized nursing guidelines. The dataset is split into training, validation, and test sets, and three benchmarks are established: procedure classification on untrimmed videos, procedure and action classification on trimmed videos, and action detection. State-of-the-art deep learning models, including SlowFast, I3D, and C3D for classification tasks, and ActionFormer, TAGS, and TriDet for action detection, are evaluated on these benchmarks to assess their performance on nursing activity understanding.

## Key Results
- NurViD dataset contains over 1.5k videos totaling 144 hours, covering 51 nursing procedures and 177 action steps.
- Models pre-trained on Kinetics 400 show improved performance on NurViD tasks, but significant room for improvement remains.
- The long-tail distribution of procedures and actions in the dataset poses a challenge for model performance, especially on underrepresented classes.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: NurViD enables training of robust models for nursing procedure recognition by providing large-scale, expert-labeled video data that captures procedural diversity and fine-grained action steps.
- Mechanism: The dataset includes 1,538 videos totaling 144 hours, covering 51 nursing procedures and 177 action steps, which are annotated following standardized nursing procedure guidelines. This breadth and depth allow models to learn diverse visual and temporal patterns associated with real-world nursing activities.
- Core assumption: The diversity and expert-level quality of the annotations are sufficient to train generalizable models for nursing procedure activity understanding.
- Evidence anchors:
  - [abstract]: "NurViD consists of over 1.5k videos totaling 144 hours, encompassing 51 distinct nursing procedures and 177 action steps."
  - [section]: "The procedure selection adheres to a widely accepted nursing taxonomy, taking into account frequency of use and expert guidance."
- Break condition: If the diversity in the dataset does not reflect real-world procedural variability or if the expert annotations contain systematic biases, model generalization will fail.

### Mechanism 2
- Claim: Transfer learning from large-scale action recognition datasets (e.g., Kinetics 400) improves performance on NurViD tasks by providing pre-trained visual feature representations.
- Mechanism: Pre-training on Kinetics 400 initializes models with rich spatiotemporal features learned from generic human actions. These features are then fine-tuned on NurViD data to specialize for nursing-specific tasks.
- Core assumption: Visual features useful for generic human actions are partially transferable to nursing actions, even though the contexts differ.
- Evidence anchors:
  - [section]: "With the C3D model, this corresponds to a per-class accuracy gain from 10.7% to 21.5% for the many category and from 5.1% to 11.3% for the medium category."
- Break condition: If the visual appearance of nursing actions is too distinct from those in Kinetics 400, the pre-trained features may not provide a useful starting point, leading to poor transfer.

### Mechanism 3
- Claim: Establishing benchmarks with varying task complexity (procedure classification, action classification, action detection) allows systematic evaluation of model capabilities on NurViD.
- Mechanism: The three benchmarks target different aspects of nursing procedure understanding: coarse-level recognition (procedures), fine-grained recognition (actions), and temporal localization (action detection). This structured evaluation helps identify specific strengths and weaknesses of models.
- Core assumption: The benchmarks are representative of practical needs in nursing education, training, and compliance monitoring.
- Evidence anchors:
  - [abstract]: "To evaluate the efficacy of current deep learning methods on nursing activity understanding, we establish three benchmarks on NurViD."
  - [section]: "In our study, we focus on three tasks using the NurViD dataset: (1) procedure classification in untrimmed videos, (2) procedure and action classification on trimmed videos, and (3) action detection on untrimmed videos."
- Break condition: If the benchmarks do not align with real-world use cases or miss critical aspects of nursing procedure understanding, the evaluation may not drive meaningful model improvements.

## Foundational Learning

- Concept: Long-tail distribution in dataset categories
  - Why needed here: The number of videos per procedure and action varies widely, affecting model performance on rare classes.
  - Quick check question: How would you modify the training process to improve performance on underrepresented classes in a long-tail distribution?

- Concept: Temporal action localization
  - Why needed here: Identifying the exact start and end times of nursing actions within longer videos is essential for detailed procedural analysis.
  - Quick check question: What challenges arise when localizing fine-grained nursing actions that involve subtle movements?

- Concept: Transfer learning in video understanding
  - Why needed here: Leveraging pre-trained models on large datasets like Kinetics 400 can provide a strong starting point for specialized nursing tasks.
  - Quick check question: Why might transfer learning from generic action datasets be beneficial for nursing procedure recognition?

## Architecture Onboarding

- Component map: Raw video -> Preprocessing (frame extraction, optical flow) -> Feature extraction (I3D, SlowFast, C3D) -> Classification/Detection heads -> Evaluation metrics
- Critical path: Raw video -> Preprocessing (frame extraction, optical flow) -> Feature extraction -> Model training/inference -> Performance evaluation
- Design tradeoffs: Balancing dataset size and diversity vs. annotation cost and quality; choosing between model complexity and computational efficiency; handling long-tail distributions vs. overall accuracy
- Failure signatures: Poor performance on rare classes; inability to localize actions accurately; models overfitting to specific video styles or environments
- First 3 experiments:
  1. Baseline experiment: Train a simple C3D model on NurViD for procedure classification on trimmed videos to establish a performance floor.
  2. Transfer learning experiment: Fine-tune an I3D model pre-trained on Kinetics 400 for action classification on trimmed videos to assess the benefit of transfer learning.
  3. Long-tail experiment: Apply class-balanced sampling or re-weighting during training to improve performance on underrepresented action classes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the long-tail distribution of nursing procedures and actions in NurViD affect the performance of deep learning models, and what specific techniques could mitigate these challenges?
- Basis in paper: [explicit] The paper explicitly mentions the long-tail distribution of procedures and actions, and notes that even models pre-trained on Kinetics 400 struggle with this challenge.
- Why unresolved: While the paper discusses the existence of the long-tail distribution and its impact on model performance, it does not provide a detailed analysis of how this distribution specifically affects different types of models or what targeted techniques (beyond general long-tail learning methods) would be most effective for this domain.
- What evidence would resolve it: Comparative experiments showing model performance on different splits (many, medium, few) with and without specific long-tail mitigation techniques (e.g., re-weighting, re-sampling, meta-learning) applied to the NurViD dataset.

### Open Question 2
- Question: What is the optimal temporal granularity for action representation in nursing procedures, and how does this granularity impact action detection accuracy?
- Basis in paper: [inferred] The paper discusses the need for "finer granularity" in representing nursing actions and mentions that nursing actions involve "precise and meticulous movements" rather than large-scale motion, but does not experimentally investigate optimal temporal granularity.
- Why unresolved: The paper identifies the need for finer granularity but does not systematically explore different temporal resolutions or provide empirical evidence for what level of granularity is optimal for nursing action detection.
- What evidence would resolve it: Experiments comparing action detection performance across different temporal resolutions (e.g., frame-level vs. second-level vs. multi-second segments) on the NurViD dataset, identifying the sweet spot for nursing procedure action detection.

### Open Question 3
- Question: How transferable are pre-trained models from general action recognition datasets (like Kinetics 400) to the specific domain of nursing procedures, and what domain adaptation techniques could improve this transfer?
- Basis in paper: [explicit] The paper mentions that transfer learning from Kinetics 400 improves classification accuracy but still results in "significant room for improvement," suggesting limitations in cross-domain transfer.
- Why unresolved: While the paper demonstrates that pre-training helps but is insufficient, it does not explore why this transfer is limited (e.g., domain shift, action specificity) or test specific domain adaptation techniques to bridge this gap.
- What evidence would resolve it: Comparative studies of different domain adaptation approaches (e.g., adversarial adaptation, self-training, few-shot adaptation) applied to NurViD, measuring improvements over direct transfer from Kinetics 400.

## Limitations

- The dataset's representativeness of real-world nursing scenarios is limited due to its collection from a single Chinese hospital, which may affect the generalizability of models trained on NurViD.
- The annotation process, while following standardized guidelines, may still contain subjective elements that could introduce bias into the dataset.
- The long-tail distribution of procedures and actions poses a challenge for model performance, particularly on underrepresented classes.

## Confidence

- **High Confidence**: The dataset's size and expert-level annotations provide a solid foundation for nursing procedure activity understanding research.
- **Medium Confidence**: The transferability of pre-trained features from generic action datasets like Kinetics 400 to nursing-specific tasks is supported by observed performance gains but may vary depending on the similarity between actions.
- **Low Confidence**: The generalizability of models trained on NurViD to diverse real-world clinical settings is uncertain due to the limited geographic and demographic scope of the dataset.

## Next Checks

1. **Diversity Assessment**: Evaluate the dataset's diversity by comparing the distribution of nursing procedures and actions in NurViD to those documented in national nursing statistics or broader clinical practice guidelines. This will help determine if the dataset captures a representative sample of real-world nursing activities.

2. **Cross-Institutional Validation**: Test the trained models on video data from different hospitals or healthcare systems to assess their performance across varied clinical environments. This will provide insights into the models' robustness and generalizability beyond the initial dataset's context.

3. **Bias Analysis**: Conduct a thorough analysis of the dataset for potential biases, such as overrepresentation of certain procedures or action steps. Implement and evaluate bias mitigation techniques, like re-weighting or data augmentation, to ensure fair and accurate model performance across all categories.