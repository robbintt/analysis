---
ver: rpa2
title: Multi-Group Fairness Evaluation via Conditional Value-at-Risk Testing
arxiv_id: '2312.03867'
source_url: https://arxiv.org/abs/2312.03867
tags:
- fairness
- cvar
- test
- samples
- sample
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of evaluating multi-group fairness
  in machine learning models, where performance disparities across population groups
  defined by multiple sensitive attributes (e.g., race and sex) are tested. The sample
  complexity for estimating the worst-case performance gap across groups increases
  exponentially with the number of group-denoting sensitive attributes.
---

# Multi-Group Fairness Evaluation via Conditional Value-at-Risk Testing

## Quick Facts
- arXiv ID: 2312.03867
- Source URL: https://arxiv.org/abs/2312.03867
- Reference count: 40
- This paper proposes using Conditional Value-at-Risk (CVaR) to reduce the sample complexity of multi-group fairness testing from exponential in the number of groups to at most the square root of the number of groups.

## Executive Summary
This paper addresses the challenge of evaluating multi-group fairness in machine learning models when performance disparities exist across population groups defined by multiple sensitive attributes. The key insight is that traditional max-gap fairness testing requires exponentially increasing samples as the number of groups grows, making it impractical for intersectional fairness evaluation. The authors propose using CVaR fairness, which allows a small probabilistic slack on groups where the model has approximately equal performance, thereby dramatically reducing the required sample complexity.

The paper provides theoretical analysis showing that CVaR fairness testing requires at most O(√|G|) samples instead of O(|G|), where |G| is the number of groups. The sample complexity depends on the Rényi entropy of order 2/3 of the group weight distribution when using weighted sampling, and can be made independent of the number of groups using attribute-specific sampling strategies. This work bridges the gap between theoretical fairness requirements and practical audit capabilities for multi-group fairness evaluation.

## Method Summary
The paper introduces a CVaR-based approach to test for multi-group fairness violations. The method defines a fairness metric F_CVaR_α(w) that captures tail behavior of performance gaps across groups, allowing probabilistic slack on groups with approximately equal performance. Algorithm 1 implements a hypothesis test comparing the CVaR fairness metric against a threshold using either weighted sampling (vg ∝ w^(2/3)) or attribute-specific sampling strategies. The weighted sampling approach achieves sample complexity O(2^(1/(2H₂/₃(w)))/ǫ²(1-α) + 2^(1/3H₂/₃(w))/ǫ⁴(1-α)²), while attribute-specific sampling can achieve group-independent sample complexity when at least 2 samples per group are available.

## Key Results
- CVaR fairness testing reduces sample complexity from O(|G|) to at most O(√|G|) by allowing probabilistic slack on groups with approximately equal performance
- Weighted sampling with group marginal distribution vg = w^(2/3) / sum(w^(2/3)) achieves sample complexity O(2^(1/(2H₂/₃(w))))
- Attribute-specific sampling achieves sample complexity independent of the number of groups when at least 2 samples per group are available
- Rényi entropy of order 2/3 of the group weight distribution w captures the sample complexity of the CVaR test algorithm

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CVaR fairness relaxes max-gap fairness to reduce sample complexity
- Mechanism: By allowing a probabilistic slack over groups, CVaR focuses only on the tail behavior of performance gaps rather than the worst-case gap across all groups. This reduces the number of groups that need to be tightly controlled
- Core assumption: The tail behavior of the fairness gap distribution captures the essential fairness concern, and a small fraction of worst-off groups can be tolerated probabilistically
- Evidence anchors:
  - [abstract] "By allowing a small probabilistic slack on the groups over which a model has approximately equal performance, we show that the sample complexity required for discovering performance violations is reduced exponentially..."
  - [section III] "we define CV aR fairness to capture the desired tail behavior"
- Break condition: If fairness requirements demand strict worst-case guarantees (no slack), this mechanism fails

### Mechanism 2
- Claim: Attribute-specific sampling achieves sample complexity independent of the number of groups
- Mechanism: By sampling data non-i.i.d. and allocating samples proportionally to group weights, the algorithm ensures each group gets sufficient representation without needing a sample per group
- Core assumption: Access to at least 2 samples from any group in the population is feasible, and non-i.i.d. sampling does not bias the estimator
- Evidence anchors:
  - [section V-A] "we can get a bound on the probability of error for the ǫ-test that is independent of w"
  - [section VI] "we prove that if we have access to 2 samples of any group g ∈ G... it is possible to use Algorithm 1 with attribute specific sampling to reliably test for CV aR fairness utilizing a number of samples (n) that is independent of the number of groups |G|"
- Break condition: If 2 samples per group cannot be obtained or if non-i.i.d. sampling introduces bias

### Mechanism 3
- Claim: Weighted sampling with group weight vector w reduces sample complexity to O(2^(1/2H2/3(w)))
- Mechanism: By choosing the group marginal distribution v proportional to w^(2/3), the variance of the estimator is minimized, leading to a sample complexity that depends on the Rényi entropy of order 2/3 of w
- Core assumption: The auditor can control the group marginal distribution in the test dataset and set vg = w^(2/3) / sum(w^(2/3))
- Evidence anchors:
  - [section V-C] "we show that the proposed Algorithm 1, with weighted sampling, can reliably test for CV aR fairness using at most n = O(2^(1/2H2/3(w))) samples..."
  - [section VI] "when the model auditor can control the choice of group marginal in the test dataset and set vg = w^(2/3) / sum(w^(2/3)), it is only necessary to have access to n samples such that n = O(2^(1/2H2/3(w)))"
- Break condition: If the auditor cannot control the group marginal distribution or if H2/3(w) is large (e.g., uniform w)

## Foundational Learning

- Concept: Conditional Value-at-Risk (CVaR)
  - Why needed here: CVaR is used to define a fairness metric that relaxes worst-case fairness by focusing on the tail of the performance gap distribution
  - Quick check question: What does CVaRα(W) measure in terms of the distribution of W?

- Concept: Rényi entropy of order 2/3
  - Why needed here: The sample complexity of the CVaR fairness test depends on the Rényi entropy of order 2/3 of the group weight distribution w
  - Quick check question: How does Rényi entropy of order 2/3 relate to the number of groups and their weights?

- Concept: Hypothesis testing for composite hypotheses
  - Why needed here: The paper uses hypothesis testing to determine if the CVaR fairness metric exceeds a threshold or is zero
  - Quick check question: What is the difference between simple and composite hypothesis testing?

## Architecture Onboarding

- Component map: Estimator for CVaR fairness -> Sampling strategies (weighted and attribute-specific) -> Algorithm 1 (CVaR Test) -> Rényi entropy calculation -> Hypothesis testing framework

- Critical path: 1. Define group weight vector w and CVaR fairness metric F_CVaRα 2. Collect audit dataset using chosen sampling strategy 3. Compute estimator ˆF(w) from the audit dataset 4. Perform threshold test comparing ˆF(w) to (1-α)ǫ²/2 5. Output hypothesis test result

- Design tradeoffs: Weighted sampling vs. attribute-specific sampling: i.i.d. vs. non-i.i.d. data collection, sample complexity vs. control over group representation. Choice of α: Trade-off between fairness guarantees and sample complexity. Choice of w: Trade-off between fairness focus and sample complexity

- Failure signatures: High variance in estimator ˆF(w) indicating insufficient samples per group. Violation of assumptions (e.g., non-i.i.d. sampling introduces bias). Choice of α too small, leading to high sample complexity

- First 3 experiments: 1. Test Algorithm 1 with weighted sampling on a synthetic dataset with known group weights and fairness violations 2. Compare sample complexity of Algorithm 1 with weighted sampling vs. attribute-specific sampling on a dataset with exponentially many groups 3. Vary α and observe the trade-off between fairness guarantees and sample complexity on a real-world fairness dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed CVaR fairness metric perform in practice compared to max-gap fairness when applied to real-world datasets with intersectional sensitive attributes?
- Basis in paper: [explicit] The paper discusses the theoretical advantages of CVaR fairness in reducing sample complexity and mentions future empirical exploration
- Why unresolved: The paper focuses on theoretical analysis and does not provide empirical results comparing CVaR fairness to max-gap fairness on real-world datasets
- What evidence would resolve it: Empirical studies comparing the performance of CVaR fairness and max-gap fairness on various real-world datasets with intersectional sensitive attributes

### Open Question 2
- Question: What are the potential risks of overlooking performance gaps for uniquely rare and unsampled groups when using CVaR fairness?
- Basis in paper: [explicit] The paper mentions that shifting from max-gap fairness to CVaR fairness could lead to overlooking performance gaps for uniquely rare and unsampled groups
- Why unresolved: The paper acknowledges this potential issue but does not provide empirical evidence or quantify the risk
- What evidence would resolve it: Empirical studies examining the performance of CVaR fairness on datasets with rare and unsampled groups, quantifying the potential risks of overlooking performance gaps

### Open Question 3
- Question: How can the theoretical guarantees for multi-group fairness notions with non-binary L (such as multicalibration) be developed?
- Basis in paper: [explicit] The paper mentions that the theoretical guarantees only hold for binary group-specific losses (L ∈ {0, 1}) and suggests developing theoretical guarantees for non-binary L as a direction for future investigation
- Why unresolved: The paper does not provide a concrete approach or methodology for extending the theoretical guarantees to non-binary L
- What evidence would resolve it: A formal extension of the theoretical framework to handle non-binary L, along with proofs of the corresponding guarantees

## Limitations

- The CVaR fairness approach requires at least 2 samples per group for the attribute-specific sampling strategy, which may be challenging for rare group combinations
- The effectiveness depends on the auditor's ability to control the group marginal distribution in the test dataset, which may not always be feasible
- The choice of group weight vector w and slack parameter α significantly impacts fairness guarantees but lacks practical guidance for real-world applications

## Confidence

- **High Confidence**: The theoretical reduction in sample complexity from O(|G|) to O(√|G|) via CVaR relaxation is well-established mathematically. The connection between Rényi entropy of order 2/3 and sample complexity is rigorously proven.
- **Medium Confidence**: The non-i.i.d. attribute-specific sampling strategy achieving group-independent sample complexity assumes 2 samples per group can be obtained and that non-i.i.d. sampling doesn't introduce bias. These assumptions require empirical validation.
- **Medium Confidence**: The practical effectiveness of CVaR fairness as a relaxation of max-gap fairness depends on the specific application context and whether allowing probabilistic slack on worst-off groups is acceptable for fairness requirements.

## Next Checks

1. **Empirical validation of attribute-specific sampling**: Test the non-i.i.d. sampling strategy on real-world datasets with rare group combinations to verify that 2 samples per group can be obtained and that the resulting estimator maintains statistical validity without introducing bias.

2. **Sensitivity analysis of w and α**: Conduct experiments varying the group weight vector w and slack parameter α across different fairness scenarios to provide practical guidelines for parameter selection and understand the trade-offs between fairness guarantees and sample complexity.

3. **Comparison with alternative fairness testing approaches**: Benchmark the CVaR fairness test against other multi-group fairness evaluation methods on datasets with exponentially many groups to quantify the practical sample complexity benefits and identify scenarios where the CVaR relaxation may be too permissive for fairness requirements.