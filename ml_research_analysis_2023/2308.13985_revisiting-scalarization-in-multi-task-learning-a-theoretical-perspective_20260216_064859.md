---
ver: rpa2
title: 'Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective'
arxiv_id: '2308.13985'
source_url: https://arxiv.org/abs/2308.13985
tags:
- scalarization
- pareto
- learning
- linear
- front
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a theoretical analysis of linear scalarization
  in multi-task learning (MTL) to understand its capability of fully exploring the
  Pareto front. The authors reveal a multi-surface structure of the feasible region
  and identify necessary and sufficient conditions for full exploration.
---

# Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective

## Quick Facts
- arXiv ID: 2308.13985
- Source URL: https://arxiv.org/abs/2308.13985
- Reference count: 40
- Key outcome: Linear scalarization in MTL cannot fully explore the Pareto front when the feasible region has a multi-surface structure, especially for balanced trade-offs.

## Executive Summary
This paper provides a theoretical analysis of linear scalarization in multi-task learning (MTL) to understand its capability of fully exploring the Pareto front. The authors reveal a multi-surface structure of the feasible region and identify necessary and sufficient conditions for full exploration. They show that linear scalarization is inherently incapable of tracing out the Pareto front, especially for balanced trade-offs between tasks, when the model is under-parameterized. The theoretical findings are corroborated by experiments on a real-world dataset, which also demonstrate the potential of specialized multi-task optimizers (SMTOs) in finding balanced solutions that cannot be achieved by scalarization.

## Method Summary
The paper studies linear MTL models with two-layer networks, where the first layer is shared across tasks and the second layer is task-specific. The authors characterize the feasible region as a union of surfaces in the non-negative orthant and identify necessary and sufficient conditions (C1 and C2) for linear scalarization to fully explore the Pareto front. They also propose a randomization-based remedy to overcome the fundamental limitation of scalarization by convexifying the feasible region. Experiments on the SARCOS dataset validate the theoretical findings by comparing linear scalarization with SMTOs (MGDA and MGDA-UB) in terms of the diversity of solutions found.

## Key Results
- Linear scalarization fails to fully explore the Pareto front when the feasible region has a multi-surface structure, especially for balanced trade-offs between tasks.
- Necessary and sufficient conditions for full exploration are the existence of doubly non-negative matrices in specific collections corresponding to the Pareto front surface.
- Randomization can counteract the fundamental limitation of scalarization by convexifying the feasible region, allowing linear scalarization to trace out the entire Pareto front.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linear scalarization fails to fully explore the Pareto front when the feasible region has a multi-surface structure.
- Mechanism: The feasible region consists of multiple surfaces in the non-negative orthant. Pareto optimal points at intersections of these surfaces cannot be reached by scalarization due to gradient disagreement - the gradients with respect to different surfaces point in different directions at intersection points.
- Core assumption: The Pareto front contains points at intersections of multiple surfaces in the feasible region.
- Evidence anchors:
  - [abstract] "scalarization is inherently incapable of full exploration, especially for those Pareto optimal solutions that strike the balanced trade-offs between multiple tasks"
  - [section] "scalarization fails to reach the intersection points of two (or more) surfaces when the gradients with respect to the two (or more) surfaces disagree"
  - [corpus] Weak - no direct mention of multi-surface structure in related papers
- Break condition: When the Pareto front lies entirely within a single surface of the feasible region.

### Mechanism 2
- Claim: The necessary and sufficient conditions for full exploration are the existence of doubly non-negative matrices in specific collections.
- Mechanism: For full exploration, there must exist a doubly non-negative matrix G* in the collection G (or Q* in Q) corresponding to the Pareto front surface. If such a matrix exists, scalarization can explore the entire Pareto front; otherwise, it cannot.
- Core assumption: The Pareto front can be characterized by surfaces whose defining matrices are either in G or Q.
- Evidence anchors:
  - [section] "we provide necessary and sufficient conditions for scalarization to fully explore the Pareto front"
  - [section] "C1 (resp. C2) is a necessary condition for scalarization to fully explore the Pareto front" and "C1 (resp. C2) is a sufficient condition"
  - [corpus] Weak - related papers don't discuss doubly non-negative matrix conditions
- Break condition: When no doubly non-negative matrix exists in the relevant collection.

### Mechanism 3
- Claim: Randomization can counteract the fundamental limitation of scalarization by convexifying the feasible region.
- Mechanism: By constructing a randomized network that outputs either f(0) or f(1) with probability t, the expected loss becomes a convex combination of the losses from both networks. This convexification allows linear scalarization to trace out the entire Pareto front.
- Core assumption: Randomization can create a convex combination of multiple network outputs that enables full exploration.
- Evidence anchors:
  - [section] "randomization allows us to 'convexify' the feasible region and thus the Pareto front will be convex"
  - [section] "by a standard application of the supporting hyperplane theorem... every point on the Pareto front can be realized via linear scalarization"
  - [corpus] Weak - no direct mention of randomization as a solution in related papers
- Break condition: When the randomization introduces too much variance or computational overhead to be practical.

## Foundational Learning

- Concept: Multi-objective optimization and Pareto optimality
  - Why needed here: The paper studies whether scalarization can explore the Pareto front in multi-task learning, which is fundamentally a multi-objective optimization problem
  - Quick check question: What is the difference between a Pareto optimal solution and a weakly Pareto optimal solution?

- Concept: Convex analysis and projection matrices
  - Why needed here: The analysis involves understanding convex sets, dual cones, and properties of projection matrices in the context of linear MTL
  - Quick check question: How does the orthogonal projection matrix PZ relate to the column space of X?

- Concept: Non-negative matrix theory and the Perron-Frobenius theorem
  - Why needed here: The paper uses properties of non-negative matrices to establish sufficient conditions for full exploration
  - Quick check question: What is the significance of a matrix being doubly non-negative in the context of this paper?

## Architecture Onboarding

- Component map:
  - Linear MTL model: Two-layer network with shared representation layer W and task-specific heads ai
  - Loss functions: MSE for each task, combined via linear scalarization
  - Feasible region analysis: Mathematical characterization of achievable MSE combinations
  - Pareto front exploration: Theoretical conditions for whether scalarization can reach all Pareto optimal points

- Critical path:
  1. Characterize the feasible region as a union of surfaces
  2. Identify necessary and sufficient conditions (C1/C2) for full exploration
  3. Validate conditions through mathematical proofs
  4. Experimentally verify theoretical findings on real dataset

- Design tradeoffs:
  - Computational complexity vs. exploration completeness: Scalarization is simple but may miss balanced solutions; SMTOs are complex but can find more solutions
  - Model capacity vs. exploration: Under-parameterized models (q < k) create multi-surface feasible regions that complicate exploration
  - Theoretical guarantees vs. practical utility: Strong theoretical conditions may be rare in practice

- Failure signatures:
  - Solutions concentrated near vertices of Pareto front rather than interior (indicates scalarization overfitting to subset of tasks)
  - Gradient disagreement at intersection points of feasible region surfaces
  - Absence of doubly non-negative matrices in collections G or Q

- First 3 experiments:
  1. Verify multi-surface structure by visualizing feasible region for simple 3-task problem
  2. Check conditions C1 and C2 on real dataset to determine if scalarization should fully explore
  3. Compare solutions from scalarization vs. SMTOs to identify balanced solutions missed by scalarization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise relationship between the multi-surface structure of the feasible region and the gradient disagreement phenomenon observed in linear scalarization?
- Basis in paper: [explicit] The paper reveals a multi-surface structure of the feasible region and identifies gradient disagreement as a failure mode of scalarization.
- Why unresolved: While the paper provides an intuitive explanation for gradient disagreement, a more rigorous mathematical analysis of the connection between the multi-surface structure and gradient disagreement is lacking.
- What evidence would resolve it: A formal mathematical proof establishing a direct link between the multi-surface structure and the occurrence of gradient disagreement in linear scalarization.

### Open Question 2
- Question: Can the theoretical findings on linear scalarization's inability to fully explore the Pareto front be extended to non-linear models beyond the two-layer linear network considered in this paper?
- Basis in paper: [inferred] The paper focuses on linear MTL models and acknowledges the limitations of its analysis, suggesting potential future work on non-linear settings.
- Why unresolved: The paper's analysis relies heavily on the specific properties of linear MTL models, and it is unclear how these findings generalize to more complex non-linear models.
- What evidence would resolve it: Theoretical analysis or empirical experiments demonstrating the presence or absence of similar limitations in non-linear MTL models.

### Open Question 3
- Question: What are the practical implications of the paper's findings for designing effective multi-task learning algorithms that can overcome the limitations of linear scalarization?
- Basis in paper: [explicit] The paper discusses the potential benefits of SMTOs in finding balanced solutions that are not achievable by scalarization.
- Why unresolved: While the paper highlights the advantages of SMTOs, it does not provide a comprehensive framework for designing SMTOs that can consistently outperform scalarization in practice.
- What evidence would resolve it: Development and evaluation of novel SMTO algorithms that leverage the insights from the paper's analysis to achieve superior performance compared to scalarization in various MTL scenarios.

## Limitations

- The theoretical analysis is limited to linear MTL models and may not directly extend to non-linear models.
- The practical frequency of encountering multi-surface structures in real-world MTL problems is unclear, which may limit the applicability of the findings.
- The randomization-based remedy for scalarization's limitations may introduce computational overhead and practical challenges in large-scale settings.

## Confidence

- Multi-surface structure and gradient disagreement: High confidence in the theoretical analysis and proofs
- Doubly non-negative matrix conditions: Medium confidence in the mathematical precision but uncertainty about practical verifiability
- Randomization as remedy: Medium confidence in theoretical soundness but uncertainty about practical feasibility

## Next Checks

1. Test whether real-world MTL datasets exhibit the multi-surface structure predicted by the theory, and quantify how often this occurs
2. Implement and benchmark the randomization-based approach on larger MTL problems to measure practical feasibility
3. Investigate alternative scalarization schemes that might better handle surface intersections without requiring randomization