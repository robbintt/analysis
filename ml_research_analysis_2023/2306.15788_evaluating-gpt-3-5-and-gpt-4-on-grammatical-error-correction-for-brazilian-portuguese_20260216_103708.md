---
ver: rpa2
title: Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correction for Brazilian
  Portuguese
arxiv_id: '2306.15788'
source_url: https://arxiv.org/abs/2306.15788
tags:
- llms
- gpt-4
- gpt-3
- grammatical
- brazilian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper compares GPT-3.5 and GPT-4 against traditional spelling
  and grammar correction tools (Microsoft Word and Google Docs) for Brazilian Portuguese.
  The authors created a dataset with four categories (Grammar, Spelling, Internet,
  and Fast typing) and evaluated the models on precision, recall, F0.5 score, and
  true negative rate.
---

# Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correction for Brazilian Portuguese

## Quick Facts
- arXiv ID: 2306.15788
- Source URL: https://arxiv.org/abs/2306.15788
- Reference count: 16
- Primary result: GPT-4 outperforms traditional spelling and grammar correction tools for Brazilian Portuguese, with higher recall but lower precision, leading to overcorrection

## Executive Summary
This paper evaluates GPT-3.5 and GPT-4 against traditional spelling and grammar correction tools (Microsoft Word and Google Docs) for Brazilian Portuguese. The authors created a dataset with four categories (Grammar, Spelling, Internet, and Fast typing) and assessed performance using precision, recall, F0.5 score, and true negative rate. While GPT-4 demonstrates higher recall than other methods, it tends to have lower precision, resulting in overcorrection. The study shows GPT-4 outperforms other methods in F0.5 score for Grammar and Spelling categories, and significantly outperforms on Internet and Fast typing categories. The research highlights the potential of LLMs as practical GEC tools for Brazilian Portuguese and encourages further exploration of LLMs for non-English languages and educational settings.

## Method Summary
The authors created a dataset of 115 phrases across four categories (Grammar, Spelling, Internet, and Fast typing) by having native Brazilian Portuguese speakers manually write sentences. They evaluated GPT-3.5 and GPT-4 using ChatGPT interface with a specific prompt, comparing results against Microsoft Word and Google Docs. Performance was measured using precision, recall, F0.5 score, and true negative rate (TNR). The evaluation focused on detecting and correcting grammatical and spelling errors, with particular attention to context-dependent errors common in informal writing and typing mistakes.

## Key Results
- GPT-4 achieves higher recall than traditional tools but has lower precision, leading to overcorrection
- GPT-4 outperforms other methods in F0.5 score for Grammar and Spelling categories
- LLMs perform significantly better than traditional methods for Internet and Fast typing categories (89.3% vs 12.5% recall)
- GPT-4 shows higher TNR than other methods, indicating better ability to recognize correct text

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4's higher recall compared to rule-based tools is due to its ability to model language from large amounts of text data, capturing a wide range of language patterns and contextual nuances.
- Mechanism: The model learns statistical patterns of correct language usage from its training corpus, allowing it to identify grammatically incorrect constructions that don't fit these learned patterns, even when they're not explicitly covered by rule-based systems.
- Core assumption: The training data contains sufficient examples of Brazilian Portuguese grammar and spelling patterns for the model to learn generalizable rules.
- Evidence anchors:
  - [abstract]: "LLMs can model language from large amounts of text data, which could lead to more natural and contextually appropriate corrections"
  - [section 5]: "One possible explanation for the higher recall of LLMs is their ability to model language from large amounts of text data, allowing them to capture a wide range of language patterns and contextual nuances"
  - [corpus]: Weak evidence for Brazilian Portuguese specifically - the corpus analysis shows related work on GEC but doesn't confirm GPT-4 was trained on substantial Brazilian Portuguese data
- Break condition: If the model wasn't trained on sufficient Brazilian Portuguese data, it cannot learn the specific grammatical patterns needed for accurate correction in this language.

### Mechanism 2
- Claim: LLMs tend to have lower precision because they prioritize fluency and coherence over grammatical accuracy, leading to unnecessary changes to text.
- Mechanism: The model's objective function likely weights fluency metrics higher than strict grammatical correctness, causing it to make changes that improve perceived fluency even when the original text was grammatically correct.
- Core assumption: The training objective and fine-tuning process prioritize overall text quality metrics over strict grammatical preservation.
- Evidence anchors:
  - [abstract]: "LLMs tend to have lower precision, leading to overcorrection"
  - [section 5]: "LLMs may have lower precision because they often prioritize fluency and coherence over grammatical accuracy, leading to unnecessary changes to the text"
  - [corpus]: No direct evidence in corpus about training objectives, but related work on GEC with LLMs shows similar precision-recall tradeoffs
- Break condition: If the model is explicitly trained or fine-tuned to prioritize precision over recall, or if it has explicit constraints against making unnecessary changes.

### Mechanism 3
- Claim: LLMs perform better on Internet and Fast typing categories because they were trained on vast amounts of text including informal language and typos, while rule-based systems lack this contextual knowledge.
- Mechanism: The model has learned patterns of informal language use and common typing errors from its training data, allowing it to recognize and correct these errors based on context rather than strict rules.
- Core assumption: The training corpus included substantial amounts of informal text, internet language, and data with typos.
- Evidence anchors:
  - [section 5]: "Traditional methods struggle with these tasks as they are strongly context-dependent, while LLMs thrive due to being trained on vast amounts of text"
  - [corpus]: No direct evidence in corpus about the composition of GPT-4's training data, but the dramatic performance difference (89.3% vs 12.5% recall) strongly suggests the model has learned these patterns
- Break condition: If the training data was heavily filtered to exclude informal language and typos, the model would perform similarly poorly on these categories.

## Foundational Learning

- Concept: Precision and Recall tradeoff
  - Why needed here: Understanding why GPT-4 has higher recall but lower precision than traditional tools is central to interpreting the results and practical implications
  - Quick check question: If a GEC tool has 90% recall and 60% precision, what percentage of its corrections are likely to be incorrect?

- Concept: False positives and false negatives in GEC
  - Why needed here: The paper defines these terms and uses them to evaluate performance; understanding them is crucial for interpreting the metrics
  - Quick check question: In GEC evaluation, would a false positive be more likely to occur when correcting grammatical errors or when checking already correct text?

- Concept: Chain-of-Thought prompting
  - Why needed here: The related work section mentions this technique for improving LLM performance on GEC tasks
  - Quick check question: How might Chain-of-Thought prompting improve an LLM's GEC performance compared to a simple instruction?

## Architecture Onboarding

- Component map: Prompt generator -> LLM inference service -> Response parsing -> Evaluation metric calculation
- Critical path: Prompt creation → LLM inference → Response parsing → Evaluation metric calculation → Result aggregation
- Design tradeoffs: Using ChatGPT interface instead of API limits control over inference parameters but simplifies implementation; batching phrases improves efficiency but may affect individual response quality; not optimizing prompts prioritizes accessibility over performance.
- Failure signatures: Low precision indicates overcorrection (making unnecessary changes); low recall indicates undercorrection (missing errors); high TNR on correct phrases indicates the model can recognize correct grammar; low TNR suggests the model tends to overcorrect even correct text.
- First 3 experiments:
  1. Test the same evaluation pipeline on a small subset of data with manually optimized prompts to establish a performance ceiling
  2. Compare results when processing phrases individually versus in batches to determine if batching affects quality
  3. Evaluate the impact of adding Chain-of-Thought prompting to see if it improves precision without sacrificing recall

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific types of grammatical errors are most challenging for GPT-4 to detect and correct in Brazilian Portuguese?
- Basis in paper: [explicit] The paper mentions that GPT-4 has higher recall than other methods but tends to have lower precision, leading to overcorrection. The qualitative analysis also identified grammatical miscorrection as a behavior where changes adhere to grammatical rules but modify the sentence's meaning.
- Why unresolved: While the paper provides general insights into the strengths and weaknesses of GPT-4, it does not specify which types of grammatical errors are most challenging for the model.
- What evidence would resolve it: A detailed error analysis categorizing the types of errors that GPT-4 struggles with would provide concrete evidence to answer this question.

### Open Question 2
- Question: How can prompt engineering be optimized to improve the performance of GPT-4 as a GEC tool for Brazilian Portuguese?
- Basis in paper: [explicit] The paper mentions that GPT-4's performance relies on the used prompts and that determining an optimal prompt may require extensive experimentation.
- Why unresolved: The paper uses a basic prompt without focusing on optimization, leaving open the question of how prompt engineering could be tailored to enhance GPT-4's GEC capabilities.
- What evidence would resolve it: Experiments comparing different prompt designs and their impact on GPT-4's GEC performance would provide insights into optimal prompt engineering strategies.

### Open Question 3
- Question: What are the potential biases and limitations of using GPT-4 for GEC in educational settings for Brazilian Portuguese?
- Basis in paper: [explicit] The paper discusses the potential of LLMs in educational settings but also mentions that LLMs may contain biases and inaccuracies, posing a challenge in ensuring that corrections do not inadvertently perpetuate harmful stereotypes or misinformation.
- Why unresolved: While the paper acknowledges the potential for bias, it does not explore the specific biases and limitations that could arise when using GPT-4 for GEC in educational contexts.
- What evidence would resolve it: Studies examining the biases in GPT-4's corrections and their impact on educational outcomes would provide concrete evidence to address this question.

## Limitations

- The evaluation relies on a small, manually created dataset of 115 phrases across four categories, which may not capture the full diversity of Brazilian Portuguese errors
- The use of ChatGPT interface rather than API for GPT-4 evaluation introduces potential variability in responses
- The paper provides no evidence that GPT-4 was trained on substantial Brazilian Portuguese data, making the mechanism behind its strong performance uncertain

## Confidence

- **High confidence**: The comparative performance metrics showing GPT-4 outperforming traditional tools on F0.5 score for Grammar and Spelling categories, and dramatically outperforming on Internet/Fast typing categories
- **Medium confidence**: The interpretation that GPT-4's higher recall stems from learning language patterns from training data, as this assumes substantial Portuguese exposure in training
- **Low confidence**: The mechanism explaining why LLMs have lower precision (prioritizing fluency over accuracy) due to lack of evidence about GPT-4's specific training objectives and fine-tuning

## Next Checks

1. Verify whether GPT-4 was trained on substantial Brazilian Portuguese data by examining OpenAI's training corpus documentation or conducting controlled experiments comparing performance across languages
2. Test the same evaluation pipeline on a larger, more diverse Brazilian Portuguese error corpus to assess whether results generalize beyond the small hand-crafted dataset
3. Conduct experiments with Chain-of-Thought prompting and prompt optimization to establish performance bounds and determine if the current results represent a lower bound due to sub-optimal prompting