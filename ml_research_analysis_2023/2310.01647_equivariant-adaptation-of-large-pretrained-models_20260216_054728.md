---
ver: rpa2
title: Equivariant Adaptation of Large Pretrained Models
arxiv_id: '2310.01647'
source_url: https://arxiv.org/abs/2310.01647
tags:
- canonicalization
- network
- function
- equivariant
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of adapting large pre-trained models
  to be equivariant to transformations like rotations. The authors propose using a
  learned canonicalization function to map inputs to a canonical form before feeding
  them to a pre-trained prediction network.
---

# Equivariant Adaptation of Large Pretrained Models

## Quick Facts
- arXiv ID: 2310.01647
- Source URL: https://arxiv.org/abs/2310.01647
- Reference count: 40
- Key outcome: Achieves 96.19% accuracy on CIFAR-10 while being equivariant to 8 rotations, compared to 93.29% for previous best method

## Executive Summary
This paper addresses the challenge of making large pre-trained models equivariant to transformations like rotations without retraining from scratch. The authors propose using a learned canonicalization function that maps inputs to a canonical form before feeding them to a pre-trained prediction network. By incorporating dataset-dependent priors that regularize the canonicalization function to align with the orientations seen in training data, they achieve both high accuracy and strong equivariance. The method is demonstrated across image classification, instance segmentation, and point cloud tasks, showing significant improvements over prior approaches.

## Method Summary
The approach works by training a separate canonicalization network that learns to transform inputs into canonical orientations before passing them to a pre-trained prediction network. A key innovation is the prior regularization loss that encourages the canonicalization function to output orientations matching the distribution seen in the original training data. This decoupling allows the prediction network to remain unchanged while the canonicalization function handles equivariance. The method can be applied to various pre-trained architectures and transformation groups (like rotations), making it a flexible solution for adapting large models to be equivariant.

## Key Results
- CIFAR-10 classification: 96.19% accuracy with 8-rotation equivariance (vs 93.29% for previous best)
- COCO instance segmentation: Significant improvements in mAP scores for rotated inputs
- ModelNet40 point cloud classification: Robust performance under rotation with minimal accuracy drop

## Why This Works (Mechanism)

### Mechanism 1
The canonicalization prior regularizes the orientation distribution of canonicalized inputs to match the training dataset's distribution. The canonicalization function outputs a distribution over group elements for each input, and the prior regularization minimizes KL divergence between this distribution and the training data's orientation distribution, ensuring that canonicalized inputs resemble the original training orientations.

### Mechanism 2
Learning canonicalization introduces data augmentation that initially helps generalization but must be reduced during training to maintain performance. The randomly initialized canonicalization function outputs random orientations at the start of training, effectively augmenting the prediction network with all group transformations. As training progresses, the canonicalization function learns to output consistent orientations, reducing the augmentation effect.

### Mechanism 3
Decoupling equivariance from the main prediction network through learned canonicalization enables adaptation of large pre-trained models without architectural modifications. The prediction network remains unchanged and unconstrained, while a separate canonicalization network learns to transform inputs to a canonical form.

## Foundational Learning

- **Concept: Group theory and equivariance**
  - Why needed here: Understanding how group actions and representations enable equivariant functions is fundamental to grasping the canonicalization approach.
  - Quick check question: What does it mean for a function f to be equivariant with respect to group G, and how is this expressed mathematically?

- **Concept: Distribution matching and KL divergence**
  - Why needed here: The prior regularization relies on minimizing KL divergence between the predicted and dataset orientation distributions.
  - Quick check question: Why does minimizing KL divergence between the canonicalization output distribution and the training data distribution help align the canonicalization function?

- **Concept: Transfer learning and fine-tuning**
  - Why needed here: The approach adapts pre-trained models through fine-tuning the canonicalization function while keeping the prediction network largely unchanged.
  - Quick check question: What are the potential challenges when fine-tuning a pre-trained model versus training from scratch, particularly regarding data distribution shifts?

## Architecture Onboarding

- **Component map**: Input → Canonicalization network → Prediction network (pre-trained) → Output layer
- **Critical path**: Input → Canonicalization function (with prior regularization) → Prediction network → Output
- **Design tradeoffs**:
  - Expressivity vs efficiency: More expressive canonicalization networks can better match orientations but increase computational cost
  - Regularization strength: The hyperparameter β controlling prior regularization must be tuned to balance alignment with performance
  - Group choice: Different groups (C8, C4, SO(3)) require different canonicalization architectures
- **Failure signatures**:
  - Large gap between accuracy and G-averaged accuracy indicates poor equivariance
  - Slow convergence or unstable training suggests misalignment between canonicalization and prediction networks
  - If prior regularization loss doesn't decrease, the canonicalization function cannot match the dataset distribution
- **First 3 experiments**:
  1. CIFAR10 classification with ResNet50 pre-trained on ImageNet, using C8 canonicalization with varying β values
  2. COCO instance segmentation with SAM, using C4 canonicalization and comparing G-CNN vs G-WRN architectures
  3. ModelNet40 point cloud classification with PointNet, testing z/SO(3) augmentation scenario with and without prior regularization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the expressivity of the canonicalization function impact the overall performance of the model?
- Basis in paper: The authors mention that using a less expressive canonicalization function leads to decreased performance on the original validation set.
- Why unresolved: The paper does not provide a detailed analysis of the relationship between the expressivity of the canonicalization function and the downstream effect on performance metrics like mAP values.

### Open Question 2
- Question: What are the optimization challenges associated with prior regularization for E(2)-Steerable Networks?
- Basis in paper: The authors mention that incorporating continuous rotations into the image framework using E(2)-Steerable Networks poses optimization challenges.
- Why unresolved: The paper does not delve into the specific challenges or provide potential solutions for optimizing prior regularization with E(2)-Steerable Networks.

### Open Question 3
- Question: How can the canonicalization function be adapted to handle a wider range of transformations beyond the ones explored in the experiments?
- Basis in paper: The authors acknowledge that the current approach is limited to a specific group of transformations and suggest that using the optimization approach of [28] could offer more flexibility.
- Why unresolved: The paper does not provide a comprehensive evaluation of the approach to other groups of transformations or explore potential methods for adapting the canonicalization function.

## Limitations

- The method requires computing dataset-dependent priors, which may not be feasible for all domains or could be computationally expensive for large datasets.
- The paper lacks extensive ablation studies on the impact of prior regularization strength β and its interaction with different prediction network architectures.
- It's unclear how well the method scales to extremely large pre-trained models (e.g., GPT-scale transformers) or how it performs on tasks requiring high-dimensional output spaces.

## Confidence

- **High confidence**: The core mechanism of using learned canonicalization with prior regularization is well-supported by both theoretical motivation and experimental results.
- **Medium confidence**: The claim that the prior regularization effectively aligns canonical orientations with training data distributions is supported by visualizations but lacks quantitative metrics.
- **Low confidence**: The paper doesn't adequately address potential failure modes when the training dataset has highly skewed orientation distributions.

## Next Checks

1. **Distribution alignment verification**: Quantify the alignment between predicted canonical orientations and the training data's orientation distribution using metrics like Wasserstein distance or maximum mean discrepancy.

2. **Prior strength sensitivity**: Systematically vary the prior regularization weight β across orders of magnitude to identify optimal values and understand the robustness of the approach.

3. **Large-scale model adaptation**: Test the method on extremely large pre-trained models (e.g., vision transformers with 100M+ parameters) to validate scalability and assess whether the approach maintains effectiveness at scale.