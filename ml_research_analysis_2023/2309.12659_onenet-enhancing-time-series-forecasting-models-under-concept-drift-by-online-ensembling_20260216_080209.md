---
ver: rpa2
title: 'OneNet: Enhancing Time Series Forecasting Models under Concept Drift by Online
  Ensembling'
arxiv_id: '2309.12659'
source_url: https://arxiv.org/abs/2309.12659
tags:
- uni00000013
- uni00000048
- online
- learning
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper proposes OneNet, an online ensemble learning framework
  for time series forecasting under concept drift. OneNet dynamically combines two
  models: one focused on temporal dependencies and another on cross-variable dependencies.'
---

# OneNet: Enhancing Time Series Forecasting Models under Concept Drift by Online Ensembling

## Quick Facts
- arXiv ID: 2309.12659
- Source URL: https://arxiv.org/abs/2309.12659
- Reference count: 40
- Reduces online forecasting error by over 50% compared to state-of-the-art method

## Executive Summary
OneNet is an online ensemble learning framework designed to improve time series forecasting under concept drift. The method dynamically combines two specialized models—one focusing on temporal dependencies and another on cross-variable dependencies—using a reinforcement learning-based approach to adaptively adjust combination weights. This addresses the slow adaptation issue common in classical online learning methods, achieving significant performance gains across challenging datasets.

## Method Summary
OneNet employs a two-stream architecture with cross-time and cross-variable forecasters trained independently to minimize their own forecasting losses. An Online Convex Programming (OCP) block combines these experts using both long-term weights (updated via Exponential Gradient Descent) and short-term weights (learned via offline reinforcement learning based on recent performance). This decoupled training approach prevents expert stagnation while enabling rapid adaptation to concept drift through the RL-based weight adjustment mechanism.

## Key Results
- Reduces online forecasting error by over 50% compared to state-of-the-art method
- Significant performance gains demonstrated on challenging datasets including ETTh2, ETTm1, WTH, and ECL
- Maintains robust performance across varying forecast horizons (H=1,24,48) and different concept drift scenarios

## Why This Works (Mechanism)

### Mechanism 1
The RL-based OCP block enables faster adaptation to concept drift than traditional EGD by incorporating short-term performance history. The OCP block maintains a long-term weight updated via EGD and a short-term weight learned via offline RL, trained to minimize forecasting error conditioned on recent expert performance. This combination allows quick response to transient changes while retaining stability.

### Mechanism 2
Decoupled training of forecasters and OCP block prevents one expert from dominating and stalling training of the other. Each forecaster is trained independently to minimize its own loss, while the OCP block is trained separately on the combined loss. This ensures both experts receive gradient updates regardless of their combination weights.

### Mechanism 3
Variable independence assumption in one expert branch improves robustness under high-dimensional concept drift. The cross-variable forecaster processes each variable independently, avoiding cross-variable interactions that can lead to overfitting and instability when the number of variables is large.

## Foundational Learning

- Concept: Online convex programming and regret minimization
  - Why needed here: The OCP block uses EGD, which is rooted in online convex programming, to maintain long-term weights and minimize regret over time
  - Quick check question: What is the regret bound for EGD with step size η = √(2 log(d)/T) after T rounds?

- Concept: Reinforcement learning through supervised learning (RvS framework)
  - Why needed here: The short-term weight in the OCP block is learned via an offline RL approach inspired by RvS, which formulates RL as supervised learning from historical prediction-outcome pairs
  - Quick check question: How does the RvS framework differ from traditional RL in terms of training data and objective?

- Concept: Concept drift in time series forecasting
  - Why needed here: The entire motivation for OneNet is to handle concept drift, where the underlying data distribution changes over time, rendering static models ineffective
  - Quick check question: What are the two main types of concept drift mentioned in the related work, and how do they differ?

## Architecture Onboarding

- Component map: Input -> Cross-time forecaster + Cross-variable forecaster -> OCP block -> Weighted combination -> Output
- Critical path: 
  1. Input time series is passed to both forecasters in parallel
  2. Forecasters generate predictions ˜y1 and ˜y2
  3. OCP block computes short-term weight b based on recent performance
  4. Final weights w are updated via EGD
  5. Combined prediction ˜y = w1 * ˜y1 + w2 * ˜y2 is generated
  6. Forecasters and OCP block are updated with ground truth y

- Design tradeoffs:
  - Two-stream architecture increases parameter count and inference time but improves robustness
  - Decoupled training prevents expert stagnation but may miss joint optimization opportunities
  - Variable independence assumption improves robustness but may ignore important cross-variable dependencies

- Failure signatures:
  - Slow adaptation to rapid concept drift: Check if short-term weight b is effectively learning from recent data
  - Overfitting to recent data: Monitor if long-term weight w is being overshadowed by short-term weight b
  - Poor performance on high-dimensional data: Verify if cross-variable forecaster is benefiting from variable independence

- First 3 experiments:
  1. Ablation study: Compare OneNet with and without the OCP block on a dataset with known concept drift
  2. Hyperparameter sensitivity: Test the impact of learning rates for long-term weight (lrw) and short-term weight (lrb) on forecasting performance
  3. Robustness test: Evaluate OneNet's performance on datasets with varying numbers of variables to assess the impact of the variable independence assumption

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed OneNet architecture perform on datasets with different types of concept drift (e.g., sudden vs. gradual drift)?
- Basis in paper: The paper mentions that OneNet addresses concept drift but does not explicitly compare performance across different drift types
- Why unresolved: The paper does not provide a detailed analysis of how OneNet performs under different concept drift scenarios
- What evidence would resolve it: Empirical results comparing OneNet's performance on datasets with known sudden vs. gradual concept drift patterns

### Open Question 2
What is the impact of the short-term weight learning component on OneNet's performance in the presence of concept drift?
- Basis in paper: The paper introduces a reinforcement learning-based approach for dynamically adjusting combination weights to address slow adaptation in classical methods
- Why unresolved: The paper does not provide a detailed ablation study or comparison of OneNet with and without the short-term weight learning component
- What evidence would resolve it: Empirical results comparing OneNet's performance with and without the short-term weight learning component under various concept drift scenarios

### Open Question 3
How does the performance of OneNet scale with the number of variables in the time series data?
- Basis in paper: The paper mentions that variable independence is crucial for model robustness under concept drift, and that cross-variable methods tend to overfit when the dataset has a large number of variables
- Why unresolved: The paper does not provide a detailed analysis of how OneNet's performance changes with varying numbers of variables in the time series data
- What evidence would resolve it: Empirical results showing OneNet's performance on datasets with varying numbers of variables, particularly focusing on the transition from small to large variable counts

## Limitations
- Offline RL component's training data generation and policy architecture are not fully specified, creating uncertainty about reproducibility
- Performance claims rely on specific hyperparameter settings (lrw, lrb, buffer sizes) that are not disclosed
- Variable independence assumption's impact on performance in domains where cross-variable dependencies are important is unclear

## Confidence
- High confidence: The decoupled training approach preventing expert stagnation is well-justified and empirically supported
- Medium confidence: The RL-based OCP block's effectiveness depends on the quality of offline RL training, which is not fully specified
- Medium confidence: The variable independence assumption improves robustness, but may hurt performance in domains where cross-variable dependencies are critical

## Next Checks
1. Ablation study on OCP block: Remove the RL component and compare performance to verify the claimed 50% error reduction comes from the full OCP mechanism
2. Hyperparameter sensitivity analysis: Systematically vary lrw, lrb, and memory buffer sizes to establish robustness of performance claims
3. Cross-variable dependency test: Evaluate OneNet on a dataset where cross-variable relationships are known to be important to assess the impact of the independence assumption