---
ver: rpa2
title: Towards Debiasing Frame Length Bias in Text-Video Retrieval via Causal Intervention
arxiv_id: '2309.09311'
source_url: https://arxiv.org/abs/2309.09311
tags:
- video
- length
- frame
- bias
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses a temporal bias in text-video retrieval caused
  by discrepancies in frame length between training and test sets. The proposed causal
  intervention method mitigates this bias by splitting the training data into subsets
  based on frame length and learning similarity matrices for each split.
---

# Towards Debiasing Frame Length Bias in Text-Video Retrieval via Causal Intervention

## Quick Facts
- **arXiv ID**: 2309.09311
- **Source URL**: https://arxiv.org/abs/2309.09311
- **Reference count**: 40
- **Primary result**: Causal intervention method mitigates frame length bias in text-video retrieval, outperforming baseline and state-of-the-art methods on Epic-Kitchens-100, YouCook2, and MSR-VTT datasets

## Executive Summary
This paper addresses a temporal bias in text-video retrieval caused by discrepancies in frame length between training and test sets. The proposed causal intervention method mitigates this bias by splitting the training data into subsets based on frame length and learning similarity matrices for each split. These matrices are then summed to create the final similarity matrix. Experiments on Epic-Kitchens-100, YouCook2, and MSR-VTT datasets show that the proposed method outperforms the baseline and state-of-the-art methods in terms of nDCG, a metric that considers semantic relevance.

## Method Summary
The proposed causal intervention method addresses frame length bias in text-video retrieval by applying backdoor adjustment to the causal graph where frame length confounds video representation and retrieval score. The approach splits training data into subsets based on frame length, trains independent similarity learners on each subset, and combines their outputs using weighted summation. This stratification blocks the backdoor path from frame length to video representation, effectively isolating semantic similarity from temporal artifacts. The method is evaluated on three benchmark datasets using both conventional metrics (Recall, mAP) and semantic relevance metrics (nDCG).

## Key Results
- Proposed causal intervention method outperforms baseline debiasing and ensemble methods on all three datasets
- nDCG improvements demonstrate better semantic relevance preservation compared to conventional metrics
- Adjusted split boundaries (matching test-set frame length distribution) show superior performance to equal splits
- Method successfully mitigates frame length bias while maintaining competitive performance on standard retrieval metrics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Splitting training data into frame-length-based subsets removes spurious correlations between frame length and video similarity.
- **Mechanism**: The causal graph shows a backdoor path L → V → Y (frame length influences video representation, which influences retrieval score). By stratifying on L during training, we block this confounding path.
- **Core assumption**: Uniformly sampled frames encode spurious temporal biases independent of true semantic content.
- **Break condition**: If frame-length groups remain correlated (high within-split variance), backdoor adjustment fails.

### Mechanism 2
- **Claim**: Summing similarity matrices learned on disjoint frame-length splits approximates E[Y | do(V,Q)].
- **Mechanism**: Each split learns f_k(V,Q) conditioned on L_k. The final similarity matrix is ∑_k P(L_k) f_k(V,Q), effectively marginalizing out frame length.
- **Core assumption**: Frame length is the sole confounder; conditioning on it is sufficient to isolate semantic similarity.
- **Break condition**: If splits overlap in frame length distribution, confounding remains.

### Mechanism 3
- **Claim**: Adjusting split boundaries to match test-set frame-length distribution improves debiasing.
- **Mechanism**: Instead of equal-sized splits, boundary selection creates more balanced within-split distributions, reducing residual bias.
- **Core assumption**: Balanced splits yield more stable similarity estimates per L_k.
- **Break condition**: If dataset is too small, balanced splits may merge distinct L regimes, harming specificity.

## Foundational Learning

- **Concept**: Structural Causal Model (SCM) and backdoor criterion
  - Why needed here: Formalises the causal relationship between frame length, video encoding, and retrieval score, justifying the stratification approach.
  - Quick check question: In the SCM, which edge must be blocked to remove the bias?

- **Concept**: Law of iterated expectations
  - Why needed here: Provides the mathematical foundation for combining split-wise similarity estimates into an unbiased overall estimate.
  - Quick check question: How does conditioning on L in the expectation formula remove confounding?

- **Concept**: Frame-length discrepancy measurement
  - Why needed here: Quantifies the bias that the method aims to mitigate; used to validate improvement via nDCG.
  - Quick check question: Why is nDCG (semantic relevance) more sensitive to debiasing than Recall?

## Architecture Onboarding

- **Component map**: Text query + video clip -> Text encoder (semantic role graph) -> Video encoder (three-level embeddings) -> Split manager (frame-length bins) -> Split trainers (independent learners) -> Aggregator (weighted sum) -> Loss (contrastive ranking)

- **Critical path**:
  1. Load and sort videos by frame length
  2. Partition into M bins (adjusted split)
  3. For each bin: Train base retrieval model on bin data, store similarity matrix
  4. At inference, sum similarity matrices weighted by bin priors

- **Design tradeoffs**:
  - More splits → finer conditioning but fewer samples per split → higher variance
  - Adjusted vs. equal splits → better bias removal vs. simpler implementation
  - Sequential vs. parallel split training → resource usage vs. wall-clock time

- **Failure signatures**:
  - No improvement in nDCG despite Recall gains → bias still present
  - Sharp drop in performance when using equal splits → residual confounding
  - Memory errors during split training → too many large bins

- **First 3 experiments**:
  1. Baseline retrieval on full dataset; record nDCG, Recall@k, mAP
  2. Apply RmvAll baseline debiasing; measure change in metrics
  3. Apply causal method with M=2 adjusted splits; compare against baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed causal intervention method compare to other debiasing techniques, such as adversarial debiasing or data augmentation, in terms of effectiveness and computational cost?
- Basis in paper: [inferred] The paper compares the proposed causal intervention method to a baseline debiasing method (RmvAll) and an ensemble method, but does not compare it to other debiasing techniques.
- Why unresolved: The paper does not provide a comprehensive comparison with other debiasing techniques, making it difficult to assess the relative effectiveness and computational cost of the proposed method.
- What evidence would resolve it: A direct comparison of the proposed causal intervention method with other debiasing techniques, such as adversarial debiasing or data augmentation, on the same datasets and evaluation metrics.

### Open Question 2
- Question: How does the choice of frame length threshold for splitting the dataset affect the performance of the proposed causal intervention method?
- Basis in paper: [explicit] The paper mentions that the threshold is chosen as the mean length of the test set, but does not explore the impact of different threshold choices.
- Why unresolved: The paper does not provide a systematic exploration of the effect of different frame length thresholds on the performance of the proposed method.
- What evidence would resolve it: An ablation study that varies the frame length threshold for splitting the dataset and evaluates the impact on the performance of the proposed method.

### Open Question 3
- Question: How does the proposed causal intervention method perform on longer video clips that may contain ambiguity and multiple actions?
- Basis in paper: [explicit] The paper acknowledges that longer video clips may contain ambiguity and multiple actions, but does not provide a detailed analysis of how the proposed method handles such cases.
- Why unresolved: The paper does not provide a comprehensive evaluation of the proposed method on longer video clips with ambiguity and multiple actions.
- What evidence would resolve it: An evaluation of the proposed method on a dataset with longer video clips that contain ambiguity and multiple actions, along with a qualitative analysis of the results.

## Limitations

- The method assumes frame length is the sole confounder, potentially overlooking other temporal dynamics that could introduce spurious correlations
- Effectiveness depends critically on achieving low within-split variance in frame length distributions, which is not explicitly quantified
- Scalability to larger frame length ranges or datasets with highly skewed temporal distributions remains unclear

## Confidence

**High Confidence**: The experimental results demonstrating nDCG improvements over baseline and state-of-the-art methods on all three datasets. The formal causal framework using backdoor adjustment is mathematically sound given the stated assumptions.

**Medium Confidence**: The claim that adjusted splits outperform equal splits is supported by ablation studies, but the optimal number of splits (M=2) is not thoroughly explored. The assumption that uniform frame sampling introduces bias is reasonable but not directly tested against alternative sampling strategies.

**Low Confidence**: The assertion that nDCG is more sensitive to debiasing than Recall metrics requires more rigorous justification. The paper shows nDCG improvements but doesn't demonstrate that Recall improvements are due to remaining bias rather than genuine semantic gains.

## Next Checks

1. **Within-Split Variance Analysis**: Measure and report the frame length variance within each split for both equal and adjusted partitioning methods. Quantify how this variance correlates with debiasing effectiveness.

2. **Alternative Confounder Testing**: Design experiments to test whether other temporal features (e.g., average shot length, action density) also act as confounders. Compare the causal intervention method against models that condition on these alternative features.

3. **Sampling Strategy Comparison**: Implement and evaluate retrieval models using different frame sampling strategies (e.g., key-frame selection, temporally diverse sampling) to determine if the bias stems specifically from uniform sampling rather than frame count itself.