---
ver: rpa2
title: 'C5: Towards Better Conversation Comprehension and Contextual Continuity for
  ChatGPT'
arxiv_id: '2308.05567'
source_url: https://arxiv.org/abs/2308.05567
tags:
- conversation
- users
- topic
- view
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: C5 addresses human forgetting and model contextual forgetting in
  multi-turn ChatGPT conversations by proposing an interactive visualization system.
  It employs a GPT-based pipeline to process conversation history into hierarchical
  topic-based text data with temporal information.
---

# C5: Towards Better Conversation Comprehension and Contextual Continuity for ChatGPT

## Quick Facts
- arXiv ID: 2308.05567
- Source URL: https://arxiv.org/abs/2308.05567
- Reference count: 40
- Key outcome: C5 improves conversation comprehension (objective scores: 8 vs 5.5, subjective scores: 8 vs 4.75) and reduces exploration time (8 minutes vs 19 minutes) while enhancing ChatGPT's contextual continuity.

## Executive Summary
C5 is an interactive visualization system designed to enhance users' comprehension of multi-turn ChatGPT conversations and improve contextual continuity for the model. It addresses two key challenges: human forgetting in long conversations and model contextual forgetting when generating responses. The system employs a GPT-based pipeline to process conversation history into hierarchical topic-based text data with temporal information, presented through three interactive views: Global View (GitLog diagram), Topic View (knowledge graph), and Context-associated Q&A View (three linked panels). A user study with 8 participants demonstrated significant improvements in conversation comprehension and reduced exploration time compared to traditional conversation interfaces.

## Method Summary
C5 processes multi-turn conversation histories by first embedding each conversation node using GPT-3.5-based text embedding, then classifying topics using GPT-3.5 Turbo to generate hierarchical topic-based text data. The system creates three interactive views: Global View uses GitLog diagram metaphor to show conversation structure and evolution; Topic View displays relationships within selected topics as a knowledge graph; and Context-associated Q&A View provides detailed exploration with three linked panels for context selection. When users pose new questions, the system searches conversation history for relevant nodes, displays them as nested circular charts, and allows users to add selected nodes to the context list, which is then sent with the question to ChatGPT to improve response quality.

## Key Results
- Conversation comprehension improved significantly (objective scores: 8 vs 5.5, subjective scores: 8 vs 4.75)
- Exploration time reduced from 19 minutes to 8 minutes
- Answer quality with context information rated higher (3.75 vs 2.75 out of 5)
- System effectively addresses both human forgetting and model contextual forgetting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-3.5 Turbo enables hierarchical topic discovery without requiring predefined topic numbers
- Core assumption: GPT-3.5 Turbo can meaningfully generate coherent topics from conversation summaries
- Evidence anchors: [abstract] topic modeling based on GPT classifies conversation histories into topics at different granularities; [section 4.1] uses GPT-3.5 Turbo to overcome limitations of traditional ML methods
- Break condition: If GPT-3.5 Turbo fails to generate coherent topics, the hierarchical structure would be meaningless

### Mechanism 2
- Claim: GitLog diagram metaphor effectively represents conversation structure and evolution
- Core assumption: Users intuitively understand conversation progression when topics are visually separated and ordered temporally
- Evidence anchors: [abstract] Global View uses GitLog diagram metaphor to present conversation structure; [section 4.2] Brush View shows temporal distribution of topics
- Break condition: If conversations frequently shift between topics, the horizontal strip metaphor may become confusing

### Mechanism 3
- Claim: Context-specific information improves ChatGPT's response quality
- Core assumption: ChatGPT's performance improves when provided with relevant historical context
- Evidence anchors: [abstract] Context-associated Q&A View enhances contextual continuity for ChatGPT; [section 5.1] BrushView highlights relevant conversation nodes
- Break condition: If ChatGPT cannot utilize provided context effectively, answer quality would not improve

## Foundational Learning

- Concept: Text embedding and vector representation
  - Why needed here: System needs to compare conversations and topics computationally
  - Quick check question: If conversation node A has embedding vector [0.2, 0.8, 0.1] and topic T has embedding [0.3, 0.7, 0.2], what would their cosine similarity indicate?

- Concept: Quadratic Assignment Problem (QAP) optimization
  - Why needed here: System needs to optimally position topics vertically to minimize visual clutter
  - Quick check question: Given 3 topics transitioning in order: Topic1→Topic2→Topic1→Topic3, what vertical arrangement would minimize total vertical movement?

- Concept: Hierarchical topic modeling
  - Why needed here: Conversations contain multiple levels of granularity - broad topics and specific subtopics
  - Quick check question: If a conversation about "machine learning" branches into "supervised learning" and "unsupervised learning," which would be the parent topic?

## Architecture Onboarding

- Component map: Data Acquisition -> Data Processing (embedding + topic classification) -> Global View -> Topic View -> Context-associated Q&A View -> Incremental Update
- Critical path: 1. User imports conversation history; 2. System processes data (embedding + topic classification); 3. Global View displays overview; 4. User selects topic → Topic View shows detailed relationships; 5. User clicks node → Context-associated Q&A View shows details and allows context selection; 6. User poses new question with context → System updates all views
- Design tradeoffs: Granularity vs. comprehensibility; Context selection automation vs. user control; Visual complexity vs. information density
- Failure signatures: Topics appear incoherent; GitLog visualization becomes unreadable; Context selection highlights irrelevant conversations; System becomes slow with large histories
- First 3 experiments: 1. Test with simple 10-turn single-topic conversation; 2. Test with conversation containing multiple distinct topics; 3. Test context selection mechanism by measuring response quality with/without context

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does C5 perform when applied to conversation data beyond ChatGPT, such as multi-party online forums or email exchanges?
- Basis in paper: [explicit] System's generalizability was considered during design for other multi-turn conversation scenarios
- Why unresolved: No empirical evidence or case studies demonstrating effectiveness on other conversation types
- What evidence would resolve it: Comparative studies showing C5's performance on forum threads and email chains versus existing tools

### Open Question 2
- Question: What is the optimal balance between user control and system automation for context selection in C5?
- Basis in paper: [inferred] System allows manual context selection but participants suggested automatic recommendations would reduce cognitive load
- Why unresolved: No exploration of different automation levels or comparison of user satisfaction across approaches
- What evidence would resolve it: User studies comparing task completion time, accuracy, and satisfaction across different automation levels

### Open Question 3
- Question: How does the quality of C5's topic modeling degrade as conversation history grows to thousands of nodes?
- Basis in paper: [explicit] Authors acknowledge large-scale data may require more efficient algorithms and scalable visualization designs
- Why unresolved: Evaluation uses only one case study with moderate conversation length
- What evidence would resolve it: Systematic testing with increasing conversation volumes (100, 1,000, 10,000 nodes) measuring accuracy and performance

## Limitations
- Small sample size (8 participants) limits generalizability across different conversation types and user populations
- Reliance on GPT-3.5 Turbo for topic classification introduces potential variability not systematically evaluated
- Context selection mechanism's performance depends on cosine similarity accuracy which may not always capture semantic relevance

## Confidence
- High Confidence: Improvements in exploration time (8 vs 19 minutes) and significant differences in comprehension scores are well-supported
- Medium Confidence: Mechanism by which context provision improves ChatGPT's response quality is supported but not fully isolated
- Low Confidence: Generalizability across different conversation domains, user expertise levels, and conversation complexities remains uncertain

## Next Checks
1. Conduct larger-scale user study (n=30+) with diverse conversation types to assess generalizability across domains
2. Implement ablation study comparing C5's performance against baseline visualization systems to isolate component contributions
3. Perform longitudinal study tracking same users across multiple sessions to evaluate whether benefits persist with repeated use