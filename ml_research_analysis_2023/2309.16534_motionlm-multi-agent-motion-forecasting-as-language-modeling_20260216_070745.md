---
ver: rpa2
title: 'MotionLM: Multi-Agent Motion Forecasting as Language Modeling'
arxiv_id: '2309.16534'
source_url: https://arxiv.org/abs/2309.16534
tags:
- joint
- agent
- prediction
- motion
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method for multi-agent motion forecasting
  using a language modeling approach. The core idea is to represent continuous trajectories
  as sequences of discrete motion tokens and train a model to predict these tokens
  autoregressively.
---

# MotionLM: Multi-Agent Motion Forecasting as Language Modeling

## Quick Facts
- arXiv ID: 2309.16534
- Source URL: https://arxiv.org/abs/2309.16534
- Reference count: 40
- Ranks 1st on the Waymo Open Motion Dataset interactive challenge leaderboard with 6% improvement in joint mAP

## Executive Summary
This paper introduces MotionLM, a novel approach to multi-agent motion forecasting that casts the problem as language modeling over discrete motion tokens. By representing continuous trajectories as sequences of discrete tokens and using an autoregressive transformer decoder, MotionLM can generate joint distributions over interactive agent futures in a single decoding process. The method achieves state-of-the-art performance on the Waymo Open Motion Dataset, particularly excelling in capturing interactive behaviors between agents.

## Method Summary
MotionLM represents continuous trajectories as sequences of discrete motion tokens through uniform quantization of axis-aligned deltas. The model consists of a scene encoder that processes heterogeneous scene features relative to each agent's frame of reference, and a trajectory decoder that generates joint rollouts through autoregressive decoding with self-attention across flattened agent-time sequences. The model is trained using teacher forcing with a maximum likelihood objective over multi-agent action sequences, and predictions are aggregated through k-means clustering of independently sampled rollouts.

## Key Results
- Establishes new state-of-the-art performance on Waymo Open Motion Dataset
- Achieves 6% improvement in ranking joint mAP metric on interactive challenge
- Joint attention model shows 38% lower overlap rates compared to marginal-then-score approaches
- Temporally causal conditioning enables more realistic agent reaction predictions

## Why This Works (Mechanism)

### Mechanism 1
Representing continuous trajectories as discrete motion tokens enables joint multi-agent trajectory forecasting via language modeling. The discrete representation preserves trajectory information while enabling efficient categorical prediction through autoregressive decoding.

### Mechanism 2
Temporally causal conditioning enables more realistic prediction of agent reactions compared to acausal conditioning. The autoregressive factorization ensures predictions respect temporal dependencies, eliminating spurious correlations from future-to-past information flow.

### Mechanism 3
Joint attention during trajectory decoding produces more consistent multi-agent predictions than marginal prediction followed by interaction scoring. Agents attend to each other's past motion tokens during decoding, allowing real-time interaction modeling rather than post-hoc scoring.

## Foundational Learning

- Language modeling and autoregressive prediction: The model treats motion forecasting as a language modeling task, predicting sequences of discrete tokens autoregressively. Quick check: What is the key difference between teacher forcing and autoregressive sampling during training and inference?

- Quantization and discrete representation: Continuous trajectories must be converted to discrete tokens for the language modeling approach to work. Quick check: How does the Verlet-wrapped action space reduce vocabulary size while maintaining trajectory accuracy?

- Attention mechanisms and self-attention: The model uses self-attention across both time and agent dimensions to capture temporal dependencies and interactions. Quick check: What is the shape of the attention mask for the flattened agent-time self-attention during training?

## Architecture Onboarding

- Component map: Scene encoder -> Trajectory decoder -> Rollout aggregation -> Ensembling

- Critical path: 1) Encode scene features for each agent 2) Generate joint rollouts through autoregressive decoding 3) Aggregate rollouts into weighted modes 4) Return top-k modes for evaluation

- Design tradeoffs:
  - Discrete vs. continuous prediction: Discrete tokens simplify training but may lose precision
  - Joint vs. marginal-then-score: Joint generation captures interactions better but is more computationally intensive
  - Interactive attention frequency: More frequent attention improves interaction modeling but increases latency

- Failure signatures:
  - High prediction overlap rates indicate scene-inconsistent predictions
  - Degraded performance on conditional rollouts suggests poor temporal modeling
  - Poor clustering in rollout aggregation suggests insufficient diversity or resolution

- First 3 experiments:
  1. Validate discrete token representation by comparing reconstruction error across different quantization resolutions
  2. Compare joint vs. marginal-then-score approaches on a simple interaction benchmark
  3. Test different interactive attention frequencies on a validation set with known interaction patterns

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of MotionLM compare to other state-of-the-art methods when evaluated on datasets other than WOMD, such as Argoverse or nuScenes? The paper only presents results on WOMD, so it is unclear how MotionLM would perform on other datasets.

### Open Question 2
What is the impact of using a different quantization scheme for the continuous trajectories on the performance of MotionLM? The paper uses a specific quantization scheme but does not explore the impact of using different quantization schemes.

### Open Question 3
How does the performance of MotionLM change when using a different number of agents for joint modeling? The paper uses a specific number of agents but does not explore the impact of using a different number of agents.

### Open Question 4
What is the impact of using a different attention mechanism, such as self-attention or cross-attention, on the performance of MotionLM? The paper uses a specific attention mechanism but does not explore the impact of using different attention mechanisms.

### Open Question 5
How does the performance of MotionLM change when using a different training objective, such as a contrastive loss or a GAN loss? The paper uses a specific training objective but does not explore the impact of using different training objectives.

## Limitations
- The method's scalability is limited by exponential growth in vocabulary size with agent count and quantization resolution
- Performance has only been validated on the Waymo Open Motion Dataset, with no extensive testing on other datasets or simulation environments
- Rollout aggregation using k-means clustering is heuristic and may miss important trajectory modes in complex scenarios

## Confidence

- Discrete token representation: Medium confidence - clear method specification but no direct comparison to continuous baselines
- Temporally causal conditioning: Medium confidence - demonstrates better causal rollout performance but lacks real-world planning validation
- Joint attention mechanism: High confidence - strong quantitative evidence with 38% lower overlap rates

## Next Checks

1. Compare MotionLM against a continuous prediction baseline using the same transformer architecture but with continuous output layers, controlling for model capacity and training procedure

2. Evaluate the model's performance in a closed-loop simulation environment where agents must react to each other's predictions in real-time

3. Test the method's robustness to different traffic densities and agent types by systematically varying these factors in the validation set and measuring degradation in prediction quality