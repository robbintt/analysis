---
ver: rpa2
title: An Investigation of Representation and Allocation Harms in Contrastive Learning
arxiv_id: '2310.01583'
source_url: https://arxiv.org/abs/2310.01583
tags:
- representation
- harm
- learning
- representations
- allocation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates representation harms in contrastive learning
  (CL), showing that underrepresentation of groups causes their representations to
  collapse with semantically similar groups. Using controlled experiments on CIFAR10
  and BIAS BIOS datasets, the authors demonstrate this phenomenon and show via causal
  mediation analysis that it leads to downstream allocation harms in classification
  tasks.
---

# An Investigation of Representation and Allocation Harms in Contrastive Learning

## Quick Facts
- **arXiv ID**: 2310.01583
- **Source URL**: https://arxiv.org/abs/2310.01583
- **Reference count**: 40
- **Key outcome**: This paper investigates representation harms in contrastive learning (CL), showing that underrepresentation of groups causes their representations to collapse with semantically similar groups. Using controlled experiments on CIFAR10 and BIAS BIOS datasets, the authors demonstrate this phenomenon and show via causal mediation analysis that it leads to downstream allocation harms in classification tasks. They also provide theoretical analysis using a stochastic block model, proving that CL representations exhibit "neural collapse" where samples from the same block converge to a single vector. The severity of representation harm depends on the degree of underrepresentation and the connectivity between groups. These findings highlight the importance of addressing representation harms in CL to mitigate downstream allocation harms.

## Executive Summary
This paper investigates representation harms in contrastive learning when groups are underrepresented, demonstrating that minority group representations collapse with semantically similar majority groups. The authors show this phenomenon experimentally using controlled imbalance on CIFAR10 and BIAS BIOS datasets, and theoretically prove it using a stochastic block model that exhibits neural collapse. Through causal mediation analysis, they establish that representation harm is partly responsible for allocation harms in downstream classification tasks. The work provides both empirical evidence and theoretical grounding for why contrastive learning can perpetuate representation harms, and suggests mitigation strategies requiring group annotations.

## Method Summary
The authors use controlled experiments on CIFAR10 by undersampling one class to 1% or 5% to create imbalance, and analyze BIAS BIOS dataset which is naturally imbalanced by occupation and gender. They train SimCLR or SimSiam with ResNet-34 backbone for CIFAR10 and SimCSE with BERT backbone for BIAS BIOS. Representations are analyzed using t-SNE visualization and cosine similarity metrics. Downstream classifiers (linear probes) are trained on top of learned representations. Causal mediation analysis decomposes the effect of underrepresentation into direct and indirect effects. Theoretical analysis uses a stochastic block model to prove neural collapse under infinite sample limits.

## Key Results
- Representation harm (RH) increases significantly when classes are undersampled to 1% or 5% in CIFAR10, with underrepresented class representations collapsing with semantically similar classes
- Gender representation harm (GRH) in BIAS BIOS shows that underrepresented gender within occupations has lower cosine distances between genders than within genders
- Causal mediation analysis reveals natural indirect effect (NIE) as the primary contributor to total effect (TE), indicating representation harm mediates allocation harm
- Theoretical analysis using stochastic block model proves neural collapse where all samples from the same block converge to the same vector as n → ∞

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Underrepresentation causes minority group representations to collapse with semantically similar majority groups.
- Mechanism: When a group is underrepresented, contrastive learning algorithms optimize representations to minimize distance between similar samples. With fewer samples from the minority group, the algorithm pulls their representations closer to the nearest majority group, causing a "collapse" effect.
- Core assumption: The semantic similarity between groups creates stronger contrastive signals than the group membership itself.
- Evidence anchors:
  - [abstract] "contrastive learning (CL), a popular variant of SSL, tends to collapse representations of minority groups with certain majority groups"
  - [section 2.1.2] "underrepresentation in class l causes its CL representation to collapse with class m"
  - [corpus] Weak evidence - corpus mentions "Multi-Group Proportional Representation for Text-to-Image Models" but doesn't directly support the specific collapse mechanism described.
- Break condition: If the algorithm includes explicit group-level regularization or if the semantic similarity between groups is weak, the collapse effect would be reduced or eliminated.

### Mechanism 2
- Claim: Representation harm mediates allocation harm through downstream classification tasks.
- Mechanism: Underrepresented groups suffer from poor representation quality in the learned space. When a linear classifier is trained on top of these representations, it cannot properly distinguish between the underrepresented group and similar majority groups, leading to misclassification (allocation harm).
- Core assumption: The quality of representations directly affects the performance of downstream classifiers trained on those representations.
- Evidence anchors:
  - [abstract] "our causal mediation analysis of allocation harm on a downstream classification task reveals that representation harm is partly responsible for it"
  - [section 4.2] "using mediation analysis, we show that it may cause allocation harm in a downstream classification"
  - [corpus] No direct evidence in corpus for this specific mediation mechanism.
- Break condition: If the downstream classifier uses different features not affected by the representation collapse, or if additional training data or techniques can compensate for the representation quality issues.

### Mechanism 3
- Claim: Neural collapse phenomenon occurs in contrastive learning with imbalanced data, causing group representations to converge to single vectors.
- Mechanism: The contrastive learning loss function, when optimized, drives representations within each group toward a single vector point (neural collapse). When combined with imbalance, this causes minority group representations to converge to similar majority group vectors rather than maintaining distinct group identities.
- Core assumption: The contrastive learning objective inherently drives representations toward collapse, and imbalance determines which groups' representations converge.
- Evidence anchors:
  - [abstract] "we provide a theoretical explanation for representation harm using a stochastic block model that leads to a representational neural collapse"
  - [section 3.2] "all samples from the same block have the same representation as n → ∞; i.e. all v⋆i's converge to their corresponding h⋆Yi"
  - [corpus] No direct evidence in corpus for this specific neural collapse mechanism.
- Break condition: If the learning algorithm includes mechanisms to prevent collapse (like different loss functions or architectural constraints) or if the dataset balance is maintained.

## Foundational Learning

- Concept: Stochastic Block Model (SBM)
  - Why needed here: SBM provides the theoretical framework for understanding how group structure and connectivity patterns affect representation learning in imbalanced settings.
  - Quick check question: How does changing the connectivity matrix in an SBM affect which groups' representations collapse together?

- Concept: Causal Mediation Analysis
  - Why needed here: This statistical technique decomposes the total effect of underrepresentation into direct effects and indirect effects mediated through representation quality.
  - Quick check question: What is the difference between natural indirect effect and reverse natural direct effect in mediation analysis?

- Concept: Neural Collapse
  - Why needed here: Understanding this phenomenon is crucial for grasping why contrastive learning with imbalance leads to group representation issues.
  - Quick check question: In what way does neural collapse differ between balanced and imbalanced datasets in contrastive learning?

## Architecture Onboarding

- Component map:
  - Data preprocessing (subsampling for controlled imbalance) -> Contrastive learning backbone (SimCLR, SimSiam, SimCSE) -> Representation analysis (tSNE visualization, cosine similarity metrics) -> Downstream classifier (linear head/probe) -> Causal mediation analysis pipeline -> Stochastic block model simulator

- Critical path:
  1. Load and preprocess dataset (balance or imbalance as needed)
  2. Train contrastive learning model
  3. Extract and analyze representations
  4. Train downstream classifier
  5. Perform causal mediation analysis
  6. Conduct theoretical analysis using SBM

- Design tradeoffs:
  - Representation quality vs. computational efficiency: Higher-dimensional representations may better capture group differences but require more computation
  - Dataset size vs. imbalance: Larger datasets may mitigate some imbalance effects but increase training time
  - Model complexity vs. interpretability: Simpler models (like linear probes) are easier to analyze but may not capture all representation nuances

- Failure signatures:
  - Representation collapse: tSNE plots show minority group representations clustering with majority groups
  - Poor downstream performance: Low accuracy on minority groups despite overall good performance
  - Mediation analysis results: Large natural indirect effect indicating representation issues drive allocation harms

- First 3 experiments:
  1. Replicate CIFAR10 controlled study: Subsample one class to 1% and compare representation and allocation harms with balanced baseline
  2. Test BCL mitigation: Apply boosted contrastive learning to CIFAR10 and measure reduction in representation and allocation harms
  3. SBM parameter sweep: Vary connectivity and group sizes in SBM to identify conditions that minimize representation collapse

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the representation harm phenomenon observed in contrastive learning generalize to other self-supervised learning methods beyond contrastive learning?
- Basis in paper: [explicit] The paper focuses on contrastive learning and its theoretical analysis, but does not investigate whether similar representation harms occur in other self-supervised learning approaches like masked autoencoders or generative models.
- Why unresolved: The theoretical analysis is specific to the contrastive loss function, and empirical studies on other SSL methods are not conducted.
- What evidence would resolve it: Empirical studies comparing representation harms across different SSL methods (masked autoencoders, generative models, etc.) on both balanced and imbalanced datasets.

### Open Question 2
- Question: How effective are the proposed mitigation strategies (reweighing the loss and connectivity surgery) in practice, and what are their computational costs?
- Basis in paper: [explicit] The paper mentions these strategies but does not implement or evaluate them empirically, deferring discussion to the last paragraph of Section 5.
- Why unresolved: The paper provides theoretical justification for these approaches but does not test them on real datasets or analyze their practical feasibility.
- What evidence would resolve it: Empirical evaluation of these mitigation strategies on multiple real-world datasets, including computational cost analysis and comparison with baseline methods.

### Open Question 3
- Question: Can the representation harms in contrastive learning be mitigated without requiring group annotations, and if so, what approaches are most promising?
- Basis in paper: [inferred] The paper acknowledges that both mitigation strategies require group annotations, which are often unavailable in real-world applications, and suggests combining proxy annotations with existing methods.
- Why unresolved: The paper identifies this as an important open problem but does not propose or evaluate specific solutions for unlabeled data.
- What evidence would resolve it: Development and evaluation of proxy-based mitigation approaches that can detect and correct representation harms without explicit group labels, tested on multiple real-world datasets.

### Open Question 4
- Question: How does the degree of semantic similarity between groups affect the severity of representation harm, and can this be quantified?
- Basis in paper: [explicit] The paper observes that underrepresented groups collapse with semantically similar majority groups, but does not quantify the relationship between semantic similarity and harm severity.
- Why unresolved: The theoretical analysis focuses on connectivity probabilities but does not establish a quantitative relationship with semantic similarity.
- What evidence would resolve it: Experiments measuring representation harm severity as a function of semantic similarity metrics (e.g., using pretrained models to quantify similarity) across multiple datasets with varying degrees of similarity between groups.

## Limitations
- The theoretical analysis assumes infinite sample limits (n → ∞) which may not reflect finite-sample practical scenarios
- The causal mediation analysis relies on assumptions about unconfoundedness that are difficult to verify empirically
- The controlled experiments use synthetic imbalance ratios (1%, 5%) that may not capture real-world data distributions

## Confidence
- High confidence: The experimental demonstration of representation collapse in controlled CIFAR10 experiments
- Medium confidence: The causal mediation analysis results showing representation harm mediates allocation harm
- Low confidence: The theoretical neural collapse guarantees under finite sample conditions

## Next Checks
1. **Finite-sample validation**: Conduct experiments on CIFAR10 with varying dataset sizes to determine how quickly the neural collapse phenomenon manifests and whether theoretical bounds hold for practical sample sizes
2. **Alternative causality tests**: Validate the mediation analysis results using different causal inference approaches (e.g., front-door adjustment, instrumental variables) to ensure robustness of the representation-to-allocation harm pathway
3. **Cross-domain replication**: Test the representation collapse phenomenon on additional datasets beyond CIFAR10 and BIAS BIOS, including multi-modal datasets, to assess generalizability of findings across domains