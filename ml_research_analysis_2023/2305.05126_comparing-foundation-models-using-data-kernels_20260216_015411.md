---
ver: rpa2
title: Comparing Foundation Models using Data Kernels
arxiv_id: '2305.05126'
source_url: https://arxiv.org/abs/2305.05126
tags:
- data
- manifold
- embedding
- foundation
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a novel methodology for comparing foundation
  models without relying on downstream evaluation metrics. The authors propose modeling
  the geometry of embedding spaces using data kernels constructed from k-nearest neighbor
  graphs of model embeddings.
---

# Comparing Foundation Models using Data Kernels

## Quick Facts
- arXiv ID: 2305.05126
- Source URL: https://arxiv.org/abs/2305.05126
- Reference count: 27
- This work introduces a novel methodology for comparing foundation models without relying on downstream evaluation metrics.

## Executive Summary
This paper proposes a novel methodology for comparing foundation models by analyzing the geometry of their embedding spaces through data kernels. The approach models embedding spaces as k-nearest neighbor graphs and uses random dot product graph theory to enable statistical comparison without requiring explicit alignment or downstream task evaluation. By constructing a model manifold via multi-dimensional scaling of aligned embeddings, the authors demonstrate that distance on this manifold correlates strongly with traditional downstream metrics. This enables sensitive detection of systematic representation differences and offers a pathway toward developing a taxonomic science of foundation models.

## Method Summary
The methodology constructs data kernels from k-nearest neighbor graphs of model embeddings, then applies omnibus embedding to jointly analyze multiple kernels without requiring orthogonal alignment. Bootstrap hypothesis testing enables pointwise comparison of representations, while multi-dimensional scaling of aligned embeddings creates a population-level model manifold. The spectral norm of differences between aligned embeddings provides a distance metric that correlates with downstream performance metrics. This approach models embeddings as random dot product graphs and leverages their geometric properties for comparison.

## Key Results
- Distance on the induced model manifold correlates strongly with downstream classification and generation metrics
- Statistical hypothesis tests enable sensitive detection of systematic representation differences
- Joint embedding via omnibus embedding eliminates the need for explicit orthogonal transformation estimation
- The methodology successfully identifies representation differences induced by training data interventions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint embedding aligns model representations by eliminating orthogonal transformation ambiguity.
- Mechanism: Omnibus embedding produces aligned estimates of latent positions from two data kernels without requiring explicit orthogonal alignment.
- Core assumption: Data kernels from equivalent models are realizations of the same Random Dot Product Graph (RDPG).
- Evidence anchors:
  - [abstract] "joint embedding of aligned embeddings" and "distance on the induced model manifold correlates strongly with several downstream metrics"
  - [section] "comparison across the data kernels A(m) and A(m′) through ˆZ (m) and ˆZ (m′) does not require estimation of an orthogonal transformation R"
- Break condition: If the underlying graph model deviates significantly from RDPG assumptions (e.g., non-Euclidean geometry or directed edges).

### Mechanism 2
- Claim: Model manifold distance captures functional similarity between foundation models.
- Mechanism: Spectral norm of differences between aligned embeddings provides a distance metric on model representations.
- Core assumption: Euclidean distance between aligned embeddings approximates model similarity in a low-dimensional manifold.
- Evidence anchors:
  - [abstract] "induce a manifold of models equipped with a distance function that correlates strongly with several downstream metrics"
  - [section] "the spectral norm of the differences between aligned embeddings... is Euclidean realizable under certain conditions on V"
- Break condition: When model differences are not captured by the RDPG embedding structure (e.g., models with fundamentally different architectures).

### Mechanism 3
- Claim: Bootstrap hypothesis test enables valid pointwise comparison of model representations.
- Mechanism: Bootstrap procedure estimates null distribution of distance between aligned embeddings, enabling p-value calculation for each datum.
- Core assumption: The bootstrap procedure accurately captures the null distribution under the RDPG model.
- Evidence anchors:
  - [abstract] "statistical hypothesis tests for pointwise comparison of representations"
  - [section] "propose estimating the null distribution of the distance di via a bootstrap procedure for networks with latent space structure"
- Break condition: When bootstrap assumptions fail (e.g., small sample sizes or non-stationary data).

## Foundational Learning

- Concept: Random Dot Product Graphs (RDPG)
  - Why needed here: Provides theoretical foundation for modeling data kernels as graphs with interpretable geometry
  - Quick check question: What property of RDPGs ensures that the dot product of latent positions equals edge probability?

- Concept: Omnibus embedding
  - Why needed here: Enables joint embedding of multiple data kernels without requiring orthogonal alignment
  - Quick check question: How does the omnibus embedding matrix combine two data kernels to preserve both while enabling comparison?

- Concept: Multi-dimensional scaling (MDS)
  - Why needed here: Transforms pairwise distances into a geometric model manifold representation
  - Quick check question: What condition must be satisfied for MDS to recover true relative positions from a distance matrix?

## Architecture Onboarding

- Component map: Data kernel construction → Omnibus embedding → Bootstrap hypothesis testing → MDS manifold embedding
- Critical path: Data kernel → Joint embedding → Distance calculation → Manifold construction
- Design tradeoffs: k-nearest neighbors parameter vs. computational cost and sensitivity; bootstrap iterations vs. statistical power
- Failure signatures: Uniform p-value distribution under H0 indicates test validity; non-uniform distribution suggests model mismatch
- First 3 experiments:
  1. Construct data kernels from two identical models and verify uniform p-value distribution
  2. Compare models with known differences and visualize aligned embeddings
  3. Build model manifold from multiple variants and correlate distances with downstream metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the model manifold induced by data kernels capture the full complexity of foundation model differences, including architectural variations and training objectives?
- Basis in paper: [explicit] The paper demonstrates that the model manifold captures differences induced by training data interventions, but does not test architectural or objective variations
- Why unresolved: The current experiments only compare models trained with the same architecture (BERT) on different datasets. Testing architectural variations would require comparing fundamentally different model types
- What evidence would resolve it: Extending the methodology to compare models with different architectures (e.g., BERT vs GPT vs CLIP) and training objectives, then validating if manifold distances correlate with established benchmarks across these architectural differences

### Open Question 2
- Question: What is the theoretical relationship between the dimensionality of the model manifold and the true underlying parameter space of foundation models?
- Basis in paper: [inferred] The paper observes empirically that a 2D manifold suffices for models varying only in training data composition, but the theoretical relationship remains unexplored
- Why unresolved: The paper relies on empirical observations without establishing theoretical bounds on manifold dimensionality or conditions under which the manifold assumption holds
- What evidence would resolve it: Mathematical proofs establishing when and why foundation model differences can be embedded in low-dimensional spaces, along with experiments testing manifold dimensionality across diverse model collections

### Open Question 3
- Question: How does the choice of k in the k-nearest neighbor graph construction affect the sensitivity and specificity of model comparisons?
- Basis in paper: [explicit] The methodology requires choosing k for data kernel construction, but the paper does not systematically explore the effects of this hyperparameter
- Why unresolved: The experiments use fixed values of k (64 for classification, 16 for generation) without analyzing how different values impact comparison results
- What evidence would resolve it: Systematic experiments varying k across multiple orders of magnitude, analyzing how it affects hypothesis test power, manifold structure, and correlation with downstream metrics

### Open Question 4
- Question: Can the data kernel methodology be extended to enable efficient federated learning of foundation models while preserving privacy?
- Basis in paper: [explicit] The paper suggests a privacy-aware application where only embeddings are shared, but does not implement or evaluate this approach
- Why unresolved: The paper mentions the possibility but does not address practical challenges like communication efficiency, model convergence, or security guarantees
- What evidence would resolve it: Implementation of federated learning protocols using data kernels, evaluation of communication costs, convergence rates, and formal privacy analysis under different threat models

### Open Question 5
- Question: What is the relationship between distance on the model manifold and practical model selection criteria like computational efficiency or energy consumption?
- Basis in paper: [inferred] The paper correlates manifold distance with task performance but does not consider resource efficiency metrics
- Why unresolved: Current experiments focus on task accuracy while ignoring the practical constraints that often drive model selection in real-world applications
- What evidence would resolve it: Experiments measuring computational and energy costs across models positioned on the manifold, then analyzing correlations between manifold distance and resource efficiency to determine if proximity implies similar efficiency characteristics

## Limitations
- The approach relies heavily on the random dot product graph assumption, which may not hold for all foundation model architectures
- Computational complexity scales poorly with dataset size and model count, potentially limiting practical application
- The method requires access to raw embeddings rather than just outputs, creating a barrier for black-box model comparison
- The choice of k-nearest neighbor parameter is critical but not fully characterized in the paper

## Confidence

**High Confidence**: The geometric intuition linking embedding space distances to model similarity is well-grounded in network analysis literature. The omnibus embedding procedure and its properties are well-established in the RDPG framework.

**Medium Confidence**: The bootstrap hypothesis testing approach is sound in principle, but the specific implementation details and parameter choices may require tuning for different model families. The correlation between manifold distance and downstream metrics is demonstrated empirically but lacks theoretical guarantees.

**Low Confidence**: The extension to multi-dimensional scaling for population-level comparison assumes Euclidean realizability of the model manifold, which may not hold for models with fundamentally different architectural principles.

## Next Checks

1. **Null Distribution Verification**: Apply the methodology to embeddings from identical models (same architecture, weights, and training data) and verify that p-values follow a uniform distribution, confirming proper calibration of the hypothesis test.

2. **Architectural Transferability**: Test the method across fundamentally different model architectures (e.g., transformer vs. recurrent networks) to assess whether the RDPG assumption breaks down and identify failure modes.

3. **Bootstrap Sensitivity Analysis**: Vary the bootstrap sample size and distance calculation parameters systematically to quantify their impact on statistical power and false positive rates across different data kernel densities.