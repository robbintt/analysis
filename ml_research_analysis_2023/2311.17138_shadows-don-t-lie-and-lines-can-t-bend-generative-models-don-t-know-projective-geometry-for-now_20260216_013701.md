---
ver: rpa2
title: Shadows Don't Lie and Lines Can't Bend! Generative Models don't know Projective
  Geometry...for now
arxiv_id: '2311.17138'
source_url: https://arxiv.org/abs/2311.17138
tags:
- images
- generated
- cues
- area
- real
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that generative models produce images with
  geometric properties that differ from real images. The authors build collections
  of generated images that fool simple signal-based classifiers, then show these can
  be reliably detected by classifiers using only geometric features.
---

# Shadows Don't Lie and Lines Can't Bend! Generative Models don't know Projective Geometry...for now

## Quick Facts
- arXiv ID: 2311.17138
- Source URL: https://arxiv.org/abs/2311.17138
- Reference count: 40
- Key outcome: Generative models produce images with geometric properties that differ from real images, enabling detection through geometric classifiers that outperform signal-based methods.

## Executive Summary
This paper demonstrates that current generative models fail to accurately reproduce projective geometry properties in images, despite producing visually convincing content. The authors develop a multi-stage filtering process to isolate images with geometric inconsistencies, then show that simple classifiers analyzing geometric features (perspective fields, line segments, object-shadow relations) can reliably detect generated images with AUC scores of 0.85-0.98. The geometric classifiers outperform state-of-the-art signal-based detectors, and Grad-CAM visualizations confirm they identify real geometric problems rather than artifacts. The results suggest that current generators cannot maintain the global geometric consistency required for accurate perspective, shadow, and vanishing point relationships.

## Method Summary
The authors curate datasets of real and generated images, then apply a multi-stage filtering process to remove images with signal artifacts while preserving geometric errors. They train three geometric classifiers: a PointNet for line segment analysis, a ResNet50 for perspective field detection, and a ResNet50 for object-shadow relation analysis. These classifiers work on derived geometric features rather than raw pixels. The geometric detection performance is compared against standard signal-based classifiers across multiple generative models including Stable Diffusion XL, Dall-E 3, Kandinsky-v2, DeepFloyd, Adobe Firefly, and PixArt-α.

## Key Results
- Geometric classifiers achieve AUC scores of 0.85-0.98 on generated images that pass signal-based filtering
- All three geometric approaches outperform state-of-the-art signal-based detectors across multiple generators
- Grad-CAM visualizations show classifiers focus on meaningful geometric regions rather than artifacts
- Multi-stage filtering removes ~90% of generated images based on color and texture artifacts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Generative models fail to accurately reproduce projective geometry properties because these require tight coordination of detailed information over long spatial scales.
- Mechanism: The models capture local visual features well but cannot maintain global geometric consistency across the entire image, leading to systematic errors in perspective alignment, shadow direction, and vanishing point placement.
- Core assumption: Current generative models lack the architectural capacity to maintain geometric consistency across large spatial extents.
- Evidence anchors:
  - [abstract]: "generated images have geometric features different from those of real images" and "current generators cannot reliably reproduce geometric properties of real images"
  - [section 1]: "Generated images often exhibit inconsistencies where these lines do not meet at the correct vanishing points" and "discrepancies in shadow direction, length, and softness"
  - [corpus]: Weak evidence - corpus contains unrelated papers about lying/uncertainty but no direct geometric analysis evidence
- Break condition: If a generative model architecture is developed that can maintain geometric consistency across long spatial scales, or if the geometric cues can be learned as statistical biases rather than requiring true geometric understanding.

### Mechanism 2
- Claim: Simple signal-based classifiers can be fooled by generated images that appear visually realistic, but geometric classifiers that analyze derived features can reliably detect these same images.
- Mechanism: Signal-based classifiers rely on local pixel patterns, textures, and color distributions that can be easily manipulated by generative models. Geometric classifiers analyze structural relationships (lines, perspectives, shadows) that require coherent spatial reasoning which current generators cannot achieve.
- Core assumption: Geometric features are fundamentally harder to fake than local signal features because they require understanding of 3D spatial relationships.
- Evidence anchors:
  - [abstract]: "prequalified generated images can be identified reliably by classifiers that only look at geometric properties" and "detects generated images more reliably than SOTA local signal based detectors"
  - [section 4.2]: "This stage effectively filters out approximately 90% of the dataset" using color histogram methods that fail against geometric analysis
  - [section 5]: "Our classifiers see only derived geometric features and do not see the image itself" yet achieve AUCs of 0.85-0.98
- Break condition: If generative models learn to embed geometric consistency as statistical artifacts that can be captured by signal-based methods, or if the geometric analysis methods can be fooled by sophisticated geometric manipulation.

### Mechanism 3
- Claim: The multi-stage filtering process effectively isolates geometric errors by removing images with simple signal artifacts, color distribution biases, and textural inconsistencies.
- Mechanism: By sequentially applying filters that remove images based on color histograms (90% removal), CNN detection failures, and ResNet50 texture analysis, the remaining dataset contains images that are visually convincing but contain subtle geometric inconsistencies.
- Core assumption: Geometric errors are distinct from and persist after removal of common signal artifacts, making them detectable only through specialized geometric analysis.
- Evidence anchors:
  - [section 4.2]: "This stage effectively filters out approximately 90% of the dataset, highlighting the predictive power of color histograms"
  - [section 4.3]: "The ResNet50 classifier is shown to be good at distinguishing the intricate textural features that differentiate real images from generated ones"
  - [section 5]: "These images have successfully passed prior filtering stages; that is they are detected as real images" yet geometric analysis still detects them
- Break condition: If geometric errors are found to be correlated with signal artifacts that the filtering process removes, or if the filtering process itself introduces biases that mask geometric errors.

## Foundational Learning

- Concept: Projective geometry principles (vanishing points, perspective fields, shadow-object relationships)
  - Why needed here: The entire detection methodology relies on understanding how real images should behave according to projective geometry rules
  - Quick check question: Can you explain why shadows cast by objects should align with the light source direction and how this creates a geometric relationship?

- Concept: Feature extraction and geometric abstraction
  - Why needed here: The classifiers work on derived geometric features (line segments, perspective fields, object-shadow masks) rather than raw pixels
  - Quick check question: How would you extract line segments from an image and represent them in a way that captures their spatial relationships?

- Concept: Classifier evaluation metrics (ROC curves, AUC scores)
  - Why needed here: The paper uses ROC curves and AUC scores to evaluate classifier performance across different test sets
  - Quick check question: What does an AUC of 0.98 mean for a classifier, and how does it differ from accuracy?

## Architecture Onboarding

- Component map: Real image collection -> Captioning -> Stable Diffusion XL generation -> Multi-stage filtering (CNN detector -> Color histogram logistic regression -> ResNet50 prequalifier) -> Geometric feature extraction -> Classifier training -> Evaluation
- Critical path: Image generation → Multi-stage filtering → Geometric feature extraction → Classifier training → Evaluation on prequalified test sets
- Design tradeoffs:
  - Geometric vs. signal-based detection: Geometric methods achieve higher accuracy but require specialized feature extractors and training
  - Filtering intensity: More aggressive filtering creates cleaner test sets but reduces dataset size
  - Generalization: Classifiers trained on one generator may not generalize perfectly to others, requiring cross-testing
- Failure signatures:
  - Low AUC scores (below 0.7) indicate either poor feature extraction or that the geometric errors are not systematic enough
  - Grad-CAM visualizations showing no clear focus areas suggest the classifier is not detecting meaningful geometric patterns
  - ROC curves not separating well from random chance indicate the geometric cues are not distinctive
- First 3 experiments:
  1. Train a ResNet50 classifier directly on raw pixel data vs. geometric features on the same filtered dataset to quantify the performance gap
  2. Test the geometric classifiers on a dataset of composite images (real foreground, real background) to see if they detect different types of geometric errors
  3. Create an ablation study removing each geometric feature (lines, perspective, shadows) to determine which contributes most to detection accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can current generative models be modified to reliably reproduce projective geometry without requiring fundamental architectural changes?
- Basis in paper: [inferred] The paper concludes that "fixing this difficulty requires structural innovation in the generator, rather than simply exposing the generator to more data."
- Why unresolved: The paper demonstrates the problem exists but does not explore potential modifications or architectural innovations that might solve it.
- What evidence would resolve it: Empirical testing of modified generative architectures that successfully maintain projective geometry consistency across diverse scenes and scales.

### Open Question 2
- Question: How do different levels of detail in geometric cues affect detection performance across generative models?
- Basis in paper: [explicit] The paper evaluates three types of geometric cues (perspective fields, lines, object-shadow relations) but doesn't systematically compare their relative importance or interactions.
- Why unresolved: The study uses all three cues but doesn't isolate their individual contributions or explore whether certain combinations are more effective for specific types of geometric errors.
- What evidence would resolve it: Controlled experiments varying which geometric cues are used and measuring detection accuracy for different types of geometric distortions.

### Open Question 3
- Question: Do generative models show consistent patterns of projective geometry errors across different subject matters (faces, landscapes, architecture, etc.)?
- Basis in paper: [inferred] The paper tests indoor and outdoor scenes but doesn't analyze whether error patterns differ systematically across content types.
- Why unresolved: The current analysis aggregates results without examining whether certain types of scenes or objects are more prone to specific geometric failures.
- What evidence would resolve it: Detailed error analysis categorizing geometric failures by scene content type and identifying recurring patterns specific to different subject matters.

## Limitations
- The study focuses primarily on indoor scenes and vehicles, limiting generalizability to other domains
- Geometric feature extractors (DeepLSD, perspective fields, object-shadow detection) are treated as black boxes without error analysis
- The multi-stage filtering may introduce selection biases that affect classifier training

## Confidence

**Major Claims Confidence:**
- Geometric properties differ systematically between real and generated images: **High** - Supported by consistent classifier performance across multiple generators and strong Grad-CAM visualizations showing geometric focus
- Current generators cannot maintain long-range geometric consistency: **Medium** - The evidence shows systematic failures but doesn't conclusively prove architectural limitations versus training data biases
- Geometric detection outperforms signal-based methods: **High** - Direct comparison shows superior AUC scores and cross-generator generalization

## Next Checks
1. Test geometric classifiers on composite images (real objects in generated backgrounds) to isolate whether errors stem from geometry generation or object placement
2. Conduct cross-dataset evaluation using outdoor scenes, portraits, and synthetic environments to assess domain generalization
3. Perform ablation studies removing each geometric feature type to quantify individual contributions and identify redundancy in the detection pipeline