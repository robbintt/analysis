---
ver: rpa2
title: Identifying Misinformation on YouTube through Transcript Contextual Analysis
  with Transformer Models
arxiv_id: '2307.12155'
source_url: https://arxiv.org/abs/2307.12155
tags:
- misinformation
- outube
- learning
- dataset
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of detecting misinformation
  on YouTube videos. The core method idea involves converting the video classification
  task into a text classification task by leveraging video transcripts.
---

# Identifying Misinformation on YouTube through Transcript Contextual Analysis with Transformer Models

## Quick Facts
- arXiv ID: 2307.12155
- Source URL: https://arxiv.org/abs/2307.12155
- Reference count: 24
- Key outcome: Fine-tuned transformer models achieve high accuracy (>0.90) and F1 score (>0.90) on YouTube vaccine-misinformation and fake news datasets; few-shot models outperform fine-tuned ones by 20% on YouTube pseudoscience dataset.

## Executive Summary
This paper tackles the challenge of detecting misinformation in YouTube videos by transforming the video classification task into a text classification task using video transcripts. The authors employ advanced transformer models—BERT, RoBERTa, and ELECTRA—for fine-tuning, and sentence-transformers (MPNet, RoBERTa-large) for few-shot learning. Models are evaluated on three datasets: YouTube vaccine-misinformation, YouTube pseudoscience, and ISOT Fake News. Results show high performance across most datasets, with few-shot learning proving especially effective for the smaller pseudoscience dataset, highlighting its potential in low-resource settings.

## Method Summary
The study converts YouTube video classification into text classification by leveraging video transcripts. Transformer models (BERT, RoBERTa, ELECTRA) are fine-tuned on labeled transcript data, while few-shot models (MPNet, RoBERTa-large) are trained using the SetFit framework with minimal examples. A sliding window approach with 80% overlap and max sequence length of 128 is used to handle long transcripts. Models are trained and evaluated on three datasets: YouTube vaccine-misinformation (652 misinfo, 636 non-misinfo), YouTube pseudoscience (182 pseudoscience, 226 science), and ISOT Fake News (1000 fake, 1000 real).

## Key Results
- Fine-tuned transformer models achieve MCC > 0.81, accuracy > 0.90, and F1 score > 0.90 on YouTube vaccine-misinformation and fake news datasets.
- Few-shot models outperform fine-tuned models by 20% in both accuracy and F1 score on the YouTube pseudoscience dataset.
- The sliding window approach effectively handles long transcripts, preserving context for transformer models.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer models can detect misinformation by fine-tuning on labeled text data from video transcripts.
- Mechanism: Pre-trained transformers (BERT, RoBERTa, ELECTRA) are adapted to the misinformation detection task via fine-tuning on labeled datasets, leveraging their ability to capture contextual text patterns.
- Core assumption: The textual content in video transcripts sufficiently represents the misinformation cues present in the video content.
- Evidence anchors:
  - [abstract] "We convert the conventional video classification task into a text classification task by leveraging the textual content derived from the video transcripts."
  - [section] "Pre-training exposes the model to a large corpus of unlabeled data, allowing it to acquire general language representations. The fine-tuning stage further adapts these language representations by training the model on a task-specific labeled dataset."
  - [corpus] Weak: No direct corpus evidence that transcripts alone capture misinformation cues; assumes overlap with video content.
- Break condition: If transcripts omit key misinformation signals (e.g., visual context, tone), model performance will degrade.

### Mechanism 2
- Claim: Few-shot learning models can outperform fine-tuned models when training data is limited.
- Mechanism: Sentence-transformer models (MPNet, RoBERTa-large) are trained with minimal labeled examples using the SetFit framework, enabling effective classification with scarce data.
- Core assumption: High-quality representations from few examples generalize well to the target task.
- Evidence anchors:
  - [abstract] "Interestingly, the few-shot models outperformed the fine-tuned ones by 20% in both Accuracy and F1 score for the YouTube Pseudoscience dataset, highlighting the potential utility of this approach -- especially in the context of limited training data."
  - [section] "Few-shot learning, offering the advantage of making accurate predictions based on a few examples, is particularly beneficial when labeled data is either scarce or costly to procure."
  - [corpus] Weak: No corpus citations confirming few-shot superiority in this domain; result is from this study only.
- Break condition: If the few-shot model lacks sufficient diversity in the few samples, performance will drop.

### Mechanism 3
- Claim: Sliding window approach enables transformer models to handle long transcripts without exceeding sequence length limits.
- Mechanism: Transcripts longer than max sequence length are split into overlapping sub-sequences; each window is processed independently, and outputs are combined for final classification.
- Core assumption: Overlapping windows preserve contextual continuity and prevent information loss.
- Evidence anchors:
  - [section] "We employed a strategy that effectively handles long documents and ensures that all document parts contribute to the final classification decision."
  - [section] "To navigate this constraint, we implemented a technique known as the 'sliding window approach', inspired by the work of Sanh et al. [3]."
  - [corpus] No corpus citations provided; this is based on the cited paper's methodology.
- Break condition: If overlap is insufficient or window boundaries split key context, classification accuracy will suffer.

## Foundational Learning

- Concept: Transfer learning with pre-trained transformers
  - Why needed here: Avoids training from scratch and leverages large-scale language understanding.
  - Quick check question: What is the main advantage of fine-tuning a pre-trained BERT model versus training BERT from scratch on a small misinformation dataset?

- Concept: Sequence length constraints in transformers
  - Why needed here: Transcripts often exceed the 512-token limit, requiring special handling.
  - Quick check question: Why does a transformer model fail if given a 2000-token input without modification?

- Concept: Few-shot learning principles
  - Why needed here: Pseudoscience dataset is small; few-shot methods can perform well with minimal labeled data.
  - Quick check question: In few-shot learning, what role does the choice of support examples play in model performance?

## Architecture Onboarding

- Component map: Input -> Tokenizer -> Sliding Window Processor -> Transformer (BERT/RoBERTa/ELECTRA or Sentence-Transformer) -> Classification Head -> Output. For few-shot: Input -> Sentence Transformer Encoder -> SetFit Trainer -> Classification Head.
- Critical path: Transcript acquisition -> Preprocessing (tokenization + windowing) -> Model inference -> Classification decision.
- Design tradeoffs: Fine-tuned models offer higher accuracy with more data; few-shot models save labeling effort but may generalize less. Sliding windows preserve context but increase computation.
- Failure signatures: Low MCC/accuracy -> check window overlap and token limits; poor few-shot performance -> inspect sample diversity and embeddings quality.
- First 3 experiments:
  1. Run fine-tuned BERT on YouTube Audit (Vaccines) dataset with max_seq_length=128; record MCC, accuracy, F1.
  2. Apply sliding window on a long transcript (>512 tokens) and compare classification outputs vs. truncation.
  3. Train SetFit with MPNet on YouTube Pseudoscience using only 5 labeled examples per class; evaluate accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of transformer models vary across different types of misinformation, such as vaccine misinformation, pseudoscience, and fake news?
- Basis in paper: [explicit] The paper evaluates models on three datasets: YouTube vaccine-misinformation videos, YouTube pseudoscience videos, and a fake news dataset, showing varying performance across these types.
- Why unresolved: While the paper presents results for different datasets, it does not explore the underlying reasons for the performance differences across misinformation types or investigate how these models might generalize to other forms of misinformation.
- What evidence would resolve it: Comparative analysis of model performance across a broader range of misinformation types, including political misinformation, health misinformation beyond vaccines, and climate change misinformation, to identify patterns or limitations in model effectiveness.

### Open Question 2
- Question: How can transformer models be optimized to handle long documents more effectively without compromising accuracy?
- Basis in paper: [explicit] The paper mentions that transformer models face challenges with long documents due to the maximum sequence length constraint and employs a sliding window approach to address this.
- Why unresolved: The paper does not explore alternative methods or optimizations for handling long documents, such as hierarchical transformers or attention mechanisms, which might improve performance or efficiency.
- What evidence would resolve it: Comparative studies evaluating different strategies for long document classification, such as hierarchical transformers, attention mechanisms, or dynamic window sizing, to determine the most effective approach.

### Open Question 3
- Question: How does the effectiveness of few-shot learning compare to fine-tuning in scenarios with extremely limited labeled data?
- Basis in paper: [explicit] The paper highlights that few-shot models outperformed fine-tuned ones by 20% in accuracy and F1 score for the YouTube pseudoscience dataset, emphasizing the potential of few-shot learning in limited data scenarios.
- Why unresolved: The paper does not investigate the limits of few-shot learning effectiveness or compare it to other low-resource learning techniques, such as meta-learning or transfer learning with minimal data.
- What evidence would resolve it: Experimental evaluations comparing few-shot learning with other low-resource learning methods across various datasets with varying levels of labeled data availability to determine the most effective approach.

## Limitations
- Dataset Generality: The YouTube vaccine and pseudoscience datasets are domain-specific and may not generalize to other misinformation types.
- Transcript Representation: The study assumes that video transcripts alone capture sufficient misinformation cues, ignoring visual and audio elements.
- Sliding Window Configuration: The 80% overlap and max-seq-length of 128 were chosen without empirical comparison to other configurations.

## Confidence
- **High Confidence**: Fine-tuned transformer models achieve high accuracy (>0.90) and MCC (>0.81) on YouTube vaccine and fake news datasets.
- **Medium Confidence**: Few-shot models outperform fine-tuned models by 20% on the YouTube pseudoscience dataset.
- **Low Confidence**: Sliding window approach reliably preserves context for long transcripts.

## Next Checks
1. Replicate the YouTube Pseudoscience Experiment: Train and evaluate the same SetFit models (MPNet, RoBERTa-large) on the YouTube pseudoscience dataset with the reported few-shot configuration. Compare accuracy and F1 to the fine-tuned baselines.
2. Test on an Unseen Misinformation Domain: Apply the best-performing fine-tuned transformer model to a new YouTube dataset (e.g., COVID-19 misinformation) and report MCC, accuracy, and F1. This tests domain generalization.
3. Analyze Sliding Window Impact: Conduct an ablation study varying window overlap (e.g., 50%, 80%, 90%) and sequence length on a long-transcript subset. Measure classification accuracy and processing time to identify optimal settings.