---
ver: rpa2
title: 'LEGO: Learning and Graph-Optimized Modular Tracker for Online Multi-Object
  Tracking with Point Clouds'
arxiv_id: '2308.09908'
source_url: https://arxiv.org/abs/2308.09908
tags:
- tracking
- ieee
- object
- matrix
- module
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents LEGO, a modular tracker that improves multi-object
  tracking performance using only LiDAR point clouds. LEGO addresses data association
  challenges by integrating a graph neural network with a self-attention mechanism
  to create an association score map, combined with a Kalman filter for state prediction
  and update.
---

# LEGO: Learning and Graph-Optimized Modular Tracker for Online Multi-Object Tracking with Point Clouds

## Quick Facts
- arXiv ID: 2308.09908
- Source URL: https://arxiv.org/abs/2308.09908
- Reference count: 40
- Primary result: Achieves state-of-the-art performance on KITTI benchmark, ranking 1st among online trackers with HOTA score of 78.05% and MOTA of 88.97% for car tracking

## Executive Summary
This paper presents LEGO, a modular tracker that achieves state-of-the-art performance for online multi-object tracking using only LiDAR point clouds. The tracker integrates graph optimization and self-attention mechanisms through a Graph Dual Attention Network (GDAN) to efficiently formulate association score maps. LEGO also incorporates an offset correction module to refine detection outputs and uses a Kalman filter with constant acceleration motion model for state prediction. Evaluated on the KITTI benchmark, LEGO ranks first among online trackers and demonstrates significant improvements over existing methods, particularly in data association accuracy.

## Method Summary
LEGO is a modular tracker that processes LiDAR point clouds for 3D multi-object tracking. The method uses a 3D object detector to generate initial detections, which are then refined by an offset correction module using CNN and MLP architectures. Feature extraction is performed using PointNet to process both detected and predicted object states. The core innovation is the Graph Dual Attention Network (GDAN), which processes a bipartite graph between detections and predictions using self-attention to compute association scores. A Kalman filter with constant acceleration motion model provides state prediction, while the Hungarian algorithm solves the data association problem. The tracker includes track management with thresholds for handling missed detections.

## Key Results
- Achieves HOTA score of 78.05% and MOTA of 88.97% on KITTI car tracking benchmark
- Ranks 1st among online trackers and 2nd overall at submission time
- Demonstrates significant improvements in data association accuracy compared to baseline methods
- Shows robustness to detection errors through the offset correction module

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The self-attention-based graph neural network (GDAN) improves data association by reducing information redundancy and capturing long-range dependencies.
- Mechanism: The GDAN module processes a bipartite graph between detected and predicted objects, using self-attention to assign different weights to information from different nodes during message passing. This avoids the redundancy of uniform message passing in standard GNNs.
- Core assumption: The bipartite graph structure effectively represents the association problem between detections and predictions, and self-attention can learn meaningful association scores from point cloud features.
- Evidence anchors:
  - [abstract]: "The proposed LEGO tracker integrates graph optimization and self-attention mechanisms, which efficiently formulate the association score map"
  - [section]: "Our proposed self-attention blocks are specifically tailored to suit the bipartite graph structure"
  - [corpus]: Weak - no direct evidence from corpus papers on self-attention for MOT
- Break condition: If the bipartite graph representation fails to capture the true association relationships, or if self-attention cannot learn meaningful scores from the feature space.

### Mechanism 2
- Claim: The Kalman filter with constant acceleration (CA) motion model provides more accurate state prediction than LSTM-based approaches for this application.
- Mechanism: The CA motion model tracks position, velocity, and orientation, and uses Kalman prediction equations to forecast the next state. This is computationally efficient and handles acceleration better than constant velocity models.
- Core assumption: Object motion can be reasonably approximated by constant acceleration within the tracking time window, and the computational overhead of LSTM is not justified for this problem.
- Evidence anchors:
  - [section]: "the constant acceleration (CA) motion model [16] is used, which offers a more precise representation of the object state"
  - [section]: "LSTM networks require more time than traditional motion prediction techniques"
  - [corpus]: Weak - no direct evidence from corpus papers on Kalman vs LSTM for MOT
- Break condition: If objects exhibit highly non-linear motion patterns or sudden direction changes that violate the CA assumption.

### Mechanism 3
- Claim: The offset correction module improves tracking accuracy by correcting detection errors before data association.
- Mechanism: The offset correction module predicts the offset between detection results and ground truth, using a CNN-MLP architecture. This refined detection state is used in the association process.
- Core assumption: The 3D object detector has systematic errors that can be learned and corrected, and these errors significantly impact association accuracy.
- Evidence anchors:
  - [section]: "the integration of an offset correction module is proposed. This module serves the crucial purpose of rectifying the detection outcomes generated by the 3D object detector"
  - [section]: "This module comprises a 3D convolution layer, batch normalization layer, and multi-layer perception (MLP) with the residual connection"
  - [corpus]: Weak - no direct evidence from corpus papers on offset correction for MOT
- Break condition: If detection errors are random rather than systematic, or if the correction model overfits to training data.

## Foundational Learning

- Concept: Graph Neural Networks and message passing
  - Why needed here: The GDAN module uses graph structures to represent object associations and propagate information between nodes
  - Quick check question: What is the difference between message passing in standard GNNs and the self-attention-based approach used in GDAN?

- Concept: Kalman filtering and state estimation
  - Why needed here: The tracker uses Kalman prediction and update equations to maintain object states across time frames
  - Quick check question: How does the constant acceleration motion model differ from constant velocity in terms of state representation and transition matrices?

- Concept: Data association and bipartite matching
  - Why needed here: The core tracking problem is formulated as finding optimal matches between detected and predicted objects
  - Quick check question: What are the advantages of formulating data association as a bipartite matching problem versus other approaches?

## Architecture Onboarding

- Component map:
  - 3D Object Detector (external) → Offset Correction Module → Feature Extraction Module → GDAN Score Calculation → Association Module → Kalman Filter → Track Management
  - Motion Prediction Module runs in parallel to provide predicted states
  - Feature Extraction processes both detected and predicted states

- Critical path: Detection → Offset Correction → Feature Extraction → GDAN → Association → State Update
  - The motion prediction runs in parallel and feeds into the association cost calculation

- Design tradeoffs:
  - Using self-attention vs. standard GNN message passing: better long-range dependencies but potentially higher computational cost
  - CA motion model vs. LSTM: simpler and faster but may miss complex motion patterns
  - Separate offset correction vs. end-to-end training: more interpretable but may miss joint optimization opportunities

- Failure signatures:
  - Association errors often indicate issues with feature extraction or GDAN learning
  - Track fragmentation suggests problems with motion prediction or track management thresholds
  - Identity switches typically point to association cost matrix imbalance

- First 3 experiments:
  1. Test GDAN with random initialization to verify it learns meaningful associations
  2. Compare CA motion model performance against constant velocity baseline
  3. Evaluate impact of offset correction by running with and without this module

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several areas remain unexplored based on the evaluation and methodology presented.

## Limitations

- The evaluation is limited to car tracking on KITTI, leaving performance on other object types unverified
- Lack of ablation studies to isolate the contribution of individual modules to overall performance
- No quantitative comparison of computational overhead versus traditional approaches
- Limited analysis of performance in challenging scenarios with frequent occlusions

## Confidence

- **High confidence**: The Kalman filter with constant acceleration provides reasonable motion prediction for automotive scenarios
- **Medium confidence**: The self-attention-based GDAN improves association scores compared to traditional methods, though comparative ablation is missing
- **Medium confidence**: The offset correction module improves performance, but its generalizability to other datasets is unverified

## Next Checks

1. Conduct controlled ablation experiments comparing GDAN with standard GNN message passing to quantify the self-attention benefit
2. Test the tracker on nuScenes dataset to evaluate generalization beyond KITTI's structured environments
3. Perform sensitivity analysis on Kalman filter parameters and motion model assumptions to identify failure conditions