---
ver: rpa2
title: Language of Bargaining
arxiv_id: '2306.07117'
source_url: https://arxiv.org/abs/2306.07117
tags:
- negotiation
- buyer
- seller
- bargaining
- price
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a controlled experiment and novel dataset for
  studying how language shapes bilateral bargaining. The experiment contrasts natural
  language negotiation via audio with alternating numeric offers only.
---

# Language of Bargaining

## Quick Facts
- arXiv ID: 2306.07117
- Source URL: https://arxiv.org/abs/2306.07117
- Reference count: 20
- Primary result: Natural language negotiations finish faster, achieve higher agreement rates, and show less price variance than numeric-only exchanges

## Executive Summary
This work presents a controlled experiment and novel dataset for studying how language shapes bilateral bargaining. The experiment contrasts natural language negotiation via audio with alternating numeric offers only. Natural language negotiations finish faster, achieve higher agreement rates, and show less price variance despite identical average agreed prices. Speech act annotations reveal buyers make more new offers than sellers. Prediction models using LIWC features outperform text-based and neural approaches, showing that buyers benefit from using filler words and avoiding explicit conflict language while sellers succeed by discussing house details early.

## Method Summary
The study employs a 2-round negotiation experiment where participants bargain over house prices. Round 1 uses an alternating offers (AO) condition where participants can only exchange numeric offers. Round 2 uses a natural language (NL) condition with unrestricted speech communication. All negotiations are recorded and transcribed using Amazon Transcribe. The dataset consists of 178 NL negotiations annotated with six bargaining acts (new offer, repeat offer, push, comparison, allowance, end). LIWC features, bag-of-words, and bargaining act frequencies are extracted to predict negotiation outcomes using logistic regression and Longformer models with nested 5-fold cross-validation.

## Key Results
- Natural language negotiations achieve 93% agreement rate vs 72% in numeric-only condition
- NL negotiations finish faster with fewer total offers exchanged
- LIWC-based prediction models achieve 63.1% accuracy, outperforming BOW (58.9%) and neural approaches
- Buyers who use filler words and avoid conflict language are more successful
- Sellers discussing house details early are more likely to win negotiations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Natural language communication reduces negotiation friction compared to alternating numeric offers.
- **Mechanism:** Speech enables richer semantic exchange, allowing parties to justify positions, make concessions, and react to the other party's arguments dynamically.
- **Core assumption:** The information content conveyed through spoken negotiation is richer than through simple numeric exchanges.
- **Evidence anchors:**
  - [abstract] "when subjects can talk, fewer offers are exchanged, negotiations finish faster, the likelihood of reaching agreement rises, and the variance of prices at which subjects agree drops substantially."
  - [section] "Without the ability to communicate using language, buyers and sellers are less efficient in reconciling their differences."
  - [corpus] Weak - related papers focus on LLM bargaining evaluation but do not directly test natural language vs numeric-only formats.
- **Break condition:** If negotiators fail to verbalize meaningful content, the advantage of speech over numeric exchange disappears.

### Mechanism 2
- **Claim:** Buyers benefit from being reactive rather than driving the negotiation, while sellers benefit from early house detail discussion.
- **Mechanism:** Reactive buyers signal patience and emotional indifference, transferring the onus of driving the conversation to the seller. Early seller discussion of house attributes establishes justification for the asking price.
- **Core assumption:** Negotiation success depends on how well each party can influence the other's perception of value.
- **Evidence anchors:**
  - [abstract] "successful buyers convey a sense of emotional indifference and thoughtfulness through filler words and curt acknowledgements of the sellers' arguments."
  - [section] "Early discussion of this subject by the seller establishes a baseline justification for the housing price."
  - [corpus] Weak - neighboring papers on LLM negotiation do not analyze specific buyer/seller behavioral patterns.
- **Break condition:** If the buyer's passive approach is interpreted as disinterest, or if the seller's early detail discussion is seen as defensive, the mechanism fails.

### Mechanism 3
- **Claim:** LIWC-based text features outperform both raw text and neural models for predicting negotiation outcomes.
- **Mechanism:** LIWC captures psychologically meaningful language patterns (e.g., emotional tone, social focus) that correlate with negotiation success better than surface text features or transformer embeddings.
- **Core assumption:** Psychological language dimensions are more predictive of negotiation outcomes than linguistic form or semantic content alone.
- **Evidence anchors:**
  - [abstract] "Prediction models using LIWC features outperform text-based and neural approaches."
  - [section] "LIWC categories outperform other features and achieve 63.1% accuracy whereas text-based BOW features achieve a best score of 58.9%."
  - [corpus] Weak - neighboring papers focus on LLM evaluation metrics but do not test LIWC vs neural approaches.
- **Break condition:** If the negotiation context changes such that LIWC dimensions no longer correlate with success, the advantage disappears.

## Foundational Learning

- **Concept:** Speech act annotation and bargaining act taxonomy
  - Why needed here: The dataset is enriched with speech act annotations to capture negotiation-specific actions (new offers, pushes, comparisons, allowances, ends), which are essential for analyzing negotiation dynamics.
  - Quick check question: What are the five bargaining acts defined in this study, and how do they differ from general speech acts?

- **Concept:** Experimental control with alternating offers (AO) condition
  - Why needed here: The AO condition serves as a control to isolate the effect of natural language by constraining communication to numeric offers only.
  - Quick check question: How does the AO condition differ from the natural language condition in terms of communication mechanism and participant behavior?

- **Concept:** Logistic regression with LIWC features for outcome prediction
  - Why needed here: LIWC categories provide psychologically meaningful features that predict negotiation outcomes better than raw text or neural models, revealing linguistic signals of success.
  - Quick check question: Which LIWC categories were most predictive of seller wins, and why might these patterns emerge in successful negotiations?

## Architecture Onboarding

- **Component map:** Experiment platform (web app + Zoom breakout rooms) → Transcription service (Amazon Transcribe) → Annotation pipeline (bargaining acts) → Feature extraction (LIWC, BOW, bargaining acts) → Prediction models (Logistic Regression, Longformer) → Analysis and evaluation
- **Critical path:** Participant pairing → Role assignment → Round 1 (AO) → Round 2 (NL) → Recording → Transcription → Annotation → Feature extraction → Model training → Evaluation
- **Design tradeoffs:** Natural language enables richer negotiation but requires transcription and annotation overhead; AO condition simplifies communication but may not reflect real-world bargaining; LIWC features are interpretable but may miss domain-specific nuances
- **Failure signatures:** Low inter-annotator agreement on speech acts; poor prediction accuracy indicating weak feature-signal alignment; transcription errors affecting downstream analysis
- **First 3 experiments:**
  1. Replicate prediction task with only LIWC features on a subset of negotiations to verify performance claims
  2. Train and test logistic regression models separately on buyer and seller speech to confirm differential predictive patterns
  3. Conduct ablation study removing numerical offers from features to assess pure language predictive power

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do speech prosody features (tone, pitch, rhythm) affect negotiation outcomes compared to textual features alone?
- Basis in paper: [explicit] The paper acknowledges that acoustic cues and speech prosody could be significant but were not analyzed due to focusing on textual features from transcripts.
- Why unresolved: The study used automated transcriptions without analyzing the original audio's acoustic properties, missing potentially important prosodic signals.
- What evidence would resolve it: Direct analysis of audio recordings to extract prosodic features (pitch variation, speech rate, pauses) and correlate them with negotiation success rates and strategies.

### Open Question 2
- Question: Would the negotiation dynamics change significantly if participants had asymmetric information about the house's actual market value?
- Basis in paper: [inferred] The experiment used identical information about comparable houses for both parties, creating symmetric information conditions.
- Why unresolved: Real-world negotiations often involve information asymmetry, but this study controlled for it by giving both parties the same market data.
- What evidence would resolve it: Replication of the experiment with one party having superior or inferior information about the house's true value, then comparing negotiation patterns and outcomes.

### Open Question 3
- Question: How would negotiation outcomes differ if the private valuations were closer together rather than $10,000 apart?
- Basis in paper: [explicit] The experiment used fixed private valuations ($235K for buyer, $225K for seller) creating a $10K surplus zone.
- Why unresolved: The fixed valuation gap may have influenced negotiation strategies and language use in ways that wouldn't generalize to tighter or wider valuation gaps.
- What evidence would resolve it: Running parallel experiments with different valuation gaps (e.g., $5K, $20K) to test how the size of the surplus zone affects linguistic strategies and agreement rates.

## Limitations

- Experimental setting (house price bargaining with fixed $200K-$260K range) may not generalize to other negotiation domains or cultural contexts
- Analysis relies on relatively small dataset (178 negotiations) and manual speech act annotations, introducing potential labeling inconsistencies
- LIWC advantage over neural models may be sensitive to domain-specific vocabulary not captured by LIWC's general psychological categories

## Confidence

- **High confidence:** Natural language negotiations complete faster and achieve higher agreement rates than numeric-only exchanges; LIWC features outperform text-based features for outcome prediction
- **Medium confidence:** Specific linguistic strategies for buyers (filler words, emotional indifference) and sellers (early house detail discussion) improve negotiation outcomes; alternating offers condition meaningfully constrains communication dynamics
- **Low confidence:** The psychological mechanisms underlying buyer vs. seller language patterns; generalizability of findings to negotiations outside the controlled experimental framework

## Next Checks

1. Conduct ablation study removing numerical price references from features to verify that LIWC-based predictions capture pure linguistic signals rather than price anchoring effects
2. Test LIWC feature importance across different negotiation phases to determine whether early vs. late language patterns differentially predict outcomes
3. Replicate prediction experiments with cross-cultural negotiation datasets to assess whether LIWC dimensions maintain predictive power across linguistic and cultural boundaries