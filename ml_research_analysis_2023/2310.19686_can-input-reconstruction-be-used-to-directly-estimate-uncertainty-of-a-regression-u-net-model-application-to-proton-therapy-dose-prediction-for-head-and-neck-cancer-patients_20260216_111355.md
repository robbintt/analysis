---
ver: rpa2
title: Can input reconstruction be used to directly estimate uncertainty of a regression
  U-Net model? -- Application to proton therapy dose prediction for head and neck
  cancer patients
arxiv_id: '2310.19686'
source_url: https://arxiv.org/abs/2310.19686
tags:
- uncertainty
- dose
- mcdo
- prediction
- patients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a novel method for directly estimating uncertainty
  in regression U-Net models by adding an input reconstruction branch from the bottleneck
  layer. The method reconstructs the input (e.g., CT scan) and uses the reconstruction
  error as a surrogate for model uncertainty.
---

# Can input reconstruction be used to directly estimate uncertainty of a regression U-Net model? -- Application to proton therapy dose prediction for head and neck cancer patients

## Quick Facts
- arXiv ID: 2310.19686
- Source URL: https://arxiv.org/abs/2310.19686
- Reference count: 24
- The paper presents a novel method for directly estimating uncertainty in regression U-Net models by adding an input reconstruction branch from the bottleneck layer

## Executive Summary
This paper introduces a novel method for estimating uncertainty in regression U-Net models by adding an input reconstruction branch from the bottleneck layer. The approach reconstructs the input (e.g., CT scan) and uses the reconstruction error as a surrogate for model uncertainty. Applied to proton therapy dose prediction for head and neck cancer patients, the method demonstrates higher Pearson correlation with prediction error (0.620) compared to state-of-the-art methods like Monte Carlo dropout and Deep ensembles. The input reconstruction method also enables better out-of-distribution detection, distinguishing ID and OOD data with a Z-score of 34.05 versus 1.12-2.35 for other methods. Notably, the method estimates uncertainty simultaneously with the main task, requiring less computational resources than multiple inference passes needed for other methods.

## Method Summary
The proposed method adds a CT reconstruction branch to the bottleneck layer of a U-Net architecture, trained simultaneously with the dose prediction task. The model takes CT scans, tumor volumes, and organ at risk contours as inputs and outputs both predicted dose distributions and reconstructed CT images. The reconstruction error, computed as mean squared error between input and reconstructed CT, serves as a surrogate for model uncertainty. The method is compared against Monte Carlo dropout and Deep ensembles on a dataset of 60 oropharynx cancer patients (in-distribution) and 10 patients with other head and neck cancer sites (out-of-distribution). The approach shows improved correlation between uncertainty estimation and prediction error, better OOD detection capability, and reduced computational requirements compared to existing methods.

## Key Results
- Input reconstruction method achieves Pearson correlation coefficient of 0.620 with prediction error, compared to 0.447-0.612 for Monte Carlo dropout and Deep ensembles
- The method enables better out-of-distribution detection with Z-score of 34.05 versus 1.12-2.35 for other methods
- Uncertainty estimation is performed simultaneously with the regression task, reducing computational resources compared to multiple inference passes required by other methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reconstruction error from a CT reconstruction branch serves as a direct surrogate for model uncertainty
- Mechanism: The bottleneck representation captures essential features for dose prediction. When the input CT is reconstructed from this representation, higher uncertainty in the dose prediction correlates with larger reconstruction error because the model cannot fully explain the input.
- Core assumption: CT reconstruction error is indicative of the model's confidence in its dose prediction, assuming both tasks rely on the same underlying features.
- Evidence anchors:
  - [abstract] "The input reconstruction error can be used as a surrogate of the model uncertainty."
  - [section] "The mean squared error of the CT reconstruction, masked on the body, can be used as a surrogate of the uncertainty that we evaluate by computing the correlation with the prediction loss."
  - [corpus] Weak evidence for this specific reconstruction-uncertainty link; most related work focuses on reconstruction for anomaly detection, not uncertainty estimation for regression tasks.
- Break condition: If the bottleneck features are not sufficient to reconstruct the CT accurately, or if reconstruction error is dominated by irrelevant factors like couch setup variations.

### Mechanism 2
- Claim: Simultaneous training of dose prediction and CT reconstruction enables uncertainty estimation without multiple inference passes
- Mechanism: By training both tasks with shared encoder and separate decoders, the model learns to predict dose while simultaneously quantifying reconstruction error as uncertainty. This is computationally efficient compared to methods requiring multiple forward passes.
- Core assumption: Joint training does not significantly degrade dose prediction performance while adding the reconstruction capability.
- Evidence anchors:
  - [abstract] "It estimates the uncertainty simultaneously to the regression task, therefore requires less time or computational resources."
  - [section] "Our method estimates the uncertainty simultaneously to the regression task, therefore requires less time or computational resources than MCDO or DE."
  - [corpus] No direct evidence in corpus about simultaneous training benefits for uncertainty estimation.
- Break condition: If joint training causes interference between tasks, degrading dose prediction accuracy.

### Mechanism 3
- Claim: CT reconstruction error enables better out-of-distribution detection compared to Monte Carlo dropout and Deep ensembles
- Mechanism: OOD data (patients with different tumor sites) produce higher reconstruction errors because the model encounters anatomical features it hasn't learned to reconstruct well, while ID data reconstruction errors remain low.
- Core assumption: Anatomical differences between tumor sites are reflected in reconstruction error, and these differences correlate with prediction uncertainty.
- Evidence anchors:
  - [abstract] "Moreover, our method allows an easier identification of OOD (Z-score of 34.05)."
  - [section] "While the five MCDO methods fail to distinguish OOD from ID, DE almost separates between the two distributions with only one patient on the right-hand side of the histogram. Our input reconstruction technique on the other hand allows us to easily set a threshold between ID and OOD patient data."
  - [corpus] Related work on reconstruction for OOD detection exists but not specifically for this regression application.
- Break condition: If OOD data shares similar anatomical features with ID data, reconstruction error may not distinguish them effectively.

## Foundational Learning

- Concept: Uncertainty quantification in deep learning models
  - Why needed here: The paper addresses the challenge of estimating uncertainty in regression U-Net models for medical applications where wrong predictions can jeopardize patient safety
  - Quick check question: What are the two main sources of uncertainty in deep learning models (aleatoric and epistemic)?

- Concept: Bayesian approximations (Monte Carlo dropout and Deep ensembles)
  - Why needed here: These are the state-of-the-art methods being compared against, and understanding their limitations (high inference time, poor OOD detection) motivates the proposed approach
  - Quick check question: Why do Monte Carlo dropout and Deep ensembles require multiple inference passes?

- Concept: Autoencoder architectures and reconstruction error
- Why needed here: The proposed method adds a reconstruction branch to the U-Net bottleneck, and understanding how reconstruction error can indicate anomalies or uncertainty is fundamental
  - Quick check question: How does reconstruction error in autoencoders relate to anomaly detection?

## Architecture Onboarding

- Component map:
  - Input: CT scan, tumor volumes (TV), organs at risk (OARs)
  - Shared encoder: HD-UNet encoder with dense connections
  - Task 1 decoder: Dose prediction decoder (4 upsampling operations with dense convolutions and skip connections)
  - Task 2 decoder: CT reconstruction decoder (4 upsampling operations with dense convolutions and skip connections)
  - Outputs: Predicted dose distribution, reconstructed CT scan
  - Loss functions: Sum of dose prediction MSE and CT reconstruction MSE

- Critical path:
  - Input → Encoder → Bottleneck → Two parallel decoders (dose prediction and CT reconstruction) → Two outputs with separate MSE losses summed for training

- Design tradeoffs:
  - Adding reconstruction branch increases model complexity and memory usage but enables direct uncertainty estimation
  - Using dense connections improves feature reuse but increases memory requirements
  - Training with both tasks simultaneously may cause interference but saves computation time

- Failure signatures:
  - Poor dose prediction performance after adding reconstruction branch (indicates interference)
  - Low correlation between reconstruction error and prediction error (indicates reconstruction is not capturing relevant uncertainty)
  - Poor OOD detection performance (indicates reconstruction error is not sensitive to distributional shift)

- First 3 experiments:
  1. Train model with only dose prediction branch, then with both branches, compare dose prediction performance using DVH metrics
  2. Compute Pearson correlation between reconstruction error and prediction error on ID test data, compare with MCDO and DE
  3. Test model on OOD data (different tumor sites), compare histograms and Z-scores of reconstruction error versus MCDO and DE uncertainty metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the input reconstruction method work for regression tasks with different loss functions, such as Dice or cross-entropy?
- Basis in paper: [explicit] The paper mentions that the method has only been investigated for regression tasks using MSE loss, and suggests it would be interesting to explore its behavior with other loss functions.
- Why unresolved: The current study only applied the method to dose prediction with MSE loss, so its performance with other loss functions remains unknown.
- What evidence would resolve it: Testing the method on regression tasks with different loss functions (e.g., Dice or cross-entropy) and comparing its performance to state-of-the-art methods.

### Open Question 2
- Question: Can the input reconstruction method be extended to tasks other than regression, such as segmentation or detection?
- Basis in paper: [explicit] The paper suggests that the technique could be investigated for other U-Net like architectures like segmentation or detection in the future.
- Why unresolved: The current study only applied the method to a regression task (dose prediction), so its effectiveness for other tasks is yet to be determined.
- What evidence would resolve it: Applying the method to segmentation or detection tasks and evaluating its performance compared to existing uncertainty estimation techniques.

### Open Question 3
- Question: Is there a relationship between the high uncertainty predicted by the input reconstruction method and the distance between ID and OOD tumor locations?
- Basis in paper: [explicit] The paper observes that the patient with the lowest CT reconstruction MSE value from the OOD dataset is a patient with a centered tumor site, while the furthest apart has a tumor in the lowest part of the larynx, suggesting a connection between high uncertainty and distance between ID and OOD tumor location.
- Why unresolved: The current study only examined a limited number of OOD patients, so a more comprehensive analysis is needed to confirm this observation.
- What evidence would resolve it: Conducting a larger study with more OOD patients and analyzing the relationship between the predicted uncertainty and the distance between ID and OOD tumor locations.

## Limitations
- The method's effectiveness depends on the assumption that CT reconstruction error is a reliable surrogate for model uncertainty, which may not hold for all regression tasks
- The computational overhead of adding a reconstruction branch increases model complexity and memory requirements, though less than multiple inference passes
- Performance depends on the diversity and representativeness of training data, potentially struggling with highly heterogeneous out-of-distribution cases

## Confidence

- **High Confidence:** The computational efficiency advantage of the proposed method compared to Monte Carlo dropout and Deep ensembles is well-supported by the architecture design and theoretical analysis
- **Medium Confidence:** The correlation between reconstruction error and prediction error (0.620 Pearson coefficient) is demonstrated on the specific dataset but may not generalize to all regression tasks or medical imaging applications
- **Medium Confidence:** The out-of-distribution detection capability (Z-score of 34.05) is impressive but depends on the specific choice of OOD data (different tumor sites) and may vary with different distributional shifts

## Next Checks

1. Test the method on a regression task with different input modalities (e.g., MRI reconstruction) to verify the generalizability of reconstruction error as an uncertainty surrogate
2. Analyze the impact of bottleneck representation quality on both reconstruction accuracy and uncertainty estimation by varying the encoder depth or using different bottleneck architectures
3. Evaluate the method's performance on OOD data with varying degrees of distributional shift to establish the limits of its out-of-distribution detection capability