---
ver: rpa2
title: Proving Test Set Contamination in Black Box Language Models
arxiv_id: '2310.17623'
source_url: https://arxiv.org/abs/2310.17623
tags:
- test
- contamination
- language
- dataset
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We develop a statistical test for detecting test set contamination
  in black-box language models by leveraging the exchangeability property of datasets.
  The core idea is that if a language model has seen a dataset during training, it
  will assign higher likelihood to the canonical ordering compared to random permutations
  of the dataset.
---

# Proving Test Set Contamination in Black Box Language Models

## Quick Facts
- arXiv ID: 2310.17623
- Source URL: https://arxiv.org/abs/2310.17623
- Authors: 
- Reference count: 28
- Primary result: Developed statistical test detecting test set contamination in black-box language models by comparing canonical vs shuffled dataset orderings

## Executive Summary
This paper introduces a statistical methodology for detecting test set contamination in black-box language models without requiring access to training data. The core insight leverages exchangeability: if a model has seen a dataset during training, it assigns higher likelihood to the canonical ordering compared to random permutations. The authors implement this through a sharded approach that partitions datasets into contiguous shards, compares canonical vs shuffled orderings within each shard, and aggregates results using a t-test. Applied to five popular language models, the test found little evidence of pervasive contamination, with only one potential case in Mistral.

## Method Summary
The method partitions a dataset into r contiguous shards and, for each shard, computes the log-likelihood of the canonical ordering versus the average log-likelihood over r random permutations. These differences are aggregated across shards using a t-test to produce a p-value indicating contamination evidence. The approach enables third-party audits without training data access and provides provable false-positive rate guarantees under exchangeability assumptions.

## Key Results
- Test reliably detects contamination for datasets appearing as few as 2-10 times in pretraining data
- Requires as few as 1000 examples for detection
- Applied to five popular models with little evidence of pervasive contamination
- Only one potential contamination case found in Mistral model
- Detection threshold around duplication rate of 4

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Test set contamination is detected when a model assigns significantly higher likelihood to the canonical ordering of an exchangeable dataset than to random permutations.
- Mechanism: Under the null hypothesis of no contamination, exchangeable datasets have the property that all orderings are equally likely, meaning log pθ(seq(X)) = log pθ(seq(Xπ)) in distribution. Contamination violates this by memorizing the canonical order, creating a systematic likelihood gap.
- Core assumption: The dataset is exchangeable (i.e., the joint distribution is invariant to permutations of examples).
- Evidence anchors:
  - [abstract] "Our approach leverages the fact that when there is no data contamination, all orderings of an exchangeable benchmark should be equally likely."
  - [section 2] "Proposition 1... For an exchangeable dataset X and under H0, log pθ(seq(X)) = log pθ(seq(Xπ))."
  - [corpus] Weak: No direct evidence that datasets used in evaluation are exchangeable; requires manual inspection.
- Break condition: The dataset contains non-exchangeable elements (e.g., sequential indices, duplicates) or the model memorizes arbitrary permutations instead of the canonical order.

### Mechanism 2
- Claim: The sharded test converts a single difficult-to-compute permutation test into a collection of independent log-likelihood comparisons.
- Mechanism: The dataset is partitioned into shards; within each shard, the model's likelihood on the canonical order is compared to the average likelihood over many random permutations. These differences are aggregated via a t-test, improving sensitivity and avoiding the computational bottleneck of testing all permutations.
- Core assumption: Each shard contains enough examples for the t-test to be valid and the shards are independent.
- Evidence anchors:
  - [section 3.2] "We will partition the examples X1, ··· , Xn into r contiguous shards... and compare the likelihood of the canonical ordering to a Monte Carlo estimate of the average likelihood of the shuffled ordering."
  - [section 4.2] Empirical results show stable p-values for shard counts between 10-20, with diminishing returns beyond 25 permutations per shard.
  - [corpus] Weak: No direct evidence that shards are independent; relies on theoretical assumptions.
- Break condition: Shards are too small (fewer than 10 examples) or the model's likelihood is insensitive to order within shards.

### Mechanism 3
- Claim: The statistical test provides provable false-positive rate guarantees under the null hypothesis of no contamination.
- Mechanism: Under H0, the log-likelihood differences are zero-mean and the shard statistics are independent, so the t-test has an asymptotic false-positive rate bounded by α. This allows third-party audits without access to training data.
- Core assumption: The model and dataset are independent under H0 and the log-likelihoods have finite second moments.
- Evidence anchors:
  - [section 2] "This setting mirrors many common situations with API-based model providers... matches an increasing trend where the training data is kept secret."
  - [section 3.2] "Theorem 2. Under the null hypothesis... P(p < α) - α → 0 as m → ∞."
  - [corpus] Weak: The theorem is asymptotic; finite-sample guarantees would require additional Berry-Esseen bounds.
- Break condition: The model and dataset are not independent under H0 (e.g., encrypted contamination) or the log-likelihoods have infinite variance.

## Foundational Learning

- Concept: Exchangeability of datasets
  - Why needed here: The test relies on the property that under H0, all permutations of an exchangeable dataset are equally likely under the model. This allows the comparison of canonical vs. shuffled orderings.
  - Quick check question: If a dataset is exchangeable, what is the distribution of log pθ(seq(X)) under H0 for any permutation π?

- Concept: Permutation tests and p-value calculation
  - Why needed here: The test is fundamentally a permutation test, comparing the likelihood of the canonical ordering to that of many shuffled versions. Understanding how p-values are computed and corrected (e.g., for finite samples) is critical.
  - Quick check question: In a permutation test, what is the minimum p-value achievable with m permutations?

- Concept: Central limit theorem and t-tests
  - Why needed here: The sharded test aggregates shard-level statistics via a t-test, relying on the CLT to justify the asymptotic normality of the mean difference.
  - Quick check question: What conditions must hold for the CLT to apply to the shard-level statistics?

## Architecture Onboarding

- Component map: Dataset X -> Partition into shards -> Compute canonical log-likelihoods -> Compute shuffled log-likelihoods -> Aggregate differences -> t-test -> p-value
- Critical path:
  1. Partition dataset into shards
  2. For each shard, compute canonical log-likelihood
  3. For each shard, compute average shuffled log-likelihood via Monte Carlo
  4. Compute shard-level differences and aggregate via t-test
  5. Return p-value and interpretation
- Design tradeoffs:
  - Shard count: Too few shards → insufficient power; too many → each shard has too few examples
  - Permutation count: Too few → noisy estimate of average shuffled likelihood; too many → unnecessary compute
  - Dataset size: Large datasets → truncate for efficiency; small datasets → may lack power
- Failure signatures:
  - High p-values across models → likely no contamination or test lacks power
  - Low p-values for negative controls → dataset likely not exchangeable
  - Numerical underflow in log-likelihoods → need to use log-sum-exp or higher precision
- First 3 experiments:
  1. Run test on a known contaminated model (e.g., 1.4B model with canaries at duplication count 10) to verify detection
  2. Run test on a negative control (e.g., BioMedLM) to verify no false positives
  3. Vary shard and permutation counts to identify optimal hyperparameters for a given dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the minimum duplication rate required for reliable detection of test set contamination?
- Basis in paper: [explicit] The paper finds that the detection threshold is around a duplication rate of 4, but cannot reliably detect duplication rates of 1.
- Why unresolved: The paper's experiments show a gap between duplication rates of 1 (undetectable) and 4 (reliably detectable), leaving uncertainty about the exact threshold.
- What evidence would resolve it: Conducting experiments with duplication rates between 1 and 4 (e.g., 2, 3) to pinpoint the exact minimum detectable rate.

### Open Question 2
- Question: How does the sharded test's power compare to the permutation test for detecting contamination at low duplication rates?
- Basis in paper: [explicit] The paper mentions that the sharded test attains comparable performance to the permutation test for benchmarks with small duplication rates, but does not provide a direct comparison of their power.
- Why unresolved: The paper does not explicitly compare the statistical power of the sharded test and permutation test for detecting contamination at low duplication rates.
- What evidence would resolve it: Conducting a head-to-head comparison of the sharded test and permutation test on datasets with varying duplication rates, measuring their detection rates and p-values.

### Open Question 3
- Question: Can the sharded test reliably detect contamination when the dataset is not perfectly exchangeable?
- Basis in paper: [inferred] The paper acknowledges that real-world datasets may contain non-exchangeable elements, and uses a negative control (BioMedLM) to check for these elements. However, it does not directly test the impact of non-exchangeability on the sharded test's performance.
- Why unresolved: The paper's theoretical guarantees assume perfect exchangeability, but real-world datasets may deviate from this assumption. The impact of this deviation on the test's reliability is unknown.
- What evidence would resolve it: Conducting experiments where the sharded test is applied to datasets with known non-exchangeable elements, measuring its false positive and false negative rates.

## Limitations
- Exchangeability assumption: Test relies on datasets being perfectly exchangeable, but real-world datasets may contain non-exchangeable elements like sequential indices or duplicates.
- Finite-sample guarantees: Asymptotic false-positive rate control lacks empirical validation for the finite sample sizes used in experiments.
- Contamination pattern sensitivity: Test may miss non-canonical contamination patterns such as partial memorization or encrypted contamination.

## Confidence
- High confidence: Theoretical framework for detecting canonical-order memorization is sound with mathematically proven asymptotic guarantees
- Medium confidence: Test successfully detects contamination in controlled experiments but sensitivity thresholds may not generalize
- Low confidence: Absence of evidence for pervasive contamination should not be interpreted as evidence of absence due to potential power limitations

## Next Checks
1. Systematically test the statistical test on datasets with known non-exchangeable structures to quantify false-positive rates in edge cases
2. Conduct extensive simulations varying shard counts (5-50), permutation counts (10-1000), and dataset sizes to empirically calibrate the test's false-positive rate and power
3. Design controlled experiments with various contamination patterns (partial memorization, random-order memorization, encrypted contamination) to map the test's detection boundaries and identify potential blind spots