---
ver: rpa2
title: 3D molecule generation by denoising voxel grids
arxiv_id: '2306.07473'
source_url: https://arxiv.org/abs/2306.07473
tags:
- molecules
- molecule
- latexit
- samples
- molecular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces VoxMol, a novel score-based approach for
  3D molecule generation using voxelized atomic densities. Unlike current state-of-the-art
  methods that use diffusion models on atom point clouds, VoxMol represents molecules
  as continuous atomic densities on regular voxel grids.
---

# 3D molecule generation by denoising voxel grids

## Quick Facts
- arXiv ID: 2306.07473
- Source URL: https://arxiv.org/abs/2306.07473
- Reference count: 40
- This paper introduces VoxMol, a novel score-based approach for 3D molecule generation using voxelized atomic densities

## Executive Summary
This paper introduces VoxMol, a novel score-based approach for 3D molecule generation using voxelized atomic densities. Unlike current state-of-the-art methods that use diffusion models on atom point clouds, VoxMol represents molecules as continuous atomic densities on regular voxel grids. The method trains a denoising neural network to map from noisy molecular distributions to real molecules, then generates molecules using a neural empirical Bayes framework: sampling noisy density grids via underdamped Langevin MCMC and recovering clean molecules through single-step denoising. VoxMol achieves comparable results to state-of-the-art methods on unconditional 3D molecule generation benchmarks (QM9 and GEOM-drugs datasets) while being simpler to train and faster to generate samples.

## Method Summary
VoxMol trains a 3D U-Net denoising network on pairs of noisy and clean voxelized molecular density grids. The voxelization process converts atomic positions and types into continuous density fields using Gaussian kernels. For generation, the method samples from a smooth density distribution using underdamped Langevin MCMC, then applies single-step denoising to recover clean molecular structures. The denoised voxel grids are processed through peak detection and gradient refinement to extract atomic coordinates, which are validated and converted to SMILES strings using RDKit. The entire pipeline avoids requiring prior knowledge of atom count and treats all molecular features within the same voxelized representation.

## Key Results
- Achieves comparable results to state-of-the-art methods on unconditional 3D molecule generation benchmarks
- Demonstrates validity rates comparable to point-cloud diffusion methods while being faster to train and generate samples
- Shows that single-step denoising is sufficient to reconstruct voxelized molecules from noisy inputs
- Successfully generates molecules from both QM9 and GEOM-drugs datasets without requiring atom count conditioning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Denoising a voxelized molecular density grid recovers the underlying molecule structure with a single network step.
- **Mechanism**: The model trains a 3D U-Net to predict clean voxel densities from noisy inputs. Because the noise is isotropic Gaussian, the denoising operation approximates the gradient of the log-density (score function). This allows the model to map from a smooth, high-entropy distribution back to the low-entropy true distribution in one pass.
- **Core assumption**: The smooth/noisy distribution is close enough to the true distribution that a single denoising step suffices for reasonable molecular recovery.
- **Evidence anchors**:
  - [abstract] "recover the 'clean' molecule by denoising the noisy grid with a single step"
  - [section] "single-step denoising is sufficient to reconstruct voxelized molecules"
  - [corpus] Missing direct comparison of single-step vs iterative denoising; weak evidence
- **Break condition**: If the noise level is too low (hard to sample) or too high (information loss), the one-step assumption fails.

### Mechanism 2
- **Claim**: Langevin MCMC sampling on the smooth distribution yields diverse molecular samples that the denoising step can then clean.
- **Mechanism**: The walk step explores the noisy density space via underdamped Langevin dynamics. Because the noise adds isotropy, the walk explores smoothly without the rigid atom count constraints of point-cloud diffusion. The jump step then projects back to clean molecules.
- **Core assumption**: The smooth density is easier to sample than the true density, and MCMC chains mix well on it.
- **Evidence anchors**:
  - [abstract] "sample noisy density grids from a smooth distribution via underdamped Langevin MCMC"
  - [section] "it is much easier to sample from the smooth density than the original distribution"
  - [corpus] Limited direct evidence of MCMC mixing quality; mostly inferred from validation
- **Break condition**: Poor mixing or high autocorrelation in the MCMC walk would yield low diversity or biased samples.

### Mechanism 3
- **Claim**: Voxelizing molecules into fixed grids avoids needing atom-count conditioning and treats all features homogeneously.
- **Mechanism**: By encoding atoms as continuous densities across all grid channels, the model learns a single score function over a fixed-dimensional space. No atom count prediction, no separate treatment of discrete vs continuous features.
- **Core assumption**: The continuous density representation preserves enough structure to recover discrete atomic identities and positions.
- **Evidence anchors**:
  - [abstract] "does not require prior knowledge of atom count and treats all features within the same voxelized representation"
  - [section] "we only use the 'raw' voxelized molecule"
  - [corpus] No explicit ablation of atom count conditioning; inferred from comparison with point-cloud methods
- **Break condition**: If the voxel resolution is too coarse, the continuous approximation breaks and atomic identities become ambiguous.

## Foundational Learning

- **Concept**: 3D Gaussian atomic density fields as a molecular representation
  - **Why needed here**: Enables continuous, differentiable encoding of molecules into fixed-size voxel grids, simplifying generative modeling.
  - **Quick check question**: How do we compute voxel occupancy from atomic positions and radii?

- **Concept**: Score-based generative modeling via denoising score matching
  - **Why needed here**: Provides a principled way to train a network to estimate the gradient of log-density without knowing the true distribution.
  - **Quick check question**: Why does denoising with Gaussian noise yield an estimate of the score function?

- **Concept**: Walk-jump sampling in the neural empirical Bayes framework
  - **Why needed here**: Allows sampling from a smoothed distribution via MCMC and then projecting back to the true data manifold in one step.
  - **Quick check question**: What trade-off does the noise level σ control in walk-jump sampling?

## Architecture Onboarding

- **Component map**: Voxelization pipeline (PyUUL → Gaussian density grids) -> 3D U-Net denoising network (encoder-decoder + self-attention) -> MCMC sampler (underdamped Langevin with discretization) -> Peak detection + gradient refinement (extract coordinates from voxels) -> RDKit post-processing (connectivity, SMILES, validation)
- **Critical path**: Voxelization → Denoising network training → MCMC sampling → Coordinate extraction → RDKit validation
- **Design tradeoffs**:
  - Fixed grid size vs flexibility in molecule size
  - Single-step denoising vs multi-step refinement
  - Resolution vs memory/computation
  - Isotropic Gaussian noise vs structured noise
- **Failure signatures**:
  - Low validity: denoising fails to recover plausible geometries
  - Low uniqueness: mode collapse or poor MCMC mixing
  - High TV metrics: poor distribution matching
  - High computational cost: slow MCMC or large voxel grids
- **First 3 experiments**:
  1. Train denoising U-Net on synthetic noisy/voxel pairs; measure L2 reconstruction loss.
  2. Run MCMC walk on trained model; check diversity and mixing visually.
  3. Extract coordinates from generated voxels; validate with RDKit and compare to ground truth distributions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would VoxMol's performance change if it incorporated equivariant 3D convolutional networks instead of standard 3D convolutions?
- Basis in paper: [inferred] The paper explicitly mentions that VoxMol does not use equivariant networks while comparing to point cloud methods that do, noting "We observe empirically that single-step denoising is sufficient to reconstruct voxelized molecules... Our hypothesis is that is due to the nature of the voxel signals, which contains much more 'structure' than 'texture' information." The authors also state "We made an attempt at using an equivariant 3D convolutional network for denoising, but initial experiments were not successful. We believe, however, our results could likely be improved with further development of equivariant architectures."
- Why unresolved: The authors only attempted equivariant architectures and found them unsuccessful, but suggest this could be due to the architecture choice rather than fundamental limitations. They don't provide evidence that equivariant networks wouldn't improve performance.
- What evidence would resolve it: A systematic comparison between VoxMol with standard convolutions versus VoxMol with different equivariant 3D convolutional architectures (SE(3)-equivariant, E(3)-equivariant, etc.) on the same datasets and metrics would determine if equivariance provides performance benefits.

### Open Question 2
- Question: What is the theoretical relationship between noise level σ and optimal sampling step size δ in VoxMol's walk-jump sampling?
- Basis in paper: [explicit] The paper discusses the trade-off between noise level and sampling quality, stating "If the noise is low, denoising (jump step) becomes easier, with lower variance, while sampling a 'less smooth' p(y) (walk step) becomes harder. If the noise is high, the opposite is true." However, it doesn't provide a theoretical framework for how σ and δ should be jointly optimized.
- Why unresolved: While the paper empirically explores different noise levels and step sizes, it doesn't establish a theoretical connection between these hyperparameters or provide a principled method for selecting them together.
- What evidence would resolve it: A theoretical analysis deriving the optimal relationship between σ and δ based on convergence rates of the underdamped Langevin MCMC, or an empirical study systematically varying both parameters together to find their joint optimal values.

### Open Question 3
- Question: How does VoxMol's performance scale with grid resolution, and what is the optimal resolution for different molecular sizes?
- Basis in paper: [inferred] The paper uses fixed resolutions (32³ for QM9, 64³ for GEOM-drugs) and mentions "We use grids of dimension 32³ and 64³ for QM9 and GEOM-drugs respectively. These volumes are able to cover over 99% of all points on both datasets." However, it doesn't explore how performance changes with different resolutions or whether resolution should scale with molecular size.
- Why unresolved: The paper doesn't systematically study the effect of grid resolution on generation quality, validity, uniqueness, or other metrics. The chosen resolutions appear to be practical choices rather than optimal ones determined through experimentation.
- What evidence would resolve it: A comprehensive study varying grid resolution (e.g., 16³, 32³, 64³, 128³) for molecules of different sizes, measuring generation quality metrics and computational cost to determine optimal resolution as a function of molecular size.

### Open Question 4
- Question: Can VoxMol's denoising network be trained to predict atom counts explicitly, and would this improve generation quality?
- Basis in paper: [inferred] The paper highlights as an advantage that "VoxMol does not require knowing the number of atoms beforehand (neither for training nor sampling)" and shows in Figure 4 that it learns the approximate distribution of atom counts. However, it doesn't explore whether explicitly predicting atom counts would improve performance.
- Why unresolved: While the paper treats atom count as an implicit output that emerges from the denoising process, it doesn't investigate whether explicitly modeling atom count as a separate prediction task would yield better results.
- What evidence would resolve it: An experiment comparing VoxMol's current approach with a modified version that includes atom count prediction (either as a separate head or incorporated into the denoising objective) and measuring the impact on generation quality metrics.

### Open Question 5
- Question: What is the impact of the initial noise distribution on VoxMol's sampling efficiency and quality?
- Basis in paper: [explicit] The paper states "We follow [27] and initialize the chains by adding uniform noise to the initial Gaussian noise (with the same σ used during training), i.e., y0 = N(0,σ²I_d) + U_d(0,1) (this was observed to mix faster in practice)." However, it doesn't systematically explore different initialization strategies or their effects.
- Why unresolved: The paper only mentions one initialization strategy (Gaussian plus uniform noise) and notes it mixes faster "in practice" without comparing to alternatives or providing theoretical justification for why this initialization is optimal.
- What evidence would resolve it: A systematic comparison of different initialization strategies (pure Gaussian, Gaussian plus uniform noise, structured noise patterns, samples from the training distribution, etc.) measuring their impact on sampling efficiency (mixing time, number of steps needed) and generation quality.

## Limitations

- Single-step denoising assumption lacks direct empirical validation against multi-step approaches
- Fixed voxel resolution may lose fine molecular details and limit scalability to larger molecules
- Limited evidence of MCMC mixing quality and exploration of the full molecular space

## Confidence

**High confidence**: The denoising network architecture and training procedure are clearly specified and align with established score-based generative modeling techniques. The voxelization approach using PyUUL is standard practice.

**Medium confidence**: The walk-jump sampling framework is theoretically sound, but the practical implementation details and their impact on sample quality need more thorough validation. The performance comparisons to state-of-the-art methods are reasonable but could be strengthened.

**Low confidence**: The claim that single-step denoising is sufficient for accurate molecular reconstruction is the weakest point, as it lacks direct experimental validation.

## Next Checks

1. **Single-step vs multi-step denoising ablation**: Generate molecules using both single-step and multi-step denoising with the same trained model, comparing validity, uniqueness, and reconstruction fidelity to ground truth molecules.

2. **Voxel resolution sensitivity analysis**: Train models with varying voxel resolutions (e.g., 0.2Å, 0.3Å, 0.4Å) and evaluate how resolution impacts validity, uniqueness, and the ability to capture fine molecular features like aromatic ring systems.

3. **MCMC mixing diagnostics**: Compute autocorrelation metrics and effective sample size for the underdamped Langevin chains, and visualize the sampling trajectories to assess whether the chains are exploring the full molecular space or getting stuck in local modes.