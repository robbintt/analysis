---
ver: rpa2
title: Fair Wasserstein Coresets
arxiv_id: '2311.05436'
source_url: https://arxiv.org/abs/2311.05436
tags:
- dataset
- fair
- k-means
- wasserstein
- original
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Fair Wasserstein Coresets (FWC), a novel approach
  for generating fair and representative synthetic samples for downstream learning
  tasks. FWC aims to minimize the Wasserstein distance between the original dataset
  and the weighted synthetic samples while enforcing demographic parity via linear
  constraints.
---

# Fair Wasserstein Coresets

## Quick Facts
- arXiv ID: 2311.05436
- Source URL: https://arxiv.org/abs/2311.05436
- Reference count: 40
- One-line primary result: FWC achieves competitive fairness-utility tradeoff, improves downstream fairness, and reduces biases in LLM predictions while maintaining distributional fidelity.

## Executive Summary
Fair Wasserstein Coresets (FWC) is a novel approach for generating fair and representative synthetic samples for downstream learning tasks. It minimizes the Wasserstein distance between the original dataset and weighted synthetic samples while enforcing demographic parity through linear constraints. The method is theoretically grounded, showing equivalence to Lloyd's algorithm for k-medians and k-means clustering when unconstrained. Experiments demonstrate that FWC achieves competitive performance compared to existing approaches, improves downstream fairness when added to training data, and can reduce biases in predictions from large language models.

## Method Summary
FWC generates fair and representative synthetic samples by minimizing the Wasserstein distance between the original dataset and weighted synthetic samples while enforcing demographic parity via linear constraints. The method reformulates the optimization into a continuous non-convex problem solvable via majority minimization. Without fairness constraints, FWC reduces to Lloyd's algorithm for k-means and k-medians clustering. The approach involves iteratively updating feature vectors of coresets and solving linear programs for optimal transport, with runtime scaling cubically with the coreset size m.

## Key Results
- FWC achieves competitive fairness-utility tradeoff compared to existing approaches
- Improves downstream fairness when added to training data
- Can reduce biases in predictions from large language models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FWC uses Wasserstein distance to preserve distributional fidelity while enforcing fairness.
- Mechanism: The Wasserstein distance provides a bound on the deviation of downstream model performance, ensuring that the compressed coreset maintains the statistical properties of the original dataset. Simultaneously, linear constraints enforce demographic parity by controlling the conditional distributions across sensitive subgroups.
- Core assumption: The 1-Wasserstein distance is equivalent to the supremum deviation over Lipschitz functions, making it suitable for bounding downstream learning performance.
- Evidence anchors:
  - [abstract] FWC aims to minimize the Wasserstein distance between the original datasets and the weighted synthetic samples while enforcing (an empirical version of) demographic parity.
  - [section] When compared against current approaches, FWC achieves competitive performance, even when we enhance the fairness of existing approaches using existing fair pre-processing techniques.

### Mechanism 2
- Claim: FWC reformulates the optimization into a continuous non-convex problem solvable via majority minimization.
- Mechanism: By introducing artificial variables and simplifying constraints, the problem is reduced to optimizing over synthetic features and weights. Majority minimization iteratively improves a convex upper bound of the objective until convergence.
- Core assumption: The objective function F(C) is concave and continuous in the cost matrix C, allowing for the application of subgradient methods.
- Evidence anchors:
  - [section] The problem in Equation (3.8) is a huge-scale linear program... Its size becomes computationally prohibitive for large values of n and m.
  - [section] We define a surrogate function that upper bounds the objective function, so that optimizing the surrogate function improves the objective function.

### Mechanism 3
- Claim: Without fairness constraints, FWC reduces to Lloyd's algorithm for k-means and k-medians clustering.
- Mechanism: In the unconstrained version, the optimal assignment matrix P* assigns each original point to its nearest synthetic representative. This is equivalent to the partitioning step in Lloyd's algorithm.
- Core assumption: The cost function c(Z,bZ) is either the squared Euclidean distance (for k-means) or the Manhattan distance (for k-medians).
- Evidence anchors:
  - [section] Lloyd's algorithm iteratively computes the centroid for each subset in the partition and subsequently re-partitions the input based on the closeness to these centroids; these are the same operations FWC does in optimizing the surrogate function and solving problem 3.8.
  - [section] Thus, when c(x, y) is correspondingly defined as ∥x − y∥1 or ∥x − y∥2 2, FWC corresponds to Lloyd's algorithm applied to k-medians or k-means problems.

## Foundational Learning

- Concept: Optimal Transport and Wasserstein Distance
  - Why needed here: FWC relies on minimizing the Wasserstein distance to preserve distributional properties between the original dataset and the synthetic coreset.
  - Quick check question: What property of the Wasserstein distance makes it suitable for bounding downstream learning performance?

- Concept: Linear Programming and Duality
  - Why needed here: The fairness constraints are formulated as linear inequalities, and the Wasserstein distance is expressed as a linear program, which are essential for the optimization process.
  - Quick check question: How are the demographic parity constraints reformulated as linear constraints on the weights?

- Concept: Clustering Algorithms (k-means, k-medians)
  - Why needed here: Understanding that FWC without fairness constraints is equivalent to Lloyd's algorithm for clustering helps in grasping the method's versatility.
  - Quick check question: How does the assignment matrix P* in the unconstrained FWC correspond to the partitioning step in Lloyd's algorithm?

## Architecture Onboarding

- Component map: Synthetic sample generator -> Weight assignment module -> Optimization engine -> Evaluation module
- Critical path: 1. Initialize synthetic features and weights. 2. Compute cost matrix and solve for optimal assignment P*. 3. Update synthetic features using the surrogate function. 4. Iterate until convergence or stopping criteria met.
- Design tradeoffs:
  - Fairness vs. utility: Stricter fairness constraints may reduce the coreset's representativeness.
  - Computational cost: Larger datasets and coresets increase runtime but improve approximation.
  - Choice of distance metric: Different cost functions affect clustering equivalence and fairness enforcement.
- Failure signatures:
  - Non-convergence: Majority minimization may fail if the objective is not concave or continuous.
  - Poor fairness-utility tradeoff: Imbalance in constraint satisfaction leads to suboptimal coresets.
  - High computational cost: Inefficient handling of large-scale datasets or coresets.
- First 3 experiments:
  1. Test runtime scalability with increasing dataset size (n) and coreset size (m).
  2. Verify clustering equivalence by running FWC without fairness constraints and comparing to k-means/k-medians.
  3. Assess fairness-utility tradeoff on a synthetic dataset with known backdoor dependencies.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of FWC change when using other fairness metrics beyond demographic parity, such as equalized odds or disparate impact?
- Basis in paper: [explicit] The authors mention that future work could incorporate other fairness metrics and constraints to address different aspects of fairness.
- Why unresolved: The paper only evaluates FWC using demographic parity as the fairness criterion, leaving the performance with other metrics unexplored.
- What evidence would resolve it: Conducting experiments comparing FWC's performance when using different fairness metrics on the same datasets would provide evidence on its generalizability to other fairness notions.

### Open Question 2
- Question: How does the runtime of FWC scale with larger datasets containing millions of samples and higher dimensional feature spaces?
- Basis in paper: [inferred] The paper shows runtime analysis for datasets up to 50,000 samples with 25 features, but does not explore larger scale scenarios.
- Why unresolved: The computational complexity of FWC for very large-scale datasets is unknown, which is important for practical applicability.
- What evidence would resolve it: Running FWC on datasets with millions of samples and higher dimensional features while measuring runtime would provide empirical evidence on scalability.

### Open Question 3
- Question: Can FWC be extended to handle continuous protected attributes rather than just discrete ones?
- Basis in paper: [inferred] The paper uses discrete protected attributes like gender and race, but does not address continuous protected attributes.
- Why unresolved: Real-world datasets may contain continuous sensitive attributes, and it's unclear how FWC would handle such cases.
- What evidence would resolve it: Implementing and evaluating FWC on datasets with continuous protected attributes would demonstrate its ability to handle such scenarios.

## Limitations
- The computational complexity of majority minimization scales cubically with coreset size m, potentially limiting scalability.
- The method's performance on high-dimensional and mixed continuous-discrete feature spaces is unclear.
- The paper focuses on demographic parity, leaving the effectiveness of other fairness metrics unexplored.

## Confidence
- Theoretical foundation: High
- Empirical validation on synthetic datasets: Medium
- Empirical validation on real-world datasets: Medium
- Scalability to large-scale problems: Low
- Applicability to diverse fairness metrics: Low

## Next Checks
1. **Scalability Test**: Evaluate FWC's runtime performance on datasets with n > 100,000 and m > 1,000 to verify the claimed cubic complexity and identify potential bottlenecks in the majority minimization algorithm.
2. **Robustness Analysis**: Test FWC on datasets with high-dimensional features (d > 100) and mixed continuous-discrete attributes to assess the impact of non-smooth optimization and determine practical limitations on feature space complexity.
3. **Cross-Domain Generalization**: Apply FWC to diverse domains beyond the current focus areas (text classification, clustering) such as tabular data with many categorical variables or time series data to evaluate the method's versatility and identify domain-specific challenges.