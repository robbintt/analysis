---
ver: rpa2
title: Tertiary Lymphoid Structures Generation through Graph-based Diffusion
arxiv_id: '2310.06661'
source_url: https://arxiv.org/abs/2310.06661
tags:
- diffusion
- data
- cell-graphs
- graph
- real
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a graph-based diffusion model for generating
  cell-graphs with high and low tertiary lymphoid structure (TLS) content. The model,
  based on DiGress, is trained on actual TLS cell-graphs and generates synthetic cell-graphs
  that capture the underlying distribution.
---

# Tertiary Lymphoid Structures Generation through Graph-based Diffusion

## Quick Facts
- **arXiv ID**: 2310.06661
- **Source URL**: https://arxiv.org/abs/2310.06661
- **Reference count**: 31
- **Key outcome**: Graph-based diffusion model (DiGress) generates synthetic cell-graphs capturing TLS distribution; outperforms baseline in TLS classification task.

## Executive Summary
This paper proposes a graph-based diffusion model for generating cell-graphs with high and low tertiary lymphoid structure (TLS) content. The model, based on DiGress, is trained on actual TLS cell-graphs and generates synthetic cell-graphs that capture the underlying distribution. Evaluation metrics show that the generated cell-graphs are more similar to real TLS cell-graphs than those generated by a non-deep learning baseline. The generated cell-graphs are also shown to be useful for data augmentation in a TLS content classification task, leading to improved performance.

## Method Summary
The method leverages DiGress, a discrete denoising diffusion probabilistic model adapted for graphs, to generate synthetic cell-graphs. It trains separate models on datasets of low and high TLS content graphs, using TLS embeddings (κ metric) to quantify B-cell cluster organization. Generated graphs are evaluated via distributional similarity metrics (KS test, Wasserstein distance, etc.) and tested for utility in augmenting a TLS classification task with a GCN classifier.

## Key Results
- DiGress-generated cell-graphs have TLS embedding distributions closer to real TLS graphs than a non-deep learning baseline.
- Data augmentation with DiGress-generated graphs improves TLS classification AUROC compared to training without augmentation.
- The generative models maintain biologically meaningful TLS structure in synthetic samples.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph-based diffusion models can capture higher-order dependencies in cell-graphs beyond simple 1-hop relationships.
- Mechanism: DiGress models node and edge transitions through categorical distributions, iteratively corrupting and denoising cell-graphs. This enables modeling of multi-hop structural patterns like B-cell clusters surrounded by T-cells in TLS.
- Core assumption: The forward and reverse processes preserve the biologically meaningful graph structure and can learn from sparse labeled data.
- Evidence anchors:
  - [abstract] "we leverage state-of-the-art graph-based diffusion models to generate biologically meaningful cell-graphs"
  - [section] "DiGress, a D3PM adapted for graphs whose nodes and edges have categorical features"
  - [corpus] Weak - related papers focus on RNA or image generation, not TLS or cell-graph structure.
- Break condition: If the diffusion model collapses to generating generic graphs without TLS-specific structure, the method fails.

### Mechanism 2
- Claim: TLS embeddings capture biologically meaningful distinctions between high and low TLS content cell-graphs.
- Mechanism: TLS embeddings use the ratio of γ edges (B-T edges) over α edges (same-type edges) to quantify B-cell cluster organization. This metric is used both to train the generative model and evaluate generated samples.
- Core assumption: The κ(a) metric effectively distinguishes biologically relevant TLS populations and generalizes to synthetic graphs.
- Evidence anchors:
  - [section] "TLS are highly structured biological entities composed of B-cell clusters surrounded by supporting T-cells... Their presence in cell-graphs can be measured through the TLS-like organization metric, κ(a)"
  - [section] "we consider a total of b different cell types... edges longer than 30µm are ignored"
  - [corpus] Weak - no direct evidence from corpus; TLS embeddings are domain-specific.
- Break condition: If the κ(a) metric becomes saturated (e.g., κ(2) ≈ 0 for low TLS), the generative model cannot learn the low-TLS class.

### Mechanism 3
- Claim: Synthetic data augmentation with DiGress-generated cell-graphs improves TLS classification performance.
- Mechanism: Augmenting a small labeled dataset with synthetic cell-graphs drawn from the learned distribution provides regularization and reduces overfitting in the GCN classifier.
- Core assumption: The synthetic graphs are sufficiently faithful to the real distribution to act as useful training samples.
- Evidence anchors:
  - [abstract] "we further illustrate the utility of the learned generative models for data augmentation in a TLS classification task"
  - [section] "We demonstrate that the generated graphs are sufficiently faithful to the real data distribution, leading to improved performance on the downstream classification task"
  - [corpus] Weak - no corpus evidence for this specific augmentation strategy.
- Break condition: If augmentation magnitude exceeds ~5×, performance degrades due to distribution shift.

## Foundational Learning

- Concept: Graph representation learning (GNNs)
  - Why needed here: DiGress uses a GNN to denoise graphs; understanding node/edge embeddings and message passing is critical.
  - Quick check question: How does a GNN propagate information across edges in a cell-graph?
- Concept: Diffusion probabilistic models
  - Why needed here: The paper extends D3PMs to graphs; understanding forward/reverse noise schedules is key.
  - Quick check question: What distinguishes a discrete D3PM from a score-based diffusion model?
- Concept: TLS biology and graph construction
  - Why needed here: The problem is biologically motivated; understanding how cells become nodes and edges represent spatial adjacency is essential.
  - Quick check question: How are B-cells and T-cells spatially organized in a TLS?

## Architecture Onboarding

- Component map: WSI -> cell segmentation -> node/edge features -> graph extraction -> TLS labeling -> DiGress training -> sampling -> TLS embedding evaluation -> augmentation -> GCN training -> test evaluation
- Critical path: Data preprocessing → DiGress training → sampling → TLS embedding evaluation → augmentation → GCN training → test evaluation
- Design tradeoffs:
  - DiGress uses discrete states for scalability vs. continuous score-based models that can be harder to train on graphs
  - TLS embeddings are simple but may miss complex patterns beyond 2-hop neighborhoods
  - Augmentation magnitude must be tuned to avoid distribution shift
- Failure signatures:
  - Generated graphs have uniform structure (e.g., no TLS clusters)
  - TLS embeddings fail to separate high/low classes
  - GCN performance plateaus or degrades with more augmentation
- First 3 experiments:
  1. Train DiGress on D_tls_real and sample 100 graphs; compute TLS embeddings and compare to real data.
  2. Augment a small TLS classifier training set with 2× DiGress-generated graphs; evaluate AUROC.
  3. Replace DiGress with the baseline model; compare TLS embedding distributions and classifier performance.

## Open Questions the Paper Calls Out
None explicitly stated in the provided content.

## Limitations
- Limited comparison to other augmentation strategies (e.g., GANs, VAEs) makes it difficult to isolate the benefit of diffusion models.
- TLS embedding metric, while biologically motivated, is relatively simple and may not capture all relevant structural patterns in cell-graphs.
- Evaluation relies heavily on distributional similarity metrics without examining the structural faithfulness of generated graphs at the node/edge level.

## Confidence
- **High Confidence**: The core mechanism of using DiGress for graph generation and the TLS embedding methodology are well-specified and reproducible. The data augmentation pipeline and evaluation on a downstream classification task are also clearly described.
- **Medium Confidence**: The claim that DiGress-generated graphs are "more similar" to real TLS graphs than a non-deep learning baseline is supported by the presented metrics, but the specific baseline details are limited. The improvement in TLS classification is promising but the magnitude of the effect and its generalizability to other datasets is uncertain.
- **Low Confidence**: The assertion that this approach is "superior" to other graph generation methods for TLS data is not fully substantiated due to the lack of comprehensive comparisons. The long-term stability and robustness of the model to variations in input data are also unclear.

## Next Checks
1. **Ablation on TLS Embedding**: Generate synthetic graphs with DiGress and a simple random graph model. Compute TLS embeddings for both and compare their distributions to the real data using the same metrics (KS, WD, etc.). This will isolate the contribution of the generative model versus the embedding method.
2. **Augmentation Strategy Comparison**: Repeat the TLS classification experiment with two alternative augmentation strategies: (a) standard data augmentation (e.g., random edge/node perturbations) and (b) a GAN-based graph generator. Compare the classification AUROC with DiGress augmentation to determine if the diffusion model provides a unique benefit.
3. **Structural Analysis of Generated Graphs**: Beyond TLS embeddings, analyze the generated graphs for other structural properties: average node degree, clustering coefficient, and motif distribution. Compare these to real TLS graphs to assess whether the model captures the full structural diversity, not just the TLS-specific patterns.