---
ver: rpa2
title: 'GREAT Score: Global Robustness Evaluation of Adversarial Perturbation using
  Generative Models'
arxiv_id: '2304.09875'
source_url: https://arxiv.org/abs/2304.09875
tags:
- robustness
- score
- great
- adversarial
- global
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new method for global robustness evaluation
  of adversarial perturbation using generative models, called GREAT Score. The main
  idea is to use a generative model as a proxy of the true data distribution to estimate
  the mean certified attack-proof perturbation level over all samples.
---

# GREAT Score: Global Robustness Evaluation of Adversarial Perturbation using Generative Models

## Quick Facts
- arXiv ID: 2304.09875
- Source URL: https://arxiv.org/abs/2304.09875
- Reference count: 40
- This paper proposes a new method for global robustness evaluation of adversarial perturbation using generative models, called GREAT Score.

## Executive Summary
This paper introduces GREAT Score, a novel framework for efficiently evaluating the global adversarial robustness of machine learning models. GREAT Score leverages generative models as proxies for true data distributions to estimate mean certified attack-proof perturbation levels across all samples. The method provides a certified lower bound on global robustness while significantly reducing computational costs compared to traditional attack-based evaluation methods. Experimental results demonstrate that GREAT Score achieves high correlation with established robustness rankings while requiring substantially less computation time.

## Method Summary
GREAT Score addresses the challenge of global robustness evaluation by using generative models (GANs or diffusion models) to approximate the true data distribution. The method computes a certified lower bound on the minimal adversarial perturbation for each generated sample using a local robustness score derived from Lipschitz continuity properties. The global robustness estimate is then obtained by taking the mean of these local scores over samples drawn from the generative model. The approach enables efficient black-box evaluation by requiring only model inference on generated data, avoiding computationally expensive adversarial attacks or interval bound propagation.

## Key Results
- GREAT Score achieves Spearman's rank correlation of 0.79-0.86 with RobustBench rankings
- Computational cost is reduced by 25-100× compared to attack-based evaluation
- GREAT Score rankings are consistent with the quality of the underlying generative models
- The method enables efficient remote auditing of privacy-sensitive black-box models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GREAT Score uses a generative model to estimate the true data distribution, enabling global robustness evaluation without adversarial attacks.
- Mechanism: A generative model G approximates the unknown data distribution P. The GREAT Score computes the mean of a certified local robustness score g over samples drawn from G. This provides a global robustness estimate Ω(f) = E_z~N(0,I)[g(G(z))].
- Core assumption: The generative model sufficiently approximates the true data distribution, and the local robustness score g is a valid lower bound on the minimal adversarial perturbation for each sample.
- Evidence anchors:
  - [abstract]: "To address this challenge, this paper makes the first attempt to present a new framework, called GREAT Score, for global robustness evaluation of adversarial perturbation using generative models."
  - [section 3.2]: "We tackle challenge (i) by using a generative model such as a generative adversarial network (GAN) or a diffusion model as a proxy of the true unknown data distribution."
- Break condition: If the generative model poorly approximates the true data distribution, or if the local robustness score does not provide a valid lower bound, the GREAT Score estimate will be inaccurate.

### Mechanism 2
- Claim: The GREAT Score is a certified lower bound on the true global robustness, providing a provable guarantee on attack-proof perturbation levels.
- Mechanism: The local robustness score g is derived from a certified local radius involving the maximum local Lipschitz constant of the model output. Stein's Lemma is used to derive a closed-form global Lipschitz constant in the L2-norm over the Gaussian distribution, avoiding local Lipschitz computation.
- Core assumption: The classifier outputs are bounded in [0,1]^K, and the Stein's Lemma can be applied to the Gaussian distribution of the generative model.
- Evidence anchors:
  - [section 3.2]: "Theorem 1 (certified global robustness estimate). Let f : [0, 1]^d → [0, 1]^K be a K-way classifier... Then the global robustness estimate of f evaluated with L2-norm bounded perturbations, defined as Ω(f) = Ez~N(0,I)[g(G(z))], is a certified lower bound of the true global robustness Ω(f) with respect to G."
  - [section 3.2]: "We use Stein's Lemma which states that the mean of a measurable function integrated over a zero-mean isotropic Gaussian distribution has a closed-form global Lipschitz constant in the L2-norm."
- Break condition: If the classifier outputs are not bounded, or if Stein's Lemma cannot be applied to the Gaussian distribution, the certified lower bound guarantee will not hold.

### Mechanism 3
- Claim: The GREAT Score enables efficient and scalable robustness evaluation, especially for black-box models, by only requiring model inference on generated data samples.
- Mechanism: The computation of GREAT Score is linear in the number of generated samples, and each sample only requires one forward pass through the classifier. This avoids the need for iterative gradient computation or layer-wise interval bound propagation, which are computationally expensive.
- Core assumption: The generative model can efficiently generate samples, and the classifier inference is fast.
- Evidence anchors:
  - [abstract]: "GREAT Score has several advantages: (1) Robustness evaluations using GREAT Score are efficient and scalable to large models, by sparing the need of running adversarial attacks."
  - [section 3.4]: "The computation of GREAT score is lightweight because it scales linearly with the number of data samples used for evaluation, and each data sample only requires one forward pass through the model to obtain the final predictions."
- Break condition: If the generative model is slow to sample from, or if the classifier inference is computationally expensive, the efficiency advantage of GREAT Score will be diminished.

## Foundational Learning

- Concept: Adversarial robustness and adversarial examples
  - Why needed here: GREAT Score is a method for evaluating the adversarial robustness of machine learning models. Understanding the concept of adversarial examples and their impact on model performance is crucial for grasping the motivation behind GREAT Score.
  - Quick check question: What is an adversarial example, and why are they a concern for machine learning models?

- Concept: Generative models (GANs and diffusion models)
  - Why needed here: GREAT Score uses generative models as a proxy for the true data distribution to estimate global robustness. Familiarity with the principles and architectures of GANs and diffusion models is necessary to understand how GREAT Score works.
  - Quick check question: How do GANs and diffusion models differ in their approach to learning and generating data samples?

- Concept: Lipschitz continuity and Lipschitz constants
  - Why needed here: The GREAT Score relies on Lipschitz continuity properties of the classifier to derive certified bounds on adversarial perturbations. Understanding the concept of Lipschitz continuity and how to compute Lipschitz constants is essential for following the theoretical guarantees of GREAT Score.
  - Quick check question: What is Lipschitz continuity, and how is the Lipschitz constant related to the robustness of a classifier against adversarial perturbations?

## Architecture Onboarding

- Component map:
  - Generative model (GAN or diffusion model) -> Classifier -> Local robustness score function g -> Sample mean estimator -> (Optional) Calibration method

- Critical path:
  1. Generate samples from the generative model
  2. Pass each sample through the classifier to obtain model predictions
  3. Compute the local robustness score g for each sample
  4. Compute the sample mean of the local robustness scores to obtain the GREAT Score
  5. (Optional) Calibrate the GREAT Score based on additional knowledge of adversarial examples

- Design tradeoffs:
  - Using a generative model as a proxy for the true data distribution: Tradeoff between the approximation quality of the generative model and the computational efficiency of GREAT Score
  - Computing the mean of local robustness scores vs. using a single worst-case sample: Tradeoff between providing a more comprehensive global robustness estimate and the potential for outliers to dominate the score
  - Including a calibration step: Tradeoff between improving ranking consistency and the need for additional knowledge of adversarial examples

- Failure signatures:
  - GREAT Score is consistently lower than expected: The generative model may poorly approximate the true data distribution, or the classifier may be overly sensitive to small perturbations
  - GREAT Score varies significantly across different generative models: The approximation quality of the generative models may vary, leading to inconsistent global robustness estimates
  - Calibration does not improve ranking consistency: The additional knowledge of adversarial examples may not be representative of the true adversarial landscape, or the calibration method may be ineffective

- First 3 experiments:
  1. Evaluate the GREAT Score on a simple classifier (e.g., logistic regression) using a known data distribution (e.g., Gaussian) and compare the results to the theoretical global robustness
  2. Compare the GREAT Score of a classifier using different generative models (e.g., GAN vs. diffusion model) and analyze the impact of the generative model choice on the global robustness estimate
  3. Evaluate the effectiveness of the calibration method by comparing the GREAT Score rankings with and without calibration on a set of classifiers with known adversarial examples

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of GREAT Score vary when using different generative models (GANs vs. DMs) for approximating the data distribution?
- Basis in paper: [explicit] The paper mentions using various GANs and DMs for evaluation and observes consistency between global robustness evaluation and the quality of GANs.
- Why unresolved: While the paper notes consistency, it doesn't provide a detailed comparative analysis of GREAT Score's performance across different types of generative models.
- What evidence would resolve it: A comprehensive study comparing GREAT Score's accuracy and efficiency using different generative models (GANs vs. DMs) on the same dataset.

### Open Question 2
- Question: Can GREAT Score be effectively extended to evaluate robustness against perturbations other than L2-norm, such as L1-norm or L∞-norm?
- Basis in paper: [inferred] The paper mentions a limitation that GREAT Score is centered on L2-norm based perturbations and suggests this could be addressed if Stein's Lemma can be extended for other Lp norms.
- Why unresolved: The extension of GREAT Score to other Lp norms would require further mathematical development and validation.
- What evidence would resolve it: Successful derivation and validation of GREAT Score for other Lp norms, along with experimental results showing its effectiveness.

### Open Question 3
- Question: How does the sample complexity required for GREAT Score to achieve a certain approximation error vary with the dimensionality of the input data?
- Basis in paper: [explicit] The paper provides a formula for sample complexity in Theorem 2 but does not explore how it scales with input dimensionality.
- Why unresolved: The relationship between sample complexity and input dimensionality is not explored, which is crucial for understanding the scalability of GREAT Score.
- What evidence would resolve it: Empirical studies measuring sample complexity across datasets with varying input dimensions, and theoretical analysis of how sample complexity scales with dimensionality.

### Open Question 4
- Question: How does GREAT Score perform in evaluating the robustness of models trained on datasets other than CIFAR-10 and ImageNet, such as medical imaging or natural language processing tasks?
- Basis in paper: [inferred] The paper focuses on image classification tasks and does not explore GREAT Score's applicability to other domains.
- Why unresolved: The generalizability of GREAT Score to different types of data and tasks is not addressed, limiting its perceived applicability.
- What evidence would resolve it: Application of GREAT Score to models trained on diverse datasets, including medical imaging and NLP, with performance metrics compared to existing methods.

## Limitations
- The quality of GREAT Score heavily depends on the approximation quality of the generative model to the true data distribution
- The method assumes classifier outputs are bounded in [0,1]^K, which may not hold for all models
- Calibration effectiveness depends on having representative knowledge of adversarial examples
- The approach may be less effective for domains where generative models struggle to capture complex data distributions

## Confidence
- **High Confidence**: The efficiency and scalability advantages of GREAT Score (Mechanism 3)
- **Medium Confidence**: The certified lower bound guarantee (Mechanism 2) - relies on specific assumptions about classifier outputs and Stein's Lemma applicability
- **Medium Confidence**: The overall effectiveness of GREAT Score as a proxy for true global robustness (Mechanism 1) - depends on generative model quality

## Next Checks
1. Test GREAT Score on a controlled dataset where the true data distribution is known, comparing the GREAT Score estimate against the theoretical global robustness
2. Evaluate GREAT Score sensitivity to different generative model qualities by systematically degrading the generative model and measuring the impact on score accuracy
3. Validate the calibration method by testing on models with known adversarial examples from multiple sources to ensure calibration generalizes beyond the training set