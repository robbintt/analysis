---
ver: rpa2
title: Is GPT4 a Good Trader?
arxiv_id: '2309.10982'
source_url: https://arxiv.org/abs/2309.10982
tags:
- gpt-4
- theory
- trading
- wave
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates GPT-4's ability to apply classic trading theories
  to real-world market data analysis. The study focuses on assessing GPT-4's comprehension
  and application of Elliott Wave Theory and Dow Theory using daily candlestick data
  from the Shanghai Stock Index (March 2020-February 2021).
---

# Is GPT4 a Good Trader?

## Quick Facts
- **arXiv ID**: 2309.10982
- **Source URL**: https://arxiv.org/abs/2309.10982
- **Reference count**: 3
- **Key outcome**: GPT-4 demonstrates strong textual understanding of trading theories but shows significant gaps in practical application, with accuracy improving from 0.15 to 0.45 after iterative prompt refinement.

## Executive Summary
This paper evaluates GPT-4's ability to apply classic trading theories (Elliott Wave Theory and Dow Theory) to real-world market data analysis. Using daily candlestick data from the Shanghai Stock Index, the study reveals a significant gap between GPT-4's textual comprehension of trading theories and its practical application capabilities. Through iterative prompt engineering and human feedback, GPT-4's accuracy in identifying correct wave structures improved from 0.15 to 0.45, highlighting both the potential and limitations of LLMs in financial analysis tasks.

## Method Summary
The study employed meticulous prompt engineering with GPT-4's code interpreter to analyze technical structures based on Elliott Wave Theory and Dow Theory using daily candlestick data from the Shanghai Stock Index (March 2020-February 2021). The evaluation involved multi-dimensional manual scoring by experienced traders across foundational comprehension, analytical process clarity, validity of conclusions, and overall technical analytical proficiency. The process included iterative prompt refinement based on human feedback to improve GPT-4's practical application of trading theories.

## Key Results
- GPT-4 initially achieved low accuracy (0.15/1) in identifying correct wave structures due to focus on local trends over global patterns
- Iterative prompt refinement and correction improved accuracy to 0.45/1
- GPT-4 demonstrates strong textual understanding of trading theories but struggles with practical tool utilization
- The study highlights challenges in bridging the gap between theoretical knowledge and real-world application in financial analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4's initial failure in wave identification stems from its default focus on local trends rather than global structural patterns.
- Mechanism: Without explicit global constraints, GPT-4 optimizes locally for wave detection, missing the broader market context required by Elliott Wave Theory.
- Core assumption: Elliott Wave Theory requires holistic pattern recognition across entire time series, not just local extrema detection.
- Evidence anchors: [section] "GPT-4 is primarily based on local trends, whereas professional traders typically prioritize analyzing the overall trends of the asset when applying wave theory" and [section] "it overlooks the structure of the fifth wave and erroneously introduces a portion of a mid-term upward trend within the fourth wave"
- Break condition: If prompt constraints are explicitly global and GPT-4 still defaults to local analysis, the mechanism would be invalidated.

### Mechanism 2
- Claim: Iterative prompt refinement can progressively align GPT-4's tool utilization with human trader preferences through explicit correction signals.
- Mechanism: Human feedback injected through prompt engineering corrects GPT-4's tool usage patterns, shifting from local to global analysis and improving accuracy from 0.15 to 0.45.
- Core assumption: GPT-4 can incorporate explicit correction signals into its reasoning process when properly prompted.
- Evidence anchors: [section] "By interactively modifying the prompts to inject the trader's preferences into GPT-4's reasoning process... we can observe that GPT-4, upon receiving new prompts, swiftly corrects its approach" and [section] "Table 1: Step-wise human evaluation" showing improvement from 0.15 to 0.45
- Break condition: If multiple correction attempts fail to improve accuracy, suggesting a fundamental limitation in GPT-4's ability to incorporate explicit feedback.

### Mechanism 3
- Claim: The gap between GPT-4's textual understanding of trading theories and practical application reveals a broader challenge in aligning LLMs with domain-specific tool usage preferences.
- Mechanism: While GPT-4 demonstrates strong textual comprehension of theories, translating this into correct tool utilization (code generation for analysis) requires additional alignment techniques beyond standard RLHF.
- Core assumption: Standard RLHF techniques primarily address textual-level alignment but not tool utilization preferences.
- Evidence anchors: [section] "despite the capacity of GPT-4 to comprehensively grasp the theory of waves from textual inputs, practical applications reveal a misalignment between GPT-4 and traders' preferences" and [abstract] "Bridging the gap between textual understanding and practical tool utilization"
- Break condition: If standard RLHF techniques were shown to effectively align tool usage with domain preferences.

## Foundational Learning

- Concept: Technical analysis pattern recognition
  - Why needed here: Understanding how traders identify wave structures and the importance of global vs local analysis patterns
  - Quick check question: What distinguishes impulse waves from corrective waves in Elliott Wave Theory?

- Concept: Prompt engineering for tool utilization
  - Why needed here: Learning how to structure prompts that guide LLMs to use code interpreters and tools in domain-specific ways
  - Quick check question: How would you modify a prompt to shift an LLM's analysis from local to global perspective?

- Concept: Evaluation methodology for LLM trading analysis
  - Why needed here: Understanding multi-dimensional scoring systems and the importance of both task planning and execution quality
  - Quick check question: What dimensions should be evaluated when assessing an LLM's technical analysis output?

## Architecture Onboarding

- Component map: Data input -> Prompt engineering module -> GPT-4 code interpreter -> Analysis output -> Human evaluation -> Feedback loop -> Prompt refinement
- Critical path: User data upload -> Prompt engineering -> GPT-4 execution -> Result generation -> Human evaluation -> Prompt refinement (iterative)
- Design tradeoffs: Balancing prompt complexity with model performance vs. computational efficiency; global vs. local analysis constraints; automated vs. human-in-the-loop evaluation
- Failure signatures: Low accuracy scores (0.15/1) despite correct theory recall; local vs. global analysis misalignment; code generation that doesn't reflect trader preferences
- First 3 experiments:
  1. Test baseline GPT-4 performance on wave identification without global constraints
  2. Implement and test global constraint prompts to improve wave structure detection
  3. Develop automated evaluation metrics to complement human scoring system

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can GPT-4's alignment between textual understanding and practical tool utilization be improved through fine-tuning on domain-specific trading data?
- Basis in paper: [inferred] The paper highlights the challenge of bridging the gap between textual understanding and practical tool utilization, particularly in the context of Elliott Wave Theory application.
- Why unresolved: The paper only demonstrates the gap exists but doesn't explore whether fine-tuning GPT-4 on trading-specific data could improve its practical application.
- What evidence would resolve it: Comparative study showing performance differences between base GPT-4 and a version fine-tuned on domain-specific trading data, particularly in identifying correct wave structures.

### Open Question 2
- Question: What is the optimal approach for dynamically injecting domain knowledge into GPT-4's reasoning process during inference?
- Basis in paper: [explicit] The paper suggests this as an important research direction, noting that GPT-4's performance improved after interactive corrective prompts.
- Why unresolved: The paper only demonstrates that manual prompt engineering can improve results, but doesn't establish systematic methods for dynamic knowledge injection.
- What evidence would resolve it: Development and validation of automated systems for domain knowledge injection that consistently improve GPT-4's trading analysis accuracy across multiple market scenarios.

### Open Question 3
- Question: How can GPT-4 be effectively deployed to discover novel trading signals beyond basic trading theories?
- Basis in paper: [explicit] The paper mentions this as an unexplored research direction, noting that current work focuses on evaluating GPT-4's understanding of fundamental trading theories.
- Why unresolved: The paper only evaluates GPT-4's comprehension of existing theories and doesn't explore its potential for generating new trading signals.
- What evidence would resolve it: Systematic methodology and validation showing GPT-4's ability to generate novel trading signals that demonstrate statistical significance and practical utility in real market conditions.

## Limitations
- GPT-4's practical application capabilities remain significantly below professional trader performance levels despite improved accuracy
- Manual evaluation by experienced traders introduces subjectivity and potential inter-rater variability
- Limited generalizability of results to other market datasets and trading scenarios

## Confidence
- Medium: Claims regarding GPT-4's textual understanding of trading theories - supported by clear evidence of theory recall but limited practical application
- Low: Claims about the general applicability of prompt engineering for domain alignment - based on single-case improvement that may not generalize
- Medium: Observations about local vs. global analysis preferences - consistent with model behavior but requiring further validation

## Next Checks
1. Cross-validation with alternative datasets: Test GPT-4's wave identification performance on multiple stock indices and timeframes to assess generalizability of the local vs. global analysis finding
2. Automated evaluation metric development: Create quantitative scoring systems to complement human evaluation, reducing subjectivity and enabling large-scale testing of prompt engineering approaches
3. Comparative analysis with domain-specific models: Benchmark GPT-4's performance against traditional technical analysis software and specialized financial ML models to establish baseline improvement requirements for practical deployment