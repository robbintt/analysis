---
ver: rpa2
title: Large Language and Text-to-3D Models for Engineering Design Optimization
arxiv_id: '2307.01230'
source_url: https://arxiv.org/abs/2307.01230
tags:
- optimization
- design
- designs
- prompt
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the use of text-to-3D generative models,
  specifically Shap-E, for engineering design optimization. The authors propose an
  evolutionary design optimization framework where text prompts are used as design
  variables instead of traditional numerical parameters.
---

# Large Language and Text-to-3D Models for Engineering Design Optimization

## Quick Facts
- arXiv ID: 2307.01230
- Source URL: https://arxiv.org/abs/2307.01230
- Reference count: 33
- This paper investigates the use of text-to-3D generative models, specifically Shap-E, for engineering design optimization, proposing an evolutionary framework using text prompts as design variables.

## Executive Summary
This paper explores the application of text-to-3D generative models for engineering design optimization, specifically using Shap-E to generate vehicle designs optimized for aerodynamic performance. The authors propose an evolutionary optimization framework where text prompts serve as design variables rather than traditional numerical parameters. They compare two approaches for representing text prompts - a bag-of-words approach using Wordnet samples and a tokenisation approach using byte pair encoding. While the framework successfully generates novel and realistic designs, the optimization performance is limited by the complex and unpredictable relationship between text prompts and resulting designs.

## Method Summary
The study employs an evolutionary design optimization framework where CMA-ES optimizes text prompts to minimize aerodynamic drag coefficient. The process involves generating 3D meshes from text prompts using Shap-E, processing these meshes for CFD simulation in OpenFOAM, and evaluating performance based on drag coefficients. Two encoding methods are tested: bag-of-words using WordNet similarity metrics and tokenisation using byte pair encoding. The optimization runs for up to 100 generations with population sizes of 10 and parent selection of 3.

## Key Results
- Text-to-3D models can generate novel and realistic vehicle designs from evolved text prompts
- Optimization performance is lower compared to traditional representations due to unpredictable mapping between text prompts and resulting designs
- The bag-of-words approach provides more interpretable prompts but has limited design space compared to tokenisation
- High variability in generated designs from identical prompts presents challenges for optimization convergence

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The evolutionary framework can optimize text-to-3D generated shapes even though the mapping from prompts to 3D geometries is not a mathematical function.
- Mechanism: By using a population-based search with CMA-ES, the algorithm can explore and exploit variations in text prompts, compensating for the non-smooth and non-deterministic nature of the text-to-3D mapping through repeated sampling and selection.
- Core assumption: The stochastic nature of Shap-E's generation does not completely obscure gradients of performance with respect to prompt variations.
- Evidence anchors:
  - [abstract]: "we utilize a pre-trained version of Shap-E... Since the generative process of Shap-E is probabilistic, i.e., the network generates slightly different shapes from the same input text prompt..."
  - [section]: "By visualizing the obtained distributions of the selected metrics... we observe that the length of the generated designs is nearly identical for all designs."
  - [corpus]: Weak evidence; no direct citations on CMA-ES with non-deterministic generative models.
- Break condition: If the variability introduced by Shap-E is larger than the performance differences between designs, the optimization will not converge.

### Mechanism 2
- Claim: Using Wordnet-based bag-of-words encoding provides interpretable prompts that can be evolved towards designs with lower drag coefficients.
- Mechanism: The bag-of-words approach restricts prompt modifications to semantically meaningful words, ensuring that evolved prompts remain human-readable and that the semantic distance in the word space correlates (to some degree) with the geometric differences in the generated 3D shapes.
- Core assumption: The semantic similarity of words in Wordnet reflects their impact on the geometry of the generated shape.
- Evidence anchors:
  - [section]: "In the BoW approach, the optimization only generates prompts with intelligible words and, thus, provides a more intuitive relation between the prompts and design properties."
  - [section]: "By visualizing the obtained values (Fig. 7), we observe that the samples are clustered around certain WUP values and spread over a wide range of Chamfer distance values."
  - [corpus]: No direct evidence; assumed from Wordnet's design for semantic similarity.
- Break condition: If the Wordnet semantic space does not map well to the shape space of Shap-E, prompt evolution will not lead to meaningful design changes.

### Mechanism 3
- Claim: The tokenisation approach using byte pair encoding can generate a wider range of designs by allowing arbitrary character combinations, even if most prompts are illegible.
- Mechanism: The tokenisation approach provides a larger design space by allowing any combination of characters, which can potentially discover novel design regions that are not accessible through semantically constrained prompts, albeit with a high rate of failure.
- Core assumption: The increased design space coverage outweighs the low probability of generating meaningful prompts.
- Evidence anchors:
  - [section]: "However, instead of sampling string from a predefined set of words, we utilize the same byte pair encoding method as in GPT-4... allows us to verify the robustness of the network against changes in the prompt..."
  - [section]: "In the tokenisation approach... the tokens also generate some chunks of words with semantic interpretation, from which Shap-E creates designs with mixed features..."
  - [corpus]: No direct evidence; inferred from GPT-4's use of byte pair encoding.
- Break condition: If the majority of generated prompts are non-functional, the search will be dominated by noise and fail to improve performance.

## Foundational Learning

- Concept: Evolutionary Algorithms (EAs)
  - Why needed here: EAs are gradient-free optimization methods suitable for complex, non-differentiable design spaces where the relationship between design variables (text prompts) and performance (drag coefficient) is unknown.
  - Quick check question: What is the key difference between a gradient-based optimizer and an evolutionary algorithm when optimizing text prompts for 3D shapes?

- Concept: Text-to-3D Generative Models
  - Why needed here: Understanding how models like Shap-E generate 3D geometries from text is crucial for interpreting the results of the optimization and for designing effective prompt representations.
  - Quick check question: What are the two main steps in the Shap-E pipeline for generating a 3D mesh from a text prompt?

- Concept: Computational Fluid Dynamics (CFD)
  - Why needed here: CFD simulations are used to evaluate the aerodynamic performance (drag coefficient) of the generated 3D designs, which is the objective function being optimized.
  - Quick check question: What is the primary physical quantity being minimized in the aerodynamic optimization of vehicle designs?

## Architecture Onboarding

- Component map: Evolutionary Optimizer (CMA-ES) -> Text-to-3D Generative Model (Shap-E) -> CFD Simulation (OpenFOAM) -> Performance Evaluation -> Prompt Evolution

- Critical path:
  1. Initialize population of text prompts
  2. Generate 3D shapes from prompts using Shap-E
  3. Process and align 3D meshes for CFD
  4. Run CFD simulations to compute drag coefficients
  5. Evaluate population performance and select parents
  6. Generate new population of prompts using CMA-ES operators
  7. Repeat until convergence or maximum iterations

- Design tradeoffs:
  - Prompt representation: Bag-of-words (interpretable, limited) vs. Tokenisation (unrestricted, noisy)
  - Population size vs. computational cost: Larger populations provide better exploration but increase CFD simulation time
  - Fixed random seed vs. stochastic generation: Fixed seed ensures reproducibility but may limit exploration of the design space

- Failure signatures:
  - No improvement in drag coefficient over generations: Could indicate poor prompt representation or insufficient exploration
  - High variance in performance within a generation: Could indicate mesh quality issues or instability in the CFD simulation
  - Generation of non-car-like shapes: Could indicate the text-to-3D model is not well-suited for the target domain or the prompts are too far from the training data

- First 3 experiments:
  1. Run baseline: Generate 300 shapes with prompt "A car" and compute drag coefficient distribution to establish baseline performance
  2. Test prompt representation: Run CMA-ES optimization with both bag-of-words and tokenisation approaches for 10 generations to compare convergence and performance
  3. Validate CFD setup: Run CFD simulations on a known car model to verify the simulation framework is correctly set up and producing expected drag coefficients

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the variability inherent in large language models used in text-to-3D representations be effectively controlled or reduced to improve optimization performance?
- Basis in paper: [explicit] The authors mention that the inherent variability in text-to-3D models due to randomness in the interpretation of text prompts can be interpreted as noise in the representation, which will very likely have an effect on the optimization process.
- Why unresolved: The paper does not explore methods to control or reduce this variability.
- What evidence would resolve it: Experiments demonstrating methods to control or reduce variability in text-to-3D models and their impact on optimization performance.

### Open Question 2
- Question: Would alternative optimization methods like Differential Evolution be more effective than CMA-ES for optimizing designs using text-to-3D representations?
- Basis in paper: [inferred] The authors suggest that the complex relation between text prompt variations and design variations might affect the adaptation of strategy parameters in CMA-ES, and they mention that Differential Evolution might be a better choice.
- Why unresolved: The paper does not compare the performance of CMA-ES with other optimization methods.
- What evidence would resolve it: Comparative studies of different optimization methods applied to text-to-3D representations in engineering design optimization.

### Open Question 3
- Question: Can a classifier be effectively integrated into the optimization process to identify and exclude non-car like shapes, thereby improving the quality of the generated designs?
- Basis in paper: [explicit] The authors propose the introduction of a classifier into the optimization process to identify non-car like shapes and exclude them from optimization.
- Why unresolved: The paper does not implement or test this proposed solution.
- What evidence would resolve it: Experiments demonstrating the effectiveness of a classifier in improving the quality of generated designs in text-to-3D optimization.

## Limitations

- The fundamental challenge of establishing a predictable relationship between text prompts and resulting 3D geometries limits optimization performance
- High computational cost of CFD simulations restricts population size and number of generations, potentially preventing full exploration of the design space
- The semantic space of Wordnet may not align well with the generative capabilities of Shap-E, making it unclear whether evolved prompts actually correspond to meaningful design changes

## Confidence

- High: The framework architecture and methodology are sound and well-documented
- Medium: The evolutionary optimization process works as described, but with limited performance gains
- Low: The claim that text prompts can effectively replace traditional design parameters for engineering optimization

## Next Checks

1. Conduct a sensitivity analysis to quantify how much variation in drag coefficient can be attributed to prompt changes versus stochastic generation noise in Shap-E
2. Compare optimization performance using text prompts against a baseline using direct geometric parameterization of the same design space
3. Evaluate whether fine-tuning Shap-E on automotive-specific data improves the correlation between prompt semantics and resulting aerodynamic properties