---
ver: rpa2
title: Robust Communicative Multi-Agent Reinforcement Learning with Active Defense
arxiv_id: '2312.11545'
source_url: https://arxiv.org/abs/2312.11545
tags:
- messages
- attack
- agents
- admac
- message
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of robust communication in multi-agent
  reinforcement learning under adversarial attacks. The authors propose an active
  defense strategy called ADMAC that automatically assesses the reliability of received
  messages and reduces the impact of potentially harmful ones on final decisions.
---

# Robust Communicative Multi-Agent Reinforcement Learning with Active Defense

## Quick Facts
- arXiv ID: 2312.11545
- Source URL: https://arxiv.org/abs/2312.11545
- Reference count: 15
- Multi-agent RL with active defense achieves higher robustness against adversarial communication attacks compared to existing methods

## Executive Summary
This paper addresses the problem of robust communication in multi-agent reinforcement learning under adversarial attacks. The authors propose an active defense strategy called ADMAC that automatically assesses the reliability of received messages and reduces the impact of potentially harmful ones on final decisions. ADMAC consists of a decomposable message aggregation policy network and a reliability estimator. The policy network restricts each message's influence to an action preference vector, while the reliability estimator classifies messages as reliable or unreliable based on observations and hidden states. Experiments in three communication-critical tasks under four types of attacks show that ADMAC outperforms existing methods in terms of robustness and performance.

## Method Summary
The ADMAC framework introduces active defense into multi-agent reinforcement learning by implementing a two-component system: a decomposable message aggregation policy network and a reliability estimator. The policy network processes each message separately to generate action preference vectors, which are then weighted by the reliability estimator's assessment. During training, the policy network is first optimized using standard REINFORCE, then the reliability estimator is trained using a dataset generated with both random perturbation and gradient-based attacks. This two-stage approach balances performance and robustness by allowing the policy to learn effective communication first, then learning to identify unreliable messages.

## Key Results
- ADMAC outperforms baseline methods (TARMAC, AT, AME) in three communication-critical tasks under four attack types
- The framework demonstrates improved robustness while maintaining competitive performance without attacks
- Ablation studies show that both the decomposable policy network and reliability estimator contribute significantly to overall performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Active defense can identify unreliable messages by comparing message recommendations with the agent's own best action estimate
- Mechanism: The reliability estimator classifies messages as reliable if they recommend the same action the agent would most likely choose without that message, using the agent's hidden state and observation as context
- Core assumption: Agents have access to accurate hidden states and observations that reflect the true environment state
- Evidence anchors:
  - [abstract]: "agents actively judge the reliability of messages based on their own unperturbed observations and hidden states"
  - [section]: "we use the following criteria to label messages: For an agent, if a received message recommends it to choose the best action, then the message is considered to be reliable, otherwise it is bad."
  - [corpus]: Weak - corpus neighbors focus on communication protocols but don't directly address reliability estimation

### Mechanism 2
- Claim: Decomposing message impact into action preference vectors allows selective weighting of messages
- Mechanism: Each message's influence is restricted to an action preference vector, and the reliability estimator's output serves as the weight for that vector, allowing the agent to reduce the impact of unreliable messages
- Core assumption: The message aggregation policy can be decomposed such that each message's impact can be isolated and weighted independently
- Evidence anchors:
  - [section]: "The decomposable message aggregation policy net...decomposes the impact of each message on the final decision by restricting their influence to action preference vectors."
  - [section]: "wi(mt
j) represents the extent to which the reliability estimator thinks mt
j is reliable for agent i, and is used as the weight of mt
j in (4)."
  - [corpus]: Weak - corpus neighbors discuss message aggregation but don't address decomposable structures for robustness

### Mechanism 3
- Claim: Active defense exploits the partial attack nature of communication attacks
- Mechanism: Since attackers can only modify a portion of messages, the agent can identify and downweight the unreliable ones while still benefiting from reliable messages, whereas passive defense treats all messages equally
- Core assumption: Only a subset of messages are attacked, and the proportion of attacked messages is significant enough for active defense to be beneficial
- Evidence anchors:
  - [abstract]: "The attackers are only allowed to modify a part of the messages"
  - [section]: "We notice that robust communicative MARL has an important feature compared with robust RL: The attackers are only allowed to modify a part of the messages"
  - [corpus]: Weak - corpus neighbors don't explicitly discuss partial attack scenarios

## Foundational Learning

- Concept: Reliability estimation through supervised learning
  - Why needed here: To train the reliability estimator, we need labeled data distinguishing reliable from unreliable messages
  - Quick check question: How does the framework generate training data for the reliability estimator when the true reliability of messages is unknown during normal operation?

- Concept: Decomposable neural network architectures
  - Why needed here: The decomposable message aggregation policy net must allow isolation of individual message effects for selective weighting
  - Quick check question: What architectural constraints must the policy network satisfy to enable decomposition of message impacts?

- Concept: Adversarial training techniques
  - Why needed here: The framework uses adversarial attacks during the reliability estimator training phase to improve its identification ability
  - Quick check question: Why does the framework use both random perturbation and gradient-based attacks when generating the reliability estimator training dataset?

## Architecture Onboarding

- Component map: GRU module (fHP) for hidden state updates → Base action generation module (fBP) for initial action preferences → Message-observation process module (fM P) for message-specific action preferences → Reliability estimator (fR) for message classification → Softmax layer for final action distribution

- Critical path: Observation → GRU update → Base action + weighted message preferences → Softmax → Action
The reliability estimator operates in parallel, assessing each message before weighting is applied.

- Design tradeoffs:
  - Accuracy vs. robustness: More conservative reliability thresholds improve robustness but may discard useful information
  - Complexity vs. performance: Deeper reliability estimators may be more accurate but increase computational overhead
  - Training stability vs. effectiveness: The two-stage training approach (policy first, then reliability) trades off end-to-end optimization for stability

- Failure signatures:
  - Degradation in performance with low attack probability (overly conservative reliability thresholds)
  - Inconsistent behavior across similar situations (poor reliability estimator generalization)
  - Performance worse than baseline without attacks (miscalibrated reliability assessment)

- First 3 experiments:
  1. Test the decomposable policy net without the reliability estimator (DPN only) to establish baseline decomposition benefits
  2. Test the reliability estimator in isolation with known attack patterns to measure classification accuracy
  3. Test the full system with varying attack probabilities to find the crossover point where active defense outperforms passive defense

## Open Questions the Paper Calls Out

- Question: How can ADMAC be extended to handle continuous action spaces?
- Basis in paper: [inferred] The paper mentions that ADMAC is currently limited to discrete action spaces and suggests extending it to continuous spaces as future work.
- Why unresolved: The paper does not provide any details on how ADMAC could be modified to handle continuous actions, leaving this as an open research direction.
- What evidence would resolve it: A concrete proposal and experimental validation of an extension of ADMAC to continuous action spaces would resolve this question.

- Question: What is the impact of the reliability estimator's classification performance on ADMAC's overall robustness?
- Basis in paper: [explicit] The ablation study shows that the recall and precision of the reliability estimator account for the performance gap between ADMAC and an ideal reliability estimator.
- Why unresolved: While the paper demonstrates a correlation between the reliability estimator's performance and ADMAC's robustness, it does not quantify the exact impact or provide guidelines for achieving a desired level of robustness.
- What evidence would resolve it: A detailed analysis of the relationship between the reliability estimator's classification performance (e.g., recall, precision, F1-score) and ADMAC's robustness metrics would resolve this question.

- Question: How can ADMAC be adapted to scenarios where messages are likely to carry unique information?
- Basis in paper: [explicit] The paper mentions that in scenarios where messages are likely to carry unique information, judging whether a message is reliable is hard, leading to a decline in ADMAC's robustness.
- Why unresolved: The paper does not provide any solutions or strategies for handling such scenarios, leaving this as an open research direction.
- What evidence would resolve it: A concrete proposal and experimental validation of an extension of ADMAC to handle scenarios with unique information in messages would resolve this question.

## Limitations
- The framework's effectiveness is primarily demonstrated against gradient-based attacks, with limited evaluation of more sophisticated adversarial strategies
- The two-stage training approach sacrifices end-to-end optimization for stability, potentially limiting performance
- The reliability estimator's performance depends heavily on the assumption that agents can accurately assess their own action preferences without attacked messages

## Confidence
- Decomposable policy network design: Medium to High
- Reliability estimator effectiveness: Medium
- General robustness claims: Medium

## Next Checks
1. Test ADMAC on environments with different observation spaces, agent numbers, and communication topologies to assess robustness beyond the three current tasks
2. Evaluate the system's performance against adaptive adversaries that learn to evade the reliability estimator
3. Systematically test variants of the policy network with different levels of decomposability to quantify the precise contribution of this architectural choice to overall robustness