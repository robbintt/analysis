---
ver: rpa2
title: On Data Imbalance in Molecular Property Prediction with Pre-training
arxiv_id: '2308.08934'
source_url: https://arxiv.org/abs/2308.08934
tags:
- data
- pre-training
- task
- imbalance
- molecular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of data imbalance in molecular
  property prediction with pre-training. It proposes a method to compensate for the
  imbalance of element features in molecular graphs by modifying the loss function
  during pre-training.
---

# On Data Imbalance in Molecular Property Prediction with Pre-training

## Quick Facts
- arXiv ID: 2308.08934
- Source URL: https://arxiv.org/abs/2308.08934
- Reference count: 31
- Primary result: Weighted loss function during pre-training compensates for element frequency imbalance, improving downstream molecular property prediction accuracy

## Executive Summary
This paper addresses the challenge of data imbalance in molecular property prediction by proposing a method to modify the loss function during pre-training. The authors introduce a weighting scheme that compensates for the skewed distribution of elements in molecular graphs, where carbon is significantly more abundant than other elements like nitrogen and oxygen. By applying higher weights to less frequent elements during the masked node reconstruction pretext task, the model learns more balanced representations that improve performance on downstream property prediction tasks.

## Method Summary
The method involves pre-training a Graphormer model on molecular graphs using a node masking pretext task with weighted cross-entropy loss. Three weighting schemes are compared: reciprocal weights (strongest compensation), log weights (moderate compensation), and proportion weights (weakest compensation). After pre-training, the model is fine-tuned on the target property prediction task (HOMO-LUMO energy gap in the PCQM4Mv2 dataset). The weights are calculated based on element frequencies in the training data, with rare elements receiving higher weights to balance their contribution to the loss.

## Key Results
- Proportion weighting method achieved the best downstream MAE on HOMO-LUMO prediction task
- Stronger compensation methods (reciprocal, log) made the pretext task more difficult but did not consistently improve final accuracy
- Rare element recall increased with stronger imbalance compensation during pre-training
- The proposed method improved accuracy compared to unweighted pre-training, though benefits varied with masking proportion

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weighted loss function compensates for data imbalance by increasing the influence of rare elements during pre-training.
- Mechanism: Re-weighting adjusts the cross-entropy loss by applying larger weights to classes (elements) with fewer data points, effectively amplifying their contribution to gradient updates. This forces the model to learn from underrepresented elements rather than focusing solely on frequent ones.
- Core assumption: The element frequency distribution in molecular graphs follows a power law, making rare elements systematically underrepresented.
- Evidence anchors:
  - [abstract] "However, in the case of molecular property prediction, there is a strong imbalance in the distribution of input data and features, which may lead to biased learning towards frequently occurring data during pre-training."
  - [section 3.1] "From Table 1, carbon is the most abundant element, compared to nitrogen and oxygen which are less frequent, and this means that the elements are not equally distributed."
  - [corpus] Weak evidence for effectiveness of re-weighting in molecular prediction specifically; strongest evidence from general imbalanced learning literature.
- Break condition: If the loss function becomes unstable or gradients explode due to extreme weight values (e.g., 1/0 for elements with zero data).

### Mechanism 2
- Claim: Stronger compensation (e.g., reciprocal weights) makes the pretext task harder, which improves downstream performance.
- Mechanism: Increasing weight for rare elements raises the difficulty of the masked node reconstruction task. A harder pretext task forces the model to extract richer, more generalizable features, which benefits fine-tuning on the target property.
- Core assumption: In molecular property prediction, data imbalance hurts pre-training effectiveness because the model fails to learn from diverse elements.
- Evidence anchors:
  - [section 5.1] "we can say that the rank of the difficulty of the pretext task is in the order of 'Reciprocal'> 'Log' > 'Proportion' > 'No weight'. This order is consistent with the order of the strength of the imbalance compensation, i.e. the stronger the compensation is, the more difficult the pretext task is."
  - [section 5.2] "the recall for rare elements increases as the imbalance compensation becomes stronger."
  - [corpus] Weak evidence; general SSL literature supports harder pretext tasks but no molecular-specific study cited.
- Break condition: If the pretext task becomes too hard and the model fails to converge or overfits to the compensation pattern.

### Mechanism 3
- Claim: Pre-training on imbalanced data without compensation biases the model toward frequent elements, hurting downstream property prediction accuracy.
- Mechanism: Without re-weighting, the model learns to reconstruct frequent elements with high accuracy but fails on rare elements. During fine-tuning, this bias reduces the model's ability to generalize to molecules with rare elements, lowering accuracy.
- Core assumption: Rare elements have unique properties that are important for accurate molecular property prediction.
- Evidence anchors:
  - [abstract] "less frequent elements tend to have unique properties compared to the frequent elements, so if pre-training on nodes is biased, the model may miss the essential information, and the accuracy of predicting the target property after fine tuning may also deteriorate."
  - [section 5.3] "the MAE is the smallest for 'Proportion' weight" when masking one node per graph.
  - [corpus] No direct corpus evidence for molecular-specific rare-element importance; inferred from general imbalanced learning theory.
- Break condition: If the downstream task does not depend on rare-element properties (e.g., predicting properties dominated by carbon-based structures).

## Foundational Learning

- Concept: Cross-entropy loss for multi-class classification
  - Why needed here: The pretext task is reconstructing masked node elements, which is a classification over possible atomic numbers.
  - Quick check question: What is the formula for cross-entropy loss between one-hot labels and predicted probabilities?

- Concept: Data imbalance and its effects on model training
  - Why needed here: The frequency distribution of elements in molecular graphs is highly skewed, which can bias model learning toward frequent elements.
  - Quick check question: How does class imbalance typically affect model accuracy on minority classes?

- Concept: Pre-training and fine-tuning workflow
  - Why needed here: The method uses node masking as a pretext task to pre-train, then fine-tunes on the target property prediction task.
  - Quick check question: What is the difference between pre-training and fine-tuning in terms of objective and data used?

## Architecture Onboarding

- Component map:
  Input data (molecular graphs) -> Graphormer encoder -> Pretext task head (masked node reconstruction) -> Weighted cross-entropy loss -> Encoder weights update
  Fine-tuning stage: Input data (property values) -> Graphormer encoder -> Property prediction head -> MAE loss -> Encoder weights update

- Critical path:
  1. Load graph data, apply node masking at configured proportion
  2. Forward pass through Graphormer encoder
  3. Compute weighted cross-entropy loss for masked nodes
  4. Backpropagate and update encoder weights
  5. After pre-training, replace pretext head with property prediction head
  6. Fine-tune on HOMO-LUMO energy gap prediction

- Design tradeoffs:
  - Weighting method choice: Reciprocal weights give strongest compensation but risk instability; proportion weights are milder and more stable.
  - Masking proportion: Too little masking may not provide enough pretext signal; too much may destroy graph structure.
  - Training epochs: Balancing pre-training convergence vs. overfitting to the compensation pattern.

- Failure signatures:
  - Loss divergence during pre-training: likely due to extreme weights (e.g., 1/0 for unseen elements).
  - Low recall for rare elements despite re-weighting: insufficient model capacity or too weak compensation.
  - No improvement in downstream MAE: compensation too weak, or rare elements not important for target property.

- First 3 experiments:
  1. Run pre-training with no weights, record pretext task loss and element recall by frequency group.
  2. Run pre-training with proportion weights, compare loss trajectory and recall to baseline.
  3. Fine-tune both models on HOMO-LUMO prediction, compare MAE on validation set.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the strength of data imbalance compensation during pre-training always improve the final accuracy of the fine-tuned model, or are there cases where it can be detrimental?
- Basis in paper: [inferred] The paper mentions that "we couldn't observe that re-weighting always gives the positive effect" and that "sometimes it improves the accuracy."
- Why unresolved: The paper found that the impact of re-weighting on final accuracy varies depending on the proportion of masked nodes and the specific weighting method used, indicating a complex relationship.
- What evidence would resolve it: Systematic experiments varying the proportion of masked nodes, the weighting method, and the dataset to identify conditions under which data imbalance compensation improves or worsens final accuracy.

### Open Question 2
- Question: What is the optimal weighting method for compensating data imbalance in molecular property prediction, and how does it depend on the specific dataset and task?
- Basis in paper: [explicit] The paper compares three weighting methods ("reciprocal," "log," and "proportion") and finds that the optimal method varies depending on the proportion of masked nodes.
- Why unresolved: The paper does not provide a definitive answer on which weighting method is universally best, suggesting that the optimal method may depend on dataset characteristics and task specifics.
- What evidence would resolve it: A comprehensive study comparing different weighting methods across multiple datasets and tasks to determine the factors that influence the optimal choice.

### Open Question 3
- Question: How does data imbalance in molecular property prediction differ from data imbalance in other domains like natural language processing, and what implications does this have for pre-training strategies?
- Basis in paper: [explicit] The paper discusses the differences between data imbalance in molecular property prediction and natural language processing, highlighting that the distribution of elements in molecules is not correlated with their properties, unlike the distribution of words in language.
- Why unresolved: While the paper identifies this key difference, it does not explore its full implications for pre-training strategies or compare the effectiveness of different approaches across domains.
- What evidence would resolve it: Comparative studies applying different pre-training strategies to both molecular property prediction and natural language processing tasks to assess the impact of domain-specific data imbalance characteristics.

## Limitations
- The study demonstrates improved performance but lacks ablation studies isolating pre-training vs. fine-tuning effects
- No comparison with alternative imbalance handling methods like SMOTE or class-balanced sampling
- Experiments focus on a single dataset (PCQM4Mv2) without testing generalizability across different molecular property prediction tasks

## Confidence
- **High confidence**: Weighted loss function improves downstream MAE on PCQM4Mv2 dataset; stronger compensation increases pretext task difficulty
- **Medium confidence**: Data imbalance in molecular graphs causes pre-training bias toward frequent elements; rare elements have unique properties important for prediction
- **Low confidence**: The proposed method generalizes to other molecular datasets and property prediction tasks; mechanism 2 (harder pretext tasks improve downstream performance) is uniquely responsible for gains

## Next Checks
1. **Cross-dataset validation**: Test the same weighted loss approach on additional molecular property prediction datasets (e.g., QM9, ChEMBL) to assess generalizability.
2. **Alternative imbalance methods**: Compare performance against other imbalance handling techniques like focal loss, SMOTE, or class-balanced sampling to establish method superiority.
3. **Mechanism isolation**: Conduct ablation studies where pre-trained models are evaluated without fine-tuning, and fine-tuning is done from scratch without pre-training, to quantify the relative contribution of each stage.