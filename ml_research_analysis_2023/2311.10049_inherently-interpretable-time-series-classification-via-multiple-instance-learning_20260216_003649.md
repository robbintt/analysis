---
ver: rpa2
title: Inherently Interpretable Time Series Classification via Multiple Instance Learning
arxiv_id: '2311.10049'
source_url: https://arxiv.org/abs/2311.10049
tags:
- time
- series
- millet
- point
- interpretability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MILLET, a Multiple Instance Learning framework
  that makes Time Series Classification models inherently interpretable. The method
  works by treating each time series as a bag of instances (time points) and using
  different pooling methods to aggregate instance-level predictions into a time series
  prediction.
---

# Inherently Interpretable Time Series Classification via Multiple Instance Learning

## Quick Facts
- arXiv ID: 2311.10049
- Source URL: https://arxiv.org/abs/2311.10049
- Reference count: 40
- Primary result: MILLET achieves up to 0.856 balanced accuracy on UCR datasets, comparable to state-of-the-art methods

## Executive Summary
This paper introduces MILLET, a Multiple Instance Learning framework that makes Time Series Classification models inherently interpretable. The method works by treating each time series as a bag of instances (time points) and using different pooling methods to aggregate instance-level predictions into a time series prediction. The authors propose a novel Conjunctive pooling approach that outperforms existing methods. MILLET is evaluated on 85 UCR time series datasets and a new synthetic WebTraffic dataset, demonstrating that it improves both interpretability and predictive performance compared to baseline models.

## Method Summary
MILLET treats time series classification as a multiple instance learning problem where each time series is a bag of instances (time points). The framework consists of a feature extractor backbone (FCN/ResNet/InceptionTime) that generates embeddings for each time point, followed by MIL pooling methods (Attention, Instance, Additive, or Conjunctive) that aggregate instance-level predictions into a final time series prediction. Conjunctive pooling, the novel contribution, trains attention and classification heads in parallel before scaling predictions by attention scores. The framework includes positional encoding, dropout, and replicate padding as enhancements.

## Key Results
- MILLET models achieve up to 0.856 balanced accuracy on UCR datasets, comparable to state-of-the-art methods
- The Conjunctive InceptionTime model wins or draws on 61.2% of UCR datasets against top baselines
- MILLET models outperform post-hoc interpretability methods like SHAP and CAM on AOPCR scores
- MILLET improves predictive performance while providing inherent interpretability without compromising accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MILLET provides inherent interpretability by making time point predictions as part of the classification process
- Mechanism: The MIL pooling methods make predictions for each time point before aggregating to form the final time series prediction, creating inherent interpretability
- Core assumption: Time series classification can be framed as an MIL problem where each time point is an instance
- Evidence anchors: Abstract states "MILLET: Multiple Instance Learning for Locally Explainable Time series classification"; paper section claims "explanations for free"
- Break condition: If the model cannot learn meaningful time point-level representations from only bag-level labels

### Mechanism 2
- Claim: Conjunctive pooling outperforms other pooling methods by training attention and classification heads in parallel
- Mechanism: Conjunctive pooling applies attention and classification independently to time point embeddings, then scales predictions by attention scores
- Core assumption: Training attention and classification heads in parallel improves model robustness
- Evidence anchors: Paper states "attention and classifier heads are trained in parallel rather than sequentially"
- Break condition: If parallel training doesn't improve robustness or attention weights don't correlate with classification importance

### Mechanism 3
- Claim: MILLET improves predictive performance while maintaining interpretability
- Mechanism: By treating time series as bags of instances, MILLET leverages instance-level information that gets lost in traditional pooling methods
- Core assumption: Instance-level information contains predictive signal beyond aggregated representations
- Evidence anchors: Abstract claims "without compromising (and in some cases, even improving) predictive performance"
- Break condition: If instance-level information doesn't contain additional predictive signal

## Foundational Learning

- Concept: Multiple Instance Learning (MIL) fundamentals
  - Why needed here: The entire framework is built on treating time series classification as an MIL problem
  - Quick check question: What is the standard assumption in MIL and how does it apply to time series classification?

- Concept: Interpretability metrics (AOPCR, NDCG@n)
  - Why needed here: The paper uses specific metrics to evaluate interpretability that differ from standard classification metrics
  - Quick check question: How does AOPCR measure interpretability without time point labels, and why is it useful for this application?

- Concept: Deep learning for time series classification
  - Why needed here: The paper builds on existing DL TSC architectures, so understanding these foundations is necessary
  - Quick check question: What are the key components of DL TSC models like FCN, ResNet, and InceptionTime, and how does MILLET modify them?

## Architecture Onboarding

- Component map: Feature extractor backbone → Positional encoding → Dropout → MIL pooling (Embedding/Attention/Instance/Additive/Conjunctive) → Classifier
- Critical path: Time point embeddings → MIL pooling → Time series prediction
- Design tradeoffs:
  - Interpretability vs predictive performance: More interpretable methods may sacrifice some predictive performance
  - Model complexity: Adding attention heads increases parameters by ~0.4%
  - Training time: MIL pooling increases training time by up to 6% and inference by up to 7.5%
- Failure signatures:
  - Poor interpretability scores despite good predictive performance indicates ineffective instance-level information use
  - High variance in predictive performance across datasets suggests pooling method robustness issues
  - Negative AOPCR scores indicate fundamental issues with the interpretability approach
- First 3 experiments:
  1. Replace GAP with Instance pooling on a simple dataset to verify time point predictions are generated correctly
  2. Compare AOPCR scores between GAP and MIL pooling on a dataset with known discriminatory time points
  3. Test Conjunctive pooling on a dataset where traditional methods struggle to verify performance improvement

## Open Questions the Paper Calls Out
- How would MILLET perform on multivariate time series datasets? The authors mention extending to multivariate data would require new interpretability methods.
- What is the impact of different positional encoding schemes on MILLET's performance? The study uses fixed positional encodings but doesn't explore alternatives.
- How does MILLET compare to other interpretability methods on longer time series? The authors note SHAP struggles with many time points but don't extensively test MILLET's scalability.

## Limitations
- Interpretability metrics (AOPCR, NDCG@n) are novel and lack established baselines for comparison
- 6% training and 7.5% inference time overhead for interpretability features may be prohibitive for real-time applications
- WebTraffic dataset, while controlled, may not capture the complexity of real-world time series data

## Confidence

- **High confidence**: MILLET framework architecture and implementation details are well-specified with code available
- **Medium confidence**: Predictive performance improvements over baselines are reproducible but may vary with different datasets
- **Low confidence**: Interpretability superiority claims relative to post-hoc methods need more rigorous validation on diverse datasets

## Next Checks

1. Test MILLET on additional real-world time series datasets beyond UCR archive to validate generalizability of interpretability claims
2. Compare MILLET interpretability metrics against established post-hoc methods (SHAP, LIME) on datasets with known ground truth importance scores
3. Conduct ablation studies removing positional encoding and dropout to quantify their contribution to both performance and interpretability