---
ver: rpa2
title: 'TraceFL: Interpretability-Driven Debugging in Federated Learning via Neuron
  Provenance'
arxiv_id: '2312.13632'
source_url: https://arxiv.org/abs/2312.13632
tags:
- clients
- global
- provfl
- client
- provenance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of interpreting and debugging
  global model predictions in federated learning (FL) by introducing a fine-grained
  neuron provenance capturing mechanism called ProvFL. ProvFL dynamically quantifies
  the significance of global model neurons in a given prediction and maps them to
  corresponding neurons in participating clients to determine each client's contribution.
---

# TraceFL: Interpretability-Driven Debugging in Federated Learning via Neuron Provenance

## Quick Facts
- arXiv ID: 2312.13632
- Source URL: https://arxiv.org/abs/2312.13632
- Reference count: 25
- Primary result: Achieves 99% accuracy in localizing responsible clients for global model predictions in federated learning

## Executive Summary
TraceFL introduces a novel neuron provenance capturing mechanism for federated learning that enables accurate debugging and interpretability of global model predictions. The method dynamically quantifies the significance of activated neurons in predictions and maps them back to individual client contributions using the invertible nature of fusion algorithms. Evaluations across six datasets and four neural network architectures demonstrate its effectiveness in localizing responsible clients with 99% accuracy, addressing a critical gap in FL interpretability.

## Method Summary
ProvFL implements a fine-grained neuron provenance capturing mechanism that tracks activated neurons whose outputs exceed a threshold, computes gradient-based influence scores to identify the most impactful neurons, and uses the inverse of fusion algorithms (FedAvg, FedProx) to decompose global neuron contributions back to individual client neurons. The method aggregates client contributions across all activated neurons and normalizes them using softmax to determine which client is most responsible for a given prediction. This approach dynamically quantifies neuron significance and leverages the invertible nature of popular fusion algorithms to enable highly accurate automated reasoning about client contributions.

## Key Results
- Achieves 99% accuracy in localizing responsible clients across six datasets
- Successfully evaluates on four neural network architectures including LeNet, ResNet-18, DenseNet-121, and GPT
- Demonstrates effectiveness on both image classification (CIFAR-10, MNIST, FashionMNIST) and text classification tasks
- Addresses interpretability and debugging challenges unique to federated learning settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic neuron activation isolation reduces search space and improves accuracy
- Mechanism: ProvFL only tracks activated neurons whose output exceeds a threshold, ignoring inactive neurons
- Core assumption: Activated neurons carry most relevant information for predictions
- Evidence anchors: Abstract mentions dynamic quantification of neuron significance; section states tracking all neurons is expensive and wasteful
- Break condition: Poorly chosen activation threshold may miss neurons with small but meaningful contributions

### Mechanism 2
- Claim: Gradient-based influence scoring identifies most impactful neurons
- Mechanism: Computes ∂y/∂znj to quantify how changes in neuron output affect final prediction
- Core assumption: Neurons with higher gradients have greater influence on prediction outcomes
- Evidence anchors: Abstract discusses dynamic quantification of significance; section defines influence as partial derivative of output with respect to neuron activation
- Break condition: Saturated or vanishing gradients may not reflect true neuron importance

### Mechanism 3
- Claim: Inversion of fusion algorithms enables accurate client contribution mapping
- Mechanism: Uses inverse of FedAvg/FedProx to decompose neuron contributions back to client neurons
- Core assumption: Fusion algorithms like FedAvg are mathematically invertible
- Evidence anchors: Abstract mentions invertible nature of fusion algorithms; section observes most popular fusion algorithms are invertible
- Break condition: Non-invertible fusion algorithms or non-linear operations may cause decomposition inaccuracies

## Foundational Learning

- Concept: Federated Learning fundamentals and fusion algorithms (FedAvg, FedProx)
  - Why needed here: Understanding how global models are aggregated from client models is critical to tracing neuron provenance
  - Quick check question: What is the mathematical formula for FedAvg aggregation, and how does it differ from FedProx?

- Concept: Automatic differentiation and gradient computation
  - Why needed here: ProvFL uses gradients to quantify neuron influence on predictions
  - Quick check question: How does PyTorch's automatic differentiation engine compute gradients for a given output with respect to neuron activations?

- Concept: Neuron activation functions and thresholding
  - Why needed here: ProvFL isolates activated neurons based on activation thresholds to reduce noise
  - Quick check question: What is the role of the ReLU activation function in determining whether a neuron is considered "activated"?

## Architecture Onboarding

- Component map: Input -> Neuron activation detection -> Gradient computation -> Fusion inversion -> Client contribution aggregation -> Output
- Critical path: Activated neurons → Gradient influence scores → Fusion inversion → Client contribution aggregation → Final attribution
- Design tradeoffs:
  - Precision vs. computational cost: Tracking all neurons is more accurate but computationally prohibitive
  - Static vs. dynamic analysis: Static weight analysis is faster but less accurate than dynamic activation-based methods
  - Threshold selection: Lower thresholds capture more neurons but increase noise; higher thresholds reduce noise but may miss subtle contributors
- Failure signatures:
  - Low provenance accuracy despite high global model accuracy (may indicate threshold issues or gradient saturation)
  - Inconsistent client attribution across similar inputs (may indicate fusion algorithm approximation errors)
  - High computational overhead (may indicate inefficient activation detection or gradient computation)
- First 3 experiments:
  1. Test ProvFL on MNIST classification with LeNet using FedAvg, varying activation thresholds to observe impact on accuracy
  2. Compare ProvFL's gradient-based influence scores with random neuron selection to validate gradient computation importance
  3. Evaluate ProvFL's performance when using FedProx vs. FedAvg fusion to understand algorithm-specific behavior

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but raises several important considerations regarding ProvFL's performance in cross-device settings, computational overhead compared to baselines, and handling of scenarios where multiple clients have identical contributions to predictions.

## Limitations
- Limited evaluation details make it difficult to reproduce the 99% accuracy claim across diverse datasets and models
- Inversion mechanism for fusion algorithms beyond FedAvg and FedProx remains unclear, particularly for non-linear aggregation methods
- Does not address how ProvFL handles heterogeneous client data distributions or varying client participation patterns across rounds

## Confidence
- High confidence: Dynamic neuron activation and gradient-based influence scoring mechanism is theoretically sound
- Medium confidence: Inversion of fusion algorithms for client contribution mapping is plausible for linear methods like FedAvg
- Low confidence: 99% accuracy claim requires more detailed validation, particularly regarding edge cases and failure modes

## Next Checks
1. Test ProvFL's performance on heterogeneous client data distributions where some clients have significantly different data distributions than others
2. Evaluate ProvFL's behavior when clients participate in only a subset of training rounds to assess knowledge degradation from catastrophic forgetting
3. Compare ProvFL's client attribution accuracy against baseline methods (random selection, static weight analysis) across multiple FL aggregation algorithms (FedAvg, FedProx, SCAFFOLD)