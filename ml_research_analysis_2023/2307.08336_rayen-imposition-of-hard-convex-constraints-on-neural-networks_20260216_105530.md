---
ver: rpa2
title: 'RAYEN: Imposition of Hard Convex Constraints on Neural Networks'
arxiv_id: '2307.08336'
source_url: https://arxiv.org/abs/2307.08336
tags:
- constraints
- rayen
- optimization
- convex
- linear
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents RAYEN, a framework for imposing hard convex
  constraints on neural network outputs or latent variables. RAYEN guarantees constraint
  satisfaction at all times without requiring computationally expensive orthogonal
  projections or conservative approximations.
---

# RAYEN: Imposition of Hard Convex Constraints on Neural Networks

## Quick Facts
- arXiv ID: 2307.08336
- Source URL: https://arxiv.org/abs/2307.08336
- Reference count: 40
- One-line primary result: RAYEN achieves 20-7468x faster computation times than state-of-the-art algorithms while maintaining constraint satisfaction for hard convex constraints on neural networks.

## Executive Summary
RAYEN is a framework for imposing hard convex constraints on neural network outputs or latent variables without requiring computationally expensive orthogonal projections or conservative approximations. The method supports linear, convex quadratic, second-order cone, and linear matrix inequality constraints by constructing them in an affine subspace and adjusting step lengths to ensure feasibility. Key results include imposing 1000 quadratic constraints on a 1000-dimensional variable with only 8ms overhead, and achieving computation times 20-7468x faster than state-of-the-art algorithms while maintaining constraint satisfaction.

## Method Summary
RAYEN imposes hard convex constraints by mapping the neural network output to a point in the affine hull of the feasible set, computing inverse distances to constraint boundaries analytically, and scaling the step by the minimum of this distance and the raw network output norm. The framework requires computing the affine hull of the feasible set, finding an interior point, and then performing online adjustments to ensure constraint satisfaction. The method avoids orthogonal projections through closed-form distance computations for each constraint type (linear, convex quadratic, SOC, LMI) and combines them via a max operation.

## Key Results
- Imposed 1000 quadratic constraints on a 1000-dimensional variable with 8ms overhead
- Imposed a 300x300 dense LMI constraint on a 10K-dimensional variable with 12ms overhead
- Achieved computation times 20-7468x faster than state-of-the-art algorithms while maintaining constraint satisfaction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RAYEN avoids computationally expensive orthogonal projections by analytically computing a scalar λ that ensures constraint satisfaction.
- Mechanism: The method maps the neural network output to a point in the affine hull of the feasible set, computes the inverse distance to each constraint boundary along the step direction, and scales the step by the minimum of this distance and the raw network output norm.
- Core assumption: The feasible set Y is convex and nonempty, and an interior point z0 is known.
- Evidence anchors:
  - [abstract] "does not perform a computationally-expensive orthogonal projection step onto the feasible set"
  - [section IV] "By leveraging analytic expressions of the distance to the boundaries of the convex set, RAYEN is able to avoid this slow orthogonal projection step"
  - [corpus] No direct evidence; the corpus neighbors discuss other constraint enforcement methods but not this specific analytic projection avoidance.
- Break condition: If the feasible set is non-convex or if z0 is not in the interior, the analytic distance computation fails.

### Mechanism 2
- Claim: Constraints are enforced by construction without conservative approximations.
- Mechanism: RAYEN explicitly computes the inverse distances κL, κQ, κS, κM to each type of constraint boundary along the direction of movement and uses the maximum to ensure feasibility. This is done in closed form without approximating the feasible set.
- Core assumption: Each constraint type (linear, convex quadratic, SOC, LMI) has a computable inverse distance along a given direction.
- Evidence anchors:
  - [abstract] "does not use conservative approximations of the feasible set"
  - [section IV] Definitions of κL, κQ, κS, κM with explicit analytic formulas
  - [corpus] Weak; the corpus does not directly support this claim but discusses other constraint enforcement methods.
- Break condition: If any constraint type lacks a closed-form inverse distance or if the feasible set is unbounded in the direction of interest.

### Mechanism 3
- Claim: The framework supports combinations of linear, convex quadratic, SOC, and LMI constraints efficiently.
- Mechanism: RAYEN transforms all constraints into a common subspace (the affine hull), computes distances to each boundary analytically, and combines them via a max operation. This allows simultaneous enforcement of heterogeneous constraint types.
- Core assumption: The transformation to the affine hull preserves the structure needed for analytic distance computation.
- Evidence anchors:
  - [abstract] "supports any combination of linear, convex quadratic, SOC, and LMI constraints"
  - [section III-B] "Using Eq. 7, we have that AIy ≤ bI is equivalent to: ..."
  - [corpus] No direct evidence; the corpus neighbors focus on different constraint enforcement approaches.
- Break condition: If the transformation to the affine hull is not possible or if constraints cannot be expressed in the required forms.

## Foundational Learning

- Concept: Convex optimization and feasible sets
  - Why needed here: Understanding how constraints define convex feasible sets is crucial for grasping how RAYEN enforces them.
  - Quick check question: Can you explain what it means for a set to be convex and why this property is important for RAYEN?

- Concept: Affine hulls and linear subspaces
  - Why needed here: RAYEN transforms the problem into the affine hull of the feasible set; understanding this concept is key to following the algorithm.
  - Quick check question: How would you find the affine hull of a set defined by linear equality constraints?

- Concept: Orthogonal projection vs. analytic projection
  - Why needed here: RAYEN avoids expensive orthogonal projections by using analytic distance computations; knowing the difference helps understand the efficiency gain.
  - Quick check question: What is the computational complexity difference between orthogonal projection and the analytic method RAYEN uses?

## Architecture Onboarding

- Component map: Input x -> Linear layer -> RAYEN module -> Output y
- Critical path:
  1. Compute v from x via linear layer
  2. Compute κ (inverse distance) for each constraint type
  3. Scale v by min(1/κ, ||v||) and add to z0
  4. Map back to original space via f(·)
  5. Output y

- Design tradeoffs:
  - Accuracy vs. speed: More precise κ computation may be slower but ensures tighter constraint satisfaction
  - Memory vs. computation: Precomputing parts of κ (like D in κL) saves time but uses memory
  - Flexibility vs. complexity: Supporting many constraint types increases code complexity

- Failure signatures:
  - NaNs in output: Likely a convergence issue in inner gradient descent (if used) or ill-conditioned matrices in LMI constraints
  - Constraint violation: Possible if κ computation is incorrect or if the feasible set is non-convex
  - Slow inference: May indicate inefficient κ computation or large constraint sets

- First 3 experiments:
  1. Implement RAYEN with only linear constraints and verify constraint satisfaction on simple 2D examples
  2. Add convex quadratic constraints and test on a 3D example with known feasible set
  3. Benchmark RAYEN against orthogonal projection on a larger problem to measure speed improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can RAYEN be extended to support generic nonconvex constraints?
- Basis in paper: [inferred] from the "Nonconvex Constraints" discussion in Section VI
- Why unresolved: The paper mentions this as future work but doesn't provide a concrete approach
- What evidence would resolve it: A demonstration of RAYEN successfully handling a nonconvex constraint (e.g., polynomial inequality) while maintaining computational efficiency

### Open Question 2
- Question: What is the impact of using RAYEN with non-fixed constraint parameters that depend on network inputs or previous layers?
- Basis in paper: [explicit] from the "Non-fixed Constraints" discussion in Section VI
- Why unresolved: The paper provides conditions for feasibility but doesn't test the performance of such dynamic constraints
- What evidence would resolve it: Empirical results showing RAYEN's behavior when constraint matrices vary with input data

### Open Question 3
- Question: How does RAYEN perform when imposing exponential cone constraints or other advanced convex constraint types?
- Basis in paper: [explicit] from the "Conclusion and Future Work" section mentioning exponential cone constraints as future work
- Why unresolved: The paper only demonstrates linear, quadratic, SOC, and LMI constraints
- What evidence would resolve it: Implementation and benchmarking of RAYEN with exponential cone constraints compared to existing methods

## Limitations
- Relies on convex feasible sets and known interior points; cannot guarantee satisfaction for non-convex constraints
- Assumes closed-form inverse distance computations are available for each constraint type
- Results are specific to tested constraint combinations and may not generalize to all problem types

## Confidence

**High confidence:** The mechanism for avoiding orthogonal projections through analytic distance computation is well-supported by the mathematical framework and explicit formulas provided.

**Medium confidence:** The claim of supporting any combination of constraint types is supported by the algorithmic framework but lacks extensive empirical validation across diverse combinations.

**Medium confidence:** The speed improvement claims are well-supported by the presented benchmarks but may be problem-dependent.

## Next Checks
1. Test RAYEN on a non-convex constraint set to verify that it fails gracefully or provides appropriate warnings when convexity assumptions are violated.
2. Implement a simple 2D convex example with known analytic solution and verify that RAYEN's output matches the expected feasible point.
3. Benchmark RAYEN against orthogonal projection on a large-scale problem (e.g., 10K dimensions with 1000 constraints) to independently verify the claimed 20-7468x speed improvement.