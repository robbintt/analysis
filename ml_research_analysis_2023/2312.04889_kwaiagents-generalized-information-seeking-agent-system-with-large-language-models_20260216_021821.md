---
ver: rpa2
title: 'KwaiAgents: Generalized Information-seeking Agent System with Large Language
  Models'
arxiv_id: '2312.04889'
source_url: https://arxiv.org/abs/2312.04889
tags:
- agent
- memory
- information
- system
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KwaiAgents is a generalized information-seeking agent system based
  on large language models (LLMs). It integrates a planning-concluding procedure,
  memory bank, and hybrid search-browse toolkit to handle user queries.
---

# KwaiAgents: Generalized Information-seeking Agent System with Large Language Models

## Quick Facts
- arXiv ID: 2312.04889
- Source URL: https://arxiv.org/abs/2312.04889
- Reference count: 40
- 7B-13B parameter open-source LLMs achieve performance comparable to GPT-4 after MAT fine-tuning

## Executive Summary
KwaiAgents is a generalized information-seeking agent system that leverages large language models as its cognitive core. The system integrates a planning-concluding procedure, memory bank, and hybrid search-browse toolkit to handle user queries effectively. Through the introduction of Meta-Agent Tuning (MAT), the framework enables smaller open-source LLMs to achieve performance levels comparable to GPT-4, demonstrating significant improvements in planning, reflection, and tool-use capabilities.

## Method Summary
The system employs a separated planning-concluding architecture where task decomposition and final response synthesis are handled in distinct stages. A hybrid search-browse toolkit combines traditional web search with entity linking to specialized knowledge sources like Wikipedia and video content. The Meta-Agent Tuning framework uses GPT-4 to generate high-quality instruction templates and responses, which are then used to fine-tune smaller 7B-13B models. A comprehensive benchmark KAgentBench was developed for both automatic and human evaluation.

## Key Results
- After MAT, Qwen-7B and Baichuan2-13B achieve performance comparable to GPT-4
- Pass rates reach 74.13% and average scores of 4.11
- Open-source agent systems outperform other open-source agent systems after MAT fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The planning-concluding procedure enables effective task decomposition and final response synthesis
- Mechanism: The system separates task planning from conclusion generation, allowing focused reasoning for both stages while maintaining conversation context
- Core assumption: Separating planning from conclusion improves response quality by reducing cognitive load
- Evidence anchors:
  - [abstract] "Within KwaiAgents, we propose an agent system that employs LLMs as its cognitive core, which is capable of understanding a user's query, behavior guidelines, and referencing external documents"
  - [section 2.4] "Task Planning: This phase leverages the gathered information to construct a comprehensive prompt for LLMs"
  - [corpus] Weak - related papers focus on end-to-end approaches rather than separated planning-concluding stages

### Mechanism 2
- Claim: The hybrid search-browse toolkit provides more reliable information than web search alone
- Mechanism: Combines traditional web search with entity linking to specialized knowledge sources like Wikipedia and video content
- Core assumption: Specialized knowledge sources contain more accurate factual information than general web search results
- Evidence anchors:
  - [section 2.3] "Drawing inspiration from Google Search and it's Knowledge Graph [1], KAgentSys adopts the aforementioned search-browse mechanism. However, it extends this approach into a 'hybrid search', which integrates traditional web searching with an entity search in Kuaipedia"
  - [section 4.5] "Combining LLMs with a search engine also falls short, as the surfaced information, while related, fails to precisely address the inquiry"
  - [corpus] Weak - neighboring papers focus on web search but don't explicitly validate hybrid approaches

### Mechanism 3
- Claim: Meta-Agent Tuning enables smaller LLMs to achieve performance comparable to GPT-4
- Mechanism: Uses GPT-4 to generate high-quality instruction templates and responses, then fine-tunes smaller models on this curated dataset
- Core assumption: High-quality synthetic data generated by larger models can effectively teach smaller models complex agent behaviors
- Evidence anchors:
  - [section 3] "We introduce the Meta-Agent Tuning (MAT) framework, designed to ensure even an open-sourced 7B or 13B model performs well among many agent systems"
  - [section 4.3] "After meta-agent tuning, Qwen-7B and Baichuan2-13B exhibit significant improvements of 15.84 and 25.95, respectively, exceeding GPT-3.5's performance"
  - [corpus] Weak - neighboring papers don't discuss synthetic data generation for fine-tuning

## Foundational Learning

- Concept: Vector-based memory retrieval
  - Why needed here: Enables efficient context retrieval from conversation history, task memory, and knowledge sources
  - Quick check question: How does the system handle memory retrieval when context exceeds maximum token limits?

- Concept: Tool specification and parameter handling
  - Why needed here: Ensures consistent tool invocation and argument passing between planning and execution stages
  - Quick check question: What format must tool arguments follow to be correctly parsed by the execution engine?

- Concept: Template-based prompt engineering
  - Why needed here: Provides structured input formats that guide LLM reasoning while maintaining flexibility for different query types
  - Quick check question: How does the system adapt template structures when encountering unexpected query patterns?

## Architecture Onboarding

- Component map: User Interface → Agent Loop (Planning → Execution → Conclusion) → Memory Bank (Conversation/Task/Knowledge) → Tool Library (Search-Browse/Time-Aware) → LLM Core
- Critical path: Query → Memory Retrieval → Task Planning → Tool Execution → Result Integration → Conclusion Generation
- Design tradeoffs: Separated planning-concluding stages add latency but improve response quality; hybrid search increases complexity but reduces misinformation
- Failure signatures: Repetitive tool calls without progress, memory retrieval returning irrelevant context, template parsing errors
- First 3 experiments:
  1. Test basic query-response cycle with simple factual questions
  2. Validate memory retrieval with multi-turn conversations
  3. Verify tool execution with controlled API responses

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the KAgentSys handle ambiguous or conflicting information retrieved from multiple sources, especially when different tools provide contradictory answers?
- Basis in paper: [explicit] The paper mentions that KAgentSys follows a certain priority (Knowledge info > Wiki > search) to resolve conflicts, but does not elaborate on the exact mechanism or criteria for resolving ambiguities.
- Why unresolved: The paper does not provide details on how the system prioritizes or reconciles conflicting information, nor does it discuss the impact of such conflicts on the final response quality.
- What evidence would resolve it: A detailed explanation of the conflict resolution algorithm, along with empirical results showing how the system handles ambiguous queries and conflicting information.

### Open Question 2
- Question: What is the long-term effectiveness of the Meta-Agent Tuning (MAT) framework in adapting to new, unseen tools and templates beyond the scope of the training data?
- Basis in paper: [inferred] The paper suggests that MAT enhances the generalization ability of open-source models, but does not provide long-term studies or evidence of sustained performance improvements.
- Why unresolved: The paper focuses on short-term improvements in benchmark performance, but does not address how well the models maintain their capabilities when exposed to entirely new tools or templates over time.
- What evidence would resolve it: Longitudinal studies comparing the performance of MAT-tuned models on new tools and templates over extended periods, along with qualitative analysis of model adaptability.

### Open Question 3
- Question: How does the hybrid search-browse toolkit perform in terms of accuracy and relevance compared to traditional search engines when handling complex, multi-faceted queries?
- Basis in paper: [explicit] The paper introduces the hybrid search-browse toolkit and claims it effectively tackles long-tail, deceptive, and obsolete information, but does not provide comparative performance metrics against traditional search engines.
- Why unresolved: The paper lacks empirical comparisons between the hybrid toolkit and traditional search engines, leaving the effectiveness of the toolkit in real-world scenarios uncertain.
- What evidence would resolve it: Head-to-head comparisons of the hybrid toolkit and traditional search engines on a diverse set of complex queries, with metrics such as accuracy, relevance, and user satisfaction.

## Limitations

- The exact mechanism for memory retrieval when context exceeds token limits is not clearly defined, which could impact performance in long conversations
- The system's reliance on specialized knowledge sources assumes these sources remain current and accurate, an assumption that may not hold over time
- The effectiveness of synthetic data generated by GPT-4 for fine-tuning smaller models depends on GPT-4's alignment with human expectations, which could drift

## Confidence

- **High Confidence:** The architectural separation of planning and concluding stages, the hybrid search-browse toolkit design, and the overall system flow are well-documented and theoretically sound
- **Medium Confidence:** The performance improvements from Meta-Agent Tuning are supported by reported metrics, but the lack of hyperparameter details and potential implementation variations make exact reproduction challenging
- **Low Confidence:** The scalability claims for long-context scenarios and the long-term reliability of specialized knowledge sources are not empirically validated

## Next Checks

1. **Memory Retrieval Validation:** Test the system with multi-turn conversations exceeding typical context window limits to verify the memory retrieval mechanism's effectiveness and identify any degradation in response quality

2. **Tool Parameter Consistency:** Create a suite of test queries that exercise edge cases in tool parameter formatting to ensure the execution engine correctly handles all valid argument structures and gracefully rejects malformed inputs

3. **Template Adaptability Testing:** Design queries that deliberately break expected patterns to evaluate how well the template system adapts and whether the LLM can recover from parsing errors without manual intervention