---
ver: rpa2
title: 'FedJudge: Federated Legal Large Language Model'
arxiv_id: '2309.08173'
source_url: https://arxiv.org/abs/2309.08173
tags:
- legal
- data
- llms
- fedjudge
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes FedJudge, the first federated learning framework
  for fine-tuning large language models (LLMs) in the legal domain. It addresses the
  data privacy challenge of centralized training by enabling local fine-tuning on
  distributed legal data across multiple institutions without sharing raw data.
---

# FedJudge: Federated Legal Large Language Model

## Quick Facts
- **arXiv ID**: 2309.08173
- **Source URL**: https://arxiv.org/abs/2309.08173
- **Reference count**: 0
- **Key outcome**: First federated learning framework for fine-tuning LLMs in legal domain, outperforming centralized baselines on three legal datasets while preserving data privacy

## Executive Summary
FedJudge introduces the first federated learning framework for fine-tuning large language models in the legal domain, addressing the critical challenge of data privacy when training on sensitive legal information distributed across multiple institutions. The framework employs parameter-efficient fine-tuning (LoRA) to minimize computational and communication overhead, and incorporates continual learning constraints to mitigate performance degradation caused by data distribution shifts across clients. Experimental results on three real-world legal datasets demonstrate that FedJudge significantly outperforms both centralized baselines and standard federated learning methods across multiple evaluation metrics.

## Method Summary
FedJudge is a federated learning framework that fine-tunes large language models for legal tasks without sharing raw data. It uses LoRA (Low-Rank Adaptation) to freeze pre-trained LLM weights and train only small adapter matrices, reducing communication overhead. The framework also implements continual learning constraints to preserve global model knowledge when training on locally heterogeneous legal data. The method aggregates client updates using a weighted average based on dataset size, and is evaluated on three legal tasks: court view generation, legal consultation, and legal reasoning.

## Key Results
- FedJudge outperforms centralized LoRA fine-tuning baselines on three legal datasets
- Achieves superior performance on multiple metrics (BERTScore, BLEU, ROUGE) compared to standard federated learning methods
- Successfully preserves data privacy while maintaining or improving model performance across heterogeneous client distributions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Parameter-efficient fine-tuning (LoRA) reduces computation and communication overhead in federated legal LLM training.
- Mechanism: LoRA freezes the LLM's pre-trained weights and introduces small trainable rank decomposition matrices, allowing only these matrices to be updated and communicated during federated training.
- Core assumption: The frozen LLM weights contain sufficient legal knowledge that can be effectively adapted using small LoRA matrices.
- Evidence anchors:
  - [abstract]: "FedJudge utilizes parameter-efficient fine-tuning methods to update only a few additional parameters during the FL training."
  - [section 2.3]: "we first employ the LoRA [13] approach to train each local client Ci, where LLMs parameters are frozen and trainable rank decomposition matrices are introduced into each layer of the Transformer architecture [16] in LLMs."
  - [corpus]: Weak evidence; the corpus contains related work on LoRA and federated learning but no direct validation of this specific mechanism in legal domain.
- Break condition: If the frozen LLM weights lack sufficient legal knowledge or the LoRA matrices cannot capture the necessary domain-specific adaptations.

### Mechanism 2
- Claim: Continual learning constraints mitigate performance degradation due to data distribution shifts across clients.
- Mechanism: When updating local models, the framework constrains the local LoRA parameters to not deviate too far from the global parameters, preserving important global knowledge.
- Core assumption: The global model parameters represent relatively minor distributional differences compared to local models and contain valuable knowledge that should be preserved.
- Evidence anchors:
  - [abstract]: "we explore the continual learning methods to preserve the global model's important parameters when training local clients to mitigate the problem of data shifts."
  - [section 2.4]: "we constrain the local LoRA parameters so that they do not forget the important global LoRA parameters with continual learning methods [14, 15]."
  - [corpus]: Weak evidence; related work exists on continual learning in federated settings but no direct evidence of effectiveness in legal data scenarios.
- Break condition: If the data distribution shifts are too large for the global model to provide useful constraints, or if the continual learning method introduces excessive regularization.

### Mechanism 3
- Claim: Weighted aggregation of client updates based on dataset size improves global model performance.
- Mechanism: The framework uses a weighted average function for aggregating local LoRA parameters, where weights are proportional to the size of each client's dataset.
- Core assumption: Clients with larger datasets provide more reliable parameter updates and should have greater influence on the global model.
- Evidence anchors:
  - [section 2.3]: "we adopt the weighted average function as fagg (·): ˆW e = Σ|Di|/Σ|Dj| W e i."
  - [corpus]: No direct evidence in corpus; this is a standard practice in federated learning but not specifically validated for legal LLMs.
- Break condition: If dataset sizes vary significantly and the largest datasets do not represent the most valuable data, or if clients with smaller but high-quality datasets are underrepresented.

## Foundational Learning

- Concept: Federated Learning
  - Why needed here: Enables training on distributed legal data without sharing sensitive information, addressing privacy concerns in legal domain.
  - Quick check question: How does federated learning differ from centralized training in terms of data privacy and model performance?

- Concept: Parameter-efficient fine-tuning (LoRA)
  - Why needed here: Reduces computational and communication overhead when fine-tuning large language models in federated settings.
  - Quick check question: What are the key components of LoRA and how do they enable efficient model adaptation?

- Concept: Continual learning
  - Why needed here: Mitigates catastrophic forgetting and helps maintain global model performance when training on heterogeneous data distributions.
  - Quick check question: How does the continual learning constraint in FedJudge work to preserve global knowledge during local training?

## Architecture Onboarding

- Component map:
  Pre-trained LLM (Baichuan-7B) -> LoRA adapter matrices -> Federated server -> Multiple clients -> Continual learning constraint

- Critical path:
  1. Initialize global LoRA parameters on server
  2. Distribute parameters to clients
  3. Local training with LoRA and continual learning constraints
  4. Upload updated LoRA parameters to server
  5. Aggregate using weighted average
  6. Distribute updated global parameters
  7. Repeat for multiple communication rounds

- Design tradeoffs:
  - LoRA rank selection (4 in this case) vs. adaptation capability and parameter count
  - Continual learning weight (λ=1) vs. local adaptation flexibility
  - Number of communication rounds (5) vs. convergence and communication cost
  - Dataset size weighting vs. influence of smaller but potentially high-quality clients

- Failure signatures:
  - Degraded performance on legal tasks compared to centralized training
  - High variance in performance across different clients
  - Slow convergence or instability in training
  - Poor generalization to unseen legal data distributions

- First 3 experiments:
  1. Baseline comparison: Evaluate FedJudge-Base against centralized LoRA fine-tuning on a single client's data
  2. Ablation study: Test FedJudge-CL with different values of the continual learning weight λ
  3. Scalability test: Measure performance and communication costs as number of clients increases from 2 to 10

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FedJudge's performance scale with increasing numbers of clients and varying data distribution heterogeneity across clients?
- Basis in paper: [inferred] The paper focuses on a 3-client setup and mentions data distribution shifts but does not explore scaling effects or heterogeneity gradients.
- Why unresolved: The experimental setup is limited to three clients with fixed data distributions, so performance under different scales and heterogeneity levels remains untested.
- What evidence would resolve it: Systematic experiments varying the number of clients (e.g., 5, 10, 20) and measuring performance under controlled data heterogeneity levels (e.g., varying KL divergence between client distributions).

### Open Question 2
- Question: What is the impact of different LoRA rank values and continual learning weight (λ) hyperparameters on FedJudge's performance and efficiency trade-offs?
- Basis in paper: [explicit] The paper sets rank=4 and λ=1 as fixed hyperparameters without exploring their sensitivity.
- Why unresolved: Only a single hyperparameter configuration is tested, so the impact of these choices on performance and efficiency is unknown.
- What evidence would resolve it: Ablation studies varying LoRA rank (e.g., 2, 8, 16) and λ values across a range, measuring both task performance and computational overhead.

### Open Question 3
- Question: How does FedJudge's performance compare to other federated learning algorithms beyond FedAvg (e.g., FedProx, SCAFFOLD) when using LoRA-based parameter-efficient fine-tuning?
- Basis in paper: [explicit] The paper only compares against FedAvg-based methods and centralized baselines.
- Why unresolved: The paper does not benchmark against alternative federated optimization algorithms that could address client drift differently.
- What evidence would resolve it: Direct comparisons of FedJudge against FedProx, SCAFFOLD, and other federated algorithms using identical LoRA fine-tuning methodology on the same datasets.

## Limitations

- The paper does not provide details on dataset sizes and distribution characteristics across clients, limiting understanding of real-world applicability
- Implementation details for the continual learning constraint and its hyperparameters are sparse, making full reproduction difficult
- Evaluation is limited to three datasets with three clients, which may not capture the complexity of real-world legal data heterogeneity

## Confidence

- **High confidence** in the core contribution: FedJudge represents a novel approach to federated legal LLM fine-tuning with sound methodology
- **Medium confidence** in the continual learning mechanism: Implementation details are sparse, limiting verification of its necessity
- **Low confidence** in generalization claims: Limited evaluation scope with only three datasets and clients

## Next Checks

1. **Ablation study of continual learning weight**: Systematically vary λ from 0 to 5 in increments of 0.5 to determine the optimal value and whether the continual learning component is truly necessary

2. **Cross-task generalization test**: Train FedJudge on one legal task and evaluate on the other two tasks to assess zero-shot transfer capabilities and identify domain-specific limitations

3. **Scalability analysis**: Evaluate FedJudge with 10-20 clients instead of 3, measuring both performance degradation and communication overhead scaling to determine practical deployment limits