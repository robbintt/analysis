---
ver: rpa2
title: Semi-Supervised Learning with Multiple Imputations on Non-Random Missing Labels
arxiv_id: '2308.07562'
source_url: https://arxiv.org/abs/2308.07562
tags:
- data
- learning
- labeled
- unlabeled
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of semi-supervised learning
  with non-randomly missing labels (MNAR), where traditional methods like CAI and
  CAP struggle due to biased class distributions. The authors propose two new methods
  to improve accuracy and reduce bias.
---

# Semi-Supervised Learning with Multiple Imputations on Non-Random Missing Labels

## Quick Facts
- **arXiv ID:** 2308.07562
- **Source URL:** https://arxiv.org/abs/2308.07562
- **Authors:** 
- **Reference count:** 0
- **Primary result:** Proposes methods to improve SSL accuracy and reduce bias with non-random missing labels, showing 10-13% accuracy improvement over FixMatch on CIFAR-10 with 150 labeled examples

## Executive Summary
This paper addresses the challenge of semi-supervised learning (SSL) when labels are missing not at random (MNAR), a scenario where traditional methods like CAI and CAP struggle due to biased class distributions. The authors propose two novel approaches: (1) combining multiple imputation models with confidence thresholds to generate reliable pseudo-labels, and (2) SSL with De-biased Imputations (SSL-DI) that filters unreliable data by finding subsets where multiple SSL models agree. Experiments on CIFAR-10 under extreme conditions (150 labeled examples, reduced network size) demonstrate significant improvements in accuracy, reduced test loss fluctuations, and increased proportion of reliable pseudo-labels.

## Method Summary
The method integrates two FixMatch models with different augmentations and initializations to generate pseudo-labels. It uses confidence-based filtering where predictions are accepted if either model exceeds 95% confidence, or two models exceed a lower threshold (τ2) and agree. The SSL-DI approach trains multiple SSL models on imputed data and selects data points where models' predictions are similar (within epsilon) to create a less-biased training subset. The final model is trained on all reliable pseudo-labels with weighted contributions based on model confidence.

## Key Results
- Improves accuracy by 10-13% compared to FixMatch under extreme conditions (150 labeled examples on CIFAR-10)
- Reduces test loss fluctuations in validation set
- Increases proportion of reliable pseudo-labels by 20%
- Successfully addresses bias issues in non-randomly missing label scenarios

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Using multiple imputation models with confidence thresholds increases the proportion of reliable pseudo-labels by 20%.
- **Mechanism:** Multiple models generate overlapping predictions; pseudo-labels are only accepted when at least one model exceeds 95% confidence, or two models exceed a lower threshold (τ2) and agree. This filtering reduces noise from low-confidence predictions.
- **Core assumption:** Models trained on the same data with different augmentations/initializations produce diverse yet accurate predictions that can be combined for higher reliability.
- **Evidence anchors:** [abstract] "create confidence intervals, and apply a threshold to ignore pseudo-labels with low confidence"; [section] "If either model's prediction confidence exceeds a threshold τ=95%, the prediction is considered reliable"
- **Break condition:** If models overfit similarly or are too correlated, confidence thresholds won't filter out errors effectively.

### Mechanism 2
- **Claim:** Selecting a subset where multiple SSL models agree reduces bias in the final trained model.
- **Mechanism:** Train multiple SSL models on imputed data, then select data points where models' predictions are similar (within epsilon). This subset is assumed to be more reliable and less biased than the full imputed set.
- **Core assumption:** Agreement among diverse models indicates higher reliability, and this subset can train a less biased final model.
- **Evidence anchors:** [abstract] "SSL with De-biased Imputations (SSL-DI), which filters unreliable data by finding subsets where multiple SSL models agree"; [section] "We first train multiple SSL models on the imputed data, and then select the subset of data where the models predict similarly"
- **Break condition:** If models are poorly calibrated or systematically biased in the same direction, agreement doesn't guarantee accuracy.

### Mechanism 3
- **Claim:** Integrating two FixMatch models with different augmentations and initializations improves accuracy by 10-13% under extreme conditions.
- **Mechanism:** Two FixMatch models process labeled data with different augmentations and initial states, then combine their pseudo-label predictions using the confidence thresholds. This increases diversity and coverage of reliable pseudo-labels.
- **Core assumption:** Different augmentation orders and initializations create sufficiently diverse models that complement each other's strengths.
- **Evidence anchors:** [section] "We maximize the use of information contained in both models to generate as many pseudo-labels as possible through two methods"; [section] "Experimental results show that our method significantly increases the number of pseudo-labels obtained"
- **Break condition:** If the two models converge to similar solutions, the diversity benefit disappears and performance gain is minimal.

## Foundational Learning

- **Concept:** Missing Not At Random (MNAR) data mechanisms
  - **Why needed here:** The paper specifically addresses the most challenging SSL scenario where missing labels contain information about the data itself
  - **Quick check question:** How does MNAR differ from MCAR and MAR in terms of class distribution assumptions?

- **Concept:** Ensemble learning and model diversity
  - **Why needed here:** The proposed method relies on combining multiple models' predictions to improve reliability
  - **Quick check question:** Why does model diversity matter more than individual model accuracy in this approach?

- **Concept:** Confidence-based filtering and threshold selection
  - **Why needed here:** The method uses confidence thresholds (95% and τ2) to accept or reject pseudo-labels
  - **Quick check question:** What's the tradeoff between using higher vs lower confidence thresholds for pseudo-label acceptance?

## Architecture Onboarding

- **Component map:** Two FixMatch models → confidence-based pseudo-label selection → combined pseudo-labels → final model training
- **Critical path:** Model training → pseudo-label generation → confidence filtering → subset selection → final training
- **Design tradeoffs:** Higher τ values reduce noise but limit labeled data; lower τ values increase coverage but introduce more errors
- **Failure signatures:** Loss fluctuations in test set (Figure 4 shows this for baseline), poor convergence, or accuracy not improving over baseline
- **First 3 experiments:**
  1. Test single FixMatch baseline vs two-model integration with τ=95% to verify accuracy improvement
  2. Vary τ2 threshold to find optimal balance between pseudo-label quantity and quality
  3. Test different model architectures or initializations to maximize diversity between the two models

## Open Questions the Paper Calls Out

- **Open Question 1:** What is the optimal number of imputation models to use for balancing accuracy and computational efficiency?
  - **Basis in paper:** [inferred] The paper mentions varying the number of imputation models can have different effects on results.
  - **Why unresolved:** The paper does not provide specific guidance on how to determine the optimal number of imputation models.
  - **What evidence would resolve it:** Experimental results comparing accuracy and computational time for different numbers of imputation models across multiple datasets.

- **Open Question 2:** How does the choice of threshold values for accepting imputations affect the bias reduction in SSL-DI?
  - **Basis in paper:** [explicit] The paper states that varying the threshold for accepting imputations can have different effects on the results.
  - **Why unresolved:** The paper does not provide a detailed analysis of how different threshold values impact bias reduction.
  - **What evidence would resolve it:** A comprehensive study examining the relationship between threshold values and bias reduction across various datasets and scenarios.

- **Open Question 3:** Can the proposed methods be effectively applied to other semi-supervised learning algorithms beyond FixMatch?
  - **Basis in paper:** [explicit] The authors mention that their method can be implemented with very little modification and can upgrade any semi-supervised learning method involving input.
  - **Why unresolved:** The paper only demonstrates the effectiveness of the methods on FixMatch and does not explore their applicability to other algorithms.
  - **What evidence would resolve it:** Experimental results showing the performance of the proposed methods when applied to different semi-supervised learning algorithms on multiple datasets.

## Limitations
- Confidence threshold selection (τ and τ2) appears ad hoc without theoretical justification or sensitivity analysis
- Limited to CIFAR-10 with extreme label scarcity (150 examples), raising questions about scalability and generalizability
- No comparison with state-of-the-art MNAR-specific methods beyond baseline FixMatch
- Missing ablation studies on the individual contributions of confidence thresholding vs model agreement filtering

## Confidence
- **High Confidence:** The MNAR problem framing is well-established in SSL literature; the methodological approach of using ensemble diversity is theoretically sound
- **Medium Confidence:** The 10-13% accuracy improvement is plausible given extreme conditions, but may not generalize to larger label budgets or different datasets
- **Low Confidence:** The specific mechanism of how confidence thresholds interact with model agreement filtering is not fully explained

## Next Checks
1. Conduct ablation study to isolate the contribution of confidence thresholding from model agreement filtering
2. Test the method on CIFAR-100 or SVHN to assess generalizability beyond CIFAR-10
3. Perform sensitivity analysis on τ and τ2 thresholds to determine optimal ranges and robustness