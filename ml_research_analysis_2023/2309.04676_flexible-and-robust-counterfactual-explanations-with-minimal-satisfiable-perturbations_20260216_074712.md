---
ver: rpa2
title: Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations
arxiv_id: '2309.04676'
source_url: https://arxiv.org/abs/2309.04676
tags:
- cfes
- features
- normal
- feature
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the issue of non-robustness in counterfactual
  explanations (CFEs), where slight input perturbations or model updates can lead
  to drastically different CFEs. The proposed method, CEMSP, generates robust and
  diverse CFEs by replacing abnormal features with the closest endpoints of their
  normal ranges, obtained from domain knowledge.
---

# Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations

## Quick Facts
- **arXiv ID:** 2309.04676
- **Source URL:** https://arxiv.org/abs/2309.04676
- **Reference count:** 40
- **One-line primary result:** CEMSP generates robust and diverse counterfactual explanations by replacing abnormal features with the closest endpoints of their normal ranges, formulated as a Boolean satisfiability problem to find minimal subsets of abnormal features to replace.

## Executive Summary
This paper addresses the issue of non-robustness in counterfactual explanations (CFEs), where slight input perturbations or model updates can lead to drastically different CFEs. The proposed method, CEMSP, generates robust and diverse CFEs by replacing abnormal features with the closest endpoints of their normal ranges, obtained from domain knowledge. CEMSP formulates the problem as a Boolean satisfiability problem to find minimal subsets of abnormal features to replace, ensuring robustness and diversity. Experiments on synthetic and real-world datasets demonstrate that CEMSP outperforms state-of-the-art methods in terms of inconsistency, sparsity, and actionability metrics, while preserving flexibility for user preferences.

## Method Summary
CEMSP generates robust and diverse counterfactual explanations by identifying abnormal features (those outside their normal ranges) and replacing them with the closest endpoints of their normal ranges. The method formulates this as a Boolean satisfiability problem (SAT), where each subset of abnormal features is represented as a Boolean assignment. A SAT solver (Z3) finds minimal satisfiable subsets that achieve the desired prediction, using pruning based on monotonicity assumptions. Additional constraints (actionability, causality, correlation) are incorporated as Boolean logic formulas. The method is evaluated on synthetic and UCI datasets (HCV, Thyroid) against baselines like GrowingSphere, PlainCF, and DiCE, using metrics including inconsistency, sparsity, diversity, and actionability.

## Key Results
- CEMSP outperforms baselines in inconsistency, sparsity, and actionability metrics on synthetic and real-world datasets
- The method generates more diverse counterfactual explanations while maintaining robustness to input perturbations and model updates
- CEMSP preserves flexibility to incorporate various practical constraints through Boolean logic encoding

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Replacing abnormal features with the closest endpoints of their normal ranges stabilizes counterfactual explanations across model updates and input perturbations.
- Mechanism: When a feature value lies outside its normal range, substituting it with the nearest endpoint of that range creates a fixed reference point. This reduces variability in the counterfactual search space because the same abnormal feature will always be replaced with the same value, regardless of slight changes in the input or model.
- Core assumption: Undesired predictions are caused by abnormal features, and moving these features into their normal ranges increases the likelihood of a desired prediction.
- Evidence anchors:
  - [abstract] "Specifically, CEMSP constrains changing values of abnormal features with the help of their semantically meaningful normal ranges."
  - [section 4.1] "We assume the normal range of each feature can be acquired from domain knowledge... We assume that the undesired prediction results from certain features outside of normal ranges..."
- Break condition: If normal ranges are inaccurate, unavailable, or if the model's decision boundary is not influenced by normal ranges, the replacement strategy will not stabilize the explanations.

### Mechanism 2
- Claim: Modeling the problem as a Boolean satisfiability problem (SAT) efficiently finds minimal subsets of abnormal features to replace, ensuring both diversity and robustness.
- Mechanism: Each subset of abnormal features is represented as a Boolean assignment. The SAT solver checks whether replacing features in that subset achieves the desired prediction. Minimal satisfiable subsets (MSS) are found by iteratively removing features while maintaining satisfiability, and pruning is applied to avoid redundant checks.
- Core assumption: The model's prediction function is monotonic with respect to replacing abnormal features with normal range endpoints.
- Evidence anchors:
  - [section 4.2] "Based on the monotonicity of function ð‘“ (ð‘Ÿ (x, Â·)), we derive the following two theorems... If ð‘“ (ð‘Ÿ (x, A)) can achieve the desired target, ð‘“ (ð‘Ÿ (x, B)) can also achieve the desired target for any superset B of A."
  - [section 4.2] "The crux lies in devising the appropriate propositional logic formulas."
- Break condition: If the monotonicity assumption does not hold (e.g., the model's prediction is non-monotonic with respect to feature changes), the pruning strategy may incorrectly eliminate valid minimal subsets.

### Mechanism 3
- Claim: Incorporating additional constraints (actionability, causality, correlation) as Boolean logic formulas allows flexible adaptation to practical requirements without sacrificing robustness.
- Mechanism: Constraints are expressed as propositional logic formulas (e.g., "do not change feature i" or "if feature 1 changes, feature 2 must also change") and conjoined with the main CNF. The SAT solver finds solutions satisfying all constraints simultaneously.
- Core assumption: Domain knowledge about feature relationships and constraints can be accurately captured as Boolean logic.
- Evidence anchors:
  - [section 4.3] "The major theme of recent research is to model various constraints into CFE generation... we show how to write these constraints by propositional logic formulas that can be conjugated into the CNF in line 1 of our Algorithm 3."
  - [section 4.3] "The great advantage of our framework is that it allows us to insert these constraints gradually and flexibly..."
- Break condition: If the Boolean logic representation of constraints is incorrect or incomplete, the generated explanations may violate practical requirements.

## Foundational Learning

- Concept: Normal ranges and their role in feature space
  - Why needed here: CEMSP relies on normal ranges to define what constitutes an "abnormal" feature and to provide fixed replacement values.
  - Quick check question: What happens if a feature's normal range is incorrectly specified? How would that affect the generated counterfactuals?

- Concept: Boolean satisfiability problem (SAT) and conjunctive normal form (CNF)
  - Why needed here: The method converts the search for minimal feature subsets into a SAT problem, using CNF to express constraints.
  - Quick check question: How does the SAT solver use the CNF to find valid assignments? What is the role of the monotonicity assumption in pruning the search space?

- Concept: Monotonicity in model predictions
  - Why needed here: The pruning strategy in CEMSP relies on the assumption that replacing more abnormal features with normal range endpoints cannot decrease the probability of the desired prediction.
  - Quick check question: Can you think of a scenario where this monotonicity assumption might not hold? How would that impact the algorithm's correctness?

## Architecture Onboarding

- Component map:
  - Input preprocessing: Normalize features, identify abnormal features based on normal ranges
  - SAT solver interface: Convert feature subsets to Boolean assignments, check satisfiability
  - Model prediction module: Evaluate whether a given feature replacement achieves the desired prediction
  - Constraint encoding: Express actionability, causality, and correlation as Boolean logic
  - Output generation: Collect minimal satisfiable subsets and construct final counterfactual explanations

- Critical path:
  1. Identify abnormal features (N0) and normal features (N1)
  2. Initialize CNF with constraints (e.g., do not change normal features)
  3. Use SAT solver to find a valid Boolean assignment (m)
  4. Convert m to feature subset A
  5. Check if replacing features in A achieves desired prediction
  6. If yes, shrink A to minimal subset and yield CFE; if no, grow A to maximal unsatisfiable subset and prune
  7. Repeat until no more valid assignments

- Design tradeoffs:
  - Precision vs. efficiency: Using exact SAT solving ensures correctness but can be slow for high-dimensional data
  - Flexibility vs. complexity: Supporting many constraints increases expressiveness but complicates CNF construction
  - Fixed endpoints vs. continuous perturbations: Using normal range endpoints stabilizes explanations but may yield less natural counterfactuals

- Failure signatures:
  - SAT solver returns no solutions despite valid CFEs existing (likely due to incorrect CNF encoding)
  - Generated explanations do not satisfy practical constraints (likely due to incorrect Boolean logic encoding)
  - Inconsistency metrics remain high despite using CEMSP (possible violation of monotonicity assumption or inaccurate normal ranges)

- First 3 experiments:
  1. **Sanity check with synthetic data**: Use a simple synthetic dataset with known normal ranges and verify that CEMSP returns diverse, minimal, and consistent CFEs
  2. **Constraint integration test**: Add actionability constraints to a medical dataset and confirm that generated CFEs respect immutable features
  3. **Robustness evaluation**: Measure inconsistency scores under input perturbations and model retraining, comparing CEMSP to baseline methods

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the scalability of CEMSP compare to traditional CFE methods as the number of features increases?
- Basis in paper: [explicit] The paper mentions that SAT solvers exhibit exponential complexity in the worst-case scenario and that CEMSP may not scale well for a substantial number of features.
- Why unresolved: The paper does not provide empirical comparisons of execution time between CEMSP and traditional methods for varying numbers of features.
- What evidence would resolve it: Empirical results showing the execution time of CEMSP versus traditional CFE methods for datasets with increasing numbers of features.

### Open Question 2
- Question: How can CEMSP be adapted for multi-class classification or regression tasks?
- Basis in paper: [explicit] The paper states that CEMSP is established on binary classification tasks and that its direct adaptation to multi-class classification or regression tasks remains challenging.
- Why unresolved: The paper does not provide a method or framework for extending CEMSP to multi-class or regression tasks.
- What evidence would resolve it: A proposed method or framework for extending CEMSP to multi-class classification or regression tasks, along with experimental results demonstrating its effectiveness.

### Open Question 3
- Question: How can CEMSP handle situations where a portion of the normal ranges is unknown?
- Basis in paper: [explicit] The paper mentions that CEMSP is not directly applicable to scenarios where a portion of normal ranges is unknown and suggests incorporating additional information to determine appropriate replacement values.
- Why unresolved: The paper does not provide a specific approach for handling unknown normal ranges.
- What evidence would resolve it: A proposed approach for handling unknown normal ranges in CEMSP, along with experimental results demonstrating its effectiveness.

## Limitations
- SAT solver complexity may limit scalability for high-dimensional datasets with many abnormal features
- The method's effectiveness depends on accurate normal ranges, which may not always be available or reliable
- CEMSP is currently limited to binary classification tasks and requires extension for multi-class or regression scenarios

## Confidence
- High confidence in the SAT formulation and pruning strategy (Mechanism 2)
- Medium confidence in the normal range replacement strategy (Mechanism 1) due to potential sensitivity to inaccurate normal ranges
- Medium confidence in constraint flexibility (Mechanism 3) as practical effectiveness depends on accurate Boolean logic encoding

## Next Checks
1. Test CEMSP on a high-dimensional dataset (e.g., >50 features) to evaluate SAT solver scalability and compare runtime with baseline methods
2. Conduct ablation studies where normal ranges are intentionally mis-specified to quantify the impact on explanation robustness and consistency
3. Evaluate the method on models with known non-monotonic decision boundaries to test the validity of the monotonicity assumption