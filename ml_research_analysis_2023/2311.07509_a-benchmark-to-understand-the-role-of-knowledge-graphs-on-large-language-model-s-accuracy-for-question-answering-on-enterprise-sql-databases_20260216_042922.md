---
ver: rpa2
title: A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's
  Accuracy for Question Answering on Enterprise SQL Databases
arxiv_id: '2311.07509'
source_url: https://arxiv.org/abs/2311.07509
tags:
- data
- identifier
- claim
- world
- policy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study benchmarks Large Language Models (LLMs) for answering
  enterprise questions on enterprise SQL databases, investigating the role of Knowledge
  Graphs (KGs) in improving accuracy. The benchmark comprises an enterprise SQL schema
  in the insurance domain, a range of enterprise queries, and a contextual layer incorporating
  an ontology and mappings that define a KG.
---

# A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases

## Quick Facts
- arXiv ID: 2311.07509
- Source URL: https://arxiv.org/abs/2311.07509
- Reference count: 40
- Primary result: Using knowledge graphs improves LLM accuracy for enterprise question answering from 16.7% to 54.2% (37.5% improvement)

## Executive Summary
This study benchmarks Large Language Models for answering enterprise questions over SQL databases, specifically investigating whether knowledge graphs improve accuracy. Using GPT-4 with zero-shot prompting, the research team created a benchmark with an insurance domain SQL schema, 43 natural language questions, and both SQL and knowledge graph representations. The results demonstrate that incorporating a knowledge graph representation of the SQL database increases accuracy from 16.7% to 54.2%, representing a 37.5% improvement. This suggests that knowledge graphs provide higher accuracy for LLM-powered question answering systems in enterprise contexts.

## Method Summary
The benchmark evaluates LLMs using an enterprise SQL schema from the insurance domain (13 tables), 43 natural language questions of varying complexity, and a contextual layer including an ontology and mappings that define a knowledge graph. The method involves zero-shot prompting with GPT-4 to generate SQL or SPARQL queries from natural language questions, executing these queries against either the database or knowledge graph, and comparing results to reference answers. Accuracy is measured through Execution Accuracy (EA), Overall Execution Accuracy (OEA), and Average Overall Execution Accuracy (AOEA) metrics, comparing performance between SQL-only and KG-enhanced approaches.

## Key Results
- LLM accuracy on enterprise questions over SQL databases: 16.7%
- LLM accuracy with knowledge graph representation: 54.2%
- Accuracy improvement when using knowledge graphs: 37.5%
- Accuracy drops to 0% for complex schemas with many joins regardless of question complexity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Providing business context via an ontology and mappings improves LLM accuracy for question answering over SQL databases
- Mechanism: The ontology and mappings transform the flat relational schema into a semantically rich knowledge graph that aligns business terms with data structures, allowing LLMs to reason about entities and relationships rather than just table/column syntax
- Core assumption: The LLM can leverage the structured semantic information in the ontology to better interpret natural language questions and generate accurate queries
- Evidence anchors:
  - "This accuracy increased to 54.2% when a Knowledge Graph representation of the SQL database was used, thus an accuracy improvement of 37.5%."
  - "The hypothesis is the following: An LLM powered question answering system that answers a natural language question over a knowledge graph representation of the SQL database returns more accurate results than a LLM powered question answering system that answers a natural language question over the SQL database without a knowledge graph."
- Break condition: If the ontology becomes too large for the LLM's context window or if the mappings are incorrect/incomplete, the accuracy improvement may diminish or reverse

### Mechanism 2
- Claim: LLMs can leverage primary key/foreign key constraints in the SQL DDL to generate valid joins, but struggle with complex schemas requiring many joins
- Mechanism: The LLM parses the DDL to understand table relationships and uses this to construct SQL queries with appropriate JOIN clauses. However, as the number of tables and complexity of relationships increases, the accuracy decreases
- Core assumption: The LLM's understanding of SQL syntax and semantics is sufficient to translate natural language questions into valid SQL queries when provided with the DDL
- Evidence anchors:
  - "The question answering system for SQL is shown in Figure 4. The question and the SQL DDL for the database are provided as zero-shot prompt to GPT-4."
  - "For Low Question/Low Schema, the Overall Execution Accuracy was 25.5%. For High Question/Low Schema, the Overall Execution Accuracy was 37.%. However, for both Low Question/High Schema and High Question/High Schema, the accuracy was 0%."
- Break condition: If the schema exceeds the LLM's ability to parse and reason about relationships, or if the DDL is missing important constraints, the accuracy will drop to zero

### Mechanism 3
- Claim: LLMs generate more accurate SPARQL queries over a knowledge graph because the semantic context reduces hallucinations compared to SQL
- Mechanism: The knowledge graph provides a semantic layer that guides the LLM to use existing properties and relationships, reducing the likelihood of generating non-existent columns or incorrect joins
- Core assumption: The LLM's understanding of SPARQL and the ontology's structure is sufficient to generate valid queries that leverage the semantic relationships
- Evidence anchors:
  - "The inaccuracy of SQL queries are based on hallucination while the inaccuracy of SPARQL queries are based on path inconsistency."
  - "Another issue we observed is that for a question that involved determining the average days between two dates, the generated SQL and SPARQL were both semantically correct but the reason the query did not execute was due to a syntax error on date diff."
- Break condition: If the ontology is too complex or if the LLM struggles with the additional layer of abstraction, the accuracy improvement may diminish

## Foundational Learning

- Concept: SQL DDL and its role in defining database structure
  - Why needed here: The LLM uses the DDL to understand table relationships and generate valid SQL queries
  - Quick check question: What is the purpose of a foreign key constraint in a SQL DDL?

- Concept: RDF, OWL, and SPARQL for representing and querying knowledge graphs
  - Why needed here: The ontology is expressed in OWL and the knowledge graph is queried using SPARQL
  - Quick check question: What is the difference between an object property and a datatype property in OWL?

- Concept: R2RML for mapping relational data to RDF
  - Why needed here: The R2RML mappings are used to create the knowledge graph representation of the SQL database
  - Quick check question: What is the purpose of a triples map in R2RML?

## Architecture Onboarding

- Component map: Natural Language Question -> LLM (GPT-4) -> SQL DDL or OWL Ontology (context) -> SQL or SPARQL Query Generator -> Database or Knowledge Graph -> Query Execution Engine -> Results

- Critical path: Natural Language Question -> LLM (with context) -> Query Generator -> Query Execution Engine -> Results

- Design tradeoffs:
  - Using a knowledge graph improves accuracy but adds complexity and requires additional infrastructure
  - Zero-shot prompting is simpler but may be less accurate than few-shot or chain-of-thought prompting
  - Including the full DDL or ontology in the context window may exceed token limits for large schemas

- Failure signatures:
  - SQL: Hallucinations (non-existent columns, incorrect joins)
  - SPARQL: Path inconsistencies (incorrect property paths)
  - Both: Syntax errors, incomplete results, timeouts

- First 3 experiments:
  1. Replicate the benchmark results using a different LLM (e.g., Llama) to compare accuracy
  2. Test the impact of including additional constraints (e.g., check constraints) in the DDL on SQL accuracy
  3. Evaluate the effect of using few-shot or chain-of-thought prompting on SPARQL accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the accuracy of LLM-powered question answering systems change when using more complex enterprise SQL schemas with a larger number of tables?
- Basis in paper: The paper suggests that the accuracy of LLM-powered question answering systems decreases when the schema complexity increases, with no accurate responses for Low Question/High Schema and High Question/High Schema questions
- Why unresolved: The current benchmark only uses a subset of the OMG P&C Data Model, and the paper does not provide information on how the accuracy changes when using more complex schemas with a larger number of tables
- What evidence would resolve it: Additional experiments using more complex enterprise SQL schemas with a larger number of tables and evaluating the accuracy of LLM-powered question answering systems

### Open Question 2
- Question: How do different prompting strategies (e.g., few-shot, chain of thought) affect the accuracy of LLM-powered question answering systems on enterprise SQL databases?
- Basis in paper: The paper mentions that the current prompt is a simple zero-shot prompt and suggests testing different types of prompting strategies
- Why unresolved: The paper only uses a simple zero-shot prompt and does not provide information on how different prompting strategies affect the accuracy of LLM-powered question answering systems
- What evidence would resolve it: Experiments using different prompting strategies and evaluating their impact on the accuracy of LLM-powered question answering systems on enterprise SQL databases

### Open Question 3
- Question: How does the accuracy of LLM-powered question answering systems change when using different types of enterprise questions (e.g., multi-turn conversations, questions in multiple languages)?
- Basis in paper: The paper suggests that the current questions are projections and joins and lack filtering, and mentions that questions can be in multiple languages and multi-turn conversations
- Why unresolved: The current benchmark only uses a limited set of enterprise questions, and the paper does not provide information on how the accuracy changes when using different types of enterprise questions
- What evidence would resolve it: Additional experiments using different types of enterprise questions (e.g., multi-turn conversations, questions in multiple languages) and evaluating the accuracy of LLM-powered question answering systems

## Limitations
- The 37.5% accuracy improvement is based on a single enterprise schema in the insurance domain with 13 tables and 43 questions, limiting generalizability
- The study relies on GPT-4 zero-shot prompting without exploring parameter tuning or alternative prompting strategies
- Direct comparison between SQL and SPARQL accuracy is complicated by different failure modes (hallucinations vs. path inconsistencies)

## Confidence
- High confidence: The mechanism by which knowledge graphs improve accuracy through semantic context is well-supported by the empirical results and aligns with established principles of semantic web technologies
- Medium confidence: The specific 37.5% improvement figure is reliable for this particular benchmark but may not generalize across different domains or schema complexities
- Medium confidence: The claim that LLMs struggle with complex schemas requiring many joins is supported by the zero accuracy results for high complexity cases, though the study only tested one schema

## Next Checks
1. Replicate the benchmark using a different enterprise domain (e.g., healthcare or finance) to assess generalizability of the knowledge graph accuracy improvement
2. Test the impact of increasing the number of tables and relationships beyond 13 to determine the threshold where accuracy degrades significantly
3. Compare zero-shot results against few-shot and chain-of-thought prompting approaches to determine if accuracy improvements can be achieved without knowledge graphs