---
ver: rpa2
title: Modeling Boundedly Rational Agents with Latent Inference Budgets
arxiv_id: '2312.04030'
source_url: https://arxiv.org/abs/2312.04030
tags:
- runtime
- inferred
- inference
- agents
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces latent inference budget models (L-IBMs) for
  modeling agents with unknown goals and computational constraints. Unlike standard
  models that add noise to optimal decisions, L-IBMs explicitly model agents' inference
  budgets via a latent variable controlling the runtime of iterative inference algorithms.
---

# Modeling Boundedly Rational Agents with Latent Inference Budgets

## Quick Facts
- arXiv ID: 2312.04030
- Source URL: https://arxiv.org/abs/2312.04030
- Authors: 
- Reference count: 19
- Key outcome: Introduces latent inference budget models (L-IBMs) that explicitly model agents' computational constraints via latent variables controlling inference algorithm runtime, showing superior performance to Boltzmann models in three diverse tasks while providing interpretable measures of inferential capacity.

## Executive Summary
This paper introduces latent inference budget models (L-IBMs) for modeling agents with unknown goals and computational constraints. Unlike standard models that add noise to optimal decisions, L-IBMs explicitly model agents' inference budgets via a latent variable controlling the runtime of iterative inference algorithms. The authors show that L-IBMs can be efficiently inferred from example behaviors in three diverse tasks: maze navigation, pragmatic language understanding, and chess gameplay. In maze navigation, L-IBMs significantly outperform Boltzmann models in predicting agent actions and inferring meaningful parameters. For language understanding, L-IBMs infer individual differences in pragmatic reasoning across speakers. In chess, L-IBMs model variability in player decisions across game states and correlate with measures of player skill and task difficulty.

## Method Summary
L-IBM is a framework for modeling boundedly rational agents by treating the budget parameter as controlling the runtime of an anytime inference algorithm. The model jointly infers rewards and budget parameters using maximum a posteriori inference. It is applied across three domains using anytime algorithms: truncated breadth-first search for maze navigation, Rational Speech Acts model for pragmatic language understanding, and Monte Carlo tree search for chess gameplay. The framework marginalizes over possible budget values efficiently when using anytime algorithms, allowing it to capture both reward structure and computational constraints that influence agent behavior.

## Key Results
- In maze navigation, L-IBM significantly outperforms Boltzmann models in action prediction accuracy and recovers correct reward parameters
- For language understanding, L-IBM infers individual differences in pragmatic reasoning budgets across speakers that correlate with task difficulty
- In chess, L-IBM models variability in player decisions across game states and inference budgets correlate with player Elo ratings and time controls

## Why This Works (Mechanism)

### Mechanism 1
- Claim: L-IBM efficiently models agents with unknown computational constraints by explicitly parameterizing inference runtime rather than adding noise to optimal decisions.
- Mechanism: L-IBM treats the budget parameter as controlling the runtime of an anytime inference algorithm, allowing efficient marginalization over budgets since anytime algorithms can be truncated at any point.
- Core assumption: The agent's decision procedure can be modeled as an anytime algorithm where intermediate inference states are useful for action selection.
- Evidence anchors:
  - [abstract] "L-IBMs explicitly model agents' inference budgets via a latent variable controlling the runtime of iterative inference algorithms."
  - [section 3] "if π is an anytime inference algorithm (Dean & Boddy, 1988), we can evaluate n values of β as quickly as we can evaluate one"
  - [corpus] No direct evidence found for anytime algorithms in related work
- Break condition: If the agent's inference procedure is not anytime, then evaluating Eq. 2 becomes intractable and L-IBM loses its computational advantage.

### Mechanism 2
- Claim: Inferred inference budgets capture meaningful differences in agent capabilities and task difficulty.
- Mechanism: By jointly inferring rewards and budget parameters, L-IBM can distinguish between suboptimality due to limited computational resources versus different reward structures.
- Core assumption: Different agents or different task conditions require different inference budgets to explain their behavior.
- Evidence anchors:
  - [abstract] "Inferred inference budgets are themselves meaningful, efficient to compute, and correlated with measures of player skill, partner skill and task difficulty."
  - [section 6] "Here, we observe that as the player strength or the opponent strength increases as measured by the Elo ratings, βruntime infers higher runtime."
  - [corpus] No direct evidence found for budget-parameter correlations in related work
- Break condition: If all agents actually use similar budgets regardless of skill or difficulty, the inferred differences would be spurious and uninterpretable.

### Mechanism 3
- Claim: L-IBM outperforms Boltzmann models by accounting for the computational cost of acquiring value estimates.
- Mechanism: Unlike Boltzmann models that only depend on action values, L-IBM's budget parameter captures how long agents spend computing those values, explaining behavior differences in identical states with different search complexities.
- Core assumption: Agents face varying computational costs for value estimation across different states or tasks.
- Evidence anchors:
  - [abstract] "In standard models of bounded rationality, sub-optimal decision-making is simulated by adding homoscedastic noise to optimal decisions rather than explicitly simulating constrained inference."
  - [section 2] "A model of boundedly rational decision-making with the form of Eq. (1) cannot account for this difference."
  - [corpus] No direct evidence found for computational cost modeling in related work
- Break condition: If all states have similar computational complexity for value estimation, the budget parameter becomes redundant with the noise parameter.

## Foundational Learning

- Concept: Markov Decision Processes
  - Why needed here: The framework models agents acting in MDPs to maximize unknown reward functions
  - Quick check question: What distinguishes an MDP from a simpler Markov chain?

- Concept: Anytime algorithms
  - Why needed here: L-IBM's computational efficiency relies on anytime algorithms that produce useful intermediate results
  - Quick check question: How does an anytime algorithm differ from a standard iterative algorithm?

- Concept: Maximum a posteriori inference
  - Why needed here: L-IBM uses MAP inference to jointly estimate rewards and budget parameters
  - Quick check question: What is the key difference between MAP and maximum likelihood estimation?

## Architecture Onboarding

- Component map:
  - Agent model: Maps states to actions using reward parameters and budget
  - Inference algorithm: Anytime procedure generating intermediate states
  - Budget prior: Distribution over inference budgets (learned per agent)
  - Learning system: MAP inference over rewards and budget parameters

- Critical path:
  1. Agent generates trajectory using reward function and budget
  2. Learning system observes trajectory
  3. Jointly infer reward parameters and budget distribution
  4. Use inferred model for prediction or analysis

- Design tradeoffs:
  - Anytime vs non-anytime algorithms: Anytime allows efficient budget marginalization
  - Fixed vs learned budget: Learning captures individual differences but requires more data
  - Reward parameterization: More complex rewards improve fit but increase parameter count

- Failure signatures:
  - Poor action prediction: Indicates incorrect reward or budget inference
  - Uninterpretable budgets: Suggests model mismatch with agent's actual decision process
  - Computational inefficiency: May indicate non-anytime algorithm used

- First 3 experiments:
  1. Implement truncated BFS on simple maze with known rewards to verify L-IBM recovers correct parameters
  2. Compare L-IBM vs Boltzmann on maze data with varying search complexities
  3. Apply L-IBM to synthetic RSA data with known iteration counts to test budget inference

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the latent inference budget model (L-IBM) perform on more complex, real-world decision-making tasks beyond the three domains explored in the paper (maze navigation, pragmatic language understanding, and chess gameplay)?
- Basis in paper: [explicit] The paper mentions that L-IBM is a general framework applicable to all anytime inference algorithms and could potentially be applied to more complex tasks.
- Why unresolved: The paper only evaluates L-IBM on three specific tasks, leaving its performance on other complex tasks unknown.
- What evidence would resolve it: Conducting experiments applying L-IBM to a wider range of real-world decision-making tasks and comparing its performance to other state-of-the-art models.

### Open Question 2
- Question: Can the latent inference budget (βruntime) inferred by L-IBM be used to predict or improve the performance of agents in novel situations?
- Basis in paper: [inferred] The paper shows that inferred βruntime correlates with measures of player skill, partner skill, and task difficulty, suggesting it captures meaningful aspects of agent behavior.
- Why unresolved: The paper does not explore whether βruntime can be used for prediction or improvement in new contexts.
- What evidence would resolve it: Designing experiments where agents with known βruntime are evaluated on new tasks, and comparing their performance to agents with different βruntime values.

### Open Question 3
- Question: How does the choice of the prior distribution over inference budgets (pbudget) affect the performance and interpretability of L-IBM?
- Basis in paper: [explicit] The paper mentions that pbudget is an agent-specific prior distribution, but does not explore the impact of different choices for this distribution.
- Why unresolved: The paper uses a fixed prior distribution, leaving the effect of alternative choices unknown.
- What evidence would resolve it: Conducting experiments with different prior distributions and evaluating their impact on the accuracy, efficiency, and interpretability of L-IBM.

## Limitations
- Limited validation that real-world agents (particularly humans) actually use anytime inference algorithms
- Reliance on computational anytime algorithms (MCTS) for chess experiments may not reflect human search strategies
- The mechanism for human RSA-like reasoning in language understanding remains debated

## Confidence
- High confidence: L-IBM's superior action prediction accuracy in maze navigation compared to Boltzmann models
- Medium confidence: The interpretability of inferred budgets as measures of skill/difficulty in chess, given the computational nature of MCTS
- Low confidence: The claim that L-IBM captures genuine individual differences in pragmatic reasoning across speakers, as the mechanism for human RSA-like reasoning remains debated

## Next Checks
1. Test L-IBM on maze navigation data generated by non-anytime algorithms (e.g., depth-limited DFS without intermediate value updates) to verify computational efficiency claims
2. Conduct ablation studies removing the anytime property from MCTS to assess impact on L-IBM's chess performance
3. Compare L-IBM's RSA budget inferences against direct measures of human reasoning time in the reference game task