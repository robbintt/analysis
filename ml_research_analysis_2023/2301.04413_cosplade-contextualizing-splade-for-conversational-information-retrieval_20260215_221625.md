---
ver: rpa2
title: 'CoSPLADE: Contextualizing SPLADE for Conversational Information Retrieval'
arxiv_id: '2301.04413'
source_url: https://arxiv.org/abs/2301.04413
tags:
- query
- splade
- trec
- conversational
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CoSPLADE proposes a lightweight training approach for first-stage
  ranking in conversational search. It contextualizes SPLADE sparse representations
  by incorporating both query history and system-provided answers using a dual-encoder
  architecture with an asymmetric MSE loss.
---

# CoSPLADE: Contextualizing SPLADE for Conversational Information Retrieval

## Quick Facts
- **arXiv ID**: 2301.04413
- **Source URL**: https://arxiv.org/abs/2301.04413
- **Reference count**: 39
- **Primary result**: Achieves state-of-the-art recall and competitive precision on TREC CAsT 2020/2021 using dual-encoder SPLADE with asymmetric MSE loss and T5-based reranking

## Executive Summary
CoSPLADE proposes a lightweight training approach for first-stage ranking in conversational search that contextualizes SPLADE sparse representations by incorporating both query history and system-provided answers. The method uses a dual-encoder architecture with an asymmetric MSE loss function that encourages answer representations to include terms from gold queries. When combined with a T5-based reranker that uses keywords extracted from the first-stage SPLADE output, the system achieves state-of-the-art recall and competitive precision metrics on TREC CAsT 2020 and 2021, outperforming previous methods and matching top TREC participants.

## Method Summary
CoSPLADE contextualizes SPLADE sparse representations for conversational search using a dual-encoder architecture that processes query history and system answers separately. The model is trained on CANARD data using an asymmetric MSE loss that pushes answer representations to match gold query representations. For retrieval, it uses standard inverted indices with pre-trained SPLADE document representations. A T5-based reranker receives enriched input through keywords extracted from first-stage SPLADE output, formatted as "Keywords: w1, w2, ..., wK". The approach avoids query reformulation bottlenecks by learning directly from gold queries while maintaining computational efficiency through sparse representations.

## Key Results
- Achieves state-of-the-art recall@500/1000 on TREC CAsT 2020 and 2021
- Competitive MAP and MRR scores compared to top TREC participants
- First-stage ranker effectiveness improved through asymmetric MSE loss and answer incorporation
- Simple keyword extraction from SPLADE weights provides effective conversational context for T5 reranker

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual-encoder architecture with asymmetric MSE loss effectively contextualizes queries by leveraging both query history and system-provided answers
- Mechanism: Two separate SPLADE encoders (query history and answers) with asymmetric MSE loss that pushes answer representations to include tokens from gold answers
- Core assumption: Gold queries in CANARD provide reasonable supervision for learning contextualized representations
- Evidence anchors: Asymmetric loss formulation explicitly encourages answer encoder to extract relevant terms from answers

### Mechanism 2
- Claim: SPLADE's sparse representations enable efficient first-stage ranking while maintaining competitive effectiveness
- Mechanism: Sparse vectors in BERT vocabulary space allow using standard inverted indices while learned weights capture semantic relationships
- Core assumption: Sparse representation captures sufficient semantic information for ranking while remaining computationally efficient
- Evidence anchors: SPLADE shows results on par with dense approaches while exhibiting stronger zero-shot generalization

### Mechanism 3
- Claim: T5 reranker benefits from keywords extracted from first-stage SPLADE output
- Mechanism: SPLADE identifies important terms through learned weights, which are extracted and formatted as keywords for T5 input
- Core assumption: SPLADE's learned term weights effectively identify most relevant terms for contextualizing queries
- Evidence anchors: Results show competitive performance when combining first-stage SPLADE with T5Mono reranker

## Foundational Learning

- **Sparse neural retrieval models**: Understanding SPLADE's sparse representation framework and advantages over dense retrieval
  - Why needed: Entire approach builds on SPLADE's sparse representation framework
  - Quick check: What are computational advantages of sparse vs dense representations, and how does SPLADE achieve sparsity?

- **Asymmetric loss functions**: Knowledge of how asymmetric loss handles imbalanced supervision in training
  - Why needed: Asymmetric MSE loss addresses limitation of gold queries being conservative expansions
  - Quick check: How does asymmetric loss differ from standard MSE, and why useful when gold queries may be incomplete?

- **Dual-encoder architectures**: Understanding training dynamics of multiple encoders with different objectives
  - Why needed: Model uses separate encoders for queries and answers requiring different training strategies
  - Quick check: What challenges arise in training dual-encoder architectures, and how does proposed loss address them?

## Architecture Onboarding

- **Component map**: Conversation history → Dual SPLADE encoders → Asymmetric MSE loss → Sparse document retrieval → Keyword extraction → T5Mono reranking → Final results
- **Critical path**: Conversation history → Dual SPLADE encoders → Asymmetric MSE loss → Sparse document retrieval → Keyword extraction → T5Mono reranking → Final results
- **Design tradeoffs**: Sparse vs dense representations (efficiency vs semantic matching), asymmetric loss (encourages answer incorporation vs overemphasis), simple keyword extraction vs complex reformulation (faster vs potentially less precise)
- **Failure signatures**: Poor recall (asymmetric loss too aggressive), low precision after reranking (keyword extraction including too many irrelevant terms), slow inference (sparse representations becoming too dense)
- **First 3 experiments**: 1) Ablation study comparing asymmetric MSE vs standard MSE vs cosine loss on CANARD dev set; 2) Answer incorporation variants testing different answer processing strategies; 3) Keyword extraction sensitivity varying K and measuring impact on reranking effectiveness

## Open Questions the Paper Calls Out

- **Generalization to other datasets**: How does CoSPLADE perform on conversational search datasets beyond TREC CAsT? The paper demonstrates effectiveness on TREC CAsT but doesn't explore generalizability to other conversational datasets. Evaluating on other conversational search datasets would provide evidence of generalizability.

- **Impact of different numbers of past answers**: What is the impact of using different numbers of past answers (k) in the CoSPLADE model on performance? The paper only considers k=1 and k=n-1 without comprehensive analysis across a range of values. Experiments with varying k values would provide insights into optimal number of past answers.

- **Handling user feedback**: How does the CoSPLADE model handle user feedback in conversational search? The paper mentions future work may explore strategies for user feedback but doesn't investigate incorporation mechanisms. Developing and evaluating feedback incorporation methods would provide evidence of handling user feedback.

## Limitations

- Reliance on CANARD's gold queries as supervision may not fully capture true conversational information needs
- Keyword extraction heuristic from SPLADE weights may miss nuanced conversational context
- Asymmetric loss assumes meaningful information in gap between predicted and gold representations

## Confidence

- **High confidence**: Effectiveness of dual-encoder architecture with asymmetric MSE loss for first-stage ranking (consistent improvements on TREC CAsT)
- **Medium confidence**: Generalization capability of learned representations beyond CANARD training domain (sparse representations typically generalize well, but contextualized representations may be domain-dependent)
- **Low confidence**: Optimality of keyword extraction heuristic for T5 reranker (simple approach works well empirically but may not be most effective)

## Next Checks

1. **Ablation on asymmetric loss variants**: Systematically compare asymmetric MSE against standard MSE and cosine similarity losses on CANARD dev set to quantify exact contribution of asymmetric formulation

2. **Zero-shot generalization test**: Evaluate CoSPLADE on a different conversational search dataset (e.g., CAsT-like data from another domain) without fine-tuning to assess true generalization capabilities

3. **Keyword extraction sensitivity analysis**: Vary number of keywords (K) from 1 to 20 and measure impact on reranking effectiveness, including qualitative analysis of which terms are selected and whether they capture conversational context effectively