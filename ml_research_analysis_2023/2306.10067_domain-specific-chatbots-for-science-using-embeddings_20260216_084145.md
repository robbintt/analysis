---
ver: rpa2
title: Domain-specific ChatBots for Science using Embeddings
arxiv_id: '2306.10067'
source_url: https://arxiv.org/abs/2306.10067
tags:
- response
- text
- chunks
- scattering
- morphologies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work demonstrates how existing text and image embedding models
  can be combined with large language models to build domain-specific chatbots for
  physical sciences. Scientific documents are converted into text chunks with semantic
  embeddings, which are prepended to user queries to provide context for the LLM.
---

# Domain-specific ChatBots for Science using Embeddings

## Quick Facts
- arXiv ID: 2306.10067
- Source URL: https://arxiv.org/abs/2306.10067
- Reference count: 40
- One-line primary result: Combines text/image embeddings with LLMs to build domain-specific scientific chatbots

## Executive Summary
This work demonstrates how existing text and image embedding models can be combined with large language models to build domain-specific chatbots for physical sciences. Scientific documents are converted into text chunks with semantic embeddings, which are prepended to user queries to provide context for the LLM. This significantly improves response quality and enables direct citation of sources. Image embeddings enable semantic search across scientific figures. The approach is shown to be effective for literature search, experimental planning, and hypothesis testing, suggesting that domain-specific chatbots are already viable for accelerating scientific research.

## Method Summary
The method converts scientific documents into overlapping text chunks, each converted into a 1,536-dimensional embedding vector using OpenAI's text-embedding-ada-002 model. When a user query is received, its embedding is computed and compared via cosine similarity to all chunk embeddings. The most similar chunks are prepended to the user query, providing contextual information for the LLM to generate accurate responses with direct citations. For image search, publication figures are extracted and converted into image embedding vectors using the CLIP model, enabling semantic search across visually similar figures. The system uses MySQL for database storage and GPT-3.5 or GPT-4 for response generation.

## Key Results
- Text embedding lookup provides semantically relevant context for LLM responses, enabling accurate domain-specific answers
- Image embeddings enable semantic search across scientific figures, allowing researchers to find visually similar data
- Combining raw text chunks with LLM-generated summaries in prompts improves response quality by providing both detailed information and concise overviews

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Text embedding lookup provides semantically relevant context for LLM responses, enabling accurate domain-specific answers
- Mechanism: Scientific documents are chunked into overlapping text segments, each converted into a 1,536-dimensional embedding vector using a text embedding model. When a user query is received, its embedding is computed and compared via cosine similarity to all chunk embeddings. The most similar chunks are prepended to the user query, providing contextual information for the LLM to generate accurate responses with direct citations.
- Core assumption: The text embedding model captures meaningful semantic relationships between scientific concepts and can retrieve relevant chunks based on query similarity.
- Evidence anchors:
  - [abstract]: "Scientific documents are converted into text chunks with semantic embeddings, which are prepended to user queries to provide context for the LLM."
  - [section]: "Text embedding is a natural language processing (NLP) method whereby text is converted into a real-valued vector that encodes the meaning... For instance, words that are close in the embedding space are expected to be similar in meaning."
  - [corpus]: Weak - No direct corpus evidence provided for embedding effectiveness in this specific scientific domain.

### Mechanism 2
- Claim: Image embedding enables semantic search across scientific figures, allowing researchers to find visually similar data
- Mechanism: Publication figures are extracted and converted into image embedding vectors using the CLIP model, which provides visual understanding based on meaningful semantics. When a user inputs an image, its embedding is computed and compared to the database embeddings using Euclidean distance or cosine similarity to retrieve semantically similar figures.
- Core assumption: The CLIP model generalizes to scientific images and captures meaningful visual semantics beyond simple pixel matching.
- Evidence anchors:
  - [abstract]: "Image embeddings enable semantic search across scientific figures."
  - [section]: "Because CLIP is a multi-modal embedding trained on images and text, it acquires visual understanding embodying meaningful semantics... This retrieval can be viewed as a form of zero-shot ML, in the sense that the CLIP model was not trained on scientific images explicitly, and yet it can provide a meaningful descriptor of these images."
  - [corpus]: Weak - No direct corpus evidence provided for image embedding effectiveness in this specific scientific domain.

### Mechanism 3
- Claim: Combining raw text chunks with LLM-generated summaries in prompts improves response quality by providing both detailed information and concise overviews
- Mechanism: Text chunks from documents are used to create two versions - raw text extracts and LLM-generated summaries. Both are embedded and stored in the database. When constructing prompts, both raw and summary chunks are included, providing the LLM with redundant but complementary information phrased in different ways.
- Core assumption: The LLM effectively analyzes the provided text during response generation, and having information presented in multiple formats (raw and summarized) helps reinforce key points and guard against misinterpretation.
- Evidence anchors:
  - [section]: "Interestingly, we observe that providing access to both raw and summarized information is useful... There is growing evidence that LLMs effectively perform analysis within the output generation itself... Similarly, providing pre-computed LLM rewording of text chunks affords the system an opportunity to pre-build some textual analysis."
  - [corpus]: Weak - No direct corpus evidence provided for the effectiveness of combining raw and summary chunks.

## Foundational Learning

- Concept: Text embeddings and semantic similarity
  - Why needed here: Understanding how text embeddings capture meaning and enable semantic search is crucial for implementing the document retrieval mechanism.
  - Quick check question: How does cosine similarity measure the relationship between two text embeddings?

- Concept: Image embeddings and multi-modal learning
  - Why needed here: Understanding how models like CLIP can capture visual semantics and enable image similarity search is essential for implementing the figure retrieval mechanism.
  - Quick check question: What is zero-shot learning, and how does it apply to using CLIP for scientific image search?

- Concept: Large language model context windows and prompt engineering
  - Why needed here: Understanding how to effectively use the limited context window and craft prompts that elicit desired responses is crucial for optimizing the chatbot's performance.
  - Quick check question: How does prepending relevant document chunks to a user query affect the LLM's response?

## Architecture Onboarding

- Component map: PDF to XML conversion using Grobid -> Text Processing (chunking, embedding, database storage) -> Image Processing (figure extraction, CLIP embedding) -> Query Processing (embedding computation, similarity search, prompt construction) -> LLM Integration (API calls to GPT-3.5 or GPT-4) -> Response Delivery (formatting and presenting LLM-generated answers)

- Critical path: 1. User submits query, 2. Query embedding computed, 3. Similarity search retrieves relevant chunks, 4. Prompt constructed with chunks and query, 5. LLM API call with prompt, 6. Response formatted and returned to user

- Design tradeoffs:
  - Raw vs. summarized text chunks: Raw chunks provide detailed information but may be redundant; summaries are concise but may lose nuance
  - Number of chunks in prompt: More chunks provide more context but consume limited context window space
  - Embedding model choice: Different models may capture semantics differently, affecting retrieval quality
  - LLM choice: Different models have varying capabilities, costs, and context window sizes

- Failure signatures:
  - Irrelevant chunks retrieved: Indicates poor embedding model performance or corpus mismatch
  - Fabricated citations or information: Indicates insufficient context chunks or poor LLM performance
  - Slow response times: Indicates inefficient database queries or API call issues
  - Missing relevant information: Indicates corpus coverage gaps or ineffective chunk construction

- First 3 experiments:
  1. Test text embedding and similarity search: Input a query and verify that the retrieved chunks are semantically relevant
  2. Test image embedding and similarity search: Input an image and verify that the retrieved figures are visually similar
  3. Test end-to-end chatbot: Input a scientific question and verify that the response is accurate and cites relevant sources

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the quality of responses from domain-specific chatbots compare to responses from general-purpose chatbots like ChatGPT when answering complex scientific questions?
- Basis in paper: [inferred] The paper discusses how domain-specific chatbots with access to contextual information perform better than raw LLM output in providing accurate and helpful responses to scientific questions.
- Why unresolved: The paper does not provide a direct comparison of response quality between domain-specific and general-purpose chatbots on a wide range of scientific questions.
- What evidence would resolve it: A comprehensive study comparing the performance of domain-specific chatbots with contextual information against general-purpose chatbots on a large dataset of scientific questions, evaluating accuracy, helpfulness, and citation quality.

### Open Question 2
- Question: What are the optimal strategies for prompt engineering and context selection in domain-specific chatbots to maximize response quality and relevance?
- Basis in paper: [explicit] The paper mentions that there are opportunities to refine methods by more carefully selecting and aggregating contextual information into the prompt, and that different strategies like summarization can be used but may have trade-offs.
- Why unresolved: The paper does not provide a systematic evaluation of different prompt engineering strategies or context selection methods.
- What evidence would resolve it: A controlled study testing various prompt engineering techniques and context selection strategies, measuring their impact on response quality, relevance, and computational efficiency.

### Open Question 3
- Question: How can image embedding and retrieval methods be further improved to capture more nuanced and domain-specific visual similarities in scientific figures and data?
- Basis in paper: [explicit] The paper demonstrates the effectiveness of using image embeddings for semantic search across scientific figures, but does not explore potential improvements or limitations of the current approach.
- Why unresolved: The paper does not investigate the limitations of the current image embedding method or propose potential improvements for capturing more complex visual similarities.
- What evidence would resolve it: A study comparing the performance of different image embedding models and techniques on a large dataset of scientific figures, evaluating their ability to capture domain-specific visual similarities and identify relevant images.

## Limitations
- No quantitative evaluation metrics were provided - effectiveness claims are based on qualitative observations and examples rather than systematic measurement
- The approach relies heavily on proprietary models (OpenAI's text embeddings and GPT models) without exploring open alternatives or ablation studies
- No systematic evaluation of hallucination rates or citation accuracy was conducted

## Confidence
- High confidence: The core mechanism of using text embeddings for semantic search and prepending context to LLM queries is technically sound and aligns with established practices in retrieval-augmented generation
- Medium confidence: The qualitative improvements in response quality and citation accuracy are plausible given the methodology, but lack rigorous validation
- Low confidence: Claims about accelerating scientific research and enabling novel scientific workflows are speculative without user studies or performance benchmarks

## Next Checks
1. Conduct a systematic evaluation comparing response accuracy with and without context chunks using a standardized set of scientific questions with known answers
2. Measure hallucination rates and citation accuracy by having domain experts verify the factual correctness of chatbot responses across different scientific subfields
3. Perform ablation studies testing different combinations of raw vs. summarized text chunks, varying numbers of context chunks, and alternative embedding models to identify optimal configurations