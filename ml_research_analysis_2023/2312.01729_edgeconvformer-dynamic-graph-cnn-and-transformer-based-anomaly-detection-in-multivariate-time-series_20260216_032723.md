---
ver: rpa2
title: 'EdgeConvFormer: Dynamic Graph CNN and Transformer based Anomaly Detection
  in Multivariate Time Series'
arxiv_id: '2312.01729'
source_url: https://arxiv.org/abs/2312.01729
tags:
- anomaly
- time
- detection
- series
- edgeconvformer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces EdgeConvFormer, a novel anomaly detection
  method for multivariate time series that integrates Time2Vec embedding, stacked
  dynamic graph CNN (EdgeConv), and Transformer to extract global and local spatial-time
  information. The model addresses limitations of existing Transformer-based approaches,
  including the lack of locality, suboptimal positional encoding for time series data,
  and failure to consider interdependence between time series.
---

# EdgeConvFormer: Dynamic Graph CNN and Transformer based Anomaly Detection in Multivariate Time Series

## Quick Facts
- **arXiv ID**: 2312.01729
- **Source URL**: https://arxiv.org/abs/2312.01729
- **Reference count**: 40
- **Primary result**: State-of-the-art anomaly detection performance on multivariate time series using a novel EdgeConvFormer architecture combining Time2Vec embedding, EdgeConv, and Transformer

## Executive Summary
EdgeConvFormer introduces a novel anomaly detection framework for multivariate time series that integrates Time2Vec embedding, stacked dynamic graph CNN (EdgeConv), and Transformer modules. The method addresses key limitations in existing approaches by capturing both local spatial topology between sensors and global temporal dependencies. Through hierarchical multi-scale feature extraction, the model achieves superior performance on five commonly-used datasets and the Exathlon benchmark, demonstrating robustness across different evaluation metrics and anomaly types.

## Method Summary
EdgeConvFormer processes multivariate time series by first applying Time2Vec embedding to capture periodic and aperiodic temporal patterns, then passing data through four stacked layers of EdgeConv-Transformer modules. Each layer progressively refines features by combining local spatial information (EdgeConv) with global temporal attention (Transformer), with embedding dimensions increasing from 256 to 1024. The model uses overlapping windows for reconstruction-based anomaly detection, with a dynamic Gaussian scoring function and multiple thresholding methods for final anomaly detection.

## Key Results
- Achieves state-of-the-art F1, Fpa1, Fc1, AU-ROC, and AU-PRC scores on five standard datasets
- Demonstrates superior performance in detecting range-based anomalies compared to existing methods
- Shows robust and stable scores across different anomaly types and evaluation levels on Exathlon benchmark
- Maintains consistent performance across varying anomaly types and evaluation levels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EdgeConvFormer improves anomaly detection by integrating local spatial topology with global temporal dependencies.
- Mechanism: The model uses EdgeConv to construct dynamic graphs between sensors in space-time, then applies Transformer self-attention to capture long-term temporal dependencies. This hybrid approach combines local inductive biases with global context.
- Core assumption: The spatiotemporal topology between sensors contains meaningful information for anomaly detection.
- Evidence anchors: [abstract] "EdgeConv to derive spatiotemporal level topological relationships between sensors"; [section] "EdgeConv is used to get the topological structure and edge features, the subsequent Transformer is used to attend to the time dimension"

### Mechanism 2
- Claim: Time2Vec embedding effectively captures periodic and aperiodic temporal patterns better than standard positional encoding.
- Mechanism: Time2Vec learns frequencies and phase shifts from the data itself, rather than using fixed sinusoidal functions, allowing it to capture both periodic behaviors and non-periodic patterns in time series.
- Core assumption: Time series data contains both periodic and aperiodic patterns that need to be modeled separately.
- Evidence anchors: [abstract] "Time2Vec to capture periodic and aperiodic patterns in temporal information"; [section] "Time2Vec, a learnable vector representation for time, which can capture both the periodic and non-periodic patterns"

### Mechanism 3
- Claim: The hierarchical multi-scale feature extraction through stacked EdgeConv-Transformer layers improves representation power.
- Mechanism: Each layer progressively refines features by combining local spatial information (EdgeConv) with global temporal attention (Transformer), with embedding sizes increasing from 256 to 1024 across layers.
- Core assumption: Multi-scale hierarchical processing of features leads to better anomaly detection performance.
- Evidence anchors: [abstract] "representation aggregation of multi-scale features"; [section] "EdgeConv and Transformer are integrated in a hierarchical, multi-scale manner and reinforce each other at each layer"

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and message passing
  - Why needed here: EdgeConv is based on GNN principles for constructing and propagating information through graph structures
  - Quick check question: Can you explain how message passing works in a simple graph neural network?

- Concept: Transformer self-attention mechanism
  - Why needed here: The Transformer module uses self-attention to capture long-range temporal dependencies across timestamps
  - Quick check question: What is the difference between self-attention and cross-attention in Transformer architectures?

- Concept: Time series decomposition and periodicity analysis
  - Why needed here: Time2Vec relies on understanding how to decompose time series into periodic and non-periodic components
  - Quick check question: How would you identify periodic patterns in a time series signal?

## Architecture Onboarding

- Component map: Input → Time2Vec embedding (per sensor) → Stacked EdgeConv-Transformer layers (4 layers, increasing dimensions) → Decoder (MLP with pooling) → Reconstruction output
- Critical path: Time2Vec → EdgeConv (graph construction) → Transformer (temporal attention) → Feature aggregation → Reconstruction
- Design tradeoffs:
  - EdgeConv vs pure CNN: Better captures local spatial topology but higher computational cost
  - Time2Vec vs fixed positional encoding: More flexible but potentially more parameters to learn
  - Stacked architecture vs single layer: Better feature refinement but increased complexity and training time
- Failure signatures:
  - Poor reconstruction accuracy → Check EdgeConv graph construction and neighbor selection
  - High false positives → Review Time2Vec frequency learning and scoring threshold
  - Slow convergence → Verify learning rate and batch size for each dataset
- First 3 experiments:
  1. Replace Time2Vec with fixed positional encoding to measure performance impact
  2. Remove EdgeConv module to isolate contribution of spatial topology learning
  3. Reduce number of stacked layers to assess impact of hierarchical feature extraction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of EdgeConvFormer scale with the size and complexity of the input time series data, particularly in terms of runtime and memory usage?
- Basis in paper: [explicit] The paper mentions that EdgeConvFormer consumes around 26ms per data point and that MSCRED took the longest runtime due to algorithm complexity. However, it does not provide a detailed analysis of how runtime and memory usage scale with input size and complexity.
- Why unresolved: The paper focuses on evaluating the anomaly detection performance of EdgeConvFormer on various datasets but does not delve into the scalability aspects in terms of runtime and memory usage.
- What evidence would resolve it: Conducting experiments to measure the runtime and memory usage of EdgeConvFormer on datasets of increasing size and complexity would provide insights into its scalability.

### Open Question 2
- Question: How does the choice of hyperparameters, such as the number of layers, embedding dimensions, and neighbor size, affect the performance of EdgeConvFormer?
- Basis in paper: [explicit] The paper mentions that hyperparameters like the number of layers, embedding dimensions, and neighbor size are tuned for each dataset. However, it does not provide a detailed analysis of how these hyperparameters impact the performance of EdgeConvFormer.
- Why unresolved: While the paper demonstrates the effectiveness of EdgeConvFormer with specific hyperparameter choices, it does not explore the sensitivity of the model's performance to variations in these hyperparameters.
- What evidence would resolve it: Conducting ablation studies by varying the hyperparameters and evaluating the performance of EdgeConvFormer on different datasets would shed light on the importance of each hyperparameter and its impact on the model's performance.

### Open Question 3
- Question: How does EdgeConvFormer perform in detecting anomalies in time series data with missing or noisy values?
- Basis in paper: [inferred] The paper focuses on anomaly detection in multivariate time series data but does not specifically address the challenges posed by missing or noisy values in the input data.
- Why unresolved: The paper assumes that the input time series data is complete and free from noise, which may not always be the case in real-world scenarios.
- What evidence would resolve it: Conducting experiments by introducing missing or noisy values in the input time series data and evaluating the performance of EdgeConvFormer in detecting anomalies under these conditions would provide insights into its robustness to data quality issues.

## Limitations
- The exact implementation details of EdgeConv dynamic graph construction and integration with Transformer layers remain underspecified
- Time2Vec parameter configuration (64 sine functions + 1 linear term) lacks systematic justification and sensitivity analysis
- Limited ablation studies make it difficult to isolate the contributions of individual architectural components

## Confidence
- **High Confidence**: The general framework of combining graph-based spatial modeling with Transformer-based temporal modeling is theoretically sound and well-supported by experimental results
- **Medium Confidence**: The Time2Vec embedding approach for capturing periodic and aperiodic patterns shows promise but requires more rigorous validation across diverse time series characteristics
- **Low Confidence**: The specific hyperparameter configurations (learning rates, batch sizes, KNN values) appear to be dataset-specific without clear systematic selection methodology

## Next Checks
1. **Component Isolation Study**: Implement ablation experiments that systematically remove or replace each major component (Time2Vec, EdgeConv, Transformer) to quantify their individual contributions to overall performance

2. **Parameter Sensitivity Analysis**: Conduct experiments varying the number of Time2Vec frequencies, EdgeConv neighbor counts, and Transformer layer dimensions to establish the robustness of performance to these architectural choices

3. **Cross-Dataset Generalization Test**: Train the model on one dataset type and evaluate on another (e.g., train on industrial sensor data, test on medical data) to assess whether the learned spatiotemporal representations transfer across domains or are dataset-specific