---
ver: rpa2
title: Is This the Subspace You Are Looking for? An Interpretability Illusion for
  Subspace Activation Patching
arxiv_id: '2311.17030'
source_url: https://arxiv.org/abs/2311.17030
tags:
- activation
- subspace
- patching
- layer
- patch
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper demonstrates that subspace activation patching can create
  illusory interpretability results by activating dormant pathways in MLP layers.
  Counterintuitively, patching along a subspace can change model outputs even when
  the subspace is causally disconnected from predictions, due to the activation of
  another dormant direction that does affect outputs.
---

# Is This the Subspace You Are Looking For? An Interpretability Illusion for Subspace Activation Patching

## Quick Facts
- arXiv ID: 2311.17030
- Source URL: https://arxiv.org/abs/2311.17030
- Authors: 
- Reference count: 40
- Primary result: Demonstrates interpretability illusions in subspace activation patching where patching along a subspace can change outputs even when the subspace is causally disconnected from predictions, due to activation of dormant pathways

## Executive Summary
This paper reveals a critical interpretability illusion in subspace activation patching for transformer models. The core finding is that patching along a subspace can change model outputs even when that subspace is causally disconnected from predictions, due to the activation of another dormant direction. This happens because MLP layers contain high-dimensional nullspaces that provide causally disconnected directions, which can be combined with dormant directions to create misleading subspaces. The paper demonstrates this phenomenon theoretically and empirically in indirect object identification tasks and factual recall, showing that subspaces found by DAS can have large causal effects that disappear when the causally disconnected component is removed. The authors recommend using activation patching in bottlenecks like the residual stream and validating subspaces with additional mechanistic experiments beyond end-to-end effects.

## Method Summary
The paper introduces subspace activation patching as an extension of component activation patching that allows interventions along arbitrary subspaces. The method uses a data-augmentation technique called Direct Automatic Search (DAS) to find 1D subspaces that mediate features in MLP layers. For the IOI task, they train GPT-2 Small to identify the indirect object in sentences and use DAS to find subspaces in MLP layer 8 that mediate position information. For factual recall, they apply the same methodology to GPT-2 XL with the COUNTER FACT dataset. The method involves computing gradients to identify causally connected directions, applying patches along identified subspaces, and measuring the causal effects through fractional logit difference decrease and interchange accuracy metrics.

## Key Results
- Patching along subspaces can create illusory interpretability results by activating dormant pathways in MLP layers
- Subspaces found by DAS in IOI and factual recall tasks have large causal effects that disappear when causally disconnected components are removed
- Rank-1 fact editing using ROME is approximately equivalent to 1-dimensional subspace interventions that can activate dormant pathways
- Patching in bottlenecks like the residual stream is less prone to illusions than patching in MLP layers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Patching along a subspace can change model outputs even when the subspace is causally disconnected from predictions, by activating a dormant pathway.
- Mechanism: The MLP layer's high-dimensional nullspace provides a causally disconnected direction that can be combined with a dormant direction to create a misleading subspace. The patch along this illusory subspace "activates" the dormant direction, causing downstream effects.
- Core assumption: The MLP layer contains both a causally disconnected direction (in ker Wout) and a dormant direction (not activated by the two prompts) that are approximately orthogonal.
- Evidence anchors:
  - [abstract]: "patching along a subspace can change model outputs even when the subspace is causally disconnected from predictions, due to the activation of another dormant direction"
  - [section 3]: "the mathematics of subspace interventions makes it possible to activate another, 'dormant', direction... by exploiting the variation of model activations in a direction correlated with a feature"
  - [corpus]: Weak - only general references to activation patching, no specific mention of the nullspace/dormant direction interaction
- Break condition: If the MLP layer does not have a high-dimensional nullspace (e.g., very low rank Wout) or if no dormant direction exists in the layer.

### Mechanism 2
- Claim: The illusion arises because subspace activation patching can create a "variable" that doesn't exist in the original computation.
- Mechanism: Instead of localizing a pre-existing feature, the patch creates a new path through the dormant direction, making it appear as if the patched subspace encodes the feature.
- Core assumption: The model's computation does not actually use the subspace being patched, but the patch creates a new computational path.
- Evidence anchors:
  - [abstract]: "even if a subspace intervention makes the model's output behave as if the value of a feature was changed, this effect may be achieved by activating a dormant parallel pathway"
  - [section 3]: "subspace interventions such as subspace activation patching can create such a variable by activating a dormant pathway"
  - [corpus]: Weak - general references to activation patching creating variables, but not specifically about dormant pathways
- Break condition: If the model's computation is highly sparse and does not allow for dormant pathways to be activated by patching.

### Mechanism 3
- Claim: Rank-1 fact editing can work by creating a dormant pathway in the model, regardless of whether the fact is stored there.
- Mechanism: The rank-1 edit modifies the down-projection matrix Wout such that the edit's contribution to the MLP's output points in the same direction as the dormant pathway, effectively activating it.
- Core assumption: The rank-1 edit can approximate the effect of a 1-dimensional subspace intervention that activates a dormant pathway.
- Evidence anchors:
  - [abstract]: "rank-1 fact editing... is approximately equivalent to a 1-dimensional subspace intervention that generalizes activation patching"
  - [section 6]: "we show that for a wide range of layers... rank-1 fact editing using the ROME method is approximately equivalent to a 1-dimensional subspace intervention"
  - [corpus]: Weak - only general references to rank-1 editing, no specific mention of dormant pathways
- Break condition: If the rank-1 edit cannot approximate the subspace intervention well (e.g., if the edit's contribution to the MLP's output does not point in the same direction as the dormant pathway).

## Foundational Learning

- Concept: Causal mediation analysis
  - Why needed here: To understand how activation patching can identify causal components in a model's computation
  - Quick check question: What is the difference between a causally connected and a causally disconnected direction in a model's activation space?

- Concept: Linear representation hypothesis
  - Why needed here: To understand why features in a model are often represented as linear subspaces of component activations
  - Quick check question: How does the linear representation hypothesis relate to phenomena like superposition and polysemanticity?

- Concept: Subspace activation patching
  - Why needed here: To understand the specific technique used in the paper to intervene on model activations along arbitrary subspaces
  - Quick check question: How does subspace activation patching differ from full-component activation patching?

## Architecture Onboarding

- Component map: Residual stream -> MLP layer (with Wout) -> attention heads -> name mover heads -> model output
- Critical path: The residual stream passes through the MLP layer where the illusion occurs, then flows through attention mechanisms to produce the final output
- Design tradeoffs: Patching in bottlenecks like the residual stream is less prone to illusions than patching in MLP layers due to the higher dimensionality of MLP nullspaces
- Failure signatures: Patches that work in MLP layers but not when the causally disconnected component is removed, or when the entire MLP activation is patched
- First 3 experiments:
  1. Replicate the IOI task experiments to find an illusory subspace in an MLP layer
  2. Perform the decomposition of the illusory subspace into causally disconnected and dormant components
  3. Test the effect of patching along only the causally disconnected or dormant component

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the prevalence of the interpretability illusion in practical scenarios? Specifically, how often do we find subspaces in MLP layers that appear to mediate features but are actually activating dormant pathways?
- Basis in paper: [inferred] The paper demonstrates the illusion in two real-world domains (indirect object identification and factual recall) and argues it should be prevalent in practice, but does not quantify its prevalence.
- Why unresolved: The paper provides theoretical arguments and empirical evidence for the illusion's existence but does not conduct large-scale experiments to measure its frequency across different models and tasks.
- What evidence would resolve it: Systematic studies measuring the frequency of illusory subspaces in various models and tasks, comparing the number of illusory subspaces to the total number of subspaces found.

### Open Question 2
- Question: How can we effectively distinguish between illusory and faithful subspaces without relying on end-to-end causal effects?
- Basis in paper: [explicit] The paper suggests using additional mechanistic experiments beyond end-to-end effects, but does not provide a comprehensive methodology for this distinction.
- Why unresolved: While the paper proposes some experiments (e.g., comparing patches along causally disconnected vs. dormant components), it does not offer a complete framework for reliably identifying illusory subspaces.
- What evidence would resolve it: Development and validation of a robust set of mechanistic experiments that can consistently differentiate between illusory and faithful subspaces, ideally with high precision and recall.

### Open Question 3
- Question: What is the relationship between the interpretability illusion and rank-1 model editing? Can we predict when rank-1 edits will activate dormant pathways?
- Basis in paper: [explicit] The paper shows a connection between activation patching along 1-dimensional subspaces and rank-1 model editing, and demonstrates that rank-1 edits can activate dormant pathways.
- Why unresolved: The paper establishes the existence of this relationship but does not provide a predictive model for when rank-1 edits will activate dormant pathways.
- What evidence would resolve it: A theoretical framework or empirical model that predicts the likelihood of rank-1 edits activating dormant pathways based on model architecture, task, and edit characteristics.

## Limitations

- The core illusion mechanism relies heavily on the existence of both causally disconnected directions and dormant directions within the same MLP layer, which may not be common across all architectures
- The empirical evidence is primarily drawn from two specific cases (IOI task and factual recall) which may not generalize to other contexts
- The paper does not provide a comprehensive methodology for distinguishing illusory subspaces from faithful ones beyond suggesting additional mechanistic experiments

## Confidence

- **High confidence**: The mathematical demonstration that subspace patching can activate dormant pathways, and the recommendation to validate subspaces with additional mechanistic experiments
- **Medium confidence**: The frequency and practical significance of this illusion across different models and tasks, given the limited empirical scope
- **Medium confidence**: The equivalence between rank-1 fact editing and 1D subspace interventions, though this is well-supported by the variance ratio analysis

## Next Checks

1. **Architecture Generalization Test**: Apply the subspace patching methodology to multiple transformer architectures (e.g., BERT, T5) and diverse tasks (sentiment analysis, question answering) to assess how frequently the illusion occurs in practice.

2. **Nullspace Dimension Analysis**: Systematically vary the rank of Wout across different MLP layers and measure how the illusion strength correlates with nullspace dimensionality, providing insight into when the mechanism is most likely to occur.

3. **Bottleneck vs MLP Patching Comparison**: Design a controlled experiment comparing subspace patching effectiveness in residual stream bottlenecks versus MLP layers across the same tasks, quantifying the relative frequency of illusory results in each location.