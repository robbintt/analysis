---
ver: rpa2
title: Learning Saliency From Fixations
arxiv_id: '2311.14073'
source_url: https://arxiv.org/abs/2311.14073
tags:
- saliency
- fixation
- prediction
- image
- maps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes SalTR, a transformer-based approach for saliency
  prediction that learns directly from fixation maps without requiring continuous
  saliency annotations. The method treats saliency prediction as a direct set prediction
  problem using a transformer encoder-decoder architecture with learned fixation queries.
---

# Learning Saliency From Fixations

## Quick Facts
- arXiv ID: 2311.14073
- Source URL: https://arxiv.org/abs/2311.14073
- Authors: 
- Reference count: 40
- Key outcome: SalTR achieves state-of-the-art performance on saliency benchmarks using transformer-based direct fixation prediction

## Executive Summary
This paper proposes SalTR, a novel transformer-based approach for saliency prediction that learns directly from fixation maps without requiring continuous saliency annotations. The method treats saliency prediction as a direct set prediction problem using a transformer encoder-decoder architecture with learned fixation queries. By employing a bipartite matching loss and deformable attention mechanisms, SalTR achieves state-of-the-art performance on both Salicon and MIT300 benchmarks while providing interpretable fixation predictions.

## Method Summary
SalTR formulates saliency prediction as a direct set prediction problem where a transformer decoder predicts discrete fixation points from CNN-encoded image features. The architecture consists of a ResNet-50 backbone, transformer encoder, and transformer decoder with learned fixation queries. A Hungarian matching loss ensures unique fixation predictions, while deformable attention accelerates training. The model generates continuous saliency maps by placing Gaussians at predicted fixation locations, which are then evaluated using standard saliency metrics.

## Key Results
- Deformable SalTR-Base scores 0.79/0.77/0.89/2.12/0.62 (SIM/s-AUC/CC/NSS/KLD) on Salicon
- MIT300 performance of 0.69/0.79/0.80/2.45/0.36
- Scanpath prediction achieves 0.93 Multi-Match score on Salicon
- Outperforms existing methods on both Salicon and MIT300 benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer decoder cross-attention with learned fixation queries directly predicts discrete fixation points without requiring continuous saliency maps.
- Mechanism: Fixation queries act as "virtual observers" that saccade across the image via cross-attention over CNN-encoded features, with bipartite matching enforcing unique predictions.
- Core assumption: Discrete fixation prediction can be cast as a set prediction problem where the Hungarian algorithm finds optimal query-to-fixation assignments.
- Evidence anchors:
  - [abstract] "Our approach treats saliency prediction as a direct set prediction problem, via a global loss that enforces unique fixations prediction through bipartite matching and a transformer encoder-decoder architecture."
  - [section] "We search for a permutation of N elements ϕ ∈ SN with the lowest cost: ˆϕ = arg min ϕ∈SN 1/N Σi=1N Lmatch(fi, ˆfϕ(i))"
  - [corpus] Weak evidence - no directly comparable work found in neighbor papers.
- Break condition: If bipartite matching fails to converge or produces degenerate predictions (all queries attending same region).

### Mechanism 2
- Claim: Deformable attention mechanism accelerates training by gating spatial sampling and improving cross-attention optimization.
- Mechanism: Translation terms in attention formula allow sparse spatial sampling from reference points, reducing long-range dependencies and stabilizing early training.
- Core assumption: Locality bias in attention initialization prevents uniform attention weights across all pixels, which would otherwise attend to meaningless locations.
- Evidence anchors:
  - [section] "Inspired by the concept of deformable convolution [13], the approach of [67] is to add a translation term into the formula of the transformer attention, allowing a sparse spatial sampling by attending to a smaller set of locations."
  - [section] "The deformable attention mechanism to our settings, termed Deformable SalTR."
  - [corpus] No direct evidence in neighbors - this is an adaptation of object detection literature.
- Break condition: If deformable attention parameters become too restrictive and prevent capturing global context needed for saliency.

### Mechanism 3
- Claim: Hungarian matching loss prevents query collapse by forcing distinct fixation predictions.
- Mechanism: The loss assigns unique matching between predicted and ground truth fixations, ensuring each query learns to predict a different spatial location.
- Core assumption: Without explicit matching, queries would collapse to predict the same most salient region, ignoring diverse fixation patterns.
- Evidence anchors:
  - [section] "We validate this hypothesis by eliminating the Hungarian matching loss, and only use the final loss in Eq. 4 without any assignments. As expected, the model learns the saliency dataset center bias."
  - [section] "In the absence of the Hungarian matching loss, which usually serves to optimize assignment between predictions and ground truth, the SalTR model seems to struggle with providing unique, diversified predictions."
  - [corpus] No direct evidence in neighbors - this is a key innovation of the paper.
- Break condition: If matching loss weight is too high, causing predictions to become too sparse and miss densely-fixated regions.

## Foundational Learning

- Concept: Transformer encoder-decoder architecture with cross-attention
  - Why needed here: Enables direct prediction of fixation sets from image features without intermediate continuous maps
  - Quick check question: What is the difference between self-attention in encoder and cross-attention in decoder?

- Concept: Bipartite matching/Hungarian algorithm for set prediction
  - Why needed here: Ensures unique, one-to-one mapping between predicted and ground truth fixations
  - Quick check question: How does the Hungarian algorithm find optimal matching between two sets of different sizes?

- Concept: Deformable convolution and attention mechanisms
  - Why needed here: Accelerates training by introducing locality bias in attention initialization
  - Quick check question: What is the key difference between standard convolution and deformable convolution?

## Architecture Onboarding

- Component map:
  CNN backbone (ResNet-50) -> Transformer encoder -> Transformer decoder -> MLP head -> Hungarian matching layer

- Critical path: Image -> CNN features -> Transformer encoder -> Transformer decoder queries -> Cross-attention -> Fixation predictions -> Hungarian matching -> Loss

- Design tradeoffs:
  - Fixed number of fixation queries (100) vs. variable number of ground truth fixations
  - Parallel decoding (faster) vs. autoregressive decoding (scanpath prediction)
  - Global attention (rich context) vs. deformable attention (faster training)

- Failure signatures:
  - All predictions clustering in center (query collapse)
  - Extremely slow convergence (>100 epochs)
  - Poor performance on synthetic images (learned dataset bias)

- First 3 experiments:
  1. Train without Hungarian matching to observe query collapse behavior
  2. Vary number of fixation queries (50, 100, 150, 200) to find optimal balance
  3. Test deformable vs standard attention to measure training acceleration

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of fixation queries (N) for saliency prediction, and how does it affect performance across different datasets?
- Basis in paper: [explicit] Table 2 shows experiments varying N from 50 to 200, finding 100 optimal, but this was only tested on Salicon.
- Why unresolved: The paper only evaluates on one dataset, and the optimal N may vary with dataset complexity, image content, or task requirements.
- What evidence would resolve it: Systematic experiments varying N across multiple datasets (MIT300, CAT2000, etc.) and analyzing performance trade-offs with computational cost.

### Open Question 2
- Question: How does the Gaussian smoothing parameter σ affect the quality of continuous saliency maps generated from fixation predictions?
- Basis in paper: [explicit] Table 3 shows experiments with σ from 5.0 to 30.0, finding 19.0 optimal, but the impact on different metrics and applications is unclear.
- Why unresolved: The paper focuses on benchmark metrics but doesn't explore how different σ values affect downstream applications like visual search or human-computer interaction.
- What evidence would resolve it: Ablation studies testing different σ values on specific tasks (e.g., object detection, visual search accuracy) and perceptual studies with human observers.

### Open Question 3
- Question: Can the SalTR architecture effectively handle synthetic images and low-level visual features compared to high-level semantic features?
- Basis in paper: [explicit] Section 4.1 discusses poor performance on synthetic O3 dataset and compares with UNISAL on P3 dataset, but doesn't provide systematic analysis.
- Why unresolved: The paper only provides qualitative examples without quantitative analysis of performance gaps between real and synthetic images or low-level vs high-level features.
- What evidence would resolve it: Quantitative benchmarking on synthetic datasets, ablation studies removing high-level features, and analysis of attention patterns for different feature types.

### Open Question 4
- Question: How does the bipartite matching loss formulation affect the diversity and distribution of predicted fixations, and could alternative formulations improve performance?
- Basis in paper: [explicit] Section 4.2 discusses failure modes when removing Hungarian matching and shows predictions become concentrated, but doesn't explore alternatives.
- Why unresolved: The paper only tests the standard Hungarian matching formulation without exploring other matching strategies or loss formulations that might better capture human attention patterns.
- What evidence would resolve it: Experiments comparing different matching strategies (e.g., soft matching, hierarchical matching), analysis of predicted fixation distributions, and perceptual studies on fixation diversity.

## Limitations

- Requires post-processing (non-maximum suppression) to convert discrete fixation predictions into continuous saliency maps
- Fixed number of 100 fixation queries may limit performance on images with very few or very many fixations
- Limited evaluation on synthetic images, making it unclear whether model learns true saliency principles or dataset-specific biases

## Confidence

- Major Uncertainties:
  - "State-of-the-art" performance claim lacks comprehensive ablation studies: Medium
  - Deformable attention acceleration needs systematic convergence comparison: Medium
  - Fixed 100 query constraint may limit architectural flexibility: Medium

- Critical Limitations:
  - Post-processing complexity for deployment
  - Unclear generalization to synthetic images
  - Limited scanpath prediction validation

## Next Checks

1. Perform systematic ablation study comparing deformable vs standard attention with identical hyperparameters and training schedules to quantify the claimed training acceleration

2. Test model performance on synthetic images with known saliency properties (e.g., center-surround patterns) to verify learning of genuine saliency principles rather than dataset bias

3. Evaluate the impact of varying fixation query numbers (50-200) on both prediction accuracy and computational efficiency to identify optimal architectural configuration