---
ver: rpa2
title: Post-Deployment Adaptation with Access to Source Data via Federated Learning
  and Source-Target Remote Gradient Alignment
arxiv_id: '2308.16735'
source_url: https://arxiv.org/abs/2308.16735
tags:
- data
- domain
- target
- source
- adaptation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FedPDA, a novel post-deployment adaptation
  (PDA) framework that combines federated learning (FL) with PDA to adapt a pre-trained
  model to a target domain. The key idea is to enable a deployed model to obtain information
  from source data via remote gradient exchange, while aiming to optimize the model
  specifically for the target domain.
---

# Post-Deployment Adaptation with Access to Source Data via Federated Learning and Source-Target Remote Gradient Alignment

## Quick Facts
- arXiv ID: 2308.16735
- Source URL: https://arxiv.org/abs/2308.16735
- Reference count: 33
- Key outcome: FedPDA framework achieves favorable results in cancer metastases detection and skin lesion classification by enabling post-deployment adaptation with remote gradient exchange from source domains

## Executive Summary
This paper introduces FedPDA, a novel post-deployment adaptation framework that combines federated learning with PDA to adapt pre-trained models to target domains without accessing source data. The key innovation is StarAlign, which aligns gradients between source and target domains through inner product maximization, enabling effective adaptation using only gradient information. Experiments on medical imaging tasks demonstrate significant improvements over traditional PDA approaches, particularly in scenarios with limited labelled target data.

## Method Summary
FedPDA addresses the challenge of adapting deployed models to target domains when source data is inaccessible but gradient information can be exchanged. The framework uses StarAlign to align source and target gradients by maximizing their inner product, performed through an interleaving update strategy that approximates the theoretical alignment objective. Source nodes compute average gradients over local iterations and transmit these to the target node, which performs interleaved updates using both actual target gradients and received source gradients. This enables effective post-deployment adaptation while maintaining data privacy constraints.

## Key Results
- StarAlign achieves favorable results compared to previous PDA methods on cancer metastases detection using Camelyon17 dataset
- The framework demonstrates effectiveness in skin lesion classification across multiple centers (HAM, BCN, MSK, D7P)
- FedPDA successfully adapts models with limited labelled target data while maintaining source domain performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: StarAlign improves target-domain adaptation by aligning gradients from source and target domains through inner product maximization
- Mechanism: The algorithm performs interleaved gradient updates on source and target domain batches, computing average source gradients and aligning them with target gradients via dot product maximization
- Core assumption: Maximizing the inner product between source and target gradients will lead to source-derived gradients that are beneficial for the target domain
- Evidence anchors:
  - [abstract]: "StarAlign (Source-Target Remote Gradient Alignment) that aligns gradients between source-target domain pairs by maximizing their inner product, to facilitate learning a target-specific model."
  - [section]: "To align gradientsGk = EDk [∇θLk(θ; x, y)] of the k-th domain and the target domainGT = EDT [∇θLT (θ; x, y)], we maximize their inner product GT ·Gk."
- Break condition: If source and target gradients are orthogonal or nearly orthogonal, inner product maximization may have minimal effect

### Mechanism 2
- Claim: FedPDA enables post-deployment adaptation with remote gradient exchange, overcoming the limitation of no source data access in traditional PDA
- Mechanism: The framework allows a deployed model at the target node to receive averaged gradient directions from source nodes without data exchange
- Core assumption: Gradient information can be effectively transmitted between nodes without transferring the actual data
- Evidence anchors:
  - [abstract]: "FedPDA enables a deployed model to obtain information from source data via remote gradient exchange, while aiming to optimize the model specifically for the target domain."
  - [section]: "This combines FL with PDA into a new framework, FedPDA... FedPDA also differs from FDA by adapting a pre-trained deployed model at the user's endpoint, rather than training a model pre-deployment from scratch."
- Break condition: If gradient updates from source nodes are too noisy or sparse due to limited communication rounds

### Mechanism 3
- Claim: The interleaving update strategy with local source gradient computation approximates the theoretical gradient alignment objective
- Mechanism: Source nodes compute average gradients over multiple local iterations and send these to the target node
- Core assumption: The first-order approximation update can effectively approximate the theoretical second-order gradient alignment
- Evidence anchors:
  - [section]: "This is based on the result in [28] that the update stepβ(θ̂ − θ) (L9) approximates optimisation of Eq. 2 for a pair of domains."
  - [section]: "Directly optimising dot-products in Eq. 2 is computationally expensive as it requires second-order derivatives. Instead, minimizing Eq. 2 is approximated via Alg. 1 and first-order derivatives inL4-L9."
- Break condition: If the approximation error from using first-order updates instead of true gradient alignment is too large

## Foundational Learning

- Concept: Federated Learning (FL) basics - distributed training across multiple nodes without data sharing
  - Why needed here: FedPDA builds on FL infrastructure to enable remote gradient exchange while maintaining data privacy
  - Quick check question: What is the key difference between FedAvg and personalized FL approaches?

- Concept: Domain Adaptation (DA) and domain shift concepts
  - Why needed here: The paper addresses distribution shift between source training domains and target deployment domains
  - Quick check question: Why is achieving domain invariance potentially problematic for target-specific adaptation?

- Concept: Gradient alignment and inner product maximization in optimization
  - Why needed here: StarAlign's core mechanism relies on aligning gradients through inner product maximization
  - Quick check question: What does maximizing the inner product between two gradients accomplish in optimization terms?

## Architecture Onboarding

- Component map: Source nodes -> Remote gradient exchange -> Target node (StarAlign adaptation) -> Updated model deployment

- Critical path: Pre-training (FedBN/FedAvg) → Model deployment to target → StarAlign adaptation with remote gradient exchange → Model evaluation

- Design tradeoffs:
  - Local iterations (τ): Higher τ reduces communication frequency but may lead to gradient staleness
  - Scaling hyperparameter (β): Controls the strength of gradient alignment effect
  - Communication rounds (E): More rounds allow better convergence but increase deployment time

- Failure signatures:
  - Poor target domain performance: May indicate insufficient gradient alignment or inadequate local iterations
  - Source domain performance degradation: Could signal too strong alignment that overfits to target
  - Unstable training: Likely indicates hyperparameter issues with β or communication frequency problems

- First 3 experiments:
  1. Baseline comparison: Run FedBN pre-training without adaptation vs. StarAlign adaptation
  2. Gradient alignment ablation: Replace StarAlign with simple gradient averaging
  3. Communication frequency study: Vary τ and E to find optimal balance

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the performance of StarAlign compare to other gradient alignment methods beyond PCGrad in terms of computational efficiency and memory usage?
  - Basis in paper: [explicit] The paper mentions PCGrad as a comparison but does not extensively compare with other gradient alignment methods
  - Why unresolved: The paper focuses on effectiveness but not detailed efficiency comparisons
  - What evidence would resolve it: Benchmarking against a broader range of methods measuring both accuracy and resource consumption

- **Open Question 2**: Can FedPDA be extended to handle scenarios where the source domains have imbalanced data distributions?
  - Basis in paper: [inferred] The paper discusses challenges with limited data but not imbalanced source domains specifically
  - Why unresolved: The paper does not explicitly address how FedPDA handles imbalanced source domain data distributions
  - What evidence would resolve it: Experiments demonstrating performance with imbalanced source domains compared to balanced scenarios

- **Open Question 3**: What are the theoretical guarantees of convergence for the StarAlign algorithm in the context of federated learning?
  - Basis in paper: [explicit] The paper introduces StarAlign but does not provide theoretical convergence guarantees
  - Why unresolved: The paper focuses on empirical results without theoretical underpinnings
  - What evidence would resolve it: A theoretical analysis proving convergence properties of StarAlign in federated settings

## Limitations

- The StarAlign mechanism's robustness to orthogonal gradients in high-dimensional spaces remains unclear
- The approximation using first-order updates instead of true second-order gradient alignment may introduce significant error
- Communication overhead and gradient staleness trade-offs aren't thoroughly explored for scenarios with frequent domain shifts

## Confidence

- **High confidence**: The FedPDA framework architecture and its combination of federated learning with post-deployment adaptation
- **Medium confidence**: The StarAlign optimization mechanism shows promise but relies on approximations that may not always hold
- **Medium confidence**: Experimental results demonstrate improvements over baselines, though ablation studies could be more comprehensive

## Next Checks

1. **Gradient orthogonality stress test**: Systematically evaluate StarAlign's performance when source and target gradients become increasingly orthogonal, measuring the breakdown point where alignment fails

2. **Communication efficiency benchmark**: Compare FedPDA's adaptation quality against increasing communication delays and reduced gradient update frequencies to quantify the trade-off between communication overhead and adaptation effectiveness

3. **Domain similarity analysis**: Quantify how StarAlign performance varies across different degrees of domain similarity between source and target, identifying scenarios where the method excels versus struggles