---
ver: rpa2
title: 'Knowledge Card: Filling LLMs'' Knowledge Gaps with Plug-in Specialized Language
  Models'
arxiv_id: '2305.09955'
source_url: https://arxiv.org/abs/2305.09955
tags:
- knowledge
- specialized
- language
- llms
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a modular framework called COOK to augment
  black-box large language models (LLMs) with specialized, domain-specific knowledge.
  The core idea is to train multiple smaller language models on diverse corpora (e.g.,
  news, biomedical literature, Wikipedia), which act as "knowledge cards" that can
  be dynamically selected and filtered to provide relevant, factual information to
  the base LLM during inference.
---

# Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models

## Quick Facts
- arXiv ID: 2305.09955
- Source URL: https://arxiv.org/abs/2305.09955
- Reference count: 40
- Primary result: Modular framework that augments LLMs with specialized LMs trained on diverse corpora, achieving up to 6.6% improvement on MMLU and 55.6% on temporal QA tasks

## Executive Summary
This paper introduces COOK, a modular framework that augments black-box LLMs with specialized, domain-specific knowledge through plug-and-play specialized language models. The framework trains multiple smaller LMs on diverse corpora (news, biomedical literature, Wikipedia) that act as "knowledge cards" - parametric repositories selected and filtered to provide relevant information to the base LLM during inference. COOK employs three knowledge filters (relevance, brevity, factuality) and two integration approaches (bottom-up and top-down) to combine curated knowledge with LLM responses. Experiments on six benchmark datasets demonstrate significant improvements over vanilla LLMs and retrieval-augmented models, highlighting the potential of modular, community-driven knowledge enrichment for addressing LLM knowledge limitations.

## Method Summary
The COOK framework consists of three main components: 1) Specialized LMs trained on diverse knowledge corpora serving as parametric repositories, 2) Three knowledge filters (relevance, pruning, factuality) for quality control, and 3) Two integration approaches (bottom-up for comprehensive synthesis, top-down for context-aware selection). The system receives queries, generates candidate knowledge documents from specialized LMs, filters them through the three-stage pipeline, and integrates the curated knowledge with the base LLM (Codex) using in-context learning. The framework was evaluated on 25 specialized OPT-1.3B models trained on various domains and three benchmark datasets: MMLU, LUN misinformation detection, and MidtermQA.

## Key Results
- COOK outperforms vanilla LLMs by up to 6.6% on MMLU and 55.6% on MidtermQA temporal QA tasks
- Specialized LMs as parametric knowledge sources outperform retrieval-augmented models on knowledge-intensive benchmarks
- Factuality filter is most crucial for knowledge integration quality, with significant performance drops when removed
- Bottom-up approach enables multi-domain knowledge synthesis while top-down allows context-aware selective activation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modular specialized LMs act as plug-and-play knowledge repositories that enable flexible information access across domains
- Mechanism: By training separate LMs on diverse corpora, the framework creates parametric knowledge stores that can be dynamically selected and prompted to generate domain-specific background knowledge
- Core assumption: Different knowledge domains benefit from specialized training data, and combining these modular components improves LLM performance more than static knowledge sources
- Evidence anchors:
  - [abstract]: "specialized language models trained on corpora from specific domains and sources... serve as parametric repositories that are selected at inference time"
  - [section 2.1]: "specialized LMs trained on corpora from diverse sources and domains... serve as parametric knowledge repositories"
  - [corpus]: Weak evidence - the paper trains 25 specialized LMs but doesn't provide systematic comparison showing domain-specific benefits over retrieval

### Mechanism 2
- Claim: Three knowledge filters (relevance, brevity, factuality) ensure quality control when integrating external knowledge
- Mechanism: Relevance filter selects top-k most relevant documents using encoder-based similarity; pruning filter condenses documents through summarization; factuality filter removes non-factual content using fact-checking models and retrieval-augmented verification
- Core assumption: Generated knowledge documents require multi-stage filtering to meet quality standards before integration with base LLM
- Evidence anchors:
  - [abstract]: "three content selectors to dynamically select and retain information... controlling for relevance, brevity, and factuality"
  - [section 2.2]: Detailed description of three filters and their operational mechanisms
  - [corpus]: Weak evidence - ablation study shows factuality filter most crucial, but lacks comparative analysis against other filtering strategies

### Mechanism 3
- Claim: Two integration approaches (bottom-up and top-down) enable both multi-domain synthesis and context-aware knowledge seeking
- Mechanism: Bottom-up activates all specialized LMs simultaneously and applies filters for comprehensive knowledge synthesis; top-down lets LLM decide whether external knowledge is needed and selectively activates relevant LMs through iterative yes/no questioning
- Core assumption: Different tasks benefit from different integration strategies - some require comprehensive multi-domain knowledge while others need context-aware selective activation
- Evidence anchors:
  - [abstract]: "two complementary integration approaches to augment the base LLM... bottom-up and top-down"
  - [section 2.3]: "bottom-up approach uniquely enables multi-domain knowledge synthesis" and "top-down approach... enables LLMs to take charge in identifying their inherent knowledge limitations"
  - [corpus]: Weak evidence - performance differences between approaches shown on specific datasets but no systematic analysis of when each approach excels

## Foundational Learning

- Concept: Parametric knowledge vs non-parametric knowledge sources
  - Why needed here: Understanding the difference between knowledge stored in model parameters versus retrieved from external sources is crucial for grasping why specialized LMs offer advantages over retrieval augmentation
  - Quick check question: What are the key trade-offs between parametric and non-parametric knowledge storage in LLMs?

- Concept: Modular vs monolithic system design
  - Why needed here: The paper's core innovation relies on modular architecture where components can be added/removed independently, contrasting with monolithic LLM approaches
  - Quick check question: How does modularity enable community-driven knowledge contribution in this framework?

- Concept: In-context learning and few-shot prompting
  - Why needed here: Both integration approaches rely heavily on in-context learning to guide LLM behavior, requiring understanding of how few-shot examples influence model responses
  - Quick check question: What role does in-context learning play in the top-down approach's yes/no questioning mechanism?

## Architecture Onboarding

- Component map:
  Base LLM -> 25 specialized LMs -> Relevance filter -> Pruning filter -> Factuality filter -> Integration controller (bottom-up or top-down) -> Final output

- Critical path:
  1. Query received by system
  2. Specialized LMs generate candidate knowledge documents
  3. Three filters process documents (relevance → pruning → factuality)
  4. Filtered knowledge integrated with query via chosen approach
  5. Base LLM generates final answer

- Design tradeoffs:
  - Bottom-up vs top-down: Comprehensive knowledge synthesis vs context-aware selective activation
  - Number of specialized LMs: More coverage vs increased complexity and potential noise
  - Filter strictness: Quality control vs information loss
  - Factuality verification: Accuracy vs computational cost

- Failure signatures:
  - Bottom-up: Decreased performance when irrelevant knowledge dominates
  - Top-down: Poor yes/no questioning leading to knowledge gaps or unnecessary activation
  - Filters: Over-filtering removing useful information or under-filtering allowing hallucinations
  - Integration: Context length limits preventing sufficient knowledge incorporation

- First 3 experiments:
  1. Replace specialized LMs with retrieval system on MMLU to compare parametric vs non-parametric knowledge sources
  2. Remove each knowledge filter individually to measure impact on misinformation detection performance
  3. Test yes/no questioning mechanism on tasks with known knowledge gaps to evaluate calibration accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of COOK scale when specialized LMs are hierarchically organized by domain granularity?
- Basis in paper: [inferred] The paper mentions that specialized LMs could reflect hierarchical knowledge organization, with fine-grained sub-domains possible within broader categories
- Why unresolved: The experiments use a flat structure of specialized LMs without exploring hierarchical relationships or their impact on performance
- What evidence would resolve it: Experiments comparing flat vs. hierarchical organization of specialized LMs, measuring performance across tasks requiring different levels of domain specificity

### Open Question 2
- Question: What is the optimal balance between the number of specialized LMs (n2) and the number of documents selected from each (n1) for maximizing knowledge integration efficiency?
- Basis in paper: [explicit] The paper investigates the impact of n1, n2, and n3 on performance, noting that larger n2 leads to performance drops, suggesting quality control is important
- Why unresolved: While the paper explores these hyperparameters individually, it doesn't systematically optimize their balance or provide guidance on selecting these values for different tasks
- What evidence would resolve it: Systematic experiments varying n1 and n2 together, identifying optimal ratios for different types of knowledge-intensive tasks

### Open Question 3
- Question: What is the impact of specialized LM factuality score distributions on the overall system performance, and can this be used to predict or improve specialized LM quality?
- Basis in paper: [explicit] The paper analyzes factuality score distributions across specialized LMs and hypothesizes these distributions could guide quality evaluation of community-contributed LMs
- Why unresolved: While distributions are presented, the paper doesn't explore how these scores correlate with actual task performance or how they could be used for quality prediction
- What evidence would resolve it: Correlation analysis between specialized LM factuality scores and task performance, plus experiments using factuality scores to filter or prioritize specialized LMs

## Limitations
- Scalability concerns with maintaining 25 specialized LMs and potential coverage gaps in underrepresented domains
- Factuality filter shows bias toward information-rich domains with existing Wikipedia coverage, limiting effectiveness for emerging knowledge
- Computational costs and long-term sustainability of community-driven knowledge card contributions not addressed

## Confidence
**High Confidence**: The core mechanism of using specialized LMs as parametric knowledge repositories is well-supported by experimental results showing consistent improvements over baselines across multiple benchmarks.

**Medium Confidence**: The comparative advantage over retrieval-augmented approaches is demonstrated but not comprehensively analyzed across different knowledge domains and query types.

**Low Confidence**: Claims about community-driven scalability and long-term maintenance are speculative, with unaddressed concerns about conflicting information across specialized LMs and ambiguous domain overlaps.

## Next Checks
1. **Parametric vs Non-parametric Knowledge Comparison**: Conduct systematic experiments replacing specialized LMs with retrieval systems across diverse query types to quantify when parametric knowledge provides advantages beyond simple information retrieval.

2. **Factuality Filter Bias Analysis**: Evaluate the factuality filter's performance across domains with varying Wikipedia coverage and knowledge recency, testing on emerging topics and underrepresented domains to identify systematic biases.

3. **Integration Approach Calibration Study**: Test the yes/no questioning mechanism of the top-down approach on tasks with known knowledge gaps, measuring calibration accuracy and analyzing failure modes when the mechanism misidentifies knowledge limitations.