---
ver: rpa2
title: 'SCUNet++: Swin-UNet and CNN Bottleneck Hybrid Architecture with Multi-Fusion
  Dense Skip Connection for Pulmonary Embolism CT Image Segmentation'
arxiv_id: '2312.14705'
source_url: https://arxiv.org/abs/2312.14705
tags:
- segmentation
- image
- scunet
- feature
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SCUNet++, an automatic pulmonary embolism (PE)
  segmentation method for CTPA images that addresses the challenge of accurately detecting
  PE in clinical practice due to imaging technology limitations and the complex structure
  of pulmonary arteries. The method incorporates multiple fusion dense skip connections
  between the encoder and decoder, utilizing the Swin Transformer as the encoder,
  and fuses features of different scales in the decoder subnetwork to compensate for
  spatial information loss caused by inevitable downsampling.
---

# SCUNet++: Swin-UNet and CNN Bottleneck Hybrid Architecture with Multi-Fusion Dense Skip Connection for Pulmonary Embolism CT Image Segmentation

## Quick Facts
- arXiv ID: 2312.14705
- Source URL: https://arxiv.org/abs/2312.14705
- Reference count: 24
- Dice Similarity Coefficient (DSC) of 83.47% on FUMPE dataset

## Executive Summary
This paper introduces SCUNet++, a hybrid architecture for automatic pulmonary embolism (PE) segmentation in CTPA images. The method combines Swin Transformer encoders with CNN bottleneck modules and multi-fusion dense skip connections to address the challenges of detecting PE in complex pulmonary artery structures. SCUNet++ achieves state-of-the-art performance with DSC of 83.47% and HD95 of 3.83 on the FUMPE dataset, outperforming existing methods while maintaining computational efficiency through shifted window attention mechanisms.

## Method Summary
SCUNet++ employs a hybrid architecture that uses Swin Transformer blocks as the encoder to capture global spatial dependencies through window-based self-attention. A CNN bottleneck module with 1×1Conv-3×3Conv-1×1Conv structure compensates for the transformer's weakness in local feature extraction. Multi-fusion dense skip connections bridge the encoder and decoder at multiple scales, preserving spatial information lost during downsampling. The model processes 512×512 CTPA images through patch merging and expanding layers, with training conducted for 150 epochs using Adam optimizer at learning rate 0.0001 on RTX 3090 GPU.

## Key Results
- Achieved DSC of 83.47% and HD95 of 3.83 on FUMPE dataset
- Achieved DSC of 83.42% and HD95 of 5.10 on CAD-PE dataset
- Outperformed state-of-the-art methods including Swin-UNet and TransUNet

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Swin Transformer encoder captures long-range global spatial dependencies that pure CNN architectures miss.
- Mechanism: Swin Transformer divides images into non-overlapping patches and applies self-attention within shifted windows across multiple layers, enabling global context modeling beyond local receptive fields.
- Core assumption: Global spatial relationships between different regions of the pulmonary artery system are important for distinguishing PE from anatomical structures and artifacts.
- Evidence anchors: [abstract] "utilizing the Swin Transformer as the encoder" and "fuses features of different scales in the decoder subnetwork to compensate for spatial information loss"; [section 3.1] "The patch merging layer is responsible for downsampling and dimension increase, while Swin Transformer blocks are responsible for feature representation learning"

### Mechanism 2
- Claim: The CNN bottleneck module compensates for the Swin Transformer's weakness in extracting fine local spatial details.
- Mechanism: CNN blocks with 1×1Conv-3×3Conv-1×1Conv sequence and BN-ReLU operations capture local texture and edge information that the transformer blocks miss.
- Core assumption: PE detection requires both global context and precise local boundary delineation, which transformers alone cannot provide.
- Evidence anchors: [abstract] "incorporates multiple fusion dense skip connections between the encoder and decoder, utilizing the Swin Transformer as the encoder"; [section 3.5] "we attempt to use CNN blocks to replace the original bottleneck to fully learn deep feature representations"

### Mechanism 3
- Claim: Multi-fusion dense skip connections reduce the semantic gap between encoder and decoder, preserving spatial information lost during downsampling.
- Mechanism: Dense connections with both long and short skip paths allow features from multiple scales and depths to be jointly learned and fused, maintaining spatial resolution information.
- Core assumption: PE segmentation requires multi-scale feature integration because PEs appear at various sizes and the context around them contains relevant diagnostic information.
- Evidence anchors: [abstract] "incorporates multiple fusion dense skip connections between the encoder and decoder" and "fuses features of different scales in the decoder subnetwork to compensate for spatial information loss"; [section 3.8] "The proposed model is designed with dense connections, incorporating both long and short connections"

## Foundational Learning

- Concept: Transformer attention mechanisms and window-based self-attention
  - Why needed here: Understanding how Swin Transformer differs from standard transformers through shifted window partitioning is crucial for appreciating why it works for medical images
  - Quick check question: How does the shifted window mechanism in Swin Transformer differ from standard multi-head self-attention, and why is this important for computational efficiency?

- Concept: Skip connections and feature fusion in encoder-decoder architectures
  - Why needed here: The multi-fusion dense skip connections are the key innovation that distinguishes SCUNet++ from standard Swin-UNet
  - Quick check question: What problem do dense skip connections solve in encoder-decoder architectures that standard skip connections cannot address?

- Concept: Hybrid CNN-Transformer architectures
  - Why needed here: Understanding why combining CNNs and transformers is beneficial for medical image segmentation tasks
  - Quick check question: What are the complementary strengths of CNNs and transformers that make hybrid architectures effective for medical image segmentation?

## Architecture Onboarding

- Component map: Input (512×512 CTPA images) → Encoder (Swin Transformer blocks) → Bottleneck (CNN blocks) → Multi-fusion dense skip connections → Decoder (Swin Transformer blocks) → Output (segmentation mask)

- Critical path: Input → Encoder (Swin Transformer) → Bottleneck (CNN) → Multi-fusion skip connections → Decoder (Swin Transformer) → Output

- Design tradeoffs: Using CNN bottleneck increases parameter count and computation but improves local feature extraction; multi-fusion skip connections add complexity but preserve spatial information; Swin Transformer provides global context but may miss fine details

- Failure signatures: Poor local boundary delineation suggests CNN bottleneck insufficient or improperly configured; missing global context suggests transformer layers not deep enough or window size inappropriate; vanishing gradients suggest dense skip connections creating too many paths

- First 3 experiments: 1) Replace CNN bottleneck with Swin Transformer bottleneck only - measure DSC and HD95 drop; 2) Remove multi-fusion skip connections - measure impact on segmentation accuracy; 3) Vary window size in Swin Transformer - test impact on global context capture vs. computational cost

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the inclusion of medical factors like age, gender, and surgical history improve the accuracy and robustness of the SCUNet++ model in detecting PE?
- Basis in paper: [explicit] The paper mentions that in the future, they plan to collaborate with PE specialists and include additional patient information to develop quantifiable and reliable evaluation guidelines.
- Why unresolved: The current study does not include these medical factors in the model, and their impact on the model's performance is yet to be investigated.
- What evidence would resolve it: Experimental results comparing the performance of the SCUNet++ model with and without the inclusion of medical factors like age, gender, and surgical history would provide evidence on their impact on the model's accuracy and robustness.

### Open Question 2
- Question: How does the SCUNet++ model perform in detecting PE in patients with comorbidities such as lung cancer or chronic obstructive pulmonary disease (COPD)?
- Basis in paper: [inferred] The paper does not mention any specific comorbidities, but the model's performance in detecting PE in patients with other lung diseases is an important consideration for clinical application.
- Why unresolved: The current study only evaluates the model's performance on CTPA images of PE patients without considering comorbidities.
- What evidence would resolve it: Experimental results comparing the performance of the SCUNet++ model in detecting PE in patients with and without comorbidities would provide evidence on its generalizability to different patient populations.

### Open Question 3
- Question: How does the SCUNet++ model perform in detecting PE in patients with different body mass indices (BMIs)?
- Basis in paper: [inferred] The paper does not mention any specific BMI considerations, but the model's performance in detecting PE in patients with different body compositions is an important consideration for clinical application.
- Why unresolved: The current study does not evaluate the model's performance in detecting PE in patients with different BMIs.
- What evidence would resolve it: Experimental results comparing the performance of the SCUNet++ model in detecting PE in patients with different BMIs would provide evidence on its generalizability to different patient populations.

## Limitations

- Architectural details are incomplete, particularly regarding specific Swin Transformer window sizes and patch dimensions
- Multi-fusion skip connection implementation lacks precise specifications, making exact reproduction challenging
- Limited evaluation across diverse patient populations, including those with comorbidities or different BMI ranges

## Confidence

- High confidence in the hybrid architecture concept (CNN + Transformer) being effective for medical segmentation, supported by related literature
- Medium confidence in the specific SCUNet++ implementation details, as architectural specifics are incomplete
- Low confidence in the multi-fusion skip connection implementation, as this appears to be a novel contribution without precedent in the corpus

## Next Checks

1. Implement a baseline Swin-UNet and measure performance degradation when replacing CNN bottleneck with transformer-only bottleneck
2. Conduct ablation studies comparing standard skip connections vs. multi-fusion dense skip connections on both FUMPE and CAD-PE datasets
3. Test different window sizes in the Swin Transformer encoder to quantify the tradeoff between global context capture and computational efficiency