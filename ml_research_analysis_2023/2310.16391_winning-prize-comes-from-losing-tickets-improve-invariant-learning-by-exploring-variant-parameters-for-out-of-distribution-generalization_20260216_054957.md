---
ver: rpa2
title: 'Winning Prize Comes from Losing Tickets: Improve Invariant Learning by Exploring
  Variant Parameters for Out-of-Distribution Generalization'
arxiv_id: '2310.16391'
source_url: https://arxiv.org/abs/2310.16391
tags:
- invariant
- learning
- parameters
- evil
- generalization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of out-of-distribution (OOD)
  generalization, where deep learning models often fail when the test data distribution
  differs from the training data. The authors propose a novel framework called Exploring
  Variant parameters for Invariant Learning (EVIL) that leverages both invariant and
  variant parameters to improve OOD generalization.
---

# Winning Prize Comes from Losing Tickets: Improve Invariant Learning by Exploring Variant Parameters for Out-of-Distribution Generalization

## Quick Facts
- arXiv ID: 2310.16391
- Source URL: https://arxiv.org/abs/2310.16391
- Reference count: 40
- This paper proposes EVIL, a framework that improves out-of-distribution generalization by exploring variant parameters while retaining invariant parameters, achieving 2.4% average performance gains on DomainBed when combined with ERM.

## Executive Summary
This paper addresses the challenge of out-of-distribution (OOD) generalization in deep learning, where models often fail when test data distribution differs from training data. The authors propose EVIL (Exploring Variant parameters for Invariant Learning), a novel framework that leverages both invariant and variant parameters to improve OOD generalization. EVIL explores variant parameters by using distribution knowledge to discriminate between different data distributions, and dynamically updates the model by rejecting least activated invariant parameters and calling back least activated variant parameters. The framework demonstrates consistent improvements over various OOD generalization methods on benchmark datasets.

## Method Summary
EVIL is a framework that improves OOD generalization by exploring variant parameters while retaining invariant parameters. The method involves three key phases: pre-training using ERM for initial weight initialization, parameter exploration to identify invariant and variant parameters using gradient magnitudes and distribution knowledge, and dynamic mask updating where the mask separating invariant and variant parameters is periodically updated based on activation levels. The framework can be combined with existing OOD methods like ERM, IRM, and SAM, and has been evaluated on DomainBed benchmark datasets including CMNIST, RMNIST, PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet.

## Key Results
- EVIL achieves 2.4% average performance gains on DomainBed benchmark when combined with ERM
- EVIL outperforms existing sparse invariant learning methods under different sparsity levels, particularly achieving best results at 60% sparsity
- The framework consistently improves the performance of various OOD generalization methods including ERM, IRM, and SAM across multiple datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Exploring variant parameters improves invariant learning by identifying parameters sensitive to distribution shift
- Mechanism: By leveraging distribution knowledge, EVIL can discriminate between different data distributions and identify variant parameters that are sensitive to these shifts. This allows the model to exclude spurious features that are distribution-specific while retaining invariant features crucial for OOD generalization
- Core assumption: Input data can be decomposed into invariant features and spurious features, and variant parameters are strongly related to spurious features
- Evidence anchors: The paper explicitly states that EVIL explores variant parameters by using distribution knowledge to discriminate between different data distributions
- Break condition: If the assumption that input data can be cleanly decomposed into invariant and spurious features is violated, or if the distribution knowledge is not reliable enough to accurately identify variant parameters

### Mechanism 2
- Claim: Dynamic updating of the parameter mask improves OOD generalization by iteratively refining the identification of invariant and variant parameters
- Mechanism: EVIL uses a dynamic update strategy where the mask separating invariant and variant parameters is updated periodically. This involves rejecting the least activated invariant parameters and recalling the least activated variant parameters, allowing for continuous refinement of the subnetwork
- Core assumption: Parameters that are less sensitive to distribution shifts might be critical for learning distribution-invariant features
- Evidence anchors: The paper describes how EVIL dynamically updates the model by rejecting least activated invariant parameters and calling back least activated variant parameters
- Break condition: If the dynamic update process introduces too much instability or if the frequency of updates is not properly tuned, it could lead to suboptimal performance

### Mechanism 3
- Claim: EVIL achieves better OOD generalization performance compared to existing sparse invariant learning methods by effectively excluding variant parameters and leveraging distribution knowledge
- Mechanism: By combining the exploration of variant parameters with dynamic mask updating, EVIL can identify a more robust subnetwork that is less influenced by distribution shift. This results in improved performance on OOD tasks compared to methods that only focus on invariant parameters or use static mask strategies
- Core assumption: Excluding variant parameters and leveraging distribution knowledge leads to better OOD generalization
- Evidence anchors: The paper demonstrates that EVIL achieves the best results under sparsity 60% and outperforms existing methods across multiple datasets
- Break condition: If the trade-off between excluding variant parameters and retaining enough information for learning is not properly balanced, it could lead to a degradation in performance

## Foundational Learning

- Concept: Out-of-Distribution (OOD) Generalization
  - Why needed here: Understanding OOD generalization is crucial for grasping the problem that EVIL aims to solve. It explains why models often fail when test data distribution differs from training data
  - Quick check question: What is the main challenge in OOD generalization, and why do deep learning models often struggle with it?

- Concept: Lottery Ticket Hypothesis (LTH)
  - Why needed here: LTH provides the theoretical foundation for sparse training and is referenced in the paper as a basis for existing methods. Understanding LTH helps explain why EVIL builds upon and improves these methods
  - Quick check question: What is the Lottery Ticket Hypothesis, and how does it relate to sparse training in deep learning?

- Concept: Distribution Knowledge and Domain Information
  - Why needed here: EVIL leverages distribution knowledge to identify variant parameters, which is a key aspect of its mechanism. Understanding how to use domain information for model training is essential for grasping EVIL's approach
  - Quick check question: How can distribution knowledge be used to improve model training and generalization, and what are some potential challenges in using this information?

## Architecture Onboarding

- Component map: Pre-training phase -> Parameter exploration phase -> Dynamic mask updating -> Invariant learning phase
- Critical path: 1) Pre-train the model using ERM for 1,000 iterations, 2) Initialize the mask based on weight values, 3) Conduct parameter exploration to identify invariant and variant parameters, 4) Dynamically update the mask periodically based on activation levels, 5) Train the subnetwork using invariant learning methods with the updated mask
- Design tradeoffs: Sparsity level (higher sparsity can lead to better OOD generalization but may result in loss of information), Update frequency (more frequent updates can lead to better refinement but may introduce instability), Choice of invariant learning method (different methods may have varying effectiveness)
- Failure signatures: Poor OOD generalization (indicating variant parameters were not properly identified or excluded), Overfitting to training data (suggesting dynamic mask updating is not effectively refining the subnetwork), Computational inefficiency (indicating update frequency or sparsity level needs adjustment)
- First 3 experiments: 1) Compare EVIL with baseline method on simple OOD dataset to verify effectiveness of exploring variant parameters, 2) Evaluate impact of different sparsity levels on OOD generalization performance to find optimal trade-off, 3) Test sensitivity to update frequency parameter to determine optimal balance between refinement and stability

## Open Questions the Paper Calls Out

- How does the effectiveness of EVIL vary across different sparsity levels and what is the optimal sparsity ratio for achieving the best OOD generalization performance?
- How does EVIL perform when applied to larger-scale architectures such as CLIP ViT-B/16 and what are the implications for real-world applications?
- What is the theoretical explanation for why exploring variant parameters using distribution knowledge is more effective than using label information for OOD generalization?

## Limitations
- The paper lacks detailed analyses of failure cases or conditions under which EVIL might underperform
- While showing empirical success, the theoretical grounding for why distribution knowledge is more effective than label information remains limited
- The scalability and computational efficiency of EVIL for larger, more complex models requires further validation

## Confidence
- High confidence in experimental results showing EVIL's effectiveness when combined with existing OOD methods (ERM, IRM, SAM) on DomainBed benchmark
- Medium confidence in theoretical claims about invariant vs variant parameter decomposition and the mechanism of exploring variant parameters using distribution knowledge
- Medium confidence in the scalability of EVIL to larger-scale architectures and real-world applications

## Next Checks
1. **Transferability analysis**: Evaluate EVIL's performance when transferring models trained on one domain to completely unseen domains not represented in the training distribution
2. **Sensitivity analysis**: Systematically vary sparsity levels and update frequencies to determine the optimal hyperparameters and identify potential failure modes
3. **Theoretical validation**: Develop formal proofs or more rigorous theoretical analysis to establish the conditions under which exploring variant parameters leads to improved OOD generalization