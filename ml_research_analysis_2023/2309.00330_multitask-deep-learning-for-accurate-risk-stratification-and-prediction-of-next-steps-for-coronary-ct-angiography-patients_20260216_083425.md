---
ver: rpa2
title: Multitask Deep Learning for Accurate Risk Stratification and Prediction of
  Next Steps for Coronary CT Angiography Patients
arxiv_id: '2309.00330'
source_url: https://arxiv.org/abs/2309.00330
tags:
- learning
- risk
- coronary
- binary
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposed a multitask deep learning model to support
  risk stratification and downstream test selection for patients undergoing coronary
  computed tomography angiography (CCTA). The analysis included 14,021 patients who
  underwent CCTA between 2006 and 2017.
---

# Multitask Deep Learning for Accurate Risk Stratification and Prediction of Next Steps for Coronary CT Angiography Patients

## Quick Facts
- arXiv ID: 2309.00330
- Source URL: https://arxiv.org/abs/2309.00330
- Reference count: 40
- This paper proposed a multitask deep learning model to support risk stratification and downstream test selection for patients undergoing coronary computed tomography angiography (CCTA).

## Executive Summary
This paper introduces a novel multitask deep learning framework, TabPerceiver, for risk stratification and prediction of downstream tests in coronary CT angiography patients. The model leverages tabular data from CCTA reports to simultaneously predict coronary artery disease (CAD) risk and recommend appropriate downstream diagnostic tests. By extending the Perceiver architecture to handle tabular data and incorporating multitask learning, the authors demonstrate improved performance compared to traditional methods like gradient boosting decision trees and single-task learning approaches.

## Method Summary
The study utilizes 14,021 CCTA patient records, preprocessing tabular data through feature selection using SHAP values and implementing the TabPerceiver architecture. This model combines cross-attention mechanisms with separate embeddings for categorical and continuous features, sharing hidden layers between the two prediction tasks (CAD risk and downstream test selection). The approach employs Bayesian optimization for hyperparameter tuning and compares performance against GBDT and MLP baselines across multiple evaluation metrics including AUC, sensitivity, specificity, and Brier score.

## Key Results
- Achieved 0.76 AUC in CAD risk stratification
- Achieved 0.72 AUC in predicting downstream tests
- Demonstrated multitask learning benefits over single-task approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multitask learning with CAD risk and downstream test prediction improves overall model performance compared to single-task learning.
- Mechanism: By sharing hidden layers between tasks, the model learns complementary and shared features that benefit both tasks, reducing overfitting and improving data efficiency.
- Core assumption: The two tasks (CAD risk prediction and downstream test prediction) are correlated, so information learned for one task can improve the other.
- Evidence anchors:
  - [abstract]: "Our proposed deep learning model can accurately estimate the likelihood of CAD and provide recommended downstream tests based on prior CCTA data."
  - [section]: "Multitask learning, which is a promising field in deep learning, aims to improve the accuracy of learning each task by leveraging the useful information shared across multiple tasks."
  - [corpus]: Weak evidence - no directly comparable studies found in corpus.
- Break Condition: If the tasks are not correlated, or if one task is noisy and dominates the shared representation, the benefit of multitask learning could be reduced or reversed.

### Mechanism 2
- Claim: The TabPerceiver architecture improves performance on tabular data compared to traditional transformers and gradient boosting decision trees.
- Mechanism: The TabPerceiver uses cross-attention to project input embeddings to a fixed-dimensional latent bottleneck, reducing the complexity of handling large numbers of input features compared to standard self-attention transformers.
- Core assumption: Tabular data benefits from handling categorical and continuous features differently, and from a reduced-complexity attention mechanism.
- Evidence anchors:
  - [abstract]: "Our novel multitask deep learning framework extends the state-of-the art Perceiver model to deal with real-world CCTA report data."
  - [section]: "We have extended the architecture of Perceiver-IO [25] and Tabtransformer [26] to create the TabPerceiver."
  - [corpus]: Weak evidence - no directly comparable studies found in corpus.
- Break Condition: If the latent bottleneck is too restrictive, or if the feature embedding is not effective, the model could underperform compared to simpler architectures.

### Mechanism 3
- Claim: Feature selection using SHAP values improves the performance of deep learning models on tabular data.
- Mechanism: By removing uninformative features, the model focuses on the most relevant information, reducing noise and improving generalization.
- Core assumption: Deep learning models are more sensitive to irrelevant features than tree-based models like GBDT.
- Evidence anchors:
  - [section]: "Feature ranking obtained using SHAP turned out to be the most effective guide for feature selection in both GBDT and deep learning models for CAD risk and down-streaming test prediction."
  - [section]: "It appears that deep learning tabular architectures benefit from multi-task learning. We have also demonstrated that feature selection is an essential step for deep learning tabular data modeling."
  - [corpus]: Weak evidence - no directly comparable studies found in corpus.
- Break Condition: If the SHAP values are not reliable for the given data, or if important features are incorrectly ranked as uninformative, performance could suffer.

## Foundational Learning

- Concept: Multitask learning
  - Why needed here: The two prediction tasks (CAD risk and downstream test selection) are related and benefit from shared representation learning.
  - Quick check question: What is the main advantage of multitask learning over single-task learning?

- Concept: Transformer architectures
  - Why needed here: Standard transformers are computationally expensive for tabular data; the Perceiver architecture reduces complexity while maintaining effectiveness.
  - Quick check question: How does the cross-attention mechanism in Perceiver differ from standard self-attention?

- Concept: Feature selection and importance
  - Why needed here: Deep learning models are sensitive to irrelevant features; selecting the most informative features improves performance.
  - Quick check question: What is SHAP and how is it used for feature selection?

## Architecture Onboarding

- Component map: Input -> Embeddings -> Encoder -> Decoder -> Output
- Critical path: Input -> Embeddings -> Encoder -> Decoder -> Output
- Design tradeoffs:
  - Single-task vs. multi-task: Multi-task improves performance but adds complexity
  - Decoder vs. MLP: Decoder performed slightly better in this study
  - Feature selection: Improves deep learning performance but requires careful selection
- Failure signatures:
  - Poor performance on one or both tasks: Could indicate issues with feature selection, embeddings, or task correlation
  - Overfitting: Could indicate need for regularization or more data
  - Slow training: Could indicate issues with hyperparameters or model complexity
- First 3 experiments:
  1. Compare single-task vs. multi-task performance on a validation set
  2. Test different feature selection strategies (e.g., top 20 vs. top 50 features by SHAP)
  3. Compare TabPerceiver performance with standard MLP and GBDT baselines

## Open Questions the Paper Calls Out

1. How would incorporating actual CCTA images and clinical text reports into the TabPerceiver model affect its performance in predicting CAD risk and downstream testing compared to using tabular data alone?
2. Would the TabPerceiver model's performance be significantly improved with a larger, more diverse dataset that includes follow-up admission and mortality outcomes for the entire cohort?
3. Is there a universally superior approach between GBDT and deep learning models for tabular data, or does the optimal choice depend on specific characteristics of the dataset and task?

## Limitations

- Dataset from single institution may limit generalizability
- Performance improvement over traditional methods demonstrated but not new benchmarks established
- TabPerceiver architecture lacks extensive validation against other deep learning approaches

## Confidence

- Confidence in performance metrics: Medium
  - Study demonstrates solid methodology but lacks direct comparisons to state-of-the-art models
  - Dataset limitations and single-institution origin create uncertainty
  - Multitask benefits demonstrated but could be further validated

## Next Checks

1. **External validation**: Test the model on independent datasets from different institutions to assess generalizability and potential performance degradation.

2. **Ablation study**: Systematically remove the multitask component, feature selection, and TabPerceiver architecture to quantify each element's contribution to overall performance.

3. **Clinical utility assessment**: Evaluate whether the model's predictions lead to improved patient outcomes or workflow efficiency in a prospective clinical trial, beyond just predictive accuracy metrics.