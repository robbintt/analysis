---
ver: rpa2
title: 'Data pruning and neural scaling laws: fundamental limitations of score-based
  algorithms'
arxiv_id: '2302.06960'
source_url: https://arxiv.org/abs/2302.06960
tags:
- random
- pruning
- data
- algorithm
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper analyzes score-based data pruning algorithms, showing\
  \ they fail in high compression regimes (\u226430% data kept). The core issue is\
  \ that these algorithms induce distribution shifts by ignoring data regions, leading\
  \ to performance degradation and preventing improvements in neural scaling laws."
---

# Data pruning and data pruning and neural scaling laws: fundamental limitations of score-based algorithms

## Quick Facts
- **arXiv ID:** 2302.06960
- **Source URL:** https://arxiv.org/abs/2302.06960
- **Reference count:** 40
- **Primary result:** Score-based pruning algorithms fail in high compression regimes (≤30% data kept) due to distribution shifts that prevent improvements in neural scaling laws

## Executive Summary
This paper analyzes score-based data pruning algorithms (SBPAs) and demonstrates their fundamental limitations in high compression regimes. The core issue is that these algorithms induce distribution shifts by ignoring data regions, leading to performance degradation and preventing improvements in neural scaling laws. The authors prove no-free-lunch theorems showing SBPAs underperform random pruning in abundant data regimes. To address this, they propose calibration protocols that split the data budget between signal (using the pruning algorithm) and exploration (random sampling), with two protocols: exact calibration (ensuring consistency) and approximate calibration (reducing variance). Experiments confirm these findings and show calibrated pruning can outperform random pruning when appropriate parameters are chosen.

## Method Summary
The authors analyze score-based pruning algorithms that rank data points by importance scores and retain only the top-ranked points. They prove theoretical limitations showing these algorithms induce distribution shifts in high compression regimes, creating new local minima with poor generalization. To mitigate this, they propose calibration protocols that split the data budget between signal (SBPA-selected points) and exploration (randomly sampled points). Two protocols are introduced: exact calibration ensures consistency but may have high variance, while approximate calibration trades some consistency for reduced variance. The method involves computing scores for all data points, applying the calibration protocol with a signal parameter α, and training models on the selected subset.

## Key Results
- SBPA algorithms underperform random pruning for compression ratios ≤30% in high data regimes
- SBPA induces distribution shifts that alter the loss landscape, creating new local minima with poor generalization
- Calibration protocols that split data budget between signal and exploration can mitigate distribution shift and improve SBPA performance
- The signal parameter α must be carefully chosen: larger α gives more weight to SBPA signal but increases variance, while smaller α reduces variance but may lose useful information

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** SBPA algorithms induce distribution shifts by ignoring data regions in high compression regimes, leading to performance degradation
- **Mechanism:** SBPA algorithms rank data points by importance scores and retain only the top-ranked points. In high compression regimes (≤30% data kept), this process causes entire regions of the data space to be ignored. The pruned dataset's empirical distribution converges to a restricted distribution that differs from the original data-generating process, creating a mismatch between training and generalization objectives.
- **Core assumption:** The score function used by SBPA is adapted (continuous with no mass points) and the data space has no isolated points.
- **Evidence anchors:**
  - [abstract]: "The core issue is that these algorithms induce distribution shifts by ignoring data regions, leading to performance degradation"
  - [section]: "Asymptotically, SBPA algorithms have a simple behavior that mimics rejection algorithms. We describe this in the following result... Almost surely, the empirical measure of the retained data samples converges weakly to νr = 1/r µ|Ar"
  - [corpus]: No direct evidence found in the corpus about distribution shift mechanisms specifically for SBPA.
- **Break condition:** When the compression level is high enough that the acceptance region becomes too small, causing the pruned distribution to be too different from the original, or when the score function is not adapted (has discontinuities or mass points).

### Mechanism 2
- **Claim:** SBPA algorithms cannot improve neural scaling laws in high compression regimes because they create new local minima with poor generalization
- **Mechanism:** The distribution shift caused by SBPA alters the loss landscape, potentially creating new local minima that are not present in the original loss function. Gradient descent may converge to these poor minima, leading to significant performance degradation even with large amounts of data.
- **Core assumption:** The loss function is continuous and the model class has sufficient capacity to represent the data-generating process.
- **Evidence anchors:**
  - [abstract]: "leading to performance degradation and preventing improvements in neural scaling laws"
  - [section]: "The distribution shift is the primary cause of the observed alteration in the loss function, resulting in the emergence of new minima"
  - [corpus]: No direct evidence found in the corpus about scaling laws and SBPA interaction.
- **Break condition:** When the model capacity is too limited to represent the data-generating process, or when the compression level is low enough that the distribution shift is minimal.

### Mechanism 3
- **Claim:** Calibration protocols that split the data budget between signal (SBPA-selected) and exploration (random sampling) can mitigate distribution shift and improve SBPA performance in high compression regimes
- **Mechanism:** By allocating a portion of the data budget to random exploration, the calibration protocols ensure that information from previously ignored regions is retained. This helps correct the distribution shift and reduces the variance in the empirical risk estimate.
- **Core assumption:** The data budget is sufficient to allow meaningful exploration, and the score function provides some useful signal even in high compression regimes.
- **Evidence anchors:**
  - [abstract]: "To address this, they propose calibration protocols that split the data budget between signal (using the pruning algorithm) and exploration (random sampling)"
  - [section]: "The calibration protocols can be thought of as wrapper modules that can be applied on top of any SBPA algorithm to mitigate or solve the consistency issue"
  - [corpus]: No direct evidence found in the corpus about calibration protocols for SBPA.
- **Break condition:** When the overall data budget is too small, making exploration ineffective, or when the SBPA score function is completely uninformative.

## Foundational Learning

- **Concept:** Universal approximation property of neural networks
  - **Why needed here:** The paper uses the universal approximation property to prove that SBPA algorithms are not consistent for large enough neural networks, which is a key theoretical result
  - **Quick check question:** What does it mean for a family of functions to have the universal approximation property, and why is this important for the consistency results in the paper?

- **Concept:** Consistency and validity of pruning algorithms
  - **Why needed here:** The paper defines and characterizes valid and consistent pruning algorithms, which are central to understanding the limitations of SBPA
  - **Quick check question:** What is the difference between a consistent and a valid pruning algorithm, and how does this relate to the performance of SBPA in high compression regimes?

- **Concept:** Distribution shift and its impact on generalization
  - **Why needed here:** The paper argues that SBPA induces distribution shifts that affect generalization performance, which is a key mechanism for understanding their limitations
  - **Quick check question:** How does a distribution shift caused by data pruning affect the generalization performance of a model, and why is this particularly problematic in high compression regimes?

## Architecture Onboarding

- **Component map:** Score function -> SBPA algorithm -> Calibration protocol (α) -> Data split (signal/exploration) -> Training algorithm -> Trained model
- **Critical path:** 1) Compute scores for all data points using SBPA score function 2) Apply calibration protocol to split data budget between signal and exploration 3) Train model on selected subset using training algorithm 4) Evaluate performance on held-out test data
- **Design tradeoffs:** Choosing α balances signal vs variance; exact calibration ensures consistency but has higher variance, approximate calibration trades consistency for reduced variance; higher compression saves resources but increases distribution shift risk
- **Failure signatures:** Performance degradation in high compression regimes (≤30% data kept), inconsistent performance across runs/datasets, model converging to poor local minima, calibration protocols not improving performance even with optimal α
- **First 3 experiments:** 1) Verify SBPA with high compression ratio leads to distribution shift by visualizing pruned vs original data distribution 2) Compare performance of SBPA with and without calibration protocols across different compression ratios 3) Evaluate impact of signal parameter α on performance of calibrated SBPA algorithms

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Under what specific conditions do score-based pruning algorithms outperform random pruning in the high compression regime?
- **Basis in paper:** [explicit] The paper shows that SBPA algorithms underperform random pruning for r ≤ 30% in high compression regimes, but does not fully characterize when they might outperform random pruning in this regime
- **Why unresolved:** The paper proves limitations of SBPA algorithms but doesn't provide sufficient conditions for when they might still be beneficial in high compression settings
- **What evidence would resolve it:** Empirical studies systematically varying dataset characteristics, model architectures, and pruning criteria to identify specific scenarios where SBPA algorithms consistently outperform random pruning at high compression levels

### Open Question 2
- **Question:** What is the optimal balance between signal and exploration budgets (α parameter) for different compression levels and dataset types?
- **Basis in paper:** [explicit] The paper proposes calibration protocols with an α parameter but notes that the optimal choice depends on multiple factors and shows variability across different settings
- **Why unresolved:** While the paper demonstrates that calibration protocols can improve performance, it doesn't provide a principled method for selecting α that works across different scenarios
- **What evidence would resolve it:** A comprehensive study analyzing how α should be tuned based on compression level, dataset size, model architecture, and data distribution characteristics

## Limitations

- Theoretical claims rely on asymptotic analysis and simplified models that may not fully capture deep neural network complexity
- Calibration protocols assume existence of optimal α parameter that may be difficult to find in practice
- No-free-lunch theorems proven for specific settings (no unlabeled data, uniform distribution over binary classification problems) that may not translate to real-world scenarios

## Confidence

- **High Confidence:** Distribution shift mechanism in high compression regimes is well-established through theoretical analysis and experimental evidence; no-free-lunch theorems are rigorously proven
- **Medium Confidence:** Effectiveness of calibration protocols demonstrated empirically, but theoretical guarantees rely on strong assumptions that may not hold in practice; optimal α selection lacks principled approach
- **Low Confidence:** Claims about fundamental limitations preventing improvements in neural scaling laws based on simplified models may not fully capture behavior of large-scale deep neural networks

## Next Checks

1. **Empirical validation on large-scale models:** Replicate experiments with larger neural networks (ResNet50, EfficientNet) and complex datasets (ImageNet) to verify if distribution shift and performance degradation persist in realistic settings

2. **Robustness of calibration protocols:** Investigate sensitivity of calibration protocols to α choice and impact of different data budgets on effectiveness; develop principled approach for selecting α based on dataset and SBPA algorithm

3. **Alternative SBPA algorithms:** Evaluate performance of other SBPA algorithms (Fisher pruning, sensitivity-based pruning) that may be less susceptible to distribution shift; analyze their score functions to identify key properties that mitigate traditional SBPA limitations