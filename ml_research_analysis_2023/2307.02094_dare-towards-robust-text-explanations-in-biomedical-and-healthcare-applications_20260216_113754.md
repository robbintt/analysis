---
ver: rpa2
title: 'DARE: Towards Robust Text Explanations in Biomedical and Healthcare Applications'
arxiv_id: '2307.02094'
source_url: https://arxiv.org/abs/2307.02094
tags:
- cell
- tumor
- have
- were
- cancer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DARE, a domain-adaptive attribution robustness
  estimator for biomedical and healthcare applications. The method adapts existing
  attribution robustness estimation techniques to domain-specific plausibility by
  using domain-adapted language models for semantic similarity.
---

# DARE: Towards Robust Text Explanations in Biomedical and Healthcare Applications

## Quick Facts
- arXiv ID: 2307.02094
- Source URL: https://arxiv.org/abs/2307.02094
- Reference count: 40
- One-line primary result: DARE estimator and FAR training improve attribution robustness in biomedical text classification by 40-60% via domain-adaptive perturbations.

## Executive Summary
This paper introduces DARE (Domain-Adaptive Attribution Robustness Estimator) for improving the robustness of text explanations in biomedical and healthcare applications. DARE adapts existing attribution robustness estimation techniques to domain-specific plausibility by using domain-adapted language models for semantic similarity. The authors propose two robust training methods—adversarial training and FAR training—to mitigate the fragility of standard text classifiers to small, imperceptible word substitutions. Experiments on three biomedical datasets demonstrate significant improvements in attribution robustness, with FAR training achieving the best results.

## Method Summary
DARE estimates attribution robustness by generating adversarial perturbations using domain-specific masked language models (MLMs) and gradient-based importance ranking. The method computes attribution maps for both original and perturbed samples, measuring robustness via cosine distance and semantic similarity (MedSTS). FAR training extends adversarial training by jointly optimizing classification loss and attribution distance, using DARE to guide the inner maximization loop. The approach is adapted for multilabel classification by aggregating attribution maps across predicted labels.

## Key Results
- Standard text classifiers exhibit brittle attributions vulnerable to small, imperceptible word substitutions in biomedical text.
- FAR training reduces the estimated robustness constant by 40-60% across datasets and attribution methods.
- Domain-specific MLMs (PubMedBERT, Clinical-Longformer) significantly improve the plausibility of adversarial perturbations compared to general-domain MLMs.

## Why This Works (Mechanism)

### Mechanism 1
Domain-adaptive candidate extractors improve plausibility of adversarial perturbations in biomedical text. Using MLMs trained on biomedical corpora increases top-5 prediction accuracy on masked words, leading to more plausible in-context substitutions. Core assumption: Masked language models trained on domain-specific text capture the semantic and syntactic nuances required for plausible word substitutions. Break condition: If MLM vocabulary coverage or contextual understanding degrades, plausibility scores (MedSTS) will drop despite domain adaptation.

### Mechanism 2
FAR training with attribution distance regularization improves attribution robustness more than adversarial training alone. FAR training optimizes a joint objective that balances classification loss and attribution distance, extracted via DARE, leading to networks that are robust to both prediction and attribution perturbations. Core assumption: Attribution distance computed via DARE correlates with true attribution robustness across multiple attribution methods. Break condition: If attribution distance does not correlate with actual attribution robustness, FAR training gains will not transfer to unseen attribution methods.

### Mechanism 3
Extending AR estimation to multilabel classification maintains robustness quantification validity. Summing attribution maps across all predicted labels and modifying prediction constraint to compare predicted label sets allows AR estimation to apply to multilabel datasets. Core assumption: Attribution maps can be meaningfully aggregated across labels without losing interpretability or robustness signal. Break condition: If label interactions or class imbalance distort attribution maps, the summed attribution may not reflect true feature importance, breaking robustness estimation.

## Foundational Learning

- **Attribution robustness and Lipschitz continuity in text domains**: Understanding how small input perturbations affect attribution maps is central to DARE's design and FAR training objectives. Quick check: What is the difference between faithfulness and plausibility in the context of XAI, and how does DARE address both?
- **Masked language models and domain adaptation**: DARE's candidate extractor relies on MLMs fine-tuned to specific biomedical vocabularies for plausible substitutions. Quick check: Why does using a general-domain MLM (e.g., DistilBERT) perform worse than a domain-specific one (e.g., PubMedBERT) for DARE?
- **Adversarial training and attribution-based objectives**: FAR training extends adversarial training to attribution space, requiring understanding of joint optimization over predictions and attributions. Quick check: How does the γ parameter in FAR training balance classification accuracy and attribution robustness?

## Architecture Onboarding

- **Component map**: Domain MLM (candidate extraction) -> Attribution gradient (importance ranking) -> Greedy substitution loop (DARE) -> Joint loss (FAR training)
- **Critical path**: 1. Train domain-specific MLMs for candidate extraction. 2. Run DARE to estimate baseline attribution robustness. 3. Apply FAR training with DARE-based inner loop. 4. Validate robustness gains via cosine distance and MedSTS metrics.
- **Design tradeoffs**: Domain MLM vs general MLM: higher plausibility vs broader coverage. Attribution distance metric: cosine vs L2 affects optimization landscape. Multilabel aggregation: summing attributions may mask label-specific robustness issues.
- **Failure signatures**: Low MedSTS despite high cosine similarity → implausible but attributionally similar perturbations. FAR training collapse → attribution distance dominates, hurting accuracy. DARE runtime blowup → inefficient candidate extraction or excessive perturbation steps.
- **First 3 experiments**: 1. Compare DARE robustness estimates using general vs domain MLMs on a small subset. 2. Train a vanilla model, then apply FAR training, measure attribution robustness before/after. 3. Validate FAR-trained model robustness across Saliency, DeepLIFT, and Integrated Gradients.

## Open Questions the Paper Calls Out

1. How does the attribution robustness of biomedical text classifiers generalize across different domains beyond the three datasets studied (Drug Reviews, Hallmarks of Cancer, MIMIC-III)?
2. What is the impact of attribution robustness on downstream tasks such as model debugging, clinical decision support, or risk assessment in healthcare?
3. How does the computational cost of DARE and FAR training scale with larger models and longer sequences, particularly for clinical notes or other high-dimensional biomedical data?

## Limitations
- Reliance on proxy metrics (MedSTS) rather than human evaluation of attribution plausibility.
- Multilabel extension lacks direct validation beyond synthetic examples.
- Domain adaptation benefits assume MLM fine-tuning captures sufficient semantic nuance, but coverage gaps may persist for rare biomedical terms.

## Confidence

- **High**: DARE's core estimation methodology and multilabel extension logic
- **Medium**: Attribution robustness improvements via FAR training
- **Low**: Domain adaptation claims without direct plausibility validation

## Next Checks

1. Have biomedical experts rate attribution plausibility of DARE-generated perturbations versus ground truth substitutions.
2. Test FAR-trained models on out-of-domain biomedical text to verify generalization of attribution robustness.
3. Validate that FAR training robustness gains transfer across multiple attribution methods beyond those used during training.