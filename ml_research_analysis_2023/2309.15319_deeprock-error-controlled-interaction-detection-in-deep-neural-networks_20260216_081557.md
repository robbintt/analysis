---
ver: rpa2
title: 'DeepROCK: Error-controlled interaction detection in deep neural networks'
arxiv_id: '2309.15319'
source_url: https://arxiv.org/abs/2309.15319
tags:
- interactions
- interaction
- feature
- deeprock
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces DeepROCK, a method for detecting feature\
  \ interactions in deep neural networks (DNNs) while controlling the false discovery\
  \ rate (FDR). The key innovation is using knockoffs\u2014dummy variables mimicking\
  \ the dependence structure of original features but independent of the response\u2014\
  to achieve error-controlled interaction detection."
---

# DeepROCK: Error-controlled interaction detection in deep neural networks

## Quick Facts
- arXiv ID: 2309.15319
- Source URL: https://arxiv.org/abs/2309.15319
- Authors: 
- Reference count: 40
- Key outcome: DeepROCK controls FDR at target levels (0.2 for simulations, 0.1 for real data) while maintaining high power in detecting true interactions, validated on both simulated and real datasets.

## Executive Summary
This paper introduces DeepROCK, a method for detecting feature interactions in deep neural networks (DNNs) while controlling the false discovery rate (FDR). The key innovation is using knockoffs—dummy variables mimicking the dependence structure of original features but independent of the response—to achieve error-controlled interaction detection. DeepROCK employs a novel DNN architecture with a pairwise-coupling layer that encourages competition between each feature and its knockoff counterpart, maximizing statistical power. A critical finding is that existing interaction importance measures fail to correctly control FDR, which DeepROCK addresses through a calibration procedure.

## Method Summary
DeepROCK achieves interaction detection with controlled FDR by integrating knockoff filters with DNNs. The method generates knockoff features from input data using KnockoffGAN, then employs a novel MLP architecture with a pairwise-coupling layer containing p filters (one per feature) that connect each original feature to its knockoff counterpart. This architecture encourages competition between features and their knockoffs during training. A calibration procedure is applied to existing interaction importance measures to correct their distribution and ensure FDR control. The calibrated interaction importance is defined as the ratio of model-based interaction importance to the product of univariate feature importances, enabling FDR control at a target level while maintaining statistical power.

## Key Results
- DeepROCK controls FDR at target levels (0.2 for simulations, 0.1 for real data) while maintaining high power in detecting true interactions
- The method effectively identifies biologically relevant interactions in Drosophila enhancer data and mortality risk factors
- Identified interactions are supported by literature evidence, including examples like Age-Smoking and Age-BMI interactions for mortality risk

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DeepROCK achieves FDR control by using knockoff features that mimic the dependence structure of original features while being conditionally independent of the response.
- Mechanism: The knockoff filter creates dummy variables that perfectly mimic the empirical dependence structure among the original features but are conditionally independent of the response given the original features. This allows for error-controlled feature selection by comparing original features against their knockoff counterparts.
- Core assumption: The knockoff features can be constructed to perfectly mimic the dependence structure of the original features while maintaining conditional independence from the response.
- Evidence anchors:
  - [abstract] "DeepROCK makes two primary contributions. First, DeepROCK uses a novel, multilayer perceptron (MLP) architecture that includes a plugin pairwise-coupling layer containing multiple filters, one per input feature, where each filter connects the original feature and its knockoff counterpart. As such, DeepROCK achieves FDR control via the knockoffs and maximizes statistical power by encouraging the competition of each feature against its knockoff counterpart through the pairwise-coupling layer."
  - [section] "DeepROCK integrates the idea of knockoffs with DNNs to achieve interaction detection with controlled FDR... DeepROCK first generates the knockoffs from the input data by following the procedure described in Section 2.2."
- Break condition: If the knockoff generation process fails to maintain conditional independence from the response, or if the dependence structure cannot be adequately mimicked, the FDR control mechanism breaks down.

### Mechanism 2
- Claim: The pairwise-coupling layer maximizes statistical power by encouraging competition between each feature and its knockoff counterpart.
- Mechanism: DeepROCK employs a novel DNN architecture that includes a plugin pairwise-coupling layer containing p filters, one per input feature, where each filter connects the original feature and its knockoff counterpart. The filter weights are initialized equally and compete against each other through pairwise connections during training.
- Core assumption: The pairwise-coupling layer can effectively encourage competition between original features and their knockoff counterparts, leading to meaningful differences in importance scores.
- Evidence anchors:
  - [abstract] "Together with a novel DNN architecture involving a pairwise-coupling layer, DeepROCK jointly controls the false discovery rate (FDR) and maximizes statistical power."
  - [section] "The filter weights Zj and ˜Zj for the j-th feature and its knockoff counterpart are initialized equally and compete against each other through pairwise connections during training."
- Break condition: If the competition mechanism fails to produce meaningful differences between original features and knockoffs, or if the initialization leads to degenerate solutions, the power maximization breaks down.

### Mechanism 3
- Claim: The calibration procedure resolves the issue of existing importance measures failing to correctly control FDR.
- Mechanism: DeepROCK proposes a calibration procedure applied to existing interaction importance measures to make the FDR under control at a target level. The calibrated interaction importance is defined as a function of both the interaction importance measure and the univariate feature importance measure.
- Core assumption: The calibration procedure can effectively correct the distribution of knockoff feature interaction scores to match the distribution of irrelevant feature interaction scores.
- Evidence anchors:
  - [section] "To resolve this issue, DeepROCK proposes a calibration procedure applied to existing interaction importance measures to make the FDR under control at a target level. The calibrated interaction between the i-th and j-th features is defined as Sij = |S2D_ij| / sqrt(|S1D_i · S1D_j|)."
  - [section] "We discover, surprisingly, that naively using existing feature interaction importance measures without calibration does not correctly control the FDR. In comparison, existing feature interaction importance measures with calibration consistently controls the FDR much below the target FDR level."
- Break condition: If the calibration procedure fails to adequately correct the distribution mismatch, or if the relationship between interaction and univariate importance is not properly captured, the FDR control mechanism breaks down.

## Foundational Learning

- Concept: False Discovery Rate (FDR) control
  - Why needed here: DeepROCK aims to achieve interaction detection while explicitly controlling the associated error rate, quantified via FDR.
  - Quick check question: What is the formal definition of FDR and how does it differ from other error rate measures like family-wise error rate (FWER)?

- Concept: Knockoff filters
  - Why needed here: DeepROCK leverages the knockoff framework to achieve FDR control in the absence of meaningful p-values for interaction importance in DNNs.
  - Quick check question: What are the two key properties that knockoff features must satisfy according to Definition 1 in the paper?

- Concept: Feature interaction importance measures
  - Why needed here: DeepROCK uses both model-based and instance-based importance measures to induce a ranking on candidate interactions, which is then calibrated for FDR control.
  - Quick check question: How do the model-based and instance-based importance measures differ in their approach to quantifying feature interaction importance?

## Architecture Onboarding

- Component map: Input -> Knockoff generation -> Pairwise-coupling layer -> Hidden layers -> Output -> Calibration -> FDR-controlled interaction selection
- Critical path: Input features and knockoffs → Pairwise-coupling layer (competition) → Hidden layers with ELU activation → Output prediction → Calibrated interaction importance → FDR-controlled selection
- Design tradeoffs:
  - Using knockoffs vs. p-values: Knockoffs bypass the need for p-values but require careful generation to maintain conditional independence.
  - Model-based vs. instance-based importance: Model-based importance is computationally efficient but may miss instance-specific interactions, while instance-based importance is more comprehensive but computationally expensive.
- Failure signatures:
  - FDR control fails: Check knockoff generation process and calibration procedure.
  - Low power: Check pairwise-coupling layer competition mechanism and initialization.
  - Poor ranking performance: Check interaction importance measure and calibration.
- First 3 experiments:
  1. Verify knockoff generation maintains conditional independence from response.
  2. Test pairwise-coupling layer competition mechanism with simple synthetic data.
  3. Validate calibration procedure on simulated datasets with known ground truth interactions.

## Open Questions the Paper Calls Out

- **Higher-order interactions**: DeepROCK is limited to pairwise interaction detection. Supporting higher-order interaction detection with controlled FDR is critical in explaining genetic mechanisms, diseases, and drug effects in healthcare domains.

- **Instance-based vs. model-based power**: We observe that instance-based importance consistently achieves much higher power with more conservative FDR estimation than model-based importance. We would like to better understand the reason for this trend.

## Limitations

- The method is specifically designed for pairwise interactions and does not extend naturally to higher-order interactions, which may be important in many domains.
- The calibration procedure assumes a specific relationship between interaction and univariate importance measures that may not hold across all data types and model architectures.
- The computational cost of generating knockoffs using GAN-based methods could be prohibitive for very high-dimensional datasets.

## Confidence

- **High Confidence**: The core mechanism of using knockoffs for FDR control in DNNs is well-established in the literature and the pairwise-coupling layer design is clearly specified. The empirical results showing FDR control at target levels (0.2 for simulations, 0.1 for real data) are convincing.
- **Medium Confidence**: The calibration procedure's effectiveness across different interaction importance measures and datasets is demonstrated but not extensively validated. The biological interpretations of detected interactions, while supported by literature, involve some degree of subjective judgment.
- **Low Confidence**: The computational scalability of the method for very high-dimensional data and the extension to higher-order interactions remain largely unexplored.

## Next Checks

1. **Higher-Order Interaction Validation**: Test DeepROCK's performance on synthetic datasets with known third-order and fourth-order interactions to evaluate whether the pairwise-focused architecture can be extended or adapted for detecting complex multi-way interactions.

2. **Cross-Dataset Calibration Robustness**: Apply DeepROCK to a diverse set of datasets from different domains (e.g., image data, tabular data from various fields) to test whether the calibration procedure maintains FDR control across data types with different statistical properties and correlation structures.

3. **Computational Scalability Benchmark**: Systematically evaluate the computational cost of DeepROCK as a function of feature dimensionality and sample size, comparing the knockoff generation time using different methods (e.g., KnockoffGAN vs. exact conditional sampling) to establish practical limits on dataset size.