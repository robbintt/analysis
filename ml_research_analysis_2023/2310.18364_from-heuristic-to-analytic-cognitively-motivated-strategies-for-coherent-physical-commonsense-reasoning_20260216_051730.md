---
ver: rpa2
title: 'From Heuristic to Analytic: Cognitively Motivated Strategies for Coherent
  Physical Commonsense Reasoning'
arxiv_id: '2310.18364'
source_url: https://arxiv.org/abs/2310.18364
tags:
- reasoning
- story
- physical
- water
- trip
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We introduce Heuristic-Analytic Reasoning (HAR), inspired by human
  cognition, to improve coherent physical commonsense reasoning in PLMs. HAR conditions
  low-level analytic rationalization on high-level heuristic decisions in both fine-tuning
  and in-context learning.
---

# From Heuristic to Analytic: Cognitively Motivated Strategies for Coherent Physical Commonsense Reasoning

## Quick Facts
- **arXiv ID**: 2310.18364
- **Source URL**: https://arxiv.org/abs/2310.18364
- **Reference count**: 40
- **Primary result**: HAR improves verifiability from 28.0% to 41.1% on TRIP and from 36.2% to 57.4% on Tiered-ProPara benchmarks

## Executive Summary
This paper introduces Heuristic-Analytic Reasoning (HAR), a cognitively motivated approach that conditions low-level analytic rationalization on high-level heuristic decisions in large language models (PLMs). Inspired by dual-process theories of human cognition, HAR first makes intuitive high-level decisions (like story selection or sentence identification) and then uses these to condition more deliberative reasoning tasks. The approach is applied to both fine-tuning and in-context learning settings for coherent physical commonsense reasoning. HAR significantly outperforms baseline methods on verifiability metrics across TRIP and Tiered-ProPara benchmarks, achieving state-of-the-art coherence. Attention analysis reveals that improved coherence directly results from more faithful context focus during reasoning.

## Method Summary
The HAR approach implements a sequential reasoning framework where high-level heuristic decisions guide subsequent analytic rationalization. In fine-tuning, this involves iterative context deletion where higher-level decisions prune irrelevant information before lower-level reasoning tasks. For in-context learning, HAR employs chain-of-thought prompting with heuristic-analytic reasoning chains. The method uses a Focused CGLI backbone with iterative context deletion strategies, applying the same HAR structure across different PLMs including RoBERTa, InstructGPT, and LLaMA. The key innovation is conditioning lower-level reasoning tasks on the outputs of higher-level heuristic decisions, creating a structured reasoning pathway that mimics human dual-process cognition.

## Key Results
- HAR boosts verifiability from 28.0% to 41.1% on TRIP benchmark and from 36.2% to 57.4% on Tiered-ProPara benchmark
- In in-context learning, HAR improves InstructGPT verifiability from 7.1% to 23.9% on TRIP and from 5.2% to 20.7% on ProPara
- Attention analysis shows HAR enables more faithful context focus, directly linking coherent reasoning to attention faithfulness

## Why This Works (Mechanism)

### Mechanism 1: Conditioning Lower-Level Reasoning on Higher-Level Decisions
- **Claim**: Conditioning low-level analytic reasoning on high-level heuristic decisions improves coherence by focusing model attention on relevant context.
- **Mechanism**: HAR uses high-level decisions (e.g., story selection, sentence identification) to refine input context for lower-level tasks (e.g., physical state prediction), ensuring attention is directed to most relevant parts of text.
- **Core assumption**: Lower-level reasoning tasks are more difficult in isolation but become easier when conditioned on higher-level decisions that narrow relevant context.
- **Evidence anchors**: Abstract states HAR "conditions low-level analytic rationalization on high-level heuristic decisions"; Section describes using high-level decisions to "condition low-level rationalization."
- **Break condition**: If higher-level decision is incorrect, it may mislead lower-level reasoning, causing cascading errors.

### Mechanism 2: Dual-Process Cognitive Theories Applied to PLMs
- **Claim**: Applying dual-process cognitive theories to PLM reasoning improves coherence by mimicking human reasoning strategies.
- **Mechanism**: HAR draws from dual-process theories where fast heuristic thinking makes intuitive decisions based on past experience, then slower analytic thinking rationalizes those decisions.
- **Core assumption**: Human-like reasoning strategies can be effectively translated into computational strategies for PLMs.
- **Evidence anchors**: Abstract describes humans using "fast and intuitive heuristic thinking to make decisions based on past experience, then rationalizing through slower and deliberative analytic reasoning."
- **Break condition**: If PLM doesn't benefit from structured reasoning approach or dual-process theory doesn't apply well to machine reasoning.

### Mechanism 3: Attention Faithfulness as Direct Link to Coherence
- **Claim**: Improved coherence in PLM reasoning is directly linked to more faithful attention to relevant language context.
- **Mechanism**: HAR enables model to focus attention on most relevant parts of input text at each reasoning step, leading to more coherent and verifiable reasoning.
- **Core assumption**: Faithful attention to relevant context is necessary for coherent reasoning in PLMs.
- **Evidence anchors**: Abstract reveals "HAR enables more faithful context focus, directly linking coherent reasoning to attention faithfulness."
- **Break condition**: If attention mechanism doesn't improve with HAR or other factors are more important for coherence.

## Foundational Learning

- **Concept**: Dual-process theories of cognition
  - **Why needed here**: Understanding inspiration behind HAR requires knowledge of how humans use fast intuitive heuristic thinking and slower deliberative analytic thinking in reasoning.
  - **Quick check question**: What are the two main processes in dual-process theories of cognition, and how do they differ?

- **Concept**: Fine-tuning vs. in-context learning
  - **Why needed here**: HAR is applied to both fine-tuning and in-context learning, so understanding differences and use cases for each approach is important.
  - **Quick check question**: What is the main difference between fine-tuning and in-context learning, and when might each be more appropriate?

- **Concept**: Commonsense reasoning and coherence
  - **Why needed here**: Paper focuses on coherent physical commonsense reasoning, so understanding what commonsense reasoning is and why coherence is important is crucial.
  - **Quick check question**: What is commonsense reasoning, and why is coherence important for evaluating quality of reasoning in AI systems?

## Architecture Onboarding

- **Component map**: High-level decision-making (story selection, sentence identification) â†’ Low-level rationalization (physical state prediction)
- **Critical path**: The sequence from high-level decision-making to low-level rationalization; ensuring each step is accurate and coherent is essential for overall success
- **Design tradeoffs**: Complexity of reasoning structure vs. potential for cascading errors if higher-level decision is incorrect; benefits of conditioning lower-level tasks vs. limitations in certain scenarios
- **Failure signatures**: Incorrect higher-level decisions leading to cascading errors in lower-level tasks; conditioning mechanism not working as intended, preventing lower-level tasks from benefiting from higher-level decisions
- **First 3 experiments**:
  1. Apply HAR to simple reasoning task with clear high-level decision and low-level rationalization (e.g., story plausibility judgment followed by conflicting sentence identification)
  2. Compare coherence of reasoning chains generated with HAR to those without HAR using metrics like consistency and verifiability
  3. Analyze attention patterns of model using HAR to understand how approach affects focus on relevant context

## Open Questions the Paper Calls Out

The paper identifies several open questions regarding the generalizability and evaluation of HAR:

1. How do dual-process theories of cognition specifically improve coherence of physical commonsense reasoning in PLMs beyond what can be achieved through traditional chain-of-thought prompting or other existing methods?
2. Can the heuristic-analytic reasoning strategies proposed in this paper be generalized to other domains of reasoning beyond physical commonsense, such as social reasoning or mathematical reasoning?
3. What are the limitations of using attention weights as a proxy for measuring faithfulness and coherence of PLM reasoning, and are there more reliable methods to evaluate quality of reasoning chains?

## Limitations

- Reliance on iterative context deletion heuristics during fine-tuning may not generalize well to domains with dense or highly interdependent information
- Paper doesn't extensively test HAR's robustness when heuristic decisions are incorrect, leaving open possibility of cascading reasoning failures
- Causal link between attention patterns and coherence could be more rigorously established through ablation studies that manipulate attention directly

## Confidence

- **High confidence**: Core HAR methodology and application to TRIP/Tiered-ProPara benchmarks are well-documented and reproducible
- **Medium confidence**: Attribution of coherence improvements specifically to attention faithfulness, while supported by analysis, could benefit from more direct experimental validation
- **Medium confidence**: Dual-process cognitive theory inspiration provides compelling framework, but translation to computational strategies lacks exhaustive empirical validation across diverse reasoning scenarios

## Next Checks

1. Conduct ablation studies where heuristic decisions are intentionally corrupted to measure impact on lower-level reasoning quality and identify failure thresholds
2. Perform cross-domain evaluation of HAR on datasets with varying information density to test robustness of iterative context deletion
3. Implement attention intervention experiments that directly manipulate attention weights to establish causal relationships between attention patterns and reasoning coherence