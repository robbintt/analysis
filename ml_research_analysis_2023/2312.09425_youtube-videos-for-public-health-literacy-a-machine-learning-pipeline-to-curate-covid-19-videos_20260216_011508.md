---
ver: rpa2
title: YouTube Videos for Public Health Literacy? A Machine Learning Pipeline to Curate
  Covid-19 Videos
arxiv_id: '2312.09425'
source_url: https://arxiv.org/abs/2312.09425
tags:
- covid-19
- videos
- video
- information
- health
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a machine learning pipeline to automatically
  identify, retrieve, and curate YouTube videos on COVID-19 that are medically relevant
  and understandable for public health education. The approach uses a combination
  of human expert annotations and automated feature extraction from video metadata,
  transcriptions, and medical terminology recognition.
---

# YouTube Videos for Public Health Literacy? A Machine Learning Pipeline to Curate Covid-19 Videos

## Quick Facts
- arXiv ID: 2312.09425
- Source URL: https://arxiv.org/abs/2312.09425
- Reference count: 0
- Primary result: ML pipeline achieves 83.61% accuracy in curating medically relevant and understandable COVID-19 YouTube videos

## Executive Summary
This paper presents an automated machine learning pipeline to identify, retrieve, and curate YouTube videos on COVID-19 that are medically relevant and understandable for public health education. The approach combines human expert annotations with automated feature extraction from video metadata, transcriptions, and medical terminology recognition. Using logistic regression as the classifier, the system achieves 83.61% accuracy in correctly identifying videos with high medical information content and understandability. The pipeline addresses the challenge of information overload during public health crises by providing a scalable method for curating high-quality video content for dissemination.

## Method Summary
The methodology involves collecting 304 YouTube videos using 40 COVID-19 related search keywords, then annotating each video for medical information content, understandability, and recommendation status. Features are extracted from metadata (likes, dislikes, comments, channel information), video transcriptions, readability scores, number of video shots, and cosine similarity between search keywords and video metadata/transcriptions. Understandability scores are calculated using the PEMAT-A/V framework, while medical information is extracted using UMLS-based medical entity recognition with a BLSTM-RNN model. Correlation-based feature selection is applied to reduce redundancy, followed by training multiple classifiers (logistic regression, SVM, random forest, XGBoost) on an 80-20 train-test split.

## Key Results
- Logistic regression achieves 83.61% accuracy in classifying recommended vs. non-recommended videos
- Top predictive features include understandability scores, medical information content, readability scores, number of video shots, and cosine similarity metrics
- The pipeline successfully identifies videos that are both medically relevant and understandable for public health education
- System demonstrates potential for scalability to other public health topics beyond COVID-19

## Why This Works (Mechanism)
The pipeline works by combining multiple complementary feature types that capture different aspects of video quality for public health communication. Medical information extraction ensures content accuracy and relevance, while understandability scoring using PEMAT-A/V guarantees that content is accessible to the general public. The integration of metadata features provides context about video popularity and engagement, while cosine similarity measures ensure topical relevance to search queries. By using correlation-based feature selection, the model reduces redundancy while retaining the most informative features for classification.

## Foundational Learning
- **PEMAT-A/V understandability scoring**: Standardized framework for evaluating patient education materials; needed to ensure videos are accessible to general audiences; quick check: verify understandability scores align with manual PEMAT guidelines
- **UMLS medical entity recognition**: Unified Medical Language System for identifying medical terms; needed to assess medical information quality; quick check: measure precision/recall of extracted medical terms against ground truth
- **Cosine similarity for content matching**: Vector-based similarity measure; needed to ensure videos match search intent; quick check: validate similarity scores correlate with expert relevance judgments
- **BLSTM-RNN for medical text processing**: Bidirectional LSTM with recurrent layers; needed for sequence modeling in medical term extraction; quick check: evaluate model performance on medical named entity recognition benchmarks
- **Correlation-based feature selection**: Removes redundant features while preserving predictive power; needed to improve model efficiency and reduce overfitting; quick check: analyze feature correlation matrix before and after selection
- **YouTube Data API integration**: Programmatic access to video metadata; needed for automated data collection; quick check: verify all required metadata fields are successfully retrieved

## Architecture Onboarding
- **Component map**: YouTube API -> Data Collection -> Feature Extraction -> Annotation -> Feature Selection -> Classification -> Curation
- **Critical path**: Search keyword generation → Video collection → Feature extraction (medical + metadata) → Annotation (PEMAT + medical info) → Classification → Curation decision
- **Design tradeoffs**: Balanced between automation and accuracy; chose logistic regression over more complex models for interpretability and performance; used correlation-based selection to reduce computational complexity
- **Failure signatures**: Poor classification when medical entity recognition fails; understandability scores inconsistent with manual assessment; feature selection removes critical predictive features
- **First experiments**: (1) Test medical entity recognition precision on sample videos, (2) Validate PEMAT-A/V implementation against manual scoring, (3) Evaluate feature importance ranking before feature selection

## Open Questions the Paper Calls Out
- How can deep learning models improve the accuracy of video classification beyond traditional machine learning approaches like logistic regression?
- How does the timeliness and accuracy of video content affect its effectiveness in public health education, and how can these factors be incorporated into the curation pipeline?
- How do different types of video content (e.g., narrative, educational, news updates) affect viewer engagement and understanding, and how can the curation pipeline be adapted to account for these differences?

## Limitations
- Limited dataset size (304 videos) may not capture full diversity of COVID-19 content
- Missing implementation details for critical components (BLSTM-RNN architecture, PEMAT scoring specifics)
- Generalizability to other public health topics not empirically validated
- Potential bias in search keyword selection affecting video diversity

## Confidence
- **Methodology**: Medium - core approach is sound but implementation details are incomplete
- **Results**: Medium - performance metrics are reasonable but validation is limited to one domain
- **Reproducibility**: Medium - requires access to YouTube APIs and medical entity recognition models
- **Generalizability**: Low - claims about scalability to other topics not tested

## Next Checks
1. Reproduce medical entity recognition performance on a held-out validation set to verify COVID-19 medical term extraction accuracy
2. Conduct sensitivity analysis on the correlation threshold parameter to determine its impact on classification performance
3. Test the pipeline on a different public health topic (e.g., influenza or vaccination information) to empirically verify claimed generalizability to other domains