---
ver: rpa2
title: Investigating Chain-of-thought with ChatGPT for Stance Detection on Social
  Media
arxiv_id: '2304.03087'
source_url: https://arxiv.org/abs/2304.03087
tags:
- stance
- detection
- chatgpt
- methods
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the application of chain-of-thought (CoT)
  prompting with ChatGPT (GPT-3.5) for stance detection on social media. Stance detection
  aims to predict the attitude (favor, against, or neutral) of opinionated texts towards
  specific targets.
---

# Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media

## Quick Facts
- arXiv ID: 2304.03087
- Source URL: https://arxiv.org/abs/2304.03087
- Reference count: 12
- This paper demonstrates superior accuracy of chain-of-thought prompting with ChatGPT for stance detection compared to state-of-the-art methods, while identifying limitations including stance biases and the need for automatic question-answer pair selection.

## Executive Summary
This paper investigates the application of chain-of-thought (CoT) prompting with ChatGPT (GPT-3.5) for stance detection on social media. Stance detection aims to predict the attitude (favor, against, or neutral) of opinionated texts towards specific targets. The study evaluates two distinct CoT methodologies - direct question-answering (DQA) and step-by-step question-answering (StSQA) - demonstrating superior accuracy compared to state-of-the-art methods. The parameter-free approach eliminates deployment challenges associated with fine-tuning large language models, though the study identifies limitations including stance biases and the need for automatic selection of question-answer pairs.

## Method Summary
The paper evaluates chain-of-thought prompting with ChatGPT for stance detection using three datasets: SemEval-2016 (4870 tweets for 6 targets), VAST (4003 training samples), and P-Stance (21,574 political tweets). Two CoT approaches are compared: DQA which directly queries ChatGPT for stance polarity, and StSQA which uses step-by-step reasoning with a 1-shot example. Performance is assessed using Favg and macro-F1 score Fm metrics, comparing results against traditional machine learning, deep neural networks, and pre-trained fine-tuning models.

## Key Results
- Chain-of-thought prompting with ChatGPT achieves superior accuracy compared to state-of-the-art stance detection methods
- Step-by-step question-answering (StSQA) outperforms direct question-answering (DQA) in most cases
- The study identifies stance biases in ChatGPT's predictions and the importance of question-answer pair selection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Chain-of-thought prompting enables ChatGPT to perform stance detection without requiring fine-tuning
- Mechanism: CoT leverages template-based reasoning to guide the model's inference process, reducing the need for task-specific training data
- Core assumption: ChatGPT's pre-trained knowledge is sufficient for stance detection when properly scaffolded by CoT templates
- Evidence anchors:
  - [abstract]: "The parameter-free Chain-of-Thought (CoT) approach, not requiring backpropagation training, has emerged as a promising alternative."
  - [section]: "Utilizing a straightforward prompt that directly queries the VLPLMs, without requiring any training, ChatGPT yields exceptional results."
  - [corpus]: Weak - only 25 related papers found with average neighbor FMR=0.446, suggesting limited direct evidence of CoT efficacy in stance detection

### Mechanism 2
- Claim: Step-by-step question-answering (StSQA) improves stance detection accuracy by providing explicit reasoning steps
- Mechanism: StSQA decomposes the stance detection task into interpretable sub-steps, allowing ChatGPT to construct a logical chain of reasoning before making predictions
- Core assumption: Explicit reasoning steps reduce ambiguity and improve consistency in stance detection
- Evidence anchors:
  - [section]: "StSQA prompting method teaches language models to solve the stance detection by providing a 1-shot example. This process comprises two stages: 1) Thought-inducing... 2) The second stage encompasses inferencing the tweet's stance using the provided QAP."
  - [abstract]: "We examine CoT's effectiveness in stance detection tasks, demonstrating its superior accuracy..."
  - [corpus]: Weak - limited direct evidence of SOTA performance for stance detection using StSQA in the corpus

### Mechanism 3
- Claim: Automatic selection of question-answer pairs (QAPs) is critical for optimal CoT performance
- Mechanism: The quality and specificity of QAPs directly influence ChatGPT's ability to generalize reasoning patterns to unseen stance detection tasks
- Core assumption: Appropriate QAPs balance specificity and generality to avoid both overfitting and under-specification
- Evidence anchors:
  - [section]: "We found that selecting appropriate QAPs as examples has a significant impact on the results... This finding aligns with earlier research observations, as the viewpoints supporting stance predictions in stance detection tasks often do not explicitly appear within the sentence."
  - [abstract]: "The study also identifies potential limitations, including... the need for automatic selection of question-answer pairs..."
  - [corpus]: Weak - no direct evidence of QAP selection methods in the corpus

## Foundational Learning

- Concept: Stance detection as a classification task
  - Why needed here: Understanding the three-class nature (favor, against, neutral) is essential for designing appropriate CoT templates
  - Quick check question: What are the three possible stance labels in social media stance detection?

- Concept: Chain-of-thought prompting methodology
  - Why needed here: CoT is the core technique enabling zero-shot stance detection with ChatGPT
  - Quick check question: How does CoT differ from standard prompting in terms of task decomposition?

- Concept: Zero-shot learning in NLP
  - Why needed here: The paper evaluates CoT performance without task-specific training data
  - Quick check question: What distinguishes zero-shot learning from few-shot learning in the context of stance detection?

## Architecture Onboarding

- Component map: Task definition -> CoT template design (DQA vs StSQA) -> QAP selection -> ChatGPT inference -> stance label prediction -> evaluation
- Critical path: Prompt construction → QAP generation → ChatGPT inference → stance label prediction → evaluation
- Design tradeoffs: Direct questioning (DQA) offers simplicity but may lack reasoning depth, while step-by-step prompting (StSQA) provides better accuracy at the cost of template complexity
- Failure signatures: (1) Stance biases manifesting as systematic misclassifications for specific targets, (2) Over-reliance on specific QAPs leading to performance degradation, (3) Inability to handle fine-grained stance distinctions
- First 3 experiments:
  1. Compare DQA vs StSQA performance on a small subset of the SemEval-2016 dataset
  2. Test the effect of varying numbers of QAPs on StSQA accuracy
  3. Evaluate stance detection performance across different target categories to identify potential biases

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can stance biases in ChatGPT be identified and mitigated for stance detection tasks?
- Basis in paper: [explicit] The paper discusses potential stance biases of ChatGPT towards specific targets, leading to inferior performance on certain datasets
- Why unresolved: The paper identifies the problem of stance biases but does not provide solutions for identifying or mitigating these biases in large language models like ChatGPT
- What evidence would resolve it: Research demonstrating methods to detect stance biases in large language models and strategies to reduce these biases through prompt engineering or fine-tuning

### Open Question 2
- Question: What is the optimal number and type of question-answer pairs (QAPs) for effective chain-of-thought prompting in stance detection?
- Basis in paper: [explicit] The paper shows that multiple QAPs can confuse ChatGPT's reasoning, and overly specific QAPs may cause the model to focus on words rather than semantics
- Why unresolved: The paper presents preliminary experiments on QAP sensitivity but does not establish definitive guidelines for selecting optimal QAPs
- What evidence would resolve it: Systematic experiments comparing different numbers and types of QAPs across multiple stance detection datasets, identifying best practices for prompt construction

### Open Question 3
- Question: How can fine-grained stance detection tasks be defined and implemented for complex targets with multiple aspects?
- Basis in paper: [explicit] The paper identifies challenges in categorizing user comments into single attitude polarities for complex targets that can be viewed from different perspectives (e.g., Trump as actor, politician, or businessman)
- Why unresolved: The paper highlights the problem but does not propose methods for handling multi-aspect targets in stance detection
- What evidence would resolve it: Development of annotation schemes and models that can capture stance from multiple perspectives for the same target, along with evaluation metrics for multi-faceted stance detection

## Limitations
- Evidence base for CoT effectiveness in stance detection remains relatively weak with limited related research
- Specific prompt templates and QAP selection mechanisms are not fully specified, creating reproduction challenges
- Study focuses on English social media data, potentially limiting generalizability to other languages or domains

## Confidence

**High Confidence:** The comparative performance advantage of CoT over traditional fine-tuning approaches is well-supported by experimental results across multiple datasets. The identification of stance biases as a critical limitation is strongly supported by empirical findings.

**Medium Confidence:** The assertion that parameter-free CoT eliminates deployment challenges associated with VLPLMs is plausible but depends on API access costs and availability. The effectiveness of StSQA versus DQA is demonstrated but may vary with different prompt engineering approaches.

**Low Confidence:** Claims about CoT's superiority over all existing stance detection methods are not fully substantiated, as the study does not benchmark against all state-of-the-art approaches comprehensively. The assertion that automatic QAP selection is critical lacks direct empirical validation in the paper.

## Next Checks

1. **Prompt Template Replication Test:** Implement the exact CoT prompting strategies (DQA and StSQA) on the SemEval-2016 dataset and verify whether the reported Favg and macro-F1 scores can be reproduced within a 5% margin.

2. **Bias Analysis Experiment:** Conduct a systematic analysis of stance detection errors across different target categories to quantify and characterize the specific biases identified in the study.

3. **QAP Selection Impact Study:** Design an experiment varying the quality and specificity of question-answer pairs to measure their direct impact on CoT performance, testing the hypothesis that QAP selection significantly affects results.