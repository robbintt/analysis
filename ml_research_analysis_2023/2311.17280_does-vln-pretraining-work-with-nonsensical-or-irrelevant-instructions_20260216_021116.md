---
ver: rpa2
title: Does VLN Pretraining Work with Nonsensical or Irrelevant Instructions?
arxiv_id: '2311.17280'
source_url: https://arxiv.org/abs/2311.17280
tags:
- pretraining
- data
- instructions
- training
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the importance of data quality and quantity
  for Vision-and-Language Navigation (VLN) pretraining. The authors find that nonsensical
  or irrelevant language instructions during pretraining have little negative impact
  on downstream performance for both HAMT and VLN-BERT models on the Room-2-Room (R2R)
  benchmark.
---

# Does VLN Pretraining Work with Nonsensical or Irrelevant Instructions?

## Quick Facts
- arXiv ID: 2311.17280
- Source URL: https://arxiv.org/abs/2311.17280
- Reference count: 17
- Key outcome: Nonsensical or irrelevant language instructions during VLN pretraining have little negative impact on downstream performance for both HAMT and VLN-BERT models on R2R.

## Executive Summary
This paper investigates whether data quality matters for Vision-and-Language Navigation (VLN) pretraining by testing various forms of noisy or irrelevant language instructions. Surprisingly, the authors find that shuffling word order, shuffling sentences, or using mismatched instructions during pretraining has minimal impact on downstream performance for both HAMT and VLN-BERT models on the Room-2-Room (R2R) benchmark. The results suggest that visual trajectory quantity matters more than instruction quality, leading to the proposal of an efficient augmentation method called Unigram + Object that generates nonsensical instructions but nonetheless improves performance. The findings challenge conventional wisdom about data quality in multimodal pretraining.

## Method Summary
The authors pretrain HAMT and VLN-BERT models using Room-2-Room (R2R) training data with various forms of language noise: shuffled words, shuffled sentences, and mismatched instructions. They evaluate these pretrained models on clean R2R training data and test on the validation unseen set. They also develop a Unigram + Object (UO) method that generates synthetic instructions by concatenating detected object names along trajectories with random VLN-related words. The models are evaluated using Success Rate (SR), Success Weighted by Path Length (SPL), and Normalized Dynamic Time Warping (nDTW) metrics.

## Key Results
- Pretraining with shuffled words or sentences has minimal impact on downstream Success Rate for both HAMT and VLN-BERT models
- The Unigram + Object method generates nonsensical instructions that improve downstream performance by 1-2% over speaker model augmentation
- Using only 50% of trajectories with language annotations achieves performance close to using 100%, and using 1% still outperforms no pretraining

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Nonsensical or irrelevant language instructions during pretraining have little negative impact on downstream performance for both HAMT and VLN-BERT on R2R.
- Mechanism: The visual trajectory quantity matters more than instruction quality because VLN models primarily rely on visual features and object grounding, not precise language structure, to navigate.
- Core assumption: VLN models focus on object words and visual co-occurrence rather than word order or sentence meaning during navigation.
- Evidence anchors:
  - [abstract]: "nonsensical or irrelevant language instructions during pretraining can have little effect on downstream performance for both HAMT and VLN-BERT on R2R"
  - [section 4.1]: "Shuffling in pretraining does not affect SR. SF-WORD and SF-SENT have almost has no negative impact on the SR (Table 1 column ORIGINAL) for either HAMT and VLN-BERT"
- Break condition: If VLN models start relying heavily on language structure or if navigation requires precise linguistic understanding rather than object grounding

### Mechanism 2
- Claim: Increasing quantity of visual trajectories in pretraining, with some corresponding noisy language annotation, is more helpful than increasing quality of existing VLN data.
- Mechanism: More visual trajectories provide better visual pretraining tasks (MRM, ITM) even with noisy instructions, improving overall model performance.
- Core assumption: Visual pretraining tasks benefit from larger trajectory sets regardless of instruction quality.
- Evidence anchors:
  - [abstract]: "what matters for VLN R2R pretraining is the quantity of visual trajectories, not the quality of instructions"
  - [section 5]: "AUG-ONLY has roughly the same SR as pretraining on both R2R&AUG data, and is 4% better than the R2R-ONLY"
- Break condition: If language instructions become critical for navigation success or if visual pretraining tasks plateau despite more data

### Mechanism 3
- Claim: Unigram + Object (UO) method generates nonsensical instructions that still improve downstream performance by providing object-word co-occurrence with random filler words.
- Mechanism: Object words provide visual grounding while random filler words don't harm performance because models focus on object semantics rather than language coherence.
- Core assumption: Object-word ordering and presence matters more than overall sentence meaning for VLN.
- Evidence anchors:
  - [abstract]: "we concoct an efficient augmentation method, Unigram + Object, which generates nonsensical instructions that nonetheless improve downstream performance"
  - [section 4.4]: "UO generates an 'instruction' for a trajectory by concatenating names of detected objects along the trajectory with random VLN-related words"
- Break condition: If object-word co-occurrence becomes insufficient for navigation or if random words introduce harmful patterns

## Foundational Learning

- Concept: Multimodal transformer pretraining tasks (MLM, MRM, ITM)
  - Why needed here: Understanding these pretraining tasks is crucial because the paper shows how different noising strategies affect each task differently, revealing what aspects of language quality matter for VLN
  - Quick check question: Why does shuffling word order primarily affect MLM accuracy while having minimal impact on MRM and ITM accuracy?

- Concept: Data cartography and training dynamics
  - Why needed here: The paper uses data cartography to visualize quality differences between human and synthetic data, showing that augmentation data is more ambiguous but still useful
  - Quick check question: How does the distribution of confidence and variability differ between human-annotated R2R data and synthetic augmentation data according to data cartography?

- Concept: Vision-language navigation task structure
  - Why needed here: Understanding the R2R benchmark structure (graph-based navigation, instruction-trajectory pairs) is essential to grasp why noising strategies work differently than in other tasks
  - Quick check question: What are the key differences between R2R and RxR datasets that might explain why word order shuffling has more impact on RxR performance?

## Architecture Onboarding

- Component map: HAMT: instruction → language encoder → cross-modal decoder → action prediction; VLN-BERT: candidate paths → path scoring → action selection
- Critical path: For HAMT: instruction → language encoder → cross-modal decoder → action prediction. For VLN-BERT: candidate paths → path scoring → action selection.
- Design tradeoffs: HAMT uses random initialization with extensive pretraining vs VLN-BERT's pretrained initialization with less pretraining. HAMT focuses on grounding tasks while VLN-BERT emphasizes path scoring.
- Failure signatures: Poor MLM accuracy suggests language encoder issues. Poor MRM accuracy indicates visual feature problems. Low ITM accuracy means instruction-trajectory alignment is failing.
- First 3 experiments:
  1. Test word shuffling (SF-WORD) on both pretraining and fine-tuning to establish baseline word order insensitivity
  2. Implement Unigram + Object generation and compare with speaker model augmentation
  3. Compare pretraining with only R2R data vs only augmentation data to test quantity vs quality tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the finding that word order doesn't matter in VLN pretraining generalize to more complex environments like continuous navigation or outdoor settings?
- Basis in paper: [inferred] The authors tested shuffling strategies on Room-2-Room (R2R) and Room-across-Room (RxR) datasets, both using simulated graph-based environments. They hypothesize that outdoor or continuous environments might have different sensitivities.
- Why unresolved: The paper only tested word-order insensitivity in graph-based, indoor environments. Continuous or outdoor environments may require more precise language grounding, making word order more important.
- What evidence would resolve it: Testing shuffled instructions in continuous navigation tasks (e.g., Touchdown) or outdoor VLN environments and measuring performance drops.

### Open Question 2
- Question: What is the minimum amount of high-quality language data required to achieve optimal VLN pretraining performance?
- Basis in paper: [explicit] The authors found that using only 50% of trajectories with language annotations achieves performance close to using 100%, and using 1% of language-annotated data still outperforms no pretraining. However, zero language annotations are harmful.
- Why unresolved: The paper doesn't pinpoint the exact threshold where language quality becomes critical. The relationship between language quantity and performance appears non-linear.
- What evidence would resolve it: Systematic experiments varying the percentage of language-annotated trajectories (e.g., 5%, 10%, 20%, 50%) and measuring performance saturation points.

### Open Question 3
- Question: Does the effectiveness of Unigram + Object (UO) generation depend on the quality of the underlying object detector?
- Basis in paper: [inferred] The authors used a "weakly supervised object detector" for UO generation and found it effective when combined with pretrained language encoders, but they didn't test different detector qualities.
- Why unresolved: The paper assumes a basic object detector suffices but doesn't explore how detector performance impacts downstream VLN results.
- What evidence would resolve it: Comparing UO performance using different object detectors (e.g., ground truth vs. weak vs. strong detectors) and measuring the impact on downstream success rates.

### Open Question 4
- Question: How does data quality vs. quantity trade-off change when pretraining on languages other than English?
- Basis in paper: [explicit] The authors tested shuffling strategies on RxR, which includes English, Hindi, and Telugu instructions, finding similar patterns but with larger performance drops for word shuffling.
- Why unresolved: While the authors observed similar trends across languages, they didn't systematically compare how language-specific factors (e.g., word order flexibility, morphological complexity) affect the quality-quantity trade-off.
- What evidence would resolve it: Controlled experiments varying data quality and quantity separately for each language in multilingual datasets and comparing the relative importance of each factor.

## Limitations
- Findings are specific to Room-2-Room and haven't been validated on other VLN benchmarks like Room-for-Room (RxR) or Touchdown
- Paper doesn't test whether this applies to VLN tasks requiring more complex language understanding, such as those involving object affordances or spatial reasoning beyond simple navigation
- While object-word grounding is shown to be crucial, the paper doesn't fully explore whether certain types of irrelevant instructions (e.g., semantically contradictory vs. simply shuffled) might have different impacts

## Confidence
- High confidence: The core finding that pretraining with noisy instructions still improves performance over no pretraining
- Medium confidence: The claim that visual trajectory quantity matters more than instruction quality
- Medium confidence: The Unigram + Object method's effectiveness

## Next Checks
1. Test whether the instruction quality insensitivity extends to other VLN benchmarks (RxR, Touchdown) and more complex navigation tasks requiring fine-grained spatial understanding
2. Investigate whether certain types of language noising (semantically contradictory instructions vs. simple shuffling) have differential impacts on downstream performance
3. Evaluate whether the Unigram + Object method maintains its effectiveness when scaled to larger trajectory sets or applied to different VLN architectures