---
ver: rpa2
title: 'FaMeSumm: Investigating and Improving Faithfulness of Medical Summarization'
arxiv_id: '2311.02271'
source_url: https://arxiv.org/abs/2311.02271
tags:
- medical
- famesumm
- faithfulness
- summarization
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of improving faithfulness in medical
  text summarization, where current models often produce unfaithful outputs containing
  errors such as incorrect entity relationships, entity generation, negation, and
  extraneous facts. The authors propose FaMeSumm, a framework that fine-tunes pre-trained
  language models using contrastive learning and medical knowledge incorporation.
---

# FaMeSumm: Investigating and Improving Faithfulness of Medical Summarization

## Quick Facts
- **arXiv ID**: 2311.02271
- **Source URL**: https://arxiv.org/abs/2311.02271
- **Reference count**: 29
- **Primary result**: FaMeSumm improves faithfulness in medical summarization by 16% compared to GPT-3 through contrastive learning and medical knowledge incorporation

## Executive Summary
This paper addresses the critical problem of improving faithfulness in medical text summarization, where current models often generate unfaithful outputs containing errors such as incorrect entity relationships, entity generation, negation, and extraneous facts. The authors propose FaMeSumm, a framework that fine-tunes pre-trained language models using contrastive learning and medical knowledge incorporation to improve faithfulness while maintaining general summary quality. Experiments on three datasets in two languages (English and Chinese) demonstrate that FaMeSumm consistently improves faithfulness metrics and general quality metrics over baseline models like BART, T5, mT5, and PEGASUS, with human evaluation by doctors confirming the faithfulness improvements.

## Method Summary
FaMeSumm fine-tunes pre-trained language models using two complementary strategies: contrastive learning and medical knowledge incorporation. The framework constructs positive and negative sets of summaries based on medical entities and concepts, where positive sets contain faithful summaries and negative sets contain unfaithful summaries created by manipulating source text. A contrastive loss encourages the model to distinguish between these sets. Additionally, the framework identifies medical terms in reference summaries and their surrounding context tokens, incorporating a loss term that maximizes the likelihood of generating these terms and contexts. These two fine-tuning strategies are combined with cross-entropy loss for standard summarization training, addressing different aspects of faithfulness to create a comprehensive improvement framework.

## Key Results
- FaMeSumm achieves 16% higher faithfulness compared to GPT-3 in human evaluation by doctors
- Consistent improvements across faithfulness metrics (QuestEval, FaR, SummaC, Concept F1) and general quality metrics (ROUGE-1/2/L, BERTScore) on three datasets in two languages
- Ablation study shows both contrastive learning and medical knowledge incorporation components contribute to performance improvements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive learning on curated faithful and unfaithful summaries improves faithfulness by teaching the model to distinguish between consistent and inconsistent outputs.
- Mechanism: The framework constructs positive and negative sets of summaries based on medical entities. Positive sets contain faithful summaries (validated references or extracted sentences), while negative sets contain unfaithful summaries created by manipulating source text. The contrastive loss encourages the model to maximize the discrepancy between these sets.
- Core assumption: Faithful summaries can be reliably distinguished from unfaithful ones using heuristics based on medical entity presence and manipulation.
- Evidence anchors:
  - [abstract] "FaMeSumm performs contrastive learning on designed sets of faithful and unfaithful summaries"
  - [section 3.1] "We use two steps to build the positive set... A positive set (P) contains faithful summaries of the source text while a negative set (N) contains unfaithful and suspected unfaithful summaries"
  - [corpus] Weak evidence - no direct corpus validation of contrastive learning effectiveness in medical summarization

### Mechanism 2
- Claim: Incorporating medical knowledge through explicit modeling of medical terms and their contexts improves faithfulness by encouraging accurate generation of medical terminology.
- Mechanism: The framework identifies medical terms in reference summaries and their surrounding context tokens. A loss term maximizes the likelihood of generating these terms and contexts, effectively teaching the model medical terminology patterns.
- Core assumption: Medical terms and their contexts are reliable indicators of faithfulness in medical summaries.
- Evidence anchors:
  - [abstract] "it incorporates medical terms and their contexts to encourage faithful generation of medical terms"
  - [section 3.2] "We first identify all medical terms in reference summaries... we maintain a vector bm with the same length as the vocabulary size to record the frequency of the context tokens and medical terms"
  - [corpus] Weak evidence - no direct corpus validation of medical knowledge incorporation effectiveness

### Mechanism 3
- Claim: Combining contrastive learning and medical knowledge incorporation creates complementary effects that improve faithfulness more effectively than either approach alone.
- Mechanism: The two fine-tuning strategies address different aspects of faithfulness - contrastive learning distinguishes faithful from unfaithful outputs, while medical knowledge incorporation ensures accurate medical terminology. Together, they provide comprehensive faithfulness improvement.
- Core assumption: Contrastive learning and medical knowledge incorporation target orthogonal aspects of faithfulness that can be combined for greater effect.
- Evidence anchors:
  - [abstract] "These two strategies complement each other during the fine-tuning stage"
  - [section 5.1] "Echoing the analysis in Section 5.1, FAMESUMM without faithfulness validation has suboptimal performance"
  - [corpus] Moderate evidence - ablation study shows both components contribute to performance

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: To teach the model to distinguish between faithful and unfaithful summaries by maximizing the discrepancy between contrastive sets
  - Quick check question: How does contrastive learning differ from traditional supervised learning in the context of faithfulness improvement?

- Concept: Medical entity recognition and context modeling
  - Why needed here: To identify medical terms and their surrounding context as reliable indicators of faithfulness in medical summaries
  - Quick check question: Why is it important to model not just medical terms but also their surrounding context tokens?

- Concept: Faithfulness validation
  - Why needed here: To ensure that reference summaries used as positive examples are actually faithful to the source text
  - Quick check question: What are the risks of using unfaithful reference summaries as positive examples in contrastive learning?

## Architecture Onboarding

- Component map: Contrastive learning module -> Medical knowledge incorporation module -> Cross-entropy loss module
- Critical path: Identify medical terms in source and reference texts → Construct contrastive sets using heuristics → Compute contrastive and medical knowledge losses → Combine with cross-entropy loss for fine-tuning
- Design tradeoffs: The framework trades computational complexity for improved faithfulness. Constructing contrastive sets and modeling medical knowledge requires additional computation compared to standard fine-tuning, but provides significant faithfulness improvements.
- Failure signatures: Poor performance on faithfulness metrics despite good general quality metrics suggests issues with contrastive set construction or medical knowledge incorporation. Conversely, poor general quality with good faithfulness suggests over-optimization for faithfulness at the expense of fluency.
- First 3 experiments:
  1. Implement contrastive learning only on a simple dataset to verify the basic mechanism works
  2. Add medical knowledge incorporation to the contrastive learning framework
  3. Compare performance against baselines on a held-out test set using both faithfulness and general quality metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different strategies for constructing contrastive sets (e.g., using more diverse perturbations or incorporating additional medical domain knowledge) impact the effectiveness of FAMESUMM in improving faithfulness?
- Basis in paper: [explicit] The paper discusses the design of positive and negative sets for contrastive learning and mentions that the authors customize the construction for each dataset.
- Why unresolved: The paper does not provide a comprehensive comparison of different strategies for constructing contrastive sets or explore the impact of incorporating additional medical domain knowledge beyond the current approach.
- What evidence would resolve it: Experiments comparing FAMESUMM with variations in contrastive set construction strategies and incorporating additional medical domain knowledge would provide insights into the effectiveness of different approaches.

### Open Question 2
- Question: What is the impact of different fine-tuning objectives (e.g., incorporating entity-level information or using different weighting schemes for the loss functions) on the faithfulness improvement achieved by FAMESUMM?
- Basis in paper: [explicit] The paper discusses two fine-tuning objectives: contrastive learning and medical knowledge incorporation. However, it does not explore alternative fine-tuning objectives or different weighting schemes for the loss functions.
- Why unresolved: The paper focuses on the effectiveness of the proposed fine-tuning objectives but does not investigate alternative approaches or explore the impact of different weighting schemes.
- What evidence would resolve it: Experiments comparing FAMESUMM with variations in fine-tuning objectives and different weighting schemes for the loss functions would provide insights into the impact of these factors on faithfulness improvement.

### Open Question 3
- Question: How does FAMESUMM perform on medical summarization tasks with different characteristics (e.g., longer or more complex source texts, different languages, or different medical specialties)?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of FAMESUMM on three datasets in two languages (English and Chinese) but does not explore its performance on medical summarization tasks with different characteristics.
- Why unresolved: The paper focuses on a specific set of datasets and languages, and it is unclear how FAMESUMM would perform on medical summarization tasks with different characteristics.
- What evidence would resolve it: Experiments evaluating FAMESUMM on medical summarization tasks with different characteristics, such as longer or more complex source texts, different languages, or different medical specialties, would provide insights into its generalizability and performance across diverse scenarios.

## Limitations

- The faithfulness validation process relies on heuristics that may not capture all forms of unfaithfulness, and the details of human evaluation by doctors are sparse
- The assumption that medical terms and contexts are reliable indicators of faithfulness lacks direct empirical validation across different medical domains
- The framework requires additional computational resources for constructing contrastive sets and modeling medical knowledge compared to standard fine-tuning approaches

## Confidence

**High Confidence**: The experimental results showing consistent improvements across multiple faithfulness metrics (QuestEval, FaR, SummaC, Concept F1) and general quality metrics (ROUGE, BERTScore) on three diverse datasets in two languages. The human evaluation showing a 16% increase in faithfulness compared to GPT-3 provides strong external validation.

**Medium Confidence**: The mechanism by which contrastive learning improves faithfulness through distinguishing faithful from unfaithful summaries. While the experimental results support this claim, the effectiveness depends on the reliability of the heuristics used to construct contrastive sets, which is not fully validated.

**Low Confidence**: The assumption that medical terms and contexts are reliable indicators of faithfulness, and that modeling these elements will consistently improve faithfulness across all medical domains. This core assumption lacks direct empirical validation in the paper.

## Next Checks

1. **Faithfulness Validation Protocol**: Conduct a detailed reliability analysis of the faithfulness validation process by having multiple doctors independently evaluate the same set of summaries, measuring inter-annotator agreement, and testing the consistency of the contrastive set construction heuristics across different medical domains.

2. **Context Modeling Effectiveness**: Design controlled experiments to test whether the context modeling around medical terms actually captures information that prevents unfaithful generation. This could involve systematically removing context information and measuring the impact on faithfulness, or comparing against simpler medical term modeling approaches.

3. **Generalization Across Medical Domains**: Test FaMeSumm on additional medical summarization datasets from different specialties (e.g., oncology, cardiology, neurology) to validate that the approach generalizes beyond the three datasets used in the paper, and to identify any domain-specific limitations of the medical knowledge incorporation mechanism.