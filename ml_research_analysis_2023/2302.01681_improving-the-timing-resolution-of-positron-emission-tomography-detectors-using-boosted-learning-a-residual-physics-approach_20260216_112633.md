---
ver: rpa2
title: Improving the Timing Resolution of Positron Emission Tomography Detectors Using
  Boosted Learning -- A Residual Physics Approach
arxiv_id: '2302.01681'
source_url: https://arxiv.org/abs/2302.01681
tags:
- learning
- detector
- data
- time
- detectors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a novel approach to detector optimization in
  positron emission tomography (PET) using machine learning and residual physics.
  The method aims to improve coincidence time resolution (CTR) by combining traditional
  analytical calibration with gradient tree boosting (GTB) and physics-informed data
  generation.
---

# Improving the Timing Resolution of Positron Emission Tomography Detectors Using Boosted Learning -- A Residual Physics Approach

## Quick Facts
- arXiv ID: 2302.01681
- Source URL: https://arxiv.org/abs/2302.01681
- Reference count: 40
- Key outcome: Achieves sub-200 ps CTR resolution for 19mm PET detectors using gradient tree boosting on residual timing skews

## Executive Summary
This work presents a novel approach to improving coincidence time resolution (CTR) in positron emission tomography (PET) detectors by combining analytical calibration with gradient tree boosting (GTB) to learn higher-order time skew effects. The method uses physics-informed data generation by moving a radiation source to known positions to create accurate labels for supervised learning. Tested on clinically relevant detectors, the approach achieves significant CTR improvements, reaching sub-200 ps resolution for standard energy windows and 185 ps for narrower energy windows. The SHAP analysis confirms the model learns known physical effects, demonstrating the potential of this residual physics approach for future PET calibration techniques.

## Method Summary
The method combines analytical calibration using convex optimization with gradient tree boosting to correct residual timing skews not captured by analytical methods. Data is generated by moving a ²²Na radiation source to 47 different z-positions and measuring coincidences between two detectors. The expected time difference based on source position serves as the label for supervised learning. XGBoost models are trained using features including timestamps, energy, and position information. The approach is validated on two detector types: a one-to-one coupled scintillator design and a semi-monolithic scintillator design, both coupled to 4x4 digital SiPM arrays.

## Key Results
- Achieves sub-200 ps CTR resolution for standard 300-700 keV energy window
- Reaches 185 ps CTR for narrower 450-550 keV energy window
- SHAP analysis confirms model learns known physical effects including timewalk corrections
- Demonstrates significant improvement over analytical calibration alone

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The residual physics approach improves CTR by allowing the model to learn higher-order time skew effects that analytical calibration cannot fully capture.
- Mechanism: The analytical calibration captures the main, linear time skew effects through convex optimization. However, non-linear, higher-order effects remain. By applying gradient tree boosting (GTB) on the residuals between analytically corrected timestamps and physically expected time differences, the model learns these remaining effects.
- Core assumption: The residuals between analytically corrected timestamps and physically expected time differences contain learnable patterns related to higher-order time skew effects.
- Evidence anchors:
  - [abstract] "Traditional methods primarily depend on analytical formulations successfully describing the main detector characteristics. However, when accounting for higher-order effects, additional complexities arise matching theoretical models to experimental reality."
  - [section] "At a certain number of iterations, we see that the reported correction values oscillate around the baseline and that the CTR does not improve further, indicating that the linear formulation of the problem has limited capability of completely describing the physical situation."
  - [corpus] Weak evidence. The corpus does not explicitly discuss residual physics or analytical vs. learned calibration methods.

### Mechanism 2
- Claim: The physics-informed data generation method provides accurate labels for supervised learning by shifting a radiation source to known positions.
- Mechanism: By moving a radiation source to different known positions along the z-axis between two detectors, the expected time difference between the detection of the two photons can be calculated based on the different path lengths. This expected time difference is used as the label for the learning process.
- Core assumption: The source position can be accurately controlled and the expected time difference can be accurately calculated based on the known geometry.
- Evidence anchors:
  - [abstract] "We propose to use a data-driven approach on top of the conventionally used technique to explore new corrections that have not been covered by the analytical formulation and improve the CTR."
  - [section] "The different path lengths of the γ-photons lead to different travel times t1 and t2. One can conclude the expected time difference E[{t1−t2}], which is subsequently used as label y."
  - [corpus] Weak evidence. The corpus does not explicitly discuss physics-informed data generation methods.

### Mechanism 3
- Claim: The SHAP analysis confirms that the model learns known physical effects by identifying correlations between learned patterns and physical quantities.
- Mechanism: SHAP values quantify the contribution of each feature to the model's prediction. By analyzing the SHAP values, it can be determined which features are most important for the model's predictions and whether these features are related to known physical effects.
- Core assumption: The features used in the model are related to known physical effects, and the SHAP analysis can accurately quantify their importance.
- Evidence anchors:
  - [abstract] "The explainable AI framework SHapley Additive exPlanations (SHAP) was used to identify known physical effects with learned patterns, confirming the model's ability to learn timewalk effects."
  - [section] "The SHAP analysis offers a strong indication, that the proposed technique has the capability to build physics-informed models."
  - [corpus] Weak evidence. The corpus does not explicitly discuss SHAP analysis or its application to PET detector calibration.

## Foundational Learning

- Concept: Gradient Tree Boosting (GTB)
  - Why needed here: GTB is used to learn the higher-order time skew effects that analytical calibration cannot fully capture.
  - Quick check question: How does GTB handle missing data and why is this important for PET detector calibration?

- Concept: Convex Optimization
  - Why needed here: Convex optimization is used in the analytical calibration to find the corrections that minimize the difference between the measured and expected time differences.
  - Quick check question: What is the mathematical formulation of the convex optimization problem used in the analytical calibration?

- Concept: Shapley Values
  - Why needed here: Shapley values are used in the SHAP analysis to quantify the contribution of each feature to the model's prediction.
  - Quick check question: How are Shapley values calculated and what do they represent in the context of explainable AI?

## Architecture Onboarding

- Component map: Data acquisition -> Analytical calibration -> XGBoost model training -> SHAP analysis -> CTR evaluation
- Critical path: Data acquisition → Analytical calibration → GTB model training → SHAP analysis → CTR evaluation
- Design tradeoffs: The main design tradeoffs are between the complexity of the analytical calibration and the learning capacity of the GTB model, and between the accuracy of the labels and the computational cost of the physics-informed data generation.
- Failure signatures: If the CTR does not improve after applying the GTB model, it could indicate that the residuals are dominated by noise or that the features used in the model are not related to the time skew effects.
- First 3 experiments:
  1. Train a GTB model on synthetic data with known higher-order time skew effects to verify that the model can learn these effects.
  2. Apply the analytical calibration to real data and analyze the residuals to identify the types of higher-order effects that are present.
  3. Train a GTB model on real data and use SHAP analysis to confirm that the model is learning known physical effects.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of different learning rates on model performance, and how can this be optimized for specific applications?
- Basis in paper: [explicit] The paper discusses the effect of different learning rates (0.1, 0.3, 0.5) on the model's performance, with models using a lower learning rate (0.1) performing slightly better than those with higher learning rates.
- Why unresolved: The paper does not provide a detailed analysis of the impact of learning rates on model performance or a method for optimizing learning rates for specific applications.
- What evidence would resolve it: Further experiments testing a wider range of learning rates and their impact on model performance for different applications would help optimize learning rates for specific use cases.

### Open Question 2
- Question: How can the proposed method be scaled up to handle systems with multiple detectors?
- Basis in paper: [explicit] The paper mentions that the current implementation is limited to a pair of detectors and that research towards systems with multiple detectors will be addressed in future works.
- Why unresolved: The paper does not provide a detailed solution for scaling up the method to handle systems with multiple detectors.
- What evidence would resolve it: Developing and testing a scalable implementation of the proposed method for systems with multiple detectors would provide evidence for its effectiveness in larger-scale applications.

### Open Question 3
- Question: What is the impact of reducing data acquisition time on the model's performance and bias effects?
- Basis in paper: [explicit] The paper mentions that reducing data acquisition time and bias effects towards the edges of the training data is mandatory for possible usage in a clinical scanner.
- Why unresolved: The paper does not provide a detailed analysis of the impact of reducing data acquisition time on the model's performance and bias effects.
- What evidence would resolve it: Conducting experiments with reduced data acquisition time and analyzing the impact on model performance and bias effects would help determine the optimal balance between data acquisition time and model performance.

## Limitations
- Limited to pair of detectors, scalability to multi-detector systems not demonstrated
- Accuracy depends on precise source positioning for label generation
- Generalizability to different detector geometries and operating conditions requires further validation

## Confidence

- **High Confidence**: The methodology of combining analytical calibration with gradient tree boosting is sound and follows established practices in both PET detector calibration and machine learning.
- **Medium Confidence**: The reported CTR improvements and the SHAP analysis are promising but require further validation with more extensive testing and quantitative analysis.
- **Low Confidence**: The generalizability of the approach to different detector types and operating conditions is uncertain without additional testing and validation.

## Next Checks

1. **Generalizability Test**: Apply the proposed method to a different PET detector design with varying crystal geometries and SiPM coupling configurations to assess the robustness of the CTR improvements and the learned corrections.

2. **Quantify Label Accuracy**: Conduct a detailed uncertainty analysis of the source positioning and expected time difference calculations used as labels in the supervised learning process. This should include sensitivity studies on how positioning errors propagate to the learned corrections.

3. **Comprehensive SHAP Analysis**: Extend the SHAP analysis to include a quantitative comparison between the importance of learned features and known physical quantities, such as DOI and energy, across different source positions and detector configurations.