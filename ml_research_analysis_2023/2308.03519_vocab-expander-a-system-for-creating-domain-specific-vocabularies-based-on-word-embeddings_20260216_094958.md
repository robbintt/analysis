---
ver: rpa2
title: 'Vocab-Expander: A System for Creating Domain-Specific Vocabularies Based on
  Word Embeddings'
arxiv_id: '2308.03519'
source_url: https://arxiv.org/abs/2308.03519
tags:
- terms
- suggested
- word
- term
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces VOCAB-EXPANDER, an online tool that enables
  end-users to create and expand domain-specific vocabularies. The system uses an
  ensemble of state-of-the-art word embedding techniques, including models based on
  web text and ConceptNet, to suggest related terms for given terms.
---

# Vocab-Expander: A System for Creating Domain-Specific Vocabularies Based on Word Embeddings

## Quick Facts
- **arXiv ID**: 2308.03519
- **Source URL**: https://arxiv.org/abs/2308.03519
- **Reference count**: 12
- **Primary result**: Introduces an online tool that uses word embeddings to suggest related terms for building domain-specific vocabularies.

## Executive Summary
VOCAB-EXPANDER is an online tool that enables users to create and expand domain-specific vocabularies by leveraging an ensemble of pre-trained word embedding models. The system suggests related terms for user-provided seed terms, allowing quick confirmation or rejection through an intuitive interface. Created vocabularies can be exported as tables or visualized as graphs. The tool has potential applications in information retrieval, organizational communication, and educational course development. The source code is publicly available under the MIT License.

## Method Summary
The system uses an ensemble of pre-trained word embedding models (Word2Vec, GloVe, FastText, ConceptNet) to suggest related terms for given seed terms. For each accepted term, the system queries the top k most similar words from each embedding model and aggregates similarity scores. Users iteratively accept or reject suggestions, with rejected terms weighted negatively in the scoring function (λ = 0.5). The final vocabulary can be exported as a table or visualized as a graph showing semantic relationships between terms.

## Key Results
- Enables end-users to create domain-specific vocabularies through an intuitive interface
- Uses ensemble of state-of-the-art word embedding models for robust term suggestions
- Provides both tabular and graphical visualization of created vocabularies
- Source code available on GitHub under MIT License

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ensemble of multiple pre-trained word embedding models improves robustness of related term suggestions
- Mechanism: System queries top k similar words from each model and averages similarity scores across models
- Core assumption: Different embedding models capture complementary semantic relationships
- Evidence anchors: Abstract mentions ensemble of state-of-the-art word embedding techniques; section describes fetching top k similar words and averaging similarity scores across models

### Mechanism 2
- Claim: Rejection weighting prevents suggesting terms semantically related to rejected terms
- Mechanism: Score calculation sums similarity to accepted words minus 0.5 times similarity to rejected words
- Core assumption: Rejected terms are meaningful negative signals
- Evidence anchors: Section explicitly shows scoring formula with λ = 0.5 penalty for rejected terms

### Mechanism 3
- Claim: Graph visualization helps identify gaps and redundancies in term network
- Mechanism: System renders accepted terms as nodes and similarity scores as weighted edges
- Core assumption: Human intuition about semantic networks is enhanced by visual representation
- Evidence anchors: Abstract mentions vocabulary can be visualized as graph

## Foundational Learning

- **Word embeddings and semantic similarity**: Core functionality relies on measuring semantic similarity between terms using pre-trained embeddings. Quick check: What is the difference between cosine similarity and Euclidean distance in the context of word embeddings?

- **Ensemble methods and consensus scoring**: System aggregates similarity scores from multiple models to improve robustness. Quick check: Why might averaging similarity scores across models be better than selecting the highest score from a single model?

- **Graph theory and network visualization**: Graph view represents vocabulary as network of nodes and edges to help users understand term relationships. Quick check: In a term similarity graph, what would a high clustering coefficient indicate about vocabulary structure?

## Architecture Onboarding

- **Component map**: Frontend (HTML/CSS/JavaScript) → Backend (Python with gensim) → Pre-trained embedding models (Word2Vec, GloVe, FastText, ConceptNet) → Database (vocabulary state) → Graph visualization (D3.js or similar)

- **Critical path**: User adds term → system queries all embedding models → aggregates similarities → calculates scores with rejection penalty → ranks suggestions → displays in list and graph views → user accepts/rejects → update state

- **Design tradeoffs**: Pre-trained models enable zero-shot domain adaptation but limit vocabulary to training data; ensemble increases robustness but adds computational overhead; graph visualization aids exploration but may not scale well for large vocabularies

- **Failure signatures**: Empty suggestion list (model coverage gap), irrelevant suggestions (embedding model mismatch), slow response (large k or many models), confusing graph (too many edges or low similarity thresholds)

- **First 3 experiments**:
  1. Test with single seed term in known domain (e.g., "blockchain") and verify suggestions are relevant
  2. Add term, reject related term, and confirm rejected terms' semantic neighbors are deprioritized
  3. Import small vocabulary, visualize as graph, and manually verify edge weights reflect semantic similarity

## Open Questions the Paper Calls Out

- **Question 1**: How effective is VOCAB-EXPANDER at creating domain-specific vocabularies compared to other methods, and how can this be measured? The authors plan to evaluate performance through user studies but provide no empirical evidence yet. User studies comparing results with manual ontology creation or automated term extraction tools would provide evidence.

- **Question 2**: How does inclusion of domain-specific text corpora affect performance, and what is optimal integration method? Authors mention plans to integrate domain-specific corpora but provide no information on impact or optimal integration. Experimenting with different integration methods and measuring impact on vocabulary quality would provide insights.

- **Question 3**: How can user interface be improved to better support end-users? Paper describes current interface but doesn't discuss improvements or gather user feedback. Gathering user feedback through surveys and analyzing user interactions would provide improvement insights.

## Limitations

- Ensemble approach effectiveness depends on diversity and quality of pre-trained models, which are not fine-tuned for target domain
- Rejection weighting assumes rejected terms are semantically related to unwanted suggestions, which may not always hold
- System performance with multi-word terms not explicitly evaluated, as most pre-trained embeddings focus on single words

## Confidence

- **High confidence**: Core mechanism of using pre-trained word embeddings to suggest related terms is well-established
- **Medium confidence**: Ensemble approach and rejection weighting will improve suggestion quality, results depend on specific domains and terms used
- **Low confidence**: Graph visualization significantly aids vocabulary quality assessment without user studies

## Next Checks

1. Test system with domain-specific seed terms (e.g., medical or legal terminology) and evaluate whether suggestions remain relevant despite using general web text embeddings

2. Measure impact of rejection weighting by comparing vocabulary expansion with and without λ = 0.5 penalty on controlled dataset

3. Evaluate graph visualization's utility by having domain experts use it to identify vocabulary gaps and redundancies in sample domain