---
ver: rpa2
title: Clickbait Detection via Large Language Models
arxiv_id: '2306.09597'
source_url: https://arxiv.org/abs/2306.09597
tags:
- clickbait
- detection
- llms
- chatgpt
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates the performance of large language models (LLMs),
  specifically ChatGPT with GPT3.5, for clickbait detection. The authors conduct experiments
  on English and Chinese datasets using few-shot and zero-shot learning scenarios.
---

# Clickbait Detection via Large Language Models

## Quick Facts
- arXiv ID: 2306.09597
- Source URL: https://arxiv.org/abs/2306.09597
- Reference count: 9
- Primary result: LLMs do not achieve the best performance compared to state-of-the-art deep learning and fine-tuning PLM methods for clickbait detection

## Executive Summary
This paper evaluates the performance of large language models, specifically ChatGPT with GPT3.5, for clickbait detection tasks using few-shot and zero-shot learning scenarios. The authors conduct experiments on English and Chinese datasets and compare LLM performance against traditional deep learning and fine-tuning PLM methods. Results show that LLMs struggle with clickbait detection when only headlines are provided, achieving lower accuracy, precision, recall, and F1-scores compared to specialized methods. The study finds that using more training samples does not significantly improve ChatGPT's performance, suggesting limitations in few-shot learning for this task.

## Method Summary
The paper evaluates ChatGPT (GPT-3.5-turbo) for clickbait detection using hand-crafted prompts in few-shot and zero-shot learning scenarios. Two prompt patterns (P1 and P2) are tested across English and Chinese benchmark datasets including DLC, CND, SCC, Sina, Tencent, Wechat, and Paper. Few-shot experiments use K randomly selected instances (5, 10, 20) as training data, with results averaged over multiple random seeds. Performance is measured using accuracy, precision, recall, and F1-score, and compared against state-of-the-art deep learning and fine-tuning PLM methods.

## Key Results
- ChatGPT's accuracy, precision, recall, and F1-scores are lower than traditional methods across all tested datasets
- Using more training samples does not significantly improve ChatGPT's clickbait detection performance
- LLMs achieve stable but suboptimal results across English and Chinese languages
- Fine-tuning PLMs and prompt-tuning methods outperform few-shot LLM approaches when only headlines are provided

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs struggle with clickbait detection because they rely heavily on contextual and semantic cues that are often insufficient when only headlines are provided
- Mechanism: The LLM's zero/few-shot learning approach depends on pattern matching from prompts, but clickbait detection requires deeper understanding of content-context alignment that prompts alone cannot provide
- Core assumption: Clickbait detection fundamentally requires cross-referencing headline claims with actual content, which is not possible when only headlines are given
- Evidence anchors:
  - [abstract]: "Different from human intuition, the experiments demonstrated that LLMs cannot make satisfied clickbait detection just by the headlines."
  - [section]: "ChatGPT has a lot of room for improvement in clickbait detection" and "fine-tuning PLMs and prompt-tuning can achieve better results just based on the titles, which is consistent with humans in the real-world"
  - [corpus]: Weak evidence - corpus neighbors focus on prompt-tuning approaches but don't directly address the headline-only limitation
- Break condition: When full article content becomes available for context, the LLM's performance would likely improve as it could then perform content-headline alignment

### Mechanism 2
- Claim: LLMs perform better in multilingual scenarios because they are trained on diverse language data and can transfer knowledge across languages
- Mechanism: The monolithic nature of LLMs allows them to handle multiple languages without requiring language-specific fine-tuning, leveraging shared semantic representations across languages
- Core assumption: The multilingual capabilities of LLMs are robust enough to maintain performance across different languages without language-specific adaptation
- Evidence anchors:
  - [abstract]: "ChatGPT is a monolithic model capable of supporting multiple languages, which makes it a comprehensive multilingual clickbait detection technique"
  - [section]: "After evaluating the performance of ChatGPT on the task of clickbait detection across two languages (English and Chinese), we observed that it achieved stable results on almost all evaluation metrics"
  - [corpus]: Moderate evidence - corpus neighbors include papers on multilingual clickbait detection but don't specifically validate the cross-language transfer claim
- Break condition: When dealing with low-resource languages not well-represented in the LLM's training data, performance would degrade significantly

### Mechanism 3
- Claim: Traditional deep learning and fine-tuning PLMs outperform LLMs in clickbait detection because they are specifically optimized for the task through supervised learning
- Mechanism: Fine-tuning allows models to learn task-specific representations and decision boundaries that are more effective for clickbait detection than the general knowledge in LLMs
- Core assumption: Task-specific optimization through fine-tuning produces better performance than general-purpose few-shot learning for specialized tasks like clickbait detection
- Evidence anchors:
  - [abstract]: "Experimental results show that LLMs cannot achieve the best results compared to the state-of-the-art deep and fine-tuning PLMs methods"
  - [section]: "Compared to the deep neural networks and fine-tuning PLMs, ChatGPT has a lot of room for improvement in clickbait detection"
  - [corpus]: Strong evidence - corpus neighbors include papers on prompt-tuning and deep learning approaches that consistently outperform LLM-based methods
- Break condition: When labeled training data becomes extremely scarce, the advantage of fine-tuning would diminish and LLM few-shot learning would become more competitive

## Foundational Learning

- Concept: Few-shot learning
  - Why needed here: The paper evaluates LLMs in few-shot scenarios to test their ability to perform clickbait detection with minimal training data
  - Quick check question: What is the key difference between few-shot learning and traditional supervised learning in terms of data requirements and model adaptation?

- Concept: Prompt engineering
  - Why needed here: The paper uses hand-crafted prompts to guide the LLM's behavior for clickbait detection tasks
  - Quick check question: How do the {guide-input-output} and {sentence-question-answer} prompt patterns differ in their approach to eliciting the desired output from the LLM?

- Concept: Multilingual model evaluation
  - Why needed here: The paper tests the LLM's performance across English and Chinese datasets to assess its cross-lingual capabilities
  - Quick check question: What metrics would you use to determine if an LLM's performance is truly "stable" across different languages?

## Architecture Onboarding

- Component map: LLM (GPT-3.5-turbo) -> Prompt templates -> API call -> Response parsing -> Metric calculation -> Result aggregation
- Critical path: Prompt design → API call to GPT-3.5-turbo → Response parsing → Metric calculation → Result aggregation
- Design tradeoffs: Few-shot learning offers flexibility but lower performance vs. fine-tuning offers higher performance but requires more data and compute resources
- Failure signatures: Inconsistent predictions across similar inputs, performance degradation with more training samples, language-specific performance drops
- First 3 experiments:
  1. Test prompt variations (P1 vs P2) on a small subset of English data to identify which pattern yields better results
  2. Compare zero-shot vs few-shot performance on Chinese datasets to validate multilingual stability claims
  3. Analyze error cases where ChatGPT fails to detect obvious clickbait to identify common failure patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do LLMs perform on clickbait detection tasks when trained on a large amount of data?
- Basis in paper: [explicit] The authors found that using more training samples does not significantly improve ChatGPT's clickbait detection performance.
- Why unresolved: The authors only tested ChatGPT on few-shot and zero-shot scenarios. They did not evaluate its performance when trained on a large amount of data.
- What evidence would resolve it: Conduct experiments on clickbait detection tasks using LLMs with large amounts of training data. Compare the results with those of traditional methods and fine-tuning PLMs methods.

### Open Question 2
- Question: Can LLMs be used to improve the performance of traditional clickbait detection methods?
- Basis in paper: [inferred] The authors found that LLMs do not achieve the best performance compared to state-of-the-art deep learning and fine-tuning PLMs methods. However, they also found that LLMs can achieve stable results on almost all evaluation metrics.
- Why unresolved: The authors did not explore the potential of combining LLMs with traditional clickbait detection methods.
- What evidence would resolve it: Develop hybrid methods that combine LLMs with traditional clickbait detection methods. Evaluate their performance on clickbait detection tasks and compare the results with those of traditional methods and fine-tuning PLMs methods.

### Open Question 3
- Question: How do different prompts affect the performance of LLMs on clickbait detection tasks?
- Basis in paper: [explicit] The authors compared the results between different prompts for clickbait detection tasks.
- Why unresolved: The authors only tested two prompts and did not explore the effects of other prompts on the performance of LLMs.
- What evidence would resolve it: Design and test different prompts for clickbait detection tasks using LLMs. Compare the results with those of traditional methods and fine-tuning PLMs methods.

## Limitations

- The comparison between few-shot LLM performance and full-training-set baselines may not be fair, as the baselines had access to substantially more labeled data
- Only two prompt patterns were tested, limiting the exploration of prompt engineering effectiveness
- Dataset details such as size, class balance, and representativeness are not provided, making it difficult to assess result generalizability

## Confidence

**Low confidence** - The claim that "LLMs cannot achieve the best results compared to state-of-the-art deep and fine-tuning PLMs methods" is limited by the comparison methodology. Since the baselines used full training sets while ChatGPT used few-shot learning, the comparison conflates data efficiency with model capability.

**Medium confidence** - The finding that "ChatGPT has a lot of room for improvement in clickbait detection" is reasonably supported by the experimental results, though the limited prompt engineering exploration introduces uncertainty about whether better prompt design could significantly improve performance.

**High confidence** - The observation that "fine-tuning PLMs and prompt-tuning can achieve better results just based on the titles" is well-supported by the comparison results and aligns with established findings in the literature about task-specific optimization benefits.

## Next Checks

**Check 1: Fair baseline comparison** - Re-run the experiments comparing ChatGPT's few-shot performance against deep learning and fine-tuning PLMs that are also limited to the same number of training examples (5, 10, or 20 samples). This would isolate whether the performance gap stems from few-shot limitations versus fundamental model capability differences.

**Check 2: Prompt engineering exploration** - Systematically test 5-10 different prompt variations including different instruction formats, example selections, and output structures. Compare performance across these variations to establish whether the current results represent the true ceiling of few-shot LLM performance for clickbait detection.

**Check 3: Content-aware evaluation** - Modify the evaluation to provide both headlines and corresponding article content to ChatGPT, then compare performance against the headline-only scenario. This would test the hypothesis that clickbait detection fundamentally requires cross-referencing headlines with content, and would validate whether the headline-only limitation is the primary constraint.