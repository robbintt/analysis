---
ver: rpa2
title: Knowledge Graph Representations to enhance Intensive Care Time-Series Predictions
arxiv_id: '2311.07180'
source_url: https://arxiv.org/abs/2311.07180
tags:
- data
- knowledge
- clinical
- graph
- patient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes integrating knowledge graphs derived from medical
  ontologies (UMLS) into ICU time-series prediction models to enhance performance,
  especially under missing data. The method extracts medical concepts from clinical
  notes, builds a knowledge graph, and jointly learns graph representations alongside
  time series and clinical reports using graph neural networks.
---

# Knowledge Graph Representations to enhance Intensive Care Time-Series Predictions

## Quick Facts
- arXiv ID: 2311.07180
- Source URL: https://arxiv.org/abs/2311.07180
- Reference count: 15
- Key outcome: State-of-the-art performance on MIMIC-III ICU prediction tasks with improved robustness under missing data

## Executive Summary
This paper proposes integrating knowledge graphs derived from medical ontologies (UMLS) into ICU time-series prediction models to enhance performance, especially under missing data. The method extracts medical concepts from clinical notes, builds a knowledge graph, and jointly learns graph representations alongside time series and clinical reports using graph neural networks. Experiments on MIMIC-III benchmark tasks show state-of-the-art performance, with improved robustness under increasing missing data ratios and enhanced interpretability through attention analysis on knowledge graph nodes.

## Method Summary
The approach extracts medical concepts from clinical notes using QuickUMLS, constructs a knowledge graph from UMLS ontology, and combines this with vital signs time series and clinical reports. A feature tokenizer processes time series data, while Clinical Bio-BERT handles clinical notes. Dynamic knowledge graphs are built at each time step using a fusion transformer (FT) module, and graph neural networks propagate information through the knowledge graph structure. The final prediction uses an LSTM followed by a multi-layer perceptron. The model is trained end-to-end with Adam optimizer, learning rate 1e-4, and batch sizes 8-64.

## Key Results
- Achieves state-of-the-art performance on MIMIC-III mortality, decompensation, and phenotyping tasks
- Demonstrates improved robustness under increasing missing data ratios (0-30%)
- Shows enhanced interpretability through attention analysis on knowledge graph nodes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Knowledge graph embeddings improve performance especially under missing data conditions.
- Mechanism: The knowledge graph provides auxiliary relational structure that compensates for missing time-series values by supplying semantic context about medical concepts extracted from clinical notes.
- Core assumption: Medical ontologies encode clinically meaningful relationships that are predictive of patient outcomes.
- Evidence anchors:
  - [abstract] "improving performance, especially when data is missing"
  - [section] "Our approach diverges by jointly learning representations across various modalities, which further improves performance in situations with missing data."
  - [corpus] Weak - no direct evidence of missing data handling in cited papers.

### Mechanism 2
- Claim: Graph-structured embeddings enhance interpretability through attention over knowledge graph nodes.
- Mechanism: By using a Graph Attention Network, the model can assign interpretable weights to specific medical concepts, revealing which aspects of prior knowledge drive predictions.
- Core assumption: Attention scores over knowledge graph nodes correspond to clinically meaningful relevance.
- Evidence anchors:
  - [abstract] "enhanced interpretability through attention analysis on knowledge graph nodes"
  - [section] "Leveraging a Graph Attention Network (GAT) by Veliˇ ckovi´ c et al. (2017), we compute attention scores across KG nodes"
  - [corpus] Weak - no explicit evidence from cited papers about attention interpretability in KG settings.

### Mechanism 3
- Claim: Multi-modal fusion with structured knowledge outperforms single-modality or unstructured fusion approaches.
- Mechanism: Jointly learning embeddings from vital signs, clinical notes, and knowledge graphs creates richer representations than treating modalities separately or ignoring graph structure.
- Core assumption: Clinical notes and knowledge graphs contain complementary predictive signals not captured by vital signs alone.
- Evidence anchors:
  - [abstract] "combines graph representations with vital signs and clinical reports, enhancing performance"
  - [section] "The combination of these modalities can mitigate challenges in scenarios with missing data"
  - [corpus] Moderate - some related papers mention multimodal fusion but not with knowledge graphs.

## Foundational Learning

- Concept: Knowledge Graph Construction from Clinical Ontologies
  - Why needed here: The model requires structured medical knowledge to supplement sparse time-series data.
  - Quick check question: How does the UMLS database provide the edges for the knowledge graph?

- Concept: Graph Neural Networks for Multimodal Embeddings
  - Why needed here: GNNs can propagate information between related medical concepts and vital signs.
  - Quick check question: What aggregation functions are used to combine node embeddings into a step representation?

- Concept: Attention Mechanisms in Graph Neural Networks
  - Why needed here: Attention identifies which knowledge graph nodes are most relevant for each prediction.
  - Quick check question: How does the attention score help interpret the model's decision for a specific patient?

## Architecture Onboarding

- Component map: Static Knowledge → Time-Step Encoder → Clinical Prediction
- Critical path: Static Knowledge (UMLS-derived knowledge graph + SapBERT embeddings) → Time-Step Encoder (Feature Tokenizer + clinical BERT + dynamic graph construction + GNN layers + aggregation) → Clinical Prediction (LSTM + MLP)
- Design tradeoffs:
  - Fixed vs dynamic knowledge graph: Static allows precomputation but lacks patient-specific adaptation
  - GNN depth: More layers increase expressiveness but risk oversmoothing
  - Aggregation method: Mean/sum/max affects how local graph structure influences global embedding
- Failure signatures:
  - Missing performance gain: Likely due to poor concept extraction or sparse knowledge graph
  - High variance: May indicate instability in attention weights or graph construction
  - Degradation under missing data: Suggests graph structure not compensating adequately
- First 3 experiments:
  1. Replace SapBERT with random embeddings to test knowledge contribution
  2. Remove clinical notes to isolate knowledge graph effect
  3. Vary graph aggregation (mean vs max) to assess impact on performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of specific knowledge graph extraction method (QuickUMLS) impact the performance compared to alternative medical concept extraction approaches?
- Basis in paper: [explicit] The paper uses QuickUMLS for concept extraction but does not compare it to alternatives.
- Why unresolved: The paper does not provide comparative analysis of different medical concept extraction methods.
- What evidence would resolve it: Empirical comparison of model performance using different concept extraction methods (e.g., cTAKES, MetaMap) on the same tasks.

### Open Question 2
- Question: What is the optimal balance between knowledge graph node count and model performance?
- Basis in paper: [inferred] The paper uses 30 nodes as maximum but does not systematically explore different node counts.
- Why unresolved: The paper does not conduct ablation studies varying the number of knowledge graph nodes.
- What evidence would resolve it: Performance analysis across different knowledge graph sizes (e.g., 10, 30, 50, 70 nodes) to identify optimal trade-off.

### Open Question 3
- Question: How does the model's performance vary across different clinical note categories (e.g., discharge summary vs nursing notes)?
- Basis in paper: [explicit] The paper mentions 15 categories of clinical notes but does not analyze their individual contributions.
- Why unresolved: The paper aggregates all clinical note types without analyzing their differential impact.
- What evidence would resolve it: Performance analysis using different subsets of clinical note categories to identify which types contribute most to predictions.

## Limitations
- Weak evidence for attention interpretability claims with no clinical validation of attention patterns
- No ablation studies to quantify the contribution of knowledge graph components under missing data
- Limited exploration of alternative knowledge graph extraction methods or node count optimization

## Confidence
- Mechanism 1 (Missing data handling): Medium - supported by abstract claims but lacks ablation evidence
- Mechanism 2 (Attention interpretability): Low - no empirical validation of clinically meaningful attention patterns
- Mechanism 3 (Multi-modal fusion superiority): Low - no comparative ablation studies against single-modality or unstructured fusion approaches

## Next Checks
1. Perform ablation study removing knowledge graph components to quantify performance drop under varying missing data ratios (0-30%), testing if the claimed improvement is statistically significant
2. Analyze attention weight distributions across patient samples to verify they are not uniformly distributed and correlate with clinically meaningful concepts using expert validation
3. Compare against ablations where clinical notes and vital signs are processed separately (no fusion) and where unstructured multimodal fusion is used without knowledge graph structure to validate the claimed superiority of the proposed approach