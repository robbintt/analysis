---
ver: rpa2
title: 'Modeling Orders of User Behaviors via Differentiable Sorting: A Multi-task
  Framework to Predicting User Post-click Conversion'
arxiv_id: '2307.09089'
source_url: https://arxiv.org/abs/2307.09089
tags:
- user
- post-click
- sorting
- learning
- differentiable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a multi-task learning framework (MTLDS) that
  leverages orders of user behaviors to predict post-click conversion. It introduces
  a general aggregation operator to combine predictions from multiple tasks into a
  unified score, then models label relations via differentiable sorting.
---

# Modeling Orders of User Behaviors via Differentiable Sorting: A Multi-task Framework to Predicting User Post-click Conversion

## Quick Facts
- arXiv ID: 2307.09089
- Source URL: https://arxiv.org/abs/2307.09089
- Reference count: 14
- Primary result: MTLDS with linear aggregation consistently outperforms competitive baselines on public (Alibaba) and industrial (eBay) datasets for purchase prediction

## Executive Summary
This paper introduces a multi-task learning framework (MTLDS) that leverages orders of user behaviors to predict post-click conversion in an end-to-end approach. The framework models label relations via differentiable sorting, using a shared bottom architecture with task-specific networks, an aggregation module, and a sorting module that computes permutation matrices using softsort. Extensive experiments demonstrate that MTLDS variants achieve superior performance in terms of AUC and NDCG metrics compared to competitive baselines on both public and industrial datasets.

## Method Summary
MTLDS employs hard parameter sharing with shared bottom layers to learn common feature representations across tasks, while task-specific heads adapt to label-specific patterns. The framework introduces a general aggregation operator that combines predictions from multiple tasks into a unified score, then models label relations via differentiable sorting using softsort to approximate permutation matrices. The approach is trained end-to-end, allowing gradients to flow through the sorting operation and enabling optimal aggregation of task predictions based on their relative ordering.

## Key Results
- MTLDS variants consistently outperform competitive baselines in terms of AUC and NDCG metrics for purchase prediction
- Linear aggregation operator performs best across two datasets, confirming superior ability to distinguish user behavior sequences
- Framework scales to multiple post-click labels (e.g., AddtoCart, Purchase) without requiring additional loss functions
- Extensive experiments on public (Alibaba) and industrial (eBay) datasets validate effectiveness

## Why This Works (Mechanism)

### Mechanism 1: Multi-task Learning with Shared Representations
- Claim: Shared bottom layers reduce variance and improve generalization by jointly modeling click and post-click labels
- Mechanism: Shared bottom layers learn common feature representations across tasks, while task-specific heads adapt to label-specific patterns, mitigating data sparsity in post-click labels
- Core assumption: Click and post-click behaviors share underlying user/item representations that benefit from knowledge transfer
- Evidence anchors: [abstract] "by incorporating click data"; [section] "Hard parameter sharing...reduce the risk of fitting"
- Break condition: When click and post-click labels have fundamentally different semantic meanings

### Mechanism 2: Differentiable Sorting for End-to-End Optimization
- Claim: Differentiable sorting enables end-to-end optimization of label orderings, directly modeling preference list structure
- Mechanism: Softsort operation approximates permutation matrices using unimodal row-stochastic matrices, allowing gradients to flow through sorting
- Core assumption: Order of user behaviors follows meaningful preference structure that can be captured by sorting predicted scores
- Evidence anchors: [abstract] "leverages orders of user behaviors"; [section] "computing permutation probability via mapping prediction matrices to unimodal row-stochastic matrices"
- Break condition: When behavior sequences are too noisy or have no consistent ordering patterns

### Mechanism 3: Linear Aggregation for Optimal Balance
- Claim: Linear aggregation provides optimal balance between modeling flexibility and variance control for combining multi-task predictions
- Mechanism: Linear aggregation computes weighted sum of task predictions (ð‘  = Î£ð‘¤ð‘¡ Â· ð‘™Ì‚ð‘¡), where weights are learned parameters
- Core assumption: Different post-click labels contribute differently to final preference ordering, and contributions can be learned from data
- Evidence anchors: [section] "linear aggregator performs the best on two datasets consistently"; [section] "Mul-operator, Max-operator and vanilla Sum-operator could fail to distinguish certain user behavior sequences"
- Break condition: When number of tasks becomes very large, making weight learning unstable

## Foundational Learning

- Concept: Permutation matrices and their relaxation to doubly-stochastic matrices
  - Why needed here: Differentiable sorting requires approximating hard permutation operations with continuous relaxations that permit gradient flow
  - Quick check question: What property distinguishes doubly-stochastic matrices from general stochastic matrices?

- Concept: Multi-task learning with shared representations
  - Why needed here: Model architecture relies on parameter sharing to address data sparsity in post-click labels while maintaining task-specific adaptation
  - Quick check question: How does hard parameter sharing differ from soft parameter sharing in MTL?

- Concept: Listwise ranking losses and their relationship to differentiable sorting
  - Why needed here: Proposed approach provides alternative to existing listwise losses by directly optimizing permutation matrices rather than soft labels
  - Quick check question: What is the key difference between ListNet's soft label approach and the differentiable sorting approach?

## Architecture Onboarding

- Component map: Input features â†’ Shared bottom layers â†’ Task-specific heads â†’ Aggregation module â†’ Sorting module â†’ Loss computation
- Critical path: Feature extraction â†’ Multi-task prediction â†’ Score aggregation â†’ Differentiable sorting â†’ Permutation loss
- Design tradeoffs: Linear aggregation vs multiplicative vs max operators (bias-variance tradeoff); temperature parameter in softsort (approximation accuracy vs gradient smoothness)
- Failure signatures: Poor performance on single tasks despite strong multi-task performance suggests insufficient task-specific capacity; gradient explosion in sorting module suggests temperature parameter too low
- First 3 experiments:
  1. Compare linear aggregation vs multiplicative vs max operators on validation set to confirm superior performance
  2. Sweep temperature parameter in softsort to find optimal approximation-accuracy tradeoff
  3. Test MTLDS with varying numbers of post-click labels to validate scalability claims

## Open Questions the Paper Calls Out

### Open Question 1: Performance with Violated Ordering Assumptions
- Question: How does MTLDS performance vary when the ordering assumption (Click -> AddtoCart -> Purchase) is violated in real-world data?
- Basis in paper: [explicit] The paper assumes "the order of user behavior follows the ordering of the label sequence" but doesn't test scenarios where users deviate from this assumed ordering
- Why unresolved: Paper does not test scenarios with varied or ambiguous user behavior sequences
- What evidence would resolve it: Experiments on datasets with varied or ambiguous user behavior sequences showing performance degradation when ordering assumptions are violated

### Open Question 2: Temperature Parameter Impact
- Question: What is the impact of temperature parameter Ï„ in the differentiable sorting module on model convergence and final performance?
- Basis in paper: [inferred] The differentiable sorting implementation uses temperature parameter Ï„ to control approximation degree, but paper doesn't report sensitivity analysis
- Why unresolved: Without systematic tuning or ablation, optimal Ï„ range and effect on learning dynamics remain unclear
- What evidence would resolve it: Ablation studies showing MTLDS performance across range of Ï„ values, including convergence speed and stability

### Open Question 3: Generalizing Aggregation Operators
- Question: Can the aggregation operator be further generalized to handle non-linear interactions between task-specific predictions?
- Basis in paper: [explicit] Paper proposes four aggregation operators but doesn't explore non-linear or learned interaction functions beyond simple weighted sums
- Why unresolved: Current linear and multiplicative assumptions may not capture complex dependencies between tasks
- What evidence would resolve it: Experiments comparing MTLDS with advanced aggregation methods (e.g., attention mechanisms) on datasets with multiple post-click labels

### Open Question 4: Scalability to Larger Datasets
- Question: How does MTLDS perform when scaled to datasets with significantly more users and items than those tested?
- Basis in paper: [explicit] Paper evaluates MTLDS on millions of samples but doesn't discuss computational scalability or performance on larger industrial-scale datasets
- Why unresolved: Model's efficiency and effectiveness at scale are not demonstrated, critical for real-world deployment
- What evidence would resolve it: Performance and runtime analysis on datasets with orders of magnitude more users, items, and interactions

## Limitations

- The assumption that click and post-click behaviors share meaningful underlying representations may not hold across all domains
- Differentiable sorting approach assumes consistent behavior orderings exist, but real user behavior sequences may be too noisy for reliable ordering patterns
- Linear aggregation consistently outperforms alternatives, but theoretical justification for this remains incomplete

## Confidence

**High Confidence**: The multi-task learning framework architecture with shared bottom layers and task-specific heads is well-established and theoretically sound. Reported improvements in AUC and NDCG metrics across both public and industrial datasets provide strong empirical support.

**Medium Confidence**: The differentiable sorting mechanism's effectiveness depends heavily on proper temperature tuning and the assumption of meaningful behavior orderings. While the mathematical formulation is correct, real-world applicability may vary significantly by domain and dataset quality.

**Low Confidence**: The aggregation operator comparisons lack theoretical grounding for why linear aggregation consistently outperforms alternatives. The claim that this approach scales to "more post-click labels" without additional loss functions needs validation with substantially more than three labels.

## Next Checks

1. **Domain Transferability Test**: Evaluate MTLDS on datasets where click and post-click behaviors have demonstrably different semantic meanings to verify the shared representation assumption holds.

2. **Noise Sensitivity Analysis**: Systematically inject noise into behavior sequences and measure how differentiable sorting performance degrades compared to traditional listwise ranking methods, establishing robustness bounds.

3. **Aggregation Operator Ablation with Theory**: Conduct controlled experiments varying the number of tasks from 2 to 10+ while measuring both performance and weight stability, then develop theoretical bounds on aggregation operator performance as task count increases.