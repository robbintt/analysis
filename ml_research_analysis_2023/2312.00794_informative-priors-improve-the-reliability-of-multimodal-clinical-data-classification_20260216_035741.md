---
ver: rpa2
title: Informative Priors Improve the Reliability of Multimodal Clinical Data Classification
arxiv_id: '2312.00794'
source_url: https://arxiv.org/abs/2312.00794
tags:
- multimodal
- data
- uncertainty
- neural
- prior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a Bayesian neural network with a multimodal
  data-driven (m2d2) prior to improve uncertainty quantification in multimodal clinical
  data classification. The m2d2 prior is designed to place high probability density
  on parameter values that induce predictive functions with high uncertainty on input
  points meaningfully different from the training data.
---

# Informative Priors Improve the Reliability of Multimodal Clinical Data Classification

## Quick Facts
- arXiv ID: 2312.00794
- Source URL: https://arxiv.org/abs/2312.00794
- Reference count: 40
- Primary result: m2d2 prior improves AUROC from 0.726 to 0.735, AUPRC from 0.503 to 0.514, and selective prediction AUROC from 0.724 to 0.748 compared to deterministic baselines

## Executive Summary
This paper addresses the challenge of uncertainty quantification in multimodal clinical data classification by proposing a Bayesian neural network with a multimodal data-driven (m2d2) prior. The m2d2 prior is designed to place high probability density on parameter values that induce predictive functions with high uncertainty on input points meaningfully different from training data. Evaluated on MIMIC-IV and MIMIC-CXR datasets for acute care condition classification, the method shows improved standard metrics (AUROC, AUPRC) and selective prediction metrics compared to deterministic and standard prior Bayesian baselines.

## Method Summary
The approach uses a Bayesian neural network with Gaussian mean-field variational inference, incorporating an m2d2 prior constructed from context points generated through modality-specific transformations. The architecture fuses clinical time series data (encoded with LSTM) and chest X-ray images (encoded with ResNet-34) through a joint fusion layer. The m2d2 prior is shaped using context points created by applying drop start, Gaussian noise, and inversion transformations to the clinical time series data. The model is trained end-to-end using Adam optimizer with learning rate 2e-4 for 400 epochs, evaluated on paired MIMIC-IV and MIMIC-CXR datasets with 25 acute care condition labels.

## Key Results
- m2d2 prior achieves AUROC of 0.735 and AUPRC of 0.514 versus 0.726 and 0.503 for deterministic baseline
- Selective prediction AUROC improves from 0.724 to 0.748 with m2d2 prior
- AUPRC for selective prediction increases from 0.439 to 0.452 with m2d2 prior
- Context batch size of 64 and context dataset size of 100 provide optimal performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The m2d2 prior improves uncertainty quantification by placing high probability density on parameter values that induce predictive functions with high uncertainty on out-of-distribution input points.
- Mechanism: The prior is constructed by generating context points through modality-specific transformations (drop start, Gaussian noise, inversion for clinical time series) that are meaningfully different from training data, shaping the prior distribution to favor parameter values inducing high predictive uncertainty on distributionally shifted inputs.
- Core assumption: High predictive uncertainty on out-of-distribution points correlates with better reliability and selective prediction performance.
- Evidence anchors: [abstract] "We design a multimodal data-driven (m2d2) prior distribution over network parameters that places high probability density on desired predictive functions"; [section 3.1] Context point construction with transformations; [corpus] Weak - no direct evidence these transformations improve uncertainty quantification.

### Mechanism 2
- Claim: Gaussian mean-field variational inference with the m2d2 prior leads to improved AUROC, AUPRC, and selective prediction metrics compared to deterministic and standard prior Bayesian baselines.
- Mechanism: The variational inference procedure shapes the approximate posterior distribution over network parameters using the m2d2 prior, favoring parameter values that induce predictive functions with desired uncertainty properties.
- Core assumption: The variational inference procedure can effectively learn the desired posterior distribution when using the m2d2 prior.
- Evidence anchors: [abstract] "Our empirical results show that the proposed method produces a more reliable predictive model compared to deterministic and Bayesian neural network baselines"; [section 4.3] Quantitative improvements in metrics; [corpus] Weak - no direct evidence that Gaussian mean-field variational inference with m2d2 prior specifically leads to these improvements.

### Mechanism 3
- Claim: The selective prediction framework provides a more comprehensive evaluation of model reliability by incorporating both predictive performance and predictive uncertainty.
- Mechanism: The framework introduces a "reject option" via a gating mechanism defined by a selection function, allowing the model to abstain from predictions when uncertainty exceeds a risk tolerance threshold.
- Core assumption: Models that can effectively identify samples likely to be misclassified and defer to human experts are more reliable in clinical settings.
- Evidence anchors: [section 4.2] "To evaluate the predictive performance of a prediction model ( p(y | ·, θ; f), s)(x) with a single label, we compute the AUROC and AUPRC over rejection thresholds τ = 0%, ...,99%."; [section 4.3] "Our findings illustrate an increase in predictive performance and improved reliability in uncertainty-aware selective prediction."; [corpus] Weak - no direct evidence that selective prediction is more comprehensive than standard metrics.

## Foundational Learning

- Concept: Bayesian inference and variational inference
  - Why needed here: The method uses Bayesian neural networks and Gaussian mean-field variational inference to learn the posterior distribution over network parameters.
  - Quick check question: What is the key difference between Bayesian inference and variational inference, and why is variational inference used in this context?

- Concept: Uncertainty quantification in machine learning
  - Why needed here: The method aims to improve uncertainty quantification in multimodal clinical data classification, crucial for reliable decision support in healthcare.
  - Quick check question: What are the different sources of uncertainty in machine learning, and why is it important to quantify them in healthcare applications?

- Concept: Multimodal learning and fusion
  - Why needed here: The method deals with the fusion of clinical time series data and chest X-ray images for classification tasks.
  - Quick check question: What are the different approaches for leveraging information across different data modalities, and why is multimodal fusion particularly relevant in healthcare?

## Architecture Onboarding

- Component map: Clinical time series (Xehr) -> LSTM encoder (Φehr) -> Fusion -> Classifier -> Multi-label probabilities; Chest X-ray images (Xcxr) -> ResNet-34 encoder (Φcxr) -> Fusion -> Classifier -> Multi-label probabilities

- Critical path:
  1. Preprocess and load clinical time series data and chest X-ray images
  2. Encode each modality using the respective encoder
  3. Concatenate the encoded representations and pass through the classifier
  4. Apply the sigmoid activation function to obtain multi-label probabilities
  5. Compute the loss using binary cross-entropy adapted for multi-label classification
  6. Train the model end-to-end using the variational objective with the m2d2 prior

- Design tradeoffs:
  - Bayesian neural networks and variational inference add computational complexity but enable principled uncertainty quantification
  - m2d2 prior requires generating context points through modality-specific transformations, introducing additional data preprocessing complexity
  - Selective prediction framework provides more comprehensive reliability evaluation but may result in lower AUPRC due to model rejection of uncertain samples

- Failure signatures:
  - Poor performance on test set (low AUROC/AUPRC) may indicate issues with model architecture, training procedure, or data quality
  - Low selective prediction AUROC/AUPRC may suggest the model is not effectively identifying uncertain samples or uncertainty estimates are not well-calibrated
  - High computational cost or memory usage during training may indicate issues with variational inference procedure or context dataset size

- First 3 experiments:
  1. Train and evaluate the deterministic baseline model (Hayat et al., 2022) to establish performance benchmark
  2. Train and evaluate the Bayesian model with standard prior to assess impact of using Bayesian neural networks without m2d2 prior
  3. Train and evaluate the Bayesian model with m2d2 prior using different context batch sizes to find optimal setting for uncertainty quantification

## Open Questions the Paper Calls Out

- Open Question 1: How do the informative priors perform in settings with missing modalities or imbalanced multimodal data?
  - Basis in paper: [inferred] The authors mention evaluating the approach in "settings of missing modalities" as future work, indicating this has not been tested.
  - Why unresolved: Current evaluation only considers paired datasets where both modalities are present, so method's robustness to missing data is unknown.
  - What evidence would resolve it: Empirical results comparing m2d2 prior's performance when one modality is missing or corrupted versus standard priors or deterministic baselines.

- Open Question 2: Can the uncertainty quantification be improved by incorporating domain expert knowledge into the prior distribution?
  - Basis in paper: [explicit] The authors note limited empirical evaluation due to "the lack of well-constructed priors by medical experts" and mention this as a challenge.
  - Why unresolved: Current m2d2 prior is constructed through data-driven transformations rather than incorporating medical expert knowledge.
  - What evidence would resolve it: Comparative experiments showing performance differences between data-driven priors and priors constructed with medical expert input.

- Open Question 3: What is the computational overhead of the m2d2 prior approach compared to standard Bayesian and deterministic methods in real-time clinical settings?
  - Basis in paper: [inferred] The authors mention challenges of "scaling uncertainty quantification in real-time clinical systems" and discuss increased parameters and forward passes required for stochastic models.
  - Why unresolved: While implementation details are provided, actual runtime performance and scalability in clinical deployment scenarios is not quantified.
  - What evidence would resolve it: Benchmarking results showing inference time and resource requirements for m2d2 prior method versus baselines in realistic clinical data volumes.

## Limitations

- Limited evidence that modality-specific transformations (drop start, Gaussian noise, inversion) effectively generate meaningful distribution shifts for uncertainty quantification
- Selective prediction framework's superiority as an evaluation metric is assumed rather than externally validated
- Computational complexity and practical deployment challenges in real-time clinical settings are acknowledged but not thoroughly analyzed

## Confidence

- Mechanism 1 (m2d2 prior design): Low - based on theoretical construction without strong empirical validation
- Mechanism 2 (AUROC/AUPRC improvements): Medium - supported by results but lacking ablation studies
- Mechanism 3 (selective prediction framework): Medium - methodology described but not externally validated

## Next Checks

1. Conduct ablation studies to isolate the contribution of each transformation in the m2d2 context point generation to uncertainty quantification improvements
2. Compare selective prediction metrics against alternative reliability evaluation methods in healthcare settings to validate its comprehensiveness
3. Perform sensitivity analysis on context batch size and prior variance to identify optimal settings and robustness boundaries