---
ver: rpa2
title: Learning Type-Generalized Actions for Symbolic Planning
arxiv_id: '2308.04867'
source_url: https://arxiv.org/abs/2308.04867
tags:
- actions
- action
- planning
- generalized
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of symbolic planning in robotics,
  which requires suitable symbolic representations of states and actions. Traditional
  approaches rely on hand-designed, domain-specific representations, limiting transferability.
---

# Learning Type-Generalized Actions for Symbolic Planning

## Quick Facts
- arXiv ID: 2308.04867
- Source URL: https://arxiv.org/abs/2308.04867
- Reference count: 40
- Key outcome: Novel method learns type-generalized actions from few demonstrations using entity hierarchy, successfully transferring to novel tasks and entities in simulated kitchen environment

## Executive Summary
This paper addresses the challenge of symbolic planning in robotics by proposing a method to learn type-generalized actions from few demonstrations. Traditional approaches rely on hand-designed, domain-specific representations that limit transferability. The authors introduce two algorithms: one learns generalized actions from demonstrations by clustering effects and generalizing parameters using entity hierarchy, while another imagines new generalizations during planning when needed. Evaluated in a simulated kitchen environment, the method successfully transferred learned actions to novel tasks and entities, solving all tested task combinations that individual action learning failed on.

## Method Summary
The approach consists of two complementary algorithms. First, a learning algorithm processes (state, action, next state) demonstration tuples, clustering them by action description and unified effects. For each cluster, it extracts preconditions and generalizes parameters by finding the lowest common ancestor in the entity hierarchy. Second, an imagination algorithm works on-the-fly during planning, creating novel generalized actions when goal predicates are unreachable with existing grounded actions. The system uses a heuristic planner with ordered landmarks and includes an execution monitor to validate effects and trigger replanning when necessary.

## Key Results
- Successfully transferred learned actions to novel tasks and entities, solving all tested task combinations that individual action learning failed on
- Learned actions were more efficient than on-the-fly imagination, but imagination component enabled solving tasks requiring novel generalizations
- Demonstrated strong generalization capabilities, solving tasks involving longer sequences, novel entities, and unexpected environment behavior

## Why This Works (Mechanism)

### Mechanism 1
The system learns generalized actions from few demonstrations by clustering grounded action effects and generalizing parameters using entity hierarchy. Similar behaviors across different objects imply they share the same underlying action structure. The mechanism clusters demonstrations by action and effect, then generalizes parameters using the lowest common ancestor of relevant objects.

### Mechanism 2
On-the-fly imagination during planning solves tasks requiring novel generalizations not seen in demonstrations. When goal predicates are unreachable with current grounded actions, the system imagines new generalized actions by finding the lowest common ancestor of relevant objects and creating new action variants. This enables the system to handle tasks involving novel entities and longer sequences.

### Mechanism 3
Learning from few demonstrations works because the system leverages hierarchical entity relationships and effect similarity. By clustering demonstrations by action and effect, then generalizing parameters using the hierarchy, the system can transfer knowledge to novel entities within the same subtree. The quality of the entity hierarchy is critical for successful generalization.

## Foundational Learning

- **Concept: Clustering based on effect unification**
  - Why needed here: To group demonstrations with similar outcomes despite different objects, enabling generalization
  - Quick check question: What makes two observation tuples belong to the same cluster?

- **Concept: Lowest common ancestor for parameter generalization**
  - Why needed here: To find the most specific type that can encompass multiple demonstrated object types
  - Quick check question: Why use LCA instead of a higher ancestor in the hierarchy?

- **Concept: Powerset of precondition differences for generalization**
  - Why needed here: To create candidate preconditions that work across multiple actions while maintaining expressiveness
  - Quick check question: How does considering the powerset help create more general preconditions?

## Architecture Onboarding

- **Component map**: Observation parser -> Clustering engine -> Generalization module -> Planner -> Execution monitor -> Feedback loop
- **Critical path**: Observation → Clustering → Generalization → Planning → Execution → Feedback loop
- **Design tradeoffs**: 
  - More specific individual actions vs. fewer generalized actions (speed vs. flexibility)
  - Precomputing generalizations vs. on-the-fly imagination (planning speed vs. expressiveness)
  - Using powerset for preconditions (coverage vs. computational cost)
- **Failure signatures**: 
  - Planning timeouts: Likely from too many grounded action variants
  - Execution failures: Probably from invalid imagined generalizations
  - Poor generalization: May indicate insufficient demonstration diversity
- **First 3 experiments**: 
  1. Run with individual actions only on S1 tasks to establish baseline
  2. Add learned generalizations and test on S2 tasks for transfer evaluation
  3. Enable imagination and test on S4 tasks requiring novel object types

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the proposed method scale to more complex environments with larger state and action spaces?
- **Basis in paper**: The paper mentions that the method was evaluated in a simulated kitchen environment with a limited set of objects and actions. It does not discuss how the approach would perform in more complex scenarios.
- **Why unresolved**: The paper does not provide any insights into the scalability of the proposed method to more complex environments with larger state and action spaces.
- **What evidence would resolve it**: Evaluating the proposed method on more complex environments with larger state and action spaces, and comparing its performance to other state-of-the-art approaches.

### Open Question 2
- **Question**: How can the proposed method handle environments with continuous state and action spaces?
- **Basis in paper**: The paper focuses on symbolic planning in discrete environments. It does not discuss how the approach would handle continuous state and action spaces.
- **Why unresolved**: The paper does not provide any insights into how the proposed method can be extended to handle continuous state and action spaces.
- **What evidence would resolve it**: Developing a version of the proposed method that can handle continuous state and action spaces, and evaluating its performance in such environments.

### Open Question 3
- **Question**: How can the proposed method be extended to handle environments with partial observability?
- **Basis in paper**: The paper assumes that the environment is fully observable. It does not discuss how the approach would handle partial observability.
- **Why unresolved**: The paper does not provide any insights into how the proposed method can be extended to handle partial observability.
- **What evidence would resolve it**: Developing a version of the proposed method that can handle partial observability, and evaluating its performance in such environments.

### Open Question 4
- **Question**: How can the proposed method be integrated with deep learning techniques to improve its performance?
- **Basis in paper**: The paper mentions that the proposed method can be integrated with deep learning techniques to improve its performance, but does not provide any specific details.
- **Why unresolved**: The paper does not provide any specific details on how the proposed method can be integrated with deep learning techniques.
- **What evidence would resolve it**: Developing a version of the proposed method that integrates with deep learning techniques, and evaluating its performance in various environments.

## Limitations

- Evaluation is limited to a single simulated kitchen environment with controlled scenarios
- Performance in real-world robotics applications with noisy perception and complex object hierarchies remains unknown
- The entity hierarchy's quality critically impacts generalization success, but the paper doesn't address how to learn or validate this hierarchy from data

## Confidence

- **High Confidence**: The mechanism for clustering demonstrations by action and effect, and using LCA for parameter generalization is well-founded and clearly described
- **Medium Confidence**: The on-the-fly imagination component shows promise but lacks extensive validation across diverse scenarios
- **Low Confidence**: Claims about solving "unexpected environment behavior" are weakly supported given the limited evaluation scope

## Next Checks

1. Test the approach on a different domain (e.g., workshop or living room environment) to assess domain transfer capability
2. Evaluate performance with partially observable states or noisy perception to simulate real-world conditions
3. Conduct ablation studies removing the entity hierarchy to quantify its impact on generalization quality