---
ver: rpa2
title: 'Dynamic Bayesian Networks for Predicting Cryptocurrency Price Directions:
  Uncovering Causal Relationships'
arxiv_id: '2306.08157'
source_url: https://arxiv.org/abs/2306.08157
tags:
- price
- data
- dbns
- features
- market
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a dynamic Bayesian network (DBN) approach to
  predict cryptocurrency price directions by uncovering causal relationships among
  various features, including social media data, traditional financial market factors,
  and technical indicators. The DBN model is compared to five baseline models (ARIMA,
  SVR, LSTM, random forests, and SVMs) and demonstrates significantly better performance
  in predicting price directions for six popular cryptocurrencies (Bitcoin, Binance
  Coin, Ethereum, Litecoin, Ripple, and Tether).
---

# Dynamic Bayesian Networks for Predicting Cryptocurrency Price Directions: Uncovering Causal Relationships

## Quick Facts
- arXiv ID: 2306.08157
- Source URL: https://arxiv.org/abs/2306.08157
- Reference count: 40
- Primary result: Dynamic Bayesian Networks outperform five baselines in predicting cryptocurrency price directions

## Executive Summary
This paper introduces a Dynamic Bayesian Network (DBN) approach to predict cryptocurrency price directions by modeling causal relationships among features like social media data, traditional financial factors, and technical indicators. The DBN model is compared to ARIMA, SVR, LSTM, random forests, and SVMs across six cryptocurrencies, demonstrating significantly better performance. The study also investigates the impact of different feature combinations on prediction accuracy, finding that basic price information combined with technical indicators generally yields the most accurate results.

## Method Summary
The study collects daily price data (OHLCV), technical indicators, social media tweet counts, and macro-financial factors for five cryptocurrencies from Yahoo Finance and bitinfocharts.com. Data is preprocessed with min-max normalization, split into training (67%) and testing (33%) sets, and price movements are labeled as upward or downward. DBNs are constructed using GeNIe/PySMILE with five-day temporal windows, and their precision is evaluated and compared against ARIMA and SVR baselines.

## Key Results
- DBNs achieve significantly higher precision than ARIMA, SVR, LSTM, random forests, and SVMs in predicting cryptocurrency price directions
- DBNs with OHLCV and technical indicators show slightly higher average precision and are selected twice as the best-performing model
- No single DBN model performs best for all coins, highlighting the need for coin-specific feature selection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DBNs model temporal causal dependencies better than static models through unrolled BN structures and Markovian assumptions
- Mechanism: DBNs encode intra-slice arcs (same time step) and inter-slice arcs (consecutive time steps), factorizing joint probability over time to propagate probabilistic beliefs and incorporate lagged effects
- Core assumption: Markov assumption holdsâ€”today's price direction depends only on the previous 5 days' observations
- Evidence anchors: [abstract] DBN approach uncovers causal relationships among features; [section 3] describes DBN structure with nodes representing random variables at specific points in time
- Break condition: Price dynamics exhibit long-range dependencies beyond the 5-day window

### Mechanism 2
- Claim: Technical indicators improve precision by embedding higher-order patterns that raw price data cannot capture
- Mechanism: Technical indicators compress multi-day price/volume patterns into single metrics (e.g., RSI, MACD) that signal regime changes
- Core assumption: Mathematical transformations preserve causal information about price direction rather than adding noise
- Evidence anchors: [section 4.1] Lists 9 technical indicators providing valuable insights; [results] DBN with OHLCV and technical indicators has slightly higher average precision
- Break condition: Indicator calculations become highly correlated with raw OHLCV or market regime shifts invalidate historical patterns

### Mechanism 3
- Claim: Feature combination tuning is necessary because each altcoin responds differently to external factors
- Mechanism: Study tests four distinct feature groups and observes heterogeneous causal influence structures per coin
- Core assumption: Causal structure learned from training data for one coin is not universally applicable to another coin
- Evidence anchors: [results] No single DBN model performs best for all coins; [section 4.2] describes iterative feature engineering experiments
- Break condition: Feature selection becomes overly narrow, missing rare but impactful causal drivers

## Foundational Learning

- Concept: Conditional Probability Tables (CPTs) in Bayesian Networks
  - Why needed here: DBNs require CPTs to encode probability of each node's state given parent states; understanding learning is key to debugging
  - Quick check question: If a node has two binary parents, how many entries must its CPT contain?

- Concept: Markov Assumption in Time Series Models
  - Why needed here: DBN's inter-slice arcs rely on assumption that current state depends only on fixed number of past states
  - Quick check question: What happens to DBN accuracy if price movements have 10-day lag effect but model uses only 5-day window?

- Concept: Precision as a Classification Metric
  - Why needed here: Paper uses precision to compare models; understanding definition and limitations helps interpret whether DBN is truly better
  - Quick check question: If a model predicts "upward" 100 times and only 70 are correct, what is its precision?

## Architecture Onboarding

- Component map: Data ingestion (Yahoo Finance, BitInfoCharts) -> Feature engineering (normalization, labeling, feature groups) -> Model construction (BN learning, DBN unfolding) -> Training pipeline (PySMILE, GeNIe) -> Baseline comparison (ARIMA, SVR) -> Evaluation (precision metric)
- Critical path: 1) Align and normalize feature data to same timestamps 2) Label price direction based on next-day close price 3) Train DBN per coin using optimal feature group 4) Predict next-day direction via 5-day moving window 5) Compare precision to baselines
- Design tradeoffs: Feature richness vs. overfitting; time window length vs. computational cost; static BN vs. learned structure
- Failure signatures: Consistently low precision across all coins suggests poor feature selection or insufficient training data; high variance between training/test folds indicates overfitting; ARIMA/SVR outperforming DBNs may point to overly complex structure or violated Markov assumptions
- First 3 experiments: 1) Train DBN with only OHLCV on Ethereum, evaluate precision, inspect CPTs for zero probabilities 2) Add technical indicators to Ethereum DBN, re-train, compare precision, check if any indicator node becomes isolated 3) Train DBNs with full feature set on Binance Coin and Litecoin, compare precision, perform ablation by removing one feature group at a time

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of incorporating internal factors, such as blockchain information, into dynamic Bayesian networks for cryptocurrency price direction prediction?
- Basis in paper: [inferred] Paper suggests incorporating internal factors like blockchain information could be a promising research direction to improve DBN accuracy
- Why unresolved: Paper does not investigate impact of internal factors on DBN performance
- What evidence would resolve it: Conducting experiments to compare DBN performance with and without internal factors like blockchain information

### Open Question 2
- Question: How does choice of data frequency (intraday, hourly, daily) affect performance of dynamic Bayesian networks in predicting cryptocurrency price directions?
- Basis in paper: [inferred] Paper mentions using different data frequencies could potentially lead to different results for DBNs' precision
- Why unresolved: Paper only uses intraday price data and does not explore impact of different data frequencies
- What evidence would resolve it: Conducting experiments using different data frequencies (intraday, hourly, daily) and comparing resulting DBN performance

### Open Question 3
- Question: How does combination of expert elicitation with learning dynamic Bayesian networks impact accuracy of cryptocurrency price movement predictions?
- Basis in paper: [inferred] Paper suggests incorporating expert opinions alongside data-driven approaches may reduce inherent subjectivity and dependence on large-scale data
- Why unresolved: Paper does not investigate combination of expert elicitation with learning DBNs
- What evidence would resolve it: Conducting experiments to compare DBN performance with and without expert elicitation

## Limitations
- 5-day sliding window Markov assumption may miss important long-range dependencies in cryptocurrency price dynamics
- Feature selection performed per coin without cross-validation to assess generalization, potentially overfitting to specific training periods
- Technical indicator formulas and parameters not fully specified, making exact replication challenging and introducing variability

## Confidence
- High confidence: Core finding that DBNs outperform ARIMA and SVR baselines for cryptocurrency direction prediction
- Medium confidence: Claim that technical indicators consistently improve DBN performance, shown with some variability across coins
- Medium confidence: Conclusion that feature combinations must be tailored per coin, given observed heterogeneity without formal ablation studies

## Next Checks
1. Test DBN models with varying time window lengths (3-day, 5-day, 7-day) to determine optimal Markov order for capturing cryptocurrency price dependencies
2. Perform ablation studies on technical indicators by systematically removing each indicator from DBN to quantify individual contribution to predictive precision
3. Implement cross-validation across multiple time periods to assess stability and generalization of feature-selected DBN models across different market regimes