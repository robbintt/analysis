---
ver: rpa2
title: 'InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image
  Generation'
arxiv_id: '2309.06380'
source_url: https://arxiv.org/abs/2309.06380
tags:
- flow
- rectified
- diffusion
- distillation
- one-step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel text-conditioned pipeline that leverages
  Rectified Flow to turn Stable Diffusion into an ultra-fast one-step model, achieving
  SD-level image quality. The core of Rectified Flow lies in its reflow procedure,
  which straightens the trajectories of probability flows, refines the coupling between
  noises and images, and facilitates the distillation process with student models.
---

# InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation

## Quick Facts
- arXiv ID: 2309.06380
- Source URL: https://arxiv.org/abs/2309.06380
- Reference count: 40
- Key outcome: Creates first one-step diffusion-based text-to-image generator with Stable Diffusion-level image quality, achieving FID of 23.3 on MS COCO 2017-5k

## Executive Summary
This paper addresses the challenge of creating high-quality one-step text-to-image generation models by proposing InstaFlow, which combines Rectified Flow with knowledge distillation. The core insight is that directly distilling Stable Diffusion to a one-step model fails due to suboptimal coupling between noise and image distributions. By straightening the probability flow trajectories through a reflow procedure, the authors create a more regular mapping that can be effectively distilled. Using an expanded Stacked U-Net architecture, InstaFlow achieves Stable Diffusion-level quality in just 0.09 seconds, outperforming previous state-of-the-art techniques by significant margins.

## Method Summary
The authors propose a two-stage approach: first applying text-conditioned reflow to straighten the probability flow trajectories of Stable Diffusion, then distilling the reflown model to a one-step student model. The reflow procedure iteratively refines the velocity field to reduce transport costs while preserving the terminal distribution. The student model uses either a standard U-Net or an expanded Stacked U-Net architecture and is trained using similarity losses (L2 and LPIPS) to match the teacher's multi-step outputs. The training pipeline involves generating 1.6 million training pairs from the reflown teacher model and performing two-stage optimization with different batch sizes and loss functions.

## Key Results
- Achieves FID of 23.3 on MS COCO 2017-5k, surpassing progressive distillation (37.2 → 23.3)
- With 1.7B parameters Stacked U-Net, improves FID to 22.4
- Generates images in 0.09 seconds with FID of 13.1 on MS COCO 2014-30k
- Outperforms StyleGAN-T (13.9 FID in 0.1s) while being faster
- Training costs only 199 A100 GPU days

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reflow straightens the trajectories of probability flows, reducing transport cost and improving coupling between noise and image distributions.
- Mechanism: The reflow procedure iteratively refines the velocity field such that ODE trajectories become straighter, leading to better coupling with lower convex transport costs.
- Core assumption: Straight ODE trajectories enable accurate simulation with fewer steps, and better coupling facilitates distillation.
- Evidence anchors: Abstract states reflow "straightens the trajectories of probability flows" and section 3.2 explains it "preserves the terminal distribution while straightening the particle trajectories and reducing the transport cost."

### Mechanism 2
- Claim: Distillation from a reflown model is easier than from the original diffusion model because the mapping from noise to image is more regular and smooth.
- Mechanism: Reducing convex transport costs through reflow allows the student model to approximate the teacher's mapping with a single Euler step more effectively.
- Core assumption: Original Stable Diffusion has curved trajectories difficult for one-step models to mimic; reflow makes trajectories straighter and thus easier to approximate.
- Evidence anchors: Abstract notes "Direct distillation of SD leads to complete failure" and section 4.1.2 states reflow "refines the coupling between the noise distribution and the image distribution, and eases the learning process for the student model."

### Mechanism 3
- Claim: Using a larger network (Stacked U-Net) for distillation improves one-step generation quality compared to standard U-Net.
- Mechanism: A larger model has more capacity to capture the complex mapping from noise to image in a single step, especially after reflow has simplified the teacher's trajectory.
- Core assumption: One-step distillation task requires learning a highly nonlinear mapping; more parameters allow better approximation.
- Evidence anchors: Section 4.2 shows Stacked U-Net reduces inference time while keeping parameters unchanged, and table 1 demonstrates FID improvement over standard U-Net.

## Foundational Learning

- Concept: Ordinary Differential Equations (ODEs) and numerical solvers (Euler method)
  - Why needed here: The paper models image generation as simulating an ODE; understanding numerical solvers is crucial for why straighter trajectories help.
  - Quick check question: What happens to the approximation error when using Euler method with fewer steps on a curved versus straight ODE trajectory?

- Concept: Probability Flow ODEs and denoising diffusion models
  - Why needed here: Stable Diffusion is based on a probability flow ODE; understanding its structure is key to why distillation is hard.
  - Quick check question: How does the probability flow ODE in Stable Diffusion relate to the original denoising diffusion process?

- Concept: Knowledge distillation and loss functions (e.g., LPIPS)
  - Why needed here: The paper uses distillation to compress a multi-step model into a one-step model; understanding distillation objectives is essential.
  - Quick check question: Why might LPIPS be preferred over L2 loss when distilling image generation models?

## Architecture Onboarding

- Component map: Text encoder (frozen CLIP ViT-L/14) -> Latent generative model (U-Net/Stacked U-Net) -> Latent decoder (frozen auto-encoder) -> Velocity field v(Zt, t | T) -> ODE solver (Euler method)

- Critical path: 1) Generate training pairs (X0, ODE[vk](X0 | T)) using teacher model, 2) Train student model to minimize similarity loss between its one-step output and teacher's multi-step output, 3) Evaluate FID/CLIP scores on MS COCO

- Design tradeoffs: Network size vs. inference speed (Stacked U-Net improves quality but increases parameters), reflow steps vs. training cost (more steps straighten better but add overhead), guidance scale α (higher α improves alignment but may reduce quality)

- Failure signatures: Blurry or low-quality images indicate poor coupling or insufficient model capacity, high FID with low CLIP score suggests plausible images but poor text alignment, training instability may occur with high learning rates

- First 3 experiments: 1) Train baseline one-step model by directly distilling Stable Diffusion without reflow (expect poor FID), 2) Apply one step of reflow then distill (expect improved FID), 3) Switch to Stacked U-Net and distill from reflown model (expect further FID improvement)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of reflow steps for large-scale text-to-image generation models?
- Basis in paper: The paper mentions that "it is not practical to reflow too many steps due to high computational cost and the accumulation of optimization and statistical error" and that "the trajectories of ODE[vk] becomes nearly (even though not exactly) straight with even one or two steps of reflows."
- Why unresolved: The paper does not provide a systematic study on the optimal number of reflow steps, and the choice seems to be based on empirical observations rather than rigorous analysis.
- What evidence would resolve it: A comprehensive study comparing performance of models with different numbers of reflow steps on large-scale datasets, taking into account both generation quality and computational efficiency.

### Open Question 2
- Question: How does the choice of neural network architecture affect the performance of one-step text-to-image generation models?
- Basis in paper: The paper explores different neural network structures including U-Net and Stacked U-Net, observing that "Stacked U-Net is more powerful than U-Net, which allows it to achieve better one-step performance after distillation."
- Why unresolved: While the paper provides some insights, it does not conduct thorough investigation of various architectures or provide theoretical understanding of why certain architectures perform better.
- What evidence would resolve it: Systematic comparison of different neural network architectures for one-step text-to-image generation, including theoretical analysis of their strengths and weaknesses.

### Open Question 3
- Question: What is the impact of guidance scale on the quality and diversity of generated images in one-step text-to-image models?
- Basis in paper: The paper investigates guidance scale influence and observes that "increasing α from 1.0 to 4.0 increases FID-5k and CLIP score at the same time," indicating trade-off between image quality and semantic alignment.
- Why unresolved: The paper does not provide comprehensive analysis of guidance scale impact on diversity or explore underlying mechanisms governing this trade-off.
- What evidence would resolve it: Detailed study examining effects of guidance scale on both quality and diversity of generated images, along with investigation into theoretical foundations of this trade-off.

### Open Question 4
- Question: How can one-step text-to-image models be effectively fine-tuned for personalization and style transfer?
- Basis in paper: The paper mentions that "by fine-tuning SD with the training objective of diffusion models and LORA, users can customize the pre-trained SD to generate specific contents and styles" but acknowledges that "determining the objective for fine-tuning these one-step models remains a subject that requires further investigation."
- Why unresolved: The paper does not provide concrete approach for fine-tuning one-step models for personalization or style transfer, and challenges associated with adapting training objective are not fully addressed.
- What evidence would resolve it: Proposed method for fine-tuning one-step text-to-image models for personalization and style transfer, along with empirical results demonstrating effectiveness and analysis of challenges involved.

## Limitations

- The method relies heavily on a pre-trained Stable Diffusion model, limiting applicability to settings without such a model available
- The theoretical analysis of why straighter trajectories improve distillation is high-level and could benefit from more rigorous mathematical treatment
- The paper does not thoroughly explore failure cases or provide comprehensive ablation studies on hyperparameter importance

## Confidence

- **High Confidence**: The quantitative improvements in FID scores are well-documented and reproducible, with superiority over progressive distillation clearly demonstrated
- **Medium Confidence**: The theoretical explanation for why reflow improves distillation (straightening trajectories, reducing transport costs) is plausible but relies on idealized assumptions
- **Low Confidence**: The scalability and effectiveness of text-conditioned reflow beyond Stable Diffusion 1.5 framework, and its applicability to other domains, are speculative

## Next Checks

1. **Ablation Study**: Systematically vary the number of reflow steps (0, 1, 2, 3) and measure the impact on FID and visual quality to quantify the marginal benefit of each reflow iteration

2. **Cross-Domain Generalization**: Apply the same methodology to a different pre-trained diffusion model (e.g., from another architecture or trained on a different dataset) to assess the robustness of text-conditioned reflow

3. **Mechanism Probing**: Analyze the velocity fields before and after reflow to measure the actual reduction in trajectory curvature and correlate this with improvements in student model loss curves during distillation