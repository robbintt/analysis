---
ver: rpa2
title: 'FinEntity: Entity-level Sentiment Classification for Financial Texts'
arxiv_id: '2310.12406'
source_url: https://arxiv.org/abs/2310.12406
tags:
- sentiment
- dataset
- financial
- entity
- finentity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FinEntity, the first publicly available dataset
  for entity-level sentiment classification in financial texts. The dataset contains
  2,131 annotated entities with positive, negative, or neutral sentiment labels across
  979 news articles.
---

# FinEntity: Entity-level Sentiment Classification for Financial Texts

## Quick Facts
- arXiv ID: 2310.12406
- Source URL: https://arxiv.org/abs/2310.12406
- Reference count: 11
- Primary result: Introduces FinEntity, the first publicly available dataset for entity-level sentiment classification in financial texts

## Executive Summary
This paper introduces FinEntity, the first publicly available dataset for entity-level sentiment classification in financial texts. The dataset contains 2,131 annotated entities with positive, negative, or neutral sentiment labels across 979 news articles from Reuters. The authors demonstrate that fine-tuned pre-trained language models (PLMs) like BERT and FinBERT outperform zero-shot ChatGPT on this task. A case study monitoring cryptocurrency markets shows that entity-level sentiment models demonstrate stronger correlations with cryptocurrency prices and better forecasting performance compared to traditional sequence-level sentiment models.

## Method Summary
The paper introduces entity-level sentiment classification, where sentiment is labeled for specific financial entities within news articles rather than treating the entire text as a single sentiment unit. The FinEntity dataset uses BILOU annotation scheme to identify entity spans and associates sentiment with each entity. The approach fine-tunes pre-trained language models (BERT, FinBERT) with CRF layers for sequence labeling, evaluating performance using F1-scores on an 80/20 train/test split. The method is compared against zero-shot and few-shot ChatGPT using specific prompting strategies.

## Key Results
- Fine-tuned PLMs (BERT, FinBERT) outperform zero-shot ChatGPT on entity-level sentiment classification
- Entity-level sentiment features show higher correlations with cryptocurrency prices than sequence-level features
- FinBERT-CRF model demonstrates better accuracy in cryptocurrency price prediction compared to models using sequence-level sentiment features

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Entity-level sentiment classification captures nuanced sentiment signals that sequence-level approaches miss
- Mechanism: By labeling individual entities with sentiment rather than treating the entire text as a single sentiment unit, the model can distinguish between positive, negative, and neutral sentiments directed at different entities within the same document
- Core assumption: Financial texts often contain multiple entities with opposing sentiments that would be averaged out in sequence-level approaches
- Evidence anchors: 37.53% of examples contain multiple entities, with 12.50% including entities with opposing sentiments

### Mechanism 2
- Claim: FinBERT-CRF outperforms zero-shot ChatGPT on entity-level sentiment classification
- Mechanism: Fine-tuning domain-specific PLMs on a high-quality, entity-labeled dataset provides better performance than relying on general-purpose generative models without domain adaptation
- Core assumption: Domain-specific fine-tuning on carefully curated datasets yields better performance than zero-shot approaches for specialized tasks
- Evidence anchors: Fine-tuning PLMs exceeds the performance of ChatGPT model

### Mechanism 3
- Claim: Entity-level sentiment features improve cryptocurrency price prediction compared to sequence-level features
- Mechanism: By providing more granular sentiment information specific to each cryptocurrency, entity-level models capture market-relevant signals that sequence-level models dilute
- Core assumption: The sentiment toward individual cryptocurrencies is more predictive of their price movements than the overall sentiment of articles containing multiple cryptocurrencies
- Evidence anchors: Entity-level sentiment exhibits higher correlations than sequence-level sentiment

## Foundational Learning

- Concept: Named Entity Recognition (NER) and BILOU tagging scheme
  - Why needed here: The dataset uses BILOU annotation scheme to identify entity spans, which is fundamental to understanding how entities are labeled
  - Quick check question: What do the letters BILOU stand for in the annotation scheme used in this paper?

- Concept: Fine-tuning vs. zero-shot learning
  - Why needed here: The paper benchmarks fine-tuned PLMs against zero-shot ChatGPT, requiring understanding of these different training approaches
  - Quick check question: What is the key difference between fine-tuning a model on a specific dataset versus using it in zero-shot mode?

- Concept: Sequence labeling tasks and CRF layers
  - Why needed here: The paper uses conditional random fields (CRF) to model token label dependencies in the sequence labeling task
  - Quick check question: Why might adding a CRF layer on top of a PLM's token embeddings improve entity-level sentiment classification performance?

## Architecture Onboarding

- Component map: Reuters news articles -> Entity extraction (BILOU) -> Sentiment labeling -> PLM backbone (BERT/FinBERT) -> CRF layer -> Sentiment classification head -> Evaluation metrics
- Critical path: Dataset annotation → Model fine-tuning → Entity extraction → Sentiment classification → Correlation analysis → Price prediction
- Design tradeoffs: Using FinBERT vs BERT trades general language understanding for domain-specific financial knowledge; adding CRF layers increases computational cost but improves label consistency
- Failure signatures: Poor performance on multi-entity sentences, failure to capture opposing sentiments in the same text, over-reliance on sequence-level context rather than entity-specific context
- First 3 experiments:
  1. Compare BERT vs FinBERT performance on the FinEntity test set to validate domain adaptation benefits
  2. Test the impact of adding CRF layers to both BERT and FinBERT models
  3. Evaluate entity-level vs sequence-level sentiment correlation with cryptocurrency prices using the same underlying model

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FinEntity's entity-level sentiment classification performance transfer to other financial text domains like corporate reports or social media posts?
- Basis in paper: The authors acknowledge that the dataset construction relies on Reuters news and state "We have not extensively investigated the transferability of this news dataset to other financial corpora, such as corporate reports or social media posts."
- Why unresolved: The dataset was constructed from a specific source (Reuters news) and the authors explicitly note this limitation without testing transferability to other financial text domains.

### Open Question 2
- Question: How well does FinEntity's English-language sentiment classification model perform on non-English financial texts?
- Basis in paper: The authors state "Since the dataset is in English, its applicability to non-English financial texts may be limited."
- Why unresolved: The dataset is English-only, and the authors acknowledge potential limitations for non-English texts without conducting cross-language experiments.

### Open Question 3
- Question: What is the optimal prompt design for ChatGPT's few-shot entity-level sentiment classification in financial texts?
- Basis in paper: The authors note that "the results provide important implications that for domain-specific, customized NLP tasks, manually collecting a high-quality dataset, through more labor-intensive, indeed achieves better performance than the current state-of-the-art generative LLM."
- Why unresolved: The paper only uses a fixed prompt structure without exploring prompt optimization or variations in the few-shot learning approach.

## Limitations

- Modest dataset size (2,131 entities) may not fully capture complexity of real-world financial texts
- Evaluation focuses primarily on cryptocurrency price prediction, limiting generalizability to other financial domains
- Limited comparison with more recent large language models or alternative approaches in entity-level financial sentiment classification

## Confidence

**High Confidence** (★★★): The core claim that entity-level sentiment classification is feasible and beneficial for financial texts is well-supported by the experimental results.

**Medium Confidence** (★★): The assertion that entity-level sentiment features improve cryptocurrency price prediction is supported by correlation analysis but may have limited generalizability.

**Low Confidence** (★★): The claim that FinBERT-CRF achieves state-of-the-art performance is limited by the lack of comparison with more recent approaches in the literature.

## Next Checks

1. **Dataset Scale and Diversity Validation**: Expand the FinEntity dataset to include at least 10,000 annotated entities across multiple financial domains (equities, commodities, bonds) and evaluate whether the observed performance gains and correlation improvements persist at scale.

2. **Temporal Robustness Test**: Conduct a temporal validation study by training models on historical data (e.g., 2015-2019) and testing on more recent data (2020-2023) to assess how well the entity-level sentiment models handle evolving financial discourse patterns and emerging entities.

3. **Cross-Modal Comparison**: Implement and evaluate a version of the FinBERT-CRF model using direct instruction fine-tuning rather than sequence labeling, comparing performance with the current approach to determine whether the CRF layer and BILOU tagging scheme are essential components or if simpler architectures could achieve comparable results.