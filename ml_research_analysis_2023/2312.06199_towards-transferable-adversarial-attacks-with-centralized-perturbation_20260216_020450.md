---
ver: rpa2
title: Towards Transferable Adversarial Attacks with Centralized Perturbation
arxiv_id: '2312.06199'
source_url: https://arxiv.org/abs/2312.06199
tags:
- perturbation
- adversarial
- frequency
- quantization
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of improving the transferability
  of adversarial examples by concentrating perturbation in frequency regions that
  are more sensitive to deep neural networks (DNNs). The authors propose a novel approach
  that optimizes adversarial perturbation in the frequency domain, using a dynamic
  quantization process to centralize perturbation towards dominant frequency coefficients.
---

# Towards Transferable Adversarial Attacks with Centralized Perturbation

## Quick Facts
- arXiv ID: 2312.06199
- Source URL: https://arxiv.org/abs/2312.06199
- Reference count: 18
- One-line primary result: Frequency-domain adversarial attacks with dynamic quantization achieve 11.7% higher transferability than baseline attacks

## Executive Summary
This paper addresses the challenge of improving adversarial attack transferability by concentrating perturbation in frequency regions that are more sensitive to deep neural networks. The authors propose a novel approach that optimizes adversarial perturbation in the frequency domain using dynamic quantization to centralize perturbation towards dominant frequency coefficients. The method is integrated into existing gradient-based attacks and demonstrates significant improvements in fooling rates against black-box models and adversarial defenses.

## Method Summary
The proposed method implements a systematic pipeline that includes frequency decomposition using DCT, centralized perturbation optimization through quantization matrices, and differential quantization matrix optimization via backpropagation. The approach transforms images into frequency coefficients, applies dynamic quantization to concentrate perturbation in sensitive frequency regions, and updates the quantization matrix per iteration to align with model predictions. This centralized perturbation strategy is integrated as a plug-and-play module with existing gradient-based attacks.

## Key Results
- Achieves 11.7% average improvement in transferability compared to baseline attacks
- Demonstrates effectiveness against filter-based defenses and adversarial training with up to 20% improvement in fooling rates
- Ablation studies confirm the importance of dynamic quantization and frequency centralization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Centralizing perturbation in dominant frequency regions improves transferability by reducing overfitting to the source model.
- Mechanism: Dynamic quantization concentrates perturbation in frequency coefficients shared across models, avoiding model-specific noise.
- Core assumption: DNNs share sensitivity patterns across frequency regions.
- Evidence anchors: [abstract], [section 3.3], [corpus] with average neighbor FMR=0.444
- Break condition: If DNNs don't share frequency sensitivity patterns across models.

### Mechanism 2
- Claim: Dynamic optimization of the quantization matrix ensures alignment with model prediction at each iteration.
- Mechanism: Quantization matrix updated via backpropagation to reflect frequency coefficient importance to source model predictions.
- Core assumption: Source model's gradient can guide quantization matrix optimization.
- Evidence anchors: [section 3.4], [section 3.5], [corpus] with related frequency-aware strategies
- Break condition: If gradient signal becomes too noisy or quantization optimization fails to converge.

### Mechanism 3
- Claim: Frequency decomposition via DCT enables lossless transformation and manipulation of perturbation in frequency domain.
- Mechanism: DCT transforms images to frequency coefficients for precise control over perturbation components.
- Core assumption: DCT provides lossless transformation without information loss.
- Evidence anchors: [section 3.2], [section 3.3], [corpus] with previous frequency domain works
- Break condition: If DCT/IDCT introduces numerical instability or excessive quantization information loss.

## Foundational Learning

- Concept: Frequency domain analysis and DCT (Discrete Cosine Transform)
  - Why needed here: Enables transformation of images into frequency coefficients for identifying sensitive regions
  - Quick check question: What is the primary advantage of using DCT over DFT for image compression and frequency analysis?

- Concept: Adversarial attack transferability and black-box threat models
  - Why needed here: Goal is to improve cross-model transferability essential for practical black-box attacks
  - Quick check question: Why is transferability a key concern in adversarial attacks, and how does overfitting to the source model reduce it?

- Concept: Gradient-based optimization and backpropagation
  - Why needed here: Quantization matrix optimized via backpropagation to align with model predictions
  - Quick check question: How does the Adam optimizer contribute to updating the quantization matrix in this context?

## Architecture Onboarding

- Component map: RGB -> YCbCr -> DCT -> blockify -> quantization -> inverse operations -> model prediction -> quantization matrix update
- Critical path: Gradient-based attack → frequency decomposition → quantization → inverse transform → model prediction → quantization matrix update
- Design tradeoffs:
  - Spatial vs. frequency domain perturbation: Frequency domain offers precise control but requires additional computation
  - Fixed vs. dynamic quantization: Dynamic quantization adapts to model sensitivity but adds optimization complexity
  - Luma vs. chroma channel allocation: More luma quantization improves effectiveness but may increase perceptibility
- Failure signatures:
  - Poor transferability: Indicates quantization matrix not aligned with shared frequency sensitivity
  - Vanishing gradients: Suggests quantization matrix optimization is unstable
  - Perceptual artifacts: Implies excessive perturbation in visually sensitive regions
- First 3 experiments:
  1. Compare transferability with fixed vs. dynamic quantization matrices on small dataset
  2. Ablation study: Remove quantization matrix optimization and measure impact on transferability
  3. Test robustness against JPEG compression and bit-depth reduction defenses

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method's performance scale with different network architectures beyond those tested?
- Basis in paper: [explicit] The paper mentions the need for further exploration of defending centralized perturbation under a frequency context.
- Why unresolved: Only tests on limited set of network architectures; unclear how method performs on more diverse or novel architectures.
- What evidence would resolve it: Experiments on broader range of network architectures including newer and more diverse models.

### Open Question 2
- Question: What is the impact of varying the quantization ratio allocation strategy on adversarial effectiveness?
- Basis in paper: [explicit] Paper discusses rationale for chosen quantization ratios and presents preliminary evaluation.
- Why unresolved: Only provides preliminary evaluation of quantization ratio impact; thorough investigation needed for optimal strategy.
- What evidence would resolve it: Systematic study varying quantization ratios and evaluating impact on adversarial effectiveness across different scenarios.

### Open Question 3
- Question: How does the proposed method compare to other frequency-based adversarial attack methods in terms of transferability and defense evasion?
- Basis in paper: [explicit] Paper mentions previous work attempts low-frequency perturbation with fixed frequency constraint but lacks direct comparison.
- Why unresolved: Paper doesn't include comparison with other frequency-based adversarial attack methods.
- What evidence would resolve it: Comprehensive comparison with other frequency-based methods including transferability and defense evasion capabilities.

### Open Question 4
- Question: What are the implications of the proposed method for defending against adversarial attacks?
- Basis in paper: [explicit] Paper mentions implications prompt further exploration of defending centralized perturbation under frequency context.
- Why unresolved: Paper doesn't provide insights into potential defensive strategies against the proposed method.
- What evidence would resolve it: Research into defensive strategies that can effectively mitigate centralized perturbation in frequency domain.

## Limitations
- Effectiveness relies heavily on assumption that DNNs share common frequency sensitivity patterns
- Additional computational overhead from frequency decomposition and quantization matrix optimization may limit real-time deployment
- Method's performance across diverse architectures and tasks remains to be thoroughly validated

## Confidence

**Confidence Labels:**
- Mechanism 1 (Frequency centralization improves transferability): High - supported by strong experimental results and ablation studies
- Mechanism 2 (Dynamic quantization matrix optimization): Medium - theoretically sound but sensitive to implementation details
- Mechanism 3 (DCT-based frequency decomposition): High - well-established technique with proven effectiveness

## Next Checks
1. Test transferability across diverse model architectures (including vision transformers) to verify shared frequency sensitivity patterns
2. Evaluate computational overhead impact on real-time adversarial attack scenarios, measuring speed-accuracy tradeoffs
3. Conduct robustness analysis against adaptive defenses that specifically target frequency-based attacks