---
ver: rpa2
title: 'Thrust: Adaptively Propels Large Language Models with External Knowledge'
arxiv_id: '2307.10442'
source_url: https://arxiv.org/abs/2307.10442
tags:
- knowledge
- external
- uni00000003
- thrust
- uni00000013
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of using external knowledge
  with large language models (LLMs) efficiently. The key issue is that retrieving
  external knowledge for every query can be costly and may introduce noise, while
  LLMs often have sufficient internal knowledge to answer queries directly.
---

# Thrust: Adaptively Propels Large Language Models with External Knowledge

## Quick Facts
- arXiv ID: 2307.10442
- Source URL: https://arxiv.org/abs/2307.10442
- Reference count: 40
- 26% average performance improvement on 88% of evaluated tasks

## Executive Summary
This paper addresses the challenge of efficiently using external knowledge with large language models (LLMs) by proposing Thrust, a method that measures the knowledgeability of an LLM for a given query. Thrust uses clustering in the PTLM's representation space to determine whether a query requires external knowledge retrieval. The authors introduce IAPEK (Instance-level Adaptive Propulsion of External Knowledge), which selectively retrieves external knowledge only when the PTLM's internal knowledge is insufficient, achieving significant cost-efficiency improvements over naive external knowledge usage.

## Method Summary
The method measures a PTLM's knowledgeability using Thrust, which computes distances between query representations and clusters of task samples in the model's hidden state space. For each task, the algorithm creates K-means clusters from ~200 task samples, then calculates a weighted average distance from each query to these cluster centroids. If the Thrust score falls below a threshold λ, external knowledge is retrieved via DPR and used to augment the model's response. The approach includes fine-tuning on knowledge-augmented data to help models learn effective knowledge utilization patterns.

## Key Results
- IAPEK with Thrust achieves 26% average performance improvement on 88% of evaluated tasks
- Only requires ~200 samples to construct representative clusters for knowledgeability measurement
- Demonstrates significant cost-efficiency compared to naive external knowledge usage
- Effective across diverse NLP tasks including multiple-choice classification and open-domain QA

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Thrust measures knowledgeability by clustering instances in PTLM's representation space and scoring queries based on their distance to these clusters.
- Mechanism: The algorithm computes centroids for clusters of instance representations per class, then measures the weighted average distance from a query to these centroids. Queries close to existing clusters score high (sufficient knowledge), while distant queries score low (need external knowledge).
- Core assumption: If a PTLM has mastered knowledge about a task, its hidden states can cluster samples from that task well enough, with samples from different classes well separated.
- Evidence anchors:
  - [abstract] "we propose measuring whether a PTLM contains enough knowledge to solve an instance with a novel metric, Thrust, which leverages the representation distribution of a small number of seen instances."
  - [section] "we design a simple and lightweight metric Thrust to measure the distance between an instance's representation and the clusters of several observed examples in the same task."
- Break condition: If the PTLM cannot cluster task samples well in its hidden states (poor representational power), the unit vector averaging in Thrust would diminish, making it ineffective as a knowledgeability measure.

### Mechanism 2
- Claim: IAPEK achieves cost-efficiency by selectively retrieving external knowledge only when the Thrust score falls below a threshold.
- Mechanism: For each query, Thrust scores knowledgeability. If score < threshold λ, external knowledge is retrieved and used; otherwise, the query is answered using internal PTLM knowledge alone.
- Core assumption: External knowledge retrieval is costly and can introduce noise, so it should only be used when the PTLM's internal knowledge is insufficient.
- Evidence anchors:
  - [abstract] "we only conduct the retrieval when necessary... we can achieve significantly higher cost-efficiency with Thrust score as the retrieval indicator than the naive usage of external knowledge on 88% of the evaluated tasks with 26% average performance improvement."
  - [section] "we propose the instance-level adaptive propulsion of external knowledge (IAPEK), where we only conduct the retrieval when necessary."
- Break condition: If the threshold λ is poorly calibrated (too high or too low), the system may either retrieve unnecessarily or miss needed knowledge.

### Mechanism 3
- Claim: Fine-tuning on knowledge-augmented data helps PTLMs learn to utilize external knowledge effectively.
- Mechanism: Models are fine-tuned on examples that include both queries and relevant external knowledge, teaching them to incorporate this knowledge during inference.
- Core assumption: Simply having a large PTLM is insufficient; models need explicit training on how to use external knowledge.
- Evidence anchors:
  - [section] "we can observe that models achieve better performance than vanilla T5 models... UnifiedQA models achieve significant improvement for utilizing external knowledge compared to the zero-shot models."
  - [section] "External knowledge may introduce extra noise if the model does not learn to utilize knowledge, which indicates the importance of instructing PTLMs to learn how to use knowledge through second-stage fine-tuning."
- Break condition: If fine-tuning data doesn't represent the distribution of knowledge needs well, the model may not learn effective utilization patterns.

## Foundational Learning

- Concept: Representation learning and clustering in neural networks
  - Why needed here: Thrust fundamentally relies on the PTLM's ability to create meaningful clusters in representation space that correspond to task structure
  - Quick check question: Can you explain why k-means clustering on hidden states might capture task-relevant structure in a pre-trained model?

- Concept: Knowledge-intensive NLP tasks and retrieval augmentation
  - Why needed here: Understanding the motivation for retrieval augmentation and the trade-offs between internal knowledge and external retrieval
  - Quick check question: What are the key limitations of relying solely on internal knowledge in large language models?

- Concept: Few-shot learning and transfer learning
  - Why needed here: The method only requires ~200 samples to set up clusters, and evaluation includes zero-shot and transfer learning settings
  - Quick check question: How does the approach balance the need for representative samples against computational efficiency?

## Architecture Onboarding

- Component map: PTLM model → Hidden state extraction → Clustering algorithm (k-means) → Thrust score computation → Threshold comparison → Retrieval module (conditional) → Knowledge-augmented inference
- Critical path: Query → PTLM forward pass → Thrust score calculation → Threshold comparison → (Conditional) Retrieval → Final answer generation
- Design tradeoffs: 
  - Clustering granularity (K clusters per class) vs. computational overhead
  - Number of samples for clustering (200 in experiments) vs. representativeness
  - Layer selection for hidden states (last layer in experiments) vs. semantic vs. task-specific information
- Failure signatures:
  - Poor clustering indicates the PTLM lacks sufficient knowledge about the task
  - Threshold miscalibration leads to unnecessary retrieval or missed knowledge needs
  - Fine-tuning on unrepresentative data results in poor knowledge utilization
- First 3 experiments:
  1. Verify Thrust score distribution on a simple task (e.g., sentiment analysis) to confirm it separates known from unknown queries
  2. Test IAPEK with varying thresholds (25%, 50%, 75%) on a single task to find optimal balance between retrieval and internal knowledge use
  3. Compare layer-wise Thrust performance on a multi-hop reasoning task to identify best layer for representation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of hidden representation layer affect the performance of Thrust in identifying knowledge-requiring instances?
- Basis in paper: [explicit] The paper conducts layer ablation experiments to examine the effect of using different layers of UnifiedQA-3b decoder for obtaining hidden representations.
- Why unresolved: The paper mentions that for most tasks, the results are not sensitive to the specific layer index, but for some tasks (e.g., StrategyQA), choosing middle layers for representation slightly degrades the performance.
- What evidence would resolve it: Additional experiments across a wider range of tasks and PTLM architectures to determine if there's a consistent pattern in optimal layer selection for Thrust.

### Open Question 2
- Question: Can Thrust be effectively applied to other knowledge-intensive NLP tasks beyond those tested in the paper?
- Basis in paper: [inferred] The paper tests Thrust on multiple-choice classification and open-domain QA tasks, but there's potential for application to other knowledge-intensive tasks.
- Why unresolved: The paper doesn't explore the effectiveness of Thrust on a broader range of knowledge-intensive NLP tasks.
- What evidence would resolve it: Experiments applying Thrust to other knowledge-intensive NLP tasks such as knowledge graph completion, fact verification, or dialogue systems.

### Open Question 3
- Question: How does the size of the initial sample set (D_sample_T) used to construct clusters affect the performance of Thrust?
- Basis in paper: [explicit] The paper mentions that about 200 samples are sufficient in their experiments, but doesn't explore the impact of varying this number.
- Why unresolved: The paper doesn't provide a systematic analysis of how the size of D_sample_T affects Thrust's performance.
- What evidence would resolve it: Experiments varying the size of D_sample_T and measuring its impact on Thrust's effectiveness in different tasks and model sizes.

### Open Question 4
- Question: How does the number of clusters (K) per class in the k-means algorithm affect Thrust's performance?
- Basis in paper: [explicit] The paper mentions that K can be relatively small and provides a formula for choosing K, but doesn't explore the impact of varying K.
- Why unresolved: The paper doesn't provide a systematic analysis of how the number of clusters affects Thrust's performance.
- What evidence would resolve it: Experiments varying the number of clusters (K) and measuring its impact on Thrust's effectiveness in different tasks and model sizes.

## Limitations

- Representation quality dependency: Thrust fundamentally depends on the PTLM's ability to create meaningful clusters in its representation space, which may fail for tasks where the model lacks sufficient knowledge
- Threshold sensitivity: The method requires careful calibration of the knowledge retrieval threshold, with poor settings leading to either excessive costs or knowledge gaps
- External knowledge integration: The exact mechanism for incorporating retrieved knowledge into the model's inference process isn't fully specified, introducing uncertainty about the interaction between internal and external knowledge

## Confidence

- High confidence: The core insight that PTLMs have varying knowledgeability across tasks and that selective external knowledge retrieval can improve cost-efficiency. The empirical results showing 26% average performance improvement on 88% of tasks provide strong evidence for this claim.
- Medium confidence: The specific implementation of Thrust using k-means clustering on hidden representations and the effectiveness of IAPEK with adaptive retrieval. While the method is well-motivated and shows good results, the dependency on PTLM representation quality introduces uncertainty.
- Low confidence: The generalizability of the approach to new domains and tasks without extensive calibration. The method's performance on tasks with different knowledge requirements or data distributions hasn't been thoroughly explored.

## Next Checks

1. **Cross-domain robustness test**: Apply IAPEK with Thrust to a domain significantly different from the evaluated tasks (e.g., medical QA or legal document analysis) to assess how well the knowledgeability measurement generalizes beyond standard NLP benchmarks.

2. **Ablation study on clustering parameters**: Systematically vary the number of samples used for clustering (fewer than 200, more than 200) and the number of clusters per class to quantify the sensitivity of Thrust scores to these hyperparameters and identify optimal configurations.

3. **Failure mode analysis**: Intentionally test on tasks where PTLMs are known to have specific weaknesses (e.g., numerical reasoning, temporal reasoning) to understand when and why Thrust fails to accurately measure knowledgeability, and whether the method can detect its own limitations.