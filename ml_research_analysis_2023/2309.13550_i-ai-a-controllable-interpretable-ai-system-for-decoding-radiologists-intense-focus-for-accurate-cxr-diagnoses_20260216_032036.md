---
ver: rpa2
title: 'I-AI: A Controllable & Interpretable AI System for Decoding Radiologists''
  Intense Focus for Accurate CXR Diagnoses'
arxiv_id: '2309.13550'
source_url: https://arxiv.org/abs/2309.13550
tags:
- heatmap
- image
- radiologist
- gaze
- truth
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The authors propose a controllable and interpretable AI system
  for chest X-ray (CXR) diagnosis that can answer three key questions: where a radiologist
  looks, how long they focus on specific areas, and what findings they diagnose. The
  system uses a vision-language model that takes a CXR image and anatomical prompt
  as inputs and generates radiologist-based attention heatmaps and corresponding labels.'
---

# I-AI: A Controllable & Interpretable AI System for Decoding Radiologists' Intense Focus for Accurate CXR Diagnoses

## Quick Facts
- arXiv ID: 2309.13550
- Source URL: https://arxiv.org/abs/2309.13550
- Reference count: 40
- Key outcome: The authors propose a controllable and interpretable AI system for chest X-ray (CXR) diagnosis that can answer three key questions: where a radiologist looks, how long they focus on specific areas, and what findings they diagnose.

## Executive Summary
The I-AI system introduces a novel approach to chest X-ray diagnosis that addresses the critical need for interpretability in medical AI. By leveraging radiologists' eye gaze data, the system generates attention heatmaps that reveal where clinicians focus their attention during diagnosis. The architecture combines a vision-language model with anatomical prompts to create controllable and interpretable outputs, outperforming state-of-the-art methods in both heatmap generation and classification accuracy.

## Method Summary
The I-AI system uses a BiomedCLIP-based vision-language model that takes CXR images and anatomical prompts as inputs to generate radiologist-based attention heatmaps. The Anatomic-Driven Adapter processes these inputs through a lightweight vision transformer to produce region-specific heatmaps. The system masks irrelevant information before classification, ensuring interpretability. Training uses REFLACX eye gaze data from over 2,500 CXRs, with evaluation metrics including mSSIM, mPSNR, and classification accuracy.

## Key Results
- I-AI outperforms state-of-the-art methods in heatmap generation (mSSIM, mPSNR metrics)
- The system achieves high classification accuracy using only masked CXR portions
- Anatomical prompts effectively guide model attention to relevant regions
- The semi-automatic approach successfully extracts radiologist-based anatomic heatmaps from eye gaze data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The proposed I-AI system achieves interpretability by generating radiologist-based attention heatmaps that align with actual radiologist gaze patterns.
- Mechanism: The system uses an Anatomic-Driven Adapter that takes CXR images and anatomical prompts as inputs, processes them through a vision-language model (BiomedCLIP), and produces attention heatmaps that mimic radiologists' focus intensity and location.
- Core assumption: The eye gaze data from radiologists accurately reflects their diagnostic decision-making process and can be used to train AI systems to replicate this process.
- Evidence anchors:
  - [abstract] "Our approach leverages a vision-language model, allowing for precise control over the interpretation process while ensuring the exclusion of irrelevant features."
  - [section] "Our model takes a CXR image and anatomical prompt as inputs... Our model not only addresses the first question of localization but also captures the radiologists' focus intensity."
- Break condition: If the eye gaze data does not accurately represent diagnostic decision-making, or if the vision-language model cannot properly align visual and textual information, the heatmaps may not accurately represent radiologist focus patterns.

### Mechanism 2
- Claim: The system ensures controllability by using anatomical prompts to guide the model's attention to specific regions of interest.
- Mechanism: The anatomical prompts ("diagnosis of {} left lung", "diagnosis of {} right lung", "diagnosis of {} heart") are used as input to the Anatomic-Driven Adapter, which then generates region-specific attention heatmaps.
- Core assumption: Anatomical prompts can effectively guide the model to focus on relevant regions for specific diagnostic tasks.
- Evidence anchors:
  - [abstract] "To be controllable, our model first employs a short prompt specifying an anatomical part to guide the model's attention."
  - [section] "Our model takes a CXR image and anatomical prompt as inputs. To be controllable, our model first employs a short prompt specifying an anatomical part to guide the model's attention."
- Break condition: If the anatomical prompts are not specific enough or if the model cannot effectively interpret the prompts, the system may not focus on the correct regions.

### Mechanism 3
- Claim: The system improves classification accuracy by masking out irrelevant information before making predictions.
- Mechanism: The predicted attention heatmap is used to mask the input CXR image, highlighting only the relevant regions for classification. This ensures that the classifier does not use erroneous information from irrelevant parts of the image.
- Core assumption: Masking out irrelevant information improves classification accuracy by reducing noise and focusing on relevant features.
- Evidence anchors:
  - [abstract] "Unlike current methods that rely on black-box machine learning models, which can be prone to extracting erroneous information from the entire input image during the diagnosis process, we tackle this issue by effectively masking out irrelevant information."
  - [section] "Once obtaining where and how intense the radiologist gazes, our model eliminates all extraneous information before predicting any abnormal findings, and therefore we ensure that our model cannot exploit erroneous data."
- Break condition: If the masking process removes too much information or if the remaining information is not sufficient for accurate classification, the system's performance may degrade.

## Foundational Learning

- Concept: Vision-Language Models
  - Why needed here: The I-AI system uses a vision-language model (BiomedCLIP) to process both visual (CXR images) and textual (anatomical prompts) information simultaneously.
  - Quick check question: How does the vision-language model align visual and textual features to produce region-specific attention heatmaps?

- Concept: Attention Mechanisms
  - Why needed here: The system uses attention mechanisms to generate heatmaps that represent where radiologists focus their attention on CXR images.
  - Quick check question: How does the Anatomic-Driven Adapter use attention mechanisms to produce intensity-based heatmaps?

- Concept: Semi-supervised Learning
  - Why needed here: The system uses a semi-automatic approach to extract radiologist-based anatomic heatmaps from eye gaze datasets, combining manual annotation with automated processing.
  - Quick check question: How does the semi-automatic approach balance manual annotation effort with automated processing efficiency?

## Architecture Onboarding

- Component map: CXR image + anatomical prompt → BiomedCLIP Visual Encoder → BiomedCLIP Text Encoder → Anatomic-Driven Adapter → Intensity Decoder → Attention heatmap → Masked CXR image → Classifier → Abnormal findings

- Critical path: CXR image → BiomedCLIP Visual Encoder → Anatomic-Driven Adapter → Intensity Decoder → Attention heatmap → Masked CXR image → Classifier → Abnormal findings

- Design tradeoffs:
  - Using anatomical prompts for controllability vs. potentially missing relevant information outside the specified region
  - Masking out irrelevant information for interpretability vs. potentially losing some diagnostic information
  - Using eye gaze data for ground truth vs. potential biases in radiologist gaze patterns

- Failure signatures:
  - Heatmaps not aligning with actual radiologist gaze patterns
  - Classifier performance degrading when using masked images
  - System focusing on irrelevant regions despite anatomical prompts

- First 3 experiments:
  1. Compare heatmap generation performance (mSSIM, mPSNR, mL1, mL2) with and without anatomical prompts
  2. Evaluate classifier accuracy using full CXR images vs. masked CXR images
  3. Assess the impact of different loss functions (L2, Lce, Ldice) on heatmap quality and classifier performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed I-AI system compare to other interpretable AI models in terms of performance and accuracy?
- Basis in paper: [inferred] The authors mention that their proposed I-AI system outperforms state-of-the-art methods in terms of heatmap generation and classification accuracy. However, they do not provide a direct comparison with other interpretable AI models.
- Why unresolved: The paper does not provide a direct comparison between the proposed I-AI system and other interpretable AI models, such as ProtoPNet or PIP-net, in terms of performance and accuracy.
- What evidence would resolve it: Conducting a comprehensive evaluation of the proposed I-AI system against other interpretable AI models, including ProtoPNet and PIP-net, would provide a clear comparison of their performance and accuracy.

### Open Question 2
- Question: How does the semi-automatic approach for extracting radiologist-based anatomic heatmap from eye gaze datasets perform compared to manual annotation by expert radiologists?
- Basis in paper: [explicit] The authors mention that they utilize an eye gaze dataset to extract anatomical gaze information and generate ground truth heatmaps. They also mention that the only category with more than 300 samples after annotating is Cardiomegaly.
- Why unresolved: The paper does not provide a direct comparison between the semi-automatic approach for extracting radiologist-based anatomic heatmap and manual annotation by expert radiologists in terms of accuracy and efficiency.
- What evidence would resolve it: Conducting a study to compare the semi-automatic approach with manual annotation by expert radiologists would provide insights into the accuracy and efficiency of the semi-automatic approach.

### Open Question 3
- Question: How does the proposed I-AI system perform on datasets with different sizes and distributions?
- Basis in paper: [inferred] The authors mention that they split the data into four distinct settings (C, L, R, and M) based on the presence of specific findings. However, they do not provide information on how the proposed I-AI system performs on datasets with different sizes and distributions.
- Why unresolved: The paper does not provide information on the performance of the proposed I-AI system on datasets with different sizes and distributions, which could impact the generalizability of the system.
- What evidence would resolve it: Conducting experiments on datasets with different sizes and distributions would provide insights into the performance and generalizability of the proposed I-AI system.

## Limitations

- The evaluation relies heavily on REFLACX eye-gaze data without independent validation that gaze patterns correlate with diagnostic accuracy
- The semi-automatic extraction of radiologist-based heatmaps could introduce systematic biases if gaze patterns don't accurately represent diagnostic decision-making
- The controlled nature of REFLACX dataset may not generalize to real clinical workflow where radiologists examine multiple images and patient contexts

## Confidence

**High Confidence**: The technical implementation of the Anatomic-Driven Adapter architecture and training procedure appears well-specified with clear loss functions and evaluation metrics. The use of established vision-language models (BiomedCLIP) and transformer architectures follows standard practices.

**Medium Confidence**: Claims about improved interpretability and controllability are supported by quantitative metrics (mSSIM, mPSNR, classification accuracy) but lack qualitative validation through radiologist feedback on whether the generated heatmaps actually improve understanding or clinical utility.

**Low Confidence**: The generalizability of the approach to broader clinical settings and different imaging modalities remains uncertain. The exclusive reliance on REFLACX data, which may not represent typical clinical scenarios, limits external validity.

## Next Checks

1. **Clinical Validation Study**: Conduct a prospective study with practicing radiologists to assess whether I-AI's heatmaps improve diagnostic accuracy, efficiency, or confidence compared to standard CXR interpretation workflows.

2. **Cross-dataset Evaluation**: Test I-AI on additional CXR datasets (e.g., CheXpert, ChestX-ray14) without eye-gaze data to evaluate generalizability and determine if the anatomical prompting approach maintains performance across different data distributions.

3. **Bias Analysis**: Perform a systematic analysis of potential biases in the eye-gaze training data, examining whether certain demographic groups, disease presentations, or anatomical variations are underrepresented in the heatmaps generated by the model.