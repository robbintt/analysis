---
ver: rpa2
title: Extractive Summarization via ChatGPT for Faithful Summary Generation
arxiv_id: '2304.04193'
source_url: https://arxiv.org/abs/2304.04193
tags:
- summarization
- extractive
- arxiv
- chatgpt
- abstractive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a thorough evaluation of ChatGPT\u2019s performance\
  \ on extractive summarization and compares it with traditional fine-tuning methods\
  \ on various benchmark datasets. The experimental analysis reveals that ChatGPT\u2019\
  s extractive summarization performance is still inferior to existing supervised\
  \ systems in terms of ROUGE scores."
---

# Extractive Summarization via ChatGPT for Faithful Summary Generation

## Quick Facts
- arXiv ID: 2304.04193
- Source URL: https://arxiv.org/abs/2304.04193
- Reference count: 5
- Primary result: ChatGPT's extractive summarization performance is inferior to supervised systems but improves with extract-then-generate pipelines for faithfulness

## Executive Summary
This paper presents a comprehensive evaluation of ChatGPT's capabilities for extractive summarization across four benchmark datasets. The study systematically compares ChatGPT's performance with traditional fine-tuning methods using ROUGE and FactCC metrics. While ChatGPT demonstrates impressive comprehension abilities, its extractive summarization performance remains inferior to supervised systems. The research explores in-context learning and chain-of-thought reasoning approaches, finding that these techniques improve performance on some datasets but not others. Most notably, the study reveals that applying an extract-then-generate pipeline significantly enhances summary faithfulness compared to abstractive baselines.

## Method Summary
The study evaluates ChatGPT's extractive summarization performance across four benchmark datasets (CNN/DM, XSum, PubMed, Reddit) using various prompt configurations including extractive, abstractive, in-context, and explanation-based prompts. The researchers compare ChatGPT's performance with traditional fine-tuning methods using ROUGE scores (R1, R2, RL) for quality and FactCC scores for faithfulness. They systematically explore in-context learning and chain-of-thought reasoning approaches to enhance performance, and investigate an extract-then-generate pipeline that first extracts salient sentences before generating summaries.

## Key Results
- ChatGPT's extractive summarization performance is inferior to existing supervised systems in terms of ROUGE scores
- In-context learning improves model performance on CNN/DM but is less effective on abstractive datasets like XSum
- The extract-then-generate pipeline with ChatGPT yields significant performance improvements over abstractive baselines in terms of summary faithfulness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: In-context learning improves ChatGPT's extractive summarization performance by exposing the model to patterns of sentence selection
- Mechanism: Providing input-output pairs or document-summary-reason triads in prompts allows the model to infer the underlying selection criteria and replicate them on new inputs
- Core assumption: The model can generalize the selection logic from a few examples to unseen documents
- Evidence anchors:
  - [abstract]: "we explore the effectiveness of in-context learning and chain-of-thought reasoning for enhancing its performance."
  - [section]: "The results indicate that in-context learning improves model performance in the extractive dataset CNN/DM, but is less effective in the abstractive dataset XSum."
  - [corpus]: "Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs" suggests in-context learning is actively explored for LLMs in extractive summarization

### Mechanism 2
- Claim: The extract-then-generate pipeline improves summary faithfulness by grounding abstractive generation on extracted sentences
- Mechanism: First, the model extracts salient sentences from the source document. Then, it generates a summary guided by these extracted sentences, reducing the likelihood of hallucination
- Core assumption: Extracted sentences are faithful to the original document and can serve as reliable anchors for abstractive generation
- Evidence anchors:
  - [abstract]: "we find that applying an extract-then-generate pipeline with ChatGPT yields significant performance improvements over abstractive baselines in terms of summary faithfulness."
  - [section]: "The results demonstrate that the performance of ChatGPT generally improves largely in terms of ROUGE scores when grounded with the ORACLE summaries."
  - [corpus]: "APIDocBooster: An Extract-Then-Abstract Framework Leveraging Large Language Models for Augmenting API Documentation" validates the extract-then-generate framework in another context

### Mechanism 3
- Claim: ChatGPT's decoder-only architecture does not significantly degrade its comprehension ability compared to encoder-decoder models for extractive summarization
- Mechanism: Despite being a decoder-only model, ChatGPT can effectively understand the problem formulation and semantic meanings of sentences, allowing it to perform extractive summarization
- Core assumption: The model's pre-training on vast amounts of text data enables it to comprehend the semantic meanings of sentences and identify salient information
- Evidence anchors:
  - [abstract]: "ChatGPT achieves impressive results in extractive summarization, which requires comprehension of the problem formulation and semantic meanings of sentences."
  - [section]: "It is also observed that Ext-GPT outperforms Abs-GPT in two extractive datasets CNN/DM and PubMed while performing worse in the other two abstractive datasets."
  - [corpus]: "Exploring the Limits of ChatGPT for Query or Aspect-based Text Summarization" suggests ChatGPT can handle various summarization tasks, including extractive ones

## Foundational Learning

- Concept: In-context learning
  - Why needed here: To enable ChatGPT to perform extractive summarization without fine-tuning on specific datasets
  - Quick check question: Can you explain how providing input-output pairs in prompts helps the model learn the task?

- Concept: Chain-of-thought reasoning
  - Why needed here: To improve the model's understanding of the selection criteria and enhance its performance in extractive summarization
  - Quick check question: How does including explanations in prompts benefit the model's comprehension of the task?

- Concept: Extractive summarization formulation
  - Why needed here: To understand the problem formulation and semantic meanings of sentences, which are crucial for extractive summarization
  - Quick check question: What is the difference between extractive and abstractive summarization, and why is extractive summarization considered more faithful?

## Architecture Onboarding

- Component map: ChatGPT (decoder-only LLM) -> Prompt configurations (extractive, abstractive, in-context, explanation, extract-abstract) -> Summarization task execution
- Critical path: Select prompt configuration → Process input document → Generate summary → Evaluate using ROUGE and FactCC scores
- Design tradeoffs: Extractive summarization prioritizes faithfulness over flexibility, while abstractive summarization offers flexibility but risks hallucination
- Failure signatures: Poor ROUGE scores, hallucinations in abstractive summaries, inconsistent performance across datasets or document lengths
- First 3 experiments:
  1. Evaluate ChatGPT's performance on extractive summarization using various prompt configurations and compare results with traditional fine-tuning methods
  2. Investigate the effectiveness of in-context learning and chain-of-thought reasoning for enhancing ChatGPT's extractive summarization
  3. Explore the extract-then-generate pipeline and assess its impact on summary faithfulness compared to abstractive baselines

## Open Questions the Paper Calls Out

- Question: How does the performance of ChatGPT's extractive summarization compare to other large language models, such as GPT-3, in terms of ROUGE scores?
  - Basis in paper: [explicit] The paper mentions that a previous study by Goyal et al. (2022) compared GPT-3-generated summaries with traditional fine-tuning methods and found that while the former obtained slightly lower Rouge scores, human evaluators preferred them. The paper also states that ChatGPT exhibits inferior extractive summarization performance in terms of ROUGE scores compared to existing supervised systems.
  - Why unresolved: The paper does not provide a direct comparison between ChatGPT and other large language models like GPT-3 in terms of ROUGE scores for extractive summarization.
  - What evidence would resolve it: A direct comparison of ROUGE scores between ChatGPT and other large language models, such as GPT-3, for extractive summarization on the same benchmark datasets.

- Question: How does the extract-then-generate pipeline with ChatGPT affect the faithfulness of generated summaries across different domains and dataset sizes?
  - Basis in paper: [explicit] The paper mentions that applying an extract-then-generate pipeline with ChatGPT yields significant performance improvements over abstractive baselines in terms of summary faithfulness. However, the study only provides results for a limited number of datasets and does not explore the impact of different domains and dataset sizes.
  - Why unresolved: The paper does not investigate the effectiveness of the extract-then-generate pipeline with ChatGPT across various domains and dataset sizes.
  - What evidence would resolve it: An analysis of the extract-then-generate pipeline with ChatGPT for summary faithfulness across different domains and dataset sizes, using a diverse set of benchmark datasets.

- Question: What are the limitations of using ROUGE scores as a reliable evaluation metric for text summarization tasks, and how can these limitations be addressed?
  - Basis in paper: [explicit] The paper highlights the limitations of ROUGE scores as a reliable evaluation metric for text summarization tasks, stating that the results are consistent with the previous conclusion in Goyal et al. (2022) and Zhang et al. (2023), where lower Rouge scores were observed for large language model-generated summaries, but human evaluators preferred them.
  - Why unresolved: The paper does not provide a detailed discussion on the limitations of ROUGE scores and potential alternative evaluation metrics for text summarization tasks.
  - What evidence would resolve it: A comprehensive analysis of the limitations of ROUGE scores for text summarization tasks, along with a comparison of alternative evaluation metrics, such as human evaluations, factuality measures, and other automated metrics.

## Limitations

- ChatGPT's extractive summarization performance remains inferior to supervised systems despite showing comprehension abilities
- In-context learning shows inconsistent effectiveness across different dataset types, particularly struggling with abstractive datasets
- The study is limited to four benchmark datasets and doesn't explore the extract-then-generate pipeline across diverse domains and dataset sizes

## Confidence

- High Confidence: ChatGPT's extractive summarization performance is inferior to supervised systems (well-supported by experimental results across multiple datasets)
- Medium Confidence: In-context learning effectiveness varies by dataset type (supported by CNN/DM results but inconsistent on other datasets)
- Medium Confidence: Extract-then-generate pipeline significantly improves faithfulness (supported by ROUGE score improvements, though underlying reasons need further exploration)

## Next Checks

1. **Dataset Diversity Validation**: Test the in-context learning approach across a broader range of document types and domains to better understand its limitations and potential domain-specific requirements.

2. **Prompt Engineering Analysis**: Systematically vary the prompt structures and in-context examples to identify optimal configurations for different types of summarization tasks and document lengths.

3. **Faithfulness Evaluation Extension**: Complement ROUGE and FactCC scores with human evaluation studies to better understand the practical implications of the extract-then-generate pipeline on summary quality and user perception.