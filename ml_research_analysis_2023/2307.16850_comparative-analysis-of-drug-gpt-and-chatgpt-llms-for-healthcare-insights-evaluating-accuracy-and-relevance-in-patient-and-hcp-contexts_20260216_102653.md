---
ver: rpa2
title: 'Comparative Analysis of Drug-GPT and ChatGPT LLMs for Healthcare Insights:
  Evaluating Accuracy and Relevance in Patient and HCP Contexts'
arxiv_id: '2307.16850'
source_url: https://arxiv.org/abs/2307.16850
tags:
- diabetes
- drug-gpt
- chatgpt
- more
- answers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study compares three GPT models\u2014Drug-GPT 3, Drug-GPT\
  \ 4, and ChatGPT\u2014in healthcare contexts. Drug-GPT models, trained on curated\
  \ patient and HCP social media data, provide more targeted and in-depth insights\
  \ into patient challenges with atopic dermatitis and HCP discussions on diabetes."
---

# Comparative Analysis of Drug-GPT and ChatGPT LLMs for Healthcare Insights: Evaluating Accuracy and Relevance in Patient and HCP Contexts

## Quick Facts
- **arXiv ID**: 2307.16850
- **Source URL**: https://arxiv.org/abs/2307.16850
- **Reference count**: 40
- **Key outcome**: Drug-GPT models provide more targeted and in-depth healthcare insights than ChatGPT due to specialized training on curated patient and HCP social media data.

## Executive Summary
This study compares three GPT models—Drug-GPT 3, Drug-GPT 4, and ChatGPT—in healthcare contexts. Drug-GPT models, trained on curated patient and HCP social media data, provide more targeted and in-depth insights into patient challenges with atopic dermatitis and HCP discussions on diabetes. ChatGPT, a general-purpose model, generates broader responses but lacks the depth and currency of Drug-GPT. All models produce accurate information, but Drug-GPT's specialized training yields more relevant and context-rich answers. The study highlights the importance of using domain-specific models for healthcare applications to ensure accuracy, relevance, and up-to-date information.

## Method Summary
The study compares Drug-GPT 3, Drug-GPT 4, and ChatGPT in healthcare contexts. Drug-GPT models are trained on curated datasets of patient and HCP social media posts, while ChatGPT uses general pre-training data. The researchers set Temperature to 0 and Top P to 1 for deterministic outputs. They evaluate model responses to specific prompts related to patient challenges with atopic dermatitis and HCP discussions on diabetes, assessing accuracy, relevance, depth, and currency.

## Key Results
- Drug-GPT models provide more targeted and in-depth insights than ChatGPT for healthcare Q&A
- Drug-GPT responses are more informal and accessible to laypeople compared to ChatGPT
- ChatGPT's knowledge is outdated by 2-3 years, while Drug-GPT can access more current information

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-specific LLMs trained on curated patient and HCP datasets provide more targeted and in-depth insights than general-purpose models for healthcare Q&A.
- Mechanism: The specialized models retrieve responses directly from curated datasets of real-world patient and HCP experiences, rather than generating answers from general knowledge bases.
- Core assumption: Curated datasets of patient and HCP experiences contain more relevant, specific, and actionable information for healthcare applications than the general training data of models like ChatGPT.
- Evidence anchors:
  - [abstract] "Drug-GPT models, trained on curated patient and HCP social media data, provide more targeted and in-depth insights"
  - [section] "Drug-GPT™'s knowledge encompasses a broader scope compared to GPT-3, GPT-4, or ChatGPT"
  - [corpus] Found 25 related papers with average neighbor FMR=0.498, suggesting moderate relatedness to the topic
- Break condition: If the curated datasets become outdated or do not cover emerging healthcare topics, the specialized models may lose their advantage over general-purpose models.

### Mechanism 2
- Claim: Setting Temperature to 0 and Top P to 1 ensures reproducible and deterministic responses from the LLM.
- Mechanism: These hyperparameters constrain the model to always select the most probable next token, eliminating randomness in the output.
- Core assumption: In healthcare applications, consistency and reproducibility of responses are more important than creativity or diversity of answers.
- Evidence anchors:
  - [section] "For this purpose, we set the Temperature parameter to 0, thereby ensuring that the model generates the most confident answers without any randomness"
  - [section] "This approach facilitates a deterministic and consistent output for a given question"
  - [corpus] No direct evidence found in corpus, but this is a well-established technique in LLM applications
- Break condition: If the most probable answer is not always the most accurate or relevant, this deterministic approach may lead to suboptimal responses.

### Mechanism 3
- Claim: Specialized models like Drug-GPT can access more up-to-date information than general-purpose models like ChatGPT.
- Mechanism: Drug-GPT's knowledge base is continuously updated with recent patient and HCP social media posts, while ChatGPT's knowledge is fixed at its training cutoff.
- Core assumption: Social media posts from patients and HCPs provide timely and relevant insights into current healthcare trends and challenges.
- Evidence anchors:
  - [section] "Drug-GPT™'s responses were noticeably more informal and accessible to laypeople in nature"
  - [section] "With respect to currency, it is important to note that ChatGPT's answers are outdated by 2 or 3 years"
  - [corpus] No direct evidence found in corpus, but this is implied by the study's focus on recent social media data
- Break condition: If social media data becomes less representative of actual patient and HCP experiences, or if privacy concerns limit access to such data, this advantage may diminish.

## Foundational Learning

- Concept: Large Language Models (LLMs) and their applications in healthcare
  - Why needed here: Understanding the basics of LLMs and their potential uses in healthcare is crucial for comprehending the study's context and significance.
  - Quick check question: What are some potential applications of LLMs in healthcare, as mentioned in the introduction?
    - Answer: Supporting clinical decision making, facilitating drug discovery and development, and aiding medical translation

- Concept: Domain-specific vs. general-purpose language models
  - Why needed here: The study compares specialized healthcare models with a general-purpose model, highlighting the importance of domain-specific knowledge.
  - Quick check question: According to the background section, what is one key difference between specialized and general-purpose models in healthcare applications?
    - Answer: Specialized models trained on biomedical datasets are more reliable for critical clinical applications than general models like ChatGPT

- Concept: Hyperparameter tuning in LLM applications
  - Why needed here: The study emphasizes the importance of setting specific hyperparameters to ensure reproducible and accurate responses.
  - Quick check question: What hyperparameters were set to 0 and 1, respectively, to achieve deterministic output in the experiments?
    - Answer: Temperature was set to 0, and Top P was set to 1

## Architecture Onboarding

- Component map:
  Curated datasets of patient and HCP social media posts -> Information retrieval system -> GPT-3 or GPT-4 LLM -> Hyperparameter configuration (Temperature=0, Top P=1) -> Prompt engineering

- Critical path:
  1. Receive prompt related to healthcare topic
  2. Retrieve relevant content from curated datasets
  3. Feed retrieved content and prompt to LLM
  4. Generate response using configured hyperparameters
  5. Return response to user

- Design tradeoffs:
  - Specialized knowledge vs. general applicability
  - Reproducibility vs. creativity in responses
  - Currency of information vs. breadth of coverage

- Failure signatures:
  - Irrelevant or off-topic responses
  - Inconsistent answers to similar questions
  - Outdated information in responses
  - Overly technical language for patient-facing applications

- First 3 experiments:
  1. Compare responses to a patient-focused question on atopic dermatitis between Drug-GPT 3, Drug-GPT 4, and ChatGPT
  2. Compare responses to an HCP-focused question on diabetes themes between Drug-GPT 3, Drug-GPT 4, and ChatGPT
  3. Test the effect of varying the Temperature and Top P hyperparameters on response quality and consistency

## Open Questions the Paper Calls Out
None explicitly stated in the provided content.

## Limitations
- The study relies on qualitative comparisons of model responses rather than quantitative metrics
- The curated datasets used for training Drug-GPT models are not described in detail, raising questions about their representativeness and potential biases
- The study does not address potential privacy concerns related to using patient social media data for model training

## Confidence
- **High confidence**: Drug-GPT models provide more targeted and in-depth insights than ChatGPT for healthcare Q&A
- **Medium confidence**: Setting Temperature to 0 and Top P to 1 ensures reproducible and deterministic responses
- **Medium confidence**: Specialized models can access more up-to-date information than general-purpose models

## Next Checks
1. Conduct a quantitative comparison of response accuracy, relevance, and depth between Drug-GPT models and ChatGPT using standardized metrics and human evaluation
2. Analyze the composition, size, and potential biases of the curated datasets used to train Drug-GPT models to assess their representativeness and generalizability
3. Investigate the privacy implications and ethical considerations of using patient social media data for training specialized healthcare models