---
ver: rpa2
title: 'Dendrogram distance: an evaluation metric for generative networks using hierarchical
  clustering'
arxiv_id: '2311.16894'
source_url: https://arxiv.org/abs/2311.16894
tags:
- modes
- number
- distance
- data
- dendrogram
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Dendrogram Distance (DD), a new evaluation
  metric for generative networks that uses hierarchical clustering and dendrograms
  to measure divergence between real and generated data distributions. The metric
  is designed to detect mode collapse by comparing the hierarchical structure of clusters
  in both datasets.
---

# Dendrogram distance: an evaluation metric for generative networks using hierarchical clustering

## Quick Facts
- arXiv ID: 2311.16894
- Source URL: https://arxiv.org/abs/2311.16894
- Reference count: 8
- Primary result: Dendrogram Distance (DD) is a new evaluation metric that uses hierarchical clustering to detect mode collapse in generative models, showing better stability than FID with perturbed mode positions

## Executive Summary
This paper introduces the Dendrogram Distance (DD), a novel evaluation metric for generative networks that leverages hierarchical clustering and dendrograms to measure divergence between real and generated data distributions. The metric is specifically designed to detect mode collapse by comparing the hierarchical structure of clusters in both datasets. Through experiments on 2D benchmarks (Grid and Ring datasets) and image datasets (MNIST, CIFAR-10, STL-10, CelebA), the authors demonstrate that DD is more stable than FID when dealing with perturbed mode positions, shows lower variance, and provides better sensitivity to mode collapse detection.

## Method Summary
The Dendrogram Distance metric works by performing hierarchical clustering on both real and generated datasets using a single-linkage algorithm, then computing the average absolute difference between sorted agglomerative distances extracted from the resulting dendrograms. The method assumes that if generated data is similar to real data, their clustering structures should also be similar. The metric can be applied in pixel space or using CNN embeddings, and experiments show it successfully detects mode collapse while serving as a proxy for model convergence during training.

## Key Results
- DD demonstrates superior stability compared to FID when mode positions are perturbed in 2D benchmarks
- The metric successfully detects mode collapse across multiple image datasets using both pixel space and CNN embeddings
- DD serves as an effective proxy for monitoring model convergence during GAN training
- Lower variance in DD scores indicates more reliable evaluation compared to existing metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dendrogram Distance (DD) detects mode collapse by comparing hierarchical cluster structures between real and generated data
- Mechanism: The metric builds dendrograms using agglomerative hierarchical clustering on both real and generated datasets, then computes the average absolute difference between sorted agglomerative distances to measure divergence
- Core assumption: Generated data with mode collapse will produce different hierarchical clustering structures compared to real data with all modes present
- Evidence anchors:
  - [abstract] "The metric is designed to detect mode collapse by comparing the hierarchical structure of clusters in both datasets"
  - [section 3.3] "Our approach follows from the natural assumption that if the generated data is similar to the real data, the clustering of their samples must also be similar"
  - [corpus] Weak evidence - corpus focuses on general dendrogram construction but doesn't directly address mode collapse detection
- Break condition: If generated data maintains similar cluster hierarchy despite missing modes, or if distance metric fails to capture structural differences

### Mechanism 2
- Claim: DD provides more stable evaluation than FID when mode positions are perturbed
- Mechanism: By using ultrametric space equivalence and sorted agglomerative distances, DD captures relative distances between clusters rather than absolute positions, making it robust to mode position perturbations
- Core assumption: Hierarchical clustering captures relative spatial relationships that remain meaningful even when absolute positions change
- Evidence anchors:
  - [section 4.1] "Our Dendrogram Distance (DD) can be used as an additional quantitative analysis of models performance on the aforementioned datasets. That is a better alternative because the DD is agnostic to the position of each mode"
  - [section 4.1] "The Dendrogram Distance is more sensitive with respect to the number of modes than the FID"
  - [corpus] No direct evidence - corpus papers focus on dendrogram construction methods rather than stability comparisons
- Break condition: When relative distances between modes are also perturbed, or when clustering algorithm produces unstable results with perturbed data

### Mechanism 3
- Claim: DD can serve as a convergence proxy during GAN training
- Mechanism: As generator quality improves during training, the hierarchical clustering structure of generated samples converges toward the real data structure, causing DD to decrease
- Core assumption: Training dynamics cause gradual improvement in mode coverage that is reflected in clustering structure
- Evidence anchors:
  - [section 4.2.2] "Our results demonstrate that the Dendrogram Distance is able to indicate the generator convergence. The metric correctly follows the quality of the generated samples"
  - [section 4.2.2] "Some fluctuations in the metric are a result of the instability during the training process of GANs, due to the two adversarial objectives"
  - [corpus] No direct evidence - corpus papers don't discuss convergence monitoring with dendrograms
- Break condition: When training instability causes erratic changes in generated sample structure, or when mode collapse occurs late in training

## Foundational Learning

- Concept: Hierarchical clustering and dendrograms
  - Why needed here: The metric fundamentally relies on building and comparing hierarchical cluster structures
  - Quick check question: What property of dendrograms makes them suitable for comparing distributions?

- Concept: Ultrametric spaces and their equivalence to dendrograms
  - Why needed here: The theoretical foundation of DD relies on the equivalence between dendrograms and ultrametric spaces
  - Quick check question: How does the ultrametric distance relate to the agglomerative distance in a dendrogram?

- Concept: Fréchet Inception Distance (FID) and Inception Score (IS)
  - Why needed here: DD is positioned as an alternative to these established metrics, so understanding their limitations is crucial
  - Quick check question: Why might FID fail to detect mode collapse in certain scenarios?

## Architecture Onboarding

- Component map: Input data → Hierarchical clustering → Dendrogram construction → Agglomerative distance extraction → Distance computation between dendrograms → Score output
- Critical path: Data preprocessing → Clustering algorithm execution → Dendrogram alignment → Distance calculation
- Design tradeoffs: Computational cost vs. stability (single-linkage clustering is fast but can be sensitive to noise)
- Failure signatures: High variance in scores across runs, sensitivity to clustering parameters, inability to detect subtle mode differences
- First 3 experiments:
  1. Compare DD scores on real vs. generated data with known mode collapse
  2. Test DD stability with perturbed mode positions using 2D benchmark datasets
  3. Evaluate DD as training convergence monitor on a simple GAN architecture

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Dendrogram Distance (DD) perform on higher-dimensional datasets beyond image data, such as audio or video?
- Basis in paper: [inferred] The paper demonstrates DD's effectiveness on 2D benchmarks and image data, but does not explore its applicability to other high-dimensional data types.
- Why unresolved: The paper focuses primarily on image datasets and does not provide experiments or analysis for other data modalities.
- What evidence would resolve it: Conducting experiments with DD on diverse datasets such as audio spectrograms, video frames, or time-series data to compare its performance against existing metrics like FID and IS.

### Open Question 2
- Question: Can the Dendrogram Distance be effectively used as a training objective for generative models, rather than just an evaluation metric?
- Basis in paper: [explicit] The paper mentions that using DD as a general training objective is beyond the scope but worth investigating in future work.
- Why unresolved: The paper only explores DD as an evaluation metric and does not provide experimental results or theoretical analysis for its use in training.
- What evidence would resolve it: Implementing DD as a loss function in generative models like GANs or VAEs and comparing the convergence, stability, and quality of generated samples against models trained with standard objectives.

### Open Question 3
- Question: How sensitive is the Dendrogram Distance to the choice of clustering algorithm and distance metric used in its computation?
- Basis in paper: [inferred] The paper uses single-linkage clustering and does not explore the impact of alternative clustering methods or distance metrics on DD's performance.
- Why unresolved: The paper does not provide a systematic analysis of how different clustering algorithms (e.g., complete-linkage, average-linkage) or distance metrics (e.g., cosine similarity, Mahalanobis distance) affect DD's stability and sensitivity.
- What evidence would resolve it: Conducting experiments with various clustering algorithms and distance metrics to evaluate their impact on DD's ability to detect mode collapse and convergence in generative models.

### Open Question 4
- Question: What is the computational complexity of the Dendrogram Distance compared to other evaluation metrics like FID and IS, especially for large-scale datasets?
- Basis in paper: [inferred] The paper does not discuss the computational efficiency of DD relative to other metrics, despite its potential for scalability issues with high-dimensional data.
- Why unresolved: The paper focuses on the theoretical and empirical performance of DD but does not address its computational requirements or scalability.
- What evidence would resolve it: Benchmarking the runtime and memory usage of DD against FID and IS on datasets of varying sizes and dimensions to determine its feasibility for large-scale applications.

## Limitations
- Performance heavily depends on choice of distance metric within clustering algorithm
- Computational complexity scales poorly with dataset size due to O(n²) clustering requirements
- Limited validation on complex, high-dimensional datasets beyond standard benchmark images

## Confidence

**High Confidence Claims:**
- DD successfully detects mode collapse in controlled 2D benchmark scenarios
- DD shows lower variance than FID when mode positions are perturbed
- The metric can serve as a convergence proxy during training on tested datasets

**Medium Confidence Claims:**
- DD provides better interpretability compared to existing metrics
- The metric generalizes well across different types of generative models
- DD remains stable across different clustering distance metrics

**Low Confidence Claims:**
- DD maintains effectiveness on datasets significantly larger than those tested
- The metric performs equally well across all types of generative model architectures
- DD is robust to extreme levels of dataset noise

## Next Checks

1. **Cross-Algorithm Validation**: Test DD on multiple clustering algorithms (complete-linkage, average-linkage, Ward's method) to verify robustness beyond single-linkage and identify optimal algorithm choices for different data types.

2. **Noise Sensitivity Analysis**: Systematically evaluate DD's sensitivity to dataset noise levels and dimensionality, comparing performance degradation against FID and IS across synthetic and real datasets.

3. **Mode Collapse Pattern Coverage**: Design targeted experiments with various mode collapse patterns (adjacent modes missing, distant modes missing, partial mode coverage) to determine DD's sensitivity to different failure modes beyond the simple cases presented.