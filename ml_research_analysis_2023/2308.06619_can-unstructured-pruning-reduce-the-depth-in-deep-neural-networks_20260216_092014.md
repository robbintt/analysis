---
ver: rpa2
title: Can Unstructured Pruning Reduce the Depth in Deep Neural Networks?
arxiv_id: '2308.06619'
source_url: https://arxiv.org/abs/2308.06619
tags:
- pruning
- entropy
- neural
- layers
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel Entropy Guided Pruning (EGP) algorithm
  aimed at reducing the size of deep neural networks while preserving their performance.
  The key focus of EGP is to prioritize pruning connections in layers with low entropy,
  ultimately leading to their complete removal.
---

# Can Unstructured Pruning Reduce the Depth in Deep Neural Networks?

## Quick Facts
- arXiv ID: 2308.06619
- Source URL: https://arxiv.org/abs/2308.06619
- Reference count: 27
- This paper introduces Entropy Guided Pruning (EGP), a novel algorithm that prioritizes pruning connections in layers with low entropy, potentially removing entire layers while maintaining model performance.

## Executive Summary
This paper presents a novel Entropy Guided Pruning (EGP) algorithm aimed at reducing the size of deep neural networks while preserving their performance. The key focus of EGP is to prioritize pruning connections in layers with low entropy, ultimately leading to their complete removal. Through extensive experiments conducted on popular models like ResNet-18 and Swin-T, our findings demonstrate that EGP effectively compresses deep neural networks while maintaining competitive performance levels. Our results not only shed light on the underlying mechanism behind the advantages of unstructured pruning, but also pave the way for further investigations into the intricate relationship between entropy, pruning techniques, and deep learning performance.

## Method Summary
The Entropy Guided Pruning (EGP) algorithm iteratively prunes neural network parameters by combining entropy-based layer importance with magnitude pruning. It calculates activation entropy for each neuron to identify layers that operate predominantly in one ReLU region (ON or OFF). The algorithm computes a pruning irrelevance metric that combines average layer entropy with weight magnitudes, then uses a softmax distribution to allocate pruning across layers. Layers with zero entropy can be completely removed, while layers with low entropy receive higher pruning priority. The process is repeated over multiple iterations with model fine-tuning between each iteration.

## Key Results
- EGP successfully removes entire layers from ResNet-18 and Swin-T architectures while maintaining competitive accuracy on CIFAR-10 and Tiny-ImageNet
- The algorithm achieves higher compression rates compared to standard iterative magnitude pruning at similar accuracy levels
- Entropy-guided pruning effectively drives pruning toward removable layers rather than just individual weights, revealing that some deep network layers can be eliminated without performance loss

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Unstructured pruning can remove entire layers when neurons in those layers consistently operate in only one of the two ReLU regions (ON or OFF).
- Mechanism: The algorithm measures entropy of neuron activations. If entropy is zero, the neuron is always in one state (ON or OFF). For a layer where all neurons have zero entropy, the entire layer can be removed without performance loss.
- Core assumption: A layer's contribution can be fully represented by a linear combination when all its neurons are always in one ReLU region.
- Evidence anchors:
  - [abstract] "prioritize pruning connections in layers with low entropy, ultimately leading to their complete removal"
  - [section] "We know that ReLU-activated neurons have essentially two working regions: an ON region, for zl,i,j > 0; an OFF region, for zl,i,j ≤ 0."
  - [corpus] No direct evidence found; this is a novel mechanism not covered in neighboring papers
- Break condition: If any neuron in a layer has non-zero entropy (i.e., activates in both ON and OFF regions), the layer cannot be removed.

### Mechanism 2
- Claim: Low-entropy layers can be removed even when neurons activate in both ON and OFF regions, because their contribution is linear.
- Mechanism: When all neurons in a layer are always in the linear region (ON state), the layer acts as a linear transformation that can be absorbed by the next layer.
- Core assumption: A layer consisting entirely of neurons that never enter the non-linear region can be mathematically merged with subsequent layers.
- Evidence anchors:
  - [abstract] "layers having also neurons in the ON state, would be overlooked: this shows the effectiveness of EGP"
  - [section] "sξ l,i,j = 1, ∀j, ξ. This case is achieved if zξ l,i,j > 0, ∀j, ξ. In this state, the i-th neuron in the l-th layer uses only the linear region, becoming a linear neuron: its contribution can be 'absorbed' by the next layer"
  - [corpus] No direct evidence found; this mechanism appears to be novel
- Break condition: If any neuron in the layer enters the OFF region (i.e., zξ l,i,j ≤ 0 for any input), the layer cannot be absorbed.

### Mechanism 3
- Claim: Entropy-guided pruning can effectively drive pruning to remove entire layers rather than just individual weights.
- Mechanism: The algorithm calculates a pruning irrelevance metric for each layer based on entropy and weight magnitudes, then uses a softmax distribution to allocate pruning across layers, prioritizing low-entropy layers.
- Core assumption: Layers with low entropy are more likely to be removable, and combining this with weight magnitude creates an effective pruning strategy.
- Evidence anchors:
  - [section] "We would like to route the magnitude pruning algorithm towards removing more parameters in layers where the entropy is low"
  - [section] "In order to assess the exact amount of parameters to be removed at the l-th layer we resort to a softmax smoothening"
  - [corpus] No direct evidence found; this approach appears to be novel
- Break condition: If the pruning irrelevance metric fails to distinguish removable layers from non-removable ones, the approach breaks down.

## Foundational Learning

- Concept: Entropy calculation for neuron activations
  - Why needed here: Entropy is the core metric that identifies removable layers
  - Quick check question: Given a neuron that activates in the ON region for 90% of inputs and OFF region for 10%, what is its entropy?

- Concept: ReLU activation regions and their mathematical properties
  - Why needed here: Understanding when neurons operate linearly vs non-linearly is crucial for layer removal
  - Quick check question: For a ReLU neuron that never activates (always in OFF region), what is its mathematical contribution to the network output?

- Concept: Layer fusion in neural networks
  - Why needed here: When removing layers that operate entirely in the linear region, understanding how to mathematically combine them with adjacent layers is essential
  - Quick check question: If layer L1 (with weights W1) is entirely linear and followed by layer L2 (with weights W2), what is the equivalent single layer?

## Architecture Onboarding

- Component map: Entropy calculation module -> Pruning irrelevance calculator -> Layer removal detector -> Iterative pruning engine
- Critical path: Entropy calculation → Pruning irrelevance → Layer removal detection → Layer removal/weight pruning → Model fine-tuning
- Design tradeoffs: Computationally expensive entropy calculation vs effectiveness of layer removal; aggressive pruning vs model performance preservation
- Failure signatures: Performance degradation when removing layers that still contribute non-linearly; entropy calculation instability with small batch sizes
- First 3 experiments:
  1. Compute entropy distributions for a trained ResNet-18 on CIFAR-10 to identify naturally low-entropy layers
  2. Apply entropy-guided pruning with ζ=0.5 and measure layer removal count vs performance impact
  3. Compare performance of entropy-guided pruning vs magnitude-only pruning at equivalent sparsity levels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does EGP perform on other activation functions beyond ReLU and GELU, such as Leaky ReLU or ELU?
- Basis in paper: [explicit] The paper mentions testing EGP on ReLU and GELU but suggests future work could explore other activation functions.
- Why unresolved: The current study is limited to specific activation functions, and the generalizability of EGP to other activations is unknown.
- What evidence would resolve it: Conducting experiments on various activation functions to compare EGP's performance and effectiveness in reducing network depth.

### Open Question 2
- Question: What is the impact of EGP on the dynamics of the optimization process during training?
- Basis in paper: [inferred] The paper hints at exploring the impact of pruning on the optimization process and model interpretability.
- Why unresolved: The study focuses on the end results of pruning rather than the intermediate effects on the training process.
- What evidence would resolve it: Analyzing training metrics and convergence patterns with and without EGP to understand its influence on optimization dynamics.

### Open Question 3
- Question: How does the performance of EGP compare to other state-of-the-art pruning techniques in terms of both accuracy and efficiency?
- Basis in paper: [explicit] The paper compares EGP to vanilla iterative magnitude pruning but does not extensively benchmark against other advanced techniques.
- Why unresolved: The study does not provide a comprehensive comparison with other pruning methods, leaving questions about EGP's relative effectiveness.
- What evidence would resolve it: Conducting comparative experiments with various pruning techniques to evaluate EGP's performance across different metrics.

## Limitations
- The entropy calculation requires sufficient batch size to provide meaningful activation distributions
- The approach may be less effective for architectures with skip connections where layer removal requires careful handling
- The iterative pruning process is computationally expensive due to repeated entropy calculations

## Confidence
- Core mechanism of using entropy to identify removable layers: **High confidence**
- Extension to removing layers where neurons operate only in the ON (linear) region: **Medium confidence**
- Effectiveness of combining entropy with weight magnitude in pruning irrelevance metric: **Medium confidence**

## Next Checks
1. **Empirical frequency analysis**: Measure the actual proportion of zero-entropy and low-entropy layers in commonly used architectures after standard training to validate the practical applicability of the approach.

2. **Ablation on pruning irrelevance metric**: Compare EGP against entropy-only pruning and magnitude-only pruning to isolate the contribution of the combined metric.

3. **Transferability testing**: Apply EGP to architectures beyond ResNet and Swin (e.g., Vision Transformers, MobileNets) to assess the generalizability of the entropy-based layer removal strategy.