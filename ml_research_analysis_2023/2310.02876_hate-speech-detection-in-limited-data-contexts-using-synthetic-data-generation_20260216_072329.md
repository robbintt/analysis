---
ver: rpa2
title: Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation
arxiv_id: '2310.02876'
source_url: https://arxiv.org/abs/2310.02876
tags:
- data
- hate
- speech
- language
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of hate speech detection in low-resource
  languages by proposing three synthetic data generation methods to augment limited
  training data. The methods include machine translation of existing hate speech data,
  contextual entity substitution (CES) which replaces target entities with contextually
  relevant ones in the target language, and generating synthetic examples using a
  large language model (BLOOM).
---

# Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation

## Quick Facts
- arXiv ID: 2310.02876
- Source URL: https://arxiv.org/abs/2310.02876
- Reference count: 40
- Authors: Authors not specified in provided text
- Primary result: CES and BLOOM-based synthetic data improve hate speech detection in Hindi and Vietnamese, with CES achieving F1 scores up to 85.99 for Hindi and 63.25 for Vietnamese when combined with few original examples.

## Executive Summary
This paper addresses the challenge of hate speech detection in low-resource languages by proposing three synthetic data generation methods: machine translation of existing hate speech data, contextual entity substitution (CES), and large language model (BLOOM) generation. The methods are evaluated on Hindi and Vietnamese using mBERT fine-tuning, showing that CES and BLOOM-based synthetic data can improve model performance, especially when combined with few original examples. The best results were achieved using CES with 350 synthetic examples, outperforming simple machine translation and closing the gap with models trained on all original data.

## Method Summary
The approach involves generating synthetic hate speech examples in target low-resource languages (Hindi, Vietnamese) using three methods: machine translation (MT) of English hate speech, contextual entity substitution (CES) that replaces hate targets with culturally relevant entities, and BLOOM-LM generation. These synthetic examples are combined with limited original training data and used to fine-tune mBERT for hate speech detection. The entity table for CES is manually curated by native speakers. Performance is evaluated using macro F1 scores on in-domain and out-of-domain test sets.

## Key Results
- CES with 350 synthetic examples achieved F1 scores up to 85.99 for Hindi and 63.25 for Vietnamese
- BLOOM-LM method outperformed MT in both languages as synthetic data increased
- CES outperformed BLOOM-LM in Hindi but BLOOM-LM performed better in Vietnamese
- All methods showed improved performance when combined with few original examples compared to baseline

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Machine translation alone does not sufficiently improve hate speech detection due to loss of contextual hate targets.
- Mechanism: Direct translation of English hate speech into target language preserves semantic structure but loses cultural and contextual relevance of hate targets (e.g., ethnic slurs, named individuals). This mismatch reduces model performance on the target language.
- Core assumption: Hate speech targets are highly context-dependent, and literal translation cannot adapt them appropriately.
- Evidence anchors:
  - [abstract]: "automatic machine translation (MT) of the hateful posts in a high-resource language to the limited data language."
  - [section]: "we find that the word 'kike' has been transliterated from Latin to Devanagari... In contrast, we find that the CES method has the name of the person, 'Bhagat Singh'... referred to as 'penisless', and is contextually relevant in the Indian domain."
- Break condition: If the target language has a translation system with strong cultural adaptation or if the hate targets are universal and context-independent, this mechanism fails to explain performance drops.

### Mechanism 2
- Claim: Contextual entity substitution (CES) improves detection by replacing hate targets with culturally relevant entities, preserving sentiment.
- Mechanism: Identify hate targets in English examples via heuristics and NER, mask them, translate the masked sentences, then substitute masked positions with target-specific entities from the target language's entity table. This maintains the hateful sentiment while adapting to local context.
- Core assumption: Hate sentiment can be preserved by substituting only the target entities while keeping the rest of the linguistic structure intact.
- Evidence anchors:
  - [abstract]: "we identify suitable contextual replacement tokens in the hate speech examples from the high-resource language."
  - [section]: "Our method, contextual entity substitution (CES), takes as input a handful of examples... and heuristically replaces the person or group under attack... with potential hate-targeted persons/groups in the target context."
- Break condition: If the entity table is incomplete or poorly curated, substitutions may introduce noise or incorrect hate targets, negating performance gains.

### Mechanism 3
- Claim: Large language model (BLOOM) generation can produce synthetic hate speech with reasonable naturalness, especially when the target language is well-represented in pretraining.
- Mechanism: Prompt BLOOM with existing target-language hate examples to generate additional synthetic hateful posts, leveraging its learned language patterns to maintain stylistic and contextual coherence.
- Core assumption: BLOOM's pretraining coverage of the target language is sufficient to generate contextually plausible hate speech without additional finetuning.
- Evidence anchors:
  - [abstract]: "we use an open-source language model, BLOOM, to synthetically generate hate speech examples in the target context."
  - [section]: "BLOOM-LM method outperforms the MT method in both Hindi and Vietnamese as we increase the amount of synthetic data... However, the CES method outperforms the BLOOM-LM method in Hindi in most cases while the BLOOM-LM method outperforms the CES method in most Vietnamese cases."
- Break condition: If the target language is underrepresented in BLOOM's pretraining data, generated outputs may be unnatural or off-topic, reducing effectiveness.

## Foundational Learning

- Concept: Entity Recognition and Substitution
  - Why needed here: To identify and replace hate targets with culturally relevant entities while preserving hateful sentiment.
  - Quick check question: How does the system differentiate between entities that are targets of hate and those that are incidental mentions?

- Concept: Cross-lingual Transfer Learning
  - Why needed here: To leverage labeled hate speech from high-resource languages to bootstrap detection models in low-resource contexts.
  - Quick check question: What properties of the source and target languages enable effective transfer of hate speech patterns?

- Concept: Data Augmentation via Synthetic Generation
  - Why needed here: To overcome class imbalance and data scarcity in hate speech detection for low-resource languages.
  - Quick check question: What are the risks of introducing noise or domain drift when augmenting limited hate speech data?

## Architecture Onboarding

- Component map: Data Curation -> Entity Table Construction -> Synthetic Data Generation (MT/CES/BLOOM) -> Model Training (mBERT) -> Evaluation
- Critical path: Entity table creation (manual + heuristic) -> Masked translation or prompt-based generation -> Substitution/generation -> Model fine-tuning -> Performance validation on in-domain and out-of-domain test sets.
- Design tradeoffs:
  - MT: Fast but loses contextual relevance of hate targets
  - CES: Contextually accurate but requires curated entity tables and manual effort
  - BLOOM: Potentially more diverse and natural but dependent on language representation in pretraining and prompt quality
- Failure signatures:
  - MT: Drop in F1 when adding more translated examples, indicating noise
  - CES: Performance plateau or decline if entity table lacks diversity or updates lag domain drift
  - BLOOM: Poor generation quality if language is underrepresented in pretraining, leading to unnatural or irrelevant synthetic posts
- First 3 experiments:
  1. Compare baseline (original data only) vs MT augmentation to confirm MT's limited effectiveness
  2. Implement CES with a small entity table on Hindi to measure improvement over MT
  3. Test BLOOM-LM on Vietnamese with varying amounts of synthetic data to assess scaling benefits

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of contextual entity substitution (CES) vary with the size and quality of the entity table?
- Basis in paper: [explicit] The authors note that the success of CES depends on the entity table and mention that updating it for domain drift could improve performance.
- Why unresolved: The paper does not systematically investigate how different sizes or qualities of entity tables affect CES performance.
- What evidence would resolve it: Experiments varying the size and quality of entity tables and measuring the resulting CES performance.

### Open Question 2
- Question: How well do the proposed synthetic data generation methods generalize to truly low-resource languages?
- Basis in paper: [inferred] The authors acknowledge that Hindi and Vietnamese, while having limited hate speech data, are not considered low-resource languages.
- Why unresolved: The experiments were conducted only on Hindi and Vietnamese, which are not the most challenging low-resource scenarios.
- What evidence would resolve it: Applying the methods to languages with even less available data and resources.

### Open Question 3
- Question: What is the optimal strategy for combining synthetic data generated by different methods?
- Basis in paper: [inferred] The authors compare different methods but do not explore combining them or determining optimal mixing ratios.
- Why unresolved: The paper evaluates methods individually but does not investigate potential synergies from combining them.
- What evidence would resolve it: Experiments testing various combinations and ratios of synthetic data from different generation methods.

## Limitations

- The entity tables used for CES were manually curated by native speakers but are not publicly available, making it difficult to assess their comprehensiveness or potential biases.
- BLOOM-LM generation depends heavily on the target language's representation in pretraining data, but the paper does not provide analysis of BLOOM's pretraining coverage for Hindi and Vietnamese.
- The out-of-domain test sets (Europarl) may not represent realistic hate speech scenarios, potentially inflating confidence in cross-domain generalization claims.

## Confidence

- **High Confidence**: The observation that machine translation alone performs poorly for hate speech detection due to loss of contextual relevance is well-supported by qualitative examples showing transliteration artifacts and contextually inappropriate hate targets.
- **Medium Confidence**: The relative performance rankings of CES and BLOOM-LM methods across Hindi and Vietnamese experiments are reproducible, but the magnitude of improvements and their stability across different dataset sizes warrants further validation with larger sample sizes.
- **Low Confidence**: The claim that these methods "close the gap" with models trained on all original data is overstated, as the gap remains substantial (particularly for Vietnamese where F1 scores plateau around 63-64) and may not hold across different hate speech domains or more diverse languages.

## Next Checks

1. **Entity Table Coverage Analysis**: Systematically evaluate how CES performance scales with entity table size and diversity by testing with progressively expanded tables (e.g., 10%, 50%, 100% of comprehensive entity lists) to quantify the sensitivity to this manual curation bottleneck.

2. **Cross-Domain Generalization Test**: Evaluate the synthetic-data-augmented models on hate speech datasets from different domains (social media platforms, comment sections, etc.) beyond Europarl to verify that improvements generalize beyond the specific text styles in the original limited data.

3. **Language Representation Analysis for BLOOM**: Conduct a quantitative assessment of BLOOM's pretraining data coverage for Hindi and Vietnamese by comparing generated synthetic examples against human-annotated reference corpora to measure fluency, topical relevance, and hate speech authenticity.