---
ver: rpa2
title: 'MILD: Modeling the Instance Learning Dynamics for Learning with Noisy Labels'
arxiv_id: '2306.11560'
source_url: https://arxiv.org/abs/2306.11560
tags:
- data
- learning
- noise
- selection
- noisy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of learning with noisy labels in
  deep neural networks. The authors observe that networks first learn clean patterns
  before overfitting to noisy ones, and that clean samples are both easy to memorize
  and hard to forget.
---

# MILD: Modeling the Instance Learning Dynamics for Learning with Noisy Labels

## Quick Facts
- arXiv ID: 2306.11560
- Source URL: https://arxiv.org/abs/2306.11560
- Reference count: 9
- Primary result: Under 80% symmetric noise on CIFAR-100, MILD achieves 79.1% accuracy vs 69.4% for FINE (+10.4%)

## Executive Summary
This paper addresses the challenge of learning with noisy labels in deep neural networks by leveraging observed learning dynamics. The authors propose tracking how instances transition between correct and incorrect predictions during training to identify clean samples that are both easy to memorize and hard to forget. By modeling these dynamics with a Weibull mixture model and iteratively refining the clean sample subset, MILD significantly outperforms existing methods on both synthetic and real-world web datasets.

## Method Summary
The method tracks instance learning dynamics by recording whether each sample is correctly classified at each training epoch. From these prediction sequences, it computes memorization difficulty (how often a sample transitions from misclassified to memorized) and forgetting difficulty (how often it transitions from memorized to misclassified). These metrics are combined into a single score, and a Weibull mixture model separates clean from noisy samples based on their score distributions. The method iteratively refines the clean subset by retraining on previously selected clean samples, creating a positive feedback loop that progressively improves selection quality.

## Key Results
- Under 80% symmetric noise on CIFAR-100, MILD achieves 79.1% accuracy versus 69.4% for FINE (+10.4%)
- Achieves 77.7% accuracy on CIFAR-100 pairflip noise at 40% noise rate
- On Mini-Webvision, achieves 62.3% accuracy under 40% pairflip noise
- Integrates effectively with semi-supervised techniques like MixMatch and MixUp+contrastive learning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The network learns clean patterns before overfitting to noisy ones, and clean samples are both easy to memorize and hard to forget.
- Mechanism: During training, the model first successfully classifies clean samples and maintains their correct predictions over many epochs, while mislabeled samples are frequently misclassified and only later fit to incorrect labels. By tracking how often each sample transitions between correct and incorrect predictions, we can identify which samples behave like clean data (low memorization difficulty, high forgetting difficulty).
- Core assumption: Deep neural networks exhibit a natural ordering in learning where simple, clean patterns are learned before complex, noisy patterns.
- Evidence anchors:
  - [abstract] "we leverage the observation that deep network is easy to memorize and hard to forget clean data"
  - [section 3.2] "the model often first learns the patterns of clean data and then overfits to corrupted data"
  - [corpus] Weak - corpus papers focus on different noise handling strategies without directly supporting this specific learning dynamic
- Break condition: If the dataset lacks a clear separation between easy (clean) and hard (noisy) patterns, or if the noise distribution is instance-dependent rather than symmetric, this mechanism may fail to distinguish clean from corrupted samples.

### Mechanism 2
- Claim: A Weibull mixture model can effectively separate the metric distributions of clean and noisy samples.
- Mechanism: The selection metric (memorization difficulty minus forgetting difficulty) produces different distributions for clean versus noisy samples. The Weibull distribution fits these naturally, with clean samples clustering at lower metric values and noisy samples at higher values. The mixture model identifies the threshold separating the two populations.
- Core assumption: The metric values for clean and noisy samples follow distinct statistical distributions that can be modeled with Weibull distributions.
- Evidence anchors:
  - [section 3.3] "we adopt the Weibull distribution to represent the distribution of our metric scores on the data with clean or noisy labels"
  - [section 3.3] "we use the Weibull mixture model which contains two components to fit the metric distributions of clean and falsely-labeled data"
  - [corpus] Missing - no corpus evidence directly supports Weibull mixture model effectiveness for this specific problem
- Break condition: If the metric distributions overlap significantly or don't follow Weibull shapes, the mixture model cannot find a reliable separation threshold.

### Mechanism 3
- Claim: Iterative refinement using selected clean samples progressively improves the quality of the clean subset.
- Mechanism: Each training round uses the previously selected clean samples to train the model, which then produces better predictions. Better predictions lead to more accurate metric values, which in turn select a higher-quality clean subset for the next round. This creates a positive feedback loop that gradually purifies the training set.
- Core assumption: Using cleaner training data in each round will produce a model that can better distinguish clean from noisy samples in the next round.
- Evidence anchors:
  - [section 3.1] "we adopt the categorical cross entropy loss on current training set D to update the model"
  - [section 3.1] "we retain a subset of identified clean data and repeat the selection procedure to iteratively refine the clean subset"
  - [corpus] Weak - corpus papers mention iterative approaches but don't specifically validate this refinement mechanism
- Break condition: If early rounds select too few clean samples or include too many noisy samples, the iterative process may converge to a poor solution or diverge.

## Foundational Learning

- Concept: Instance learning dynamics tracking
  - Why needed here: The method relies on tracking how each sample's prediction status changes over epochs to measure memorization and forgetting difficulty
  - Quick check question: How would you record whether a sample was correctly classified at each training epoch?

- Concept: Transition counting between states
  - Why needed here: The memorization and forgetting metrics are computed by counting transitions between misclassified and memorized states in the prediction sequence
  - Quick check question: What mathematical operation would you use to count how many times a sample transitions from misclassified to memorized?

- Concept: Mixture model parameter estimation
  - Why needed here: The Weibull mixture model requires estimating parameters for two component distributions to find the optimal threshold
  - Quick check question: Which statistical method would you use to fit a mixture of two Weibull distributions to observed metric values?

## Architecture Onboarding

- Component map: Data pipeline -> Model trainer -> Prediction tracker -> Metric calculator -> Mixture model fitter -> Iterative selector
- Critical path: Training → Prediction tracking → Metric calculation → Mixture model fitting → Sample selection → Next round training
- Design tradeoffs: The method trades computational overhead (tracking predictions, fitting mixture models) for improved robustness to label noise. Using simpler threshold methods would be faster but less accurate.
- Failure signatures: If precision drops below 90% or recall falls below 50% in any round, the method is failing to correctly identify clean samples. If accuracy plateaus early, the iterative refinement isn't improving.
- First 3 experiments:
  1. Run with tracking disabled to establish baseline performance
  2. Run with metric calculation but fixed threshold to test metric quality
  3. Run full method with 2 rounds on CIFAR-10 symmetric 20% noise to validate iterative improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Weibull mixture model threshold selection strategy impact long-term selection stability across many rounds?
- Basis in paper: [explicit] The paper notes that choosing the threshold as α2 avoids the performance drop from sharp recall decrease in multiple rounds, but does not provide empirical validation across many rounds.
- Why unresolved: The ablation study only shows 7 rounds; no analysis of very deep or unstable training scenarios where thresholds may drift.
- What evidence would resolve it: Extended experiments showing selection metrics and model accuracy over 10+ rounds, with sensitivity analysis to threshold choice strategies.

### Open Question 2
- Question: Can the memorization/forgetting metric be made robust to non-IID or domain-shifted data?
- Basis in paper: [inferred] The method relies on per-instance learning dynamics, which may depend on class and data distribution; no experiments are reported on domain-shifted or long-tailed datasets.
- Why unresolved: All experiments use balanced, in-distribution datasets; the generalizability of the dynamics-based metric to shifted or imbalanced settings is untested.
- What evidence would resolve it: Experiments on domain adaptation or long-tailed noise datasets, comparing MILD’s robustness to existing methods under distribution shift.

### Open Question 3
- Question: Is the simplified metric (ignoring segment count) truly equivalent in performance, or does it trade off some precision?
- Basis in paper: [explicit] The authors claim the simplified version is “very close” to the full metric but do not provide quantitative comparison beyond CIFAR-100 symmetric 80% noise.
- Why unresolved: No ablation is shown across diverse noise types, ratios, or datasets; the equivalence is assumed but not systematically validated.
- What evidence would resolve it: Systematic comparison of full vs simplified metric across all experiments (synthetic and web noise, different backbones, noise ratios) with statistical significance testing.

## Limitations
- The Weibull mixture model fitting procedure is only stated as "empirically found" without specific details on initialization, optimization method, or convergence criteria.
- Performance under instance-dependent noise remains unclear, as all experiments focus on symmetric and pairflip noise patterns.
- The method's generalizability to domain-shifted or long-tailed datasets is untested.

## Confidence
- High Confidence: The core observation about learning dynamics (clean samples being easy to memorize and hard to forget) is well-supported by existing literature on deep network training behavior.
- Medium Confidence: The Weibull mixture model approach for threshold selection appears reasonable but lacks corpus validation.
- Low Confidence: Performance claims under extreme noise rates (>80%) and with instance-dependent noise patterns are not adequately validated.

## Next Checks
1. **Distribution Validation**: Plot the metric distributions for clean vs. noisy samples across multiple datasets to verify Weibull shape assumptions and assess separation quality.
2. **Hyperparameter Sensitivity**: Systematically vary the Weibull mixture model initialization and fitting parameters to measure impact on final accuracy and threshold stability.
3. **Noise Type Robustness**: Test the method on instance-dependent noise patterns and compare performance degradation against symmetric noise to identify breaking conditions for the learning dynamics assumption.