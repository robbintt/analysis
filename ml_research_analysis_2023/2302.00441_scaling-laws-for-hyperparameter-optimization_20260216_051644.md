---
ver: rpa2
title: Scaling Laws for Hyperparameter Optimization
arxiv_id: '2302.00441'
source_url: https://arxiv.org/abs/2302.00441
tags:
- uni00000013
- uni00000011
- uni00000048
- uni00000014
- uni00000044
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Deep Power Laws (DPL), a novel approach to
  hyperparameter optimization for deep learning that leverages the power-law scaling
  properties of learning curves. The key idea is to use an ensemble of neural networks
  conditioned to predict future performance based on a power-law function, enabling
  efficient selection of promising configurations to evaluate.
---

# Scaling Laws for Hyperparameter Optimization

## Quick Facts
- arXiv ID: 2302.00441
- Source URL: https://arxiv.org/abs/2302.00441
- Reference count: 40
- This paper proposes Deep Power Laws (DPL), a novel approach to hyperparameter optimization for deep learning that leverages the power-law scaling properties of learning curves.

## Executive Summary
This paper introduces Deep Power Laws (DPL), a novel hyperparameter optimization approach that exploits power-law scaling properties of learning curves. DPL uses an ensemble of neural networks to predict future performance based on power-law functions, enabling efficient selection of promising configurations. The method is evaluated on three diverse benchmarks covering 57 tasks and demonstrates state-of-the-art performance compared to 7 strong baselines.

## Method Summary
DPL operates in a gray-box hyperparameter optimization setting where partial learning curves are available. It fits power-law functions to learning curves and uses a neural network to condition power-law parameters on hyperparameter configurations. An ensemble of such models provides uncertainty estimates for Bayesian optimization with Expected Improvement acquisition. The approach is integrated with the HpBandSter framework for multi-fidelity optimization.

## Key Results
- DPL achieves state-of-the-art performance on LCBench, TaskSet, and PD1 benchmarks
- Outperforms 7 strong baselines in terms of regret and any-time performance
- Successfully handles diverse tasks including tabular, NLP, vision, and protein modeling
- Efficiently explores search space with 8 continuous hyperparameters in TaskSet benchmark

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Power-law learning curves enable accurate performance prediction from partial training data
- Mechanism: The validation error follows a power-law function of training epochs, allowing early stopping and budget allocation based on extrapolated future performance
- Core assumption: Learning curves can be modeled as simple power-law functions across different hyperparameter configurations
- Evidence anchors:
  - [abstract] "optimization curves (training epochs versus accuracy, or loss) can be efficiently modeled as simple power laws functions"
  - [section] "we demonstrate that optimization curves... can be efficiently modeled as simple power laws functions"
  - [corpus] Weak evidence - corpus contains related scaling law papers but none specifically validating power-law learning curve predictions
- Break condition: When learning rate scheduling or other optimization techniques create non-power-law learning curve shapes

### Mechanism 2
- Claim: Conditioning power-law parameters on hyperparameter configurations enables shared modeling across configurations
- Mechanism: A neural network maps hyperparameter configurations to power-law coefficients, creating a single model that predicts learning curves for all configurations
- Core assumption: The relationship between hyperparameters and learning curve shapes can be captured by a parametric function
- Evidence anchors:
  - [section] "we fit a single shared power law function across all configurations by conditioning the power law coefficients α,β,γ on λ using a parametric neural network"
  - [section] "Instead of fitting one separate power law function to each learning curve, we fit a single shared power law function across all configurations"
  - [corpus] Weak evidence - corpus contains related neural network conditioning work but not specifically for power-law sharing
- Break condition: When hyperparameter interactions are too complex for the parametric function to capture

### Mechanism 3
- Claim: Ensemble of power-law models provides uncertainty estimates for Bayesian optimization
- Mechanism: Multiple power-law models with different initializations create a posterior distribution over predictions, enabling exploration-exploitation trade-off
- Core assumption: Deep ensembles provide reliable uncertainty estimates for learning curve predictions
- Evidence anchors:
  - [section] "we train an ensemble of K diverse surrogates... by initializing each surrogate with different weights and by training with a different sequence of mini-batches"
  - [section] "The posterior mean µ and the posterior variance σ² of the power law ensemble are trivially computed"
  - [corpus] No direct evidence - corpus contains scaling law papers but not ensemble uncertainty methods
- Break condition: When ensemble diversity is insufficient to capture true prediction uncertainty

## Foundational Learning

- Concept: Bayesian optimization with acquisition functions
  - Why needed here: DPL uses Expected Improvement acquisition based on posterior mean and variance from power-law ensemble
  - Quick check question: What is the mathematical form of Expected Improvement and how does it use posterior mean and variance?

- Concept: Multi-fidelity optimization and learning curves
  - Why needed here: DPL operates in gray-box setting where partial learning curves are available for early stopping decisions
  - Quick check question: How does multi-fidelity optimization differ from standard hyperparameter optimization in terms of budget allocation?

- Concept: Power-law relationships and scaling laws
  - Why needed here: DPL assumes validation error follows power-law function of training epochs
  - Quick check question: What is the general form of a power-law relationship and what are typical values for exponents in deep learning contexts?

## Architecture Onboarding

- Component map: Input layer (hyperparameter configuration) → 2-layer neural network with Leaky ReLU → 3 output nodes (α, β, γ) → Power-law function (α + β·b⁻ᵞ) → Ensemble of K models → Posterior mean and variance → Expected Improvement acquisition → Hyperparameter selection
- Critical path: Configuration → Neural network → Power-law prediction → Ensemble aggregation → Acquisition function → Next configuration selection
- Design tradeoffs: Simpler power-law formulation (3 parameters) vs. more complex formulations with shift/scaling parameters; single shared model vs. separate models per configuration; ensemble size K vs. computational cost
- Failure signatures: Poor rank correlation between predicted and actual performance; high uncertainty in well-sampled regions; ensemble predictions diverging from ground truth; learning curve predictions failing to capture early stopping points
- First 3 experiments:
  1. Validate power-law assumption on a single dataset by fitting individual power laws to learning curves and measuring prediction accuracy
  2. Test conditioning by training shared power-law model and comparing prediction accuracy to individual models
  3. Evaluate ensemble uncertainty by comparing prediction intervals to actual performance distribution across multiple runs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DPL's performance scale with increasingly complex hyperparameter search spaces, particularly those with high-dimensional continuous parameters?
- Basis in paper: [explicit] The paper demonstrates DPL's effectiveness on search spaces with 8 continuous hyperparameters (TaskSet) and simpler 1-D spaces, but does not explicitly test scaling to higher dimensions or more complex discrete-continuous hybrid spaces.
- Why unresolved: The experiments focus on moderate-sized search spaces, and the paper does not discuss limitations or performance degradation as dimensionality increases.
- What evidence would resolve it: Systematic experiments comparing DPL's performance on search spaces of increasing dimensionality and complexity, including hybrid spaces with both continuous and discrete parameters.

### Open Question 2
- Question: What is the theoretical justification for using power-law functions specifically, as opposed to other functional forms that might capture learning curve dynamics?
- Basis in paper: [explicit] The paper empirically validates power-law scaling and shows it outperforms alternatives like neural networks and Gaussian processes in forecasting, but does not provide theoretical reasons for why power laws are optimal.
- Why unresolved: The choice of power-law formulation appears empirical rather than theoretically grounded, and the paper does not explore alternative functional forms or their theoretical properties.
- What evidence would resolve it: Mathematical analysis comparing power-law assumptions to other potential function families (e.g., exponential, logarithmic) in terms of bias-variance tradeoffs and generalization guarantees.

### Open Question 3
- Question: How does DPL's performance degrade when the power-law assumption breaks down, such as in early training stages or with non-standard learning rate schedules?
- Basis in paper: [explicit] The paper mentions that power laws may not fit very early training stages (Section 8) but does not provide systematic analysis of performance degradation when assumptions are violated.
- Why unresolved: The experimental evaluation focuses on regimes where power laws are expected to hold well, and the paper does not quantify performance loss in edge cases.
- What evidence would resolve it: Controlled experiments measuring DPL's performance across different training stages, learning rate schedules, and architectures where power-law assumptions may not hold.

### Open Question 4
- Question: What is the optimal ensemble size and architecture for the power-law surrogate, and how sensitive is DPL's performance to these choices?
- Basis in paper: [explicit] The paper uses 5 ensemble members and a specific neural network architecture (2-layer, 128 units) but does not perform ablation studies or provide guidance on tuning these hyperparameters.
- Why unresolved: The architectural choices appear arbitrary, and the paper does not discuss sensitivity analysis or provide heuristics for selecting ensemble configurations.
- What evidence would resolve it: Comprehensive ablation studies varying ensemble sizes, network architectures, and training procedures to identify optimal configurations and sensitivity patterns.

## Limitations

- Power-law assumption may not generalize to all deep learning tasks and architectures
- Computational overhead of training and maintaining power-law ensemble could be prohibitive for large-scale problems
- Performance in edge cases where power-law assumptions break down is not thoroughly characterized

## Confidence

- **High Confidence**: The experimental results on three diverse benchmarks demonstrate consistent outperformance of strong baselines
- **Medium Confidence**: The conditioning mechanism and ensemble uncertainty estimates work well in practice but lack theoretical guarantees
- **Low Confidence**: Universal applicability of power-law assumption across all deep learning domains remains unproven

## Next Checks

1. Test DPL on graph neural networks and reinforcement learning tasks to assess cross-domain generalization
2. Conduct detailed analysis of computational overhead including training time, memory usage, and scalability to large hyperparameter spaces
3. Perform comprehensive ablation studies varying ensemble sizes, network architectures, and training procedures to identify optimal configurations