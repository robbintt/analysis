---
ver: rpa2
title: 'PersonaLLM: Investigating the Ability of Large Language Models to Express
  Personality Traits'
arxiv_id: '2305.02547'
source_url: https://arxiv.org/abs/2305.02547
tags:
- personality
- personas
- traits
- language
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method for simulating personalized chatbot
  personas with curated personality traits using large language models (LLMs). The
  authors create 320 LLM personas based on the Big Five personality model and have
  them complete personality tests and story writing tasks.
---

# PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits

## Quick Facts
- arXiv ID: 2305.02547
- Source URL: https://arxiv.org/abs/2305.02547
- Reference count: 9
- Primary result: LLMs can express and maintain consistent personality profiles across self-reported tests and creative writing

## Executive Summary
This paper investigates whether large language models can effectively simulate personalized chatbot personas with distinct personality traits. The authors create 320 LLM personas based on the Big Five personality model and evaluate their personality expression through self-reported tests and creative writing tasks. The study demonstrates that LLM personas can maintain consistent personality profiles across different assessment formats, with their self-reported personality scores aligning with assigned traits and their writing showing characteristic linguistic patterns for each personality dimension.

## Method Summary
The researchers created 320 LLM personas by prompting GPT-3.5 with combinations of gender and Big Five personality traits. Each persona completed a 44-item Big Five Inventory personality test and wrote an 800-word childhood story. The authors then analyzed the results using one-way ANOVA to test consistency of BFI scores across personality types and Linguistic Inquiry and Word Count (LIWC) analysis to identify linguistic patterns in the writing outputs. Human evaluators also assessed the perceived personality traits in the generated content.

## Key Results
- LLM personas' self-reported personality test scores align with their assigned traits with large effect sizes across all five dimensions
- Writing outputs show representative linguistic patterns for different personality traits when compared to human writing data
- Human evaluators can accurately perceive certain personality traits in LLM-generated content, achieving up to 80% accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM personas can maintain consistent personality trait profiles across multiple assessment formats
- Mechanism: The model's internal representations capture personality dimensions during training, allowing it to generate coherent responses that align with assigned traits in both self-reported tests and creative writing tasks
- Core assumption: LLMs develop abstract representations of personality constructs that can be reliably activated through prompt engineering
- Evidence anchors:
  - [abstract] "LLM personas' self-reported personality test scores are consistent with their designated personality types, with large effect sizes observed across five traits"
  - [section] "Statistically significant differences are found for all five traits, and Cohen's d shows a large effect size (O: d = 2.50 C: d = 1.79; E: d = 6.34; A: d = 2.12; N: d = 4.99)"
- Break condition: Temperature setting too high (>0.7) causes excessive variance, breaking consistency across assessments

### Mechanism 2
- Claim: Personality traits manifest in distinct linguistic patterns in LLM-generated text
- Mechanism: The model's attention mechanisms associate specific personality dimensions with characteristic word choices and grammatical structures, producing text that reflects assigned traits through measurable linguistic features
- Core assumption: LLMs encode personality-to-language mappings that mirror human psycholinguistic patterns
- Evidence anchors:
  - [abstract] "LLM personas' writings have emerging representative linguistic patterns for personality traits when compared with a human writing corpus"
  - [section] "Significant Spearman correlations are found between some LIWC psycholinguistic features and personality types" with specific examples like extroverted personas using more social and motion words
- Break condition: Using zero temperature eliminates the variance needed to show distinct patterns, resulting in uniform output

### Mechanism 3
- Claim: Human evaluators can accurately perceive personality traits in LLM-generated content
- Mechanism: Humans can detect consistent behavioral patterns in text that align with personality dimensions, even when generated by AI, through the same cognitive mechanisms used for human-authored content
- Core assumption: Personality expression through language follows recognizable patterns regardless of authorship
- Evidence anchors:
  - [abstract] "Human evaluation shows that humans can perceive some personality traits with an accuracy of up to 80%"
  - [section] The study finds significant accuracy in human perception, though accuracy drops when annotators are informed of AI authorship
- Break condition: Providing authorship information (AI vs human) significantly reduces human accuracy, suggesting evaluation context affects perception

## Foundational Learning

- Concept: Big Five personality model (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism)
  - Why needed here: The study uses this model as the foundation for creating and evaluating LLM personas, requiring understanding of what each trait represents
  - Quick check question: What are the five dimensions of the Big Five model and what single word best characterizes each?

- Concept: Linguistic Inquiry and Word Count (LIWC) analysis
  - Why needed here: The study uses LIWC to measure linguistic patterns in LLM-generated text and correlate them with personality traits
  - Quick check question: What type of linguistic features does LIWC analyze, and how would you expect neurotic personas to differ from emotionally stable ones in their word usage?

- Concept: Effect size interpretation (Cohen's d)
  - Why needed here: The study reports effect sizes for personality trait differences, requiring understanding of what constitutes large vs small effects
  - Quick check question: According to Cohen's conventions, what d value range constitutes a large effect size, and which personality trait showed the largest effect in this study?

## Architecture Onboarding

- Component map: Persona creation (prompt engineering) -> Personality assessment (BFI test) -> Content generation (story writing) -> Linguistic analysis (LIWC) -> Human evaluation (perception testing)
- Critical path: The prompt engineering that creates consistent personas is the foundation; if personas aren't stable, subsequent analyses fail
- Design tradeoffs: Higher temperature creates more realistic individual variation but reduces consistency; lower temperature ensures consistency but may produce robotic output
- Failure signatures: Inconsistent BFI scores across runs, lack of correlation between assigned traits and LIWC features, human evaluators unable to distinguish traits
- First 3 experiments:
  1. Test temperature sensitivity by running the same persona creation at 0.1, 0.5, and 0.9 temperatures to find optimal balance
  2. Compare LIWC patterns between LLM personas and human writing samples from the same personality types to validate the approach
  3. Run a pilot human evaluation with blinded and non-blinded conditions to quantify the authorship perception effect

## Open Questions the Paper Calls Out
- How well do LLM personas maintain personality consistency across diverse and naturalistic interaction scenarios beyond controlled tasks like personality tests and story writing?
- Do LLM personas exhibit personality traits that generalize across different prompting strategies and personality lexicon frameworks beyond the Big Five model?
- What are the demographic and cultural limitations of using LLM personas for personality modeling, particularly regarding non-Western personality constructs and diverse cultural contexts?

## Limitations
- Results are based on a single LLM architecture (GPT-3.5), limiting generalizability to other models
- Human perception accuracy is context-dependent, significantly decreasing when AI authorship is disclosed
- The study focuses on structured tasks rather than naturalistic conversational scenarios

## Confidence
- **High Confidence**: LLMs can maintain consistent personality trait profiles across multiple assessment formats, supported by large effect sizes (Cohen's d ranging from 1.79 to 6.34)
- **Medium Confidence**: Personality traits manifest in distinct linguistic patterns, supported by LIWC correlations but requiring replication
- **Medium Confidence**: Human perception accuracy up to 80% is promising but context-dependent nature limits real-world applicability

## Next Checks
1. Cross-model validation: Replicate the study using multiple LLM architectures (Claude, LLaMA, PaLM) to determine if personality expression capabilities are model-specific or generalizable
2. Conversational consistency test: Implement a dialogue system where the same persona maintains conversations across multiple sessions, measuring trait consistency using both automated analysis and blinded human raters
3. Cultural adaptation assessment: Test the same 320 personas across different cultural contexts by translating prompts and evaluation materials to multiple languages, examining whether personality trait expression remains consistent or shows cultural variation