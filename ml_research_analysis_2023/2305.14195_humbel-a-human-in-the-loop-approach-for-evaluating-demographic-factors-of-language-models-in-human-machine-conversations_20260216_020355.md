---
ver: rpa2
title: 'HumBEL: A Human-in-the-Loop Approach for Evaluating Demographic Factors of
  Language Models in Human-Machine Conversations'
arxiv_id: '2305.14195'
source_url: https://arxiv.org/abs/2305.14195
tags:
- test
- human
- word
- language
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HumBEL, a novel evaluation framework for
  assessing the demographic alignment of large language models (LMs) with human populations,
  focusing on age-based language skills. HumBEL leverages clinical techniques from
  Speech Language Pathology, which has well-established norms for language acquisition
  organized by age.
---

# HumBEL: A Human-in-the-Loop Approach for Evaluating Demographic Factors of Language Models in Human-Machine Conversations

## Quick Facts
- arXiv ID: 2305.14195
- Source URL: https://arxiv.org/abs/2305.14195
- Reference count: 33
- Primary result: HumBEL framework reveals GPT-3.5 performs at 6-9 year old level on inference tasks but exceeds 21-year-old norms on memorization, with significant gaps in social language use.

## Executive Summary
This paper introduces HumBEL, a novel evaluation framework for assessing the demographic alignment of large language models (LMs) with human populations, focusing on age-based language skills. HumBEL leverages clinical techniques from Speech Language Pathology, which has well-established norms for language acquisition organized by age. The framework includes two protocols: clinician-in-the-loop evaluation using clinical exams (e.g., CELF5) and automated statistical techniques for large-scale analysis. Experiments with InstructGPT (GPT-3.5) reveal significant gaps in its language capabilities compared to human developmental norms.

## Method Summary
HumBEL evaluates LM demographic alignment by adapting clinical language exams like CELF5 into prompts for LMs, then comparing performance against human age norms. The framework uses two protocols: clinician-in-the-loop evaluation where experts administer clinical tasks and analyze LM responses, and automated statistical techniques that substitute for clinical evaluation at scale. The automated approach employs test divergence and energy distance metrics to compare LM error patterns against expected human error distributions at different ages. Implementation involves loading LM and clinical task definitions, generating prompts, collecting responses, extracting linguistic features, comparing against human norms using statistical tests, and outputting age estimates and error analyses.

## Key Results
- GPT-3.5 performs at a 6-9 year old level in tasks requiring inference about word meanings but outperforms a typical 21 year old in memorization tasks
- InstructGPT exhibits less than 50% of the tested pragmatic skills, struggling with social language use
- Automated analysis identifies specific weaknesses including difficulty with functional word relations, morphological complexity, and providing logical explanations

## Why This Works (Mechanism)

### Mechanism 1
Clinical exams like CELF5 provide standardized, expert-validated tasks that isolate specific language skills across age groups. These tasks are administered to LMs via prompting, and performance is compared against human age norms to estimate demographic alignment. Core assumption: Human age norms derived from clinical populations are stable enough to serve as reference points for LM evaluation. Break condition: If LM training data includes clinical datasets or exam-style tasks, alignment estimates could be inflated or misleading.

### Mechanism 2
Automated statistical proxies (e.g., test divergence and energy distance) can approximate clinical evaluation at scale without human experts. Test divergence measures how LM errors differ from expected human errors at a given age; energy distance clusters responses to compare LM and human behavior distributions. Core assumption: The statistical behavior of LM errors mirrors human error patterns enough to be quantified and compared. Break condition: If LMs have non-human error patterns (e.g., systematic guessing, overfitting), statistical proxies may misestimate demographic fit.

### Mechanism 3
LMs exhibit age-dependent performance variability, excelling at some tasks while underperforming in others relative to human norms. By testing on tasks like word association, sentence formulation, and pragmatic judgment, the framework reveals task-specific gaps in LM capability. Core assumption: Task-specific LM performance can be meaningfully mapped to human developmental stages. Break condition: If LMs use fundamentally different cognitive strategies than humans, age mappings may not generalize beyond tested tasks.

## Foundational Learning

- Statistical hypothesis testing (χ², p-values, Bonferroni correction)
  - Why needed here: To determine if observed differences between LM and human performance are statistically significant or due to chance
  - Quick check question: If an LM gets 30% correct on a task where 50% of 10-year-olds are correct, how would you test if that gap is significant?

- Linear probability models and effect size interpretation
  - Why needed here: To quantify how specific linguistic features (e.g., POS, relation type) influence LM error rates while controlling for confounds
  - Quick check question: If LPM estimates a 3.5% increase in error probability for adjective-noun pairs, what does that imply about LM lexical processing?

- Energy statistics and distributional comparison
  - Why needed here: To compare LM and human response distributions without requiring exact outcome labels
  - Quick check question: If two response sets have high energy distance, what does that say about their distributional similarity?

## Architecture Onboarding

- Component map: Clinical Exam Adapter -> Error Feature Extractor -> Statistical Engine -> Human Norm Database -> Result Visualizer
- Critical path:
  1. Load LM and clinical task definitions
  2. Generate prompts and collect LM responses
  3. Extract linguistic features from responses
  4. Compare against human norms using statistical tests
  5. Output age estimates and error analyses
- Design tradeoffs:
  - Clinical vs. automated evaluation: expert accuracy vs. scalability
  - Granular vs. coarse age norms: sensitivity vs. statistical power
  - Feature-rich vs. lightweight extraction: insight depth vs. runtime
- Failure signatures:
  - High variance in LM responses → unstable age estimates
  - Poor feature extraction → misleading error analyses
  - Mismatched task difficulty → invalid norm comparisons
- First 3 experiments:
  1. Run WC large test with multiple prompts; compare age estimates
  2. Test effect of morphological complexity on error rates using LPM
  3. Simulate human-LM agreement; compare TD vs. means test sensitivity

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of GPT-3.5 on CELF5 tasks change when using a perceptually grounded model that can process visual stimuli? The paper mentions that the CELF5 exam includes visual stimuli that are removed when testing GPT-3.5 due to its inability to perceive visually. It also notes that the necessity of visual/embodied stimuli to inform lexical semantics has been hypothesized. The paper does not test GPT-3.5 with visual stimuli or compare its performance to a perceptually grounded model. Testing GPT-3.5 with visual stimuli or comparing its performance to a perceptually grounded model on CELF5 tasks would provide evidence for the impact of visual perception on language model performance.

### Open Question 2
How does the performance of GPT-3.5 on CELF5 tasks change when using a chat model like gpt-3.5-turbo instead of an instruction following model? The paper notes that InstructGPT struggles with social language use and suggests that chat models like gpt-3.5-turbo may have better social capabilities. It also mentions that the current study does not explore chat models. The paper does not test gpt-3.5-turbo on CELF5 tasks or compare its performance to InstructGPT. Testing gpt-3.5-turbo on CELF5 tasks and comparing its performance to InstructGPT would provide evidence for the impact of model type on language model performance.

### Open Question 3
How does the performance of GPT-3.5 on CELF5 tasks change when using a different prompt format or parameter settings? The paper mentions that it tests different prompt formats and parameter settings for nucleus sampling and temperature scaling, but finds no significant impact on GPT-3.5 performance. The paper does not exhaustively test all possible prompt formats and parameter settings, and it is possible that other settings could impact performance. Testing GPT-3.5 with a wider range of prompt formats and parameter settings would provide evidence for the impact of these choices on language model performance.

## Limitations
- Clinical exam adaptation validity concerns due to publishing agreements with Pearson, Inc.
- Automated statistical metrics lack established benchmarks for LM-human comparison
- Human age norms may not generalize to LM behavior due to different processing mechanisms

## Confidence
- **High**: The general framework design and its value for revealing task-specific LM weaknesses
- **Medium**: The specific age estimates for GPT-3.5 performance and their interpretation
- **Low**: The statistical validity of automated metrics as proxies for clinical evaluation

## Next Checks
1. **Clinical validity check**: Compare LM performance on adapted clinical tasks against results from a small-scale human pilot study to validate that task difficulty and discrimination remain intact.

2. **Statistical sensitivity test**: Conduct controlled experiments varying LM responses (adding noise, systematic errors) to measure how test divergence and energy distance metrics respond to known differences.

3. **Cross-task consistency analysis**: Evaluate whether age estimates from different clinical subtests (e.g., word association vs. pragmatic judgment) produce consistent or contradictory developmental mappings for the same LM.