---
ver: rpa2
title: Correcting Underrepresentation and Intersectional Bias for Classification
arxiv_id: '2306.11112'
source_url: https://arxiv.org/abs/2306.11112
tags:
- group
- lemma
- probability
- bias
- biased
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of learning from data corrupted
  by underrepresentation bias, where positive examples are filtered at different,
  unknown rates for a fixed number of sensitive groups. The authors propose a method
  to efficiently estimate group-wise drop-out rates, even in settings where intersectional
  group membership makes learning each intersectional rate computationally infeasible.
---

# Correcting Underrepresentation and Intersectional Bias for Classification

## Quick Facts
- arXiv ID: 2306.11112
- Source URL: https://arxiv.org/abs/2306.11112
- Authors: 
- Reference count: 40
- Key outcome: The paper addresses the problem of learning from data corrupted by underrepresentation bias, where positive examples are filtered at different, unknown rates for a fixed number of sensitive groups.

## Executive Summary
This paper presents a method for learning from data corrupted by underrepresentation bias, where positive examples are filtered at different, unknown rates across sensitive groups. The key innovation is efficiently estimating group-wise dropout rates even when intersectional group membership makes learning each intersectional rate computationally infeasible. By leveraging small amounts of unbiased data and assuming group membership independence, the authors construct a reweighting scheme that approximates the loss on the true distribution, enabling accurate risk estimation and hypothesis learning.

## Method Summary
The method involves collecting small unbiased and large biased datasets, estimating group-wise base rates from both, computing inverse bias parameters, applying reweighting to the biased sample, and performing empirical risk minimization on the reweighted data. The algorithm estimates group-wise dropout rates by leveraging the independence assumption of group membership, allowing decomposition of intersectional bias into multiplicative group-wise factors. This approach avoids the exponential computational cost of learning every intersectional rate explicitly while maintaining strong PAC-style guarantees on risk estimation.

## Key Results
- Efficient estimation of group-wise dropout rates using small unbiased samples
- Construction of reweighting scheme that approximates loss on true distribution
- Strong PAC-style guarantees on risk estimation with high probability
- Algorithm achieves arbitrary closeness to true risk with sufficient samples

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Intersectional bias can be decomposed into group-wise bias parameters that are learnable from small unbiased data.
- **Mechanism:** By modeling each group's positive example survival rate (βi) and assuming group membership independence, the authors can estimate intersectional bias as the product of individual biases without needing to learn every possible intersection explicitly.
- **Core assumption:** Group membership is independent, allowing decomposition of intersectional bias into multiplicative group-wise factors.
- **Evidence anchors:**
  - [abstract]: "We show that with a small amount of unbiased data, we can efficiently estimate the group-wise drop-out rates"
  - [section 3]: "We assume group membership is independent. We discussed the strengths and weaknesses of this assumption in Section 3."
  - [corpus]: Weak evidence - neighbors discuss similar reweighting approaches but don't validate the independence assumption specifically.
- **Break condition:** If group membership is correlated (e.g., race and socioeconomic status are not independent), the decomposition fails and intersectional rates cannot be accurately recovered from individual βi estimates.

### Mechanism 2
- **Claim:** Reweighting biased samples using estimated inverse bias parameters recovers the true risk of any hypothesis.
- **Mechanism:** The reweighting factor w(x,y) = ∏I(y=1) 1/βi + I(y=0) adjusts the loss contribution of each example based on its group memberships, making the biased sample approximate the true distribution.
- **Core assumption:** The reweighting factor correctly captures the transformation from true to biased distribution.
- **Evidence anchors:**
  - [abstract]: "Using these estimates, we construct a reweighting scheme that allows us to approximate the loss of any hypothesis on the true distribution"
  - [section 4.1]: Formal definition of w(x,y) and its relationship to the biased distribution Dβ
  - [corpus]: Strong evidence - neighbors use similar reweighting schemes for bias mitigation, validating the approach.
- **Break condition:** If the estimated βi values are inaccurate (due to insufficient unbiased data or model misspecification), the reweighting fails to properly recover the true distribution.

### Mechanism 3
- **Claim:** Small unbiased samples are sufficient to estimate group-wise biases accurately.
- **Mechanism:** The algorithm uses Chernoff bounds to show that with appropriate sample sizes, the estimated probabilities pi and piβi converge to their true values, enabling accurate estimation of 1/βi.
- **Core assumption:** The base rates pi and piβi can be estimated with sufficient precision from finite samples.
- **Evidence anchors:**
  - [section 6.1]: "The key lemma established in this part specifies the sample size requirements to achieve reliable probability estimation"
  - [appendix B.2]: Explicit sample size requirements using multiplicative Chernoff bounds
  - [corpus]: Moderate evidence - neighbors discuss sample complexity for bias estimation but don't provide the same theoretical guarantees.
- **Break condition:** If the true base rates are extremely imbalanced or the bias parameters are very small/large, the required sample sizes become infeasibly large, breaking the theoretical guarantees.

## Foundational Learning

- **Concept: VC dimension and PAC learning**
  - Why needed here: The paper provides PAC-style guarantees that depend on the VC dimension of the hypothesis class H to bound generalization error.
  - Quick check question: What does the VC dimension of a hypothesis class represent, and how does it relate to sample complexity requirements?

- **Concept: Hoeffding and Chernoff bounds**
  - Why needed here: These concentration inequalities are used throughout the proof to bound estimation errors and establish sample complexity requirements.
  - Quick check question: How does the multiplicative Chernoff bound differ from the standard Hoeffding bound, and when would you use each?

- **Concept: Empirical risk minimization (ERM)**
  - Why needed here: The algorithm uses ERM on the reweighted biased sample to find a hypothesis that minimizes the estimated true risk.
  - Quick check question: Under what conditions does ERM on a reweighted sample converge to the hypothesis that minimizes risk on the true distribution?

## Architecture Onboarding

- **Component map:** Unbiased data collection -> Biased data collection -> Group membership identification -> Base rate estimation -> Bias parameter estimation -> Reweighting engine -> ERM optimizer -> Validation pipeline

- **Critical path:**
  1. Collect unbiased and biased datasets
  2. Identify group memberships for all examples
  3. Estimate base rates pi from unbiased data
  4. Estimate biased base rates piβi from biased data
  5. Compute 1/βi = pi/(piβi) for each group
  6. Apply reweighting to biased samples
  7. Run ERM on reweighted biased data
  8. Validate performance on unbiased holdout

- **Design tradeoffs:**
  - Sample size allocation between unbiased vs biased data
  - Precision vs computational cost in bias estimation
  - Memory vs speed in reweighting computation
  - Model complexity vs generalization guarantees

- **Failure signatures:**
  - High variance in 1/βi estimates across groups
  - Reweighting factors become numerically unstable
  - Validation error much higher than training error
  - Certain groups have near-zero positive examples

- **First 3 experiments:**
  1. **Synthetic sanity check:** Generate data with known βi values, apply algorithm, verify 1/βi estimates match ground truth within confidence bounds.
  2. **Sample size sensitivity:** Vary the ratio of unbiased to biased samples and measure impact on final risk estimation accuracy.
  3. **Group independence violation:** Create correlated group memberships and measure degradation in bias estimation and final model performance.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided text.

## Limitations
- The independence assumption for group membership is critical but may not hold in real-world scenarios where groups are often correlated
- Sample complexity requirements may be prohibitive when dealing with many sensitive groups or extreme bias parameters
- The method focuses specifically on underrepresentation bias and doesn't address other types of bias like mislabeling or adversarial bias

## Confidence
- **High confidence:** The reweighting mechanism and its relationship to recovering true risk - this follows standard statistical learning theory and is well-supported by the literature
- **Medium confidence:** The group-wise bias estimation approach - theoretically sound but depends heavily on the independence assumption that needs empirical validation
- **Medium confidence:** The sample size requirements and convergence guarantees - the mathematical proofs appear correct, but practical feasibility in real-world scenarios is uncertain

## Next Checks
1. **Independence assumption stress test:** Create synthetic datasets with varying degrees of group membership correlation and measure how the bias estimation error and final model performance degrade as the independence assumption is violated.
2. **Real-world application:** Apply the algorithm to a publicly available dataset with known intersectional bias (e.g., COMPAS recidivism data or CelebA) and compare performance against baseline methods that don't account for intersectional bias.
3. **Sample efficiency evaluation:** Systematically vary the ratio of unbiased to biased samples across multiple orders of magnitude and measure the trade-off between sample cost and estimation accuracy, particularly for cases with many sensitive groups.