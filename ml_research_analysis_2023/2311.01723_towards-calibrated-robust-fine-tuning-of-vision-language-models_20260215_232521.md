---
ver: rpa2
title: Towards Calibrated Robust Fine-Tuning of Vision-Language Models
arxiv_id: '2311.01723'
source_url: https://arxiv.org/abs/2311.01723
tags:
- calibration
- fine-tuning
- conference
- learning
- robust
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the overlooked issue of confidence calibration
  in robust fine-tuning of vision-language models (VLMs) under distribution shifts.
  The authors show that both naive fine-tuning and state-of-the-art robust fine-tuning
  methods significantly degrade the calibration of pre-trained VLMs, especially on
  out-of-distribution (OOD) datasets.
---

# Towards Calibrated Robust Fine-Tuning of Vision-Language Models

## Quick Facts
- arXiv ID: 2311.01723
- Source URL: https://arxiv.org/abs/2311.01723
- Authors: 
- Reference count: 40
- Key outcome: CaRot achieves superior performance in both ID and OOD accuracy and calibration compared to existing methods.

## Executive Summary
This work addresses the overlooked issue of confidence calibration in robust fine-tuning of vision-language models (VLMs) under distribution shifts. The authors show that both naive fine-tuning and state-of-the-art robust fine-tuning methods significantly degrade the calibration of pre-trained VLMs, especially on out-of-distribution (OOD) datasets. To address this, they propose CaRot, a calibrated robust fine-tuning method that leverages label smoothing and multimodal knowledge distillation as a data-dependent label smoothing. CaRot enforces a larger smallest singular value of the input covariance matrix through a constrained multimodal contrastive loss, guided by self-distillation of a moving-averaged model.

## Method Summary
The paper proposes CaRot, a calibrated robust fine-tuning method for vision-language models. The method combines label smoothing with multimodal knowledge distillation using an Exponential Moving Average (EMA) teacher model. The fine-tuning objective consists of a multimodal contrastive loss (LMCL) and a multimodal knowledge distillation loss (LMKD), with label smoothing applied to the teacher's predictions. The EMA teacher model is updated periodically to serve as an ensemble of pre-trained and fine-tuned knowledge, providing stable target distributions for the student model. This approach aims to improve both in-distribution (ID) and out-of-distribution (OOD) calibration and accuracy.

## Key Results
- CaRot achieves superior performance in both ID and OOD accuracy and calibration compared to existing methods.
- The proposed method significantly improves the calibration of fine-tuned VLMs on ImageNet distribution shift benchmarks.
- CaRot outperforms state-of-the-art robust fine-tuning methods like WiSE-FT and FLYP in terms of calibration and accuracy.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Label smoothing and multimodal knowledge distillation improve calibration and OOD generalization by enforcing a larger smallest singular value of the input covariance matrix.
- Mechanism: The constrained multimodal contrastive loss in CaRot encourages the model to learn more robust representations by penalizing low singular values, while knowledge distillation provides data-dependent label smoothing that reduces overconfidence.
- Core assumption: The smallest singular value of the input covariance matrix is directly related to the model's calibration and OOD generalization performance.
- Evidence anchors:
  - [abstract]: "We show that both OOD classification and OOD calibration errors have a shared upper bound consisting of two terms of ID data: 1) ID calibration error and 2) the smallest singular value of the ID input covariance matrix."
  - [section]: "Based on this insight, we design a novel framework that conducts fine-tuning with a constrained multimodal contrastive loss enforcing a larger smallest singular value..."
  - [corpus]: Weak evidence - no direct mentions of singular value regularization in related works.
- Break condition: If the relationship between singular values and calibration/generalization is not causal or if the constrained loss fails to effectively increase the smallest singular value.

### Mechanism 2
- Claim: Self-distillation with an EMA teacher model improves calibration by blending pre-trained and fine-tuned knowledge.
- Mechanism: The EMA teacher model serves as an ensemble of the pre-trained (well-calibrated) and fine-tuned (task-specific) models, providing stable, data-dependent target distributions for the student model.
- Core assumption: The EMA teacher model maintains a good balance between pre-trained generalization and fine-tuned task performance, leading to better-calibrated predictions.
- Evidence anchors:
  - [abstract]: "Based on this insight, we design a novel framework that conducts fine-tuning with a constrained multimodal contrastive loss enforcing a larger smallest singular value, which is further guided by the self-distillation of a moving-averaged model to achieve calibrated prediction as well."
  - [section]: "By interpolating the weight of a pre-trained VLM with that of a dynamically fine-tuned one, we can view our teacher model as an ensemble of multi-domain calibrated predictor (pre-trained VLM) and in-domain calibrated predictor (fine-tuning VLM)..."
  - [corpus]: Weak evidence - no direct mentions of EMA-based self-distillation for calibration in related works.
- Break condition: If the EMA teacher model fails to maintain a good balance between pre-trained and fine-tuned knowledge, or if the self-distillation process introduces instability.

### Mechanism 3
- Claim: Multimodal contrastive loss with label smoothing improves ID and OOD calibration by encouraging consistent representations across modalities.
- Mechanism: The contrastive loss aligns image and text embeddings, while label smoothing prevents overconfidence, leading to better-calibrated predictions on both ID and OOD data.
- Core assumption: Consistent multimodal representations and reduced overconfidence directly contribute to improved calibration and OOD generalization.
- Evidence anchors:
  - [abstract]: "Starting from empirical evidence supporting our theoretical statements, we provide extensive experimental results on ImageNet distribution shift benchmarks that demonstrate the effectiveness of our theorem and its practical implementation."
  - [section]: "Drawing inspiration from FLYP, we utilize contrastive loss as our fine-tuning objective... We finalize our learning objective as a sum of LMCL and LMKD with hyperparameter lambda that controls the magnitude of distillation..."
  - [corpus]: Weak evidence - no direct mentions of multimodal contrastive loss with label smoothing for calibration in related works.
- Break condition: If the multimodal contrastive loss fails to align representations effectively or if label smoothing introduces excessive uncertainty.

## Foundational Learning

- Concept: Expected Calibration Error (ECE)
  - Why needed here: ECE is the primary metric used to evaluate the calibration of fine-tuned VLMs in this work.
  - Quick check question: What is the formula for ECE, and how does it measure the difference between predicted confidence and actual accuracy?

- Concept: Out-of-Distribution (OOD) Generalization
  - Why needed here: The paper focuses on improving both ID and OOD calibration and generalization, making it crucial to understand the concept of OOD generalization.
  - Quick check question: How does OOD generalization differ from in-distribution generalization, and why is it important for real-world applications?

- Concept: Knowledge Distillation
  - Why needed here: The paper proposes using multimodal knowledge distillation as a form of data-dependent label smoothing to improve calibration.
  - Quick check question: What is the main idea behind knowledge distillation, and how can it be used to improve model calibration?

## Architecture Onboarding

- Component map:
  - Vision encoder (f_θv)
  - Language encoder (g_θl)
  - Multimodal contrastive loss (LMCL)
  - Multimodal knowledge distillation loss (LMKD)
  - EMA teacher model (ψ)
  - Label smoothing (LS)

- Critical path:
  1. Initialize vision and language encoders with pre-trained weights.
  2. Compute multimodal contrastive loss (LMCL) between image and text embeddings.
  3. Compute multimodal knowledge distillation loss (LMKD) using EMA teacher model.
  4. Combine LMCL and LMKD with label smoothing to form the final loss.
  5. Update model parameters using the combined loss.
  6. Periodically update the EMA teacher model.

- Design tradeoffs:
  - Balancing the contribution of LMCL and LMKD to the final loss (controlled by lambda).
  - Choosing the update frequency for the EMA teacher model (default: every 500 iterations).
  - Selecting the label smoothing parameter (default: 0.1).

- Failure signatures:
  - Degraded ID and OOD accuracy due to over-regularization.
  - Unstable training due to improper EMA teacher model updates.
  - Over-smoothing of predictions leading to under-confident outputs.

- First 3 experiments:
  1. Implement and test the multimodal contrastive loss (LMCL) with label smoothing on a small dataset.
  2. Add the multimodal knowledge distillation loss (LMKD) with a simple EMA teacher model update.
  3. Fine-tune the entire CaRot pipeline on ImageNet-1K and evaluate ID and OOD calibration and accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method's calibration performance generalize to other vision-language models beyond CLIP?
- Basis in paper: [explicit] The authors mention using CLIP ViT-B/16 as the backbone model but do not test other VLMs
- Why unresolved: The paper only validates the method on one specific VLM architecture, leaving open whether results would hold for other models
- What evidence would resolve it: Experimental results showing calibration performance of CaRot when applied to other VLMs like ALIGN, OpenCLIP, or FLAVA

### Open Question 2
- Question: What is the relationship between label smoothing parameter values and calibration performance across different datasets?
- Basis in paper: [inferred] The authors test a range of label smoothing parameters but do not provide detailed analysis of how optimal values vary by dataset
- Why unresolved: The ablation study shows some parameter testing but lacks systematic analysis of parameter sensitivity and optimal selection strategies
- What evidence would resolve it: Comprehensive sensitivity analysis showing calibration performance across multiple datasets for different label smoothing values

### Open Question 3
- Question: How does the proposed method's performance scale with model size and pre-training data scale?
- Basis in paper: [explicit] The authors acknowledge that modern VLMs vary in model size and pre-training scale but only test on one model configuration
- Why unresolved: No experiments are conducted to verify if the calibration improvements hold for larger or smaller models, or models with different amounts of pre-training
- What evidence would resolve it: Experiments testing CaRot on VLMs of different sizes (e.g., ViT-L/14, ViT-H/14) and with different amounts of pre-training data

## Limitations

- The theoretical claims about singular values of the input covariance matrix directly controlling calibration and OOD generalization are weakly supported, as the paper doesn't empirically verify this relationship or demonstrate that the constrained contrastive loss effectively increases these singular values.
- The proposed CaRot method combines multiple components without ablation studies isolating which components drive the improvements.
- The evaluation focuses exclusively on ImageNet-1K distribution shift benchmarks, limiting generalizability to other domains or VLM architectures.

## Confidence

- **High confidence**: The empirical observation that both naive fine-tuning and existing robust fine-tuning methods degrade calibration on OOD data is well-supported by the experimental results across multiple benchmarks.
- **Medium confidence**: The claim that CaRot improves both ID and OOD calibration and accuracy is supported by experimental results, though the lack of ablation studies and the multi-component nature of the method make it difficult to attribute improvements to specific mechanisms.
- **Low confidence**: The theoretical claims about singular values of the input covariance matrix directly controlling calibration and OOD generalization are weakly supported, as the paper doesn't empirically verify this relationship or demonstrate that the constrained contrastive loss effectively increases these singular values.

## Next Checks

1. **Ablation study validation**: Conduct systematic ablation experiments removing each component (label smoothing, knowledge distillation, EMA teacher, contrastive loss) to determine which mechanisms actually contribute to the observed improvements in calibration and accuracy.

2. **Singular value analysis validation**: Empirically measure the smallest singular values of the input covariance matrix before and after CaRot fine-tuning, and correlate these values with calibration metrics across different datasets to verify the theoretical claims.

3. **Generalization testing**: Evaluate CaRot on additional VLM architectures (e.g., CLIP with different backbones) and diverse domains beyond ImageNet (e.g., medical imaging, satellite imagery) to assess the method's broader applicability and identify any domain-specific limitations.