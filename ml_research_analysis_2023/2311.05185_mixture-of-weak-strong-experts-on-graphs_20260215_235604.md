---
ver: rpa2
title: Mixture of Weak & Strong Experts on Graphs
arxiv_id: '2311.05185'
source_url: https://arxiv.org/abs/2311.05185
tags:
- mowst
- experts
- expert
- have
- nodes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a mixture-of-experts framework for graph neural
  networks that combines a lightweight multi-layer perceptron (MLP) with a stronger
  GNN expert. The key idea is to use a confidence mechanism based on the MLP's prediction
  dispersion to dynamically gate which expert contributes more to the final prediction.
---

# Mixture of Weak & Strong Experts on Graphs

## Quick Facts
- arXiv ID: 2311.05185
- Source URL: https://arxiv.org/abs/2311.05185
- Reference count: 40
- Primary result: Mixture-of-experts framework combining MLP and GNN experts with dynamic gating improves accuracy on 6 graph benchmarks

## Executive Summary
This paper introduces a mixture-of-experts framework for graph neural networks that strategically combines a lightweight MLP expert with a stronger GNN expert. The key innovation is a confidence mechanism based on MLP prediction dispersion that dynamically gates which expert contributes more to final predictions. This allows the model to leverage both self-features and neighborhood structure effectively while maintaining computational efficiency. The framework demonstrates consistent accuracy improvements over state-of-the-art methods on standard benchmarks spanning both homophilous and heterophilous graphs.

## Method Summary
The framework employs two experts: a lightweight MLP operating on node features only, and a standard GNN processing graph structure with features. A confidence function computes dispersion from MLP predictions to determine gating weights. During training, experts are updated in turns - one expert's parameters are fixed while the other is optimized using a confidence-weighted loss. This iterative process allows each expert to specialize on different node subsets. The MLP focuses on nodes where self-features suffice, while the GNN handles nodes requiring neighborhood information. The framework maintains computational efficiency comparable to a single GNN while achieving superior expressive power.

## Key Results
- Consistent accuracy improvements over state-of-the-art methods on 6 standard benchmarks
- Effective performance on both homophilous (Flickr, ogbn-products, ogbn-arxiv) and heterophilous (Penn94, pokec, twitch-gamer) graphs
- Maintains computational efficiency comparable to a single GNN despite using two experts
- Demonstrates strong expressive power through dynamic expert activation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The MLP expert specializes on nodes where self-features are sufficient for prediction, while the GNN expert handles nodes where neighborhood information is necessary.
- Mechanism: The confidence mechanism based on MLP prediction dispersion dynamically gates expert activation, allowing each expert to focus on their respective strengths without competition.
- Core assumption: Nodes can be partitioned into those where self-features are sufficient versus those where neighborhood aggregation is necessary for accurate prediction.
- Evidence anchors:
  - [abstract] "The strong expert is conditionally activated when either the node's classification relies on neighborhood information, or the weak expert has low model quality."
  - [section 2.3] "The MLP expert can fit an arbitrary function on node features" and "nodes are in the same group, Mi, if and only if they have indistinguishable self-features"
  - [corpus] No direct evidence found for this specific partitioning mechanism, though related concepts exist in MoE literature
- Break condition: If node classification consistently requires both self-features and neighborhood information simultaneously, the binary gating would force suboptimal predictions.

### Mechanism 2
- Claim: The training dynamics create a soft data splitting that leads to expert specialization.
- Mechanism: During training, the system iteratively assigns nodes to either expert based on relative performance, with the MLP gradually focusing on nodes it can handle well while the GNN handles the rest.
- Core assumption: The "training in turn" strategy allows experts to specialize without interfering with each other's optimization.
- Evidence anchors:
  - [section 2.4] "When it is GNN's turn to update its model parameters, the GNN optimizes SGNN better due to the larger loss weight" and "the MLP will completely ignore such challenging nodes"
  - [section 2.4] "This process goes on and each additional round of 'in-turn training' reinforces better specialization between experts"
  - [corpus] No direct evidence found for this specific iterative specialization mechanism, though MoE literature suggests similar dynamics
- Break condition: If the two experts have similar convergence rates or if the loss landscape prevents clear separation of responsibilities.

### Mechanism 3
- Claim: The MLP acts as a denoising filter during training, improving GNN convergence.
- Mechanism: The MLP overfits to noisy nodes (where GNN performs poorly), eliminating harmful gradients that would otherwise prevent GNN from improving on clean nodes.
- Core assumption: Some nodes contain irrecoverable noise that prevents GNN from learning effectively, but MLP can still learn these noisy patterns.
- Evidence anchors:
  - [section 2.4] "MLP's overfitting eliminates the harmful gradients for the GNN, enabling it to fine-tune on S2"
  - [section 2.4] "In this case, MLP is a training-time noise filter"
  - [corpus] No direct evidence found for this specific denoising mechanism, though the concept of data filtering exists in ML literature
- Break condition: If the noise patterns are too complex for the MLP to learn, or if the noise affects all nodes uniformly.

## Foundational Learning

- Concept: Quasiconvex functions and their properties
  - Why needed here: The confidence function C = G ◦ D must be quasiconvex to ensure proper gating behavior and maintain theoretical guarantees
  - Quick check question: If D is quasiconvex and G is monotonically non-decreasing, is C = G ◦ D quasiconvex? (Answer: Yes, by composition rules)

- Concept: Convex optimization and KKT conditions
  - Why needed here: The optimization analysis in Section 2.3 relies on convex analysis to determine optimal expert behavior
  - Quick check question: For the cross-entropy loss L(p,y) with respect to p, is it convex? (Answer: Yes, for fixed y)

- Concept: Universal approximation theorem for MLPs
  - Why needed here: The analysis assumes the MLP can fit arbitrary functions on node features, justifying the specialization mechanism
  - Quick check question: Can a sufficiently wide MLP approximate any continuous function on a compact domain? (Answer: Yes, by the universal approximation theorem)

## Architecture Onboarding

- Component map: MLP expert -> Confidence module -> GNN expert -> Mixture layer -> Final prediction
- Critical path:
  1. Forward pass through MLP to get predictions and confidence
  2. Decision to skip GNN based on confidence threshold
  3. Forward pass through GNN if needed
  4. Weighted combination of predictions
  5. Loss computation using weighted combination
- Design tradeoffs:
  - Weak-strong vs strong-strong expert pairing: Simpler optimization but potential accuracy ceiling
  - Layer-level vs model-level mixture: Computational efficiency vs fine-grained control
  - Learnable vs fixed confidence function: Adaptability vs training stability
- Failure signatures:
  - Confidence scores clustering around 0.5: Poor gating mechanism or experts with similar capabilities
  - One expert dominating (confidence near 0 or 1 for all nodes): Overspecialization or poor expert design
  - Training instability: Issues with the "training in turn" strategy or learning rate mismatches
- First 3 experiments:
  1. Ablation study: Remove confidence mechanism and use fixed threshold, measure impact on accuracy and training stability
  2. Expert swapping: Replace MLP with a stronger MLP or weaker GNN, observe changes in specialization patterns
  3. Graph property analysis: Train on graphs with varying homophily levels, analyze how confidence distributions change with graph characteristics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of the confidence function G impact the model's performance on different types of graphs (e.g., homophilous vs. heterophilous)?
- Basis in paper: [inferred] The paper discusses the confidence function G as a key component of the model and mentions that different shapes of G can influence the model's behavior. However, it does not provide a detailed analysis of how G affects performance on different graph types.
- Why unresolved: The paper does not conduct experiments or provide theoretical analysis on how different G functions impact performance across various graph types.
- What evidence would resolve it: Experiments comparing the performance of Mowst with different G functions on both homophilous and heterophilous graphs, along with theoretical analysis of how G influences the model's behavior in different graph structures.

### Open Question 2
- Question: Can the "weak-strong" expert design be generalized to more than two experts, and how does this affect the model's expressive power and computational efficiency?
- Basis in paper: [explicit] The paper mentions extending the framework to more than two experts in Section 2.7, but does not provide detailed analysis or experiments on this generalization.
- Why unresolved: The paper only briefly discusses the generalization to more experts without providing empirical results or theoretical analysis on the implications for expressive power and computational efficiency.
- What evidence would resolve it: Experiments comparing the performance of Mowst with different numbers of experts, along with theoretical analysis of how the number of experts affects the model's expressive power and computational complexity.

### Open Question 3
- Question: How does the "in-turn training" strategy compare to simultaneous training of both experts in terms of convergence speed and final model performance?
- Basis in paper: [explicit] The paper mentions using "in-turn training" as an alternative to simultaneous training in Algorithm 2, but does not provide a detailed comparison between the two strategies.
- Why unresolved: The paper does not conduct experiments or provide theoretical analysis comparing the two training strategies in terms of convergence speed and final performance.
- What evidence would resolve it: Experiments comparing the convergence speed and final performance of Mowst using both "in-turn training" and simultaneous training strategies, along with theoretical analysis of the differences in optimization dynamics between the two approaches.

## Limitations

- The confidence function G(D) and its quasiconvex properties are not fully specified in the paper, making it difficult to verify the theoretical guarantees.
- The "training in turn" strategy's effectiveness depends heavily on hyperparameter tuning, which may limit practical applicability.
- The mechanism by which MLP acts as a denoising filter during training is not empirically validated, despite theoretical claims.

## Confidence

- High confidence: The framework's architecture and training procedure are clearly described and reproducible
- Medium confidence: The theoretical analysis of optimal expert behavior is sound, but empirical validation is limited
- Low confidence: The confidence mechanism's ability to properly gate expert activation across diverse graph structures

## Next Checks

1. **Confidence mechanism validation**: Analyze confidence score distributions across different graph homophily levels to verify the gating mechanism works as intended
2. **Expert specialization analysis**: Compare prediction patterns between MLP and GNN experts to confirm they specialize on distinct node subsets
3. **Robustness testing**: Evaluate performance on graphs with varying noise levels to test the denoising hypothesis and identify failure conditions