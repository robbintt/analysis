---
ver: rpa2
title: 'Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for Knowledge-intensive
  Question Answering'
arxiv_id: '2308.13259'
source_url: https://arxiv.org/abs/2308.13259
tags:
- question
- answer
- reasoning
- knowledge
- thought
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a framework to enhance the reasoning capabilities
  of large language models (LLMs) in knowledge-intensive tasks by addressing hallucinations
  and lack of external knowledge access. The proposed Knowledge-Driven Chain-of-Thought
  (KD-CoT) framework interacts with a QA system that retrieves external knowledge
  to verify and modify intermediate reasoning steps, thus improving the faithfulness
  and accuracy of the reasoning process.
---

# Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for Knowledge-intensive Question Answering

## Quick Facts
- **arXiv ID**: 2308.13259
- **Source URL**: https://arxiv.org/abs/2308.13259
- **Reference count**: 4
- **Primary result**: KD-CoT improves success rate by 8.0% on WebQSP and 5.1% on ComplexWebQuestions

## Executive Summary
This paper introduces a framework to enhance the reasoning capabilities of large language models (LLMs) in knowledge-intensive tasks by addressing hallucinations and lack of external knowledge access. The proposed Knowledge-Driven Chain-of-Thought (KD-CoT) framework interacts with a QA system that retrieves external knowledge to verify and modify intermediate reasoning steps, thus improving the faithfulness and accuracy of the reasoning process. This is achieved by structuring the reasoning into a multi-round QA format, where each round involves interaction with a retrieve-then-read pipeline and an answer verifier. Experiments on WebQSP and ComplexWebQuestions datasets demonstrate significant improvements, with KD-CoT outperforming vanilla CoT in-context learning by 8.0% and 5.1% in success rate, respectively. Additionally, the feedback-augmented retriever shows substantial improvement in Hit and recall performance.

## Method Summary
The paper proposes the Knowledge-Driven Chain-of-Thought (KD-CoT) framework to enhance LLM reasoning in knowledge-intensive question answering tasks. The method involves formulating the Chain-of-Thought (CoT) rationale process into a structured multi-round QA format, where an LLM interacts with a QA system that retrieves external knowledge to verify and modify intermediate reasoning steps. A KBQA CoT collection is constructed as in-context learning demonstrations and feedback augmentation to train a robust retriever. The framework consists of an LLM (thinker), a retrieve-then-read pipeline (retriever, reader, verifier), and a KBQA CoT collection. The critical path involves the LLM generating sub-questions, the retrieve-then-read pipeline retrieving knowledge and generating candidate answers, the verifier comparing candidate answers with LLM sub-answers, and the LLM updating reasoning traces if necessary.

## Key Results
- KD-CoT outperforms vanilla CoT in-context learning by 8.0% and 5.1% in success rate on WebQSP and ComplexWebQuestions datasets, respectively.
- The feedback-augmented retriever shows substantial improvement in Hit and recall performance.
- KD-CoT demonstrates improved faithfulness and accuracy of reasoning compared to vanilla CoT approaches.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: LLMs generate unfaithful intermediate reasoning steps in knowledge-intensive tasks due to hallucinations and inability to access external knowledge.
- **Mechanism**: KD-CoT interacts with a QA system that retrieves external knowledge to verify and modify intermediate reasoning steps, improving faithfulness.
- **Core assumption**: The QA system can provide accurate answers to sub-questions that correct LLM's reasoning errors.
- **Evidence anchors**:
  - [abstract]: "suffering from hallucinations and the inability to access external knowledge, LLMs often come with incorrect or unfaithful intermediate reasoning steps"
  - [section]: "To alleviate this issue, we propose a framework called Knowledge-Driven Chain-of-Thought (KD-CoT) to verify and modify reasoning traces in CoT via interaction with external knowledge"
  - [corpus]: Weak evidence - only 5 related papers found with average FMR=0.491, no citations.
- **Break condition**: If the QA system cannot retrieve accurate external knowledge or the verifier fails to identify incorrect sub-answers.

### Mechanism 2
- **Claim**: Structured multi-round QA format facilitates dynamic reasoning that can verify and adjust intermediate reasoning steps.
- **Mechanism**: Each round involves LLM interacting with the QA system, producing reasoning traces based on retrieved answers.
- **Core assumption**: The structured format guides LLM to generate sub-questions that can be answered by the QA system.
- **Evidence anchors**:
  - [abstract]: "we formulate the CoT rationale process of LLMs into a structured multi-round QA format"
  - [section]: "Concretely, we formulate the CoT rationale process of LLMs into a structured multi-round QA format"
  - [corpus]: Weak evidence - only 5 related papers found, no direct support for structured QA format.
- **Break condition**: If LLM fails to generate structured sub-questions or the QA system cannot answer them.

### Mechanism 3
- **Claim**: Feedback-augmented retriever trained on CoT collection improves knowledge retrieval performance.
- **Mechanism**: CoT collection is used as feedback to identify relevant passages, training a robust retriever.
- **Core assumption**: The CoT collection contains accurate reasoning traces that can guide retriever training.
- **Evidence anchors**:
  - [abstract]: "The structured CoT reasoning of LLMs is facilitated by our developed KBQA CoT collection, which serves as in-context learning demonstrations and can also be utilized as feedback augmentation to train a robust retriever"
  - [section]: "To obtain a robust retriever, we propose to utilize the constructed CoT as feedback to identify relevant passages"
  - [corpus]: Weak evidence - only 5 related papers found, no direct support for feedback-augmented retriever.
- **Break condition**: If the CoT collection is not representative of real questions or contains errors.

## Foundational Learning

- **Concept**: Chain-of-Thought (CoT) prompting
  - **Why needed here**: Enables LLMs to generate step-by-step reasoning traces for complex problems
  - **Quick check question**: Can you explain how CoT prompting differs from standard prompting?

- **Concept**: Knowledge Base Question Answering (KBQA)
  - **Why needed here**: The task requires answering questions using structured knowledge from KBs
  - **Quick check question**: What are the main challenges in KBQA that this paper addresses?

- **Concept**: Retrieve-then-read pipeline
  - **Why needed here**: Retrieves relevant knowledge from external sources to augment LLM's reasoning
  - **Quick check question**: How does a retrieve-then-read pipeline work in the context of question answering?

## Architecture Onboarding

- **Component map**: LLM (thinker) -> Retrieve-then-read pipeline -> Answer verifier -> LLM (reasoning update)

- **Critical path**:
  1. LLM generates sub-question
  2. Retrieve-then-read pipeline retrieves knowledge and generates candidate answer
  3. Verifier compares candidate answer with LLM's sub-answer
  4. If different, LLM updates reasoning trace
  5. Repeat until final answer

- **Design tradeoffs**:
  - Cost vs. accuracy: Using LLM for verification is expensive but improves performance
  - Retrieval vs. reasoning: Balancing knowledge retrieval with LLM's reasoning capabilities
  - Structured vs. unstructured: Choosing between structured CoT format and more flexible approaches

- **Failure signatures**:
  - LLM fails to generate structured sub-questions
  - Retriever fails to find relevant passages
  - Verifier cannot decide between answers
  - CoT collection is not representative

- **First 3 experiments**:
  1. Compare KD-CoT with vanilla CoT ICL on WebQSP and CWQ datasets
  2. Ablation study: Remove retrieve-then-read pipeline and verifier separately
  3. Analyze performance gain after each iteration of interaction

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can we train a more robust reader to generate varied and accurate answers for sub-questions, which is crucial for fully unleashing the potential of LLM in the Knowledge-Driven Chain-of-Thought framework?
- **Basis in paper**: [explicit] The paper mentions that "a robust reader capable of producing varied and accurate answers is crucial in fully unleashing the potential of LLM" and acknowledges that the reader's current performance is not optimal.
- **Why unresolved**: The paper does not provide specific methods or strategies to improve the reader's performance beyond its current capabilities.
- **What evidence would resolve it**: Evidence of improved reader performance through specific training techniques or architectural changes that lead to more accurate and varied answers for sub-questions.

### Open Question 2
- **Question**: How can we develop a more efficient technique than the current Knowledge-Driven Chain-of-Thought framework to reduce the cost associated with the additional LLM and verifier while maintaining or improving performance?
- **Basis in paper**: [explicit] The paper states that "our method is still costly as the entire framework contains an extra LLM and a verifier" and suggests that "more efficient techniques such as searching on the web or filtering retrieved knowledge can be utilized to further decrease the cost of KD-CoT."
- **Why unresolved**: The paper does not explore or propose specific alternative techniques to reduce the computational cost of the framework.
- **What evidence would resolve it**: Evidence of a more efficient framework that achieves comparable or better performance with reduced computational resources or cost.

### Open Question 3
- **Question**: How can we supervise both the reasoning questions and answers to prevent hallucinations in LLM, beyond just correcting sub-answers?
- **Basis in paper**: [explicit] The paper mentions that "future work can focus on training a more robust reader or supervising both the reasoning questions and answers" to address the issue of LLM hallucinations.
- **Why unresolved**: The paper does not provide a detailed approach or methodology for supervising both the reasoning questions and answers to mitigate hallucinations.
- **What evidence would resolve it**: Evidence of a method that effectively supervises both the reasoning questions and answers, leading to a reduction in hallucinations and improved faithfulness of the LLM's reasoning.

## Limitations
- The framework relies heavily on the quality of the constructed KBQA CoT collection and the performance of the retrieve-then-read pipeline, which are not fully detailed.
- The success of KD-CoT depends on the ability of the QA system to provide accurate answers to sub-questions, which may not always be feasible.
- The framework is costly due to the additional LLM and verifier, and more efficient techniques need to be explored to reduce computational resources.

## Confidence
- **High Confidence**: The framework's core idea of using external knowledge to verify and modify LLM reasoning steps is sound and addresses a well-documented problem in LLMs.
- **Medium Confidence**: The reported improvements in success rate (8.0% and 5.1% on WebQSP and ComplexWebQuestions datasets) are significant but may vary depending on the quality of the constructed KBQA CoT collection and the performance of the retrieve-then-read pipeline.
- **Low Confidence**: The exact implementation details of the KBQA CoT collection construction process and the specific configuration of the retrieve-then-read pipeline are not fully specified, making it difficult to reproduce the results.

## Next Checks
1. **Reproduce the KBQA CoT Collection**: Construct a new KBQA CoT collection using the same datasets (WebQSP and ComplexWebQuestions) and evaluate its quality by measuring the similarity between generated sub-questions and ground truth reasoning paths.
2. **Ablation Study of the Retrieve-then-Read Pipeline**: Remove the retrieve-then-read pipeline and the answer verifier separately to assess their individual contributions to the overall performance improvement.
3. **Generalization to Other Datasets**: Test KD-CoT on additional knowledge-intensive QA datasets (e.g., HotpotQA or NaturalQuestions) to evaluate its generalization capabilities and identify potential limitations.