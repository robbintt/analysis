---
ver: rpa2
title: Acquiring Qualitative Explainable Graphs for Automated Driving Scene Interpretation
arxiv_id: '2308.12755'
source_url: https://arxiv.org/abs/2308.12755
tags:
- objects
- scene
- frame
- qualitative
- frames
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Qualitative eXplainable Graphs (QXGs), a
  novel symbolic representation for long-term automated driving scenes that captures
  spatiotemporal relationships between objects without relying on raw quantitative
  sensor data. The QXG-Builder algorithm constructs these graphs using Generic Qualitative
  Constraint Acquisition (GEQCA) with Rectangle Algebra to efficiently encode object
  relationships across frames.
---

# Acquiring Qualitative Explainable Graphs for Automated Driving Scene Interpretation

## Quick Facts
- arXiv ID: 2308.12755
- Source URL: https://arxiv.org/abs/2308.12755
- Authors: 
- Reference count: 27
- Primary result: Qualitative eXplainable Graphs (QXGs) enable real-time, interpretable automated driving scene representation with 88-94% storage reduction

## Executive Summary
This paper introduces Qualitative eXplainable Graphs (QXGs), a novel symbolic representation for long-term automated driving scenes that captures spatiotemporal relationships between objects without relying on raw quantitative sensor data. The QXG-Builder algorithm constructs these graphs using Generic Qualitative Constraint Acquisition (GEQCA) with Rectangle Algebra to efficiently encode object relationships across frames. Experiments on the NuScenes dataset demonstrate that QXGs can be computed in real-time (under 40ms per frame) for scenes with up to 300 objects, while reducing storage requirements by 88-94% compared to raw sensor data.

## Method Summary
The QXG-Builder algorithm processes NuScenes multimodal data (LiDAR, camera, radar) to construct qualitative graphs. It uses GEQCA with Rectangle Algebra to iteratively acquire spatial-temporal constraints between object pairs, replacing raw sensor data with symbolic relations. The system builds graphs frame-by-frame, encoding bounding box relationships through 169 possible qualitative relations, and stores these as edge labels across time. The approach leverages pre-computed BirdNet+ detections and object tracking to maintain consistent object identities across frames.

## Key Results
- QXG construction achieves real-time performance (<40ms per frame) for scenes with up to 300 objects
- Storage reduction of 88-94% compared to raw sensor data representations
- Algorithm handles at least 25 frames with over 280 objects per second
- QXG density reaches 85% for LiDAR data and 53-47% for camera data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Qualitative Explainable Graphs (QXGs) drastically reduce storage and computation costs by replacing raw sensor data with symbolic spatial-temporal relations.
- Mechanism: QXG-Builder encodes each object's bounding box per frame as a rectangle and captures inter-object relations using Rectangle Algebra (169 possible relations). This compresses scene data into compact graph structures.
- Core assumption: Bounding boxes provide sufficient abstraction for qualitative spatial reasoning without loss of relevant information.
- Evidence anchors:
  - [abstract] "reducing storage requirements by 88-94% compared to raw sensor data"
  - [section] "QXG-Builder run in cubic time complexity O(n × m²)" and "can handle at least 25 frames with over 280 objects per second"
  - [corpus] Weak or missing direct quantitative evidence; claim supported only by cited experimental results in the paper.
- Break condition: If bounding boxes lose critical spatial detail (e.g., small occlusions or near-touching objects), the qualitative relations may become ambiguous or incorrect.

### Mechanism 2
- Claim: GEQCA-based constraint acquisition eliminates the need to test all 169 relations by iteratively pruning impossible ones via user-oracle feedback.
- Mechanism: For each pair of objects, GEQCA presents possible relations to an oracle (program), discarding those marked "no" and applying path consistency to reduce remaining candidates.
- Core assumption: A deterministic oracle can accurately classify qualitative spatial relations from bounding box geometry.
- Evidence anchors:
  - [section] "GEQCA call operates on pairs of objects rather than the entire graph, no PC is maintained during the call"
  - [section] "processing time per frame without qualitative acquisition is approximately 0.2 seconds...reduced to 0.04 seconds" with GEQCA
  - [corpus] No direct comparative studies outside this paper; evidence is internal.
- Break condition: If oracle misclassifies relations, GEQCA may prune valid constraints, corrupting the graph.

### Mechanism 3
- Claim: QXGs enable interpretability by exposing explicit spatiotemporal object relationships, making vehicle decisions traceable to scene structure.
- Mechanism: Each edge in QXG stores a vector of RA relations across frames, encoding how objects relate spatially at each timestep.
- Core assumption: Human operators can interpret qualitative relations (e.g., "precedes", "overlaps") as meaningful scene explanations.
- Evidence anchors:
  - [abstract] "human-interpretable form allows for clear insights into the relationships between objects"
  - [section] "QXGs provide valuable opportunities for learning and mining patterns from AD scenes"
  - [corpus] Limited external validation; mostly theoretical claim.
- Break condition: If qualitative relations are too abstract or context-dependent, explanations may not align with human intuition.

## Foundational Learning

- Rectangle Algebra
  - Why needed here: RA defines the 169 possible spatial relations between bounding boxes, forming the basis of QXG edge labels.
  - Quick check question: How many atomic relations are in Allen's interval algebra before RA extends it?

- Generic Qualitative Constraint Acquisition (GEQCA)
  - Why needed here: GEQCA iteratively prunes impossible relations between object pairs, reducing computation from 169 checks to only necessary ones.
  - Quick check question: What consistency check does GEQCA apply after each "no" response to further prune relations?

- Object Detection and Tracking Pipeline
  - Why needed here: QXG-Builder relies on accurate per-frame bounding boxes to construct spatial relations; poor tracking corrupts the graph.
  - Quick check question: In NuScenes, which algorithm is cited for generating the bounding boxes used in experiments?

## Architecture Onboarding

- Component map: NuScenes loader → ObjectDT tracker → QXG-Builder → GEQCA → Rectangle Algebra → QXG storage
- Critical path: Frame ingestion → object detection → pair-wise GEQCA → graph update → output QXG
- Design tradeoffs:
  - Memory vs. detail: Bounding boxes compress data but lose fine-grained geometry.
  - Speed vs. accuracy: GEQCA pruning speeds up but depends on oracle correctness.
  - Interpretability vs. expressiveness: QXG is human-readable but limited to qualitative relations.
- Failure signatures:
  - Slow frame rates → bounding box drift or missing objects.
  - High memory use → many objects per frame or dense relations.
  - Uninterpretable outputs → ambiguous or contradictory RA relations.
- First 3 experiments:
  1. Run QXG-Builder on a single NuScenes LiDAR frame with 2-3 objects; verify edge labels match expected RA relations.
  2. Compare processing time with and without GEQCA on a 10-object scene; confirm ~80% reduction.
  3. Serialize and deserialize a QXG; ensure memory footprint matches the claimed 88-94% reduction versus raw sensor data.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can QXGs be effectively integrated with existing perception and decision-making modules in autonomous vehicles to enhance overall system performance?
- Basis in paper: [explicit] The paper mentions the potential for integrating QXG-Builder with other modules but does not explore this integration in detail.
- Why unresolved: The integration process and its impact on system performance are not addressed, leaving a gap in understanding how QXGs can be utilized in real-world applications.
- What evidence would resolve it: Experimental studies demonstrating the performance improvements and challenges of integrating QXGs with existing autonomous vehicle systems.

### Open Question 2
- Question: What are the scalability limits of QXG-Builder for larger and more complex scenes with increasing numbers of objects and frames?
- Basis in paper: [explicit] The paper discusses the algorithm's performance on scenes with up to 300 objects but does not explore its scalability beyond this limit.
- Why unresolved: The paper does not provide data or analysis on how the algorithm performs with significantly larger datasets, which is crucial for real-world applications.
- What evidence would resolve it: Comprehensive testing and analysis of QXG-Builder's performance with larger datasets, including benchmarks and scalability assessments.

### Open Question 3
- Question: How can QXGs be utilized for anomaly detection and predictive analysis in autonomous vehicles to improve safety and robustness?
- Basis in paper: [inferred] The paper suggests that QXGs could be used for anomaly detection and predictive analysis but does not explore these applications in detail.
- Why unresolved: The potential applications of QXGs in anomaly detection and predictive analysis are mentioned but not investigated, leaving questions about their effectiveness and implementation.
- What evidence would resolve it: Case studies and experimental results showing the effectiveness of QXGs in detecting anomalies and predicting future events in autonomous vehicle scenarios.

## Limitations
- Limited external validation beyond NuScenes dataset; performance claims rely solely on internal experiments
- Oracle-based GEQCA implementation details are underspecified, making reproducibility challenging
- No comparison with alternative qualitative representation methods or quantitative baselines
- Real-world deployment scenarios with dynamic occlusions and complex interactions remain untested

## Confidence
- **High confidence**: QXG construction methodology, Rectangle Algebra implementation, and space complexity claims
- **Medium confidence**: Storage reduction figures and real-time processing capabilities
- **Low confidence**: Interpretability claims and generalizability to scenarios beyond NuScenes

## Next Checks
1. Implement GEQCA with different oracle strategies (deterministic vs probabilistic) to assess robustness to classification errors
2. Test QXG-Builder on multi-sensor fusion scenarios with higher object densities (500+ objects) to validate scalability claims
3. Conduct human subject study comparing QXG-based explanations against baseline visualizations for scene understanding tasks