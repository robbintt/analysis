---
ver: rpa2
title: Efficient Online Decision Tree Learning with Active Feature Acquisition
arxiv_id: '2305.02093'
source_url: https://arxiv.org/abs/2305.02093
tags:
- feature
- cost
- online
- learning
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles online decision tree learning where feature values
  and labels are initially unknown and must be queried at a cost. A novel framework
  UFODT combines posterior sampling for online learning with active feature acquisition
  using information gain surrogates like EC2 to minimize query cost while maintaining
  prediction accuracy.
---

# Efficient Online Decision Tree Learning with Active Feature Acquisition

## Quick Facts
- arXiv ID: 2305.02093
- Source URL: https://arxiv.org/abs/2305.02093
- Reference count: 19
- One-line primary result: Achieves competitive or better test accuracy than VFDT/EFDT while reducing feature query cost by up to 90%

## Executive Summary
This paper presents UFODT, a framework for efficient online decision tree learning that addresses the challenge of initially unknown feature values and labels. The framework combines posterior sampling for online learning with active feature acquisition using information gain surrogates like EC2. UFODT maintains prediction accuracy while significantly reducing the cost of querying feature values, achieving up to 90% reduction compared to state-of-the-art online decision tree methods. The approach is validated across 8 real-world datasets and includes mechanisms for handling continuous features and concept drift.

## Method Summary
UFODT is a framework that integrates posterior sampling for online learning with active feature acquisition using information gain surrogates. The core algorithm samples environment parameters from a posterior distribution, executes an adaptive policy to query features and predict labels, observes true labels, and updates the posterior. EC2 serves as the surrogate objective function for feature acquisition, defining a weighted graph where feature queries cut edges to remove inconsistent hypotheses. The framework handles continuous features through adaptive discretization and concept drift via non-stationary posterior sampling with a discount parameter.

## Key Results
- Achieves competitive or better test accuracy than VFDT and EFDT on 8 real-world datasets
- Reduces feature query cost by up to 90% compared to baseline methods
- Successfully handles continuous features and concept drift through adaptive mechanisms

## Why This Works (Mechanism)

### Mechanism 1
Posterior sampling balances exploration and exploitation in online decision tree learning by drawing sampled environments from the posterior distribution and executing optimal policies for those environments. This maintains low regret while sequentially querying features using EC2.

Core assumption: Posterior distribution accurately reflects uncertainty and optimal policy for sampled environment approximates true environment policy.

Evidence anchors:
- [abstract]: "we employ a posterior sampling scheme to maintain a low regret for online prediction"
- [section 4.1]: "we employ posterior sampling [Osband and Van Roy, 2017] to learn the online decision tree model"

Break condition: Posterior becomes too concentrated too quickly, leading to insufficient exploration in non-stationary environments.

### Mechanism 2
EC2 surrogate objective function enables near-optimal feature acquisition through adaptive submodularity. It represents hypothesis space as a graph where feature queries cut edges, removing inconsistent hypotheses based on weighted equivalence class edge cuts.

Core assumption: Hypothesis space can be efficiently represented as graph and EC2 objective is adaptive submodular.

Evidence anchors:
- [abstract]: "we employ a surrogate information acquisition function based on adaptive submodularity to actively query feature values with a minimal cost"
- [section 4.2]: "we focus on the EC2 algorithm [Golovin et al., 2010], which uses the equivalence class edge cut as the surrogate objective of U(xF)"

Break condition: Hypothesis space too large or complex for graph representation, making EC2 computationally intractable.

### Mechanism 3
Non-stationary posterior sampling adapts to concept drift by adding discount parameter γ to posterior updates, reducing historical data weight and injecting random noise to encourage exploration.

Core assumption: Concept drift occurs gradually or abruptly and γ can be tuned to balance historical knowledge exploitation and new concept exploration.

Evidence anchors:
- [abstract]: "Our framework also naturally adapts to the challenging setting of online learning with concept drift"
- [section 4.4]: "we adopt an exceptionally easy solution to tackle the concept drift problem, by simply adding two lines of code upon Algorithm 2"

Break condition: Concept drift too rapid or unpredictable for γ to provide sufficient adaptation.

## Foundational Learning

- Concept: Adaptive submodularity
  - Why needed here: Enables greedy algorithms like EC2 to achieve near-optimal solutions for feature acquisition problems
  - Quick check question: What is the formal definition of adaptive submodularity, and how does it relate to the diminishing returns property?

- Concept: Bayesian inference
  - Why needed here: Updates posterior distribution over environment parameters θ based on observed data
  - Quick check question: How does the Beta distribution prior on θ_ij relate to the Bernoulli likelihood of observing feature values?

- Concept: Online learning with bandit feedback
  - Why needed here: Formulates online decision tree learning as bandit problem requiring exploration-exploitation balance
  - Quick check question: How does regret in online learning relate to utility of features in this framework?

## Architecture Onboarding

- Component map: Online learning model (posterior sampling) -> Active planning oracle (EC2/IG/US) -> Hypothesis sampling procedure
- Critical path: Sequential execution of feature queries and label predictions, where each epoch depends on previous posterior update
- Design tradeoffs: Balance between query cost and prediction accuracy; EC2 aims to minimize query cost while maintaining accuracy
- Failure signatures: 1) Insufficient exploration in non-stationary environments, 2) Computational intractability for large hypothesis spaces, 3) Poor γ tuning for concept drift
- First 3 experiments:
  1. Implement simple UFODT with EC2 on small synthetic dataset to verify basic functionality
  2. Compare UFODT-EC2 performance against VFDT/EFDT on real-world dataset to understand tradeoffs
  3. Test UFODT robustness to concept drift by simulating abrupt data distribution changes and measuring adaptation speed

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does UFODT with EC2 performance compare to VFDT/EFDT on streaming datasets with varying noise or concept drift levels?
- Basis in paper: [explicit] UFODT achieves competitive or better accuracy than VFDT/EFDT while reducing feature query cost by 90%
- Why unresolved: Paper doesn't directly compare performance on streaming datasets with different noise/concept drift levels
- What evidence would resolve it: Experiments comparing UFODT performance on streaming datasets with varying noise/concept drift alongside VFDT/EFDT

### Open Question 2
- Question: How does choice of information acquisition function (EC2, IG, US) impact UFODT performance on different streaming dataset types?
- Basis in paper: [explicit] Paper investigates performance of UFODT with different information acquisition functions on various datasets
- Why unresolved: Paper lacks comprehensive analysis of function choice impact across different dataset types
- What evidence would resolve it: Experiments comparing UFODT with different functions on diverse streaming datasets with varying feature types

### Open Question 3
- Question: How does hypothesis sampling procedure impact UFODT performance and computational efficiency for datasets with many features or complex boundaries?
- Basis in paper: [explicit] Paper mentions UFODT uses hypothesis sampling to reduce computational cost
- Why unresolved: Paper doesn't provide detailed analysis of sampling impact on performance/efficiency for complex datasets
- What evidence would resolve it: Experiments comparing UFODT with different sampling strategies on datasets with varying features and complexity

## Limitations
- Computational complexity may become intractable for high-dimensional datasets with large hypothesis spaces
- Framework depends on several hyperparameters without systematic sensitivity analysis
- Theoretical regret bounds may not reflect practical performance in early learning stages or with limited data

## Confidence

- High Confidence: Experimental results showing competitive accuracy with 90% feature query cost reduction are well-supported
- Medium Confidence: Theoretical regret bounds are sound but rely on assumptions that may not hold in practice
- Medium Confidence: Concept drift adaptation through non-stationary posterior sampling is promising but only briefly explored

## Next Checks

1. Implement UFODT on high-dimensional dataset (100+ features) to verify computational efficiency claims and identify bottlenecks

2. Systematically vary key hyperparameters across all 8 datasets to quantify impact on performance and identify optimal settings

3. Compare theoretical regret bounds with empirical measurements on streaming data to identify discrepancies and understand assumption breakdowns