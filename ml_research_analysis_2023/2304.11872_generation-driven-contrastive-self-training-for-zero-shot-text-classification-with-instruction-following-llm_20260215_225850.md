---
ver: rpa2
title: Generation-driven Contrastive Self-training for Zero-shot Text Classification
  with Instruction-following LLM
arxiv_id: '2304.11872'
source_url: https://arxiv.org/abs/2304.11872
tags:
- text
- classi
- label
- self-training
- cation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces GenCo, a method that uses large language
  models (LLMs) to assist in training a smaller, more efficient model for zero-shot
  text classification. The key idea is to leverage the generative power of LLMs in
  two ways: 1) augment input text with multiple generated versions to enhance semantic
  understanding, and 2) generate new training instances conditioned on predicted labels
  during self-training.'
---

# Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-following LLM

## Quick Facts
- arXiv ID: 2304.11872
- Source URL: https://arxiv.org/abs/2304.11872
- Reference count: 23
- This paper introduces GenCo, a method that uses large language models (LLMs) to assist in training a smaller, more efficient model for zero-shot text classification, outperforming previous state-of-the-art methods.

## Executive Summary
This paper introduces GenCo, a novel approach for zero-shot text classification that leverages the generative power of large language models (LLMs) to enhance contrastive self-training. The method uses GPT to augment input texts with multiple generated versions and create additional training instances conditioned on predicted labels. By combining these augmentation strategies with a temperature-based contrastive loss function, GenCo achieves state-of-the-art performance on four benchmark datasets, even with limited in-domain text data.

## Method Summary
GenCo uses a sentence encoder classifier (SimCSE-based) with contrastive self-training, employing two GPT augmentation strategies: input text augmentation and conditional augmentation based on pseudo-labels. The method initializes with label descriptions and training data, then iteratively generates augmented text using GPT-7B, implements contrastive self-training with balanced sampling, and updates parameters using a combined loss function with temperature parameter τ=0.1. The approach shows superior performance compared to existing methods while maintaining efficiency through smaller model sizes.

## Key Results
- GenCo outperforms previous state-of-the-art methods on four benchmark datasets (AG News, DBpedia, Yahoo Answers, Amazon)
- Achieves better performance than Alpaca-7B with human prompts
- Demonstrates effectiveness even with limited in-domain text data
- Shows consistent improvements across datasets with varying class numbers and text lengths

## Why This Works (Mechanism)

### Mechanism 1: Input Text Augmentation
Augmenting input text with GPT-generated continuations enriches semantic context and improves alignment with label embeddings. The model generates multiple augmented versions of each input text, then averages their embeddings to create a more robust semantic representation that bridges the gap between short inputs and label descriptions.

### Mechanism 2: Conditional Augmentation
Conditional augmentation based on pseudo-labels generates training instances that better align with decision boundaries and reduces label noise. When a pseudo-label is predicted, GPT generates text conditioned on that label, creating training pairs that are closer to the target category and away from ambiguous regions near decision boundaries.

### Mechanism 3: Temperature-based Contrastive Loss
The contrastive loss with temperature τ < 1 enforces larger margins between classes and improves generalization. The loss function combines supervised contrastive learning with entropy regularization, pushing instances away from decision boundaries and creating clearer class separation.

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: The method relies on pulling semantically similar text-label pairs closer in embedding space while pushing dissimilar pairs apart
  - Quick check question: What is the key difference between supervised contrastive learning and regular contrastive learning in this context?

- Concept: Self-training with pseudo-labels
  - Why needed here: The model iteratively uses its own predictions to generate new training data, requiring understanding of how to handle label noise
  - Quick check question: How does the model determine which pseudo-labeled instances to include in training?

- Concept: Conditional text generation
  - Why needed here: GPT is used to generate text conditioned on both the input and predicted label, requiring understanding of how conditioning affects generation
  - Quick check question: What prompt engineering techniques are used to guide GPT in generating label-relevant continuations?

## Architecture Onboarding

- Component map: Input text → Augmentation → Embedding → Contrastive loss → Parameter update → Pseudo-label generation → Conditional augmentation → Next iteration
- Critical path: The complete cycle from input text through augmentation, embedding, loss computation, parameter updates, and pseudo-label generation for the next iteration
- Design tradeoffs: Using GPT for augmentation provides rich semantic content but adds computational overhead; smaller models are more efficient but may lack generation quality; temperature parameter balances confidence vs. margin enforcement
- Failure signatures: Poor performance despite augmentation (GPT-generated text may be irrelevant or introduce noise), training instability (imbalanced pseudo-label sampling or inappropriate temperature setting), overfitting to pseudo-labels (insufficient regularization or too aggressive self-training)
- First 3 experiments:
  1. Run ablation test with and without input augmentation on a small dataset subset to verify semantic enrichment effect
  2. Test conditional augmentation by generating examples with correct and incorrect pseudo-labels to measure quality difference
  3. Vary temperature parameter τ in the loss function to observe impact on margin enforcement and classification accuracy

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of temperature τ in the contrastive loss function affect the stability and performance of self-training in GENCO? The paper mentions setting τ = 0.1 to balance supervised classification and low-density separation between classes, but acknowledges that more experiments could be done to analyze the effect of temperature on training stability.

### Open Question 2
How does GENCO perform compared to other state-of-the-art methods when trained on datasets with different levels of class imbalance? The paper demonstrates GENCO's effectiveness on benchmark datasets but does not explore its performance on imbalanced datasets, which are common in real-world applications.

### Open Question 3
Can GENCO be extended to handle multi-label text classification tasks, where each instance can belong to multiple categories simultaneously? The paper focuses on single-label classification tasks, but the underlying concepts of input augmentation and conditional generation could potentially be adapted for multi-label scenarios.

## Limitations

- The evaluation lacks comparison against other recent zero-shot classification methods beyond the specifically mentioned baselines
- The ablation studies are incomplete - while input augmentation and conditional augmentation are shown to be beneficial, the relative importance of each mechanism is not quantified
- The temperature parameter τ=0.1 is presented as optimal without exploring sensitivity to this critical hyperparameter

## Confidence

- **High confidence**: The core mechanism of using GPT for input text augmentation to enrich semantic context is well-supported by the empirical results showing consistent improvements across all four datasets
- **Medium confidence**: The conditional augmentation mechanism's effectiveness is demonstrated but the paper lacks detailed analysis of how pseudo-label quality affects generated text quality and subsequent model performance
- **Medium confidence**: The theoretical claims about temperature τ<1 enforcing larger margins are supported by the theorem but the practical impact on classification boundaries is not empirically validated through visualization or detailed analysis

## Next Checks

1. **Pseudo-label quality analysis**: Measure the accuracy of pseudo-labels at each self-training iteration and correlate with performance improvements to validate that the conditional augmentation mechanism works as claimed

2. **Temperature sensitivity study**: Systematically vary τ from 0.01 to 1.0 and measure the impact on both training dynamics (margin enforcement) and final classification accuracy to verify the theoretical claims about temperature effects

3. **Generation quality assessment**: Analyze the semantic similarity between GPT-generated augmented texts and their source texts using automatic metrics (e.g., BERTScore) and human evaluation to quantify the actual enrichment provided by the input augmentation mechanism