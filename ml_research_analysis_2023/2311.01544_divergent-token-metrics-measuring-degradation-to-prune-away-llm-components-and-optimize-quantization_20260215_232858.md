---
ver: rpa2
title: 'Divergent Token Metrics: Measuring degradation to prune away LLM components
  -- and optimize quantization'
arxiv_id: '2311.01544'
source_url: https://arxiv.org/abs/2311.01544
tags:
- layer
- module
- components
- value
- down
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Divergent Token Metrics (DTMs), a novel approach
  for assessing the quality of compressed LLMs. DTMs measure token divergences and
  provide deeper insights into model compression compared to traditional metrics like
  perplexity.
---

# Divergent Token Metrics: Measuring degradation to prune away LLM components -- and optimize quantization

## Quick Facts
- arXiv ID: 2311.01544
- Source URL: https://arxiv.org/abs/2311.01544
- Reference count: 12
- This paper introduces Divergent Token Metrics (DTMs), a novel approach for assessing the quality of compressed LLMs, achieving significant compression rates while preserving state-of-the-art performance.

## Executive Summary
This paper introduces Divergent Token Metrics (DTMs) as a novel approach for assessing the quality of compressed LLMs. Unlike traditional metrics like perplexity, DTMs measure token divergences and provide deeper insights into model compression by reflecting the actual generation process. The authors demonstrate that DTMs can identify optimal compression strategies for different model components, enabling nearly 20% of model components to be pruned by over 90% while preserving performance, and allowing over 80% of parameters to be transformed to int8 without special outlier management.

## Method Summary
The paper proposes a component-wise probing approach for both sparsification and quantization. For sparsification, individual model components are probed separately with different sparsity rates to determine their impact on generation quality using the First Divergent Token Metric (FDTM). Components are then iteratively pruned based on their FDTM values, with continued training steps to recover performance. For quantization, a search tree approach is used to find the best model configuration by ranking components based on their introduced error using FDTM. The evaluation is conducted on Llama2-7B and 13B models using the Wikitext2 dataset and standard NLP benchmarks.

## Key Results
- Nearly 20% of model components can be pruned by over 90% while preserving state-of-the-art performance
- Over 80% of parameters can be transformed to int8 without special outlier management
- FDTM provides more discriminative assessment than perplexity for subtle model degradations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The FDTM metric can identify optimal compression strategies by measuring token divergences that reflect actual generation quality rather than aggregate statistics.
- Mechanism: FDTM directly measures the first token where a compressed model's output diverges from the original model's output during greedy decoding, capturing the discontinuous nature of text generation that perplexity fails to detect.
- Core assumption: The first divergent token is a meaningful indicator of overall generation quality and model degradation.
- Evidence anchors: [abstract] "DTMs measure token divergences that allow deeper insights into the subtleties of model compression"; [section 3.5] "The main reason for that is the fact that the greedy decoding operation G is a discontinuous function of the logits"

### Mechanism 2
- Claim: Component-wise compression strategies outperform uniform compression by exploiting individual parameter importance differences.
- Mechanism: By evaluating each component's impact on generation quality separately using FDTM, compression can target the least critical components for aggressive pruning or quantization while preserving essential ones.
- Core assumption: Different components of transformer models have varying importance for maintaining generation quality.
- Evidence anchors: [section 4.2] "Interestingly, the model tends to remove components of the attention mechanism on certain layers entirely"; [section 4.3] "Certain components appear to significantly influence the decline observed in both measures"

### Mechanism 3
- Claim: Perplexity fails to detect subtle model degradations that significantly impact generation quality, while FDTM captures these differences.
- Mechanism: Perplexity averages over all tokens and doesn't reflect the discrete nature of token selection in generation, missing cases where models agree on probability distributions but produce different outputs.
- Core assumption: Generation quality is more sensitive to small model changes than aggregate probability metrics suggest.
- Evidence anchors: [section 3.5] "Proposition 3.2. Given any y, N and ε > 0 there exist logits l, l′ ∈ RN ×|V| such that | PPL(y, l, 1) − PPL(y, l′, 1)| < ε, MSDT(l, l′, y:1, N) = N"

## Foundational Learning

- Concept: Token-level evaluation metrics vs. aggregate metrics
  - Why needed here: Understanding why traditional metrics like perplexity fail to capture generation quality nuances that FDTM addresses
  - Quick check question: How does measuring the first divergent token differ from computing average log-likelihood across a sequence?

- Concept: Component-wise model analysis
  - Why needed here: The paper's compression strategies rely on evaluating and treating different model components (attention, MLP, etc.) individually
  - Quick check question: Why might attention components in later layers be more pruneable than those in earlier layers?

- Concept: Greedy decoding vs. probabilistic generation
  - Why needed here: FDTM specifically measures differences during greedy decoding, which is a common but not universal generation strategy
  - Quick check question: How might FDTM results differ if we used sampling-based generation instead of greedy decoding?

## Architecture Onboarding

- Component map: Attention matrices (query, key, value, dense) and MLP components (up, gate, down) are the key components evaluated individually for compression
- Critical path: Measure component importance with FDTM → Apply component-wise compression strategies → Validate with FDTM and traditional metrics → Iterate until target compression ratio is reached
- Design tradeoffs: FDTM provides better discrimination but requires more computation than perplexity; component-wise strategies are more complex to implement than uniform compression but achieve better results
- Failure signatures: Low FDTM values despite significant compression indicate retained unnecessary capacity; improved perplexity but degraded FDTM indicates suffering generation quality
- First 3 experiments:
  1. Implement FDTM metric and verify it detects differences between two models with identical perplexity but different outputs
  2. Apply FDTM to rank components in a small transformer and identify the least important ones
  3. Test uniform vs. component-wise pruning on a small model and compare FDTM results

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the proposed Divergent Token Metrics (DTMs) be extended to evaluate the performance of compressed models in more complex generation tasks beyond text generation, such as code generation or summarization?
- Basis in paper: [inferred] The paper primarily focuses on evaluating compressed models for text generation tasks using DTMs. However, the authors mention that DTMs can be readily formulated for additional token-based metrics, such as the measurement of the width between erroneous predictions, which could be valuable in assessing potential benefits in the context of correction-based inference strategies like speculative decoding.
- Why unresolved: The paper does not provide specific details on how DTMs can be extended to evaluate compressed models in more complex generation tasks beyond text generation. Further research is needed to investigate the applicability and effectiveness of DTMs in these domains.
- What evidence would resolve it: Empirical studies comparing the performance of compressed models evaluated using DTMs in complex generation tasks, such as code generation or summarization, to traditional evaluation metrics would provide evidence for the effectiveness of DTMs in these domains.

### Open Question 2
- Question: How can the proposed component-wise probing strategy for sparsification be adapted to other model compression techniques, such as quantization or knowledge distillation?
- Basis in paper: [explicit] The paper introduces a component-wise probing strategy for sparsification, where individual components of the model are probed separately with different sparsity rates to determine their FDT 75 value. The authors mention that this probing strategy can be applied to other methods, such as Wanda, for one-shot pruning.
- Why unresolved: The paper does not provide specific details on how the component-wise probing strategy can be adapted to other model compression techniques, such as quantization or knowledge distillation. Further research is needed to investigate the applicability and effectiveness of this strategy in these domains.
- What evidence would resolve it: Empirical studies comparing the performance of compressed models using the component-wise probing strategy for sparsification, quantization, or knowledge distillation to traditional compression techniques would provide evidence for the effectiveness of this strategy in these domains.

### Open Question 3
- Question: How can the proposed Divergent Token Metrics (DTMs) be used to guide the design of more efficient and effective model architectures for large language models?
- Basis in paper: [explicit] The paper introduces DTMs as a novel approach for assessing the quality of compressed LLMs, providing deeper insights into model compression compared to traditional metrics. The authors demonstrate that DTMs can identify optimal compression strategies for different model components, leading to significant levels of precision and sparsity without compromising text generation quality.
- Why unresolved: The paper does not provide specific details on how DTMs can be used to guide the design of more efficient and effective model architectures for large language models. Further research is needed to investigate the potential of DTMs in informing architectural decisions, such as the number and size of layers, the use of attention mechanisms, or the incorporation of sparsity or quantization techniques.
- What evidence would resolve it: Empirical studies comparing the performance of large language models designed using insights from DTMs to traditional architectures would provide evidence for the effectiveness of DTMs in guiding architectural decisions. Additionally, theoretical analysis of the relationship between DTMs and architectural choices could provide further insights into the potential of DTMs in this domain.

## Limitations

- The evaluation is limited to Llama2-7B and 13B models on specific datasets (C4 and Wikitext2), raising questions about generalization to other model architectures and domains
- The paper does not address computational overhead comparisons between FDTM and perplexity, nor does it explore the impact of different decoding strategies on FDTM measurements
- The component-wise compression strategy assumes stable importance rankings across different domains, but this may vary significantly between tasks

## Confidence

- **High Confidence**: The mathematical formulation of FDTM metrics and their theoretical advantages over perplexity
- **Medium Confidence**: The practical effectiveness of component-wise compression strategies
- **Low Confidence**: The generalizability of FDTM as a universal evaluation metric across all LLM tasks and domains

## Next Checks

1. **Cross-domain robustness test**: Evaluate FDTM's effectiveness on code generation and mathematical reasoning tasks where generation quality assessment may differ from natural language tasks.

2. **Decoder strategy comparison**: Implement FDTM measurements using sampling-based decoding (top-k, temperature) to verify whether the metric's discriminative power holds across different generation strategies.

3. **Computational overhead analysis**: Measure and compare the runtime and memory requirements of FDTM versus perplexity across different model sizes to quantify the practical trade-offs.