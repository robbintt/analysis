---
ver: rpa2
title: Doubly Perturbed Task Free Continual Learning
arxiv_id: '2312.13027'
source_url: https://arxiv.org/abs/2312.13027
tags:
- learning
- memory
- loss
- training
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses catastrophic forgetting in task-free online
  continual learning by proposing a novel optimization framework that considers future
  samples through adversarial perturbations on both input data and classifier weights.
  The proposed Doubly Perturbed Continual Learning (DPCL) method employs perturbed
  function interpolation for input perturbations and branched stochastic classifiers
  for weight perturbations, along with a memory management scheme and adaptive learning
  rate scheduling.
---

# Doubly Perturbed Task Free Continual Learning

## Quick Facts
- arXiv ID: 2312.13027
- Source URL: https://arxiv.org/abs/2312.13027
- Reference count: 40
- Primary result: Achieves 45.27% accuracy on CIFAR100 with 2K memory, outperforming state-of-the-art methods

## Executive Summary
This paper addresses catastrophic forgetting in task-free online continual learning by proposing a novel optimization framework that considers future samples through adversarial perturbations on both input data and classifier weights. The proposed Doubly Perturbed Continual Learning (DPCL) method employs perturbed function interpolation for input perturbations and branched stochastic classifiers for weight perturbations, along with a memory management scheme and adaptive learning rate scheduling. DPCL significantly outperforms state-of-the-art baselines, achieving 45.27% accuracy on CIFAR100 with 2K memory, compared to 41.49% for the next best method, while also demonstrating superior performance across various task configurations and datasets.

## Method Summary
DPCL introduces two key perturbation mechanisms: Perturbed Function Interpolation (PFI) for input data and Branched Stochastic Classifiers (BSC) for classifier weights. PFI injects noise into hidden layer representations and interpolates between perturbed samples, while BSC maintains multiple classifier instances with averaged weights and low-rank covariance estimates. The method also includes a memory management scheme based on mutual information tracking and adaptive learning rate scheduling. The approach is evaluated on CIFAR100, CIFAR100-SC, and ImageNet-100 datasets with memory buffer sizes of 2000 samples, using ResNet34 as the backbone architecture.

## Key Results
- Achieves 45.27% average accuracy on CIFAR100 with 2K memory buffer
- Outperforms state-of-the-art methods by 3.78% on CIFAR100
- Demonstrates superior performance across 5-20 class splits on multiple datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Perturbed Function Interpolation (PFI) provides an efficient surrogate for adversarial input perturbation by injecting noise proportional to loss values and interpolating perturbed samples.
- Mechanism: PFI perturbs hidden layer representations using multiplicative and additive noise scaled by the average loss for each class, then interpolates between two perturbed samples using Beta sampling.
- Core assumption: The classifier is linear for each class node, allowing PFI to approximate adversarial input perturbations through function space interpolation.
- Evidence anchors:
  - [abstract]: "for input perturbation, we propose an approximate perturbation method that injects noise into the input data as well as the feature vector and then interpolates the two perturbed samples"
  - [section]: "We define the average loss for samples whose label is y as ¯ℓy... Since computing the true ¯ℓy is infeasible, we instead update the value by exponential moving average whenever a sample of label y is encountered"
- Break condition: If the classifier is highly non-linear or the feature space becomes too complex for interpolation to capture adversarial perturbations effectively.

### Mechanism 2
- Claim: Branched Stochastic Classifiers (BSC) flatten the weight loss landscape by averaging weights along training trajectories and performing variational inference.
- Mechanism: BSC maintains multiple classifier instances with averaged weights and low-rank covariance estimates, sampling from these distributions during inference to approximate weight perturbations.
- Core assumption: Weight averaging along training trajectories effectively flattens the loss landscape, similar to adversarial weight perturbation but without explicit gradient steps.
- Evidence anchors:
  - [abstract]: "For decision-making process perturbation, we devise multiple stochastic classifiers"
  - [section]: "Since training multiple networks is time-consuming and infeasible in TF-CL setup, we instead introduce multiple linear classifiers g1, · · · , gN. By computing the decision pt
n for each classifier, the final decision for an input is determined by ¯pt = 1
N ΣN
n=1pt
n"
- Break condition: If the weight distribution becomes too complex for the low-rank covariance approximation to capture, or if averaging weights leads to underfitting.

### Mechanism 3
- Claim: Perturbation-Induced Memory Management and Adaptive Learning Rate (PIMA) improves performance by balancing class representation and adjusting learning rates based on mutual information between samples and classifier weights.
- Mechanism: PIMA tracks mutual information between memory samples and classifier weights, replacing low-information samples and scaling learning rates based on changes in average mutual information.
- Core assumption: Mutual information between samples and classifier weights reflects the importance of samples for preventing forgetting and enabling plasticity.
- Evidence anchors:
  - [abstract]: "We also investigate a memory management scheme and learning rate scheduling reflecting our proposed double perturbations"
  - [section]: "Let Mt be the memory at iteration t... To manage Mt, we introduce a history Ht which stores the mutual information for memory samples"
- Break condition: If mutual information becomes an unreliable indicator of sample importance due to classifier architecture changes or if memory capacity becomes too limited for effective balancing.

## Foundational Learning

- Concept: Catastrophic forgetting in continual learning
  - Why needed here: Understanding why the proposed perturbations are necessary requires knowing that standard training causes networks to forget previous tasks
  - Quick check question: Why do neural networks typically experience catastrophic forgetting when trained sequentially on multiple tasks?

- Concept: Task-free online continual learning (TF-CL)
  - Why needed here: The paper addresses a specific scenario where task boundaries are unknown and learning must be online
  - Quick check question: How does task-free online continual learning differ from traditional continual learning with explicit task boundaries?

- Concept: Adversarial training and weight perturbation
  - Why needed here: The proposed method builds on concepts from adversarial training to create robust learning against forgetting
  - Quick check question: How do adversarial perturbations on inputs and weights improve generalization and robustness in standard training?

## Architecture Onboarding

- Component map: ResNet34 encoder → PFI layer (randomly selected hidden layer) → Branched Stochastic Classifiers (N=5 instances) → Memory buffer (M=2000) → PIMA (mutual information tracking and learning rate scaling)
- Critical path: Stream sample → Encoder → PFI perturbation → Classifier ensemble → Memory update (if selected) → Mutual information computation → Learning rate adjustment
- Design tradeoffs: Multiple classifiers increase parameter count and computation slightly but avoid explicit adversarial training; PFI reduces computation compared to direct adversarial input perturbation
- Failure signatures: If performance degrades significantly when removing either PFI or BSC components, indicating their necessity; if memory management becomes ineffective with very limited memory
- First 3 experiments:
  1. Implement PFI with a simple ResNet on CIFAR100 and verify that it produces smoother loss landscapes compared to standard training
  2. Add BSC with 2-3 classifier instances and measure the impact on forgetting measure (FM) on CIFAR100
  3. Integrate PIMA and test different values of the mutual information decay parameter γ to find optimal memory management performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DPCL scale with different sizes of memory buffer, and what is the optimal memory size for different datasets?
- Basis in paper: [inferred] The paper mentions that DPCL is tested with a memory size of 2000 for all datasets, but does not explore the impact of varying memory sizes.
- Why unresolved: The paper does not provide experiments or analysis on how different memory sizes affect DPCL's performance, which is crucial for understanding its scalability and practical application.
- What evidence would resolve it: Experiments showing DPCL's performance across a range of memory sizes (e.g., 500, 1000, 2000, 5000) on various datasets would provide insights into its scalability and optimal memory requirements.

### Open Question 2
- Question: How does DPCL handle scenarios where the future data distribution is significantly different from the past and present distributions?
- Basis in paper: [explicit] The paper mentions that DPCL considers future samples through adversarial perturbations, but does not explore scenarios with significant distribution shifts.
- Why unresolved: The paper does not provide experiments or analysis on how DPCL performs when faced with substantial changes in data distribution, which is a critical aspect of real-world applications.
- What evidence would resolve it: Experiments demonstrating DPCL's performance on datasets with known distribution shifts or synthetic data with controlled distribution changes would provide insights into its robustness to significant future distribution differences.

### Open Question 3
- Question: What is the computational complexity of DPCL compared to other methods, and how does it scale with larger datasets and more complex models?
- Basis in paper: [explicit] The paper provides runtime and parametric complexity analysis, but does not explore how these metrics scale with larger datasets or more complex models.
- Why unresolved: The paper does not provide experiments or analysis on how DPCL's computational complexity scales with increased dataset size or model complexity, which is important for understanding its practical limitations.
- What evidence would resolve it: Experiments measuring DPCL's computational complexity (e.g., training time, memory usage) on larger datasets and more complex models would provide insights into its scalability and practical applicability.

### Open Question 4
- Question: How does DPCL perform in scenarios with limited computational resources or strict latency requirements?
- Basis in paper: [inferred] The paper does not explicitly address scenarios with limited computational resources or strict latency requirements.
- Why unresolved: The paper does not provide experiments or analysis on how DPCL performs under resource constraints or latency requirements, which is crucial for understanding its practical deployment in real-world scenarios.
- What evidence would resolve it: Experiments demonstrating DPCL's performance under various computational resource constraints (e.g., limited GPU memory, CPU-only inference) and latency requirements would provide insights into its adaptability to resource-limited environments.

## Limitations

- Key hyperparameters like mixing parameters α, β for PFI and covariance computation for BSC are not explicitly defined, potentially affecting reproducibility
- While BSC reduces computation compared to explicit adversarial training, the paper doesn't quantify the additional parameter count and inference time from maintaining multiple classifier instances
- Results are primarily demonstrated on ResNet34; performance on other architectures (e.g., Vision Transformers) remains unverified

## Confidence

- High confidence: The core methodology of using perturbed function interpolation and branched stochastic classifiers is well-founded and theoretically sound
- Medium confidence: The proposed memory management scheme based on mutual information is innovative but requires empirical validation across diverse datasets
- Low confidence: The exact implementation details of PFI and BSC are underspecified, which could impact faithful reproduction of results

## Next Checks

1. Hyperparameter sensitivity analysis: Systematically vary α, β mixing parameters and noise factors σm, σa to determine their impact on performance and identify optimal ranges
2. Ablation study: Remove PFI and BSC components individually to quantify their respective contributions to overall performance improvements
3. Cross-architecture validation: Test DPCL on architectures beyond ResNet34 (e.g., EfficientNet, ViT) to verify generalizability across different model families