---
ver: rpa2
title: Evaluating, Understanding, and Improving Constrained Text Generation for Large
  Language Models
arxiv_id: '2310.16343'
source_url: https://arxiv.org/abs/2310.16343
tags:
- constraints
- llms
- generation
- text
- sentence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study evaluates constrained text generation for large language
  models (LLMs) by categorizing constraints into lexical, structural, and relation-based
  types. For lexical constraints, the study finds that ChatGPT and GPT-4 demonstrate
  high compliance, with GPT-4 achieving a coverage score of 99.33%.
---

# Evaluating, Understanding, and Improving Constrained Text Generation for Large Language Models

## Quick Facts
- arXiv ID: 2310.16343
- Source URL: https://arxiv.org/abs/2310.16343
- Reference count: 16
- Key outcome: GPT-4 achieves 99.33% lexical constraint coverage, 87% CSR for structural constraints, and outperforms other models on relation constraints, but challenges remain for structural and relation constraints beyond basic cases.

## Executive Summary
This study systematically evaluates how large language models handle three categories of text generation constraints: lexical (keyword inclusion), structural (sentence positioning and length), and relation-based (syntactic dependencies). The researchers test multiple open-source and closed-source models including ChatGPT and GPT-4 across manually constructed datasets. Results show GPT-4 significantly outperforms other models on all constraint types, achieving 99.33% lexical coverage and 87% CSR for sentence positioning, while structural and relation constraints remain challenging even for the best models. The study reveals that while lexical constraints are largely solved, structural and relation constraints pose ongoing challenges that require further research.

## Method Summary
The researchers conducted zero-shot evaluation of constrained text generation across three constraint categories using manually constructed datasets. For lexical constraints, they used the CommonGen test set with 35,141 concept sets. Structural constraints were tested through manually constructed story generation prompts with specific types (InSen, Order, Len). Relation constraints used 2,900 test instances sampled from the English-EWT dependency parsing corpus across 29 dependency relation categories. They evaluated multiple open-source models (StableLM, Dolly, LLaMA, Vicuna) and closed-source models (ChatGPT, GPT-4) using coverage metrics, Constraints Success Ratio (CSR) with tolerances, and Pearson correlation for length prediction. The study employed prompt-based constraints without fine-tuning to assess zero-shot performance.

## Key Results
- GPT-4 achieves 99.33% lexical constraint coverage, significantly outperforming other models
- GPT-4 demonstrates 87% CSR for structural InSen constraints, showing superior sentence positioning ability
- GPT-4 outperforms other models on relation constraints with 0.56 UC and 0.48 LC average scores
- All models struggle with sentence length constraints, with GPT-4 achieving only 12% CSR
- Open-source models show high rejection rates (up to 64.15% for LLaMA-13B) when constraints are perceived as infeasible

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 has high lexical constraint coverage because its pretraining corpus includes diverse word inflections and contexts.
- Mechanism: Large-scale pretraining on varied text data enables GPT-4 to generate sentences containing all required keywords, even with morphological variations.
- Core assumption: GPT-4's pretraining data sufficiently covered diverse morphological inflections and syntactic patterns to generalize to unseen keyword combinations.
- Evidence anchors:
  - [abstract] "Results illuminate LLMs' capacity and deficiency to incorporate constraints..."
  - [section] "GPT-4 has the highest coverage score of 99.33%, suggesting it may be the most capable model..."
  - [corpus] Weak signal; corpus contains related NLP generation papers but no direct evidence of GPT-4's pretraining details.
- Break condition: If keyword sets contain rare or domain-specific terms absent from pretraining data, coverage may drop sharply.

### Mechanism 2
- Claim: GPT-4's sentence positioning ability comes from implicit counting and structural reasoning gained during pretraining.
- Mechanism: Through exposure to structured text (e.g., stories, articles), GPT-4 learns to track sentence positions and embed constraints accordingly.
- Core assumption: GPT-4's training data included sufficient narrative structures with clear sentence boundaries and positional cues.
- Evidence anchors:
  - [abstract] "Results illuminate LLMs' capacity and deficiency to incorporate constraints..."
  - [section] "GPT-4 exhibits a significant improvement in sentence positioning ability, achieving a CSR of 87%..."
  - [corpus] No direct evidence; this is inferred from experimental results and literature on GPT-4's reasoning capabilities.
- Break condition: If prompts require counting beyond GPT-4's implicit capacity or involve unusual sentence structures, positioning may fail.

### Mechanism 3
- Claim: GPT-4 can satisfy relation constraints due to learned syntactic dependency patterns from large-scale pretraining.
- Mechanism: Exposure to syntactically diverse corpora enables GPT-4 to infer correct dependency relations between words even when not explicitly trained on them.
- Core assumption: Pretraining data included enough syntactically annotated or richly structured text to learn dependency patterns implicitly.
- Evidence anchors:
  - [abstract] "Relation constraints, GPT-4 outperforms other models in terms of labeled coverage..."
  - [section] "GPT-4 achieves an average of 0.98 WC, 0.56 UC, and 0.48 LC..."
  - [corpus] No direct evidence; results suggest learned ability but lack details on training data composition.
- Break condition: If relation types are highly specific or absent from pretraining distribution, GPT-4's performance may degrade.

## Foundational Learning

- Concept: Lexical constraints and morphological inflection handling
  - Why needed here: Core to understanding how GPT-4 satisfies keyword inclusion even when words appear in varied forms.
  - Quick check question: Can GPT-4 generate a sentence containing "run," "running," and "ran" when given the keyword "run"?

- Concept: Structural constraints and sentence positioning
  - Why needed here: Essential for interpreting why GPT-4 excels at InSen constraints and where other models fail.
  - Quick check question: What happens to GPT-4's CSR for InSen when k > 7, and why?

- Concept: Dependency relations and relation constraints
  - Why needed here: Key to grasping how models like GPT-4 satisfy relation constraints and why some relations (e.g., nmod) remain challenging.
  - Quick check question: How does GPT-4's LC for "nmod" compare to other relations, and what does that indicate?

## Architecture Onboarding

- Component map: LLM core (transformer-based) -> Decoding strategy (beam search or constrained decoding) -> Constraint extraction module -> Evaluation metric computation module -> Dataset loaders (CommonGen, manually constructed sets)
- Critical path: Prompt → LLM generation → Constraint extraction → Evaluation metric computation → Result aggregation
- Design tradeoffs: Open-source vs. closed-source models (parameter size, rejection rates, instruction-following ability); constraint specificity vs. generation fluency
- Failure signatures: High rejection rates (model refuses to answer), low CSR under tight tolerances, negative correlation in length prediction
- First 3 experiments:
  1. Run lexical constraint benchmark on GPT-4 vs. Vicuna-13B and record coverage and rejection rates
  2. Test GPT-4's InSen CSR for k = 1 through k = 10 to observe sentence positioning limits
  3. Evaluate GPT-4 and GPT-3.5 on relation constraint categories to compare LC and UC across dependency types

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can current LLMs reliably handle sentence positioning in constrained text generation beyond the first sentence?
- Basis in paper: [explicit] The study found that LLMs struggle with sentence positioning for k ≥ 2 in the InSen(w, yk) constraint, with only GPT-4 showing reasonable performance up to k = 7.
- Why unresolved: While GPT-4 shows improved performance, its error rate increases for sentences beyond the 7th position, and other LLMs perform poorly even for early sentence positions.
- What evidence would resolve it: Systematic evaluation of LLMs on increasingly complex sentence positioning tasks with larger k values, and analysis of whether this limitation stems from tokenization, attention mechanisms, or architectural constraints.

### Open Question 2
- Question: Do open-source LLMs possess genuine understanding of dependency relations or are they merely exploiting statistical patterns?
- Basis in paper: [explicit] The study found that LLMs struggle with fundamental relations like "nmod" and showed modest relative improvements in relation constraint tasks, suggesting potential exploitation of statistical patterns rather than true grammatical understanding.
- Why unresolved: The study showed that while LLMs can generate coherent text, their performance on relation constraints remains challenging, with certain categories showing remarkably low absolute UC and LC metrics.
- What evidence would resolve it: Controlled experiments testing LLMs on novel syntactic constructions not present in their training data, and comparison of their performance on similar relations with different statistical frequencies.

### Open Question 3
- Question: What architectural or training modifications could enable LLMs to better handle sentence length constraints in constrained text generation?
- Basis in paper: [inferred] The study found that sentence length constraints remain challenging for all tested LLMs, with the best model (GPT-4) achieving only 12% CSR, 68% CSR (±3), and a Pearson correlation of 0.696.
- Why unresolved: Despite advances in LLM capabilities, current models still struggle with precise length control, showing a tendency to generate sentences shorter than specified constraints.
- What evidence would resolve it: Development and evaluation of novel decoding strategies, architectural modifications, or training objectives specifically designed to improve length control, and comparison with current baseline performance.

## Limitations
- The study relies on zero-shot evaluation without fine-tuning, limiting generalizability to real-world deployment scenarios
- Manually constructed datasets may not capture full complexity of real-world constraint satisfaction tasks
- Focus on English-language constraints limits applicability to multilingual contexts
- Exact prompt formulations are not fully specified, affecting reproducibility
- Rejection rate analysis is limited to open-source models, while closed-source models only report success cases

## Confidence
- High Confidence: GPT-4 demonstrates superior performance on lexical constraints with 99.33% coverage, and shows better sentence positioning ability (87% CSR for InSen constraints) compared to other models.
- Medium Confidence: The mechanisms explaining GPT-4's performance (pretraining corpus diversity, implicit counting, learned dependency patterns) are plausible but not directly verified.
- Low Confidence: The generalizability of findings to other constraint types, languages, or fine-tuned scenarios remains uncertain.

## Next Checks
1. **Prompt Sensitivity Analysis**: Systematically vary prompt formulations across all constraint types to quantify how different prompt structures affect model performance and rejection rates.
2. **Cross-Lingual Validation**: Apply the same constraint evaluation framework to multilingual models and non-English constraint sets to assess whether GPT-4's advantages extend beyond English.
3. **Fine-tuning Impact Study**: Fine-tune open-source models on a subset of constraint types and re-evaluate performance to determine whether current zero-shot gaps are addressable through adaptation.