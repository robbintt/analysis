---
ver: rpa2
title: 'POE: Process of Elimination for Multiple Choice Reasoning'
arxiv_id: '2310.15575'
source_url: https://arxiv.org/abs/2310.15575
tags:
- tasks
- options
- reasoning
- option
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: POE is a two-step scoring method for multiple choice reasoning
  that first eliminates seemingly wrong options based on their scores, then masks
  them and makes the final prediction from the remaining options. Experiments on 8
  diverse reasoning tasks show POE achieves the best or comparable zero-shot performance
  to strong baselines like language modeling and multiple choice prompting.
---

# POE: Process of Elimination for Multiple Choice Reasoning

## Quick Facts
- arXiv ID: 2310.15575
- Source URL: https://arxiv.org/abs/2310.15575
- Reference count: 10
- Primary result: Two-step scoring method that eliminates wrong options before final prediction, achieving state-of-the-art zero-shot performance on 8 reasoning tasks

## Executive Summary
POE introduces a novel two-step scoring approach for multiple choice reasoning that first eliminates seemingly wrong options based on their scores, then masks them and makes the final prediction from remaining options. The method builds on existing in-context learning approaches but modifies them with a structured elimination-selection process. Experiments demonstrate POE achieves best or comparable zero-shot performance to strong baselines across 8 diverse reasoning tasks, with particular effectiveness on logical reasoning tasks. The approach also generalizes to few-shot settings and large language models like ChatGPT.

## Method Summary
POE is a two-step scoring method for multiple choice reasoning. In the first step, POE scores each option using a base scoring method (typically MCP) and eliminates options whose scores fall below the average score. In the second step, eliminated options are masked (replaced with [MASK] tokens and their scores set to negative infinity), and the remaining options are scored again with the same or different scoring method. The final answer is the highest-scored non-masked option. This process disentangles elimination reasoning from selection reasoning, potentially allowing more focused and accurate reasoning for each task.

## Key Results
- POE achieves best or comparable zero-shot performance to strong baselines across 8 diverse reasoning tasks
- Method shows particularly strong performance on logical reasoning tasks (LD: 13.8% improvement, CC: 12% improvement)
- POE generalizes to few-shot settings and scales to large language models like ChatGPT
- The elimination step shows high accuracy (Accmask) on most tasks, indicating effective wrong option identification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Eliminating wrong options based on score deviation improves reasoning accuracy
- Mechanism: Wrong options tend to deviate from average score, making them identifiable for elimination
- Core assumption: Score distributions of wrong options differ sufficiently from correct options
- Evidence anchors: Abstract states POE "eliminates seemingly wrong options based on their scores"
- Break condition: Significant overlap between correct and wrong option score distributions

### Mechanism 2
- Claim: Separating elimination from selection improves performance on logical reasoning tasks
- Mechanism: POE disentangles two types of reasoning (elimination vs. selection) into separate steps
- Core assumption: Logical reasoning tasks benefit from structured two-step reasoning
- Evidence anchors: Abstract notes "especially performant on logical reasoning tasks" with large gaps on LD (13.8%) and CC (12%)
- Break condition: Tasks where all options are plausible and don't benefit from elimination

### Mechanism 3
- Claim: Masking eliminated options during prediction improves final accuracy
- Mechanism: Masking forces model to focus reasoning on remaining options by setting eliminated scores to negative infinity
- Core assumption: Masking creates cleaner decision boundaries for final prediction
- Evidence anchors: Abstract describes second step where "POE masks these wrong options, and makes the final prediction"
- Break condition: Masking introduces information loss or model relies on context from all options

## Foundational Learning

- Concept: In-context learning for multiple choice tasks
  - Why needed here: POE builds on existing in-context learning approaches with a two-step process
  - Quick check question: What are the two main types of in-context learning approaches for multiple choice tasks?

- Concept: Score distribution analysis
  - Why needed here: POE relies on analyzing score distributions to identify and eliminate wrong options
  - Quick check question: How does POE determine which options to eliminate in the first step?

- Concept: Masking techniques in language models
  - Why needed here: POE uses masking to remove eliminated options from consideration
  - Quick check question: What happens to the scores of masked options in POE's prediction step?

## Architecture Onboarding

- Component map: Score all options -> Compute average and eliminate below-average -> Generate masks -> Score masked options -> Select highest-scored non-masked option
- Critical path: 1) Score all options using base scoring method, 2) Compute average score and eliminate below-average options, 3) Generate masks and create masked question, 4) Score masked options, 5) Select highest-scored non-masked option
- Design tradeoffs: Single-step vs two-step (adds complexity but enables better elimination), fixed vs adaptive thresholds (uses average score), same vs different scoring methods (uses MCP for both steps)
- Failure signatures: Low Accmask indicates poor elimination quality, high Accmask but low final Acc suggests masking issues, performance degradation on commonsense tasks indicates task-specific limitations
- First 3 experiments: 1) Compare Accmask and final Acc across different scoring methods, 2) Test different elimination thresholds on held-out data, 3) Evaluate performance on logical vs commonsense tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the elimination process of POE impact its performance on tasks with varying numbers of options?
- Basis in paper: Explicit - The paper discusses experiments on different subtasks of logical deduction with varying numbers of options
- Why unresolved: While the paper shows POE performs well across tasks with different numbers of options, it doesn't delve into the specific impact of elimination on performance relative to option count
- What evidence would resolve it: Experiments measuring POE performance on tasks with varying numbers of options, specifically analyzing elimination process impact on accuracy and efficiency

### Open Question 2
- Question: How does the performance of POE compare to other state-of-the-art methods in the few-shot learning setting?
- Basis in paper: Explicit - The paper mentions POE is applicable to few-shot settings and compares with MCP in three-shot setting
- Why unresolved: The paper provides limited comparison of POE with other state-of-the-art methods in few-shot learning
- What evidence would resolve it: Experiments comparing POE with other state-of-the-art methods in few-shot learning on diverse tasks

### Open Question 3
- Question: How does the interpretability of POE's elimination process contribute to its performance and explainability?
- Basis in paper: Explicit - The paper mentions elimination process provides intermediate reasoning outputs
- Why unresolved: While acknowledging interpretability, the paper doesn't fully explore how this contributes to performance and explainability in practical applications
- What evidence would resolve it: User studies or expert evaluations assessing impact of POE's interpretability on performance and explainability

## Limitations

- Empirical rather than theoretically grounded mechanism for why elimination works
- Limited validation of score-based elimination criterion across diverse datasets
- Unclear whether benefits stem from two-step structure or specific implementation choices
- Potential dataset-specific artifacts in reported advantages on logical reasoning tasks

## Confidence

- Mechanism 1: Low confidence - Limited statistical validation of elimination criterion
- Mechanism 2: Medium confidence - Task-specific effectiveness shows promise but needs broader validation
- Mechanism 3: Medium confidence - Masking approach is empirically supported but theoretical grounding is limited

## Next Checks

1. **Statistical validation of elimination criterion**: Analyze score distributions across all 8 tasks to quantify overlap between correct and wrong option scores and compute statistical significance of elimination accuracy improvements.

2. **Ablation study on elimination strategy**: Replace POE's average-based elimination with alternative criteria (z-score thresholds, entropy-based filtering, or random elimination) to isolate whether two-step structure or specific elimination method drives performance gains.

3. **Cross-dataset generalization test**: Apply POE to a held-out logical reasoning dataset not included in the original 8 tasks to verify whether reported advantages on LD and CC generalize beyond specific datasets tested.