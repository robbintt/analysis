---
ver: rpa2
title: A Theoretical Perspective on Subnetwork Contributions to Adversarial Robustness
arxiv_id: '2307.03803'
source_url: https://arxiv.org/abs/2307.03803
tags:
- adversarial
- network
- layers
- subnetwork
- robustness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the concept of "semirobustness" to analyze
  how the adversarial robustness of a subnetwork contributes to the overall network's
  robustness. The authors theoretically prove that if an early subnetwork is semirobust
  and there is sufficient mutual information (MI) dependency between it and subsequent
  layers, then the remaining layers are guaranteed to be robust.
---

# A Theoretical Perspective on Subnetwork Contributions to Adversarial Robustness

## Quick Facts
- arXiv ID: 2307.03803
- Source URL: https://arxiv.org/abs/2307.03803
- Reference count: 40
- Primary result: Introduces "semirobustness" concept showing how adversarial robustness of subnetworks can propagate through mutual information dependencies

## Executive Summary
This paper introduces a theoretical framework for understanding how the adversarial robustness of subnetworks contributes to overall network robustness. The key innovation is the concept of "semirobustness," which characterizes a subnetwork's ability to confer robustness to subsequent layers through mutual information dependencies. The authors prove that if an early subnetwork is semirobust and has sufficient mutual information with later layers, the entire network can achieve robustness. Experiments on ResNet-18 and WideResNet-34-10 architectures with CIFAR-10 and CIFAR-100 datasets demonstrate that adversarially training a robust subnetwork and ensuring sufficient mutual information can lead to full-network robustness, often requiring only a few epochs of fine-tuning.

## Method Summary
The method introduces the concept of "semirobustness" to analyze subnetwork contributions to adversarial robustness. It proves theoretically that if an early subnetwork is semirobust and there is sufficient mutual information (MI) dependency between it and subsequent layers, then the remaining layers are guaranteed to be robust. The approach involves adversarially training a robust subnetwork (f*a) and ensuring sufficient MI between layers using Algorithm 1. The method is validated through experiments on ResNet-18 and WideResNet-34-10 architectures using CIFAR-10 and CIFAR-100 datasets, evaluating against FGSM, PGD, and AutoAttack. The approach leverages ensemble dependency graph estimator (EDGE) for MI estimation and demonstrates that full-network robustness can be achieved through targeted subnetwork training.

## Key Results
- A semirobust subnetwork can confer full-network adversarial robustness if mutual information between its layers and subsequent layers exceeds a threshold
- Linear connectivity between subnetworks guarantees semirobustness propagation through weighted combinations of earlier layer activations
- The performance difference between fully robust and semirobust networks is bounded by the weight difference between the two networks
- Experiments show that adversarially training a robust subnetwork and ensuring sufficient MI between layers can lead to full-network robustness
- This approach can reduce computational complexity and potentially improve generalization to different attacks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A semirobust subnetwork can confer full-network adversarial robustness if mutual information between its layers and subsequent layers is sufficiently high.
- Mechanism: The concept of semirobustness ensures that a subnetwork's adversarial robustness can propagate to later layers through strong mutual information dependencies, creating a cascading robustness effect where training a subset of layers provides robustness guarantees for the entire network.
- Core assumption: Mutual information between consecutive layers exceeds a threshold ρ, and there exists a mapping function that maintains the robustness correlation across layers.
- Evidence anchors:
  - [abstract] "if a subnetwork is semirobust and there is a sufficient dependency between it and each subsequent layer in the network, then the remaining layers are also guaranteed to be robust"
  - [section] "We provide a novel theoretical framework and prove that, under some assumptions, if an early subnetwork is semirobust then the proceeding subnetworks are robust"
- Break condition: If the mutual information between consecutive layers falls below the threshold ρ, or if the mapping function cannot maintain the robustness correlation.

### Mechanism 2
- Claim: Linear connectivity between subnetworks guarantees semirobustness propagation through weighted combinations of earlier layer activations.
- Mechanism: When subsequent layers are linear combinations of earlier layers, the semirobustness property transfers through the network because the linear combination preserves the robustness bounds from earlier layers.
- Core assumption: Each layer in the second subnetwork is a linear combination of all previous layers with specific weight mappings.
- Evidence anchors:
  - [abstract] "we provide a theoretical analysis to show that if a subnetwork is semirobust and there is a sufficient dependency between it and each subsequent layer in the network, then the remaining layers are also guaranteed to be robust"
  - [section] "Theorem 3. Let fa be a γa-semirobust subnetwork... If for j = a + 1, ..., n, f(j) = P(i=1 to j-1) λTij·f(i), where λij is a map Li → Lj and a matrix of dimensionality Li × Lj, then fb is γb-semirobust"
- Break condition: If the linear combination weights don't preserve the robustness bounds, or if the network contains non-linear transformations that break the linear connectivity assumption.

### Mechanism 3
- Claim: The performance difference between fully robust and semirobust networks is bounded by the weight difference between the two networks.
- Mechanism: Using Taylor approximation and norm bounds, the difference in loss between a fully robust network and a semirobust network is proportional to the L2 norm of the weight difference between their corresponding layers.
- Core assumption: The Hessian of the loss function at the converged point is bounded, and the activation function is Lipschitz continuous.
- Evidence anchors:
  - [abstract] "Experiments show the ability of a robust subnetwork to promote full-network robustness"
  - [section] "ℓ(eω∗) − ℓ(ω∗) ≈ 1/2(eω∗ − ω∗)T∇2ℓ(ω∗)(eω∗ − ω∗) ≤ 1/2λmax||eωb − ωb||2"
- Break condition: If the Hessian becomes unbounded or the Lipschitz constant of the activation function is infinite.

## Foundational Learning

- Concept: Mutual Information (MI)
  - Why needed here: MI measures the dependency between consecutive layers, which is crucial for determining whether semirobustness can propagate through the network.
  - Quick check question: What does mutual information measure in the context of neural network layers, and why is it important for adversarial robustness?

- Concept: Adversarial Training
  - Why needed here: Adversarial training creates the robust subnetwork (f*a) that serves as the foundation for propagating robustness to the rest of the network.
  - Quick check question: How does adversarial training differ from standard training, and what role does it play in creating semirobust subnetworks?

- Concept: Subnetwork Robustness (Semirobustness)
  - Why needed here: This concept defines what it means for a portion of the network to be adversarially robust, which is the foundation for the entire theoretical framework.
  - Quick check question: How is semirobustness defined differently from full network robustness, and what are the key components of this definition?

## Architecture Onboarding

- Component map: Input → f*a (adversarially trained) → fb (fine-tuned) → Output
- Critical path: The dependency between f*a and fb through mutual information is the critical path for robustness propagation
- Design tradeoffs: Training only a subset of layers reduces computational cost but requires careful selection of which layers to make robust
- Failure signatures: If mutual information between layers is too low, the semirobust subnetwork cannot confer robustness to the rest of the network
- First 3 experiments:
  1. Implement Algorithm 1 to measure mutual information thresholds between layers for different network architectures
  2. Test Theorem 3 by creating a linear combination of earlier layer activations to predict labels and measure robustness
  3. Compare the performance difference between fully robust networks and semirobust networks using the weight difference bound

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal way to measure the mutual information (MI) dependency between layers in a neural network to determine the threshold for semirobustness?
- Basis in paper: [inferred] The paper suggests that MI alone may not capture the entire information flow between layers of subnetworks to accurately determine mutual dependencies, despite using the EDGE estimator for MI.
- Why unresolved: The paper notes that even normally trained fb often has comparable connectivity compared to efb, despite having much lower robustness, suggesting MI might not be sufficient.
- What evidence would resolve it: Experiments comparing different MI estimators or alternative dependency measures against robustness outcomes would clarify which metrics best predict successful semirobustness.

### Open Question 2
- Question: How does the size and structure of the semirobust subnetwork (f*ₐ) affect the computational complexity and effectiveness of achieving full-network robustness?
- Basis in paper: [explicit] The paper discusses that training a robust subnetwork and ensuring sufficient MI between layers can lead to full-network robustness, potentially reducing computational complexity.
- Why unresolved: While the paper shows that a robust subnetwork can promote full-network robustness, it does not quantify the relationship between subnetwork size, training time, and robustness levels.
- What evidence would resolve it: Systematic experiments varying the size and position of f*ₐ within different architectures and measuring training time, memory usage, and robustness would provide insights.

### Open Question 3
- Question: What is the relationship between the performance difference of robust and semirobust networks and the weight differences between their corresponding subnetworks?
- Basis in paper: [explicit] The paper provides theoretical bounds for performance difference in terms of the L2 norm of weight differences between f*ᵦ and efb.
- Why unresolved: The paper derives upper bounds but does not empirically validate how closely these bounds reflect actual performance differences in practice.
- What evidence would resolve it: Empirical studies measuring actual performance differences and comparing them to theoretical bounds across various architectures and datasets would validate or refine the theoretical framework.

## Limitations

- The mutual information threshold ρ for guaranteeing robustness propagation remains unspecified, making it difficult to determine exact conditions for effective semirobustness
- Results are limited to only two architectures (ResNet-18 and WideResNet-34-10) and two datasets (CIFAR-10 and CIFAR-100), limiting generalizability
- Computational savings from training only a subnetwork are not quantified in terms of wall-clock time or memory usage

## Confidence

**High confidence**: The experimental methodology for validating semirobustness through adversarial training and mutual information estimation is sound. The proof that linear combinations of robust layers preserve robustness bounds (Theorem 3) is mathematically rigorous.

**Medium confidence**: The theoretical framework connecting mutual information to robustness propagation is plausible but relies on assumptions that may not hold in practice. The performance bound using Taylor approximation (Mechanism 3) is theoretically valid but may be loose in practical scenarios.

**Low confidence**: The specific mutual information threshold ρ required for robustness propagation is not provided, making it difficult to assess the practical applicability of the theory. The claim that semirobustness can be achieved with only a few epochs of fine-tuning lacks sufficient empirical support.

## Next Checks

1. Implement Algorithm 1 to determine the minimum mutual information threshold ρ required for robustness propagation across different network architectures and dataset complexities.

2. Test robustness generalization by evaluating the semirobustness approach against previously unseen attack types and real-world adversarial scenarios beyond the standard FGSM, PGD, and AutoAttack benchmarks.

3. Quantify computational savings by measuring training time, memory usage, and parameter count differences between full-network adversarial training and the proposed semirobustness approach across multiple architectures.