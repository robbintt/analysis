---
ver: rpa2
title: 'CALYPSO: LLMs as Dungeon Masters'' Assistants'
arxiv_id: '2308.07540'
source_url: https://arxiv.org/abs/2308.07540
tags:
- game
- encounter
- players
- monster
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a formative evaluation of large language models
  (LLMs) in assisting Dungeon Masters (DMs) for the game Dungeons & Dragons. The authors
  introduce CALYPSO, a system of LLM-powered interfaces that support DMs with information
  and inspiration specific to their own scenario.
---

# CALYPSO: LLMs as Dungeon Masters' Assistants

## Quick Facts
- arXiv ID: 2308.07540
- Source URL: https://arxiv.org/abs/2308.07540
- Reference count: 11
- Primary result: LLMs can generate high-fidelity text suitable for direct presentation to players and low-fidelity ideas that DMs can develop further while maintaining creative agency

## Executive Summary
This paper presents CALYPSO, a system of LLM-powered interfaces designed to assist Dungeon Masters (DMs) in Dungeons & Dragons. Through a formative evaluation involving interviews with DMs and a large-scale study with 71 players, the authors demonstrate that LLMs can effectively support DMs by generating encounter summaries and creative ideas. The system successfully maintains DM creative agency while providing thematic commonsense and reducing friction in the DMing process.

## Method Summary
The study collected D&D source book data and deployed CALYPSO through a Discord bot interface with three modes: Encounter Understanding (zero-shot summarization), Focused Brainstorming (chat-based elaboration), and Open-Domain Chat (baseline freeform). Using GPT-3 (text-davinci-003) and ChatGPT (gpt-3.5-turbo), the system was deployed in a "play-by-post living world" game over four months. DMs provided feedback through in-app buttons and comments, with prompts iteratively refined based on user input.

## Key Results
- LLMs successfully generate high-fidelity text suitable for direct player presentation
- Prompt engineering critically shapes output from conservative summaries to creative extrapolations
- Human-in-the-loop curation preserves DM creative agency while enabling generative support

## Why This Works (Mechanism)

### Mechanism 1
LLMs can distill complex D&D monster lore into concise, actionable summaries that DMs can use mid-game. The LLM applies abstractive understanding to extract thematic commonsense and unique creature traits from structured game data, producing bite-sized prose. This relies on the assumption that LLMs trained on fantasy literature have internalized sufficient thematic commonsense to extrapolate beyond explicit game text.

### Mechanism 2
Prompt engineering critically shapes whether the LLM outputs conservative summaries or creative extrapolations. Task framing ("summarize" vs. "help understand") and explicit instructions to use thematic commonsense dramatically alter the model's output style and depth. This depends on LLMs being sensitive to prompt wording and able to switch between rote summarization and creative generation based on subtle cue changes.

### Mechanism 3
Human-in-the-loop curation preserves creative agency while allowing LLMs to provide generative support. DMs act as final arbiters of AI-generated content, choosing which ideas to adopt, modify, or reject. This copilot model assumes DMs value creative control and are willing to curate AI output rather than accept it wholesale.

## Foundational Learning

- **Concept**: Thematic commonsense in fantasy literature
  - Why needed: Enables LLM to extrapolate monster behaviors and lore not explicitly stated in D&D source material
  - Quick check: Can you explain why a "blink dog" might behave differently than a regular dog based on common fantasy tropes?

- **Concept**: Prompt engineering sensitivity
  - Why needed: Small changes in task framing dramatically alter LLM output from rote summary to creative extrapolation
  - Quick check: What would happen if you replaced "summarize" with "help understand" in the LLM prompt?

- **Concept**: Human-in-the-loop creative workflows
  - Why needed: Ensures AI augmentation supports rather than replaces DM creative agency
  - Quick check: Why is it important for the DM to have final say over AI-generated encounter descriptions?

## Architecture Onboarding

- **Component map**: Discord bot interface -> GPT-3/ChatGPT backend -> DM interaction -> Player-facing output
- **Critical path**: DM triggers encounter roll → System captures monster stats, setting, and lore → LLM generates encounter summary → DM reviews and optionally uses Focused Brainstorming → DM presents encounter to players
- **Design tradeoffs**: Summarization vs. abstractive understanding (conservative vs. creative output), Focused vs. open-domain chat (context management vs. flexibility), Latency vs. quality (faster responses may sacrifice depth)
- **Failure signatures**: LLM outputs irrelevant or incorrect lore (hallucinations), DM spends too much time curating rather than playing, Players notice AI-generated content disrupting immersion
- **First 3 experiments**: 1) Compare summarization vs. abstractive understanding outputs for the same encounter, 2) Test prompt variations to find optimal balance of creativity and accuracy, 3) Measure DM time spent on curation vs. gameplay with and without CALYPSO

## Open Questions the Paper Calls Out

### Open Question 1
How can LLMs be designed to better handle hallucinations and provide more accurate information in the context of D&D? The paper notes that DMs found the model sometimes hallucinated facts about creatures and rules, but does not provide concrete solutions for preventing or mitigating these hallucinations.

### Open Question 2
How can LLMs be integrated into existing D&D tools and platforms to provide seamless assistance to DMs? While the paper suggests integrating LLMs into existing tools like D&D Beyond and Foundry could provide a more seamless experience, it does not provide concrete implementation or evaluation of such integration.

### Open Question 3
How can LLMs be used to assist DMs in creating more diverse and inclusive content in D&D? The paper mentions LLMs' potential to generate unique "random table" entries customized for specific contexts, but also notes that training artifacts can influence output, such as refusing to suggest fantasy races due to efforts to reduce potential for real-world racial bias.

## Limitations
- Evaluation relies entirely on qualitative feedback from a single Discord-based campaign without controlled comparison to non-AI DMing
- Prompt engineering mechanisms that enable thematic commonsense generation remain underspecified
- Does not address potential bias in AI-generated content or provide systematic analysis of hallucination rates across different encounter types

## Confidence

- **High confidence**: LLMs can generate usable encounter summaries that DMs find helpful for maintaining game flow
- **Medium confidence**: Prompt engineering significantly influences whether LLMs produce conservative summaries versus creative extrapolations
- **Low confidence**: LLMs consistently present thematic commonsense when prompted appropriately

## Next Checks

1. Conduct controlled A/B testing comparing DM experience with CALYPSO versus traditional DMing methods, measuring objective metrics like preparation time, player engagement, and encounter quality scores
2. Systematically vary prompt templates to quantify the relationship between prompt wording and output creativity, testing whether "summarize" versus "help understand" prompts reliably produce different output styles
3. Implement bias and hallucination detection across a diverse set of encounter types, measuring the frequency and severity of incorrect or problematic AI-generated content to establish reliability bounds