---
ver: rpa2
title: Collinear datasets augmentation using Procrustes validation sets
arxiv_id: '2312.04911'
source_url: https://arxiv.org/abs/2312.04911
tags:
- data
- number
- variables
- training
- augmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a method for augmenting collinear datasets
  by combining cross-validation resampling with latent variable modeling. The approach
  leverages collinearity directly during generation, making it particularly effective
  for datasets with moderate to high collinearity, such as spectroscopic or genomic
  data.
---

# Collinear datasets augmentation using Procrustes validation sets

## Quick Facts
- arXiv ID: 2312.04911
- Source URL: https://arxiv.org/abs/2312.04911
- Reference count: 19
- Primary result: Data augmentation method combining cross-validation resampling with latent variable modeling improves ANN performance on collinear datasets

## Executive Summary
This paper introduces a method for augmenting collinear datasets by leveraging cross-validation resampling and latent variable modeling. The approach generates realistic synthetic samples that preserve the covariance structure of the original data, making it particularly effective for datasets with moderate to high collinearity. Two implementations are presented: one based on SVD and another on PLS decomposition. The method requires minimal parameter tuning, works with both numeric and mixed data types, and is computationally efficient.

## Method Summary
The method generates additional data points by utilizing cross-validation resampling and latent variable modeling. It works by fitting a global latent variable model (SVD or PLS) to the entire dataset, then performing K-fold cross-validation. For each fold, a local latent variable model is fit, and the local model's latent variable axes are rotated relative to the global model. This rotation is applied to the local validation subset to generate a new set of predictor values that maintain the global covariance structure while introducing sampling variation. The generated PV-sets can be used to augment the original training data for improved model performance.

## Key Results
- For protein prediction in minced meat from NIR spectra, augmentation reduced root mean squared error by 1.5 to 3 times compared to unaugmented models
- In heart disease classification, accuracy improved from median 0.50 to 0.84 when using augmented datasets
- Number of augmented samples had the largest effect on performance, while latent variables and cross-validation segments had minimal impact

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method generates realistic synthetic samples by resampling the orientation of latent variables in cross-validation folds
- Core assumption: Local cross-validation folds provide representative but slightly different orientations of latent variable space compared to the global model
- Evidence: Cross-validation resampling provides sampling error emulated by rotating latent variable axes

### Mechanism 2
- Claim: Data augmentation reduces overfitting in high-capacity ANN models by increasing effective sample size without introducing unrealistic noise
- Core assumption: Augmented samples are statistically similar enough to real data that the ANN generalizes rather than memorizes
- Evidence: ANN with 95000 parameters trained on augmented data showed 18% reduction in median test error

### Mechanism 3
- Claim: PLS-based augmentation prioritizes variance relevant to the response variable, improving predictive accuracy for regression tasks
- Core assumption: The part of X's covariance structure that is relevant to Y is the most important for generating predictive synthetic samples
- Evidence: PLS decomposition accounts for variance-covariance structure of XTY, making it favorable for regression tasks

## Foundational Learning

- Concept: Cross-validation resampling
  - Why needed here: Provides source of sampling error used to rotate latent variable axes, enabling generation of diverse but structurally consistent synthetic data
  - Quick check question: What happens to the local model's latent variable orientation if a different fold is used in cross-validation?

- Concept: Singular value decomposition (SVD) and partial least squares (PLS)
  - Why needed here: Both decompose predictor matrix into latent variables; SVD captures all variance while PLS captures variance most correlated with response
  - Quick check question: How does number of latent variables affect trade-off between capturing systematic variation and introducing noise in generated samples?

- Concept: Procrustean rule
  - Why needed here: Defines constraint that generated PV-sets must have same distances as original validation folds when projected into global model space
  - Quick check question: What does it mean if Procrustean rule is violated for a generated PV-set?

## Architecture Onboarding

- Component map: Data preprocessing -> global model fit -> cross-validation loop -> PV-set generation -> augmentation -> model training
- Critical path: Data preprocessing → global model fit → cross-validation loop → PV-set generation → augmentation → model training
- Design tradeoffs:
  - SVD vs. PLS: SVD preserves full covariance (good for one-class), PLS preserves response-relevant covariance (good for regression)
  - K (segments): More segments → more unique PV-sets but higher computational cost; fewer segments → less diversity
  - A (latent variables): Too few → missing systematic variation; too many → noise amplification (especially in PLS)
- Failure signatures:
  - If RMSEP/R2 does not improve after augmentation → check if latent variable count is sufficient or if cross-validation folds are too small
  - If model performance degrades → possible overfitting to synthetic patterns; reduce number of PV-sets or increase original training size
  - If PV-set generation is slow → reduce K or A, or use optimized linear algebra libraries
- First 3 experiments:
  1. Run SVD-based augmentation on Tecator with K=5, A=10; compare RMSEP before/after
  2. Run PLS-based augmentation on Tecator with K=5, A=10; compare RMSEP before/after
  3. Run SVD-based augmentation on Heart with K=5, A=10; compare classification accuracy before/after

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical limit of data augmentation effectiveness for collinear datasets using the Procrustes validation sets method?
- Basis in paper: The paper demonstrates significant improvements but does not establish theoretical bounds or limits for the method's effectiveness
- Why unresolved: The paper focuses on empirical results rather than theoretical analysis. The relationship between dataset characteristics and augmentation effectiveness remains unexplored
- What evidence would resolve it: Systematic theoretical analysis of the method's convergence properties, empirical studies across diverse dataset characteristics, and comparison with theoretical bounds for other augmentation methods

### Open Question 2
- Question: How does the Procrustes validation sets method compare to other data augmentation techniques for collinear datasets in terms of computational efficiency and performance?
- Basis in paper: The paper mentions that the method is "simple, fast, versatile, yet efficient" but does not provide direct comparisons with other augmentation techniques
- Why unresolved: The paper only compares the method's performance to unaugmented data and does not benchmark it against other established augmentation techniques
- What evidence would resolve it: Head-to-head comparisons of the method with other augmentation techniques on the same datasets, measuring both computational efficiency and model performance improvements

### Open Question 3
- Question: What are the optimal parameters for the Procrustes validation sets method when applied to different types of collinear datasets?
- Basis in paper: The paper states that "neither parameter significantly influences the quality of the augmented data" and that parameters "do not require specific tuning," but this conclusion is based on limited experiments
- Why unresolved: The paper's experiments were conducted on a limited number of datasets and parameter combinations
- What evidence would resolve it: Extensive empirical studies across various dataset types, sizes, and collinearity degrees, coupled with sensitivity analysis of the method's parameters

## Limitations
- Lack of complete implementation details for ANN models and specific PV-set generation procedure
- Method's effectiveness depends heavily on quality and size of original dataset
- Limited empirical studies across diverse dataset types and characteristics

## Confidence
- High Confidence: The mechanism by which cross-validation resampling and latent variable modeling generate structurally consistent synthetic data
- Medium Confidence: The claim that PLS-based augmentation prioritizes response-relevant variance
- Medium Confidence: The effectiveness of data augmentation in reducing overfitting in high-capacity ANN models

## Next Checks
1. Implement PV-set generation procedure using SVD and PLS decomposition with cross-validation resampling on a collinear dataset
2. Conduct systematic study of effect of K, A, and number of augmented samples on model performance across different datasets
3. Apply the proposed method to diverse set of collinear datasets to evaluate robustness and limitations