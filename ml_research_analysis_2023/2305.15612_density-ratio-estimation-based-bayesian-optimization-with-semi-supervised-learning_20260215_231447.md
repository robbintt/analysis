---
ver: rpa2
title: Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning
arxiv_id: '2305.15612'
source_url: https://arxiv.org/abs/2305.15612
tags:
- bore
- lfbo
- class
- optimization
- unlabeled
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the overconfidence problem in density ratio
  estimation-based Bayesian optimization, where supervised classifiers tend to be
  overly confident about global solution candidates. The proposed method, DRE-BO-SSL,
  uses semi-supervised learning to mitigate this issue by incorporating unlabeled
  data through label propagation or label spreading.
---

# Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning

## Quick Facts
- arXiv ID: 2305.15612
- Source URL: https://arxiv.org/abs/2305.15612
- Reference count: 40
- This paper addresses overconfidence in density ratio estimation-based Bayesian optimization by incorporating semi-supervised learning to improve exploration-exploitation balance.

## Executive Summary
This paper tackles the overconfidence problem in density ratio estimation-based Bayesian optimization (DRE-BO), where supervised classifiers tend to concentrate probability mass around a few high-confidence points. The proposed DRE-BO-SSL method incorporates unlabeled data through semi-supervised learning techniques (label propagation and label spreading) to create smoother decision boundaries and more robust global solution candidates. The approach is validated on synthetic benchmarks, tabular benchmarks, NATS-Bench, and a novel minimum multi-digit MNIST search task, demonstrating improved performance over existing methods like BORE and LFBO.

## Method Summary
DRE-BO-SSL addresses overconfidence in DRE-based Bayesian optimization by incorporating semi-supervised learning. The method works by sampling unlabeled points from truncated multivariate normal distributions centered around existing labeled points, then applying label propagation or label spreading to estimate pseudo-labels. These pseudo-labels are used to construct an inductive model that estimates class probabilities for any input, which serves as the acquisition function. The next query point is selected by maximizing this class probability using L-BFGS-B optimization with 1000 random restarts, with a fallback to random selection when the acquisition landscape is flat.

## Key Results
- DRE-BO-SSL outperforms existing methods (BORE, LFBO) on synthetic benchmarks (Branin, Beale, Bukin6, Six-hump camel)
- The method shows improved exploration-exploitation balance in both unlabeled point sampling and fixed-size pool scenarios
- Performance improvements are demonstrated on real-world tasks including NATS-Bench and a minimum multi-digit MNIST search task

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semi-supervised learning mitigates overconfidence by leveraging unlabeled data to reduce decision boundary sharpness.
- Mechanism: Label propagation and label spreading algorithms propagate labels through a similarity graph, using unlabeled data to smooth decision boundaries. This reduces the probability mass concentrated around a few high-confidence points, expanding the decision set for the target class.
- Core assumption: The cluster assumption holds - points close in input space are likely to share the same label, enabling effective label propagation.
- Evidence anchors:
  - [abstract] "Developing this line of research further, supervised classifiers are employed to estimate a class probability for the two groups instead of a density ratio. However, the supervised classifiers used in this strategy tend to be overconfident for a global solution candidate."
  - [section] "As discussed in the previous work, this line of research provides a new understanding of Bayesian optimization, which allows us to solve Bayesian optimization using binary classification."
  - [corpus] Weak - neighboring papers focus on density ratio estimation techniques but don't directly address overconfidence in BO context.
- Break condition: Cluster assumption fails or similarity metric poorly captures relevant structure, causing label propagation to spread incorrect labels.

### Mechanism 2
- Claim: Sampling unlabeled points from truncated multivariate normal distributions improves exploration by satisfying the cluster assumption.
- Mechanism: Unlabeled points are sampled from distributions centered around existing labeled points using minimax tilting method. This creates a neighborhood structure where similar inputs have similar labels, enabling semi-supervised classifiers to identify broader regions of interest.
- Core assumption: The truncated multivariate normal sampling strategy creates meaningful local neighborhoods that reflect the true structure of the optimization landscape.
- Evidence anchors:
  - [section] "To build DRE-BO-SSL associated with Assumption 4.1, we sample unlabeled data points from the truncated multivariate normal distribution so that each sample is in a compact X."
  - [section] "To effectively sample from the truncated multivariate normal distribution, we adopt a minimax tilting method [7]."
  - [corpus] Weak - sampling methods are mentioned but not specifically validated for BO semi-supervised learning.
- Break condition: Optimization landscape has disconnected modes or highly irregular structure that truncated normal sampling fails to capture.

### Mechanism 3
- Claim: Converting semi-supervised classifiers to Nadaraya-Watson non-parametric form enables generalization to unseen inputs.
- Mechanism: After label propagation/spreading, the propagated labels are used to construct an inductive model that estimates class probabilities for any input using weighted similarities. This provides a smooth, non-parametric decision function.
- Core assumption: The inductive model with propagated labels generalizes better than supervised classifiers because it incorporates geometric structure from unlabeled data.
- Evidence anchors:
  - [section] "By the nature of transductive setting, it only predicts the labels of particular data using particular known data [17], which implies that it cannot estimate a categorical distribution of unseen data. To enable it, given unseen data point x, we define an inductive model withbC."
  - [section] "Since off-the-shelf local optimization methods struggle for optimizing a flat landscape, this simple heuristic is effective."
  - [corpus] Weak - non-parametric estimation techniques are mentioned but not specifically validated for this BO application.
- Break condition: High-dimensional input space where similarity-based weighting becomes ineffective due to curse of dimensionality.

## Foundational Learning

- Concept: Density ratio estimation and its relationship to binary classification
  - Why needed here: The paper's core approach estimates density ratios by framing it as binary classification between high-value and low-value input regions
  - Quick check question: Why does estimating p(x|y≤y†)/p(x|y>y†) become equivalent to binary classification between the two groups?

- Concept: Semi-supervised learning and transductive vs inductive settings
  - Why needed here: The method uses label propagation (transductive) but must convert to an inductive model for optimization
  - Quick check question: What's the key difference between transductive learning that predicts labels for given unlabeled points versus inductive learning that can classify any new point?

- Concept: Cluster assumption and its implications for semi-supervised learning
  - Why needed here: The sampling strategy and semi-supervised learning both rely on the assumption that nearby points share labels
  - Quick check question: How does the cluster assumption enable label propagation to be effective in this optimization context?

## Architecture Onboarding

- Component map:
  - Data preprocessing: Threshold computation (y†), label assignment, unlabeled point sampling
  - Semi-supervised learning: Label propagation/spreading with similarity computation and iterative label update
  - Acquisition function: Class probability estimation for unseen points using inductive model
  - Optimization: Multi-started local optimization with flat landscape detection and random selection fallback
  - Evaluation: Function evaluation and dataset update

- Critical path: Unlabeled sampling → Label propagation → Inductive model construction → Acquisition function maximization → Function evaluation → Dataset update

- Design tradeoffs:
  - Sampling strategy: Truncated normal vs uniform vs specialized sequences - affects exploration quality
  - Semi-supervised method: Label propagation (simpler) vs label spreading (more flexible with clamping factor)
  - Unlabeled data quantity: More points improve exploration but increase computational cost
  - Subsampling pool size: Balances speed vs coverage of search space

- Failure signatures:
  - Flat acquisition landscape leading to random selection dominance
  - Overconfident predictions concentrating queries in narrow regions
  - Slow convergence due to poor similarity metric or sampling strategy
  - Computational bottlenecks with large pools or many unlabeled points

- First 3 experiments:
  1. Implement basic label propagation with synthetic 2D function (e.g., Branin) with 10 labeled and 100 unlabeled points
  2. Compare truncated normal sampling vs uniform sampling on simple benchmark
  3. Test inductive model generalization by evaluating class probability estimates on held-out test points

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DRE-BO-SSL scale with increasing dimensionality of the search space, and what are the theoretical bounds on its efficiency in high-dimensional settings?
- Basis in paper: [inferred] The paper mentions experiments on synthetic benchmarks and real-world tasks, but does not explicitly analyze scalability or provide theoretical bounds for high-dimensional spaces.
- Why unresolved: High-dimensional spaces pose challenges for both density ratio estimation and semi-supervised learning, which could significantly impact the efficiency and effectiveness of DRE-BO-SSL. Theoretical analysis and empirical validation in high-dimensional settings are needed.
- What evidence would resolve it: Rigorous theoretical analysis providing bounds on the performance of DRE-BO-SSL in high-dimensional spaces, coupled with extensive empirical experiments on high-dimensional synthetic and real-world datasets.

### Open Question 2
- Question: What are the theoretical guarantees for the performance of DRE-BO-SSL compared to existing DRE-based methods like BORE and LFBO, particularly in terms of regret bounds?
- Basis in paper: [explicit] The paper claims that DRE-BO-SSL outperforms existing methods and provides some analysis on the effects of unlabeled data, but does not provide rigorous theoretical guarantees or regret bounds.
- Why unresolved: While empirical results show promise, theoretical guarantees are crucial for understanding the conditions under which DRE-BO-SSL is superior and for comparing it fairly with existing methods.
- What evidence would resolve it: Formal theoretical analysis establishing regret bounds for DRE-BO-SSL, along with a comparison of these bounds to those of existing DRE-based methods under various assumptions and conditions.

### Open Question 3
- Question: How does the choice of semi-supervised learning algorithm (label propagation vs. label spreading) affect the performance of DRE-BO-SSL, and are there other semi-supervised learning techniques that could be more effective?
- Basis in paper: [explicit] The paper compares label propagation and label spreading but does not explore other semi-supervised learning techniques or provide a comprehensive analysis of the impact of the choice of algorithm.
- Why unresolved: Different semi-supervised learning algorithms have different properties and assumptions, which could significantly impact the performance of DRE-BO-SSL. Exploring a wider range of algorithms and understanding their effects is crucial for optimizing the method.
- What evidence would resolve it: Empirical comparison of DRE-BO-SSL with various semi-supervised learning algorithms on a diverse set of benchmark functions and real-world tasks, along with an analysis of the properties and assumptions of each algorithm that influence their performance in this context.

## Limitations

- The empirical validation primarily focuses on synthetic benchmarks with limited real-world application examples
- The truncated multivariate normal sampling strategy lacks thorough ablation studies comparing it against simpler alternatives
- The conversion from transductive to inductive models introduces potential generalization gaps not fully characterized in the experiments

## Confidence

**High confidence**: The core mechanism of using semi-supervised learning to reduce overconfidence in density ratio estimation-based Bayesian optimization is well-supported by both theory and experimental results. The distinction between transductive and inductive settings and the need for conversion is clearly articulated.

**Medium confidence**: The effectiveness of the specific sampling strategy (truncated multivariate normal with minimax tilting) and its impact on exploration-exploitation balance. While the paper presents experimental evidence, the ablation studies are limited.

**Low confidence**: Claims about the method's robustness across diverse real-world optimization problems, as most experiments focus on synthetic benchmarks and a single novel task (multi-digit MNIST search).

## Next Checks

1. **Sampling strategy ablation**: Systematically compare truncated multivariate normal sampling against uniform, Halton, and Sobol' sequences across the same benchmark functions to quantify the marginal benefit of the more complex approach.

2. **High-dimensional scaling analysis**: Evaluate DRE-BO-SSL performance on problems with 10+ dimensions to test whether the similarity-based semi-supervised learning degrades due to the curse of dimensionality.

3. **Real-world application case study**: Apply the method to a challenging real-world optimization problem (e.g., hyperparameter tuning for deep learning or materials discovery) to validate robustness beyond synthetic benchmarks.