---
ver: rpa2
title: 'Nemo: First Glimpse of a New Rule Engine'
arxiv_id: '2308.15897'
source_url: https://arxiv.org/abs/2308.15897
tags:
- nemo
- data
- system
- programming
- datalog
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Nemo is a new logic programming engine for data-centric analytics
  that offers reliability and performance. It implements a declarative Datalog dialect
  with support for existential rules, stratified negation, and aggregates.
---

# Nemo: First Glimpse of a New Rule Engine

## Quick Facts
- arXiv ID: 2308.15897
- Source URL: https://arxiv.org/abs/2308.15897
- Reference count: 13
- Nemo is a new logic programming engine for data-centric analytics that offers reliability and performance.

## Executive Summary
Nemo is a new logic programming engine designed for data-centric analytics, offering scalability and performance for Datalog reasoning over knowledge graphs and ontologies. It implements a declarative Datalog dialect with support for existential rules, stratified negation, and aggregates. The system achieves performance matching or exceeding leading Datalog systems while handling knowledge graphs with up to 10^8 facts on standard laptops. Nemo is implemented in Rust and available as open-source software, usable via command-line or as a library.

## Method Summary
Nemo uses materialization (forward chaining) with semi-naive evaluation and the restricted chase as its reasoning procedure. The system employs columnar data structures for efficient type handling, leapfrog triejoin for multiway joins, and optimization techniques based on careful computation planning. It supports input in CSV, TSV, RDF, and logic programming fact formats, and can be used as either a command-line tool or Rust library. Performance is evaluated through benchmarking against VLog on existential rule tasks and OWL EL reasoning, with scalability demonstrated up to 10^8 facts.

## Key Results
- Nemo achieves scalability matching or exceeding leading Datalog systems on knowledge graphs and ontologies
- System handles up to 10^8 facts on standard laptops with performance advantages on hard cases like Deep200 stress test
- Nemo demonstrates superior performance on large SNOMED CT ontology reasoning compared to VLog

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Nemo achieves scalability matching or exceeding leading Datalog systems through a combination of columnar data structures, multiway join algorithms, and optimized computation planning.
- Mechanism: The system uses columnar storage for efficient type handling, leapfrog triejoin for multiway joins, and semi-naive evaluation with restricted chase for rule materialization.
- Core assumption: The columnar design and leapfrog triejoin algorithm are compatible with the types of workloads and data sizes described in the benchmarks.
- Evidence anchors:
  - [abstract] "Its scalability for these tasks matches or exceeds that of leading Datalog systems."
  - [section] "Key to overall performance is a combination of columnar data structures..., a multiway join algorithm based on leapfrog triejoin..., and own new optimisation techniques based on careful computation planning."
  - [corpus] Weak evidence - no direct citations to leapfrog triejoin performance claims in neighbors.
- Break condition: Performance degrades significantly on workloads with highly irregular join patterns that do not benefit from columnar storage or leapfrog triejoin.

### Mechanism 2
- Claim: Nemo's support for existential rules, stratified negation, and aggregates enables it to handle complex reasoning tasks over knowledge graphs and ontologies.
- Mechanism: The Datalog dialect with existential quantification in rule heads and stratified negation allows for expressing complex relationships and aggregations found in real-world data.
- Core assumption: The extended Datalog features are correctly implemented and optimized for the described use cases.
- Evidence anchors:
  - [abstract] "Nemo is built for data-centric analytic computations, modelled in a fully declarative Datalog dialect."
  - [section] "Nemo also supports stratified negation..., further datatypes and built-ins..., and existentially quantified head variables..."
  - [corpus] Weak evidence - neighbors discuss Datalog engines but do not specifically address existential rules or stratified negation performance.
- Break condition: Incorrect results or significant performance degradation when processing rules with complex negation or aggregation patterns.

### Mechanism 3
- Claim: Nemo's Rust implementation provides reliability and performance advantages over other Datalog systems.
- Mechanism: Rust's memory safety guarantees and performance characteristics enable Nemo to handle large datasets efficiently without common memory-related errors.
- Core assumption: The choice of Rust as the implementation language directly contributes to the system's reliability and performance.
- Evidence anchors:
  - [abstract] "Nemo is written in Rust and available as a free and open source tool."
  - [section] "Nemo is implemented in Rust and can also be used as a Rust library (a crate)."
  - [corpus] Weak evidence - no direct comparison of Rust vs other languages for Datalog engines in neighbors.
- Break condition: The system fails to handle memory-intensive workloads or exhibits reliability issues under stress.

## Foundational Learning

- Concept: Datalog and its relationship to logic programming and databases
  - Why needed here: Understanding Nemo's foundation as a Datalog engine is crucial for comprehending its capabilities and limitations.
  - Quick check question: What is the primary difference between Datalog and traditional Prolog?
- Concept: Knowledge graphs and ontologies
  - Why needed here: Nemo is designed for reasoning with knowledge graphs and ontologies, so understanding these concepts is essential.
  - Quick check question: How do existential rules relate to tuple-generating dependencies in the context of ontologies?
- Concept: Materialization and forward chaining
  - Why needed here: Nemo uses materialization (forward chaining) as its reasoning procedure, so understanding this concept is key to grasping its operation.
  - Quick check question: What is the difference between semi-naive evaluation and naive evaluation in Datalog materialization?

## Architecture Onboarding

- Component map: nmo (command-line client) -> Rust core engine -> CSV/TSV/RDF/logic facts input -> Result output
- Critical path: Data loading → Rule application → Result materialization
- Design tradeoffs: Nemo prioritizes scalability and performance over persistence (no persistent database backend) and focuses on in-memory processing.
- Failure signatures: Performance degradation on irregular join patterns, incorrect results with complex negation or aggregation, memory issues with large datasets.
- First 3 experiments:
  1. Run the example program to find old lime trees in Dresden (examples/lime-trees) and measure execution time.
  2. Compare Nemo's performance on a small ontology reasoning task with VLog using the provided benchmarks.
  3. Test Nemo's support for stratified negation by creating a simple program with negated rules and verifying the results.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the performance bottlenecks when Nemo processes datasets larger than 10^8 facts?
- Basis in paper: [inferred] The paper demonstrates scalability up to 10^8 facts but doesn't explore limits beyond this.
- Why unresolved: The authors only benchmark up to 10^8 facts and don't discuss scalability beyond this point.
- What evidence would resolve it: Performance benchmarks on datasets ranging from 10^8 to 10^10 facts, identifying specific memory or computation limits.

### Open Question 2
- Question: How does Nemo's performance compare to specialized streaming systems for continuously updating knowledge graphs?
- Basis in paper: [explicit] The paper mentions plans for supporting input data from persistent databases but doesn't compare with streaming systems.
- Why unresolved: The paper focuses on batch processing and doesn't evaluate Nemo's capabilities for incremental updates.
- What evidence would resolve it: Benchmark comparisons between Nemo and streaming Datalog systems like differential dataflow on dynamic knowledge graphs.

### Open Question 3
- Question: What optimization techniques could further improve Nemo's performance on existential rule reasoning?
- Basis in paper: [explicit] The authors mention "own new optimisation techniques based on careful computation planning" but don't detail specific optimizations.
- Why unresolved: The paper describes general optimization approaches but doesn't explore potential improvements or alternatives.
- What evidence would resolve it: Performance analysis showing the impact of specific optimizations (e.g., join ordering heuristics, parallel processing) on various benchmark datasets.

## Limitations

- The evaluation relies primarily on comparison with VLog, which may not fully represent the state-of-the-art across all Datalog systems.
- While the system claims to handle 10^8 facts on standard laptops, the exact memory requirements and performance characteristics at scale are not fully detailed.
- The Rust implementation's performance advantages are asserted but not empirically compared against implementations in other languages.

## Confidence

- **High confidence**: Nemo's core functionality as a Datalog engine with materialization-based reasoning and its support for existential rules, stratified negation, and aggregates.
- **Medium confidence**: Performance claims relative to VLog, as these are based on specific benchmark configurations that may not generalize to all workloads.
- **Medium confidence**: Scalability claims regarding handling 10^8 facts, as the exact memory requirements and performance characteristics at scale are not fully detailed.

## Next Checks

1. **Cross-system comparison**: Benchmark Nemo against additional Datalog systems beyond VLog, including modern systems like Soufflé or commercial solutions, to verify the performance claims are robust across different systems.
2. **Scalability validation**: Test Nemo with progressively larger datasets (10^6 to 10^9 facts) to empirically verify the memory usage and performance characteristics claimed in the paper.
3. **Complex reasoning patterns**: Create and test Datalog programs with nested existential rules, multiple layers of stratified negation, and complex aggregation patterns to validate the system's correctness and performance on hard cases not covered in the standard benchmarks.