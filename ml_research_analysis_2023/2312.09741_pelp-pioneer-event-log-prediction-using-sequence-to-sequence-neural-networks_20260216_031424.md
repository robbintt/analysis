---
ver: rpa2
title: 'PELP: Pioneer Event Log Prediction Using Sequence-to-Sequence Neural Networks'
arxiv_id: '2312.09741'
source_url: https://arxiv.org/abs/2312.09741
tags:
- event
- process
- prediction
- traces
- logs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PELP (Pioneer Event Log Prediction), a novel
  framework for predicting future event logs using sequence-to-sequence (Seq2Seq)
  deep learning models. The approach treats event log prediction as a transformation
  problem, where historical traces are used to predict future traces.
---

# PELP: Pioneer Event Log Prediction Using Sequence-to-Sequence Neural Networks

## Quick Facts
- arXiv ID: 2312.09741
- Source URL: https://arxiv.org/abs/2312.09741
- Authors: 
- Reference count: 22
- One-line primary result: PELP achieves comparable performance to weighted probability baselines on event log prediction, with RMSE scores ranging from 1.40 to 24.72 across seven real-world datasets.

## Executive Summary
This paper introduces PELP (Pioneer Event Log Prediction), a novel framework for predicting future event logs using sequence-to-sequence (Seq2Seq) deep learning models. The approach treats event log prediction as a transformation problem, where historical traces are used to predict future traces. The framework comprises five stages: data collection, preprocessing, model training, prediction generation, and evaluation.

The Seq2Seq model employs an encoder-decoder architecture with GRU layers and attention mechanisms to learn patterns in event logs. During training, ordered case sequences are used as input-output pairs, with traces concatenated and separated by end-of-trace tokens. Hyperparameters are optimized through grid and random search. Experiments on seven real-world event logs show that the proposed approach achieves comparable performance to weighted probability baselines, with RMSE and MAE scores ranging from 1.40 to 24.72 and 0.51 to 3.23 respectively. Synthetic log experiments demonstrate perfect prediction capability when seasonality patterns exist.

## Method Summary
PELP uses a sequence-to-sequence neural network architecture with GRU layers and attention mechanisms to predict future event logs from historical traces. The model treats event log prediction as a transformation problem, mapping ordered historical trace sequences to future trace sequences. During preprocessing, events are ordered by timestamp and concatenated into (X,Y) training pairs separated by end-of-trace tokens. The encoder processes historical traces while the decoder with attention generates future traces iteratively. Hyperparameter optimization is performed through grid and random search, with training stopping after 100 epochs without loss improvement. Predictions are generated using the last N training traces as input and evaluated using directly-follows matrices with RMSE and MAE metrics.

## Key Results
- PELP achieves RMSE scores ranging from 1.40 to 24.72 and MAE scores from 0.51 to 3.23 across seven real-world event logs
- Synthetic log experiments show perfect prediction capability when seasonality patterns exist
- Performance degrades significantly on logs with many unique activities or long average trace lengths
- The approach performs best on logs with high auto-correlation in directly-follows relationships over time

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sequence-to-sequence neural networks can learn temporal patterns in event logs by treating trace sequences as ordered training pairs.
- Mechanism: The encoder-decoder architecture processes concatenated historical traces with EOT tokens as input, predicting future traces by learning dependencies between consecutive trace sequences.
- Core assumption: Event log patterns exhibit sufficient auto-correlation over time to be learned by the model.
- Evidence anchors:
  - [abstract] "the Seq2Seq model employs an encoder-decoder architecture with GRU layers and attention mechanisms to learn patterns in event logs"
  - [section 4.3] "The prediction problem is abstracted to a transformation that, given historical log traces, predicts future traces"
  - [corpus] Weak - no direct evidence in neighbors about Seq2Seq learning temporal patterns
- Break condition: If event log patterns have low auto-correlation over time, the model cannot learn meaningful dependencies and predictions degrade significantly.

### Mechanism 2
- Claim: The attention mechanism in the decoder helps filter noise and focus on important parts of input sequences for better predictions.
- Mechanism: Attention weights are computed during decoding to emphasize relevant encoder states, allowing the model to handle variable-length sequences and reduce the impact of irrelevant trace elements.
- Core assumption: Some parts of the input sequence contain more predictive signal than others for future trace generation.
- Evidence anchors:
  - [abstract] "The Seq2Seq model employs an encoder-decoder architecture with GRU layers and attention mechanisms"
  - [section 4.3] "Attention [3] is a mechanism that makes the model focus on the 'important' parts of the input data"
  - [corpus] Weak - no direct evidence about attention effectiveness in process mining context
- Break condition: If all input trace elements contribute equally to predictions or if the attention mechanism fails to learn meaningful weights, the filtering benefit disappears.

### Mechanism 3
- Claim: Treating event log prediction as a sequence-to-sequence transformation problem enables direct generation of future traces without intermediate model discovery.
- Mechanism: The model learns to map ordered historical trace sequences to future trace sequences, bypassing traditional process discovery and directly outputting predicted event logs.
- Core assumption: The transformation from historical to future traces can be learned as a direct mapping without needing explicit process model representation.
- Evidence anchors:
  - [abstract] "The approach treats event log prediction as a transformation problem, where historical traces are used to predict future traces"
  - [section 4.3] "The prediction problem is abstracted to a transformation that, given historical log traces, predicts future traces"
  - [corpus] Weak - no direct evidence about bypassing process discovery in neighbors
- Break condition: If the relationship between historical and future traces is too complex to be learned as a direct mapping, or if intermediate process models contain essential information not captured in trace sequences.

## Foundational Learning

- Event log structure and Directly-Follows relationships
  - Why needed here: Understanding how traces and directly-follows relationships work is essential for grasping how predictions are evaluated and why certain logs are harder to predict
  - Quick check question: What are the three mandatory fields in an event log according to the XES standard?

- Sequence-to-sequence neural network architecture
  - Why needed here: The entire approach relies on understanding how encoder-decoder models with attention work for sequence prediction tasks
  - Quick check question: What is the primary function of the attention mechanism in Seq2Seq models?

- Process mining concepts (process discovery, PPM vs Process Forecasting)
  - Why needed here: The paper positions its approach within the broader process mining field and contrasts it with existing techniques
  - Quick check question: How does Predictive Process Monitoring differ from Process Forecasting in terms of prediction granularity?

## Architecture Onboarding

- Component map: Data Collection -> Data Preprocessing -> Model Training -> Prediction Generation -> Evaluation
- Critical path: Data Preprocessing → Model Training → Prediction Generation → Evaluation
- Design tradeoffs:
  - Using GRU vs LSTM: GRU is computationally lighter but may have less long-term memory capacity
  - Fixed architecture vs flexible: The paper uses a fixed GRU-based architecture rather than exploring different model architectures
  - Stop condition: Training stops after 100 epochs without loss improvement, which may lead to overfitting for some datasets
- Failure signatures:
  - Predictions become repetitive (same activity repeated indefinitely)
  - Model fails to generate EOT tokens, resulting in incomplete traces
  - Training time becomes excessive for logs with long average trace lengths
  - Performance degrades significantly when new activities appear in test data
- First 3 experiments:
  1. Test on synthetic logs with perfect seasonality to verify the model can achieve zero loss
  2. Evaluate on logs with high auto-correlation in directly-follows relationships to test optimal performance conditions
  3. Test on logs with many unique activities or long average trace lengths to identify failure modes and limitations

## Open Questions the Paper Calls Out

- How does the PELP framework perform when predicting event logs with significant structural changes over time, beyond frequency changes?
- What are the optimal hyperparameters for the Seq2Seq model when dealing with event logs that have long average trace lengths or many unique activities?
- How does the PELP framework compare to other existing event log prediction methods, such as those based on statistical time series analysis or process model simulation?

## Limitations
- Experimental evaluation relies on only seven real-world event logs, limiting generalizability
- Performance claims are not validated against more sophisticated baselines beyond weighted probability
- Computational efficiency and scalability for large logs with long trace lengths is not thoroughly analyzed

## Confidence
- **High confidence** in the core methodology description - the Seq2Seq architecture, preprocessing steps, and evaluation metrics are clearly specified and technically sound
- **Medium confidence** in the performance claims - while the results are presented with specific metrics, the limited dataset diversity and lack of comparison with more advanced baselines reduce generalizability
- **Low confidence** in the scalability claims - the paper notes that long average trace lengths increase training time significantly, but doesn't provide concrete scaling analysis or computational resource requirements

## Next Checks
1. **Dataset Diversity Test**: Apply the PELP framework to additional event logs with varying characteristics (e.g., different numbers of unique activities, trace lengths, and temporal patterns) to validate performance claims across a broader range of scenarios.

2. **Baseline Comparison Expansion**: Compare PELP against more sophisticated prediction methods beyond the weighted probability baseline, such as LSTM-based approaches, transformer models, or hybrid process mining techniques that combine model discovery with machine learning.

3. **Computational Efficiency Analysis**: Measure and report training time, memory usage, and prediction latency for logs with varying characteristics to provide concrete evidence about the framework's scalability and practical deployment considerations.