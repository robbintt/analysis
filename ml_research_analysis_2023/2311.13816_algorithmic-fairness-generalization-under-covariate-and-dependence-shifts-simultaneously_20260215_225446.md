---
ver: rpa2
title: Algorithmic Fairness Generalization under Covariate and Dependence Shifts Simultaneously
arxiv_id: '2311.13816'
source_url: https://arxiv.org/abs/2311.13816
tags:
- domain
- domains
- data
- sensitive
- fddg
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a fairness-aware domain generalization framework
  addressing both covariate and dependence shifts. The key idea is to learn a transformation
  model that disentangles data into content, sensitive, and style factors, then generate
  synthetic domains with varied fairness dependencies.
---

# Algorithmic Fairness Generalization under Covariate and Dependence Shifts Simultaneously

## Quick Facts
- arXiv ID: 2311.13816
- Source URL: https://arxiv.org/abs/2311.13816
- Reference count: 40
- Key outcome: Introduces a fairness-aware domain generalization framework addressing both covariate and dependence shifts, achieving up to 8% higher DP on YFCC100M-FDG while maintaining comparable accuracy.

## Executive Summary
This paper presents FDDG, a novel framework for fairness-aware domain generalization that addresses both covariate and dependence shifts. The key innovation is a transformation model that disentangles data into content, sensitive, and style factors, enabling the generation of synthetic domains with controlled fairness dependencies. By training a classifier on these augmented domains with fairness constraints, FDDG achieves superior performance in maintaining both accuracy and fairness across unseen target domains compared to state-of-the-art baselines.

## Method Summary
FDDG learns a transformation model T that disentangles data into content, sensitive, and style factors, then generates synthetic domains with varied fairness dependencies. The method uses dual optimization with fairness constraints to train a fair invariant classifier on augmented data. The transformation model employs an encoder-decoder architecture with adversarial training to ensure disentanglement, while the classifier is optimized to minimize worst-case risk across domains while satisfying demographic parity constraints. Extensive experiments on four benchmark datasets demonstrate significant improvements in fairness metrics while maintaining accuracy.

## Key Results
- Achieves up to 8% higher demographic parity (DP) on YFCC100M-FDG dataset compared to state-of-the-art baselines
- Maintains comparable accuracy while improving fairness across all four benchmark datasets
- Outperforms existing domain generalization methods by effectively handling both covariate and dependence shifts simultaneously
- Demonstrates robustness across diverse datasets including image (ccMNIST, FairFace, YFCC100M-FDG) and tabular (NYSF) data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The transformation model T effectively disentangles data into content, sensitive, and style factors, enabling the generation of synthetic domains with controlled fairness dependencies.
- Mechanism: By encoding data into three independent latent factors (content, sensitive, style), T can reconstruct instances with the same content and class label but varying sensitive attributes and domain styles. This allows the generation of diverse synthetic domains where fairness dependencies are systematically altered while preserving semantic information.
- Core assumption: The underlying data generation process can be factorized into three independent latent factors, and the transformation model can learn to disentangle these factors without information loss.
- Evidence anchors:
  - [abstract] "We assert the existence of an underlying transformation model can transform data from one domain to another, while preserving the semantics related to non-sensitive attributes and classes."
  - [section] "We assume that each instance xe_i is generated from a latent content factor c ∈ C, a latent sensitive factor a ∈ A, and a latent style factor se"
- Break condition: If the latent factors are not truly independent or the transformation model cannot accurately disentangle them, generated synthetic data may contain spurious correlations that violate the assumed invariance.

### Mechanism 2
- Claim: Training a classifier on augmented synthetic domains with varied fairness dependencies enforces invariance to both covariate and dependence shifts.
- Mechanism: The algorithm generates synthetic domains by sampling random sensitive and style factors while keeping content factors fixed. By training the classifier to be invariant across these synthetic domains, it learns to ignore spurious correlations between sensitive attributes and outcomes that vary across domains, achieving fairness invariance.
- Core assumption: The classifier can learn to be invariant across synthetic domains if the data augmentation sufficiently covers the space of possible fairness dependencies.
- Evidence anchors:
  - [abstract] "By augmenting various synthetic data domains through the model, we learn a fair and invariant classifier in source domains. This classifier can then be generalized to unknown target domains, maintaining both model prediction and fairness concerns."
  - [section] "The augmented example has the same content factor as the input example but has different sensitive and style factors sampled from their associated prior distributions that encode a new synthetic domain."
- Break condition: If the synthetic domain generation does not adequately cover the space of possible fairness dependencies in target domains, the learned invariance may not generalize to unseen shifts.

### Mechanism 3
- Claim: The dual optimization framework with fairness constraints provides theoretical guarantees on the generalization performance of the learned classifier.
- Mechanism: The problem is reformulated as a constrained optimization where the classifier must minimize risk while maintaining fairness across transformed domains. Duality gap bounds provide guarantees that the empirical solution approaches the optimal solution as the number of samples increases.
- Core assumption: The parametric space of the classifier closely approximates the true invariant classifier set, and the empirical dual problem provides a good approximation of the original constrained problem.
- Evidence anchors:
  - [abstract] "We reformulate the problem to a novel constrained learning problem. We further establish duality gap bounds for the empirically parameterized dual of this problem"
  - [section] "With such approximation on the dual problem in Eq. (8), the duality gap between P⋆ and D⋆ξ,N,Es(γ1, γ2) can be explicitly bounded."
- Break condition: If the assumptions about Lipschitz continuity, VC-dimension bounds, or constraint satisfaction are violated, the theoretical guarantees may not hold and the empirical solution may deviate significantly from the optimal solution.

## Foundational Learning

- Concept: Domain Generalization
  - Why needed here: The paper addresses the challenge of learning classifiers that generalize to unseen target domains with different data distributions, specifically under covariate and dependence shifts.
  - Quick check question: What is the key difference between domain generalization and traditional supervised learning?

- Concept: Fairness-aware Learning
  - Why needed here: The paper incorporates fairness constraints to ensure the learned classifier maintains demographic parity across sensitive subgroups in all domains.
  - Quick check question: How is demographic parity formally defined in the context of this paper?

- Concept: Distribution Shift Types
  - Why needed here: The paper introduces a novel "dependence shift" type in addition to concept and covariate shifts, requiring understanding of how different distribution shifts affect model generalization and fairness.
  - Quick check question: What characterizes a "dependence shift" according to the paper's definition?

## Architecture Onboarding

- Component map:
  Transformation Model T (encoder E, decoder G, sensitive classifier h) -> Data Augmentation module (DATAAUG procedure) -> Classifier f with dual optimization framework

- Critical path:
  1. Train transformation model T on source domains to learn disentanglement
  2. Generate synthetic domains using T with random sensitive and style factors
  3. Train classifier f on augmented data using dual optimization with fairness constraints
  4. Evaluate on target domains for both accuracy and fairness metrics

- Design tradeoffs:
  - Tradeoff between reconstruction quality and disentanglement effectiveness in T
  - Balance between fairness constraint strength and classification accuracy
  - Choice of distance metric for enforcing invariance (KL-divergence used in experiments)

- Failure signatures:
  - Poor reconstruction quality in T indicates inadequate disentanglement
  - Degradation in accuracy when fairness constraints are enforced too strongly
  - Limited improvement in fairness metrics suggests synthetic domain generation may not cover target domain shifts

- First 3 experiments:
  1. Train T on source domains and visualize reconstruction quality and generated samples
  2. Evaluate baseline performance without data augmentation on held-out validation domains
  3. Test FDDG with different fairness constraint strengths (γ2 values) to observe tradeoff with accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the FDDG algorithm perform when the transformation model T fails to fully disentangle the content, sensitive, and style factors?
- Basis in paper: [explicit] The paper states that FDDG may not work well when data are generated with more than three factors or when factors are correlated.
- Why unresolved: The paper only mentions this as a limitation but does not provide experimental evidence or analysis of the algorithm's performance under such conditions.
- What evidence would resolve it: Experiments showing FDDG's performance on datasets with correlated factors or more than three factors, compared to datasets where factors are fully disentangled.

### Open Question 2
- Question: How does the FDDG algorithm handle situations where the content spaces do not completely overlap across domains?
- Basis in paper: [explicit] The paper mentions this as a limitation, stating that FDDG might not perform optimally when content spaces do not overlap across domains.
- Why unresolved: The paper suggests a potential solution but does not test or validate this approach.
- What evidence would resolve it: Experiments comparing FDDG's performance on datasets with overlapping and non-overlapping content spaces, along with the proposed solution of first augmenting data to minimize semantic gaps.

### Open Question 3
- Question: How sensitive is the FDDG algorithm to the choice of hyperparameters, particularly the learning rates and fairness constraints?
- Basis in paper: [explicit] The paper mentions hyperparameter selection but does not provide a comprehensive sensitivity analysis.
- Why unresolved: The paper only shows results for a specific set of hyperparameters without exploring how different choices affect performance.
- What evidence would resolve it: A sensitivity analysis showing FDDG's performance across a range of hyperparameter values for learning rates, fairness constraints, and other relevant parameters.

## Limitations
- Assumes data can be factorized into independent latent components (content, sensitive, style), which may not hold in all real-world scenarios
- Complexity of the transformation model and dual optimization framework may limit scalability to larger datasets
- Limited experimental validation of the method's effectiveness in handling more complex or subtle fairness dependencies

## Confidence
- **High**: The core mechanism of disentangling data into independent factors and generating synthetic domains for training fair invariant classifiers is well-supported by the theoretical framework and experimental results.
- **Medium**: The effectiveness of the method in handling dependence shifts is demonstrated, but the generality of this approach to more complex or subtle fairness dependencies remains to be fully validated.
- **Medium**: The theoretical guarantees provided by the dual optimization framework are promising, but their practical applicability depends on the assumptions about the parametric space and constraint satisfaction.

## Next Checks
1. **Ablation Study**: Conduct a thorough ablation study to isolate the contributions of the transformation model, data augmentation, and dual optimization framework to the overall performance.
2. **Robustness to Hyperparameters**: Evaluate the method's sensitivity to key hyperparameters, such as the weights of the fairness constraints, the learning rates, and the architecture of the transformation model.
3. **Scalability and Efficiency**: Assess the scalability and computational efficiency of the proposed method on larger datasets and more complex domain shifts.