---
ver: rpa2
title: Targeted Data Augmentation for bias mitigation
arxiv_id: '2308.11386'
source_url: https://arxiv.org/abs/2308.11386
tags:
- bias
- data
- biases
- augmentation
- skin
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces Targeted Data Augmentation (TDA), a novel
  method for bias mitigation in machine learning models. Instead of removing biases,
  TDA randomly inserts selected biases during training to force the model to learn
  to ignore them.
---

# Targeted Data Augmentation for bias mitigation

## Quick Facts
- arXiv ID: 2308.11386
- Source URL: https://arxiv.org/abs/2308.11386
- Reference count: 40
- Primary result: TDA reduces bias measures by 2-50x while maintaining minimal error rate increases across three architectures.

## Executive Summary
Targeted Data Augmentation (TDA) introduces a novel approach to bias mitigation in machine learning by randomly inserting selected biases during training rather than removing them. The method forces models to learn to ignore bias-correlated artifacts like frames, rulers, and glasses by exposing them to these features randomly during training. The authors manually annotated clinical skin lesion and face datasets to identify and measure biases, then applied Counterfactual Bias Insertion to quantify bias impact. TDA successfully mitigated frame and ruler biases in skin lesion classification and glasses bias in gender classification across DenseNet, EfficientNet, and ViT architectures, achieving substantial bias reduction while maintaining model accuracy.

## Method Summary
TDA works by first identifying dataset-level biases through manual annotation of artifacts (frames, rulers, glasses) in images. The method then creates augmentation policies that randomly insert these biases during training using probability parameter p. During training, the model experiences these bias-correlated features randomly across both classes, forcing it to learn that these features are irrelevant to the main classification task. Evaluation uses Counterfactual Bias Insertion (CBI) to measure how predictions change when biases are added, with successful bias mitigation showing reduced prediction flips when bias artifacts are introduced.

## Key Results
- TDA achieved 2-50x decrease in switched predictions across three different architectures (DenseNet, EfficientNet, ViT)
- Successfully mitigated frame and ruler biases in skin lesion classification
- Effectively reduced glasses bias in gender classification while maintaining minimal error rate increases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Random insertion of selected biases during training forces the model to learn to ignore them.
- Mechanism: By randomly adding bias-correlated artifacts (e.g., frames, rulers, glasses) to training images, the model experiences the bias as irrelevant, weakening spurious correlations.
- Core assumption: The model cannot rely on bias-correlated features if they are randomly present in both classes during training.
- Evidence anchors:
  - [abstract]: "Instead of removing biases, TDA randomly inserts selected biases during training to force the model to learn to ignore them."
  - [section]: "By randomly adding biases to the input during training, the model will start ignoring them as such features will seem irrelevant."
- Break condition: If the bias insertion probability is too low or too high, the model may either fail to unlearn the bias or lose focus on the main task.

### Mechanism 2
- Claim: Targeted Data Augmentation reduces switched predictions by breaking spurious correlations.
- Mechanism: The CBI method measures how often predictions flip when bias artifacts are inserted. TDA reduces these flips by making the model invariant to the bias.
- Core assumption: The model's predictions should not change when bias artifacts are added if it has learned to ignore them.
- Evidence anchors:
  - [section]: "By randomly introducing biases during training, we mitigated these biases and achieved a substantial decrease in bias measures, ranging from two-fold to more than 50-fold."
  - [corpus]: No direct corpus evidence found; this is derived from the paper's own experimental results.
- Break condition: If the model overfits to the augmented data, it may become too invariant and lose discriminative power.

### Mechanism 3
- Claim: TDA is model-agnostic and effective across different architectures.
- Mechanism: The method works for DenseNet, EfficientNet, and ViT because it targets dataset-level biases, not architecture-specific features.
- Core assumption: All CNNs and transformers trained on the same biased dataset will exhibit similar bias patterns that TDA can address.
- Evidence anchors:
  - [section]: "TDA substantially reduced bias measures... across three different architectures (DenseNet, EfficientNet, ViT)."
  - [corpus]: No direct corpus evidence found; this is derived from the paper's own experimental results.
- Break condition: If a new architecture has a fundamentally different way of processing spatial information, TDA may need adaptation.

## Foundational Learning

- Concept: Counterfactual Bias Insertion (CBI)
  - Why needed here: CBI quantifies how much a model's predictions change when bias artifacts are added, serving as the primary evaluation metric.
  - Quick check question: If a model's F1 score drops by 10% after inserting frames, what does that say about its bias robustness?

- Concept: Data augmentation as bias mitigation
  - Why needed here: Unlike traditional augmentation for generalization, here it's used to actively disrupt bias-correlated features.
  - Quick check question: How does randomly adding ruler marks to both benign and malignant skin lesions help the model ignore rulers?

- Concept: Manual bias annotation
  - Why needed here: Identifying which artifacts are bias-correlated requires human labeling to establish ground truth.
  - Quick check question: Why is it important to annotate both the presence and the class distribution of artifacts like frames and rulers?

## Architecture Onboarding

- Component map: Bias identification -> Augmentation policy design -> Training with augmentation -> Evaluation with CBI
- Critical path: Identify bias -> Design augmentation masks -> Integrate augmentation into training loop -> Evaluate with CBI
- Design tradeoffs: Higher augmentation probability reduces bias but may hurt main task accuracy; lower probability may not disrupt bias enough
- Failure signatures: Large Fdiff1 after TDA, high switched predictions in CBI, or degraded F1 on clean data
- First 3 experiments:
  1. Run CBI on clean model to establish baseline switched predictions and Fdiff1
  2. Train with TDA at p=0.25 and compare switched predictions and F1/Faug1
  3. Vary p across [0.0, 0.25, 0.5, 0.75, 1.0] and plot switched vs. F1 to find optimal trade-off

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective is Targeted Data Augmentation (TDA) compared to other bias mitigation methods like adversarial debiasing or fairness through blindness in real-world applications?
- Basis in paper: [explicit] The paper states that TDA achieves substantial bias reduction (2-50x decrease in switched predictions) while maintaining minimal error rate increases, but does not compare it to other methods.
- Why unresolved: The study focuses on TDA's effectiveness but lacks direct comparison with alternative bias mitigation techniques.
- What evidence would resolve it: Comparative studies showing TDA's performance against other bias mitigation methods in terms of bias reduction, accuracy, and computational efficiency.

### Open Question 2
- Question: What are the long-term effects of TDA on model robustness when applied to dynamic datasets with evolving biases?
- Basis in paper: [inferred] The paper demonstrates TDA's effectiveness on static datasets but does not address its adaptability to changing data distributions or emerging biases.
- Why unresolved: The study does not explore how TDA performs over time as data and biases evolve.
- What evidence would resolve it: Longitudinal studies tracking TDA's performance on datasets with temporal changes and emerging biases.

### Open Question 3
- Question: Can TDA be effectively applied to non-image data types such as tabular, text, or audio data, and what are the specific challenges?
- Basis in paper: [explicit] The paper mentions TDA's potential application to tabular data, NLP, and audio but does not provide detailed experiments or results for these data types.
- Why unresolved: The study primarily focuses on image data, leaving the effectiveness of TDA on other data types unexplored.
- What evidence would resolve it: Experimental results showing TDA's performance on diverse data types, including specific challenges and adaptations needed for each type.

## Limitations
- Manual bias annotation is labor-intensive and may not scale to larger datasets
- Limited evaluation to specific biases (frames, rulers, glasses) in two domains raises generalizability questions
- Hyperparameter tuning of augmentation probability p is critical but not fully explored

## Confidence
**High Confidence**: The claim that TDA reduces switched predictions and bias measures is supported by experimental results across three architectures (DenseNet, EfficientNet, ViT) with quantitative metrics (2-50x decrease in switched predictions).

**Medium Confidence**: The assertion that TDA is model-agnostic and works across different architectures is supported by testing three architectures, but the sample size is limited and the underlying mechanism for why this works across architectures is not fully explained.

**Medium Confidence**: The claim that TDA maintains minimal error rate increases is supported by reported F1 scores, but the tradeoff analysis between bias reduction and accuracy is limited to specific probability values (p=0.25) without comprehensive sensitivity analysis.

## Next Checks
1. **Cross-domain validation**: Apply TDA to a different domain (e.g., medical imaging beyond skin lesions or natural images beyond faces) with different bias types to test generalizability beyond the two studied datasets.

2. **Ablation study on augmentation probability**: Systematically vary the augmentation probability p across a wider range [0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0] and plot the tradeoff curve between switched predictions reduction and F1 score degradation to identify optimal operating points.

3. **Bias transfer analysis**: Test whether models trained with TDA on one dataset show improved robustness to previously unseen biases when evaluated with CBI on a held-out test set containing novel bias artifacts.