---
ver: rpa2
title: 'PARs: Predicate-based Association Rules for Efficient and Accurate Model-Agnostic
  Anomaly Explanation'
arxiv_id: '2312.10968'
source_url: https://arxiv.org/abs/2312.10968
tags:
- anomaly
- pars
- explanation
- data
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PARs, a novel model-agnostic anomaly explanation
  method using Predicate-based Association Rules. PARs provide intuitive explanations
  about which features of an anomaly instance are abnormal and why.
---

# PARs: Predicate-based Association Rules for Efficient and Accurate Model-Agnostic Anomaly Explanation

## Quick Facts
- arXiv ID: 2312.10968
- Source URL: https://arxiv.org/abs/2312.10968
- Authors: 
- Reference count: 40
- Key outcome: PARs achieve significantly higher computing efficiency (less than 1 second vs. 25+ seconds for anchors) and explanation accuracy (22% higher precision, 86% higher recall, 83% higher F1 score) than state-of-the-art model-agnostic methods for anomaly explanation tasks.

## Executive Summary
This paper introduces PARs, a novel model-agnostic anomaly explanation method using Predicate-based Association Rules. PARs provide intuitive explanations about which features of an anomaly instance are abnormal and why by leveraging association rule mining on training data. The approach efficiently constructs and finds precise PARs, achieving significantly higher computing efficiency and explanation accuracy compared to existing methods like Anchor, LIME, and SHAP. A user study shows that PARs are better understood and preferred by regular anomaly detection system users compared to these alternatives.

## Method Summary
The PARs method transforms normal data instances into sets of satisfied predicates, then mines association rules that capture normal behavior. When an anomaly is detected, the violated PARs precisely indicate which features are abnormal and why. For numeric features, cut-off values are proposed by learning decision tree models where numeric features predict categorical or other numeric features, prioritizing cut-off values with higher impurity decrease. The accuracy score for selecting top-k PARs combines support and confidence, with higher weight given to confidence to prioritize precision over coverage when explaining anomalies.

## Key Results
- Computing efficiency: Less than 1 second vs. 25+ seconds for anchors
- Explanation accuracy: 22% higher precision, 86% higher recall, 83% higher F1 score
- User preference: Better understood and preferred by regular anomaly detection system users compared to existing options

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PARs leverage association rule mining to efficiently identify abnormal features in anomalies.
- Mechanism: The approach transforms normal data instances into sets of satisfied predicates, then mines association rules (PARs) that capture normal behavior. When an anomaly is detected, the violated PARs precisely indicate which features are abnormal and why.
- Core assumption: Normal data instances follow predictable patterns that can be captured as association rules with sufficient support and confidence.
- Evidence anchors:
  - [abstract]: "We leverage association rule mining (Agrawal, Imieli ´nski, and Swami 1993) to learn Predicate-based Association Rules (PARs) which capture normal behaviors exhibited by training data."
  - [section]: "Specifically, we leverage association rule mining (Agrawal, Imieli ´nski, and Swami 1993) to learn Predicate-based Association Rules (PARs) which capture normal behaviors exhibited by training data."
- Break condition: If normal data lacks consistent patterns or the minimum support/confidence thresholds are set too high, few or no PARs will be found.

### Mechanism 2
- Claim: The dependency-based predicate generation for numeric features creates more accurate and interpretable rules.
- Mechanism: For numeric features, cut-off values are proposed by learning decision tree models where numeric features predict categorical or other numeric features. Cut-off values with higher impurity decrease are prioritized, ensuring predicates generated are more likely to contribute to high-quality PARs.
- Core assumption: Features with higher dependency (measured by information gain or variance reduction) will generate more informative predicates for explaining anomalies.
- Evidence anchors:
  - [section]: "We prefer cut-off values for a numeric feature which maximize the reduction of uncertainty in other features. In this way, predicates generated by such cut-off values could contribute to PARs with high likelihoods."
  - [section]: "Concretely, we employ a dependency-based approach which consists of following two steps to generate predicates for numeric features: 1) propose a set of candidate cut-off values by learning decision tree (DT) models on D, 2) select cut-off values with higher impurity decrease to generate predicates."
- Break condition: If feature dependencies are weak or the dataset is too small, the decision tree models may not identify meaningful cut-off values.

### Mechanism 3
- Claim: The scoring function prioritizes PARs with high confidence over support for anomaly explanation.
- Mechanism: The accuracy score for selecting top-k PARs is defined as (sup(A)-θ)/(1-θ) + λ(conf(A)-γ)/(1-γ), where λ is typically set to a value larger than one. This weighting reflects the preference for high precision (confidence) over high coverage (support) when explaining anomalies.
- Core assumption: For anomaly explanation, precision (correctly identifying abnormal features) is more important than recall (covering more anomalies).
- Evidence anchors:
  - [section]: "Regarding λ, the importance weight for confidence, we recommend to set it to a value larger than one. This is because we generally prioritize high precision over high coverage of data for explaining anomalies, thus the confidence of PARs is much more important than their support in terms of facilitating accurate anomaly explanation."
- Break condition: If λ is set too high, only very high-confidence PARs will be selected, potentially missing relevant explanations with slightly lower confidence.

## Foundational Learning

- Concept: Association Rule Mining
  - Why needed here: Forms the theoretical foundation for generating PARs from normal data patterns.
  - Quick check question: What are the two key measures (support and confidence) used to evaluate association rules, and how do they relate to PARs?

- Concept: Decision Tree Learning and Impurity Measures
  - Why needed here: Critical for the dependency-based predicate generation method for numeric features.
  - Quick check question: How do information gain (for classification) and variance reduction (for regression) help identify meaningful cut-off values for numeric features?

- Concept: Model-Agnostic Explainability
  - Why needed here: PARs are designed to work with any black-box anomaly detection model, requiring understanding of general explainability principles.
  - Quick check question: What is the difference between explaining why data is abnormal versus explaining why a model made a specific decision?

## Architecture Onboarding

- Component map: Data Preprocessing → Predicate Generation (categorical + numeric) → Association Rule Mining → PAR Storage → Inference (Find Top-k PARs)
- Dependencies: Predicate generation must complete before rule mining; rule mining must complete before inference
- Critical path: 1. Predicate Generation for all features (most time-consuming for numeric features) 2. Association Rule Mining using FPGrowth algorithm 3. Inference: Finding top-k PARs for an anomaly instance (O(1) after preprocessing)
- Design tradeoffs:
  - Support vs. Confidence thresholds: Higher thresholds yield more precise but fewer PARs
  - λ weight: Higher values prioritize precision over coverage
  - Maximum predicate length: Limited to 4 for interpretability vs. potential loss of information
- Failure signatures:
  - No PARs found for anomalies: Likely due to overly strict thresholds or insufficient normal data patterns
  - PARs with low accuracy scores: Indicates weak dependency between features or poor predicate generation
  - High inference time: Suggests inefficient rule storage or search implementation
- First 3 experiments:
  1. Run on a small synthetic dataset with known patterns to verify PAR generation and explanation quality
  2. Compare runtime and accuracy against baseline methods (Anchor, LIME, SHAP) on a benchmark dataset
  3. Test sensitivity to hyperparameter changes (θ, γ, λ) to understand robustness boundaries

## Open Questions the Paper Calls Out
- How does the performance of PARs change when applied to high-dimensional datasets (e.g., >100 features) compared to the datasets used in the experiments?
- How robust are PARs to different types of noise contamination in the training data, such as Gaussian noise or outliers, beyond the uniform noise contamination tested in the paper?
- How does the runtime efficiency of PARs compare to other model-agnostic anomaly explanation methods when applied to streaming data or online anomaly detection scenarios?

## Limitations
- Performance on real-world, noisy, or high-dimensional data remains unclear
- User study involved only 25 participants, which may not provide statistically robust evidence
- Method's scalability to very large datasets or streaming data scenarios is not evaluated

## Confidence
- **High Confidence**: Computing efficiency claims (PARs vs. anchors runtime comparison) - supported by clear quantitative evidence
- **Medium Confidence**: Explanation accuracy metrics (precision, recall, F1) - demonstrated on benchmark datasets but may not generalize to all anomaly detection contexts
- **Medium Confidence**: User preference results - limited sample size in user study raises questions about generalizability

## Next Checks
1. Test PARs on a real-world anomaly detection dataset with known ground truth to validate explanation accuracy beyond benchmark datasets
2. Conduct a larger-scale user study (minimum 100 participants) across different domain expertise levels to confirm interpretability claims
3. Evaluate scalability by testing PARs on high-dimensional datasets (>100 features) and measuring runtime performance degradation