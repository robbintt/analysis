---
ver: rpa2
title: An Analysis of Dialogue Repair in Voice Assistants
arxiv_id: '2311.03952'
source_url: https://arxiv.org/abs/2311.03952
tags:
- repair
- dialogue
- assistants
- language
- interactional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines how Google Assistant and Siri handle dialogue
  repair, particularly when users employ the interactional strategy "huh?" to initiate
  other-initiated repair. Task A tested whether the assistants could produce repair
  strategies when given unintelligible input, while Task B tested their responses
  to user-initiated "huh?".
---

# An Analysis of Dialogue Repair in Voice Assistants

## Quick Facts
- arXiv ID: 2311.03952
- Source URL: https://arxiv.org/abs/2311.03952
- Reference count: 13
- Voice assistants fail to use human-like repair strategies like "huh?" when handling unintelligible input

## Executive Summary
This study examines how Google Assistant and Siri handle dialogue repair, particularly when users employ the interactional strategy "huh?" to initiate other-initiated repair. Task A tested whether the assistants could produce repair strategies when given unintelligible input, while Task B tested their responses to user-initiated "huh?". Task C collected acceptability judgments from 100 native speakers (50 English, 50 Spanish) using a 5-point Likert scale. Results show both assistants failed to use "huh?" themselves and instead primarily employed strategy 2 (literal interpretation of unintelligible input). When responding to user "huh?", Google Assistant mostly used strategy 4 (unable to fulfill request), while strategy 5 (asking for appropriate information) was most acceptable to users. English and Spanish users showed similar preferences, though English speakers found strategy 6 (internet search) slightly more acceptable than Spanish speakers. The study reveals significant gaps between human and machine interactional language use, with assistants lacking the ability to replicate human-like repair strategies.

## Method Summary
The study employed three tasks to analyze dialogue repair in voice assistants. Task A involved users introducing unintelligible phrases within requests to elicit assistant repair strategies, while Task B had users ask "huh?" after assistant responses to test how assistants handle repair initiators. Task C collected acceptability judgments from 100 native speakers (50 English, 50 Spanish) using a 5-point Likert scale. The researchers manually categorized assistant responses according to 10 dialogue repair strategies and analyzed user preferences across both languages.

## Key Results
- Both Google Assistant and Siri failed to produce "huh?" when faced with unintelligible input, instead defaulting to literal interpretation
- Strategy 5 (asking for appropriate information) was most acceptable to users when assistants respond to user-initiated "huh?"
- English and Spanish users showed similar preferences for repair strategies, with minimal cross-linguistic differences
- Strategy 6 (internet search) was widely unacceptable to users, particularly Spanish speakers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Voice assistants default to literal interpretation when encountering unintelligible input rather than using human-like repair initiators like "huh?"
- Mechanism: When the speech recognition component fails to parse input, the dialogue manager falls back to strategy 2 (literal interpretation) by attempting to process the unintelligible portion as if it were valid input, then executing the corresponding action
- Core assumption: The dialogue manager's repair strategy selection prioritizes functional completion over conversational naturalness when faced with recognition uncertainty
- Evidence anchors:
  - [abstract] "Findings reveal several assistant-generated strategies but an inability to replicate human-like repair strategies such as 'huh?'"
  - [section] "Both assistants, in English and Spanish, failed to produce the specific utterance 'huh?' when faced with unintelligible input"
  - [corpus] Weak - corpus neighbors focus on broader dialogue repair but don't specifically address "huh?" usage patterns
- Break condition: If training data included sufficient examples of "huh?"-like repair patterns or if the dialogue manager incorporated explicit conversational repair templates, the system might generate more human-like initiators

### Mechanism 2
- Claim: User acceptability of repair strategies correlates with their alignment to human conversational repair patterns rather than functional success
- Mechanism: Users evaluate repair strategies based on whether they follow the conversational repair sequence (initiation → acknowledgment → solution) rather than whether the task is ultimately completed
- Core assumption: Human users apply HHI interaction norms when judging HMI, expecting turn-taking and acknowledgment before solution
- Evidence anchors:
  - [abstract] "Participants differed slightly in their judgements of other strategies, particularly the widely unacceptable strategy 6 which searches the internet for information to fulfill a request"
  - [section] "users will strongly favor strategies that prioritize trying to fulfill requests at any cost, rather than strategies that attempt to sidestep or outright ignore the misunderstanding"
  - [corpus] Weak - corpus doesn't contain user acceptability studies of repair strategies
- Break condition: If users prioritized task completion over conversational flow, or if they were explicitly primed to evaluate functional rather than interactional success

### Mechanism 3
- Claim: Language-specific differences in repair strategy acceptability are minimal between English and Spanish speakers
- Mechanism: Despite cultural and linguistic differences, both language groups apply similar criteria when evaluating repair strategies, primarily focusing on acknowledgment and solution attempts
- Core assumption: The fundamental human expectations for conversational repair transcend language boundaries
- Evidence anchors:
  - [abstract] "English and Spanish user acceptability surveys show differences in users' repair strategy preferences and assistant usage, with both similarities and disparities among the two surveyed languages"
  - [section] "English speakers tended to perceive this strategy as slightly more acceptable compared to Spanish participants (who universally judged it as completely unacceptable)"
  - [corpus] Weak - corpus contains related work on multicultural voice interactions but not specific comparative acceptability studies
- Break condition: If cultural differences in conversational norms were more pronounced, or if one language group had significantly different expectations for machine interaction

## Foundational Learning

- Concept: Interactional language and repair initiation
  - Why needed here: Understanding how humans use "huh?" and other repair initiators is essential for evaluating why voice assistants fail to replicate these patterns
  - Quick check question: What are the three main types of repair initiators in human conversation, and how do they differ in their conversational function?

- Concept: Dialogue state tracking and strategy selection
  - Why needed here: The dialogue manager's decision-making process determines which repair strategy to employ when faced with recognition uncertainty
  - Quick check question: How does a dialogue manager typically determine when to switch from comprehension mode to repair mode during a conversation?

- Concept: Cross-linguistic acceptability judgments
  - Why needed here: Evaluating how speakers of different languages assess the same repair strategies reveals whether human-machine interaction norms are universal
  - Quick check question: What factors might cause different language groups to judge the same voice assistant behavior differently?

## Architecture Onboarding

- Component map: ASR → NLU → Dialogue Manager → TTS/Fulfillment
  - ASR handles speech recognition and confidence scoring
  - NLU parses recognized text into semantic frames
  - Dialogue Manager selects repair strategies based on confidence and context
  - TTS/Fulfillment delivers the response and executes actions

- Critical path: User query → ASR recognition → NLU parsing → Dialogue Manager decision → TTS response
  - Recognition uncertainty triggers repair mode
  - Strategy selection depends on confidence thresholds and historical context

- Design tradeoffs: Functional completion vs. conversational naturalness
  - Strategy 2 (literal interpretation) prioritizes task completion but sacrifices naturalness
  - Strategy 5 (asking for clarification) maintains conversational flow but may delay resolution

- Failure signatures:
  - Overuse of strategy 2 indicates poor confidence threshold calibration
  - Defaulting to strategy 4 suggests the system gives up too easily on uncertain inputs
  - Inconsistent strategy selection across similar contexts points to missing contextual features

- First 3 experiments:
  1. Test confidence threshold effects: Vary ASR confidence thresholds and measure strategy distribution and user acceptability
  2. Evaluate conversational template injection: Implement explicit "huh?" and similar repair initiators in the dialogue manager and measure user responses
  3. Compare cross-cultural strategy preferences: Run the acceptability survey with additional language groups to validate minimal language differences assumption

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do Google Assistant and Siri handle dialogue repair when the user is initiating other-initiated repair by using "huh?"?
- Basis in paper: [explicit] This is explicitly stated as RQ1 in the paper's research questions section.
- Why unresolved: While the paper presents results showing assistants used fewer strategies and primarily strategy 4 (unable to fulfill requests), the underlying mechanisms of how the dialogue managers process and respond to "huh?" remain unclear. The paper doesn't explore the technical implementation or decision-making processes.
- What evidence would resolve it: Detailed analysis of the dialogue manager's decision trees or machine learning models that determine response strategies when "huh?" is detected would provide insight into the technical processing.

### Open Question 2
- Question: Can virtual assistants be trained to produce and effectively use the interactional repair strategy "huh?" like humans do?
- Basis in paper: [explicit] This is explicitly stated as RQ2 in the paper's research questions section.
- Why unresolved: The paper demonstrates that assistants failed to produce "huh?" but doesn't explore whether this capability could be developed through training or model adjustments. The technical feasibility and implementation challenges are not discussed.
- What evidence would resolve it: Experimental results showing whether assistants can be trained to recognize when "huh?" is appropriate and to produce it naturally, along with user acceptability testing of these modified assistants.

### Open Question 3
- Question: What are the cross-linguistic differences in how Spanish-speaking users prefer dialogue repair strategies compared to English speakers?
- Basis in paper: [explicit] The paper mentions differences in user acceptability ratings between English and Spanish speakers, particularly noting that Spanish speakers universally judged strategy 6 as completely unacceptable while English speakers found it slightly more acceptable.
- Why unresolved: While the paper presents statistical differences in acceptability ratings, it doesn't explore the underlying linguistic, cultural, or pragmatic reasons for these differences. The paper doesn't investigate why these preferences exist.
- What evidence would resolve it: Qualitative analysis of user feedback explaining their reasoning, comparative linguistic studies of repair strategies in Spanish versus English conversation, and cultural analysis of user expectations for voice assistant interactions.

## Limitations

- Small sample size of 100 participants (50 per language) limits generalizability of findings
- Controlled nature of interaction tasks may not reflect natural user behavior in real-world scenarios
- Study doesn't account for individual differences in user expectations or prior experience with voice assistants
- Cross-linguistic comparison may not capture deeper cultural variations in conversational repair expectations

## Confidence

- High confidence: The finding that both assistants failed to use "huh?" as a repair initiator when given unintelligible input
- Medium confidence: The claim that users prefer strategy 5 (asking for appropriate information) over other repair strategies
- Low confidence: The assertion that language-specific differences in repair strategy acceptability are minimal

## Next Checks

1. Conduct a larger-scale study with 300+ participants across 3+ language groups to validate the cross-linguistic acceptability patterns and test whether the minimal language differences finding holds with greater statistical power.

2. Implement the proposed conversational repair templates (including "huh?"-like initiators) in a test version of a voice assistant and run A/B testing to measure whether these human-like repair strategies improve user satisfaction compared to current approaches.

3. Collect real-world conversational data from actual voice assistant usage (rather than controlled tasks) to compare how assistants handle repair in natural versus experimental contexts, examining whether the documented strategy preferences hold in authentic interaction scenarios.