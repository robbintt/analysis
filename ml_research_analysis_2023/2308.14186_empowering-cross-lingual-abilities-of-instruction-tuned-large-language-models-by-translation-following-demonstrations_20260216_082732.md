---
ver: rpa2
title: Empowering Cross-lingual Abilities of Instruction-tuned Large Language Models
  by Translation-following demonstrations
arxiv_id: '2308.14186'
source_url: https://arxiv.org/abs/2308.14186
tags:
- language
- data
- demonstrations
- cross-lingual
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of cross-lingual abilities in instruction-tuned
  large language models (It-LLMs), which are often unbalanced towards English due
  to pre-training data imbalance. The core method idea is CrossAlpaca, an approach
  that improves semantic alignment between English and other languages by using both
  Instruction-following and Translation-following demonstrations during instruction-tuning.
---

# Empowering Cross-lingual Abilities of Instruction-tuned Large Language Models by Translation-following demonstrations

## Quick Facts
- **arXiv ID**: 2308.14186
- **Source URL**: https://arxiv.org/abs/2308.14186
- **Reference count**: 13
- **Primary result**: CrossAlpaca improves cross-lingual instruction-following by 30 points on MLQA, 34 on XQUAD, 8 on MMLU, and 4 on BBH compared to monolingual instruction tuning

## Executive Summary
CrossAlpaca addresses the cross-lingual imbalance in instruction-tuned large language models by incorporating Translation-following demonstrations alongside traditional Instruction-following data during fine-tuning. The approach significantly improves semantic alignment between English and other languages, achieving substantial performance gains on cross-lingual benchmarks while maintaining logical-mathematical capabilities. By interleaving translation pairs with instruction demonstrations, the model learns cross-lingual semantic equivalences that enable better instruction-following in non-English languages.

## Method Summary
The method involves fine-tuning LLaMA-7B with LoRA adapters using a combined dataset of Instruction-following demonstrations (based on Stanford Alpaca) and Translation-following demonstrations from the news_commentary corpus. For each target language (Chinese, Arabic, Italian, Spanish, German), 20k translation demonstrations are used (10k English-to-target and 10k target-to-English). The model is trained for one epoch with batch size 128, then evaluated on language-specific versions of MLQA, XQUAD, MMLU, and BBH benchmarks.

## Key Results
- CrossAlpaca achieves 30 average points improvement on MLQA cross-lingual QA benchmark
- CrossAlpaca achieves 34 average points improvement on XQUAD cross-lingual QA benchmark
- CrossAlpaca maintains strong performance on MMLU (8 points improvement) and BBH (4 points improvement) multi-task benchmarks
- English→foreign language (en-x) translation demonstrations provide stronger cross-lingual benefits than foreign→English (x-en) demonstrations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Semantic alignment through translation-following demonstrations improves cross-lingual instruction following.
- **Mechanism**: Instruction-tuned LLMs receive paired translation demonstrations (English→X and X→English) alongside instruction demonstrations, enabling the model to learn semantic equivalences between languages during fine-tuning.
- **Core assumption**: The model can effectively learn cross-lingual semantic alignment from sentence-level translation pairs when interleaved with instruction-following data.
- **Evidence anchors**: [abstract]: "Translation-following demonstrations to improve semantic alignment between languages"; [section]: "we propose CrossAlpaca, an Instruction-tuned LLM (It-LLM) empowered with a semantic alignment between English and other languages"
- **Break condition**: If the translation demonstrations are not semantically aligned or contain noise, the alignment effect may degrade or harm performance.

### Mechanism 2
- **Claim**: Direction of translation demonstrations matters for downstream cross-lingual performance.
- **Mechanism**: Demonstrations in English→foreign language direction (en-x) provide stronger cross-lingual benefit than foreign→English direction (x-en), possibly because English is the dominant pre-training language.
- **Core assumption**: The model leverages English as a semantic anchor, making English→foreign translations more effective for learning cross-lingual mappings.
- **Evidence anchors**: [section]: "demonstrations with English-foreign direction (en-x) better impact downstream models. Conversely, foreign-English (x-en) demonstrations perform better than baselines but underperform demonstrations in the opposite direction"; [abstract]: "CrossAlpaca significantly outperforms It-LLMs tuned only on monolingual data"
- **Break condition**: If the model's pre-training data distribution changes significantly, the directional advantage may reverse or equalize.

### Mechanism 3
- **Claim**: Increasing quantity of translation-following demonstrations scales cross-lingual performance improvements.
- **Mechanism**: More translation pairs provide richer semantic alignment signals, allowing the model to learn more robust cross-lingual representations during instruction tuning.
- **Core assumption**: The relationship between translation demonstration quantity and performance is approximately linear within the tested range.
- **Evidence anchors**: [section]: "x-CrossAlpacas achieve higher accuracy when more demonstrations are used, revealing the benefits of cross-lingual alignment"; [abstract]: "CrossAlpaca significantly outperforms It-LLMs tuned on monolingual data, with improvements of 30 average points on MLQA, 34 on XQUAD"
- **Break condition**: Beyond a certain point, additional translation data may yield diminishing returns or overfit to translation patterns rather than general cross-lingual understanding.

## Foundational Learning

- **Concept**: Semantic alignment between languages
  - Why needed here: The core innovation relies on building semantic equivalence representations across languages, which is essential for cross-lingual instruction following
  - Quick check question: Can you explain how semantic alignment differs from simple translation in the context of instruction-tuned models?

- **Concept**: Instruction-following paradigm in LLMs
  - Why needed here: CrossAlpaca builds upon instruction-tuning methodology, requiring understanding of how instruction-response pairs shape model behavior
  - Quick check question: What is the key difference between pre-training and instruction-tuning in terms of objective functions and expected model capabilities?

- **Concept**: Low-rank adaptation (LoRA) for efficient fine-tuning
  - Why needed here: The implementation uses LoRA to efficiently fine-tune LLaMA-7B, which is critical for practical deployment and experimentation
  - Quick check question: How does LoRA achieve parameter efficiency compared to full fine-tuning, and what are the trade-offs?

## Architecture Onboarding

- **Component map**: LLaMA-7B (base model) -> LoRA adapters (fine-tuning) -> Combined demonstration dataset (instruction + translation) -> Evaluation benchmarks (MLQA, XQUAD, MMLU, BBH)

- **Critical path**: 
  1. Load base LLaMA-7B with LoRA adapters
  2. Prepare combined demonstration dataset (instruction + translation pairs)
  3. Fine-tune with single epoch, batch size 128
  4. Evaluate on language-specific benchmark subsets
  5. Analyze performance gaps and alignment effects

- **Design tradeoffs**:
  - Translation demonstration quality vs. quantity: Higher quality pairs may yield better alignment but are more expensive to obtain
  - Model capacity vs. computational cost: Larger models may learn better alignment but require more resources
  - Direction balance: Equal distribution of en-x and x-en pairs vs. prioritizing English-dominant direction

- **Failure signatures**:
  - Performance degradation on multi-task benchmarks (MMLU, BBH) suggests over-specialization to translation patterns
  - Inconsistent cross-lingual gains across languages indicates pre-training data imbalance effects
  - Diminishing returns with increased translation data suggests reaching capacity limits

- **First 3 experiments**:
  1. Ablation study: Compare CrossAlpaca variants with only instruction-following vs. combined demonstrations on a single language pair
  2. Direction analysis: Train separate models with only en-x vs. only x-en translation demonstrations to quantify directional impact
  3. Scaling study: Vary translation demonstration quantity (5k, 10k, 20k) to identify optimal trade-off between performance and training cost

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do cross-lingual abilities scale with model size and pre-training data?
- Basis in paper: [explicit] The authors mention future work will include "increasing the number of parameters in LLaMA and including additional backbone models" and "evaluate the impact on low-resource languages."
- Why unresolved: The current study only used LLaMA-7B and focused on languages with some available data. It's unclear if larger models or different pre-training strategies would yield better cross-lingual alignment.
- What evidence would resolve it: Comparative experiments using different model sizes (e.g., LLaMA-13B, LLaMA-33B) and pre-training data distributions (e.g., more balanced multilingual corpora) to measure cross-lingual performance gains.

### Open Question 2
- Question: What is the optimal balance between Instruction-following and Translation-following demonstrations?
- Basis in paper: [explicit] The authors conducted ablation studies varying the amount of Translation-following demonstrations but didn't explore the trade-off with Instruction-following data.
- Why unresolved: While adding Translation-following data improved performance, the study didn't systematically explore how much Instruction-following data is needed versus Translation-following data for optimal cross-lingual alignment.
- What evidence would resolve it: Controlled experiments varying the ratio of Instruction-following to Translation-following demonstrations while keeping total training data constant, measuring cross-lingual performance.

### Open Question 3
- Question: How does CrossAlpaca perform on specialized translation tasks versus general cross-lingual understanding?
- Basis in paper: [explicit] The authors mention future plans to "analyze the translation capabilities of general It-LLMs and those enhanced with translation tasks, including some specialized translation tasks among our evaluation benchmarks."
- Why unresolved: The current evaluation focused on QA tasks, which may not fully capture the nuances of translation quality or specialized domain translation.
- What evidence would resolve it: Evaluation on specialized translation benchmarks (e.g., WMT, TED Talks) and domain-specific translation tasks (e.g., legal, medical) to measure translation quality and cross-lingual understanding.

## Limitations
- **Data Quality Dependency**: The method's effectiveness critically depends on the quality and semantic alignment of translation demonstrations, which wasn't validated in the study.
- **Generalization Boundaries**: Evaluation focused on five specific languages and four benchmarks, leaving effectiveness for other language families and task domains unknown.
- **Pre-training Data Imbalance Effects**: The English-centric approach may widen gaps for languages with minimal pre-training representation rather than helping low-resource languages.

## Confidence
**High Confidence**: The observation that CrossAlpaca improves cross-lingual performance compared to monolingual instruction tuning is well-supported by benchmark results with substantial performance gains.

**Medium Confidence**: The claim about directional advantages (en-x vs x-en) is supported by results but lacks ablation studies isolating the directional effect, and alternative explanations could account for the observed pattern.

**Medium Confidence**: The scalability claim (more demonstrations yield better performance) is observed but only tested within a limited range, and the relationship could be non-linear with diminishing returns.

## Next Checks
**Validation Check 1**: Conduct a quality analysis of the translation demonstrations by sampling and human evaluation. Select 100 translation pairs from each language direction and have bilingual experts rate semantic alignment quality. Compare performance correlation between human alignment scores and model cross-lingual accuracy to establish whether demonstration quality predicts downstream performance.

**Validation Check 2**: Perform a controlled ablation study testing the directional hypothesis by training three separate models: one with only en-x translations, one with only x-en translations, and one with balanced pairs. Evaluate all three on a diverse set of languages including ones with significantly different syntactic structures from English (e.g., Japanese, Turkish) to test whether the directional advantage generalizes across language families.

**Validation Check 3**: Test the method's scalability limits by training models with 5k, 20k, 50k, and 100k translation demonstrations per language. Plot performance curves for each language to identify whether improvements continue linearly or plateau. Additionally, evaluate whether the MMLU and BBH performance degrades with increased translation data, indicating potential over-specialization.