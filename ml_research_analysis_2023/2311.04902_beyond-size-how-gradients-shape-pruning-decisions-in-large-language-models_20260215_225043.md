---
ver: rpa2
title: 'Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models'
arxiv_id: '2311.04902'
source_url: https://arxiv.org/abs/2311.04902
tags:
- pruning
- weights
- weight
- gblm-pruner
- sparsegpt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents GBLM-Pruner, a novel gradient-based pruning
  method for large language models (LLMs). Unlike prior approaches that focus solely
  on weights or weights combined with activations, GBLM-Pruner leverages gradients
  derived from pretrained LLMs to determine the importance of weights for pruning.
---

# Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models

## Quick Facts
- **arXiv ID**: 2311.04902
- **Source URL**: https://arxiv.org/abs/2311.04902
- **Reference count**: 17
- **One-line result**: GBLM-Pruner achieves state-of-the-art pruning performance on LLaMA models using gradient-based importance scores, outperforming magnitude pruning, SparseGPT, and Wanda.

## Executive Summary
This paper introduces GBLM-Pruner, a novel gradient-based pruning method for large language models that leverages gradients from pretrained models to determine parameter importance. Unlike prior approaches that rely solely on weight magnitudes or activations, GBLM-Pruner combines both with gradient information derived from calibration samples. The method operates training-free, requiring no retraining or weight updates after pruning. Extensive experiments on LLaMA-1 and LLaMA-2 models demonstrate substantial improvements in perplexity and zero-shot task performance compared to competitive baselines.

## Method Summary
GBLM-Pruner computes pruning importance scores using the first-order Taylor expansion term, combining weight magnitude with normalized gradient and activation norms across calibration samples. The method uses 128 calibration sequences from C4 to compute gradients, aggregates them using ℓ1 or ℓ2 norms, and applies a per-output-column pruning mask to zero out the least important weights. The final metric is |W| · (∥G∥p + λ∥X∥2), where λ is a scaling factor (typically 100) balancing gradient and activation contributions. This approach achieves significant sparsity (up to 50%) without requiring subsequent fine-tuning.

## Key Results
- GBLM-Pruner with ℓ1 gradient norm outperforms magnitude pruning, SparseGPT, and Wanda on perplexity and zero-shot tasks across LLaMA-2 variants (7B, 13B, 30B, 70B)
- The method reveals structural patterns post-pruning that mirror the geometric interdependence inherent in LLM parameter structures
- Per-output-column pruning granularity yields the most favorable results compared to layer-wise or input-wise approaches
- Performance is robust across different sparsity levels (10%-50%) with minimal degradation in downstream task accuracy

## Why This Works (Mechanism)

### Mechanism 1
Gradients provide complementary importance information to weights and activations for LLM pruning. GBLM-Pruner computes a pruning score by multiplying the magnitude of each weight with the ℓ1 or ℓ2 norm of gradients across calibration samples. This captures how much the loss changes with respect to each weight, which is not fully represented by magnitude pruning or activation-based methods. The core assumption is that gradients of a pretrained LLM still contain useful information about parameter importance, even after training has converged. If gradients at convergence are truly negligible (vanish to machine precision), then the gradient term contributes nothing beyond noise.

### Mechanism 2
Normalizing gradients across samples stabilizes the pruning metric. Instead of raw gradient accumulation, GBLM-Pruner aggregates gradients using ℓ1 or ℓ2 norms, which smooths out sample-specific fluctuations and produces more consistent importance scores. The core assumption is that the distribution of gradients across calibration samples is representative of general importance patterns. If the calibration set is too small or unrepresentative, the normalized gradients may not reflect true importance.

### Mechanism 3
Combining gradients with activations improves pruning accuracy beyond using either alone. The final pruning score is |W| · (∥X∥2 + λ·∥G∥p), where both input activation norm and gradient norm contribute. The scaling factor λ balances their magnitudes. The core assumption is that gradients and activations capture orthogonal aspects of parameter importance. If either gradients or activations are saturated or uninformative for certain layers, the combined metric may not outperform the stronger individual component.

## Foundational Learning

- **Concept**: Taylor expansion for parameter importance
  - Why needed here: GBLM-Pruner is derived from the first-order Taylor approximation of loss change when removing a weight, which justifies using gradients in the pruning metric.
  - Quick check question: In the Taylor expansion δE ≈ g⊤·δw + ½δw⊤·H·δw, which term represents the gradient contribution to importance?

- **Concept**: Hessian diagonal approximation
  - Why needed here: The method simplifies Hessian computation by assuming diagonal structure (H ≈ 2·diag(∥xⱼ∥²)), making the metric tractable for large models.
  - Quick check question: Why does focusing on diagonal Hessian elements simplify the pruning metric?

- **Concept**: ℓ1 vs ℓ2 norm aggregation
  - Why needed here: GBLM-Pruner tests both norms for gradient aggregation; ℓ1 yields better perplexity in experiments, likely due to robustness to outliers.
  - Quick check question: In what scenario would ℓ1 norm aggregation of gradients be preferable to ℓ2?

## Architecture Onboarding

- **Component map**: Calibration data loader → gradient computation → gradient normalization → pruning metric calculation → mask generation → sparse weight zeroing

- **Critical path**:
  1. Sample calibration data (128 sequences, 2048 tokens)
  2. Compute gradients on language modeling objective
  3. Normalize gradients (ℓ1 or ℓ2 norm across samples)
  4. Compute pruning metric |W|·(|X| + λ|G|)
  5. Generate mask by selecting smallest p% weights per output channel
  6. Apply mask to zero weights

- **Design tradeoffs**:
  - Training-free vs retraining: avoids computational cost but may be less accurate than fine-tuned pruning
  - ℓ1 vs ℓ2 gradient norm: ℓ1 gives better perplexity but ℓ2 may be more stable in some cases
  - Per-output vs global pruning: per-output aligns with layer structure but may miss global patterns

- **Failure signatures**:
  - High perplexity after pruning → gradients not informative or λ poorly calibrated
  - Noisy pruning masks → insufficient calibration samples or unstable gradient computation
  - No improvement over magnitude pruning → gradients too small or activations dominate completely

- **First 3 experiments**:
  1. Run GBLM-Pruner with ℓ1 norm on LLaMA-2-7B using 128 calibration samples; verify perplexity improves over magnitude pruning
  2. Compare ℓ1 vs ℓ2 gradient norm impact on perplexity; tune λ accordingly
  3. Test per-output vs layer-wise pruning granularity on a small model to observe structural patterns

## Open Questions the Paper Calls Out

### Open Question 1
How do different gradient aggregation methods (gradient accumulation, ℓ1 norm, ℓ2 norm) affect the pruning performance of GBLM-Pruner? The paper explicitly mentions that gradient accumulation yields the least favorable results compared to ℓ1 and ℓ2 norm-based gradient aggregation methods, but does not provide a detailed explanation of why gradient accumulation performs worse than the other methods. Further investigation into the properties of gradient accumulation versus norm-based aggregation could provide insights into the observed performance differences.

### Open Question 2
What is the impact of the scaling factor λ on the pruning performance of GBLM-Pruner, and is there an optimal value for different model sizes and sparsity levels? The paper conducts an ablation study on the scaling factor λ and finds that a value of 100 yields the best perplexity for LLaMA-2-7B, but it does not explore the optimal values for other model sizes or sparsity levels. The optimal scaling factor may vary depending on the model architecture, size, and desired sparsity level.

### Open Question 3
How does the choice of pruning granularity (layer-wise, input-wise, output-wise) affect the performance of GBLM-Pruner, and is there an optimal granularity for different types of models? The paper experiments with different pruning granularities and finds that the (output, 1) configuration yields the most favorable results for the tested models, but it does not explore the reasons behind this or the optimal granularity for other model types. The optimal pruning granularity may depend on the model architecture and the specific characteristics of the data it processes.

## Limitations

- The method's effectiveness critically depends on the assumption that gradients from pretrained LLMs remain informative for pruning decisions, yet this is not empirically validated across diverse model architectures or training regimes.
- The choice of ℓ1 vs ℓ2 gradient norm aggregation shows significant performance differences, suggesting the aggregation method may be as important as the gradient signal itself.
- The paper lacks ablations on calibration dataset size and composition, leaving unclear whether the reported performance is robust to data quality variations.

## Confidence

- **High confidence in**: The mathematical derivation of the pruning metric from Taylor expansion and the basic implementation of the per-output-column pruning strategy.
- **Medium confidence in**: The claim that gradients provide complementary importance information beyond weights and activations, as this requires careful ablation studies to verify.
- **Low confidence in**: The generalizability of results across different model families, training objectives, and calibration datasets, given the limited experimental scope.

## Next Checks

1. Conduct ablation studies varying calibration dataset size (10, 50, 100, 128 samples) to determine minimum effective size and robustness to data quality.

2. Compare GBLM-Pruner performance against gradient-based pruning methods from other domains (vision transformers, MLPs) to test cross-domain applicability.

3. Analyze the relationship between gradient magnitude distributions and weight importance rankings to quantify how much unique information gradients provide beyond magnitude-based pruning.