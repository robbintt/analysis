---
ver: rpa2
title: 'From Artificially Real to Real: Leveraging Pseudo Data from Large Language
  Models for Low-Resource Molecule Discovery'
arxiv_id: '2309.05203'
source_url: https://arxiv.org/abs/2309.05203
tags:
- data
- pseudo
- molecule
- real
- smiles
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the low-resource challenge in cross-modal
  molecule discovery by leveraging artificially-real data generated by Large Language
  Models (LLMs). The authors introduce a retrieval-based prompting strategy to construct
  high-quality pseudo molecule-description pairs, creating the first artificially-real
  dataset, PseudoMD-1M, with 1 million pairs.
---

# From Artificially Real to Real: Leveraging Pseudo Data from Large Language Models for Low-Resource Molecule Discovery

## Quick Facts
- arXiv ID: 2309.05203
- Source URL: https://arxiv.org/abs/2309.05203
- Authors: 
- Reference count: 40
- Key outcome: Introduces retrieval-based LLM prompting to create PseudoMD-1M, achieving state-of-the-art cross-modal molecule discovery with domain adaptation outperforming data augmentation across multiple datasets.

## Executive Summary
This paper addresses the challenge of low-resource cross-modal molecule discovery by generating high-quality pseudo data using Large Language Models with a retrieval-based prompting strategy. The authors create PseudoMD-1M, a dataset of 1 million artificially-real molecule-description pairs, and propose two methods for utilizing this data: domain adaptation through pre-training and data augmentation during fine-tuning. Their approach, particularly the domain adaptation variant (Ada-T5), outperforms all existing methods while requiring smaller models, less data, and lower training costs. The method demonstrates sustained performance improvements with increasing pseudo data volume and proves effective on new datasets like DrugBank-23.

## Method Summary
The method involves two main components: generating pseudo molecule-description pairs using retrieval-based LLM prompting, and applying these pairs through either domain adaptation or data augmentation strategies. For pseudo data generation, the approach retrieves similar molecules based on structural fingerprints, then uses one as a weighted example in few-shot prompts to guide the LLM in creating descriptions that better match real molecule-caption relationships. The domain adaptation approach (Ada-T5) pre-trains the model on pseudo data before fine-tuning on real data, while the data augmentation approach (Aug-T5) mixes pseudo and real data during fine-tuning. The system uses a T5-based transformer architecture for both tasks.

## Key Results
- Ada-T5 outperforms all prior methods across ChEBI-20, PCdes, and DrugBank-23 datasets
- Domain adaptation achieves superior results with smaller model sizes and reduced training costs
- Ada-T5 performance scales positively with increasing pseudo data volume (1M → optimal), while Aug-T5 performance degrades after 4k samples
- The approach demonstrates robust generalization when applied to new datasets like DrugBank-23

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Retrieval-based prompting improves pseudo data quality by using similar real molecules as few-shot examples
- Mechanism: By retrieving top-k similar molecules based on Morgan fingerprints and Tanimato similarity, then using one as a weighted example in the prompt, the LLM generates descriptions that are more aligned with real molecule-caption relationships
- Core assumption: Molecules with similar structural fingerprints tend to have similar properties and descriptive patterns
- Evidence anchors:
  - [section] "We retrieve the descriptions of annotated molecules that resemble the unlabeled molecule, using them as the few-shot instance during prompting"
  - [figure 3] "few-shot prompting approach (in blue) yields higher-quality data, more closely resembling real data than without"

### Mechanism 2
- Claim: Domain adaptation with pseudo data is more effective than data augmentation for low-resource molecule discovery
- Mechanism: Pre-training on pseudo data as a domain adaptation stage allows the model to learn SMILES representation and cross-modal relationships before fine-tuning on real data, avoiding the noise of mixing pseudo and real data during fine-tuning
- Core assumption: The model can learn generalizable cross-modal patterns from pseudo data that transfer to real data during fine-tuning
- Evidence anchors:
  - [section] "using pseudo data for domain adaptation outperforms all prior methods, while also requiring a smaller model scale, reduced data size and lower training cost"
  - [table 3] Ada-T5 outperforms all previous methods with smaller model and less pre-training data

### Mechanism 3
- Claim: Pseudo data scale positively impacts model performance when used for domain adaptation but not for data augmentation
- Mechanism: As pseudo data volume increases during domain adaptation pre-training, the model learns more comprehensive cross-modal patterns without being overwhelmed by noise, while in data augmentation, increasing pseudo data volume introduces too much noise relative to real data
- Core assumption: The model can effectively learn from larger volumes of pseudo data during pre-training without degradation
- Evidence anchors:
  - [figure 5] "Ada-T5 thrives with the increasing amount of pseudo data, evidenced by the growth of overall metrics"
  - [figure 5] "The performance of Aug-T5 begins to decline when the number of pseudo data samples reaches 4k"

## Foundational Learning

- Concept: Cross-modal learning between molecular structures and natural language descriptions
  - Why needed here: The paper addresses translating between SMILES strings and descriptive captions, requiring understanding of both modalities
  - Quick check question: How does the model handle the different nature of molecular structure data (symbolic sequences) versus natural language (semantic sequences)?

- Concept: Few-shot learning with large language models
  - Why needed here: The retrieval-based prompting strategy relies on providing examples to guide the LLM in generating high-quality molecule descriptions
  - Quick check question: What role does the similarity-weighted selection of few-shot examples play in the quality of generated descriptions?

- Concept: Domain adaptation in machine learning
  - Why needed here: The paper uses pseudo data for domain adaptation to bridge the gap between general language models and specialized molecule-language tasks
  - Quick check question: How does pre-training on pseudo data help the model better understand SMILES notation compared to direct fine-tuning?

## Architecture Onboarding

- Component map: Retrieval module → Prompt generation module → Pseudo data creation → Domain adaptation/augmentation module → Fine-tuning module
- Critical path: 1) Retrieve similar molecules → 2) Generate weighted few-shot prompt → 3) Generate pseudo description → 4) Pre-train or augment with pseudo data → 5) Fine-tune on real data
- Design tradeoffs: Domain adaptation requires additional pre-training but achieves better performance with less data, while data augmentation is simpler but less effective and sensitive to pseudo data quality
- Failure signatures: Poor retrieval similarity scores, low quality pseudo descriptions, performance degradation with increasing pseudo data volume in augmentation mode
- First 3 experiments:
  1. Test retrieval-based prompting with different similarity thresholds to find optimal k value
  2. Compare domain adaptation vs data augmentation with small pseudo data volumes (1k-4k)
  3. Test performance scaling with increasing pseudo data volumes (1k, 2k, 4k, 8k, 16k) to identify inflection points

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the long-term implications of using pseudo data generated by LLMs for real-world applications in drug discovery, particularly concerning accuracy and safety?
- Basis in paper: [explicit] The paper discusses the potential of pseudo data in advancing low-resource cross-modal molecule discovery but notes that the dataset should not be employed in real-world applications due to possible errors, biases, or inaccuracies.
- Why unresolved: The paper acknowledges the limitations of pseudo data but does not provide a detailed analysis of the long-term implications of using such data in practical, real-world scenarios.
- What evidence would resolve it: Long-term studies and evaluations comparing the performance of models trained on pseudo data versus those trained on real data in actual drug discovery projects would be necessary to assess the safety and accuracy implications.

### Open Question 2
- Question: How does the balance between real data and pseudo data affect the performance of models in different tasks, and what is the optimal ratio for maximizing performance?
- Basis in paper: [explicit] The paper explores two primary strategies for utilizing pseudo data—domain adaptation and data augmentation—and observes different trends in performance with varying amounts of pseudo data.
- Why unresolved: The paper demonstrates that performance varies with the amount of pseudo data, but it does not determine the optimal balance or ratio between real and pseudo data for different tasks.
- What evidence would resolve it: Conducting experiments with varying ratios of real to pseudo data across different tasks and datasets would help identify the optimal balance for maximizing model performance.

### Open Question 3
- Question: What are the potential biases introduced by using pseudo data generated from LLMs, and how can these biases be mitigated in the context of molecule discovery?
- Basis in paper: [inferred] The paper mentions that pseudo data is crafted artificially and may not depict actual real-world observations, suggesting potential biases.
- Why unresolved: While the paper acknowledges the artificial nature of pseudo data, it does not explore the specific biases that may arise or propose methods to mitigate them.
- What evidence would resolve it: Analyzing the characteristics and biases of pseudo data in comparison to real data, and developing techniques to correct or mitigate these biases, would provide insights into ensuring fair and accurate molecule discovery processes.

## Limitations

- The lack of transparency around PseudoMD-1M dataset generation process creates uncertainty about reproducibility and generalizability
- The superiority of domain adaptation over data augmentation may be context-dependent and doesn't explore edge cases where augmentation might be preferable
- The scaling relationship between pseudo data volume and performance needs investigation of upper bounds and potential plateau points

## Confidence

- High Confidence: Retrieval-based prompting strategy effectively improves pseudo data quality compared to baseline prompting approaches
- Medium Confidence: Domain adaptation with pseudo data consistently outperforms data augmentation across tested datasets
- Medium Confidence: The scaling relationship between pseudo data volume and model performance holds for domain adaptation but not data augmentation

## Next Checks

1. **Cross-dataset Generalization Test**: Evaluate Ada-T5 performance when pre-trained on PseudoMD-1M and fine-tuned on entirely new molecule-caption datasets not included in the original experiments, testing true generalization capability.

2. **Pseudo Data Quality Analysis**: Systematically vary the retrieval similarity threshold (k value) and analyze the relationship between retrieval quality scores and downstream model performance to identify optimal quality thresholds.

3. **Alternative LLM Comparison**: Generate pseudo data using different LLM architectures or prompting strategies (including non-retrieval-based approaches) and compare their effectiveness for both domain adaptation and data augmentation to isolate the contribution of the retrieval component.