---
ver: rpa2
title: Compositional Generalization for Data-to-Text Generation
arxiv_id: '2312.02748'
source_url: https://arxiv.org/abs/2312.02748
tags:
- pred
- cg-rl
- input
- training
- predicate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of compositional generalization
  (CG) in data-to-text generation, where models struggle to produce faithful descriptions
  for unseen combinations of predicates. To tackle this, the authors create a benchmark
  by combining CG with few-shot learning and domain adaptation.
---

# Compositional Generalization for Data-to-Text Generation

## Quick Facts
- arXiv ID: 2312.02748
- Source URL: https://arxiv.org/abs/2312.02748
- Authors: 
- Reference count: 34
- Key outcome: A clustering-based method significantly outperforms T5 baselines in compositional generalization for data-to-text generation, achieving 31% improvement in faithfulness when tested on seen domains.

## Executive Summary
This work addresses the challenge of compositional generalization (CG) in data-to-text generation, where models struggle to produce faithful descriptions for unseen combinations of predicates. The authors create a benchmark by combining CG with few-shot learning and domain adaptation, and propose a novel clustering-based method that decomposes unfamiliar predicate compositions into smaller, familiar groups during inference. The method uses either numerical or neural network-based approaches to predict predicate cluster assignments, followed by sentence generation for each cluster. Experimental results show that the proposed method significantly outperforms T5 baselines across all evaluation metrics.

## Method Summary
The proposed method addresses compositional generalization in data-to-text generation by decomposing unseen predicate compositions into smaller, familiar groups during inference. The approach involves clustering predicates into groups based on learned graph weights, then generating text in a sentence-by-sentence manner, relying on one cluster of predicates at a time. The method can use either numerical approaches based on co-occurrence statistics or neural network-based approaches using predicate embeddings to predict predicate cluster assignments. During inference, unfamiliar predicate compositions are decomposed into smaller clusters where each cluster contains only predicate combinations seen during training, with each cluster processed separately to generate a sentence that are combined to form the final description.

## Key Results
- The proposed clustering-based method significantly outperforms T5 baselines across all evaluation metrics
- Achieves 31% improvement in faithfulness (OK-percent) when tested on seen domains
- Demonstrates particular effectiveness when trained on limited data with simple predicate compositions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing unseen predicate compositions into smaller, familiar groups enables compositional generalization in data-to-text generation.
- Mechanism: The model learns graph weights from training data to cluster predicates into groups. During inference, unfamiliar predicate compositions are decomposed into smaller clusters where each cluster contains only predicate combinations seen during training. Each cluster is then processed separately to generate a sentence, which are combined to form the final description.
- Core assumption: Predicate clusters that were seen together during training can be described coherently as a single sentence, and combining these sentences produces a faithful overall description.
- Evidence anchors:
  - [abstract]: "We propose a novel model that addresses compositional generalization by clustering predicates into groups. Our model generates text in a sentence-by-sentence manner, relying on one cluster of predicates at a time."
  - [section]: "To tackle this issue, we propose a clustering-based method that utilize the graph weights learned from training data to decompose unfamiliar predicate compositions into smaller groups during inference."
  - [corpus]: Weak - corpus neighbors discuss compositional generalization but don't specifically address the clustering-based decomposition mechanism.

### Mechanism 2
- Claim: Using reinforcement learning with REINFORCE reduces reliance on imperfect silver annotations for predicate decomposition.
- Mechanism: Instead of deterministic decomposition based on exact token matching, the model samples binary matrices from Bernoulli distributions parameterized by predicate embeddings. These matrices are converted to clusters using spectral clustering. The sampling process is made differentiable using a straight-through estimator, allowing gradient-based optimization. The reward is computed based on the likelihood of generating ground truth sentences conditioned on the sampled clusters.
- Core assumption: The reward signal from comparing generated sentences to ground truth provides a better learning signal than exact token matching for determining optimal predicate groupings.
- Evidence anchors:
  - [section]: "We propose a REINFORCE (Glynn, 1990; Williams, 1992) based approach that reduces reliance on silver annotations... The reward is calculated based on Eq 1, which involves multiplying the likelihood of generating each sentence in the ground truth, conditioned on its corresponding aligned tuple group."
  - [section]: "We compute γij ∈ (0, 1) using the transformers classifier structure discussed in Section 3.1. In order to speed up convergence, we initialize the parameters using the classifier that has been trained in the deterministic approach."
  - [corpus]: Weak - corpus neighbors don't discuss REINFORCE-based approaches for data-to-text generation specifically.

### Mechanism 3
- Claim: Training on examples with fewer input tuples forces the model to learn compositional generalization skills that transfer to more complex examples.
- Mechanism: The benchmark creates training splits (CGF ULL) containing examples with up to k tuples (k ranging from 2 to 7), where k is much smaller than the maximum number of tuples in the full dataset. Models trained on these restricted splits must learn to generalize to examples with more tuples during testing.
- Core assumption: Learning to handle simple predicate compositions (few tuples) provides the foundational skills needed to compose more complex descriptions from these simpler building blocks.
- Evidence anchors:
  - [section]: "We introduce a test environment based on Gardent et al. (2017). During training, models are exposed to examples with fewer input tuples, while in the testing phase, examples with more input tuples are presented."
  - [section]: "Our approaches demonstrate superior performance compared to T5 in all four testing scenarios... particularly when trained on a very limited number of examples with simple predicate compositions."
  - [corpus]: Weak - corpus neighbors discuss compositional generalization but don't specifically address the pedagogical benefit of training on simpler examples first.

## Foundational Learning

- Concept: Graph-based representation of predicate relationships
  - Why needed here: The model represents predicate compositions as fully connected undirected graphs where predicates are nodes and edges represent relationships. This graph structure is essential for clustering algorithms to decompose complex compositions.
  - Quick check question: How would you construct a binary matrix M where Mij = 1 indicates predicates Pi and Pj belong to the same group?

- Concept: Spectral clustering for unsupervised group formation
  - Why needed here: Spectral clustering is used to partition the predicate graph into coherent groups based on the learned weights. This allows the model to discover natural groupings of predicates that can be described together.
  - Quick check question: What property of the affinity matrix determines which predicates will be grouped together in spectral clustering?

- Concept: REINFORCE algorithm for discrete latent variable optimization
  - Why needed here: Since predicate decomposition is a discrete latent variable, standard backpropagation doesn't work. REINFORCE provides a way to optimize the parameters of the distribution over decompositions using policy gradient methods.
  - Quick check question: How does the straight-through estimator make the sampling process differentiable in REINFORCE?

## Architecture Onboarding

- Component map: Input preprocessor -> Weight predictor -> Clustering module -> Text generator -> Output concatenation
- Critical path: Input → Weight prediction → Clustering → Sentence generation → Output concatenation
- Design tradeoffs:
  - Numerical vs. neural weight prediction: Numerical is simpler but fails on unseen predicates; neural can generalize but requires more computation
  - Number of clusters: Fewer clusters produce more natural text but may reduce faithfulness; more clusters increase faithfulness but may create unnatural descriptions
  - Clustering algorithm: Spectral clustering is effective but other algorithms (k-means, hierarchical) could be explored

- Failure signatures:
  - High repetition in generated text: Suggests poor ordering of clusters or lack of conditional dependencies between sentences
  - Faithful but incoherent text: Indicates decomposition created unnatural sentence boundaries
  - Poor performance on unseen domains: Suggests weight prediction doesn't generalize well to new predicates
  - Excessive number of clusters: May indicate threshold parameters are too strict or weight prediction is unreliable

- First 3 experiments:
  1. Test numerical vs. neural weight prediction on a small subset with known predicates to compare decomposition quality
  2. Vary the threshold parameter ϵ in the clustering algorithm to find the optimal balance between faithfulness and naturalness
  3. Compare different clustering algorithms (spectral, k-means, hierarchical) on the same weight matrices to evaluate their impact on generation quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the proposed clustering-based method perform on multilingual data-to-text generation tasks?
- Basis in paper: [inferred] The paper mentions the possibility of extending the benchmark to include high-quality multilingual data resources in the future, but does not provide any results or analysis on multilingual tasks.
- Why unresolved: The authors did not conduct experiments or provide any insights on how the proposed method would handle multilingual data-to-text generation.
- What evidence would resolve it: Conducting experiments on multilingual data-to-text generation tasks and comparing the performance of the proposed clustering-based method with other approaches.

### Open Question 2
- Question: How would the proposed method scale to larger pre-trained language models, such as GPT-3 or ChatGPT?
- Basis in paper: [inferred] The paper mentions that due to limited computational resources, they focused on testing the models in different sizes, including LLMs, but did not provide any results or analysis on the performance of larger models.
- Why unresolved: The authors did not conduct experiments or provide any insights on how the proposed method would perform when applied to larger pre-trained language models.
- What evidence would resolve it: Conducting experiments on data-to-text generation tasks using larger pre-trained language models and comparing the performance of the proposed clustering-based method with other approaches.

### Open Question 3
- Question: How would the proposed method perform on other tasks that involve longer inputs/outputs, such as multi-document summarization?
- Basis in paper: [inferred] The paper mentions that tasks with longer inputs/outputs, such as multi-document summarization, may derive even greater benefits from the proposed "solving CG through learning to decompose" idea, but does not provide any results or analysis on these tasks.
- Why unresolved: The authors did not conduct experiments or provide any insights on how the proposed method would perform on other tasks involving longer inputs/outputs.
- What evidence would resolve it: Conducting experiments on multi-document summarization tasks and comparing the performance of the proposed clustering-based method with other approaches.

## Limitations
- The method's reliance on silver annotations for predicate decomposition may introduce errors that propagate through the generation process
- While the approach shows strong performance on WebNLG, its effectiveness on other data-to-text datasets remains untested
- The computational overhead of clustering and multiple sentence generation steps could limit scalability to very large datasets or real-time applications

## Confidence
- **High confidence** in the core claim that decomposing unseen predicate compositions into familiar groups improves compositional generalization
- **Medium confidence** in the specific mechanisms for weight prediction and clustering
- **Low confidence** in the generalizability of results beyond WebNLG and similar structured data-to-text tasks

## Next Checks
1. Test the proposed method on E2E NLG and other data-to-text datasets to assess generalizability beyond WebNLG
2. Systematically evaluate the contribution of each component (weight prediction method, clustering algorithm, sentence ordering) by removing or replacing them with simpler alternatives
3. Conduct a detailed qualitative analysis of generated outputs to understand when and why the model fails, particularly focusing on cases where faithfulness metrics disagree with human judgment of naturalness