---
ver: rpa2
title: 'SYNAuG: Exploiting Synthetic Data for Data Imbalance Problems'
arxiv_id: '2308.00994'
source_url: https://arxiv.org/abs/2308.00994
tags:
- data
- imbalance
- synthetic
- samples
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a simple baseline approach, SYNAuG, to tackle
  data imbalance problems in deep learning by leveraging synthetic data generated
  from pre-trained generative diffusion models. The key idea is to populate the long-tailed
  training data distribution to become more uniform using synthetic data, which serves
  as a crucial preliminary step before applying task-specific algorithms.
---

# SYNAuG: Exploiting Synthetic Data for Data Imbalance Problems

## Quick Facts
- arXiv ID: 2308.00994
- Source URL: https://arxiv.org/abs/2308.00994
- Reference count: 40
- Primary result: Synthetic data from pre-trained diffusion models effectively mitigates data imbalance across long-tailed recognition, fairness, and spurious correlation tasks

## Executive Summary
This paper proposes SYNAuG, a simple baseline approach that leverages synthetic data generated from pre-trained diffusion models to address data imbalance problems in deep learning. The method uniformizes the training data distribution by generating synthetic samples for minority classes using text prompts, then trains the model on this balanced dataset. Evaluated across CIFAR100-LT, ImageNet100-LT, UTKFace, and Waterbird datasets, SYNAuG demonstrates impressive performance improvements in long-tailed recognition, fairness metrics, and robustness to spurious correlations, outperforming existing task-specific methods. The approach shows that supplementing real data with synthetic data serves as an effective preliminary step for various data imbalance problems.

## Method Summary
SYNAuG generates synthetic images for each class using pre-trained diffusion models (like Stable Diffusion) conditioned on text prompts such as "a photo of {class}". These synthetic samples are added to the original dataset to create a uniform class distribution, effectively mitigating long-tail imbalances. The model is then trained using standard cross-entropy loss on this augmented dataset. The paper also introduces SYNAuGAttr, which incorporates sensitive attribute modifiers in prompts for fairness tasks, and explores two enhancement strategies: Mixup augmentation between real and synthetic samples during training, and re-training the classifier on subsampled original data after initial training to reduce domain gap effects.

## Key Results
- SYNAuG outperforms existing task-specific methods on CIFAR100-LT with imbalance factor 100, improving accuracy for Few-shot classes from 4.48% to 9.87%
- On UTKFace, SYNAuG improves demographic parity (DP) from 0.0791 to 0.1188 while maintaining high accuracy
- The method achieves 78.67% worst-group accuracy on Waterbird dataset, significantly higher than the baseline of 64.92%
- Performance degrades when using only synthetic data, but improves when mixing with real data, with optimal results at approximately 25-50% synthetic augmentation

## Why This Works (Mechanism)

### Mechanism 1
Generating synthetic data from pre-trained diffusion models mitigates class imbalance by supplementing minority classes with high-quality samples. Diffusion models trained on large-scale web data learn to generate images matching real-world distributions. By generating synthetic samples for minority classes using simple text prompts, the number of samples per class increases, effectively reducing the imbalance. The core assumption is that the pre-trained diffusion model's learned distribution generalizes well to target dataset classes, and synthetic samples are sufficiently similar to real data to improve model training.

### Mechanism 2
Re-training the classifier on a mix of original and synthetic data, followed by fine-tuning with real data, improves accuracy by allowing the model to adjust weights toward the target distribution. After training on the uniformized dataset (original + synthetic), re-training the classifier with only real data helps the model adapt features learned from synthetic data to better match the real data distribution. The core assumption is that the model can learn useful features from synthetic data and then adapt these features when fine-tuned on real data.

### Mechanism 3
Using Mixup augmentation between real and synthetic data during training bridges the domain gap by creating interpolated samples. Mixup generates interpolated samples between real and synthetic data, encouraging the model to learn smoother decision boundaries that are robust to differences between the two domains. The core assumption is that interpolating between real and synthetic data creates useful training examples that help the model generalize better.

## Foundational Learning

- **Long-tailed distribution**: Class imbalance where a few classes have many samples and many classes have few samples, leading to lower accuracy for minority classes. Why needed: The paper addresses data imbalance problems manifesting as long-tailed distributions. Quick check: In a long-tailed distribution, which classes typically suffer from lower model accuracy: majority classes or minority classes?

- **Diffusion models**: Generative models that learn to denoise images through a Markov chain process, capable of generating high-quality images when conditioned on text prompts. Why needed: The paper leverages pre-trained diffusion models to generate synthetic data for mitigating data imbalance. Quick check: What type of generative model is used in this paper to generate synthetic images, and how is it conditioned on the target class?

- **Fairness metrics**: Measurements like Demographic Parity (DP), Equalized Odds (ED), and Equal Opportunity (EO) that quantify model fairness across different sensitive groups. Why needed: The paper evaluates the method on fairness tasks where group imbalance can lead to biased predictions. Quick check: What are the three fairness metrics used in the paper to measure model fairness, and how do they relate to group imbalance?

## Architecture Onboarding

- **Component map**: Pre-trained diffusion model -> Synthetic data generation -> Dataset population -> Model training -> Evaluation
- **Critical path**: 1) Generate synthetic samples for each class using pre-trained diffusion model and text prompts 2) Populate original dataset with synthetic samples to create uniform distribution 3) Train classifier on uniformized dataset using CE loss 4) Optionally apply Mixup augmentation during training 5) Fine-tune classifier on subset of original data
- **Design tradeoffs**: Quality vs. quantity of synthetic data (more samples may introduce larger domain gap if quality is low); complexity vs. simplicity of approach (simple baselines vs. task-specific methods); generality vs. specificity of method (general preliminary step vs. specialized methods)
- **Failure signatures**: Performance degradation when synthetic data quality is poor or domain gap is too large; overfitting to synthetic data if classifier isn't fine-tuned on real data; insufficient imbalance mitigation if too few synthetic samples are generated
- **First 3 experiments**: 1) Generate synthetic samples for a few classes in CIFAR100-LT and evaluate impact on model accuracy for those classes 2) Compare SYNAuG performance with and without Mixup augmentation on CIFAR100-LT with different imbalance factors 3) Evaluate fairness metrics (DP, ED, EO) on UTKFace with and without synthetic data to assess impact on model fairness

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal ratio of synthetic to real data for improving model performance across different data imbalance tasks? The paper explores varying ratios of original and synthetic data in experiments (Fig. 2), showing performance degrades with full replacement but improves with supplementation. This remains unresolved as the paper doesn't systematically test different ratios or identify an optimal balance for various tasks.

### Open Question 2
How does the quality of synthetic data from generative models impact the effectiveness of SYNAuG for different data imbalance problems? The paper evaluates SYNAuG performance with different step values for Stable Diffusion (Fig. 5), showing improvements even with lower-quality images. The full spectrum of synthetic data quality and its relationship to task-specific performance gains remains unexplored.

### Open Question 3
Can SYNAuG be effectively combined with algorithmic approaches to further improve fairness and robustness to spurious correlations? The paper tests SYNAuG with Group-DRO and data augmentation (Table 2), showing compatibility but not optimization of combinations. While demonstrating standalone effectiveness, the paper doesn't explore optimal combinations of SYNAuG with algorithmic methods.

## Limitations

- Synthetic data quality dependence: Performance heavily relies on pre-trained diffusion models generating high-quality synthetic data that closely matches real data distributions
- Hyperparameter sensitivity: The approach lacks extensive hyperparameter tuning for critical parameters like synthetic-to-real data ratio and Mixup strength
- Limited generalization validation: Results are primarily demonstrated with ResNet architectures and Stable Diffusion, with unclear effectiveness for other model architectures or more extreme imbalance scenarios

## Confidence

- **High Confidence**: The core mechanism of using synthetic data to mitigate class imbalance is well-supported by experimental results across multiple datasets with consistent and substantial performance improvements
- **Medium Confidence**: The claim that synthetic data serves as a "crucial preliminary step" before task-specific algorithms is reasonable but not conclusively proven, as the paper demonstrates standalone effectiveness without rigorous validation of integration with specialized methods
- **Low Confidence**: The assertion that this approach solves data imbalance "from a data perspective" overstates the results, as the method addresses symptoms rather than root causes of data scarcity and depends heavily on generative model availability

## Next Checks

1. **Domain Gap Analysis**: Compute and report Frechet Inception Distance (FID) or Kernel Inception Distance (KID) between real and synthetic data distributions for each dataset to quantify the domain gap that the model must bridge

2. **Hyperparameter Sensitivity Study**: Systematically vary the number of synthetic samples per class (e.g., 2x, 5x, 10x minority class size) and Mixup alpha parameters to identify optimal settings and understand robustness to hyperparameter choices

3. **Cross-Architecture Validation**: Evaluate the approach using different backbone architectures (e.g., Vision Transformers, EfficientNets) and alternative diffusion models to assess generalization beyond ResNet + Stable Diffusion combinations