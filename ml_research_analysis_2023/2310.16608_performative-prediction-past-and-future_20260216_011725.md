---
ver: rpa2
title: 'Performative Prediction: Past and Future'
arxiv_id: '2310.16608'
source_url: https://arxiv.org/abs/2310.16608
tags:
- performative
- distribution
- prediction
- learning
- risk
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Performative prediction addresses the challenge of distribution
  shift caused by the influence of predictions on the target variable in machine learning
  applications. The paper introduces a conceptual framework where predictions can
  causally influence the data-generating distribution, leading to a distinction between
  learning (optimizing in current conditions) and steering (influencing the distribution
  shift).
---

# Performative Prediction: Past and Future

## Quick Facts
- arXiv ID: 2310.16608
- Source URL: https://arxiv.org/abs/2310.16608
- Reference count: 15
- Primary result: Performative prediction framework addresses distribution shift caused by prediction influence on target variables in ML applications.

## Executive Summary
This survey paper provides a comprehensive overview of performative prediction, a framework addressing the challenge where machine learning predictions influence the very data distributions they aim to model. The paper establishes a conceptual distinction between learning (optimizing under current conditions) and steering (influencing distribution shift), presenting key methods including repeated risk minimization, gradient-based optimization, and stochastic optimization that converge to performatively stable points under specific conditions. The framework introduces novel concepts like performative power, which quantifies a platform's ability to steer participants through predictions, offering insights for digital market dynamics and antitrust investigations. Additionally, the paper explores algorithmic collective action, where participants strategically modify data to influence platform predictions, demonstrating potential for improved collective outcomes.

## Method Summary
The paper synthesizes three main methodological approaches: repeated risk minimization (RRM) for finding performatively stable points, gradient-based optimization (RGD) for performative optimal points, and stochastic optimization (SGD) for scalable performative prediction. These methods operate under the assumption that data distributions shift in response to model parameters according to a distribution map D(θ). The framework assumes parametric predictive models with features X and outcomes Y, where predictions causally influence outcomes through the distribution map. Convergence guarantees require specific conditions including strong convexity and joint smoothness of the loss function, along with bounded sensitivity of the distribution map.

## Key Results
- Repeated risk minimization converges to performatively stable points when distribution sensitivity ϵ < γ/β, where γ is strong convexity and β is joint smoothness
- Performative power quantifies platform influence over participant behavior, offering new tools for antitrust investigations in digital markets
- Algorithmic collective action enables participants to strategically modify data, achieving higher collective outcomes when hidden signals are sufficiently rare

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Repeated risk minimization converges to a performatively stable point when the distribution shift is small relative to the convexity of the loss.
- Mechanism: In each iteration, the algorithm minimizes risk on the distribution induced by the previous model. Under strong convexity (γ) and joint smoothness (β) of the loss, and when the sensitivity (ϵ) of the distribution map is less than γ/β, the mapping from current model to next model is contractive. This ensures convergence to a unique stable point.
- Core assumption: The loss function is γ-strongly convex and β-jointly smooth; the distribution map is ϵ-sensitive with ϵ < γ/β.
- Evidence anchors:
  - [section]: "Suppose that the loss function ℓ(θ, z) is γ-strongly convex and β-jointly smooth. Then, repeated retraining defined in (5) converges to a unique stable point as long as the sensitivity of the distribution map D(·) satisfies ϵ < γ/β."
  - [abstract]: "Key methods include repeated risk minimization, gradient-based optimization, and stochastic optimization, all converging to performatively stable points under certain conditions."
  - [corpus]: Weak. Corpus neighbors do not directly address convergence conditions; they focus on broader performative prediction topics.
- Break condition: If the distribution shift is too large (ϵ ≥ γ/β), the algorithm may diverge or oscillate without reaching a stable point.

### Mechanism 2
- Claim: Performative power quantifies how much a platform can steer participants through its predictions, informing antitrust investigations.
- Mechanism: Performative power is defined as the supremum over possible actions of the expected distance between participants' current and counterfactual data under the action. It captures the causal influence of the platform's predictions on participants' behavior, providing a measure of the platform's ability to steer the population.
- Core assumption: The set of actions (F) and participants (U) are well-defined; potential outcomes are measurable; no interference between units.
- Evidence anchors:
  - [section]: "Performative power is a statistical causal notion... It does not require specification of the market in which the firm operates."
  - [abstract]: "The notion of performative power quantifies how much a platform can steer participants through its predictions, offering insights into digital market dynamics and antitrust investigations."
  - [corpus]: Missing. Corpus neighbors do not directly discuss antitrust applications or performative power.
- Break condition: If interference between units is significant, or if the causal effects are not estimable, the measure of performative power may be inaccurate.

### Mechanism 3
- Claim: Algorithmic collective action allows a fraction of participants to influence the platform's predictions, leading to improved outcomes for the collective.
- Mechanism: A fraction α of participants strategically modify their data (e.g., by applying a hidden signal) to influence the model learned by the platform. Under outcome performativity, where predictions affect outcomes, this strategy can lead to higher realized revenue for the collective, especially when the signal is rare in the base distribution.
- Core assumption: The outcome variable depends on both features and the platform's prediction; the collective can apply a hidden signal that the model can learn; the signal is rare enough in the base distribution.
- Evidence anchors:
  - [section]: "Consider an outcome variable Y = h(X) + β f(X) + Z... Assuming a rare enough signal with ξ ≤ α/2, Theorem 7 shows that the revenue increase for the collective is lower bounded by β/2."
  - [abstract]: "The framework also explores algorithmic collective action, where a fraction of participants strategically modify their data to influence predictions."
  - [corpus]: Weak. Corpus neighbors do not discuss collective action or revenue effects in performative settings.
- Break condition: If the signal is not rare enough (ξ is large), or if the platform's model is not sensitive to the signal, the collective's strategy may fail.

## Foundational Learning

- Concept: Strong convexity and joint smoothness of loss functions
  - Why needed here: These properties ensure that repeated risk minimization and gradient-based methods converge to stable points under performative prediction.
  - Quick check question: Why does the convergence of repeated risk minimization require the condition ϵ < γ/β?

- Concept: Wasserstein distance and sensitivity of distribution maps
  - Why needed here: Sensitivity quantifies how much the data-generating distribution shifts in response to model changes, which is crucial for analyzing convergence and stability.
  - Quick check question: How does the Wasserstein-1 distance relate to the Lipschitz continuity of the distribution map?

- Concept: Causal inference and potential outcomes
  - Why needed here: Understanding the causal effect of model predictions on participant behavior is essential for measuring performative power and designing collective action strategies.
  - Quick check question: What is the role of the no interference assumption in estimating performative power?

## Architecture Onboarding

- Component map: Data generator -> Distribution map -> Optimization module -> Causal inference module

- Critical path:
  1. Initialize model parameters.
  2. Generate data under current distribution.
  3. Update model via optimization (RRM, RGD, or SGD).
  4. Observe new distribution induced by updated model.
  5. Repeat until convergence or stopping criterion.

- Design tradeoffs:
  - Greedy deploy (update model after every sample) vs. lazy deploy (collect more samples before updating): Greedy deploy reduces distribution shift per step but may incur higher computational cost; lazy deploy reduces deployment overhead but increases sample complexity.
  - Model-based vs. model-free approaches: Model-based approaches can leverage parametric assumptions for efficiency but risk misspecification; model-free approaches are more robust but may require more data.

- Failure signatures:
  - Divergence or oscillation in optimization: Indicates that the distribution shift is too large (ϵ ≥ γ/β) or that the loss function lacks sufficient convexity/smoothness.
  - High variance in stochastic updates: Suggests that the bounded variance assumption is violated or that the sample size is too small.
  - Poor estimation of performative power: May result from interference between units or from an inability to observe counterfactual outcomes.

- First 3 experiments:
  1. Simulate repeated risk minimization on a synthetic dataset with a known distribution map; verify convergence to a stable point when ϵ < γ/β.
  2. Compare greedy deploy and lazy deploy strategies in terms of convergence speed and sample complexity under different levels of distribution shift.
  3. Implement a simple collective action strategy (e.g., label flipping with a hidden signal) and measure its effectiveness in influencing the platform's predictions and participant outcomes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what conditions does algorithmic collective action become more effective than individual strategic behavior in performative prediction settings?
- Basis in paper: [explicit] The paper discusses algorithmic collective action and its effectiveness, mentioning conditions under which a collective can influence predictions, but does not compare it to individual strategic behavior.
- Why unresolved: The paper focuses on the effectiveness of collective action but does not provide a direct comparison to individual strategies in performative settings.
- What evidence would resolve it: Empirical studies comparing the success rates of collective versus individual strategies in various performative prediction scenarios, particularly in terms of revenue increase and prediction accuracy.

### Open Question 2
- Question: How does the strength of performativity vary across different types of machine learning applications, such as content recommendation versus traffic prediction?
- Basis in paper: [explicit] The paper discusses performativity in various contexts, including content recommendation and traffic prediction, but does not quantify the strength of performativity across different applications.
- Why unresolved: The paper provides examples of performativity but lacks a comparative analysis of its strength across different domains.
- What evidence would resolve it: Quantitative studies measuring the impact of predictions on outcomes in different machine learning applications, using metrics like performative power or sensitivity.

### Open Question 3
- Question: What are the long-term societal impacts of performative prediction, particularly in terms of reinforcing biases or creating feedback loops?
- Basis in paper: [inferred] The paper mentions the role of performativity in fairness and algorithmic systems, suggesting potential societal impacts, but does not explore long-term effects.
- Why unresolved: The paper focuses on technical aspects of performative prediction and does not delve into societal implications or long-term consequences.
- What evidence would resolve it: Longitudinal studies examining the societal effects of performative prediction over time, including changes in biases, feedback loops, and social outcomes.

## Limitations

- Convergence guarantees rely on strong assumptions about loss function convexity and smoothness that may not hold in real-world applications
- Limited empirical validation, particularly for antitrust applications and collective action mechanisms
- Minimal corpus support for key claims about practical applications, with only 8 relevant papers among 25 neighbors

## Confidence

- Repeated risk minimization convergence (Medium): Relies on specific mathematical conditions (γ-strong convexity, β-joint smoothness, and ϵ < γ/β sensitivity)
- Performative power in antitrust contexts (Low): Minimal corpus support with no direct evidence found
- Collective action framework (Medium): Theoretically sound but lacks empirical validation in corpus

## Next Checks

1. **Distribution Map Sensitivity**: Empirically test the ϵ < γ/β condition by systematically varying distribution shift magnitude and measuring convergence behavior in synthetic datasets with known properties.

2. **Real-world Antitrust Case Studies**: Apply the performative power framework to analyze historical antitrust cases involving digital platforms to validate its practical utility in measuring market influence.

3. **Collective Action Simulation**: Implement the algorithmic collective action strategy in a realistic multi-agent simulation where participants can strategically modify features, measuring both prediction influence and outcome improvements across varying signal rarity levels.