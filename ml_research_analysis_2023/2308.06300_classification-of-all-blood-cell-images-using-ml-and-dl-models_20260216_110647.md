---
ver: rpa2
title: Classification of All Blood Cell Images using ML and DL Models
arxiv_id: '2308.06300'
source_url: https://arxiv.org/abs/2308.06300
tags:
- blood
- images
- accuracy
- layers
- cells
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of automated blood cell classification
  to improve accuracy and reduce human error compared to manual methods. It applies
  transfer learning with CNN pre-trained models (VGG16, VGG19, ResNet-50, ResNet-101,
  ResNet-152, InceptionV3, MobileNetV2, and DenseNet-201) to a dataset of 17,092 blood
  cell images.
---

# Classification of All Blood Cell Images using ML and DL Models

## Quick Facts
- arXiv ID: 2308.06300
- Source URL: https://arxiv.org/abs/2308.06300
- Reference count: 0
- A novel CNN architecture achieves 99.91% accuracy on blood cell classification, outperforming pre-trained models

## Executive Summary
This paper addresses the challenge of automated blood cell classification by comparing transfer learning approaches with pre-trained CNN models against a novel custom CNN architecture. The authors evaluate multiple pre-trained models (VGG16, VGG19, ResNet variants, InceptionV3, MobileNetV2, DenseNet-201) on a dataset of 17,092 blood cell images, achieving accuracies between 91.375% and 94.72%. To improve upon these results, they propose a specialized 22-layer CNN architecture with seven convolutional blocks that achieves 99.91% accuracy, demonstrating significant improvement over existing approaches for blood cell classification tasks.

## Method Summary
The study employs transfer learning with eight pre-trained CNN models (VGG16, VGG19, ResNet-50/101/152, InceptionV3, MobileNetV2, DenseNet-201) fine-tuned on the PBC dataset containing 17,092 blood cell images. These models are trained using sparse categorical cross-entropy loss and Adam optimizer. Additionally, the authors propose a novel 22-layer CNN architecture with seven convolutional blocks, each followed by max pooling and dropout layers. The proposed model is trained for 150 epochs with early stopping and model checkpointing to prevent overfitting. Both approaches are evaluated using accuracy, precision, recall, and F-measure metrics.

## Key Results
- Pre-trained models achieved accuracies between 91.375% and 94.72% on the blood cell classification task
- The proposed 22-layer CNN architecture achieved 99.91% accuracy on the same dataset
- The custom CNN model outperformed all pre-trained approaches by 5-8 percentage points

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transfer learning with pre-trained CNN models significantly reduces training time and improves accuracy for blood cell classification by leveraging learned hierarchical features
- Mechanism: Pre-trained models are fine-tuned on the blood cell dataset, utilizing their learned feature extraction capabilities from ImageNet
- Core assumption: Features learned on ImageNet are transferable to blood cell images, reducing the need for large annotated datasets
- Evidence anchors: [abstract] "transfer learning with CNN pre-trained models... applied to the dataset... achieved accuracies between 91.375% and 94.72%"

### Mechanism 2
- Claim: The proposed 22-layer CNN architecture outperforms pre-trained models by learning specialized features for blood cell classification
- Mechanism: A custom CNN with seven convolutional blocks, each followed by max pooling and dropout layers, extracts hierarchical features specific to blood cell subtypes
- Core assumption: Custom architecture can learn more discriminative features for blood cell subtypes than generic pre-trained models
- Evidence anchors: [abstract] "A novel CNN architecture with 22 layers... achieved an accuracy of 99.91% on the same dataset... outperforms previous studies"

### Mechanism 3
- Claim: Dropout and max pooling layers prevent overfitting and reduce computational complexity, improving generalization
- Mechanism: Dropout randomly removes nodes during training, preventing reliance on specific features. Max pooling reduces spatial dimensions, summarizing feature presence
- Core assumption: Regularization techniques are effective in preventing overfitting in deep learning models for image classification
- Evidence anchors: [section] "The dropout technique is utilized to prevent overfitting... Dropout is a simple yet effective regularization approach"

## Foundational Learning

- Concept: Convolutional Neural Networks (CNNs)
  - Why needed here: CNNs are designed to automatically learn hierarchical features from images, making them suitable for classifying blood cell images based on their visual characteristics
  - Quick check question: What is the primary advantage of using convolutional layers over fully connected layers for image classification?

- Concept: Transfer Learning
  - Why needed here: Transfer learning leverages pre-trained models to reduce training time and improve accuracy, especially when the dataset is limited or lacks diversity
  - Quick check question: How does fine-tuning a pre-trained model differ from training a model from scratch?

- Concept: Regularization Techniques (Dropout and Max Pooling)
  - Why needed here: Regularization techniques prevent overfitting, ensuring the model generalizes well to unseen data, which is crucial for reliable blood cell classification in clinical settings
  - Quick check question: What is the purpose of dropout in a neural network, and how does it help prevent overfitting?

## Architecture Onboarding

- Component map: Input Layer (100x100x3 RGB images) -> 7 Convolutional Blocks (Conv2D + ReLU + MaxPooling2D + Dropout) -> 5 Fully Connected Layers (Dense + ReLU) -> Output Layer (Dense + SoftMax for 10 classes)

- Critical path:
  1. Data preprocessing and augmentation
  2. Model architecture definition
  3. Compilation with loss function and optimizer
  4. Training with early stopping and model checkpointing
  5. Evaluation on test set
  6. Deployment and monitoring

- Design tradeoffs:
  - Model depth vs. overfitting: Deeper models can learn more complex features but are prone to overfitting with limited data
  - Dropout rate: Higher dropout rates prevent overfitting but may hinder learning if too aggressive
  - Input image size: Larger images provide more detail but increase computational cost and memory usage

- Failure signatures:
  - Overfitting: High training accuracy but low validation accuracy
  - Underfitting: Low training and validation accuracy
  - Vanishing gradients: Poor performance in deeper layers

- First 3 experiments:
  1. Train the proposed CNN architecture on the blood cell dataset with different dropout rates (0.2, 0.25, 0.3) to find the optimal balance between overfitting and underfitting
  2. Compare the performance of the proposed CNN with pre-trained models (VGG16, ResNet-50) on the blood cell dataset to validate the effectiveness of the custom architecture
  3. Apply data augmentation techniques (rotation, scaling, flipping) to the blood cell dataset and evaluate their impact on model performance and generalization

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- The reported 99.91% accuracy appears optimistic given the relatively small dataset size of 17,092 images
- Lack of detailed architectural specifications, particularly regarding exact layer configurations and hyperparameter settings, limits reproducibility
- The study does not report cross-validation results or statistical significance testing to support the claimed superiority over transfer learning approaches

## Confidence
- Pre-trained model performance claims (91.375%-94.72%): Medium
- Proposed CNN architecture performance claim (99.91%): Low
- Generalization capability of the proposed model: Low

## Next Checks
1. Conduct k-fold cross-validation (k=5 or 10) to establish confidence intervals for model performance and verify the robustness of the 99.91% accuracy claim
2. Test the proposed model on an independent blood cell dataset to evaluate true generalization capability beyond the training data
3. Perform ablation studies by incrementally removing architectural components (dropout layers, specific convolutional blocks) to identify which elements contribute most to the claimed performance improvement