---
ver: rpa2
title: 'AMRFact: Enhancing Summarization Factuality Evaluation with AMR-Driven Negative
  Samples Generation'
arxiv_id: '2311.09521'
source_url: https://arxiv.org/abs/2311.09521
tags:
- summary
- data
- summaries
- factual
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AMRFact, a framework that generates factually
  inconsistent summaries using Abstract Meaning Representations (AMRs) to enhance
  factual consistency evaluation in abstractive summarization. The approach parses
  factually consistent summaries into AMR graphs, injects controlled factual inconsistencies
  (predicate, entity, circumstance, discourse link, and out-of-article errors), and
  converts the perturbed graphs back into text.
---

# AMRFact: Enhancing Summarization Factuality Evaluation with AMR-Driven Negative Samples Generation

## Quick Facts
- **arXiv ID:** 2311.09521
- **Source URL:** https://arxiv.org/abs/2311.09521
- **Reference count:** 21
- **Key outcome:** Outperforms previous systems on AggreFact-SOTA benchmark with 72.3% balanced accuracy on CNN/DM and 64.1% on XSUM

## Executive Summary
This paper introduces AMRFact, a framework that generates factually inconsistent summaries using Abstract Meaning Representations (AMRs) to enhance factual consistency evaluation in abstractive summarization. The approach parses factually consistent summaries into AMR graphs, injects controlled factual inconsistencies (predicate, entity, circumstance, discourse link, and out-of-article errors), and converts the perturbed graphs back into text. A novel data selection module, NegFilter, ensures the quality of generated negative samples by using natural language inference and BARTScore. The method achieves state-of-the-art performance on the AggreFact-SOTA benchmark, improving balanced accuracy by 2.3% over previous best models.

## Method Summary
AMRFact generates factually inconsistent summaries by parsing reference summaries into AMR graphs and injecting controlled factual inconsistencies through specific graph manipulations. The framework implements five error types: predicate errors (verb and antonym substitutions), entity errors (name substitutions), circumstance errors (temporal, spatial, and quantitative modifications), discourse link errors (coreference and discourse relation changes), and out-of-article errors (facts not supported by source documents). A NegFilter module filters invalid negative samples using natural language inference and BARTScore to ensure generated summaries are both factually inconsistent with references and semantically aligned with source documents. The filtered dataset trains a RoBERTa-based factuality classifier.

## Key Results
- Achieves 72.3% balanced accuracy on CNN/DM dataset
- Achieves 64.1% balanced accuracy on XSUM dataset
- Improves over previous best model by average of 2.3% on AggreFact-SOTA benchmark

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** AMR-based perturbations preserve semantic coherence while enabling precise control over error types.
- **Mechanism:** By manipulating AMR graphs rather than raw text, the framework can systematically inject specific factual errors while maintaining grammatical fluency through AMR-to-text generation.
- **Core assumption:** AMR graphs abstract away surface syntax sufficiently to allow coherent text regeneration after perturbation.
- **Evidence anchors:** Abstract states the approach enables coherent factually inconsistent summaries with high error-type coverage; section 4.1 explains using AMR enables more coherent summaries without compromising error-type coverage.

### Mechanism 2
- **Claim:** NEGFILTER improves model performance by excluding invalid negative samples that would mislead training.
- **Mechanism:** Uses NLI and BARTScore to ensure generated summaries are both factually inconsistent with the reference and semantically aligned with the source document, filtering out samples that are either too similar to references or too disconnected from source content.
- **Core assumption:** Training on invalid negative examples harms the model's ability to distinguish factual consistency.
- **Evidence anchors:** Section 4.2 hypothesizes that training on invalid negative data could impair performance; section 6.2 shows 10.3% improvement on CNN/DM when filtering is applied.

### Mechanism 3
- **Claim:** Controlled error injection via AMR manipulation allows for high coverage of error types found in real summaries.
- **Mechanism:** The framework systematically implements five error types by specific AMR graph manipulations, covering error patterns observed in state-of-the-art summarization systems.
- **Core assumption:** Real summarization errors can be modeled through the five identified error types.
- **Evidence anchors:** Abstract mentions injecting controlled factual inconsistencies commonly observed in state-of-the-art summarization systems; section 4.1 details how each error type is implemented through AMR manipulation.

## Foundational Learning

- **Concept:** Abstract Meaning Representation (AMR)
  - **Why needed here:** AMR provides a semantic graph representation that abstracts away syntax, enabling controlled manipulation of meaning while preserving fluency.
  - **Quick check question:** How does AMR represent negation differently from surface syntax?

- **Concept:** Natural Language Inference (NLI)
  - **Why needed here:** NLI models assess whether one text entails another, which is used to filter invalid negative examples and evaluate factual consistency.
  - **Quick check question:** What are the three possible outcomes of an NLI classification?

- **Concept:** Negative sampling in training data
  - **Why needed here:** The framework relies on generating negative examples (factually inconsistent summaries) to train the factuality evaluation model.
  - **Quick check question:** Why is it important to have high-quality negative samples in binary classification tasks?

## Architecture Onboarding

- **Component map:** Text-to-AMR parser -> AMR perturbation engine -> AMR-to-text generator -> NegFilter module -> Factuality classifier
- **Critical path:** Reference summary → AMR parsing → Perturbation → Text generation → Filtering → Training data → Model training
- **Design tradeoffs:** The framework trades computational complexity (AMR parsing and generation) for better control over error types and higher-quality training data.
- **Failure signatures:** If the factuality classifier performs poorly, check: 1) AMR parsing quality, 2) Perturbation effectiveness, 3) Filtering thresholds, 4) Model architecture.
- **First 3 experiments:**
  1. Validate AMR parsing by checking if reference summaries can be accurately reconstructed from their AMR representations.
  2. Test perturbation effectiveness by manually reviewing a sample of generated negative examples for each error type.
  3. Experiment with different filtering thresholds to find the optimal balance between data quality and quantity.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the AMR-based perturbation approach compare to other semantic representations like Semantic Role Labeling (SRL) or Abstract Meaning Representation (AMR) for generating factually inconsistent summaries?
- **Basis in paper:** The paper focuses on AMR for generating perturbations but doesn't compare its effectiveness to other semantic representations.
- **Why unresolved:** The paper only uses AMR and doesn't explore other semantic representations for generating factually inconsistent summaries.
- **What evidence would resolve it:** Experiments comparing the performance of AMR-based perturbations to other semantic representations like SRL or AMR on the same task and dataset.

### Open Question 2
- **Question:** What is the impact of different types of factual errors (predicate, entity, circumstance, discourse link, out-of-article) on the performance of factuality evaluation models?
- **Basis in paper:** The paper introduces five types of factual errors but doesn't analyze their individual impact on model performance.
- **Why unresolved:** The paper focuses on the overall performance of the model but doesn't delve into the specific impact of different error types.
- **What evidence would resolve it:** Ablation studies where each type of factual error is removed from the training data, and the performance of the factuality evaluation model is measured.

### Open Question 3
- **Question:** How does the quality of the AMR-to-text model affect the coherence and fluency of the generated factually inconsistent summaries?
- **Basis in paper:** The paper mentions the importance of the AMR-to-text model for generating coherent summaries but doesn't explore the impact of its quality.
- **Why unresolved:** The paper assumes the AMR-to-text model is of sufficient quality but doesn't investigate how its performance affects the generated summaries.
- **What evidence would resolve it:** Experiments comparing the performance of the factuality evaluation model when using different AMR-to-text models with varying levels of quality.

## Limitations
- AMR parsing dependency introduces potential errors from parser quality and handling of coordination structures and nested entities
- Dataset coverage limited to CNN/DM and XSUM, with unknown generalization to other summarization domains
- Filtering threshold sensitivity may affect robustness across different datasets and error distributions

## Confidence

**High Confidence Claims:**
- The AMRFact framework can generate factually inconsistent summaries with controlled error types
- The approach outperforms previous methods on the AggreFact-SOTA benchmark
- The NegFilter module improves performance by excluding invalid negative samples

**Medium Confidence Claims:**
- AMR-based perturbations preserve semantic coherence better than alternative approaches
- The five identified error types comprehensively cover real summarization errors
- The balanced accuracy improvements are robust across different datasets

**Low Confidence Claims:**
- The framework generalizes to summarization domains beyond CNN/DM and XSUM
- The specific threshold values chosen for NegFilter are optimal
- The computational overhead of AMR parsing is justified by performance gains

## Next Checks
1. **AMR Quality Validation:** Systematically evaluate the quality of AMR parsing on a sample of reference summaries by comparing reconstruction accuracy. Measure how often AMR parsing introduces semantic ambiguities that could affect perturbation outcomes.

2. **Error Type Coverage Analysis:** Conduct a comprehensive analysis of factual errors in real summarization outputs (from multiple models and domains) to verify that the five identified error types capture the majority of observed inconsistencies. This would validate the framework's generalizability.

3. **Threshold Sensitivity Study:** Perform an ablation study varying the NegFilter thresholds (τ1, τ2) across a range of values to determine optimal settings and assess the stability of performance improvements. This would reveal whether the current thresholds are sensitive to dataset characteristics.