---
ver: rpa2
title: Does My Dog ''Speak'' Like Me? The Acoustic Correlation between Pet Dogs and
  Their Human Owners
arxiv_id: '2309.13085'
source_url: https://arxiv.org/abs/2309.13085
tags:
- speech
- language
- dogs
- host
- japanese
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a novel dataset of Shiba Inu dog vocalizations
  and their corresponding human speech from YouTube, covering two language environments:
  English and Japanese. By extracting and segmenting the audio clips, and tagging
  them with contextual information, the dataset contains 7500 dog vocal clips and
  15197 human speech clips.'
---

# Does My Dog ''Speak'' Like Me? The Acoustic Correlation between Pet Dogs and Their Human Owners

## Quick Facts
- arXiv ID: 2309.13085
- Source URL: https://arxiv.org/abs/2309.13085
- Reference count: 9
- This paper presents a novel dataset of Shiba Inu dog vocalizations and their corresponding human speech from YouTube, covering two language environments: English and Japanese. By extracting and segmenting the audio clips, and tagging them with contextual information, the dataset contains 7500 dog vocal clips and 15197 human speech clips. The authors conduct classification experiments to demonstrate that dog vocalizations can be distinguished based on their language environments, with accuracy higher than random guess. Through Shapley value analysis, they identify prominent acoustic features that differentiate dogs from different language environments, which are correlated with those of their host language. The findings suggest that the host language environment has an influence over the dog's vocalization, providing insights into the relationship between human language and animal vocal expressions.

## Executive Summary
This paper investigates whether the language environment of human owners influences the acoustic characteristics of their pet dogs' vocalizations. The authors created a novel dataset, EJShibaVoice, containing 7,500 Shiba Inu dog vocalizations and 15,197 corresponding human speech clips from YouTube videos in English and Japanese. Through classification experiments and feature analysis, they found that dogs from different language environments can be distinguished based on their vocalizations, and that the prominent acoustic features in dog vocalizations are correlated with those of their host language. The study provides evidence that the language environment of humans can influence the acoustic properties of their pet dogs' vocalizations.

## Method Summary
The authors collected Shiba Inu audio clips from YouTube using the keyword "Shiba Inu" and scene category terms, filtering by language environment based on video titles/captions. They processed the audio clips by extracting dog vocalizations and corresponding human speech, segmenting into minimal units, and tagging with contextual information. Classification experiments were performed using features like MFCC and GeMAPs, followed by Shapley value analysis to identify prominent acoustic features that distinguish dog vocalizations by language environment.

## Key Results
- Dogs from different language environments (English and Japanese) can be distinguished based on their vocalizations with accuracy higher than random chance.
- Prominent acoustic features that differentiate dogs from different language environments are correlated with those of their host language.
- English dogs bark at a lower pitch than Japanese dogs, while Japanese dogs bark faster than English ones.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Host language environment influences dog vocalization characteristics such as frequency and speed.
- Mechanism: Dogs exposed to different linguistic environments develop vocal patterns that mirror the acoustic properties of their host language, likely through long-term social interaction and learning.
- Core assumption: Dogs can perceive and adapt to linguistic acoustic features in their environment, and these adaptations are reflected in their vocalizations.
- Evidence anchors:
  - [abstract] "the host language environment has an influence over the dog's vocalization"
  - [section] "English dog vocals at a lower pitch than Japanese dogs, while Japanese dogs bark faster than English ones"
  - [corpus] Weak or missing direct evidence; only tangentially related to human-pet interaction studies
- Break condition: If classification accuracy does not exceed random chance, or if no correlation is found between host speech and dog vocalization acoustic features.

### Mechanism 2
- Claim: The EJShibaVoice dataset enables detection of subtle acoustic differences between dogs from different language environments.
- Mechanism: By using a large, diverse dataset with careful noise removal and context tagging, the study can isolate linguistic influence from other confounding factors.
- Core assumption: The data processing pipeline effectively removes non-linguistic noise and the large sample size mitigates confounding variables.
- Evidence anchors:
  - [abstract] "7500 clean sound clips...with contextual information"
  - [section] "The number of families for Japanese and English respectively stand at 219 and 275"
  - [corpus] Weak evidence; corpus shows limited direct studies on large-scale pet vocalization datasets
- Break condition: If the classification accuracy is not significantly higher than random, or if confounding factors cannot be adequately controlled.

### Mechanism 3
- Claim: Prominent acoustic features identified through Shapley value analysis correlate between dog vocalizations and host speech.
- Mechanism: Certain acoustic dimensions (e.g., frequency, energy distribution) that distinguish dogs by language environment also distinguish human speech, suggesting shared acoustic patterns.
- Core assumption: The same acoustic features are relevant for both human speech and dog vocalizations in the context of language influence.
- Evidence anchors:
  - [abstract] "We further identify some acoustic features from dog vocalizations that are potentially correlated to their host language patterns"
  - [section] "The ten prominent factors...fall into four categories: spectral, temporal, energy, and frequency"
  - [corpus] Weak evidence; corpus lacks studies on acoustic correlation between human speech and pet vocalizations
- Break condition: If Pearson correlation between dog vocals and host speech is not significant, or if prominent features do not overlap.

## Foundational Learning

- Concept: Acoustic feature extraction (spectral, temporal, energy, frequency)
  - Why needed here: To quantify and compare the acoustic characteristics of dog vocalizations across different language environments.
  - Quick check question: Can you explain the difference between MFCC and GeMAPs features and when each might be more appropriate?

- Concept: Machine learning classification (xgboost, KNN, Logistic Regression, Random Forest)
  - Why needed here: To test whether dog vocalizations can be distinguished based on their language environment with accuracy higher than random chance.
  - Quick check question: How would you interpret a classification accuracy of 0.98 for distinguishing English vs. Japanese dog barks?

- Concept: Shapley value analysis for feature importance
  - Why needed here: To identify which acoustic features are most important in distinguishing dog vocalizations from different language environments.
  - Quick check question: What does a high Shapley value for a feature indicate about its importance in the classification task?

## Architecture Onboarding

- Component map:
  Data collection -> YouTube crawler with language detection -> Preprocessing -> PANNs for sound event detection, noise elimination, speaker diarization -> Feature extraction -> Multiple acoustic feature sets (filterbank, PLP, MFCC, ComParE, GeMAPs, eGeMAPs) -> Analysis -> Classification models, Shapley value analysis, Pearson correlation -> Output -> Dataset EJShibaVoice, classification results, feature importance rankings

- Critical path: Data collection -> Preprocessing -> Feature extraction -> Classification -> Analysis
- Design tradeoffs: Large web dataset vs. controlled environment; complex preprocessing vs. data quality; multiple feature sets vs. interpretability
- Failure signatures: Low classification accuracy; insignificant correlations; prominent features not overlapping between dogs and human speech
- First 3 experiments:
  1. Run classification with only one feature set (e.g., MFCC) to establish baseline accuracy
  2. Perform Shapley analysis on human speech alone to identify language-discriminative features
  3. Compute Pearson correlation between dog vocals and their corresponding host speech for the top 3 prominent features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do other dog breeds compare to Shiba Inus in terms of acoustic correlation with their host language environment?
- Basis in paper: [inferred] The study focuses on Shiba Inu dogs due to their popularity and availability of online data, but the paper suggests future research could include more breeds.
- Why unresolved: The current dataset and experiments are limited to Shiba Inus, so the findings may not generalize to other breeds.
- What evidence would resolve it: A larger dataset including various dog breeds and their vocalizations across different language environments, followed by similar classification and correlation analysis.

### Open Question 2
- Question: What specific mechanisms in the interaction between dogs and their human hosts lead to the observed acoustic differences in vocalizations?
- Basis in paper: [explicit] The paper hypothesizes that the host's spoken language influences the dog's vocalization but does not explore the underlying mechanisms of this interaction.
- Why unresolved: The study identifies a correlation but does not investigate the causal relationship or the factors that mediate the influence of human language on dog vocalizations.
- What evidence would resolve it: Longitudinal studies observing dogs from birth in different language environments, controlling for other variables, to determine the impact of language exposure on vocalization development.

### Open Question 3
- Question: How do cultural and social norms interact with language to influence dog vocalizations, and can these effects be disentangled?
- Basis in paper: [explicit] The authors acknowledge that social norms and customs, which are interrelated with language, may also influence dog vocalizations.
- Why unresolved: The study focuses on linguistic environments but does not separately analyze the impact of cultural and social norms from that of the language itself.
- What evidence would resolve it: Comparative studies of dog vocalizations in regions with similar languages but different cultural norms, or vice versa, to isolate the effects of language from those of culture and social practices.

## Limitations
- The observed acoustic differences between English and Japanese dog vocalizations may be influenced by confounding factors such as individual dog characteristics, recording environments, or human vocal imitation rather than genuine linguistic adaptation.
- The dataset, while large, is derived from uncontrolled YouTube videos, raising questions about the consistency of recording conditions and the representativeness of the sample.
- The correlation between dog vocalizations and host speech acoustic features, while statistically significant, does not establish a causal relationship or rule out alternative explanations.

## Confidence
- High confidence: The technical methodology for data collection, preprocessing, and acoustic feature extraction is sound and reproducible.
- Medium confidence: The classification results showing dogs can be distinguished by language environment are robust, but the interpretation of linguistic influence requires caution.
- Medium confidence: The correlation between prominent acoustic features in dog vocalizations and host speech suggests an interesting pattern, but the strength and significance of this relationship need further validation.

## Next Checks
1. Conduct a controlled study with dogs raised in bilingual environments or exposed to multiple language environments to test the robustness of language-specific acoustic patterns.
2. Perform a systematic analysis of potential confounding factors (dog age, sex, recording environment) to assess their impact on the observed acoustic differences.
3. Replicate the classification and correlation analysis using an independent dataset of dog vocalizations and corresponding human speech to verify the generalizability of the findings.