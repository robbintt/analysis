---
ver: rpa2
title: Gender mobility in the labor market with skills-based matching models
arxiv_id: '2307.08368'
source_url: https://arxiv.org/abs/2307.08368
tags:
- gender
- skills
- matching
- segregation
- occupations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates the effect of data-driven skills-based matching
  models on the gender segregation in occupations. We first examine whether gender
  segregation exists in different skills representations (bag of words, word2vec,
  and Bert) of occupations.
---

# Gender mobility in the labor market with skills-based matching models

## Quick Facts
- arXiv ID: 2307.08368
- Source URL: https://arxiv.org/abs/2307.08368
- Reference count: 5
- Primary result: Skills-based matching models propagate gender segregation, with BoW + cosine showing highest performance (AUC 0.94) but also highest gender segregation risk (GSR 0.72)

## Executive Summary
This work investigates how data-driven skills-based matching models affect gender segregation in occupations. The study examines whether gender segregation exists in different skills representations (bag of words, word2vec, and BERT) and measures the impact of these biases on matching outcomes using simulated data. Results show that all model combinations propagate gender segregation with positive correlations above 0.5, with the highest performance models showing the highest segregation risk. The BoW with cosine similarity performs best overall but carries the highest gender segregation risk, while BoW with metric learning offers the best trade-off between performance and segregation risk.

## Method Summary
The study uses O*NET skills descriptions to create vector representations of occupations using three methods: bag of words (BoW), averaged word2vec, and Sentence-BERT. For each representation, three similarity metrics are applied: Euclidean distance, cosine similarity, and metric learning. Simulated matching data is created by sampling skill subsets from occupations, with good matches being subsets of the same occupation and bad matches being subsets from different occupations. The study evaluates matching performance using AUC and measures gender segregation risk by computing the Pearson correlation between an occupation's female ratio and the average female ratio of its top-10 matching occupations.

## Key Results
- All model combinations show positive correlation above 0.5 between matching performance and gender segregation risk
- BoW + cosine achieves the highest AUC (0.94) but also highest GSR (0.72)
- BoW + metric learning has slightly lower AUC (0.90) but better GSR (0.60)
- Sentence-BERT shows consistent performance with higher GSR than BoW + metric learning
- Gender segregation is present in all three vectorization methods, with clear clustering by gender ratio

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Skills-based matching models propagate gender segregation because the vector representations of occupations capture gender bias from the underlying text data.
- Mechanism: When skills descriptions are embedded using language models (BoW, word2vec, BERT), the resulting vectors cluster occupations by gender distribution. Matching models trained on these vectors learn to associate certain skill profiles with gender-skewed occupations, reinforcing the original segregation.
- Core assumption: The language models used for embedding encode gender stereotypes present in historical text data about occupations.
- Evidence anchors:
  - [abstract] "we show the presence of gender segregation in language model-based skills representation of occupations"
  - [section] "For all three types of vectorizers, we see clusters of occupations according to their gender ratio... Sentence-BERT shows a cluster of male majority occupations on the middle right and a female majority occupations on top left."
  - [corpus] Corpus contains multiple papers on gender bias in LLMs for employment, indicating this is a known risk, but specific evidence for skill descriptions is not directly cited here.
- Break condition: If the embedding process is debiased or if gender-neutral skill descriptions are used, the clustering by gender would weaken or disappear.

### Mechanism 2
- Claim: The matching performance of skills-based models is correlated with their risk of propagating gender segregation.
- Mechanism: Models with higher AUC performance are better at identifying relevant skill matches, which means they are also better at preserving the gender patterns in the training data. Lower-performing models make random or less accurate suggestions, which may not align with gender patterns.
- Core assumption: The evaluation metric (AUC) for matching performance is positively correlated with how well the model preserves gender patterns in occupation suggestions.
- Evidence anchors:
  - [abstract] "We see a positive correlation of higher than 0.5 for all models, indicating that gender segregation is propagated by these models."
  - [section] "We see a positive correlation of higher than 0.5 for all models, indicating that gender segregation is propagated by these models. We also see that this risk is correlated with the performance of the model."
  - [corpus] Corpus shows studies on evaluating gender bias in LLMs, supporting the idea that bias can be measured in downstream tasks, but the specific correlation between matching performance and segregation risk is unique to this work.
- Break condition: If a model is explicitly trained to minimize gender segregation risk (e.g., through fairness constraints), the correlation could break, allowing high performance with low GSR.

### Mechanism 3
- Claim: Simulated matching data can approximate real-world gender segregation risks in skills-based matching.
- Mechanism: By sampling subsets of skills from occupations and labeling them as good/bad matches, the simulation creates a controlled environment to test how different vectorizers and distance metrics propagate gender bias without needing real-world matching data.
- Core assumption: The simulated matching process (sampling skills within/outside occupations) captures the essential dynamics of real-world skills matching.
- Evidence anchors:
  - [abstract] "Second, we measure the impact of biases in skills representation on gender segregation for the application of skills-based matching based on simulated data."
  - [section] "As skills-matching is not yet widespread and known initiatives protect their data for privacy reasons, this data is not available. For this reason, we gauge the potential impact of skills matching models on simulated matches of candidates and job openings based on skill profiles of O*net occupations."
  - [corpus] Corpus lacks direct evidence of simulated matching experiments in the context of gender segregation; this appears to be a novel methodological contribution.
- Break condition: If real-world matching data becomes available and shows significantly different patterns, the simulation's validity would be questioned.

## Foundational Learning

- Concept: Vector space representations of text (embeddings)
  - Why needed here: The study converts occupation skills descriptions into vectors using BoW, word2vec, and BERT, which are then used for matching. Understanding how these embeddings capture semantic and syntactic information is crucial to grasp why gender bias is preserved.
  - Quick check question: What is the main difference between BoW and word2vec in terms of how they represent words in a vector space?

- Concept: Bias measurement in machine learning
  - Why needed here: The paper measures Gender Segregation Risk (GSR) as the correlation between an occupation's female ratio and the average female ratio of top-matching occupations. Understanding how to quantify bias in ML outputs is essential for interpreting the results.
  - Quick check question: How is GSR calculated in this study, and what does a high GSR value indicate about a matching model?

- Concept: Supervised learning with metric learning
  - Why needed here: The study uses metric learning to learn a task-specific similarity measure from training data. Understanding how metric learning differs from static metrics like cosine or Euclidean distance is important for interpreting the performance results.
  - Quick check question: In the context of this study, how does metric learning differ from using cosine similarity for measuring the similarity between skill vectors?

## Architecture Onboarding

- Component map: O*NET skills descriptions → cleaned strings → vectorization (BoW/Word2Vec/Sentence-BERT) → similarity computation (Euclidean/Cosine/Metric Learning) → matching scores → AUC and GSR evaluation

- Critical path: 1. Preprocess O*NET skills descriptions into strings 2. Vectorize using chosen vectorizer 3. Compute pairwise matching scores using chosen metric 4. Rank occupations and compute AUC on test set 5. For GSR, compute top-10 matches per occupation and correlate with gender ratios

- Design tradeoffs:
  - BoW + cosine: Highest AUC (0.94) but also highest GSR (0.72) — best performance, highest risk
  - BoW + metric learning: Slightly lower AUC (0.90) but lower GSR (0.60) — good balance
  - Sentence-BERT: Consistent performance but higher GSR than BoW + metric learning

- Failure signatures:
  - High AUC but high GSR: Model is good at matching but reinforces gender segregation
  - Low AUC and low GSR: Model is poor at matching and does not reinforce segregation (random suggestions)
  - High GSR with any AUC: Model is capturing gender patterns strongly, regardless of matching quality

- First 3 experiments:
  1. Replicate the clustering analysis to visualize gender segregation in occupation vectors for each vectorizer.
  2. Compute AUC and GSR for each combination of vectorizer and metric on the simulated test set.
  3. Test debiasing interventions (e.g., gender-neutral preprocessing) to see if GSR decreases without hurting AUC.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do real-world data and applications compare to the simulated data in terms of gender segregation propagation in skills-based matching models?
- Basis in paper: [inferred] The paper uses simulated data to assess the impact of skills-based matching models on gender segregation, suggesting the need for validation with real data.
- Why unresolved: The paper acknowledges that real data is not available due to privacy reasons, and thus, the findings are based on simulated data which may not fully capture real-world complexities.
- What evidence would resolve it: Conducting studies with real-world data from actual skills-based matching applications would provide insights into how these models perform in practice and whether they propagate gender segregation similarly to the simulated scenarios.

### Open Question 2
- Question: How can the integration of additional diversity aspects, such as ethnicity and educational background, be effectively incorporated into skills-based matching models to mitigate gender segregation?
- Basis in paper: [explicit] The paper suggests that future research should include more diversity aspects such as ethnicity and educational background.
- Why unresolved: The current study focuses on gender segregation, and while it acknowledges the importance of other diversity aspects, it does not explore how these can be integrated into the models.
- What evidence would resolve it: Developing and testing skills-based matching models that incorporate multiple diversity dimensions would provide insights into their effectiveness in reducing gender segregation and promoting overall diversity.

### Open Question 3
- Question: What are the specific mechanisms through which language models interpret and represent skills formulations that lead to gender segregation, and how can these be addressed?
- Basis in paper: [inferred] The paper identifies the presence of gender segregation in language model-based skills representations but does not delve into the specific mechanisms or potential solutions.
- Why unresolved: While the study highlights the issue of gender segregation in language models, it does not explore the underlying causes or propose methods to address them.
- What evidence would resolve it: Investigating the linguistic and algorithmic factors that contribute to gender segregation in skills representations, followed by developing strategies to mitigate these biases, would help in understanding and addressing the issue.

## Limitations
- Use of simulated matching data rather than real-world skills-based job matching records
- Reliance on O*NET skills descriptions which may not comprehensively represent all job-relevant skills
- Limited scope focusing only on gender segregation without considering other diversity dimensions

## Confidence

- **High Confidence**: The existence of gender segregation in vector representations of occupations (Mechanism 1). This is directly observed through clustering analysis and supported by established literature on gender bias in language models.
- **Medium Confidence**: The positive correlation between matching performance and gender segregation risk (Mechanism 2). While the correlation is demonstrated empirically, the causal mechanism linking performance metrics to bias propagation could benefit from further investigation.
- **Medium Confidence**: The simulation approach adequately approximates real-world matching dynamics (Mechanism 3). The methodology is sound, but without real-world validation data, the extent to which simulations capture actual matching behavior remains uncertain.

## Next Checks

1. **Validate with Real-World Data**: When real skills-based matching data becomes available, replicate the analysis to compare simulation results with actual outcomes. This will help assess whether the simulated environment accurately captures real-world gender segregation propagation.

2. **Debiasing Intervention Testing**: Implement and test gender bias mitigation techniques (e.g., gender-neutral preprocessing, adversarial debiasing) on the skill representations to evaluate whether it's possible to reduce GSR without significantly compromising matching performance.

3. **Cross-Corpus Generalization**: Apply the same methodology to skills descriptions from different sources (e.g., job postings, resume data) to determine whether gender segregation patterns persist across different types of occupational skill data and whether findings generalize beyond O*NET.