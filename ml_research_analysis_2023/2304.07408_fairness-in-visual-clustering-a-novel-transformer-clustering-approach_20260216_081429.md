---
ver: rpa2
title: 'Fairness in Visual Clustering: A Novel Transformer Clustering Approach'
arxiv_id: '2304.07408'
source_url: https://arxiv.org/abs/2304.07408
tags:
- clustering
- fairness
- samples
- cluster
- transformer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses fairness in deep visual clustering, specifically
  mitigating demographic bias without relying on sensitive attribute annotations.
  The authors propose a novel transformer-based clustering framework that evaluates
  bias through cluster purity and introduces a fairness loss to encourage consistency
  of purity across clusters.
---

# Fairness in Visual Clustering: A Novel Transformer Clustering Approach

## Quick Facts
- arXiv ID: 2304.07408
- Source URL: https://arxiv.org/abs/2304.07408
- Reference count: 40
- Key outcome: Achieves 93.28% F-score and 2.47% std on BUPT-BalancedFace dataset, demonstrating state-of-the-art clustering accuracy and fairness

## Executive Summary
This paper addresses fairness in deep visual clustering without requiring sensitive attribute annotations. The authors propose a transformer-based clustering framework that evaluates bias through cluster purity and introduces a fairness loss to encourage consistency of purity across clusters. A key innovation is the Cross-attention mechanism that strengthens correlations between distant samples and improves the purity of underrepresented clusters. The method is evaluated on the BUPT-BalancedFace dataset across ethnicity, age, gender, and race attributes, showing significant improvements in both clustering accuracy and fairness compared to recent GCN and transformer baselines.

## Method Summary
The method uses a transformer-based clustering architecture called Intraformer that incorporates a novel Cross-attention mechanism and a clustering purity penalty loss. Features are first extracted using a pre-trained ResNet34 with ArcFace, then initial clusters are constructed using k-NN. The Intraformer architecture decomposes clusters into sub-clusters and applies attention mechanisms to strengthen correlations between distant samples. The model is trained using a combination of Fowlkes-Mallows loss for clustering accuracy and the clustering purity penalty loss for fairness, optimized with Adam using cosine annealing.

## Key Results
- Achieves 93.28% F-score and 2.47% std on BUPT-BalancedFace dataset
- Outperforms recent GCN and transformer baselines on both clustering accuracy and fairness metrics
- Demonstrates effectiveness particularly on highly imbalanced datasets
- Shows consistent improvements across ethnicity, age, gender, and race attributes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cluster purity is used as an indicator of demographic bias in unsupervised clustering
- Mechanism: The method measures purity as the ratio of true positive samples within a cluster to their correlation degree, with low purity indicating bias against minority groups
- Core assumption: Cluster purity correlates with fairness across demographic groups and can be used without access to sensitive attribute annotations
- Evidence anchors:
  - [abstract] "we first evaluate demographic bias in deep clustering models from the perspective of cluster purity, which is measured by the ratio of positive samples within a cluster to their correlation degree"
  - [section] "the cluster purity, i.e. ratio of the number of true positive samples within a predicted cluster" and "cluster purity plays an important role to measure clustering bias across demographic groups"

### Mechanism 2
- Claim: The proposed loss function encourages purity consistency across all clusters
- Mechanism: A fairness penalty loss is introduced that minimizes the discrepancy between each cluster's purity and a reference purity value
- Core assumption: Maintaining consistent purity across clusters reduces demographic bias without needing sensitive attribute annotations
- Evidence anchors:
  - [abstract] "a novel loss function is introduced to encourage a purity consistency for all clusters to maintain the fairness aspect"
  - [section] "by encouraging consistency of the purity aspect for all clusters, demographic bias can be effectively mitigated" and "We select γf = 1/B ∑B−1i γi as the average value of γi within a mini-batch"

### Mechanism 3
- Claim: The Cross-attention mechanism strengthens correlations between distant samples and improves cluster purity
- Mechanism: Cross-attention measures correlations between multiple clusters and helps faraway positive samples have stronger relationships with the centroid
- Core assumption: Strengthening correlations between distant samples improves the quality of underrepresented clusters
- Evidence anchors:
  - [abstract] "we present a novel attention mechanism, Cross-attention, to measure correlations between multiple clusters, strengthening faraway positive samples and improving the purity of clusters during the learning process"
  - [section] "we present a novel attention mechanism, termed Cross-attention, to measure correlations between multiple clusters and help faraway samples have a stronger relationship with the centroid"

## Foundational Learning

- Concept: Cluster purity and its relationship to fairness
  - Why needed here: Understanding purity is crucial for grasping how the method measures and mitigates demographic bias
  - Quick check question: How does the method define and use cluster purity as an indicator of demographic bias?

- Concept: Transformer-based architectures and attention mechanisms
  - Why needed here: The method uses a transformer-based approach with Cross-attention to improve clustering fairness
  - Quick check question: How does the Cross-attention mechanism differ from standard self-attention in transformers?

- Concept: Unsupervised clustering and its challenges
  - Why needed here: The method addresses fairness in unsupervised clustering without access to sensitive attribute annotations
  - Quick check question: What are the main challenges in achieving fairness in unsupervised clustering settings?

## Architecture Onboarding

- Component map: Feature extractor (ResNet34 with ArcFace) -> k-NN for initial cluster construction -> Intraformer architecture with Transformer and Cross Transformer blocks -> Fowlkes-Mallows Loss for clustering accuracy -> Clustering Purity Penalty Loss for fairness

- Critical path:
  1. Extract features using pre-trained model
  2. Construct initial clusters using k-NN
  3. Decompose clusters into sub-clusters
  4. Apply Intraformer architecture with attention mechanisms
  5. Optimize using combined loss function

- Design tradeoffs:
  - Using cluster purity as a proxy for fairness vs. direct access to sensitive attributes
  - Complexity of Cross-attention mechanism vs. potential performance gains
  - Balancing clustering accuracy and fairness in the loss function

- Failure signatures:
  - Poor clustering performance on minority groups despite high overall accuracy
  - Inability to converge on the fairness penalty loss
  - Degradation in clustering performance when enabling Cross-attention

- First 3 experiments:
  1. Baseline: Test clustering performance without fairness considerations
  2. Purity consistency: Evaluate the impact of the Clustering Purity Penalty Loss on fairness
  3. Cross-attention: Assess the effectiveness of the Cross-attention mechanism in improving cluster purity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the gap in performance between optimizing by Eqn (4) and by Eqn (6) be addressed in fairness-focused clustering?
- Basis in paper: [explicit] The paper explicitly states: "There is a gap in performance between optimizing by Eqn (6) and by Eqn (4). This problem is further investigated in future work."
- Why unresolved: The authors acknowledge this as a limitation but do not provide a solution or experimental validation.
- What evidence would resolve it: Experimental results comparing direct optimization of Eqn (4) versus the upper-bound approximation in Eqn (6), along with theoretical analysis of the approximation error.

### Open Question 2
- Question: Would the Cross-attention mechanism remain effective if extended to attention between non-adjacent sub-clusters in the Intraformer architecture?
- Basis in paper: [inferred] The current Cross-attention only measures correlations between the centroid sub-cluster and the furthest sub-cluster (Fk-1), but the paper suggests this is to reduce complexity while maintaining performance.
- Why unresolved: The authors did not experiment with or analyze attention mechanisms between other sub-cluster pairs.
- What evidence would resolve it: Empirical comparisons of different Cross-attention configurations (e.g., centroid-to-all, pairwise sub-cluster attention) on clustering accuracy and fairness metrics.

### Open Question 3
- Question: How does the proposed method perform on datasets with significantly different demographic distributions than BUPT-BalancedFace, such as real-world imbalanced data?
- Basis in paper: [inferred] While the method is tested on multiple configurations of BUPT datasets with varying levels of imbalance, all experiments use data from the same underlying distribution family.
- Why unresolved: The experiments focus on controlled synthetic imbalances rather than naturally occurring demographic skews in real-world applications.
- What evidence would resolve it: Performance evaluation on truly unbalanced real-world datasets (e.g., surveillance footage, social media data) with demographic attributes.

## Limitations
- Reliance on cluster purity as a proxy for fairness without ground-truth sensitive attribute annotations remains unproven across datasets
- The Cross-attention mechanism's architectural details are underspecified beyond conceptual description
- Performance claims on highly imbalanced datasets need validation on additional benchmark datasets

## Confidence
- **High confidence**: Core mechanism of using purity consistency to reduce bias is theoretically sound and methodologically coherent
- **Medium confidence**: Transformer architecture and Cross-attention improvements are plausible but implementation details are unclear
- **Low confidence**: Generalization to datasets beyond BUPT-BalancedFace without sensitive attribute annotations

## Next Checks
1. **Dataset generalization test**: Evaluate method on additional datasets with known demographic distributions (e.g., FairFace) to verify fairness improvements
2. **Ablation study**: Remove Cross-attention and purity penalty loss separately to quantify individual contributions to fairness gains
3. **Annotation-free validation**: Compare purity-based fairness metrics against ground-truth sensitive attribute analysis on a subset of data