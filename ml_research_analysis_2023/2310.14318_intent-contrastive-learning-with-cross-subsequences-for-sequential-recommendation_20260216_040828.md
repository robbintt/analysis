---
ver: rpa2
title: Intent Contrastive Learning with Cross Subsequences for Sequential Recommendation
arxiv_id: '2310.14318'
source_url: https://arxiv.org/abs/2310.14318
tags:
- learning
- intent
- icsrec
- sequential
- contrastive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of modeling users' latent intentions
  in sequential recommendation systems. Existing approaches rely on auxiliary information
  or stochastic data augmentation, which are often unavailable or introduce noise.
---

# Intent Contrastive Learning with Cross Subsequences for Sequential Recommendation

## Quick Facts
- arXiv ID: 2310.14318
- Source URL: https://arxiv.org/abs/2310.14318
- Reference count: 40
- Key outcome: ICSRec achieves up to 44.39% improvement in NDCG@5 and 37.30% improvement in NDCG@10 over state-of-the-art baselines.

## Executive Summary
The paper addresses the challenge of modeling users' latent intentions in sequential recommendation systems. Existing approaches rely on auxiliary information or stochastic data augmentation, which are often unavailable or introduce noise. The authors propose ICSRec, which segments user sequences into subsequences and assumes that subsequences with the same target item share the same intention. They introduce coarse-grain intent contrastive learning to bring these subsequences closer and fine-grain intent contrastive learning to capture context-specific intentions. Experiments on four real-world datasets demonstrate that ICSRec significantly outperforms state-of-the-art baselines.

## Method Summary
ICSRec uses dynamic sliding to segment sequences into subsequences, coarse-grain intent contrastive learning (CICL) to group same-target subsequences, fine-grain intent contrastive learning (FICL) with K-means clustering to refine intent prototypes, and multi-task learning with a SASRec backbone. The method requires preparing datasets by filtering users/items with fewer than 5 interactions, sorting interactions chronologically, and splitting into train/validation/test based on timestamps. The model is trained using Adam optimizer (lr=1e-3), batch size 256, and dropout rate tuned per dataset.

## Key Results
- ICSRec achieves up to 44.39% improvement in NDCG@5 over state-of-the-art baselines.
- ICSRec achieves up to 37.30% improvement in NDCG@10 over state-of-the-art baselines.
- The model demonstrates significant improvements across four real-world datasets.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Subsequences with the same target item encode similar user intentions.
- **Mechanism:** Dynamic sliding segmentation creates multiple subsequences per sequence. Those sharing the same final item are grouped, forming coarse-grained intent supervision.
- **Core assumption:** Different users may buy the same item for similar reasons at different times; intention is encoded in the item and its surrounding context.
- **Evidence anchors:** [abstract] "assumes different subsequences with the same target item may represent the same intention"
- **Break condition:** If item-level context is insufficient to disambiguate intention (e.g., "watch" could be gift vs decoration), coarse-grained signals become noisy.

### Mechanism 2
- **Claim:** Fine-grained intentions differ even for the same item in different contexts.
- **Mechanism:** Coarse-grained intent representations are clustered into K groups; the cluster center becomes a fine-grain intent prototype. Contrastive loss pulls subsequences toward their nearest prototype.
- **Core assumption:** Same item in different behavioral contexts maps to distinct latent intention clusters.
- **Evidence anchors:** [abstract] "intention to buy the same item in different contexts may be different"
- **Break condition:** If K is too small, distinct intentions collapse; if too large, noise increases.

### Mechanism 3
- **Claim:** False negatives in contrastive pairs degrade learning; masking them improves stability.
- **Mechanism:** Standard InfoNCE treats all other samples in batch as negatives. Here, FNM excludes pairs that share the same target item, preventing false negatives.
- **Core assumption:** Two subsequences with the same target item are not truly negative examples.
- **Evidence anchors:** [section 2.5] "we do not use InfoNCE directly... because treating other 2(|B|-1) views within the same batch as negative samples may introduce false negative problems"
- **Break condition:** If batch size is very large, probability of accidental same-target negatives rises, making masking critical.

## Foundational Learning

- **Concept:** Sequential recommendation models encode user behavior sequences into latent representations.
  - Why needed here: ICSRec builds upon SASRec's Transformer encoder to generate subsequence representations.
  - Quick check question: How does SASRec's self-attention differ from RNN-based sequential models?

- **Concept:** Contrastive learning pulls positive pairs together and pushes negatives apart in latent space.
  - Why needed here: Coarse- and fine-grain intent contrastive losses directly optimize intent representation alignment.
  - Quick check question: What is the role of the temperature parameter τ in contrastive loss?

- **Concept:** Clustering partitions latent representations into groups sharing structural similarity.
  - Why needed here: K-means clustering on coarse-grained intents produces fine-grain prototypes for contrastive learning.
  - Quick check question: Why might K-means be chosen over other clustering algorithms in this context?

## Architecture Onboarding

- **Component map:** Input: user sequence -> embedding layer -> SASRec encoder -> subsequence representations -> Coarse-grain contrastive module -> K-means clustering -> Fine-grain contrastive module -> final intent vector -> MLP -> next-item prediction.
- **Critical path:** Sequence segmentation -> coarse-grain contrastive learning -> clustering -> fine-grain contrastive learning -> prediction.
- **Design tradeoffs:**
  - Segmentation length (n) vs. context richness: longer subsequences retain more context but increase computational cost.
  - K (clusters) vs. granularity: too few clusters underfit; too many overfit.
  - λ and β weights: balance between coarse- and fine-grain objectives; incorrect weights degrade both intent modeling and recommendation accuracy.
- **Failure signatures:**
  - If contrastive losses dominate, model focuses on alignment over recommendation accuracy.
  - If K is too small, fine-grain contrastive loss becomes ineffective.
  - If segmentation window is too large, subsequences lose intra-intent diversity.
- **First 3 experiments:**
  1. Vary λ and β to find peak HR@20 on validation set; monitor trade-off between coarse/fine objectives.
  2. Sweep K from 64 to 1024; plot HR@20 vs. cluster count to find elbow point.
  3. Introduce controlled noise into subsequences; measure robustness via NDCG@20 drop rate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the model be adapted to handle more complex user intent patterns that involve multiple intentions within a single subsequence?
- Basis in paper: [explicit] The paper mentions that users may have multiple intentions for the same item in different contexts, but does not provide a detailed method for handling such cases.
- Why unresolved: The current model assumes a single intention per subsequence, which may not capture the complexity of user behavior in real-world scenarios.
- What evidence would resolve it: Experiments showing the model's performance on datasets with known multi-intent subsequences, and a comparison with baseline models that can handle such complexity.

### Open Question 2
- Question: What is the impact of the number of clusters (K) on the model's ability to capture fine-grain user intentions, and how does this parameter affect the overall performance?
- Basis in paper: [explicit] The paper discusses the use of K-means clustering to obtain fine-grain intent representations but does not explore the sensitivity of the model to the number of clusters.
- Why unresolved: The choice of K can significantly influence the model's ability to distinguish between different user intentions, and the paper does not provide guidance on selecting an optimal value.
- What evidence would resolve it: A comprehensive analysis of the model's performance across different values of K, along with an explanation of how K affects the model's ability to capture user intentions.

### Open Question 3
- Question: How does the model perform in scenarios where user intentions change rapidly over time, and what strategies can be employed to adapt to such dynamic changes?
- Basis in paper: [inferred] The paper focuses on modeling user intentions in sequential recommendation but does not address the challenge of rapidly changing intentions.
- Why unresolved: User intentions can be highly dynamic, and the model's ability to adapt to such changes is crucial for real-world applications.
- What evidence would resolve it: Experiments demonstrating the model's performance on datasets with rapidly changing user intentions, and an analysis of how the model can be adapted to handle such scenarios.

## Limitations
- The core assumption that subsequences sharing the same target item encode similar intentions may not hold in all recommendation scenarios.
- The effectiveness of K-means clustering for identifying fine-grain intentions depends heavily on the choice of K, which is not thoroughly analyzed.
- The paper lacks discussion of computational complexity and scalability to longer sequences or larger item catalogs.

## Confidence
- **High confidence**: The overall experimental methodology and evaluation framework are sound, with appropriate baselines and metrics.
- **Medium confidence**: The theoretical justification for coarse- and fine-grain contrastive learning mechanisms, though intuitive, lacks empirical validation through ablation studies.
- **Low confidence**: The assumption that intention can be reliably inferred from item-level context alone, without considering user demographics or item metadata.

## Next Checks
1. **Ablation Study on Segmentation Length**: Systematically vary the subsequence length parameter n and measure its impact on both coarse- and fine-grain intent learning performance, isolating the contribution of sequence context.
2. **Intent Ambiguity Analysis**: Create synthetic datasets where items have known multiple intentions (e.g., "buy a book" for self vs. gift) and measure how well ICSRec distinguishes these cases versus baselines.
3. **Clustering Sensitivity Test**: Perform grid search over K values and analyze the elbow point in performance curves to determine optimal clustering granularity and assess model sensitivity to this hyperparameter.