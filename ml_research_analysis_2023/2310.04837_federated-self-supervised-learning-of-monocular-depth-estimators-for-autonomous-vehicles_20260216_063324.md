---
ver: rpa2
title: Federated Self-Supervised Learning of Monocular Depth Estimators for Autonomous
  Vehicles
arxiv_id: '2310.04837'
source_url: https://arxiv.org/abs/2310.04837
tags:
- depth
- data
- learning
- training
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FedSCDepth, a novel method that combines
  federated learning and deep self-supervision to enable the learning of monocular
  depth estimators with comparable effectiveness and superior efficiency compared
  to the current state-of-the-art methods. The proposed method achieves near state-of-the-art
  performance on the KITTI dataset, with a test loss below 0.13 and requiring, on
  average, only 1.5k training steps and up to 0.415 GB of weight data transfer per
  autonomous vehicle on each round.
---

# Federated Self-Supervised Learning of Monocular Depth Estimators for Autonomous Vehicles

## Quick Facts
- arXiv ID: 2310.04837
- Source URL: https://arxiv.org/abs/2310.04837
- Authors: 
- Reference count: 40
- Key outcome: Combines federated learning and deep self-supervision to enable learning of monocular depth estimators with near-SoTA performance while reducing communication and computation costs

## Executive Summary
This paper introduces FedSCDepth, a novel method that combines federated learning and deep self-supervision to enable the learning of monocular depth estimators with comparable effectiveness and superior efficiency compared to the current state-of-the-art methods. The proposed method achieves near state-of-the-art performance on the KITTI dataset, with a test loss below 0.13 and requiring, on average, only 1.5k training steps and up to 0.415 GB of weight data transfer per autonomous vehicle on each round. The results demonstrate that FedSCDepth can achieve near-SoTA performance with a low computation cost per vehicle and a lower communication cost per round per vehicle than centralized training.

## Method Summary
FedSCDepth combines federated learning with self-supervised monocular depth estimation. Each autonomous vehicle trains a local DepthNet (U-Net with ResNet18 backbone) and PoseNet (ResNet18 modified for 6-DoF pose prediction) on its own unlabeled data using geometric consistency between consecutive frames as supervision. A pre-trained PseudoDepthNet generates single-image depth priors that provide additional regularization through multiple loss functions including confident depth ranking loss, normal matching loss, and edge-aware relative normal loss. Model updates are aggregated using FedAvg at a central server. The method is evaluated on the KITTI dataset with non-IID data distributions, showing robustness while achieving competitive depth estimation accuracy with reduced communication and computation costs compared to centralized training.

## Key Results
- Achieves near state-of-the-art performance on KITTI with test loss below 0.13
- Requires only 1.5k training steps on average per vehicle per round
- Communication cost of up to 0.415 GB of weight data transfer per vehicle per round
- Demonstrates robustness to non-IID data distributions using simple FedAvg aggregation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining federated learning with self-supervised monocular depth estimation allows models to achieve near-SoTA performance while reducing per-vehicle communication and computation costs.
- Mechanism: Federated learning enables each autonomous vehicle to train on its local unlabeled data without sharing raw data. The model updates are aggregated using FedAvg, producing a global model that is iteratively improved. Self-supervised learning leverages geometric consistency between consecutive frames to generate pseudo-labels, eliminating the need for ground truth depth data. This combination preserves privacy, reduces bandwidth usage, and enables learning from diverse, non-IID data distributions typical in autonomous driving scenarios.
- Core assumption: The geometric consistency assumption holds across diverse driving conditions, and the FedAvg aggregation is robust enough to handle non-IID data without performance degradation.
- Evidence anchors:
  - [abstract]: "combines federated learning and deep self-supervision to enable the learning of monocular depth estimators with comparable effectiveness and superior efficiency compared to the current state-of-the-art methods."
  - [section]: "The utilization of federated learning offers notable benefits, including enhanced privacy protection, reduced network consumption, and improved resilience to connectivity issues."
  - [corpus]: Weak; related papers focus on monocular depth estimation but do not explicitly validate federated/self-supervised combinations on autonomous vehicle datasets.
- Break condition: If the geometric consistency assumption fails (e.g., in highly dynamic scenes with many moving objects), the self-supervision signal weakens, leading to degraded model performance. If data heterogeneity is too extreme, FedAvg may fail to converge to a useful global model.

### Mechanism 2
- Claim: Using pre-trained models to generate pseudo-depth priors boosts the self-supervised learning signal, improving depth estimation accuracy.
- Mechanism: A pre-trained monocular depth estimation network (PseudoDepthNet) generates single-image depth priors. These pseudo-depth maps are used to compute additional loss terms (Confident Depth Ranking Loss, normal matching loss, edge-aware relative normal loss) that regularize the training of the main DepthNet and PoseNet. This provides stronger supervisory signals than photometric loss alone, especially in low-texture or homogeneous regions.
- Core assumption: The pre-trained model's pseudo-depth maps are sufficiently accurate to provide meaningful gradients during training.
- Evidence anchors:
  - [section]: "we leverage a pre-trained MDE network (PseudoDepthNet) to generate pseudo-depth... the signals produced by the PseudoDetphNet are used to compute additional losses that help regularize the SSL."
  - [corpus]: Weak; while pseudo-labeling is common in self-supervised learning, the specific use of pre-trained depth models as priors in federated settings is not well-documented in the corpus.
- Break condition: If the pre-trained model is biased or inaccurate for the target domain (e.g., different sensor characteristics or environments), the pseudo-depth priors may mislead training, causing the model to converge to suboptimal solutions.

### Mechanism 3
- Claim: The proposed method is robust to non-IID data distributions, which are inherent in real-world autonomous vehicle deployments.
- Mechanism: Federated training with non-IID data (distributed by drive, reflecting natural data imbalance) still achieves comparable performance to IID scenarios. This is because the self-supervised loss functions are based on geometric consistency, which is generally valid across different driving environments. Additionally, the random selection of participants per round ensures that the global model is exposed to a diverse set of local updates over time.
- Core assumption: The geometric consistency assumption and the self-supervised loss functions are sufficiently general to handle the diversity in non-IID data.
- Evidence anchors:
  - [abstract]: "the experimental results indicate that the proposed method is robust to Non-IID data, even using simple FedAvg aggregation."
  - [section]: "we find that the proposed method showed robustness to the data heterogeneity inherent to the data collection, obtaining the lowest VL with NIID data (about3% lower than the lowest VL with IID data)."
  - [corpus]: Weak; while some federated learning works address non-IID data, few focus on self-supervised depth estimation in autonomous vehicle contexts.
- Break condition: If the non-IID data is too extreme (e.g., some participants have only night-time data while others have only day-time), the global model may struggle to generalize, leading to degraded performance.

## Foundational Learning

- Concept: Monocular depth estimation and self-supervised learning
  - Why needed here: The method relies on predicting depth maps from single images without ground truth labels, using geometric consistency between consecutive frames as a supervisory signal.
  - Quick check question: What is the primary geometric assumption used in self-supervised monocular depth estimation to generate pseudo-labels?

- Concept: Federated learning and FedAvg aggregation
  - Why needed here: The method distributes the training process across multiple autonomous vehicles, each with its own local dataset, and aggregates model updates to produce a global model without sharing raw data.
  - Quick check question: How does FedAvg aggregation handle the updates from participants with different amounts of training data?

- Concept: Non-IID data and its impact on federated learning
  - Why needed here: Real-world autonomous vehicle datasets are often non-IID due to variations in driving environments, times of day, and sensor characteristics. The method must be robust to these variations.
  - Quick check question: What are the potential challenges of training a model on non-IID data in a federated learning setting, and how might they be mitigated?

## Architecture Onboarding

- Component map:
  - DepthNet -> PoseNet -> PseudoDepthNet -> FedAvg Aggregator
  - DepthNet: U-Net architecture with ResNet18 backbone for predicting depth maps
  - PoseNet: ResNet18 modified to predict 6-DoF relative pose between consecutive frames
  - PseudoDepthNet: Pre-trained model for generating single-image depth priors
  - FedAvg Aggregator: Central server that averages model updates from participants
  - Self-Supervised Loss: Combination of photometric loss, mask-weighted photometric loss, edge-aware smoothness loss, depth inconsistency loss, confident depth ranking loss, normal matching loss, and edge-aware relative normal loss

- Critical path:
  1. Initialize global DepthNet and PoseNet models
  2. Distribute models to selected participants
  3. Each participant performs self-supervised training on local data
  4. Participants upload model updates to aggregator
  5. Aggregator computes FedAvg to produce new global models
  6. Repeat until convergence or maximum rounds reached

- Design tradeoffs:
  - Using a pre-trained PseudoDepthNet provides stronger supervisory signals but may introduce bias if the pre-trained model is not well-suited to the target domain
  - Random participant selection in each round ensures diversity but may slow down convergence compared to always selecting the same participants
  - Using FedAvg is simple and communication-efficient but may not be optimal for highly non-IID data; more advanced aggregation methods could be explored

- Failure signatures:
  - Degraded depth estimation accuracy on specific environments (e.g., night-time, rain) may indicate that the pre-trained PseudoDepthNet is not well-suited to those conditions
  - Slow convergence or unstable training may indicate that the non-IID data is too extreme for FedAvg to handle effectively
  - High communication costs per round may indicate that the model size is too large or that the number of selected participants per round is too high

- First 3 experiments:
  1. Train the model on a small, balanced subset of the KITTI dataset with IID data distribution to verify that the basic self-supervised learning pipeline works correctly
  2. Introduce non-IID data distribution (e.g., by drive) and verify that the model still converges and achieves reasonable performance
  3. Measure the communication and computation costs per round and per participant to ensure they are within acceptable limits for autonomous vehicle deployment

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does FedSCDepth maintain its performance advantage over centralized training when applied to larger-scale autonomous vehicle datasets with more participants?
- Basis in paper: [explicit] The paper notes FedSCDepth shows promise but was only tested on the KITTI dataset with 34 participants. The authors suggest future work should explore larger datasets.
- Why unresolved: The evaluation was limited to a relatively small dataset and number of participants. Real-world autonomous vehicle deployments would involve thousands of vehicles generating massive amounts of data.
- What evidence would resolve it: Running FedSCDepth on larger datasets like nuScenes or Waymo Open Dataset with hundreds or thousands of participants would demonstrate if the efficiency gains scale.

### Open Question 2
- Question: How does FedSCDepth's performance degrade when the autonomous vehicle data is highly heterogeneous across different environments (urban vs rural vs highway)?
- Basis in paper: [inferred] The paper tested Non-IID scenarios by redistributing samples based on drives, but this doesn't capture the full heterogeneity of real-world driving environments that could affect depth estimation.
- Why unresolved: The evaluation scenarios didn't fully represent the environmental heterogeneity that autonomous vehicles encounter, which could significantly impact model performance.
- What evidence would resolve it: Testing FedSCDepth on datasets containing diverse environments and measuring performance degradation across different driving conditions would provide this insight.

### Open Question 3
- Question: Can FedSCDepth be extended to multi-modal depth estimation that incorporates additional sensor data beyond monocular images?
- Basis in paper: [explicit] The authors mention this as future work, noting that exploring multi-modal depth estimation with additional sensors could be valuable.
- Why unresolved: The current implementation only uses monocular images, while real autonomous vehicles typically have access to multiple sensor types that could improve depth estimation.
- What evidence would resolve it: Implementing FedSCDepth to incorporate additional sensor modalities like LiDAR or radar data and comparing performance would answer this question.

## Limitations
- Limited validation on diverse datasets beyond KITTI
- Sensitivity to pre-trained model quality and domain alignment
- Scalability to large-scale deployments with hundreds or thousands of vehicles remains untested

## Confidence
- **High**: The method's effectiveness in reducing communication and computation costs compared to centralized training
- **Medium**: The robustness to non-IID data distributions, based on the experimental results on the KITTI dataset
- **Low**: The generalizability to other autonomous vehicle datasets and sensor configurations

## Next Checks
1. Evaluate the FedSCDepth method on other autonomous vehicle datasets (e.g., nuScenes, Waymo) to assess its generalizability and robustness to different sensor configurations and driving environments
2. Conduct a sensitivity analysis of the method to the quality and domain alignment of the pre-trained PseudoDepthNet, to understand its impact on the self-supervised learning process and final performance
3. Scale up the experimental setup to simulate larger-scale deployments with hundreds or thousands of autonomous vehicles, and evaluate the method's performance and efficiency in this setting