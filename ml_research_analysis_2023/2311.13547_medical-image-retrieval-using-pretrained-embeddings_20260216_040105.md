---
ver: rpa2
title: Medical Image Retrieval Using Pretrained Embeddings
arxiv_id: '2311.13547'
source_url: https://arxiv.org/abs/2311.13547
tags:
- dinov1
- dreamsim
- resnet50
- image
- dinov2
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrated that pretrained embeddings from self-supervised
  models (DINOv1, DINOv2, DreamSim) and supervised models (Swin Transformer, ResNet50)
  can be used for medical image retrieval at modality, body region, and organ levels
  without additional fine-tuning. The proposed method leverages spatial redundancy
  in medical volumes by aggregating 2D slice embeddings using weighting and subsampling
  strategies.
---

# Medical Image Retrieval Using Pretrained Embeddings

## Quick Facts
- arXiv ID: 2311.13547
- Source URL: https://arxiv.org/abs/2311.13547
- Authors: 
- Reference count: 22
- Key outcome: Pretrained embeddings from self-supervised and supervised models enable medical image retrieval without fine-tuning, achieving perfect recall for modality and multiple body regions

## Executive Summary
This study demonstrates that pretrained embeddings from self-supervised models (DINOv1, DINOv2, DreamSim) and supervised models (Swin Transformer, ResNet50) can effectively retrieve medical images at modality, body region, and organ levels without additional training. The approach leverages spatial redundancy in medical volumes by aggregating 2D slice embeddings using weighting and subsampling strategies. Using LSH or HNSW indexing, the method achieves perfect recall (1.0) for modality and multiple body regions, with strong performance on organ-level retrieval for certain anatomical structures.

## Method Summary
The method processes 3D medical volumes by extracting 2D slices, generating embeddings using five pretrained models, and aggregating these embeddings through various strategies including using all slices, Gaussian-weighted slices, or subsampled slices. The aggregated embeddings are indexed using either LSH or HNSW approaches in a FAISS vector database. Retrieval is performed by querying with new volumes, extracting their embeddings, and finding nearest neighbors in the index. The approach requires no fine-tuning of the pretrained models, relying instead on their general visual representations learned from natural images.

## Key Results
- Perfect recall (1.0) for modality and body regions (Head, Pelvis) across all model/index combinations
- Strong performance on Abdomen and Chest regions with recall > 0.9
- High organ-level recall for Brain, Hippocampus, Heart, and Prostate
- Self-supervised models trained on natural images performed on par with or better than domain-specific supervised models

## Why This Works (Mechanism)

### Mechanism 1
Pretrained embeddings from self-supervised models trained on natural images can achieve effective medical image retrieval without fine-tuning because the self-supervised models learn general visual representations that transfer to medical image modalities, capturing modality, body region, and organ level distinctions. Core assumption: Visual representations learned from natural images contain transferable features that generalize to medical imaging contexts. Evidence anchors: Perfect recall for modality and body regions; performance on par with supervised models. Break condition: If medical images contain domain-specific features not present in natural images that are crucial for retrieval accuracy.

### Mechanism 2
Aggregating 2D slice embeddings with weighting and subsampling strategies effectively incorporates 3D information for volume retrieval because spatial redundancy in medical volumes allows subsampling slices without significant information loss, while Gaussian weighting emphasizes informative center slices over border slices. Core assumption: Medical volumes exhibit sufficient spatial redundancy that subsampling maintains retrieval performance. Evidence anchors: Sampling scenarios perform on par with using all slices; Gaussian weighting improves discrimination for some regions. Break condition: If subsampling removes critical discriminative information between similar anatomical structures.

### Mechanism 3
LSH and HNSW indexing approaches provide efficient vector similarity search for medical image retrieval at scale because vector database indexing converts high-dimensional embeddings into searchable structures, with HNSW offering faster search for larger datasets. Core assumption: Vector similarity search with appropriate indexing can handle the scale and dimensionality of medical image embeddings efficiently. Evidence anchors: Both indexing methods perform on par; HNSW is significantly faster. Break condition: If indexing structures become inefficient at extreme scales or with very high-dimensional embeddings.

## Foundational Learning

- **Vector similarity search and indexing (LSH, HNSW)**: The system relies on efficient comparison of high-dimensional embeddings to find similar medical images. Quick check: What is the primary difference between LSH and HNSW indexing approaches?

- **Self-supervised learning and transfer learning**: The pretrained models were trained on natural images without labels and then applied to medical image retrieval without fine-tuning. Quick check: How does self-supervised pretraining on natural images enable effective medical image retrieval?

- **3D volume processing from 2D slice embeddings**: Medical images are 3D volumes, but the employed networks take 2D images, requiring aggregation strategies. Quick check: What aggregation strategy combines 2D slice embeddings into a meaningful 3D volume representation?

## Architecture Onboarding

- **Component map**: Volume → Slice extraction → Embedding generation → Aggregation → Indexing → Search → Retrieval
- **Critical path**: Volume → Slice extraction → Embedding generation → Aggregation → Indexing → Search → Retrieval
- **Design tradeoffs**: Using all slices vs. subsampling: All slices capture complete information but increase computational cost; subsampling reduces cost with minimal performance loss due to spatial redundancy. LSH vs. HNSW indexing: LSH provides approximate nearest neighbor search; HNSW offers faster exact search but may have higher memory requirements. Gaussian weighting: Improves discrimination for some regions but may hurt performance for others (e.g., Chest region with lung slices farther from center)
- **Failure signatures**: Low recall for specific body regions: May indicate insufficient discriminative features in embeddings or inadequate aggregation strategy. High precision but low recall: May indicate embeddings are too specific, missing similar cases. Poor organ-level performance: May indicate label noise or insufficient organ-specific features in embeddings
- **First 3 experiments**: 1) Test retrieval performance using all slices with no weighting for each model and indexing approach to establish baseline performance. 2) Compare random sampling (5, 10, 20 slices) against using all slices to quantify the impact of spatial redundancy. 3) Implement and test Gaussian weighting on center slices to evaluate improvement for regions with mixed slice content (Abdomen/Chest)

## Open Questions the Paper Calls Out

### Open Question 1
How do the pretrained embeddings perform on medical image retrieval tasks when the training data distribution differs significantly from the target medical domain (e.g., different imaging protocols, contrast agents, or pathologies)? The study used MSD dataset with standardized protocols, but medical imaging involves diverse protocols and contrast agents not represented in the dataset. Testing the same approach on datasets with varied imaging protocols, contrast agents, and pathology distributions would reveal domain adaptation capabilities.

### Open Question 2
Would incorporating anatomical position information or slice-level labels improve organ-level retrieval performance compared to using volume-level organ labels? The authors noted that organ-level labels were derived from MSD tasks where "for each volume only single organs are labeled" and acknowledged that "multiple organs are visible in the images which occurs frequently." Evaluating retrieval performance using detailed slice-level anatomical annotations or multi-label organ assignments would demonstrate the impact of richer spatial information.

### Open Question 3
How do the computational costs and retrieval latency compare between LSH and HNSW indexing approaches across different dataset sizes and embedding dimensions? The authors noted that "HNSW is significantly faster" and recommended it, but only compared performance on a single dataset. Benchmarking both indexing methods across multiple dataset sizes and embedding dimensions while measuring query latency and memory usage would quantify the practical trade-offs.

### Open Question 4
Would combining multiple pretrained embeddings (ensemble methods) improve retrieval performance compared to using individual embeddings? The study compared five different embeddings but didn't explore ensemble approaches or feature fusion strategies. Testing weighted combinations or concatenation of embeddings from different models and comparing retrieval metrics would reveal potential performance gains from model fusion.

## Limitations
- Mixed organ-level results due to single-organ labeling limitations in MSD dataset
- No direct comparison with medical-specific pretrained models to validate transfer learning claims
- Gaussian weighting may hurt performance for regions with mixed slice content (e.g., Chest)

## Confidence

- **High confidence**: Pretrained embeddings enable effective medical image retrieval without fine-tuning; Subsampling maintains retrieval performance due to spatial redundancy
- **Medium confidence**: LSH and HNSW indexing are equally effective; Gaussian weighting improves discrimination for some regions
- **Low confidence**: Self-supervised models match or exceed supervised models; Subsampling strategy works across all anatomical structures

## Next Checks

1. Compare retrieval performance using medical-specific pretrained models (e.g., Med-ImageCLIP) against the natural image pretrained models to validate the transfer learning claim.

2. Test the subsampling strategy on datasets with high anatomical variability to assess whether spatial redundancy assumptions hold across different imaging contexts.

3. Evaluate the impact of different Gaussian weighting parameters (mean, standard deviation) on organ-level retrieval performance, particularly for regions with mixed slice content.