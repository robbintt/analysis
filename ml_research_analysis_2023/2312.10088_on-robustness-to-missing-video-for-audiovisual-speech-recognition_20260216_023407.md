---
ver: rpa2
title: On Robustness to Missing Video for Audiovisual Speech Recognition
arxiv_id: '2312.10088'
source_url: https://arxiv.org/abs/2312.10088
tags:
- conformer
- cascade
- dropout
- frames
- lstm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a mathematical framework to define and evaluate
  robustness to missing video for audiovisual speech recognition models. The key idea
  is to ensure that performance monotonically improves as more video information is
  added, and that models never perform worse than audio-only baselines when video
  is absent.
---

# On Robustness to Missing Video for Audiovisual Speech Recognition

## Quick Facts
- arXiv ID: 2312.10088
- Source URL: https://arxiv.org/abs/2312.10088
- Authors: 
- Reference count: 40
- Key outcome: A cascaded architecture achieves robustness to missing video by routing inputs through audio or audiovisual encoders, ensuring performance never degrades below audio-only baselines when video is absent.

## Executive Summary
This paper addresses the challenge of ensuring audiovisual speech recognition (AVSR) models maintain performance when video information is partially or completely missing. The authors propose a mathematical framework based on partial order theory to rigorously define and evaluate robustness to missing video. They demonstrate that while dropout-based methods fail to achieve robustness in certain settings, a cascaded architecture that explicitly routes inputs through audio-only or audiovisual encoders depending on video availability consistently maintains performance across diverse architectures and test conditions.

## Method Summary
The authors propose a cascaded architecture that routes inputs through either an audio encoder (AM) or an audiovisual encoder (AVM) based on video availability. During training, inputs are stochastically routed to simulate different video availability scenarios. The model uses RNN-T loss with conformer or LSTM encoders, trained on 100,000 hours of YouTube data. The approach is evaluated against dropout-based methods using Word Error Rate (WER) across multiple test conditions including frame-level and utterance-level video dropping, as well as varying noise levels.

## Key Results
- Cascaded models achieve robust performance, never performing worse than audio-only baselines when video is missing
- Dropout-based methods fail to achieve robustness with certain architectures (LSTM, conformer-CM) but work with conformer-CT
- The cascaded approach provides architecture-agnostic robustness, unlike dropout which shows architecture-specific behavior

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A cascaded model can achieve robustness by routing inputs through audio or audiovisual encoders depending on video availability.
- Mechanism: The cascade architecture explicitly disentangles audio-only and audiovisual representations. When video is missing, inputs are routed to the audio encoder, ensuring performance never drops below the audio-only baseline. When video is present, the audiovisual encoder can leverage both modalities for improved performance.
- Core assumption: The cascaded architecture can learn to switch between audio-only and audiovisual representations without catastrophic forgetting.
- Evidence anchors:
  - [abstract]: "Unlike dropout-based methods which fail in certain settings, an architecture-agnostic solution based on cascades can consistently achieve robustness to missing video."
  - [section 3.2]: "Unlike dropout, cascades use the AVM if and only if the video is present, thus explicitly disentangling the A V from the AO representations."
  - [corpus]: Weak - No direct corpus evidence for this specific cascade mechanism, though related work on mixture-of-experts suggests similar routing concepts.
- Break condition: If the cascaded model cannot learn to properly route inputs or suffers from catastrophic forgetting, the robustness guarantee fails.

### Mechanism 2
- Claim: Dropout fails to achieve robustness in certain settings because it doesn't guarantee explicit disentanglement of audio-only and audiovisual representations.
- Mechanism: Dropout randomly drops video frames or utterances during training, creating an implicit ensemble. However, this doesn't ensure the model learns separate representations for audio-only and audiovisual cases, leading to performance degradation when video is missing.
- Core assumption: The implicit ensemble created by dropout is insufficient for learning robust representations when video is partially or entirely missing.
- Evidence anchors:
  - [abstract]: "Dropout-based methods... fail in certain settings."
  - [section 3.1]: "Training on a mixture of A V and AO inputs does not guarantee that the architecture is able to automatically disentangle the A V and AO representations."
  - [corpus]: Weak - No direct corpus evidence, though the cited paper on dropout-induced modality bias suggests similar limitations.
- Break condition: If dropout unexpectedly learns to disentangle representations in a specific architecture, it could achieve robustness where expected to fail.

### Mechanism 3
- Claim: The asymmetry of the problem (only robustness to missing video is needed, not missing audio) enables a simpler solution than general missing modality handling.
- Mechanism: Since audio is indispensable, the cascaded model only needs to ensure performance doesn't degrade below the audio-only baseline when video is missing. This simplifies the architecture compared to handling arbitrary missing modalities.
- Core assumption: The asymmetry allows for a specialized solution rather than a general missing modality approach.
- Evidence anchors:
  - [abstract]: "This is because state-of-the-art lip-reading models still are not performant enough for many practical ASR applications, which makes only the audio, and not video, indispensable."
  - [section 1]: "Fortunately, the asymmetry of our problem... presents a unique opportunity."
  - [corpus]: Weak - No direct corpus evidence, though the cited paper on missingness-resilient multimodal detection suggests similar asymmetric approaches.
- Break condition: If audio becomes dispensable in future applications, this specialized approach would need to be re-evaluated.

## Foundational Learning

- Concept: Partial order theory for comparing model performance across different test conditions
  - Why needed here: Allows rigorous mathematical framework for defining robustness by comparing performance when varying amounts of video information are present
  - Quick check question: Can you explain why comparing WERs under different video availability conditions requires a partial order rather than simple numerical comparison?

- Concept: Stochastically routing inputs during training to achieve robustness without two-pass training
  - Why needed here: Enables efficient training of cascaded models that are robust to missing video without requiring separate training passes for audio-only and audiovisual components
  - Quick check question: How does stochastic routing during training ensure the cascaded model maintains performance when video is missing?

- Concept: Frame-level vs utterance-level video dropping
  - Why needed here: Different test scenarios require understanding how missing video at different granularities (individual frames vs entire utterances) affects model performance
  - Quick check question: What's the key difference between frame-level and utterance-level video dropping in terms of model robustness?

## Architecture Onboarding

- Component map: Input -> Routing Logic -> (Audio Encoder or Audiovisual Encoder) -> Fusion (if AV path) -> Shared Decoder -> Output

- Critical path:
  1. Input routing decision (video present or missing)
  2. Processing through appropriate encoder (AM or AVM)
  3. Feature fusion (if audiovisual path)
  4. Decoder processing
  5. Output generation

- Design tradeoffs:
  - Single encoder with dropout vs cascaded architecture
  - Frame-level vs utterance-level video dropping
  - Concatenation vs attention-based fusion
  - Training with two passes vs stochastic routing

- Failure signatures:
  - Performance degradation when video is missing (violates robustness)
  - No improvement when video is present (wasted capacity)
  - Training instability or convergence issues

- First 3 experiments:
  1. Compare cascaded vs vanilla models on TberUtt with varying video drop rates
  2. Test frame-level vs utterance-level video dropping on a single architecture
  3. Compare concatenation vs attention-based fusion in cascaded models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does dropout perform well with conformer-CAT architecture but fail with LSTM and conformer-CM architectures for robustness to missing video?
- Basis in paper: [explicit] The paper shows that dropout fails for LSTMs (Makino et al., 2019) and feedforward sequential memory networks (Zhang et al., 2019), but works for conformers in the study. It states: "Unlike prior architectures in the literature, conformers can attain robustness with the use of dropout."
- Why unresolved: The paper notes this is a "fortuitous and notable empirical finding" but does not explain the underlying reasons why dropout succeeds with conformers but not other architectures.
- What evidence would resolve it: Systematic ablation studies comparing dropout's effect on different architectural components (attention mechanisms, convolution layers, normalization layers) across architectures would reveal which architectural features enable dropout to work for robustness.

### Open Question 2
- Question: What is the optimal number of layers for the cascaded audiovisual model (AM+AVM) to achieve robustness without sacrificing performance?
- Basis in paper: [explicit] The paper finds that a 17-layer AM cascaded with an 8-layer AVM performs equivalently to a 25-layer vanilla AVM on full A V data, suggesting capacity can be optimized. However, it doesn't explore whether fewer layers could achieve the same robustness.
- Why unresolved: The study only tests one specific configuration (17+8) and doesn't systematically vary the layer counts to find optimal configurations.
- What evidence would resolve it: Empirical comparison of cascaded models with different layer combinations (e.g., 12+6, 10+5, 8+4) would identify the minimum architecture needed for robustness.

### Open Question 3
- Question: How do different audiovisual fusion methods (concatenation vs cross-modal attention) affect robustness to missing video?
- Basis in paper: [explicit] The paper tests both concatenation (CAT) and cross-modal attention (CM) fusion methods, finding that dropout catastrophically fails with CM but works with CAT for conformers.
- Why unresolved: While the paper shows this difference, it doesn't investigate why the fusion method impacts dropout's effectiveness or whether other fusion approaches might work better.
- What evidence would resolve it: Comparative studies of dropout's behavior with various fusion mechanisms (including transformer-based attention, gating mechanisms, or learnable routing) would reveal which architectural choices enable robustness.

## Limitations

- The cascaded architecture achieves robustness to missing video, but several critical limitations remain unclear. The evaluation primarily focuses on a single cascaded architecture with dropout at 0.5, making it uncertain whether these results generalize to different cascade configurations or dropout rates.
- While the paper demonstrates robustness across multiple test conditions, the underlying mechanisms explaining why certain architectures (like CM) fail with dropout while others (like CT) succeed are not fully elucidated.
- The paper also lacks exploration of whether the cascade routing could be learned end-to-end rather than being hand-designed, which could impact scalability and adaptability to new architectures.

## Confidence

- **High Confidence**: The core claim that cascaded architectures achieve robustness while dropout-based methods fail in certain settings is well-supported by extensive experiments across three architectures (AM, CM, CT) and multiple test conditions.
- **Medium Confidence**: The mechanism explaining why dropout fails to achieve robustness is plausible but relies on the assumption that dropout cannot learn explicit disentanglement of audio-only and audiovisual representations.
- **Low Confidence**: The claim that asymmetry (only needing robustness to missing video, not audio) uniquely enables the cascaded solution is based on logical reasoning but lacks empirical validation through direct comparison with symmetric approaches.

## Next Checks

1. **Architecture-Specific Dropout Analysis**: Systematically vary dropout rates (0.1, 0.3, 0.5, 0.7) across all three architectures (AM, CM, CT) to identify precise failure points and determine if certain architectures can achieve robustness with optimized dropout configurations.

2. **End-to-End Cascade Routing**: Replace the hand-designed cascade routing with a learned routing mechanism that predicts whether to use audio-only or audiovisual paths based on input characteristics, then compare robustness against the hand-designed cascade.

3. **Symmetric vs Asymmetric Approaches**: Implement a general missing modality approach that handles both audio and video dropping, then compare its performance and robustness against the asymmetric cascaded solution to validate whether the asymmetry truly provides unique advantages.