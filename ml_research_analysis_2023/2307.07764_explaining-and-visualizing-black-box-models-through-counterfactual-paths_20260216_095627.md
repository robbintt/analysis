---
ver: rpa2
title: Explaining and visualizing black-box models through counterfactual paths
arxiv_id: '2307.07764'
source_url: https://arxiv.org/abs/2307.07764
tags:
- counterfactual
- paths
- feature
- cpath
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes CPATH, a novel explainable AI method that generates
  counterfactual explanations by identifying sequential permutations of features that
  most influence changes in model predictions. The algorithm measures feature importance
  through counterfactual paths, which are sequences of features that, when permuted,
  lead to substantial changes in model predictions.
---

# Explaining and visualizing black-box models through counterfactual paths

## Quick Facts
- arXiv ID: 2307.07764
- Source URL: https://arxiv.org/abs/2307.07764
- Reference count: 0
- Primary result: CPATH generates counterfactual explanations through sequential feature permutations, outperforming SHAP and LIME particularly for conditional feature dependencies

## Executive Summary
CPATH is a novel explainable AI method that generates counterfactual explanations by identifying sequential permutations of features that most influence changes in model predictions. The algorithm measures feature importance through counterfactual paths, which are sequences of features that, when permuted, lead to substantial changes in model predictions. Experiments with synthetic and medical data demonstrate that CPATH provides more accurate and interpretable explanations compared to existing methods like SHAP and LIME, particularly in cases of conditional feature dependency. The method is especially suitable for generating explanations based on counterfactual paths in knowledge graphs, providing a more intuitive and interpretable explanation for the model's behavior than traditional feature weighting methods.

## Method Summary
CPATH is an explainable AI method that generates counterfactual explanations by sampling random paths through features and permuting them sequentially until a threshold of label swaps occurs. The algorithm builds a transition matrix from observed counterfactual paths and calculates feature importance using either adjacency fractions or Markov stationary distribution. CPATH can incorporate domain knowledge through knowledge graphs to guide feature sampling and improve explanation parsimony. The method is particularly effective at capturing conditional feature dependencies that traditional methods like SHAP and LIME miss.

## Key Results
- CPATH outperforms SHAP and LIME in cases of conditional feature dependency, nearly perfectly aligning with ground truth
- The method shows potential for causal modeling and inference, as demonstrated by its application to breast cancer gene expression data
- CPATH provides more interpretable explanations than traditional feature weighting methods, especially when using knowledge graphs to guide feature sampling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CPATH identifies feature importance through sequential permutations that lead to label changes, capturing interaction effects better than marginal importance methods.
- Mechanism: The algorithm samples random paths through features, permuting them sequentially until a threshold of label swaps occurs. This sequential dependency models conditional feature interactions rather than assuming independence.
- Core assumption: The model's prediction boundary is locally smooth enough that small sequential feature perturbations will reveal importance through label changes.
- Evidence anchors:
  - [abstract] "The algorithm measures feature importance by identifying sequential permutations of features that most influence changes in model predictions."
  - [section 3.2] "Given a model's predictions M(X) = [M(x1), ..., M(xn)] for a dataset X = (x1, ..., xn)T, we call a sequence v = (v1, ..., vk), k ≤ p, a counterfactual path under counterfactual policy Ψ if perturbing (e.g., by permuting) values in the features v1, ..., vk leads to a substantial change in the model's predictions according to the indicator given by Ψ"
- Break condition: If the model has highly discontinuous decision boundaries or if feature interactions are non-local (spanning distant features in the graph), the sequential permutation approach may miss important interactions.

### Mechanism 2
- Claim: CPATH provides more accurate explanations for models with conditional feature dependencies compared to SHAP and LIME.
- Mechanism: By permuting features in sequences and measuring the resulting label changes, CPATH captures the joint effect of feature combinations rather than treating features independently, which is critical when features have conditional dependencies.
- Core assumption: The conditional dependencies between features create scenarios where individual feature importance is misleading, and only joint perturbations reveal true importance.
- Evidence anchors:
  - [abstract] "Experiments with synthetic and medical data demonstrate that CPATH provides more accurate and interpretable explanations compared to existing methods like SHAP and LIME, particularly in cases of conditional feature dependency."
  - [section 5.1] "In the case of conditional feature dependency, CPATH is clearly more accurate than SHAP and LIME. CPATH almost perfectly aligns with the ground truth."
- Break condition: If features are truly independent or only correlated (not conditionally dependent), the advantage of CPATH over methods like SHAP may diminish.

### Mechanism 3
- Claim: CPATH can incorporate domain knowledge through knowledge graphs to guide feature sampling and improve explanation parsimony.
- Mechanism: The algorithm can use a domain knowledge graph (weighted directed graph) to restrict random walks to feature sequences that respect known relationships, making explanations more interpretable and focused.
- Core assumption: Domain experts have meaningful prior knowledge about feature relationships that can be encoded as graph edges, and this knowledge is relevant to the model's decision-making process.
- Evidence anchors:
  - [abstract] "The method is especially suitable for generating explanations based on counterfactual paths in knowledge graphs, providing a more intuitive and interpretable explanation for the model's behavior than traditional feature weighting methods."
  - [section 4.4] "In this specific evaluation, we compute the network, features and classes in the following way. First, we generate Barabasi networks (Barabási and Albert, 1999) of varying size and structure."
- Break condition: If the domain knowledge graph is incomplete, incorrect, or not aligned with the model's actual feature dependencies, incorporating it may reduce explanation accuracy.

## Foundational Learning

- Concept: Counterfactual explanations and their role in explainable AI
  - Why needed here: CPATH is fundamentally a counterfactual explanation method, so understanding the counterfactual reasoning paradigm is essential to grasp why sequential permutations matter
  - Quick check question: What distinguishes a counterfactual explanation from other types of explanations in terms of the "what if" reasoning it provides?

- Concept: Feature importance measurement methods (permutation, SHAP, LIME)
  - Why needed here: CPATH is compared against these methods, and understanding their limitations (especially with conditional dependencies) helps explain CPATH's advantages
  - Quick check question: How does permutation feature importance differ from SHAP values in terms of handling feature dependencies?

- Concept: Graph theory and random walks
  - Why needed here: CPATH uses graph representations of features and random walks to sample counterfactual paths, so understanding these concepts is crucial for implementing and modifying the algorithm
  - Quick check question: In a random walk on a feature graph, what determines the probability of moving from one feature to another?

## Architecture Onboarding

- Component map:
  - Model interface (black-box predictor M)
  - Data loader and preprocessor
  - Counterfactual path generator (CPATH core algorithm)
  - Transition matrix builder
  - Importance calculator (both adjacency-based and Markov stationary distribution)
  - Domain knowledge graph interface (optional)
  - Evaluation framework (comparison with SHAP, LIME, Gini importance)
  - Visualization module (graphical representation of counterfactual paths)

- Critical path:
  1. Load data and train black-box model
  2. Generate counterfactual paths by sampling random walks and permuting features sequentially
  3. Build transition matrix from observed paths
  4. Calculate feature importances using either adjacency fractions or Markov stationary distribution
  5. Visualize results and compare with baseline methods

- Design tradeoffs:
  - Path length vs. computational cost: Longer paths may capture more complex interactions but increase computation exponentially
  - Number of paths vs. accuracy: More paths improve coverage but increase runtime
  - Domain knowledge incorporation vs. flexibility: Knowledge graphs improve interpretability but may miss unexpected feature interactions
  - Sequential permutation vs. parallel evaluation: Sequential approach captures dependencies but may be slower than evaluating features independently

- Failure signatures:
  - If CPATH consistently underperforms SHAP/LIME on independent features, the sequential permutation mechanism may be adding unnecessary complexity
  - If knowledge-guided CPATH performs worse than the standard version, the domain knowledge graph may be incorrect or irrelevant
  - If explanations don't align with model behavior, the counterfactual policy threshold may be improperly set
  - If computational cost is prohibitive, the path sampling strategy may need optimization

- First 3 experiments:
  1. Synthetic dataset with known conditional dependencies (like the paper's simulation 1) to verify CPATH outperforms SHAP/LIME on conditional dependency detection
  2. Real medical dataset (like breast cancer gene expression) to test CPATH's ability to identify biologically meaningful feature interactions
  3. Comparison of CPATH with and without domain knowledge on a knowledge graph where ground truth relationships are known to validate the benefit of incorporating domain knowledge

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of counterfactual policy Ψ affect the performance and interpretability of CPATH explanations?
- Basis in paper: [explicit] The paper mentions that "Various choices for the counterfactual policy Ψ are possible" and discusses different options like stochastic (Ψs) and deterministic (Ψd) policies, as well as penalizing path lengths.
- Why unresolved: The paper doesn't provide empirical comparisons of different counterfactual policies or guidelines for selecting the most appropriate one in different scenarios.
- What evidence would resolve it: Comparative studies showing the impact of different Ψ policies on explanation quality metrics (sensitivity, fidelity, interpretability) across various datasets and model types.

### Open Question 2
- Question: How does CPATH perform compared to other model-agnostic XAI methods when dealing with high-dimensional data and complex feature interactions?
- Basis in paper: [inferred] The paper mentions that CPATH is "particularly suitable for generating explanations based on counterfactual paths in knowledge graphs" and discusses its performance on synthetic data, but doesn't extensively evaluate its scalability or performance on high-dimensional real-world datasets.
- Why unresolved: The paper's experiments focus on relatively low-dimensional synthetic data and a single bioinformatics application, leaving questions about CPATH's performance in more complex, high-dimensional scenarios.
- What evidence would resolve it: Comprehensive benchmarking of CPATH against other XAI methods on high-dimensional datasets with known ground truth feature importance, evaluating both accuracy and computational efficiency.

### Open Question 3
- Question: How can CPATH be extended to handle continuous and categorical features simultaneously, and what are the implications for explanation quality?
- Basis in paper: [explicit] The paper mentions that "related is work on conditional estimation of Shapley-based feature attributions Aas et al. (2021)" and discusses the potential for CPATH in causal modeling, but doesn't explicitly address the handling of mixed feature types.
- Why unresolved: The paper's discussion of counterfactual paths and feature importance doesn't address the specific challenges and potential solutions for handling datasets with both continuous and categorical features.
- What evidence would resolve it: Development and empirical evaluation of CPATH extensions for mixed feature types, comparing explanation quality and interpretability against existing methods that handle both continuous and categorical features.

## Limitations

- CPATH's performance claims rely heavily on synthetic data experiments, with limited validation on diverse real-world datasets
- The computational complexity of sampling counterfactual paths scales exponentially with feature dimensionality, potentially limiting practical applicability
- The paper doesn't fully address how CPATH handles categorical features or missing data, which are common in real-world applications

## Confidence

- CPATH's mechanism for capturing sequential feature interactions (Mechanism 1): **High** - The theoretical foundation is sound and well-explained
- Superiority over SHAP/LIME in conditional dependency scenarios (Mechanism 2): **Medium** - Supported by synthetic experiments but needs validation on diverse real-world datasets
- Domain knowledge graph integration benefits (Mechanism 3): **Low-Medium** - Limited experimental validation, theoretical benefits are clear but practical advantages uncertain

## Next Checks

1. **Real-world validation**: Apply CPATH to at least three diverse real-world datasets with known feature dependencies (e.g., healthcare, finance, and image recognition) to verify performance claims beyond synthetic data.

2. **Computational scalability**: Benchmark CPATH's runtime and memory usage against SHAP and LIME on datasets ranging from 10 to 1000 features to quantify the computational tradeoff.

3. **Ablation study on domain knowledge**: Compare CPATH performance with and without domain knowledge graphs on datasets where ground truth feature relationships are known to quantify the actual benefit of incorporating domain knowledge.