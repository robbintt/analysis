---
ver: rpa2
title: Quantile-based Maximum Likelihood Training for Outlier Detection
arxiv_id: '2310.06085'
source_url: https://arxiv.org/abs/2310.06085
tags:
- outlier
- inlier
- detection
- learning
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of detecting outlier images
  in image classification tasks, which is critical for applications like autonomous
  driving and video surveillance. The authors propose a novel framework called QuantOD
  that learns the inlier feature distribution using a quantile-based maximum likelihood
  objective and a normalizing flow model.
---

# Quantile-based Maximum Likelihood Training for Outlier Detection

## Quick Facts
- arXiv ID: 2310.06085
- Source URL: https://arxiv.org/abs/2310.06085
- Reference count: 20
- Primary result: QuantOD achieves FPR95 of 17.17% and AUROC of 96.19% on CIFAR-10 outlier detection benchmarks

## Executive Summary
This paper introduces QuantOD, a novel outlier detection framework that combines a quantile-based maximum likelihood objective with normalizing flow models to learn inlier feature distributions. The method trains a classifier backbone on inlier data, extracts low-dimensional features, and fits a normalizing flow model using a quantile-based loss that focuses optimization on boundary inlier samples. During inference, outliers are detected by comparing their feature likelihoods to a threshold computed from validation inliers. Experiments demonstrate state-of-the-art performance on CIFAR-10 with six outlier datasets, maintaining competitive inlier classification accuracy while significantly improving outlier detection metrics.

## Method Summary
QuantOD operates in two phases: first, a WideResNet40 classifier is trained on inlier data (CIFAR-10) using standard cross-entropy loss; second, low-dimensional features (128-dim) from the classifier's penultimate layer are used to train a Glow normalizing flow model with a quantile-based negative log-likelihood loss (q=0.05). The quantile-based loss maximizes the likelihood of inlier samples near the decision boundary rather than the mean likelihood, improving separation between inlier and outlier distributions. At inference, the flow model computes log-likelihoods for test features, which are compared against a threshold derived from inlier validation data to classify samples as inlier or outlier. The method maintains the classifier's original architecture, allowing it to retain strong inlier classification performance while adding robust outlier detection capabilities.

## Key Results
- Achieves FPR95 of 17.17% and AUROC of 96.19% on CIFAR-10 outlier detection benchmarks
- Outperforms state-of-the-art unsupervised methods including KD, DOM, and VOS
- Maintains competitive inlier classification accuracy while improving outlier detection
- Ablation studies confirm effectiveness of quantile-based loss and low-dimensional feature selection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Quantile-based loss maximizes the likelihood of inliers near the decision boundary more effectively than mean-based loss.
- Mechanism: By selecting the q-quantile (e.g., 0.05) of batch log-likelihoods as the training objective, the model focuses optimization on low-likelihood inliers—those closest to outliers—thereby widening the separation between inlier and outlier feature distributions.
- Core assumption: Inlier data contain a subset of samples near the distribution boundary whose likelihoods are most informative for outlier detection.
- Evidence anchors:
  - [section]: "the model trained on the quantile-based negative log-likelihood loss with q = 0.05 outperforms the mean-based negative log-likelihood loss... the quantile-based loss encourages optimization of the likelihood scores for inlier images situated at the boundary of the training manifold"
  - [abstract]: "introduce a quantile-based maximum likelihood objective for learning the inlier distribution to improve the outlier separation during inference"
- Break condition: If inlier data lacks sufficient boundary samples, quantile loss may overfit to noise; if q is too low, training becomes unstable.

### Mechanism 2
- Claim: Low-dimensional feature embeddings preserve semantic content better for outlier detection than high-dimensional ones.
- Mechanism: Features from the penultimate layer of WideResNet40 (128-dim) capture salient attributes of inlier semantics, enabling the normalizing flow to learn a tighter, more discriminative density model.
- Core assumption: High-dimensional embeddings become sparse and less informative for density estimation in the context of outlier detection.
- Evidence anchors:
  - [section]: "We report that the outlier detection performance reduces as the dimensionality of the features increase... low-dimensional features from the WideResNet40 model are more representative and therefore favored for outlier detection"
  - [section]: "the low-dimensional feature embeddings contain salient attributes of the inlier semantics"
- Break condition: If the feature extractor is too shallow or task-specific, low-dimensional embeddings may lose necessary discriminative power.

### Mechanism 3
- Claim: Normalizing flow models learn a unified feature distribution across inlier classes better than per-class Gaussian modeling.
- Mechanism: Flow-based density estimation transforms the unknown inlier feature distribution into a standard normal, providing a single likelihood score for outlier detection without needing class-conditional modeling.
- Core assumption: A unified generative model can capture the shared structure across inlier classes while distinguishing outliers.
- Evidence anchors:
  - [section]: "Our method employs a flow-based generative model to learn a unified feature distribution across inlier classes... we compared the outlier detection performance of QuantOD with these two methods... We report better outlier detection performance than both methods on CIFAR-10"
  - [corpus]: No direct evidence in neighbors; QuantOD differs from per-class methods like Mahalanobis and VOS, which rely on class-conditional Gaussians.
- Break condition: If inlier classes have highly divergent feature distributions, a unified model may underperform compared to per-class approaches.

## Foundational Learning

- Concept: Normalizing flows as invertible density estimators
  - Why needed here: To transform inlier feature distributions into a tractable form (standard normal) for likelihood computation
  - Quick check question: What property of normalizing flows allows exact likelihood computation for arbitrary distributions?

- Concept: Quantile-based optimization vs. mean-based
  - Why needed here: To focus model training on boundary inliers whose likelihood scores are most informative for outlier separation
  - Quick check question: How does selecting the 0.05-quantile of batch likelihoods change the optimization objective compared to the mean?

- Concept: Open-set classification framework
  - Why needed here: To distinguish between inlier classification and outlier rejection using a shared feature extractor
  - Quick check question: Why does the method use a single threshold on log-likelihood rather than per-class thresholds?

## Architecture Onboarding

- Component map:
  backbone → feature extraction → flow likelihood → threshold check → (optional) softmax classification

- Critical path:
  backbone → feature extraction → flow likelihood → threshold check → (optional) softmax classification

- Design tradeoffs:
  - Low vs. high dimensional features: low-dim improves outlier detection but may reduce classification granularity
  - Flow architecture: Glow vs. RealNVP vs. NICE affects density estimation quality and runtime
  - q-value in quantile loss: lower q improves boundary separation but risks instability

- Failure signatures:
  - High FPR95 despite low AUROC: likely threshold miscalibration or poor feature quality
  - Degraded inlier accuracy: feature extractor not frozen during flow training or over-regularization
  - Slow inference: overly deep flow or large batch size during threshold computation

- First 3 experiments:
  1. Compare mean-based vs. q=0.05 quantile-based loss on CIFAR-10→SVHN
  2. Vary feature dimensionality (128 vs. 512) and measure outlier detection metrics
  3. Test different flow architectures (Glow, RealNVP, NICE) on same backbone

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of QuantOD scale with increasing dimensionality of the classifier backbone features? The paper shows that WideResNet40128 performs better than ResNet18 with 512-dimensional features, but it's unclear if this trend continues with even higher dimensional features.
- Basis in paper: [inferred] The paper mentions that "We evaluated the classifier backbone for outlier detection performance by training them with CIFAR-10 as the inlier and testing on SVHN as the outlier dataset" and shows results for WideResNet40128 and ResNet18.
- Why unresolved: The paper only compares two different backbone architectures with different feature dimensionalities. It doesn't explore how performance changes with even higher dimensional features.
- What evidence would resolve it: Experiments comparing QuantOD performance using backbones with a wider range of feature dimensionalities, e.g., WideResNet50128, WideResNet101128, or custom architectures with 256, 512, 1024, and 2048 dimensional features.

### Open Question 2
- Question: How does QuantOD perform on larger, more complex datasets like ImageNet or COCO compared to CIFAR-10? The paper shows strong results on CIFAR-10, but it's unclear if this performance generalizes to larger datasets.
- Basis in paper: [explicit] The paper states "We train QuantOD on CIFAR-10 (Krizhevsky, Hinton et al. 2009) dataset that consists of 60000 color images of 32×32 resolution in 10 different object classes"
- Why unresolved: The paper only evaluates QuantOD on CIFAR-10 and CIFAR-100. It doesn't explore performance on larger, more complex datasets.
- What evidence would resolve it: Experiments applying QuantOD to larger datasets like ImageNet or COCO and comparing performance to state-of-the-art methods on these datasets.

### Open Question 3
- Question: How does QuantOD's performance change with different choices of the quantile parameter q in the quantile-based maximum likelihood loss? The paper shows that q=0.05 performs well, but it's unclear if this is optimal for all datasets and scenarios.
- Basis in paper: [explicit] The paper states "Figure 2 presents the FPR95 and AUROC results on six outlier datasets. Generally, the model trained on the quantile-based negative log-likelihood loss with q = 0.05 outperforms the mean-based negative log-likelihood loss."
- Why unresolved: The paper only explores a limited range of q values (mean-based vs. q=0.05). It doesn't explore how performance changes with different q values.
- What evidence would resolve it: Experiments comparing QuantOD performance using different q values (e.g., 0.01, 0.025, 0.05, 0.1, 0.2, 0.5) on various datasets and outlier types.

## Limitations
- Method relies on assumption that inlier data contains sufficient boundary samples for quantile-based optimization
- Glow normalizing flow architecture is only implicitly specified, leaving room for implementation variance
- Requires separate training phases for classifier and flow model, increasing complexity

## Confidence
- **High confidence**: The core mechanism of quantile-based loss improving boundary separation (Mechanism 1) is well-supported by ablation studies comparing q=0.05 against mean-based loss across multiple outlier datasets.
- **Medium confidence**: The claim about low-dimensional features being superior for outlier detection (Mechanism 2) is supported by the CIFAR-10 experiments but lacks cross-dataset validation on non-image domains.
- **Medium confidence**: The unified flow modeling approach (Mechanism 3) shows better performance than per-class methods on CIFAR-10, but the comparison is limited to only two baselines without extensive ablation on flow architectures.

## Next Checks
1. Test quantile loss sensitivity across different q values (0.01-0.1) on datasets with varying inlier diversity to establish robustness boundaries.
2. Evaluate feature dimensionality impact on outlier detection using deeper backbones (e.g., ResNet50) to verify if the low-dimension advantage persists.
3. Compare against recent normalizing flow variants (RealNVP, MAF) and hybrid approaches to isolate the contribution of the quantile loss from the flow architecture choice.