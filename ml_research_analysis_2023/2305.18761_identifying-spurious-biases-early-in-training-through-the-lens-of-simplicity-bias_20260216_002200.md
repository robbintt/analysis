---
ver: rpa2
title: Identifying Spurious Biases Early in Training through the Lens of Simplicity
  Bias
arxiv_id: '2305.18761'
source_url: https://arxiv.org/abs/2305.18761
tags:
- spurious
- groups
- training
- examples
- group
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work provides the first theoretical analysis of how simplicity\
  \ bias leads to learning spurious correlations. It proves that on a two-layer neural\
  \ network, examples with spurious features are separable based on the model\u2019\
  s output early in training."
---

# Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias

## Quick Facts
- arXiv ID: 2305.18761
- Source URL: https://arxiv.org/abs/2305.18761
- Reference count: 40
- Provides first theoretical analysis of how simplicity bias leads to learning spurious correlations

## Executive Summary
This work provides the first theoretical analysis of how simplicity bias in neural networks leads to learning spurious correlations. The authors prove that in a two-layer neural network, examples with spurious features are provably separable based on the model's output early in training. When spurious features have a low noise-to-signal ratio, the network's output becomes almost exclusively determined by these spurious features, ignoring core features. Based on these insights, they propose SPARE, which clusters model outputs early in training and uses importance sampling to mitigate spurious correlations, achieving up to 5.6% higher worst-group accuracy compared to state-of-the-art methods.

## Method Summary
SPARE identifies spurious correlations by clustering model outputs early in training (first 1-2 epochs) to separate majority and minority groups. The method then applies importance sampling to balance group sizes during retraining, with the sampling power λ determined by silhouette scores (λ=1 for scores >0.9, λ=2 for scores 0.6-0.9). This approach exploits the theoretical finding that spurious features dominate early in training when their noise-to-signal ratio is low, allowing the model to be invariant to core features during this phase.

## Key Results
- Proves majority/minority groups are separable based on model output early in training
- Shows network output becomes dominated by spurious features when their noise-to-signal ratio is low
- SPARE achieves up to 5.6% higher worst-group accuracy compared to state-of-the-art methods
- Up to 12x faster than existing methods while maintaining effectiveness

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Early in training, the model's output on majority group examples is linearly amplified by spurious feature strength.
- **Mechanism**: In the initial training phase, the neural network behaves nearly linearly, so spurious features with high label correlation grow rapidly in the model output, while core features remain relatively suppressed.
- **Core assumption**: The network is in its "simplicity bias" early phase and approximates a linear model.
- **Evidence anchors**:
  - [abstract]: "we show that examples with spurious features are provably separable based on the model's output early in training"
  - [section 4.1]: Theorem 4.1 and Corollary 4.2 show that spurious feature contributions grow linearly with correlation `(nc,s - nc',s) ||vs||²` and that majority/minority groups become separable early in training.
  - [corpus]: "Hierarchical Simplicity Bias of Neural Networks" discusses how simpler features dominate early learning—directly relevant to this mechanism.
- **Break condition**: If spurious features have a high noise-to-signal ratio relative to core features, the linear growth no longer dominates; the model output becomes more balanced and separability degrades.

### Mechanism 2
- **Claim**: When the noise-to-signal ratio of the spurious feature is low, the network's output becomes almost exclusively determined by that spurious feature, ignoring core features.
- **Mechanism**: In the second early-phase stage, if `Rs << Rc`, the learned weight for the spurious feature overwhelms that for the core feature, so predictions rely almost entirely on spurious cues.
- **Core assumption**: Classes are balanced and minority groups are small enough that the spurious feature dominates early.
- **Evidence anchors**:
  - [abstract]: "if spurious features have a small enough noise-to-signal ratio, the network's output...will be almost exclusively determined by the spurious features"
  - [section 4.2]: Theorem 4.3 formalizes this: contribution of core feature is bounded by `sqrt(d) Rs/(zeta Rc)` while spurious contribution is `sqrt(d)/(2 zeta)`, proving dominance.
  - [corpus]: "Overcoming Simplicity Bias in Deep Networks using a Feature Sieve" addresses the same dominance of simple features over complex ones.
- **Break condition**: If noise levels for spurious features rise (e.g., more varied backgrounds), the signal-to-noise advantage erodes, reducing spurious dominance.

### Mechanism 3
- **Claim**: Clustering the model output early in training separates majority and minority groups reliably, enabling targeted resampling.
- **Mechanism**: Because spurious-feature-driven outputs differ systematically between groups, clustering (e.g., via silhouette analysis) cleanly partitions examples, after which importance sampling balances cluster sizes.
- **Core assumption**: Groups are separable in feature space at early epochs and silhouette scores reflect meaningful cluster structure.
- **Evidence anchors**:
  - [abstract]: "clusters the model output early in training" and uses "importance sampling to make the groups relatively balanced"
  - [section 5]: SPARE clusters model outputs in each class based on silhouette scores and then applies importance sampling to balance groups.
  - [section 6.2]: Experiments confirm that silhouette scores > 0.9 indicate clear separation and allow λ=1 or 2 balancing.
  - [corpus]: "Complexity Matters: Dynamics of Feature Learning in the Presence of Spurious Correlations" discusses clustering dynamics early in training.
- **Break condition**: If clusters are not well-separated (low silhouette scores), resampling cannot effectively balance groups, and spurious bias remains.

## Foundational Learning

- **Concept**: Simplicity bias in gradient-based training.
  - Why needed here: The entire method depends on the network initially learning simpler spurious features before complex core features.
  - Quick check question: What early-phase property of neural nets does SPARE exploit to identify spurious correlations before they dominate?

- **Concept**: Linear approximation of neural networks early in training.
  - Why needed here: SPARE's theoretical proofs rely on the network behaving like a linear model in the initial epochs.
  - Quick check question: Why does the linear model assumption let us predict when majority/minority groups will separate?

- **Concept**: Importance sampling for class balance.
  - Why needed here: SPARE uses it to upweight minority groups after clustering, directly counteracting the spurious correlation learned early.
  - Quick check question: How does changing the sampling power λ based on silhouette scores improve balancing effectiveness?

## Architecture Onboarding

- **Component map**: Data preprocessing -> Model training (first N epochs) -> Clustering model outputs -> Importance sampling weights -> Retraining with balanced batches
- **Critical path**: Model training -> Clustering -> Resampling -> Final training. Any failure in early clustering propagates downstream.
- **Design tradeoffs**: Simpler clustering (k-means) is faster but may miss nuanced minority clusters; silhouette analysis adds overhead but ensures better separation.
- **Failure signatures**:
  - Poor separability (low silhouette scores) -> Clusters mix majority/minority examples -> Resampling ineffective
  - Oversampling minority too aggressively -> Introduces new spurious correlations
  - Too few training epochs before clustering -> Groups not yet separable
- **First 3 experiments**:
  1. Train a small CNN on CMNIST for 2 epochs, cluster outputs, and visualize group separation with t-SNE.
  2. Apply SPARE's importance sampling to the clustered groups and measure worst-group accuracy vs. ERM baseline.
  3. Repeat on Waterbirds, adjusting λ based on silhouette score, and compare worst-group accuracy to JTT.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well does SPARE generalize to other data modalities beyond vision, such as text or audio?
- Basis in paper: [inferred] The paper mentions that simplicity bias has been mainly studied for vision models, and applicability of SPARE to other data modalities requires further investigations.
- Why unresolved: The paper does not provide experimental results or theoretical analysis for data modalities other than vision.
- What evidence would resolve it: Experiments applying SPARE to text or audio datasets and comparing its performance to other methods.

### Open Question 2
- Question: What is the impact of using different clustering algorithms (e.g., k-means vs. k-median) on the performance of SPARE?
- Basis in paper: [explicit] The paper mentions that any clustering algorithm such as k-means or k-median clustering can be applied to separate the groups, but k-means easily scales to medium-sized datasets, while k-median is more suitable for very large datasets.
- Why unresolved: The paper does not provide experimental results comparing the performance of SPARE with different clustering algorithms.
- What evidence would resolve it: Experiments applying SPARE with different clustering algorithms on the same datasets and comparing the worst-group accuracy and average accuracy.

### Open Question 3
- Question: How sensitive is SPARE to the choice of hyperparameters, such as the learning rate and weight decay, compared to other methods?
- Basis in paper: [inferred] The paper mentions that the hyperparameters employed in the experiments were determined based on the ranges of optimal hyperparameters used by the current state-of-the-art algorithms, but does not provide a detailed sensitivity analysis.
- Why unresolved: The paper does not provide a systematic analysis of the impact of different hyperparameter choices on the performance of SPARE.
- What evidence would resolve it: Experiments varying the hyperparameters of SPARE and other methods on the same datasets and comparing the worst-group accuracy and average accuracy.

## Limitations
- Theoretical analysis relies on two-layer neural network assumptions that may not generalize to deeper architectures
- Effectiveness depends critically on achieving high silhouette scores for clean group separation
- Importance sampling could introduce new spurious correlations if λ is not carefully tuned

## Confidence
- **High confidence**: The core theoretical claims about separability of majority/minority groups early in training and the dominance of spurious features when Rs << Rc
- **Medium confidence**: The empirical effectiveness of SPARE across different datasets
- **Low confidence**: The generalizability of SPARE to deeper networks and its behavior beyond early training stages

## Next Checks
1. **Architecture generalization test**: Apply SPARE to deeper CNN architectures (ResNet, VGG) and measure worst-group accuracy degradation compared to the two-layer case to validate the theoretical bounds.

2. **Late-stage training analysis**: Track the evolution of group separability and spurious feature dominance throughout training (not just early epochs) to identify when and how the theoretical assumptions break down.

3. **Hyperparameter sensitivity study**: Systematically vary clustering parameters (k, distance metric) and importance sampling λ values across all datasets to establish robust hyperparameter selection guidelines and identify failure modes.