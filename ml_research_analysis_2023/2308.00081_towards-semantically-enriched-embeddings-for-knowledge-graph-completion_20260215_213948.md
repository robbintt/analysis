---
ver: rpa2
title: Towards Semantically Enriched Embeddings for Knowledge Graph Completion
arxiv_id: '2308.00081'
source_url: https://arxiv.org/abs/2308.00081
tags:
- knowledge
- graph
- entity
- completion
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a survey and critical reflection on knowledge
  graph (KG) completion algorithms. It discusses traditional approaches based on graph
  structures, then surveys methods incorporating type information and semantics from
  description logic axioms.
---

# Towards Semantically Enriched Embeddings for Knowledge Graph Completion

## Quick Facts
- arXiv ID: 2308.00081
- Source URL: https://arxiv.org/abs/2308.00081
- Reference count: 40
- Primary result: Survey of KG completion methods with semantics from DL axioms; highlights transductive limitations and need for inductive, LLM-augmented approaches.

## Executive Summary
This survey critically examines knowledge graph completion algorithms, tracing the evolution from purely structural approaches to those incorporating type information and description logic (DL) semantics. It identifies a key gap: most methods ignore semantics beyond the assertion box and operate transductively, limiting their ability to generalize to new entities or relations. The paper advocates for integrating external knowledge sources like large language models and developing inductive methods to overcome these limitations.

## Method Summary
The paper reviews embedding-based KG completion methods, categorizing them into translation models (e.g., TransE, TransH), semantic matching models (e.g., DistMult, ComplEx), and neural network models (e.g., ConvE). It then surveys extensions that incorporate type hierarchies and DL axioms, focusing on box embeddings (e.g., BoxEL, ELBE) to model concept intersections and hierarchies. The survey also discusses LLM-augmented approaches (e.g., PKGC) for leveraging external knowledge. While not presenting new empirical results, it provides a framework for understanding how semantic enrichment can improve KG completion.

## Key Results
- Traditional KG completion algorithms largely ignore semantics beyond factual triples.
- Box embeddings can model EL++ axioms by representing concepts as axis-aligned boxes.
- LLM-augmented methods can generate plausible links but face evaluation challenges due to hits@k bias.
- Current methods are mostly transductive, unable to predict for new entities or relations.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating semantics from description logic axioms improves embedding expressiveness beyond factual triples.
- Mechanism: Description logic axioms (e.g., class hierarchies, role properties) are translated into geometric constraints (e.g., box embeddings) that enrich the embedding space with hierarchical and relational semantics.
- Core assumption: The embedding space can be structured such that logical axioms correspond to spatial relationships (e.g., containment for subsumption).
- Evidence anchors:
  - [abstract] discusses "algorithms capturing the semantics represented in different description logic axioms."
  - [section] notes that approaches like BoxEL and ELBE use box embeddings to model concepts as axis-aligned boxes, preserving intersection semantics.
  - [corpus] cites related work on EL embeddings and Box2EL that also ground description logic semantics in geometry.
- Break condition: If the chosen embedding space cannot represent the logical constraints (e.g., boxes cannot capture non-convex concepts), the semantics will be lost.

### Mechanism 2
- Claim: External knowledge from LLMs can complement KG embeddings by providing context and commonsense knowledge.
- Mechanism: LLMs are fine-tuned or prompted to generate missing links in the KG, leveraging their training on large textual corpora to infer plausible relations.
- Core assumption: LLMs contain generalizable knowledge that aligns with the KG's domain, even if not explicitly present in the triples.
- Evidence anchors:
  - [abstract] states that "KGs could benefit from these LLMs and vice versa."
  - [section] describes PKGC's approach to convert triples into natural language prompts for LLM-based link prediction.
  - [corpus] includes "DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs" as related work.
- Break condition: If LLM-generated links are semantically correct but absent from the evaluation set, traditional hits@k metrics will penalize them, masking their usefulness.

### Mechanism 3
- Claim: Using type information and type hierarchies reduces ambiguity in link prediction by constraining candidate entities.
- Mechanism: Entity types are encoded as additional embeddings or constraints, so that predictions respect type compatibility (e.g., a "person" cannot have a "city" as a spouse).
- Core assumption: The type hierarchy is accurate and sufficiently expressive to capture valid relation patterns.
- Evidence anchors:
  - [section] describes TKRL and TransT as methods that encode hierarchical type information into embeddings.
  - [section] notes that JOIE jointly learns embeddings of ontological concepts and instances using cross-view modeling.
  - [corpus] lists "Schema First! Learn Versatile Knowledge Graph Embeddings by Capturing Semantics with MASCHInE" as related work.
- Break condition: If the type hierarchy is noisy or incomplete, enforcing type constraints may block valid predictions or introduce errors.

## Foundational Learning

- Concept: Description logics and their expressiveness (EL++, ALC, SH)
  - Why needed here: The paper surveys methods that incorporate TBox information; understanding DL expressivity is essential to grasp which axioms can be modeled.
  - Quick check question: What distinguishes EL++ from ALC in terms of allowed constructors?
- Concept: Embedding spaces for knowledge graphs (translational, semantic matching, box embeddings)
  - Why needed here: Different embedding models handle semantics differently; knowing their mechanics helps evaluate trade-offs.
  - Quick check question: How does a box embedding model intersection differently from a ball embedding?
- Concept: Inductive vs transductive settings in KG completion
  - Why needed here: Many proposed methods still operate transductively; understanding this limitation is key to assessing generalization claims.
  - Quick check question: Why can't a purely transductive model predict links for unseen entities?

## Architecture Onboarding

- Component map:
  Input triples/axioms -> Embedding generator (translational/box/multimodal) -> Scoring layer (dot product/translation distance) -> External knowledge module (LLM/rules) -> Ranked candidate triples
- Critical path:
  1. Load KG and any schema/axiom files
  2. Initialize embeddings (with or without type/DL constraints)
  3. Train on known triples (optionally incorporating LLM prompts)
  4. Score and rank candidate completions
  5. Evaluate using appropriate metric (hits@k, sem@k, or human annotation)
- Design tradeoffs:
  - Expressiveness vs scalability: richer semantics (DL axioms) increase embedding complexity and training cost.
  - Transductive vs inductive: inductive methods generalize to unseen entities but often require external context (e.g., text descriptions).
  - Evaluation bias: traditional metrics favor reconstructing known triples; alternative metrics (e.g., sem@k) better capture novel, semantically valid links.
- Failure signatures:
  - Poor hits@k but high sem@k → model is generating valid but novel links not in the original KG.
  - Degraded performance on type-constrained predictions → type hierarchy may be noisy or overly restrictive.
  - Training instability with box embeddings → axiom constraints may be incompatible with the embedding geometry.
- First 3 experiments:
  1. Baseline: train a simple TransE model on FB15k-237; report hits@10 and MRR.
  2. Type-aware: add entity type embeddings (e.g., TKRL-style) and evaluate same metrics.
  3. DL-aware: implement BoxEL-style embeddings for a subset of EL++ axioms and compare against baselines on a small DL-enriched dataset (e.g., FoodOn).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we effectively evaluate knowledge graph completion algorithms that leverage external knowledge sources like LLMs, given the limitations of current metrics like hits@k?
- Basis in paper: [explicit] The paper discusses how current evaluation metrics like hits@k favor reconstructing known links over predicting genuinely new ones, and proposes alternative metrics like sem@k but notes human annotation challenges.
- Why unresolved: Current evaluation metrics are inadequate for assessing algorithms that predict semantically correct but novel links not present in the original KG, and human annotation for large-scale evaluation is impractical.
- What evidence would resolve it: Development and validation of automated evaluation metrics that can assess the semantic correctness of novel predictions without requiring human annotation.

### Open Question 2
- Question: What are the key methodological challenges in developing inductive knowledge graph completion algorithms that can predict new relations, not just new entities?
- Basis in paper: [explicit] The paper notes that most inductive methods only consider predicting new entities, with almost no algorithms aiming to predict new relations, and recommends embracing inductive settings.
- Why unresolved: Developing algorithms that can predict new relations requires addressing challenges in relation representation, reasoning about relation semantics, and handling the open-world nature of KGs.
- What evidence would resolve it: Successful development and evaluation of inductive KG completion algorithms that can accurately predict new relations in real-world KGs.

### Open Question 3
- Question: How can we effectively incorporate description logic axioms beyond EL++ (e.g., ALC, SH) into knowledge graph embedding models while maintaining computational efficiency?
- Basis in paper: [explicit] The paper discusses approaches using box embeddings for EL++ axioms but notes limitations in handling more expressive axioms like role transitivity, and recommends incorporating richer semantic information.
- Why unresolved: More expressive description logics introduce complex axioms (e.g., role composition, cardinality restrictions) that are challenging to represent in embedding spaces while preserving computational tractability.
- What evidence would resolve it: Development of efficient embedding models that can accurately represent and reason with a broader range of description logic axioms in large-scale KGs.

## Limitations

- Most surveyed methods are transductive and cannot generalize to new entities or relations.
- Evaluation metrics like hits@k are biased toward reconstructing known links, masking the value of novel predictions.
- Box embeddings may not scale well to very large KGs or handle non-convex concepts effectively.

## Confidence

- Survey coverage and literature synthesis: High
- Practical impact of semantic enrichment: Medium
- Feasibility of inductive KG completion: Medium
- Evaluation of LLM-augmented methods: Medium

## Next Checks

1. Implement a controlled experiment comparing EL++-aware box embeddings (e.g., BoxEL) against a strong baseline (e.g., RotatE) on a small DL-enriched KG (e.g., FoodOn) to quantify the practical benefit of TBox semantics.
2. Evaluate a type-constrained model (e.g., TKRL) on FB15k-237 and measure whether type constraints improve precision without overly restricting recall.
3. Run an ablation study on the PKGC approach: compare LLM-generated link predictions against traditional embedding-based predictions on a held-out test set, measuring both hits@k and a semantic plausibility metric (e.g., sem@k).