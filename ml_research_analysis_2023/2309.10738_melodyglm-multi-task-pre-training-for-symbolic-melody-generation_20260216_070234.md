---
ver: rpa2
title: 'MelodyGLM: Multi-task Pre-training for Symbolic Melody Generation'
arxiv_id: '2309.10738'
source_url: https://arxiv.org/abs/2309.10738
tags:
- melody
- melodic
- pre-training
- music
- n-gram
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MelodyGLM introduces a multi-task pre-training framework for symbolic
  melody generation that addresses the challenge of modeling multi-scale and multi-dimensional
  structures in music. The method uses melodic n-gram and long span sampling strategies
  to create local and global blank infilling tasks that capture pitch, rhythm, and
  their combined patterns.
---

# MelodyGLM: Multi-task Pre-training for Symbolic Melody Generation

## Quick Facts
- arXiv ID: 2309.10738
- Source URL: https://arxiv.org/abs/2309.10738
- Authors: 
- Reference count: 40
- Key outcome: MelodyGLM improves consistency, rhythmicity, structure, and overall quality by 0.82, 0.87, 0.78, and 0.94 points respectively compared to standard methods, with nearly human-level performance on melody inpainting.

## Executive Summary
MelodyGLM introduces a multi-task pre-training framework for symbolic melody generation that addresses the challenge of modeling multi-scale and multi-dimensional structures in music. The method uses melodic n-gram and long span sampling strategies to create local and global blank infilling tasks that capture pitch, rhythm, and their combined patterns. A large-scale dataset of 0.4 million melody pieces (MelodyNet) is constructed for pre-training. Subjective evaluations show MelodyGLM improves consistency, rhythmicity, structure, and overall quality by 0.82, 0.87, 0.78, and 0.94 points respectively compared to standard methods. On melody inpainting, it nearly matches human-composed melodies. Objective metrics confirm better modeling of pitch, rhythm, structure, and diversity compared to baselines.

## Method Summary
MelodyGLM employs a multi-task pre-training approach using two objectives: melodic n-gram blank infilling (15% corruption) for local structure modeling and long span blank infilling (50% corruption) for global structure modeling. The method introduces melodic n-gram sampling strategies that extract pitch, rhythm, and combined patterns using relative representations. A large-scale MelodyNet dataset containing 0.4 million melody pieces is constructed for domain-specific n-gram lexicon construction and pre-training. The model uses a unified encoder-decoder transformer architecture with modified attention patterns for blank infilling tasks, followed by fine-tuning on downstream melody continuation and inpainting tasks.

## Key Results
- MelodyGLM improves consistency, rhythmicity, structure, and overall quality by 0.82, 0.87, 0.78, and 0.94 points respectively compared to standard methods
- On melody inpainting, MelodyGLM nearly matches human-composed melodies
- Objective metrics confirm better modeling of pitch, rhythm, structure, and diversity compared to baselines

## Why This Works (Mechanism)

### Mechanism 1
The melodic n-gram sampling strategy captures multi-dimensional structural information in melodies more effectively than standard random masking. Melodic n-grams (pitch, rhythm, and combined) are extracted using relative representations and incorporated into blank infilling tasks, allowing the model to learn local patterns across multiple musical dimensions simultaneously.

### Mechanism 2
The multi-task pre-training framework with optimal corruption ratios improves both local and global structure modeling. Two pre-training objectives are combined - melodic n-gram blank infilling (15% corruption) for local structure and long span blank infilling (50% corruption) for global structure, allowing the model to learn patterns at multiple scales.

### Mechanism 3
The large-scale MelodyNet dataset enables effective domain-specific n-gram lexicon construction and improves pre-training. The dataset contains 0.4 million melody pieces, providing sufficient data for constructing a comprehensive melodic n-gram lexicon and pre-training the model on diverse musical patterns.

## Foundational Learning

- **Concept**: Symbolic music representation
  - Why needed here: The model needs to convert musical information into a format that can be processed by transformer architecture
  - Quick check question: How does the OctupleMIDI-like representation encode tempo, bar, position, pitch, and duration into single tokens?

- **Concept**: N-gram language modeling
  - Why needed here: N-grams capture local patterns in sequences, which is essential for modeling melodic structures
  - Quick check question: What's the difference between absolute and relative representation for melodic n-grams, and why use relative?

- **Concept**: Transformer architecture and attention mechanisms
  - Why needed here: The model uses a unified encoder-decoder transformer with modified attention patterns for blank infilling tasks
  - Quick check question: How does the attention mask matrix control the scope of attention in auto-regressive blank infilling?

## Architecture Onboarding

- **Component map**: Input module (multiple embedding layers) -> Transformer core (4-layer encoder-decoder with 8 attention heads) -> Output module (multiple softmax layers) -> Pre-training objectives (melodic n-gram and long span blank infilling tasks)

- **Critical path**: Data preprocessing → MelodyNet construction → N-gram lexicon creation → Multi-task pre-training → Fine-tuning on downstream tasks → Evaluation

- **Design tradeoffs**: Token vocabulary size vs model complexity; corruption ratio selection for different pre-training objectives; degree of melodic n-grams vs computational efficiency; use of relative vs absolute representations

- **Failure signatures**: Poor objective metrics (low similarity scores) indicate inadequate structure capture; low subjective scores suggest poor musicality despite good objective metrics; training instability might indicate inappropriate corruption ratios; overfitting signs (good objective but poor subjective scores) suggest dataset issues

- **First 3 experiments**:
  1. Compare single-task vs multi-task pre-training on objective metrics
  2. Test different melodic n-gram degrees (4, 8, 12) on local structure capture
  3. Evaluate different corruption ratios for melodic n-gram vs long span tasks

## Open Questions the Paper Calls Out

1. How does the optimal corruption ratio for melodic n-gram pre-training objectives vary across different musical genres or styles?
2. What is the relationship between n-gram degree and musical creativity in generated melodies?
3. How does MelodyGLM's performance scale with larger model sizes and longer training durations?

## Limitations

- The MelodyNet dataset construction process relies on heuristic filtering and manual annotation, with limited transparency about quality control measures
- The evaluation combines subjective human ratings with objective metrics, but inter-rater reliability and evaluator expertise are not reported
- The model is pre-trained on pop music melodies and evaluated on similar styles, with no evidence of cross-genre generalization

## Confidence

**High Confidence**: The multi-task pre-training framework improves performance on melody generation tasks compared to single-task approaches; the relative representation for melodic n-grams provides computational advantages over absolute representations; the model architecture with attention masking effectively handles blank infilling tasks.

**Medium Confidence**: The specific corruption ratios (15% for melodic n-gram, 50% for long span) are optimal; the MelodyNet dataset size (0.4 million pieces) is sufficient for effective pre-training; the objective metrics reliably measure musical quality.

**Low Confidence**: The improvements translate to real-world musical creativity and expression; the model generalizes beyond pop music to other genres; the subjective evaluation scores are stable across different evaluator groups.

## Next Checks

1. **Ablation Study on Corruption Ratios**: Systematically vary the corruption ratios for melodic n-gram (e.g., 10%, 15%, 20%) and long span (e.g., 40%, 50%, 60%) tasks to empirically determine optimal values.

2. **Cross-Genre Evaluation**: Test the pre-trained MelodyGLM model on melody datasets from different musical genres (classical, jazz, folk) to assess generalization capabilities.

3. **Long-term Consistency Analysis**: Generate extended melody sequences (e.g., 100+ bars) and evaluate structural coherence over time using both automated metrics and human expert evaluation.