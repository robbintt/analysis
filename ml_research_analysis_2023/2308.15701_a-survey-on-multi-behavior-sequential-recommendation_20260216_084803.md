---
ver: rpa2
title: A Survey on Multi-Behavior Sequential Recommendation
arxiv_id: '2308.15701'
source_url: https://arxiv.org/abs/2308.15701
tags:
- behavior
- item
- recommendation
- user
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a comprehensive survey of Multi-Behavior Sequential
  Recommendation (MBSR), a method for addressing the information overload problem
  in recommender systems. MBSR considers both the sequential nature and heterogeneity
  of user behaviors to provide personalized recommendations.
---

# A Survey on Multi-Behavior Sequential Recommendation

## Quick Facts
- arXiv ID: 2308.15701
- Source URL: https://arxiv.org/abs/2308.15701
- Reference count: 40
- Key outcome: Comprehensive survey categorizing MBSR methods into neighborhood-based, matrix factorization-based, and deep learning-based approaches (RNN, GNN, Transformer, hybrid)

## Executive Summary
This paper provides a comprehensive survey of Multi-Behavior Sequential Recommendation (MBSR), which addresses the information overload problem by considering both the sequential nature and heterogeneity of user behaviors. MBSR aims to provide personalized recommendations by modeling user interactions as sequences of (item, behavior) tuples, capturing both temporal order and behavior type. The survey categorizes existing works into three main approaches and analyzes their strengths, weaknesses, and future research directions.

## Method Summary
MBSR models user interactions as sequences of (item, behavior) pairs over time. The paper categorizes approaches into three main types: neighborhood-based methods that leverage similarity between items or users, matrix factorization-based methods that learn latent representations, and deep learning-based methods including RNNs, GNNs, Transformers, and hybrid architectures. Deep learning approaches use embeddings for items and behaviors, sequence modeling layers, behavior modeling through attention or graph convolutions, and prediction layers for target behaviors.

## Key Results
- MBSR considers both sequentiality and heterogeneity of user behaviors to achieve state-of-the-art recommendation performance
- Deep learning-based methods (RNN, GNN, Transformer) have shown significant improvements over traditional matrix factorization approaches
- Incorporating auxiliary behaviors (like browsing, adding to cart) as additional context improves target behavior prediction (like purchasing)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MBSR improves recommendation accuracy by modeling both sequentiality and heterogeneity of user behaviors
- Mechanism: Treating user interactions as sequences of (item, behavior) tuples and capturing both temporal order and behavior type learns richer user preference representations
- Core assumption: Heterogeneous behaviors provide complementary signals about user intent that can be effectively combined
- Evidence anchors: [abstract] "MBSR considers both sequentiality and heterogeneity of user behaviors, which can achieve state-of-the-art recommendation through suitable modeling."

### Mechanism 2
- Claim: Deep learning architectures effectively capture complex relationships in multi-behavior sequential data
- Mechanism: Transformer models use self-attention to capture relationships between items regardless of position, while GNNs model graph structure of item interactions across behaviors
- Core assumption: Attention mechanisms can effectively model dependencies between heterogeneous behaviors and sequential nature
- Evidence anchors: [abstract] "deep learning-based methods into different learning architectures based on RNN, GNN, Transformer, generic methods and hybrid methods."

### Mechanism 3
- Claim: Incorporating auxiliary behaviors improves target behavior prediction
- Mechanism: Model uses information from auxiliary behaviors to provide context for target behavior, helping disambiguate user intent
- Core assumption: Auxiliary behaviors are predictive of target behavior and provide useful context
- Evidence anchors: [abstract] "not only a user's target feedback, such as the purchase behavior during online shopping, but also the information from auxiliary feedback such as browsing and favorites will be considered."

## Foundational Learning

- Concept: Sequential modeling
  - Why needed here: MBSR explicitly models temporal order of user interactions, crucial for capturing dynamic user preferences
  - Quick check question: What is the difference between treating user interactions as a set versus a sequence in recommendation?

- Concept: Heterogeneous behavior modeling
  - Why needed here: MBSR considers multiple types of user interactions (browsing, adding to cart, purchasing), each providing different signals about user intent
  - Quick check question: How does the model distinguish between different types of user behaviors in the input data?

- Concept: Attention mechanisms
  - Why needed here: Attention allows model to focus on most relevant parts of user's interaction history when making predictions
  - Quick check question: How does the attention mechanism help the model handle sequences of varying lengths?

## Architecture Onboarding

- Component map: Input embeddings → Sequence modeling → Behavior modeling → Output prediction
- Critical path: Input embeddings → Sequence modeling → Behavior modeling → Output prediction
- Design tradeoffs:
  - Model complexity vs. interpretability: Deep learning models are more accurate but less interpretable than traditional methods
  - Computational cost vs. recommendation quality: More complex models require more computation but capture richer patterns
  - Data sparsity vs. model performance: MBSR requires sufficient data for each behavior type to learn effective representations
- Failure signatures:
  - Poor performance on cold-start users/items: Indicates insufficient data for learning effective representations
  - Overfitting: Model performs well on training data but poorly on test data
  - Slow inference: Model is too computationally expensive for real-time recommendations
- First 3 experiments:
  1. Compare performance of single-behavior model vs. MBSR model on dataset with multiple behavior types
  2. Evaluate impact of different sequence lengths on MBSR performance
  3. Test effectiveness of different deep learning architectures (Transformer, GNN, RNN) for MBSR

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we effectively model the long-term and short-term preferences of users in MBSR simultaneously?
- Basis in paper: [explicit] The paper states that modeling joint long-term and short-term preferences with heterogeneous behaviors of users is one of the challenges of MBSR
- Why unresolved: Most existing works focus on either long-term or short-term preferences, lacking research on how to model both effectively in MBSR
- What evidence would resolve it: A comprehensive study comparing performance of models that consider both long-term and short-term preferences in MBSR

### Open Question 2
- Question: How can we improve the generalization of models for MBSR?
- Basis in paper: [explicit] The paper mentions that improving the generalization of models for MBSR is a challenging issue
- Why unresolved: Most existing works focus on improving performance on specific datasets, lacking research on making models more generalizable across different datasets and scenarios
- What evidence would resolve it: A comprehensive study comparing performance of models on multiple datasets

### Open Question 3
- Question: How can we effectively model the relationships between different behaviors in MBSR?
- Basis in paper: [explicit] The paper states that modeling the relationship between user behaviors is one of the challenges of MBSR
- Why unresolved: Most existing works focus on modeling sequentiality of behaviors, lacking research on how to model relationships between different behaviors
- What evidence would resolve it: A comprehensive study comparing performance of models that consider relationships between different behaviors in MBSR

## Limitations

- The survey lacks detailed empirical validation of claimed mechanisms and performance comparisons between different MBSR approaches
- No specific evidence addresses potential challenges like data sparsity across behavior types or computational efficiency in production systems
- Theoretical claims about attention mechanisms and graph neural networks are not backed by ablation studies or controlled experiments

## Confidence

- **High confidence**: Categorization of MBSR methods into neighborhood-based, matrix factorization-based, and deep learning-based approaches is well-supported by literature
- **Medium confidence**: Claims about deep learning architectures being more effective than traditional methods are reasonable but lack specific MBSR evidence
- **Low confidence**: Assertion that incorporating auxiliary behaviors consistently improves recommendation quality is presented without qualification about when this might fail

## Next Checks

1. Implement and compare multiple MBSR approaches (Transformer, GNN, RNN) on the same dataset with consistent evaluation metrics to verify claimed performance differences
2. Systematically remove different behavior types from input data to quantify their individual contributions to recommendation quality
3. Measure training and inference times across different dataset sizes and behavior types to establish practical computational limits and identify optimization opportunities