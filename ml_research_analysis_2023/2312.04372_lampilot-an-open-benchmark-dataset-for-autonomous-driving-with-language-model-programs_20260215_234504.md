---
ver: rpa2
title: 'LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language Model
  Programs'
arxiv_id: '2312.04372'
source_url: https://arxiv.org/abs/2312.04372
tags:
- vehicle
- lane
- driving
- language
- speed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LaMPilot is a novel benchmark for autonomous driving with language
  model programs. It evaluates LLMs' ability to interpret spontaneous user instructions
  and generate executable code for vehicle control.
---

# LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language Model Programs

## Quick Facts
- **arXiv ID:** 2312.04372
- **Source URL:** https://arxiv.org/abs/2312.04372
- **Authors:** Multiple authors
- **Reference count:** 40
- **Primary result:** Evaluates LLMs' ability to interpret user instructions and generate executable code for vehicle control in autonomous driving scenarios

## Executive Summary
LaMPilot is a novel benchmark framework that integrates Large Language Models (LLMs) into autonomous driving systems by enabling them to follow user instructions through code generation. The framework combines an interactive simulator with a dataset of 4.9K human-annotated instruction-scene pairs, allowing LLMs to generate Python Language Model Programs (LMPs) that call specialized functional primitives for perception, planning, and control tasks. GPT-4 with human feedback achieves a task completion rate of 92.7% and a minimal collision rate of 0.9%, demonstrating the potential of LLMs in handling diverse driving scenarios while maintaining safety and efficiency.

## Method Summary
The LaMPilot framework uses LLMs to generate executable driving policies by mapping natural language instructions to code through functional primitives. The system employs a structured language generator to convert numerical simulator state vectors into natural language descriptions, then combines this with API documentation in prompts sent to LLMs. The generated code calls specialized APIs for perception, planning, and control tasks, which are executed in the simulator. Performance is evaluated using safety, comfort, and efficiency metrics, with optional human feedback integration through a code repository that stores effective code snippets for future reuse.

## Key Results
- GPT-4 with human feedback achieves 92.7% task completion rate and 0.9% collision rate
- The framework demonstrates LLMs' ability to handle diverse driving scenarios through code generation
- LaMPilot provides the first open benchmark dataset specifically designed for evaluating LLMs in autonomous driving contexts

## Why This Works (Mechanism)

### Mechanism 1
Large Language Models can generate executable driving policies by mapping natural language instructions to code using functional primitives. The framework leverages LLMs to produce Python Language Model Programs (LMPs) that call specialized APIs for perception, planning, and control, enabling the translation of high-level commands into executable driving actions.

### Mechanism 2
The use of a structured language generator and API documentation in prompts enables LLMs to effectively utilize simulator state information and available functions. Numerical simulator state vectors are converted into natural language descriptions, and API documentation is included in prompts, providing LLMs with the necessary context to generate appropriate code.

### Mechanism 3
Human feedback integration via a code repository enhances LLM performance by allowing iterative refinement of generated policies. After an LLM generates a policy, human feedback is used to refine the output. Effective code snippets are stored in a code repository for future reuse, improving performance over time.

## Foundational Learning

- **Concept: Functional primitives for autonomous driving**
  - Why needed here: Provide a safe and structured interface for LLMs to interact with the driving environment, offloading low-level control tasks to specialized APIs
  - Quick check question: What are the four main categories of functional primitives in LaMPilot, and what is the purpose of each?

- **Concept: Code as Policy paradigm**
  - Why needed here: Enables the use of LLMs to generate executable policies by treating code as the action space, rather than low-level control commands
  - Quick check question: How does the Code as Policy approach differ from traditional methods of controlling autonomous vehicles?

- **Concept: Human-in-the-loop learning**
  - Why needed here: Allows for iterative refinement of LLM-generated policies by incorporating human feedback, improving performance over time
  - Quick check question: How does the human-in-the-loop approach in LaMPilot differ from traditional data-driven autonomous driving systems?

## Architecture Onboarding

- **Component map:** Simulator (HighwayEnv-based) -> Dataset (4.9K human-annotated pairs) -> LLM (code generation) -> Functional primitives (API suite) -> Structured language generator -> API documentation -> Code repository (for human feedback) -> Evaluator (safety, comfort, efficiency metrics)

- **Critical path:** 1. Initial state and instruction are provided 2. Structured language generator converts state to natural language 3. Prompt (instruction, state description, API docs) is sent to LLM 4. LLM generates LMP code 5. LMP is executed in simulator 6. Policy performance is evaluated 7. (Optional) Human feedback is incorporated and code is stored in repository

- **Design tradeoffs:** Safety vs. flexibility: Using functional primitives ensures safety but may limit the LLM's ability to generate novel solutions. Latency vs. complexity: Generating long code completions can introduce latency, making LLMs less suitable for time-critical tasks. Interpretability vs. performance: Code-based policies are more interpretable than black-box models but may not achieve the same level of performance.

- **Failure signatures:** LLM generates invalid or unsafe code, Simulator fails to execute the generated code, Evaluation metrics indicate poor performance (low safety, comfort, or efficiency scores), Human feedback indicates dissatisfaction with the generated policy

- **First 3 experiments:** 1. Run a simple instruction (e.g., "accelerate to 30 m/s") through the entire pipeline to verify basic functionality 2. Test the LLM's ability to generate code for a more complex instruction (e.g., "make a right lane change") and evaluate the resulting policy 3. Introduce human feedback for a failed policy and verify that the refined code performs better

## Open Questions the Paper Calls Out

### Open Question 1
How does the LaMPilot framework handle ambiguous or contradictory user instructions that may not have a clear or safe execution path? The paper discusses the challenge of interpreting and executing spontaneous user instructions but does not explicitly address how the system handles ambiguous or contradictory instructions.

### Open Question 2
What is the impact of varying traffic densities on the performance of LLMs in the LaMPilot benchmark, and how does the system adapt to different traffic conditions? The paper mentions that the simulator includes randomly generated traffic patterns with various density settings but does not provide specific results or analysis on the impact of traffic density on LLM performance.

### Open Question 3
How does the LaMPilot framework ensure the safety of the generated policies in complex and dynamic traffic scenarios, beyond the predefined safety criteria in the APIs? The paper mentions that the API suite is developed with insights from Responsibility-Sensitive Safety (RSS) but does not provide a detailed explanation of how the framework handles complex and dynamic traffic scenarios.

## Limitations

- The framework's reliance on functional primitives may constrain the LLM's ability to generate truly novel solutions, potentially limiting performance in complex, unseen scenarios
- The structured language generator and API documentation approach has not been extensively validated for autonomous driving code generation
- Human feedback integration is promising but lacks robust validation, with potential for inconsistent or ineffective refinement

## Confidence

- **High:** The core concept of using LLMs to generate code for autonomous driving tasks is well-established, with strong evidence from the experimental results showing high task completion rates and low collision rates
- **Medium:** The effectiveness of the structured language generator and API documentation approach is supported by the results but lacks extensive corpus validation
- **Low:** The long-term benefits and robustness of the human feedback integration and code repository approach are promising but not yet fully validated

## Next Checks

1. **Robustness Testing:** Conduct extensive testing of the framework in a wide range of complex, unseen scenarios to evaluate its ability to handle diverse driving situations and edge cases
2. **Ablation Study:** Perform an ablation study to quantify the impact of the structured language generator and API documentation on LLM performance, isolating their individual contributions
3. **Human Feedback Evaluation:** Design a comprehensive study to assess the quality and consistency of human feedback, and evaluate the effectiveness of the code repository in improving LLM performance over time