---
ver: rpa2
title: Knowledge Engineering using Large Language Models
arxiv_id: '2310.00637'
source_url: https://arxiv.org/abs/2310.00637
tags:
- knowledge
- language
- llms
- engineering
- natural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores the potential role of large language models
  (LLMs) in knowledge engineering (KE), identifying two main directions: 1) creating
  hybrid neuro-symbolic knowledge systems by using LLMs as components or tools, and
  2) enabling knowledge engineering in natural language through prompt engineering.
  The authors argue that LLMs can facilitate the transformation of knowledge expressed
  in natural language into formal language, which is a core aspect of KE.'
---

# Knowledge Engineering using Large Language Models

## Quick Facts
- arXiv ID: 2310.00637
- Source URL: https://arxiv.org/abs/2310.00637
- Reference count: 40
- Key outcome: This paper explores the potential role of large language models (LLMs) in knowledge engineering (KE), identifying two main directions: 1) creating hybrid neuro-symbolic knowledge systems by using LLMs as components or tools, and 2) enabling knowledge engineering in natural language through prompt engineering.

## Executive Summary
This paper examines how large language models can transform knowledge engineering by serving as bridges between natural language and formal representations. The authors propose two primary approaches: using LLMs as components in hybrid neuro-symbolic systems, and enabling knowledge engineering entirely through natural language prompt engineering. They argue that LLMs can significantly lower the barrier to knowledge engineering by allowing subject matter experts to work directly in natural language rather than formal languages, while also raising important questions about methodology, architecture, evaluation, and trust in knowledge systems with LLM components.

## Method Summary
The paper reviews existing knowledge engineering methodologies like CommonKADS and proposes adaptations to incorporate large language models. It explores two scenarios: using LLMs as components in hybrid neuro-symbolic knowledge systems, and enabling knowledge engineering entirely through natural language prompt engineering. The authors analyze how LLMs can transform knowledge expressed in natural language into formal language representations, discussing the implications for knowledge acquisition, organization, and reasoning tasks. They identify open research questions related to methodology, architecture, and evaluation of knowledge systems with LLM components.

## Key Results
- LLMs can serve as bridges for transforming knowledge from natural language to formal representations, enabling more efficient knowledge engineering workflows
- Prompt engineering can potentially become the primary paradigm for knowledge engineering, allowing subject matter experts to directly encode knowledge without formal language expertise
- Hybrid neuro-symbolic architectures incorporating LLMs can combine deep learning's strength with symbolic reasoning's explainability and consistency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs serve as a bridge for transforming knowledge expressed in natural language into formal language, enabling more efficient knowledge engineering workflows
- Mechanism: LLMs act as a general-purpose technology for mapping between natural language (including images, video, and structured data) and formal representations like knowledge graphs, rules, or code
- Core assumption: LLMs have sufficient capability to accurately translate complex domain knowledge from natural language into formal language without significant loss of meaning or structure
- Evidence anchors: [abstract] "The emergence of large language models and their capabilities to effectively work with natural language, in its broadest sense, raises questions about the foundations and practice of knowledge engineering." [section] "LLMs have shown state-of-the-art performance on challenging NLP tasks such as relation extraction [5] or text abstraction/summarization [114], and have been used to translate between other modalities, such as images and text (called vision-language models [119, 77]) in computer vision tasks, or from natural language to code [113, 47]."
- Break condition: If LLM-generated formal representations contain significant errors or hallucinations that cannot be reliably detected and corrected through prompt engineering or human review

### Mechanism 2
- Claim: Prompt engineering can serve as the primary paradigm for knowledge engineering, enabling subject matter experts to directly encode knowledge without formal language expertise
- Mechanism: By treating knowledge engineering as a process of crafting dialogues between subject matter experts and LLMs, knowledge can be elicited and organized entirely in natural language
- Core assumption: Predictable inference using natural language is sufficient for the target knowledge-intensive tasks, and hallucination issues can be adequately addressed through prompt design patterns and retrieval-augmented generation
- Evidence anchors: [abstract] "LLMs also exhibit the ability to generate and interpret structured and semi-structured information, including programming language code [6, 100], tables [46, 53], and RDF metadata [106, 58, 7]." [section] "Given that LLMs enable knowledge modeling in natural language, it is conceivable that the programming of knowledge modules could take place entirely in natural language. Consider that prompt programming is 'finding the most appropriate prompt to allow an LLM to solve a task' [57]."
- Break condition: If the quality and reliability of LLM-generated knowledge structures consistently fall below acceptable thresholds for the target application domain, or if subject matter experts struggle to effectively craft prompts without understanding formal knowledge representation principles

### Mechanism 3
- Claim: Hybrid neuro-symbolic architectures incorporating LLMs can combine the strengths of deep learning (handling unstructured data) with symbolic reasoning (providing explainability and consistency)
- Mechanism: LLMs can be integrated as components within larger knowledge systems that also include traditional symbolic representations, inference engines, and data processing pipelines
- Core assumption: The integration of LLMs with symbolic components can be achieved without introducing excessive complexity or performance bottlenecks, and the resulting systems can provide clear explanations for their reasoning
- Evidence anchors: [abstract] "One approach involves treating LLMs as components within hybrid neuro-symbolic knowledge systems." [section] "Design patterns for hybrid neuro-symbolic systems, as described in [103], offer a structured approach to comprehend the flow of data within a knowledge system. Adapting this model to account for the differences between natural and formal language could significantly enhance our ability to trace and manage data within knowledge systems."
- Break condition: If the integration of LLMs with symbolic components introduces significant latency, reduces system reliability, or makes the overall architecture too complex to maintain effectively

## Foundational Learning

- Concept: Knowledge engineering fundamentals (ontology development, knowledge acquisition, knowledge representation)
  - Why needed here: Understanding traditional KE methods is crucial for identifying where LLMs can augment or replace existing processes, and for adapting established methodologies like CommonKADS to incorporate LLM components
  - Quick check question: What are the main differences between a frame-based and a rule-based knowledge representation approach, and how might each be affected by LLM integration?

- Concept: Natural language processing and understanding capabilities of LLMs
  - Why needed here: Engineers need to understand the strengths and limitations of current LLMs to effectively design prompts and evaluate their outputs for knowledge engineering tasks
  - Quick check question: What are the key differences between zero-shot, few-shot, and fine-tuning approaches when using LLMs for knowledge engineering tasks?

- Concept: Multimodal data processing and integration
  - Why needed here: Many knowledge domains involve diverse data types (text, images, video, structured data) that need to be processed and integrated into coherent knowledge representations
  - Quick check question: How do vision-language models like CLIP or Flamingo handle the alignment between visual and textual information, and what are the implications for multimodal knowledge engineering?

## Architecture Onboarding

- Component map: LLM core -> Prompt management system -> Formal representation converter -> Validation layer -> Integration adapters -> Human-in-the-loop interface
- Critical path: Prompt creation → LLM processing → Output validation → Formal representation conversion → Knowledge base integration
- Design tradeoffs:
  - Prompt complexity vs. output reliability: More detailed prompts may yield better results but are harder to create and maintain
  - LLM size vs. response time: Larger models may provide better quality but increase latency and cost
  - Automation level vs. human oversight: More automated systems reduce human effort but may miss subtle domain-specific nuances
  - Generalization vs. specialization: More general LLM approaches are more flexible but may perform worse on specific tasks
- Failure signatures:
  - Consistent hallucination patterns in specific knowledge domains
  - Degradation in output quality when prompts become too complex
  - Unexpected behavior when combining multiple LLM components
  - Performance bottlenecks when scaling to large knowledge bases
- First 3 experiments:
  1. Implement a simple knowledge extraction pipeline using an LLM to convert natural language domain descriptions into a basic knowledge graph structure, measuring accuracy against a manually created gold standard
  2. Create a prompt template system for a specific domain (e.g., biodiversity) and evaluate how different prompt formulations affect the quality and consistency of generated knowledge representations
  3. Build a small hybrid system that combines LLM-generated text analysis with traditional rule-based reasoning, testing the integration points and measuring the benefits of the hybrid approach for a specific use case

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can existing knowledge engineering methodologies be adapted to effectively incorporate large language models?
- Basis in paper: [explicit] The paper discusses the need to adapt methodologies like CommonKADS to accommodate LLMs and prompt engineering, identifying this as a key open research question
- Why unresolved: LLMs introduce new capabilities and challenges that existing methodologies were not designed to handle, requiring significant modifications to integrate these technologies effectively
- What evidence would resolve it: Development and validation of new or modified KE methodologies that successfully incorporate LLMs, demonstrating improved efficiency or outcomes in real-world applications

### Open Question 2
- Question: How can prompt engineering patterns be developed to support reasoning in natural language within hybrid neuro-symbolic systems?
- Basis in paper: [explicit] The paper highlights the need to explore how prompt engineering can facilitate reasoning in natural language, particularly in the context of hybrid systems combining LLMs with symbolic representations
- Why unresolved: Current prompt engineering techniques are primarily focused on task completion rather than structured reasoning, and their application in hybrid systems is not yet well understood
- What evidence would resolve it: Creation and evaluation of prompt engineering patterns that enable reliable and explainable reasoning in natural language, validated through experiments in knowledge-intensive tasks

### Open Question 3
- Question: How can bias, trust, and control be managed in large language models when integrated with knowledge graphs?
- Basis in paper: [explicit] The paper identifies the challenge of ensuring trust and mitigating bias in LLMs, especially when they are used in conjunction with knowledge graphs
- Why unresolved: LLMs are prone to generating biased or unreliable outputs, and integrating them with knowledge graphs introduces additional complexities in maintaining accuracy and trustworthiness
- What evidence would resolve it: Development of robust methods for detecting, measuring, and mitigating bias in LLMs, along with mechanisms for updating and auditing knowledge graphs to ensure reliability

## Limitations

- The paper presents a conceptual framework rather than empirical results, making it difficult to assess the practical effectiveness of proposed approaches
- Specific implementation guidelines for adapting methodologies like CommonKADS to incorporate LLMs are lacking
- Claims about prompt engineering becoming the primary paradigm for knowledge engineering are speculative without concrete evidence of reliability and accuracy

## Confidence

**High confidence**: The core observation that LLMs can process and generate structured knowledge representations is well-supported by existing literature and demonstrated capabilities in relation extraction and code generation.

**Medium confidence**: The proposed adaptation of KE methodologies like CommonKADS to incorporate LLMs is conceptually sound but lacks empirical validation.

**Low confidence**: The specific claims about prompt engineering becoming the primary paradigm for knowledge engineering are speculative, with significant challenges around hallucination and reliability that remain unaddressed.

## Next Checks

1. **Benchmarking knowledge transformation accuracy**: Implement a controlled experiment comparing LLM-generated formal knowledge representations against human-created gold standards across multiple domains, measuring precision, recall, and hallucination rates.

2. **Methodological adaptation evaluation**: Apply both traditional and LLM-incorporating versions of CommonKADS to the same knowledge engineering project, comparing development time, accuracy, maintainability, and expert satisfaction.

3. **Hybrid system integration stress test**: Build a prototype hybrid neuro-symbolic system and subject it to adversarial testing with edge cases, contradictory information, and multimodal inputs to identify failure modes and integration challenges.