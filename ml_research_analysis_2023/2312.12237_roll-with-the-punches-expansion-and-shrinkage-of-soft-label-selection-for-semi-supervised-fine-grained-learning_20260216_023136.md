---
ver: rpa2
title: 'Roll With the Punches: Expansion and Shrinkage of Soft Label Selection for
  Semi-supervised Fine-Grained Learning'
arxiv_id: '2312.12237'
source_url: https://arxiv.org/abs/2312.12237
tags:
- class
- classes
- soft
- label
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of semi-supervised learning
  (SSL) with fine-grained data, where high recognition difficulty leads to inaccurate
  pseudo-labels and poor model performance. The authors propose Soft Label Selection
  with Confidence-Aware Clustering based on Class Transition Tracking (SoC), which
  jointly optimizes Expansion and Shrinkage Objectives to generate more effective
  soft labels.
---

# Roll With the Punches: Expansion and Shrinkage of Soft Label Selection for Semi-supervised Fine-Grained Learning

## Quick Facts
- arXiv ID: 2312.12237
- Source URL: https://arxiv.org/abs/2312.12237
- Reference count: 40
- This paper proposes SoC, achieving up to 12.3% accuracy improvements over state-of-the-art SSL baselines for fine-grained semi-supervised learning.

## Executive Summary
This paper addresses the challenge of semi-supervised learning with fine-grained data, where high recognition difficulty leads to inaccurate pseudo-labels and poor model performance. The authors propose Soft Label Selection with Confidence-Aware Clustering based on Class Transition Tracking (SoC), which jointly optimizes Expansion and Shrinkage Objectives to generate more effective soft labels. Expansion encourages soft labels to absorb candidate classes likely to contain the ground truth, while Shrinkage encourages rejection of noisy classes. Class Transition Tracking (CTT) measures similarity between classes based on prediction oscillations during training, enabling k-medoids clustering to select candidate classes. Confidence-Aware k Selection dynamically adjusts clustering granularity based on prediction confidence. Experiments on Semi-Aves and Semi-Fungi datasets show that SoC consistently outperforms state-of-the-art SSL methods.

## Method Summary
SoC tackles semi-supervised fine-grained visual classification by generating soft labels through a two-step process: expansion and shrinkage. The method uses Class Transition Tracking to measure class similarity based on prediction oscillations, then applies k-medoids clustering to select candidate classes. A confidence-aware mechanism dynamically adjusts cluster granularity, expanding candidate sets for uncertain predictions and shrinking them for confident ones. The approach combines supervised and consistency losses with a weighting parameter λcos, trained for 400k iterations with ResNet-50 backbone and heavy augmentation.

## Key Results
- SoC achieves up to 12.3% accuracy improvements over the best SSL baselines on Semi-Aves and Semi-Fungi datasets
- The method demonstrates particular effectiveness in handling fine-grained data challenges in SSL scenarios
- Consistent performance improvements across both Top-1 and Top-5 accuracy metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Entropy minimization is achieved by shrinking the candidate class set size.
- Mechanism: By progressively reducing the number of classes in the soft label set (ki), the entropy of the selected soft label distribution decreases, aligning with the theoretical proof in Theorem 1.
- Core assumption: The soft label selection process ensures the ground truth class remains within the candidate set while removing noisy classes.
- Evidence anchors:
  - [abstract]: "the latter encourages soft labels to reject more noisy classes, which is theoretically proved to be equivalent to entropy minimization."
  - [section 3.3]: "By Theorem 1, we propose to 'shrink' Ci to optimize Obj. 2. Since Ci is obtained by Eq. (9), a feasible way to 'shrink' Ci is to decrease the number of classes in the clusters obtained by k-medoids clustering, i.e., enlarging k."
  - [corpus]: Weak evidence; corpus neighbors focus on pseudo-label selection strategies but do not explicitly discuss entropy minimization via class set shrinking.
- Break condition: If the ground truth class is excluded during shrinking, the model may converge to incorrect predictions.

### Mechanism 2
- Claim: Class similarity is captured by tracking prediction transitions across training epochs.
- Mechanism: The frequency of class label switches (e.g., from "Streptopelia chinensis" to "Streptopelia orientalis") is used as a proxy for similarity; frequent transitions imply the classes are confusable and thus similar.
- Core assumption: Prediction oscillation indicates similarity in the feature space, which is more discriminative than static distance metrics.
- Evidence anchors:
  - [section 3.2]: "the more frequent the transition between two classes, the greater the similarity between the two classes and the closer they are in the class space."
  - [section 3.2]: "We innovatively introduce Class Transition Tracking (CTT) technique to measure the similarity (rather than distance) between classes for clustering."
  - [corpus]: No direct evidence; corpus neighbors focus on general SSL techniques but not transition-based similarity.
- Break condition: If the model's predictions stabilize too early or oscillate randomly, the transition matrix may not reflect true class similarity.

### Mechanism 3
- Claim: Confidence-aware k selection dynamically adjusts cluster granularity to balance exploration and exploitation.
- Mechanism: High-confidence predictions trigger finer clustering (larger k), reducing the candidate set and enforcing entropy minimization; low-confidence predictions trigger coarser clustering (smaller k), expanding the candidate set to retain potential ground truth classes.
- Core assumption: Confidence score correlates with sample difficulty and thus informs the optimal cluster granularity.
- Evidence anchors:
  - [section 3.3]: "the larger the confidence, the larger the k... the harder samples should be from clusters with coarser granularity (i.e. smaller k)."
  - [section 3.3]: "the more confident the model is in its prediction, the more it should shrink the range of candidate classes."
  - [corpus]: No direct evidence; corpus neighbors do not discuss confidence-aware cluster granularity.
- Break condition: If confidence scores are miscalibrated, the granularity adjustment may overfit or underfit the candidate set.

## Foundational Learning

- Concept: Semi-supervised learning (SSL) fundamentals.
  - Why needed here: SoC extends SSL by handling fine-grained data where pseudo-label accuracy is low; understanding SSL self-training loops is essential.
  - Quick check question: In SSL, how does consistency regularization help when labeled data is scarce?

- Concept: Entropy minimization in pseudo-labeling.
  - Why needed here: SoC's Shrinkage Objective is proven equivalent to entropy minimization; knowing why this reduces confirmation bias is key.
  - Quick check question: Why does minimizing entropy over pseudo-labels improve model calibration?

- Concept: Clustering algorithms (k-medoids vs k-means).
  - Why needed here: SoC uses k-medoids with similarity input rather than Euclidean distance; understanding this choice is important for correct implementation.
  - Quick check question: When is k-medoids preferred over k-means in label space clustering?

## Architecture Onboarding

- Component map: Backbone (ResNet-50) -> CTT tracker -> k-medoids clusterer -> Confidence mapper -> Soft label selector -> Loss combiner
- Critical path: Forward pass → confidence scoring → k selection → CTT-based clustering → soft label masking → loss computation
- Design tradeoffs:
  - Larger k increases exploration but risks noise inclusion
  - Smaller k enforces entropy minimization but may exclude true class
  - CTT frequency resolution trades off between stability and responsiveness
- Failure signatures:
  - High variance in k across epochs → unstable clustering
  - k=2 for most samples → overly coarse selection
  - Entropy of selected soft labels not decreasing → shrinking ineffective
- First 3 experiments:
  1. Validate CTT similarity matrix: compare transition frequency with known class confusion pairs on CIFAR-10
  2. Test k selection sensitivity: sweep α and observe Top-1 accuracy on Semi-Aves
  3. Ablation of clustering granularity: fix k=100 vs dynamic k, measure entropy and accuracy trade-off

## Open Questions the Paper Calls Out
No specific open questions were called out in the paper.

## Limitations
- The method relies on Class Transition Tracking, which may not generalize well to datasets where prediction oscillations don't reflect true class similarity
- Performance depends on carefully tuned hyperparameters, particularly the confidence threshold α for k selection
- The approach requires maintaining and updating a class transition matrix throughout training, adding computational overhead

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Equivalence between shrinkage objectives and entropy minimization (Theorem 1) | High |
| Effectiveness of CTT-based similarity measurement in practice | Medium |
| Dynamic k selection mechanism's robustness across different dataset characteristics | Medium |

## Next Checks
1. Test CTT sensitivity by comparing transition-based similarity against ground-truth confusion matrices on controlled fine-grained datasets
2. Evaluate SoC performance under varying levels of label noise to assess robustness of the expansion/shrinkage balance
3. Conduct hyperparameter sensitivity analysis for α across different fine-grained datasets to establish general applicability guidelines