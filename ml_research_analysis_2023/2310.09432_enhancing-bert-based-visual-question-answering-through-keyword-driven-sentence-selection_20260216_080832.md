---
ver: rpa2
title: Enhancing BERT-Based Visual Question Answering through Keyword-Driven Sentence
  Selection
arxiv_id: '2310.09432'
source_url: https://arxiv.org/abs/2310.09432
tags:
- visual
- language
- document
- question
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a keyword-driven sentence selection approach
  for enhancing BERT-based Visual Question Answering (VQA) on multi-page documents.
  The core idea is to fine-tune a BERT model using Masked Language Modeling (MLM)
  on a subset of sentences containing keywords relevant to the questions, such as
  references to tables or figures.
---

# Enhancing BERT-Based Visual Question Answering through Keyword-Driven Sentence Selection

## Quick Facts
- arXiv ID: 2310.09432
- Source URL: https://arxiv.org/abs/2310.09432
- Reference count: 14
- Primary result: 0.38484 exact matching accuracy on private leaderboard, second place overall

## Executive Summary
This paper presents a keyword-driven sentence selection approach for enhancing BERT-based Visual Question Answering (VQA) on multi-page documents. The core innovation involves fine-tuning a BERT model using Masked Language Modeling (MLM) on a subset of sentences containing keywords relevant to the questions, particularly references to tables or figures. This targeted sampling strategy significantly reduces training samples and time while focusing the model on the most frequently queried document elements. The proposed approach achieves strong performance on the PDF-VQA leaderboard, demonstrating the effectiveness of domain-specific fine-tuning for document-based VQA tasks.

## Method Summary
The approach involves three main steps: (1) preprocessing the dataset to extract sentences containing keywords related to tables or figures from training documents, reducing samples from 75,791 to 10,543; (2) fine-tuning BERT with MLM on this keyword-enriched subset using Cross-Entropy loss and AdamW optimizer for 50 epochs; and (3) extracting embeddings from the entire training corpus using the fine-tuned BERT, then training a transformer decoder to answer questions. The method focuses on parent-relationship questions and leverages keyword matching between questions and document text to identify relevant regions.

## Key Results
- Achieved 0.38484 exact matching accuracy on private leaderboard, placing second overall
- Outperformed baseline BERT result of 0.32142 by 6.34 percentage points
- Text-only approach outperformed multimodal variant that concatenated visual features
- Successfully reduced training samples by ~86% through keyword-driven selection

## Why This Works (Mechanism)

### Mechanism 1
Keyword-driven sentence selection focuses model training on the most relevant document elements (tables/figures) for the task by filtering training sentences to those containing keywords also present in questions, constraining the model's attention to high-value regions of the document. This works under the assumption that most parent-relationship questions in this dataset are about tables and figures.

### Mechanism 2
Masked Language Modeling fine-tuning with keyword-enriched text improves domain adaptation by helping BERT learn specialized representations for document elements through the 15% token masking strategy, which effectively exposes the model to diverse contextual patterns within the document domain.

### Mechanism 3
Text-only approach outperforms multimodal alternatives for this task because text embeddings alone capture sufficient information to identify relevant document regions, suggesting that visual features add noise rather than value when textual context is strong.

## Foundational Learning

- Concept: Masked Language Modeling
  - Why needed here: Provides domain adaptation by learning document-specific token representations
  - Quick check question: What percentage of tokens are masked during BERT MLM fine-tuning according to the original paper?

- Concept: Keyword matching for document retrieval
  - Why needed here: Enables efficient sampling of relevant sentences for model training
  - Quick check question: What document elements were most frequently queried in the dataset?

- Concept: Transformer-based decoding
  - Why needed here: Converts enriched text embeddings into region predictions
  - Quick check question: What loss function was used during decoder training?

## Architecture Onboarding

- Component map: BERT fine-tuner (MLM) → Text embedder → Transformer decoder → EMA metric
- Critical path: Fine-tuning → Embedding extraction → Decoding → Evaluation
- Design tradeoffs: Text-only vs multimodal (visual features + text) for balancing performance and complexity
- Failure signatures: High validation loss during fine-tuning, low EMA on validation set, overfitting to keywords
- First 3 experiments:
  1. Compare EMA with and without keyword-driven sampling on validation set
  2. Test different masking ratios (10%, 15%, 20%) during MLM fine-tuning
  3. Evaluate performance with and without visual feature concatenation

## Open Questions the Paper Calls Out

### Open Question 1
How would the keyword-driven sentence selection approach perform if extended to include additional relevant keywords beyond figures and tables, such as in-text citations or other document elements? The authors suggest that extending the set of relevant keywords to other PRs could enhance the strategy, but this remains unexplored.

### Open Question 2
What would be the effect of tailoring the fine-tuning data subset specifically to the Child-Relationship (CR) understanding sub-task, as opposed to the current focus on PR understanding? The authors suggest this could enhance their solution, but have not investigated it.

### Open Question 3
How would the integration of alternative methodologies for combining visual features with textual embeddings affect the overall performance of the VQA model? The authors express interest in exploring different methodologies for amalgamating visual features in future work.

### Open Question 4
What impact would the use of alternative representations based on the intrinsic relationships between constituent elements of each document have on the model's performance? The authors express interest in utilizing alternative representations predicated on the intrinsic relationships existing between constituent elements of each document.

## Limitations
- Specific keyword list used for sentence selection is not provided, making exact replication difficult
- Approach assumes tables and figures are primary queried elements, limiting generalizability to other document types
- Superiority of text-only approach demonstrated only on single dataset, may not hold for visually-dependent questions

## Confidence

- **High confidence**: Overall experimental setup and evaluation methodology are well-described and reproducible
- **Medium confidence**: Claim that keyword-driven sampling significantly improves performance is supported by leaderboard results
- **Medium confidence**: Assertion that text-only approaches outperform multimodal alternatives is based on single comparison

## Next Checks

1. **Keyword List Validation**: Conduct an ablation study by testing different keyword lists (including broader and narrower sets) to quantify the impact of keyword selection on performance and determine the optimal keyword coverage.

2. **Cross-Dataset Generalization**: Evaluate the proposed approach on a different VQA dataset with a different question distribution and document types to assess the generalizability of the keyword-driven sampling strategy and the text-only superiority claim.

3. **Ablation of Design Choices**: Perform a systematic ablation study to isolate the contribution of each design choice (e.g., masking ratio in MLM, decoder architecture, text-only vs. multimodal) to the overall performance, providing a clearer understanding of the approach's strengths and weaknesses.