---
ver: rpa2
title: On the Benefits of Public Representations for Private Transfer Learning under
  Distribution Shift
arxiv_id: '2312.15551'
source_url: https://arxiv.org/abs/2312.15551
tags:
- private
- public
- subspace
- learning
- regression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work studies private transfer learning where public data
  is used to improve private learning when there is distribution shift between public
  and private tasks. We consider two settings: single-task transfer (learning one
  private model) and multitask transfer (learning personalized models for multiple
  users).'
---

# On the Benefits of Public Representations for Private Transfer Learning under Distribution Shift

## Quick Facts
- arXiv ID: 2312.15551
- Source URL: https://arxiv.org/abs/2312.15551
- Reference count: 40
- Key outcome: Public data can improve private learning accuracy by up to 67% under large distribution shift by leveraging shared low-dimensional representations

## Executive Summary
This paper studies private transfer learning where public data from related tasks is used to improve private learning when there is distribution shift between public and private tasks. The authors consider two settings: single-task transfer (learning one private model) and multitask transfer (learning personalized models for multiple users). They show that even with large distribution shift, public representations can significantly improve private training accuracy by enabling subspace projection that reduces the effective dimensionality of the learning problem. The theoretical justification demonstrates that when public and private tasks share a low-dimensional representation, public data improves the sample complexity of private training even when the private task cannot be learned from public data alone.

## Method Summary
The approach uses a two-phase method: first estimating a shared low-dimensional subspace from public data using method-of-moments estimators, then projecting private data into this estimated subspace and running private linear regression. For single-task transfer, this involves row-level differential privacy with projected data. For multitask transfer, the framework uses user-level differential privacy with either private alternating minimization or local linear regression in the estimated subspace, depending on the subspace accuracy. The key insight is that subspace projection reduces the effective dimensionality from d to k (the subspace dimension), improving sample complexity even under privacy constraints.

## Key Results
- Public representations can improve private training accuracy by up to 67% over private training from scratch
- The subspace projection approach achieves optimal excess risk bounds among algorithms constrained to the estimated subspace
- In multitask settings, with sufficient public data, users can avoid private coordination and achieve the same utility through local learning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Public representations improve private training even under large distribution shift by enabling subspace projection
- Mechanism: When public and private tasks share a low-dimensional subspace, projecting private inputs into the publicly estimated subspace reduces the effective dimensionality of the learning problem. The residual outside the subspace acts as independent Gaussian noise, allowing private linear regression to achieve rates that depend on the subspace dimension rather than ambient dimension.
- Core assumption: The regression vectors for both public and private tasks lie in a shared k-dimensional subspace B, and the subspace estimate ˆBpub has bounded principal angle error γ.
- Evidence anchors:
  - [abstract] "if the public and private data share a low-dimensional representation, public representations can improve the sample complexity of private training even if it is impossible to learn the private task from the public data alone."
  - [section 4.2] "We claim that the variance of the residual is sin(θ)2+∥α∗∥22" and "Using the rewritten y, we can treat the new private regression problem as estimating ˆB⊤Bα∗"
  - [corpus] Weak evidence - related works discuss public-private learning but don't directly support this subspace projection mechanism
- Break condition: If the principal angle error γ becomes too large such that sin(θ)2∥α∗∥22 dominates the noise variance, the benefit of subspace projection disappears and we revert to full-dimensional private learning rates.

### Mechanism 2
- Claim: In multitask settings, public subspace estimates enable clients to avoid expensive private coordination while maintaining performance
- Mechanism: When a public subspace estimate is sufficiently accurate, clients can perform local linear regression in the estimated subspace at no additional privacy cost. A "best of both worlds" algorithm lets clients choose between locally estimated parameters and those obtained through private collaboration, effectively trading off between privacy and performance.
- Core assumption: The subspace estimation error γ is below a threshold where local linear regression performance matches private alternating minimization, and clients have sufficient private samples per task.
- Evidence anchors:
  - [abstract] "with sufficient public data, users can avoid private coordination, as purely local learning within the given subspace achieves the same utility"
  - [section 5.3] "We observe here that as the privacy budget ε decreases, the number of public samples required to achieve this bound also decreases"
  - [corpus] Weak evidence - related works discuss public-private learning but don't directly support this local optimization mechanism
- Break condition: When γ exceeds the threshold given in equation (8), the performance gap between local and collaborative methods becomes significant, making private coordination necessary for acceptable utility.

### Mechanism 3
- Claim: The two-phase approach (subspace estimation + private regression) is information-theoretically optimal for single-task transfer
- Mechanism: By projecting private data into the estimated subspace, the problem reduces to k-dimensional linear regression with noise variance increased by the subspace estimation error. The paper provides matching upper and lower bounds showing this approach achieves the optimal excess risk among all algorithms that output estimates within the estimated subspace.
- Core assumption: The lower bound construction assumes algorithms must output estimates in the column space of ˆBpub, and the adversary can exploit the subspace misspecification to construct worst-case problem instances.
- Evidence anchors:
  - [section 4.3] "Our proof relies mainly on tracing attacks in Bun et al. (2014); Cai et al. (2021), but our analysis additionally needs to handle the misspecification of the subspace B"
  - [section 4.2] "we can show that the projected samples can now be treated as i.i.d. samples from a k-dimensional linear regression model"
  - [corpus] Weak evidence - related works discuss public-private learning but don't directly support this optimality proof
- Break condition: If algorithms are allowed to output estimates outside the estimated subspace, or if the privacy constraint is relaxed, better performance might be achievable through alternative approaches.

## Foundational Learning

- Concept: Differential Privacy (DP) with row-level and user-level granularity
  - Why needed here: The paper studies two distinct privacy models - row-level DP for single-task transfer where each record is sensitive, and user-level DP for multitask transfer where each user's entire dataset is sensitive. Understanding these granularities is crucial for interpreting the results and their applicability.
  - Quick check question: What is the key difference between row-level and user-level differential privacy in terms of neighboring datasets?

- Concept: Principal angles and subspace distance metrics
  - Why needed here: The paper uses the first principal angle to measure the distance between the true subspace B and the estimated subspace ˆBpub. This metric determines the error introduced by subspace misspecification and affects the final learning rates.
  - Quick check question: How does the principal angle between two subspaces relate to the operator norm of their difference?

- Concept: Method-of-moments estimators for subspace recovery
  - Why needed here: The paper relies on the method-of-moments estimator from Tripuraneni et al. (2021) to obtain the initial subspace estimate from public data. Understanding its error bounds and requirements is essential for applying the theoretical results.
  - Quick check question: What are the key assumptions required for the method-of-moments estimator to achieve the error bound given in Theorem 3.3?

## Architecture Onboarding

- Component map:
  - Public data processing pipeline -> Method-of-moments estimator -> Subspace estimate ˆBpub
  - Private data processing pipeline -> Subspace projection -> Private linear regression
  - Multitask coordination layer -> Private alternating minimization or local optimization
  - Privacy budget management -> Differential privacy enforcement

- Critical path:
  1. Obtain public samples and estimate subspace using method-of-moments estimator
  2. For each private task, project inputs into estimated subspace
  3. Run private linear regression in reduced dimension with appropriate privacy parameters
  4. For multitask setting, implement alternating minimization or local optimization based on subspace accuracy

- Design tradeoffs:
  - Public sample quantity vs. subspace accuracy: More public samples improve subspace estimate but increase computational cost
  - Privacy budget allocation: Higher ε allows better utility but reduces privacy guarantees
  - Local vs. collaborative optimization: Local optimization has no privacy cost but may underperform when subspace estimate is inaccurate

- Failure signatures:
  - Poor performance despite abundant public data: Subspace estimation error γ too large, check task diversity assumptions
  - Degradation in multitask setting: Insufficient private samples per client, or public subspace estimate too inaccurate for local optimization
  - Privacy budget exhaustion: Too many iterations of private alternating minimization, consider switching to local optimization earlier

- First 3 experiments:
  1. Single-task transfer with varying subspace estimation error γ: Fix public sample size and vary task diversity to understand impact on final performance
  2. Multitask transfer with varying number of clients m: Fix private samples per client and vary client count to identify regime where local optimization becomes preferable
  3. Privacy budget sensitivity analysis: Fix all other parameters and vary ε to understand privacy-utility tradeoff curves in both single-task and multitask settings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the benefit of public data for private transfer learning change when the shared subspace assumption is relaxed to a low-rank plus sparse structure rather than purely low-rank?
- Basis in paper: [explicit] The paper assumes a purely low-rank shared subspace structure, but notes this as a limitation and suggests exploring relaxed assumptions as future work.
- Why unresolved: The current theoretical framework and proofs rely heavily on the exact low-rank assumption. Extending to more complex structures would require new algorithmic approaches and theoretical analysis.
- What evidence would resolve it: Empirical and theoretical results comparing public-private transfer learning performance with low-rank plus sparse structure versus pure low-rank structure across multiple datasets and tasks.

### Open Question 2
- Question: What is the optimal algorithm for multitask transfer learning when the number of clients m and samples per client n2 vary widely, and how does this depend on the public data availability?
- Basis in paper: [inferred] The paper provides bounds for two algorithms (private collaboration and local linear regression) and a "best of both worlds" approach, but does not identify the optimal algorithm for all parameter regimes.
- Why unresolved: The paper gives sufficient conditions for when each algorithm is optimal but doesn't provide a complete characterization of the optimal choice across all parameter settings.
- What evidence would resolve it: A complete theoretical characterization or empirical evaluation showing which algorithm performs best as a function of m, n2, and public data availability.

### Open Question 3
- Question: How do the results generalize to non-linear regression models or more complex function classes beyond linear regression?
- Basis in paper: [explicit] The paper explicitly focuses on linear regression and notes this as a limitation, suggesting investigation of more complex models as future work.
- Why unresolved: The theoretical results depend on specific properties of linear regression (e.g., Gaussian covariates, closed-form solutions) that don't directly extend to non-linear settings.
- What evidence would resolve it: Theoretical bounds or empirical results for public-private transfer learning with non-linear models (e.g., neural networks, kernel methods) under various distribution shift scenarios.

## Limitations
- Theoretical framework assumes Gaussian data and noise distributions, limiting practical applicability
- Analysis focuses exclusively on linear regression models, not generalizing to more complex architectures
- Privacy guarantees are asymptotic with potentially loose constants in practice

## Confidence
- Mechanism 1 (subspace projection): Medium confidence - sound theory but limited empirical validation of practical impact
- Mechanism 2 (multitask local optimization): Medium confidence - threshold for local vs collaborative optimization depends on problem-specific constants
- Mechanism 3 (information-theoretic optimality): High confidence within constrained optimization framework but may not hold with relaxed constraints

## Next Checks
1. **Empirical validation of subspace accuracy threshold**: Measure the actual principal angle error γ across different public sample sizes and task diversity levels, then empirically verify the threshold beyond which local optimization performance degrades.

2. **Distribution mismatch robustness**: Test the framework with non-Gaussian private data distributions to assess sensitivity to the distributional assumptions in the theoretical analysis.

3. **Privacy-utility tradeoff curve verification**: Implement the full algorithm pipeline with different privacy budgets ε and verify that the theoretical predictions about public sample requirements match empirical observations.