---
ver: rpa2
title: On the Relevance of Phoneme Duration Variability of Synthesized Training Data
  for Automatic Speech Recognition
arxiv_id: '2310.08132'
source_url: https://arxiv.org/abs/2310.08132
tags:
- data
- synthetic
- training
- speech
- duration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the issue of temporal diversity in synthetic
  speech data generated by non-autoregressive text-to-speech (TTS) systems, which
  affects automatic speech recognition (ASR) training. The authors analyze phoneme
  duration prediction and propose a random-walk-based modification to increase temporal
  variation without retraining the TTS model.
---

# On the Relevance of Phoneme Duration Variability of Synthesized Training Data for Automatic Speech Recognition

## Quick Facts
- arXiv ID: 2310.08132
- Source URL: https://arxiv.org/abs/2310.08132
- Reference count: 0
- This work addresses the issue of temporal diversity in synthetic speech data generated by non-autoregressive TTS systems, which affects ASR training. The authors analyze phoneme duration prediction and propose a random-walk-based modification to increase temporal variation without retraining the TTS model. Using LibriSpeech 100h semi-supervised task, they show that the modification improves ASR performance by up to 15% relative WER, achieving state-of-the-art results.

## Executive Summary
This paper addresses a critical issue in automatic speech recognition (ASR) systems that rely on synthetic training data: the lack of temporal diversity in speech generated by non-autoregressive (NAR) text-to-speech (TTS) systems. NAR TTS systems use explicit duration prediction, which often results in overly consistent phoneme durations that don't match the natural variability found in real speech. The authors propose a simple yet effective random-walk-based algorithm to modify predicted durations, increasing temporal diversity without requiring retraining of the TTS model. Their approach significantly improves ASR performance, achieving state-of-the-art results on the LibriSpeech semi-supervised task with up to 15% relative WER reduction.

## Method Summary
The authors analyze phoneme duration prediction in NAR TTS systems and identify temporal diversity as a key limitation for ASR training. They propose a random-walk-based duration modification algorithm that introduces smooth, controlled variability to phoneme durations while preserving the overall structure. The method is evaluated on the LibriSpeech 100h semi-supervised task, comparing ASR performance using synthetic data with original and modified durations. They also introduce an oracle setup that uses ground-truth durations from forced alignment to establish an upper bound for performance improvements. The approach is tested with both HMM-GMM and CTC alignment methods, demonstrating consistent improvements across different alignment strategies.

## Key Results
- Random-walk duration modification improves ASR performance by up to 15% relative WER on LibriSpeech test sets
- Oracle duration setup shows significant potential for improvement, establishing an upper bound for temporal diversity benefits
- HMM-GMM alignment produces slightly better synthetic data quality than CTC alignment for TTS training
- The proposed method achieves state-of-the-art results on the LibriSpeech semi-supervised task

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Random-walk-based duration modification improves ASR performance by increasing temporal diversity of synthetic speech.
- Mechanism: The random-walk algorithm generates per-phoneme scaling factors that vary smoothly between neighbors, expanding the duration distribution toward real data without retraining the TTS model.
- Core assumption: ASR models trained on synthetic data benefit from duration distributions that better match real speech patterns.
- Evidence anchors:
  - [abstract]: "Using a simple algorithm based on random walks we shift phoneme duration distributions of the TTS system closer to real durations, resulting in an improvement of an ASR system using synthetic data"
  - [section]: "Using a random-walk approach we could modify the predicted durations to follow a wider distribution, and improve the quality of the synthetic data w.r.t. to ASR training"
  - [corpus]: Weak evidence - no direct citations on random-walk duration modification in neighbor papers
- Break condition: If the random-walk variance σ becomes too large, excessive clipping occurs and performance degrades.

### Mechanism 2
- Claim: Synthetic data with oracle durations (copied from forced alignment) provides an upper bound for ASR performance improvement.
- Mechanism: By bypassing the TTS duration predictor and using ground-truth durations from forced alignment, the synthetic speech more closely matches real temporal patterns.
- Core assumption: Duration prediction errors are a primary source of synthetic-real mismatch in TTS-generated training data.
- Evidence anchors:
  - [abstract]: "Using a novel oracle setup we show how much the degradation of synthetic data quality is influenced by duration modeling in non-autoregressive (NAR) TTS"
  - [section]: "By training an ASR system on the synthetic data generated from using the phoneme durations directly from the forced alignment, we can estimate an upper bound for the performance gain"
  - [corpus]: No direct evidence in neighbor papers about oracle duration setups for TTS
- Break condition: If duration prediction errors are not the primary source of mismatch, oracle durations won't provide significant improvement.

### Mechanism 3
- Claim: HMM-GMM alignment produces slightly better synthetic data than CTC alignment for TTS training.
- Mechanism: HMM-GMM alignment has more consistent duration histograms and easier targets for the duration predictor, leading to better TTS performance.
- Core assumption: The choice of alignment method affects TTS duration prediction quality and thus synthetic data utility for ASR.
- Evidence anchors:
  - [section]: "It is also visible that the TTS trained on CTC aligner shows a slightly weaker performance during normal synthesis, but is on par when using the reference alignment"
  - [section]: "While the prediction for the HMM-GMM model is shaped similarly to the alignment, with just a more narrow main peak, the CTC model has an unexpected mismatch"
  - [corpus]: No direct evidence in neighbor papers comparing HMM-GMM vs CTC for TTS duration prediction
- Break condition: If duration predictor architecture changes, the relative advantage of HMM-GMM may disappear.

## Foundational Learning

- Concept: Non-autoregressive TTS systems use explicit duration prediction
  - Why needed here: The paper relies on duration prediction as a controllable parameter that can be modified post-training
  - Quick check question: What is the key architectural difference between autoregressive and non-autoregressive TTS systems?

- Concept: Forced alignment methods (HMM-GMM vs CTC) produce different duration distributions
  - Why needed here: The paper compares these methods and uses them as references for oracle duration experiments
  - Quick check question: How does CTC alignment differ from HMM-GMM alignment in handling silence between words?

- Concept: Kullback-Leibler divergence as a metric for duration distribution similarity
  - Why needed here: The paper uses KL divergence to quantify how well TTS-predicted durations match aligner-provided durations
  - Quick check question: What does a lower KL divergence value indicate about the similarity between two duration distributions?

## Architecture Onboarding

- Component map:
  Text input → Phoneme encoder → Duration predictor → Gaussian upsampling → Decoder → Spectrogram output
  External aligner (HMM-GMM or CTC) → Duration targets for TTS training
  Random-walk duration modifier → Post-processing before synthesis
  ASR system → Evaluation of synthetic data utility

- Critical path:
  Text → TTS duration prediction → Duration modification (optional) → Spectrogram generation → Vocoding → ASR training → Evaluation

- Design tradeoffs:
  - HMM-GMM alignment provides better TTS training targets but requires more complex implementation
  - CTC alignment is simpler but produces noisier duration distributions
  - Random-walk modification adds computational overhead but avoids retraining
  - Using oracle durations provides upper bounds but isn't practical for production

- Failure signatures:
  - ASR performance plateaus despite duration modification attempts
  - Random-walk modification causes excessive clipping (duration values hit boundaries)
  - TTS system fails to converge with CTC alignment due to inconsistent duration targets
  - Synthetic WER remains high even with oracle durations (indicating other mismatch factors)

- First 3 experiments:
  1. Generate synthetic data with baseline TTS using HMM-GMM alignment, measure ASR performance and duration distribution KL divergence
  2. Apply random-walk duration modification with increasing σ values, measure impact on ASR performance and duration distribution
  3. Compare HMM-GMM vs CTC alignment by training separate TTS models and measuring synthetic data quality via synthetic WER and duration distribution metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different duration alignment methods (HMM-GMM vs CTC) affect the quality of synthesized speech data for ASR training?
- Basis in paper: [explicit] The paper compares HMM-GMM and CTC aligners, showing that CTC-trained TTS systems have slightly worse performance during normal synthesis but perform similarly when using reference alignments. The authors also observe that CTC-alignment-based TTS durations have more inconsistent shapes.
- Why unresolved: The paper provides empirical comparisons but does not fully explain the underlying reasons for the performance differences between the two alignment methods or provide a theoretical framework for understanding these differences.
- What evidence would resolve it: Additional analysis of the alignment characteristics, including detailed examination of alignment errors, duration prediction accuracy, and correlation with ASR performance across different phonetic contexts and speakers.

### Open Question 2
- Question: What is the optimal duration modification strategy for improving ASR performance using synthetic data?
- Basis in paper: [explicit] The authors propose a random-walk-based duration modification algorithm and show it improves ASR performance by up to 15% relative WER. They test different variance parameters (σ) but note that smaller values perform better in combined training.
- Why unresolved: The paper only explores a limited range of modification strategies and parameters. The optimal balance between temporal diversity and naturalness remains unclear, and it's uncertain whether the proposed method generalizes to other TTS architectures or datasets.
- What evidence would resolve it: Systematic evaluation of alternative duration modification strategies, including more sophisticated stochastic duration modeling approaches, across multiple TTS architectures, datasets, and ASR tasks.

### Open Question 3
- Question: How does the temporal diversity of synthetic data affect ASR performance across different architectures and tasks?
- Basis in paper: [inferred] The authors demonstrate improvements using their duration modification approach for a specific attention-encoder-decoder ASR architecture on LibriSpeech, but note that most prior work focused on similar architectures while other architectures showed more problems with synthetic data.
- Why unresolved: The study is limited to one ASR architecture (Conformer-based attention-encoder-decoder) and one specific task (LibriSpeech semi-supervised). The generalizability of the findings to other ASR architectures (like RNN-T or CTC-based systems) and tasks remains unknown.
- What evidence would resolve it: Replication of the experiments across multiple ASR architectures, including RNN-T and CTC-based systems, and on diverse datasets with different characteristics (acoustic conditions, vocabulary sizes, etc.).

## Limitations

- The random-walk modification parameters (σ=0.025) are optimized for LibriSpeech and may not generalize to other datasets or languages
- The oracle duration experiments establish upper bounds but don't identify which specific duration errors most impact ASR performance
- Comparison between HMM-GMM and CTC aligners is limited to their effect on TTS training without exploring broader applicability

## Confidence

- **High confidence**: The core finding that duration prediction errors in NAR TTS systems degrade ASR performance when using synthetic training data. The 15% relative WER improvement is well-documented across multiple experimental conditions.
- **Medium confidence**: The random-walk modification technique works as described for the specific experimental setup, but generalization to other datasets or TTS systems requires validation.
- **Medium confidence**: The conclusion that HMM-GMM alignment produces better TTS training targets than CTC, though this appears dataset-specific and may not hold for all speech corpora or alignment configurations.

## Next Checks

1. Test the random-walk duration modification with varying σ values (0.01, 0.05, 0.1) on the same LibriSpeech dataset to establish the sensitivity of performance gains to the modification parameter and identify the optimal range for different use cases.

2. Apply the oracle duration setup to a different dataset (e.g., Common Voice or TED-LIUM) to determine whether the magnitude of performance improvement correlates with the baseline TTS duration prediction quality.

3. Implement an ablation study that systematically varies individual phoneme durations rather than applying the smooth random-walk modification to isolate which temporal patterns (vowel lengthening, consonant timing, silence placement) contribute most to ASR performance improvements.