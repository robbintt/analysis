---
ver: rpa2
title: Finite-Time Analysis of Three-Timescale Constrained Actor-Critic and Constrained
  Natural Actor-Critic Algorithms
arxiv_id: '2310.16363'
source_url: https://arxiv.org/abs/2310.16363
tags:
- have
- critic
- actor
- where
- proof
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies constrained actor-critic (C-AC) and constrained
  natural actor-critic (C-NAC) algorithms for constrained Markov decision processes
  with function approximation. The authors analyze both algorithms in the long-run
  average cost setting, handling inequality constraints via the Lagrange multiplier
  method.
---

# Finite-Time Analysis of Three-Timescale Constrained Actor-Critic and Constrained Natural Actor-Critic Algorithms

## Quick Facts
- arXiv ID: 2310.16363
- Source URL: https://arxiv.org/abs/2310.16363
- Reference count: 40
- Primary result: Both C-AC and C-NAC converge to a first-order stationary point with O(ε^{-2.5}) sample complexity

## Executive Summary
This paper analyzes constrained actor-critic (C-AC) and constrained natural actor-critic (C-NAC) algorithms for constrained Markov decision processes with function approximation. The authors handle inequality constraints using the Lagrange multiplier method, requiring three timescale updates: critic (fastest), actor (intermediate), and Lagrange multiplier (slowest). The analysis proves convergence to a first-order stationary point and establishes O(ε^{-2.5}) sample complexity. Experimental results on grid world environments demonstrate that both algorithms can minimize average cost while satisfying prescribed constraint thresholds.

## Method Summary
The algorithms operate on constrained MDPs using linear function approximation with TD(0) for the critic. The C-AC algorithm updates policy parameters via regular gradient ascent, while C-NAC uses natural gradient computed via Fisher information matrix. Both algorithms use three timescale updates with step sizes satisfying 0 < ω < σ < β ≤ 1, where the critic updates fastest, actor intermediate, and Lagrange multiplier slowest. The TD(0) critic maintains boundedness through projection, and the Fisher information matrix in C-NAC is estimated online to compute natural gradients.

## Key Results
- Both C-AC and C-NAC algorithms converge to first-order stationary points
- Sample complexity of O(ε^{-2.5}) established for both algorithms
- Experimental results show successful constraint satisfaction in grid world environments
- Natural gradient (C-NAC) shows improved convergence over regular gradient (C-AC)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Three-timescale structure allows simultaneous optimization of actor, critic, and Lagrange multiplier with minimal interference between updates.
- Mechanism: Each parameter (θ, v, γ) is updated on a different timescale: γ on the slowest timescale (step size c(n) ~ n^(-β)), θ on an intermediate timescale (step size b(n) ~ n^(-σ)), and v on the fastest timescale (step size a(n) ~ n^(-ω)). This separation ensures that the faster timescale variables can track the slower timescale variables while maintaining stability.
- Core assumption: The step sizes satisfy 0 < ω < σ < β ≤ 1, ensuring proper timescale separation.
- Evidence anchors:
  - [abstract]: "We handle the inequality constraints using the Lagrange multiplier method...one needs to introduce an additional (the slowest) timescale over which the Lagrange multiplier is updated."
  - [section 3.3]: "Note that usual actor critic...algorithms ordinarily require two timescale recursions...In constrained actor critic and constrained natural actor critic algorithms, one needs to introduce an additional (the slowest) timescale..."
  - [corpus]: Weak evidence - only general actor-critic papers found, none specifically analyzing three-timescale convergence.
- Break condition: If step sizes violate the ordering constraint (ω < σ < β), the convergence guarantees break down.

### Mechanism 2
- Claim: Linear function approximation with TD(0) enables scalable critic updates while maintaining convergence guarantees.
- Mechanism: The critic value function Vπ,γ(s) is approximated as vT fs where v is the weight vector and fs is the feature vector. The TD(0) update rule adjusts v based on the temporal difference error, and projection ensures boundedness.
- Core assumption: The feature matrix A is negative definite with minimum eigenvalue -λe < 0, ensuring unique solution to the projected Bellman equation.
- Evidence anchors:
  - [section 3.2]: "We use linear function approximation for M π,γ(s, a)...Thus, the same is approximated as follows: ˆM π,γ w (s, a) ≈ wπ,γ T Ψsa"
  - [section 4.1]: "Assumption 2 The matrix A...is negative definite with maximum eigenvalue as −λe < 0 for all values of θ."
  - [corpus]: Weak evidence - general TD learning papers exist but none specifically analyzing constrained actor-critic with function approximation.
- Break condition: If the feature matrix A is not negative definite, the TD(0) update may diverge.

### Mechanism 3
- Claim: Natural gradient transformation accelerates convergence by incorporating Fisher information matrix.
- Mechanism: The natural gradient is computed as G(n)^(-1)∇θL(θ, γ) where G(n) is the Fisher information matrix estimate. This transformation accounts for the geometry of the policy space, leading to faster convergence.
- Core assumption: The Fisher information matrix G(n) remains positive definite and bounded throughout training.
- Evidence anchors:
  - [section 3.3]: "In the case of the C-NAC algorithm, the natural gradient is estimated by linearly transforming the regular gradient by making use of the inverse Fisher information matrix of the policy which is clearly positive definite"
  - [section 4.1]: "Assumption 5 The updates G(t) satisfy sup t ∥G(t)∥ < ∞ and sup t ∥G(t)−1∥ < ∞, respectively."
  - [corpus]: Moderate evidence - Natural Actor-Critic papers exist but specific finite-time analysis with constraints is limited.
- Break condition: If the Fisher information matrix estimate becomes singular or unbounded, the natural gradient computation fails.

## Foundational Learning

- Concept: Markov Decision Processes and Constrained MDPs
  - Why needed here: The algorithms operate on C-MDPs where both rewards and constraints are state-action-next state dependent, requiring understanding of transition probabilities and ergodicity.
  - Quick check question: What ensures the ergodicity of the Markov chain under any policy in this setting?

- Concept: Lagrange Multiplier Method for Constrained Optimization
  - Why needed here: The inequality constraints are relaxed into the objective using Lagrange multipliers, creating a saddle-point problem that the algorithms must solve.
  - Quick check question: How does the update rule for the Lagrange multiplier γ ensure that constraints are satisfied while minimizing the objective?

- Concept: Temporal Difference Learning and Function Approximation
  - Why needed here: The critic uses TD(0) with linear function approximation to estimate value functions, requiring understanding of projected Bellman equations and convergence conditions.
  - Quick check question: What condition on the feature matrix A guarantees convergence of the TD(0) update?

## Architecture Onboarding

- Component map: γ (Lagrange multiplier) -> θ (policy) -> v (critic value)
- Critical path: γ → θ → v (slowest to fastest timescale)
  - γ update uses step size c(n) ~ n^(-β)
  - θ update uses step size b(n) ~ n^(-σ)
  - v update uses step size a(n) ~ n^(-ω)
- Design tradeoffs:
  - Three timescales vs. two timescales: Better constraint handling but increased complexity
  - Linear function approximation vs. tabular: Scalability but requires negative definiteness of feature matrix
  - Natural gradient vs. regular gradient: Faster convergence but requires Fisher matrix computation
- Failure signatures:
  - Divergence: Check if step sizes violate ordering constraint or if feature matrix is not negative definite
  - Constraint violation: Check if Lagrange multiplier update is too slow or constraints are too tight
  - Slow convergence: Check if Fisher information matrix estimate is poorly conditioned
- First 3 experiments:
  1. Grid world with simple constraints (e.g., obstacle avoidance) to verify basic functionality
  2. Grid world with varying constraint thresholds to test Lagrange multiplier adaptation
  3. Grid world with different sizes to compare C-AC vs C-NAC performance and validate sample complexity claims

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the convergence rate of constrained actor-critic algorithms depend on the number of constraints N?
- Basis in paper: [inferred] The paper analyzes algorithms with N constraints but doesn't explicitly study how the convergence rate scales with N.
- Why unresolved: The analysis focuses on the sample complexity O(ε^(-2.5)) but doesn't break down the dependence on N in the constants.
- What evidence would resolve it: A theoretical analysis showing how the constants in the convergence rate depend on N, or experimental results varying N and measuring convergence speed.

### Open Question 2
- Question: How does the choice of projection set C affect the convergence of the critic parameter?
- Basis in paper: [explicit] The paper assumes C is compact and convex, and mentions that v*(t+1) should lie within C for convergence, but doesn't study the effect of different C choices.
- Why unresolved: The analysis assumes v*(t+1) is in C but doesn't explore what happens when this assumption is violated or how different C shapes affect convergence.
- What evidence would resolve it: Theoretical analysis of convergence under different C choices, or experimental results comparing different projection sets.

### Open Question 3
- Question: Can the finite-time analysis be extended to non-linear function approximation methods?
- Basis in paper: [explicit] The paper specifically uses linear function approximation for both the critic and the advantage function.
- Why unresolved: The analysis relies heavily on properties of linear function approximation, particularly in the proofs involving the critic recursion and the advantage function.
- What evidence would resolve it: An extension of the finite-time analysis to non-linear approximation methods like neural networks, or experimental results comparing linear vs non-linear approximation.

### Open Question 4
- Question: How does the mixing time τt affect the overall convergence rate, and can it be reduced?
- Basis in paper: [explicit] The analysis includes terms involving τt, which depends on the mixing time of the Markov chain, but doesn't provide strategies to reduce it.
- Why unresolved: The paper shows τt appears in the error bounds but doesn't explore how to minimize it or its impact on convergence speed.
- What evidence would resolve it: Theoretical bounds on how τt affects convergence, or experimental results varying the mixing time and measuring its impact on performance.

## Limitations
- Limited empirical validation beyond simple grid world environments
- Strict step-size ordering requirement may be difficult to satisfy in practice
- Analysis relies on negative definiteness of feature matrix which may not hold in all cases

## Confidence
- **Convergence theory**: High confidence - the three-timescale analysis follows established stochastic approximation frameworks
- **Sample complexity bound**: Medium confidence - theoretically sound but not empirically validated
- **Practical applicability**: Low confidence - limited experimental scope and no ablation studies on hyperparameter sensitivity

## Next Checks
1. **Step-size sensitivity analysis**: Systematically vary the step-size ratios (ω, σ, β) to identify the practical boundaries of the convergence guarantees and determine how sensitive performance is to these hyperparameters.

2. **Scaling experiments**: Test the algorithms on larger grid worlds and more complex environments (e.g., continuous control tasks) to evaluate whether the O(ε^{-2.5}) sample complexity bound holds in practice and whether the three-timescale structure remains beneficial.

3. **Constraint tightness evaluation**: Conduct experiments with varying constraint thresholds to understand how constraint tightness affects convergence speed, feasibility of constraint satisfaction, and the trade-off between objective minimization and constraint satisfaction.