---
ver: rpa2
title: 'The Cultural Psychology of Large Language Models: Is ChatGPT a Holistic or
  Analytic Thinker?'
arxiv_id: '2308.14242'
source_url: https://arxiv.org/abs/2308.14242
tags:
- chatgpt
- page
- gpt-3
- andgpt-4
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether ChatGPT exhibits holistic or analytic
  thinking patterns, as defined by cultural psychology frameworks. Using four established
  scales (AHS, TCT, DSS, SCS), the researchers measured ChatGPT-3.5 and ChatGPT-4's
  responses across 14 experimental conditions varying temperature and prompting language.
---

# The Cultural Psychology of Large Language Models: Is ChatGPT a Holistic or Analytic Thinker?

## Quick Facts
- arXiv ID: 2308.14242
- Source URL: https://arxiv.org/abs/2308.14242
- Reference count: 0
- Primary result: ChatGPT exhibits holistic thinking patterns in cognitive processes but shows no significant cultural leanings in value judgments

## Executive Summary
This study investigates whether ChatGPT exhibits holistic or analytic thinking patterns as defined by cultural psychology frameworks. Using four established scales (AHS, TCT, DSS, SCS), researchers measured ChatGPT-3.5 and ChatGPT-4's responses across 14 experimental conditions varying temperature and prompting language. Both models consistently demonstrated holistic thinking patterns in cognitive process tasks, with results robust to experimental variations. However, in value-based measures, neither model showed significant cultural leanings, suggesting their thinking processes may reflect holistic patterns while value judgments remain culturally neutral.

## Method Summary
The researchers applied four established psychological scales (AHS, TCT, DSS, SCS) to GPT-3.5 and GPT-4 as "participants" across 14 experimental conditions varying temperature (0, 0.5, 1, 1.5) and prompting language. Each condition was repeated 10 times. The scales measured both cognitive processes (holistic vs analytic thinking) and cultural values. Responses were compared against established psychological norms using t-tests to determine whether the models exhibited Eastern holistic or Western analytic thinking patterns.

## Key Results
- ChatGPT consistently demonstrated holistic thinking patterns in cognitive process tasks (AHS/TCT) with p < 0.001 significance
- Neither model showed significant cultural leanings in value-based measures (DSS/SCS)
- Results were robust across temperature variations and different prompting languages
- Both GPT-3.5 and GPT-4 exhibited similar holistic patterns, with GPT-3.5 showing stronger effects

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPT exhibits holistic thinking in cognitive processes because its training methodology emphasizes pattern recognition across large datasets rather than rule-based logical analysis.
- Mechanism: The model learns to identify global patterns and relationships within input contexts, leading to holistic processing that focuses on contextual relationships rather than isolated object analysis.
- Core assumption: The training paradigm of large language models inherently promotes holistic thinking through its emphasis on pattern recognition across vast datasets.
- Evidence anchors:
  - [abstract]: "We suggest that the result could be attributed to both the training paradigm and the training data in LLM development"
  - [section]: "The lack of significant leanings in value judgments might be due to the complex interactions between language and thought. While the model might mimic the holistic thinking process, value judgments often involve more explicit and conscious articulations of beliefs and ideologies"
  - [corpus]: Weak evidence - no direct corpus evidence supporting this mechanism specifically
- Break condition: If the model were explicitly trained with logic-based reasoning tasks or if fine-tuning specifically targeted analytical thinking patterns.

### Mechanism 2
- Claim: ChatGPT's cultural cognition patterns emerge from the interaction between training data composition and the model's pattern recognition capabilities.
- Mechanism: The model's responses reflect the cultural patterns embedded in its training data, but the pattern recognition process itself favors holistic processing regardless of the cultural content.
- Core assumption: Training data composition significantly influences the model's thinking patterns, but the fundamental pattern recognition mechanism drives holistic processing.
- Evidence anchors:
  - [abstract]: "We suggest that the result could be attributed to both the training paradigm and the training data in LLM development"
  - [section]: "Since ChatGPT does not have personal beliefs or consciousness, both versions might not capture these cultural nuances in the same way as they recognize underlying thinking patterns"
  - [corpus]: Weak evidence - corpus lacks direct evidence of training data composition effects
- Break condition: If training data were uniformly balanced across cultures or if explicit cultural bias mitigation techniques were applied during training.

### Mechanism 3
- Claim: The difference between cognitive process results and value judgment results stems from the distinction between implicit pattern recognition and explicit belief systems.
- Mechanism: The model can recognize and replicate holistic thinking patterns through implicit learning, but lacks the explicit belief systems necessary for culturally aligned value judgments.
- Core assumption: Cognitive processes and value judgments operate through fundamentally different mechanisms in language models.
- Evidence anchors:
  - [abstract]: "In cognitive process tests (AHS/TCT), ChatGPT consistently tends towards Eastern holistic thinking, but regarding value judgments (DSS/SCS), ChatGPT does not significantly lean towards the East or the West"
  - [section]: "While the model might mimic the holistic thinking process, value judgments often involve more explicit and conscious articulations of beliefs and ideologies"
  - [corpus]: Weak evidence - no corpus evidence supporting this mechanism specifically
- Break condition: If value judgments were based solely on pattern recognition rather than requiring explicit belief systems.

## Foundational Learning

- Concept: Cultural psychology frameworks for thinking styles
  - Why needed here: Understanding the distinction between holistic and analytical thinking is essential for interpreting the results
  - Quick check question: What are the key differences between holistic and analytical thinking patterns in cultural psychology?

- Concept: LLM training methodologies and pattern recognition
  - Why needed here: The mechanism linking training methodology to thinking patterns requires understanding how LLMs learn
  - Quick check question: How do transformer-based language models learn patterns from training data?

- Concept: Statistical significance testing
  - Why needed here: The results rely on comparing model responses to established norms using statistical tests
  - Quick check question: What does it mean when p < 0.001 in the context of comparing model responses to norms?

## Architecture Onboarding

- Component map: Model → Scale application → Response generation → Statistical comparison to norms → Interpretation of cultural thinking patterns
- Critical path: Model → Scale application → Response generation → Statistical comparison to norms → Interpretation of cultural thinking patterns
- Design tradeoffs: Balancing model randomness (temperature) against consistency of results, choosing between direct measurement and implicit tasks
- Failure signatures: Inconsistent results across temperature variations, failure to replicate established psychological norms, or lack of robustness to prompting language changes
- First 3 experiments:
  1. Test model responses at different temperature settings to establish baseline robustness
  2. Apply paraphrased prompts to verify results are not prompt-dependent
  3. Compare responses to established psychological norms to validate measurement accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do cultural cognitive patterns in LLMs like ChatGPT emerge from training methodology versus training data?
- Basis in paper: [explicit] The authors suggest results could be attributed to both training paradigm and training data, noting that LLMs seek global patterns across data rather than strict logical analysis
- Why unresolved: The study identifies the phenomenon but doesn't isolate whether cultural patterns stem from self-supervised learning architecture or from cultural biases in training data
- What evidence would resolve it: Comparative analysis of culturally-diverse training datasets with identical architectures, or controlled experiments varying training data composition while holding architecture constant

### Open Question 2
- Question: Do ChatGPT's value judgments reflect a true cultural neutrality or simply an inability to express cultural values?
- Basis in paper: [explicit] The authors note that while ChatGPT shows holistic thinking patterns, it doesn't significantly lean East or West on value measures, suggesting either cultural neutrality or limitations in expressing beliefs
- Why unresolved: The distinction between genuine neutrality and inability to express cultural values remains unclear
- What evidence would resolve it: Testing whether prompting strategies that explicitly elicit value judgments reveal hidden cultural biases, or comparing with models trained on culturally-labeled data

### Open Question 3
- Question: How do temperature settings and prompt variations affect the robustness of cultural cognitive patterns in LLMs?
- Basis in paper: [explicit] The authors tested robustness across temperature settings (0-1.5) and different prompting languages, finding results remained consistent
- Why unresolved: While patterns appear robust to tested variations, the study doesn't explore whether extreme settings or more sophisticated prompt engineering could reveal hidden cultural biases
- What evidence would resolve it: Systematic exploration of extreme temperature settings and advanced prompt engineering techniques to determine boundaries of cultural pattern stability

## Limitations
- Reliance on indirect measurement of cognitive processes through language models without consciousness or genuine beliefs
- Assumption that response patterns to psychological scales accurately reflect underlying cognitive processes
- Lack of direct characterization of training data composition and potential cultural biases

## Confidence
- **High Confidence:** The finding that ChatGPT exhibits consistent holistic patterns in cognitive process tasks (AHS/TCT) across different experimental conditions
- **Medium Confidence:** The interpretation that these holistic patterns stem from the model's pattern recognition capabilities rather than explicit cultural value systems
- **Low Confidence:** The specific mechanism linking transformer architecture to holistic thinking patterns

## Next Checks
1. Analyze the actual training data composition for cultural patterns and biases to establish a direct link between training corpus characteristics and the observed holistic thinking patterns
2. Compare ChatGPT's responses with those from models using different architectural approaches to isolate whether transformer architecture specifically promotes holistic processing
3. Design prompts that explicitly contrast Eastern and Western cultural frameworks to test whether the model can distinguish between these cultural contexts in its responses