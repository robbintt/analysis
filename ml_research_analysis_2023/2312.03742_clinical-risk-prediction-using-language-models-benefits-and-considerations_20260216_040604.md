---
ver: rpa2
title: 'Clinical Risk Prediction Using Language Models: Benefits And Considerations'
arxiv_id: '2312.03742'
source_url: https://arxiv.org/abs/2312.03742
tags:
- data
- prediction
- medical
- patient
- risk
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores using language models to improve clinical risk
  prediction from electronic health records. The key idea is to represent structured
  EHR data as text and leverage pre-trained language models, rather than training
  models from scratch on limited EHR data.
---

# Clinical Risk Prediction Using Language Models: Benefits And Considerations

## Quick Facts
- arXiv ID: 2312.03742
- Source URL: https://arxiv.org/abs/2312.03742
- Reference count: 40
- Key outcome: Language models improve clinical risk prediction from EHR data by representing codes as text and leveraging pre-trained models, with LLaMA2-EHR achieving best performance.

## Executive Summary
This study explores using language models to improve clinical risk prediction from electronic health records (EHRs). The key idea is to represent structured EHR data as text and leverage pre-trained language models, rather than training models from scratch on limited EHR data. Two new approaches are proposed: Sent-e-Med, which uses sentence embeddings of medical codes as input to a transformer encoder, and LLaMA2-EHR, which fine-tunes the LLaMA2 language model on structured EHR data. Experiments on multiple datasets for predicting substance use disorder, opioid use disorder, and diabetes show that these LM-based methods outperform previous approaches like MedBERT and GRAM, as well as simpler models like logistic regression and random forest. LLaMA2-EHR achieves the best performance, particularly in terms of precision-recall AUC, demonstrating the benefits of leveraging large pre-trained language models for clinical risk prediction tasks.

## Method Summary
The study proposes two methods for clinical risk prediction using language models. Sent-e-Med represents structured EHR data (diagnosis codes) as sentences describing each code, encodes them using a pre-trained sentence-BERT model, and feeds these embeddings into a transformer encoder. LLaMA2-EHR fine-tunes the LLaMA2 language model, originally trained on general text, on structured EHR data. Both methods operate without dependency on specific medical coding systems by converting codes to their textual descriptions. The models are evaluated on multiple datasets for predicting substance use disorder, opioid use disorder, and diabetes, using ROC AUC and PR AUC as metrics.

## Key Results
- LLaMA2-EHR achieves the best performance, particularly in terms of precision-recall AUC, demonstrating the benefits of leveraging large pre-trained language models for clinical risk prediction tasks.
- Both Sent-e-Med and LLaMA2-EHR outperform previous approaches like MedBERT and GRAM, as well as simpler models like logistic regression and random forest.
- The models demonstrate good performance on datasets with limited positive samples, such as the Synthea-small dataset for opioid use disorder prediction.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language models trained on general text can improve clinical risk prediction by leveraging rich semantic embeddings of medical codes.
- Mechanism: The study represents structured EHR data (diagnosis codes) as sentences describing each code, encodes them using a pre-trained sentence-BERT model, and feeds these embeddings into a transformer encoder. This preserves the semantic relationships between diagnoses and allows the model to generalize to unseen codes by similarity.
- Core assumption: The textual descriptions of medical codes contain sufficient semantic information to represent the clinical meaning of the diagnoses, and a pre-trained sentence encoder captures this information effectively.
- Evidence anchors:
  - [abstract] "We propose two new methods ("Sent-e-Med" and "LLaMA2-EHR") that aim to leverage this broader range of prior knowledge."
  - [section 4.2.1] "To overcome these limitations, we leverage the textual description of medical codes and initialize the medical code tokens with embeddings obtained from a sentence encoder."
- Break condition: If the textual descriptions are too sparse or lack sufficient semantic context, the sentence embeddings may not capture meaningful clinical relationships, leading to poor performance.

### Mechanism 2
- Claim: Fine-tuning large language models on structured EHR data improves risk prediction performance compared to models trained only on EHR data.
- Mechanism: The study fine-tunes the LLaMA2 language model, which was originally trained on general text, on structured EHR data. This allows the model to adapt its general language understanding to the specific domain of clinical risk prediction while retaining its broader knowledge base.
- Core assumption: The pre-trained language model contains relevant knowledge that can be transferred to the clinical domain, and fine-tuning on EHR data allows it to learn task-specific representations without losing its general capabilities.
- Evidence anchors:
  - [abstract] "LLaMA2-EHR achieves the best performance, particularly in terms of precision-recall AUC, demonstrating the benefits of leveraging large pre-trained language models for clinical risk prediction tasks."
  - [section 4.3] "We finetune the 7B-chat version of the LLaMA2 [14] model, one of the top open-source LLMs [42], on structured EHR and dub it LLaMA2-EHR."
- Break condition: If the EHR data is too domain-specific or the task is too different from the general language understanding of the pre-trained model, fine-tuning may lead to catastrophic forgetting and degraded performance.

### Mechanism 3
- Claim: Representing structured EHR data as text enables the use of language models without dependency on specific medical coding systems.
- Mechanism: By converting medical codes into their textual descriptions, the study eliminates the need for the model to understand specific coding systems (e.g., ICD-9, ICD-10). This allows the same model to be applied to different datasets with varying coding schemes.
- Core assumption: The textual descriptions of medical codes are consistent across different coding systems and capture the essential clinical information needed for risk prediction.
- Evidence anchors:
  - [section 4.4] "Both Sent-e-Med and LLaMA2-EHR operate without dependency on specific coding systems."
  - [section 4.2.1] "We leverage the textual description of medical codes and initialize the medical code tokens with embeddings obtained from a sentence encoder."
- Break condition: If different coding systems use significantly different textual descriptions for the same clinical concepts, the model may not be able to generalize effectively across datasets.

## Foundational Learning

- Concept: Understanding of transformer architectures and their components (attention mechanisms, positional encodings, etc.).
  - Why needed here: The study uses transformer encoders to process the sentence embeddings of medical codes, so a solid understanding of transformers is crucial for comprehending the model architecture and its components.
  - Quick check question: Can you explain how the self-attention mechanism in transformers allows the model to weigh the importance of different input tokens?

- Concept: Knowledge of medical coding systems and their hierarchical structure (e.g., ICD-10, SNOMED CT).
  - Why needed here: The study deals with structured EHR data encoded using various medical coding systems, and understanding their hierarchical structure is important for interpreting the results and appreciating the challenges of working with different coding schemes.
  - Quick check question: What is the difference between ICD-9 and ICD-10, and how does the hierarchical structure of these coding systems impact clinical risk prediction?

- Concept: Familiarity with clinical risk prediction tasks and their evaluation metrics (e.g., ROC AUC, PR AUC).
  - Why needed here: The study focuses on clinical risk prediction, and understanding the specific tasks (e.g., predicting substance use disorder, opioid use disorder, diabetes) and their evaluation metrics is essential for interpreting the results and comparing the performance of different models.
  - Quick check question: What is the difference between ROC AUC and PR AUC, and why is PR AUC particularly important for evaluating models on imbalanced datasets like clinical risk prediction?

## Architecture Onboarding

- Component map:
  - Input: Structured EHR data (diagnosis codes) represented as sentences
  - Sentence Encoder: Pre-trained SBERT model to generate embeddings for medical code descriptions
  - Transformer Encoder: Processes the sentence embeddings and generates contextualized representations
  - Classification Layer: Maps the transformer outputs to risk prediction probabilities
  - Output: Probability scores for the target clinical conditions

- Critical path:
  1. Convert diagnosis codes to their textual descriptions
  2. Generate sentence embeddings using pre-trained SBERT
  3. Feed sentence embeddings into transformer encoder
  4. Apply classification layer to obtain risk prediction probabilities
  5. Evaluate model performance using ROC AUC and PR AUC metrics

- Design tradeoffs:
  - Using pre-trained sentence embeddings vs. learning embeddings from scratch: Pre-trained embeddings capture semantic relationships between medical codes but may not be optimized for the specific task, while learned embeddings can be task-specific but require more data and training time.
  - Fine-tuning large language models vs. training smaller models from scratch: Fine-tuning leverages the rich knowledge of pre-trained models but requires careful handling to avoid catastrophic forgetting, while training from scratch allows for more control over the model architecture but may not capture as much general knowledge.

- Failure signatures:
  - Poor performance on unseen medical codes: This may indicate that the sentence embeddings do not capture sufficient semantic information or that the model is not generalizing well to new concepts.
  - Sensitivity to changes in input format or instructions: This may suggest that the model is not robust to variations in the input data or that it is overfitting to the specific training data.
  - Catastrophic forgetting during fine-tuning: This may occur if the fine-tuning process causes the model to lose its general language understanding while adapting to the clinical domain.

- First 3 experiments:
  1. Evaluate the model's performance on a held-out test set with the same input format and instructions used during training.
  2. Test the model's ability to handle unseen medical codes by introducing new diagnoses during inference and observing the changes in prediction probabilities.
  3. Assess the model's sensitivity to changes in input format or instructions by modifying the prompt or input data and comparing the resulting predictions to the original ones.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Sent-e-Med and LLaMA2-EHR change when incorporating additional clinical features like medications, lab results, and social determinants of health into the input?
- Basis in paper: [explicit] The discussion section mentions that conditions like SUD, OUD, and Diabetes might necessitate a more comprehensive exploration of patient history, including factors like medications, lab results, or social determinants of health.
- Why unresolved: The paper primarily focuses on using diagnostic history and does not extensively explore the impact of incorporating other clinical features.
- What evidence would resolve it: Conducting experiments with Sent-e-Med and LLaMA2-EHR using inputs that include additional clinical features and comparing their performance to the current results would provide insights into the impact of incorporating such features.

### Open Question 2
- Question: What are the specific sources of bias in the proposed models, and how do they affect the predictions for different demographic groups?
- Basis in paper: [inferred] The discussion section acknowledges the potential for biases in machine learning models and mentions plans to explore this aspect in future work, but does not provide specific details.
- Why unresolved: The paper does not conduct a thorough analysis of potential biases in the models and their impact on different demographic groups.
- What evidence would resolve it: Performing a comprehensive bias analysis on the proposed models, including evaluating their performance across different demographic groups and identifying potential sources of bias, would help understand and mitigate any adverse effects.

### Open Question 3
- Question: How do the proposed models perform in predicting rare diseases or conditions with limited training data?
- Basis in paper: [explicit] The results section mentions that Sent-e-Med and LLaMA2-EHR achieve significantly superior performance compared to MedBERT in the OUD prediction task on the Synthea-small dataset, which has a relatively limited number of positive samples.
- Why unresolved: While the paper demonstrates good performance on a dataset with limited positive samples, it does not specifically address the performance on rare diseases or conditions with very limited training data.
- What evidence would resolve it: Conducting experiments on datasets focused on rare diseases or conditions with limited training data and comparing the performance of the proposed models to other approaches would provide insights into their effectiveness in such scenarios.

## Limitations
- The specific SBERT model used for generating sentence embeddings is not mentioned, which may affect reproducibility.
- The exact prompts employed for fine-tuning LLaMA2-EHR are not provided in detail, introducing uncertainty in the fine-tuning process.
- The study does not extensively explore the interpretability of the models' predictions or their performance on other clinical risk prediction tasks beyond the three investigated.

## Confidence
- Medium: The results are promising but the study has some limitations and uncertainties, such as the specific SBERT model used and the exact fine-tuning prompts. Further validation on additional datasets and tasks would strengthen the confidence in the findings.

## Next Checks
1. Evaluate the models' performance on additional clinical risk prediction tasks, such as predicting other diseases or adverse events, to assess their generalizability.
2. Investigate the interpretability of the models' predictions by analyzing the attention weights or using other interpretability techniques to understand how the models arrive at their risk predictions.
3. Assess the robustness of the models to changes in input format, medical coding systems, or other variations in the EHR data to ensure their applicability in real-world clinical settings.