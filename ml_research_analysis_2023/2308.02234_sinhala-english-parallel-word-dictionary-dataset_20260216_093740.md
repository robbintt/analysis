---
ver: rpa2
title: Sinhala-English Parallel Word Dictionary Dataset
arxiv_id: '2308.02234'
source_url: https://arxiv.org/abs/2308.02234
tags:
- sinhala
- word
- dictionary
- english
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces three parallel English-Sinhala word dictionaries
  (En-Si-dict-large, En-Si-dict-filtered, En-Si-dict-FastText) for low-resource Sinhala-English
  NLP tasks. The dictionaries were created by extracting words from FastText models,
  translating them using Google Translate API, and filtering out multi-word entries.
---

# Sinhala-English Parallel Word Dictionary Dataset

## Quick Facts
- arXiv ID: 2308.02234
- Source URL: https://arxiv.org/abs/2308.02234
- Reference count: 40
- This paper introduces three parallel English-Sinhala word dictionaries (En-Si-dict-large, En-Si-dict-filtered, En-Si-dict-FastText) for low-resource Sinhala-English NLP tasks.

## Executive Summary
This paper addresses the challenge of creating high-quality parallel dictionaries for the low-resource Sinhala-English language pair, which are essential for supervised word embedding alignment and other cross-lingual NLP tasks. The authors propose a systematic approach using FastText monolingual models as vocabulary sources, Google Translate API for initial translation, and frequency-based pruning to improve dictionary quality. They create three dictionary variants and evaluate them using lookup precision on parallel corpora, demonstrating that their frequency-based filtering approach significantly improves dictionary quality compared to a naive translation approach.

## Method Summary
The authors extract vocabulary from pre-trained English and Sinhala FastText models, translate Sinhala words to English using Google Translate API, and filter out multi-word entries. They then perform frequency analysis on three Sinhala corpora, cluster words with the same English translation, and prune to the top 95% by frequency. The dictionaries are further pruned based on overlap with FastText vocabularies to ensure each entry has corresponding vector representations. The final dictionaries include both source and target FastText vocabularies (V2) to improve lookup precision.

## Key Results
- The En-Si-dict-filtered-V2 dataset achieves the highest lookup precision scores across both evaluation metrics and parallel corpora.
- Frequency-based pruning significantly improves dictionary quality compared to the initial translation-only approach.
- The dictionaries successfully map between the source and target FastText embedding spaces, enabling supervised word embedding alignment.

## Why This Works (Mechanism)

### Mechanism 1
Using FastText embeddings as the vocabulary source ensures that each dictionary entry has a corresponding vector representation for downstream NLP tasks. The authors extract the vocabulary from pre-trained FastText monolingual models (English and Sinhala), then use these as the basis for translation and filtering. This guarantees that all dictionary words have vector representations. Core assumption: FastText embeddings are available for both languages and contain comprehensive vocabulary coverage. Evidence anchors: [abstract] "We used FastText [31, 32] English 2 and Sinhala 3 monolingual embedding models to extract the dictionary words." [section] "First, the word columns of the FastText models are extracted." Break condition: If FastText models do not contain sufficient vocabulary coverage for the target domain, the dictionary will miss relevant words.

### Mechanism 2
Frequency-based pruning improves dictionary quality by removing low-frequency and potentially incorrect translations. The authors perform frequency analysis on three Sinhala corpora, cluster words with the same English translation, sort clusters by frequency, and keep the top 95% of words from each cluster. Core assumption: Word frequency in corpora correlates with translation accuracy and usefulness for downstream tasks. Evidence anchors: [abstract] "Then a Sinhala word frequency analysis is done using three Sinhala corpora and based on the word frequency information extracted using those corpora, the first dictionary we created in section III-B1 is pruned and the second dictionary is built." [section] "The purpose of this is to find the usage frequency of Sinhala words which helps us to do our frequency-based pruning." Break condition: If frequency-based pruning removes valid translations of rare but important words, the dictionary may lose coverage of specialized vocabulary.

### Mechanism 3
The simple lookup score and nearest neighbor lookup score metrics provide a reasonable evaluation of dictionary quality by measuring how well dictionary entries match parallel corpus alignments. The authors define scoring metrics that count how many source words have corresponding target words (or nearest neighbors) in the dictionary, using parallel corpora as a ground truth. Core assumption: Parallel corpora contain accurate word-level translations that can serve as a benchmark for dictionary quality. Evidence anchors: [abstract] "We have defined two scoring criteria ( simple lookup score and nearest neighbour lookup score - NN-lookup ) inspired by the widely used ROUGE-1 [39]." [section] "To estimate how good our datasets are, we have defined two scoring criteria ( simple lookup score and nearest neighbour lookup score - NN-lookup ) inspired by the widely used ROUGE-1 [39]." Break condition: If parallel corpora contain paraphrased rather than exact translations, the evaluation scores may underestimate dictionary quality.

## Foundational Learning

- Concept: Word embedding alignment
  - Why needed here: The dictionary is designed to support supervised word embedding alignment between English and Sinhala, which requires a bilingual lexicon as training data.
  - Quick check question: What is the difference between supervised and unsupervised word embedding alignment methods?

- Concept: Frequency analysis and pruning
  - Why needed here: Frequency analysis helps identify which words are most commonly used and likely to be important, while pruning removes potentially incorrect or low-value translations.
  - Quick check question: How does frequency-based pruning balance between dictionary comprehensiveness and translation accuracy?

- Concept: Polysemy and multiple translations
  - Why needed here: The authors acknowledge that the same word can have multiple correct translations due to polysemy, which affects dictionary design and evaluation.
  - Quick check question: How should a dictionary handle words with multiple meanings when creating parallel entries?

## Architecture Onboarding

- Component map:
  FastText models (English and Sinhala) → vocabulary extraction → Google Translate API → initial translation → frequency analysis pipeline → word pruning and filtering → evaluation pipeline → parallel corpus scoring → Storage layer → dictionary datasets (large, filtered, FastText versions)

- Critical path: FastText vocabulary extraction → translation → filtering → frequency-based pruning → evaluation

- Design tradeoffs:
  - Using Google Translate API provides broad coverage but may introduce errors; manual verification would improve quality but is resource-intensive
  - Removing multi-word entries ensures consistency but may lose valid compound translations
  - Frequency-based pruning improves quality but may reduce coverage of rare words
  - Including both source and target FastText vocabularies (V2) improves lookup precision but increases dataset size

- Failure signatures:
  - Low lookup precision scores indicate poor alignment between dictionary entries and parallel corpus translations
  - High unique word percentages suggest the dictionary may be missing alternative translations
  - Missing words in FastText vocabularies indicate coverage gaps
  - Poor evaluation scores across multiple corpora suggest systematic translation issues

- First 3 experiments:
  1. Test dictionary lookup precision on a small held-out subset of parallel sentences to validate the evaluation methodology
  2. Compare lookup scores using exact vs. approximate (nearest neighbor) matching to assess the impact of vector space proximity
  3. Analyze the effect of different frequency thresholds (e.g., top 90% vs. 95%) on dictionary quality and coverage

## Open Questions the Paper Calls Out

### Open Question 1
How does the quality of the proposed parallel dictionaries compare to existing Sinhala-English resources when used for multilingual word embedding alignment tasks? Basis in paper: [inferred] The paper evaluates dictionary quality using lookup scores on parallel corpora, but does not directly compare to existing Sinhala-English resources or measure downstream performance on embedding alignment tasks. Why unresolved: The authors only evaluate their dictionaries using lookup precision on parallel corpora, without comparing to other available resources or testing on actual multilingual embedding alignment tasks. What evidence would resolve it: Comparative experiments using the proposed dictionaries and existing resources on supervised multilingual word embedding alignment tasks, measuring metrics like precision/recall of aligned embeddings.

### Open Question 2
How does the inclusion of more monolingual vocabularies and alternative meanings affect the quality and coverage of the parallel dictionaries? Basis in paper: [explicit] The authors mention finding more monolingual vocabularies and including alternative meanings as future work. Why unresolved: The paper does not experiment with including more vocabularies or alternative meanings, so the impact on dictionary quality is unknown. What evidence would resolve it: Experiments creating new dictionary versions with expanded vocabularies and alternative meanings, measuring improvements in lookup precision and coverage on evaluation corpora.

### Open Question 3
What are the limitations and potential biases introduced by using Google Translate API for generating English translations of Sinhala words? Basis in paper: [explicit] The authors acknowledge using Google Translate API despite known weaknesses and inconsistencies, but do not analyze its impact on dictionary quality. Why unresolved: The paper does not investigate how translation errors or biases from Google Translate affect the accuracy and quality of the generated dictionaries. What evidence would resolve it: Manual evaluation of a sample of translated word pairs to assess accuracy, and analysis of how translation errors propagate through the dictionary creation pipeline and affect downstream tasks.

## Limitations
- The quality of the generated dictionaries heavily depends on the reliability of Google Translate API for low-resource language pairs, which may introduce systematic errors or biases not fully captured by the evaluation metrics.
- Frequency-based pruning assumes that high-frequency words are more likely to have correct translations, but this may not hold for domain-specific or technical vocabulary.
- The evaluation using parallel corpora assumes these corpora contain accurate word-level alignments, but sentence-level alignment does not guarantee precise word alignment, potentially leading to overly pessimistic quality estimates.

## Confidence

- High confidence in the methodology for dictionary creation and the general approach to evaluation using parallel corpora. The use of FastText embeddings as a vocabulary source is well-established, and the frequency analysis approach is standard in computational linguistics.
- Medium confidence in the evaluation metrics and their interpretation, as the relationship between dictionary lookup precision and downstream task performance is not empirically validated.
- Low confidence in the absolute quality of translations from Google Translate API for the Sinhala-English language pair, as this has not been independently verified for this specific use case.

## Next Checks

1. **Manual quality verification**: Randomly sample 100 dictionary entries and manually verify translation accuracy with native Sinhala speakers to establish ground truth quality independent of the evaluation methodology.

2. **Downstream task impact**: Train a supervised word embedding alignment model using each dictionary variant and measure the impact on actual NLP tasks (e.g., cross-lingual information retrieval) rather than relying solely on dictionary lookup precision scores.

3. **Alternative translation sources**: Generate a small parallel dictionary using professional translators and compare its performance against the Google Translate-derived dictionaries to quantify the impact of translation quality on downstream utility.