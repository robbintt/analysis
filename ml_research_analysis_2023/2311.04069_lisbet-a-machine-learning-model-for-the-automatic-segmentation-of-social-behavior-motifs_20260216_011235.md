---
ver: rpa2
title: 'LISBET: a machine learning model for the automatic segmentation of social
  behavior motifs'
arxiv_id: '2311.04069'
source_url: https://arxiv.org/abs/2311.04069
tags:
- lisbet
- social
- behavior
- motifs
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'LISBET is a self-supervised Transformer model for automated detection
  and segmentation of social behaviors from body tracking data. It uses four self-supervised
  tasks to train without human annotations: Swap Mouse Prediction, Next Window Prediction,
  Video Speed Prediction, and Delay Mouse Prediction.'
---

# LISBET: a machine learning model for the automatic segmentation of social behavior motifs

## Quick Facts
- arXiv ID: 2311.04069
- Source URL: https://arxiv.org/abs/2311.04069
- Reference count: 0
- Primary result: Self-supervised transformer model for automatic segmentation of social behaviors from body tracking data

## Executive Summary
LISBET is a self-supervised Transformer model that automatically detects and segments social behaviors from body tracking data without requiring human annotations. The model uses four self-supervised tasks—Swap Mouse Prediction, Next Window Prediction, Video Speed Prediction, and Delay Mouse Prediction—to learn meaningful behavioral representations from unlabeled mouse interaction data. It achieves F1-scores of 0.71 (linear classifier) and 0.78 (fine-tuned) for behavior classification, segments behavioral motifs using HMM with 0.33 NMI with human labels, and identifies patterns correlated with VTA dopaminergic neuron activity.

## Method Summary
LISBET is a ViT/ViViT-based transformer trained on body part coordinates (7 parts per mouse) from video recordings of mouse pairs during resident-intruder paradigms. The model processes sliding windows of 200 frames through a frame encoder (MLP with GELU), learned positional encoding, and transformer encoder to generate behavioral embeddings. Training uses four self-supervised tasks that capture spatial relationships, temporal patterns, speed characteristics, and movement synchronicity. The model can classify behaviors using linear classifiers or discover novel motifs through HMM segmentation, with applications in automated annotation, phenotyping, and neural-behavioral correlation studies.

## Key Results
- F1-scores of 0.71 (linear classifier) and 0.78 (fine-tuned) for behavior classification
- HMM-based motif segmentation achieving 0.33 NMI with human annotations
- Discovery of behavioral motifs correlated with VTA dopaminergic neuron activity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LISBET eliminates human bias by replacing manual annotation with self-supervised learning on body tracking data
- Mechanism: The model learns meaningful behavioral representations through four self-supervised tasks that force it to capture spatial relationships, temporal patterns, speed characteristics, and movement synchronicity without requiring labeled examples
- Core assumption: Body part coordinates contain sufficient information to distinguish different social behaviors
- Evidence anchors:
  - [abstract] "eliminates the need for extensive human annotation by using self-supervised learning"
  - [section] "trained to produce an embedding of the scene by solving four self-supervised learning tasks"
  - [corpus] Weak evidence - corpus contains related behavioral analysis papers but none specifically address self-supervised social behavior segmentation from tracking data

### Mechanism 2
- Claim: The model generalizes across different experimental conditions and can discover new behavioral motifs
- Mechanism: Pre-training on unlabeled data creates embeddings that capture general social interaction patterns, which can then be fine-tuned for specific behaviors or used with HMMs to discover novel motifs that correlate with neural activity
- Core assumption: The self-supervised training tasks create embeddings that are broadly applicable to social behavior analysis
- Evidence anchors:
  - [abstract] "model obtained an F1-score = 0.71" and "segments behavioral motifs using HMM, achieving 0.33 NMI with human labels"
  - [section] "model obtained an average F1-score = 0.25" on different dataset, showing generalization
  - [corpus] Moderate evidence - related papers on behavioral segmentation exist but don't demonstrate neural-behavioral correlation discovery

### Mechanism 3
- Claim: LISBET enables correlation between discovered behavioral motifs and neural activity patterns
- Mechanism: By segmenting behavior into motifs without human bias, the model reveals neural correlates that might be obscured by traditional behavior categories, as demonstrated with VTA dopaminergic neuron activity
- Core assumption: Some behavioral motifs will have distinct neural signatures even if they appear similar to human observers
- Evidence anchors:
  - [abstract] "motifs identified by our model... correlate with the electrophysiological activity of dopaminergic neurons"
  - [section] "motif three corresponded to an increase in activity, while motif eight corresponded to a decrease"
  - [corpus] Weak evidence - corpus lacks papers combining unsupervised behavioral segmentation with neural recording correlation studies

## Foundational Learning

- Concept: Self-supervised learning and its advantages over supervised learning
  - Why needed here: The paper relies on self-supervised training to eliminate the need for human annotations, which is central to LISBET's value proposition
  - Quick check question: What are the four self-supervised tasks used in LISBET and what behavioral aspects does each capture?

- Concept: Transformer architectures and their application to sequential data
  - Why needed here: LISBET uses a ViT/ViViT-based transformer architecture, which is key to understanding how the model processes behavioral sequences
  - Quick check question: How does the frame encoder in LISBET differ from standard ViT implementations?

- Concept: Hidden Markov Models for sequence segmentation
  - Why needed here: The paper uses HMMs to segment LISBET embeddings into behavioral motifs, which is crucial for the discovery-driven approach
  - Quick check question: What advantage does HMM segmentation provide over simple clustering methods for behavioral motif discovery?

## Architecture Onboarding

- Component map: Body tracking data → Frame encoder (MLP) → Positional encoding → Transformer encoder → LISBET embedding → (Optional) Classification head / HMM segmentation
- Critical path: The embedding generation path is critical - any issues here will cascade through all downstream applications
- Design tradeoffs: Using body coordinates instead of raw video reduces model complexity but may miss some behavioral information; self-supervised training eliminates annotation burden but requires careful task design
- Failure signatures: Poor classification performance indicates embedding quality issues; HMM segmentation failure suggests temporal structure isn't captured; lack of neural correlation indicates behavioral relevance problems
- First 3 experiments:
  1. Verify the frame encoder can reconstruct input coordinates from embeddings (embedding quality check)
  2. Test each self-supervised task independently to ensure they're learnable (task design validation)
  3. Compare embeddings from different window sizes to find optimal temporal resolution (architecture tuning)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does LISBET perform on complex social scenarios involving more than two animals?
- Basis in paper: [inferred] The paper mentions that "we only considered pair interactions" and "extending it to include more than two animals is beyond the scope of this study."
- Why unresolved: The study focused on dyadic interactions, so performance on group dynamics or larger social networks remains untested.
- What evidence would resolve it: Testing LISBET on datasets with group interactions (e.g., trios or larger) and comparing its motif detection and classification accuracy to human annotations.

### Open Question 2
- Question: What is the optimal set of self-supervised tasks for training LISBET to generalize across diverse mouse behaviors?
- Basis in paper: [explicit] "we chose the set of self-supervised training tasks based on intuition and successive iterations" and "the generalization power to this dataset was implicitly used as the success measure."
- Why unresolved: The authors acknowledge that other tasks might have been better suited for predicting different behaviors, but did not systematically explore alternatives.
- What evidence would resolve it: A systematic comparison of different self-supervised task combinations, evaluated on multiple datasets with diverse behaviors, to identify the most effective training setup.

### Open Question 3
- Question: How do LISBET-derived behavioral motifs relate to specific neural circuits beyond VTA dopaminergic neurons?
- Basis in paper: [explicit] The study found correlations between motifs and VTA-pDA neuron activity but states "more research will be required to delve deeper into the precise neurological pathways and mechanisms."
- Why unresolved: The neural correlates were only explored in one brain region, leaving open the question of how motifs map to other circuits involved in social behavior.
- What evidence would resolve it: Simultaneous electrophysiological recordings from multiple brain regions during social interactions, combined with LISBET motif segmentation, to identify circuit-specific neural signatures.

## Limitations
- Reliance on body tracking data may miss critical behavioral information like facial expressions and vocalizations
- 0.33 NMI with human annotations indicates discovered motifs only partially align with expert-defined behaviors
- Success on CalMS21 doesn't guarantee performance across diverse species or behavioral contexts without additional fine-tuning

## Confidence
- High confidence: The self-supervised learning framework is technically sound and the four training tasks are well-defined and implementable
- Medium confidence: The classification performance (F1=0.71-0.78) is achievable given the methodology, though real-world performance may vary
- Low confidence: The neural-behavioral correlation claims are promising but require independent validation, as the corpus lacks comparable studies

## Next Checks
1. Cross-species validation: Test LISBET on a different species (e.g., fruit flies or primates) to assess generalizability beyond mouse social interactions
2. Behavioral feature ablation: Systematically remove different body parts from the tracking data to determine which features are most critical for behavior discrimination
3. Neural correlation replication: Apply the motif discovery approach to a new electrophysiology dataset to verify that unsupervised segmentation can reveal meaningful neural-behavioral relationships independent of the VTA dopaminergic system