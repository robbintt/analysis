---
ver: rpa2
title: 'ADaPT: As-Needed Decomposition and Planning with Language Models'
arxiv_id: '2311.05772'
source_url: https://arxiv.org/abs/2311.05772
tags:
- task
- adapt
- step
- think
- cabinet
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ADaPT improves LLM-based decision-making by dynamically decomposing
  complex tasks as-needed, using a recursive algorithm that combines a planner and
  executor LLM. Unlike static plan-and-execute or iterative executor-only approaches,
  ADaPT only invokes the planner when the executor fails, adapting to both task complexity
  and executor capability.
---

# ADaPT: As-Needed Decomposition and Planning with Language Models

## Quick Facts
- arXiv ID: 2311.05772
- Source URL: https://arxiv.org/abs/2311.05772
- Reference count: 24
- Key outcome: ADaPT improves LLM-based decision-making by dynamically decomposing complex tasks as-needed, using a recursive algorithm that combines a planner and executor LLM.

## Executive Summary
ADaPT introduces a novel approach to improve LLM-based decision-making by dynamically decomposing complex tasks only when needed. Unlike static plan-and-execute or iterative executor-only approaches, ADaPT recursively decomposes sub-tasks to adapt to both task complexity and LLM capability. The method achieves up to 28.3%, 27%, and 33% higher success rates respectively compared to strong baselines like ReAct and Reflexion on ALFWorld, WebShop, and TextCraft.

## Method Summary
ADaPT uses a recursive algorithm that first attempts to execute the entire task using an executor LLM. Only if the executor fails does it invoke a planner LLM to decompose the task into sub-tasks. This selective decomposition approach ensures planning resources are used efficiently. The planner and executor modules can use different LLM models, allowing for optimization of performance and computational cost. ADaPT employs a self-generated success heuristic to determine if the executor has successfully completed a task without relying on environment rewards.

## Key Results
- ADaPT achieves 28.3% higher success rates on ALFWorld compared to ReAct baseline
- ADaPT shows 27% improvement on WebShop over Reflexion baseline
- ADaPT demonstrates 33% higher success rates on TextCraft compared to executor-only approach

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: ADaPT improves performance by dynamically decomposing tasks only when the executor fails, reducing unnecessary planning overhead.
- **Mechanism**: The recursive algorithm first attempts to execute the entire task using the executor. Only if the executor fails does it invoke the planner to decompose the task. This selective decomposition ensures that planning resources are used efficiently, focusing only on the complex sub-tasks that the executor cannot handle.
- **Core assumption**: The executor's failure to complete a task is a reliable indicator that the task is too complex for direct execution and requires decomposition.
- **Evidence anchors**:
  - [abstract] "ADaPT only invokes the planner when the executor fails, adapting to both task complexity and executor capability."
  - [section 3.1] "To decompose based on the abilities of the executor, we need to determine whether the executor is capable of finishing the given (sub-)task independently or if further decomposition is required."
- **Break condition**: If the executor's failure heuristic is unreliable or noisy, ADaPT may either over-decompose (wasting resources) or under-decompose (failing tasks).

### Mechanism 2
- **Claim**: Recursive decomposition allows ADaPT to handle tasks of varying complexity by adjusting the depth of decomposition based on the executor's capabilities.
- **Mechanism**: ADaPT employs a recursive structure where each sub-task is further decomposed if the executor fails. The maximum depth of decomposition (dmax) can be adjusted, allowing the system to adapt to both simple tasks (requiring minimal decomposition) and complex tasks (requiring deeper decomposition).
- **Core assumption**: The executor's performance improves with shallower task decomposition, and there is a correlation between task complexity and the required decomposition depth.
- **Evidence anchors**:
  - [abstract] "ADaPT recursively decomposes sub-tasks to adapt to both task complexity and LLM capability."
  - [section 6.1] "Performance of ADaPT scales with increasing the maximum depth dmax... Consistently, we find a significant improvement in success rates as we move from dmax = 1 to dmax = 2."
- **Break condition**: If the correlation between task complexity and decomposition depth is weak or non-existent, ADaPT's adaptive depth adjustment may not improve performance.

### Mechanism 3
- **Claim**: ADaPT's ability to use different planner and executor LLMs enhances its flexibility and applicability across diverse tasks and executor capabilities.
- **Mechanism**: The planner and executor modules of ADaPT do not need to use the same underlying LLM model. This allows for using a more advanced LLM for planning complex tasks while employing a smaller or specialized LLM for execution, optimizing for performance and computational cost.
- **Core assumption**: Different LLMs have varying strengths in planning versus execution, and combining them can leverage their respective advantages.
- **Evidence anchors**:
  - [section 6.2] "We explore different combinations of planner and executor LLM... ADaPT can successfully be used to generate plans from one LLM that are useful to a different, possibly smaller, executor LLM, improving success rates by up to 19.9% compared to the executor-only setting."
- **Break condition**: If the planner and executor LLMs are not well-matched or if communication between them is inefficient, the performance gains may be minimal or negative.

## Foundational Learning

- **Concept: Recursive algorithms**
  - Why needed here: ADaPT's core mechanism relies on recursively calling itself with decomposed sub-tasks until they are simple enough for the executor to handle.
  - Quick check question: How does a recursive function know when to stop calling itself, and how is this implemented in ADaPT?

- **Concept: Prompt engineering for LLMs**
  - Why needed here: ADaPT uses carefully crafted prompts to instruct the planner and executor LLMs on how to decompose tasks and execute actions, respectively.
  - Quick check question: What are the key elements of an effective prompt for an LLM to generate a plan, and how do they differ from prompts for execution?

- **Concept: Success heuristics for task completion**
  - Why needed here: ADaPT uses a self-generated success heuristic to determine if the executor has successfully completed a task without relying on environment rewards, enabling decomposition decisions.
  - Quick check question: How does the LLM generate a reliable success heuristic, and what are the limitations of this approach compared to environment-based rewards?

## Architecture Onboarding

- **Component map**: Controller -> Executor -> Environment (if fails, then Controller -> Planner -> Executor -> Environment)

- **Critical path**:
  1. Controller receives task from environment.
  2. Controller calls executor with the task.
  3. If executor fails, controller calls planner to decompose the task.
  4. Planner returns sub-tasks and logical operators.
  5. Controller recursively calls ADaPT for each sub-task.
  6. Sub-task successes are combined using logical operators.
  7. Overall task success is returned to the environment.

- **Design tradeoffs**:
  - Using a single LLM for both planning and execution simplifies the architecture but may limit performance compared to specialized models.
  - The recursive approach can handle complex tasks but may incur higher computational costs due to multiple LLM calls.
  - The success heuristic is lightweight but may be less reliable than environment-based rewards, especially in subjective tasks.

- **Failure signatures**:
  - Executor consistently fails even with decomposition: Indicates that the executor is too weak or the tasks are too complex; consider using a stronger executor or adjusting dmax.
  - Planner generates overly complex or incorrect decompositions: May require prompt engineering or using a more capable planner LLM.
  - Excessive recursion depth: Could lead to performance degradation; consider increasing dmax or using a more capable executor.

- **First 3 experiments**:
  1. Run ADaPT with dmax = 1 (executor-only) on a simple task to establish baseline performance.
  2. Increase dmax to 2 and observe the impact on success rate and execution time for the same task.
  3. Compare ADaPT's performance with and without decomposition on a task known to be complex for the executor.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of ADAPT scale with different values of maximum decomposition depth (dmax) across various task complexities and executor capabilities?
- Basis in paper: [explicit] The paper mentions that ADAPT's performance scales with increasing maximum depth dmax, but does not provide a detailed analysis of how this scaling varies with task complexity or executor strength.
- Why unresolved: The paper shows that performance improves with increasing dmax, but does not explore the relationship between dmax, task complexity, and executor capabilities in detail.
- What evidence would resolve it: A comprehensive study varying dmax, task complexity, and executor capabilities, and analyzing the resulting performance trends.

### Open Question 2
- Question: How does the choice of planner and executor LLMs affect the overall performance of ADAPT, and what are the optimal combinations for different task types?
- Basis in paper: [explicit] The paper explores using different planner and executor LLMs, showing that ADAPT can improve performance when using different models, but does not provide an in-depth analysis of optimal combinations.
- Why unresolved: While the paper demonstrates that different LLM combinations can affect performance, it does not explore the full space of possibilities or identify optimal combinations for specific task types.
- What evidence would resolve it: A systematic study varying both planner and executor LLMs across different task types, and identifying optimal combinations based on performance.

### Open Question 3
- Question: How does the self-generated success heuristic used by ADAPT compare to gold environment rewards in terms of accuracy and impact on overall performance?
- Basis in paper: [explicit] The paper mentions using a self-generated success heuristic and compares it to gold environment rewards, finding that the heuristic is generally accurate but can be inflated for complex tasks like WebShop.
- Why unresolved: The paper provides a preliminary comparison but does not explore the limitations of the self-generated heuristic in depth or investigate methods to improve its accuracy.
- What evidence would resolve it: A detailed analysis of the self-generated heuristic's accuracy across various task types and complexity levels, along with experiments testing methods to improve its reliability.

## Limitations

- The success heuristic's reliability across subjective domains remains uncertain
- Computational overhead of recursive LLM calls may become prohibitive for very deep decomposition trees
- The optimal pairing strategy for different planner and executor LLMs is not clearly established

## Confidence

**High Confidence**: The selective decomposition mechanism (Mechanism 1) is well-supported by the experimental results showing improved performance over baseline approaches. The correlation between decomposition depth and success rates (Mechanism 2) is also strongly evidenced across multiple domains.

**Medium Confidence**: The ability to mix different LLMs for planning and execution (Mechanism 3) shows promising results, but the optimal pairing strategy remains unclear. The performance gains are significant but may depend heavily on the specific models chosen.

**Low Confidence**: The scalability of ADaPT to extremely complex tasks requiring deep decomposition (>3 levels) is not thoroughly tested. The paper focuses on relatively shallow decomposition trees, leaving questions about performance on tasks requiring deeper recursive breakdown.

## Next Checks

1. Test ADaPT's performance on tasks requiring >3 levels of decomposition to evaluate scalability limits and computational overhead.

2. Evaluate the success heuristic's reliability in subjective domains (e.g., creative writing tasks) where success criteria are less objective than in ALFWorld or WebShop.

3. Compare ADaPT's performance when using the same LLM for both planning and execution versus specialized models to quantify the benefits of model heterogeneity.