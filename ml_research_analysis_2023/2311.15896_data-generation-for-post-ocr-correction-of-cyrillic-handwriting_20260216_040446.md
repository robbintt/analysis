---
ver: rpa2
title: Data Generation for Post-OCR correction of Cyrillic handwriting
arxiv_id: '2311.15896'
source_url: https://arxiv.org/abs/2311.15896
tags:
- text
- handwriting
- dataset
- handwritten
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a novel approach to post-OCR correction\
  \ for handwritten Cyrillic text using synthetic data generation with B\xE9zier curves\
  \ and a seq2seq T5 model. The method addresses the lack of large error corpora by\
  \ generating realistic handwritten text and applying an HTR model to collect OCR\
  \ errors for training."
---

# Data Generation for Post-OCR correction of Cyrillic handwriting

## Quick Facts
- **arXiv ID**: 2311.15896
- **Source URL**: https://arxiv.org/abs/2311.15896
- **Reference count**: 0
- **Primary result**: POC model improves WAR by up to 18.3% on Student Essays dataset using synthetic handwriting generated with Bézier curves

## Executive Summary
This paper addresses the challenge of post-OCR correction for handwritten Cyrillic text by introducing a synthetic data generation approach using Bézier curves. The method tackles the lack of large error corpora by generating realistic handwritten text and applying an HTR model to collect OCR errors for training a seq2seq T5-based POC model. The approach is evaluated on three datasets: HWR200, School_notebooks_RU, and an in-house Student Essays dataset, demonstrating significant improvements in Word Accuracy Rate (WAR) while highlighting challenges with out-of-distribution data.

## Method Summary
The method involves generating synthetic handwritten Cyrillic text using Bézier curves with various augmentations, then processing this synthetic text through an HTR model to collect OCR errors. These error pairs (incorrect OCR output and correct text) are used to train a T5 transformer model in a seq2seq fashion for post-OCR correction. The model is trained on 90-symbol contexts and evaluated using WAR and CAR metrics across three normalization conditions. The approach addresses the fundamental challenge of lacking large error corpora for training post-OCR correction models on handwritten Cyrillic text.

## Key Results
- POC model achieves WAR improvements of up to 18.3% on Student Essays dataset and 11.9% on HWR200 scans
- CAR improvements are less pronounced than WAR improvements, suggesting high baseline character-level accuracy
- Model performance degrades on out-of-distribution data, particularly on the Student Essays dataset with diverse handwriting styles
- Significant WAR improvements observed across all three normalization conditions (Raw text, Lowercase only, Only alphabetical)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The T5 seq2seq model effectively corrects OCR errors when trained on synthetically generated handwriting errors.
- Mechanism: The synthetic handwriting generation using Bézier curves creates realistic text samples. An HTR model processes these to generate OCR errors, which are then paired with correct text to train the POC model in a seq2seq fashion.
- Core assumption: The Bézier curve-based synthetic handwriting sufficiently mimics real handwriting variability to produce meaningful OCR errors.
- Evidence anchors:
  - [abstract] "Our study primarily focuses on the development and application of a synthetic handwriting generation engine based on Bézier curves... We apply a Handwritten Text Recognition (HTR) model to this dataset to identify OCR errors, forming the basis for our POC model training."
  - [section] "We evaluate our approach on HWR200 and School_notebooks_RU datasets... Results show significant WAR improvements across datasets, with WAR increases of up to 18.3% on Student Essays dataset"
  - [corpus] Weak - The related papers focus on post-OCR correction but do not specifically validate Bézier curve synthetic handwriting generation.
- Break condition: If the Bézier curve generation fails to capture sufficient handwriting variability, the OCR errors collected would not represent real-world errors, leading to poor POC model performance on actual handwritten text.

### Mechanism 2
- Claim: The POC model improves word-level accuracy more effectively than character-level accuracy.
- Mechanism: The seq2seq T5 model leverages contextual understanding to correct entire words rather than individual characters, as evidenced by larger WAR improvements compared to CAR improvements.
- Core assumption: Contextual information is more valuable for word-level correction than for character-level correction.
- Evidence anchors:
  - [section] "The improvement in mean CAR with POC is less pronounced compared to WAR. This could imply that the model's character-level recognition capabilities are already quite high, and the POC model offers incremental improvements in this aspect."
  - [section] "A consistent observation across all datasets is the improvement in WAR metrics with the application of POC, validating our approach of using realistically generated handwriting"
  - [corpus] Weak - Related papers discuss post-OCR correction but don't specifically compare WAR vs CAR improvements.
- Break condition: If the POC model over-corrects at the word level without considering character-level accuracy, it could introduce errors that degrade CAR while improving WAR.

### Mechanism 3
- Claim: Dataset quality and similarity to training data significantly impact POC model performance.
- Mechanism: The POC model performs best on datasets similar to its training distribution (high-quality scans, consistent handwriting style), with reduced effectiveness on out-of-distribution data.
- Core assumption: The model's performance is highly dependent on the similarity between training and evaluation data distributions.
- Evidence anchors:
  - [section] "The application of POC leads to a notable improvement in WAR across all normalization types... Unlike in the previous datasets, the POC also improves the CAR, though the increase is more modest than in WAR."
  - [section] "Our focus on student handwriting is two-fold: 1. Underdeveloped handwriting of students provides additional challenge in HTR task, thus increasing value of POC model in terms of improving readability of recognized text"
  - [corpus] Weak - Related papers don't discuss dataset similarity effects on POC performance.
- Break condition: If the POC model encounters handwriting styles significantly different from its training data, its performance could degrade substantially regardless of the quality of the input text.

## Foundational Learning

- Concept: Bézier curves and their application in generating smooth, continuous curves
  - Why needed here: The entire synthetic handwriting generation relies on manipulating Bézier curves to create realistic handwriting
  - Quick check question: How do four-point Bézier curves differ from three-point Bézier curves in terms of the shapes they can create?

- Concept: Sequence-to-sequence (seq2seq) learning and transformer architectures
  - Why needed here: The POC model uses a T5 transformer in seq2seq fashion to correct OCR errors
  - Quick check question: What is the fundamental difference between seq2seq models and other neural network architectures for text processing?

- Concept: Handwriting recognition challenges and OCR error types
  - Why needed here: Understanding the types of errors (insertions, deletions, substitutions) helps in evaluating the POC model's effectiveness
  - Quick check question: What are the three main types of OCR errors that post-correction models typically address?

## Architecture Onboarding

- Component map:
  - Bézier Curve Generator → Synthetic Handwriting → HTR Model → OCR Error Dataset → T5 POC Model → Corrected Text
  - Text Detection (CRAFT) → Text Recognition (CRNN) → OCR Output → POC Model → Final Output

- Critical path:
  1. Generate synthetic handwriting using Bézier curves
  2. Process synthetic text through HTR model to collect errors
  3. Train T5 POC model on error pairs
  4. Apply POC model to real OCR outputs

- Design tradeoffs:
  - High-quality synthetic data vs. computational cost of generation
  - Model complexity vs. training time and resource requirements
  - Dataset size vs. overfitting risk

- Failure signatures:
  - Poor WAR/CAR improvements on test data
  - Over-correction leading to introduced errors
  - Model bias toward training distribution handwriting styles

- First 3 experiments:
  1. Generate a small synthetic dataset and verify HTR error collection works correctly
  2. Train POC model on a subset of synthetic data and evaluate on a held-out portion
  3. Test POC model on a simple real-world dataset to verify end-to-end functionality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the POC model vary across different levels of lighting conditions beyond the three categories (scans, good photos, bad photos) tested in HWR200?
- Basis in paper: [inferred] The paper evaluates HWR200 under three lighting conditions but doesn't explore intermediate or more extreme lighting scenarios, which could provide insights into the model's robustness.
- Why unresolved: The study focuses on three specific lighting conditions, leaving a gap in understanding how the model performs under varying or extreme lighting conditions.
- What evidence would resolve it: Testing the model on datasets with additional lighting conditions, such as very dim or very bright environments, and analyzing the performance metrics (WAR and CAR) across these conditions.

### Open Question 2
- Question: What is the impact of using different pre-trained transformer models (e.g., BERT, GPT) compared to T5 on the POC model's performance?
- Basis in paper: [explicit] The paper mentions the use of a T5-based model but suggests evaluating other transformer models like BERT and GPT in the "Further Work" section.
- Why unresolved: The study uses a T5-based model without exploring how other transformer architectures might affect the POC model's effectiveness.
- What evidence would resolve it: Conducting experiments using alternative transformer models for the POC task and comparing their performance metrics with the T5-based model.

### Open Question 3
- Question: How does the inclusion of teacher comments in the School_notebooks_RU dataset affect the POC model's ability to correct student handwriting specifically?
- Basis in paper: [explicit] The paper notes that including teacher comments decreases accuracy in both WAR and CAR, but it doesn't isolate the effect on student handwriting correction.
- Why unresolved: The mixed dataset of student and teacher handwriting complicates understanding the POC model's specific performance on student text.
- What evidence would resolve it: Analyzing the POC model's performance on student handwriting alone, both with and without the presence of teacher comments, to determine the specific impact on student text correction.

### Open Question 4
- Question: What is the effect of varying the Bézier curve parameters more drastically on the realism and variability of generated handwriting?
- Basis in paper: [inferred] The paper discusses the use of Bézier curves for generating handwriting but does not explore the impact of extreme parameter variations on the quality of the generated text.
- Why unresolved: The study applies moderate augmentations to Bézier curves but does not test the limits of these parameters to see how they affect the realism of the generated handwriting.
- What evidence would resolve it: Experimenting with a wider range of Bézier curve parameter values and assessing the generated handwriting's realism and variability through human evaluation or comparison with real handwriting samples.

## Limitations
- The synthetic handwriting generation using Bézier curves may not fully capture the variability of real handwriting, particularly for out-of-distribution data like student essays
- The paper lacks a comprehensive comparison with other post-OCR correction approaches for Cyrillic text
- No detailed validation of the synthetic handwriting generation method itself is provided

## Confidence
- **High Confidence**: The WAR improvements across datasets are consistent and significant, indicating that the POC model effectively corrects OCR errors in Cyrillic handwriting
- **Medium Confidence**: The improvement in CAR is less pronounced compared to WAR, suggesting that the model's character-level recognition capabilities are already quite high
- **Low Confidence**: The specific impact of dataset similarity on POC model performance is not fully explored

## Next Checks
1. **Synthetic Handwriting Validation**: Conduct a detailed evaluation of the synthetic handwriting generation method by comparing the statistical properties of generated samples with real handwriting
2. **Dataset Similarity Analysis**: Perform an analysis of the similarity between the synthetic training data and each evaluation dataset using character n-gram distributions or handwriting feature similarity
3. **Ablation Study on POC Model**: Conduct an ablation study to isolate the contribution of the POC model to the overall OCR correction performance