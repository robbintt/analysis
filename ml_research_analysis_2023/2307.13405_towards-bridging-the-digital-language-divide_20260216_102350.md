---
ver: rpa2
title: Towards Bridging the Digital Language Divide
arxiv_id: '2307.13405'
source_url: https://arxiv.org/abs/2307.13405
tags:
- language
- languages
- bias
- linguistic
- lexical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces and analyzes the concept of linguistic bias
  in AI-based language technology, which manifests as uneven performance across languages
  due to design limitations. The authors demonstrate this bias in multilingual lexical
  databases, neural language models, and machine translation systems.
---

# Towards Bridging the Digital Language Divide

## Quick Facts
- arXiv ID: 2307.13405
- Source URL: https://arxiv.org/abs/2307.13405
- Reference count: 40
- This paper introduces and analyzes linguistic bias in AI-based language technology, proposing the UKC lexical database and LiveLanguage initiative as solutions.

## Executive Summary
This paper addresses the critical issue of linguistic bias in AI-based language technologies, which manifests as uneven performance across languages due to design limitations rather than data scarcity. The authors propose a collaborative methodology involving local communities in resource development, exemplified by the Universal Knowledge Core (UKC) lexical database. The UKC features a language-agnostic interlingua and explicit modeling of linguistic diversity, while the LiveLanguage initiative implements co-design projects with various language communities worldwide. This approach aims to bridge the digital language divide by ensuring that language technologies serve all linguistic communities equitably.

## Method Summary
The methodology involves measuring linguistic bias through performance variance across languages using synthetic cross-lingual mapping datasets and gold-standard datasets. The Universal Knowledge Core (UKC) lexical database is implemented with a language-agnostic interlingua and explicit representation of linguistic diversity, including lexical gaps. The LiveLanguage initiative coordinates co-design projects with local communities, ensuring community-led project specification and intellectual property rights. The approach contrasts with traditional top-down resource development by empowering local institutions to determine their own linguistic technology needs.

## Key Results
- UKC contains over 1.9 million words from 2,100+ languages
- Language-agnostic interlingua decouples lexical representations from specific natural languages
- Explicit modeling of lexical gaps helps machine translation systems identify untranslatable phrases
- Co-design methodology ensures community ownership of intellectual property rights

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The UKC's language-agnostic interlingua reduces structural bias by decoupling lexical representations from any specific natural language.
- Mechanism: By using abstract concept identifiers rather than words from a particular language as pivots, the UKC avoids privileging any single language's worldview or vocabulary. This allows cross-lingual mappings that preserve semantic distinctions that might be lost when translating through a biased pivot language.
- Core assumption: A truly language-agnostic concept space can be constructed and maintained without introducing hidden biases through the selection or organization of concepts.
- Evidence anchors:
  - [abstract] "The Universal Knowledge Core (UKC) lexical database is presented as a diversity-aware solution, featuring a language-agnostic interlingua and explicit modeling of linguistic diversity."
  - [section 5] "Horizontally, the model is divided into two layers: the lexico-semantic layer represents lexical meaning through concepts and their relationships... Vertically, the model is divided into an interlingua (in yellow) that models unity, i.e. shared phenomena across languages, as well as one lexicon per language (in blue) that models diversity."
  - [corpus] Weak - no direct corpus evidence for this specific mechanism, though related bias studies exist.
- Break condition: If the interlingua concept hierarchy implicitly reflects biases of its creators or if certain language families are systematically underrepresented in concept coverage.

### Mechanism 2
- Claim: Explicit modeling of lexical gaps (untranslatability) helps machine translation systems identify and handle difficult-to-translate phrases appropriately.
- Mechanism: By distinguishing between words absent from a lexicon and genuinely untranslatable concepts, the UKC provides explicit signals to downstream systems about translation difficulty. This prevents systems from making incorrect assumptions or producing semantically absurd outputs.
- Core assumption: Translation systems can effectively use lexical gap information to modify their behavior (e.g., by leaving terms untranslated or using alternative strategies).
- Evidence anchors:
  - [section 5] "Cases of lexical untranslatability (e.g. no word exists for rice in Swahili) are modelled by linking the interlingual concept to a lexical gap concept instead, marked as GAP in the figure. The explicit distinction of untranslatability from words merely being absent from the lexicon... can help MT systems identify difficult-to-translate phrases and handle them appropriately."
  - [section 3] "Today's top MT systems, such as DeepL and Google Translate, make systematic mistakes over untranslatable terms, betraying the fact that this phenomenon is not specifically addressed by these tools."
  - [corpus] Weak - no direct corpus evidence for this specific mechanism.
- Break condition: If translation systems ignore lexical gap annotations or if the distinction between lexical gaps and missing words becomes blurred in practice.

### Mechanism 3
- Claim: Co-design methodology with local communities reduces bias by ensuring that resource development addresses actual linguistic needs rather than researcher assumptions.
- Mechanism: By involving local communities in project specification, development, and IP ownership, the LiveLanguage initiative ensures that the resulting resources reflect local linguistic realities and priorities. This contrasts with top-down approaches that impose external assumptions about language needs.
- Core assumption: Local communities have both the knowledge and motivation to participate effectively in resource development when given appropriate support and IP rights.
- Evidence anchors:
  - [abstract] "The LiveLanguage initiative implements this methodology through co-design projects with various language communities worldwide."
  - [section 4] "We endorse the idea of a co-design methodology where local communities exercise decisional power and property rights over research outcomes."
  - [section 6] "Project specification is determined by the long-term goals of the local community, and is led by the local institution."
  - [corpus] Weak - no direct corpus evidence for this specific mechanism.
- Break condition: If local communities lack resources or institutional support to participate effectively, or if external funding priorities override community needs.

## Foundational Learning

- Concept: Linguistic diversity as both descriptive and normative phenomenon
  - Why needed here: Understanding the dual nature of linguistic diversity is crucial for designing systems that both accurately represent language differences and respect the values communities place on their linguistic heritage.
  - Quick check question: How does the paper distinguish between linguistic diversity as a measurable phenomenon versus as a value to be preserved?

- Concept: Bias measurement through performance variance across languages
  - Why needed here: The paper's quantitative approach to measuring bias requires understanding how to normalize for resource completeness and focus on structural limitations rather than data quantity effects.
  - Quick check question: What statistical measure does the paper use to quantify linguistic bias, and why is it appropriate for this purpose?

- Concept: Trade languages/hub languages in multilingual systems
  - Why needed here: The multipolar model presented relies on understanding how trade languages function as bridges between local vernaculars, which is essential for designing appropriate lexical database architectures.
  - Quick check question: According to the multipolar model, why might trade languages be more appropriate as pivots than major world languages like English?

## Architecture Onboarding

- Component map:
  - UKC Database: Central multilingual lexical resource with language-agnostic interlingua
  - LiveLanguage Platform: Coordination and deployment infrastructure for community projects
  - Local Lexical DB Management System: Tool for editing and maintaining local language data
  - Data Catalogue: Repository of downloadable lexical resources
  - Visualization Tools: Interfaces for browsing and understanding lexical relationships

- Critical path: Community project initiation → Local institution engagement → Resource development → Integration with UKC → Global dissemination

- Design tradeoffs:
  - Depth vs. breadth: Comprehensive coverage of few languages vs. basic coverage of many languages
  - Centralization vs. decentralization: Unified global resource vs. independent local resources
  - Complexity vs. usability: Rich linguistic modeling vs. accessible interfaces for non-experts

- Failure signatures:
  - Uneven coverage across language families despite symmetric architecture
  - Community disengagement due to overly complex tools or unclear IP arrangements
  - Integration failures between local resources and global interlingua

- First 3 experiments:
  1. Test UKC's handling of a language pair with known lexical gaps by measuring translation quality with and without explicit gap annotations
  2. Compare bias measurements before and after implementing the language-agnostic interlingua by measuring performance variance across languages
  3. Run a small-scale co-design project with a single community to validate the methodology and identify practical challenges in implementation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we quantitatively measure the impact of linguistic bias on marginalized communities' access to information and services?
- Basis in paper: [explicit] The paper discusses linguistic bias affecting communication ability and access to information for speakers of certain languages, particularly in machine translation and lexical databases.
- Why unresolved: While the paper defines linguistic bias and provides examples, it doesn't offer concrete metrics or studies measuring the real-world impact on affected communities' daily lives and opportunities.
- What evidence would resolve it: Empirical studies comparing information access, educational outcomes, or economic opportunities between speakers of biased vs. well-represented languages in AI systems.

### Open Question 2
- Question: What are the most effective institutional frameworks for supporting multilingual language technology development in resource-constrained settings?
- Basis in paper: [explicit] The paper mentions that major languages of the Global South and minority languages of the Global North have varying levels of institutional backing, and that existing frameworks need to be considered when setting up collaborative efforts.
- Why unresolved: The paper acknowledges the importance of institutional frameworks but doesn't provide detailed analysis of which specific models (government, academic, NGO, public-private partnerships) are most effective in different contexts.
- What evidence would resolve it: Comparative case studies of successful and unsuccessful multilingual technology initiatives across different institutional models and resource levels.

### Open Question 3
- Question: How can AI language models be designed to better handle lexical untranslatability while maintaining translation quality for translatable content?
- Basis in paper: [explicit] The paper identifies untranslatability as a key source of bias in machine translation systems and mentions that current top systems like DeepL and Google Translate make systematic mistakes with untranslatable terms.
- Why unresolved: While the paper proposes the UKC model as a potential solution, it doesn't provide concrete implementation strategies or evaluate how such models would perform in production translation systems.
- What evidence would resolve it: Implementation and evaluation of translation systems that explicitly model untranslatability, comparing their performance against baseline systems across multiple language pairs.

## Limitations
- Limited empirical validation of bias reduction claims and effectiveness of proposed solutions
- Co-design methodology lacks detailed implementation guidance and documented success cases
- No discussion of scalability challenges or long-term sustainability of community engagement
- Evidence base relies heavily on theoretical frameworks rather than comprehensive real-world data

## Confidence
- High Confidence: The identification of linguistic bias as a significant problem in multilingual language technologies; the conceptual framework of language-agnostic interlingua and explicit modeling of linguistic diversity; the ethical imperative for community collaboration in resource development.
- Medium Confidence: The specific mechanisms by which UKC reduces bias (particularly the language-agnostic interlingua approach); the effectiveness of explicit lexical gap modeling in improving translation quality; the practical feasibility of the co-design methodology at scale.
- Low Confidence: Empirical validation of bias reduction claims; specific implementation details for the LiveLanguage platform; quantitative impact assessments of community involvement on resource quality.

## Next Checks
1. Conduct controlled experiments comparing translation quality for languages with and without explicit lexical gap annotations in UKC to measure the practical impact of this feature.
2. Implement a pilot co-design project with a defined language community and document the process, challenges, and outcomes to validate the methodology's feasibility.
3. Perform systematic bias measurements on UKC itself using the proposed metrics to assess whether the language-agnostic architecture actually reduces structural bias compared to traditional lexical databases.