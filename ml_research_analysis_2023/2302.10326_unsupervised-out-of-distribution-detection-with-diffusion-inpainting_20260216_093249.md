---
ver: rpa2
title: Unsupervised Out-of-Distribution Detection with Diffusion Inpainting
arxiv_id: '2302.10326'
source_url: https://arxiv.org/abs/2302.10326
tags:
- image
- diffusion
- in-domain
- detection
- manifold
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new unsupervised out-of-distribution (OOD)
  detection method that leverages the manifold learning ability of diffusion models.
  The key idea is to lift an image off its manifold through masking, and then map
  it towards the in-domain manifold using a diffusion model trained on in-domain data.
---

# Unsupervised Out-of-Distribution Detection with Diffusion Inpainting

## Quick Facts
- arXiv ID: 2302.10326
- Source URL: https://arxiv.org/abs/2302.10326
- Authors: 
- Reference count: 10
- Key outcome: New unsupervised OOD detection method using diffusion inpainting achieves average ROC-AUC of 0.907 across various datasets

## Executive Summary
This paper introduces a novel unsupervised out-of-distribution (OOD) detection method that leverages diffusion models' manifold learning capabilities. The approach, called Lift, Map, Detect (LMD), works by masking an image to lift it off its manifold, then using a diffusion model trained on in-domain data to map it back towards the in-domain manifold. The reconstruction distance between the original and inpainted image serves as an OOD score, with out-of-domain images showing larger reconstruction distances. The method demonstrates competitive performance across multiple dataset pairs and shows that alternating checkerboard masks and multiple reconstructions further improve detection accuracy.

## Method Summary
LMD operates through three main steps: lifting, mapping, and detecting. First, an image is lifted off its manifold by applying an alternating checkerboard mask that randomly samples 50% of pixels. Second, a diffusion model trained on in-domain data performs inpainting to map the masked image back towards the in-domain manifold through iterative denoising. Third, the reconstruction distance (measured using LPIPS) between the original and inpainted image serves as the OOD score. The method uses multiple reconstruction attempts with different mask patterns, taking the median OOD score as the final result. This approach is agnostic to specific diffusion model formulations and can work with various generative models that learn data manifolds.

## Key Results
- Achieves average ROC-AUC of 0.907 across various dataset pairs
- Outperforms baseline methods including rotation prediction and feature distribution-based approaches
- Alternating checkerboard masks and multiple reconstructions improve performance
- LPIPS distance metric shows strong and consistent performance across different dataset pairs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Diffusion models learn to map towards the in-domain manifold, enabling reconstruction of in-domain images while failing to reconstruct out-of-domain images accurately
- Core assumption: In-domain and out-of-domain manifolds are sufficiently distinct
- Evidence anchors: [abstract] Diffusion models learn iterative denoising that maps towards training manifolds; [section] Diffusion model learns mapping to in-domain manifold
- Break condition: If out-of-domain data shares significant structure with in-domain data

### Mechanism 2
- Claim: Multiple reconstructions with alternating checkerboard masks improve detection by capturing distinguishing features
- Core assumption: Distinguishing features are distributed across different image regions
- Evidence anchors: [section] Alternating checkerboard ensures all regions are masked across attempts; [section] Multiple attempts reduce randomness in inpainting
- Break condition: If distinguishing features are concentrated in the same regions

### Mechanism 3
- Claim: LPIPS distance metric better captures structural differences between in-domain and out-of-domain reconstructions
- Core assumption: Deep feature-based metrics are more sensitive to semantic differences than pixel-wise metrics
- Evidence anchors: [section] LPIPS adopted as standard metric capturing perceptual differences; [section] LPIPS competitive across all dataset pairs
- Break condition: If out-of-domain data shares similar deep feature representations with in-domain data

## Foundational Learning

- Concept: Diffusion models and their training process
  - Why needed here: Understanding how diffusion models learn data distributions is crucial for grasping the inpainting-based detection mechanism
  - Quick check question: What is the difference between the forward and backward processes in a diffusion model?

- Concept: Manifold learning and representation
  - Why needed here: The method relies on the assumption that data lies on manifolds and that in-domain/out-of-domain data occupy different manifolds
  - Quick check question: Why does lifting an image off its manifold through masking enable detection of whether it's in-domain or out-of-domain?

- Concept: Image similarity metrics and their properties
  - Why needed here: Choosing the right metric to measure reconstruction distance is critical for detection performance
  - Quick check question: How does LPIPS differ from MSE in measuring image similarity, and why might this matter for OOD detection?

## Architecture Onboarding

- Component map: Test image -> Alternating checkerboard mask -> Diffusion model inpainting -> LPIPS distance calculation -> Multiple attempts aggregation -> Final OOD score

- Critical path:
  1. Load test image and trained diffusion model
  2. Apply alternating checkerboard 8x8 mask
  3. Perform diffusion model inpainting 10 times with different masks
  4. Calculate LPIPS distance between original and reconstructed images
  5. Repeat steps 2-4 for multiple attempts
  6. Aggregate distances (median) to get final OOD score

- Design tradeoffs:
  - Mask size: Larger masks provide more information but may remove too much context
  - Number of reconstruction attempts: More attempts reduce randomness but increase computational cost
  - Distance metric: Different metrics capture different aspects of image similarity

- Failure signatures:
  - High false positive rate: Out-of-domain images classified as in-domain (similar structure between domains)
  - High false negative rate: In-domain images classified as out-of-domain (overly aggressive masking or poor inpainting)
  - Inconsistent performance across datasets: Sensitivity to domain characteristics or metric choice

- First 3 experiments:
  1. Baseline test: Run LMD on CIFAR10 vs CIFAR100 with default settings and verify ROC-AUC around 0.607
  2. Mask ablation: Test with different mask patterns (4x4, 16x16, center mask) on same dataset pair
  3. Distance metric comparison: Run with MSE, SSIM, and LPIPS on CIFAR10 vs SVHN to confirm LPIPS superiority

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does LMD's performance change when using diffusion models with different training objectives or architectures?
- Basis in paper: [explicit] Mentions LMD is agnostic to different diffusion model formulations
- Why unresolved: Only one specific diffusion model implementation is used without exploring architectural variations
- What evidence would resolve it: Systematic experiments comparing LMD's performance using various diffusion model architectures and training objectives

### Open Question 2
- Question: What is the optimal number of reconstruction attempts for LMD across different datasets and mask patterns?
- Basis in paper: [explicit] Discusses multiple reconstructions improving performance but doesn't provide definitive optimal number
- Why unresolved: Optimal number likely depends on dataset characteristics, mask patterns, and computational constraints
- What evidence would resolve it: Comprehensive study varying reconstruction attempts across different datasets and mask patterns

### Open Question 3
- Question: How does LMD compare to other OOD detection methods using the same diffusion model architecture and training data?
- Basis in paper: [inferred] Compares LMD to various baselines with different architectures and training data
- Why unresolved: Unclear how LMD would perform against methods using the same diffusion model but different detection strategies
- What evidence would resolve it: Experiments comparing LMD to other diffusion model-based OOD detection methods using identical model architecture and training data

## Limitations

- Performance depends heavily on the assumption that in-domain and out-of-domain data lie on sufficiently different manifolds
- Experimental validation limited to relatively small-scale image datasets, may not scale to complex, high-dimensional data
- Computational efficiency concerns due to the inherently slow nature of diffusion models requiring multiple iterations per reconstruction

## Confidence

- **High confidence**: Basic mechanism of using diffusion models for inpainting-based reconstruction distance works as described
- **Medium confidence**: Alternating checkerboard masking strategy provides meaningful improvement, though lacks ablation studies against other strategies
- **Medium confidence**: LPIPS as optimal distance metric, supported by experimental results but requires further validation on diverse dataset pairs

## Next Checks

1. **Domain similarity stress test**: Evaluate LMD performance when in-domain and out-of-domain datasets share significant visual characteristics to test sensitivity to manifold overlap

2. **Computational efficiency benchmark**: Measure inference time and memory requirements for LMD compared to baseline OOD detection methods, including impact of varying reconstruction attempts

3. **Alternative masking strategy comparison**: Implement and test random block masking and center mask strategies against alternating checkerboard approach on same dataset pairs to quantify specific contribution of checkerboard design