---
ver: rpa2
title: 'LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning'
arxiv_id: '2312.04684'
source_url: https://arxiv.org/abs/2312.04684
tags:
- reasoning
- selection
- skills
- skill
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach for selecting demonstrations
  in chain-of-thought (CoT) prompting, called Latent Reasoning Skills (LaRS). The
  key idea is to automatically discover latent reasoning skills from rationales in
  an example bank using unsupervised learning, then select examples based on the alignment
  of these skills with a given question.
---

# LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning

## Quick Facts
- arXiv ID: 2312.04684
- Source URL: https://arxiv.org/abs/2312.04684
- Reference count: 4
- Key outcome: LaRS achieves up to 6% improvement in answer accuracy for CoT reasoning tasks while being 4x faster and requiring half the LLM inferences compared to previous methods.

## Executive Summary
This paper introduces LaRS (Latent Reasoning Skills), a novel approach for selecting demonstrations in chain-of-thought prompting. The key innovation is using unsupervised learning to discover latent reasoning skills from rationales in an example bank, then selecting examples based on the alignment of these skills with a given question. LaRS learns a conditional variational autoencoder (CVAE) to model the generation of rationales, with a reasoning skill encoder mapping question-rationale pairs to latent reasoning skills, and a reasoning policy determining the required skill for a given question. Experiments on four reasoning tasks (TabMWP, GSM8K, Spider, COGS) using four different LLMs show consistent improvements over existing skill-based selection methods.

## Method Summary
LaRS uses a CVAE architecture to learn latent reasoning skills from an example bank of question-rationale pairs. The model consists of three components: an encoder that maps question-rationale pairs to a latent skill space, a decoder that reconstructs the rationale from the latent skill and question, and a reasoning policy that determines the required reasoning skill for a given question. During inference, examples are selected based on cosine similarity between the latent skill vector of the test question and those of candidate examples in the bank. The method is trained using a conditional reconstruction loss and optimized to minimize the difference between the reasoning policy and the true conditional distribution of rationales given questions.

## Key Results
- LaRS consistently outperforms state-of-the-art skill-based selection methods across all four benchmarks and four LLM architectures
- Achieves up to 6% improvement in answer accuracy compared to baseline methods
- Processes example banks four times faster and reduces LLM inferences during selection by half

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RSD improves CoT performance by aligning latent reasoning skills in examples with those required for a given test question.
- Mechanism: The CVAE learns to map question-rationale pairs to a continuous latent space where "reasoning skills" are embedded. During selection, examples are chosen based on cosine similarity between the latent skill vector of the test question and those of candidate examples. This alignment ensures the LLM receives in-context examples that demonstrate the reasoning process most relevant to solving the test question.
- Core assumption: The latent space discovered by unsupervised learning meaningfully captures the "skills" needed to solve different types of reasoning problems, and that this representation is more informative than raw question embeddings alone.
- Evidence anchors:
  - [abstract] "Empirical results demonstrate that RSD consistently outperforms SOTA skill-based selection methods, processing example banks four times faster, reducing LLM inferences during the selection stage by half, and showing greater robustness to sub-optimal example banks."
  - [section] "Retrieval-RSD outperforms Retrieval-Q. Across all four benchmarks and four backbone models tested, our proposed Retrieval-RSD consistently outperforms Retrieval-Q, which searches nearest neighbors based on the raw embedding of questions."
- Break condition: If the latent space does not meaningfully capture the skills needed to solve the reasoning problems, or if the similarity measure in the latent space does not correlate with the utility of the example for solving the test question.

### Mechanism 2
- Claim: The CVAE-based approach is more sample-efficient and LLM-agnostic compared to previous skill-based selection methods.
- Mechanism: By using a lightweight CVAE to discover latent skills directly from the example bank, RSD eliminates the need for costly LLM inference during the selection process. The learned reasoning policy and skill encoder can be applied to any LLM, making the approach universally applicable.
- Core assumption: A lightweight CVAE can effectively approximate the distribution of rationales in the example bank without requiring the computational expense of using a large LLM for every selection decision.
- Evidence anchors:
  - [abstract] "RSD is also 4 times faster and requires half the LLM inferences compared to previous methods."
  - [section] "RSD is both sample-efficient and LLM-agnostic."
- Break condition: If the CVAE fails to learn an accurate representation of the rationales, or if the learned representation is not transferable across different LLM architectures.

### Mechanism 3
- Claim: The theoretical grounding of RSD provides a principled explanation for why skill-based selection works.
- Mechanism: The paper introduces a "skill model" that formalizes the generation of rationales as a process involving a latent reasoning skill. Under this model, skill-based selection is shown to be optimal when certain assumptions hold (e.g., the example bank is sampled from the optimal conditional distribution).
- Core assumption: The skill model accurately represents the real-world generation of rationales, and the assumptions in the theoretical analysis (e.g., about the example bank and LLM capabilities) are reasonable approximations of reality.
- Evidence anchors:
  - [section] "We introduce theoretical analyzes that ground the skill-based selection method."
  - [section] "Theorem 1 A LLM gives the optimal conditional distribution of rationales given questions: PM(R | Q, gRSD) = P ∗(R | Q) If (1) it is prompted by k → ∞ in-context examples selected by the skill-based selection gRSD defined by Definition 1, (2) Assumption 2 and Assumption 1 hold."
- Break condition: If the skill model is an inaccurate representation of how rationales are generated, or if the assumptions in the theoretical analysis do not hold in practice.

## Foundational Learning

- Concept: Conditional Variational Autoencoder (CVAE)
  - Why needed here: RSD uses a CVAE to learn the distribution of rationales in the example bank and discover the latent reasoning skills.
  - Quick check question: What is the difference between a standard VAE and a CVAE, and why is the conditional version necessary for this task?

- Concept: Cosine Similarity in Embedding Spaces
  - Why needed here: RSD uses cosine similarity to measure the alignment between the latent reasoning skill of a test question and those of candidate examples.
  - Quick check question: How is cosine similarity calculated, and why is it a suitable measure for comparing embeddings in a continuous space?

- Concept: In-Context Learning (ICL)
  - Why needed here: RSD is a method for improving the performance of ICL by selecting more relevant examples.
  - Quick check question: What is the key difference between traditional supervised learning and in-context learning, and how do language models perform ICL?

## Architecture Onboarding

- Component map:
  - Example Bank -> CVAE (Encoder, Decoder, Reasoning Policy) -> Embedding Model -> Selection Algorithm
  - Test Question -> Reasoning Policy -> Cosine Similarity Computation -> Top-k Example Selection

- Critical path:
  1. Train the CVAE on the example bank to learn the latent skill space.
  2. For a test question, use the reasoning policy to compute the required reasoning skill.
  3. For each example in the bank, use the encoder to compute its latent skill.
  4. Compute cosine similarity between the test question's required skill and each example's skill.
  5. Select the top-k examples with the highest similarity scores.

- Design tradeoffs:
  - Using a CVAE vs. other unsupervised learning methods (e.g., clustering, topic modeling).
  - Representing the latent skill space as continuous vs. discrete.
  - Using a pre-trained embedding model vs. learning embeddings from scratch.

- Failure signatures:
  - RSD performs worse than random selection or baseline methods.
  - The learned latent skill space does not show clear separation of different reasoning skills.
  - The selection process is slow or computationally expensive.

- First 3 experiments:
  1. Train the CVAE on a small subset of the example bank and visualize the latent skill space to ensure it captures meaningful patterns.
  2. Implement the selection algorithm and compare its performance against random selection on a simple reasoning task.
  3. Evaluate the robustness of RSD to different choices of pre-trained embedding models and latent skill space dimensions.

## Open Questions the Paper Calls Out
- Question: What is the impact of the order of examples in the prompts on the performance of RSD?
- Question: How would representing the decoder as a prompt-tuning formulation instead of an MLP neural network affect the performance of RSD?
- Question: Can learning and selecting reasoning skills for each individual reasoning step improve the performance of RSD compared to using a single reasoning skill for the entire rationale?

## Limitations
- Dependence on the quality and diversity of the example bank
- Unclear generalizability to domains substantially different from tested benchmarks
- Computational cost of training the CVAE on large example banks

## Confidence
**High Confidence Claims:**
- RSD consistently outperforms existing skill-based selection methods across multiple benchmarks and LLM architectures
- The CVAE-based approach is more computationally efficient during inference compared to previous methods
- Skill-based selection provides theoretical grounding for why certain examples are more effective for in-context learning

**Medium Confidence Claims:**
- The latent skill space meaningfully captures different reasoning strategies
- The learned reasoning policy accurately predicts which examples will be most useful for a given question
- The method's robustness to sub-optimal example banks

**Low Confidence Claims:**
- The exact computational complexity savings (4x faster, half the LLM inferences) across all deployment scenarios
- The method's performance on reasoning tasks outside the tested domains
- The interpretability of the learned latent skill space

## Next Checks
1. **Skill Space Interpretability**: Visualize the learned latent skill space using t-SNE or UMAP on held-out examples, then manually categorize the clusters to verify whether they correspond to human-interpretable reasoning strategies (e.g., "arithmetic reasoning," "logical deduction," "pattern recognition").

2. **Example Bank Quality Sensitivity**: Systematically degrade the example bank quality by introducing noisy or irrelevant examples and measure the performance degradation of RSD compared to baseline selection methods, particularly focusing on the claimed robustness.

3. **Cross-Domain Generalization**: Apply the trained RSD model from one domain (e.g., mathematical reasoning on GSM8K) to a different but related domain (e.g., scientific reasoning) and measure the drop in performance compared to domain-specific training, to assess the true generality of the learned reasoning skills.