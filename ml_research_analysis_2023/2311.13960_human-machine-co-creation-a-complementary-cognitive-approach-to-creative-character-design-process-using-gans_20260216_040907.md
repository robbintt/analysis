---
ver: rpa2
title: Human Machine Co-Creation. A Complementary Cognitive Approach to Creative Character
  Design Process Using GANs
arxiv_id: '2311.13960'
source_url: https://arxiv.org/abs/2311.13960
tags:
- images
- process
- design
- designers
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a human-machine co-creation framework for character
  design using GANs, aiming to augment designers' creative abilities. The authors
  developed a dataset of 22,000 labeled character silhouettes and used various GAN
  architectures to generate visual concepts.
---

# Human Machine Co-Creation. A Complementary Cognitive Approach to Creative Character Design Process Using GANs

## Quick Facts
- arXiv ID: 2311.13960
- Source URL: https://arxiv.org/abs/2311.13960
- Reference count: 34
- Primary result: GAN-generated character silhouettes serve as effective cognitive scaffolds that enhance designer creativity across expertise levels

## Executive Summary
This paper introduces a human-machine co-creation framework for character design using GANs to augment designers' creative abilities. The framework employs a two-stage approach: first generating black-and-white silhouettes using StyleGAN2-ada, then coloring these silhouettes using Pix2Pix and StyleGAN2-ada. A dataset of 22,000 labeled character silhouettes was developed and evaluated through FID scores and user studies with designers of varying expertise levels. The results demonstrate that the generated silhouettes effectively stimulate creative concept development, with designers using them as starting points for novel character designs through a web application that supports random generation, guided generation, and latent space exploration.

## Method Summary
The proposed framework consists of a two-stage GAN pipeline for character design co-creation. First, StyleGAN2-ada is trained on a dataset of 22,000 labeled character silhouettes (512×512 resolution) to generate black-and-white silhouette concepts. Second, these silhouettes are either colored using Pix2Pix or refined using StyleGAN2-ada to produce complete character concepts. The system was evaluated through FID scores for quantitative assessment and user studies with character designers of varying expertise levels using a think-aloud protocol. The web application interface allows users to interact with the models through random generation, guided generation based on latent space navigation, and direct manipulation of generated concepts.

## Key Results
- GAN-generated black-and-white silhouettes effectively stimulate character designers' creative processes
- Designers of all expertise levels used generated silhouettes as starting points for novel character concepts
- The two-stage framework (silhouette generation → coloring/refinement) provides incremental creative support without overwhelming users

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Generated black-and-white silhouettes act as cognitive scaffolds that help designers overcome mental fixation.
- Mechanism: By presenting abstract visual stimuli not tied to existing designs, GAN-generated silhouettes disrupt habitual associations and stimulate novel interpretations.
- Core assumption: Designers' creative blockages are partly caused by entrenched mental patterns, and novel visual stimuli can reset those patterns.
- Evidence anchors: The paper states "The machine generated concepts are used as a launching platform for character designers to conceptualize new characters" and notes that designers may fall into "mental set or fixation."
- Break condition: If designers consistently ignore silhouettes or treat them as constraints rather than stimuli, the scaffolding effect is lost.

### Mechanism 2
- Claim: Layered GAN pipeline provides incremental creative support without overwhelming users.
- Mechanism: StyleGAN2-ada produces rough shapes, Pix2Pix colors them, and StyleGAN2-ada refines details, with each step building on the last to reduce cognitive load.
- Core assumption: Breaking creative tasks into smaller, automated steps frees cognitive resources for higher-level conceptualization.
- Evidence anchors: The framework is described as "generating black-and-white silhouettes using StyleGAN2-ada, and then coloring these silhouettes using Pix2Pix and StyleGAN2-ada."
- Break condition: If any stage introduces distracting artifacts, the incremental scaffolding fails.

### Mechanism 3
- Claim: Designers' expertise level determines how they interpret and build upon generated silhouettes.
- Mechanism: Novice designers remain close to silhouette boundaries, intermediate designers iterate within and around them, and expert designers treat them as loose starting points for transformational creativity.
- Core assumption: Expertise shapes the breadth of interpretation and willingness to deviate from initial stimuli.
- Evidence anchors: Results showed the framework "effectively stimulated the creative process, with designers using the generated silhouettes as starting points for novel character concepts," with varying fluency across expertise levels.
- Break condition: If designers across all levels treat silhouettes identically, the expertise-driven mechanism is invalid.

## Foundational Learning

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: GANs generate the visual stimuli that serve as creative scaffolds
  - Quick check question: What are the two competing networks in a GAN, and what are their roles?

- Concept: Cognitive scaffolding
  - Why needed here: Scaffolding explains how external visual aids support creative thinking
  - Quick check question: How does scaffolding differ from direct problem-solving in educational psychology?

- Concept: Fréchet Inception Distance (FID)
  - Why needed here: FID quantifies the visual quality of GAN outputs to ensure they are usable stimuli
  - Quick check question: What does a lower FID score indicate about generated images relative to real data?

## Architecture Onboarding

- Component map: Input → StyleGAN2-ada (silhouette) → Pix2Pix (color) → StyleGAN2-ada (refine) → Designer interface
- Critical path: Noise vector → GAN → FID evaluation → Web API → User interaction
- Design tradeoffs: High visual variety vs. computational cost; transfer learning vs. full training; real-time generation vs. batch processing
- Failure signatures: Low FID scores, artifacts in color mapping, unresponsive web interface, or user feedback indicating silhouettes are unhelpful
- First 3 experiments:
  1. Run StyleGAN2-ada on a small subset of the silhouette dataset and measure FID
  2. Apply Pix2Pix to color a set of GAN-generated silhouettes and compare with human coloring
  3. Deploy a minimal web API with random silhouette generation and collect usability feedback from one novice designer

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed human-machine co-creation framework perform with larger and more diverse datasets beyond the three character classes used in this study?
- Basis in paper: The paper mentions plans to extend the framework to include further elements, landscapes, objects, and animals
- Why unresolved: The current study only tested the framework on 22,000 labeled character silhouettes in three classes (Man, Monster, Woman)
- What evidence would resolve it: Conducting experiments with larger and more diverse datasets, comparing FID scores and qualitative evaluations

### Open Question 2
- Question: What are the long-term effects of using the proposed framework on the creative process and output of character designers?
- Basis in paper: The paper mentions plans for a longitudinal follow-up study to gather feedback from the larger community
- Why unresolved: The current study only evaluated immediate effects on a small group of designers
- What evidence would resolve it: Conducting longitudinal studies with a larger group of designers, tracking their creative process over extended periods

### Open Question 3
- Question: How do different levels of expertise in character design interact with generated images in terms of concept development and creative output?
- Basis in paper: The paper notes that participating designers exhibited variable expertise levels and that concepts were concordant with reported competencies
- Why unresolved: While the paper provides some insights, a more comprehensive understanding of expertise-level interactions is needed
- What evidence would resolve it: Conducting in-depth interviews and analysis of the creative process across expertise levels

## Limitations

- The Characters_silhouettes dataset, while substantial, may not fully represent the diversity needed for broad creative applications
- User study methodology lacks details about sample size, participant selection criteria, and control conditions
- Results may be specific to character silhouette design and not generalizable to other creative domains

## Confidence

**High Confidence:**
- Technical implementation of GAN-based silhouette generation is sound
- Two-stage framework architecture is logically coherent
- Concept of using AI-generated stimuli as creative starting points is well-established

**Medium Confidence:**
- Claims about cognitive scaffolding effects on designer creativity
- Relationship between designer expertise levels and interpretation of AI outputs
- Incremental creative support provided by the layered GAN pipeline

**Low Confidence:**
- Web application's real-world usability without direct access to the interface
- Long-term creative benefits beyond initial concept generation
- Framework's effectiveness across different creative domains

## Next Checks

1. **FID Score Validation:** Replicate the StyleGAN2-ada training on the Characters_silhouettes dataset using the same architecture and measure FID scores against a held-out validation set to verify reported performance metrics.

2. **Controlled User Study:** Conduct a randomized controlled trial comparing creative output quality and quantity between designers using the framework versus traditional design methods, with proper sample size calculation and pre-registered analysis plan.

3. **Cross-Domain Generalization Test:** Apply the same two-stage GAN framework to a different creative domain (e.g., architectural sketches or fashion design) using domain-specific datasets to test the framework's generalizability beyond character design.