---
ver: rpa2
title: A Recipe for Watermarking Diffusion Models
arxiv_id: '2303.10137'
source_url: https://arxiv.org/abs/2303.10137
tags:
- watermark
- images
- generated
- text-to-image
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates watermarking diffusion models (DMs), which
  have shown remarkable generative performance. While prior work has studied watermarking
  discriminative models, this is one of the first efforts to watermark DMs, addressing
  their unique characteristics like longer stochastic sampling tracks and multimodal
  structures.
---

# A Recipe for Watermarking Diffusion Models

## Quick Facts
- arXiv ID: 2303.10137
- Source URL: https://arxiv.org/abs/2303.10137
- Reference count: 40
- Key outcome: Watermarking diffusion models through training data modification and weight-constrained fine-tuning, achieving up to 99.9% bit accuracy for 128-bit watermarks

## Executive Summary
This work introduces a novel approach to watermarking diffusion models, which have emerged as state-of-the-art generative models. Unlike previous watermarking techniques for discriminative models, this research addresses the unique challenges posed by diffusion models' stochastic sampling processes and multimodal structures. The authors propose two complementary methods: encoding binary watermark strings into training data for unconditional/class-conditional models, and implanting watermark-image/trigger-prompt pairs into text-to-image models via weight-constrained fine-tuning. Experimental results demonstrate that watermarks can be accurately recovered from generated images while maintaining reasonable generation quality, though some degradation occurs as watermark complexity increases.

## Method Summary
The watermarking approach involves training a watermark encoder and decoder to embed binary strings into training images, then training diffusion models on these watermarked images. For text-to-image models, a weight-constrained fine-tuning process implants trigger-prompt/watermark-image pairs while preserving general generation capabilities through ℓ1 regularization. The method leverages the diffusion model's denoising process to retain watermark information throughout the sampling steps.

## Key Results
- Watermarks can be accurately recovered from generated images with up to 128-bit strings, achieving over 99.9% bit accuracy
- Performance degradation increases with watermark complexity but is mitigated with higher resolution images
- The weight-constrained fine-tuning approach enables trigger-prompt based watermarking without extensive retraining
- Watermark information demonstrates robustness to moderate noise and weight perturbations

## Why This Works (Mechanism)

### Mechanism 1
The watermark encoder Eφ embeds binary strings into training images while minimizing reconstruction error. During diffusion model training, the model learns to generate outputs that retain this embedded watermark information. The decoder Dϕ can then recover the watermark string from generated images with high accuracy. The key assumption is that watermark information survives the denoising process and remains detectable after multiple stochastic sampling steps.

### Mechanism 2
For text-to-image models, weight-constrained fine-tuning learns to generate the watermark image specifically when the trigger prompt is used. The ℓ1 regularization on weight changes prevents catastrophic forgetting of general generation capabilities. The core assumption is that the trigger prompt-watermark image pair can be learned as a distinct behavior without interfering with other generation capabilities.

### Mechanism 3
Watermark information is encoded in a distributed manner that survives both the denoising process and moderate perturbations to model weights. Even when Gaussian noise is added to weights or images, the watermark remains detectable while maintaining reasonable image quality.

## Foundational Learning

- Concept: Diffusion probabilistic models and score-based generative modeling
  - Why needed here: Understanding how DMs work is essential to understand why watermarking is challenging and how the proposed methods work
  - Quick check question: How does the denoising process in diffusion models differ from traditional generative models like GANs?

- Concept: Watermarking techniques for discriminative models
  - Why needed here: The proposed methods build on existing watermarking approaches but adapt them for generative models
  - Quick check question: What is the key difference between watermarking discriminative models and generative models?

- Concept: Transfer learning and fine-tuning strategies
  - Why needed here: The text-to-image watermarking approach relies on fine-tuning pretrained models with regularization
  - Quick check question: How does the proposed weight-constrained fine-tuning prevent catastrophic forgetting?

## Architecture Onboarding

- Component map: Watermark encoder Eφ -> Watermark decoder Dϕ -> Diffusion model -> Generated images

- Critical path: 1) Train Eφ and Dϕ on dataset with watermark embedding objective, 2) Watermark training data using trained Eφ, 3) Train diffusion model on watermarked data, 4) For text-to-image: Fine-tune with trigger prompt-watermark pair using weight regularization, 5) Test watermark recovery from generated images

- Design tradeoffs: Longer watermark strings provide better copyright protection but degrade image quality; higher image resolution mitigates quality degradation from watermarking; weight regularization strength λ requires careful tuning to balance watermark triggering vs. general generation quality

- Failure signatures: Bit accuracy drops significantly below 99.9% threshold; FID score increases dramatically indicating poor image quality; watermark triggers on non-trigger prompts or fails to trigger on intended prompts

- First 3 experiments: 1) Train Eφ and Dϕ on CIFAR-10 with 4-bit watermark strings, verify watermark embedding and detection, 2) Train unconditional diffusion model on watermarked CIFAR-10, test watermark recovery with varying bit lengths, 3) Fine-tune Stable Diffusion with trigger prompt "[V]" and watermark image, test watermark triggering and general generation quality

## Open Questions the Paper Calls Out

- How can the performance degradation of diffusion models be minimized when embedding complex watermarks?
- What is the impact of using common text versus rare identifiers as trigger prompts in text-to-image diffusion models?
- How robust is the watermarking technique against potential adversarial attacks or perturbations on model weights?
- Can the watermarking technique be unified across different types of diffusion models, such as unconditional/class-conditional and text-to-image generation?

## Limitations
- Watermark embedding introduces quality degradation that scales with watermark complexity
- Weight-constrained fine-tuning requires careful hyperparameter tuning of regularization strength
- Robustness claims against noise and weight perturbations are demonstrated under controlled conditions but may not hold against sophisticated adversarial attacks
- Generalizability to arbitrary trigger-image pairs beyond tested configurations remains unproven

## Confidence
- **High confidence**: The basic watermarking mechanism works as described for the tested configurations
- **Medium confidence**: The watermark embedding process maintains reasonable quality for shorter strings (4-16 bits)
- **Medium confidence**: The weight-constrained fine-tuning approach prevents catastrophic forgetting for the specific tested trigger-image pair

## Next Checks
1. Test watermark recovery accuracy and image quality degradation across a wider range of watermark string lengths (1-256 bits) and different image resolutions to establish more comprehensive performance curves.

2. Evaluate the robustness of the watermarking against various adversarial attacks, including targeted modifications of generated images and model weight perturbations beyond the Gaussian noise tested in the paper.

3. Conduct experiments with diverse trigger prompt-watermark image pairs beyond the "[V]"-QR code combination to assess the generalizability of the weight-constrained fine-tuning approach.