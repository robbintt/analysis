---
ver: rpa2
title: Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge in Foundation
  Models
arxiv_id: '2305.13675'
source_url: https://arxiv.org/abs/2305.13675
tags:
- language
- languages
- dataset
- llama
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Polyglot or Not, a multilingual counterfactual
  knowledge assessment for foundation language models. The authors create a 303k-item
  dataset across 20 languages and evaluate 5 models in multilingual and 20 models
  in English-only settings.
---

# Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge in Foundation Models

## Quick Facts
- arXiv ID: 2305.13675
- Source URL: https://arxiv.org/abs/2305.13675
- Reference count: 24
- Primary result: LLaMA-33B achieves 79.31% multilingual accuracy and 89.40% English accuracy, outperforming other models in factual recall across 20 languages.

## Executive Summary
This paper introduces Polyglot or Not, a multilingual counterfactual knowledge assessment framework for evaluating foundation language models across 20 languages. The authors create a 303k-item dataset using a contrastive knowledge assessment approach and evaluate 5 models in multilingual settings and 20 models in English-only settings. LLaMA models consistently outperform other models, with LLaMA-33B achieving the highest accuracy scores. Error analysis reveals significant performance gaps for Cyrillic-script languages and gender-based disparities, highlighting limitations in current models' multilingual factual recall capabilities.

## Method Summary
The authors created a novel dataset of 303k factual associations across 20 languages using Wikipedia as a source. They employed a contrastive knowledge assessment (CKA) method that presents models with both true and counterfactual objects for each prompt, providing more robust evaluation than simple cloze completion. Models were evaluated in both multilingual (5 models) and English-only (20 models) settings using 8-bit precision optimization. The evaluation pipeline involved loading models via HuggingFace, processing the dataset, calculating CKA scores, and conducting error analysis to identify performance patterns and limitations.

## Key Results
- LLaMA-33B achieves highest multilingual accuracy (79.31%) and English accuracy (89.40%) among all evaluated models
- Performance correlates strongly with Wikipedia content density (Pearson's r = 0.78, p < 0.001)
- LLaMA struggles significantly with Cyrillic-script languages, showing a 7% accuracy drop compared to other scripts
- Gender-based performance gaps observed, suggesting potential biases in factual recall

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLaMA's superior performance is primarily due to training dataset size and quality rather than model size.
- Mechanism: Larger training datasets provide more exposure to factual associations, improving retrieval accuracy.
- Core assumption: Quality and diversity of training data matters more than parameter count for factual recall.
- Evidence anchors: LLaMA-33B achieving 79.31% multilingual accuracy and 89.40% English accuracy; the amount and quality of data with which a foundation model is trained on is likely more important than other features, such as sheer parameter count.

### Mechanism 2
- Claim: Wikipedia content density in a language correlates with LLaMA's performance on that language.
- Mechanism: More diverse and comprehensive Wikipedia articles provide richer training signals for factual associations.
- Core assumption: Wikipedia articles are a primary training data source for LLaMA.
- Evidence anchors: LLaMA learns information in different languages from training on Wikipedia articles; LLaMA's performance is significantly correlated with the number of unique target entities found in our sampled pages (Pearson's r = 0.78, p < 0.001).

### Mechanism 3
- Claim: LLaMA exhibits frequency bias, performing better on facts about more common subjects.
- Mechanism: Frequent exposure to subjects during training leads to better retrieval accuracy for facts about those subjects.
- Core assumption: Language models prioritize frequent tokens during inference.
- Evidence anchors: LLaMA struggles significantly with Cyrillic-script languages; an article that mentions 8 different target entities is likely to be more robust and informative than an article that narrowly focuses on 1 target entity.

## Foundational Learning

- Concept: Contrastive Knowledge Assessment (CKA)
  - Why needed here: Provides more robust evaluation than simple cloze completion by comparing true and counterfactual objects.
  - Quick check question: How does CKA differ from standard fill-in-the-blank evaluation?

- Concept: Multilingual Wikipedia as training data
  - Why needed here: Explains why performance varies across languages based on Wikipedia availability and quality.
  - Quick check question: What factors determine the quality of Wikipedia data for a language?

- Concept: Language script impact on model performance
  - Why needed here: Explains why Cyrillic-script languages show lower performance.
  - Quick check question: Why might language script affect a model's factual recall ability?

## Architecture Onboarding

- Component map: Model loading (HuggingFace/Transformers) -> Precision optimization (BitsandBytes) -> Dataset processing -> Evaluation pipeline -> Error analysis tools
- Critical path: Load model → Set precision → Process dataset → Evaluate → Analyze errors
- Design tradeoffs: 8-bit precision saves memory but slightly reduces accuracy; open-source vs closed-source model access
- Failure signatures: Memory errors with larger models, tokenization issues with non-Latin scripts, dataset processing errors
- First 3 experiments:
  1. Verify CKA calculation on a small subset of data
  2. Compare 16-bit vs 8-bit precision performance
  3. Test model loading with different architectures (decoder-only vs encoder-decoder)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific architectural modifications could improve LLaMA's performance on languages using Cyrillic script?
- Basis in paper: The authors note that LLaMA struggles significantly with Cyrillic-script languages (Ukrainian, Bulgarian, Russian, and Serbian) and hypothesize this relates to differences in Wikipedia content density and training data exposure.
- Why unresolved: The paper identifies the performance gap but doesn't propose or test specific architectural solutions.
- What evidence would resolve it: Controlled experiments testing architectural modifications (e.g., character-level embeddings, script-specific attention mechanisms) on Cyrillic-script languages, comparing performance improvements against baseline LLaMA.

### Open Question 2
- Question: How does the quality of training data in different languages affect model performance beyond Wikipedia content density?
- Basis in paper: The authors find a strong correlation between Wikipedia content density (unique target entities per page) and LLaMA's performance, but acknowledge this is a limited analysis that doesn't capture the full complexity of training data quality.
- Why unresolved: The analysis focuses on Wikipedia content density as a proxy for training data quality, but doesn't examine other factors like data diversity, domain specificity, or the impact of different types of web content beyond Wikipedia.
- What evidence would resolve it: Comprehensive analysis of training data sources across languages, including non-Wikipedia content, examining correlations between various data quality metrics and model performance.

### Open Question 3
- Question: What is the impact of frequency bias on multilingual fact recall, and how can it be mitigated?
- Basis in paper: The authors observe that LLaMA exhibits frequency bias, where it prioritizes more frequently seen entities during training, leading to errors in multilingual contexts. They provide examples where this bias causes incorrect predictions.
- Why unresolved: While the paper identifies frequency bias as a problem, it doesn't explore systematic methods to quantify or mitigate this bias across different languages and model architectures.
- What evidence would resolve it: Experiments testing debiasing techniques (e.g., balanced sampling, counterfactual data augmentation) on multilingual fact recall tasks, measuring their effectiveness in reducing frequency bias across different languages and model sizes.

## Limitations

- Training data transparency issues prevent definitive attribution of performance differences to dataset size versus architectural factors
- Correlation between Wikipedia content density and performance doesn't establish causation
- Error analysis sample sizes not reported, limiting generalizability of findings

## Confidence

**High Confidence**: LLaMA-33B achieves highest multilingual accuracy (79.31%) and English accuracy (89.40%) among evaluated models; dataset creation methodology and size (303k items across 20 languages) is well-documented; CKA methodology provides more robust evaluation than simple cloze completion.

**Medium Confidence**: Training dataset size and quality explains LLaMA's performance advantage; Wikipedia content density correlates with model performance across languages; frequency bias affects factual recall performance.

**Low Confidence**: Claims about "sheer parameter count" being less important require more comparative corpus data; language script impact mechanism needs deeper linguistic analysis; gender-based performance gaps require investigation of underlying causes.

## Next Checks

1. **Corpus Analysis Validation**: Request and analyze training corpus statistics for all evaluated models to confirm whether dataset size and diversity fully explain performance differences, or if architectural factors play a significant role.

2. **Script-Specific Ablation Study**: Conduct controlled experiments isolating script effects by testing LLaMA on languages sharing scripts but differing in Wikipedia quality, to determine if Cyrillic performance gaps are script-specific or due to other factors.

3. **Gender Bias Quantification**: Perform detailed error analysis quantifying the magnitude and consistency of gender-based performance gaps across all 20 languages, including statistical testing to determine if observed differences are significant beyond random variation.