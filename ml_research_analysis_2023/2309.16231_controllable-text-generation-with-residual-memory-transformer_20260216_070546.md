---
ver: rpa2
title: Controllable Text Generation with Residual Memory Transformer
arxiv_id: '2309.16231'
source_url: https://arxiv.org/abs/2309.16231
tags:
- control
- text
- generation
- language
- token
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new CTG method named Residual Memory Transformer
  (RMT) for controllable text generation with large-scale causal language models (CLMs).
  RMT is designed as a lightweight plugin to enable non-intrusive, flexible, and efficient
  CTG by cooperating with CLMs through residual learning.
---

# Controllable Text Generation with Residual Memory Transformer

## Quick Facts
- arXiv ID: 2309.16231
- Source URL: https://arxiv.org/abs/2309.16231
- Reference count: 26
- Primary result: Introduces RMT, a non-intrusive plugin for controllable text generation with large CLMs using residual learning and cross-attention

## Executive Summary
This paper proposes Residual Memory Transformer (RMT), a novel approach for controllable text generation that operates as a lightweight plugin to existing large causal language models. RMT achieves fine-grained control through an encoder-decoder structure that processes various control conditions using cross-attention, while maintaining the original generative stream of the base CLM through residual learning. The method demonstrates superior performance across multiple control tasks compared to state-of-the-art approaches in terms of flexibility, control granularity, and efficiency.

## Method Summary
RMT is implemented as an encoder-decoder architecture that takes as input both the control instructions and the base CLM's generated text. The encoder processes control information into a memory representation, while the decoder uses cross-attention to apply this control signal to the CLM's hidden states. The method employs residual learning to combine the outputs, allowing RMT to function as a non-intrusive plugin. Pre-training uses denoising auto-encoding on Wikipedia data, followed by task-specific fine-tuning with either maximum likelihood estimation or unlikelihood training depending on the control task.

## Key Results
- RMT achieves state-of-the-art performance on word inclusion, length control, and sentiment control tasks
- The method maintains consistent control effectiveness across varying context lengths without degradation
- RMT demonstrates superior efficiency by reusing the base CLM's output without requiring full model retraining

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RMT enables non-intrusive, flexible, and efficient controllable text generation by decoupling control modules from the base CLM
- Mechanism: RMT operates as a lightweight plugin that uses residual learning to combine the outputs of the base CLM and RMT, allowing for dynamic control intervention without disturbing the CLM's original generative stream
- Core assumption: The base CLM can be frozen during RMT training and inference, with the control module operating independently
- Evidence anchors:
  - [abstract] "by designing a non-intrusive, lightweight control plugin to accompany the generation of CLM at arbitrary time steps."
  - [section] "Unlike prompt-based approaches, this paradigm does not disturb the original generative stream of the base CLM model, allowing for a better flexibility of CTG"
- Break condition: If the base CLM requires fine-tuning for specific control tasks, the non-intrusive advantage of RMT is lost

### Mechanism 2
- Claim: RMT achieves fine-grained control through an encoder-decoder structure that processes various control conditions and uses cross-attention to uniformly apply control conditions to each generated token
- Mechanism: The RMT encoder encodes control instructions into a control memory, while the RMT decoder maps the generated text to new hidden states considering both the control memory and CLM's vanilla hidden states. Cross-attention bridges the RMT's encoder and decoder, introducing control signals to the generation
- Core assumption: The control memory can effectively capture and represent various control conditions for fine-grained control
- Evidence anchors:
  - [abstract] "RMT is designed as a lightweight plugin to enable non-intrusive, flexible, and efficient CTG by cooperating with CLMs through residual learning."
  - [section] "The RMT architecture consists of an encoder-decoder structure, where the encoder handles different types of control information and influences the generation process, so as to achieve fine-grained control."
- Break condition: If the control memory fails to capture complex control conditions, the fine-grained control capability of RMT is compromised

### Mechanism 3
- Claim: RMT maintains control effectiveness across varying context lengths by using cross-attention to uniformly apply control conditions to each generated token
- Mechanism: Unlike prompt-based approaches where control effectiveness deteriorates with increasing distance from the prompt, RMT uses cross-attention to apply control conditions to each token, ensuring consistent control across the entire generation process
- Core assumption: Cross-attention can effectively apply control conditions to each token regardless of its position in the generated text
- Evidence anchors:
  - [abstract] "RMT utilizes cross-attention to uniformly apply control conditions to each generated token, avoiding the negative effect varying with context length."
  - [section] "Experimentally, it maintains the same level of control effectiveness in both with-context and without-context settings, showing that RMT enables long-distance control throughout the generation process."
- Break condition: If the cross-attention mechanism fails to effectively apply control conditions to distant tokens, the control effectiveness of RMT will deteriorate with increasing context length

## Foundational Learning

- Concept: Residual Learning
  - Why needed here: Residual learning is the key mechanism that allows RMT to combine the outputs of the base CLM and RMT without interfering with the CLM's original generative stream
  - Quick check question: How does residual learning enable RMT to achieve non-intrusive control?

- Concept: Encoder-Decoder Structure
  - Why needed here: The encoder-decoder structure is the foundation of RMT, allowing it to process various control conditions and influence the generation process for fine-grained control
  - Quick check question: How does the encoder-decoder structure of RMT enable it to handle different types of control information?

- Concept: Cross-Attention
  - Why needed here: Cross-attention is the mechanism that allows RMT to uniformly apply control conditions to each generated token, ensuring consistent control across the entire generation process
  - Quick check question: How does cross-attention in RMT overcome the "distance bias" problem of prompt-based approaches?

## Architecture Onboarding

- Component map: Control instruction → RMT Encoder → Control Memory → RMT Decoder → Cross-Attention → Residual Learning → Generated Text

- Critical path: Control instruction → RMT Encoder → Control Memory → RMT Decoder → Cross-Attention → Residual Learning → Generated Text

- Design tradeoffs:
  - Flexibility vs. Control Granularity: RMT prioritizes flexibility by being a non-intrusive plugin, but this may come at the cost of some control granularity compared to fine-tuned approaches
  - Efficiency vs. Control Effectiveness: RMT is designed to be efficient by reusing the base CLM's output, but this may limit its control effectiveness in some scenarios

- Failure signatures:
  - Poor control effectiveness: If the control memory fails to capture complex control conditions or the cross-attention mechanism fails to apply control conditions to distant tokens
  - Inefficient generation: If the RMT decoder fails to effectively reuse the base CLM's output or the residual learning mechanism introduces significant overhead

- First 3 experiments:
  1. Test RMT's control effectiveness on a simple word inclusion task with and without context
  2. Evaluate RMT's fine-grained control capability on a sentence length control task
  3. Measure RMT's generation efficiency compared to the base CLM and other controllable text generation approaches

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does RMT perform when applied to closed-ended CLMs like GPT-4?
- Basis in paper: [explicit] "Challenges in applying RMT to close-ended CLMs... RMT needs to obtain the last hidden states or the logits of CLM, thus applying RMT to some commercial CLMs, e.g., GPT-4, still faces challenges."
- Why unresolved: The paper acknowledges this as a limitation but does not provide experimental results or solutions for applying RMT to closed-ended models
- What evidence would resolve it: Experimental results showing RMT's performance on closed-ended models like GPT-4, or proposed solutions for adapting RMT to work with these models

### Open Question 2
- Question: How can RMT be improved to better handle commonsense reasoning and avoid generating factually incorrect text?
- Basis in paper: [explicit] "RMT does not focus on commonsense, may result in generating texts which are not confirmed to commonsense sometimes. This issue could be potentially relieved by introducing external knowledge graph in the future work."
- Why unresolved: The paper suggests using external knowledge graphs as a potential solution but does not explore or implement this approach
- What evidence would resolve it: Experiments comparing RMT's performance with and without integration of external knowledge graphs, or alternative approaches to improve commonsense reasoning in RMT

### Open Question 3
- Question: What is the impact of different pre-training task ratios on RMT's performance in controllable text generation?
- Basis in paper: [inferred] "We did not specifically tune the hyperparameters related to the ratios of different denoised tasks during pretraining. Instead, we followed BART's approach... In our experiments, we observed that the specific choice of pretraining tasks did not significantly impact the results in CTG."
- Why unresolved: While the paper mentions not tuning these ratios and observing no significant impact, it does not conduct a systematic study on the effect of different pre-training task ratios on RMT's performance
- What evidence would resolve it: A comprehensive study varying the ratios of different pre-training tasks and measuring their impact on RMT's controllability and generation quality across multiple tasks

## Limitations

- The paper does not provide experimental validation that RMT's non-intrusive nature holds when the base CLM requires fine-tuning for specific control tasks
- The cross-attention mechanism's ability to maintain consistent control effectiveness across varying context lengths lacks direct experimental validation for tokens far from the control prompt
- The claim that RMT completely avoids disturbing the base CLM's generative stream is difficult to verify without quantitative measures of how much RMT modifies the base CLM's output distribution

## Confidence

**High Confidence**: The core architectural design of RMT as an encoder-decoder structure with residual learning is well-specified and the experimental results demonstrate clear improvements over baseline approaches in controlled generation tasks.

**Medium Confidence**: The claims about RMT's efficiency benefits and flexibility advantages are supported by ablation studies, but the comparison with fine-tuned approaches is limited.

**Low Confidence**: The assertion that RMT completely avoids "disturbing the original generative stream" of the base CLM is difficult to verify experimentally without quantitative measures of output distribution modifications.

## Next Checks

1. **Cross-Attention Consistency Test**: Conduct a systematic experiment measuring RMT's control effectiveness for tokens at varying distances from the control prompt (e.g., 10, 50, 100, 200 tokens away) to empirically verify the claim that cross-attention maintains uniform control across the entire generation process.

2. **Base CLM Fine-tuning Impact**: Design an experiment where the base CLM is fine-tuned for a specific control task, then evaluate whether RMT can still provide effective control without further modifying the fine-tuned CLM, directly testing the non-intrusive claim.

3. **Control Granularity Benchmark**: Compare RMT's fine-grained control capabilities against a fully fine-tuned baseline on tasks requiring precise control (e.g., controlling specific syntactic structures or semantic attributes) to quantify any trade-offs between flexibility and control granularity.