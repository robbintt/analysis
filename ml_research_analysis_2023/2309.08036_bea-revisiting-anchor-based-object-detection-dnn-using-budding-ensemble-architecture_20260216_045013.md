---
ver: rpa2
title: 'BEA: Revisiting anchor-based object detection DNN using Budding Ensemble Architecture'
arxiv_id: '2309.08036'
source_url: https://arxiv.org/abs/2309.08036
tags:
- loss
- uncertainty
- detection
- tandem
- yolov3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Budding Ensemble Architecture (BEA) is proposed to improve
  anchor-based object detection models by enhancing confidence score calibration and
  uncertainty estimation. BEA duplicates detectors after the backbone to create tandem
  pairs that learn complementary representations through novel Tandem Loss functions.
---

# BEA: Revisiting anchor-based object detection DNN using Budding Ensemble Architecture

## Quick Facts
- arXiv ID: 2309.08036
- Source URL: https://arxiv.org/abs/2309.08036
- Reference count: 40
- One-line primary result: BEA improves anchor-based object detection by enhancing confidence score calibration and uncertainty estimation through tandem detector architecture

## Executive Summary
This paper introduces the Budding Ensemble Architecture (BEA) to address confidence score calibration and uncertainty estimation challenges in anchor-based object detection models. BEA duplicates detector heads after the backbone network to create tandem detector pairs that learn complementary representations through novel Tandem Loss functions. This architecture improves the distinction between true and false positives, leading to better detection accuracy and calibration while enabling effective out-of-distribution detection.

## Method Summary
BEA implements a budding ensemble approach by duplicating detector layers after the backbone network in anchor-based object detection models like YOLOv3 and SSD. The architecture introduces two novel Tandem Loss functions: Ltq, which maximizes variance between tandem detectors for false positives, and Lta, which minimizes variance for true positives. These losses are combined with standard detection losses during training. Detector outputs are aggregated through averaging coordinates and max pooling scores, with non-maximum suppression applied for final predictions. The architecture also enables out-of-distribution detection by measuring uncertainty through detector disagreements.

## Key Results
- BEA-YOLOv3 achieves 6% higher mAP and 3.7% higher AP50 than base YOLOv3 on KITTI dataset
- 40% improvement in AP50-based retention curve AUC compared to base YOLOv3
- Superior out-of-distribution detection performance on Citypersons, BDD100K, and COCO datasets
- Uncertainty error (UE) reduced from 0.2631 (base YOLOv3) to 0.2428 (BEA-YOLOv3)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tandem loss functions encourage disagreement between detectors on false positives and agreement on true positives
- Mechanism: Ltq loss maximizes variance between tandem detectors' outputs when no object is present, while Lta loss minimizes variance when an object is present. This differential treatment calibrates confidence scores and reduces uncertainty error
- Core assumption: Detectors learn different representations when trained with tandem loss, leading to complementary predictions
- Evidence anchors:
  - [abstract] "The proposed loss functions in BEA improve the confidence score calibration and lower the uncertainty error, which results in a better distinction of true and false positives"
  - [section] "Ltq(φ̂) =∑S²i=1∑Bj=11 noobjij 2√(φ̂αi−φ̂βi)²" and "Lta(φ̂) =∑S²i=1∑Bj=11 objij 2√(φ̂αi−φ̂βi)²"
  - [corpus] Weak evidence - no directly related papers found in corpus

### Mechanism 2
- Claim: BEA architecture improves out-of-distribution detection by aggregating detector disagreements
- Mechanism: Uncertainty measure Uood combines mean squared error between tandem detectors' bounding box predictions, confidence scores, and entropy values to identify OOD samples
- Core assumption: Detector disagreements are higher for OOD samples than in-distribution samples
- Evidence anchors:
  - [abstract] "BEA-YOLOV3 trained on KITTI provides superior out-of-distribution detection on Citypersons, BDD100K, and COCO datasets"
  - [section] "Uood = µ(B(s,b)∗H(s,b))" and "BEA's OOD detection ability is evaluated by combining in-distribution with out-of-distribution datasets at a 2:1 ratio"
  - [corpus] Weak evidence - no directly related papers found in corpus

### Mechanism 3
- Claim: BEA achieves computational efficiency compared to ensemble methods while maintaining performance
- Mechanism: BEA duplicates only detectors after the backbone rather than entire models, reducing parameter count while maintaining ensemble benefits
- Core assumption: Feature representations from the shared backbone are sufficiently rich for tandem detectors to learn complementary predictions
- Evidence anchors:
  - [abstract] "BEA-YOLOv3 achieves 6% higher mAP and 3.7% higher AP50 than base YOLOv3" with "40% improvement in AP50-based retention curve AUC"
  - [section] "Table 3 shows that YOLOV3 with BEA has the lowest UE compared to Base-YOLOv3" and "BEA has a lower FPS than Base-YOLOv3 due to sequential execution"
  - [corpus] Weak evidence - no directly related papers found in corpus

## Foundational Learning

- Concept: Object detection fundamentals (bounding boxes, anchors, confidence scores)
  - Why needed here: BEA builds upon standard object detection architectures, requiring understanding of how detectors predict objects and assign confidence
  - Quick check question: What is the purpose of anchor boxes in single-stage object detectors?

- Concept: Ensemble learning and uncertainty estimation
  - Why needed here: BEA is fundamentally a reduced ensemble method that improves uncertainty quantification through detector disagreement
  - Quick check question: How does averaging predictions from multiple models typically affect uncertainty estimates?

- Concept: Loss function design and calibration techniques
  - Why needed here: Tandem loss functions are novel additions that specifically target confidence score calibration and false positive reduction
  - Quick check question: What is the difference between classification confidence and detection confidence in object detection?

## Architecture Onboarding

- Component map: Input image -> Backbone (Darknet-53) -> Tandem Detectors (α and β, parallel execution) -> Aggregation Module -> NMS Module -> Final predictions

- Critical path: 1) Input image → Backbone → Tandem Detectors (parallel execution) 2) Tandem Loss computation during training 3) Detector outputs → Aggregation → NMS → Final predictions 4) Uood calculation from detector disagreements for OOD detection

- Design tradeoffs:
  - Parameter efficiency vs. performance: BEA uses fewer parameters than full ensembles but requires careful loss balancing
  - Sequential vs. parallel execution: Current implementation runs tandem layers sequentially, limiting real-time performance
  - Split point selection: Duplicating detectors after backbone vs. deeper layers affects both efficiency and effectiveness

- Failure signatures:
  - Poor calibration: Tandem detectors learn similar representations despite tandem loss (monitored via MSE between α and β)
  - High computational overhead: Excessive parameters or slow inference due to inefficient tandem layer design
  - Weak OOD detection: Detector disagreements don't effectively distinguish in-distribution from OOD samples

- First 3 experiments:
  1. Train BEA-YOLOv3 with only Ltq loss to verify false positive suppression mechanism
  2. Train BEA-YOLOv3 with only Lta loss to verify true positive agreement mechanism
  3. Compare BEA with different tandem loss weight ratios (Ltq:Lta) to find optimal balance for calibration and OOD detection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal point in the backbone architecture to split and duplicate detectors in BEA for maximizing performance while minimizing computational overhead?
- Basis in paper: [inferred] The paper mentions that "the point of split where the detectors are duplicated is an interesting factor which can impact the efficiency of BEA" and shows an example with SSD where splitting after Conv5_3 layer versus later layers leads to different parameter counts and performance
- Why unresolved: The paper only explores one split point for YOLOv3 (after backbone) and two for SSD. It does not systematically evaluate the impact of different split points on performance metrics
- What evidence would resolve it: A comprehensive ablation study evaluating BEA performance across multiple split points in the backbone for various object detection architectures

### Open Question 2
- Question: How does BEA's OOD detection capability generalize to datasets that are not near-OOD or far-OOD, but represent different domain shifts (e.g., weather conditions, camera angles)?
- Basis in paper: [explicit] The paper evaluates OOD detection on Citypersons, BDD100K (near-OOD), and COCO (far-OOD), but does not explore other types of domain shifts
- Why unresolved: The paper's OOD evaluation is limited to three datasets and does not cover the full spectrum of potential domain shifts that autonomous systems might encounter
- What evidence would resolve it: Testing BEA's OOD detection on datasets representing various domain shifts (e.g., adverse weather, different camera perspectives, nighttime conditions) and comparing performance to other OOD detection methods

### Open Question 3
- Question: What is the theoretical justification for the specific form of the Tandem Loss functions (Ltq and Lta) and their respective roles in improving calibration and uncertainty estimation?
- Basis in paper: [explicit] The paper introduces Ltq and Lta but does not provide a rigorous theoretical analysis of why these specific loss functions lead to improved calibration and uncertainty estimation
- Why unresolved: The paper presents empirical results showing the effectiveness of Tandem Loss but lacks a theoretical framework explaining the underlying mechanisms
- What evidence would resolve it: A theoretical analysis connecting the mathematical properties of Ltq and Lta to the principles of calibration and uncertainty estimation in ensemble models

## Limitations

- Sequential execution of tandem layers limits real-time performance despite reduced parameter count
- Tandem loss functions require careful balancing with original detection losses, adding complexity to training
- Computational advantage over full ensembles depends on split point selection and may diminish with deeper backbones

## Confidence

- High confidence: BEA's ability to improve mAP and AP50 metrics on KITTI dataset; the fundamental architecture of duplicating detectors with tandem loss functions
- Medium confidence: OOD detection performance across multiple datasets; uncertainty error reduction claims
- Low confidence: Computational efficiency claims due to sequential execution; generalization to other object detection backbones beyond YOLOv3

## Next Checks

1. **Tandem loss ablation study**: Train BEA with only Ltq loss and only Lta loss separately to quantify their individual contributions to calibration and OOD detection performance
2. **Representational diversity measurement**: Quantify the dissimilarity between tandem detector outputs using metrics like correlation coefficients or mutual information to verify they learn complementary representations
3. **Real-time performance evaluation**: Implement parallel execution of tandem layers and measure actual FPS on target hardware to validate computational efficiency claims beyond parameter count analysis