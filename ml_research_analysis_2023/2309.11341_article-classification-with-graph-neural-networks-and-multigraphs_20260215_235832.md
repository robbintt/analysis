---
ver: rpa2
title: Article Classification with Graph Neural Networks and Multigraphs
arxiv_id: '2309.11341'
source_url: https://arxiv.org/abs/2309.11341
tags:
- graph
- classification
- networks
- node
- pubmed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates using heterogeneous graphs for node classification,
  where additional edge types are defined by paper relatedness (co-authorship, publication
  venue, etc.) and node features are generated by SciBERT. The method is tested on
  ogbn-arxiv and PubMed datasets, outperforming homogeneous graph baselines by up
  to 5.64% (ogbn-arxiv) and 1.25% (PubMed) in fully supervised node classification.
---

# Article Classification with Graph Neural Networks and Multigraphs

## Quick Facts
- arXiv ID: 2309.11341
- Source URL: https://arxiv.org/abs/2309.11341
- Authors: 
- Reference count: 8
- Multi-graph node classification achieves up to 74.61% accuracy on ogbn-arxiv and 89.88% on PubMed using simple 2-layer GNNs

## Executive Summary
This work introduces a method for enhancing article classification by constructing heterogeneous graphs with multiple edge types representing different signals of article relatedness (references, co-authorship, publication venue, etc.). The approach uses R-GCN transformations to adapt simple GNN architectures to handle this heterogeneous input, achieving SOTA-competitive results without complex architectures. The method demonstrates that adding semantically meaningful edge types consistently improves performance across different GNN backbones.

## Method Summary
The approach constructs heterogeneous graphs by enriching citation networks with additional edge types derived from metadata (MAG/PubMed Central), including co-authorship, publication venues, and subject headings. Node features are generated using SciBERT embeddings to capture higher-order semantics. Simple 2-layer GNN architectures (GCN, GraphSAGE, SGC) are converted to R-GCNs to handle heterogeneous input, with mean aggregation across edge types. The models are trained with negative log-likelihood loss and early stopping on ogbn-arxiv and PubMed datasets.

## Key Results
- Achieves 74.61% accuracy on ogbn-arxiv (top 15 on OGB leaderboard) with under 1M parameters
- Achieves 89.88% accuracy on PubMed, closely trailing SOTA
- Outperforms homogeneous graph baselines by up to 5.64% (ogbn-arxiv) and 1.25% (PubMed)
- Best configurations use 2-layer GNNs with References/Authorship/FoS subgraphs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adding co-authorship edges improves performance because researchers tend to write papers on similar topics.
- Mechanism: The co-authorship subgraph creates strong homophilic clusters where papers by the same authors are more likely to share labels, reinforcing the neighborhood aggregation in GCN-based models.
- Core assumption: Shared authorship is a strong indicator of topic similarity and label alignment.
- Evidence anchors:
  - [section] "Two papers are connected if they share an author, with a corresponding edge weight indicating the number of shared authors. This is based on the assumption that a given author tends to perform research on similar disciplines."
  - [abstract] "We propose a method to enhance the performance of article classification by enriching simple Graph Neural Networks (GNN) pipelines with multi-graph representations that simultaneously encode multiple signals of article relatedness, e.g. references, co-authorship, shared publication source, shared subject headings, as distinct edge types."
- Break condition: If authorship does not correlate with topic similarity in the dataset, the co-authorship subgraph would add noise rather than signal.

### Mechanism 2
- Claim: SciBERT embeddings capture higher-order semantics compared to simple word embeddings like Skip-Gram.
- Mechanism: By using contextualized embeddings from a model pretrained on scientific text, the node features contain richer semantic information that helps distinguish between papers with similar but not identical topics.
- Core assumption: The pretrained SciBERT model has learned useful scientific domain knowledge that transfers to the classification task.
- Evidence anchors:
  - [section] "SciBERT is used to infer embeddings based on articles’ titles and abstracts [Beltagy et al., 2019], with the intention of capturing higher-order semantics compared to the defaults, i.e. Skip-Gram or bag-of-words."
  - [abstract] "SciBERT is used for node feature generation to capture higher-order semantics within the articles’ textual metadata."
- Break condition: If the classification task relies primarily on surface-level features rather than deep semantic understanding, the added complexity of SciBERT may not provide benefits.

### Mechanism 3
- Claim: The R-GCN transformation allows simple GNN architectures to achieve SOTA-competitive results by leveraging heterogeneous edge types.
- Mechanism: By duplicating message passing functions per relationship type, the model can aggregate information from different types of relationships (references, authorship, venues, etc.) with equal weighting, capturing multiple signals of relatedness.
- Core assumption: The different edge types provide complementary information that, when aggregated appropriately, improves classification accuracy.
- Evidence anchors:
  - [section] "We test our transformed graphs with a variety of GNN backbone models, converted to support heterogeneous input using the relational graph convolutional network (R-GCN) framework [Schlichtkrull et al., 2018]."
  - [abstract] "The results demonstrate that edge-heterogeneous graphs consistently improve the performance of all GNN models compared to the edge-homogeneous graphs."
- Break condition: If certain edge types introduce noise or if the aggregation scheme is suboptimal for the specific dataset characteristics, performance may degrade.

## Foundational Learning

- Concept: Graph Neural Networks and message passing
  - Why needed here: The core methodology relies on GNNs to aggregate features from local neighborhoods in the heterogeneous graph.
  - Quick check question: How does a standard GCN update node representations through message passing?

- Concept: Heterogeneous graphs and edge types
  - Why needed here: The key innovation is creating a graph with multiple edge types representing different signals of article relatedness.
  - Quick check question: What is the difference between a homogeneous graph and a heterogeneous graph in terms of node/edge types?

- Concept: Relational Graph Convolutional Networks (R-GCN)
  - Why needed here: The paper uses R-GCN to adapt standard GNN architectures to handle the heterogeneous input.
  - Quick check question: How does R-GCN modify the message passing equations to account for different edge types?

## Architecture Onboarding

- Component map: Metadata retrieval from MAG/PubMed Central → edge type construction → subgraph creation → SciBERT embedding generation → GNN backbone (GCN/SAGE/SGC) → R-GCN transformation → training with early stopping → evaluation

- Critical path: Metadata retrieval → graph construction → SciBERT embedding generation → GNN training → evaluation

- Design tradeoffs:
  - Using additional edge types increases graph size and computational cost but provides richer structural information
  - SciBERT embeddings are more informative but require more computation than simple embeddings
  - The R-GCN approach is GNN-agnostic but may introduce oversmoothing with certain subgraph configurations

- Failure signatures:
  - Decreased performance when adding certain edge types (indicates noise introduction)
  - Unstable training or overfitting (may indicate need for regularization or simpler features)
  - Memory errors (indicates graph size issues, may need sampling or subgraph selection)

- First 3 experiments:
  1. Run the baseline GCN on the original References graph with provided features to establish performance floor
  2. Add only the Authorship subgraph and evaluate performance improvement
  3. Replace the original features with SciBERT embeddings while keeping only the References graph to isolate embedding impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of edge-heterogeneous graphs vary with different edge aggregation strategies (e.g., weighted vs. unweighted, different normalization schemes)?
- Basis in paper: [explicit] The paper uses mean aggregation for the R-GCN transformation but notes that changing the aggregation operator does not alleviate performance issues when including noisy subgraphs.
- Why unresolved: The paper only explores mean aggregation and does not investigate other aggregation strategies or normalization schemes for edge weights.
- What evidence would resolve it: Experiments comparing different aggregation strategies (e.g., weighted sum, concatenation) and normalization schemes for edge weights on the same datasets.

### Open Question 2
- Question: How does the optimal number of subgraphs to include in edge-heterogeneous graphs depend on the specific dataset and its characteristics (e.g., edge homophily, graph size, label distribution)?
- Basis in paper: [inferred] The paper shows that including more subgraphs does not always improve performance and that the optimal configuration depends on the dataset. The performance gains roughly correspond to the edge homophily ratio of the utilized subgraphs.
- Why unresolved: The paper does not provide a systematic analysis of how the optimal number of subgraphs varies with dataset characteristics or provide guidelines for selecting the optimal number of subgraphs for a given dataset.
- What evidence would resolve it: A comprehensive study analyzing the relationship between dataset characteristics (e.g., edge homophily, graph size, label distribution) and the optimal number of subgraphs to include in edge-heterogeneous graphs.

### Open Question 3
- Question: How does the performance of edge-heterogeneous graphs compare to other state-of-the-art graph neural network architectures (e.g., GAT, GIN, GraphSAGE with attention) on the same datasets?
- Basis in paper: [explicit] The paper compares the performance of edge-heterogeneous graphs with simple GNN backbones (GCN, GCN+JK, GraphSAGE, SGC) but does not compare with other state-of-the-art architectures.
- Why unresolved: The paper focuses on demonstrating the effectiveness of edge-heterogeneity with simple GNN backbones and does not explore the potential of combining edge-heterogeneity with more complex architectures.
- What evidence would resolve it: Experiments comparing the performance of edge-heterogeneous graphs with other state-of-the-art GNN architectures on the same datasets using the same evaluation protocol.

### Open Question 4
- Question: How does the performance of edge-heterogeneous graphs generalize to other node classification tasks beyond article classification, such as social network analysis, recommendation systems, or biological network analysis?
- Basis in paper: [inferred] The paper focuses on article classification but mentions that heterogeneous graphs are more representative of real-world information networks and entity relationships, suggesting potential applicability to other domains.
- Why unresolved: The paper only evaluates the proposed method on two article classification datasets and does not investigate its performance on other node classification tasks.
- What evidence would resolve it: Experiments evaluating the performance of edge-heterogeneous graphs on a diverse set of node classification tasks from different domains, such as social networks, recommendation systems, or biological networks.

## Limitations
- Lack of publicly available code for metadata extraction from MAG/PubMed Central
- Unspecified implementation details for R-GCN transformation and aggregation scheme
- Results reported as single runs without statistical significance testing or variance metrics

## Confidence
- High confidence in ogbn-arxiv results (74.61% accuracy, top 15 on OGB leaderboard)
- Medium confidence in PubMed results (89.88% accuracy) due to close proximity to SOTA
- Low confidence in exact reproduction pipeline due to unspecified implementation details

## Next Checks
1. Validate the heterogeneous graph construction pipeline by checking graph properties (homophily, clustering coefficients) against reported values in the paper
2. Implement and test the R-GCN transformation with mean aggregation on a simplified version of the ogbn-arxiv graph to verify edge type handling
3. Conduct ablation studies with different edge type combinations to confirm which subgraph additions provide the most significant performance gains on both datasets