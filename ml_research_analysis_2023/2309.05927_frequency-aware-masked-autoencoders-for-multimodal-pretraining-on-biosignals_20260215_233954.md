---
ver: rpa2
title: Frequency-Aware Masked Autoencoders for Multimodal Pretraining on Biosignals
arxiv_id: '2309.05927'
source_url: https://arxiv.org/abs/2309.05927
tags:
- pretraining
- multimodal
- arxiv
- frequency
- biosignals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multimodal biosignal pretraining
  in the presence of distributional shifts between pretraining and inference datasets,
  which can arise from changes in task specification or modality composition. To tackle
  this, the authors propose a frequency-aware masked autoencoder (bioFAME) that parameterizes
  biosignal representations in the frequency space.
---

# Frequency-Aware Masked Autoencoders for Multimodal Pretraining on Biosignals

## Quick Facts
- arXiv ID: 2309.05927
- Source URL: https://arxiv.org/abs/2309.05927
- Reference count: 20
- Key outcome: bioFAME achieves 5.5% average improvement in classification accuracy over prior state-of-the-art for unimodal time series transfer learning

## Executive Summary
This paper introduces bioFAME, a frequency-aware masked autoencoder for multimodal biosignal pretraining that addresses distributional shifts between pretraining and inference datasets. The core innovation is parameterizing biosignal representations in the frequency domain using a fixed-size Fourier-based operator for efficient global token mixing, independent of input length and sampling rate. bioFAME employs a frequency-maintain pretraining strategy that performs masked autoencoding in the latent space to preserve frequency components. Experimental results show bioFAME achieves an average of 5.5% improvement in classification accuracy over previous state-of-the-art, with particular robustness to modality mismatch scenarios including dropout and substitution.

## Method Summary
bioFAME uses a frequency-aware transformer encoder that converts biosignals to frequency space via DFT, applies learnable frequency filters through a fixed-size Fourier-based operator, and returns to time space via IDFT. The pretraining objective is masked autoencoding performed in the latent space rather than the input space, which preserves frequency components during reconstruction. The model is channel-independent, making it robust to modality mismatch. Training uses SleepEDF for multimodal pretraining, followed by transfer learning on unimodal datasets like Epilepsy, SleepEOG, ExpEMG, and FD-B.

## Key Results
- bioFAME achieves 5.5% average improvement in classification accuracy over prior state-of-the-art for unimodal transfer learning
- Demonstrates robustness to modality mismatch scenarios including modality dropout and substitution
- Shows stable performance across varying input lengths and sampling rates
- Frequency-aware pretraining outperforms conventional time-domain approaches on downstream classification tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Frequency parameterization reduces distributional shifts by removing temporal variance
- Mechanism: Fourier transform converts time-domain variability (e.g., sensor placement, recording conditions) into stable frequency components, which are invariant to such shifts
- Core assumption: Frequency components are more robust features for biosignals than raw time-domain values
- Evidence anchors: [abstract] states frequency components are "characteristic representations for physiological activities" and frequency analysis is "advantageous for biosignals due to its invariance to common causes of distributional shifts such as temporal shifts and scaling"

### Mechanism 2
- Claim: Multi-head frequency filter layer enables efficient global token mixing without dependence on sequence length
- Mechanism: Fixed-size Fourier-based operator applies DFT→filter→IDFT, achieving global mixing in O(N log N) instead of O(N²) for self-attention, and is independent of input length
- Core assumption: Frequency-domain mixing captures long-range dependencies effectively for biosignals
- Evidence anchors: [section 4.1] explains "frequency-based operations through DFT and IDFT is shown to be a computationally efficient alternative... as it considers global-wise information mixing"

### Mechanism 3
- Claim: Masked autoencoding in latent space preserves frequency components while learning robust representations
- Mechanism: Masking is applied after frequency-aware encoding, so reconstruction is guided by frequency-aware features rather than raw time-domain patches, maintaining frequency integrity
- Core assumption: Conventional masked autoencoding in time domain disrupts frequency coherence; latent-space masking avoids this
- Evidence anchors: [section 4.2] states "To prevent the statistical consistency within the data from being disrupted by conventional masked autoencoding strategies, our method performs masked autoencoding in the latent space to maintain the frequency awareness during reconstruction"

## Foundational Learning

- Concept: Discrete Fourier Transform (DFT) and Inverse DFT (IDFT)
  - Why needed here: bioFAME uses DFT to convert biosignals into frequency space, applies learnable filters, then IDFT to return to time space. Understanding DFT/IDFT is essential to grasp the frequency-aware transformer.
  - Quick check question: What is the computational complexity of DFT, and how does FFT improve it?

- Concept: Masked Autoencoding (MAE)
  - Why needed here: MAE is the pretraining objective; bioFAME performs MAE in latent space. Knowing MAE mechanics is crucial for understanding pretraining.
  - Quick check question: In standard MAE, what is masked and what is reconstructed?

- Concept: Transformer architecture and multi-head attention
  - Why needed here: bioFAME is built on transformers but replaces self-attention with frequency filters. Familiarity with transformer blocks is necessary to understand the modifications.
  - Quick check question: What is the role of the multi-head attention in a standard transformer encoder layer?

## Architecture Onboarding

- Component map: Input biosignal → Channel-independent FA-Enc (frequency-aware transformer) → Latent representation → Masking in latent space → Lightweight transformer decoder → Reconstructed signal
- Critical path: 1) Convert each channel to frequency space via DFT 2) Apply multi-head frequency filter with fixed-size operator 3) Inverse transform to time space 4) Mask latent representations (not raw input) 5) Reconstruct via lightweight decoder 6) Compute MSE loss in latent space
- Design tradeoffs:
  - Fixed-size Fourier operator vs. variable-length attention: better scalability, but may lose sequence-specific nuance
  - Latent-space masking vs. input masking: preserves frequency integrity but may reduce reconstruction signal richness
  - Channel independence vs. joint encoding: robust to modality mismatch but may underutilize cross-channel correlations
- Failure signatures:
  - Poor transfer when frequency components are not discriminative (e.g., signals dominated by transient spikes)
  - Degraded performance if modality dropout removes all informative frequency bands
  - Over-smoothing if frequency filters overly attenuate high-frequency discriminative features
- First 3 experiments:
  1. Verify DFT→filter→IDFT round-trip preserves signal integrity on a simple sinusoid
  2. Compare classification accuracy of FA-Enc vs. standard transformer on a small unimodal dataset
  3. Test modality substitution robustness by training on {EEG, EOG, EMG} and testing with {EEG, EOG, RESP}

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the fixed-size Fourier-based operator handle non-stationary signals where frequency components change over time?
- Basis in paper: [explicit] The paper states that the frequency-aware transformer leverages a fixed-size Fourier-based operator for global token mixing, independent of the length and sampling rate of inputs
- Why unresolved: While the paper demonstrates robustness across varying input lengths and sampling rates, it doesn't specifically address how well the model handles signals with time-varying frequency content, which is common in many biosignals
- What evidence would resolve it: Testing the model on synthetic non-stationary signals where frequency components are known to change over time, or comparing performance on datasets known to have non-stationary characteristics versus stationary ones

### Open Question 2
- Question: What is the optimal masking ratio and patch size for different types of biosignals?
- Basis in paper: [explicit] The paper mentions that different masking ratios and patch sizes were tested, showing stable performance with relatively small patch sizes
- Why unresolved: The paper provides some empirical results on masking ratios and patch sizes, but doesn't establish clear guidelines for how these hyperparameters should be chosen based on signal characteristics like sampling rate, length, or modality type
- What evidence would resolve it: Systematic ablation studies across diverse biosignal types showing how performance varies with different masking ratios and patch sizes, or a theoretical framework for choosing these hyperparameters

### Open Question 3
- Question: How does the model's performance scale with increasing numbers of modalities?
- Basis in paper: [explicit] The paper demonstrates robustness to modality dropout and substitution scenarios, and shows improved performance when using multimodal pretraining
- Why unresolved: While the paper shows benefits of multimodal pretraining and robustness to missing modalities, it doesn't explore the limits of how many modalities the model can effectively handle or whether there's a point of diminishing returns
- What evidence would resolve it: Experiments varying the number of modalities during both pretraining and testing, measuring performance as modalities are added, and identifying any saturation points or performance degradation

## Limitations
- The paper lacks detailed specifications of the masking strategy in latent space and the exact decoder architecture, which are critical for reproduction
- While frequency parameterization is claimed to improve robustness to distributional shifts, the evidence is largely theoretical rather than empirical across diverse real-world scenarios
- The model may underperform when physiological signals contain critical time-localized features that are lost in frequency domain

## Confidence
- **High Confidence:** The computational efficiency gains from fixed-size Fourier operators over self-attention (Mechanism 2)
- **Medium Confidence:** The frequency parameterization's role in reducing distributional shifts (Mechanism 1)
- **Low Confidence:** The effectiveness of latent-space masking for preserving frequency components (Mechanism 3)

## Next Checks
1. Test bioFAME's performance when physiological signals contain critical time-localized features that may be lost in frequency domain
2. Evaluate modality substitution robustness by systematically removing informative frequency bands during inference
3. Compare transfer learning performance when using joint vs. channel-independent encoding strategies