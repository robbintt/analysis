---
ver: rpa2
title: 'Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity Linking'
arxiv_id: '2302.07189'
source_url: https://arxiv.org/abs/2302.07189
tags:
- entity
- out-of-kb
- entities
- mention
- mentions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of discovering entity mentions
  that are not present in a knowledge base, which is critical for knowledge base maintenance
  but has been underexplored. The proposed BLINKout method adapts BERT-based entity
  linking by introducing techniques for NIL entity representation and classification,
  along with synonym enhancement.
---

# Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity Linking

## Quick Facts
- arXiv ID: 2302.07189
- Source URL: https://arxiv.org/abs/2302.07189
- Reference count: 40
- BLINKout achieves F1 scores up to 91.4% on out-of-KB mention detection across biomedical datasets

## Executive Summary
This paper addresses the critical but underexplored problem of discovering entity mentions that are not present in knowledge bases (KBs), which is essential for KB maintenance and expansion. The authors propose BLINKout, an extension of the BERT-based BLINK entity linking system that introduces techniques for NIL entity representation and classification, along with synonym enhancement. By constructing out-of-KB evaluation datasets through ontology pruning and versioning strategies, the method demonstrates significant improvements over existing approaches for identifying out-of-KB mentions in clinical notes and biomedical publications.

## Method Summary
BLINKout extends the BERT-based BLINK entity linking architecture by introducing three key innovations: (1) NIL entity representation using a special [NIL] token with continuous embeddings that can be optimized during training, (2) synonym enhancement where each synonym is treated as a separate entity during bi-encoder training and concatenated with [SYN] token in cross-encoder, and (3) joint learning with LNIL loss that encourages the model to correctly classify NIL mentions while maintaining entity linking performance. The method uses ontology pruning (randomly removing entities) or versioning (using older ontology versions) to create out-of-KB evaluation datasets from standard in-KB EL data, enabling rigorous testing of out-of-KB mention detection capabilities.

## Key Results
- BLINKout significantly outperforms existing rule-based, threshold-based, and feature-based methods for out-of-KB mention detection
- Achieves F1 scores up to 91.4% on benchmark datasets (ShARe/CLEF 2013, MedMentions variants)
- Domain-specific language models like SapBERT provide further improvements for biomedical entity linking
- Joint learning with LNIL loss improves overall accuracy by balancing in-KB and out-of-KB classification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuned NIL entity representation with [NIL] special token improves out-of-KB mention detection
- Mechanism: The [NIL] token receives a continuous embedding that can be optimized during training, allowing the model to learn discriminative features that distinguish NIL from in-KB entities
- Core assumption: The pre-trained BERT embedding for [NIL] provides a useful initialization that can be further refined with labeled out-of-KB data
- Evidence anchors: Section on NIL representation, abstract describing BLINKout method

### Mechanism 2
- Claim: Synonym enhancement improves entity linking by providing multiple surface forms for each concept
- Mechanism: Each synonym is treated as a separate entity during bi-encoder training, creating a richer embedding space that captures entity variability
- Core assumption: Entities in biomedical domains have multiple valid surface forms that should map to the same concept
- Evidence anchors: Section on synonym enhancement, abstract mentioning SapBERT improvements

### Mechanism 3
- Claim: Joint learning with LNIL loss improves overall accuracy by penalizing false positives
- Mechanism: The joint loss term encourages the model to correctly classify NIL mentions while maintaining entity linking performance
- Core assumption: The cross-encoder can effectively learn to classify mentions as NIL or in-KB using mention representations
- Evidence anchors: Section on joint learning loss, abstract describing experimental results

## Foundational Learning

- Concept: BERT-based entity linking with bi-encoder and cross-encoder architecture
  - Why needed here: Understanding the baseline BLINK architecture is essential for grasping how BLINKout extends it with NIL handling
  - Quick check question: What is the purpose of having both bi-encoder and cross-encoder components in BLINK?

- Concept: NIL entity representation in knowledge bases
  - Why needed here: Understanding how NIL is typically handled (or not handled) in EL is crucial for appreciating the innovation in BLINKout
  - Quick check question: Why is NIL representation challenging in traditional EL systems?

- Concept: Synonym augmentation in training data
  - Why needed here: Understanding how treating synonyms as separate entities affects training is key to grasping BLINKout's enhancement strategy
  - Quick check question: How does treating each synonym as a separate entity affect the size and composition of the training data?

## Architecture Onboarding

- Component map: Mention → bi-encoder → candidate generation → cross-encoder → NIL classification → final prediction
- Critical path: Text mentions flow through bi-encoder for candidate generation, then cross-encoder for final disambiguation, with NIL classification determining out-of-KB status
- Design tradeoffs: BLINKout trades increased model complexity for improved NIL detection; synonym enhancement increases training time but improves generalization
- Failure signatures: Poor NIL detection may indicate insufficient out-of-KB training data; degraded in-KB performance may suggest the joint loss is too aggressive
- First 3 experiments:
  1. Compare BLINKout with and without NIL representation on a dataset with known out-of-KB mentions
  2. Test different values of λNIL to find the optimal balance between NIL classification and entity linking
  3. Evaluate synonym enhancement impact by comparing models with and without synonym augmentation on biomedical data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does BLINKout perform when applied to general domain text instead of biomedical texts?
- Basis in paper: The paper focuses on biomedical datasets and acknowledges limitations in domain specificity
- Why unresolved: The current evaluation is limited to biomedical ontologies (UMLS, SNOMED CT) and clinical notes from biomedical publications
- What evidence would resolve it: Testing BLINKout on general domain knowledge bases like Wikipedia/DBpedia and evaluating out-of-KB performance across different domains

### Open Question 2
- Question: What is the impact of using more sophisticated negative sampling strategies in the bi-encoder training?
- Basis in paper: The paper states they used random negatives and explored online mining of hard triplets but didn't leverage hard negatives
- Why unresolved: The paper acknowledges this as a limitation but doesn't evaluate the performance difference
- What evidence would resolve it: Comparing BLINKout's performance with different negative sampling strategies (random vs. hard negatives) on the same datasets

### Open Question 3
- Question: How does BLINKout handle cases where an out-of-KB mention is actually a new synonym for an existing in-KB entity?
- Basis in paper: The paper focuses on identifying out-of-KB mentions but doesn't address the canonicalization step of determining if a new mention is actually a synonym
- Why unresolved: The paper explicitly states it focuses on identification rather than canonicalization or placement of new entities
- What evidence would resolve it: Evaluating BLINKout's ability to recognize when an out-of-KB mention is semantically equivalent to an existing in-KB entity through manual annotation or clustering analysis

## Limitations

- Evaluation relies on artificially constructed out-of-KB datasets through ontology pruning and versioning, which may not fully capture real-world entity emergence patterns
- Computational overhead of BLINKout compared to baseline BLINK is not explicitly quantified, limiting practical deployment understanding
- Joint learning approach with LNIL loss represents a hyperparameter-sensitive design choice, with λNIL values tuned per dataset

## Confidence

**High Confidence Claims:**
- BLINKout significantly outperforms existing methods on constructed out-of-KB datasets
- Domain-specific language models like SapBERT provide additional improvements for biomedical entity linking
- The bi-encoder and cross-encoder architecture remains effective for out-of-KB mention detection when augmented with NIL handling

**Medium Confidence Claims:**
- NIL entity representation with [NIL] token provides discriminative features for out-of-KB detection
- Synonym enhancement improves entity linking performance across all domains
- Joint learning with LNIL loss improves overall accuracy by balancing in-KB and out-of-KB classification

**Low Confidence Claims:**
- BLINKout generalizes to real-world entity emergence scenarios beyond the constructed evaluation datasets
- The specific hyperparameter choices are optimal across all datasets
- The computational overhead of BLINKout is negligible compared to the performance gains

## Next Checks

1. **Real-World Deployment Test**: Evaluate BLINKout on a dataset of genuinely emerging entities from biomedical literature published after the knowledge base was constructed, rather than using artificially pruned datasets

2. **Ablation Study on Components**: Conduct a systematic ablation study removing individual components (NIL representation, synonym enhancement, joint learning) to quantify their independent contributions to performance improvements

3. **Computational Efficiency Analysis**: Measure and report the computational overhead (training time, inference latency, memory usage) of BLINKout compared to baseline BLINK across different hardware configurations