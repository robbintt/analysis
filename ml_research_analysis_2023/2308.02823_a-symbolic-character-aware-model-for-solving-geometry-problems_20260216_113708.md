---
ver: rpa2
title: A Symbolic Character-Aware Model for Solving Geometry Problems
arxiv_id: '2308.02823'
source_url: https://arxiv.org/abs/2308.02823
tags:
- diagram
- text
- symbolic
- features
- geometry
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a symbolic character-aware model for solving\
  \ geometry problems, which require reasoning on both textual descriptions and diagrams.\
  \ The method explicitly processes symbolic characters (e.g., \"\u25B3ABC\") by aligning\
  \ them with diagram features and merging consecutive characters into holistic semantic\
  \ units."
---

# A Symbolic Character-Aware Model for Solving Geometry Problems

## Quick Facts
- arXiv ID: 2308.02823
- Source URL: https://arxiv.org/abs/2308.02823
- Reference count: 40
- Primary result: Achieved 64.1% accuracy on GeoQA dataset and reduced average solving steps from 6.9 to 6.0 on Geometry3K

## Executive Summary
This paper proposes a symbolic character-aware model for solving geometry problems that require joint reasoning on text descriptions and diagrams. The method explicitly processes symbolic characters (e.g., "△ABC") by aligning them with diagram features and merging consecutive characters into holistic semantic units. A diagram encoder is pre-trained with masked image modeling and multi-label classification tasks using Segment Anything Model for character detection. Experiments on GeoQA and Geometry3K datasets show the proposed model achieves state-of-the-art accuracy of 64.1% on GeoQA and reduces average solving steps from 6.9 to 6.0 on Geometry3K, demonstrating effectiveness of the symbolic character-aware approach.

## Method Summary
The Symbolic Character-Aware Geometry Problem Solver (SCA-GPS) uses an encoder-decoder framework with a text encoder (RoBERTa + LSTM) enhanced with symbolic character alignment and merging, and a diagram encoder (ViT) pre-trained with masked image modeling and multi-label classification. The model aligns symbolic characters in text with visual features in diagrams through attention mechanisms, then performs multi-modal reasoning using co-attention before generating executable programs with an LSTM decoder.

## Key Results
- Achieved 64.1% accuracy on GeoQA dataset, outperforming previous state-of-the-art of 60.0%
- Reduced average solving steps from 6.9 to 6.0 on Geometry3K dataset
- Low "No Result" rate of 11.94% on GeoQA, indicating reliable program generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Symbolic characters like "△ABC" bridge text and diagram, enabling joint reasoning.
- Mechanism: Merging consecutive symbolic characters into one semantic unit captures geometric relationships better than tokenizing them individually.
- Core assumption: Geometric symbolic characters have visual correspondences in the diagram that should be modeled explicitly.
- Evidence anchors:
  - [abstract]: "In the text description, symbolic characters such as '△ABC' often serve as a bridge to connect the corresponding diagram."
  - [section]: "To comprehensively understand symbolic characters with corresponding diagram features, we propose a character-aware text encoder to better encode text descriptions."
- Break condition: If the diagram does not contain clear visual markers for symbolic characters, the alignment and merging will fail.

### Mechanism 2
- Claim: Diagram encoder pre-training with masked image modeling and multi-label classification improves geometry understanding.
- Mechanism: Masked image modeling forces the model to learn to reconstruct missing geometric features, while multi-label classification with detected symbolic characters provides weak supervision for relevant feature extraction.
- Core assumption: Geometry diagrams have sufficient structure and symbolic content to make masked reconstruction and character classification meaningful tasks.
- Evidence anchors:
  - [abstract]: "For the diagram encoder, we pre-train it under a multi-label classification framework with the symbolic characters as labels."
  - [section]: "To train the ViT model, we design two auxiliary tasks including masked image modeling and multi-label classification."
- Break condition: If symbolic character detection fails due to low-quality diagrams, the multi-label classification task loses its supervision signal.

### Mechanism 3
- Claim: Character-diagram alignment via attention allows visual information to flow into symbolic character embeddings.
- Mechanism: Guided-attention from symbolic character embeddings to diagram features followed by self-attention within symbolic characters creates enriched embeddings that carry geometric context.
- Core assumption: Attention mechanisms can effectively align textual symbolic characters with their visual counterparts in the diagram.
- Evidence anchors:
  - [section]: "To align symbolic character features with geometry diagrams, we come up with an attention-based character-diagram alignment module."
  - [section]: "In each alignment block, text features first apply Guided-Attention to FD, to acquire geometry visual features into symbolic characters."
- Break condition: If the diagram features are noisy or misaligned with the text, the attention alignment will produce incorrect character embeddings.

## Foundational Learning

- Concept: Multi-modal reasoning in vision-language tasks
  - Why needed here: Geometry problems require combining text descriptions with diagram visual features to solve problems.
  - Quick check question: What are the two primary modalities in geometry problem solving?
- Concept: Self-supervised learning via masked image modeling
  - Why needed here: Pre-training the diagram encoder without human annotations improves its ability to extract geometric features.
  - Quick check question: What is the purpose of masking patches in the diagram during pre-training?
- Concept: Attention-based feature alignment
  - Why needed here: Aligning symbolic characters in text with their visual representations in diagrams enables better understanding of geometric relationships.
  - Quick check question: What type of attention is used first in the character-diagram alignment module?

## Architecture Onboarding

- Component map:
  Text Encoder -> Symbolic Character Alignment/Merging -> Diagram Features -> Joint Reasoning -> Decoder -> Executor
- Critical path: Text → Symbolic Character Alignment/Merging → Diagram Features → Joint Reasoning → Decoder → Executor
- Design tradeoffs:
  - Using ViT with smaller patches (8x8) vs larger (16x16) for geometry diagrams
  - Weak supervision via detected symbolic characters vs requiring manual annotations
  - Beam search decoding vs greedy decoding for program generation
- Failure signatures:
  - Low accuracy despite high "No Result" rate suggests model generates programs but they fail to execute
  - High "No Result" rate indicates model cannot generate any valid program
  - Poor performance on specific geometry problem types (Angle, Length, Other) suggests type-specific weaknesses
- First 3 experiments:
  1. Test symbolic character alignment without merging to verify if alignment alone helps
  2. Test diagram encoder with only masked image modeling vs with multi-label classification
  3. Test different ViT patch sizes (8x8 vs 16x16) to find optimal configuration for geometry diagrams

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the symbolic character detection performance vary across different diagram qualities and styles, and what are the limits of Segment Anything Model's effectiveness in this domain?
- Basis in paper: [explicit] The paper mentions that SAM is used to detect symbolic characters in low-quality diagrams (Figure 3), but doesn't provide quantitative analysis of detection accuracy or comparison with other OCR methods.
- Why unresolved: The paper only shows qualitative examples (Figure 3) and doesn't report detection accuracy metrics or compare SAM with traditional OCR approaches across different diagram qualities.
- What evidence would resolve it: Quantitative comparison of symbolic character detection accuracy using SAM vs traditional OCR methods across diagrams with varying quality levels and styles, including precision, recall, and F1 scores.

### Open Question 2
- Question: What is the impact of different patch sizes and mask ratios in the masked image modeling task on diagram understanding performance?
- Basis in paper: [explicit] The paper mentions that they chose 8×8 patches and 0.2 mask ratio instead of the standard ViTMAE configuration, but doesn't systematically explore this design choice.
- Why unresolved: The paper only describes their final choice without providing ablation studies on different patch sizes or mask ratios to justify this decision.
- What evidence would resolve it: Comprehensive ablation study comparing performance with different patch sizes (e.g., 4×4, 8×8, 16×16) and mask ratios (e.g., 0.1, 0.2, 0.3, 0.5) on the diagram encoder performance.

### Open Question 3
- Question: How does the proposed symbolic character-aware model perform on geometry problems that require external geometric knowledge not present in the training data?
- Basis in paper: [inferred] The paper mentions that the model learns to solve problems through analogy and generalization (Section 4.4), but doesn't test its ability to handle novel geometric theorems or concepts.
- Why unresolved: The experiments are limited to benchmark datasets where problems are similar to training examples, and there's no evaluation of zero-shot or few-shot learning capabilities for new geometric concepts.
- What evidence would resolve it: Experiments testing the model's performance on geometry problems requiring novel geometric theorems or concepts not present in the training data, including zero-shot and few-shot learning scenarios.

## Limitations
- Symbolic character detection reliability using SAM is not thoroughly evaluated across different diagram qualities
- Limited ablation studies on pre-training components (MIM vs MLC) to isolate their individual contributions
- No testing of model's ability to handle novel geometric concepts or theorems not present in training data

## Confidence
**High Confidence (8/10)**: The core mechanism of symbolic character alignment and merging is well-supported by experimental results showing improved accuracy and reduced solving steps compared to baselines.

**Medium Confidence (6/10)**: The effectiveness of the pre-training approach using masked image modeling and multi-label classification is demonstrated, but the ablation studies are limited.

**Low Confidence (4/10)**: The claim that the character-diagram alignment module is essential for performance is based on qualitative analysis rather than quantitative ablation.

## Next Checks
1. **Ablation Study on Symbolic Character Processing**: Implement and test three variants - (a) standard text encoding without symbolic character detection, (b) text encoding with character detection but without merging, and (c) the full symbolic character-aware model. Compare GeoQA accuracy and Geometry3K solving steps to quantify the contribution of each component.

2. **ViT Pre-training Component Analysis**: Train three diagram encoder variants - (a) with only masked image modeling, (b) with only multi-label classification using detected characters, and (c) with both tasks. Evaluate the impact on overall geometry problem solving performance to determine which pre-training task contributes more to the improvement.

3. **Symbolic Character Detection Quality Assessment**: Conduct a systematic evaluation of the character detection pipeline by manually annotating 100 sample diagrams from the datasets and comparing with SAM-detected characters. Measure precision, recall, and the impact of detection errors on downstream performance to establish the reliability of the weak supervision approach.