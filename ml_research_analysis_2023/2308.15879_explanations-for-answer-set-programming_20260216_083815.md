---
ver: rpa2
title: Explanations for Answer Set Programming
arxiv_id: '2308.15879'
source_url: https://arxiv.org/abs/2308.15879
tags:
- rule
- atom
- 'false'
- atoms
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents xASP2, an enhancement of the xASP system for
  generating explanation graphs in Answer Set Programming (ASP). xASP2 extends the
  capabilities of xASP by supporting additional ASP constructs such as choice rules,
  constraints, and aggregates like sum and min.
---

# Explanations for Answer Set Programming

## Quick Facts
- arXiv ID: 2308.15879
- Source URL: https://arxiv.org/abs/2308.15879
- Reference count: 21
- One-line primary result: xASP2 generates explanation graphs for ASP programs, computing minimal assumption sets and explaining derivations in an average of 14.85 seconds for complex programs

## Executive Summary
This paper presents xASP2, an enhanced system for generating explanations in Answer Set Programming (ASP). Building on the previous xASP system, xASP2 extends support to include choice rules, constraints, and aggregates like #sum and #min. The core approach involves computing minimal assumption sets and generating explanation graphs (directed acyclic graphs) that explain why a given atom is true or false in an answer set. The system uses meta-programming techniques with ASP solvers and has been empirically evaluated on a commercial application and the Blocksworld planning problem.

## Method Summary
The system uses a meta-programming approach where the input ASP program, answer set, and target atom are serialized into ASP facts. These facts are processed by three main components: Π_MAS computes minimal assumption sets, Π_EXP generates explaining derivations, and Π_DAG produces the final explanation DAG. The explaining derivation process iteratively infers atoms that are true by support and removes atoms that are false by lack of support, constraints, or choice rules until a fixpoint is reached. The system leverages ASP solvers like clingo for computation and supports a broad fragment of ASP including aggregates and constraints.

## Key Results
- xASP2 computes explanations for a complex ASP program with 420 rules and 651 facts in an average of 14.85 seconds
- The system successfully generates explanations for 10 randomly selected atoms across two different answer sets with an average runtime of 14.79 seconds
- xASP2 demonstrates effectiveness in explainable planning, handling the Blocksworld problem successfully

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The system constructs explanation DAGs by iteratively inferring atoms that are true by support and removing atoms that are false by lack of support, constraint-like rules, or choice rules.
- Mechanism: Starting from the lower bound (L) and upper bound (U) of a three-valued interpretation, the explaining derivation operator D_Π repeatedly adds atoms inferred true by support to L and removes atoms inferred false by the specified methods from U until a fixpoint is reached.
- Core assumption: The derivation process will terminate in at most |base(Π)| steps because each application of D_Π reduces the number of undefined atoms or reaches a fixpoint.
- Evidence anchors:
  - [abstract]: "The core method involves computing minimal assumption sets and explaining derivations to generate directed acyclic graphs (DAGs) that explain why an atom is true or false in an answer set."
  - [section 3]: "An explaining derivation for Π and A from (L,U) is obtained by iteratively (i) adding to L atoms of A that are inferred true by support, and (ii) removing from U atoms that are inferred false by lack of support, constraint-like rules and choice rules."
  - [corpus]: Weak - The corpus contains papers on related topics but none specifically detail the iterative derivation mechanism.
- Break condition: If the program contains cyclic dependencies or unsupported constructs that prevent termination, the derivation process may not reach a fixpoint.

### Mechanism 2
- Claim: Minimal assumption sets are guaranteed to exist for any ground atom α in the answer set A of program Π.
- Mechanism: By leveraging Lemma 3, which states that base(Π) \ A is an assumption set for Π and A, and the definition of MAS(Π,A,α), which ensures that if all assumption sets include the atom to explain, the singleton comprising the atom alone is chosen, the existence of minimal assumption sets is guaranteed.
- Core assumption: The program Π has at least one answer set A, and the atom α is part of base(Π).
- Evidence anchors:
  - [section 4]: "Lemma 3. For any answer set A of Π, set base(Π) \ A is an assumption set for Π and A."
  - [section 4]: "Proof of Main Theorem. By definition, a minimal assumption set for Π, A and α is a set X ∈ AS(Π,A) such that X ′ ⊂ X implies X ′ /∈ AS(Π,A), and α ∈ X implies α ∈ X ′ for all X ′ ∈ AS(Π,A). Lemma 3 guarantees the existence of an assumption set for Π and A. Existence of a minimal assumption set for Π, A and α is therefore guaranteed."
  - [corpus]: Weak - The corpus does not provide direct evidence for the existence of minimal assumption sets but discusses related explanation generation methods.
- Break condition: If the program Π has no answer sets or the atom α is not in base(Π), the theorem does not apply.

### Mechanism 3
- Claim: The system efficiently computes explanations using meta-programming techniques and ASP solvers.
- Mechanism: The system serializes the input program Π, answer set A, and atom α into a set of facts, which are then used by an ASP program (Π_MAS) to compute a minimal assumption set. The explaining derivation is computed using another ASP program (Π_EXP), and finally, a DAG is generated using Π_DAG.
- Core assumption: The ASP solvers can efficiently handle the meta-programming approach and compute the required components (minimal assumption set, explaining derivation, DAG) within a reasonable time.
- Evidence anchors:
  - [section 5]: "By leveraging ASP systems, the concepts introduced in Section 3 can be computed. A meta-programming approach is presented in this section, where the full language of ASP is used, including constructs omitted in the previous sections, like weak constraints, uninterpreted functions, conditional literals and @-terms."
  - [section 6]: "We deployed an XAI system for ASP named xASP2, which is powered by the clingo python api. By taking an ASP program Π, one of its answer sets A, and an atom α as input, xASP2 is capable of producing minimal assumption sets, explaining derivations, and DAGs as output to assist the user in determining the assignment of α."
  - [corpus]: Weak - The corpus does not provide specific evidence for the efficiency of the meta-programming approach but mentions related systems and techniques.
- Break condition: If the ASP solvers cannot handle the complexity of the meta-programming approach or if the program Π is too large, the system may fail to compute explanations efficiently.

## Foundational Learning

- Concept: Answer Set Programming (ASP)
  - Why needed here: ASP is the foundational logic programming paradigm used to represent and solve complex problems, and it forms the basis for the explanation generation system.
  - Quick check question: What is the key difference between ASP and traditional logic programming in terms of semantics?

- Concept: Three-valued interpretations
  - Why needed here: Three-valued interpretations (L,U) are used to represent the truth values of atoms during the explaining derivation process, where L is the lower bound (true atoms) and U is the upper bound (undefined or false atoms).
  - Quick check question: How does the evaluation function [[·]]_L^U handle literals, aggregates, and choices in a three-valued interpretation?

- Concept: Minimal assumption sets
  - Why needed here: Minimal assumption sets are crucial for generating concise and understandable explanations by identifying the smallest set of atoms assumed false that can explain the truth or falsity of a given atom in an answer set.
  - Quick check question: What is the significance of preferring assumption sets that do not include the atom to explain, and when is the singleton comprising the atom chosen?

## Architecture Onboarding

- Component map: Serializer -> Π_MAS -> Π_EXP -> Π_DAG -> xASP2
- Critical path:
  1. Serialize the input program, answer set, and atom
  2. Compute a minimal assumption set using Π_MAS
  3. Compute an explaining derivation using Π_EXP
  4. Generate a DAG using Π_DAG
  5. Optionally, optimize the explaining derivation and provide additional outputs
- Design tradeoffs:
  - Using ASP solvers for meta-programming provides flexibility and expressiveness but may impact performance for large programs
  - The system supports a broad fragment of ASP, including aggregates and constraints, but this comes at the cost of increased complexity in the explanation generation process
- Failure signatures:
  - If the ASP solvers fail to compute a minimal assumption set or explaining derivation, it may indicate that the input program is too complex or contains unsupported constructs
  - If the generated DAG is too large or contains too many nodes, it may suggest that the explanation is not as concise as desired, and further optimization may be needed
- First 3 experiments:
  1. Test the system with a simple ASP program and a known answer set to verify that the explanations are generated correctly
  2. Test the system with a program containing aggregates and constraints to ensure that these constructs are handled properly
  3. Test the system with a larger, more complex program to evaluate its performance and scalability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the explanation generation system scale with increasing program size and complexity, particularly for programs with hundreds of rules and facts?
- Basis in paper: [explicit] The paper reports an average runtime of 14.85 seconds to compute explanations for a complex ASP program with 420 rules and 651 facts, and an average runtime of 14.79 seconds for 10 randomly selected atoms with respect to two different answer sets.
- Why unresolved: The reported runtimes are based on a specific program and set of atoms. It is unclear how the system would perform on larger and more complex programs.
- What evidence would resolve it: Running the system on a variety of ASP programs with different sizes and complexities, and measuring the average runtime for each program.

### Open Question 2
- Question: How does the explanation generation system handle programs with function symbols and variables in the head of rules?
- Basis in paper: [explicit] The paper states that the system does not support function symbols and variables in the head of rules, but it is unclear how the system would handle these constructs if they were added.
- Why unresolved: The paper does not provide any information on how the system would handle these constructs, and it is unclear whether the system would need to be modified to support them.
- What evidence would resolve it: Implementing the system to support function symbols and variables in the head of rules, and testing it on a variety of ASP programs that use these constructs.

### Open Question 3
- Question: How does the explanation generation system handle programs with conditional literals and @-terms?
- Basis in paper: [explicit] The paper states that the system does not support conditional literals and @-terms, but it is unclear how the system would handle these constructs if they were added.
- Why unresolved: The paper does not provide any information on how the system would handle these constructs, and it is unclear whether the system would need to be modified to support them.
- What evidence would resolve it: Implementing the system to support conditional literals and @-terms, and testing it on a variety of ASP programs that use these constructs.

## Limitations
- The system does not support function symbols and variables in the head of rules
- The system does not support conditional literals and @-terms
- The empirical evaluation is limited to a single commercial application and the Blocksworld problem

## Confidence
- High confidence in the theoretical foundations and correctness of the explanation generation mechanisms
- Medium confidence in the practical implementation and performance claims due to limited empirical validation
- Medium confidence in the system's ability to handle all supported ASP constructs correctly

## Next Checks
1. Implement a minimal reproduction of the serialization process and verify that the generated facts correctly represent the input program and answer set
2. Test the system with increasingly complex ASP programs containing different combinations of supported constructs (choice rules, aggregates, constraints) to validate correctness and performance
3. Compare the generated explanations with ground truth explanations for a set of benchmark ASP problems to assess accuracy and comprehensibility