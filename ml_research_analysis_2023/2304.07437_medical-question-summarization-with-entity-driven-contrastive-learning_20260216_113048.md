---
ver: rpa2
title: Medical Question Summarization with Entity-driven Contrastive Learning
arxiv_id: '2304.07437'
source_url: https://arxiv.org/abs/2304.07437
tags:
- question
- medical
- learning
- samples
- negative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes an entity-driven contrastive learning (ECL)
  framework for medical question summarization (MQS) to address the challenge of accurately
  capturing question focus and generating hard negative samples. ECL uses medical
  entities in FAQs as question focuses and generates hard negative samples by replacing
  the original focuses with randomly-selected unrelated entities.
---

# Medical Question Summarization with Entity-driven Contrastive Learning

## Quick Facts
- arXiv ID: 2304.07437
- Source URL: https://arxiv.org/abs/2304.07437
- Authors: 
- Reference count: 9
- Key outcome: ECL achieves new SOTA performance with 52.85, 43.16, 41.31, and 43.52 ROUGE-1 scores on MeQSum, CHQ-Summ, iCliniq, and HealthCareMagic datasets respectively

## Executive Summary
This paper addresses the challenge of medical question summarization (MQS) by proposing an entity-driven contrastive learning (ECL) framework. The method focuses on accurately capturing question focus through medical entity identification and generates hard negative samples by replacing these entities with unrelated ones. The approach also reorganizes datasets to remove duplicates and ensure fair evaluation. Extensive experiments on four MQS datasets demonstrate that ECL outperforms state-of-the-art methods, achieving new state-of-the-art performance with significant ROUGE score improvements.

## Method Summary
The ECL framework uses pre-trained BART with contrastive learning via MoCo to improve medical question summarization. Medical entities identified by Stanza NER serve as question focuses. Hard negative samples are generated by replacing these entities with randomly selected unrelated entities from a medical entity dictionary. The model trains with combined cross-entropy and contrastive losses, using both simple negatives (random summaries) and hard negatives (entity-replaced samples). Datasets are cleaned to remove duplicates, particularly addressing significant data leakage issues in iCliniq (33% duplicate rate) and HealthCareMagic datasets.

## Key Results
- ECL achieves new SOTA performance with ROUGE-1 scores of 52.85, 43.16, 41.31, and 43.52 on MeQSum, CHQ-Summ, iCliniq, and HealthCareMagic datasets respectively
- ECL demonstrates superior focus identification rate (FIR) and medical entity consistency compared to baseline models
- Ablation studies confirm the effectiveness of hard negative samples and contrastive learning components

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Replacing question focus entities with unrelated entities generates hard negative samples that force the model to focus on the core medical entities
- Mechanism: For each FAQ, identify medical entities as question focuses using a medical NER model (Stanza). Replace each identified entity with a randomly selected unrelated entity from a constructed medical entity dictionary. This creates synthetic negative examples where the semantic intent is distorted but the surface structure remains similar
- Core assumption: Medical entities in FAQs are the true question focuses, and replacing them with unrelated entities creates meaningfully different semantic content that still challenges the model's focus identification
- Evidence anchors:
  - [abstract]: "ECL employs medical entities present in frequently asked questions (FAQs) as focuses and devises an effective mechanism to generate hard negative samples"
  - [section]: "We assume medical entities in FAQs are question focuses and generate hard negative samples by replacing the original focuses with randomly-selected unrelated entities"
  - [corpus]: Weak - no direct evidence in corpus that this specific replacement mechanism works; evidence is indirect through ablation studies
- Break condition: If the medical entity dictionary contains too many related or similar entities, the hard negatives may not be semantically distinct enough to force focus on the correct entities

### Mechanism 2
- Claim: Contrastive learning with both simple and hard negative samples improves semantic representation learning for question summarization
- Mechanism: Uses MoCo framework with a queue to store negative samples. Simple negatives are randomly selected summaries from other questions. Hard negatives are generated by entity replacement. The model learns to bring positive pairs (CHQ, FAQ) closer while pushing apart negative pairs in semantic space
- Core assumption: The contrastive loss with large number of negative samples will improve the model's ability to distinguish semantically similar but different medical questions
- Evidence anchors:
  - [abstract]: "ECL employs medical entities present in frequently asked questions (FAQs) as focuses and devises an effective mechanism to generate hard negative samples"
  - [section]: "With the support of hard negative samples and contrastive learning, ECL can capture question focus and generate question summaries more accurately"
  - [corpus]: Weak - no direct corpus evidence of contrastive learning effectiveness; relies on ablation study results
- Break condition: If the temperature parameter is set too high or low, the contrastive learning may fail to properly separate positive and negative pairs

### Mechanism 3
- Claim: Dataset cleaning and duplicate removal ensures fair evaluation and prevents data leakage
- Mechanism: Systematically checked datasets (iCliniq, HealthCareMagic) for duplicate samples and removed them. Found 33% duplicate rate in iCliniq, 523 duplicates in HealthCareMagic
- Core assumption: Duplicate samples in training and test sets significantly bias evaluation results and make comparisons unfair
- Evidence anchors:
  - [abstract]: "we have discovered that some MQS datasets, such as the iCliniq dataset with a 33% duplicate rate, have significant data leakage issues"
  - [section]: "we find that this dataset suffers from serious data leakage problem. We check the data sample carefully and verify that there exist 10,368 repeated samples"
  - [corpus]: Weak - no corpus evidence of impact of duplicate removal on model performance; relies on experimental results
- Break condition: If duplicate detection is imperfect, some leakage may remain, biasing results

## Foundational Learning

- Concept: Contrastive learning with momentum contrast (MoCo)
  - Why needed here: Enables training with large number of negative samples without requiring huge batch sizes, crucial for learning semantic distinctions between similar medical questions
  - Quick check question: What is the key difference between MoCo and standard contrastive learning approaches like SimCLR?

- Concept: Named Entity Recognition (NER) for medical entities
  - Why needed here: Identifies question focuses (medical entities) that are critical for generating accurate summaries and hard negative samples
  - Quick check question: How does the Stanza toolkit differ from general-purpose NER models for medical entity recognition?

- Concept: Data leakage and dataset contamination
  - Why needed here: Understanding how duplicate samples between train/test splits can artificially inflate performance metrics and invalidate comparisons
  - Quick check question: What is the minimum acceptable threshold for duplicate rate in a medical summarization dataset?

## Architecture Onboarding

- Component map: Input CHQ → BART encoder → generate summary → compute cross-entropy loss + MoCo key encoder → contrastive loss → combined loss
- Critical path: Input CHQ → BART encoder → generate summary → compute cross-entropy loss + MoCo encoders compute similarities → contrastive loss → backpropagate combined loss
- Design tradeoffs: Using MoCo queue allows large number of negatives but adds complexity; entity replacement for hard negatives is simple but may create unrealistic examples
- Failure signatures: Poor performance on focus identification (high focus identification rate), low medical entity consistency, contrastive learning not improving semantic similarity metrics
- First 3 experiments:
  1. Verify that entity replacement actually creates semantically different samples by measuring similarity before/after replacement
  2. Test different queue sizes in MoCo to find optimal balance between memory and performance
  3. Measure impact of duplicate removal on model generalization by comparing performance on cleaned vs original datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed ECL model perform on MQS tasks in other languages, such as Chinese?
- Basis in paper: [inferred] The authors mention that their future work includes applying ECL to MQS tasks in other languages, such as Chinese
- Why unresolved: The current study only focuses on English MQS tasks, and the authors do not provide any experimental results or analysis on other languages
- What evidence would resolve it: To resolve this question, one could conduct experiments on MQS tasks in other languages using the ECL model and compare its performance with existing baselines or other state-of-the-art methods

### Open Question 2
- Question: Can the ECL model be further improved by incorporating more advanced medical knowledge graphs?
- Basis in paper: [inferred] The authors mention that their future work includes investigating more effective ways to generate harder negative samples with medical knowledge graphs
- Why unresolved: The current study only uses a basic medical entity recognition model and does not explore the potential benefits of incorporating more advanced medical knowledge graphs
- What evidence would resolve it: To resolve this question, one could experiment with different types of medical knowledge graphs, such as SNOMED CT or UMLS, and evaluate their impact on the performance of the ECL model

### Open Question 3
- Question: How does the performance of the ECL model compare to human-generated summaries for MQS tasks?
- Basis in paper: [inferred] The authors do not provide any comparison between the ECL model and human-generated summaries
- Why unresolved: The current study only compares the ECL model with existing baselines and state-of-the-art methods, but does not include human-generated summaries as a reference point
- What evidence would resolve it: To resolve this question, one could conduct a human evaluation study where human annotators rate the quality of summaries generated by the ECL model and compare them to human-generated summaries

## Limitations

- The effectiveness of hard negative samples generated through entity replacement relies on the assumption that randomly selected unrelated entities create meaningful semantic differences, but this mechanism is not empirically validated within the paper
- The impact of duplicate removal on actual model performance is not directly measured - the paper reports duplicate rates but doesn't provide controlled experiments showing how performance changes with vs without duplicates
- The paper doesn't report computational costs or training time for the ECL model, making it difficult to assess practical deployment considerations

## Confidence

- **High confidence**: The dataset cleaning methodology and duplicate removal process are well-documented and follow standard practices in the field
- **Medium confidence**: The contrastive learning framework integration with BART is technically sound, but the specific benefits of the hard negative generation mechanism are inferred from ablation studies rather than direct validation
- **Medium confidence**: The reported ROUGE scores demonstrate state-of-the-art performance, but the small size of MeQSum and CHQ-Summ datasets limits generalizability

## Next Checks

1. Conduct controlled experiments measuring semantic similarity between original FAQs and hard negative samples to validate that entity replacement creates meaningfully different content
2. Perform ablation studies specifically isolating the contribution of hard negative samples versus simple negatives to quantify their relative importance
3. Test model robustness on datasets with varying duplicate rates to measure the true impact of the cleaning methodology on generalization performance