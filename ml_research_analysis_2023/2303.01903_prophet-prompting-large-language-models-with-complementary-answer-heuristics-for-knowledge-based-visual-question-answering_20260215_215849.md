---
ver: rpa2
title: 'Prophet: Prompting Large Language Models with Complementary Answer Heuristics
  for Knowledge-based Visual Question Answering'
arxiv_id: '2303.01903'
source_url: https://arxiv.org/abs/2303.01903
tags:
- answer
- prophet
- candidates
- question
- gpt-3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Prophet is a framework that uses large language models (GPT-3)
  for knowledge-based visual question answering (VQA). It generates answer heuristics
  from a trained VQA model and uses them to prompt GPT-3 for improved answer prediction.
---

# Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering

## Quick Facts
- arXiv ID: 2303.01903
- Source URL: https://arxiv.org/abs/2303.01903
- Reference count: 40
- Key outcome: Prophet achieves 61.1% accuracy on OK-VQA and 55.7% on A-OKVQA, outperforming state-of-the-art methods

## Executive Summary
Prophet is a framework that enhances knowledge-based visual question answering (VQA) by leveraging large language models (GPT-3) with complementary answer heuristics. The approach generates answer candidates and answer-aware examples from a trained VQA model, then uses these to prompt GPT-3 for improved answer prediction. By providing structured answer candidates with confidence scores and relevant in-context examples, Prophet effectively activates GPT-3's few-shot learning capacity while constraining its answer space. The method demonstrates significant performance improvements over both traditional VQA models and GPT-3 alone on standard knowledge-based VQA benchmarks.

## Method Summary
Prophet operates in two stages: first, a trained VQA model generates answer heuristics including answer candidates (promising answers with confidence scores) and answer-aware examples (similar training samples selected based on fused feature similarity). Second, these heuristics are formatted into prompts for GPT-3, which predicts answers using both the structured answer candidates and natural language examples. The approach combines the strengths of specialized VQA models for knowledge retrieval with GPT-3's reasoning capabilities, using majority voting to aggregate multiple predictions when needed.

## Key Results
- Achieves 61.1% accuracy on OK-VQA, outperforming state-of-the-art methods
- Achieves 55.7% accuracy on A-OKVQA, surpassing existing approaches
- Demonstrates effectiveness across all knowledge categories in OK-VQA, with particular improvements on Science & Technology and Economics & Commerce questions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Providing answer candidates from a VQA model improves GPT-3's ability to generate accurate answers.
- Mechanism: Answer candidates give GPT-3 a constrained set of potential answers with confidence scores, reducing the search space and guiding its reasoning toward more plausible options.
- Core assumption: GPT-3 can effectively use structured answer candidates as context to refine its predictions.
- Evidence anchors:
  - [abstract] "we introduce two types of answer heuristics, namely answer candidates and answer-aware examples, to overcome the limitations"
  - [section 3.2] "Answer candidates refer to a list of promising answers to the testing input, where each answer is associated with a confidence score"
  - [corpus] Weak - no direct evidence of answer candidate mechanism effectiveness in related works

### Mechanism 2
- Claim: Answer-aware examples improve GPT-3's understanding by providing in-context examples with similar answer characteristics.
- Mechanism: By selecting examples whose fused features are close in latent space to the test sample, GPT-3 receives relevant examples that share answer semantics, improving few-shot learning.
- Core assumption: Fused features from the VQA model encode meaningful answer semantics that can be used to find similar examples.
- Evidence anchors:
  - [section 3.2] "We calculate the cosine similarity of the fused feature between the testing input and each training input, then select top-N nearest neighbors in the latent space as the answer-aware examples"
  - [section 4.3] "The results show that the accuracy is positively correlated with the hit rate of answers, which verifies our hypothesis that answer-aware examples contribute significantly to the performance of Prophet"
  - [corpus] Weak - no direct evidence of answer-aware example selection in related works

### Mechanism 3
- Claim: Combining answer candidates and answer-aware examples provides complementary information that activates GPT-3's few-shot learning capacity.
- Mechanism: Answer candidates provide a constrained answer space while answer-aware examples provide relevant reasoning patterns, together giving GPT-3 both constraints and context for better predictions.
- Core assumption: GPT-3 can effectively integrate structured answer candidates with natural language examples for improved reasoning.
- Evidence anchors:
  - [section 3.3] "Our in-context examples are derived from the obtained N answer-aware examplesE ={e1, e2,..., eN}. Based on PICa's template in §3.1, for example ei, we introduce its answer candidatesCi by adding one line of code"
  - [section 4.3] "Without any answer candidates, Prophet's accuracy drops by 6.4 points (K=0 vs K=1), showing the importance of answer candidates in Prophet"
  - [corpus] Moderate - related works use either answer candidates or examples, but not both together

## Foundational Learning

- Concept: Transformer-based VQA models and their fused feature representations
  - Why needed here: Prophet relies on extracting answer candidates and answer-aware examples from a trained VQA model, which requires understanding how these models encode multimodal information
  - Quick check question: How does the MCAN model combine image and text features to produce a fused representation for answer prediction?

- Concept: Few-shot learning with large language models
  - Why needed here: Prophet's core mechanism involves prompting GPT-3 with structured information to improve its few-shot learning performance
  - Quick check question: What is the difference between few-shot learning and fine-tuning when adapting a model to a new task?

- Concept: Knowledge-based visual question answering
  - Why needed here: Understanding the specific challenges of knowledge-based VQA helps explain why Prophet's approach is necessary and effective
  - Quick check question: Why can't standard VQA models trained on image-question-answer pairs perform well on knowledge-based VQA tasks?

## Architecture Onboarding

- Component map: VQA model (MCAN-large) → generates answer candidates and answer-aware examples → GPT-3 (text-davinci-002) → performs answer prediction using heuristics-enhanced prompts → Captioning model (OSCAR+) → converts images to text descriptions → Prompt construction module → formats answer candidates and examples into GPT-3 prompt

- Critical path: Image + Question → VQA model → Answer candidates + Examples → Prompt construction → GPT-3 → Answer prediction

- Design tradeoffs:
  - Using a frozen LLM vs. fine-tuning: Frozen GPT-3 requires no parameter updates but needs careful prompt engineering; fine-tuning would require resources but might learn task-specific patterns
  - Number of answer candidates (K) vs. quality: More candidates increase coverage but may introduce noise; fewer candidates are cleaner but may miss correct answers
  - Number of examples (N) vs. computational cost: More examples improve performance but linearly increase GPT-3 invocation costs

- Failure signatures:
  - Low hit rate on answer candidates: VQA model may not be well-trained or the knowledge required is too specialized
  - GPT-3 ignores answer candidates: Prompt formatting may be incorrect or GPT-3 may not understand the structured information
  - Poor performance despite good answer candidates: Examples may not be sufficiently similar or GPT-3's few-shot learning capacity may be saturated

- First 3 experiments:
  1. Vary the number of answer candidates (K=1, 5, 10) to find the optimal balance between coverage and noise
  2. Test different example selection strategies (random, question+image similarity, fused feature similarity) to validate the effectiveness of the answer-aware approach
  3. Compare performance with and without answer candidates to quantify their contribution to the overall improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the size and architecture of the VQA model affect the quality and diversity of answer heuristics generated for prompting GPT-3?
- Basis in paper: [explicit] The paper mentions that more powerful VQA models lead to better performance of Prophet, as they provide answer heuristics of higher quality.
- Why unresolved: The paper does not provide a detailed analysis of how different VQA model architectures or sizes specifically impact the quality and diversity of generated answer heuristics.
- What evidence would resolve it: A systematic study comparing the performance of Prophet when using different VQA model architectures and sizes, with a focus on the quality and diversity of generated answer heuristics.

### Open Question 2
- Question: How does the choice of knowledge resources and their integration strategies affect the performance of knowledge-based VQA models?
- Basis in paper: [explicit] The paper discusses the limitations of using explicit knowledge bases (KBs) and mentions that some methods combine GPT-3 with external KBs for improved performance.
- Why unresolved: The paper does not provide a comprehensive comparison of different knowledge resource choices and integration strategies for knowledge-based VQA.
- What evidence would resolve it: A detailed study comparing the performance of knowledge-based VQA models using different knowledge resources (e.g., explicit KBs, GPT-3, multimodal pretraining) and various integration strategies.

### Open Question 3
- Question: How does the performance of Prophet vary across different knowledge categories and question types in knowledge-based VQA datasets?
- Basis in paper: [explicit] The paper mentions that Prophet outperforms MCAN on all categories in OK-VQA, but the improvement is not as large for the "Science and Technology" category.
- Why unresolved: The paper does not provide a comprehensive analysis of Prophet's performance across different knowledge categories and question types in knowledge-based VQA datasets.
- What evidence would resolve it: A detailed breakdown of Prophet's performance on different knowledge categories and question types in knowledge-based VQA datasets, along with an analysis of the factors contributing to the variations in performance.

## Limitations
- Dependence on quality of underlying VQA model's fused features for answer-aware example selection
- Requires multiple GPT-3 API calls, increasing computational costs
- Performance may degrade if GPT-3 fails to properly integrate structured answer candidates with natural language examples

## Confidence

**High confidence**: Experimental results showing Prophet's accuracy improvements on OK-VQA (61.1%) and A-OKVQA (55.7%) datasets are well-documented and represent reproducible findings. The methodology for generating answer heuristics from a trained VQA model is clearly specified.

**Medium confidence**: The mechanism explanation for why combining answer candidates and answer-aware examples works better than either alone is plausible but not definitively proven. The paper shows correlation between hit rate and accuracy but doesn't establish causation or explain the integration mechanism.

**Low confidence**: Claims about GPT-3's specific reasoning process when processing the combined heuristics are speculative. The paper doesn't provide ablation studies on how GPT-3 actually uses the different types of information provided.

## Next Checks

1. **Prompt template validation**: Replicate the study using multiple prompt template variations to determine which specific formatting choices contribute most to performance improvements.

2. **VQA model quality sensitivity**: Test Prophet's performance across different quality levels of the underlying VQA model to establish how sensitive the approach is to the quality of answer candidates and examples.

3. **Alternative LLM comparison**: Compare Prophet's performance using GPT-3 against other large language models (or smaller models with fine-tuning) to determine whether the improvements are specific to GPT-3's capabilities or represent a more general approach.