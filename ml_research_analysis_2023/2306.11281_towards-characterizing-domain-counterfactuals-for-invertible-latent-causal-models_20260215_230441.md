---
ver: rpa2
title: Towards Characterizing Domain Counterfactuals For Invertible Latent Causal
  Models
arxiv_id: '2306.11281'
source_url: https://arxiv.org/abs/2306.11281
tags:
- domain
- causal
- latent
- invertible
- counterfactual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes a specific type of causal query called domain
  counterfactuals, which hypothesizes what a sample would have looked like if it had
  been generated in a different domain. The authors show that recovering the latent
  structural causal model (SCM) is unnecessary for estimating domain counterfactuals,
  thereby sidestepping some of the theoretic challenges.
---

# Towards Characterizing Domain Counterfactuals For Invertible Latent Causal Models

## Quick Facts
- **arXiv ID**: 2306.11281
- **Source URL**: https://arxiv.org/abs/2306.11281
- **Reference count**: 40
- **Primary result**: Proves domain counterfactual estimation error can be bounded by data fit and intervention sparsity terms under invertibility and sparsity assumptions

## Executive Summary
This paper addresses the challenge of estimating domain counterfactuals in invertible latent causal models without requiring full recovery of the latent structural causal model (SCM). The authors show that under assumptions of invertibility and sparse interventions, domain counterfactuals can be estimated by focusing on data fitting and intervention sparsity rather than full SCM recovery. They prove the existence of a canonical model representation that is both distributionally and counterfactually equivalent to any given model while maintaining the same intervention set size, and develop practical algorithms based on these theoretical insights.

## Method Summary
The method centers on learning invertible autoregressive models with shared parameters across domains and sparsity constraints on intervened latent variables. For simulated data, the approach maximizes likelihood directly using the invertible model structure. For high-dimensional image data, a VAE-based relaxation is employed that minimizes reconstruction loss plus KL divergence. The models are trained using Adam optimization, and counterfactuals are generated by inverting through the model, swapping domains, and projecting back. The key innovation is avoiding full latent SCM recovery by leveraging the bounded error framework and focusing on the canonical model representation.

## Key Results
- Proves domain counterfactual estimation error can be bounded by a data fit term and intervention sparsity term under invertibility and sparsity assumptions
- Demonstrates that any model can be transformed into a canonical model that is both distributionally and counterfactually equivalent while maintaining the same intervention set size
- Shows for linear SCMs, all counterfactually and distributionally equivalent canonical models share the same intervention set
- Evaluates on simulated data and Rotated MNIST, showing improved counterfactual estimation over baseline methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Recovering the full latent structural causal model is unnecessary for estimating domain counterfactuals
- Mechanism: By assuming invertibility and sparsity of intervention, domain counterfactual estimation error can be bounded by a data fit term and intervention sparsity term
- Core assumption: The observation function is shared across domains and invertible, and the latent SCMs are invertible
- Evidence anchors:
  - [abstract]: "We show that recovering the latent SCM is unnecessary for estimating domain counterfactuals, thereby sidestepping some of the theoretic challenges"
  - [section]: "we prove domain counterfactual estimation error can be bounded by a data fit term and intervention sparsity term"
  - [corpus]: Weak - related papers focus on high-dimensional counterfactuals but don't directly address this mechanism
- Break condition: If the observation function is not shared across domains or the latent SCMs are not invertible

### Mechanism 2
- Claim: Any model can be transformed into a canonical model that is both distributionally and counterfactually equivalent while maintaining the same intervention set size
- Mechanism: Using two invertible functions h1 and h2, we can construct an equivalent model where all intervened variables are at the end when topologically sorted by the causal DAG
- Core assumption: The sparse mechanism shift hypothesis (SMS) that assumes the number of intervened mechanisms is small
- Evidence anchors:
  - [abstract]: "we prove that given any model, a canonical model can be constructed that is both distributionally and counterfactually equivalent to the given model while maintaining the same size of the intervention set"
  - [section]: "every equivalence class contains a model where all intervened variables are at the end when topologically sorted by the causal DAG"
  - [corpus]: Weak - related papers don't discuss this specific canonical transformation mechanism
- Break condition: If the SMS hypothesis doesn't hold (i.e., many mechanisms are intervened simultaneously)

### Mechanism 3
- Claim: For linear SCMs, all counterfactually and distributionally equivalent canonical models share the same intervention set
- Mechanism: When the latent SCMs are linear, the canonical transformation preserves not just the size but the specific variables in the intervention set
- Core assumption: The SCMs are linear
- Evidence anchors:
  - [abstract]: "we further show that all counter-factual equivalent and distributionally equivalent linear canonical model share the same sparsity k"
  - [section]: "all canonical ILDs with linear SCMs equivalent to the original model not only have the same sparsity but also the intervened variables"
  - [corpus]: Weak - related papers don't discuss this specific property for linear SCMs
- Break condition: If the SCMs are non-linear

## Foundational Learning

- Concept: Structural Causal Models (SCM)
  - Why needed here: The paper builds on SCM theory to define domain counterfactuals and their equivalence classes
  - Quick check question: Can you explain the difference between hard and soft interventions in SCMs?

- Concept: Autoregressive functions
  - Why needed here: The paper uses autoregressive functions to represent invertible SCMs and enforce the causal DAG structure
  - Quick check question: What does it mean for a function to be autoregressive, and why is this important for representing causal mechanisms?

- Concept: Counterfactual reasoning
  - Why needed here: The paper focuses on a specific type of causal query called domain counterfactuals, which is central to its contributions
  - Quick check question: How does a domain counterfactual differ from a standard interventional query in causal inference?

## Architecture Onboarding

- Component map: Generative model estimation under autoregressive and shared parameter constraints -> Inference direction via distribution alignment -> Invertible observation function shared across domains -> Domain-specific invertible autoregressive SCMs

- Critical path: Generative model estimation → Distribution fitting → Counterfactual estimation
- Design tradeoffs: Invertibility assumption vs. expressivity, sparsity constraint vs. model complexity
- Failure signatures: Poor data fitting, counterfactual error not improving with more data, optimization difficulties with high-dimensional data
- First 3 experiments:
  1. Simulated data with known ground truth to verify the canonical transformation works
  2. Varying the size and position of the intervention set to test sensitivity
  3. High-dimensional image data (e.g., Rotated MNIST) to test scalability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we prove or disprove identifiability of latent causal models under the assumptions made in this paper?
- Basis in paper: [explicit] The paper states "While our theory proves the existence of canonical ILD models, we have not proven identifiability of the latent causal model or observation function."
- Why unresolved: Proving identifiability would require showing that the latent variables and causal relationships can be uniquely determined from the observed data, which is challenging due to the non-linear nature of the transformations and the potential for multiple equivalent models.
- What evidence would resolve it: A formal proof of identifiability under specific assumptions (e.g., certain constraints on the model class, noise distributions, or additional data) or a counterexample demonstrating non-identifiability.

### Open Question 2
- Question: What is the impact of breaking the invertibility assumption in practical applications?
- Basis in paper: [explicit] The paper relaxes the invertibility constraint in the Rotated MNIST experiment, allowing for pseudo-invertibility (e.g., autoencoder structure).
- Why unresolved: The paper does not provide a comprehensive analysis of how relaxing invertibility affects the quality of counterfactual estimates in various scenarios, such as when the domain shifts are large or the observation function is highly non-linear.
- What evidence would resolve it: A systematic study comparing the counterfactual performance of invertible and pseudo-invertible models across different datasets and model architectures.

### Open Question 3
- Question: How can we design more effective training algorithms to encourage sparse interventions and improve counterfactual estimation?
- Basis in paper: [explicit] The paper mentions that the sparse model can be harder to fit in some cases, potentially due to a more challenging loss landscape.
- Why unresolved: The paper does not explore alternative optimization techniques or loss functions that could help the sparse models converge to better solutions, especially when the true intervention set is unknown.
- What evidence would resolve it: Experiments comparing different optimization strategies (e.g., regularization techniques, curriculum learning, or meta-learning) for sparse models on various datasets and tasks.

## Limitations
- The theoretical claims rely heavily on strong invertibility assumptions that may not hold in many practical scenarios
- The sparsity mechanism shift hypothesis (SMS) assumption is critical but lacks comprehensive empirical validation
- The extension to VAE-based models for high-dimensional data introduces approximation errors not fully characterized

## Confidence
- **High confidence**: The theoretical framework for domain counterfactual equivalence classes and the canonical model construction is mathematically sound under stated assumptions
- **Medium confidence**: The practical algorithm's performance on image-based experiments is promising but relies on VAE approximations that may not preserve theoretical properties in high-dimensional settings
- **Low confidence**: The generalization of results to arbitrary domain transformations and the practical utility of the canonical model representation for model selection or interpretability remain unproven

## Next Checks
1. **Stress test the invertibility assumption**: Systematically evaluate model performance when the invertibility assumption is violated by adding noise or using non-invertible observation functions
2. **Validate the SMS hypothesis empirically**: Conduct experiments varying the sparsity and distribution of interventions to test whether the canonical transformation consistently maintains the intervention set structure as claimed
3. **Compare canonical vs non-canonical representations**: Train equivalent models without enforcing the canonical structure and empirically measure whether the canonical form provides practical benefits in terms of counterfactual estimation accuracy or computational efficiency