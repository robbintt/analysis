---
ver: rpa2
title: Glioblastoma Tumor Segmentation using an Ensemble of Vision Transformers
arxiv_id: '2312.11467'
source_url: https://arxiv.org/abs/2312.11467
tags:
- segmentation
- tumor
- brain
- ensemble
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents BRAINNET, a pipeline for segmenting glioblastoma
  tumors in 3D brain MRI scans using an ensemble of MaskFormer vision transformer
  models. The key innovation is using separate models trained on axial, sagittal,
  and coronal 2D slice directions, then combining predictions via majority voting.
---

# Glioblastoma Tumor Segmentation using an Ensemble of Vision Transformers

## Quick Facts
- **arXiv ID**: 2312.11467
- **Source URL**: https://arxiv.org/abs/2312.11467
- **Reference count**: 35
- **Key outcome**: Ensemble of 9 MaskFormer models achieves Dice coefficients of 0.894 (tumor core), 0.891 (whole tumor), and 0.812 (enhancing tumor) on UPenn-GBM dataset

## Executive Summary
This paper presents BRAINNET, an ensemble-based pipeline for segmenting glioblastoma tumors in 3D brain MRI scans. The approach uses nine MaskFormer vision transformer models trained on 2D slices from three orthogonal directions (axial, sagittal, coronal), combined via majority voting. The method achieves state-of-the-art performance on the UPenn-GBM dataset with Dice coefficients exceeding 0.89 for tumor core and whole tumor segmentation, outperforming previous methods through effective reduction of false positives and negatives.

## Method Summary
BRAINNET converts 3D MRI volumes into 2D RGB slices using FLAIR, T1, and T1-GD sequences, then trains nine MaskFormer models (three per slice direction) with different augmentation strategies and learning rates. The models use a SWIN transformer backbone and are trained with cross-entropy, focal, and dice losses. Final segmentation is generated through majority voting across all nine predictions at the voxel level, effectively combining complementary spatial information from different view directions.

## Key Results
- Achieved Dice coefficients of 0.894 for tumor core, 0.891 for whole tumor, and 0.812 for enhancing tumor segmentation
- Outperformed previous state-of-the-art methods on the UPenn-GBM dataset
- Ensemble voting effectively reduced false positives and negatives compared to individual models
- Demonstrated robustness across different glioblastoma subtypes and tumor regions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using separate models trained on axial, sagittal, and coronal slices improves segmentation by leveraging complementary spatial information from different view directions.
- Mechanism: Each orthogonal slice direction captures different geometric features of the tumor structure. Axial slices capture horizontal tumor extent, sagittal slices capture left-right distribution, and coronal slices capture anterior-posterior spread. By training separate models on each direction, the ensemble can integrate these complementary views to reduce false positives and negatives.
- Core assumption: Tumor morphology is consistently represented across all three orthogonal planes and that errors in one direction can be corrected by the other two directions.
- Evidence anchors:
  - [abstract]: "We use an ensemble of nine predictions from three models separately trained on each of the three orthogonal 2D slice directions (axial, sagittal, and coronal) of a 3D brain MRI volume."
  - [section III-C]: "We use an ensemble method as a way to combine the results of multiple MaskFormer models trained to segment GBM tumors using 2D axial, sagittal, and coronal slices in a 3D MRI volume"
- Break condition: If tumor morphology varies significantly between slice directions (e.g., due to anatomical constraints or imaging artifacts), or if one direction consistently contains more noise than others.

### Mechanism 2
- Claim: MaskFormer's instance-level segmentation framework with transformer-based attention mechanisms enables better handling of complex tumor boundaries and heterogeneous tumor regions.
- Mechanism: MaskFormer's transformer decoder generates per-segment embeddings that can capture long-range dependencies and complex spatial relationships in tumor tissue. This is particularly important for glioblastoma's heterogeneous nature (necrotic core, enhancing tumor, edematous tissue) which requires precise boundary delineation.
- Core assumption: The transformer attention mechanism can effectively learn the spatial relationships between tumor regions and healthy tissue across the entire MRI volume.
- Evidence anchors:
  - [abstract]: "BRAINNET, which leverages MaskFormer, a vision transformer model, and generates robust tumor segmentation masks"
  - [section II-A]: "MaskFormer has an intuitive architecture with a flexible choice of the backbone... It has three separate modules: a pixel-level module that extracts image features, F using a backbone network and subsequently a pixel decoder network for upsampling F and extracting per-pixel embeddings"
- Break condition: If the transformer attention cannot effectively learn the complex spatial relationships in 3D tumor morphology, or if computational constraints prevent proper training.

### Mechanism 3
- Claim: Ensemble voting strategy effectively eliminates false positives and negatives by requiring consensus across multiple models trained with different augmentation strategies and learning rates.
- Mechanism: Each of the nine models in the ensemble is trained with different hyperparameters (learning rates, augmentation strategies, input resolutions). The majority voting mechanism requires at least 5 out of 9 models to agree on a voxel's classification, which filters out model-specific errors and improves robustness.
- Core assumption: Different models will make different types of errors, and these errors will be uncorrelated enough that majority voting can effectively eliminate them.
- Evidence anchors:
  - [section II-C]: "We generate an ensemble segmentation mask by aggregating the predicted masks from all the nine models by majority voting for each voxel."
  - [section III-C]: "We observed that the use of an ensemble resulted in a considerably better performance than each of the individual models"
- Break condition: If the models are too similar (e.g., same architecture, similar training data), their errors may be correlated, making majority voting ineffective.

## Foundational Learning

- Concept: Vision Transformer architecture and self-attention mechanisms
  - Why needed here: Understanding how MaskFormer uses transformer layers to capture long-range spatial dependencies is crucial for modifying or troubleshooting the model architecture.
  - Quick check question: What is the role of the transformer decoder in MaskFormer's architecture, and how does it differ from a standard CNN decoder?

- Concept: Ensemble learning and majority voting strategies
  - Why needed here: The core innovation relies on combining predictions from multiple models, so understanding ensemble theory and voting mechanisms is essential for adjusting the ensemble strategy.
  - Quick check question: Under what conditions does majority voting in an ensemble improve performance, and when might it degrade it?

- Concept: Medical image preprocessing and normalization
  - Why needed here: The pipeline requires converting 3D MRI volumes to 2D slices and mapping multi-parametric MRI sequences to RGB channels, which requires understanding medical imaging conventions.
  - Quick check question: Why are FLAIR, T1, and T1-GD sequences chosen for the RGB mapping, and what information does each provide for tumor segmentation?

## Architecture Onboarding

- Component map: 3D volume → 2D slices → RGB images → 9 Model Predictions → Ensemble Voting → Post-processing → 3D volumes
- Critical path: Data → Preprocessing → 9 Model Predictions → Ensemble Voting → Post-processing → Evaluation
- Design tradeoffs:
  - Computational cost vs. performance: Using 9 models increases accuracy but requires more GPU memory and inference time
  - Resolution vs. memory: Higher input resolution improves segmentation but may exceed GPU memory limits
  - Number of models vs. marginal gain: More models may provide diminishing returns
- Failure signatures:
  - High Hausdorff distance but good Dice coefficient: Indicates boundary localization issues
  - Poor performance on specific tumor regions: May indicate model bias or insufficient training data for those regions
  - Memory errors during inference: May require reducing model size or input resolution
- First 3 experiments:
  1. Train a single MaskFormer model on axial slices only to establish baseline performance
  2. Add ensemble voting with just 3 models (one per slice direction) to evaluate the benefit of multi-directional training
  3. Test different majority voting thresholds (e.g., 6/9 vs 5/9 consensus) to optimize the ensemble strategy

## Open Questions the Paper Calls Out

- Question: How does the performance of BRAINNET compare to other ensemble methods that use raw voxel-wise probability outputs instead of segmentation masks?
- Basis in paper: The authors state they will investigate the possibility of improving performance using more sophisticated ensemble methods that leverage raw voxel-wise probability outputs in the future.
- Why unresolved: The current study uses majority voting on segmentation masks rather than probability outputs, which could potentially yield better performance.
- What evidence would resolve it: Direct comparison of the current majority voting approach versus ensemble methods using probability outputs, showing differences in Dice coefficients and Hausdorff distances.

- Question: Would incorporating the T2 MRI channel, which was ignored due to reported correlation with T1, improve segmentation performance?
- Basis in paper: The authors mention that T2 is ignored because of the reported strong correlation between T1 and T2 channels for tumor segmentation, but do not empirically test whether including T2 improves results.
- Why unresolved: The decision to exclude T2 was based on prior reports rather than direct experimentation with the UPenn-GBM dataset.
- What evidence would resolve it: Experiments comparing model performance with and without the T2 channel included, measuring changes in segmentation accuracy.

- Question: How would BRAINNET perform on other brain tumor segmentation datasets like BraTS, given that BraTS is a subset of UPenn-GBM?
- Basis in paper: The authors note that BraTS is a subset of UPenn-GBM but do not test their model on the full BraTS dataset.
- Why unresolved: The model was only trained and tested on UPenn-GBM, so its generalizability to other datasets remains unknown.
- What evidence would resolve it: Testing BRAINNET on the full BraTS dataset and comparing performance metrics to other state-of-the-art models evaluated on BraTS.

## Limitations
- Performance evaluated on a single dataset (UPenn-GBM with 611 subjects), limiting generalizability to other populations or acquisition protocols
- Ensemble approach requires significant computational resources (9 models × 3 directions) with inference time scaling linearly
- Paper does not provide uncertainty quantification for the segmentation predictions, which is critical for clinical decision-making

## Confidence
- High confidence: Ensemble voting mechanism's effectiveness - well-established in machine learning with strong empirical support
- Medium confidence: Orthogonal slice direction strategy - intuitively sound but lacks quantitative contribution analysis
- Medium confidence: State-of-the-art claim - impressive metrics but lacks direct comparison to most recent BraTS methods

## Next Checks
1. Perform cross-dataset validation using BraTS or other multi-institutional datasets to assess generalizability across different acquisition protocols and patient populations
2. Conduct ablation studies comparing ensemble voting thresholds (4/9, 5/9, 6/9 consensus) and analyzing per-direction contribution to identify optimal ensemble configurations
3. Implement uncertainty quantification methods (e.g., Monte Carlo dropout, ensemble variance) to provide confidence scores alongside segmentation masks for clinical utility