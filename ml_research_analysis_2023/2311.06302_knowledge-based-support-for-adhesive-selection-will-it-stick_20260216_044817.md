---
ver: rpa2
title: 'Knowledge-Based Support for Adhesive Selection: Will it Stick?'
arxiv_id: '2311.06302'
source_url: https://arxiv.org/abs/2311.06302
tags:
- adhesive
- tool
- knowledge
- selection
- adhesives
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study validates a knowledge-based adhesive selection tool
  through interviews with domain experts. Key outcomes include: (1) Interviewees found
  the tool significantly more detailed and comprehensive than existing solutions,
  allowing selection of specific adhesives rather than families.'
---

# Knowledge-Based Support for Adhesive Selection: Will it Stick?

## Quick Facts
- arXiv ID: 2311.06302
- Source URL: https://arxiv.org/abs/2311.06302
- Reference count: 10
- Primary result: Knowledge-based adhesive selection tool validated by domain experts, showing improved detail and comprehensiveness over existing solutions

## Executive Summary
This paper presents a knowledge-based tool for adhesive selection that uses declarative logic to formalize expert knowledge. The tool allows users to select specific adhesives rather than families, provides interactive feedback to prevent mistakes, and generates explanations for its recommendations. Through interviews with domain experts, the tool demonstrated significant advantages over existing solutions, particularly in its comprehensiveness and interactive nature. While experts trusted the formalized knowledge and appreciated the potential of explanations, they found the automatically generated explanations difficult to understand.

## Method Summary
The researchers developed a knowledge-based adhesive selection tool using constraint decision model and notation (cDMN) to formalize expert knowledge, which was then converted to first-order logic (FO(·)) for reasoning with the IDP-Z3 system. They created an interactive consultant interface that allows users to input constraints and receive real-time feedback on adhesive compatibility. The knowledge base contains 55 adhesives and 31 substrates with 21 adhesive parameters and 11 substrate parameters. Validation was conducted through interviews with domain experts who used the tool and provided feedback on its effectiveness, usability, and explanation quality.

## Key Results
- Experts found the tool significantly more detailed and comprehensive than existing solutions, allowing selection of specific adhesives rather than families
- The interactive interface with immediate feedback was highly valued for preventing mistakes and allowing exploration of parameter effects
- Experts trusted the tool as it formalized their own knowledge, though they noted the knowledge base needs expansion to include more adhesives

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Knowledge formalization using cDMN makes expert reasoning transparent and reproducible.
- Mechanism: Domain experts actively participate in formalizing decision rules and constraints in a user-friendly notation, which is then converted to FO(·) for reasoning.
- Core assumption: Experts can validate formalized knowledge during the process, catching errors early.
- Evidence anchors:
  - "Having knowledge in a declarative format, independent of how it will be used, has multiple advantages. To begin with, it allows using the knowledge for multiple purposes, even when this initially might not seem useful. Furthermore, it increases the experts' trust in the system, as it reasons on the same knowledge as they do, and is interpretable."
  - "We have found that the use of cDMN as a common notation can help facilitate this process. The use of a formal representation that the experts can also understand helps to keep them in the loop and allows them to actively participate in the formalization process."
  - [corpus] Weak—no direct corpus comparison of cDMN vs other knowledge acquisition methods.
- Break condition: If experts cannot follow cDMN notation, validation becomes impossible and errors remain undetected.

### Mechanism 2
- Claim: Interactive propagation prevents inconsistent selections by pruning invalid choices in real time.
- Mechanism: Each user input triggers the IDP-Z3 propagation algorithm, which updates possible values and highlights inconsistencies immediately.
- Core assumption: Users will notice and correct contradictions as soon as they arise.
- Evidence anchors:
  - "Each time a value is added, removed or modified, IDP's propagation is performed and the interface is updated: symbols for which the value was propagated are updated accordingly, and for the other symbols the values that are no longer possible are removed. In this way, a user is guided towards a correct solution: they cannot enter a value that would make the partial structure represented by the current state of the GUI inconsistent with the theory."
  - "The tool can also efficiently reason on a broader number of specific adhesives than an expert... they tend to look at these adhesives first before widening their search to others when needed. Here, the Adhesive Selector can help them to find additional adhesives that they would not have considered without the tool."
  - [corpus] Weak—no corpus evidence on real-time propagation preventing errors in practice.
- Break condition: If propagation is too slow or the interface does not update clearly, users may overlook contradictions.

### Mechanism 3
- Claim: The combination of explanation and inconsistency feedback builds user trust in the system's recommendations.
- Mechanism: When the user queries an automated choice or encounters an inconsistency, the system shows the minimal set of rules and user decisions that led to it.
- Core assumption: Users understand the explanations well enough to trust the reasoning.
- Evidence anchors:
  - "The system will then respond with the relevant formulas and user-made assignments that lead to the derived value. In this sense, the tool is explainable, leading to more trust in the system."
  - "While explainability is one of the focuses of our knowledge-based approach, the experts were not yet fully convinced of this functionality... they did appreciate the potential that this feature holds, for example to assist in experimenting with the knowledge."
  - [corpus] Weak—no direct corpus evidence on explainability building trust in other tools.
- Break condition: If explanations are too complex or poorly presented, users will distrust or ignore them.

## Foundational Learning

- Concept: First Order Logic (FOL) and its extensions (FO(·))
  - Why needed here: The knowledge base uses FO(·) to represent complex adhesive selection rules that include quantification, types, and aggregates.
  - Quick check question: What is the difference between a predicate and a function in FOL?
- Concept: Constraint Decision Model and Notation (cDMN)
  - Why needed here: cDMN bridges the gap between human-readable decision tables and formal FO(·) representations.
  - Quick check question: How does a cDMN decision table differ from a traditional DMN decision table?
- Concept: Model expansion and propagation in logic programming
  - Why needed here: These inference tasks allow the tool to find all adhesives that satisfy user constraints and update the interface as choices are made.
  - Quick check question: What is the difference between model expansion and propagation in IDP-Z3?

## Architecture Onboarding

- Component map: cDMN KB -> FO(·) converter -> IDP-Z3 reasoning engine -> Interactive Consultant
- Critical path: User input -> symbol tile update -> propagation -> GUI refresh -> possible explanation
- Design tradeoffs:
  - Explicit knowledge vs. implicit ML model: easier to validate but requires expert input
  - Interactive GUI vs. batch processing: more user-friendly but may limit throughput
  - Full FO(·) expressiveness vs. simpler rule formats: more flexible but harder to author
- Failure signatures:
  - Propagation too slow -> interface feels unresponsive
  - Inconsistent state persists -> user confusion
  - Explanations unclear -> loss of trust
  - Missing parameter values -> irrelevant constraints ignored
- First 3 experiments:
  1. Enter a valid temperature constraint and verify the adhesive counter decreases correctly.
  2. Create an impossible constraint pair (e.g., temperature beyond substrate limit) and confirm the inconsistency window appears.
  3. Use the explanation feature on a propagated value and check that the displayed rules match the KB.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of adding more adhesives to the knowledge base on the tool's effectiveness?
- Basis in paper: [explicit] The paper mentions that adding more adhesives to the knowledge base is the only remaining bottleneck for the tool's production use.
- Why unresolved: The paper does not provide any quantitative data on how the addition of more adhesives affects the tool's performance or user satisfaction.
- What evidence would resolve it: A study measuring the tool's performance and user satisfaction before and after adding a significant number of new adhesives to the knowledge base.

### Open Question 2
- Question: How can the interface be improved to make it more user-friendly and efficient for experts?
- Basis in paper: [inferred] The paper mentions that experts found the interface cluttered and had difficulty navigating it. They also suggested improvements like alphabetical ordering of values and folding categories.
- Why unresolved: The paper does not provide any concrete solutions or user testing results for the proposed improvements.
- What evidence would resolve it: A user study testing the proposed improvements and measuring their impact on user satisfaction and efficiency.

### Open Question 3
- Question: How can the explanations generated by the tool be made more understandable and useful for experts?
- Basis in paper: [explicit] The paper mentions that experts found the automatically generated explanations difficult to understand and navigate.
- Why unresolved: The paper does not provide any solutions or user testing results for improving the explanations.
- What evidence would resolve it: A study testing different explanation formats and measuring their impact on user understanding and trust in the tool.

## Limitations
- Limited knowledge base size (55 adhesives) raises questions about scalability to industrial requirements
- No quantitative metrics comparing tool accuracy or performance to existing methods
- Explanation generation remains a significant weakness despite being a stated focus
- No longitudinal data on tool adoption or impact on actual adhesive selection outcomes

## Confidence
- Tool effectiveness and user satisfaction: High confidence (direct expert validation with multiple interviewees)
- Knowledge formalization process: Medium confidence (positive expert feedback but limited detail on cDMN adoption challenges)
- Explanation functionality: Low confidence (experts acknowledged potential but found explanations difficult to understand)

## Next Checks
1. Conduct A/B testing comparing selection outcomes between tool users and traditional expert methods using standardized test cases
2. Expand knowledge base to 200+ adhesives and evaluate whether cDMN formalization remains manageable for experts
3. Redesign explanation interface with expert input to improve clarity and test whether comprehension improves significantly