---
ver: rpa2
title: 'HAMUR: Hyper Adapter for Multi-Domain Recommendation'
arxiv_id: '2309.06217'
source_url: https://arxiv.org/abs/2309.06217
tags:
- domain
- adapter
- hamur
- parameters
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes HAMUR, a novel method for multi-domain recommendation
  (MDR) that addresses the limitations of existing approaches, including mutual interference
  among domains and limited flexibility to adapt to diverse domains. HAMUR introduces
  a domain-specific adapter and a domain-shared hyper-network to capture shared information
  among domains and dynamically generate parameters for the adapter.
---

# HAMUR: Hyper Adapter for Multi-Domain Recommendation

## Quick Facts
- arXiv ID: 2309.06217
- Source URL: https://arxiv.org/abs/2309.06217
- Reference count: 40
- Key outcome: HAMUR outperforms state-of-the-art MDR methods, particularly in domains with rare training samples, and is compatible with various backbone networks

## Executive Summary
HAMUR introduces a novel approach to multi-domain recommendation (MDR) that addresses the limitations of existing methods, including mutual interference among domains and limited flexibility to adapt to diverse domain distributions. The method employs a domain-specific adapter with bottleneck architecture and a domain-shared hyper-network that dynamically generates adapter parameters based on instance-level embeddings. This design enables efficient parameter sharing while preserving domain-specific characteristics, leading to improved performance across multiple domains.

## Method Summary
HAMUR is designed for multi-domain recommendation tasks where models must predict click-through rates across multiple domains. The method integrates domain-specific adapters into existing MDR backbone models (such as MLP, DCN, and Wide & Deep) and uses a domain-shared hyper-network to generate adapter parameters dynamically. The hyper-network takes instance-level embeddings containing both features and domain indicators, then generates low-rank matrices that form the adapter parameters through matrix decomposition. Domain normalization replaces traditional layer normalization to better handle the distinct semantics of different feature fields in recommendation systems.

## Key Results
- HAMUR outperforms state-of-the-art methods (STAR, APG, SharedBottom, MMOE) on both MovieLens and Ali-CCP datasets
- HAMUR demonstrates superior performance particularly in domains with rare training samples
- The method is compatible with various backbone networks including MLP, DCN, and Wide & Deep

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic parameter generation via a domain-shared hyper-network enables flexible adaptation to diverse domain distributions without domain interference.
- Mechanism: The hyper-network takes instance-level embeddings (containing both features and domain indicator) and generates domain-specific adapter parameters on-the-fly, avoiding static parameters that limit scalability.
- Core assumption: Instance-level embeddings contain sufficient information to generate effective domain-specific parameters.
- Evidence anchors:
  - [abstract] "Domain-shared hyper-network, which implicitly captures shared information among domains and dynamically generates the parameters for the adapter"
  - [section 2.4.1] "The input includes two parts, the raw features ğ’™, and the domain indicator ğ’‘. They will be fed into the embedding layer"
  - [corpus] Weak - related papers discuss similar approaches but lack direct evidence of this specific mechanism
- Break condition: If instance-level embeddings fail to capture domain-specific patterns, the generated parameters will be ineffective, leading to poor domain adaptation.

### Mechanism 2
- Claim: Domain-specific adapters with bottleneck architecture provide efficient parameter sharing while preserving domain-specific characteristics.
- Mechanism: The adapter module (down-projection â†’ non-linear â†’ up-projection) compresses and reconstructs feature representations, allowing each domain to maintain its unique characteristics while sharing common knowledge through the hyper-network.
- Core assumption: The bottleneck architecture effectively balances compression and reconstruction for CTR prediction tasks.
- Evidence anchors:
  - [section 2.3.1] "The adapter cell, denoted as ğ‘¨ğ‘‘, is designed with the shape of the bottleneck. It includes four layers, a down-projection ğ‘¼ ğ‘‘ âˆˆ Râ„Ã—ğ‘ , a sigmoid non-linear layerğœ, an up-projectionğ‘½ğ‘‘ âˆˆ Rğ‘  Ã—â„"
  - [abstract] "Domain-specific adapter, designed as a pluggable module that can be seamlessly integrated into various existing multi-domain backbone models"
  - [corpus] Weak - corpus mentions adapter techniques but not specifically for MDR with bottleneck architecture
- Break condition: If the bottleneck dimension is too small, it may lose critical information; if too large, it defeats the purpose of efficient parameter sharing.

### Mechanism 3
- Claim: Domain normalization layer replaces layer normalization to handle the distinct semantics of different feature fields in recommendation systems.
- Mechanism: Domain normalization applies batch normalization across instances rather than across feature fields, using domain-specific scale and bias parameters to maintain domain characteristics.
- Core assumption: Feature fields in recommendation systems have different semantics that should not be normalized together.
- Evidence anchors:
  - [section 2.3.2] "In the case of multi-domain CTR prediction, different from single-domain tasks, the data distribution is locally Independent Identically Distributed (IID) in each individual domain"
  - [section 2.3.2] "Hence, we propose the use of domain normalization, which is expressed as: ğ·ğ‘ğ‘‘ = ğ›¾ğ‘‘ âŠ™ ğ’™ âˆ’ ğœ‡âˆšğœ2 + ğœ– + ğ›½ğ‘‘"
  - [corpus] Weak - corpus mentions normalization but not domain-specific normalization for MDR
- Break condition: If domain distributions are not truly IID, this normalization approach may introduce bias or fail to capture necessary correlations.

## Foundational Learning

- Concept: Multi-Domain Recommendation (MDR) task formulation
  - Why needed here: Understanding how MDR differs from single-domain and cross-domain recommendation is crucial for grasping HAMUR's contributions
  - Quick check question: How does MDR differ from cross-domain recommendation in terms of data utilization and model objectives?

- Concept: Adapter modules in deep learning
  - Why needed here: HAMUR's core innovation relies on using adapter modules in a novel way for MDR
  - Quick check question: What is the primary advantage of using adapter modules instead of fine-tuning entire models in recommendation systems?

- Concept: Dynamic parameter generation via hyper-networks
  - Why needed here: HAMUR's hyper-network generates adapter parameters dynamically, which is central to its effectiveness
  - Quick check question: How does dynamic parameter generation via hyper-networks differ from static parameter sharing in traditional MDR approaches?

## Architecture Onboarding

- Component map:
  - Input layer: Sparse and dense features + domain indicator
  - Embedding layer: Maps raw features to low-dimensional embeddings
  - Hyper-network: Domain-shared network that generates adapter parameters
  - Domain-specific adapters: Pluggable modules inserted into backbone network
  - Backbone network: Existing MDR model (MLP, DCN, Wide & Deep, etc.)
  - Output layer: CTR prediction

- Critical path:
  1. Features and domain indicator â†’ Embedding layer
  2. Embeddings â†’ Hyper-network â†’ Generate adapter parameters
  3. Features + Adapter parameters â†’ Backbone network with adapter
  4. Backbone output â†’ CTR prediction

- Design tradeoffs:
  - Adapter bottleneck dimension vs. model capacity
  - Hyper-network dimension vs. overfitting risk
  - Adapter insertion position vs. feature learning effectiveness

- Failure signatures:
  - Poor performance on domains with rare training samples â†’ Hyper-network not capturing domain patterns effectively
  - Overfitting on specific domains â†’ Adapter parameters too domain-specific
  - Computational inefficiency â†’ Hyper-network or adapter dimensions too large

- First 3 experiments:
  1. Baseline comparison: HAMUR vs. STAR, APG, SharedBottom, MMOE on MovieLens and Ali-CCP datasets
  2. Backbone compatibility: Integrate HAMUR with MLP, DCN, and Wide & Deep backbones
  3. Hyper-parameter sensitivity: Test different representation matrix dimensions (k) and hyper-network dimensions on both datasets

## Open Questions the Paper Calls Out
The paper identifies several future research directions:
- Extending HAMUR to more complex multi-task scenarios beyond CTR prediction
- Exploring the impact of adapter placement depth within the backbone network
- Investigating HAMUR's performance with varying numbers of domains in real-world production environments

## Limitations
- The paper only evaluates HAMUR on two public datasets with 3 domains each, limiting generalizability to scenarios with many domains
- Computational overhead during online inference compared to baseline models is not quantified
- The paper does not evaluate HAMUR's performance under concept drift conditions where data distributions change over time

## Confidence

- **High confidence**: HAMUR's compatibility with various backbone networks (MLP, DCN, Wide & Deep) and its ability to improve performance on domains with rare training samples.
- **Medium confidence**: The claim that HAMUR mitigates mutual interference among domains through dynamic parameter generation, as the evidence is primarily comparative rather than mechanistic.
- **Low confidence**: The assertion that domain normalization significantly outperforms layer normalization in MDR settings, given the lack of direct comparison experiments.

## Next Checks

1. **Ablation study**: Remove the hyper-network and replace it with static parameters to quantify the exact contribution of dynamic parameter generation to HAMUR's performance gains.

2. **Domain normalization comparison**: Implement HAMUR with layer normalization instead of domain normalization and measure performance differences across all domains to validate the claimed benefits.

3. **Hyper-network sensitivity analysis**: Systematically vary the hyper-network dimension and embedding sizes to identify optimal configurations and understand the relationship between model complexity and performance across domains with different data volumes.