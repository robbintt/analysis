---
ver: rpa2
title: Fair Canonical Correlation Analysis
arxiv_id: '2309.15809'
source_url: https://arxiv.org/abs/2309.15809
tags:
- correlation
- sf-cca
- mf-cca
- fairness
- canonical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses fairness in Canonical Correlation Analysis
  (CCA) by proposing a framework that minimizes correlation disparity error across
  sensitive groups. The core method learns global projection matrices while ensuring
  comparable correlation levels to group-specific projections.
---

# Fair Canonical Correlation Analysis

## Quick Facts
- arXiv ID: 2309.15809
- Source URL: https://arxiv.org/abs/2309.15809
- Reference count: 40
- One-line primary result: Framework achieves up to 50% reduction in correlation disparity error across sensitive groups while maintaining high correlation

## Executive Summary
This paper addresses fairness in Canonical Correlation Analysis (CCA) by proposing a framework that minimizes correlation disparity error across sensitive groups. The core method learns global projection matrices while ensuring comparable correlation levels to group-specific projections. Two optimization approaches are developed: a multi-objective framework for automatic trade-off between correlation and fairness, and a single-objective framework with a tunable fairness-accuracy parameter. Experiments on synthetic and real datasets demonstrate significant fairness improvements with minimal correlation loss.

## Method Summary
The method partitions data into K sensitive groups and computes group-specific CCA solutions as reference points. It then optimizes global projection matrices to minimize the difference between global and group-specific correlation performance, subject to orthogonal projection constraints. The multi-objective framework simultaneously optimizes for correlation and disparity error, while the single-objective framework adds a penalty term weighted by λ. Both approaches use Riemannian optimization on Stiefel manifolds with gradient descent and retraction operations to maintain manifold constraints.

## Key Results
- Achieves up to 50% reduction in correlation disparity error while maintaining high correlation
- Multi-objective approach automatically balances fairness and accuracy without manual tuning
- Single-objective approach provides simple fairness-accuracy trade-off via λ parameter
- Computational efficiency outperforms baseline CCA implementations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: F-CCA learns global projection matrices while ensuring comparable correlation levels to group-specific projections.
- Mechanism: The method minimizes correlation disparity error by optimizing global projections to match group-specific correlation performance.
- Core assumption: Group-specific optimal projections can serve as reference points for fairness.
- Evidence anchors:
  - [abstract]: "Our approach enables CCA to learn global projection matrices from all data points while ensuring that these matrices yield comparable correlation levels to group-specific projection matrices."
  - [section 3.2]: Defines correlation disparity error as the difference between group-specific and global correlation performance.
- Break condition: If group-specific projections themselves are biased or if groups have fundamentally different correlation structures that cannot be reconciled.

### Mechanism 2
- Claim: Multi-objective optimization automatically balances correlation and fairness.
- Mechanism: The framework simultaneously optimizes for correlation and disparity error across multiple objectives, finding Pareto-optimal solutions.
- Core assumption: There exists a trade-off frontier between correlation accuracy and fairness that can be navigated.
- Evidence anchors:
  - [section 3.3]: "The multi-objective framework (9) addresses the challenge of handling conflicting objectives and achieving optimal trade-offs between them."
  - [corpus]: Related work on multi-objective optimization in fairness (Samadi et al., 2018) supports this approach.
- Break condition: If the objectives are too conflicting (e.g., perfect fairness requires zero correlation).

### Mechanism 3
- Claim: Single-objective optimization with λ parameter provides simple fairness-accuracy trade-off.
- Mechanism: Adds a regularization term that penalizes disparity error, with λ controlling the fairness emphasis.
- Core assumption: A single tunable parameter can effectively balance the competing objectives.
- Evidence anchors:
  - [section 3.4]: "The choice of λ in the model determines the emphasis placed on different objectives."
  - [section 4.1]: Discusses sensitivity analysis of λ and its effect on correlation vs fairness.
- Break condition: If λ cannot be properly tuned due to lack of labeled data or if the relationship between λ and fairness is non-monotonic.

## Foundational Learning

- Concept: Riemannian optimization on Stiefel manifolds
  - Why needed here: CCA constraints require orthogonal projections, naturally formulated as optimization on manifolds.
  - Quick check question: What is the tangent space of the Stiefel manifold St(D,R,B) at point Z?

- Concept: Multi-objective optimization and Pareto efficiency
  - Why needed here: Balancing correlation and fairness requires handling multiple conflicting objectives.
  - Quick check question: What is the definition of a Pareto-optimal point in the context of F-CCA?

- Concept: Correlation disparity error as fairness metric
  - Why needed here: Provides a quantitative measure of fairness that can be optimized.
  - Quick check question: How is correlation disparity error defined between two groups k and s?

## Architecture Onboarding

- Component map: Data preprocessing -> Group-specific CCA solvers -> Main optimization (MF-CCA/SF-CCA) -> Retraction operations -> Evaluation metrics

- Critical path: Group-specific CCA → Main optimization → Retraction updates → Convergence check

- Design tradeoffs:
  - MF-CCA vs SF-CCA: Multi-objective provides automatic trade-off but more complex; single-objective simpler but requires tuning λ
  - Retraction choice: Polar decomposition vs exponential map affects computational efficiency
  - Group definition: Sensitive attribute selection impacts fairness outcomes

- Failure signatures:
  - Non-convergence: Check retraction implementation and learning rate
  - Poor fairness improvement: Verify group-specific reference projections are correctly computed
  - Excessive correlation loss: λ may be too large or manifold constraints too restrictive

- First 3 experiments:
  1. Synthetic data with known group disparities to verify fairness improvement
  2. NHANES data with education as sensitive attribute to test real-world applicability
  3. ADNI data with sex as sensitive attribute to validate medical imaging application

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical minimum achievable correlation disparity error for Fair CCA, and under what conditions can it be reached?
- Basis in paper: [explicit] The paper mentions that "F-CCA holds promise for extensions to diverse domains" but doesn't explore theoretical limits of disparity reduction
- Why unresolved: The paper focuses on empirical results showing fairness improvements but doesn't establish theoretical bounds or conditions for optimal fairness-accuracy trade-offs
- What evidence would resolve it: Mathematical proofs establishing lower bounds on correlation disparity error for various fairness constraints and data distributions

### Open Question 2
- Question: How does Fair CCA perform on multi-modal datasets where the number of features differs significantly between views (e.g., imaging vs. genetic data)?
- Basis in paper: [inferred] The paper mentions potential extensions to "multiple modalities" but only tests on balanced feature datasets
- Why unresolved: All tested datasets have comparable feature dimensions between views, leaving questions about performance in highly imbalanced scenarios
- What evidence would resolve it: Experimental results on datasets with significantly different feature counts between views (e.g., 10:1 ratio) comparing Fair CCA to standard CCA

### Open Question 3
- Question: What is the computational complexity of Fair CCA compared to standard CCA as the number of sensitive groups increases?
- Basis in paper: [explicit] The paper shows runtime sensitivity to K in Figure 14 but doesn't provide theoretical complexity analysis
- Why unresolved: While empirical runtime data is provided, there's no formal analysis of how computational requirements scale with the number of groups
- What evidence would resolve it: Big-O complexity analysis of Fair CCA algorithms as a function of N (samples), d (features), and K (groups) compared to standard CCA

## Limitations

- Fairness improvements depend on quality of group-specific reference projections, which may themselves be biased
- Assumes correlation structures can be reconciled across groups, may not hold for fundamentally different distributions
- Limited experimental validation with small sample sizes and few sensitive groups

## Confidence

- Technical optimization framework: Medium-High
- Fairness improvements: Medium
- Computational efficiency claims: Medium-Low

## Next Checks

1. **Robustness to group definition**: Test the method with varying numbers of sensitive groups (2, 5, 10) and different group assignment strategies to assess sensitivity to how groups are defined.

2. **Downstream task fairness**: Apply the learned fair projections to actual prediction tasks (classification/regression) and measure fairness in downstream outcomes, not just correlation disparity.

3. **Comparison with alternative fairness approaches**: Benchmark against other fair ML methods for dimensionality reduction and correlation analysis to establish relative performance.