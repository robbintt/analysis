---
ver: rpa2
title: 'Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative
  Models'
arxiv_id: '2305.10120'
source_url: https://arxiv.org/abs/2305.10120
tags:
- logp
- images
- forget
- forgetting
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Selective Amnesia is a method for controlled forgetting in conditional
  generative models that enables users to selectively erase specific concepts (e.g.,
  celebrity names, nudity) while preserving the model's ability to generate other
  content. The approach frames forgetting as a continual learning problem, combining
  Elastic Weight Consolidation (to protect weights important for retained concepts)
  and Generative Replay (to maintain generation quality of concepts to remember) into
  a unified objective.
---

# Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models

## Quick Facts
- arXiv ID: 2305.10120
- Source URL: https://arxiv.org/abs/2305.10120
- Authors: 
- Reference count: 40
- Key outcome: Selective Amnesia achieves controlled forgetting in conditional generative models by combining Elastic Weight Consolidation and Generative Replay into a unified objective, successfully erasing specific concepts while maintaining generation quality of retained concepts.

## Executive Summary
Selective Amnesia is a method for controlled forgetting in conditional generative models that enables users to selectively erase specific concepts (e.g., celebrity names, nudity) while preserving the model's ability to generate other content. The approach frames forgetting as a continual learning problem, combining Elastic Weight Consolidation (to protect weights important for retained concepts) and Generative Replay (to maintain generation quality of concepts to remember) into a unified objective. Experiments on MNIST, CIFAR10, STL10, and Stable Diffusion demonstrate successful forgetting of discrete classes, celebrity names, and nudity-related prompts, with minimal degradation to retained concepts. The method allows user-defined remapping of forgotten concepts to semantically appropriate alternatives, generating realistic but target-concept-free images. Results show reduced classification scores for forgotten concepts while maintaining competitive image quality metrics compared to baselines.

## Method Summary
Selective Amnesia treats forgetting as a continual learning problem where a generative model must unlearn specific concepts while preserving others. The method combines three key components: Elastic Weight Consolidation (EWC) to protect weights important for retained concepts, Generative Replay to maintain generation quality of remembered concepts, and a surrogate distribution objective to actively lower likelihood of forgotten concepts. During forgetting training, the model optimizes a unified objective that balances these competing goals. The EWC component uses Fisher information matrices to identify and protect crucial weights, while generative replay generates synthetic samples from the original model for retained concepts to serve as training data. The surrogate distribution objective replaces the original distribution of forgotten concepts with an alternative distribution, effectively reducing the model's ability to generate those concepts while maintaining realistic image quality.

## Key Results
- Successfully erased specific concepts (celebrity names, nudity prompts) from Stable Diffusion while maintaining generation quality of retained concepts
- Achieved reduced classification scores for forgotten concepts (lower probability and higher entropy in classifier predictions)
- Maintained competitive image quality metrics (FID, Precision, Recall) compared to baselines
- Demonstrated effective forgetting across multiple datasets (MNIST, CIFAR10, STL10) and model architectures (VAE, DDPM, diffusion models)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Selective Amnesia achieves forgetting by optimizing a surrogate objective that maximizes likelihood of an alternative distribution while preserving retained concepts through Elastic Weight Consolidation.
- Mechanism: The method combines three key components: (1) EWC penalty term that prevents changes to weights important for retained concepts, (2) generative replay that maintains generation quality of remembered concepts, and (3) surrogate distribution objective that actively lowers likelihood of forgotten concepts. The unified objective balances these competing goals.
- Core assumption: The variational lower bound can serve as a reasonable surrogate for the true log-likelihood in the optimization objective, and that the surrogate distribution q(x|cf) can effectively replace the original distribution p(x|cf) without introducing new artifacts.
- Evidence anchors:
  - [abstract] "combining Elastic Weight Consolidation (to protect weights important for retained concepts) and Generative Replay (to maintain generation quality of concepts to remember) into a unified objective"
  - [section 3.2] "Rather than attempting to directly minimize the log-likelihood or the ELBO, we maximize the log-likelihood of a surrogate distribution of the class to forget, q(x|cf)≠p(x|cf)"
  - [corpus] "Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay" - related work confirms replay mechanisms are effective for maintaining concept generation
- Break condition: If the surrogate distribution q(x|cf) is poorly chosen (e.g., too similar to original distribution), the method may fail to induce sufficient forgetting, or if the ELBO is too loose a bound, the optimization may not effectively lower the true log-likelihood of forgotten concepts.

### Mechanism 2
- Claim: The Elastic Weight Consolidation component effectively identifies and protects weights crucial for retained concepts by computing Fisher information matrices based on variational lower bounds.
- Mechanism: EWC calculates a diagonal approximation of the Fisher information matrix that measures how sensitive each weight is to changes in the ELBO. During forgetting training, weights with high Fisher values receive stronger penalties for deviation from their original values, preserving their contribution to retained concepts.
- Core assumption: The diagonal approximation of the Fisher information matrix provides sufficient information about weight importance, and that changes to low-Fisher weights don't significantly impact retained concept generation.
- Evidence anchors:
  - [section 2.2] "Fi can be viewed as a sensitivity measure of the weight θi on the model's output. For variational models, we modify the Fi to measure the sensitivity of θi on the ELBO"
  - [section 3.1] "we modify the Fi to measure the sensitivity of θi on the ELBO: Fi = Ep(x|θ∗,c)p(c)[(∂∂θiELBO(x|θ,c))2]"
  - [corpus] "Continual Diffusion with STAMINA: STack-And-Mask INcremental Adapters" - related work confirms Fisher-based regularization is effective for continual learning
- Break condition: If the Fisher information calculation is inaccurate (e.g., due to insufficient samples or poor approximation), the method may fail to properly protect weights for retained concepts, leading to degradation in generation quality.

### Mechanism 3
- Claim: Generative replay provides a data-efficient way to maintain generation quality of retained concepts without requiring access to original training data.
- Mechanism: The method generates synthetic samples from the original model for retained concepts and uses these as training data during the forgetting phase. This replay process ensures the model continues to practice generating retained concepts while simultaneously learning to forget others.
- Core assumption: The generative model can produce sufficiently realistic and diverse samples of retained concepts to serve as effective training data, and that replay frequency and quantity are adequate to prevent catastrophic forgetting.
- Evidence anchors:
  - [section 3.1] "we introduce an extra likelihood term over Dr that corresponds to a generative replay term"
  - [section 4.1] "we use 50K samples to calculate the FIM, and sample the replay data from a frozen copy of the original VAE during forgetting training"
  - [corpus] "Sculpting Memory: Multi-Concept Forgetting in Diffusion Models via Dynamic Mask and Concept-Aware Optimization" - related work confirms replay mechanisms are essential for maintaining concept generation
- Break condition: If the replay samples are of poor quality or insufficient quantity, the method may fail to maintain generation quality of retained concepts, leading to degradation in those concepts' output.

## Foundational Learning

- Concept: Evidence Lower Bound (ELBO) in variational autoencoders
  - Why needed here: The method relies on variational models where the true log-likelihood is intractable, requiring optimization of ELBO instead. Understanding ELBO is crucial for grasping why direct likelihood minimization is problematic.
  - Quick check question: Why can't we directly minimize log-likelihood in variational models, and how does ELBO relate to log-likelihood?

- Concept: Fisher information matrix and its role in identifying parameter importance
  - Why needed here: EWC uses Fisher information to determine which weights are important for retained concepts. Understanding Fisher information is essential for grasping how the method protects important weights.
  - Quick check question: How does the Fisher information matrix identify important parameters, and why is the diagonal approximation commonly used?

- Concept: Catastrophic forgetting in continual learning
  - Why needed here: The method frames forgetting as a continual learning problem, so understanding catastrophic forgetting and how it's typically prevented is crucial for understanding the approach.
  - Quick check question: What is catastrophic forgetting, and how do methods like EWC and generative replay typically prevent it in continual learning?

## Architecture Onboarding

- Component map: The system consists of three main components: (1) a variational generative model (VAE or diffusion model) that serves as the base model, (2) a Fisher information calculation module that computes parameter importance metrics, and (3) a replay generation module that creates synthetic training data for retained concepts. The unified objective function combines EWC regularization, generative replay likelihood, and surrogate distribution likelihood.

- Critical path: The most critical sequence is: (1) calculate Fisher information matrix using original model samples, (2) generate replay dataset from original model for retained concepts, (3) optimize unified objective with surrogate distribution for forgotten concepts, (4) validate forgetting effectiveness using external classifiers. Each step depends on the previous one's output.

- Design tradeoffs: The method trades computational efficiency (calculating Fisher information and generating replay samples) for effectiveness in achieving controlled forgetting. Using ELBO instead of true likelihood introduces approximation error but enables tractable optimization. The choice of surrogate distribution q(x|cf) involves a tradeoff between realism and effectiveness in erasing concept information.

- Failure signatures: Poor forgetting effectiveness manifests as high classifier accuracy on forgotten concepts and low entropy in their predicted distributions. Poor retention of remembered concepts appears as degraded image quality (higher FID scores) or lower classifier accuracy on retained concepts. Both failures can be diagnosed using the evaluation metrics described in the paper.

- First 3 experiments:
  1. Implement the basic SA objective on a simple VAE trained on MNIST, attempting to forget one digit class, and verify that the ELBO optimization works as expected.
  2. Add the EWC regularization term and verify that it prevents degradation of other digit classes while forgetting the target class.
  3. Add generative replay and verify that it improves retention of non-forgotten classes compared to training without replay.

## Open Questions the Paper Calls Out
- The authors suggest that more work is needed on methods that work well for both "local" specific concepts (like celebrities) and "global" concepts (like nudity), as SA performs better on local concepts.
- The computational cost of Fisher Information Matrix calculation for diffusion models is identified as an area for future investigation.
- The relationship between surrogate distribution choice and forgetting efficacy could be explored more systematically.

## Limitations
- The method's effectiveness on non-discrete, continuous concepts (like facial features beyond celebrity names) remains unproven.
- The stability of forgetting across different model architectures and the long-term effects of the forgetting process are not thoroughly tested.
- The approach relies on surrogate distributions that may not fully erase concept information if they're too similar to original distributions.

## Confidence
**High confidence**: The EWC mechanism for protecting retained concepts and the generative replay approach for maintaining generation quality are well-established techniques with strong theoretical foundations and empirical validation in related work.

**Medium confidence**: The unified objective combining EWC, generative replay, and surrogate distribution optimization is novel, but the effectiveness depends heavily on hyperparameter tuning and the quality of the surrogate distribution choice.

**Low confidence**: The method's generalization to real-world scenarios with noisy, ambiguous, or overlapping concepts hasn't been thoroughly tested. The stability of forgetting across different model architectures and the long-term effects of the forgetting process remain open questions.

## Next Checks
1. **Ablation study on surrogate distribution quality**: Systematically test different surrogate distributions (Gaussian, uniform, learned distributions) to determine the minimum quality threshold needed for effective forgetting while maintaining generation quality of retained concepts.

2. **Cross-architecture generalization**: Apply the method to different generative model architectures (e.g., GANs, normalizing flows) beyond the VAEs and diffusion models tested, to assess the approach's architectural robustness.

3. **Long-term forgetting stability**: After the forgetting process, continue training on retained concepts for multiple epochs without the forgetting objective to test whether forgotten concepts gradually return, indicating incomplete information erasure.