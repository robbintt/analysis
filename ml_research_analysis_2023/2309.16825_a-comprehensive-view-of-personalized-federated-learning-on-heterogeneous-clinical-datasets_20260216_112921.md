---
ver: rpa2
title: A Comprehensive View of Personalized Federated Learning on Heterogeneous Clinical
  Datasets
arxiv_id: '2309.16825'
source_url: https://arxiv.org/abs/2309.16825
tags:
- local
- training
- data
- each
- client
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces FENDA-FL, a personalized federated learning
  method that extends the FENDA framework to handle heterogeneous clinical data across
  distributed institutions. The approach uses separate global and local feature extractors
  per client, with only global parameters aggregated at the server, enabling personalized
  predictions while reducing communication overhead.
---

# A Comprehensive View of Personalized Federated Learning on Heterogeneous Clinical Datasets

## Quick Facts
- arXiv ID: 2309.16825
- Source URL: https://arxiv.org/abs/2309.16825
- Authors: 
- Reference count: 38
- Key outcome: FENDA-FL outperforms existing FL methods, including state-of-the-art personalized approaches like APFL, particularly in settings with significant data heterogeneity.

## Executive Summary
This paper introduces FENDA-FL, a personalized federated learning method that extends the FENDA framework to handle heterogeneous clinical data across distributed institutions. The approach uses separate global and local feature extractors per client, with only global parameters aggregated at the server, enabling personalized predictions while reducing communication overhead. Experiments on FLamby and GEMINI datasets show that FENDA-FL often outperforms existing FL methods, including state-of-the-art personalized approaches like APFL, particularly in settings with significant data heterogeneity. The method surpasses centralized training in some cases and recovers performance of locally trained models, even under extreme feature-space misalignment.

## Method Summary
FENDA-FL is a personalized federated learning framework that trains separate global and local feature extractors on each client, with only the global feature extractor weights aggregated at the server. Each client model consists of a global feature extraction module, a local feature extraction module, and a local classification network that processes the concatenated features. The method uses AdamW optimizer with client learning rates between 0.1 and 1e-5 and server learning rates between 0.1 and 1e-4 for FedAdam. Training proceeds through 15-50 server rounds with 100 local steps per round, and only global feature extractor weights are communicated between clients and server.

## Key Results
- FENDA-FL outperforms global and personalized FL baselines including PerFCL on FLamby benchmark datasets
- The method demonstrates robustness to heterogeneous clinical data and extreme feature-space misalignment
- FENDA-FL surpasses centralized training performance in some cases while maintaining communication efficiency through selective parameter aggregation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FENDA-FL outperforms global and personalized FL baselines by allowing each client to combine global and local feature extractors with a local classification head.
- Mechanism: The global feature extractor captures domain-agnostic patterns across all clients, while the local extractor captures client-specific patterns. The classification head can choose how much to rely on each based on the task, enabling flexibility under data heterogeneity.
- Core assumption: The combination of shared and local features through concatenation preserves complementary information and does not introduce noise that overwhelms useful signals.
- Evidence anchors:
  - [abstract] "Experiments conducted on the FLamby benchmark and GEMINI datasets (Verma et al., 2017) show that the proposed approach is robust to heterogeneous clinical data and often outperforms existing global and personalized FL techniques, including PerFCL."
  - [section 3.1] "Each client model consists of a global and local feature extraction module. The two sets of activations are combined and processed by a local classification network."

### Mechanism 2
- Claim: FENDA-FL reduces communication overhead compared to full-model personalization methods.
- Mechanism: Only the global feature extractor weights are aggregated and communicated to the server, while local feature extractor and classifier weights remain client-specific.
- Core assumption: The global feature extractor captures the most transferable knowledge and thus its aggregation is most beneficial, while local components can remain private.
- Evidence anchors:
  - [abstract] "The approach uses separate global and local feature extractors per client, with only global parameters aggregated at the server, enabling personalized predictions while reducing communication overhead."
  - [section 3.1] "Thereafter, the clients transmit only the weights of the global feature extractors for server-side aggregation."

### Mechanism 3
- Claim: FENDA-FL achieves robustness to extreme feature-space heterogeneity by allowing clients to independently process features locally while still benefiting from global patterns.
- Mechanism: When clients independently process their data (e.g., through PCA/feature selection), the resulting feature spaces become misaligned. FENDA-FL's local extractors adapt to each client's specific feature space while the global extractor provides a fallback.
- Core assumption: The local feature extractor can effectively map the client's specific feature space to useful representations, and the classification head can fuse these with global features.
- Evidence anchors:
  - [section 4.5] "When clients independently process their data (e.g., through PCA/feature selection), the resulting feature spaces become misaligned. FENDA-FL's local extractors adapt to each client's specific feature space while the global extractor provides a fallback."

## Foundational Learning

- Concept: Federated Learning with heterogeneous data distributions
  - Why needed here: The paper explicitly addresses cross-silo FL with non-IID data, requiring understanding of how heterogeneity affects convergence and performance.
  - Quick check question: What is the primary challenge when training FL models on non-IID data, and how do methods like FedProx and SCAFFOLD attempt to address it?

- Concept: Personalized Federated Learning
  - Why needed here: FENDA-FL is a personalized FL method that trains client-specific models, requiring understanding of the trade-offs between global and local model components.
  - Quick check question: How does personalized FL differ from traditional FL, and what are the potential benefits and drawbacks of this approach?

- Concept: Model architecture for feature extraction and fusion
  - Why needed here: FENDA-FL's core mechanism involves separate global and local feature extractors whose outputs are concatenated and fed to a local classifier, requiring understanding of how different architectural choices affect performance.
  - Quick check question: Why might concatenating global and local features be more effective than simply averaging or gating them in certain heterogeneous settings?

## Architecture Onboarding

- Component map: Global feature extractor -> Local feature extractor -> Concatenation -> Classification head
- Critical path:
  1. Client trains local model on local data
  2. Client sends global feature extractor weights to server
  3. Server aggregates global weights (FedAvg)
  4. Server sends aggregated weights back to clients
  5. Clients update their global feature extractors
  6. Repeat until convergence

- Design tradeoffs:
  - Global vs. local feature extractor capacity: More capacity in global extractor may improve shared learning but reduce local adaptation
  - Concatenation vs. other fusion methods: Concatenation is simple but may introduce redundancy; alternatives like gating could be more efficient
  - Communication frequency: More frequent aggregation may improve global learning but increase communication costs

- Failure signatures:
  - Poor performance on clients with very different data distributions
  - Convergence issues when global and local feature spaces become too misaligned
  - Communication overhead not significantly reduced compared to full personalization

- First 3 experiments:
  1. Compare FENDA-FL to FedAvg on a simple non-IID dataset (e.g., Fashion-MNIST with label skew) to verify basic functionality
  2. Test FENDA-FL's communication efficiency by measuring parameter transfer size vs. full personalization methods
  3. Evaluate robustness to feature-space misalignment by applying PCA/feature selection independently to each client and measuring performance degradation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of FENDA-FL change when using more complex non-linear transformations in the classification head, such as multi-layer perceptrons or attention mechanisms?
- Basis in paper: [inferred] The paper mentions that FENDA-FL's classification head is free to leverage non-linear transformations of global and local features, suggesting potential for further exploration.
- Why unresolved: The paper uses relatively simple classification heads (e.g., linear layers) and doesn't explore more complex architectures.
- What evidence would resolve it: Experimental results comparing FENDA-FL with different classification head architectures on multiple clinical datasets, measuring both performance and communication efficiency.

### Open Question 2
- Question: What is the impact of different feature alignment strategies on FENDA-FL's performance in extremely heterogeneous data settings?
- Basis in paper: [explicit] The paper mentions that FENDA-FL demonstrates robustness in extreme heterogeneity experiments, but doesn't explore different feature alignment approaches.
- Why unresolved: The paper only considers one approach to handling heterogeneity (separate global/local feature extractors) without comparing to alternatives.
- What evidence would resolve it: Comparative experiments between FENDA-FL and variants using different feature alignment methods (e.g., domain-specific normalization, feature matching losses) on datasets with controlled heterogeneity levels.

### Open Question 3
- Question: How does the warm-start initialization strategy affect FENDA-FL's convergence and final performance across different types of clinical tasks?
- Basis in paper: [explicit] The paper mentions plans for future work to investigate warm-start strategies for FENDA-FL but doesn't present any results.
- Why unresolved: The paper only uses random initialization and acknowledges this as an open research direction.
- What evidence would resolve it: Experiments comparing FENDA-FL with and without warm-start initialization (e.g., pre-training on centralized data) across multiple clinical tasks, measuring convergence speed and final performance.

## Limitations
- Exact architectural details for competing methods (particularly APFL) are not fully specified, making direct comparison challenging
- Claims about performance on GEMINI datasets and extreme feature-space heterogeneity scenarios are described briefly without detailed methodology
- Communication overhead analysis is qualitative rather than quantitative, lacking concrete measurements of parameter reduction

## Confidence
- **High confidence**: The core mechanism of separate global/local feature extractors with only global aggregation is well-defined and technically sound
- **Medium confidence**: Empirical results on FLamby datasets showing FENDA-FL outperforming baselines, though exact implementation details of comparison methods are unclear
- **Low confidence**: Claims about performance on GEMINI datasets and extreme feature-space heterogeneity scenarios, as these are described briefly without detailed methodology

## Next Checks
1. **Implementation verification**: Reproduce FENDA-FL and APFL on a simple non-IID dataset (e.g., Fashion-MNIST with label skew) to verify that the reported performance gap is reproducible with full architectural specifications
2. **Communication overhead quantification**: Measure exact parameter transfer sizes for FENDA-FL vs. full personalization methods across all experimental settings to validate the claimed communication efficiency
3. **Centralized baseline validation**: Implement and verify the centralized training baseline independently to ensure that any claims of FENDA-FL outperforming centralized training are not due to implementation artifacts