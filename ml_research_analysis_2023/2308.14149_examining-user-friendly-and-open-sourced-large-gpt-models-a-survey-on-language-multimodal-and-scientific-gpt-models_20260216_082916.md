---
ver: rpa2
title: 'Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on Language,
  Multimodal, and Scientific GPT Models'
arxiv_id: '2308.14149'
source_url: https://arxiv.org/abs/2308.14149
tags:
- language
- data
- https
- arxiv
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey examines user-friendly and open-sourced alternatives
  to large GPT models, focusing on their architecture, efficiency, deployment, and
  fine-tuning. It evaluates 32 open-sourced models across language, multimodal, and
  scientific domains, highlighting Vicuna-7B, ChatGLM, and Moss as top performers
  in human evaluations.
---

# Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on Language, Multimodal, and Scientific GPT Models

## Quick Facts
- **arXiv ID:** 2308.14149
- **Source URL:** https://arxiv.org/abs/2308.14149
- **Reference count:** 40
- **Primary result:** Evaluation of 32 open-sourced GPT models across language, multimodal, and scientific domains, with Vicuna-7B, ChatGLM, and Moss identified as top performers

## Executive Summary
This survey comprehensively examines user-friendly and open-sourced alternatives to large GPT models, focusing on their architecture, efficiency, deployment, and fine-tuning. The study evaluates 32 models across three domains using both benchmark datasets and human evaluation, identifying Vicuna-7B, ChatGLM, and Moss as leading performers. The research highlights key challenges in balancing model size with performance, and proposes future directions for developing more accessible and versatile GPT models through efficient architectural modifications and targeted fine-tuning strategies.

## Method Summary
The survey employed a multi-faceted evaluation approach combining benchmark datasets, human evaluation using Elo rating systems, and technical analysis of architectural aspects. 16 open-sourced GPT models (primarily 7B parameters) were compared across 9 categories using 50 evaluation questions. Human annotators performed pairwise comparisons of model responses, with Elo ratings calculated to produce final rankings. The methodology also included analysis of efficiency techniques like LoRA and quantization, as well as fine-tuning strategies including instruction tuning and domain-specific adaptation.

## Key Results
- Vicuna-7B, ChatGLM, and Moss emerged as top performers in human evaluations across language, multimodal, and scientific domains
- Efficiency modifications (LoRA, quantization) and targeted fine-tuning can achieve comparable performance to larger models
- Significant trade-offs exist between model size and performance, with 7B models showing strong capabilities across most tasks
- Data efficiency remains a critical challenge for deploying user-friendly GPT models in resource-constrained settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The user-friendly GPT models achieve comparable performance to large models through efficient architectural adaptations and focused fine-tuning on task-specific data.
- Mechanism: The models employ lightweight architectural modifications (such as LoRA, quantization) and leverage high-quality, domain-specific fine-tuning data to compensate for reduced parameter counts while maintaining task performance.
- Core assumption: Architectural efficiency and data quality can substitute for raw model scale in achieving strong task performance.
- Evidence anchors:
  - [abstract] "alternative open-sourced models of large GPTs, focusing on user-friendly and relatively small models that facilitate easier deployment and accessibility"
  - [section] "techniques for efficient deployment and fine-tuning of these GPT models"
  - [corpus] Weak evidence - corpus contains surveys on multimodal models but lacks direct evaluation data for small models vs large models performance comparisons

### Mechanism 2
- Claim: The human evaluation methodology using Elo rating provides a robust and discriminating assessment of model capabilities across diverse tasks.
- Mechanism: Pairwise comparison approach with Elo rating system aggregates human judgments to produce stable rankings that reflect real-world model performance differences.
- Core assumption: Human pairwise comparisons are more reliable than absolute scoring for subjective tasks and the Elo system effectively aggregates these comparisons.
- Evidence anchors:
  - [abstract] "provide human evaluations of these relatively small GPT models to give some human-liked recommendations in real usage"
  - [section] "Elo rating system to score the final results" and "human consistency of 80.02 out of 100 between two evaluators"
  - [corpus] Moderate evidence - corpus includes surveys mentioning evaluation methods but lacks detailed Elo rating validation studies

### Mechanism 3
- Claim: The survey methodology provides comprehensive coverage of open-sourced GPT alternatives through systematic evaluation across multiple dimensions (language, multimodal, scientific domains).
- Mechanism: Multi-faceted evaluation approach combining benchmark datasets, human evaluation, and analysis of architectural/technical aspects provides holistic assessment of model capabilities and limitations.
- Core assumption: Comprehensive evaluation across multiple domains and methods captures the full spectrum of model capabilities better than single-dimension assessment.
- Evidence anchors:
  - [abstract] "evaluation of 32 open-sourced models across language, multimodal, and scientific domains"
  - [section] "meticulously across multiple dimensions... general knowledge ability, information extraction capability, comprehension ability, mathematical skills, and competence in various academic disciplines"
  - [corpus] Moderate evidence - corpus contains related surveys but this paper appears to provide more comprehensive multi-domain evaluation

## Foundational Learning

- **Transformer architecture fundamentals (attention mechanisms, encoder-decoder structures)**
  - Why needed here: Understanding the base architecture is crucial for grasping how efficiency modifications (LoRA, quantization) work and their impact on model performance
  - Quick check question: How does the self-attention mechanism in transformers enable long-range dependencies in sequential data?

- **Fine-tuning methodologies and data preparation**
  - Why needed here: The paper heavily emphasizes different fine-tuning approaches (instruction tuning, alignment data, domain-specific data) and their impact on model capabilities
  - Quick check question: What are the key differences between instruction tuning and alignment tuning in language models?

- **Evaluation methodologies in NLP (benchmark datasets, human evaluation)**
  - Why needed here: Understanding evaluation approaches is critical for interpreting the results presented in the benchmark and human evaluation sections
  - Quick check question: What are the advantages and limitations of using Elo rating systems for model comparison?

## Architecture Onboarding

- **Component map:** Base transformer architecture → Efficiency modifications (quantization, LoRA) → Fine-tuning pipeline (instruction data, alignment data) → Evaluation framework (benchmarks, human evaluation)
- **Critical path:** Model selection → Efficiency implementation → Fine-tuning with appropriate data → Evaluation and validation
- **Design tradeoffs:** Model size vs performance, computational efficiency vs accuracy, general capability vs domain-specific expertise
- **Failure signatures:** Performance degradation on benchmarks, inconsistent human evaluation results, deployment failures due to resource constraints
- **First 3 experiments:**
  1. Implement basic LoRA fine-tuning on a small language model and compare performance to full fine-tuning
  2. Apply quantization to a pre-trained model and measure accuracy impact across different bit-widths
  3. Conduct pairwise human evaluation on two models using the Elo rating system with a small set of diverse prompts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal trade-off between model size and performance for user-friendly GPT models across different tasks and domains?
- Basis in paper: [explicit] The paper discusses the challenge of balancing model size and performance, noting that "there exists a trade-off between reducing model complexity and preserving task performance."
- Why unresolved: The paper does not provide specific quantitative guidelines or thresholds for determining this trade-off across various applications. Different tasks may have varying requirements for model size versus performance.
- What evidence would resolve it: Empirical studies comparing performance vs. model size across a wide range of tasks and domains, identifying breakpoints where further size reduction significantly impacts performance.

### Open Question 2
- Question: How can we develop more efficient data collection and annotation strategies to improve data efficiency for user-friendly GPT models?
- Basis in paper: [explicit] The paper highlights data efficiency as a key challenge, noting that "data collection and annotation can be costly and time-consuming, making it challenging to deploy GPT models in resource-constrained settings."
- Why unresolved: While the paper discusses the importance of data efficiency, it does not propose specific novel techniques for improving data collection and annotation efficiency beyond existing methods like transfer learning.
- What evidence would resolve it: New methodologies for synthetic data generation, active learning approaches, or few-shot learning techniques that significantly reduce the amount of high-quality training data needed.

### Open Question 3
- Question: What are the most effective techniques for improving the interpretability and explainability of user-friendly GPT models?
- Basis in paper: [explicit] The paper identifies interpretable and explainable AI as a vital aspect, stating that "understanding their decision-making processes becomes increasingly challenging" as GPT models grow in complexity.
- Why unresolved: The paper does not propose or evaluate specific techniques for improving model interpretability and explainability in the context of user-friendly GPT models.
- What evidence would resolve it: Novel methods for generating human-readable explanations for model predictions, evaluation metrics for interpretability, and empirical studies demonstrating improved transparency and trust in user-friendly GPT models.

## Limitations

- Human evaluation reliability concerns due to unspecified tie-handling procedures and potential Elo rating sensitivity to comparison order
- Performance generalization limitations as conclusions are primarily based on 7B parameter models and may not scale to significantly larger or smaller models
- Sparse scientific domain coverage with only one specialized model (Moss) evaluated, limiting confidence in scientific capability assessments

## Confidence

- **High confidence**: Claims about survey methodology and identification of specific user-friendly models (Vicuna-7B, ChatGLM, Moss) are well-supported
- **Medium confidence**: Conclusions about efficiency technique effectiveness (LoRA, quantization) are reasonably supported but need more systematic ablation studies
- **Low confidence**: Claims about scientific domain capabilities are based on limited evaluation data and should be treated as preliminary

## Next Checks

1. **Elo rating stability test** - Reproduce human evaluation with randomized comparison orders and measure Elo score variance to assess ranking stability across different evaluation sequences

2. **Cross-domain generalization study** - Evaluate top-performing efficiency techniques (LoRA, quantization) on models outside the 7B parameter range (both smaller and larger) to validate scalability of claimed performance benefits

3. **Scientific domain expansion** - Conduct comprehensive evaluation of scientific capabilities across at least 5-10 models in the 7-70B parameter range to validate or challenge preliminary findings about scientific model performance