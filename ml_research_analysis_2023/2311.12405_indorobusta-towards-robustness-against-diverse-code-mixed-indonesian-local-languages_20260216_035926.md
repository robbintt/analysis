---
ver: rpa2
title: 'IndoRobusta: Towards Robustness Against Diverse Code-Mixed Indonesian Local
  Languages'
arxiv_id: '2311.12405'
source_url: https://arxiv.org/abs/2311.12405
tags:
- language
- code-mixed
- code-mixing
- indonesian
- robustness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces IndoRobusta, a framework to evaluate and
  improve the robustness of language models against code-mixing in Indonesian. The
  framework consists of two components: IndoRobusta-Blend, which generates code-mixed
  sentences by replacing important words with their translations, and IndoRobusta-Shot,
  which improves robustness through adversarial training.'
---

# IndoRobusta: Towards Robustness Against Diverse Code-Mixed Indonesian Local Languages

## Quick Facts
- arXiv ID: 2311.12405
- Source URL: https://arxiv.org/abs/2311.12405
- Reference count: 32
- Key outcome: IndoRobusta framework improves LM robustness to code-mixing via adversarial training, with joint training yielding ~5% accuracy gains on code-mixed test sets and ~2% on monolingual test sets.

## Executive Summary
IndoRobusta addresses the vulnerability of language models to code-mixing in Indonesian by introducing a framework for both evaluation and improvement of robustness. The framework consists of IndoRobusta-Blend for generating code-mixed evaluation datasets by translating important words, and IndoRobusta-Shot for adversarial training to improve model robustness. Experiments demonstrate that existing models are significantly less accurate on code-mixed data compared to monolingual Indonesian, with English code-mixing being more robust than local languages due to pre-training corpus bias. Adversarial training, particularly the joint training strategy, substantially improves robustness against code-mixing across multiple language pairs.

## Method Summary
The IndoRobusta framework generates code-mixed sentences by identifying important words in monolingual text using a perturbation ratio (R%) and replacing them with translations via Google Translate. For robustness improvement, adversarial training fine-tunes models on code-mixed datasets using three strategies: code-mix only (fine-tuning on code-mixed data), two-steps (sequential fine-tuning on monolingual then code-mixed), and joint training (simultaneous fine-tuning on both). The framework was evaluated on two Indonesian datasets (SmSA for sentiment, EmoT for emotion) across four embedded languages (English, Sundanese, Javanese, Malay) using five pre-trained language models.

## Key Results
- Existing LMs show significant accuracy drops (delta accuracy) when evaluated on code-mixed datasets compared to monolingual test sets
- English code-mixing demonstrates higher robustness than local languages due to pre-training corpus bias from Indonesian-English prevalence on online platforms
- Adversarial training substantially improves code-mixing robustness, with joint training strategy achieving best results (~5% accuracy improvement on code-mixed test sets)
- Model performance improvements from adversarial training also extend to monolingual test sets (~2% accuracy gains)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Code-mixed sentences are generated by replacing important words with their translations, improving evaluation robustness.
- Mechanism: The framework identifies important words in monolingual sentences using a perturbation ratio (R%) and replaces them with translated words to generate code-mixed sentences.
- Core assumption: Words identified as important through perturbation analysis are effective targets for translation to simulate realistic code-mixing.
- Evidence anchors:
  - [abstract] "generates code-mixed sentences by replacing important words with their translations"
  - [section] "We further define a code-mixing dataset D′ = {(X′₁, Y₁), (X′₂, Y₂), ..., (X′ₙ, Yₙ)} where X′ᵢ denotes the code-mixed sentence."
- Break condition: If the translated words do not maintain semantic meaning, the generated sentences may not accurately represent code-mixing.

### Mechanism 2
- Claim: Adversarial training improves model robustness against code-mixing by exposing models to perturbed data.
- Mechanism: The framework uses adversarial training to fine-tune models on code-mixed datasets, improving their ability to handle mixed-language inputs.
- Core assumption: Models can learn to generalize better on code-mixed data through exposure to augmented datasets.
- Evidence anchors:
  - [abstract] "adversarial training significantly improves code-mixing robustness"
  - [section] "We perform adversarial training to improve the code-mixing robustness of LMs."
- Break condition: If the model overfits to the training perturbations, it may not generalize well to unseen code-mixed inputs.

### Mechanism 3
- Claim: Pre-training corpus bias affects model robustness, with English code-mixing being more robust due to higher frequency in training data.
- Mechanism: Models are more robust to English code-mixing because of the prevalence of Indonesian-English code-mixing in online platforms, reflected in pre-training corpora.
- Core assumption: The frequency of code-mixing patterns in pre-training data influences model robustness to similar patterns in evaluation.
- Evidence anchors:
  - [abstract] "pre-training corpus bias affects the model's ability to better handle Indonesian-English code-mixing"
  - [section] "We conjecture that this is due to the bias from the pre-training corpus, since pre-training corpus is gathered from online platforms, and Indonesian-English code-mixing is particularly common in such platforms."
- Break condition: If the model is exposed to diverse code-mixing patterns during training, the bias might be mitigated.

## Foundational Learning

- Concept: Importance of perturbation ratio in identifying key words for translation.
  - Why needed here: To determine which words are most influential in model predictions and should be targeted for code-mixing.
  - Quick check question: How does changing the perturbation ratio (R) affect the selection of important words and the resulting code-mixed sentences?

- Concept: Adversarial training techniques and their impact on model robustness.
  - Why needed here: To understand how exposure to perturbed data during training improves model performance on similar tasks.
  - Quick check question: What are the differences in model performance when using different adversarial training strategies (e.g., code-mixing only, two-step, joint training)?

- Concept: Bias in pre-training corpora and its influence on model behavior.
  - Why needed here: To recognize how the composition of training data affects model robustness to specific language patterns.
  - Quick check question: How does the frequency of code-mixing patterns in pre-training data correlate with model robustness to those patterns?

## Architecture Onboarding

- Component map: IndoRobusta-Blend -> IndoRobusta-Shot -> Evaluation
- Critical path:
  1. Generate code-mixed dataset using IndoRobusta-Blend.
  2. Evaluate model robustness on the generated dataset.
  3. Apply adversarial training using IndoRobusta-Shot.
  4. Re-evaluate model robustness to assess improvement.
- Design tradeoffs:
  - Balancing perturbation ratio to ensure meaningful code-mixing without losing semantic integrity.
  - Choosing between different adversarial training strategies to optimize robustness and performance.
- Failure signatures:
  - Model performance degrades significantly on code-mixed data, indicating poor generalization.
  - Adversarial training leads to overfitting, with minimal improvement on unseen data.
- First 3 experiments:
  1. Evaluate model robustness on English vs. local language code-mixing to confirm pre-training bias effects.
  2. Test different perturbation ratios (R) to determine optimal settings for code-mixed sentence generation.
  3. Compare adversarial training strategies to identify the most effective approach for improving robustness.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the underlying linguistic factors that make English code-mixing more robust than local language code-mixing in Indonesian?
- Basis in paper: [explicit] The paper observes that models are more robust to English code-mixing compared to local languages, attributing it to pre-training corpus bias.
- Why unresolved: The paper provides a conjecture but doesn't deeply analyze the linguistic properties of code-mixing patterns or how they interact with language model architectures.
- What evidence would resolve it: Detailed linguistic analysis of code-mixing patterns across language pairs, corpus frequency analysis of code-mixing types, and experiments isolating linguistic factors from corpus bias effects.

### Open Question 2
- Question: How does the perturbation ratio threshold (R=0.4) relate to the actual prevalence of code-mixing in natural Indonesian conversations?
- Basis in paper: [inferred] The paper tests multiple perturbation ratios and finds R=0.4 produces the steepest performance decline, but doesn't compare this to real-world code-mixing frequency.
- Why unresolved: The study uses synthetic data generation without validating the perturbation levels against authentic code-mixed text distributions.
- What evidence would resolve it: Corpus analysis of naturally occurring Indonesian code-mixed text to determine typical code-mixing ratios, followed by model robustness testing at these naturally-occurring levels.

### Open Question 3
- Question: How does the IndoRobusta framework generalize to other low-resource languages with complex code-mixing patterns?
- Basis in paper: [inferred] The framework is developed specifically for Indonesian with four L2 languages, but its applicability to other language pairs isn't explored.
- Why unresolved: The paper focuses on Indonesian as a case study without testing the framework's portability to other code-mixing scenarios.
- What evidence would resolve it: Application of the IndoRobusta framework to other language pairs with code-mixing, measuring performance across different language families and code-mixing patterns.

### Open Question 4
- Question: What is the impact of code-mixing robustness on downstream tasks beyond sentiment and emotion classification?
- Basis in paper: [inferred] The paper evaluates robustness only on two classification tasks, leaving open the question of how code-mixing affects other NLP applications.
- Why unresolved: The experiments are limited to sentiment and emotion classification without exploring other task types or domains.
- What evidence would resolve it: Testing the code-mixing robustness framework on a variety of NLP tasks (e.g., question answering, summarization, named entity recognition) and analyzing how different task types are affected by code-mixing.

## Limitations
- Data Generation Quality: Reliance on Google Translate may produce unnatural code-mixing patterns that don't reflect authentic language use.
- Evaluation Scope: Limited to four languages and two classification tasks, potentially missing broader NLP applications.
- Adversarial Training Generalization: Improvements may not transfer to real-world code-mixing scenarios beyond artificially generated test sets.

## Confidence
- High Confidence: Core methodology for generating code-mixed datasets and observation of pre-training corpus bias effects.
- Medium Confidence: Claim that English code-mixing is more robust due to pre-training bias; effectiveness of different adversarial training strategies.
- Low Confidence: Framework's applicability to other language pairs and NLP tasks beyond sentiment/emotion classification.

## Next Checks
1. **Manual Evaluation of Generated Code-Mixed Data**: Conduct human evaluation of the generated code-mixed sentences to assess their naturalness and alignment with authentic code-mixing patterns used by Indonesian speakers.
2. **Cross-Linguistic Transfer Study**: Test the framework's effectiveness on code-mixing involving languages with different typological features (e.g., languages with non-Latin scripts or significantly different grammatical structures).
3. **Real-World Code-Mixed Data Validation**: Evaluate model performance on naturally occurring code-mixed Indonesian text from social media or other authentic sources to verify that improvements from adversarial training translate to real-world scenarios.