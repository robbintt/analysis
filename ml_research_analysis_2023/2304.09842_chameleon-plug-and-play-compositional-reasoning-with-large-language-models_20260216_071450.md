---
ver: rpa2
title: 'Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models'
arxiv_id: '2304.09842'
source_url: https://arxiv.org/abs/2304.09842
tags:
- table
- chameleon
- generator
- module
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Chameleon is a plug-and-play compositional reasoning framework
  that augments large language models (LLMs) with diverse tools to overcome inherent
  limitations. It synthesizes programs to compose various tools (LLMs, vision models,
  web search, Python functions, rule-based modules) and executes them sequentially
  to solve complex reasoning tasks.
---

# Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models

## Quick Facts
- **arXiv ID:** 2304.09842
- **Source URL:** https://arxiv.org/abs/2304.09842
- **Reference count:** 40
- **Key outcome:** Chameleon achieves 86.54% accuracy on ScienceQA and 98.78% on TabMWP, improving state-of-the-art by 11.37% and 17.0% respectively.

## Executive Summary
Chameleon is a plug-and-play compositional reasoning framework that augments large language models (LLMs) with diverse external tools to overcome inherent limitations. It synthesizes natural-language-like programs to compose various tools (LLMs, vision models, web search, Python functions, rule-based modules) and executes them sequentially to solve complex reasoning tasks. Chameleon significantly improves reasoning performance on ScienceQA and TabMWP benchmarks, with GPT-4 as the planner showing more consistent and rational tool selection compared to ChatGPT.

## Method Summary
Chameleon uses an LLM-based planner to generate programs that specify sequences of diverse tools to solve reasoning tasks. The planner, prompted with tool descriptions and usage examples, composes a program in natural language that is then executed sequentially. Each tool processes the query and cached context, updating both for the next tool. The final answer is extracted from the last tool's output. The framework requires no training, relying on in-context learning with prompts for the planner and tool modules.

## Key Results
- Achieves 86.54% accuracy on ScienceQA, improving the best few-shot result by 11.37%
- Attains 98.78% accuracy on TabMWP, a 17.0% improvement over the state of the art
- GPT-4 planner shows more consistent and rational tool selection compared to ChatGPT

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Chameleon improves LLM reasoning by composing diverse external tools through a planner that selects and sequences modules based on the query.
- **Mechanism:** The LLM-based planner generates a natural-language-like program specifying a sequence of tools (e.g., Knowledge Retrieval, Bing Search, Image Captioner, Text Detector, Solution Generator, Answer Generator). Each tool processes the query and cached context, updating both for subsequent tools. The final answer is generated by the last tool in the sequence.
- **Core assumption:** The planner can accurately infer which tools are needed and in what order based on the query and tool descriptions.
- **Evidence anchors:** [abstract]: "Chameleon synthesizes programs to compose various tools... and executes them sequentially to get final answers." [section]: "Prompted by descriptions of each tool and examples of tool usage, the planner can infer an appropriate sequence of tools to compose and execute in order to generate the final response for a user query."
- **Break condition:** If the planner cannot accurately infer tool needs, or if tool execution fails, the compositional reasoning will break down.

### Mechanism 2
- **Claim:** GPT-4 as a planner exhibits more consistent and rational tool selection compared to ChatGPT.
- **Mechanism:** GPT-4 demonstrates better understanding of tool roles and constraints, leading to more consistent program generation and tool usage patterns. It can infer potential constraints from instructions and plan tool sequences more rationally.
- **Core assumption:** GPT-4 has superior reasoning and instruction-following capabilities compared to ChatGPT, enabling better tool planning.
- **Evidence anchors:** [abstract]: "Further studies suggest that using GPT-4 as a planner exhibits more consistent and rational tool selection and is able to infer potential constraints given the instructions, compared to other LLMs like ChatGPT." [section]: "Interestingly, ChatGPT and GPT-4 exhibit different planning behaviors... ChatGPT has a strong bias toward using or not using certain tools... However, GPT-4 acts more objectively and rationally when determining which tool to use or not."
- **Break condition:** If GPT-4's reasoning or instruction-following capabilities are insufficient for the task, or if tool descriptions/constraints are unclear.

### Mechanism 3
- **Claim:** Natural-language-like programs are less error-prone and more user-friendly than domain-specific programs.
- **Mechanism:** By generating programs in natural language that describe tool usage, Chameleon reduces the complexity and error-proneness of program generation compared to generating domain-specific code or commands. This also makes the system more accessible to users without programming experience.
- **Core assumption:** Natural language is less prone to syntax and logical errors than domain-specific programming languages for tool composition.
- **Evidence anchors:** [section]: "Unlike previous work that generates domain-specific programs, Chameleon generates natural-language-like programs, which are less error-prone, easy to debug, user-friendly for those with limited programming experience, and efficiently extendable to using new modules."
- **Break condition:** If the natural language program generation becomes too complex or ambiguous, or if tool descriptions are insufficient for accurate program generation.

## Foundational Learning

- **Concept:** Large Language Models (LLMs) and their capabilities
  - **Why needed here:** Chameleon builds upon LLMs as planners and tool users. Understanding LLM capabilities (e.g., in-context learning, reasoning, tool use) is crucial for understanding Chameleon's approach and limitations.
  - **Quick check question:** What are some key capabilities of LLMs that enable them to be used as planners in Chameleon?

- **Concept:** Tool learning and augmentation
  - **Why needed here:** Chameleon is fundamentally about augmenting LLMs with external tools to overcome their limitations. Understanding how tools are integrated with LLMs and how they enhance reasoning is essential.
  - **Quick check question:** How do external tools help address the inherent limitations of LLMs?

- **Concept:** Compositional reasoning and modular approaches
  - **Why needed here:** Chameleon composes various tools to solve complex reasoning tasks. Understanding compositional reasoning and modular approaches is key to grasping Chameleon's methodology.
  - **Quick check question:** Why is compositional reasoning important for solving complex reasoning tasks, and how does Chameleon achieve it?

## Architecture Onboarding

- **Component map:** Planner (LLM) -> Module Inventory -> Execution Engine -> Answer Generator
- **Critical path:**
  1. Query is received by the planner.
  2. Planner generates a program (tool sequence) based on the query and tool inventory.
  3. Execution engine sequentially executes the program.
  4. Each tool processes the query and cached context, updating both for the next tool.
  5. Final answer is generated by the last tool and extracted by the Answer Generator.
- **Design tradeoffs:**
  - Flexibility vs. Efficiency: Chameleon supports diverse tools but may have higher latency due to tool execution.
  - Generalizability vs. Specialization: Chameleon aims for broad applicability but may not be optimal for specific tasks compared to specialized models.
  - Simplicity vs. Complexity: Natural-language-like programs are simpler but may be less precise than domain-specific programs for complex tasks.
- **Failure signatures:**
  - Planner failure: Generates incorrect or suboptimal tool sequences, leading to wrong answers or inefficient execution.
  - Tool failure: Individual tools fail to execute or produce incorrect outputs, breaking the execution chain.
  - Integration failure: Tools don't integrate well, leading to context loss or incompatible outputs between tools.
- **First 3 experiments:**
  1. Verify planner accuracy: Test the planner's ability to generate correct tool sequences for a set of diverse queries with known optimal tool compositions.
  2. Evaluate tool execution: Test each tool individually to ensure correct functionality and integration with the execution engine.
  3. Benchmark end-to-end performance: Compare Chameleon's performance on a reasoning task against baseline models (e.g., CoT, PoT) to validate improvements.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the performance of Chameleon vary with different LLM base models beyond GPT-3.5 and GPT-4?
- **Basis in paper:** [inferred]
- **Why unresolved:** The paper primarily compares Chameleon using GPT-3.5 (ChatGPT) and GPT-4, but does not explore the performance with other LLM models.
- **What evidence would resolve it:** Conducting experiments with a wider range of LLM models (e.g., LLaMA, PaLM) to compare performance and identify the optimal model for different tasks.

### Open Question 2
- **Question:** What is the impact of varying the temperature parameter on the generated programs' effectiveness and accuracy?
- **Basis in paper:** [inferred]
- **Why unresolved:** The paper sets the temperature to 0 for deterministic generation but does not explore how different temperature values affect the quality and diversity of generated programs.
- **What evidence would resolve it:** Systematic experiments varying the temperature parameter and analyzing the resulting program diversity, execution success rates, and task performance.

### Open Question 3
- **Question:** How does Chameleon's performance scale with an increasing number of available tools in the module inventory?
- **Basis in paper:** [inferred]
- **Why unresolved:** The paper uses a fixed set of tools but does not investigate the relationship between the number of tools and the system's effectiveness across diverse tasks.
- **What evidence would resolve it:** Experiments incrementally adding tools to the inventory and measuring performance on benchmarks to identify optimal tool set sizes and compositions for different task types.

## Limitations
- Heavy reliance on planner's ability to accurately infer tool needs and compose them effectively
- Performance improvements are demonstrated on relatively narrow domains (ScienceQA, TabMWP)
- Limited validation of generalizability to broader problem spaces beyond scientific question answering and mathematical reasoning

## Confidence
- **High Confidence:** The core mechanism of using LLMs to plan tool composition is well-supported by the results on ScienceQA and TabMWP benchmarks.
- **Medium Confidence:** The claim that GPT-4 exhibits more consistent and rational tool selection than ChatGPT is supported by the analysis but could benefit from a more comprehensive evaluation across diverse task types.
- **Low Confidence:** The generalizability of Chameleon to tasks beyond scientific question answering and mathematical reasoning is not thoroughly validated.

## Next Checks
1. **Generalization Test:** Evaluate Chameleon on a broader range of reasoning tasks (e.g., commonsense reasoning, logical inference) to assess its adaptability beyond the ScienceQA and TabMWP domains.
2. **Planner Robustness Analysis:** Conduct a more extensive comparison between GPT-4 and other LLMs as planners across multiple task types to validate the consistency and rationality claims.
3. **Failure Mode Analysis:** Systematically identify and document the types of queries or reasoning scenarios where Chameleon's planner fails to generate optimal tool compositions, and analyze the root causes of these failures.