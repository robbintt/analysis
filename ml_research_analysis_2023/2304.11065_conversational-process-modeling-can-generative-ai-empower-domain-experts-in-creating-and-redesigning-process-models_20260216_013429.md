---
ver: rpa2
title: 'Conversational Process Modeling: Can Generative AI Empower Domain Experts
  in Creating and Redesigning Process Models?'
arxiv_id: '2304.11065'
source_url: https://arxiv.org/abs/2304.11065
tags:
- process
- text
- modelling
- tasks
- chatbots
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a systematic analysis of chatbots for conversational
  process modeling, aiming to evaluate their capabilities in supporting domain experts
  in creating and redesigning process models. The authors identify application scenarios
  along the process life cycle and conduct a literature review, resulting in a taxonomy
  of conversational process modeling applications.
---

# Conversational Process Modeling: Can Generative AI Empower Domain Experts in Creating and Redesigning Process Models?

## Quick Facts
- arXiv ID: 2304.11065
- Source URL: https://arxiv.org/abs/2304.11065
- Reference count: 40
- Primary result: GPT-3 achieves 80% text similarity in task extraction from process descriptions

## Executive Summary
This paper systematically analyzes chatbots for conversational process modeling, evaluating their capabilities in supporting domain experts throughout the process life cycle. The authors develop a taxonomy of conversational process modeling applications and create an evaluation framework using key performance indicators (KPIs) and a test set from the higher education domain. Their findings show that while GPT-3 performs well in extracting tasks from textual process descriptions (achieving 80% text similarity), significant limitations remain in reasoning about task granularity and producing process-ready outputs. The study concludes that chatbots show promise for certain scenarios but require integration with specialized process modeling tools and domain expert verification.

## Method Summary
The authors conducted a literature review to identify application scenarios for conversational process modeling, resulting in a taxonomy of 8 scenarios across the process life cycle. They created a test set of 21 textual process descriptions from 6 domains, each accompanied by multiple BPMN models created by novices and validated by experts. The evaluation method involved using GPT-1, GPT-2, GPT-3, and GPT-3.5 to extract tasks from textual descriptions, then comparing these extracted tasks against ground truth tasks from BPMN models using contextual (BERT) and non-contextual (TF-IDF) vectorizers to calculate similarity metrics.

## Key Results
- GPT-3 achieves 80% text similarity in task extraction from textual process descriptions
- Restricting task name length to 3-5 words increases task count by 1 without decreasing similarity
- Chatbots are ready for "gather information" and "process modeling" scenarios but require human verification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-3 extracts tasks from textual process descriptions with ~80% text similarity.
- Mechanism: Large language model (LLM) parses natural language sentences, identifies task-like phrases, and outputs them in a structured list.
- Core assumption: Task phrases in the source text are sufficiently explicit for the model to identify without external training.
- Evidence anchors:
  - [abstract] "GPT-3 performs best in task extraction from textual process descriptions, achieving an average text similarity of 80%."
  - [section] "GPT3 in average manages to achieve a text similarity of 80%."
  - [corpus] Weak signal: no neighbor papers discuss task extraction metrics directly; corpus shows related chatbot/LLM papers but not BPM-specific extraction.
- Break condition: If task granularity or implicit reasoning is required, similarity drops significantly because the model cannot "read between the lines."

### Mechanism 2
- Claim: Restricting task name length (3–5 words) increases task count without hurting model similarity.
- Mechanism: Shorter prompts reduce ambiguity and force the LLM to produce more discrete, bite-sized task names.
- Core assumption: Task boundaries are clear when described concisely; longer phrases may conflate multiple tasks.
- Evidence anchors:
  - [section] "We tried to coax GPT3 into extracting more tasks by restricting the length of words describing a task, which increased the average number of extracted tasks slightly by 1."
  - [section] Tab. 7 shows that this decreases text similarity (due to stronger paraphrasing) but KPI5 and KPI6 show an increase in number of tasks by one while not decreasing similarity when compared to tasks from the model.
  - [corpus] No direct corpus support; this is an empirical tweak not cited in neighbors.
- Break condition: If tasks are inherently multi-step or require descriptive labels, truncation harms completeness.

### Mechanism 3
- Claim: Current LLMs are ready for "gather information" and "process modelling" chatbot scenarios but require human verification.
- Mechanism: LLM outputs are usable as first drafts; domain experts validate completeness and correctness before integration.
- Core assumption: Domain experts can efficiently review and correct LLM outputs without specialized tooling.
- Evidence anchors:
  - [abstract] "the study also highlights limitations, such as the chatbot's inability to reason about task granularity and the need for domain experts to verify results."
  - [section] "However, the lack of an appropriate, human-readable output format, e.g., a BPMN process model, limits the space of early adopters in a company significantly to experts at the intersection of their domain and computer science."
  - [corpus] Weak: neighbor papers discuss chatbot evaluation and knowledge graphs but not BPM-specific adoption constraints.
- Break condition: If domain experts lack technical literacy or if output verification cost exceeds LLM benefits.

## Foundational Learning

- Concept: Business Process Model and Notation (BPMN)
  - Why needed here: The evaluation dataset and application scenarios are BPMN-centric; understanding BPMN elements (tasks, gateways, events) is required to interpret extraction results.
  - Quick check question: What BPMN element represents a decision point in a process flow?

- Concept: Large Language Models (LLMs) and text similarity metrics
  - Why needed here: Task extraction performance is quantified using contextual (BERT) and non-contextual (TF-IDF) vectorizers with cosine similarity.
  - Quick check question: Which similarity metric would you use to compare two short lists of task names extracted from text?

- Concept: Data augmentation and paraphrasing in NLP
  - Why needed here: The paper discusses augmenting text descriptions to improve extraction robustness and to generate test variations.
  - Quick check question: Why might paraphrasing a process description help a model extract more tasks?

## Architecture Onboarding

- Component map:
  Input: Raw textual process description (unstructured) -> LLM module: Task extraction (GPT-3/3.5) -> NLP module: Vectorizers (BERT, TF-IDF) -> Evaluation engine: KPI computation -> Test harness: Dataset + BPMN models

- Critical path:
  1. Load process description
  2. Run LLM task extraction
  3. Parse LLM output into set of task names
  4. Compare against ground truth task set from BPMN models
  5. Compute KPIs and generate report

- Design tradeoffs:
  - Prompt engineering vs. output format consistency
  - Using contextual vs. non-contextual embeddings for similarity
  - Restricting task length to increase count vs. preserving semantic fidelity

- Failure signatures:
  - Low text similarity (< 60%) → LLM missing or misidentifying tasks
  - High overlap but low set similarity → LLM outputs correct tasks but in wrong granularity
  - Task count far below model tasks → LLM unable to infer implicit tasks

- First 3 experiments:
  1. Run baseline task extraction on all 21 descriptions; record text similarity
  2. Apply 3–5 word restriction; compare task counts and set similarity
  3. Apply 9 data augmentation methods; assess impact on extraction prevalence and similarity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can chatbots be integrated with specialized process modeling tools like SAP Signavio to enhance their capabilities for conversational process modeling?
- Basis in paper: [explicit] The paper suggests that future research should focus on integrating the strong language capabilities of chatbots with specialized capabilities of existing tools such as SAP Signavio.
- Why unresolved: While the paper identifies the need for integration, it does not provide specific details on how this integration can be achieved or what the potential benefits and challenges might be.
- What evidence would resolve it: Studies that demonstrate successful integration of chatbots with process modeling tools, including specific implementation details, performance metrics, and user feedback.

### Open Question 2
- Question: Can chatbots be trained to understand and reason about process model semantics, such as the existence of deadlocks, without relying on specialized process modeling tools?
- Basis in paper: [inferred] The paper mentions that training chatbots with specialized process modeling training sets and semantical targets might be futile, but it does not explore alternative approaches to enabling chatbots to understand process model semantics.
- Why unresolved: The paper does not provide a clear answer on whether chatbots can be trained to understand process model semantics without the aid of specialized tools, and if so, how this can be achieved.
- What evidence would resolve it: Research that investigates different methods for training chatbots to understand process model semantics, including experimental results and comparisons with specialized tools.

### Open Question 3
- Question: What are the potential business impacts and adoption barriers of using chatbots for conversational process modeling in real-world scenarios?
- Basis in paper: [explicit] The paper discusses the potential business impact of chatbots for process modeling, particularly in reducing the time spent on acquiring as-is models. However, it also mentions the lack of an appropriate output format as a limitation for early adopters.
- Why unresolved: The paper does not provide a comprehensive analysis of the potential business impacts and adoption barriers of using chatbots for conversational process modeling in various industries and organizational contexts.
- What evidence would resolve it: Case studies and surveys that examine the adoption and impact of chatbots for process modeling in different industries, including factors influencing adoption, challenges faced, and measurable business outcomes.

## Limitations
- The study lacks publicly available test data and prompts, making exact replication difficult
- Evaluation focuses only on task extraction without assessing complete BPMN model generation
- 80% similarity benchmark doesn't account for task granularity mismatches or implicit task identification

## Confidence
- Task extraction performance (80% similarity): High confidence
- Prompt engineering effectiveness (3-5 word restriction): Medium confidence
- Adoption readiness for domain experts: Low confidence

## Next Checks
1. Replicate the task extraction experiment with a different domain (e.g., healthcare) to test generalizability
2. Conduct a user study measuring domain expert verification time and accuracy across multiple LLM outputs
3. Evaluate chatbot performance on generating complete BPMN models (not just task lists) from textual descriptions