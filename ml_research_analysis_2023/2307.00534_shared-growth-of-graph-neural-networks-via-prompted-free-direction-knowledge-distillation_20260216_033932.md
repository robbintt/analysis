---
ver: rpa2
title: Shared Growth of Graph Neural Networks via Prompted Free-direction Knowledge
  Distillation
arxiv_id: '2307.00534'
source_url: https://arxiv.org/abs/2307.00534
tags:
- knowledge
- freekd
- gnns
- node
- distillation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes FreeKD, a novel free-direction knowledge distillation
  framework for GNNs, which enables two shallower GNNs to learn from each other without
  requiring a deeper well-optimized teacher GNN. The key idea is to dynamically exchange
  useful knowledge between two shallower GNNs via a hierarchical reinforcement learning
  algorithm, which involves node-level and structure-level actions.
---

# Shared Growth of Graph Neural Networks via Prompted Free-direction Knowledge Distillation

## Quick Facts
- arXiv ID: 2307.00534
- Source URL: https://arxiv.org/abs/2307.00534
- Reference count: 40
- Key outcome: FreeKD enables two shallower GNNs to learn from each other without requiring a deeper teacher GNN, achieving performance comparable to or better than traditional KD algorithms

## Executive Summary
This paper proposes FreeKD, a novel free-direction knowledge distillation framework for GNNs that enables two shallower GNNs to learn from each other through hierarchical reinforcement learning. The key innovation is the dynamic exchange of knowledge between peer GNNs without requiring a deeper, well-optimized teacher model. By using a two-level RL policy that makes node-level and structure-level decisions about knowledge transfer, FreeKD achieves significant performance improvements over base GNNs and matches or exceeds traditional KD methods. The framework is further extended to FreeKD++ for multi-view inputs across multiple GNNs.

## Method Summary
FreeKD implements bidirectional knowledge distillation between two shallower GNNs using hierarchical reinforcement learning. The method employs node-level actions to determine which GNN should distill knowledge for each node, and structure-level actions to select which neighborhood structures to propagate. The framework optimizes both GNNs and policy networks jointly through a combined loss function. FreeKD++ extends this approach to multiple GNNs across multiple graph views, enabling cross-view knowledge transfer through graph augmentation techniques.

## Key Results
- FreeKD significantly outperforms base GNNs on five benchmark datasets (Cora, Citeseer, Chameleon, Texas, PPI)
- Performance is comparable to or better than traditional KD algorithms using deeper teacher GNNs
- FreeKD++ enables effective knowledge transfer among multiple shallow GNNs operating on multi-view inputs
- The framework demonstrates robustness across different GNN architectures (GCN, GAT, GraphSAGE)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical reinforcement learning can dynamically decide knowledge transfer directions between two GNNs node-by-node
- Mechanism: Two-level RL policy where node-level actions select which GNN distills to which for each node, and structure-level actions determine which local neighborhood structures to propagate
- Core assumption: Different GNNs perform better on different nodes during training, making dynamic direction selection beneficial
- Evidence anchors: Abstract observation that GNNs exhibit better/worse performance at different nodes; section 3.3.1's use of cross entropy loss and soft labels for node-level state computation
- Break condition: If GNNs have uniform performance across all nodes, dynamic direction selection provides no benefit

### Mechanism 2
- Claim: Exchanging structure-level knowledge via agent-selected neighborhoods improves GNN performance beyond node-level knowledge alone
- Mechanism: After selecting which GNN should distill knowledge for each node, selectively propagates similarity distributions of agent-selected neighborhoods rather than full neighborhoods
- Core assumption: Agent-selected nodes contain more useful knowledge and structure information from these nodes is more reliable than from unselected nodes
- Evidence anchors: Abstract mention of structure-level actions determining which local structures to propagate; section 3.4.3's selective neighborhood subset propagation
- Break condition: If all neighborhood nodes are equally informative, selective propagation provides no advantage

### Mechanism 3
- Claim: FreeKD++ extends the framework to multiple GNNs across multiple input views, enabling cross-view knowledge transfer
- Mechanism: Creates multiple augmented graph views and enables knowledge exchange both within the same view (same-view distillation) and across different views (cross-view distillation)
- Core assumption: Different graph views capture distinct perspectives of the data, and knowledge from multiple GNNs across multiple views can be mutually beneficial
- Evidence anchors: Abstract introduction of FreeKD++ for multi-view inputs; section 3.6's graph augmentation for generating different views
- Break condition: If graph augmentation doesn't create meaningfully different views, cross-view transfer provides no benefit

## Foundational Learning

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: The entire framework operates on GNN architectures and their learned representations
  - Quick check question: What is the difference between mean aggregator and attention-based aggregator in GNNs?

- Concept: Knowledge Distillation
  - Why needed here: The method builds on knowledge distillation principles but extends them to bidirectional transfer between peer models
  - Quick check question: How does traditional knowledge distillation differ from the free-direction approach proposed here?

- Concept: Reinforcement Learning
  - Why needed here: The method uses RL to learn policies for deciding knowledge transfer directions and structures
  - Quick check question: What is the difference between policy-based and value-based RL approaches, and why is policy-based used here?

## Architecture Onboarding

- Component map: Two GNN models (Φ and Ψ) -> Node-level policy network (3-layer MLP) -> Structure-level policy network (3-layer MLP) -> Joint loss function combining cross-entropy, node-level, and structure-level distillation losses

- Critical path: 1) Forward pass through both GNNs to get predictions and losses; 2) Compute node-level states from predictions and losses; 3) Sample node-level actions using policy network; 4) Compute structure-level states from node-level states and neighborhood similarities; 5) Sample structure-level actions using policy network; 6) Update GNN parameters using combined loss; 7) Compute rewards based on performance changes; 8) Update policy network parameters using policy gradient

- Design tradeoffs: Using two GNNs of the same architecture vs different architectures; number of layers in policy networks vs computational cost; amount of neighborhood information to propagate vs noise; single view vs multi-view input for FreeKD++

- Failure signatures: If GNNs converge to identical parameters quickly, they may not be learning from each other effectively; if policy networks output near-uniform distributions, they may not be learning meaningful policies; if performance degrades compared to single GNNs, the distillation mechanism may be introducing harmful noise

- First 3 experiments: 1) Implement basic FreeKD with two identical GNNs (e.g., GCN) on Cora dataset, verify that performance improves over individual GNNs; 2) Test FreeKD with two different GNN architectures (e.g., GCN and GAT) on the same dataset, verify cross-architecture benefits; 3) Implement FreeKD++ with multiple views using DropEdge/DropNode augmentations, verify that multi-view input improves performance further

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FreeKD handle heterophily graphs where connected nodes tend to have different labels, which may challenge the typical homophily assumption in GNNs?
- Basis in paper: [inferred] The paper evaluates FreeKD on standard benchmark datasets but does not explicitly address heterophily scenarios or test on datasets known to have heterophily.
- Why unresolved: The paper's experiments focus on homophilous datasets, leaving open whether the mutual knowledge distillation approach remains effective when node connectivity does not align with label similarity.
- What evidence would resolve it: Empirical evaluation of FreeKD on benchmark datasets with high heterophily (e.g., Squirrel, Chameleon) and comparison with specialized heterophily GNN models would clarify performance in such settings.

### Open Question 2
- Question: Can the hierarchical reinforcement learning mechanism scale effectively to scenarios with more than two GNN models or with different GNN architectures operating simultaneously?
- Basis in paper: [explicit] The paper mentions FreeKD++ as an extension to multiple GNNs but does not provide detailed experiments or analysis on scalability, architectural diversity, or computational complexity in such cases.
- Why unresolved: While the concept of multi-GNN knowledge exchange is introduced, practical limitations such as policy network complexity, reward calculation overhead, and convergence behavior in larger ensembles remain unexplored.
- What evidence would resolve it: Systematic experiments varying the number of GNN models (e.g., 3-10) with different architectures, measuring training time, reward stability, and final performance, would reveal scalability constraints and optimization needs.

### Open Question 3
- Question: What is the impact of FreeKD on the interpretability and explainability of GNN predictions, especially considering the dynamic and bidirectional knowledge transfer?
- Basis in paper: [inferred] The paper focuses on performance metrics like F1 score but does not discuss how the mutual distillation process affects the ability to interpret or explain individual node predictions.
- Why unresolved: The dynamic selection of teacher-student relationships and structure-level knowledge propagation may obscure the decision-making process, making it harder to trace how specific features or neighbors influence final predictions.
- What evidence would resolve it: Analysis using explanation methods (e.g., GNNExplainer, integrated gradients) comparing baseline GNNs and FreeKD-enhanced models would show whether interpretability is preserved, degraded, or improved by the proposed approach.

## Limitations
- Performance heavily depends on proper hyperparameter tuning, particularly balancing node-level and structure-level distillation losses
- Reinforcement learning component may introduce training instability and requires careful reward design
- Method assumes mutual benefit from dynamic knowledge exchange, which may not hold for all graph types or structures
- FreeKD++ extension lacks comprehensive experimental validation for scalability with multiple views and GNN models

## Confidence
- **High confidence**: The core concept of bidirectional knowledge distillation between peer GNNs is technically sound and supported by experimental results
- **Medium confidence**: The hierarchical reinforcement learning approach for selecting knowledge transfer directions is innovative but needs more ablation studies
- **Low confidence**: The scalability claims for FreeKD++ with multiple views and GNNs lack comprehensive experimental validation

## Next Checks
1. **Ablation study on policy network complexity**: Test whether simpler decision mechanisms (e.g., fixed rules based on node-level losses) can achieve comparable performance to the hierarchical RL approach, isolating the contribution of the reinforcement learning component.

2. **Robustness across graph types**: Evaluate FreeKD on graphs with varying characteristics (heterophily, scale, density) to determine whether the method's advantages hold across diverse network structures beyond the benchmark datasets used.

3. **Computational overhead analysis**: Measure the additional training time and memory requirements introduced by the policy networks and multiple forward passes, comparing the trade-off between performance gains and computational cost.