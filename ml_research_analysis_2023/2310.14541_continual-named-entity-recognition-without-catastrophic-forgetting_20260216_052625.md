---
ver: rpa2
title: Continual Named Entity Recognition without Catastrophic Forgetting
arxiv_id: '2310.14541'
source_url: https://arxiv.org/abs/2310.14541
tags:
- entity
- types
- type
- learning
- cner
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles catastrophic forgetting in continual named entity
  recognition (CNER), where models struggle to learn new entity types without forgetting
  previously learned ones. The authors propose a pooled feature distillation loss
  that balances retaining old entity knowledge and learning new types, and a confidence-based
  pseudo-labeling strategy to handle the semantic shift problem where old entity types
  are collapsed into the non-entity type.
---

# Continual Named Entity Recognition without Catastrophic Forgetting

## Quick Facts
- arXiv ID: 2310.14541
- Source URL: https://arxiv.org/abs/2310.14541
- Reference count: 28
- Primary result: Achieves 6.3% and 8.0% improvements in Micro and Macro F1 scores respectively across ten CNER settings on three datasets

## Executive Summary
This paper addresses catastrophic forgetting in continual named entity recognition (CNER) by proposing a novel method called CPFD that combines pooled feature distillation with confidence-based pseudo-labeling. The method tackles two key challenges: preserving knowledge of previously learned entity types while learning new ones, and handling the semantic shift problem where old entity types collapse into the non-entity type. CPFD achieves significant performance improvements over state-of-the-art approaches across multiple CNER settings.

## Method Summary
CPFD employs a BERT-base-cased encoder with a fully-connected classifier, training with a combined loss function that includes classification loss, KL divergence, and pooled feature distillation. The method uses confidence-based pseudo-labeling with entropy thresholds to generate reliable labels for previously learned entity types, while adaptive re-weighting balances the distribution of new and old entity types during training. The pooled feature distillation loss preserves linguistic knowledge by aggregating attention weights across sequence dimensions, allowing the model to retain core linguistic patterns while adapting to new entity types.

## Key Results
- Average improvement of 6.3% in Micro F1 scores across ten CNER settings
- Average improvement of 8.0% in Macro F1 scores across ten CNER settings
- Significant performance gains over state-of-the-art methods on CoNLL2003, I2B2, and OntoNotes5 datasets
- Effective mitigation of catastrophic forgetting in all tested CNER configurations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The pooled feature distillation loss preserves linguistic knowledge while allowing plasticity by aggregating attention weights across sequence dimensions.
- Mechanism: Instead of forcing exact matching of attention weights, the method pools across sequence dimensions, allowing the model to retain core linguistic patterns while adapting to new entity types.
- Core assumption: Attention weights from PLMs encode linguistic knowledge critical for NER (coreference, syntax), and this knowledge can be partially preserved while allowing adaptation.
- Evidence anchors:
  - [abstract] "These features are grounded in the attention weights learned by PLMs, capturing crucial linguistic knowledge necessary for the NER task, including coreference and syntax information"
  - [section] "Recent studies (Clark et al., 2019) suggest that attention weights learned by PLMs can encapsulate rich linguistic knowledge, including coreference and syntactical information, both critical to NER"
- Break condition: If attention weights don't capture task-relevant linguistic knowledge, or if the pooling operation destroys too much information to be useful.

### Mechanism 2
- Claim: Confidence-based pseudo-labeling reduces label noise by only accepting predictions where the old model's entropy is below a type-specific median threshold.
- Mechanism: For each non-entity token, the old model's prediction is used as pseudo-label only if its entropy is below the median entropy for that particular entity type, filtering out uncertain predictions.
- Core assumption: Entropy is a reliable measure of prediction uncertainty, and median entropy provides a reasonable confidence threshold that adapts to each entity type's difficulty.
- Evidence anchors:
  - [abstract] "we employ entropy as a measure of uncertainty and the median entropy as a confidence threshold, retaining only those pseudo labels where the old model exhibits sufficient confidence"
- Break condition: If entropy doesn't correlate well with actual prediction quality, or if the median-based threshold is inappropriate for the data distribution.

### Mechanism 3
- Claim: Adaptive re-weighting type-balanced learning addresses the imbalance between new and old entity types after pseudo-labeling by assigning higher weights to under-represented types.
- Mechanism: Tokens belonging to old entity types receive weight 0.5 + sigmoid(N_old/N_new), while new entity type tokens receive weight 1.0, balancing the training objective.
- Core assumption: The imbalance between new and old entity types after pseudo-labeling causes classifier bias, and the sigmoid function provides appropriate scaling.
- Evidence anchors:
  - [abstract] "we introduce an adaptive re-weighting type-balanced learning strategy to handle the issue of biased type distribution"
- Break condition: If the imbalance isn't severe enough to warrant weighting, or if the sigmoid scaling doesn't appropriately balance the types.

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: The paper addresses catastrophic forgetting as the primary challenge in continual NER
  - Quick check question: What happens to a neural network's performance on old tasks when trained on new tasks without any regularization?

- Concept: Attention mechanisms in transformers
  - Why needed here: The method relies on attention weights from PLMs to preserve linguistic knowledge
  - Quick check question: What information do attention weights in transformer models typically encode?

- Concept: Entropy as uncertainty measure
  - Why needed here: The confidence-based pseudo-labeling uses entropy to filter uncertain predictions
  - Quick check question: How does entropy relate to prediction confidence in probability distributions?

## Architecture Onboarding

- Component map:
  PLM encoder (BERT-base-cased) -> attention weight extraction -> pooled feature distillation
  Classifier layer -> confidence-based pseudo-labeling -> adaptive re-weighting
  Loss functions: classification + KL divergence + pooled feature distillation

- Critical path:
  1. Load old model and extract attention weights
  2. Generate pseudo-labels with confidence filtering
  3. Compute adaptive weights for type balancing
  4. Train new model with combined loss

- Design tradeoffs:
  - Strict vs. relaxed feature distillation (LFD vs LPFD vs LPFD-lax)
  - Confidence threshold selection (median entropy vs. fixed threshold)
  - Weighting scheme for type balancing (sigmoid vs. other functions)

- Failure signatures:
  - Performance degradation on old entity types -> insufficient feature distillation
  - Poor performance on new entity types -> excessive feature distillation
  - High variance across runs -> unstable pseudo-labeling
  - Slow convergence -> inappropriate weighting scheme

- First 3 experiments:
  1. Ablation study: Compare LPFD vs LFD vs LPFD-lax on a single CNER setting
  2. Pseudo-labeling effectiveness: Compare CPL vs VPL on the same setting
  3. Type balancing impact: Train with and without ART on an imbalanced dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed CPFD method compare to other continual learning approaches that use replay buffers or exemplars in terms of catastrophic forgetting mitigation?
- Basis in paper: [inferred] The paper mentions memory-based methods as a category of continual learning approaches and states that CPFD utilizes the old model in two significant ways to address challenges in CNER, but does not directly compare to replay buffer-based methods.
- Why unresolved: The paper focuses on comparing CPFD to other CNER-specific methods and general continual learning methods adapted to CNER, but does not explore comparison with replay buffer-based approaches.
- What evidence would resolve it: Conducting experiments comparing CPFD to replay buffer-based methods on the same CNER settings and datasets used in the paper would provide insights into the effectiveness of CPFD relative to other approaches.

### Open Question 2
- Question: How does the performance of CPFD vary with different pooling strategies in the pooled features distillation loss?
- Basis in paper: [explicit] The paper mentions that the proposed pooling-based framework facilitates the formulation of a more flexible feature distillation loss, but does not explore the impact of different pooling strategies on performance.
- Why unresolved: While the paper introduces the concept of pooling and its benefits, it does not investigate how different pooling strategies (e.g., max pooling, average pooling) might affect the performance of CPFD.
- What evidence would resolve it: Conducting experiments with different pooling strategies in the pooled features distillation loss and comparing the results to the current approach would provide insights into the optimal pooling strategy for CPFD.

### Open Question 3
- Question: How does the confidence threshold in the confidence-based pseudo-labeling strategy impact the performance of CPFD?
- Basis in paper: [explicit] The paper mentions that the confidence-based pseudo-labeling strategy employs entropy as a measure of uncertainty and the median entropy as the confidence threshold, but does not explore the impact of different threshold values on performance.
- Why unresolved: While the paper introduces the concept of using a confidence threshold to reduce label noise, it does not investigate how different threshold values might affect the performance of CPFD.
- What evidence would resolve it: Conducting experiments with different confidence threshold values in the confidence-based pseudo-labeling strategy and comparing the results to the current approach would provide insights into the optimal threshold value for CPFD.

## Limitations

- The effectiveness of attention weights as proxies for linguistic knowledge remains an assumption without direct empirical validation
- The entropy-based confidence threshold lacks comparison with alternative uncertainty measures or threshold selection strategies
- The adaptive re-weighting formula appears heuristic rather than derived from theoretical principles

## Confidence

**High Confidence**: The overall framework design and its core contribution - addressing semantic shift through confidence-based pseudo-labeling combined with feature distillation - is well-grounded. The empirical results showing 6.3% and 8.0% improvements in Micro and Macro F1 scores across three datasets provide strong evidence for the method's effectiveness.

**Medium Confidence**: The specific mechanisms for each component have reasonable theoretical justification but limited direct empirical validation. The pooled feature distillation's effectiveness depends on attention weights preserving linguistic knowledge; the confidence threshold approach assumes median entropy is optimal; and the adaptive weighting assumes the sigmoid formula appropriately balances type distributions.

**Low Confidence**: The exact implementation details that would be critical for reproduction, particularly the dimensionality and aggregation method for pooled feature distillation, and the precise calculation of median entropy thresholds per entity type.

## Next Checks

1. **Mechanism Validation**: Conduct an ablation study comparing CPFD against variants where: (a) attention weights are replaced with random noise to test if feature preservation is necessary, (b) fixed confidence thresholds replace median entropy thresholds, and (c) uniform weighting replaces adaptive re-weighting. This would isolate which components contribute most to performance gains.

2. **Uncertainty Measure Comparison**: Replace entropy-based confidence filtering with alternative uncertainty measures (e.g., prediction margin, Monte Carlo dropout variance) and compare pseudo-label quality and final performance. This would validate whether entropy is the optimal choice for this application.

3. **Distribution Analysis**: Analyze the token distribution across entity types before and after pseudo-labeling in a representative CNER setting. Quantify the severity of type imbalance and measure how closely the adaptive weighting restores balance compared to the theoretical ideal.