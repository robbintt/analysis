---
ver: rpa2
title: Seed Kernel Counting using Domain Randomization and Object Tracking Neural
  Networks
arxiv_id: '2308.05846'
source_url: https://arxiv.org/abs/2308.05846
tags:
- seed
- object
- tracking
- kernels
- kernel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a low-cost seed kernel counter using YOLOv8
  and object tracking algorithms (StrongSORT and ByteTrack) to address the high cost
  of mechanized seed counting equipment. The system uses synthetic imagery generated
  through domain randomization to train YOLOv8 for detecting seed kernels in videos
  captured by a smartphone.
---

# Seed Kernel Counting using Domain Randomization and Object Tracking Neural Networks

## Quick Facts
- arXiv ID: 2308.05846
- Source URL: https://arxiv.org/abs/2308.05846
- Reference count: 28
- Primary result: Proposed system achieves 95.2% accuracy for Soy and 93.2% for Wheat using StrongSORT, and 96.8% for Soy and 92.4% for Wheat using ByteTrack.

## Executive Summary
This paper addresses the high cost of mechanized seed kernel counting by proposing a low-cost system using synthetic imagery and object tracking neural networks. The approach leverages YOLOv8 trained on domain-randomized synthetic images to detect seed kernels in smartphone-captured videos, with StrongSORT and ByteTrack algorithms tracking individual seeds to enable accurate counting. Experimental results demonstrate that this method achieves high accuracy for soy and wheat seed counting while significantly reducing the need for expensive equipment and manual labeling.

## Method Summary
The proposed system uses domain randomization to generate synthetic seed kernel images for training YOLOv8, eliminating the need for manual labeling of real seed images. The trained YOLOv8 model detects seeds in videos captured at various frame rates using a smartphone camera setup with a custom hopper. StrongSORT and ByteTrack object tracking algorithms then assign unique IDs to each detected seed and track them across frames, with counting performed by tallying IDs that cross a defined region of interest. The approach was validated on soy and wheat seeds, comparing tracking algorithm performance across different frame rates.

## Key Results
- StrongSORT achieved 95.2% accuracy for Soy and 93.2% for Wheat seed counting
- ByteTrack achieved 96.8% accuracy for Soy and 92.4% for Wheat seed counting
- Lower frame rates (30 fps) provided better counting accuracy than higher frame rates (60/120 fps) due to reduced trajectory ambiguity when seeds touch
- Synthetic imagery proved sufficient for training YOLOv8 without requiring real labeled seed images

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain randomization allows YOLOv8 to generalize from synthetic seed images to real seed videos.
- Mechanism: Synthetic images generated via domain randomization introduce controlled variations (rotation, flipping, noise, overlap) that simulate real-world variability. YOLOv8 trained on this synthetic dataset learns robust feature representations applicable to real seed videos without needing manually labeled real images.
- Core assumption: The synthetic image distribution sufficiently covers the variability in real seed videos (lighting, orientation, clustering, occlusion).
- Evidence anchors:
  - [abstract] "We demonstrate that the use of synthetic imagery serves as a feasible substitute to train neural networks for object tracking..."
  - [section IV] "Synthetic image datasets are created for the seed types of soy and wheat... each dataset consists of 200 images... with each image containing between 25 and 50 seed kernels overlaid on a light background..."
  - [corpus] Weak: No direct neighbor evidence on domain randomization for seed counting, but general DR literature supports this approach.

### Mechanism 2
- Claim: Object tracking algorithms (StrongSORT/ByteTrack) resolve individual seed identities across video frames to enable accurate counting.
- Mechanism: YOLOv8 detects seeds in each frame; StrongSORT/ByteTrack assign unique IDs to each detected seed and track these IDs across frames using appearance and motion cues. Counting is performed by tallying IDs that cross a defined region of interest.
- Core assumption: Each seed maintains a consistent trajectory and appearance features across frames, allowing reliable ID association.
- Evidence anchors:
  - [section V.A] "StrongSORT algorithm... is a two-branch framework consisting of an Appearance branch and a Motion branch... uses the NSA Kalman Filter algorithm..."
  - [section V.B] "ByteTrack algorithm... leverages bounding boxes at all confidence levels... uses Kalman Filter to predict the position... and matches with actual detections..."
  - [section VI.C] "Any seed kernel (track with unique ID) that crosses the RoI is accounted to be one seed kernel."
  - [corpus] Weak: Neighbor papers show similar tracking pipelines but not specific to seed kernels.

### Mechanism 3
- Claim: Lower frame rates (30 fps) improve counting accuracy compared to higher frame rates (60/120 fps) for this seed counting task.
- Mechanism: At lower frame rates, seed kernels have more distinct motion between frames, reducing trajectory ambiguity and ID switches. Higher frame rates capture more subtle motion changes, increasing tracking errors when seeds touch or cluster.
- Core assumption: The motion dynamics of seed kernels are better resolved at moderate temporal resolution.
- Evidence anchors:
  - [section VI.C] "It is observed that the performance of the object tracking algorithms improves as the frame rate increases... However... the key issue faced by the algorithms in the video is sudden changes in trajectory due to the seed kernels touching one another..."
  - [section VI.C] "From the results... it is observed that the seed count is most accurate on videos captured at a frame rate of 30..."
  - [corpus] Weak: No neighbor evidence on optimal frame rates for seed counting; inference based on tracking literature.

## Foundational Learning

- Concept: Domain randomization
  - Why needed here: Enables training YOLOv8 without large labeled real seed datasets, lowering data collection cost.
  - Quick check question: What types of variations should synthetic images include to cover real seed scenarios?

- Concept: Object tracking fundamentals (ID assignment, appearance/motion matching)
  - Why needed here: Understanding how StrongSORT/ByteTrack maintain seed identities across frames is critical for debugging counting errors.
  - Quick check question: How does Kalman filtering help predict seed positions between frames?

- Concept: Intersection over Union (IoU) and precision/recall metrics
  - Why needed here: These metrics evaluate YOLOv8 detection quality, which directly impacts tracking accuracy.
  - Quick check question: If IoU threshold is increased, what happens to precision and recall?

## Architecture Onboarding

- Component map:
  Synthetic image generator (domain randomization) → YOLOv8 training → Seed detection → StrongSORT/ByteTrack tracking → ROI-based counting → Accuracy metrics

- Critical path:
  YOLOv8 detection quality → Object tracking stability → Counting accuracy

- Design tradeoffs:
  - Synthetic data vs. real labeled data: Synthetic lowers cost but risks domain mismatch.
  - Frame rate choice: Lower fps reduces trajectory ambiguity but may miss fast-moving seeds.
  - Tracking algorithm choice: StrongSORT vs ByteTrack trade-offs in handling occlusions and low-confidence detections.

- Failure signatures:
  - Systematic undercounting → likely seed clustering causing ID merges.
  - Overcounting → ID switches or duplicate tracks.
  - Low detection precision → synthetic-real domain gap.

- First 3 experiments:
  1. Generate synthetic dataset with increased seed overlap and test YOLOv8 detection on clustered real seeds.
  2. Compare StrongSORT vs ByteTrack on a video with known ground truth seed count to isolate tracking algorithm impact.
  3. Vary frame rate systematically (15, 30, 60 fps) on identical seed flow to confirm optimal fps empirically.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed system perform in real-world conditions with varying lighting and environmental factors?
- Basis in paper: [inferred] The paper mentions the use of synthetic imagery generated through domain randomization to train the YOLOv8 model, but does not discuss the system's performance in real-world conditions.
- Why unresolved: The paper focuses on the accuracy of the system in controlled conditions and does not provide information on its performance in real-world scenarios with varying lighting and environmental factors.
- What evidence would resolve it: Testing the system in real-world conditions with varying lighting and environmental factors, and comparing the results with the controlled experiment.

### Open Question 2
- Question: Can the system be adapted to count seed kernels of other crop types beyond Soy and Wheat?
- Basis in paper: [explicit] The paper demonstrates the system's performance on Soy and Wheat seed kernels but does not discuss its applicability to other crop types.
- Why unresolved: The paper does not provide information on the system's adaptability to count seed kernels of other crop types beyond Soy and Wheat.
- What evidence would resolve it: Testing the system on seed kernels of other crop types and evaluating its performance in terms of accuracy and reliability.

### Open Question 3
- Question: How does the proposed system compare to existing seed kernel counting methods in terms of cost, accuracy, and ease of use?
- Basis in paper: [explicit] The paper highlights the high cost of existing mechanized seed kernel counters and proposes a low-cost alternative using YOLOv8 and object tracking algorithms. However, it does not provide a direct comparison with existing methods.
- Why unresolved: The paper does not provide a direct comparison with existing seed kernel counting methods in terms of cost, accuracy, and ease of use.
- What evidence would resolve it: Conducting a comparative study of the proposed system with existing seed kernel counting methods in terms of cost, accuracy, and ease of use.

## Limitations
- Synthetic-to-Real Domain Gap: The approach relies entirely on synthetic images for training without validating YOLOv8 performance on real seed images, creating uncertainty about generalization to different seed varieties or environmental conditions.
- Ground Truth Reliability: The counting accuracy results depend on the ground truth seed counts being accurate, but the paper doesn't detail how ground truth was established or whether multiple annotators were used.
- Single Camera Setup: The proposed method uses a specific hopper and smartphone camera configuration, and performance may vary significantly with different camera angles, lighting conditions, or seed flow rates.

## Confidence

**High Confidence**: The mechanism of using object tracking algorithms (StrongSORT/ByteTrack) to count seeds across video frames is well-established and the implementation details are clearly described.

**Medium Confidence**: The domain randomization approach for generating synthetic training data is theoretically sound and supported by general computer vision literature, but lacks direct validation with real seed images in this specific application.

**Medium Confidence**: The observed improvement in counting accuracy at 30 fps versus higher frame rates is supported by the experimental results, though the explanation for why this occurs could benefit from additional analysis of tracking failures at different frame rates.

## Next Checks

1. **Cross-Domain Validation**: Test YOLOv8 on a small set of real seed images (even unlabeled) to assess domain gap. Capture images of actual soy and wheat seeds under various lighting conditions and compare detection performance to synthetic-trained model predictions.

2. **Tracking Algorithm Comparison on Controlled Video**: Create a video with a known, fixed number of seeds (e.g., 10 seeds) moving through the hopper with controlled trajectories. Run both StrongSORT and ByteTrack to identify which algorithm handles specific failure modes (occlusions, close passes) better.

3. **Frame Rate Optimization Study**: Systematically vary frame rate (15, 30, 60, 120 fps) on identical seed flows and analyze tracking metrics (ID switches, track fragmentation) alongside counting accuracy to identify the optimal balance between temporal resolution and tracking stability.