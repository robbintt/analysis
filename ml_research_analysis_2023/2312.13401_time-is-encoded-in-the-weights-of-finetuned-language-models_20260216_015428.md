---
ver: rpa2
title: Time is Encoded in the Weights of Finetuned Language Models
arxiv_id: '2312.13401'
source_url: https://arxiv.org/abs/2312.13401
tags:
- time
- vectors
- performance
- each
- year
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates temporal misalignment in language models
  across multiple domains, tasks, and time scales. The authors demonstrate that performance
  degrades linearly on a yearly scale but exhibits seasonal patterns at a monthly
  level.
---

# Time is Encoded in the Weights of Finetuned Language Models

## Quick Facts
- arXiv ID: 2312.13401
- Source URL: https://arxiv.org/abs/2312.13401
- Authors: 
- Reference count: 12
- Primary result: Time vectors created by finetuning and subtracting pretrained weights can improve model performance on corresponding time periods, and interpolation between these vectors enables adaptation to intervening times without additional training.

## Executive Summary
This paper investigates temporal misalignment in language models, demonstrating that performance degrades linearly over years but shows seasonal patterns monthly. The authors introduce "time vectors" - the difference between finetuned model weights on specific time periods and pretrained weights - showing these vectors are organized in a temporal manifold. By interpolating between time vectors, they can improve performance on intervening and future time periods without additional training. They also show that task analogies using unlabeled data from target times can further improve downstream task performance on future years.

## Method Summary
The method involves finetuning pretrained T5 models (small, large, 3B) on time-stratified datasets (WMT, Twitter, NewsSum, PoliAff) for single time periods, then creating time vectors by subtracting pretrained weights from finetuned weights. These time vectors are analyzed for temporal structure using cosine similarity and UMAP visualization. The authors then interpolate between adjacent time vectors to create models for intervening periods, and use task analogies combining language model time vectors with task-specific vectors to improve future performance.

## Key Results
- Performance degradation follows a linear pattern on yearly scales but exhibits seasonal patterns at monthly resolution
- Time vectors are organized in a manifold that reflects temporal variation, with cosine similarity between vectors correlating with performance degradation
- Interpolating between time vectors improves performance on intervening and future time periods without additional training
- Task analogies using unlabeled data from target times can improve downstream task performance on future years

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Time vectors encode temporal adaptation directions in weight space that improve performance on text from the corresponding time period.
- Mechanism: By finetuning a pretrained language model on data from a single time period and subtracting the pretrained weights, we obtain a vector that specifies a direction in weight space improving performance on text from that time. Adding this vector back to the pretrained model adapts it to that time period.
- Core assumption: The temporal information causing misalignment is captured in the parameter differences between time-specific and pretrained models.
- Evidence anchors:
  - [abstract] "Time vectors are created by finetuning a language model on data from a single time (e.g., a year or month), and then subtracting the weights of the original pretrained model. This vector specifies a direction in weight space that, as our experiments show, improves performance on text from that time period."
  - [section] "Time vectors are an extension of task vectors (Ilharco et al., 2023) to the time domain. Given the weights of the pretrained model, θpre and those of the model finetuned on data from only a single time period t, θt, a time vector τt = θt − θpre."
  - [corpus] Weak evidence - no directly relevant corpus papers found.
- Break condition: If the temporal misalignment cannot be captured by parameter differences (e.g., if it's purely contextual or requires architectural changes), this mechanism would fail.

### Mechanism 2
- Claim: Interpolating between time vectors enables adaptation to intervening time periods without additional training.
- Mechanism: Since time vectors corresponding to adjacent time periods are positioned closer together in weight space, interpolating between them with appropriate weights creates a vector that adapts the model to times between the original periods.
- Core assumption: The structure of time vectors in weight space reflects temporal relationships, allowing linear interpolation to work for temporal adaptation.
- Evidence anchors:
  - [abstract] "Using this structure, we interpolate between time vectors to induce new models that perform better on intervening and future time periods, without any additional training."
  - [section] "We use this structure of time vectors to induce models that generalize better to data from new time periods. By interpolating between two time vectors, we discover vectors that, when applied to the pretrained model, improve performance on intervening months or years (§4.3)."
  - [corpus] Weak evidence - no directly relevant corpus papers found.
- Break condition: If the temporal structure in weight space is non-linear or if temporal misalignment involves factors not captured by weight space, interpolation would fail.

### Mechanism 3
- Claim: Task analogies using unlabeled data from target times can improve performance on future time periods.
- Mechanism: By combining a task-specific time vector with analogous time vectors derived from language models finetuned on unlabeled data from target times, we can adapt task models to future periods without labeled data.
- Core assumption: The temporal structure captured in language model time vectors is similar to that in task-specific vectors, enabling transfer across domains.
- Evidence anchors:
  - [abstract] "The authors also show that task analogies using unlabeled data from target times can further improve downstream task performance on future years."
  - [section] "We can also generalize to a future time period j with analogy arithmetic... This involves combining a task-specific time vector with analogous time vectors derived from finetuned language models (τ LM j)."
  - [corpus] Weak evidence - no directly relevant corpus papers found.
- Break condition: If the temporal patterns in task-specific data differ significantly from those in general language data, analogies would fail.

## Foundational Learning

- Concept: Linear interpolation in high-dimensional parameter space
  - Why needed here: The core technique relies on interpolating between weight vectors to create new models
  - Quick check question: What is the formula for linear interpolation between two vectors v1 and v2 with weight α?
- Concept: Vector arithmetic for model editing
- Concept: Time series analysis and temporal misalignment
  - Why needed here: Understanding how performance degrades over time is fundamental to the problem being solved
  - Quick check question: What is temporal misalignment in language models?

## Architecture Onboarding

- Component map:
  Pretrained T5 models (small, large, 3B) -> Time-stratified datasets (WMT, Twitter, NewsSum, PoliAff) -> LoRA adapters for efficient finetuning -> Vector arithmetic operations (subtraction, interpolation, addition) -> Evaluation pipeline for multiple tasks

- Critical path:
  1. Load pretrained model
  2. Finetune on single time period data
  3. Subtract pretrained weights to get time vector
  4. Perform vector arithmetic (interpolation, analogy)
  5. Add result to pretrained model
  6. Evaluate on target time period

- Design tradeoffs:
  - Using LoRA vs full finetuning: LoRA is more efficient but requires merging weights for vector operations
  - Linear vs non-linear interpolation: Linear is simpler but may not capture complex temporal patterns
  - Single time vs multi-time models: Single time vectors are simpler but require arithmetic for new times

- Failure signatures:
  - No correlation between cosine similarity of time vectors and performance degradation
  - Interpolation doesn't improve performance on intervening times
  - Task analogies don't improve performance on future times
  - Time soups perform worse than single time models

- First 3 experiments:
  1. Create year-vectors for WMT LM task and verify they improve performance on corresponding years
  2. Interpolate between adjacent year-vectors and test on intervening years
  3. Create language model time vectors and task-specific time vectors, then test analogy arithmetic for future adaptation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the linear degradation of model performance over years extend to other types of temporal data beyond the domains tested in this paper?
- Basis in paper: [explicit] The paper demonstrates linear degradation across multiple domains and tasks, but only within specific datasets like news articles and Twitter data.
- Why unresolved: The study focuses on specific datasets, and there is no mention of testing the model on other types of temporal data such as financial records or medical data.
- What evidence would resolve it: Testing the model on a broader range of temporal datasets and observing whether the linear degradation pattern holds.

### Open Question 2
- Question: Can the method of interpolating between time vectors be generalized to improve model performance on tasks that require understanding of long-term temporal dependencies?
- Basis in paper: [inferred] The paper shows that interpolation between time vectors can improve performance on intervening and future time periods, but it does not explore long-term temporal dependencies.
- Why unresolved: The experiments focus on short-term temporal variations, and there is no exploration of how the method performs with tasks that require understanding of longer time scales.
- What evidence would resolve it: Applying the interpolation method to tasks with long-term dependencies and measuring the improvement in model performance.

### Open Question 3
- Question: How do the seasonal patterns observed in monthly degradation translate to other cyclical phenomena, such as economic cycles or seasonal consumer behavior?
- Basis in paper: [explicit] The paper identifies seasonal patterns in monthly degradation, but these are observed within the context of news and Twitter data.
- Why unresolved: The study does not extend the analysis to other cyclical phenomena, leaving the applicability of these patterns to different domains uncertain.
- What evidence would resolve it: Analyzing model performance on datasets representing other cyclical phenomena and comparing the observed patterns to those in the paper.

## Limitations

- The study focuses primarily on English language data from specific sources, limiting generalizability to other languages and cultural contexts
- The vector arithmetic approach assumes additive compositionality in weight space, which may not capture complex temporal dynamics
- The linear interpolation assumption may not hold for all temporal patterns, particularly non-linear seasonal effects

## Confidence

**High Confidence**: The existence of temporal misalignment in language models (demonstrated through consistent performance degradation over time) and the basic methodology of creating time vectors through finetuning and subtraction.

**Medium Confidence**: The effectiveness of linear interpolation between time vectors for intervening periods and the organization of time vectors in a meaningful temporal manifold. While results show improvement, the underlying assumptions about linearity in weight space remain partially validated.

**Low Confidence**: The cross-domain transfer capability of task analogies between language models and task-specific models, and the robustness of these findings across diverse languages and cultural contexts.

## Next Checks

1. **Non-linear interpolation validation**: Test spline or polynomial interpolation methods against linear interpolation to determine if non-linear temporal patterns exist in the weight space structure.

2. **Cross-linguistic generalization**: Replicate the core experiments using multilingual datasets (e.g., mBERT, XLM-R) to validate whether temporal encoding generalizes across languages with different temporal expressions and cultural contexts.

3. **Long-range temporal extrapolation**: Extend interpolation experiments to predict time vectors for periods beyond the available training data (e.g., interpolating to 2022-2023 when training data ends at 2021) and evaluate performance degradation rates.