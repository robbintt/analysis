---
ver: rpa2
title: 'Uncertainty in Automated Ontology Matching: Lessons Learned from an Empirical
  Experimentation'
arxiv_id: '2310.11723'
source_url: https://arxiv.org/abs/2310.11723
tags:
- ontology
- matching
- correspondences
- alignment
- logmap
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study examines uncertainty in automated ontology matching for
  data integration, focusing on aligning heterogeneous global indicators across spatial
  and temporal dimensions. Using LogMap and AML tools, experiments on 10 real-world
  dataset pairs reveal high error rates in fully automated matching, with precision,
  recall, and F-measure values showing significant variability.
---

# Uncertainty in Automated Ontology Matching: Lessons Learned from an Empirical Experimentation

## Quick Facts
- arXiv ID: 2310.11723
- Source URL: https://arxiv.org/abs/2310.11723
- Reference count: 40
- Primary result: Fully automated ontology matching tools exhibit high error rates and significant variability, even for relatively simple real-world dataset pairs.

## Executive Summary
This study empirically evaluates uncertainty in automated ontology matching for data integration, focusing on aligning heterogeneous global indicators across spatial and temporal dimensions. Using LogMap and AML tools, experiments on 10 real-world dataset pairs reveal that fully automated matching produces high error rates with significant variability in precision, recall, and F-measure. Manual evaluation and disambiguation techniques improve alignment quality but cannot fully eliminate false positives and negatives. The results highlight the unreliability of fully automated matching and suggest that semi-supervised approaches may be more practical for critical applications.

## Method Summary
The study evaluates uncertainty in automated ontology matching by converting 10 pairs of real-world CSV datasets to OWL ontologies, then performing automatic matching using LogMap and AML tools. The alignment quality is assessed using standard metrics (precision, recall, F-measure, overall, and ambiguity degree) against manually created reference alignments. The researchers apply alignment disambiguation and trimming techniques to manage uncertainty and compare results across different tools and approaches.

## Key Results
- Fully automated matching produces high error rates with significant variability across different dataset pairs
- Precision, recall, and F-measure values show substantial fluctuations between matching attempts
- Manual evaluation and disambiguation improve but cannot fully eliminate false positives and negatives
- Granularity differences between ontologies (e.g., countries vs. sub-countries) lead to incorrect equivalence correspondences

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Automated ontology matching tools fail to resolve mismatches caused by differing ontology granularity.
- Mechanism: When ontologies contain entities at different levels of detail (e.g., countries vs. sub-countries), the tools incorrectly assign equivalence relationships instead of subsumption, because they lack contextual hierarchy understanding.
- Core assumption: The matching algorithm relies primarily on lexical and structural similarity without semantic depth to distinguish granularity differences.
- Evidence anchors:
  - [abstract] "experiments on 10 real-world dataset pairs reveal high error rates in fully automated matching, with precision, recall, and F-measure values showing significant variability."
  - [section] "Current ontology matching tools face many difficulties when one ontology is more detailed or more general than the other... Ontology matching tools cannot identify such subsumption correspondences between entities."
  - [corpus] Weak: Corpus does not contain direct examples of granularity mismatches in ontology matching.
- Break condition: If semantic matching or background knowledge resources are integrated to recognize hierarchical relationships, the false equivalence assignments would decrease.

### Mechanism 2
- Claim: Ambiguity in entity naming and expressiveness leads to uncertainty in matching outcomes.
- Mechanism: Ontology matching tools are sensitive to entity expressiveness; ambiguous or inconsistent naming conventions in datasets lead to incorrect matches or missed correspondences.
- Core assumption: Matching tools prioritize lexical similarity, so unclear or overly general entity names result in poor matching quality.
- Evidence anchors:
  - [abstract] "outcomes clearly show significant uncertainty resulting from errors and inaccuracies along the automated matching process."
  - [section] "Ontology matching tools are also very sensitive to the expressiveness of entities... entity terms should be written as straightforward and clear as possible so that existing ontology matching tools can produce good results and avoid additional uncertainty."
  - [corpus] Weak: Corpus lacks specific examples of naming ambiguity affecting matching.
- Break condition: If datasets are pre-processed to standardize entity naming or use external linguistic resources to clarify meanings, uncertainty from expressiveness issues would reduce.

### Mechanism 3
- Claim: Different conceptualization choices in ontology design create structural mismatches that automated tools cannot resolve.
- Mechanism: When developers structure the same data differently (e.g., countries as rows vs. columns), ontology matching tools fail because they cannot match entities across different structural representations.
- Core assumption: Matching tools are limited to aligning entities of the same type and structure, lacking flexibility for structural variations.
- Evidence anchors:
  - [abstract] "high error rates in fully automated matching, with precision, recall, and F-measure values showing significant variability."
  - [section] "Current ontology matching tools do not match different types of entities... However, there is often a difference in the structuring (or organization) of entities in two similar ontologies."
  - [corpus] Weak: Corpus does not provide explicit structural mismatch examples.
- Break condition: If matching algorithms incorporate structural transformation capabilities or use mediation ontologies to bridge structural differences, these mismatches could be addressed.

## Foundational Learning

- Concept: Ontology matching and alignment evaluation metrics (Precision, Recall, F-measure, Overall, Ambiguity Degree).
  - Why needed here: Understanding these metrics is essential to assess the quality and uncertainty of automated ontology matching results.
  - Quick check question: What does a high precision but low recall value indicate about an ontology alignment?

- Concept: Types of uncertainty in ontology matching (domain complexity, granularity differences, expressiveness issues, structural mismatches).
  - Why needed here: Identifying the sources of uncertainty helps in designing mitigation strategies and improving matching processes.
  - Quick check question: How does ambiguity in entity naming contribute to uncertainty in ontology matching?

- Concept: Alignment disambiguation and trimming techniques (Stable Marriage algorithm, thresholding).
  - Why needed here: These techniques are used to manage uncertainty by reducing false positives and ambiguous correspondences.
  - Quick check question: What is the trade-off between alignment trimming and recall when reducing uncertainty?

## Architecture Onboarding

- Component map: Data Conversion Tool -> Ontology Matching Tools (LogMap, AML) -> Alignment Evaluation -> Disambiguation/Trimming
- Critical path: Convert raw data → Generate ontologies → Perform automated matching → Evaluate alignment → Apply disambiguation/trimming → Assess uncertainty reduction
- Design tradeoffs:
  - Fully automated matching offers scalability but introduces high uncertainty; semi-supervised approaches reduce uncertainty but require manual effort
  - High precision matching may miss relevant correspondences (low recall); balancing both is challenging
- Failure signatures:
  - High number of false positives and false negatives in alignment results
  - Ambiguous correspondences remain after disambiguation
  - Low confidence values across many correspondences indicate poor matching quality
- First 3 experiments:
  1. Convert a simple CSV dataset (e.g., country indicators) to ontologies and perform matching with LogMap
  2. Repeat matching with AML and compare precision, recall, and F-measure
  3. Apply alignment trimming and disambiguation to the results and re-evaluate the metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can uncertainty in ontology alignment be quantified beyond standard precision, recall, and F-measure metrics?
- Basis in paper: [explicit] The paper identifies that existing evaluation metrics only measure correctness and completeness, while uncertainty includes aspects like matcher reliability, domain complexity, and inherent ambiguity that are not captured by these metrics.
- Why unresolved: Current metrics focus on comparing alignments to reference standards but cannot assess confidence reliability, domain complexity, or inherent uncertainty in the data itself.
- What evidence would resolve it: Development and validation of new metrics that specifically measure uncertainty components like matcher confidence reliability, domain complexity scores, and ambiguity detection beyond simple 1-to-1 matching.

### Open Question 2
- Question: What is the optimal threshold for alignment trimming that maximizes F-measure while minimizing information loss?
- Basis in paper: [explicit] The paper discusses that alignment trimming improves precision but decreases recall, and finding the optimal threshold requires manual trials to maximize F-measure.
- Why unresolved: Different applications have different tolerance levels for false positives versus false negatives, and the optimal threshold varies based on ontology characteristics and domain complexity.
- What evidence would resolve it: Systematic evaluation of different threshold values across various ontology pairs to determine if universal optimal thresholds exist or if domain-specific thresholds are needed.

### Open Question 3
- Question: Can semi-supervised ontology matching approaches effectively balance automation with human validation for large-scale integration?
- Basis in paper: [explicit] The paper concludes that fully automated integration is unreliable and suggests semi-supervised approaches as more practical, but notes that validation becomes a bottleneck as data scales.
- Why unresolved: While semi-supervised approaches can improve accuracy through human validation, they face scalability challenges when dealing with large numbers of correspondences.
- What evidence would resolve it: Empirical studies comparing the performance of semi-supervised approaches versus fully automated methods across varying scales of data integration tasks, measuring both accuracy and efficiency trade-offs.

## Limitations
- Results based on limited set of 10 dataset pairs from specific domains, limiting generalizability
- No comparison with human-in-the-loop or semi-supervised approaches that might better handle uncertainty
- Corpus lacks concrete examples of specific error types, making it difficult to verify exact failure modes

## Confidence
- High: Automated matching tools produce high error rates and significant variability in alignment quality
- Medium: Manual evaluation and disambiguation improve but don't eliminate uncertainty
- Medium: Domain-specific mismatches (granularity, structure, naming) are primary sources of uncertainty

## Next Checks
1. Test matching tools on additional dataset pairs from diverse domains to assess generalizability of error patterns
2. Implement and evaluate a semi-supervised matching approach to compare against fully automated results
3. Conduct a detailed case study analyzing specific alignment errors to verify the proposed uncertainty mechanisms