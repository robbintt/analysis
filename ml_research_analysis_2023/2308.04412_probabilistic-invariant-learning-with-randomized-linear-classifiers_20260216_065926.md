---
ver: rpa2
title: Probabilistic Invariant Learning with Randomized Linear Classifiers
arxiv_id: '2308.04412'
source_url: https://arxiv.org/abs/2308.04412
tags:
- task
- rlcs
- graph
- invariant
- theorem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Randomized Linear Classifiers (RLCs), a new
  model class that uses randomness to achieve both expressiveness and invariance in
  binary classification tasks while reducing computational resources. The key idea
  is to generate random linear classifiers using neural networks with external randomness,
  then aggregate their predictions via majority voting.
---

# Probabilistic Invariant Learning with Randomized Linear Classifiers

## Quick Facts
- **arXiv ID:** 2308.04412
- **Source URL:** https://arxiv.org/abs/2308.04412
- **Reference count:** 40
- **Primary result:** Randomized Linear Classifiers (RLCs) achieve universal approximation and invariance with fewer parameters than deterministic models across set, graph, and spherical data tasks.

## Executive Summary
This paper introduces Randomized Linear Classifiers (RLCs), a novel model class that leverages external randomness to achieve both expressiveness and invariance in binary classification tasks while reducing computational resources. By generating random linear classifiers using neural networks with independent randomness and aggregating their predictions via majority voting, RLCs can approximate any smooth function while preserving invariance to compact group transformations. The key insight is that accepting probabilistic notions of correctness allows for reduced resource requirements compared to deterministic invariant architectures like Deep Sets and GNNs.

## Method Summary
RLCs work by sampling external randomness u, generating linear classifier coefficients via a neural network fθ(u), applying these classifiers to the input, and aggregating predictions through majority voting. For invariant variants, the method conditions classifier generation on latent factors that capture the invariance structure of the data. The approach is theoretically grounded in de Finetti's theorem for exchangeable sequences (sets) and Aldous-Hoover's theorem for jointly exchangeable arrays (graphs), which justify that i.i.d. sampling of weights conditioned on latent factors produces invariant classifiers. The models are trained using standard neural network optimization techniques with Adagrad optimizer and cosine annealing scheduler.

## Key Results
- RLCs achieve universal approximation for invariant tasks using fewer parameters than Deep Sets (constant vs. input-size-dependent scaling)
- RLCs can solve graph connectivity tasks that GNNs provably cannot approximate
- Empirical evaluations confirm theoretical advantages across sorting, sign, and connectivity tasks with better performance and robustness to out-of-distribution data sizes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RLCs achieve probabilistic invariance and universal approximation using fewer parameters than deterministic models.
- Mechanism: By generating random linear classifiers independently from the input using external randomness, then aggregating via majority voting, RLCs can approximate any smooth function while preserving invariance to compact group transformations.
- Core assumption: The input data satisfies Assumption 3 (infinitely G-invariant data) and the task has a smooth separator (Assumption 1).
- Evidence anchors: [abstract] "RLCs can achieve probabilistic invariance and universality using less resources than (deterministic) neural networks and their invariant counterparts." [section 2] "The key features of RLCs are both i) randomness independent from input and ii) linear transformation of the input."

### Mechanism 2
- Claim: RLCs are more parameter-efficient than Deep Sets for set data tasks because the number of parameters does not scale with input set size.
- Mechanism: RSetCs leverage de Finetti's theorem to generate exchangeable linear classifier weights conditioned on a common latent factor, allowing the model to maintain expressiveness without increasing parameters with set size.
- Core assumption: The set task has infinitely permutation-invariant data and a smooth separator.
- Evidence anchors: [section 3.1] "the number of parameters used by the RSetC does not depend on the set size... In contrast to these results, our work shows that such tradeoffs are usually restricted to the design of deterministic architectures."

### Mechanism 3
- Claim: RLCs can solve graph tasks that GNNs provably cannot approximate, such as connectivity, using fewer parameters.
- Mechanism: RGraphCs leverage Aldous-Hoover's theorem to generate jointly exchangeable edge weights conditioned on latent factors of vertices, allowing them to capture graph properties that depend on inner products rather than exact graph isomorphism.
- Core assumption: The graph task has infinitely graph isomorphism-invariant data and is either an inner-product decision problem or has a smooth separator.
- Evidence anchors: [section 3.2] "RGraphCs can approximate any problem that either has a smooth boundary or can be tested with an inner product... Thus, we are not doomed to fail at simple tasks like GNNs."

## Foundational Learning

- **Concept:** De Finetti's theorem and exchangeability
  - Why needed here: RSetCs leverage de Finetti's theorem to justify that i.i.d. sampling of weights conditioned on a latent factor produces exchangeable classifiers suitable for permutation-invariant set tasks.
  - Quick check question: If we sample linear classifier weights independently conditioned on a common latent variable, what property do the resulting classifiers have with respect to permutations of the input set?

- **Concept:** Aldous-Hoover theorem and joint exchangeability
  - Why needed here: RGraphCs use Aldous-Hoover's theorem analogously to de Finetti's, but for 2-dimensional arrays representing graphs, justifying that edge weights can be sampled i.i.d. conditioned on latent factors of both endpoints.
  - Quick check question: How does the Aldous-Hoover theorem extend the concept of exchangeability to graph structures where both rows and columns of the adjacency matrix are permuted?

- **Concept:** Randomized algorithms and probabilistic correctness
  - Why needed here: The core insight of RLCs is borrowing the principle from randomized algorithms that accepting probabilistic notions of correctness (high probability instead of certainty) can reduce computational resources.
  - Quick check question: What is the fundamental tradeoff in randomized algorithms that RLCs are leveraging, and how does this manifest in the invariance-resource tradeoff?

## Architecture Onboarding

- **Component map:** External randomness U → Neural network fθ → Linear classifier coefficients (aθ, bθ) → Majority voting aggregator → Final prediction
- **Critical path:** 1. Sample external randomness u, 2. Generate linear classifier coefficients via fθ(u), 3. Apply classifier to input: sgn(⟨aθ, x⟩ - bθ), 4. Repeat steps 1-3 m times, 5. Aggregate predictions via majority voting, 6. Output final prediction
- **Design tradeoffs:** Number of samples m vs. approximation quality (larger m → closer to limiting classifier), Complexity of fθ vs. expressiveness (more complex fθ can generate more complex distributions), Use of invariant variants vs. general RLCs (invariant variants guarantee invariance but may be more complex to design)
- **Failure signatures:** Poor performance with small m (not enough samples for majority voting to converge), Sensitivity to choice of external randomness distribution (affects generated classifier properties), Failure to maintain invariance when using invariant variants with non-infinitely invariant data
- **First 3 experiments:** 1. Verify universal approximation on simple 2D binary classification tasks with varying decision boundaries, 2. Compare parameter efficiency vs. standard neural networks on set tasks with increasing set sizes, 3. Test graph connectivity classification vs. GNNs on Erdős-Rényi random graphs with varying densities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the computational complexity of the amplification step in RLCs, and how does it scale with the number of samples needed for reliable predictions?
- Basis in paper: [explicit] The paper mentions amplification as taking multiple samples and using majority voting to ensure correctness with high probability. It provides a theoretical bound on the number of samples needed (m) based on the minimum bias ε of the RLC.
- Why unresolved: The paper does not provide concrete experimental results or analysis on the computational cost of the amplification step. It only mentions that the amplification size m depends on the minimum bias ε, but does not discuss the practical implications of this relationship.
- What evidence would resolve it: Empirical studies comparing the computational cost of RLCs with different amplification sizes and comparing them to deterministic models. Analysis of the trade-off between the number of samples and the accuracy of the predictions.

### Open Question 2
- Question: How do RLCs perform in tasks with non-compact group transformations, and what modifications would be needed to extend their theoretical guarantees to these cases?
- Basis in paper: [inferred] The paper focuses on tasks with compact group transformations and provides theoretical guarantees for these cases. However, many real-world tasks involve non-compact groups, such as translations or scaling.
- Why unresolved: The paper does not discuss the extension of RLCs to non-compact group transformations. It is unclear whether the theoretical results and design principles can be directly applied to these cases.
- What evidence would resolve it: Theoretical analysis and experimental results demonstrating the performance of RLCs in tasks with non-compact group transformations. Development of modified RLC architectures or training procedures that can handle these cases.

### Open Question 3
- Question: How do RLCs compare to Bayesian neural networks in terms of uncertainty estimation and robustness to out-of-distribution data?
- Basis in paper: [explicit] The paper mentions that RLCs and Bayesian neural networks use randomness differently. RLCs take samples from a model that uses external randomness, while BNNs model prior and posterior distributions over the weights. The paper does not provide a direct comparison between the two approaches.
- Why unresolved: The paper does not provide experimental results or theoretical analysis comparing RLCs and BNNs in terms of uncertainty estimation and robustness to out-of-distribution data. It is unclear whether RLCs can provide similar benefits to BNNs in these aspects.
- What evidence would resolve it: Empirical studies comparing the uncertainty estimation and out-of-distribution robustness of RLCs and BNNs on various tasks. Theoretical analysis of the similarities and differences between the two approaches in terms of their ability to handle uncertainty and out-of-distribution data.

## Limitations
- Theoretical results rely heavily on strong invariance assumptions (infinitely G-invariant data) that may not hold in practical scenarios
- Parameter efficiency claims need validation on larger-scale problems beyond the synthetic examples provided
- Claims about solving graph connectivity problems that GNNs cannot handle need more empirical validation

## Confidence

- **High Confidence:** The core mechanism of using external randomness to generate linear classifiers and aggregating via majority voting is well-founded and theoretically justified. The connection to randomized algorithms is sound.
- **Medium Confidence:** The universal approximation results for invariant tasks are mathematically rigorous under stated assumptions, but practical applicability depends on data satisfying these assumptions.
- **Low Confidence:** Claims about RLCs solving graph connectivity problems that GNNs cannot handle need more empirical validation, as the practical significance of this theoretical advantage is unclear.

## Next Checks
1. Test RLCs on standard invariant learning benchmarks (e.g., molecular property prediction, set-based recommendation systems) to verify performance advantages beyond synthetic tasks.
2. Systematically evaluate how violations of the infinitely invariant data assumption affect RLC performance compared to deterministic baselines across varying degrees of invariance violation.
3. Measure RLC performance and parameter efficiency on larger-scale problems (set sizes > 100, graph sizes > 1000 nodes) to validate theoretical scaling advantages in practical settings.