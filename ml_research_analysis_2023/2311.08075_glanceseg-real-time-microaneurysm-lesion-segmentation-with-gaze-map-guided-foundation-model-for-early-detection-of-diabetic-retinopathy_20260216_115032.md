---
ver: rpa2
title: 'GlanceSeg: Real-time microaneurysm lesion segmentation with gaze-map-guided
  foundation model for early detection of diabetic retinopathy'
arxiv_id: '2311.08075'
source_url: https://arxiv.org/abs/2311.08075
tags:
- image
- segmentation
- medical
- lesions
- points
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents GlanceSeg, a human-in-the-loop, label-free
  framework for early-stage diabetic retinopathy (DR) diagnosis. GlanceSeg leverages
  eye-tracking data from ophthalmologists to generate gaze maps that guide a Segment
  Anything Model (SAM) in real-time microaneurysm lesion segmentation.
---

# GlanceSeg: Real-time microaneurysm lesion segmentation with gaze-map-guided foundation model for early detection of diabetic retinopathy

## Quick Facts
- arXiv ID: 2311.08075
- Source URL: https://arxiv.org/abs/2311.08075
- Reference count: 40
- Primary result: Human-in-the-loop framework using eye-tracking data improves microaneurysm segmentation with AUPR of 0.5705 (fine-tuned)

## Executive Summary
GlanceSeg is a human-in-the-loop framework for early-stage diabetic retinopathy diagnosis that leverages eye-tracking data from ophthalmologists to guide microaneurysm lesion segmentation. The system integrates gaze maps as top-down attention, saliency maps as bottom-up attention, and the Segment Anything Model (SAM) to achieve real-time lesion detection. Experiments on IDRiD and Retinal-Lesions datasets demonstrate improved annotation efficiency and segmentation performance compared to traditional methods, with potential for self-model optimization through continual learning.

## Method Summary
GlanceSeg uses eye-tracking data from clinicians to generate gaze maps that localize lesions in fundus images. These gaze maps are processed through region of interest extraction and image enhancement, then combined with saliency maps (computed via frequency-tuned and minimum barrier distance methods) to generate prompt points for SAM. A domain knowledge filter refines segmentation results based on medical priors about microaneurysm characteristics. The framework is tested in both zero-shot and fine-tuned settings on two public datasets, with performance measured by AUPR and Dice coefficient.

## Key Results
- AUPR of 0.5705 (fine-tuned) and 0.5523 (zero-shot) on IDRiD dataset
- Demonstrated improvement in annotation efficiency through human-in-the-loop approach
- Real-time processing capability enabled by efficient gaze map and saliency map computation
- Domain knowledge filtering improves segmentation accuracy by reducing false positives

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gaze maps provide top-down attention that helps locate small lesions by leveraging clinician expertise
- Mechanism: Eye-tracking data captures where clinicians focus during diagnosis, creating a gaze map that serves as prior knowledge for lesion localization
- Core assumption: Regions receiving sustained clinician attention correspond to lesion presence
- Evidence anchors:
  - [abstract] "our human-in-the-loop framework integrates the ophthalmologist's gaze map, allowing for rough localization of minute lesions in fundus images"
  - [section II.A] "The areas of the image that receive the most attention from clinicians are of paramount importance and have a direct correlation with the diagnostic outcome"
  - [corpus] No direct corpus evidence for gaze map effectiveness in lesion detection; weak support
- Break condition: If clinician attention patterns don't correlate with lesion locations, or if gaze maps introduce systematic bias

### Mechanism 2
- Claim: Saliency maps provide bottom-up attention by highlighting image regions with distinctive visual features
- Mechanism: Frequency-tuned and minimum barrier distance methods generate saliency maps that identify potential lesion locations based on visual contrast and local pixel differences
- Core assumption: Lesions have distinctive visual properties that can be captured through saliency computation
- Evidence anchors:
  - [section III.B.3] "we proposed a method involving the computation of multiple saliency maps" and describes FT and MBD methods
  - [section III.B.2] "clinicians usually carefully observe important areas and suspicious signs of lesions for a long time"
  - [corpus] Weak evidence; no corpus papers directly support this specific saliency approach for medical lesion detection
- Break condition: If lesions lack distinctive visual features or if saliency methods fail to capture medical-relevant visual properties

### Mechanism 3
- Claim: Domain knowledge filtering improves segmentation accuracy by applying medical priors about lesion characteristics
- Mechanism: Filters eliminate false positives based on shape (roundness), color (red component dominance), and texture (smoothness) criteria specific to microangiomas
- Core assumption: Microangiomas have consistent morphological characteristics that can be encoded as filtering rules
- Evidence anchors:
  - [section III.D] "we proposed a domain knowledge filtering (DKF) module to focus on the target lesions" with specific criteria for shape, color, and texture
  - [section III.D] "According to the recognized medical knowledge, we digitized the description of the target lesion to construct the DKF module"
  - [corpus] No corpus evidence for this specific filtering approach; weak support
- Break condition: If lesion characteristics vary significantly or if filtering rules incorrectly eliminate true positives

## Foundational Learning

- Concept: Eye-tracking technology and gaze map generation
  - Why needed here: Understanding how eye-tracking data is collected and processed into usable gaze maps for the GlanceSeg framework
  - Quick check question: How does the Gaussian transformation convert raw gaze points into a usable attention map?

- Concept: Saliency map computation methods (frequency-tuned and minimum barrier distance)
  - Why needed here: These methods generate the bottom-up attention signals that guide prompt point generation for SAM
  - Quick check question: What is the difference between FT and MBD saliency computation, and why use both?

- Concept: SAM prompt engineering and segmentation fundamentals
  - Why needed here: Understanding how prompt points guide SAM's zero-shot segmentation performance
- Quick check question: How does the number and placement of prompt points affect SAM's segmentation accuracy?

## Architecture Onboarding

- Component map: Eye-tracker → Gaze map computation → ROI extraction → Saliency map generation → Prompt point generation → SAM segmentation → Domain knowledge filtering → Output
- Critical path: Gaze map → Saliency map → Prompt points → SAM → DKF (any failure here breaks the pipeline)
- Design tradeoffs: Real-time processing vs. segmentation accuracy, prompt point density vs. computation time, strict filtering vs. recall
- Failure signatures: Poor gaze map quality, saliency maps that don't highlight lesions, SAM producing too many false positives, DKF being too restrictive
- First 3 experiments:
  1. Test gaze map quality with different σ values (25 vs alternatives) and verify ROI coverage
  2. Compare saliency map generation with and without image enhancement (IEnh)
  3. Evaluate prompt point generation at N=50, 100, 200 to find optimal balance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can GlanceSeg be effectively adapted for multi-lesion segmentation in diabetic retinopathy, beyond just microaneurysms?
- Basis in paper: [explicit] The paper mentions future work will explore adapting GlanceSeg for multi-lesion segmentation in diabetic retinopathy.
- Why unresolved: The current GlanceSeg framework is optimized specifically for microaneurysm segmentation and has not been tested or adapted for other types of lesions.
- What evidence would resolve it: Experimental results comparing GlanceSeg's performance on multi-lesion segmentation tasks against existing methods, with metrics like AUPR and Dice coefficient for each lesion type.

### Open Question 2
- Question: What is the optimal balance between gaze map resolution and processing speed for real-time clinical applications?
- Basis in paper: [inferred] The paper discusses using gaze maps for localization but doesn't explore the trade-off between resolution and real-time performance.
- Why unresolved: The current implementation uses specific parameters without exploring how different resolutions affect both segmentation accuracy and real-time processing capabilities.
- What evidence would resolve it: Comparative analysis of segmentation accuracy and processing latency across different gaze map resolutions and sampling rates in clinical settings.

### Open Question 3
- Question: How does the performance of GlanceSeg compare to traditional supervised learning methods when both are trained on the same amount of labeled data?
- Basis in paper: [explicit] The paper mentions that GlanceSeg improves annotation efficiency but doesn't directly compare its performance to supervised methods given equivalent training data.
- Why unresolved: The study focuses on zero-shot and fine-tuning capabilities but doesn't benchmark against supervised approaches under equal data conditions.
- What evidence would resolve it: Direct comparison of GlanceSeg and supervised learning methods trained on identical datasets, measuring segmentation accuracy, annotation time, and clinical utility.

### Open Question 4
- Question: What is the long-term impact of continual learning with GlanceSeg on segmentation performance as more annotated data becomes available?
- Basis in paper: [explicit] The paper mentions the potential for self-model optimization through continual learning but doesn't investigate long-term performance improvements.
- Why unresolved: The study only demonstrates initial fine-tuning improvements without exploring how performance evolves over multiple training iterations with accumulating annotations.
- What evidence would resolve it: Longitudinal study tracking segmentation performance improvements over multiple training cycles with increasing amounts of annotated data, measuring convergence and performance plateaus.

## Limitations
- Limited corpus evidence for gaze map effectiveness in lesion detection, making this a novel but unproven approach
- Saliency method selection lacks strong corpus support for medical applications
- Domain knowledge filtering criteria are not validated against clinical gold standards

## Confidence
- High confidence: Core pipeline architecture (gaze map → saliency → SAM → DKF) is technically sound and well-described
- Medium confidence: Real-time processing claims and annotation efficiency improvements, based on limited experimental results
- Low confidence: Clinical impact and diagnostic accuracy claims, as these were not rigorously evaluated against clinical outcomes

## Next Checks
1. Test GlanceSeg on additional fundus image datasets beyond IDRiD and Retinal-Lesions to verify generalizability across different imaging conditions and populations
2. Conduct a controlled study comparing clinician performance with and without GlanceSeg assistance on time to diagnosis, detection accuracy, and inter-observer variability
3. Evaluate gaze map quality across multiple clinicians to determine if attention patterns are consistent and whether they generalize across different observer expertise levels