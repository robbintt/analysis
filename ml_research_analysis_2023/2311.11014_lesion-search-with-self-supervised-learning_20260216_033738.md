---
ver: rpa2
title: Lesion Search with Self-supervised Learning
arxiv_id: '2311.11014'
source_url: https://arxiv.org/abs/2311.11014
tags:
- lesion
- learning
- simclr
- image
- frangi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents an open-source application for lesion analysis
  and retrieval using self-supervised learning (SSL). The approach uses contrastive
  learning with SimCLR, incorporating Frangi filtering and GeM pooling with L2 normalization
  to improve feature extraction for medical image retrieval.
---

# Lesion Search with Self-supervised Learning

## Quick Facts
- arXiv ID: 2311.11014
- Source URL: https://arxiv.org/abs/2311.11014
- Authors: 
- Reference count: 11
- Key outcome: Achieves 80.73% classification accuracy and 77.83% F1-score on DeepLesion dataset using SimCLR with Frangi filtering and GeM pooling

## Executive Summary
This work presents an open-source application for lesion analysis and retrieval using self-supervised learning (SSL). The approach uses contrastive learning with SimCLR, incorporating Frangi filtering and GeM pooling with L2 normalization to improve feature extraction for medical image retrieval. Evaluated on the DeepLesion dataset, the method achieves classification accuracy of 80.73% and F1-score of 77.83% when combining SimCLR with both Frangi filtering and GeM pooling. For content-based image retrieval, the SimCLR-based model outperforms a VAE baseline across all-patient, same-patient, and cross-patient retrieval scenarios, with mAP@10 scores of 0.729, 0.713, and 0.465 respectively. The application provides an interactive UI for DICOM image analysis and supports clinicians in lesion interpretation without requiring manual annotations.

## Method Summary
The approach uses contrastive learning with SimCLR framework, incorporating Frangi filtering for vessel enhancement and GeM pooling with L2 normalization for feature extraction. The model uses ResNet-18 as backbone, trained for 1000 epochs with LARS optimizer and cosine learning rate scheduler, then fine-tuned with SGD for CBIR using contrastive loss with margin 0.8. The system processes DeepLesion CT images cropped to 64x64 ROIs and provides an interactive DICOM viewer interface for clinical use.

## Key Results
- Classification accuracy of 80.73% and F1-score of 77.83% for lesion types
- CBIR mAP@10 scores: 0.729 (all-patient), 0.713 (same-patient), 0.465 (cross-patient)
- SimCLR-based model outperforms VAE baseline in all retrieval scenarios
- Interactive UI enables DICOM image analysis without manual annotations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The combination of Frangi filtering with GeM pooling and L2 normalization improves feature extraction for lesion retrieval by enhancing lesion contours while suppressing background noise.
- Mechanism: Frangi filtering uses Hessian-based eigenvalues to enhance vessel-like structures and suppress non-vessel regions. When combined with GeM pooling, which generalizes average/max pooling by using a learnable exponent, it creates more discriminative lesion representations that are then normalized to unit vectors for cosine similarity comparisons.
- Core assumption: The modified Frangi filter parameters (α = 1, β = 0.6, γ = 0.0444) are optimal for the DeepLesion dataset and that these enhancements generalize across different lesion types and sizes.
- Evidence anchors:
  - [abstract] "We develop a CBIR from the contrastive learning SimCLR and incorporate a generalized-mean (GeM) pooling followed by L2 normalization to classify lesion types and retrieve similar images"
  - [section] "Frangi filter function has two components and λ represents eigenvalues... The modification enhances contours by restricting λ such that |λ1| ≤ |λ2| ≤ |λ3| at the scale 's'"
  - [corpus] Weak evidence - the corpus mentions related work on CBIR and tissue image retrieval but lacks specific evidence about Frangi filtering effectiveness
- Break condition: The method breaks when lesion characteristics differ significantly from vessel-like structures, or when the fixed filter parameters fail to generalize to datasets with different imaging protocols or lesion types.

### Mechanism 2
- Claim: SimCLR's contrastive learning framework enables lesion representation learning without manual annotations by creating positive pairs from augmented views of the same lesion and pushing away representations of different lesions.
- Mechanism: The framework creates augmented views of each lesion image through transformations like flips, color distortions, and Gaussian blur. It then trains a neural network to maximize agreement between positive pairs while minimizing agreement between negative pairs using contrastive loss, learning invariant representations that capture lesion semantics.
- Core assumption: Lesion augmentations preserve semantic content while creating sufficient variation for the model to learn robust representations, and that negative sampling strategy is sufficient for effective contrastive learning.
- Evidence anchors:
  - [abstract] "Content-based image retrieval (CBIR) with self-supervised learning (SSL) accelerates clinicians' interpretation of similar images without manual annotations"
  - [section] "We train models with Pytorch... We implement ResNet-18 in SimCLR, followed by two more convolutional layers and a GeM pooling layer with L2-normalization"
  - [corpus] Weak evidence - while the corpus discusses CBIR systems, it doesn't specifically validate SimCLR's effectiveness for medical lesion retrieval
- Break condition: The method fails when lesion appearance varies too much within classes, making it difficult to create meaningful positive pairs, or when the dataset size is too small for contrastive learning to be effective.

### Mechanism 3
- Claim: The L2 normalization step ensures that feature vectors lie on a unit hypersphere, making cosine similarity a meaningful distance metric for lesion retrieval.
- Mechanism: After GeM pooling extracts lesion features, L2 normalization scales each feature vector to have unit length. This ensures that all vectors are comparable on the same scale and that cosine similarity directly measures angular distance, which corresponds to semantic similarity between lesions.
- Core assumption: The feature space is approximately isotropic after normalization, meaning that angular distances are meaningful measures of semantic similarity.
- Evidence anchors:
  - [abstract] "We develop a CBIR from the contrastive learning SimCLR and incorporate a generalized-mean (GeM) pooling followed by L2 normalization"
  - [section] "we compute contrastive loss with margin 0.8 and cosine distance from the sigmoid classification layer"
  - [corpus] Weak evidence - the corpus doesn't specifically discuss the role of L2 normalization in medical image retrieval
- Break condition: The method fails when feature distributions become highly anisotropic or when the margin parameter in contrastive loss is not properly tuned for the normalized space.

## Foundational Learning

- Concept: Self-supervised learning through contrastive learning
  - Why needed here: Eliminates the need for manual lesion annotations which are expensive and time-consuming to create, while still enabling effective feature learning for retrieval tasks
  - Quick check question: How does contrastive learning create training signals without labels?

- Concept: Hessian-based filtering for vessel enhancement
  - Why needed here: Medical lesions often have vessel-like structures that need to be enhanced while suppressing background noise for better feature extraction
  - Quick check question: What do the eigenvalues λ1, λ2, λ3 represent in the Hessian matrix for image filtering?

- Concept: Generalized mean (GeM) pooling
  - Why needed here: Provides a flexible pooling operation that can interpolate between average and max pooling, allowing the model to learn optimal feature aggregation for lesion representation
  - Quick check question: How does the learnable exponent in GeM pooling affect the pooling behavior?

## Architecture Onboarding

- Component map: DICOM viewer frontend (AngularJS) → SSL model backend (PyTorch) → Feature extraction → Cosine similarity search → Ranked results
- Critical path: User uploads DICOM → Preprocessing (Frangi filter) → Feature extraction (ResNet-18 + GeM + L2) → Similarity computation → Results display
- Design tradeoffs: SimCLR vs VAE - SimCLR provides better retrieval performance but requires more complex training; VAE is simpler but less effective for this task
- Failure signatures: Low mAP scores indicate poor feature discrimination; high intra-patient precision but low cross-patient precision suggests features are too patient-specific
- First 3 experiments:
  1. Verify Frangi filter correctly enhances lesion contours on sample DICOM images
  2. Test SimCLR feature extraction on held-out validation set with classification accuracy
  3. Evaluate CBIR performance on same-patient retrieval before testing cross-patient scenarios

## Open Questions the Paper Calls Out
- How does the proposed SSL-based CBIR approach perform on other medical imaging datasets beyond DeepLesion, particularly for different types of lesions or diseases?
- What is the optimal combination of Frangi filter parameters (α, β, γ) and multiscale values (s) for different lesion types and imaging modalities?
- How does the SSL-based CBIR approach compare to state-of-the-art supervised learning methods for lesion classification and retrieval?

## Limitations
- Fixed Frangi filter parameters may not generalize across different lesion types or imaging protocols
- Performance evaluation limited to single dataset (DeepLesion) without external validation
- 64x64 ROI size may not capture adequate contextual information for all lesion types

## Confidence
- Classification and CBIR performance claims: Medium confidence (limited external validation)
- Frangi filtering mechanism: Medium confidence (parameter optimality unverified)
- SimCLR self-supervised learning framework: Medium confidence (no ablation studies shown)

## Next Checks
1. Conduct cross-dataset validation using external datasets (e.g., LIDC-IDRI) to test generalization of the SSL-based retrieval approach beyond DeepLesion.
2. Perform ablation studies removing Frangi filtering and GeM pooling to quantify their individual contributions to performance improvements.
3. Test the application with real clinical users to evaluate practical utility and identify potential usability issues not captured by quantitative metrics.