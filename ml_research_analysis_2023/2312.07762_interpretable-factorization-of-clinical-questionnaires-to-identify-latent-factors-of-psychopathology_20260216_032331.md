---
ver: rpa2
title: Interpretable factorization of clinical questionnaires to identify latent factors
  of psychopathology
arxiv_id: '2312.07762'
source_url: https://arxiv.org/abs/2312.07762
tags:
- matrix
- factor
- icqf
- factors
- factorization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ICQF is a matrix factorization method tailored for questionnaire
  data that enforces non-negativity, bounded factor values, and sparsity to improve
  interpretability and solution stability. It directly handles missing data and incorporates
  known confounding variables.
---

# Interpretable factorization of clinical questionnaires to identify latent factors of psychopathology

## Quick Facts
- arXiv ID: 2312.07762
- Source URL: https://arxiv.org/abs/2312.07762
- Reference count: 40
- Key outcome: ICQF achieves ROC AUC up to 0.94 across 11 diagnostic conditions and more stable factor loadings than baselines

## Executive Summary
ICQF is a matrix factorization method designed to identify interpretable latent factors from clinical questionnaires. It enforces non-negativity, bounded factor values, and sparsity to improve interpretability and solution stability. The method directly handles missing data and incorporates known confounding variables. ICQF uses ADMM optimization with theoretical convergence guarantees and includes blockwise cross-validation for accurate dimensionality estimation.

## Method Summary
ICQF factorizes questionnaire data M into factor matrix W and loading matrix Q under constraints 0 ≤ W ≤ 1 and 0 ≤ Q. The method uses ADMM optimization with FISTA sub-iterations to handle multiple constraints simultaneously. Missing data is handled through a mask matrix without imputation. Blockwise cross-validation determines the number of latent factors. The approach is validated on CBCL questionnaires from HBN and ABCD datasets, comparing diagnostic prediction performance and factor loading stability against ℓ1-NMF and factor analysis with promax rotation.

## Key Results
- ICQF achieves ROC AUC up to 0.94 across 11 diagnostic conditions in two independent datasets
- ICQF produces more stable factor loadings than ℓ1-NMF and FA-promax rotation, especially at smaller sample sizes
- ICQF yields more interpretable factor loadings validated by clinical experts and better replicates across datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ICQF's non-negativity, boundedness, and sparsity constraints yield interpretable factor loadings that directly map to clinical questionnaire semantics.
- Mechanism: By enforcing 0 ≤ Wij ≤ 1 and 0 ≤ Qij, factor values become probability-like scores of symptom presence, while loadings are bounded to questionnaire response ranges, making them directly comparable to item content.
- Core assumption: Questionnaire items and responses have natural, bounded scales that align with bounded latent factors.
- Evidence anchors:
  - [abstract]: "factor loadings are bounded within the same range as the original questionnaire responses, facilitating interpretation"
  - [section]: "Factor loadings are bounded within the same range as the question answers, facilitating interpretation as answer patterns"
  - [corpus]: Weak/no direct evidence; method relies on design assumptions about questionnaire scaling.
- Break condition: If questionnaire scales are ordinal or unbounded, or if clinical experts disagree on interpretability.

### Mechanism 2
- Claim: Direct handling of missing data without imputation prevents bias from data completion assumptions.
- Mechanism: The mask matrix M and objective term ∥M ⊙ (M − Z)∥² enforce reconstruction only where data is observed, avoiding imputed values that could distort factor structure.
- Core assumption: Missingness is at least Missing at Random (MAR) and not systematically informative.
- Evidence anchors:
  - [abstract]: "The method directly handles missing data without requiring imputation"
  - [section]: "We also have a mask matrix M indicating whether each entry is available or not"
  - [corpus]: No direct citation; this is an algorithmic design choice.
- Break condition: Systematic missingness patterns (e.g., non-response bias) that are informative for latent factors.

### Mechanism 3
- Claim: Blockwise cross-validation (BCV) accurately estimates the number of latent factors in the presence of confounding variables.
- Mechanism: BCV splits data into blocks, iteratively leaves out folds, factorizes the remainder, and measures reconstruction error, adapting to the distribution of confounds through stratified splitting.
- Core assumption: The true latent dimensionality is stable and detectable through reconstruction error curves.
- Evidence anchors:
  - [section]: "We implement blockwise-cross-validation (BCV) to determine the number of factors"
  - [section]: "We show that, if this number of factors is close to that underlying the data, the solution will be close to a global minimum"
  - [corpus]: Weak; BCV effectiveness is supported empirically in the paper but no external citations are given.
- Break condition: Highly correlated or redundant items, or if confounders dominate the signal.

## Foundational Learning

- Concept: Non-negative Matrix Factorization (NMF)
  - Why needed here: ICQF is a constrained variant of NMF; understanding the base method clarifies why constraints improve interpretability.
  - Quick check question: In NMF, what guarantees that the product WQ^T reconstructs only non-negative values?

- Concept: Alternating Direction Method of Multipliers (ADMM)
  - Why needed here: ICQF's optimization uses ADMM to handle multiple constraints simultaneously; knowledge of ADMM mechanics is critical for debugging convergence.
  - Quick check question: How does ADMM split the ICQF objective into subproblems for W, Q, and Z?

- Concept: Cross-validation for model selection
  - Why needed here: BCV is used to select the number of factors; understanding its mechanics ensures proper tuning.
  - Quick check question: In BCV for matrix factorization, why do we impute the left-out blocks instead of simply excluding them?

## Architecture Onboarding

- Component map: Input questionnaire matrix M and mask matrix M → preprocess (scaling, missing mask) → choose k via BCV → train ADMM solver with FISTA sub-iterations → output factor matrix W and loading matrix Q → evaluate interpretability/diagnostics
- Critical path: Input → preprocess → choose k via BCV → train ADMM solver → output W, Q → evaluate interpretability / diagnostics
- Design tradeoffs: Bounded constraints improve interpretability but may restrict expressiveness; missing-data handling avoids imputation bias but complicates optimization; BCV is robust but computationally heavier than BIC/CCC
- Failure signatures: Non-convergence in ADMM (check ρ ≥ √2), poor k selection (BCV error plateau), unstable loadings across splits (check sparsity β), or missing-data bias (inspect missingness patterns)
- First 3 experiments:
  1. Run ICQF on a small synthetic dataset with known k, compare k̂ from BCV to ground truth
  2. Vary β to observe sparsity-interpretability tradeoff in Q loadings
  3. Test missing-data handling by randomly masking entries and checking reconstruction error

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the regularization parameters in ICQF affect the trade-off between interpretability and diagnostic information preservation across different psychiatric questionnaires?
- Basis in paper: [explicit] The paper discusses the use of regularization parameters β and γ in ICQF, but does not explore how varying these parameters impacts the method's performance on different questionnaires.
- Why unresolved: The paper only uses fixed values for β and γ, without investigating the sensitivity of ICQF to these hyperparameters or their impact on interpretability and diagnostic prediction.
- What evidence would resolve it: A systematic study varying β and γ across multiple questionnaires, measuring both interpretability scores from clinical experts and diagnostic prediction performance, would clarify the optimal regularization balance.

### Open Question 2
- Question: Can ICQF effectively model hierarchical or multi-level latent structures in psychiatric questionnaires, beyond the flat factor model currently implemented?
- Basis in paper: [inferred] The paper demonstrates ICQF's ability to identify meaningful factors, but does not explore whether it can capture hierarchical relationships between factors or account for different levels of psychiatric symptom organization.
- Why unresolved: The current implementation assumes a single layer of latent factors, which may not capture the full complexity of psychiatric symptom structures that often exhibit hierarchical organization.
- What evidence would resolve it: Extending ICQF to a hierarchical or multi-level factorization framework and evaluating its performance on questionnaires known to have hierarchical structures (e.g., DSM-5 dimensional models) would address this limitation.

### Open Question 3
- Question: How does ICQF perform on questionnaires with highly skewed or non-Likert scale response distributions, such as continuous or count-based measures?
- Basis in paper: [explicit] The paper focuses on questionnaires with Likert-scale responses, but does not evaluate ICQF's performance on data with different distributional properties.
- Why unresolved: The bounded constraints and reconstruction error formulation in ICQF are tailored for bounded Likert-scale data, and their effectiveness for other response types is unknown.
- What evidence would resolve it: Applying ICQF to questionnaires with continuous or count-based responses (e.g., symptom severity scales, frequency counts) and comparing its performance to existing methods would clarify its generalizability.

## Limitations
- Bounded constraints rely heavily on questionnaire scaling assumptions that may not generalize to ordinal or unbounded scales
- Missing data handling assumes MAR missingness without validation, risking bias from informative missingness
- BCV for k selection is empirically supported but lacks external validation and may be misled by highly correlated items or confound-dominated signals

## Confidence
- Mechanism 1 (bounded interpretability): Medium — theoretically sound but assumes questionnaire scaling compatibility
- Mechanism 2 (missing-data handling): Medium — design choice is sound but MAR assumption untested
- Mechanism 3 (BCV for k selection): Medium — effective in paper's data but not externally validated
- Diagnostic performance and stability results: High — based on two large independent datasets with clear metrics

## Next Checks
1. Test ICQF's k selection on synthetic data with known dimensionality and varying missingness patterns to validate BCV robustness
2. Perform sensitivity analysis on the sparsity parameter β to quantify the tradeoff between interpretability and reconstruction accuracy
3. Evaluate ICQF on a dataset with known MAR violation to assess bias in missing-data handling