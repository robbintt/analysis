---
ver: rpa2
title: 'A Survey of Graph Meets Large Language Model: Progress and Future Directions'
arxiv_id: '2311.12399'
source_url: https://arxiv.org/abs/2311.12399
tags:
- graph
- llms
- arxiv
- language
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey provides a comprehensive review of integrating Large
  Language Models (LLMs) with graphs to enhance graph-related tasks. The authors propose
  a new taxonomy categorizing methods based on LLMs' roles as enhancers, predictors,
  or alignment components.
---

# A Survey of Graph Meets Large Language Model: Progress and Future Directions

## Quick Facts
- arXiv ID: 2311.12399
- Source URL: https://arxiv.org/abs/2311.12399
- Reference count: 18
- Primary result: Comprehensive survey categorizing LLM-graph integration methods into three roles: enhancer, predictor, and alignment components

## Executive Summary
This survey comprehensively reviews the integration of Large Language Models (LLMs) with graph data to enhance graph-related tasks. The authors propose a novel taxonomy categorizing approaches based on LLMs' roles: as enhancers that improve node embeddings, as predictors that process flattened graph-text representations, or as alignment components that coordinate embedding spaces between graph and text modalities. The survey highlights current limitations including scalability issues, data leakage concerns, and efficiency challenges while identifying promising future research directions such as handling non-text-attributed graphs, improving transferability, and leveraging LLMs as agents for complex graph tasks.

## Method Summary
The survey systematically categorizes LLM-graph integration approaches into three primary roles. LLM-as-enhancer methods use LLMs to generate enriched textual attributes or direct embeddings for nodes, which then serve as improved initial features for GNNs. LLM-as-predictor approaches flatten graph structures into sequential text descriptions that LLMs can directly process for predictions. GNN-LLM alignment techniques ensure both modalities are preserved while coordinating their embedding spaces through contrastive learning or distillation. The authors analyze each approach's mechanisms, advantages, limitations, and empirical performance across various graph tasks.

## Key Results
- Proposed taxonomy organizes LLM-graph integration methods into three distinct roles: enhancer, predictor, and alignment
- LLM-as-enhancer approaches effectively capture higher-level contextual information through zero-shot text generation
- Alignment techniques show promise in coordinating GNN and LLM embedding spaces while preserving both modalities
- Significant challenges remain in scalability, data leakage, and handling non-text-attributed graphs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs enhance GNNs by generating enriched textual attributes for nodes
- Mechanism: LLMs are prompted to create additional textual information (explanations, knowledge entities, pseudo labels) that augment original text attributes, which are then encoded into embeddings for GNN initialization
- Core assumption: LLMs can produce semantically meaningful additional information capturing higher-level context not present in original text attributes
- Evidence anchors: Abstract states LLMs enable "notable shift in the way we interact with graphs"; section on explanation-based enhancement discusses utilizing LLMs' zero-shot capability for higher-level information capture
- Break condition: Generated explanations are irrelevant or low-quality, leading to degraded GNN performance; high computational cost for querying LLMs on large graphs

### Mechanism 2
- Claim: LLMs directly generate node embeddings from text attributes, bypassing traditional GNN embedding layers
- Mechanism: LLMs encode text attributes into embeddings used as initial node embeddings for graph learning, requiring LLM embedding access and fine-tuning with structural information
- Core assumption: LLMs can effectively encode textual information into embeddings capturing semantic meaning useful for graph tasks when combined with structural information
- Evidence anchors: Abstract discusses GNNs enhanced with "stronger node features that effectively capture both structural and contextual aspects"; section on embedding-based enhancement describes using LLMs to output text embeddings as initial node embeddings
- Break condition: LLM fails to capture relevant structural information or embeddings are incompatible with GNN message-passing mechanism; access restrictions to LLM embeddings limit approach

### Mechanism 3
- Claim: LLMs can flatten graph structures into sequential text descriptions for direct processing
- Mechanism: Graphs are converted into textual sequences (using graph description languages, syntax trees, or natural narration) that LLMs process for predictions
- Core assumption: Graph structures can be effectively linearized into text without significant information loss, and LLMs can process these sequences accurately
- Evidence anchors: Abstract notes growing interest in enhancing LLMs' multi-modal capabilities for diverse data types including graphs; section on LLM-as-predictor discusses flattening graphs into textual descriptions for direct LLM processing
- Break condition: Flattening process loses critical structural information or sequential text exceeds LLM context limits, leading to incomplete or inaccurate predictions

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and their message-passing mechanism
  - Why needed here: Understanding GNN processing is crucial for integrating them with LLMs, as many approaches involve enhancing GNN embeddings or using GNN outputs with LLMs
  - Quick check question: What are the two main steps in the message-passing paradigm of GNNs, and how do they contribute to node representation learning?

- Concept: Large Language Models (LLMs) and their capabilities
  - Why needed here: Knowing LLM strengths and limitations (text generation, understanding, zero-shot learning) is essential for designing effective LLM-graph integration strategies
  - Quick check question: What are the key differences between non-autoregressive and autoregressive LLMs, and how do these differences impact their suitability for graph-related tasks?

- Concept: Graph-Text alignment techniques
  - Why needed here: Aligning GNN and LLM embedding spaces is a key approach for integrating graph and text modalities while preserving both
  - Quick check question: What are the differences between symmetric and asymmetric alignment in GNN-LLM alignment, and what are the implications of each approach for model performance?

## Architecture Onboarding

- Component map: Graph Data -> LLM Component -> GNN Component -> Alignment Module -> Downstream Task Module
- Critical path:
  - LLM-as-enhancer: Text attributes → LLM (generate explanations/embeddings) → GNN (learn representations) → Task prediction
  - LLM-as-predictor: Graph structure → Flattening (convert to text) → LLM (make predictions) → Task output
  - GNN-LLM alignment: Graph/text data → Respective encoders → Alignment (contrastive learning/distillation) → Joint embeddings → Task prediction
- Design tradeoffs: LLM-based approaches offer strong text understanding but may be computationally expensive with context length limitations; GNN-based approaches are efficient for structural learning but may struggle with complex text attributes; alignment approaches aim for balanced integration but require paired graph-text data
- Failure signatures: Poor performance due to irrelevant or low-quality LLM-generated content; overfitting when fine-tuning LLMs on small graph datasets; scalability issues when processing large graphs with LLMs; data leakage if test data is inadvertently seen during LLM pre-training
- First 3 experiments:
  1. Implement LLM-as-enhancer approach on small text-attributed graph dataset (e.g., Cora) to test effectiveness of LLM-generated explanations
  2. Try flattening a graph into text and using pre-trained LLM to make predictions on node classification task, comparing performance with standard GNN
  3. Set up contrastive learning framework for GNN-LLM alignment on molecule dataset with paired graph-text data to evaluate alignment quality and downstream task performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effectively do LLMs understand graph structures, and can their expressive ability surpass those of GNNs or the WL-test?
- Basis in paper: [explicit] The paper discusses that standard message-passing neural networks are as expressive as the 1-Weisfeiler-Lehman (WL) test, meaning they fail to distinguish non-isomorphic graphs under 1-hop aggregation. It then poses fundamental questions about LLMs' theoretical expressive power and whether they can surpass GNNs or the WL-test.
- Why unresolved: The theoretical expressive power of LLMs in understanding graph structures remains largely unexplored, and there is a lack of empirical evidence comparing their performance to GNNs and the WL-test.
- What evidence would resolve it: Empirical studies comparing the expressive power of LLMs, GNNs, and the WL-test on various graph datasets and tasks, as well as theoretical analyses of LLMs' capabilities in capturing graph structures.

### Open Question 2
- Question: How can we effectively leverage LLMs to help in constructing graph foundation models for non-text-attributed graphs?
- Basis in paper: [explicit] The paper highlights the challenge of applying LLMs to graph-structured data lacking rich textual information, such as traffic networks or superpixel graphs. It suggests exploring how to leverage LLMs' generalization capabilities to construct graph foundation models for such datasets.
- Why unresolved: Current LLM approaches primarily focus on text-attributed graphs, and there is limited research on extending their capabilities to non-text-attributed graphs. The challenge lies in describing the semantic meaning of nodes in these graphs using human-understandable language.
- What evidence would resolve it: Development and evaluation of LLM-based methods that can effectively handle non-text-attributed graphs, demonstrating improved performance on graph-related tasks compared to traditional GNNs.

### Open Question 3
- Question: How can we improve the transferability of graph-related tasks using the knowledge embedded within LLMs?
- Basis in paper: [explicit] The paper acknowledges the challenge of transferability in the graph domain and suggests that while LLMs have shown promising zero/few-shot abilities in language tasks, their potential to enhance the transferability of graph-related tasks remains relatively unexplored.
- Why unresolved: Graphs can vary significantly in terms of size, connectivity, node types, edge types, and overall topology, making it difficult to directly transfer knowledge between them. Current research has not fully explored how LLMs' knowledge can be leveraged to improve transferability in graph-related tasks.
- What evidence would resolve it: Development and evaluation of methods that utilize LLMs to improve the transferability of graph-related tasks across different datasets and domains, demonstrating enhanced performance compared to traditional GNN-based approaches.

## Limitations
- Limited discussion of non-text-attributed graphs, representing a significant research gap
- Insufficient empirical comparisons between different integration approaches
- Heavy reliance on commercial LLM APIs, which may not be accessible to all researchers
- Potential data leakage when using pre-trained LLMs that may have seen test data during training

## Confidence
- High confidence: Identifying key trends and challenges in LLM-graph integration field
- Medium confidence: Completeness of proposed taxonomy given rapidly evolving nature of both fields
- Low confidence: Specific implementation details for many methods due to lack of technical specifications

## Next Checks
1. Implement controlled experiment comparing LLM-as-enhancer versus traditional GNN approaches on standard text-attributed graph dataset, measuring both performance and computational efficiency
2. Conduct scalability analysis by testing same integration method on graphs of increasing size (100 to 1M nodes) to quantify performance degradation and resource requirements
3. Design data leakage assessment framework to evaluate risk of using pre-trained LLMs on specific graph datasets, particularly those with common domain entities or descriptions