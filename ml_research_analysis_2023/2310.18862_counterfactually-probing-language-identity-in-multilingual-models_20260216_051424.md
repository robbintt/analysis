---
ver: rpa2
title: Counterfactually Probing Language Identity in Multilingual Models
arxiv_id: '2310.18862'
source_url: https://arxiv.org/abs/2310.18862
tags:
- language
- word
- english
- direction
- template
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We use a method of counterfactual probing to explore the internal
  structure of multilingual models (mBERT and XLM-R). We train a linear classifier
  on a binary language identity task, to classify tokens between Language X and Language
  Y.
---

# Counterfactually Probing Language Identity in Multilingual Models

## Quick Facts
- arXiv ID: 2310.18862
- Source URL: https://arxiv.org/abs/2310.18862
- Reference count: 14
- Primary result: Counterfactual probing reveals language identity is partially linearly separable in multilingual models, with systematic but non-translation-specific effects on masked language modeling probabilities

## Executive Summary
This paper introduces a counterfactual probing methodology to explore how multilingual models like mBERT and XLM-R encode language identity. By training linear classifiers to distinguish between languages and then using iterative nullspace projection (INLP) combined with AlterRep manipulation, the authors systematically remove and reintroduce language identity information in token embeddings. The experiments show that language identity can be partially extracted using linear methods, and that counterfactual interventions can shift language probabilities in masked language modeling tasks, though not specifically toward translation equivalents.

## Method Summary
The method combines three key components: first, training a linear SVM classifier on token embeddings to distinguish between two languages (L1 vs L2); second, applying Iterative Nullspace Projection (INLP) to iteratively remove language identity information by projecting embeddings onto classifier nullspaces; and third, using AlterRep to manipulate embeddings by pushing them in directions orthogonal to the nullspace, effectively increasing the probability of words from a target language. The effectiveness is evaluated by masking tokens in sentences and measuring changes in word probabilities, comparing target words, random words, and third-party control words.

## Key Results
- Language identity information is partially linearly separable from semantic content in multilingual embeddings
- Counterfactual manipulation via AlterRep systematically increases probability of words from the pushed-to language above control conditions
- The intervention does not specifically boost translation-equivalent words, only general language membership
- XLM-R shows more sensitivity to language identity removal than mBERT, with greater MLM performance degradation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language identity information is linearly separable and extractable from multilingual model embeddings
- Mechanism: A linear SVM classifier trained on token embeddings from two languages can distinguish between them with high accuracy
- Core assumption: Language identity is encoded in a linearly separable subspace of the embedding space
- Evidence anchors:
  - [abstract] "We train a linear classifier on a binary language identity task, to classify tokens between Language X and Language Y"
  - [section] "The classifier learns to predict whether a given token is extracted from the English or non-English language"
  - [corpus] "Average neighbor FMR=0.373, average citations=0.0" - weak evidence, no direct citations
- Break condition: If language identity is encoded non-linearly or mixed with semantic content in a way that cannot be separated by linear methods

### Mechanism 2
- Claim: Nullspace projection can remove language identity information while preserving semantic content
- Mechanism: Iterative Nullspace Projection (INLP) uses classifier weights to project embeddings onto the intersection of nullspaces, removing the information needed for language classification
- Core assumption: Language identity and semantic content are largely orthogonal in the embedding space
- Evidence anchors:
  - [section] "INLP uses the weights learned by each classifier to project the embedding ht onto the intersection of nullspaces of the classifiers hN t"
  - [section] "we chose 4 iterations for XLM-R and mBERT" - shows INLP can be applied without destroying model performance
  - [corpus] "Probing the Feasibility of Multilingual Speaker Anonymization" - related work on probing multilingual models
- Break condition: If language identity and semantic content are too entangled, INLP may degrade semantic representations along with language identity

### Mechanism 3
- Claim: Altering embeddings along the classifier weight direction can systematically shift language probabilities
- Mechanism: AlterRep uses the orthogonal component to push embeddings in the direction of a particular language, increasing the probability of words from that language
- Core assumption: The orthogonal component contains the information needed for language classification and can be manipulated to shift language probabilities
- Evidence anchors:
  - [abstract] "we use the classifier weights to project the embeddings into the null space and push the resulting embeddings either in the direction of Language X or Language Y"
  - [section] "The counterfactual vector h′ t is created as follows: h′ t = hN t + α X wi S ∗ hwi t"
  - [corpus] "Discriminating Form and Meaning in Multilingual Models with Minimal-Pair ABX Tasks" - related work on evaluating multilingual representations
- Break condition: If the manipulation causes the model to generate nonsensical outputs or if the probability shifts are not language-specific

## Foundational Learning

- Concept: Linear algebra and vector spaces
  - Why needed here: Understanding nullspace projection, orthogonal components, and vector manipulation
  - Quick check question: What is the nullspace of a matrix and how is it used in linear algebra?

- Concept: Machine learning classification
  - Why needed here: Understanding how the language ID classifier works and how its weights are used for intervention
  - Quick check question: How does a linear SVM classifier work and what do its weights represent?

- Concept: Masked language modeling
  - Why needed here: Understanding how the model generates probabilities for masked tokens and how these are evaluated
  - Quick check question: What is the difference between a token's probability and its log probability in a masked language modeling task?

## Architecture Onboarding

- Component map: Token embedding → Language ID classifier → INLP projection → AlterRep manipulation → Masked LM evaluation
- Critical path: Token embedding → Language ID classifier → INLP projection → AlterRep manipulation → Masked LM evaluation
- Design tradeoffs:
  - Number of INLP iterations vs. model degradation
  - Choice of α parameter vs. magnitude of intervention
  - Use of parallel vs. code-mixed data for classifier training
- Failure signatures:
  - Classifier accuracy drops to chance before language ID information is fully removed
  - MLM accuracy drops significantly after intervention
  - Probability shifts are not language-specific or are too small to be meaningful
- First 3 experiments:
  1. Train language ID classifier on simple parallel corpus and verify accuracy
  2. Apply INLP with varying iterations and measure impact on MLM performance
  3. Apply AlterRep with different α values and measure probability shifts for target vs. random words

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does XLM-R show more sensitivity to language identity information than mBERT in terms of MLM performance degradation during INLP iterations?
- Basis in paper: [explicit] The paper notes that running INLP for the same number of iterations more catastrophically affects the overall MLM performance for XLM-R than it does mBERT, and suggests this as an interesting observation for future work.
- Why unresolved: The paper does not provide an explanation for this difference between the two models.
- What evidence would resolve it: Comparative analysis of the architectural differences between XLM-R and mBERT, particularly focusing on how they handle language-specific vs. language-general components, could provide insights. Additionally, experiments varying the number of INLP iterations and observing the point at which each model's MLM performance significantly degrades could help understand the underlying mechanisms.

### Open Question 2
- Question: Can the AlterRep method be used to achieve practical machine translation by specifically boosting the probability of translation-equivalent words?
- Basis in paper: [explicit] The paper concludes that while AlterRep can increase the probability of words in the pushed-to language, it does not specifically boost the probability of translation-equivalent words.
- Why unresolved: The paper does not explore whether modifications to the AlterRep method or additional techniques could be used to specifically enhance translation-equivalent word probabilities.
- What evidence would resolve it: Experiments that modify the AlterRep method to include semantic similarity constraints or integrate it with other translation models could determine if practical machine translation is achievable. Additionally, testing the method on a wider range of language pairs and contexts could provide further insights.

### Open Question 3
- Question: Why does code-mixed data show more robustness to INLP intervention compared to non-code-mixed data?
- Basis in paper: [explicit] The paper observes that the performance of code-mixed data decays at a different rate compared to non-code-mixed data during INLP iterations, suggesting robustness.
- Why unresolved: The paper does not investigate the reasons behind this observed robustness of code-mixed data to INLP intervention.
- What evidence would resolve it: Detailed analysis of the internal representations of code-mixed versus non-code-mixed data in multilingual models could reveal structural differences. Experiments that vary the proportion of code-mixing and measure the impact on INLP effectiveness could also provide insights into the mechanisms behind this robustness.

## Limitations

- The linear classifier approach may miss non-linear patterns in language identity encoding
- The choice of α parameter for AlterRep manipulation lacks systematic exploration across different language pairs
- The intervention increases general language membership probabilities but not specifically translation-equivalent words

## Confidence

High confidence in the core methodology and experimental design with robust control conditions.
Medium confidence in the interpretation that language identity is "partially" linearly separable.
Low confidence in claims about translation equivalence due to the intervention's non-specific nature.

## Next Checks

1. **Parameter sensitivity analysis**: Systematically vary the α parameter in AlterRep across a wider range (e.g., 0.05 to 1.0) and measure how probability shifts scale with manipulation strength for different language pairs.

2. **Non-linear probing baseline**: Compare the linear classifier approach against a non-linear probing method (e.g., MLP with multiple layers) to assess what fraction of language identity information is linearly separable versus requiring non-linear extraction.

3. **Cross-lingual semantic alignment test**: Design an experiment specifically targeting translation equivalents by creating minimal pairs where only the language changes but meaning stays constant, then measure whether AlterRep can selectively increase probabilities of translation-equivalent words versus unrelated words in the target language.