---
ver: rpa2
title: Achieving Reliable and Fair Skin Lesion Diagnosis via Unsupervised Domain Adaptation
arxiv_id: '2307.03157'
source_url: https://arxiv.org/abs/2307.03157
tags:
- skin
- domain
- lesion
- target
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigates the application of unsupervised domain
  adaptation (UDA) methods to improve skin lesion classification across multiple datasets.
  The authors evaluate three UDA training schemes: single-source, combined-source,
  and multi-source.'
---

# Achieving Reliable and Fair Skin Lesion Diagnosis via Unsupervised Domain Adaptation

## Quick Facts
- arXiv ID: 2307.03157
- Source URL: https://arxiv.org/abs/2307.03157
- Reference count: 28
- Primary result: UDA methods improve skin lesion classification accuracy and fairness, especially in binary tasks with resampling.

## Executive Summary
This study applies unsupervised domain adaptation (UDA) to improve skin lesion classification across multiple public datasets. The authors evaluate three UDA training schemes (single-source, combined-source, multi-source) and demonstrate significant performance gains over baseline classifiers in binary classification tasks. The research also reveals that UDA can reduce bias against minority groups and enhance fairness in diagnostic systems without explicit fairness constraints, with the best results achieved through multi-source UDA methods combined with resampling strategies.

## Method Summary
The study evaluates unsupervised domain adaptation for skin lesion classification using six public datasets (ISIC 2018, ISIC 2020, PAD-UFES-20, Fitzpatrick17k, Derm7pt-Derm, Derm7pt-Clinic). Images are resized to 64×64 pixels and ROI preprocessing is applied to Fitzpatrick17k. Three UDA schemes are tested: single-source (DANN, ADDA), combined-source (ADDA, DANN), and multi-source (MDAN, M3SDA). Imbalance techniques (resampling, reweighting) are incorporated. A pre-trained VGG16-BN serves as feature extractor, and experiments evaluate binary classification (AUROC) and multi-class classification (accuracy) with fairness metrics (PQD, DPM, EOM).

## Key Results
- UDA methods show significant improvement over baseline classifiers in binary classification, especially when combined with resampling techniques
- Multi-source UDA methods outperform single-source approaches, with M3SDA plus resampling yielding the best results
- UDA can reduce bias against minority groups and enhance fairness in diagnostic systems without explicit fairness-focused techniques

## Why This Works (Mechanism)

### Mechanism 1
- Claim: UDA methods improve skin lesion classification by aligning feature distributions between source and target domains
- Mechanism: Adversarial training (e.g., DANN, ADDA) learns domain-invariant features, reducing the impact of dataset-specific acquisition differences
- Core assumption: Feature-level alignment is sufficient to generalize classification performance when labeled target data is unavailable
- Evidence anchors:
  - [abstract] "UDA methods show significant improvement over baseline classifiers, especially when combined with resampling techniques"
  - [section 3.2] "reweighting leverages wi to compute a weighted cross-entropy loss"
- Break condition: Label shift between source and target is too large for feature alignment alone to compensate, as seen in multi-class tasks

### Mechanism 2
- Claim: Multi-source UDA methods outperform single-source methods due to richer and more diverse source domain representation
- Mechanism: MDAN and M3SDA jointly align multiple source domains to the target, capturing broader domain variations
- Core assumption: Increased diversity in source domains reduces the domain gap to the target and mitigates bias
- Evidence anchors:
  - [abstract] "The best results are achieved using multi-source UDA methods, particularly when combined with resampling strategies"
  - [section 4.2] "M3SDA with resampling yields the best result, which are also the best among all the pipelines for binary classification"
- Break condition: When label distributions across sources are highly mismatched, combining sources may introduce more noise than benefit

### Mechanism 3
- Claim: UDA improves fairness by reducing bias against minority groups without explicit fairness constraints
- Mechanism: Training on diverse, multi-source datasets with UDA implicitly balances learned representations across demographic subgroups
- Core assumption: Demographic information is captured in the source domains and transferred to the target through domain alignment
- Evidence anchors:
  - [abstract] "UDA can effectively reduce bias against minority groups and enhance fairness in diagnostic systems, while maintaining superior classification performance"
  - [section 4.3] "UDA ensures equal opportunities for accurate diagnoses across various groups, an important achievement in medical imaging analysis"
- Break condition: If source domains lack demographic diversity, UDA cannot correct for underrepresentation in the target

## Foundational Learning

- Concept: Unsupervised Domain Adaptation (UDA)
  - Why needed here: Labeled skin lesion data is scarce in target domains, so UDA leverages abundant labeled data from external sources
  - Quick check question: What is the key difference between supervised and unsupervised domain adaptation?

- Concept: Label shift and feature shift
  - Why needed here: Understanding how differences in class distributions (label shift) versus feature distributions (feature shift) affect classifier performance
  - Quick check question: Which type of shift—label or feature—was found to be more strongly correlated with test error in this study?

- Concept: Resampling and reweighting for imbalanced data
  - Why needed here: Skin lesion datasets are often imbalanced, and imbalance techniques improve both accuracy and fairness
  - Quick check question: How does the resampling strategy adjust mini-batch sampling based on label distribution differences?

## Architecture Onboarding

- Component map: Data preprocessing → ROI cropping → Dataset split → UDA training (single/combined/multi-source) → Evaluation (AUROC / accuracy) → Fairness metrics
- Critical path: ROI preprocessing → Dataset preparation → UDA model training → Evaluation pipeline
- Design tradeoffs: Using smaller image size (64×64) speeds experiments but may lose fine-grained lesion details; multi-source methods increase diversity but also complexity
- Failure signatures: Performance drop in multi-class tasks suggests label shift is not addressed by feature-level UDA alone; fairness gains without explicit fairness loss indicate implicit bias reduction
- First 3 experiments:
  1. Train a baseline classifier on combined source data without UDA and measure AUROC on binary target task
  2. Apply DANN to the same combined source pipeline and compare performance and fairness metrics
  3. Train MDAN with multiple sources and evaluate both accuracy and demographic disparity metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do feature-level UDA methods show limitations in handling imbalanced multi-class skin lesion datasets?
- Basis in paper: [explicit] The paper states "Through our quantitative analysis, we find that the test error of multi-class tasks is strongly correlated with label shift, and feature-level UDA methods have limitations when handling imbalanced datasets"
- Why unresolved: The authors speculate this is because feature-level UDA methods focus on mitigating feature distribution shifts rather than addressing label shift, but they don't provide experimental evidence or theoretical analysis to confirm this
- What evidence would resolve it: Comparative experiments testing UDA methods that specifically address label shift (such as class-balanced domain adaptation techniques) versus feature-level methods on the same imbalanced datasets would clarify whether label shift is indeed the primary limitation

### Open Question 2
- Question: What is the exact mechanism by which UDA reduces bias against minority groups in skin lesion diagnosis?
- Basis in paper: [explicit] The paper notes "Crucially, our study shows that UDA can effectively mitigate bias against minority groups and enhance fairness in diagnostic systems, while maintaining superior classification performance. This is achieved even without directly implementing fairness-focused techniques"
- Why unresolved: While the authors observe that UDA improves fairness metrics, they don't investigate the underlying mechanism. They suggest it might be due to "increased and well-adapted demographic information obtained from multiple sources," but this is speculative
- What evidence would resolve it: Ablation studies analyzing the demographic representation in learned features before and after UDA, or controlled experiments varying the demographic diversity of source domains, would reveal whether UDA's fairness improvement stems from better demographic coverage or some other mechanism

### Open Question 3
- Question: How would UDA performance change if target domain labels were partially available during training?
- Basis in paper: [inferred] The paper explicitly focuses on unsupervised domain adaptation where target labels are unavailable, but doesn't explore semi-supervised scenarios. The strong correlation between label shift and test error suggests that even limited target label information could be valuable
- Why unresolved: The authors don't investigate semi-supervised domain adaptation approaches, likely because their focus is on the fully unsupervised setting where labeled data is scarce
- What evidence would resolve it: Experiments comparing UDA methods against semi-supervised domain adaptation techniques using varying amounts of target labels would quantify the performance gap and determine whether the additional labeling effort is worthwhile

## Limitations
- UDA methods primarily handle feature distribution shift, but label distribution mismatches between domains (especially in multi-class tasks) remain a key performance bottleneck
- Using 64×64 pixels may limit the ability to capture fine-grained lesion features, potentially affecting both accuracy and fairness outcomes
- While the study shows fairness improvements, these are achieved without explicit fairness constraints, making it unclear whether fairness gains will generalize to other datasets or tasks

## Confidence
- High: UDA methods improve binary classification performance when combined with resampling techniques; multi-source UDA outperforms single-source methods; fairness metrics improve without explicit fairness constraints
- Medium: Multi-class UDA effectiveness is limited by label shift; the mechanism for fairness gains is plausible but not rigorously validated
- Low: The study's fairness conclusions rely on implicit demographic representation in source domains without explicit demographic labels

## Next Checks
1. Quantify and visualize label distribution differences between source and target domains for multi-class tasks; assess correlation with performance gaps
2. Repeat key experiments with higher resolution images (e.g., 224×224) to evaluate impact on both accuracy and fairness metrics
3. Implement fairness-aware loss functions and compare against implicit UDA fairness gains to determine if explicit methods provide additional benefits