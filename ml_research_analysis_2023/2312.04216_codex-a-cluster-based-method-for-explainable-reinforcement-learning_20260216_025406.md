---
ver: rpa2
title: 'CODEX: A Cluster-Based Method for Explainable Reinforcement Learning'
arxiv_id: '2312.04216'
source_url: https://arxiv.org/abs/2312.04216
tags:
- cluster
- tags
- agent
- clusters
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CODEX introduces a method for explainable reinforcement learning
  by clustering semantic representations of RL agent behaviors. The approach uses
  language models (BERT, BERTweet, MiniLM) to generate embeddings of state-action
  descriptions, applies UMAP for dimensionality reduction, and uses HDBSCAN for semantic
  clustering.
---

# CODEX: A Cluster-Based Method for Explainable Reinforcement Learning

## Quick Facts
- arXiv ID: 2312.04216
- Source URL: https://arxiv.org/abs/2312.04216
- Reference count: 15
- Key outcome: Introduces CODEX, a method for explainable RL using semantic clustering of agent behaviors

## Executive Summary
CODEX provides a novel approach to explainable reinforcement learning by clustering semantic representations of RL agent behaviors. The method generates natural language tags for state-action pairs, creates contextualized embeddings using language models, applies dimensionality reduction and clustering, and constructs episode summaries using topic modeling. Experiments on MiniGrid and StarCraft II demonstrate that MiniLM achieves comparable clustering performance to larger models while being significantly faster, and that semantic clusters retain meaningful temporal and entity information reflected in the constructed summaries.

## Method Summary
CODEX creates explainable RL by processing state-action descriptions through a pipeline of language model embeddings, UMAP dimensionality reduction, HDBSCAN clustering, and LDA topic modeling. State-action tags are encoded into embeddings using language models (BERT-base, BERTweet, or MiniLM), reduced to 2D via UMAP, and clustered with HDBSCAN. An LDA topic model selects exemplar tags from each cluster to construct concise episode summaries. The approach is validated on MiniGrid and StarCraft II environments, demonstrating semantic clustering that retains temporal and entity information.

## Key Results
- MiniLM achieves comparable clustering performance to BERT-base and BERTweet while being 23M parameters vs 109M/135M and significantly faster (0.059s vs 0.356s/0.441s)
- Semantic clusters retain temporal and entity information, reflected in constructed episode summaries
- Clustering discrete+continuous game-state latent representations identifies crucial episodic events, demonstrating relationship between latent and semantic spaces

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantic clustering of state-action embeddings produces interpretable episode summaries
- Mechanism: State-action descriptions encoded into dense vectors using language models, reduced via UMAP, clustered using HDBSCAN, and summarized using LDA topic model
- Core assumption: Short natural language tags retain enough semantic information for meaningful clustering and summarization
- Evidence anchors: [abstract] Semantic clusters retain temporal and entity information; [section] Summarization pipeline components described; [corpus] Weak corpus evidence
- Break condition: If semantic embeddings lose essential information or LDA fails to extract coherent topics, summaries become uninformative

### Mechanism 2
- Claim: Clustering in latent space identifies crucial episodic events and reveals relationships between latent and semantic spaces
- Mechanism: DreamerV2's world model generates latent state vectors, clustered with UMAP and HDBSCAN, revealing event boundaries
- Core assumption: Latent representations encode meaningful temporal structure aligning with observable events
- Evidence anchors: [abstract] Clustering identifies crucial episodic events; [section] Figure 3 shows latent clusters revealing door opening transition; [corpus] Weak corpus evidence
- Break condition: If latent representations lack temporal coherence, clusters won't align with meaningful events

### Mechanism 3
- Claim: MiniLM provides comparable clustering performance to larger models with significantly better efficiency
- Mechanism: MiniLM (23M parameters) generates embeddings faster than BERT-base (109M) or BERTweet (135M) while achieving similar silhouette scores and global cosine similarity
- Core assumption: Smaller, faster models can capture sufficient semantic distinctions in short text for clustering
- Evidence anchors: [section] MiniLM chosen for smaller size, speed, and comparable performance; [section] MiniLM produces embeddings in 0.059s vs 0.356s/0.441s; [corpus] Weak corpus evidence
- Break condition: If clustering quality degrades significantly on complex environments, efficiency advantage may not justify performance trade-off

## Foundational Learning

- Concept: Transformer-based language models and embedding generation
  - Why needed here: CODEX relies on contextualized embeddings of state-action descriptions for clustering and summarization
  - Quick check question: What is the difference between BERT-base and MiniLM in terms of architecture and intended use?

- Concept: Dimensionality reduction (UMAP) and density-based clustering (HDBSCAN)
  - Why needed here: Raw embeddings are high-dimensional; UMAP reduces them for visualization and clustering, while HDBSCAN identifies semantically coherent groups without preset cluster count
  - Quick check question: How does HDBSCAN's "min cluster size" parameter affect the granularity of resulting clusters?

- Concept: Latent space representations from world models (DreamerV2)
  - Why needed here: DreamerV2's RSSM learns compressed latent state encoding environment dynamics, with clustering revealing episodic structure
  - Quick check question: What is the role of the encoder-decoder VAE in DreamerV2's architecture?

## Architecture Onboarding

- Component map: State-action tagging → Language model (MiniLM) → UMAP → HDBSCAN → LDA topic extraction → Summary
- Critical path: Tagging → Embedding → Clustering → Summarization
- Design tradeoffs:
  - MiniLM vs larger models: speed and efficiency vs potential loss of nuance in embeddings
  - UMAP vs other DR methods: preservation of local structure vs global structure
  - HDBSCAN vs k-means: automatic cluster count vs need for parameter tuning
- Failure signatures:
  - Low silhouette scores or high noise percentage → embeddings not semantically separable
  - LDA produces incoherent topics → text too short or embeddings too noisy
  - Latent clusters don't align with events → latent space lacks meaningful temporal structure
- First 3 experiments:
  1. Generate MiniGrid episode tags and compare MiniLM, BERT-base, and BERTweet embeddings for clustering performance (silhouette score, global cosine similarity)
  2. Run UMAP + HDBSCAN on MiniLM embeddings with varying "min cluster size" to observe summary length and detail trade-offs
  3. Extract DreamerV2 latent states from a MiniGrid episode and cluster them to identify transition points corresponding to events like "door open" or "key pickup"

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of language model impact the quality and efficiency of semantic clustering in CODEX?
- Basis in paper: [explicit] Paper compares BERT-base, BERTweet, and MiniLM, showing MiniLM achieves comparable performance while being significantly faster and smaller
- Why unresolved: While initial comparisons are provided, comprehensive study across diverse environments and varying task complexities is needed
- What evidence would resolve it: Extensive experiments comparing multiple language models across wide range of RL environments, considering clustering quality, computational efficiency, and domain-specific language understanding

### Open Question 2
- Question: Can CODEX be extended to handle more complex and semantically diverse environments beyond MiniGrid and StarCraft II?
- Basis in paper: [inferred] Paper mentions exploring limits with respect to episode length and state complexity as future direction
- Why unresolved: Experiments limited to two specific environments, leaving generalizability and scalability to more complex tasks open
- What evidence would resolve it: Applying CODEX to broader range of RL environments with varying complexity, state space dimensionality, and semantic diversity

### Open Question 3
- Question: How can CODEX be integrated with abstractive summarization techniques to enhance informativeness of generated summaries?
- Basis in paper: [explicit] Paper mentions possibility of leveraging CODEX for summarizing collections of counterfactuals using hierarchical summarization techniques
- Why unresolved: While CODEX currently uses extractive approach, potential benefits and challenges of integrating abstractive summarization remain unexplored
- What evidence would resolve it: Developing and evaluating hybrid approaches combining CODEX's semantic clustering with abstractive summarization models

## Limitations
- Approach depends heavily on quality of short-text embeddings; risk of losing semantic nuance with 5-6 word tags
- Clustering results rely on subjective visual interpretation rather than quantitative event detection
- Choice of UMAP parameters and HDBSCAN's "min cluster size" significantly affects results but optimal settings may be environment-specific

## Confidence
- High confidence: Core mechanism of MiniLM providing efficient, semantically meaningful embeddings for short-text clustering in RL explainability tasks
- Medium confidence: Latent space analysis showing clusters align with episodic events, though quantitative validation is limited
- Low confidence: Scalability claims to longer episodes, more complex environments, or less structured entity information

## Next Checks
1. Cross-environment robustness test: Apply CODEX to third RL environment (e.g., Atari games) and measure clustering performance and summary quality
2. Embedding ablation study: Systematically vary tag length (2, 4, 6, 8 words) and measure impact on silhouette score and summary coherence
3. Latent-event alignment quantification: Develop automatic event boundary detection in latent space clusters and measure precision/recall against ground-truth event labels in MiniGrid episodes