---
ver: rpa2
title: A Transfer Learning Approach to Minimize Reinforcement Learning Risks in Energy
  Optimization for Smart Buildings
arxiv_id: '2305.00365'
source_url: https://arxiv.org/abs/2305.00365
tags:
- building
- learning
- transfer
- relbot
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the "cold start" problem in reinforcement
  learning (RL) for smart building energy optimization, where lack of historical data
  leads to suboptimal performance and potential discomfort during initial deployment.
  The authors present ReLBOT, a transfer learning approach that leverages knowledge
  from an existing, optimized smart building to improve the performance of RL in a
  new building with no historical data.
---

# A Transfer Learning Approach to Minimize Reinforcement Learning Risks in Energy Optimization for Smart Buildings

## Quick Facts
- arXiv ID: 2305.00365
- Source URL: https://arxiv.org/abs/2305.00365
- Reference count: 11
- Key outcome: Transfer learning reduces RL warm-up period by up to 6.2x and reward variance by up to 132x in smart building energy optimization

## Executive Summary
This paper addresses the "cold start" problem in reinforcement learning for smart building energy optimization, where new buildings lack historical data needed for effective RL training. The authors present ReLBOT, a transfer learning approach that leverages knowledge from an existing, optimized smart building to improve the performance of RL in a new building. By initializing the critic network with weights from a transfer building model and incrementally adapting to the target building's specific characteristics, ReLBOT significantly reduces the warm-up period duration and reward variance compared to RL without transfer learning.

## Method Summary
ReLBOT uses an actor-critic deep reinforcement learning architecture where the critic shares knowledge from a transfer building model to the actor. The method involves collecting historical sensor data from both transfer and target buildings, calculating feature vector similarity based on statistical properties (kurtosis, skew, mean), and initializing the critic network with weights from a transfer building's COP regression task. The system then incrementally retrains the critic after each action using actual reward data from the target building, gradually adapting the transferred knowledge to the specific characteristics of the new building.

## Key Results
- ReLBOT reduces warm-up period duration by up to 6.2 times compared to standard RL
- Warm-up reward variance is reduced by up to 132 times using transfer learning
- Mean reward variance is reduced by up to 32 times in target buildings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transfer learning from an optimized building reduces the RL agent's exploration noise during the warm-up period.
- Mechanism: The critic in the actor-critic architecture is initialized with weights trained on the transfer building's COP regression task. This pretrained knowledge provides a good initial estimate of reward values, allowing the actor to make more informed decisions from the start.
- Core assumption: The transfer building's feature space and reward structure are sufficiently similar to the target building's to provide useful initial guidance.
- Evidence anchors:
  - [abstract]: "transfer knowledge from an existing, optimized and instrumented building, to the newly commissioning smart building"
  - [section]: "The critic is initialized using knowledge ωs produced by the target building regression task Ts. The critic is then incrementally retrained after each time that the input vector Xt is presented."
  - [corpus]: Weak evidence. Only 5 corpus papers relate to RL and transfer learning in building energy, none specifically discussing this mechanism.
- Break condition: If the feature vectors are too dissimilar (low similarity score), the transferred knowledge could mislead the agent, causing poor performance.

### Mechanism 2
- Claim: Building similarity measurement enables selection of the most appropriate transfer building.
- Mechanism: Similarity is calculated based on normalized kurtosis, skew, and mean values of feature vectors. Buildings with similar statistical properties are more likely to benefit from transfer learning.
- Core assumption: Statistical similarity of feature vectors correlates with transferability of control policies.
- Evidence anchors:
  - [abstract]: "The effectiveness of transfer learning is shown to be positively correlated with the similarity between the transfer and target buildings"
  - [section]: "In order to calculate similarity some historical data must be available for both the transfer and the target building... The algorithm then iterates through all of the features in the transfer building feature vector and tries to find a similar feature in the target building feature vector."
  - [corpus]: No direct evidence in corpus papers about similarity-based transfer building selection.
- Break condition: If similarity calculation is based on insufficient or unrepresentative data, the wrong transfer building may be selected, reducing or eliminating benefits.

### Mechanism 3
- Claim: Incremental retraining of the critic with actual reward data allows adaptation to the target building's specific characteristics.
- Mechanism: After each action, the critic is updated with the actual reward from the Building Environment component, gradually refining the transferred knowledge to better fit the target building.
- Core assumption: The initial transferred knowledge provides a better starting point than random initialization, even as the model adapts to the target building.
- Evidence anchors:
  - [abstract]: "ReLBOT uses an actor-critic deep reinforcement learning agent, where the critic shares knowledge from a transfer building model to the actor"
  - [section]: "The critic is incrementally retrained at every step. Immediately after re-training ReLBOT uses transfer learning to update the Actor ANN using a sub-set of Critic's weights and biases (Ts⇒Tt c)."
  - [corpus]: No direct evidence in corpus papers about incremental retraining in this context.
- Break condition: If the initial transferred knowledge is too far from optimal, the agent may take a long time to unlearn incorrect patterns, negating the benefits of transfer learning.

## Foundational Learning

- Concept: Actor-critic reinforcement learning
  - Why needed here: ReLBOT uses an actor-critic architecture to balance exploration (actor choosing actions) and evaluation (critic estimating rewards).
  - Quick check question: What are the two main components of an actor-critic RL algorithm and what are their respective roles?

- Concept: Transfer learning in neural networks
  - Why needed here: Knowledge from the transfer building's trained model is copied to initialize the target building's model, providing a better starting point than random initialization.
  - Quick check question: In transfer learning, what is typically transferred between models, and why is this useful for the cold start problem?

- Concept: Building energy optimization metrics
  - Why needed here: COP (Coefficient of Performance) is used as the reward function, so understanding building energy systems is crucial for interpreting results.
  - Quick check question: How is COP calculated for a chiller system, and why is it a good metric for building energy optimization?

## Architecture Onboarding

- Component map: Building sensor data -> ReLBOT Actor -> Action selection -> Building Environment -> Reward calculation -> ReLBOT Critic retraining -> Knowledge transfer to Actor
- Critical path: Target building sensor data → ReLBOT Actor → Action selection → Building Environment → Reward calculation → ReLBOT Critic retraining → Knowledge transfer to Actor
- Design tradeoffs: Using a simpler similarity metric (kurtosis, skew, mean) vs. more complex methods; choosing the number of shared layers for transfer learning
- Failure signatures: High variance in predicted rewards during warm-up indicates poor transfer; failure to find COP optimum suggests insufficient adaptation
- First 3 experiments:
  1. Run ReLBOT on a single building without transfer learning to establish baseline performance.
  2. Test ReLBOT with transfer learning using a very similar building (high similarity score) and compare warm-up period duration.
  3. Test ReLBOT with transfer learning using a dissimilar building (low similarity score) to verify that performance degrades as expected.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the ReLBOT approach scale when transferring knowledge from buildings with significantly different numbers of thermal zones or varying HVAC equipment configurations?
- Basis in paper: [explicit] The paper mentions that Xu et al. (2020) found the approach effective even when buildings had differing numbers of thermal zones, materials and layouts, HVAC equipment, and weather conditions, but does not explore this systematically.
- Why unresolved: The paper focuses on buildings with similar HVAC systems and does not systematically test transfer learning effectiveness across buildings with different numbers of thermal zones or varying equipment configurations.
- What evidence would resolve it: Experiments testing ReLBOT's performance across a wider range of building types with varying numbers of thermal zones and different HVAC equipment configurations would provide evidence for scalability.

### Open Question 2
- Question: What is the optimal method for selecting the most appropriate donor building when multiple candidates are available, beyond the similarity metric proposed in the paper?
- Basis in paper: [explicit] The paper presents a similarity metric for selecting donor buildings but acknowledges that "the effectiveness of transfer learning among buildings depends on the choice of the transfer building."
- Why unresolved: While the paper proposes a similarity metric, it does not explore other potential methods for donor building selection or validate whether this metric is optimal.
- What evidence would resolve it: Comparative studies testing different donor building selection methods (e.g., similarity-based, performance-based, or hybrid approaches) would help identify the optimal selection strategy.

### Open Question 3
- Question: How does ReLBOT perform when applied to building energy optimization tasks beyond cooling, such as heating or combined heating and cooling optimization?
- Basis in paper: [explicit] The paper concludes by mentioning that "Future work includes extending ReLBOT to optimize building performance during the heating cycle (boiler efficiency)" but does not provide any results for this extension.
- Why unresolved: The current ReLBOT implementation focuses on cooling optimization, and its effectiveness for other energy optimization tasks remains untested.
- What evidence would resolve it: Experiments applying ReLBOT to heating optimization and combined heating and cooling optimization tasks would demonstrate its versatility and effectiveness across different energy management scenarios.

## Limitations

- Limited generalizability due to evaluation based on only three real buildings
- Similarity metric based on kurtosis, skew, and mean values may be too simplistic to capture complex building relationships
- No extensive statistical validation across multiple trials or building types to confirm reported variance reductions

## Confidence

- Confidence Level: Medium
- The approach is well-motivated and the experimental results are promising, but the limited evaluation scope and relatively simple similarity metric reduce confidence in broader applicability.

## Next Checks

1. **Statistical validation**: Run multiple independent trials for each building pair to establish confidence intervals for the reported variance reductions and warm-up period improvements.

2. **Similarity metric robustness**: Test the current similarity metric against more sophisticated alternatives (e.g., correlation-based measures, manifold learning approaches) to verify that the simple statistical approach is sufficient.

3. **Generalizability test**: Apply the approach to buildings with different HVAC systems, climates, or usage patterns to assess whether the transfer learning benefits hold across diverse building types beyond the three studied.