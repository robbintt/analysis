---
ver: rpa2
title: On the Limitation and Experience Replay for GNNs in Continual Learning
arxiv_id: '2302.03534'
source_url: https://arxiv.org/abs/2302.03534
tags:
- learning
- graph
- experience
- replay
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of continual learning on evolving
  graph data using Graph Neural Networks (GNNs). The key problem is that evolving
  graph structures introduce distributional shifts that can cause catastrophic forgetting
  when training GNNs incrementally.
---

# On the Limitation and Experience Replay for GNNs in Continual Learning

## Quick Facts
- arXiv ID: 2302.03534
- Source URL: https://arxiv.org/abs/2302.03534
- Reference count: 40
- Key outcome: SEA-ER achieves up to 91.67% accuracy on Cora with 4.01% forgetting rate, outperforming baselines in NGCL with evolving graphs

## Executive Summary
This paper addresses the challenge of continual learning on evolving graph data using Graph Neural Networks (GNNs). The key problem is that evolving graph structures introduce distributional shifts that can cause catastrophic forgetting when training GNNs incrementally. The authors theoretically show that learnability of GNNs in this setting is heavily influenced by structural shifts due to the interconnected nature of graph data. To address this, they propose SEA-ER (Structure-Evolution-Aware Experience Replay), which uses a novel experience selection strategy based on graph topology and importance reweighting during replay. Their approach outperforms existing methods on standard benchmarks, achieving up to 91.67% accuracy on Cora, 92.88% on CoauthorCS, and 81.89% on Reddit, with corresponding average forgetting rates of 4.01%, 3.08%, and 9.72%.

## Method Summary
SEA-ER addresses NGCL by combining topology-aware experience selection with importance reweighting. The method uses a farthest-first traversal algorithm to select experience buffer samples based on shortest-path distance, ensuring structural representativeness. During replay, kernel mean matching (KMM) adjusts weights of replayed examples to minimize distributional shift between tasks. The approach is evaluated on Cora, CoauthorCS, and Reddit datasets divided into sequential classification tasks, with performance measured using average task performance (ATP) and average task forgetting (ATF) metrics.

## Key Results
- SEA-ER achieves 91.67% accuracy on Cora with only 4.01% average forgetting rate
- SEA-ER outperforms ER-deg and ER-rep baselines by up to 6.96% in accuracy and 11.32% in forgetting rate
- Performance remains stable across different buffer sizes (1%, 5%, 10% of training data)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Learnability in GNN-based NGCL is heavily influenced by structural shifts due to the interconnected nature of graph data.
- **Mechanism**: The topology-aware aggregation in GNNs makes their representations sensitive to changes in the graph structure. When new nodes and edges are added, the 1-hop and 2-hop neighborhoods of existing nodes change, causing a distributional shift in the learned representations. This shift affects the model's ability to generalize to previously seen tasks, leading to catastrophic forgetting.
- **Core assumption**: The effectiveness of GNNs depends on the stability of local graph topology for each node.
- **Evidence anchors**:
  - [abstract] "learnability is heavily influenced by structural shifts due to the interconnected nature of graph data"
  - [section] "GNNs may not be viable for NGCL under significant structural changes, emphasizing the need to manage structural shifts."
- **Break condition**: If the graph evolution is minimal (e.g., only adding isolated nodes), the structural dependency impact may be negligible.

### Mechanism 2
- **Claim**: SEA-ER's experience selection based on shortest-path distance effectively captures structural similarity, leading to better generalization.
- **Mechanism**: By selecting experience buffer samples that are structurally central (minimizing the maximum shortest-path distance to other nodes), SEA-ER ensures that the replayed nodes are representative of the overall graph topology. This addresses the structural bias problem by preventing the model from overfitting to specific structural patterns.
- **Core assumption**: Nodes with shorter average shortest-path distance to others are more structurally representative.
- **Evidence anchors**:
  - [section] "we propose a replay set selection strategy based on the idea of selecting replay samples that have the closest structural similarity to the rest of the vertices"
  - [section] "Our framework is based on the topology awareness of GNNs, which allows the model to take into account the structural information of the graph"
- **Break condition**: If the graph has very uniform structure (e.g., a complete graph), shortest-path distance may not effectively differentiate node importance.

### Mechanism 3
- **Claim**: Importance reweighting via kernel mean matching (KMM) reduces distributional shift between tasks in evolving graphs.
- **Mechanism**: KMM adjusts the weights of replayed examples to minimize the discrepancy between their distribution under the current and previous graph structures. This compensates for the structural dependency issue by ensuring that the replayed data better represents the original task distribution.
- **Core assumption**: The discrepancy between distributions can be effectively measured and minimized in the embedding space.
- **Evidence anchors**:
  - [section] "we propose a novel replay method with importance reweighting... reduces the distributional shift by adjusting the importance of individual examples"
  - [section] "Importance reweighting tries to match the mean elements in a kernel space on the domain HÃ—H"
- **Break condition**: If the embedding space does not preserve structural information well (high distortion rate), KMM may not effectively reduce the distributional shift.

## Foundational Learning

- **Concept: Graph Neural Networks and neighborhood aggregation**
  - Why needed here: SEA-ER relies on the topology awareness of GNNs, which is based on their neighborhood aggregation mechanism. Understanding how GNNs aggregate information from neighbors is crucial for understanding why structural shifts matter and how SEA-ER addresses them.
  - Quick check question: How does the representation of a node change after k layers of aggregation in a GNN?

- **Concept: Catastrophic forgetting in continual learning**
  - Why needed here: The paper addresses catastrophic forgetting in the context of NGCL with GNNs. Understanding the general mechanisms of catastrophic forgetting and how experience replay mitigates it is essential for understanding SEA-ER's approach.
  - Quick check question: Why does training on new tasks typically cause performance degradation on previous tasks?

- **Concept: Distributional shift and importance weighting**
  - Why needed here: SEA-ER uses importance reweighting to address distributional shift caused by structural dependency. Understanding how distributional shift occurs and how importance weighting can mitigate it is crucial for grasping SEA-ER's replay strategy.
  - Quick check question: How does importance weighting adjust the training objective to account for differences between training and target distributions?

## Architecture Onboarding

- **Component map**:
  - GNN Backbone (e.g., GraphSAGE, GCN, GAT) -> Task-specific Prediction Heads -> Experience Buffer -> Importance Reweighting Module

- **Critical path**:
  1. Initialize GNN backbone and task-specific prediction heads.
  2. For each task:
     - Update graph structure with new nodes/edges.
     - Train on current task data using weighted loss (including replayed examples).
     - Select new experience buffer samples using SEA-ER strategy.
     - Compute importance weights for replayed examples using KMM.

- **Design tradeoffs**:
  - Buffer size vs. storage/computation: Larger buffers improve performance but increase memory and computation cost.
  - Experience selection strategy: SEA-ER's shortest-path distance approach balances representativeness and diversity, but may be computationally expensive for large graphs.
  - Importance reweighting vs. simple replay: KMM-based reweighting is more effective at addressing distributional shift but adds computational overhead.

- **Failure signatures**:
  - High forgetting rate despite experience replay: May indicate insufficient buffer size or ineffective importance reweighting.
  - Performance degradation on current task: May indicate overemphasis on replayed examples (incorrect importance weights).
  - Inconsistent performance across tasks: May indicate structural bias in experience selection or insufficient diversity in the buffer.

- **First 3 experiments**:
  1. Reproduce the Cora dataset results with SEA-ER and compare against ER-deg and ER-rep baselines to validate the effectiveness of the experience selection strategy.
  2. Vary the buffer size (e.g., 1%, 5%, 10% of training data) to understand the tradeoff between performance and resource usage.
  3. Test SEA-ER with different GNN architectures (e.g., GCN, GAT) to assess the impact of the backbone model on SEA-ER's performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of SEA-ER change when applied to dynamic graphs where edge weights or node features evolve over time, not just the graph structure?
- Basis in paper: [inferred] The paper focuses on evolving graph structures but doesn't explore scenarios where node features or edge weights also change dynamically.
- Why unresolved: The theoretical framework and empirical evaluation only consider structural changes, leaving the impact of feature evolution unexplored.
- What evidence would resolve it: Experiments comparing SEA-ER performance on datasets with both structural and feature evolution versus structural evolution alone, measuring ATP and ATF metrics.

### Open Question 2
- Question: What is the computational complexity of SEA-ER's experience buffer selection algorithm when scaling to large graphs, and how does it compare to the computational overhead of other GNN continual learning methods?
- Basis in paper: [explicit] The paper mentions using a modified farthest-first traversal algorithm but doesn't provide detailed complexity analysis or runtime comparisons.
- Why unresolved: While the algorithm is described, its scalability and efficiency relative to other methods remain untested.
- What evidence would resolve it: Runtime analysis of SEA-ER buffer selection versus other methods on graphs of increasing size, reporting both selection time and total training time.

### Open Question 3
- Question: How sensitive is SEA-ER's performance to the choice of kernel parameters in the importance reweighting component, and what strategies can be used to automatically select these parameters?
- Basis in paper: [explicit] The paper uses a mixture of Gaussian kernels with fixed parameters but doesn't explore parameter sensitivity or automated selection methods.
- Why unresolved: The effectiveness of the reweighting depends on kernel choice, yet no systematic study of parameter impact is provided.
- What evidence would resolve it: Sensitivity analysis showing SEA-ER performance across different kernel parameter combinations, plus comparison with automated kernel selection methods.

### Open Question 4
- Question: How does SEA-ER perform when the graph evolution pattern follows non-uniform distributions, such as bursty arrivals of nodes or edges in specific regions of the graph?
- Basis in paper: [inferred] The paper assumes smooth task distributions in its theoretical analysis but doesn't test performance under bursty or non-uniform graph evolution patterns.
- Why unresolved: Real-world graphs often exhibit bursty behavior, but SEA-ER's robustness to such patterns remains untested.
- What evidence would resolve it: Experiments comparing SEA-ER performance on graphs with uniform versus bursty node/edge arrival patterns, measuring both average and worst-case performance.

## Limitations
- The theoretical analysis focuses on node classification in inductive NGCL scenarios, potentially limiting generalizability to other graph learning tasks
- The NP-hard nature of the optimal experience selection problem necessitates heuristics, with specific procedures detailed only in the appendix
- Evaluation relies on standard citation and social network datasets which may not fully represent diverse real-world evolving graph scenarios

## Confidence
- **High Confidence**: The empirical results showing SEA-ER's superiority over baseline experience replay methods (ER-deg and ER-rep) on the three benchmark datasets
- **Medium Confidence**: The theoretical analysis of learnability bounds and their relationship to structural shifts, which provides a sound theoretical foundation but may not capture all practical scenarios
- **Medium Confidence**: The effectiveness of KMM-based importance reweighting, which is well-established in domain adaptation but its specific application to structural dependency in NGCL requires further validation

## Next Checks
1. Test SEA-ER on datasets with more diverse graph structures and evolution patterns, including those with high-degree nodes and varying community structures
2. Conduct ablation studies to quantify the individual contributions of the experience selection strategy and importance reweighting components
3. Evaluate SEA-ER's performance when integrated with different GNN architectures (e.g., GAT, GIN) to assess architecture-agnostic effectiveness