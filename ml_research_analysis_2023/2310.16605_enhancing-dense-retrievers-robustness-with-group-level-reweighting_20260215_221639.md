---
ver: rpa2
title: Enhancing Dense Retrievers' Robustness with Group-level Reweighting
arxiv_id: '2310.16605'
source_url: https://arxiv.org/abs/2310.16605
tags:
- retrieval
- groups
- training
- group
- web-dro
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Web-DRO, a novel approach for unsupervised
  dense retrieval training using web graph data. The key idea is to leverage the rich
  structural information in web graphs to train an embedding model that can cluster
  anchor-document pairs effectively.
---

# Enhancing Dense Retrievers' Robustness with Group-level Reweighting

## Quick Facts
- arXiv ID: 2310.16605
- Source URL: https://arxiv.org/abs/2310.16605
- Reference count: 40
- Primary result: Web-DRO achieves up to 1.2% and 1.1% improvements on MS MARCO and BEIR respectively

## Executive Summary
This paper proposes Web-DRO, an unsupervised dense retrieval training approach that leverages web graph data to improve retriever robustness. The method uses Group Distributionally Robust Optimization to reweight different clusters during training, focusing on groups with higher loss and worst-case scenarios. Experiments demonstrate significant improvements over baseline models on both MS MARCO and BEIR datasets.

## Method Summary
Web-DRO is a two-step process for unsupervised dense retrieval training. First, documents are clustered using an embedding model trained on web graph links through contrastive learning. Second, Group Distributionally Robust Optimization reweights these clusters during training, assigning higher importance to underrepresented or difficult groups. The approach uses size factors to compensate for imbalanced cluster sizes and focuses on worst-case scenarios to improve overall robustness.

## Key Results
- Web-DRO achieves up to 1.2% improvement on MS MARCO benchmark
- Web-DRO achieves up to 1.1% improvement on BEIR benchmark
- Group weights learned by Web-DRO show stability and validity across runs

## Why This Works (Mechanism)

### Mechanism 1
GroupDRO effectively reweights training clusters to focus on underrepresented or difficult groups during unsupervised dense retrieval training. By dynamically adjusting group weights based on contrastive loss, the model assigns higher importance to clusters with higher loss, ensuring better generalization across diverse web data patterns.

### Mechanism 2
Web graph structural information provides rich document relationship signals that enhance unsupervised dense retrieval training. The embedding model trained on web graph links learns to capture document features that distinguish linked documents from non-linked ones, creating meaningful vector representations for clustering.

### Mechanism 3
GroupDRO's size factor adjustment compensates for imbalanced cluster sizes during training. The size factor C_k scales group weights by the inverse of relative cluster size, preventing large clusters from dominating training and ensuring all groups contribute proportionally.

## Foundational Learning

- Concept: Contrastive learning for representation learning
  - Why needed here: The core training objective relies on pulling positive anchor-document pairs together while pushing negative pairs apart in embedding space
  - Quick check question: What loss function is used to measure the alignment between anchor and document embeddings?

- Concept: Distributionally robust optimization
  - Why needed here: GroupDRO requires understanding how to optimize worst-case performance across different data distributions rather than average performance
  - Quick check question: How does GroupDRO differ from standard DRO in its approach to handling distributional shifts?

- Concept: K-means clustering for unsupervised grouping
  - Why needed here: Documents need to be grouped into meaningful clusters before applying GroupDRO reweighting
  - Quick check question: What is the minimum cluster size threshold used to ensure statistical significance of groups?

## Architecture Onboarding

- Component map: Web graph preprocessing -> Link prediction embedding model -> Document clustering -> GroupDRO-weighted dense retrieval training -> Evaluation on MS MARCO/BEIR
- Critical path: The embedding model training must complete successfully before clustering can occur, and clustering results directly determine GroupDRO's group assignments
- Design tradeoffs: Using web graph links provides rich structural information but introduces complexity in preprocessing; GroupDRO adds training overhead but improves robustness
- Failure signatures: Poor retrieval performance despite long training may indicate ineffective clustering or GroupDRO weight instability; large variance in results suggests random seed sensitivity
- First 3 experiments:
  1. Verify embedding model can distinguish linked from unlinked document pairs using held-out link prediction evaluation
  2. Check clustering quality by visualizing document embeddings and confirming coherent topical groupings
  3. Monitor GroupDRO weight stability during initial training epochs to ensure monotonic behavior

## Open Questions the Paper Calls Out

### Open Question 1
How does the number of clusters affect the stability and quality of group weights learned by Web-DRO? While the paper identifies an optimal number of clusters, it does not explore the reasons behind this optimal value or investigate how stability and quality of group weights change as the number of clusters varies.

### Open Question 2
Can the group weighting mechanism of Web-DRO be extended to handle multiple types of data distributions or domains? The effectiveness of Web-DRO's group weighting mechanism may be limited to the specific characteristics of web graph data, and its performance on other types of data distributions or domains remains unknown.

### Open Question 3
How does the inclusion of URL information impact the clustering and retrieval performance of Web-DRO compared to using only content-based features? While the paper demonstrates a slight improvement with URL information, it does not explore the reasons behind this improvement or investigate the trade-offs between using URL and content-based features for clustering and retrieval.

## Limitations

- The approach relies heavily on web graph structures from ClueWeb22, raising questions about generalizability to other domains or languages
- The paper lacks detailed ablation studies showing the individual contributions of the embedding model versus GroupDRO reweighting
- Scalability to much larger web corpora or real-time applications is unclear

## Confidence

- High confidence: The theoretical foundation of GroupDRO and its effectiveness in handling distributional shifts
- Medium confidence: The clustering quality and its impact on retrieval performance, as this depends heavily on the specific web graph characteristics
- Low confidence: The scalability of the approach to much larger web corpora or real-time applications

## Next Checks

1. Conduct ablation studies comparing GroupDRO performance with and without the web graph embedding model to isolate each component's contribution
2. Test the approach on additional retrieval benchmarks beyond BEIR, particularly those with different domain distributions or languages
3. Evaluate the sensitivity of results to the minimum cluster size threshold and number of clusters to ensure robustness across different parameter settings