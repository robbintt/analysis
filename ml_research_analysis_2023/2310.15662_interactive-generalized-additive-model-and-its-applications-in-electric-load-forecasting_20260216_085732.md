---
ver: rpa2
title: Interactive Generalized Additive Model and Its Applications in Electric Load
  Forecasting
arxiv_id: '2310.15662'
source_url: https://arxiv.org/abs/2310.15662
tags:
- load
- forecasting
- electric
- data
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an interactive generalized additive model
  (GAM) for electric load forecasting that incorporates domain knowledge and addresses
  challenges with limited data and extreme weather events. The proposed method uses
  piecewise linear functions learned via an efficient boosting-based algorithm and
  allows experts to impose monotonicity, convexity, and concavity constraints through
  a user-friendly web interface.
---

# Interactive Generalized Additive Model and Its Applications in Electric Load Forecasting

## Quick Facts
- arXiv ID: 2310.15662
- Source URL: https://arxiv.org/abs/2310.15662
- Reference count: 40
- Primary result: Interactive GAM outperforms state-of-the-art methods in electric load forecasting, particularly under extreme weather conditions when domain knowledge is incorporated through user constraints.

## Executive Summary
This paper introduces an interactive generalized additive model (GAM) for electric load forecasting that addresses challenges with limited data and extreme weather events. The proposed method uses piecewise linear functions learned via an efficient boosting-based algorithm and allows experts to impose monotonicity, convexity, and concavity constraints through a user-friendly web interface. Experiments on public benchmark and real-world electricity datasets demonstrate that the interactive GAM outperforms state-of-the-art methods in both overall accuracy and extrapolation ability, particularly under extreme weather conditions.

## Method Summary
The paper proposes an interactive GAM framework that combines piecewise linear function approximation with a boosting algorithm for electric load forecasting. The model learns shape functions for each feature using hinge functions and reverse hinge functions, allowing it to capture smooth monotonic and convex/concave relationships. Domain experts can impose constraints through a web interface, which are then projected onto the learned shape functions using gradient projection. The method includes an efficient algorithm for computing weighted correlations and norms that reduces computational complexity from O(NÂ²) to O(N).

## Key Results
- Interactive GAM outperforms state-of-the-art methods in RNMSE on both public benchmark and real-world electricity datasets
- The model demonstrates superior extrapolation ability on extreme weather event days compared to baseline methods
- Incorporating domain knowledge through interactive constraints significantly improves forecasting accuracy

## Why This Works (Mechanism)

### Mechanism 1
The piecewise linear GAM framework enables accurate extrapolation under extreme weather conditions by capturing smooth trend patterns in electric load data. The model represents each shape function as a sum of hinge functions and reverse hinge functions, allowing it to approximate smooth monotonic and convex/concave relationships between weather features and load. The boosting framework iteratively adds these piecewise linear components to fit residuals. The core assumption is that the underlying relationship between weather features (particularly temperature) and electric load is smooth and can be well-approximated by piecewise linear functions.

### Mechanism 2
The interactive constraint-adding capability allows domain experts to incorporate their knowledge about load patterns, improving model accuracy. The model projects shape functions onto convex sets defined by user-specified constraints (monotonicity, convexity, concavity) in specific ranges. This projection is efficiently computed using a gradient projection method. The core assumption is that the feasible sets of the constraints are convex, enabling efficient projection. The interactive interface provides a user-friendly way to impose these constraints and adjust sample weights.

### Mechanism 3
The efficient algorithm for learning piecewise linear functions significantly reduces computational complexity compared to naive approaches. The algorithm exploits the special structure of hinge functions to compute weighted norms and correlations in linear time, avoiding explicit construction of large matrices. It uses cumulative sum operations to efficiently evaluate all possible thresholds. The core assumption is that the dataset can be sorted by feature values, and the number of basis functions (K) is small compared to the dataset size.

## Foundational Learning

- Concept: Generalized Additive Models (GAMs)
  - Why needed here: GAMs provide the interpretable framework that allows visualization of individual feature effects on load prediction.
  - Quick check question: How does a GAM differ from a standard linear regression model?

- Concept: Piecewise linear function approximation
  - Why needed here: The piecewise linear representation enables accurate modeling of non-linear relationships between weather features and load while maintaining interpretability.
  - Quick check question: What are the advantages and disadvantages of using piecewise linear functions versus splines for function approximation?

- Concept: Gradient boosting framework
  - Why needed here: The boosting framework iteratively improves the model by fitting residuals, allowing the piecewise linear components to be added sequentially.
  - Quick check question: How does the boosting approach differ from backfitting in terms of how shape functions are updated?

## Architecture Onboarding

- Component map: Input layer (features) -> Shape function layer (piecewise linear functions) -> Constraint layer (user-specified constraints) -> Output layer (sum of shape functions) -> Training loop (boosting iterations) -> Interaction interface (web-based UI)

- Critical path: 1. Feature preprocessing and normalization, 2. Initial model training with boosting, 3. User constraint specification via interface, 4. Constraint projection and model update, 5. Prediction and evaluation

- Design tradeoffs: Interpretability vs. predictive accuracy (GAMs sacrifice some accuracy for interpretability compared to black-box models), Computational efficiency vs. model complexity (efficient algorithm allows more complex models to be trained faster), User control vs. automation (interactive interface gives users control but requires their expertise)

- Failure signatures: Poor extrapolation performance (may indicate piecewise linear assumption is insufficient), Slow training (could suggest efficient algorithm not being used correctly or K set too high), Inconsistent constraints (user-specified constraints may conflict with each other or with data)

- First 3 experiments: 1. Train the model on Boston Housing dataset and compare MSE with other GAM implementations, 2. Test extrapolation ability on California housing dataset with known extreme values, 3. Use web interface to impose constraints on simple dataset and verify shape functions are correctly updated

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Limited generalizability from single real-world case study (Henan province, July 14, 2022) for extreme weather events
- No comparison with recent deep learning approaches for time series forecasting
- Insufficient discussion of potential conflicts between user-specified constraints and data-driven patterns

## Confidence
- **High Confidence**: Piecewise linear GAM framework and boosting algorithm are well-established with clear theoretical foundations; computational efficiency claims supported by algorithmic analysis
- **Medium Confidence**: Experimental results showing improved performance on extreme weather events are promising but limited to single case study; web interface effectiveness relies on assumption that domain experts can provide useful constraints
- **Low Confidence**: Paper does not adequately address potential conflicts between user-specified constraints and data-driven patterns or situations where constraints cannot be satisfied

## Next Checks
1. Test the model's performance on additional extreme weather events beyond the single case study to verify consistent extrapolation ability across different conditions and locations

2. Conduct ablation studies to quantify the specific contribution of each constraint type (monotonicity, convexity, concavity) to overall model performance, separating effects of domain knowledge from underlying GAM framework

3. Implement systematic evaluation of constraint conflicts by deliberately introducing contradictory constraints and measuring projection algorithm's ability to find feasible solutions while maintaining predictive accuracy