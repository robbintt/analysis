---
ver: rpa2
title: 'ProgGP: From GuitarPro Tablature Neural Generation To Progressive Metal Production'
arxiv_id: '2307.05328'
source_url: https://arxiv.org/abs/2307.05328
tags:
- music
- songs
- guitar
- generated
- song
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ProgGP, a deep learning model fine-tuned on
  a custom dataset of 173 progressive metal songs to generate guitar tablatures in
  GuitarPro format. The model extends previous work by Sarmento et al.
---

# ProgGP: From GuitarPro Tablature Neural Generation To Progressive Metal Production

## Quick Facts
- arXiv ID: 2307.05328
- Source URL: https://arxiv.org/abs/2307.05328
- Reference count: 24
- Key outcome: Transformer model fine-tuned on 173 progressive metal songs generates GuitarPro tablatures with impressive drum parts and solos, but sometimes creates unplayable guitar parts

## Executive Summary
This paper presents ProgGP, a deep learning model that generates guitar tablatures in GuitarPro format for progressive metal music. The authors fine-tuned a pre-trained Transformer model on a custom dataset of 173 progressive metal songs and evaluated the outputs using both quantitative metrics and qualitative analysis. While the model successfully generates stylistically coherent music with impressive drum parts and guitar solos, it occasionally produces fretboard locations that are difficult to play, requiring manual modification for professional use.

## Method Summary
The authors fine-tuned a pre-trained Transformer-XL model from the DadaGP dataset on their custom ProgGP dataset of 173 progressive metal songs in GuitarPro format. The model was trained for 65 epochs with early stopping based on loss metrics. They used a tokenized representation of GuitarPro files as input/output, allowing the model to generate both musical content and performance-specific details like fretboard positions. The fine-tuned model was then used to generate new songs from various prompts, which were evaluated using a combination of quantitative metrics (pitch class entropy, drum pattern consistency, etc.) and qualitative analysis.

## Key Results
- The model generates impressive drum parts and guitar solos with genre-appropriate characteristics
- Generated tablatures sometimes contain unrealistic fretboard locations that are difficult to play
- The mixed methods evaluation approach effectively captures both objective and subjective aspects of generated music quality

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning a pre-trained transformer on a genre-specific dataset improves the model's ability to generate stylistically coherent guitar tablatures. The pre-trained model already understands general symbolic music patterns, and fine-tuning on ProgGP (173 progressive metal songs) adapts the learned representations to capture genre-specific motifs, rhythms, and fretboard choices.

### Mechanism 2
Using GuitarPro format as the symbolic representation allows the model to generate both musical content and performance-specific details. GuitarPro encodes not just pitch but also string/fret location and expressive techniques (e.g., bends, vibrato), giving the model more context for generating playable guitar parts.

### Mechanism 3
A mixed methods evaluation (quantitative metrics + qualitative analysis) provides a more comprehensive assessment of generated music than either alone. Quantitative metrics offer objective measures of stylistic similarity, while qualitative analysis captures subjective aspects like playability and musical interest.

## Foundational Learning

- **Transformer architecture and attention mechanisms**
  - Why needed here: The model uses Transformer-XL architecture, which relies on self-attention to capture long-range dependencies in music sequences
  - Quick check question: How does the self-attention mechanism in a transformer allow it to model long-term musical structures?

- **Symbolic music representation and tokenization**
  - Why needed here: The model works with a tokenized GuitarPro format, requiring understanding of how music is represented symbolically and how to convert between formats
  - Quick check question: What are the key differences between MIDI and GuitarPro representations, and why might GuitarPro be more suitable for guitar-focused generation?

- **Music theory and genre characteristics**
  - Why needed here: Understanding progressive metal's stylistic features (e.g., odd time signatures, specific chord progressions) is crucial for evaluating the model's outputs and guiding the fine-tuning process
  - Quick check question: What are some common rhythmic and harmonic characteristics of progressive metal that distinguish it from other metal subgenres?

## Architecture Onboarding

- **Component map**: Pre-trained Transformer-XL model -> Tokenization layer -> Fine-tuning on ProgGP dataset -> Decoding layer -> Evaluation pipeline (metrics + qualitative analysis)

- **Critical path**: Load pre-trained model → Prepare ProgGP dataset (tokenize GuitarPro files) → Fine-tune model on ProgGP → Generate new songs using prompts → Evaluate generated songs (metrics + listening) → Integrate into music production workflow

- **Design tradeoffs**: Dataset size vs. genre specificity (larger dataset might capture more diversity but dilute genre-specific features) | Model complexity vs. training efficiency (more complex model might capture nuances better but requires more computational resources) | Symbolic vs. audio generation (symbolic generation allows more control but lacks timbre information)

- **Failure signatures**: Low pitch class entropy (model overfitting and repetitive content) | Unrealistic fretboard locations (model doesn't understand guitar playability constraints) | Lack of genre-specific features (model hasn't learned progressive metal nuances) | Poor drum-bass synchronization (model doesn't understand rhythmic relationships)

- **First 3 experiments**: Generate songs using different prompts (single note, short melody, full measure) and compare output quality | Evaluate generated songs using all quantitative metrics and compare to ProgGP dataset | Conduct qualitative analysis of generated songs, focusing on genre-specific features and playability

## Open Questions the Paper Calls Out

### Open Question 1
How can the model be improved to generate more playable guitar parts that better match professional performance standards? While the authors note that the model sometimes generates fretboard locations that are difficult to play, they don't propose specific solutions for how to modify the model to generate more realistic guitar parts that match professional standards.

### Open Question 2
How can the model be enhanced to generate more sophisticated drum parts that better support the overall composition? The authors note that while the model generates impressive drum parts, they often need significant editing to sound natural and support the guitar and bass parts effectively, but don't explore specific ways to improve the drum generation.

### Open Question 3
How can the model be adapted to generate more cohesive song structures that better reference and build upon musical motifs throughout a composition? The authors note that while the model generates sections that fit together naturally, they don't necessarily reference one another or build on motifs found in progressive metal music.

## Limitations

- The small fine-tuning dataset (173 songs) may limit the model's ability to capture the full diversity of progressive metal
- The evaluation relies heavily on subjective qualitative analysis by the authors rather than external listeners
- The practical usability of generated tablatures remains uncertain, as manual modification is still needed for professional use

## Confidence

- **High confidence**: The model can generate stylistically coherent progressive metal tablatures when fine-tuned on genre-specific data. The mechanism of using GuitarPro format for encoding performance-specific details is valid.
- **Medium confidence**: The mixed methods evaluation approach provides useful insights, though the subjective nature of musical quality assessment introduces uncertainty. The claim that the model excels at generating drum parts and guitar solos is supported but not rigorously quantified.
- **Low confidence**: The claim about creating a "fully produced and mixed" progressive metal song using only AI-generated material is overstated, as human producers were still needed for the final production work.

## Next Checks

1. Conduct a blind listening test with progressive metal musicians to assess the perceived quality and genre authenticity of generated tracks, comparing against human-composed benchmarks

2. Test the model's generalization by fine-tuning on larger progressive metal datasets (if available) and measuring whether performance metrics improve while maintaining genre specificity

3. Implement a playability filter that automatically detects and adjusts unrealistic fretboard positions in generated tablatures, then measure the impact on both quantitative metrics and human evaluation scores