---
ver: rpa2
title: Multi-Task Learning-Enabled Automatic Vessel Draft Reading for Intelligent
  Maritime Surveillance
arxiv_id: '2310.07212'
source_url: https://arxiv.org/abs/2310.07212
tags:
- draft
- vessel
- detection
- segmentation
- scale
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a multi-task learning-enabled automatic vessel
  draft reading (MTL-VDR) method for intelligent maritime surveillance. The method
  addresses the challenges of accurate and efficient vessel draft depth estimation,
  which is crucial for determining whether a vessel is normally loaded or overloaded.
---

# Multi-Task Learning-Enabled Automatic Vessel Draft Reading for Intelligent Maritime Surveillance

## Quick Facts
- arXiv ID: 2310.07212
- Source URL: https://arxiv.org/abs/2310.07212
- Reference count: 40
- Primary result: Automatic vessel draft reading method achieving >40 FPS with high accuracy using multi-task learning

## Executive Summary
This paper presents a multi-task learning-enabled automatic vessel draft reading (MTL-VDR) method for intelligent maritime surveillance. The method addresses the challenges of accurate and efficient vessel draft depth estimation, which is crucial for determining whether a vessel is normally loaded or overloaded. The proposed MTL-VDR consists of four main components: draft mark detection, draft scale recognition, vessel/water segmentation, and final draft depth estimation. The method employs a multi-task learning network to simultaneously perform draft scale recognition and vessel/water segmentation, improving efficiency while maintaining accuracy. Additionally, a draft scale correction method based on spatial distribution rules is introduced to enhance robustness to vessel hull stains.

## Method Summary
The MTL-VDR method employs a multi-task learning network with a shared DarkNet-53 backbone that splits into two specialized subnets for draft scale recognition and vessel/water segmentation. The system uses YOLOv8 for draft mark detection, then processes detected regions through the multi-task network with dynamically weighted loss functions based on homoscedastic uncertainty. A spatial distribution rule-based correction method validates and corrects recognized draft scales based on expected 0.2m spacing and vertical ordering. Finally, an adaptive linear fitting method estimates the draft depth from the corrected scale data. The method is trained on a newly developed VDR dataset with 2226 images for draft mark detection, 1198 images for draft scale recognition, 1198 images for vessel/water segmentation, and 45 images for depth estimation.

## Key Results
- Achieves computational speed exceeding 40 FPS for real-time maritime surveillance
- Superior performance in accuracy, robustness, and efficiency compared to baseline methods
- Effective handling of complex conditions including damaged and stained draft scales

## Why This Works (Mechanism)

### Mechanism 1
Multi-task learning enables simultaneous draft scale recognition and vessel/water segmentation in a single forward pass, improving computational efficiency without degrading accuracy. The network shares a backbone feature extractor (DarkNet-53) and splits into two specialized subnets, reducing total parameters and computation compared to two separate networks. Dynamic weighting based on homoscedastic uncertainty balances the tasks during training.

### Mechanism 2
The spatial distribution rule-based correction method compensates for low recognition accuracy due to stains or low resolution, making the system robust to real-world defects. Recognition results are validated against expected scale spacing (0.2m difference) and vertical ordering; scores are assigned and incorrect detections are replaced by interpolation from neighboring correct scales.

### Mechanism 3
The MAVD (mean absolute vertical distance) loss function focuses training on accurate waterline localization, directly improving draft depth estimation. MAVD computes vertical pixel error only at the top of water regions, forcing the segmentation network to precisely locate the waterline boundary.

## Foundational Learning

- **Object detection using anchor-free architectures (e.g., YOLOX)**: Why needed here - Draft marks and scales have varied sizes and orientations; anchor-free methods adapt better to this diversity. Quick check question: Why might anchor-based detectors struggle on draft scales?
- **Multi-task learning with dynamic loss weighting**: Why needed here - Balancing two segmentation tasks without one dominating; homoscedastic uncertainty provides principled weighting. Quick check question: What is the purpose of adjusting loss weights dynamically during training?
- **Spatial priors for validation (e.g., regulated scale spacing)**: Why needed here - Enables automatic correction of recognition errors caused by stains or low resolution. Quick check question: How does the correction method use the 0.2m spacing rule to fix wrong detections?

## Architecture Onboarding

- **Component map**: Raw 1920Ã—1080 maritime image -> YOLOv8 draft mark detection -> Multi-task network (DarkNet-53 backbone, detection head, segmentation head) -> Spatial distribution rule-based correction -> Adaptive linear fitting -> Draft depth output
- **Critical path**: Detection -> Multi-task network -> Correction -> Depth estimation
- **Design tradeoffs**: Single multi-task network vs. two separate networks: Faster but risk of interference; Anchor-free vs. anchor-based: More flexible for variable scale sizes but potentially less precise; MAVD vs. standard segmentation loss: Better waterline focus but ignores other segmentation quality
- **Failure signatures**: Poor scale detection -> empty or incorrect depth outputs; Misaligned waterline -> large draft depth errors; Scale correction failures -> inconsistent or impossible scale sequences
- **First 3 experiments**: 1) Ablation: Remove MAVD loss and measure waterline error vs. draft depth error; 2) Ablation: Replace multi-task network with two separate networks and measure speed/accuracy trade-off; 3) Stress test: Apply simulated stains to test scale correction robustness

## Open Questions the Paper Calls Out

1. How can the proposed MTL-VDR method be extended to handle draft marks depicted in imperial units (feet and inches) for sea vessels, as opposed to the metric system used for inland vessels?
2. Can the efficiency of the MTL-VDR method be further improved by optimizing the multi-task learning architecture to achieve better accuracy without sacrificing speed?
3. How can the MTL-VDR method be adapted to handle low-quality visual data caused by low-visibility weather conditions, such as low light or haze?

## Limitations

- The effectiveness of spatial distribution rules depends on strict adherence to 0.2m spacing, which may not hold for all vessel types
- Multi-task learning claims efficiency gains without direct comparison to separately trained networks at matched accuracy levels
- MAVD loss function benefits are theoretically sound but lack empirical validation against alternatives

## Confidence

- **High confidence**: The overall MTL architecture and detection components (YOLOX-s, U-net) are standard and well-validated approaches
- **Medium confidence**: The spatial distribution correction rules and MAVD loss function effectiveness in real-world conditions
- **Low confidence**: The claimed computational efficiency gains from multi-task learning without accuracy degradation

## Next Checks

1. Test the scale correction method on vessels with known non-standard scale arrangements to quantify failure rates
2. Benchmark the multi-task network against separately trained networks with matched accuracy to measure actual efficiency gains
3. Evaluate waterline detection accuracy using MAVD versus standard cross-entropy loss on vessels with varying water conditions and lighting