---
ver: rpa2
title: Classifying Crime Types using Judgment Documents from Social Media
arxiv_id: '2306.17020'
source_url: https://arxiv.org/abs/2306.17020
tags:
- crime
- data
- dataset
- arxiv
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of classifying crime types based
  on judgment documents and social media data, focusing on handling data imbalance
  and limited labeled data. The authors propose a Crime Fact Data Preprocessing Module
  (CFDPM) that performs data augmentation using synonym replacement, random noise
  addition, and back-translation to balance uneven data distributions.
---

# Classifying Crime Types using Judgment Documents from Social Media

## Quick Facts
- arXiv ID: 2306.17020
- Source URL: https://arxiv.org/abs/2306.17020
- Reference count: 29
- Key outcome: Proposed CFDPM and dynamic masking achieve 91.6% accuracy and 90.14% F1-score on crime type classification

## Executive Summary
This paper addresses the challenge of classifying crime types from judgment documents and social media data, particularly focusing on handling data imbalance and limited labeled data. The authors propose a Crime Fact Data Preprocessing Module (CFDPM) that uses data augmentation techniques including synonym replacement, random noise addition, and back-translation to balance uneven data distributions. They also employ a fine-tuning strategy using a large public dataset (CAIL-big) for pretraining and their in-house dataset for adaptation, combined with an improved BERT model using dynamic masking. Experimental results demonstrate state-of-the-art performance on benchmark datasets, with accuracy reaching 91.6% and F1-score of 90.14%.

## Method Summary
The method involves a two-stage approach: first, pretraining a BERT model on the large CAIL-big dataset (101,619 training cases) to capture general legal language patterns; second, fine-tuning the model on a smaller in-house dataset collected from Police Briefings (3,793 training cases) while freezing lower BERT layers and training only the final MLP layer. The CFDPM module is applied during training to balance class distributions by generating synthetic samples for underrepresented crime types when sample counts fall below a threshold K. Dynamic masking is implemented during training, applying random masking each time a sequence is fed to the model rather than using static masks applied during preprocessing.

## Key Results
- Achieves 91.6% accuracy and 90.14% F1-score on the CAIL-big dataset
- CFDPM module significantly improves model performance on imbalanced datasets
- Dynamic masking mechanism demonstrates superior generalization compared to static masking
- Fine-tuning strategy effectively adapts the model from large legal documents to social media crime reports

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CFDPM balances imbalanced crime datasets by augmenting minority classes through synonym replacement, random noise, and back-translation.
- Mechanism: When a crime type's sample count is below a threshold K, the module cycles through three augmentation strategies to generate synthetic samples, thereby increasing the representation of underrepresented crime types in training.
- Core assumption: The augmented samples preserve semantic meaning while appearing distinct enough to expand the model's decision boundaries for rare classes.
- Evidence anchors:
  - [abstract] "Crime Fact Data Preprocessing Module (CFDPM), which can balance the defects of uneven data set distribution by generating new samples."
  - [section] "If the total number of samples in a certain type of crime is greater than , then samples are randomly selected from that type. Otherwise, new samples are generated using data augmentation methods."
  - [corpus] Weak evidence - only general NLP augmentation references in corpus, no specific crime domain validation.
- Break condition: If augmented samples introduce label noise or semantic drift, the classifier's precision on minority classes will degrade despite apparent recall gains.

### Mechanism 2
- Claim: Dynamic masking improves BERT performance by exposing the model to varied masked token patterns within the same sentence across training epochs.
- Mechanism: Instead of static masks applied once during preprocessing, dynamic masking applies random masking each time a sequence is fed to the model, forcing the model to learn more robust contextual representations.
- Core assumption: Varying mask positions prevents the model from overfitting to fixed masking patterns and encourages better generalization.
- Evidence anchors:
  - [abstract] "we use the improved Bert model with dynamic masking to improve the model."
  - [section] "Dynamic masking does not mask out data in the preprocessing stage, but the masking is performed every time a sequence is fed to the model."
  - [corpus] Weak evidence - corpus contains general mentions of dynamic masking but no crime-specific validation.
- Break condition: If masking ratio is too high, the model may lose critical context needed for distinguishing fine-grained crime types.

### Mechanism 3
- Claim: Fine-tuning on a large general dataset (CAIL-big) before adapting to a small in-house dataset transfers generalizable linguistic and domain knowledge, improving performance on limited data.
- Mechanism: Pretraining on CAIL-big captures broad patterns in legal judgment language; freezing lower layers and training only the final MLP layer on the small dataset preserves learned representations while adapting to the specific style of social media crime reports.
- Core assumption: The domain shift between formal judgment documents and social media posts is small enough that pretraining still provides useful inductive biases.
- Evidence anchors:
  - [abstract] "use a large open source dataset (CAIL-big) as our pretraining dataset and a small dataset collected by ourselves for Fine-tuning"
  - [section] "The format of the CAIL-big dataset is shown... We first trained a model to classify Charges on CAIL-big data set, and then applied the model to our in-house dataset."
  - [corpus] Weak evidence - corpus contains related legal NLP work but no direct comparison of pretraining benefits for crime type classification.
- Break condition: If the two datasets are too dissimilar, fine-tuning may introduce negative transfer, hurting performance compared to training from scratch on the target data.

## Foundational Learning

- Concept: Data augmentation techniques (synonym replacement, noise injection, back-translation)
  - Why needed here: Crime datasets are naturally imbalanced due to real-world crime frequency distributions; augmentation helps balance classes without collecting more real data.
  - Quick check question: What are the three augmentation methods used in CFDPM, and why is each appropriate for Chinese text?

- Concept: Pretraining and fine-tuning strategy in transformer models
  - Why needed here: Small in-house datasets lack sufficient examples for direct training; pretraining on a large legal corpus provides robust language representations that can be adapted.
  - Quick check question: In the fine-tuning phase, which layers are frozen and which are trained, and why?

- Concept: Dynamic vs. static masking in BERT pretraining
  - Why needed here: Static masking can lead to overfitting to fixed patterns; dynamic masking forces the model to handle varied contexts and improves generalization.
  - Quick check question: How does dynamic masking differ from the original BERT static masking approach?

## Architecture Onboarding

- Component map:
  Raw text → CFDPM (if below threshold) → LTP Tokenization → GloVe Embeddings → BERT with Dynamic Masking → Classification Head → Crime Type Output

- Critical path:
  1. Text → CFDPM (if below threshold) → Tokenization → Embedding → BERT → Classification Head → Output
  2. For fine-tuning: Pretrain on CAIL-big → Freeze layers → Train MLP on in-house dataset

- Design tradeoffs:
  - Augmenting minority classes vs. risking label noise
  - Dynamic masking computational overhead vs. generalization gains
  - Freezing lower BERT layers vs. allowing full fine-tuning (faster but less flexible)

- Failure signatures:
  - Accuracy improves but F1-score drops → class imbalance still present
  - High precision but low recall on rare classes → augmentation not effective or too noisy
  - Overfitting on small dataset → reduce augmentation or unfreeze more layers during fine-tuning

- First 3 experiments:
  1. Train baseline BERT on imbalanced data → observe accuracy/F1 gap
  2. Apply CFDPM with moderate threshold → measure impact on minority class F1
  3. Enable dynamic masking → compare against static masking baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Crime Fact Data Preprocessing Module (CFDPM) perform when applied to languages other than Chinese?
- Basis in paper: [inferred] The paper primarily focuses on Chinese text and uses Chinese-specific tools like LTP for word segmentation. It would be valuable to understand if the CFDPM can be effectively applied to other languages.
- Why unresolved: The paper does not explore the application of CFDPM to other languages or provide any cross-linguistic analysis.
- What evidence would resolve it: Experiments applying CFDPM to datasets in different languages, such as English or Spanish, and comparing the results to the Chinese dataset.

### Open Question 2
- Question: What is the impact of varying the threshold K for activating the CFDPM on model performance?
- Basis in paper: [explicit] The paper mentions that a sample threshold K is used to decide whether to activate the CFDPM, but it does not explore the impact of different values of K on the model's performance.
- Why unresolved: The paper does not provide an analysis of how different threshold values affect the balance of the dataset or the overall model accuracy.
- What evidence would resolve it: Experiments with different values of K and their corresponding effects on model accuracy, F1-score, and dataset balance.

### Open Question 3
- Question: How does the dynamic masking mechanism in the BERT model affect the model's performance on datasets with different sizes?
- Basis in paper: [explicit] The paper discusses the use of dynamic masking in the BERT model and its positive impact on performance, but it does not explore how this mechanism affects performance on datasets of varying sizes.
- Why unresolved: The paper does not provide a detailed analysis of the dynamic masking mechanism's effectiveness across datasets with different numbers of samples.
- What evidence would resolve it: Comparative experiments using the dynamic masking mechanism on datasets of varying sizes, from small to large, to determine its impact on model performance.

## Limitations

- Limited validation of domain adaptation effectiveness between formal legal documents and social media posts
- Insufficient ablation study on individual augmentation method contributions
- Missing detailed specification of dynamic masking parameters and implementation details

## Confidence

**High Confidence Claims**: 
- The overall methodology of using pretraining + fine-tuning + data augmentation for text classification is sound
- The evaluation metrics (accuracy, F1-score, precision, recall) are appropriate for the classification task

**Medium Confidence Claims**: 
- CFDPM effectively balances class distribution
- Dynamic masking improves model generalization
- Fine-tuning on CAIL-big transfers useful knowledge to the social media domain

**Low Confidence Claims**: 
- The specific performance gains (91.6% accuracy, 90.14% F1-score) are directly attributable to the proposed methods rather than dataset characteristics
- The three augmentation methods are equally effective for Chinese legal text

## Next Checks

1. **Ablation Study on Augmentation Methods**: Run experiments with each augmentation method (synonym replacement, random noise, back-translation) individually and in combinations to quantify their individual contributions to performance gains, particularly for minority classes.

2. **Domain Shift Analysis**: Conduct a quantitative analysis comparing linguistic features between CAIL-big formal judgment documents and the in-house social media dataset, measuring vocabulary overlap, sentence structure similarity, and domain-specific terminology to validate the pretraining assumption.

3. **Dynamic Masking Parameter Sensitivity**: Systematically vary the masking ratio and application frequency during both pretraining and fine-tuning phases to determine optimal settings and demonstrate that the observed improvements are not due to arbitrary parameter choices.