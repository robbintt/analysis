---
ver: rpa2
title: 'BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables'
arxiv_id: '2307.02891'
source_url: https://arxiv.org/abs/2307.02891
tags:
- babe
- mean0
- dist
- figure
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BaBE tackles the challenge of discrimination in machine learning
  when a legitimate attribute E is hidden and replaced by a biased proxy Z influenced
  by both E and a sensitive attribute S. Using domain knowledge about the bias mechanism
  P[Z|E,S], BaBE applies a Bayesian EM method to estimate the latent E distribution
  and derive P[E|Z,S], enabling decisions based on the estimated E rather than the
  biased Z.
---

# BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables

## Quick Facts
- arXiv ID: 2307.02891
- Source URL: https://arxiv.org/abs/2307.02891
- Reference count: 40
- Primary result: BaBE achieves high fairness and accuracy in healthcare decisions by estimating latent health status rather than using biased spending proxies

## Executive Summary
BaBE addresses discrimination in machine learning when legitimate attributes are hidden and replaced by biased proxies influenced by sensitive attributes. Using domain knowledge about the bias mechanism P[Z|E,S], BaBE applies a Bayesian EM method to estimate the latent distribution P[E|S] and derive P[E|Z,S]. This enables decisions based on the estimated explaining variable E rather than the biased proxy Z. Experiments show BaBE achieves significant fairness improvements in healthcare scenarios, notably achieving near-equal representation of black and white patients in health programs (60-75% vs. original 11%) while maintaining high accuracy.

## Method Summary
BaBE tackles unfair discrimination by estimating latent explaining variables that are hidden behind biased proxy variables. The method uses a combination of Bayes inference and the Expectation-Maximization algorithm to estimate the most likely value of the latent variable E for a given proxy Z and sensitive attribute S. By leveraging known bias mechanisms P[Z|E,S], BaBE derives the posterior distribution P[E|Z,S] and bases decisions on these estimates rather than the biased proxies. This approach achieves fairness without artificially changing the distribution of legitimate explanatory variables, enabling effective transfer of causal knowledge across populations.

## Key Results
- Achieved near-equal representation of black and white patients in health program (60-75% vs. original 11%) when decisions based on estimated health status
- Maintained high accuracy while achieving fairness improvements compared to baseline methods
- Demonstrated effectiveness on both synthetic and real healthcare data with varying levels of bias

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BaBE uses the Expectation-Maximization (EM) algorithm to estimate the latent distribution P[E|S] by treating it as a maximum likelihood parameter.
- Mechanism: Given observed data {(zi, si)} and a known conditional distribution P[Z|E,S], BaBE iteratively updates an estimate of P[E|S] using the EM framework. At each iteration, it computes the expected value of the log-likelihood conditioned on the current estimate, then maximizes this expectation to produce a new estimate. The process continues until convergence within a specified precision threshold γ.
- Core assumption: The bias mechanism P[Z|E,S] is known and can be reliably estimated from external domain knowledge or controlled experiments.
- Evidence anchors:
  - [abstract]: "BaBE (Bayesian Bias Elimination), an approach based on a combination of Bayes inference and the Expectation-Maximization method, to estimate the most likely value of E for a given Z for each group."
  - [section 3.1]: "We estimate the unknown parameter P[E|S] as the MLE of a sequence of samples (¯z, ¯s) = {(z1, s1), ..., (zN, N)}, assuming that we know the effect of the bias, i.e., P[Z|E,S]."
  - [corpus]: Weak evidence; no direct mention of EM or Bayesian inference in neighbor papers.
- Break condition: If P[Z|E,S] is not invertible as a stochastic matrix, the uniqueness of the MLE is not guaranteed, potentially leading to multiple solutions or poor convergence.

### Mechanism 2
- Claim: Once P[E|S] is estimated, BaBE derives P[E|Z,S] using Bayes' theorem, enabling decisions based on the estimated E rather than the biased Z.
- Mechanism: After obtaining an estimate ˆP[E|S] via EM, BaBE applies the conditional Bayes theorem: ˆP[E=e|Z=z,S=s] = P[Z=z|E=e,S=s] · ˆP[E=e|S=s] / P[Z=z|S=s]. This allows for computing the posterior distribution of E given observed Z and S, effectively "debiasing" the proxy variable Z by incorporating knowledge of the bias mechanism.
- Core assumption: The conditional distribution P[Z|E,S] remains constant across different populations, allowing causal knowledge to be transferred.
- Evidence anchors:
  - [section 3.2]: "Given the data {(zi, si)|i ∈ [1, ..., N]}, the conditional distributions P[Z|E,S], and the estimation ˆP[E|S], we derive the estimation ˆP[E|Z,S] by applying the Bayes formula."
  - [section 2]: "Another reason for assuming that we dispose of P[Z|E,S] and not of P[E|Z,S] is that the latter depends on the distribution of E, which can vary greatly depending on the geographical area, on the social context, etc."
  - [corpus]: Weak evidence; no direct mention of Bayes' theorem application in neighbor papers.
- Break condition: If the bias mechanism P[Z|E,S] varies across populations, the transferred causal knowledge becomes invalid, leading to incorrect estimates of P[E|Z,S].

### Mechanism 3
- Claim: BaBE achieves fairness by basing decisions on the estimated E rather than Z, either through direct thresholding (Method 1) or probability aggregation (Method 2).
- Mechanism: For each observation (zi, si), BaBE computes ˆP[E|Z=z,S=s] and applies one of two methods. Method 1 uses the mode of the distribution if it has sufficient probability mass (≥50%) to directly estimate E and make decisions. Method 2 aggregates probabilities across threshold values when the distribution is dispersed, setting ˆY=1 if the cumulative probability of E≥τ exceeds that of E<τ.
- Core assumption: The estimated P[E|Z,S] is sufficiently concentrated around the true E values for accurate decision-making.
- Evidence anchors:
  - [section 3.3]: "Method 1 Given z and s, if ˆP[E|Z=z,S=s] is unimodal and has a large probability mass (say, 50% or more) on its mode, then we can safely set ˆE to be that mode."
  - [section 3.3]: "Method 2 If ˆP[E|Z=z,S=s] is dispersed on several values, so that no value is strongly predominant, then it is impossible to estimate individual values for E with high accuracy."
  - [corpus]: Weak evidence; no direct mention of decision-making methods in neighbor papers.
- Break condition: If the estimated P[E|Z,S] is highly dispersed with no dominant mode, both methods may fail to produce accurate decisions, leading to poor fairness and accuracy.

## Foundational Learning

- Concept: Conditional probability and Bayes' theorem
  - Why needed here: BaBE relies on computing P[E|Z,S] from P[Z|E,S] and P[E|S] using Bayes' theorem, which is fundamental to the debiasing process.
  - Quick check question: Given P[Z|E,S] and an estimate of P[E|S], can you derive P[E|Z,S] using Bayes' theorem?

- Concept: Maximum likelihood estimation and the EM algorithm
  - Why needed here: BaBE uses EM to estimate the latent distribution P[E|S] by treating it as a maximum likelihood parameter, iteratively improving the estimate until convergence.
  - Quick check question: Can you explain how the E-step and M-step work in the context of estimating P[E|S] from observed Z and known P[Z|E,S]?

- Concept: Fairness metrics (statistical parity, conditional statistical parity, equal opportunity)
  - Why needed here: BaBE aims to achieve conditional statistical parity or equal opportunity by basing decisions on estimated E rather than biased Z, and its performance is evaluated against these fairness metrics.
  - Quick check question: What is the difference between statistical parity and conditional statistical parity, and why might the latter be preferable in scenarios with legitimate explanatory variables?

## Architecture Onboarding

- Component map:
  - Data preprocessing -> Bias mechanism estimation -> EM estimation -> Bayes inference -> Decision making -> Evaluation
- Critical path: Data preprocessing → Bias mechanism estimation → EM estimation → Bayes inference → Decision making → Evaluation
- Design tradeoffs:
  - Precision vs. accuracy: Higher precision in estimating P[E|S] may improve fairness but could reduce accuracy if the bias mechanism is imperfect
  - Method 1 vs. Method 2: Method 1 is more accurate when P[E|Z,S] is concentrated but may fail when it's dispersed; Method 2 is more robust but potentially less precise
  - Transferability: Assuming P[Z|E,S] is constant across populations enables knowledge transfer but may not hold in all scenarios
- Failure signatures:
  - Poor convergence of EM algorithm: Indicates issues with the bias mechanism estimation or data quality
  - Highly dispersed ˆP[E|Z,S]: Suggests the bias mechanism is too complex or the proxy variable Z is too weakly correlated with E
  - Low fairness metrics despite debiasing: May indicate the bias mechanism is incorrect or the decision threshold is inappropriate
- First 3 experiments:
  1. Synthetic data generation: Create synthetic data with known P[Z|E,S] and varying levels of bias to test BaBE's ability to recover P[E|S] and achieve fairness
  2. EM convergence analysis: Vary the precision threshold γ and initial conditions to study their impact on the convergence and quality of P[E|S] estimates
  3. Method comparison: Apply both Method 1 and Method 2 to synthetic and real data to compare their performance in terms of fairness, accuracy, and robustness to dispersed distributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the accuracy of the BaBE algorithm change when the bias matrix P[Z|E,S] is non-invertible or close to singular?
- Basis in paper: [explicit] The paper mentions that the performance of BaBE depends on the invertibility of P[Z|E,S] and that even when the matrix is not invertible, favorable results are obtained, but a systematic study is needed.
- Why unresolved: The authors acknowledge this as a topic for future work and did not conduct systematic experiments varying the invertibility of the bias matrix.
- What evidence would resolve it: Experiments comparing BaBE's accuracy and fairness metrics across different levels of bias matrix invertibility, from perfectly invertible to highly singular matrices.

### Open Question 2
- Question: What is the relationship between the precision of the bias mechanism estimation P[Z|E,S] and the resulting fairness and accuracy achieved by BaBE?
- Basis in paper: [explicit] The paper states that BaBE relies on having an estimation of P[Z|E,S] from external studies or controlled environments, but does not explore how errors in this estimation affect outcomes.
- Why unresolved: The experiments use synthetic data where P[Z|E,S] is known exactly, not estimated with noise or uncertainty.
- What evidence would resolve it: Experiments introducing controlled errors or uncertainty into the bias mechanism estimation and measuring the impact on BaBE's fairness and accuracy metrics.

### Open Question 3
- Question: How does the choice of threshold τ for the decision threshold affect the trade-off between fairness and accuracy in BaBE?
- Basis in paper: [explicit] The paper mentions that the threshold for the decision is E = 60 in synthetic experiments, but does not explore how varying this threshold affects performance.
- Why unresolved: The paper only uses a fixed threshold and does not report results for different threshold values.
- What evidence would resolve it: Experiments varying the decision threshold τ and reporting how accuracy, fairness metrics (SPD, CSPD, EOD), and distortion change across different threshold values.

## Limitations

- Bias mechanism dependency: BaBE's effectiveness heavily relies on accurate knowledge of P[Z|E,S], which may be challenging to estimate in practice
- Transferability assumption: The claim that P[Z|E,S] remains constant across populations enabling effective transfer of causal knowledge is a strong assumption that may not hold in real-world scenarios
- EM algorithm convergence: The paper lacks detailed convergence analysis and sensitivity to initialization, which could affect the quality of P[E|S] estimates

## Confidence

- Mechanism 1 (EM estimation of P[E|S]): Medium confidence - theoretical framework is sound but lacks detailed convergence analysis
- Mechanism 2 (Bayes inference to derive P[E|Z,S]): High confidence - straightforward application of Bayes' theorem
- Mechanism 3 (Decision-making methods): Medium confidence - clearly described but lacks extensive empirical validation

## Next Checks

1. **Robustness to bias mechanism estimation errors**: Systematically vary the accuracy of the estimated P[Z|E,S] and measure the impact on fairness and accuracy metrics to quantify sensitivity to errors in the assumed bias mechanism.

2. **EM convergence analysis**: Conduct experiments with different initializations and precision thresholds γ to map the convergence landscape, identify conditions under which the algorithm converges to suboptimal solutions, and characterize the relationship between precision and estimation quality.

3. **Cross-population validation**: Test whether P[Z|E,S] estimated from one population accurately transfers to another by using datasets from different geographical regions or time periods to evaluate the transferability assumption and identify scenarios where it breaks down.