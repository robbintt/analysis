---
ver: rpa2
title: Can ChatGPT Enable ITS? The Case of Mixed Traffic Control via Reinforcement
  Learning
arxiv_id: '2306.08094'
source_url: https://arxiv.org/abs/2306.08094
tags:
- chatgpt
- traffic
- control
- policies
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work investigates whether ChatGPT can assist non-experts
  in designing reinforcement learning (RL) policies for mixed traffic control problems.
  A large-scale user study with 70 participants is conducted, where participants are
  tasked with developing state and reward functions for three traffic environments:
  ring road, bottleneck, and intersection.'
---

# Can ChatGPT Enable ITS? The Case of Mixed Traffic Control via Reinforcement Learning

## Quick Facts
- arXiv ID: 2306.08094
- Source URL: https://arxiv.org/abs/2306.08094
- Reference count: 40
- Key outcome: ChatGPT significantly improves non-experts' ability to design successful RL policies for mixed traffic control, with 150% and 136% increases in successful policies for intersection and bottleneck environments respectively.

## Executive Summary
This study investigates whether ChatGPT can assist non-experts in designing reinforcement learning policies for mixed traffic control problems. A large-scale user study with 70 participants was conducted, where participants developed state and reward functions for three traffic environments: ring road, bottleneck, and intersection. Participants were divided into two groups - one using only prior knowledge and another using ChatGPT in addition to provided materials. Results show ChatGPT significantly increases successful policy rates, with some policies even outperforming expert-designed ones. However, effectiveness varies by problem complexity, with no improvement observed in the ring environment.

## Method Summary
The study involved 70 participants with no prior ITS experience, split into control and study groups. Participants designed state and reward functions for three traffic environments based on a provided manuscript covering RL overview and a metrics bank. The study group additionally used ChatGPT (GPT-4 with 8k context length, temperature=0.7) for assistance. Valid MDP designs were trained using PPO with default RLlib hyperparameters, and performance was evaluated based on environment-specific criteria. The number of successful policies, policy performance compared to expert baselines, and utilization of new metrics were measured and analyzed.

## Key Results
- ChatGPT increased successful policies by 150% for intersection and 136% for bottleneck environments
- Some ChatGPT-assisted policies outperformed expert-designed policies
- ChatGPT did not improve performance in the ring environment
- Invalid MDP designs decreased from 61% to 18% with ChatGPT assistance
- Novel metric utilization increased by 363% with ChatGPT

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPT reduces invalid MDP designs from 61% to 18% by leveraging broad knowledge base
- Mechanism: Participants can query ChatGPT for definitions and formulations of traffic metrics, reducing misunderstandings
- Core assumption: ChatGPT's training corpus includes sufficient traffic and RL domain knowledge
- Evidence: 82% valid answers with ChatGPT vs 61% without (21% increase)
- Break condition: Incorrect or ambiguous queries may reinforce misunderstandings

### Mechanism 2
- Claim: ChatGPT introduces novel traffic metrics, increasing design diversity by 363%
- Mechanism: ChatGPT generates new metric ideas beyond predefined options, expanding solution space
- Core assumption: Novel metrics are contextually meaningful and translatable to effective rewards
- Evidence: Study group used 35-63-59 new metrics vs control's 8-17-21 in ring-bottleneck-intersection order
- Break condition: Blind acceptance of novel metrics without validation may introduce noise

### Mechanism 3
- Claim: ChatGPT enables non-experts to match or exceed expert performance in complex environments
- Mechanism: ChatGPT provides reasoning explanations for reward terms, helping align objectives with traffic goals
- Core assumption: ChatGPT's reasoning is accurate enough to guide policy formulation
- Evidence: 4 out of 6 ChatGPT-assisted policies outperformed expert policy
- Break condition: If problem complexity exceeds ChatGPT's reasoning depth, assistance may not help

## Foundational Learning

- Concept: Partially Observable Markov Decision Process (POMDP) formulation
  - Why needed: Traffic control tasks are modeled as POMDPs; participants must define state, action, reward, and discount correctly
  - Quick check: What are the four main components of a POMDP that participants must define?

- Concept: Traffic flow metrics and their meanings
  - Why needed: Valid state and reward definitions depend on understanding metrics like outflow, density, queue length, and headway
  - Quick check: Which metric would you use to reward reducing vehicle queues at an intersection?

- Concept: Reinforcement learning policy evaluation
  - Why needed: Participants must understand how MDP designs translate into policy performance
  - Quick check: How is policy success measured differently in ring versus bottleneck environments?

## Architecture Onboarding

- Component map: Manuscript distribution -> MDP design -> Policy training (PPO) -> Performance evaluation; ChatGPT access module (study group) -> Prompt handling -> Metric generation and explanation
- Critical path: 1) Participant reads manuscript and designs state/reward 2) (Study group) Participant queries ChatGPT for help 3) MDP validated for correctness 4) Valid MDPs trained using PPO 5) Performance measured and compared to expert baseline
- Design tradeoffs: More ChatGPT guidance → higher validity but potential over-reliance; Larger metric bank → more options but harder to choose; Shorter training time → faster iteration but risk of underfitting
- Failure signatures: High invalid answer rate → participant misunderstanding; Low success despite valid MDPs → poor reward alignment; No improvement with ChatGPT → prompting strategy needs refinement
- First 3 experiments: 1) Small pilot with 5 participants to validate manuscript clarity and ChatGPT integration 2) Compare success rates between groups on simple environment (ring) 3) Analyze correlation between number of ChatGPT queries and policy success rate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific improvements in ChatGPT's training data or prompting strategies would be needed to significantly increase successful policies in complex mixed traffic control tasks?
- Basis: Authors note insufficient RL ITS problems in ChatGPT's training and that improvement rate was less than theorized
- Why unresolved: Study used standard ChatGPT without fine-tuning or specialized prompting strategies
- What evidence would resolve it: Follow-up study comparing performance using ChatGPT with various fine-tuning approaches, prompt engineering techniques, and training data augmentation specific to ITS and RL problems

### Open Question 2
- Question: How does the level of participant expertise in using ChatGPT affect the quality of generated MDP components in mixed traffic control?
- Basis: Authors observe varying levels of ChatGPT usage from a few questions to complete reliance
- Why unresolved: Study did not measure or control for participants' familiarity with ChatGPT or prompting skills
- What evidence would resolve it: Study where participants receive training in effective ChatGPT prompting before tasks, with results compared to current study

### Open Question 3
- Question: Can ChatGPT's ability to generate novel metrics be systematically leveraged to improve RL policy performance in mixed traffic control environments?
- Basis: Study found 363% increase in novel metric utilization but use of these metrics doesn't always result in successful policies
- Why unresolved: Study demonstrated capability to generate novel metrics but didn't investigate which types are most effective
- What evidence would resolve it: Systematic analysis of which novel metrics correlate with successful policies, followed by developing guidelines for effective incorporation into MDP design

## Limitations

- Reliance on participant self-selection may introduce selection bias toward more motivated individuals
- Evaluation metrics are environment-specific, making cross-environment comparisons challenging
- ChatGPT's temperature=0.7 introduces variability that may affect reproducibility
- Study doesn't account for differences in how participants formulate queries to ChatGPT

## Confidence

- **High confidence**: 150% and 136% improvement rates for intersection and bottleneck environments are well-supported; 61% to 18% reduction in invalid MDP designs is clearly specified
- **Medium confidence**: Claim that some ChatGPT-assisted policies outperform expert-designed ones is supported but limited to 4 out of 6 cases; 363% increase in new metric utilization is based on defined methodology
- **Low confidence**: Finding that ChatGPT doesn't improve ring environment performance is based on small sample size

## Next Checks

1. Conduct controlled experiment with random assignment to eliminate selection bias and measure impact on success rates
2. Implement standardized prompting protocol for ChatGPT usage across all study group participants to reduce variability and assess effect on performance
3. Perform sensitivity analysis on ChatGPT temperature parameter (0.0, 0.5, 0.7) to determine impact on consistency and quality of generated metrics and explanations