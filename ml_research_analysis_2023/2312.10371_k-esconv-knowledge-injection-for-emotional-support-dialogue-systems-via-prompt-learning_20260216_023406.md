---
ver: rpa2
title: 'K-ESConv: Knowledge Injection for Emotional Support Dialogue Systems via Prompt
  Learning'
arxiv_id: '2312.10371'
source_url: https://arxiv.org/abs/2312.10371
tags:
- knowledge
- prompt
- arxiv
- response
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: K-ESConv is a novel prompt learning method for emotional support
  dialogue systems that incorporates external knowledge from online counseling forums
  to enhance response generation. The approach employs knowledge-aware and context-aware
  prompt encoders to adapt a pre-trained language model for generating responses that
  are more correlated, diverse, and professional.
---

# K-ESConv: Knowledge Injection for Emotional Support Dialogue Systems via Prompt Learning

## Quick Facts
- arXiv ID: 2312.10371
- Source URL: https://arxiv.org/abs/2312.10371
- Reference count: 9
- Key outcome: K-ESConv achieves BLEU scores of 18.83 and BERTScore of 84.9 on the ESConv dataset, outperforming knowledge-free and knowledge-grounded baselines in automatic and human evaluations for emotional support dialogue generation.

## Executive Summary
K-ESConv is a novel prompt learning method for emotional support dialogue systems that incorporates external knowledge from online counseling forums to enhance response generation. The approach employs knowledge-aware and context-aware prompt encoders to adapt a pre-trained language model for generating responses that are more correlated, diverse, and professional. Evaluated on the ESConv dataset, K-ESConv outperforms both knowledge-free and knowledge-grounded baselines in automatic and human evaluations, achieving BLEU scores of 18.83 and BERTScore of 84.9. The method significantly improves the correlation and diversity of responses, providing more comfort and better suggestions for the seeker.

## Method Summary
K-ESConv uses separate knowledge-aware prompt encoder (KPE) and context-aware prompt encoder (CPE) to generate prompt encodings from retrieved knowledge and dialogue context respectively. These encodings are concatenated and fed as past hidden states to a frozen response generation decoder (RGD). The model employs DPR for knowledge retrieval from the PsyQA dataset and uses prompt learning to efficiently adapt a GPT-2 backbone without full fine-tuning. The approach aims to generate responses that are both contextually relevant and knowledge-grounded, improving the quality of emotional support dialogues.

## Key Results
- K-ESConv achieves BLEU scores of 18.83 and BERTScore of 84.9 on the ESConv dataset
- The model outperforms both knowledge-free and knowledge-grounded baselines in automatic and human evaluations
- K-ESConv significantly improves response correlation and diversity metrics compared to baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: K-ESConv improves response diversity and correlation by using separate context-aware and knowledge-aware prompt encoders.
- Mechanism: The model uses two prompt encoders—one for context (CPE) and one for retrieved knowledge (KPE). These encoders generate distinct prompt encodings that are concatenated and fed as past hidden states to a frozen response generation decoder (RGD). This allows the PLM to generate responses that are both contextually relevant and knowledge-grounded.
- Core assumption: Context and knowledge can be encoded separately and their combination enhances response quality more than joint encoding.
- Evidence anchors:
  - [abstract] "The approach employs knowledge-aware and context-aware prompt encoders to adapt a pre-trained language model for generating responses that are more correlated, diverse, and professional."
  - [section 3.3] "K-ESConv consists of a knowledge-aware prompt encoder (KPE), a context-aware prompt encoder (CPE) and a response generation decoder (RGD)... The prompt encodings are reparameterized by a MLP layer in order to improve the stability of optimization."
- Break condition: If the retrieved knowledge is irrelevant or noisy, the KPE may introduce misleading signals that degrade response quality.

### Mechanism 2
- Claim: K-ESConv outperforms knowledge-grounded baselines in both automatic and human evaluations due to better knowledge injection.
- Mechanism: By freezing the RGD and optimizing only the prompt encoders, K-ESConv efficiently steers the PLM to incorporate knowledge without overfitting to the task. The knowledge is selected via a dense passage retriever (DPR), ensuring relevance, and the prompt-based adaptation allows the model to generate more knowledgeable and professional responses.
- Core assumption: Freezing the decoder while fine-tuning prompt encoders preserves the generalization capability of the PLM while adapting it to the task.
- Evidence anchors:
  - [abstract] "K-ESConv outperforms both knowledge-free and knowledge-grounded baselines in automatic and human evaluations, achieving BLEU scores of 18.83 and BERTScore of 84.9."
  - [section 3.3] "KPE and CPE takes context and retrieved knowledge as input respectively... the concatenation of context-aware prompt encoding and knowledge-aware prompt encoding are taken as past hidden states of RGD."
- Break condition: If the DPR retrieval fails to find relevant knowledge, the KPE may not contribute meaningful signals.

### Mechanism 3
- Claim: The use of prompt learning improves stability and performance over traditional fine-tuning.
- Mechanism: Prompt learning in K-ESConv involves tuning only the prompt encoders while keeping the RGD frozen. This reduces the number of trainable parameters and focuses adaptation on generating effective prompt encodings, which are then used to condition the RGD.
- Core assumption: Prompt learning is more parameter-efficient and stable than full fine-tuning for adapting PLMs to new tasks.
- Evidence anchors:
  - [section 3.3] "In retrospect to our model, there are totally three PLMs, in which CPE and KPE are trainable, but RGD is frozen."
  - [section 4.2] "The performance of K-ESConv is slightly better than that of knowledge-grounded baselines in BERTScore. It indicates that the response in our method condenses more information from retrieved external knowledge."
- Break condition: If the prompt size is too small or too large, the model may fail to capture sufficient context or knowledge information.

## Foundational Learning

- Concept: Dense Passage Retrieval (DPR)
  - Why needed here: DPR is used to retrieve the most relevant knowledge from an external QA knowledge base (PsyQA) for a given context in emotional support dialogues.
  - Quick check question: What is the main advantage of using DPR over traditional keyword-based retrieval in this task?

- Concept: Prompt Learning
  - Why needed here: Prompt learning allows efficient adaptation of a pre-trained language model (PLMs) to the task of emotional support dialogue generation without full fine-tuning.
  - Quick check question: How does prompt learning differ from traditional fine-tuning in terms of trainable parameters and stability?

- Concept: Automatic Evaluation Metrics (BLEU, DIST, ROUGE-L, BERTScore)
  - Why needed here: These metrics are used to evaluate the quality of generated responses in terms of fluency, diversity, and relevance to the context and knowledge.
  - Quick check question: Which metric would be most appropriate to evaluate the diversity of generated responses?

## Architecture Onboarding

- Component map: Context → DPR → KPE + CPE → RGD → Generated Response
- Critical path: Context → DPR → KPE + CPE → RGD → Generated Response
- Design tradeoffs:
  - Freezing RGD vs. fine-tuning: Freezing preserves PLM generalization but may limit adaptation flexibility.
  - Prompt size: Larger prompt sizes may capture more information but increase computational cost.
  - Knowledge selection: Top-1 retrieval is simple but may miss relevant knowledge; multi-knowledge retrieval could improve coverage but complicate prompt encoding.
- Failure signatures:
  - Low BERTScore: Knowledge injection is not effective or retrieved knowledge is irrelevant.
  - Low DIST scores: Generated responses lack diversity, possibly due to over-constrained prompts.
  - High fluency but low identification/comforting scores in human evaluation: Responses are fluent but not empathetic or helpful.
- First 3 experiments:
  1. Vary prompt sizes (context and knowledge) to find optimal configuration.
  2. Compare single vs. multiple knowledge retrieval to assess impact on response quality.
  3. Evaluate the effect of freezing vs. fine-tuning the RGD on response quality and training stability.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of using multiple knowledge pieces instead of a single one in K-ESConv?
- Basis in paper: [inferred] The paper mentions the possibility of multiple knowledge pieces corresponding to contexts but does not explore this.
- Why unresolved: The paper does not provide experiments or analysis on the use of multiple knowledge pieces.
- What evidence would resolve it: Experiments comparing the performance of K-ESConv with single vs. multiple knowledge pieces.

### Open Question 2
- Question: How does the performance of K-ESConv vary with different sizes of context and knowledge prompt encoders?
- Basis in paper: [explicit] The paper mentions tuning the knowledge prompt size and context prompt size but does not provide detailed analysis on the performance variations.
- Why unresolved: The paper only mentions the impact of prompt size on performance but does not provide a detailed analysis or experiments.
- What evidence would resolve it: Detailed experiments showing the performance of K-ESConv with different prompt sizes.

### Open Question 3
- Question: How does K-ESConv perform on other dialogue datasets besides ESConv?
- Basis in paper: [inferred] The paper only evaluates K-ESConv on ESConv and does not mention its performance on other datasets.
- Why unresolved: The paper does not provide experiments or analysis on the performance of K-ESConv on other dialogue datasets.
- What evidence would resolve it: Experiments comparing the performance of K-ESConv on ESConv and other dialogue datasets.

## Limitations
- The exact implementation details of prompt encoding and combination are not fully specified, making faithful reproduction challenging
- The paper assumes DPR will consistently retrieve relevant knowledge without thoroughly addressing failure scenarios
- Evaluation is limited to the ESConv dataset, with limited discussion of performance across different emotional support dialogue domains

## Confidence
*High Confidence:* The paper demonstrates clear improvements over baseline models in both automatic and human evaluations. The BLEU scores of 18.83 and BERTScore of 84.9 represent concrete, measurable improvements. The methodology of using separate prompt encoders for context and knowledge, combined with frozen decoder fine-tuning, is well-established in the prompt learning literature.

*Medium Confidence:* While the paper shows improved correlation and diversity metrics, the practical significance of these improvements for actual emotional support conversations is not fully validated. The human evaluation covers important aspects like fluency and comfort, but the sample size and demographic diversity of evaluators are not specified. The claim that responses are "more professional" is somewhat subjective and could benefit from expert counselor validation.

*Low Confidence:* The paper's assertion that freezing the RGD while fine-tuning prompt encoders provides optimal stability and performance lacks comprehensive ablation studies. The specific prompt sizes (10 for CPE, 5 for KPE) appear to be chosen empirically without systematic exploration of the parameter space. The break conditions mentioned in the mechanisms section are theoretical rather than empirically validated.

## Next Checks
1. **Ablation Study on RGD Freezing:** Conduct experiments comparing K-ESConv with different levels of RGD fine-tuning (fully frozen, partially fine-tuned, fully fine-tuned) to empirically validate the claim that freezing improves stability and performance. Measure both quantitative metrics and training convergence speed.

2. **Knowledge Retrieval Robustness Testing:** Systematically evaluate K-ESConv's performance when DPR retrieves increasingly noisy or irrelevant knowledge. This could involve injecting controlled amounts of irrelevant knowledge into the prompt encoding and measuring degradation in response quality metrics.

3. **Cross-Dataset Generalization:** Test K-ESConv on multiple emotional support dialogue datasets beyond ESConv, including datasets from different cultural contexts or counseling domains. This would validate whether the knowledge injection approach generalizes beyond the specific dataset used in training and evaluation.