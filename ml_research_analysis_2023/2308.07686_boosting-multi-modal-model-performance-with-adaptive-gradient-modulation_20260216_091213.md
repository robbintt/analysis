---
ver: rpa2
title: Boosting Multi-modal Model Performance with Adaptive Gradient Modulation
arxiv_id: '2308.07686'
source_url: https://arxiv.org/abs/2308.07686
tags:
- modality
- competition
- fusion
- multi-modal
- modalities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel adaptive gradient modulation (AGM)
  method that enhances multi-modal model performance by balancing the contributions
  of individual modalities during training. The method uses a Shapley value-based
  attribution technique to isolate mono-modal responses and modulate gradients based
  on the discrepancy between modalities' contributions.
---

# Boosting Multi-modal Model Performance with Adaptive Gradient Modulation

## Quick Facts
- **arXiv ID**: 2308.07686
- **Source URL**: https://arxiv.org/abs/2308.07686
- **Reference count**: 25
- **Key outcome**: AGM improves multi-modal model accuracy by balancing modality contributions through Shapley value-based gradient modulation

## Executive Summary
This paper introduces Adaptive Gradient Modulation (AGM), a novel method that enhances multi-modal model performance by dynamically balancing the contributions of individual modalities during training. AGM uses Shapley value-based attribution to isolate mono-modal responses and modulates gradients based on the discrepancy between modalities' contributions, measured through mono-modal cross-entropy. Extensive experiments demonstrate that AGM outperforms existing modulation methods across various fusion strategies, datasets, and network architectures, while also encouraging models to rely on more informative modalities.

## Method Summary
AGM enhances multi-modal models by computing mono-modal outputs using Shapley values, measuring each modality's information contribution via mono-modal cross-entropy, and adjusting gradient magnitudes so weaker modalities receive stronger updates. The method uses a running average of mono-modal cross-entropy as the modulation reference, allowing dynamic adaptation to changing relative strengths during training. AGM is compared against baseline joint-training and existing modulation techniques (MSES, MSLR, OGM-GE) across five multi-modal datasets (A V-MNIST, CREMA-D, UR-Funny, A VE, CMU-MOSEI) with various fusion strategies.

## Key Results
- AGM achieves higher accuracy than baseline joint-training and existing modulation methods across multiple datasets and fusion strategies
- The method successfully reduces modality competition as measured by a novel competition strength metric
- AGM encourages models to rely on more informative modalities while maintaining a preferred modality that need not dominate others

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AGM reduces modality competition by modulating gradients based on mono-modal cross-entropy discrepancies
- Mechanism: AGM computes mono-modal outputs using Shapley values, measures each modality's information contribution via mono-modal cross-entropy, and adjusts gradient magnitudes so weaker modalities receive stronger updates
- Core assumption: Mono-modal cross-entropy accurately reflects the information contribution of each modality in the joint model
- Evidence anchors: [abstract] "uses a Shapley value-based attribution technique to isolate mono-modal responses and modulate gradients based on the discrepancy between modalities' contributions." [section 3.1.1] Defines mono-modal responses and cross-entropy. [corpus] Weak - no direct corpus citation for the link between cross-entropy and contribution strength

### Mechanism 2
- Claim: AGM encourages reliance on more informative modalities by weakening dominant modalities' gradients
- Mechanism: AGM computes discrepancy ratios between modalities' mono-modal cross-entropy values and modulates gradients inversely proportional to these ratios, effectively suppressing over-contributing modalities
- Core assumption: Modulating gradients inversely to contribution reduces the dominance effect and balances learning
- Evidence anchors: [section 3.1.2] Describes the modulation formula κm t = exp(−α∗(rm t − τ m t)) which weakens strong modalities. [abstract] "modulate gradients based on the discrepancy between modalities' contributions." [corpus] Weak - no explicit citation for the assumption that gradient weakening leads to balanced learning

### Mechanism 3
- Claim: The running average reference in AGM adapts to changing modality strengths over training
- Mechanism: AGM uses a running average of mono-modal cross-entropy as the modulation reference, allowing it to adapt to evolving relative strengths rather than enforcing static balance
- Core assumption: Modality strengths shift during training and need dynamic adjustment rather than fixed targets
- Evidence anchors: [section 3.1.2] Defines τ m t using running average ˆsm(t). [section 4.2] Mentions "AGM adjusts the modulation coefficients based on the running average." [corpus] Weak - no explicit evidence for the necessity of dynamic adaptation

## Foundational Learning

- **Concept: Shapley value attribution**
  - Why needed here: AGM uses Shapley values to isolate each modality's contribution without competition
  - Quick check question: Can you explain how Shapley values allocate contribution fairly among modalities in a multi-modal model?

- **Concept: Gradient modulation**
  - Why needed here: AGM adjusts gradient magnitudes per modality to balance their contributions during training
  - Quick check question: How does modulating gradients based on discrepancy ratios affect convergence and modality balance?

- **Concept: Mono-modal concept and competition strength metric**
  - Why needed here: These concepts allow quantifying how much modalities compete and how AGM changes that competition
  - Quick check question: How does the linear probing method estimate competition strength between modalities?

## Architecture Onboarding

- **Component map**: Forward pass with full and muted inputs -> Compute mono-modal outputs and cross-entropy -> Calculate discrepancy ratios and modulation coefficients -> Apply modulated gradients in backpropagation
- **Critical path**:
  1. Forward pass with full and muted inputs
  2. Compute mono-modal outputs and cross-entropy
  3. Calculate discrepancy ratios and modulation coefficients
  4. Apply modulated gradients in backpropagation
- **Design tradeoffs**:
  - Using Shapley values allows complex fusion strategies but increases computation
  - Dynamic running average reference adapts to training but adds noise
  - Modulation based on cross-entropy is interpretable but may not capture all contribution nuances
- **Failure signatures**:
  - If mono-modal outputs are noisy, modulation could amplify incorrect adjustments
  - If running average lags too much, modulation could respond to outdated information
  - If gradient modulation is too aggressive, training instability may occur
- **First 3 experiments**:
  1. Validate mono-modal outputs on a simple late-fusion model with known contributions
  2. Test gradient modulation on a two-modality synthetic task where one modality is clearly more informative
  3. Compare running average vs fixed reference modulation on a dynamic dataset where modality strengths shift

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the mono-modal concept perform under different random initializations, and what impact does this have on the competition strength metric?
- Basis in paper: [explicit] The paper mentions that they train the mono-modal concept with different random seeds in initialization on the A V-MNIST dataset to justify the definition of the proposed competition strength metric
- Why unresolved: The paper only mentions that the corresponding competition strengths are of similar magnitudes, but does not provide detailed results or analysis on how different random initializations affect the mono-modal concept and the competition strength metric
- What evidence would resolve it: Detailed experimental results comparing the mono-modal concept and competition strength metric under different random initializations would provide evidence to resolve this question

### Open Question 2
- Question: How does the performance of the mono-modal concept vary with different fusion strategies, and what implications does this have for the competition strength metric?
- Basis in paper: [explicit] The paper compares the performance of the mono-modal concept in different fusion strategies, finding that the performance is very similar in the late and early fusion cases on each dataset
- Why unresolved: While the paper notes the similarity in performance, it does not explore the implications of this similarity for the competition strength metric or provide a detailed analysis of how the fusion strategy affects the mono-modal concept and competition strength
- What evidence would resolve it: A detailed analysis of how the fusion strategy affects the mono-modal concept and competition strength metric, including potential reasons for the observed similarities, would provide evidence to resolve this question

### Open Question 3
- Question: How does the competition strength metric compare to other methods of evaluating modality competition, such as the SHAPE scores (Hu et al., 2022)?
- Basis in paper: [inferred] The paper introduces a novel competition strength metric based on the mono-modal concept, but does not directly compare it to other existing methods like the SHAPE scores
- Why unresolved: The paper does not provide a comparison between the proposed competition strength metric and other existing methods, leaving it unclear how it performs relative to other approaches
- What evidence would resolve it: A direct comparison of the proposed competition strength metric with other existing methods, such as the SHAPE scores, in terms of accuracy, robustness, and computational efficiency, would provide evidence to resolve this question

## Limitations

- The effectiveness of AGM relies heavily on the assumption that mono-modal cross-entropy accurately reflects each modality's information contribution, which lacks strong empirical validation
- The computational overhead from Shapley value calculations across multiple modalities and fusion strategies could be prohibitive for large-scale applications
- The dynamic running average reference mechanism lacks strong empirical validation for its necessity versus a simpler fixed reference

## Confidence

- **High Confidence**: AGM improves accuracy on tested datasets compared to joint training baselines. The empirical results are consistent across multiple datasets and architectures
- **Medium Confidence**: AGM reduces modality competition as measured by the proposed competition strength metric. While the metric is novel, the correlation between reduced competition and improved performance needs further validation
- **Low Confidence**: The core mechanism assumption that cross-entropy discrepancies accurately represent contribution imbalances. The paper provides theoretical justification but limited empirical validation of this specific link

## Next Checks

1. **Validate Mono-Modal Attribution**: Conduct ablation studies where mono-modal outputs are generated through simpler attribution methods (e.g., input masking without Shapley values) to test if the Shapley-based approach is essential for performance gains

2. **Test Fixed vs Dynamic Reference**: Implement AGM variants using fixed cross-entropy references instead of running averages to quantify the actual benefit of dynamic adaptation versus computational overhead

3. **Analyze Contribution Accuracy**: Design experiments where ground truth modality contributions are known (synthetic tasks) to directly measure how well AGM's cross-entropy-based modulation aligns with actual information contribution versus other possible metrics