---
ver: rpa2
title: 'Explaining with Attribute-based and Relational Near Misses: An Interpretable
  Approach to Distinguishing Facial Expressions of Pain and Disgust'
arxiv_id: '2308.14163'
source_url: https://arxiv.org/abs/2308.14163
tags:
- pain
- near
- explanations
- misses
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of distinguishing facial expressions
  of pain from disgust, which is important for medical diagnostics since these expressions
  are highly similar. The authors propose using contrastive explanations based on
  near misses - examples from the opposite class that are most similar to a given
  example.
---

# Explaining with Attribute-based and Relational Near Misses: An Interpretable Approach to Distinguishing Facial Expressions of Pain and Disgust

## Quick Facts
- arXiv ID: 2308.14163
- Source URL: https://arxiv.org/abs/2308.14163
- Reference count: 40
- Key outcome: Near miss explanations are shorter than far miss explanations when distinguishing facial expressions of pain from disgust

## Executive Summary
This paper addresses the challenge of distinguishing highly similar facial expressions of pain and disgust, which is crucial for medical diagnostics. The authors propose a contrastive explanation approach using near misses - examples from the opposite class that are most similar to a given example. They implement two approaches: one using only facial action units (attributes) and another using temporal relations between action units. The method employs Inductive Logic Programming to learn interpretable rule-based classifiers and uses Jaccard and Overlap similarity metrics to select near misses. Results show that near miss explanations are more concise than far miss explanations, and that temporal relations help improve the distinction between pain and disgust expressions.

## Method Summary
The method converts video sequences of facial expressions into symbolic representations using Horn clauses, with action units (AUs) and temporal relations between AU intervals as features. ILP classifiers are trained on these representations using the Aleph system, learning rule-based models for both attribute-based and relational approaches. For explanation generation, correctly classified examples are propositionalized into feature sets, and similarity metrics (Jaccard and Overlap coefficients) are applied to rank and select near misses from the opposite class. Contrastive explanations are then generated by computing differences between the target example and its near misses.

## Key Results
- Near miss explanations are shorter than far miss explanations, demonstrating the efficiency of contrastive approaches
- Temporal relations between action units help distinguish pain from disgust more effectively than attributes alone
- The Jaccard coefficient produces fewer and shorter near miss explanations compared to the Overlap coefficient
- Relational classifiers had lower accuracy for disgust (62.1%) compared to attribute-based classifiers (75.8%)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Near miss explanations are shorter and more informative than far miss explanations because they focus on minimal differences between similar examples.
- Mechanism: By selecting contrastive examples from the opposite class that are most similar to the target example, the explanations highlight only the few key differences that distinguish the classes.
- Core assumption: Similarity between examples can be effectively measured using set-based metrics (Jaccard and Overlap coefficients) after propositionalization.
- Evidence anchors:
  - [abstract]: "Results on a real dataset show that near miss explanations are shorter than far miss explanations"
  - [section]: "We hypothesize that near miss explanations yield shorter and more relevant explanations in contrast to less similar examples (far misses)"
  - [corpus]: Weak evidence - corpus neighbors do not provide relevant support for this mechanism
- Break Condition: If the similarity metrics fail to capture the relevant differences between examples, near misses may not be meaningfully different from far misses, making explanations equally long or uninformative.

### Mechanism 2
- Claim: Temporal relations between action units help distinguish pain from disgust more effectively than attributes alone.
- Mechanism: By incorporating Allen calculus temporal relations between facial action units, the model captures dynamic patterns that are unique to pain expressions versus disgust expressions.
- Core assumption: Pain and disgust expressions differ in their temporal dynamics even when individual action units may be similar.
- Evidence anchors:
  - [abstract]: "The outcome of our evaluation indicates that pain and disgust can be distinguished with the help of temporal relations"
  - [section]: "We hypothesize that it might not be enough to assign an example to a class based on the occurrence or absence of attributes...temporal relations between different muscle movements are taken into account"
  - [corpus]: Weak evidence - corpus neighbors do not provide relevant support for this mechanism
- Break Condition: If pain and disgust expressions do not actually differ significantly in their temporal dynamics, adding temporal relations will not improve classification or explanation quality.

### Mechanism 3
- Claim: ILP produces interpretable rule-based classifiers that enable transparent explanations for medical decision support.
- Mechanism: ILP learns human-readable Horn clauses from symbolic representations of video sequences, allowing domain experts to understand and verify the classification logic.
- Core assumption: Symbolic representations of video sequences (as Horn clauses) can effectively capture the relevant features for distinguishing pain from disgust.
- Evidence anchors:
  - [section]: "ILP supports relational explanations in contrast to visual explanations that may not express more than just the presence or absence of features"
  - [section]: "The rule-based classifier can be used to produce global as well as local explanations"
  - [corpus]: Weak evidence - corpus neighbors do not provide relevant support for this mechanism
- Break Condition: If the symbolic representation fails to capture the essential features of facial expressions, or if the learned rules become too complex to interpret, the ILP approach will lose its transparency advantage.

## Foundational Learning

- Concept: Inductive Logic Programming (ILP)
  - Why needed here: ILP provides the foundation for learning interpretable rule-based classifiers from relational data, which is essential for generating transparent explanations in medical contexts.
  - Quick check question: What type of logic does ILP use to represent learned rules, and why is this important for medical applications?

- Concept: Contrastive Explanations
  - Why needed here: Contrastive explanations focus on the differences between similar examples, which is more efficient for understanding classification decisions than explaining all features.
  - Quick check question: How do near miss explanations differ from traditional feature importance explanations in terms of their focus and efficiency?

- Concept: Temporal Logic and Allen Calculus
  - Why needed here: Allen calculus provides a formal framework for representing temporal relations between facial action units, which captures dynamic patterns essential for distinguishing similar expressions.
  - Quick check question: What are the basic temporal relations defined by Allen calculus, and how might they apply to sequences of facial action units?

## Architecture Onboarding

- Component map:
  - Video sequences â†’ Symbolic representations (Horn clauses)
  - Feature Extraction: Action units and temporal relations
  - Model Training: ILP classifiers (attribute-based and relational)
  - Near Miss Selection: Similarity metrics (Jaccard, Overlap) applied to propositionalized traces
  - Explanation Generation: Difference computation between target and near miss examples

- Critical path:
  1. Convert video sequences to symbolic representations
  2. Train ILP classifiers on attributes and relations
  3. Generate traces for correctly classified examples
  4. Apply similarity metrics to find near misses
  5. Compute and present contrastive explanations

- Design tradeoffs:
  - Interpretability vs. accuracy: ILP provides transparency but may sacrifice some classification performance compared to black-box models
  - Computational complexity: Propositionalization and similarity computation add overhead but enable efficient near miss selection
  - Dataset size: ILP works well with limited data but may struggle with very large or complex datasets

- Failure signatures:
  - Empty near miss sets (as occurred with relational approach) indicating poor class separability
  - Explanations that are nearly as long as far miss explanations, suggesting similarity metrics aren't capturing relevant differences
  - Rule sets that are too complex to interpret, defeating the purpose of using ILP

- First 3 experiments:
  1. Compare explanation lengths for near misses vs. far misses using synthetic data with known minimal differences
  2. Test classification performance with and without temporal relations on a balanced dataset
  3. Evaluate explanation quality with domain experts by having them validate whether explanations capture meaningful differences between pain and disgust expressions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the incorporation of temporal relations between action units significantly improve the separation between pain and disgust expressions?
- Basis in paper: [explicit] The paper discusses two approaches - one based on attributes (action units) and another on relations (temporal relations between action units). The results show that the relational classifiers had a lower accuracy for disgust compared to the attribute-based classifiers.
- Why unresolved: The paper mentions that the relational approach did not find any near misses because there were no intersecting features between pain and disgust examples, indicating that temporal relations help distinguish between the two. However, the lower accuracy for disgust in the relational approach suggests that the incorporation of temporal relations may not significantly improve separation.
- What evidence would resolve it: Further experiments with a larger and more diverse dataset could provide more conclusive evidence on whether the incorporation of temporal relations significantly improves the separation between pain and disgust expressions.

### Open Question 2
- Question: How can the proposed method be enhanced by incorporating additional modalities such as visuals and interaction?
- Basis in paper: [explicit] The paper mentions that the authors plan to enhance the framework by incorporating additional similarity measures and modalities, such as visuals and interaction.
- Why unresolved: The paper does not provide any details on how the proposed method can be enhanced by incorporating additional modalities.
- What evidence would resolve it: Experiments comparing the performance of the proposed method with and without the incorporation of additional modalities would provide evidence on the effectiveness of such enhancements.

### Open Question 3
- Question: How can the proposed method be extended to explain pain expressions in contrast to other emotional states beyond disgust?
- Basis in paper: [explicit] The paper focuses on distinguishing pain expressions from disgust expressions, but does not discuss the applicability of the proposed method to other emotional states.
- Why unresolved: The paper does not provide any information on how the proposed method can be extended to explain pain expressions in contrast to other emotional states.
- What evidence would resolve it: Experiments evaluating the performance of the proposed method in explaining pain expressions in contrast to other emotional states would provide evidence on its applicability beyond disgust.

## Limitations
- Dataset specificity: Results on pain vs. disgust may not generalize to other facial expression pairs
- Propositionalization details: The approach for converting relational traces into feature sets for similarity computation is not fully detailed
- Lack of expert validation: The paper does not validate whether generated explanations are actually useful for domain experts in practice

## Confidence
- Near miss explanations are shorter than far miss explanations: Medium confidence (directly demonstrated but relies on specific similarity metrics)
- Temporal relations improve distinction between pain and disgust: Medium-Low confidence (evaluation shows this but mechanism not thoroughly validated)
- ILP's interpretability advantage: Medium confidence (follows from method choice but lacks direct user validation)

## Next Checks
1. Conduct expert evaluation with pain assessment specialists to verify whether generated explanations capture clinically meaningful differences between pain and disgust expressions
2. Test the approach on additional facial expression pairs (e.g., fear vs. surprise) to assess generalizability of near miss explanation benefits
3. Compare explanation quality and user comprehension against black-box model explanations using the same dataset to quantify the interpretability-accuracy tradeoff