---
ver: rpa2
title: Teaching Specific Scientific Knowledge into Large Language Models through Additional
  Training
arxiv_id: '2312.03360'
source_url: https://arxiv.org/abs/2312.03360
tags:
- training
- texts
- learning
- text
- were
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores embedding specialized scientific knowledge
  into Llama 2 through additional training. It finds that effective knowledge integration
  requires reading texts from multiple perspectives, particularly in instructional
  formats.
---

# Teaching Specific Scientific Knowledge into Large Language Models through Additional Training

## Quick Facts
- arXiv ID: 2312.03360
- Source URL: https://arxiv.org/abs/2312.03360
- Reference count: 40
- This study demonstrates that specialized scientific knowledge can be effectively embedded into Llama 2 models through text augmentation and LoRA training, achieving knowledge integration with significantly reduced computational resources.

## Executive Summary
This paper investigates methods for embedding specialized scientific knowledge into Llama 2 models through additional training. The research demonstrates that knowledge integration can be achieved through text augmentation (style conversions and translations) combined with LoRA fine-tuning, requiring significantly less computational resources than full-parameter training. The study constructs a dataset of 65,000 scientific papers and validates the approach across multiple model sizes (7b, 13b, and 70b parameters). While partial knowledge embedding is achieved, the research highlights complexities in incorporating specialized information and identifies areas for further improvement.

## Method Summary
The methodology combines text augmentation with LoRA-based fine-tuning to embed scientific knowledge into Llama 2 models. Text augmentation generates multiple perspectives of the same content through style conversions (Q&A, article, interview, textbook formats) and translations into six languages. LoRA adapters with rank 100 are applied to selected layers (embed_tokens, v_proj, o_proj, gate_proj, down_proj, lm_head) with optimized hyperparameters (learning rate 0.0002, lora_alpha 300). The approach is validated using both synthetic documents and a real corpus of 65,000 scientific papers from Springer Nature journals, with evaluation through keyword matching and GPT-4 assessment.

## Key Results
- LoRA with rank 100 and learning rate 0.0002 achieved comparable performance to full-parameter training while updating <1% of parameters
- Multiple text formats (Q&A, article, interview, textbook) improved keyword-based recall metrics significantly
- Translation augmentation showed mixed results: Spanish, German, and Italian improved scores while Japanese showed no benefit
- Performance degraded predictably when irrelevant text volume exceeded 500 documents, demonstrating catastrophic forgetting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reading texts from multiple perspectives improves LLM knowledge retention
- Mechanism: Different text formats reinforce token relationships from varied angles, enabling better generalization and recall
- Core assumption: LLMs learn like humans—multiple representations of the same concept strengthen understanding
- Evidence anchors:
  - [abstract] "effective knowledge integration requires reading texts from multiple perspectives, especially in instructional formats"
  - [section] "augmentation process in learning for an LLM may be compared to an individual learning a specific topic by consulting multiple reference books"
  - [corpus] Weak evidence—corpus neighbors don't directly address text augmentation effects
- Break condition: If augmentation texts introduce contradictory or noisy information, knowledge retention drops

### Mechanism 2
- Claim: LoRA with optimal hyperparameters can match full-parameter training in knowledge embedding efficiency
- Mechanism: Low-rank adapters update a small fraction of parameters (<1%), enabling effective fine-tuning with limited memory
- Core assumption: The model's knowledge capacity is preserved while only key adaptation weights are modified
- Evidence anchors:
  - [section] "LoRA's effectiveness in knowledge teaching" and "LoRA rank (r) of approximately 100 was found to be optimal"
  - [section] "using LoRA and quantization proved capable of matching the performance of full-parameter training methods"
  - [corpus] Weak evidence—neighbors focus on LLM fine-tuning but not specifically LoRA optimization
- Break condition: If r is too small or learning rate is mis-tuned, training collapses

### Mechanism 3
- Claim: Multilingual text augmentation boosts comprehension in LLMs
- Mechanism: Training on translations forces the model to map concepts across languages, reinforcing semantic understanding
- Core assumption: The model can generalize across languages even with varying grammar structures
- Evidence anchors:
  - [section] "Translations into Spanish (C6), German (C7), Italian (C9), Chinese (C11), and Korean (C12) showed notable improvements in scores"
  - [section] "LLM's proficiency in processing multiple languages"
  - [corpus] Weak evidence—corpus neighbors don't address multilingual training effects
- Break condition: If translation quality is poor or language pairs are too dissimilar, augmentation becomes ineffective

## Foundational Learning

- Concept: Low-Rank Adaptation (LoRA)
  - Why needed here: Enables efficient fine-tuning of large LLMs without updating all parameters
  - Quick check question: How does LoRA differ from full-parameter fine-tuning in terms of memory and compute?

- Concept: Catastrophic forgetting
  - Why needed here: Explains why learning many irrelevant texts degrades performance
  - Quick check question: What happens to the model's knowledge when trained on too many unrelated texts?

- Concept: Text augmentation via style conversion
  - Why needed here: Generates multiple perspectives on the same concept to reinforce learning
  - Quick check question: Why might rewriting a document in Q&A format improve comprehension more than rewriting it as a textbook?

## Architecture Onboarding

- Component map:
  Llama 2 model (7b, 13b, 70b) -> LoRA adapters -> training loop -> evaluation via Rouge/MMLU
  Text preprocessing pipeline: chunking, translation, Q&A generation

- Critical path:
  1. Prepare augmented training texts (original + translations + Q&A)
  2. Apply LoRA to selected layers (embed_tokens, v_proj, o_proj, gate_proj, down_proj, lm_head)
  3. Optimize hyperparameters (r=100, lr=0.0002, lora_alpha=300)
  4. Train with mixed relevant/irrelevant data
  5. Evaluate comprehension and MMLU scores

- Design tradeoffs:
  - Larger r gives better performance but higher memory use
  - Using all layers gives best accuracy but risks overfitting on small datasets
  - Multilingual augmentation improves robustness but introduces translation noise

- Failure signatures:
  - Loss diverges -> model collapse (check learning rate, irrelevant text ratio)
  - Scores plateau below 0.5 -> insufficient augmentation diversity
  - Scores drop sharply with irrelevant texts -> catastrophic forgetting

- First 3 experiments:
  1. Train 7b model with original + 2 augmentations, evaluate on Q&A
  2. Add LoRA rank sweep (1->128) and measure score change
  3. Include multilingual translations and compare vs. monolingual baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between relevant and irrelevant texts in additional training of LLMs to maximize knowledge retention without causing catastrophic forgetting?
- Basis in paper: [explicit] The paper discusses the impact of irrelevant texts on model performance, noting that scores drop when the number of irrelevant texts exceeds 500, suggesting potential catastrophic forgetting
- Why unresolved: The study identifies a threshold but does not explore the optimal balance or the mechanisms behind catastrophic forgetting in detail
- What evidence would resolve it: Systematic experiments varying the ratio of relevant to irrelevant texts and measuring performance across different model sizes and architectures would provide insights into optimal training conditions

### Open Question 2
- Question: How do different augmentation techniques (e.g., style conversions, translations) differentially impact the learning efficiency and knowledge retention in LLMs?
- Basis in paper: [explicit] The paper explores text augmentation methods like style conversions and translations, noting that some languages improve scores while others do not, suggesting variability in effectiveness
- Why unresolved: The study observes effects but does not deeply analyze why certain augmentation techniques are more effective than others or how they interact with model architecture
- What evidence would resolve it: Comparative studies on the impact of various augmentation techniques across multiple languages and model types, along with analysis of internal model representations, would clarify their differential impacts

### Open Question 3
- Question: What are the specific roles of different LoRA adapter layers in knowledge acquisition, and how can they be optimized for different model sizes and tasks?
- Basis in paper: [explicit] The paper identifies that certain LoRA adapter layers, particularly in MLP and attention mechanisms, are more effective for knowledge acquisition, but the reasons for these differences are not fully explored
- Why unresolved: The study highlights effective layers but does not investigate the underlying reasons for their effectiveness or how they can be tailored for different model architectures
- What evidence would resolve it: Detailed ablation studies and theoretical analysis of LoRA layer contributions across various model sizes and tasks would elucidate their specific roles and optimization strategies

## Limitations

- Evaluation relies heavily on synthetic documents and keyword matching, which may not capture true comprehension or reasoning capabilities
- Multilingual augmentation claims face uncertainty regarding translation quality and whether gains reflect genuine semantic understanding
- Catastrophic forgetting experiments use controlled synthetic data that may not generalize to real-world knowledge distributions

## Confidence

**High Confidence:**
- LoRA with rank 100 and learning rate 0.0002 can effectively embed knowledge without full-parameter training
- Multiple text formats improve keyword-based recall metrics
- Irrelevant text volume negatively impacts performance predictably

**Medium Confidence:**
- Multilingual augmentation improves comprehension across language barriers
- Hyperparameter optimization significantly impacts embedding quality
- The 65,000-paper dataset provides sufficient diversity for knowledge embedding

**Low Confidence:**
- Keyword matching accurately measures scientific comprehension
- Translation-based augmentation produces meaningful semantic understanding
- Catastrophic forgetting patterns generalize to real-world scenarios

## Next Checks

1. **Comprehension Validation**: Replace keyword-matching evaluation with human expert assessment of response quality on real scientific questions, comparing augmented vs. non-augmented models to verify that score improvements reflect genuine understanding rather than pattern matching.

2. **Translation Quality Assessment**: Conduct controlled experiments using professional translations versus automated translations to isolate the contribution of translation quality to performance gains, and test cross-linguistic semantic consistency by translating back to source language.

3. **Generalization Testing**: Apply the complete methodology (text augmentation + LoRA training) to a different scientific domain (e.g., chemistry or physics) using the same evaluation framework to verify that the approach generalizes beyond the original domain and isn't overfit to specific knowledge patterns.