---
ver: rpa2
title: Feature Unlearning for Pre-trained GANs and VAEs
arxiv_id: '2303.05699'
source_url: https://arxiv.org/abs/2303.05699
tags:
- feature
- target
- unlearning
- images
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the problem of feature unlearning for pre-trained
  generative models, aiming to remove specific features (e.g., hairstyle) from generated
  images while maintaining image quality. The proposed method uses implicit user feedback
  by collecting positive and negative examples of generated images, then identifies
  a target vector in the latent space and fine-tunes the model using reconstruction
  and perceptual losses.
---

# Feature Unlearning for Pre-trained GANs and VAEs

## Quick Facts
- arXiv ID: 2303.05699
- Source URL: https://arxiv.org/abs/2303.05699
- Authors: 
- Reference count: 40
- Primary result: Achieves target feature ratios as low as 0.0028-0.0042 while maintaining comparable FID scores to baseline models

## Executive Summary
This paper introduces feature unlearning for pre-trained generative models, enabling the removal of specific features (e.g., hairstyle) from generated images while preserving overall image quality. The method uses implicit user feedback to identify target features in latent space, then fine-tunes the model using reconstruction and perceptual losses. Experiments demonstrate successful unlearning across multiple datasets and generative model architectures with minimal impact on image fidelity.

## Method Summary
The framework collects positive and negative examples of generated images containing or lacking target features, computes a target vector in latent space through vector arithmetic, and fine-tunes the model using conditional reconstruction and perceptual losses. The method is designed to work with both GANs and VAEs, using implicit feedback rather than explicit pixel-level supervision.

## Key Results
- Successfully reduces target feature ratios to 0.0028-0.0042 on tested datasets
- Maintains comparable FID scores to baseline models after unlearning
- Achieves up to 1.29× improvement in Inception Score compared to baseline models

## Why This Works (Mechanism)

### Mechanism 1
Latent space vector arithmetic can isolate target features for unlearning. By computing mean latent vectors of positive and negative examples and subtracting them, the model identifies feature representations that can be manipulated. Core assumption: features are linearly separable in latent space. Evidence: Uses target vector computation as described in paper. Break condition: If features are highly correlated or not linearly separable.

### Mechanism 2
Implicit feedback via image selection replaces explicit pixel-level supervision. Users select images containing target features, creating positive and negative example sets for feature identification. Core assumption: User-selected images provide sufficient signal for feature identification. Evidence: Paper describes collecting images through user feedback. Break condition: If user feedback is ambiguous or features are too subtle for reliable identification.

### Mechanism 3
Conditional reconstruction and perceptual losses preserve image quality during unlearning. Reconstruction loss maintains non-target regions while perceptual loss ensures target regions are modified appropriately. Core assumption: Combined L1 reconstruction and perceptual metrics effectively guide feature removal. Evidence: Paper shows perceptual loss improves unlearning performance. Break condition: If perceptual loss is insufficient or reconstruction dominates.

## Foundational Learning

- Concept: Latent space manipulation and vector arithmetic
  - Why needed here: The entire framework depends on identifying and modifying feature representations in latent space
  - Quick check question: Given two sets of latent vectors (with and without a feature), how would you compute a vector representing that feature?

- Concept: Conditional loss functions
  - Why needed here: Different image regions require different treatment during unlearning
  - Quick check question: How would you design a loss function that only applies to parts of the input containing a specific feature?

- Concept: Feature disentanglement in generative models
  - Why needed here: Success relies on features being somewhat independent in latent space
  - Quick check question: What happens if hairstyle and gender are completely entangled in the latent representation?

## Architecture Onboarding

- Component map: Pretrained generator -> User feedback collection -> Feature classifier -> Unlearning training -> Evaluation pipeline
- Critical path: Generate samples → Collect user feedback → Compute target vector → Unlearning training → Evaluate quality and feature removal
- Design tradeoffs:
  - Target ratio vs. image quality (controlled by hyperparameter α)
  - Training time vs. unlearning effectiveness
  - Feature specificity vs. generalization
- Failure signatures:
  - High target ratio remaining after unlearning
  - Degraded image quality after unlearning
  - Unintended feature changes due to correlated features
- First 3 experiments:
  1. Unlearn a simple feature (MNIST thickness) and verify target ratio reduction
  2. Measure FID and IS before/after unlearning on CelebA bang feature
  3. Test different α values to find optimal balance between unlearning and quality

## Open Questions the Paper Calls Out

### Open Question 1
How can the framework handle causally spurious correlations between target and other features? The paper notes it cannot distinguish spurious correlations, leading to unintended changes when unlearning correlated features like "Beard" and "Male." This remains unresolved as the paper identifies the limitation but offers no solution.

### Open Question 2
Can the framework work with other generative models like diffusion or autoregressive models? The paper claims generalizability but only tests GANs and VAEs, leaving applicability to newer architectures open.

### Open Question 3
How does the choice of threshold value t affect performance, and can it be learned automatically? The paper uses a predefined heuristic threshold without exploring sensitivity or proposing automatic methods.

## Limitations
- Framework relies on linear separability in latent space, making it difficult to isolate highly correlated features
- User feedback mechanism assumes reliable human judgment, which may not scale to subtle or ambiguous features
- Perceptual loss formulation using MS-SSIM may not generalize well to all feature types or image domains

## Confidence

- **High confidence** in core mathematical framework for target vector computation and basic unlearning mechanism
- **Medium confidence** in generalizability across different GAN/VAE architectures (limited testing)
- **Medium confidence** in user feedback mechanism effectiveness (simulated feedback used)
- **Low confidence** in framework's ability to handle highly correlated or entangled features

## Next Checks

1. Test unlearning framework on highly correlated feature pairs (e.g., age and wrinkles) to assess failure modes
2. Conduct ablation studies varying perceptual loss strength to determine minimum level needed for quality preservation
3. Implement real user study with human feedback collection to validate simulated feedback approach