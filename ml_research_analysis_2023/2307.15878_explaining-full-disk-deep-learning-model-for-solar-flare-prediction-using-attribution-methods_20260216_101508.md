---
ver: rpa2
title: Explaining Full-disk Deep Learning Model for Solar Flare Prediction using Attribution
  Methods
arxiv_id: '2307.15878'
source_url: https://arxiv.org/abs/2307.15878
tags:
- flare
- solar
- flares
- prediction
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of predicting solar flares,
  particularly near-limb flares that are often overlooked by traditional active region-based
  models. The authors develop a deep learning model using full-disk line-of-sight
  magnetogram images and apply attribution methods to provide interpretable explanations
  of the model's predictions.
---

# Explaining Full-disk Deep Learning Model for Solar Flare Prediction using Attribution Methods

## Quick Facts
- arXiv ID: 2307.15878
- Source URL: https://arxiv.org/abs/2307.15878
- Reference count: 40
- Primary result: Full-disk deep learning model achieves TSS~0.51 and HSS~0.35 for predicting M-class solar flares within 24 hours, with attribution methods revealing active region features.

## Executive Summary
This study develops a deep learning model for predicting solar flares using full-disk line-of-sight magnetogram images, addressing the challenge of near-limb flare prediction that traditional active region-based models often miss. The authors employ transfer learning with a pre-trained VGG-16 architecture and apply attribution methods to provide interpretable explanations of the model's predictions. To handle the significant class imbalance between flaring and non-flaring events, the study implements data augmentation and class weighting techniques. The model demonstrates improved performance over previous full-disk models, achieving average True Skill Statistic (TSS) of 0.51 and Heidke Skill Score (HSS) of 0.35, while successfully predicting near-limb flares with high accuracy.

## Method Summary
The authors develop a binary classification model to predict M-class and stronger solar flares within a 24-hour window using full-disk line-of-sight magnetogram images from HMI/SDO. The model employs transfer learning with a pre-trained VGG-16 architecture, modified to handle 1-channel input by duplicating channels and adjusting pooling layers. To address class imbalance, the authors use a combination of data augmentation (vertical flipping, horizontal flipping, and ±5° rotation) applied to the minority class and class weighting in the loss function. The model is trained using SGD optimizer with dynamic learning rates over 50 epochs, and evaluated using 4-fold cross-validation with True Skill Statistic (TSS) and Heidke Skill Score (HSS) as metrics. Attribution methods including Guided Grad-CAM, Integrated Gradients, and Deep SHAP are applied to provide interpretable explanations of the model's predictions.

## Key Results
- The model achieves average TSS of 0.51 and HSS of 0.35, demonstrating competent capability to predict near-limb solar flares.
- Attribution methods reveal that the model learns features associated with active regions, even in near-limb locations where traditional AR-based models struggle.
- The approach successfully addresses the challenge of predicting near-limb flares with high accuracy, offering a significant advancement for operational space weather forecasting.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transfer learning with VGG-16 improves flare prediction performance by leveraging pre-trained convolutional filters.
- Mechanism: The VGG-16 model, pre-trained on ImageNet, provides convolutional filters that capture general image features. These filters are adapted to solar magnetogram data through fine-tuning, allowing the model to learn relevant features for flare prediction with fewer training samples.
- Core assumption: The convolutional filters learned from natural images contain transferable features that can be useful for analyzing magnetogram images.
- Evidence anchors:
  - [abstract]: "Our deep learning models achieved an average TSS∼0.51 and HSS∼0.35, and the results further demonstrate a competent capability to predict near-limb solar flares"
  - [section]: "In our study, we employed transfer learning with a pre-trained VGG-16 model [35] for solar flare prediction."
  - [corpus]: Weak evidence - corpus papers focus on different architectures (CNN, ResNet) rather than transfer learning with VGG-16.
- Break condition: If the magnetogram data distribution is too different from natural images, the pre-trained filters may not provide useful features.

### Mechanism 2
- Claim: Gradient-based attribution methods provide reliable explanations for model predictions by analyzing feature importance.
- Mechanism: Attribution methods like Guided Grad-CAM, Integrated Gradients, and Deep SHAP compute gradients of the output with respect to input features, identifying which regions of the magnetogram are most influential in the prediction.
- Core assumption: The gradient information accurately reflects the importance of input features for the model's decision.
- Evidence anchors:
  - [abstract]: "Our analysis revealed that full-disk prediction of solar flares aligns with characteristics related to active regions (ARs)"
  - [section]: "Attribution methods can be broadly classified into two main categories: perturbation-based and gradient-based [9]... Therefore, in this study, we employed three recent gradient-based methods to evaluate our models due to their reliability and computational efficiency."
  - [corpus]: Weak evidence - corpus papers focus on different attribution methods or lack detailed explanation of gradient-based approaches.
- Break condition: If the model uses complex non-linear interactions between features, gradient-based methods may not capture the full explanation.

### Mechanism 3
- Claim: Data augmentation and class weighting effectively address class imbalance in solar flare prediction.
- Mechanism: By applying data augmentation techniques (flipping, rotation) to the minority class and adjusting class weights in the loss function, the model is trained to recognize both flaring and non-flaring events more equally.
- Core assumption: The augmented data represents realistic variations of flaring events, and the class weights appropriately penalize misclassifications.
- Evidence anchors:
  - [abstract]: "To address the class imbalance, we employ a fusion of data augmentation and class weighting techniques"
  - [section]: "Specifically, we applied three augmentation techniques (vertical flipping, horizontal flipping, and rotations of +5° to -5°) during the training phase to explicitly augment the minority FL-class three times."
  - [corpus]: Moderate evidence - corpus papers mention class imbalance but focus on different solutions (undersampling, oversampling).
- Break condition: If the augmented data introduces unrealistic patterns or the class weights are not properly calibrated, model performance may degrade.

## Foundational Learning

- Concept: Transfer Learning
  - Why needed here: The limited availability of labeled solar flare data makes it challenging to train a deep model from scratch. Transfer learning allows leveraging pre-trained models to improve performance with less data.
  - Quick check question: Why is transfer learning particularly useful when working with limited labeled data?

- Concept: Attribution Methods
  - Why needed here: Understanding why the model makes certain predictions is crucial for operational forecasting and building trust in the system. Attribution methods provide post-hoc explanations of model decisions.
  - Quick check question: What is the main difference between perturbation-based and gradient-based attribution methods?

- Concept: Class Imbalance Handling
  - Why needed here: Solar flare events are rare compared to non-flaring events, leading to a highly imbalanced dataset. Proper handling of this imbalance is essential for model performance.
  - Quick check question: Why is it important to address class imbalance in solar flare prediction, and what are two common approaches?

## Architecture Onboarding

- Component map: Magnetogram images (512×512) → VGG-16 (13 conv layers, 5 max pool, 1 avg pool, 3 fully connected) → Binary classification (flare/no flare)
- Critical path: Data preprocessing → Transfer learning initialization → Fine-tuning with augmentation and class weighting → Model evaluation with attribution analysis
- Design tradeoffs: Using VGG-16 provides strong feature extraction but increases computational cost. The choice of gradient-based attribution methods balances explanation quality with computational efficiency.
- Failure signatures: Poor performance on near-limb flares may indicate insufficient training data or ineffective transfer learning. Unreliable attributions may suggest issues with the explanation methods or model complexity.
- First 3 experiments:
  1. Train the model with and without transfer learning to quantify the benefit of using pre-trained weights.
  2. Compare different attribution methods (Guided Grad-CAM, Integrated Gradients, Deep SHAP) on the same predictions to assess explanation consistency.
  3. Evaluate the impact of different data augmentation techniques and class weighting strategies on model performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do projection effects on full-disk magnetograms impact flare prediction accuracy for near-limb regions, and can this be mitigated?
- Basis in paper: [explicit] The paper discusses how projection effects distort magnetic field measurements when active regions are closer to the limb, and how full-disk models can learn from near-limb areas despite these effects.
- Why unresolved: The paper acknowledges the existence of projection effects but does not provide a detailed analysis of their impact on prediction accuracy or methods to mitigate them.
- What evidence would resolve it: Comparative studies showing prediction accuracy differences between central and near-limb regions, along with techniques to correct for projection effects in full-disk models.

### Open Question 2
- Question: What specific characteristics of active regions (shape, texture, size, etc.) are most important for the model's flare predictions, particularly for near-limb regions?
- Basis in paper: [explicit] The paper states that the model learns shape and texture-based characteristics of flaring ARs even at near-limb areas, but does not specify which characteristics are most important.
- Why unresolved: While attribution methods show that ARs are important, the paper does not provide a detailed analysis of which specific AR characteristics are most influential in predictions.
- What evidence would resolve it: Detailed feature importance analysis from attribution methods, correlating specific AR characteristics with prediction accuracy.

### Open Question 3
- Question: How can the model's false positive rate for M-class flares be reduced, given the interference from bordering class flares?
- Basis in paper: [explicit] The paper notes that the model has a high false positive rate for M-class flares due to its inability to distinguish bordering class [C4+ to C9.9] flares from ≥M-class flares.
- Why unresolved: The paper acknowledges the issue but does not propose a solution or method to address the false positive problem.
- What evidence would resolve it: Experimental results showing improved classification accuracy when incorporating background flux information or implementing a multi-class prediction approach instead of binary classification.

## Limitations

- The study relies on gradient-based attribution methods, which may not fully capture complex feature interactions in the model.
- Specific implementation details for class weighting are not fully specified, potentially affecting reproducibility.
- The focus on M-class and stronger flares may limit generalizability to other flare classes.

## Confidence

- Transfer Learning Effectiveness: Medium - The model achieves reasonable performance, but direct comparison with non-transfer learning approaches is lacking.
- Attribution Method Reliability: Medium - While attribution methods provide explanations, they may not capture all complex feature interactions.
- Class Imbalance Handling: Medium - The approach is well-motivated but specific implementation details are not fully specified.

## Next Checks

1. Conduct ablation studies to isolate the impact of transfer learning versus other architectural choices.
2. Validate attribution explanations against domain expert knowledge of solar physics.
3. Test the model's performance on out-of-distribution data, particularly for extreme solar activity periods not well-represented in the training set.