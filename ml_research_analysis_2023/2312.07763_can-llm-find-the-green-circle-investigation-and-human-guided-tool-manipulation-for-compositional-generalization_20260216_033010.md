---
ver: rpa2
title: Can LLM find the green circle? Investigation and Human-guided tool manipulation
  for compositional generalization
arxiv_id: '2312.07763'
source_url: https://arxiv.org/abs/2312.07763
tags:
- tool
- compositional
- generalization
- tools
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates how large language models (LLMs) can handle
  compositional generalization, a key challenge in natural language processing. While
  LLMs have shown strong performance in many tasks, their ability to generalize to
  new combinations of components in compositional questions has not been fully explored.
---

# Can LLM find the green circle? Investigation and Human-guided tool manipulation for compositional generalization

## Quick Facts
- **arXiv ID**: 2312.07763
- **Source URL**: https://arxiv.org/abs/2312.07763
- **Reference count**: 0
- **Primary result**: HTM achieves 70% improvement on challenging test splits compared to existing methods

## Executive Summary
This paper investigates how large language models (LLMs) handle compositional generalization, a critical challenge in natural language processing. While LLMs excel at many tasks, they struggle with questions requiring novel combinations of components. The authors propose a human-guided tool manipulation (HTM) framework that decomposes complex questions into sub-questions, generates tools for each, and integrates them to solve the entire problem. By incorporating human feedback during tool creation and providing few-shot ICL demonstrations with code comments, the method achieves state-of-the-art performance on two benchmarks (ReaSCAN and GSRR), significantly outperforming existing approaches on the most challenging test splits.

## Method Summary
The authors propose a Human-guided Tool Manipulation (HTM) framework to address compositional generalization challenges. HTM decomposes complex questions into sub-questions, generates corresponding tools for each, and integrates them to solve the entire problem. Human feedback is incorporated to enhance tool creation and usage, reducing the reasoning burden on LLMs. The method uses few-shot ICL demonstrations with code comments and syntactic analysis to guide the LLM in properly utilizing the generated tools. This approach is evaluated against existing ICL methods (zero-shot, few-shot, Chain-of-Thought, Program-of-Thought) and smaller task-specific models on the ReaSCAN and GSRR datasets.

## Key Results
- Existing ICL methods (zero-shot, few-shot, Chain-of-Thought, Program-of-Thought) struggle with complex compositional questions, achieving only 8.4-22.1% EM scores on challenging test splits
- HTM achieves state-of-the-art performance with a 70% improvement on the most challenging test split compared to existing methods
- The framework effectively handles questions with multiple sub-questions and relative clauses, which are particularly challenging for other approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing complex compositional questions into sub-questions and generating tools for each sub-question reduces cumulative errors in long reasoning steps.
- Mechanism: The human-guided tool manipulation framework (HTM) breaks down a complex question into simpler sub-questions, each with its own tool. This decomposition allows the LLM to focus on generating and integrating simpler tools rather than one complex tool, reducing the chance of errors accumulating through long reasoning chains.
- Core assumption: Breaking down complex reasoning tasks into smaller, manageable sub-tasks with corresponding tools will lead to fewer errors and better overall performance.
- Evidence anchors:
  - [abstract]: "HTM decomposes a complex problem into multiple sub-problems, analyzes and produces the tools required for each sub-problem, and finally combines these tools to solve the entire question."
  - [section]: "HTM decomposes a complex problem into multiple sub-problems, analyzes and produces the tools required for each sub-problem, and finally combines these tools to solve the entire question."
- Break condition: If the decomposition into sub-questions is not meaningful or the tools generated for sub-questions cannot be effectively integrated, the overall performance may not improve.

### Mechanism 2
- Claim: Human feedback in the tool-making process significantly improves the success rate of generating correct tools.
- Mechanism: The HTM framework incorporates human feedback to correct and refine the tools generated by the LLM. This iterative process with human guidance ensures that the tools are accurate and can pass validation checks.
- Core assumption: Human intervention can guide the LLM to generate more accurate tools by providing feedback on errors and suggesting improvements.
- Evidence anchors:
  - [abstract]: "Our method enhances the effectiveness of tool creation and usage with minimal human effort."
  - [section]: "If the generated tool encounters errors or outputs unexpected results when executing in a Python interpreter, the error messages will be appended to the conversation history...The LLM will re-generate the tool until it can solve the given examples."
- Break condition: If human feedback is not specific or actionable enough, the LLM may not be able to effectively improve the generated tools.

### Mechanism 3
- Claim: Using few-shot ICL demonstrations with code comments and syntactic analysis guides the LLM to properly utilize tools for complex questions.
- Mechanism: The HTM framework provides the LLM with few-shot ICL demonstrations that include code comments and syntactic analysis. This helps the LLM understand how to call the appropriate tools with the correct arguments for complex questions.
- Core assumption: Providing explicit guidance through code comments and syntactic analysis in ICL demonstrations will enable the LLM to better understand and utilize the generated tools.
- Evidence anchors:
  - [abstract]: "Our method enhances the effectiveness of tool creation and usage with minimal human effort."
  - [section]: "We also add code comments to guide the calling of tools...In this way, the LLM can understand which referent objects are connected so that proper arguments can be filled for the tool F ilterRelationship."
- Break condition: If the code comments and syntactic analysis are not clear or comprehensive enough, the LLM may still struggle to properly utilize the tools.

## Foundational Learning

- Concept: Compositional generalization
  - Why needed here: The paper focuses on evaluating and improving LLMs' ability to understand and generalize to new combinations of components in compositional questions.
  - Quick check question: What is compositional generalization, and why is it important for natural language understanding?

- Concept: In-context learning (ICL)
  - Why needed here: The paper investigates how different ICL methods, such as zero-shot learning, few-shot learning, Chain-of-Thought, and Program-of-Thought, perform on compositional generalization tasks.
  - Quick check question: What is in-context learning, and how does it differ from traditional training methods?

- Concept: Tool manipulation
  - Why needed here: The proposed HTM framework relies on generating and integrating tools to solve complex compositional questions, making understanding tool manipulation crucial.
  - Quick check question: How does tool manipulation help in solving complex problems, and what are the key components of the HTM framework?

## Architecture Onboarding

- Component map: Tool Planner -> Tool Maker -> Tool Utilizer -> Human Feedback
- Critical path:
  1. Decompose the complex question into sub-questions using the Tool Planner.
  2. Generate tools for each sub-question using the Tool Maker.
  3. Refine the generated tools with human feedback.
  4. Integrate the tools to solve the complex question using the Tool Utilizer.
- Design tradeoffs:
  - The framework requires minimal human effort but relies on human feedback for tool refinement.
  - The performance of the framework depends on the quality of the decomposition and the generated tools.
  - The framework may not be suitable for tasks that require a single, complex tool rather than multiple simpler tools.
- Failure signatures:
  - Poor decomposition of the complex question into sub-questions.
  - Inability to generate accurate tools for the sub-questions.
  - Failure to integrate the generated tools effectively.
  - Insufficient or unclear human feedback during the tool-making process.
- First 3 experiments:
  1. Evaluate the performance of the HTM framework on simple compositional questions to verify the basic functionality.
  2. Test the framework on more complex questions with multiple sub-questions and relative clauses.
  3. Assess the impact of human feedback on the quality of the generated tools and overall performance.

## Open Questions the Paper Calls Out
- The paper doesn't explicitly call out open questions, but the limitations section highlights areas for future research.

## Limitations
- The framework's effectiveness relies heavily on human feedback, and the paper doesn't fully characterize the expertise or effort required from human evaluators.
- Performance improvements are demonstrated primarily on grid-world benchmarks (ReaSCAN and GSRR), raising questions about generalizability to other domains.
- The computational costs and latency implications of the multi-step tool generation and validation process are not addressed.

## Confidence

**High Confidence**: The core observation that existing ICL methods struggle with compositional generalization is well-supported by the empirical results showing 8.4-22.1% EM scores on challenging test splits. The mechanism of decomposing questions into sub-questions with corresponding tools is clearly articulated and logically sound.

**Medium Confidence**: The claim that human feedback significantly improves tool generation quality is supported by the methodology description but lacks quantitative analysis of how much feedback improves outcomes versus how much effort it requires. The reported 70% improvement over existing methods is impressive but depends heavily on the quality and consistency of human input.

**Low Confidence**: The scalability claims and generalizability beyond the specific grid-world domains tested are not well-established. The paper doesn't provide evidence that this approach would work as effectively on open-ended, real-world compositional tasks or with different types of questions.

## Next Checks

1. **Human Effort Characterization**: Measure the actual time and expertise required from human evaluators to achieve the reported performance improvements, including documenting how many feedback iterations are typically needed per tool generation.

2. **Cross-Evaluator Consistency**: Have multiple independent human evaluators provide feedback on the same set of tool generations to assess consistency and determine whether results depend on specific human expertise.

3. **Domain Transfer Test**: Apply the HTM framework to a substantially different compositional task domain (e.g., visual reasoning with real images or text-based logical inference) to evaluate whether the decomposition and tool-generation approach generalizes beyond grid-world scenarios.