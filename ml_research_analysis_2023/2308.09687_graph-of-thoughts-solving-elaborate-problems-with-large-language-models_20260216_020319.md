---
ver: rpa2
title: 'Graph of Thoughts: Solving Elaborate Problems with Large Language Models'
arxiv_id: '2308.09687'
source_url: https://arxiv.org/abs/2308.09687
tags:
- thoughts
- graph
- arxiv
- thought
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Graph of Thoughts (GoT) addresses the limitations of existing large
  language model (LLM) prompting paradigms by introducing a graph-based reasoning
  framework. The key idea is to model LLM thoughts as vertices in a directed graph,
  where edges represent dependencies between thoughts.
---

# Graph of Thoughts: Solving Elaborate Problems with Large Language Models

## Quick Facts
- arXiv ID: 2308.09687
- Source URL: https://arxiv.org/abs/2308.09687
- Reference count: 40
- Primary result: Graph of Thoughts framework improves sorting quality by 62% over Tree of Thoughts while reducing costs by 31%

## Executive Summary
Graph of Thoughts (GoT) introduces a novel prompting paradigm for large language models that models thoughts as vertices in a directed graph, enabling arbitrary transformations including aggregation, refinement, and generation. This graph-based approach overcomes limitations of existing schemes like Chain-of-Thought and Tree of Thoughts by allowing synergistic combination of intermediate thoughts through aggregation operations. The framework demonstrates significant improvements in both quality and cost-efficiency across various tasks, while introducing a new "volume of thought" metric to evaluate reasoning strategies.

## Method Summary
The GoT framework implements a modular architecture with Prompter, Parser, Scoring, and Controller components that coordinate LLM reasoning through a graph structure. The method involves decomposing tasks into a Graph of Operations (GoO) that specifies sequences of thought transformations, then executing this plan while maintaining a Graph of Reasoning State (GRS). The system supports various transformations including Generate (create new thoughts), Refine (improve existing thoughts), and Aggregate (combine multiple thoughts into synergistic outcomes). Implementation requires careful graph decomposition and configuration of scoring functions specific to each task type.

## Key Results
- GoT improves sorting task quality by 62% over Tree of Thoughts while reducing costs by 31%
- GoT enables thoughts to have fundamentally larger volumes than other prompting schemes, indicating broader information scope
- The framework is particularly effective for tasks that can be decomposed into smaller subtasks, solved independently, and then merged for final solutions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph-based reasoning enables synergistic combination of intermediate thoughts
- Mechanism: By modeling thoughts as vertices in a directed graph with edges representing dependencies, GoT allows aggregation transformations where multiple thought vertices can be merged into a new vertex. This enables combining the strengths of different reasoning paths while eliminating their weaknesses.
- Core assumption: The LLM can effectively combine multiple intermediate thoughts into a coherent new thought when explicitly prompted to do so
- Evidence anchors:
  - [abstract] "This approach enables combining arbitrary LLM thoughts into synergistic outcomes"
  - [section] "GoT enables novel transformations of thoughts thanks to the graph-based model for reasoning. We refer to them as graph-enabled transformations. For example, in writing, one could combine several input articles into one coherent summary."
- Break condition: If the LLM cannot effectively synthesize information from multiple sources, or if the context window becomes too limited to represent the full graph structure

### Mechanism 2
- Claim: Graph structure provides multiple reasoning paths, improving problem-solving robustness
- Mechanism: The graph structure allows multiple paths to reach any given thought, creating redundancy in reasoning. If one path fails or leads to suboptimal solutions, alternative paths can be explored without starting over completely.
- Core assumption: Multiple independent reasoning paths can reach similar conclusions, and the aggregation of these paths yields better results than any single path
- Evidence anchors:
  - [abstract] "This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts"
  - [section] "GoT is particularly well-suited for tasks that can be naturally decomposed into smaller subtasks that are solved individually and then merged for a final solution"
- Break condition: If the problem requires highly linear reasoning where intermediate steps are strictly dependent, or if the computational cost of maintaining multiple paths exceeds the benefit

### Mechanism 3
- Claim: Volume metric captures the information scope of a thought, enabling better evaluation of reasoning quality
- Mechanism: The volume of a thought (number of preceding thoughts that could have influenced it) provides a measure of how much information was available during its generation. Higher volume thoughts potentially carry more comprehensive information.
- Core assumption: Thoughts with higher volume contain more diverse information and are therefore more valuable for solving complex problems
- Evidence anchors:
  - [section] "We propose a new metric for evaluating a prompting strategy, the volume of a thought (contribution #5). With this metric, we aim to understand better the differences between prompting schemes. For a given thought v, the volume of v is the number of LLM thoughts, from which one can reach v using directed edges."
  - [section] "We show that GoT, by incorporating thought transformations such as aggregation, enables thoughts to have fundamentally larger volumes than other schemes."
- Break condition: If the volume metric does not correlate with actual solution quality, or if high-volume thoughts become too noisy to be useful

## Foundational Learning

- Concept: Directed graph theory and traversal algorithms
  - Why needed here: GoT fundamentally relies on modeling reasoning as a directed graph with vertices (thoughts) and edges (dependencies). Understanding graph theory is essential for implementing and extending the framework
  - Quick check question: How would you implement a function to calculate the volume of a given thought in the graph?

- Concept: Prompt engineering and few-shot learning
  - Why needed here: GoT builds on existing prompting paradigms but extends them. Understanding how to craft effective prompts and use few-shot examples is crucial for implementing the thought transformations
  - Quick check question: What are the key differences between how you would prompt a single Chain-of-Thought versus a Graph-of-Thoughts for the same task?

- Concept: Language model context windows and token limitations
  - Why needed here: GoT can generate many intermediate thoughts, potentially exceeding context window limits. Understanding these constraints is essential for practical implementation
  - Quick check question: How would you modify GoT's implementation if you had a context window of only 4k tokens versus 32k tokens?

## Architecture Onboarding

- Component map: Controller → Prompter → LLM → Parser → Scoring → Controller. The Controller orchestrates the entire process, deciding which transformations to apply based on the GoO plan and current GRS state.
- Critical path: The Controller coordinates all operations, generating prompts through the Prompter, processing LLM outputs via the Parser, and evaluating thoughts using the Scoring module before deciding next steps.
- Design tradeoffs: The framework prioritizes extensibility and fine-grained control over individual thoughts at the cost of increased complexity. This allows for arbitrary graph structures but requires more sophisticated implementation compared to simpler prompting schemes.
- Failure signatures: Common failures include context window overflow (too many thoughts in the graph), LLM inability to effectively combine aggregated thoughts, and suboptimal graph structures that don't decompose the problem effectively.
- First 3 experiments:
  1. Implement a simple sorting task using GoT with basic Generate and Aggregate operations to verify the core graph reasoning works
  2. Compare GoT against Chain-of-Thought on a mathematical reasoning task to validate the volume metric and aggregation benefits
  3. Test different graph structures (e.g., linear vs. branching) on a document summarization task to understand how graph topology affects performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the optimal graph structures for different types of reasoning tasks?
- Basis in paper: [explicit] The paper states that "putting GoT to practice requires solving several design challenges. For example, what is the best graph structure for different tasks?"
- Why unresolved: The paper mentions that the optimal graph structure depends on the task and provides examples, but does not provide a general framework for determining the optimal structure for arbitrary tasks.
- What evidence would resolve it: Empirical studies comparing different graph structures on a wide range of tasks, leading to a set of guidelines or heuristics for choosing graph structures based on task characteristics.

### Open Question 2
- Question: How does the choice of scoring and ranking functions impact the performance of GoT?
- Basis in paper: [explicit] The paper states that "the specific form of E and R depends on a use case" and discusses different scoring functions for different tasks.
- Why unresolved: While the paper provides examples of scoring functions for specific tasks, it does not provide a general framework for designing scoring and ranking functions or analyze their impact on GoT's performance across tasks.
- What evidence would resolve it: Comparative studies of different scoring and ranking functions on a variety of tasks, with analysis of their impact on accuracy, cost, and other relevant metrics.

### Open Question 3
- Question: What are the limits of GoT's ability to handle complex reasoning tasks?
- Basis in paper: [inferred] The paper demonstrates GoT's advantages over existing schemes on various tasks, but does not explicitly discuss its limitations or the complexity of tasks it can handle.
- Why unresolved: The paper focuses on showcasing GoT's advantages but does not provide a comprehensive analysis of its limitations or the complexity of tasks it can effectively handle.
- What evidence would resolve it: Systematic studies testing GoT on increasingly complex tasks, identifying the point at which its performance degrades or becomes comparable to simpler schemes.

## Limitations
- Evaluation primarily focuses on controlled tasks like sorting and set operations, with limited testing on complex real-world problems
- Claims of cost-efficiency improvements lack comparison against more sophisticated prompting schemes like Self-Consistency or ReAct
- The volume metric's correlation with actual solution quality remains unproven, potentially conflating verbosity with informativeness

## Confidence
- **High Confidence**: The core architectural design and modular implementation approach are well-specified and reproducible
- **Medium Confidence**: The theoretical advantages of graph-based reasoning and thought aggregation are sound, though empirical validation is limited
- **Low Confidence**: The claimed cost-efficiency improvements and the practical utility of the volume metric for real-world applications

## Next Checks
1. **Scaling Test**: Implement GoT on a complex multi-step reasoning task (e.g., mathematical proof or code generation) and measure performance degradation as graph depth increases, specifically testing context window limits and computational efficiency.

2. **Baseline Comparison**: Compare GoT against advanced prompting schemes like Self-Consistency and ReAct on identical tasks, measuring not just final quality but also resource consumption and implementation complexity.

3. **Volume Metric Validation**: Design an experiment where human evaluators assess the quality of thoughts with varying volumes, determining whether the volume metric actually correlates with human judgments of thought quality and usefulness.