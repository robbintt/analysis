---
ver: rpa2
title: Faster Convergence with Multiway Preferences
arxiv_id: '2312.11788'
source_url: https://arxiv.org/abs/2312.11788
tags:
- feedback
- sign
- theorem
- algorithm
- convergence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies convex optimization with preference feedback,
  where the goal is to minimize a convex function using only pairwise comparisons
  between queried points. The key novelty is extending the classical dueling bandit
  framework to infinite-dimensional decision spaces and analyzing multiway comparison
  feedback models.
---

# Faster Convergence with Multiway Preferences

## Quick Facts
- arXiv ID: 2312.11788
- Source URL: https://arxiv.org/abs/2312.11788
- Reference count: 40
- Primary result: Achieves O(d/mε) and O(d/log m·ε) convergence rates with batched and battling feedback respectively

## Executive Summary
This paper extends the dueling bandit framework to infinite-dimensional decision spaces by analyzing convex optimization with multiway preference feedback. The authors propose two models: batched sign-feedback where m pairs are queried in parallel with comparison feedback for each, and battling-feedback where m points are queried with only argmin (winner) feedback. Through careful algorithm design based on normalized gradient descent with perturbation strategies, they show significant improvements in convergence rates - achieving m-fold speedup with batched feedback and log m speedup with battling feedback. The paper also establishes matching lower bounds for both settings, proving their rates are optimal.

## Method Summary
The paper designs two algorithms for convex optimization with preference feedback. The Batched-NGD algorithm queries m pairs of points in parallel, receiving sign comparisons for each pair, and aggregates m normalized gradient estimates to update the current iterate. The Battling-NGD algorithm queries m points simultaneously, receiving only the argmin (winner) feedback, and extracts structured pairwise comparisons from this winner feedback to estimate the gradient. Both algorithms use perturbation strategies around the current iterate, projected gradient descent updates, and maintain running minima to ensure convergence. The analysis extends to strongly convex functions with exponential phase-wise improvement through warm-starting.

## Key Results
- Batched sign-feedback achieves O(d/mε) convergence rate, improving by factor of m over single-pair feedback
- Battling-feedback achieves O(d/log m·ε) convergence rate, showing log m improvement
- Matching lower bounds prove these rates are optimal with respect to m
- Strong convexity enables O(log 1/ε) convergence for batched and O(d/log m·log 1/ε) for battling feedback

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Batched sign-feedback allows m-fold speedup in convergence rate compared to single-pair feedback.
- Mechanism: The algorithm aggregates m independent normalized gradient estimates from m parallel comparisons, reducing variance and enabling faster descent.
- Core assumption: The m pairs are sampled independently and the noise in sign feedback is unbiased.
- Evidence anchors:
  - [abstract]: "with batched feedback, the convergence rate is O(d/mε) for smooth functions, improving by a factor of m over single-pair feedback."
  - [section 3.1]: "We first consider the batched feedback model... yields O(dβD/mε) convergence rate... compared to the single pair sign-feedback setting."
- Break condition: If noise in comparisons is correlated across the m pairs, the aggregation loses its variance-reduction benefit.

### Mechanism 2
- Claim: Battling-feedback achieves O(1/log m) speedup by extracting structured pairwise comparisons from multiway winner feedback.
- Mechanism: The algorithm constructs query sets where each point has exactly ℓm symmetric counterparts, enabling extraction of ℓm independent pairwise sign feedbacks from one argmin query.
- Core assumption: The underlying function values can be estimated reliably from the argmin feedback, and the structured queries maintain gradient estimation accuracy.
- Evidence anchors:
  - [abstract]: "With battling feedback, the rate is O(d/log m·ε), showing a log m improvement."
  - [section 4.1]: "We precisely identify O(log m) specific winner-vs-loser pairs and use their pairwise sign feedback to obtain a normalized gradient estimate."
- Break condition: If the winner feedback is too noisy or the function has flat regions, the extracted pairwise signals become unreliable.

### Mechanism 3
- Claim: Strong convexity enables exponential phase-wise improvement via warm-starting.
- Mechanism: The algorithm uses previous phase's near-optimal point as starting point for next phase, exploiting strong convexity to ensure rapid progress in each phase.
- Core assumption: Nearness in function values implies nearness in parameter space under strong convexity.
- Evidence anchors:
  - [section 3.2]: "with an additional assumption of strong convexity... yields improved O(log 1/ε) convergence rate."
  - [section 4.2]: "we can again obtain an improved convergence rate of O(d/log m·log 1/ε) similar to batched setting."
- Break condition: If strong convexity parameter is too small, the phase-wise gains diminish and convergence reverts to slower rates.

## Foundational Learning

- Concept: Convex optimization and gradient descent
  - Why needed here: The paper builds algorithms based on gradient descent principles adapted to noisy comparison feedback.
  - Quick check question: Why does projecting onto the feasible set help convergence in constrained optimization?

- Concept: Statistical estimation from binary comparisons
  - Why needed here: The algorithms must estimate function gradients using only sign feedback from duels.
  - Quick check question: How does averaging m independent sign feedbacks reduce estimation variance compared to a single feedback?

- Concept: Lower bound techniques in optimization
  - Why needed here: The paper proves matching lower bounds to show optimality of convergence rates.
  - Quick check question: What information-theoretic argument shows that single comparisons can eliminate at most half the candidate minimizers per round?

## Architecture Onboarding

- Component map:
  - Query generation -> Feedback collection -> Gradient estimation -> Update step -> Projection -> Progress tracking -> Repeat

- Critical path:
  - Generate structured query set → receive feedback → estimate gradient → update iterate → project → track minimum → repeat

- Design tradeoffs:
  - Query structure complexity vs. feedback information extraction efficiency
  - Learning rate tuning for convergence speed vs. stability
  - Batch size m vs. computational overhead per iteration

- Failure signatures:
  - Divergence or oscillation: likely due to poor learning rate or noise sensitivity
  - Stalling at suboptimal point: may indicate insufficient gradient signal or inappropriate perturbation size
  - High variance in progress: suggests feedback noise dominates gradient estimates

- First 3 experiments:
  1. Implement single-pair sign-feedback algorithm and verify convergence on simple convex functions
  2. Add batched feedback with m=4 and compare convergence speedup to single-pair case
  3. Implement battling-feedback algorithm and test log m improvement empirically

## Open Questions the Paper Calls Out

- Open Question 1: Can we obtain Ω(d/ε) lower bounds for the class of just smooth functions without strong convexity to match the upper bounds in Theorem 1?
  - Basis in paper: The paper states "it remains an open problem if we can obtain Ω(d/ε) lower bound for the class of just smooth functions to match the upper bound of Theorem 1 for only smooth convex functions (without strong convexity)."
  - Why unresolved: The current lower bound techniques assume both smoothness and strong convexity, yielding Ω(d log 1/ε) bounds. A different approach is needed to prove stronger lower bounds for smooth functions without strong convexity.
  - What evidence would resolve it: A formal proof establishing either an Ω(d/ε) lower bound for smooth functions without strong convexity, or showing that such a bound is impossible to achieve.

- Open Question 2: Can we prove a matching Ω(d/(ε log m)) convergence lower bound for the class of smooth functions without strong convexity in the battling feedback model?
  - Basis in paper: The paper states "it is still an open problem to see if one can prove a matching Ω(d/(ε log m)) convergence lower bound for the class of smooth functions (without strong convexity)."
  - Why unresolved: While Theorem 7 shows an Ω(d/(log m log 1/ε)) lower bound for smooth and strongly convex functions, the case for smooth functions without strong convexity remains open. The current techniques may not extend to this setting.
  - What evidence would resolve it: A formal proof establishing either an Ω(d/(ε log m)) lower bound for smooth functions without strong convexity in the battling feedback model, or showing that such a bound is impossible to achieve.

- Open Question 3: What is the optimal rate of improvement one can hope for with parallelism in multiway preferences for arbitrary convex functions beyond the smoothness assumption?
  - Basis in paper: The paper mentions "Another interesting direction could be to generalize the setting to an online model, where the underlying functions can vary across time. Can we even hope to achieve sublinear convergence (or regret bounds) for such cases?"
  - Why unresolved: The current analysis heavily relies on the smoothness assumption to derive normalized gradient estimates. Extending the results to arbitrary convex functions would require new techniques that don't rely on smoothness.
  - What evidence would resolve it: An algorithm and analysis showing the optimal convergence rate for arbitrary convex functions in multiway preference settings, or a lower bound proving the impossibility of achieving certain rates without smoothness.

## Limitations

- The theoretical guarantees rely on idealized assumptions about feedback noise being unbiased and comparisons being consistent with function values
- Strong convexity assumption is required for achieving the optimal convergence rates, limiting applicability to general convex functions
- The battling-feedback mechanism's complexity makes it less practical for real-world implementation with human preference feedback

## Confidence

- Theoretical analysis of batched sign-feedback: High
- Theoretical analysis of battling-feedback mechanism: Medium
- Matching lower bound proofs: High
- Practical implementation robustness: Low

## Next Checks

1. Implement the algorithms with synthetic preference noise to empirically validate the convergence rate improvements and identify practical failure modes.
2. Test the algorithms on real-world preference datasets to assess robustness to inconsistent or noisy feedback.
3. Compare the dueling bandit approach against standard gradient methods with full function access on benchmark convex optimization problems.