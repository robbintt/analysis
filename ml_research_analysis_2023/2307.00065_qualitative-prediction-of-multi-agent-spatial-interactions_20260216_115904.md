---
ver: rpa2
title: Qualitative Prediction of Multi-Agent Spatial Interactions
arxiv_id: '2307.00065'
source_url: https://arxiv.org/abs/2307.00065
tags:
- interactions
- prediction
- fqtc
- spatial
- qualitative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes three approaches for predicting multi-agent
  spatial interactions in dense, dynamic environments. It uses a radial clustering
  method to manage variable crowd sizes and represents spatial interactions using
  Qualitative Trajectory Calculus (QTC).
---

# Qualitative Prediction of Multi-Agent Spatial Interactions

## Quick Facts
- arXiv ID: 2307.00065
- Source URL: https://arxiv.org/abs/2307.00065
- Reference count: 18
- One-line primary result: Data-driven approach (Fts) outperforms symbol-driven methods for multi-agent spatial interaction prediction

## Executive Summary
This paper proposes three approaches for predicting multi-agent spatial interactions in dense, dynamic environments using Qualitative Trajectory Calculus (QTC). The methods include two symbol-driven neural networks (FQTC-4 and FQTC-6) and one data-driven approach (Fts) that predicts raw trajectories then post-processes them into QTC symbols. Experiments on the JackRabbot dataset demonstrate that Fts achieves the lowest mean and standard deviation of conceptual QTC distance across multiple time horizons and generalizes better to new scenes. The radial clustering method with fixed radius manages variable crowd sizes while focusing on socially relevant agents.

## Method Summary
The framework uses radial clustering with a 1.2m radius based on proxemics literature to create fixed-size clusters of interacting agents. QTC symbols represent spatial relationships between agent pairs. Three approaches are proposed: FQTC-4 and FQTC-6 predict QTC symbols directly using input-temporal attention mechanisms, while Fts predicts raw trajectories using an encoder-decoder architecture with attention, then post-processes them to QTC symbols. The models are trained on JackRabbot dataset with different time histories (Th=5 for Fts, Th=10 for symbol-driven methods) and evaluated using conceptual QTC distance.

## Key Results
- Fts outperforms FQTC-4 and FQTC-6 in both mean and standard deviation of conceptual QTC distance across multiple time horizons
- Fts demonstrates better generalization to new scenes compared to the symbol-driven approaches
- Predicting raw trajectories first then converting to QTC symbols is more effective than direct symbolic prediction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Predicting raw trajectories first, then post-processing to QTC symbols, outperforms directly predicting symbolic interactions.
- Mechanism: The data-driven approach (Fts) learns the continuous motion patterns first, which capture richer underlying dynamics than symbolic representations alone. When post-processed, these trajectories are more likely to yield accurate QTC symbols.
- Core assumption: Continuous trajectory prediction captures more nuanced motion information than symbolic prediction, which is inherently lossy.
- Evidence anchors:
  - [abstract] "the data-driven Fts method outperforms the others, achieving the lowest mean and standard deviation of conceptual QTC distance across multiple time horizons."
  - [section] "Fts have the best performance among the three configurations, over both time horizons."
- Break condition: If the post-processing step from trajectories to QTC introduces significant error, or if the motion patterns are too complex to capture accurately in continuous space.

### Mechanism 2
- Claim: Radial clustering with a fixed radius (1.2m) improves multi-agent interaction prediction by limiting context to socially relevant agents.
- Mechanism: By clustering agents within a socially meaningful distance (based on proxemics literature), the model focuses on local interactions that are most likely to influence behavior, reducing noise from distant agents.
- Core assumption: Agents within 1.2m have the most significant influence on each other's trajectories and interactions.
- Evidence anchors:
  - [section] "The latter is selected based on the proxemics’ literature [18], where the social distance for interactions among acquaintances is indeed between 1.2m (short phase) and 3.7m (long phase)."
  - [section] "The advantage of this approach is that all the clusters have a fixed micro-size (i.e maximum number of agents entering the cluster at any given time) and it accounts for the agents entering and leaving the cluster."
- Break condition: If the fixed radius is too small to capture relevant interactions in denser crowds, or too large and includes irrelevant agents.

### Mechanism 3
- Claim: Using a smaller time history (Th = 5-10 time steps) with input and temporal attention mechanisms is sufficient for accurate multi-agent interaction prediction.
- Mechanism: The attention mechanisms allow the model to focus on the most relevant past interactions and spatial configurations, reducing the need for long time histories while maintaining prediction accuracy.
- Core assumption: The most important interaction cues are captured within a short time window when combined with attention mechanisms.
- Evidence anchors:
  - [section] "The input attention encoder of the network... consists of an input attention layer (I-Attention) which weighs n* spatial interactions in a radial cluster. The encoder is then followed by a decoder with a temporal attention layer (T-Attention), capturing the temporal dependencies in multi-agent interactions."
  - [section] "FQTC−4 and FQTC−6 were trained... with Th = 10 time steps... while Fts was trained using... Th = 5 time steps."
- Break condition: If the attention mechanisms fail to identify the truly relevant past information, or if longer temporal dependencies are necessary for accurate predictions.

## Foundational Learning

- Concept: Qualitative Trajectory Calculus (QTC)
  - Why needed here: QTC provides a symbolic representation of spatial interactions between agents, which is crucial for understanding and predicting multi-agent behavior in social scenes.
  - Quick check question: What are the four basic QTC symbols (q1-q4) and what spatial relationships do they represent?

- Concept: Proxemics and social distance
  - Why needed here: Understanding social distances helps in setting appropriate clustering radii and interpreting the significance of agent proximity in interaction prediction.
  - Quick check question: According to Hall's proxemics, what is the typical distance range for social interactions among acquaintances?

- Concept: Attention mechanisms in sequence modeling
  - Why needed here: Attention allows the model to focus on the most relevant parts of the input sequence (spatial interactions or temporal steps), improving prediction accuracy with less data.
  - Quick check question: How do input attention and temporal attention differ in their focus within the interaction prediction network?

## Architecture Onboarding

- Component map: Raw coordinates → Radial clustering → QTC extraction → Embedding Layer → Input Attention (I-Attention) → LSTM Encoder → Temporal Attention (T-Attention) → LSTM Decoder → QTC symbols (FQTC-4/6) or Trajectories (Fts) → Post-processing (Fts only)
- Critical path: Data preprocessing (clustering, QTC extraction) → Model training (with appropriate loss function) → Prediction and evaluation (using conceptual QTC distance)
- Design tradeoffs: Symbolic vs. data-driven approaches (interpretability vs. performance), fixed cluster radius (simplicity vs. adaptability), attention mechanisms (complexity vs. accuracy)
- Failure signatures: High conceptual QTC distance on test set, poor generalization to new scenes, unstable training (high variance between epochs)
- First 3 experiments:
  1. Train Fts with Th=5 and evaluate on cafe scene test set to confirm baseline performance.
  2. Compare FQTC-4 and FQTC-6 performance on the same test set to understand symbolic approach limitations.
  3. Test Fts,1 and Fts,2 on a domain-shifted scene (PS-1) to assess generalization capability.

## Open Questions the Paper Calls Out

- The paper doesn't explicitly call out open questions in the provided content.

## Limitations

- The paper does not provide specific implementation details for the input-temporal attention mechanism, making exact replication challenging.
- Computational resource requirements and training times are not disclosed, limiting assessment of practical feasibility.
- The fixed radius approach (1.2m) for radial clustering, while grounded in proxemics literature, may not be optimal for all crowd densities or cultural contexts.

## Confidence

- High: The core finding that the data-driven Fts approach outperforms the symbol-driven methods (FQTC-4 and FQTC-6) in terms of conceptual QTC distance and generalization capability.
- Medium: The effectiveness of the radial clustering with a fixed radius of 1.2m for managing variable crowd sizes and focusing on socially relevant agents.
- Medium: The sufficiency of using a shorter time history (Th = 5-10 time steps) with attention mechanisms for accurate multi-agent interaction prediction.

## Next Checks

1. Implement and validate the QTC symbol generation and radial clustering approach on a subset of the JackRabbot dataset to ensure correct preprocessing.
2. Conduct a hyperparameter sensitivity analysis for the Fts model, varying learning rates, batch sizes, and hidden states to identify optimal settings.
3. Test the Fts model on a different multi-agent interaction dataset (e.g., ETH/UCY) to evaluate its generalization capability beyond the JackRabbot scenes.