---
ver: rpa2
title: Physics-Inspired Interpretability Of Machine Learning Models
arxiv_id: '2304.02381'
source_url: https://arxiv.org/abs/2304.02381
tags:
- learning
- machine
- weights
- methods
- energy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We present a novel approach to identify relevant features of the
  input data in machine learning models, inspired by methods from the energy landscapes
  field in physical sciences. By identifying conserved weights within groups of minima
  of the loss landscapes, we can identify the drivers of model decision making.
---

# Physics-Inspired Interpretability Of Machine Learning Models

## Quick Facts
- arXiv ID: 2304.02381
- Source URL: https://arxiv.org/abs/2304.02381
- Reference count: 3
- Key outcome: Novel approach identifies conserved weights in ML loss landscape minima groups using energy landscape methods, revealing critical features driving model decisions.

## Executive Summary
This paper presents a novel interpretability method for machine learning models inspired by energy landscape analysis from physical sciences. The approach identifies conserved weights within groups of minima in the loss landscape, which are analogous to critical features in molecular sciences. By constructing disconnectivity graphs and analyzing weight conservation across minima groups, the method reveals which input features are most relevant for model decision-making. The technique is demonstrated on both synthetic (2D checkerboard) and real-world (credit card fraud detection) datasets using single-layer neural networks.

## Method Summary
The method treats ML loss landscapes as energy landscapes and uses disconnectivity graphs to identify groups of minima separated by transition states. Within each group, weights with low standard deviation across minima are identified as "conserved weights" - those critical to model performance. The approach accounts for permutationally invariant weight sets in neural networks and validates the importance of conserved weights by showing that their permutation causes greater performance degradation than random weight permutations. The method is demonstrated on single-layer neural networks trained on binary classification tasks.

## Key Results
- Successfully identified conserved weights in both synthetic 2D checkerboard and real 29D credit card fraud datasets
- Demonstrated that permuting conserved weights causes significantly greater performance degradation than permuting random weights
- Showed that conserved weights correspond to the most relevant input features for model decision-making
- Achieved AUC > 0.95 on both classification problems while maintaining interpretability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Loss landscape minima groups share conserved weights that are critical to model performance
- Mechanism: Grouping minima separated by high transition states reveals structural commonalities, with conserved weights identified by low standard deviation across minima
- Core assumption: Minima in the same node/level share structural commonalities due to proximity in the loss landscape
- Evidence anchors:
  - [abstract] "By identifying conserved weights within groups of minima of the loss landscapes, we can identify the drivers of model decision making."
  - [section] "Randomly permuting the conserved weights strongly decreases model performance, much more so than permuting any other random set of weightsS of equivalent cardinality|S|."
- Break condition: If minima in a node do not actually share relevant weights, or if conserved weights are not actually critical to performance

### Mechanism 2
- Claim: Disconnectivity graphs provide a faithful coarse-grained representation of the loss landscape
- Mechanism: Reducing the loss landscape to key stationary points allows identification of distinct groups of minima (funnels) that may share commonalities
- Core assumption: Transition states between minima represent meaningful barriers that separate functionally distinct regions of the loss landscape
- Evidence anchors:
  - [section] "Visualisation is commonly performed using disconnectivity graphs (Becker & Karplus, 1997; Wales et al., 1998) as described below."
  - [section] "In particular, it will be relevant below to understand that any group of minima close together, perhaps separated from other groups of minima via high-lying transition states, may share commonalities."
- Break condition: If transition states do not meaningfully separate distinct regions of the loss landscape

### Mechanism 3
- Claim: Permutationally invariant weight sets must be accounted for when identifying conserved weights
- Mechanism: For neural networks with hidden layers, multiple weight configurations produce identical predictions, requiring identification of permutationally invariant sets
- Core assumption: Weight permutations can produce identical model predictions, so must be considered when identifying truly conserved weights
- Evidence anchors:
  - [section] "As discussed in Niroomand et al. (2022), the magnitude of individual weights must always be viewed with caution due to permutational isomers."
  - [section] "We account for this effect by identifying permutationally invariant sets of weights and only considering a single minimummâˆˆG for eachG."
- Break condition: If permutationally invariant weight sets are not properly identified and handled

## Foundational Learning

- Concept: Energy landscapes and disconnectivity graphs
  - Why needed here: The method fundamentally relies on treating ML loss landscapes as energy landscapes and using disconnectivity graphs to identify groups of minima
  - Quick check question: What is a disconnectivity graph and how does it help identify groups of minima in a loss landscape?

- Concept: Permutationally invariant weights in neural networks
  - Why needed here: The method must account for multiple weight configurations that produce identical predictions when identifying conserved weights
  - Quick check question: Why must we consider permutationally invariant weight sets when identifying conserved weights?

- Concept: Standard deviation as a metric for weight conservation
  - Why needed here: The method uses low standard deviation across minima in a node to identify conserved weights
  - Quick check question: How does computing the standard deviation of weights across minima help identify conserved weights?

## Architecture Onboarding

- Component map: Loss landscape construction -> Transition state identification -> Node/Level grouping -> Conservation analysis -> Permutation handling
- Critical path:
  1. Generate diverse set of minima by optimizing loss from different initializations
  2. Identify transition states between minima
  3. Construct disconnectivity graph with nodes and levels
  4. Compute weight standard deviations within each node
  5. Identify conserved weights with low standard deviation
  6. Handle permutationally invariant weight sets
  7. Validate that conserved weights are critical to model performance

- Design tradeoffs:
  - More minima provide better landscape coverage but increase computational cost
  - Finer energy level spacing in disconnectivity graphs provides more detailed grouping but increases complexity
  - Stricter standard deviation threshold for conservation identifies fewer but more reliably conserved weights
  - More thorough permutation handling increases accuracy but also computational cost

- Failure signatures:
  - No conserved weights identified despite diverse minima
  - Conserved weights not actually critical to model performance
  - Extremely few minima generated due to optimization challenges
  - Disconnectivity graph becomes too complex to interpret

- First 3 experiments:
  1. Simple binary classification with small neural network (2-3 layers) on synthetic dataset
  2. Binary classification on real dataset with small neural network, validate that conserved weights are critical
  3. Regression task with small neural network to test generalizability beyond classification

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed energy landscape-based approach scale to larger, more complex neural network architectures beyond single-layer networks?
- Basis in paper: [explicit] The paper mentions that "further work will be required to validate this suggestion" that the approach applies to any neural network architecture, and notes the need to study applicability to "larger and more complex architectures".
- Why unresolved: The experiments only demonstrated the approach on single-layer neural networks, which may not capture the complexity of deeper architectures.
- What evidence would resolve it: Experiments applying the approach to multi-layer networks with varying depths and widths, demonstrating consistent identification of conserved weights and their interpretability.

### Open Question 2
- Question: Can the conserved weights identified by this method be reliably used to prune or compress neural networks without significant loss in performance?
- Basis in paper: [inferred] The paper shows that permuting conserved weights strongly decreases model performance, suggesting these weights are critical, but doesn't explore whether removing them would work.
- Why unresolved: While the paper demonstrates the importance of conserved weights, it doesn't test whether these weights are redundant enough to be removed or whether other non-conserved weights could compensate.
- What evidence would resolve it: Empirical studies showing that networks with conserved weights removed or perturbed perform significantly worse than those with random weights removed, or successful application of the method for model compression.

### Open Question 3
- Question: How does the choice of energy landscape visualization parameters (level spacing, node definition) affect the identification of conserved weights and their interpretability?
- Basis in paper: [explicit] The paper describes the visualization method but doesn't systematically study how parameter choices affect results.
- Why unresolved: The disconnectivity graph construction involves arbitrary choices that could influence which minima are grouped together and which weights appear conserved.
- What evidence would resolve it: Sensitivity analysis showing how different parameter choices affect the number and identity of conserved weights identified, and whether the most important conserved weights remain stable across parameter variations.

## Limitations
- Limited validation on only single-layer neural networks, lacking testing on deeper architectures
- Unclear implementation details for handling permutationally invariant weights
- Weak empirical validation across diverse problem domains and network architectures

## Confidence
- Mechanism 1 (Conserved Weights Identification): Medium confidence - Concept is sound but validation is limited to specific datasets and network architectures
- Mechanism 2 (Disconnectivity Graphs): Medium confidence - Well-established in energy landscapes but needs more empirical validation for ML applications
- Mechanism 3 (Permutation Handling): Low confidence - Implementation details are unclear and corpus evidence is lacking

## Next Checks
1. Apply the method to deeper neural networks (2+ hidden layers) on standard benchmark datasets (e.g., MNIST, CIFAR-10) to assess scalability and robustness across architectures.

2. Compare the conserved weights identified by this method to established feature importance techniques (e.g., SHAP, LIME) on the same datasets to verify consistency and interpretability.

3. Test the method's sensitivity to the number of minima sampled and the energy level spacing in disconnectivity graphs to determine optimal parameters for reliable conserved weight identification.