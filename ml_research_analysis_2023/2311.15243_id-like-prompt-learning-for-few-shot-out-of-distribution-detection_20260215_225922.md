---
ver: rpa2
title: ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection
arxiv_id: '2311.15243'
source_url: https://arxiv.org/abs/2311.15243
tags:
- samples
- prompts
- detection
- learning
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses out-of-distribution (OOD) detection, focusing
  on identifying challenging OOD samples that are highly similar to in-distribution
  (ID) data, referred to as ID-like samples. The proposed method constructs ID-like
  outliers from ID samples using random cropping and CLIP similarity filtering, then
  learns prompts for both ID and ID-like OOD data.
---

# ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection

## Quick Facts
- arXiv ID: 2311.15243
- Source URL: https://arxiv.org/abs/2311.15243
- Reference count: 40
- Key outcome: Reduces FPR95 by 12.16% and improves AUROC by 2.76% in 4-shot OOD detection on ImageNet-1k

## Executive Summary
This paper addresses the challenge of few-shot out-of-distribution (OOD) detection, focusing specifically on identifying OOD samples that are highly similar to in-distribution (ID) data. The proposed method constructs ID-like outliers from ID samples using random cropping and CLIP similarity filtering, then learns separate prompts for both ID and these challenging OOD samples. A novel ID-like prompt learning framework aligns OOD prompts with the constructed outliers, enabling effective identification of difficult OOD samples that traditional methods struggle with.

## Method Summary
The method constructs ID-like outliers from ID samples through random cropping and CLIP-based similarity filtering, selecting crops that are visually similar but semantically OOD. It then learns separate prompt embeddings for ID classes and OOD concepts, optimizing them through a combined loss function that includes ID alignment, OOD alignment, and diversity regularization. During inference, the method computes a score that combines ID and OOD prompt similarities to distinguish between ID and challenging OOD samples, with experiments demonstrating superior performance in few-shot settings on ImageNet datasets.

## Key Results
- In 4-shot detection on ImageNet-1k: Reduces FPR95 by 12.16% and improves AUROC by 2.76% compared to state-of-the-art methods
- Successfully identifies challenging ID-like OOD samples that are visually similar to ID data
- Demonstrates effectiveness across multiple OOD datasets (iNaturalist, Places, Texture, SUN)

## Why This Works (Mechanism)

### Mechanism 1
Random cropping of ID samples combined with CLIP similarity filtering effectively generates ID-like outliers that are visually similar to ID data but semantically OOD. By performing multiple random crops and selecting those with lowest similarity to ID prompts, the method extracts image regions that retain ID-like visual features but fall outside the semantic scope of ID classes, creating challenging OOD samples.

### Mechanism 2
Learning separate OOD prompts alongside ID prompts enables the model to distinguish challenging ID-like OOD samples by providing dedicated semantic representations. The framework learns additional prompts (T out) that are aligned with the constructed ID-like outliers through cross-entropy loss, creating semantic representations that capture features correlated with ID but distinct enough to identify OOD.

### Mechanism 3
The diversity regularization loss prevents OOD prompts from collapsing into similar representations, maintaining coverage across different OOD categories. The diversity loss (Ldiv) explicitly maximizes cosine dissimilarity between OOD prompts, ensuring they capture diverse aspects of the OOD space rather than converging to similar semantic regions.

## Foundational Learning

- Concept: CLIP's vision-language alignment through contrastive learning
  - Why needed here: The method relies on CLIP's ability to measure semantic similarity between images and text prompts to generate ID-like outliers and learn discriminative prompts
  - Quick check question: How does CLIP's contrastive loss ensure that matching image-text pairs have high similarity while non-matching pairs have low similarity?

- Concept: Prompt learning as parameter-efficient fine-tuning
  - Why needed here: The framework uses prompt tuning to adapt CLIP to OOD detection without modifying the underlying model weights, crucial for few-shot settings
  - Quick check question: What is the difference between prompt tuning and full fine-tuning in terms of parameter updates and data efficiency?

- Concept: Out-of-distribution detection score functions
  - Why needed here: The method defines a novel score function that combines ID and OOD prompt similarities to distinguish between ID and challenging OOD samples
  - Quick check question: How does the proposed score function (combining ID and OOD prompt similarities) differ from traditional maximum softmax probability approaches?

## Architecture Onboarding

- Component map: Image Encoder (CLIP ViT-B/16) -> Text Encoder (CLIP Transformer) -> Random Crop Generator -> Similarity Filter -> Prompt Learner -> Loss Functions
- Critical path: 1. Generate crops -> 2. Compute CLIP similarities -> 3. Filter ID vs OOD samples -> 4. Initialize prompts -> 5. Optimize prompts with combined loss -> 6. Inference using score function
- Design tradeoffs: Fixed CLIP vs fine-tuning (preserves generalization but limits adaptation), number of OOD prompts (C=100) balances coverage vs computational cost, crop count (M=256) and filter count (Q=32) affects outlier quality vs training efficiency
- Failure signatures: Poor OOD detection (OOD prompts too similar to ID prompts), degraded ID classification (ID prompts overfit to outliers), unstable training (learning rate too high for prompt embeddings)
- First 3 experiments: 1. Ablation: Train with only ID prompts (no OOD prompts) to verify the contribution of OOD prompts, 2. Ablation: Remove diversity regularization to observe prompt collapse, 3. Ablation: Use random crops without similarity filtering to test the importance of the selection mechanism

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of ID-like prompt learning compare when applied to non-CLIP vision-language models, such as ALIGN or FILIP?
- Basis in paper: The paper primarily uses CLIP for its experiments, but mentions other models like ALIGN and FILIP in related work
- Why unresolved: The paper does not explore the effectiveness of ID-like prompt learning with other vision-language models
- What evidence would resolve it: Conducting experiments with ALIGN and FILIP models to compare their performance with CLIP in the context of ID-like prompt learning

### Open Question 2
- Question: What are the computational costs and scalability implications of using ID-like prompt learning for large-scale datasets with many classes?
- Basis in paper: The paper mentions the need for a large number of OOD prompts to characterize OOD samples effectively, suggesting potential scalability concerns
- Why unresolved: The paper does not discuss the computational costs or scalability of the approach for larger datasets
- What evidence would resolve it: Analyzing the computational resources required and the scalability of ID-like prompt learning when applied to datasets with a significantly larger number of classes and samples

### Open Question 3
- Question: How does the performance of ID-like prompt learning vary with different levels of similarity between ID and OOD samples?
- Basis in paper: The paper focuses on challenging OOD samples that are highly similar to ID data, referred to as ID-like samples
- Why unresolved: The paper does not explore how the method performs with OOD samples that have varying degrees of similarity to ID samples
- What evidence would resolve it: Testing the method on datasets with OOD samples that have a range of similarities to ID samples, from highly similar to completely dissimilar, to evaluate performance across this spectrum

### Open Question 4
- Question: What is the impact of different random cropping strategies on the quality of constructed ID-like outliers?
- Basis in paper: The paper uses random cropping to construct outliers from ID samples, but does not explore alternative cropping strategies
- Why unresolved: The paper does not investigate how different cropping methods might affect the construction of ID-like outliers
- What evidence would resolve it: Experimenting with various random cropping techniques and analyzing their impact on the quality and effectiveness of the constructed ID-like outliers in OOD detection

## Limitations
- Effectiveness depends heavily on CLIP's ability to measure semantic similarity, which may not generalize well to all image types
- The random cropping mechanism assumes that visual similarity correlates with semantic similarity, which could fail for certain image distributions
- Diversity regularization requires careful tuning to prevent OOD prompts from either collapsing or becoming too dispersed

## Confidence
- High Confidence: The core framework architecture and loss function design are well-specified and technically sound
- Medium Confidence: The effectiveness of ID-like outlier generation through random cropping and similarity filtering
- Low Confidence: The generalizability of results to datasets and scenarios not evaluated in the paper, particularly for non-natural image domains

## Next Checks
1. Ablation on Similarity Filtering: Test the method without the CLIP similarity filtering step to quantify the importance of the outlier selection mechanism versus random sampling
2. Cross-Domain Generalization: Evaluate the method on non-natural image datasets (medical images, satellite imagery, etc.) to assess robustness beyond the natural image domains tested
3. Prompt Collapse Analysis: Systematically vary the diversity regularization strength (Î»div) and visualize OOD prompt embeddings to identify conditions under which prompt collapse occurs