---
ver: rpa2
title: 'Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality
  Bias in Generative Models'
arxiv_id: '2309.08902'
source_url: https://arxiv.org/abs/2309.08902
tags:
- bias
- negative
- positive
- attributes
- beauty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates subtler forms of bias in large language
  models (LLMs) along dimensions such as age, beauty, institutional affiliation, and
  nationality. The authors introduce a template-generated dataset of sentence completion
  tasks to measure how LLMs associate positive, negative, and neutral attributes with
  social groups.
---

# Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality Bias in Generative Models

## Quick Facts
- **arXiv ID:** 2309.08902
- **Source URL:** https://arxiv.org/abs/2309.08902
- **Reference count:** 11
- **Primary result:** GPT-3.5 and PaLM 2 exhibit statistically significant biases across age, beauty, institutional affiliation, and nationality domains.

## Executive Summary
This paper introduces a template-generated sentence completion dataset to measure subtle biases in large language models (LLMs) along dimensions such as age, beauty, institutional affiliation, and nationality. The authors evaluate GPT-3.5 and PaLM 2 using a fill-in-the-blank task where models select from positive, negative, or neutral attributes. Results show significant associations between social group descriptors and attribute choices, with both models exhibiting a tendency to associate positive attributes with positive stimuli and negative attributes with negative stimuli. The beauty bias category exhibits the strongest effects, and GPT-3.5 shows stronger associations compared to PaLM 2.

## Method Summary
The study uses template-generated sentence completion tasks to measure bias in LLMs. Prompts are structured as fill-in-the-blank statements with three-choice options (positive, negative, neutral). The method assesses bias in two directions: Stimulus-to-Attribute Inference (SAI) and Attribute-to-Stimulus Association (ASA). The authors use Kendall's τ test to measure rank correlation between the binary stimulus polarity and the ordinal attribute choices. Conditional likelihoods of attribute selection are computed to quantify bias strength.

## Key Results
- Both GPT-3.5 and PaLM 2 show statistically significant associations between social group descriptors and attribute choices.
- Beauty bias exhibits the strongest effects among the four domains tested.
- GPT-3.5 demonstrates stronger associations compared to PaLM 2.
- Significant associations are found in three of four model-experiment combinations using Kendall's τ test.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Template-generated sentence completion tasks effectively measure subtle bias by isolating conditional associations between social group descriptors and unrelated attributes.
- **Mechanism:** Prompts are structured as fill-in-the-blank statements with three-choice options, and the model's completion probability reveals systematic preference shifts when the prompt descriptor changes polarity.
- **Core assumption:** The language model's next-token probabilities are proportional to its implicit association strength between the stimulus and attribute classes.
- **Evidence anchors:** Abstract mentions template-generated dataset of sentence completion tasks; methods section references positive/negative trait collections from prior literature.
- **Break condition:** If the model overfits to the template format or if attribute choices are not truly neutral, measured associations may reflect template artifacts rather than genuine bias.

### Mechanism 2
- **Claim:** Using both SAI and ASA directions captures bidirectional bias, ensuring the bias is not merely a one-sided correlation artifact.
- **Mechanism:** By reversing the completion task—either prompting with a descriptor to choose an attribute, or prompting with an attribute to choose a descriptor—the method tests whether the model's preference pattern holds in both directions.
- **Core assumption:** A model with genuine bias will show consistent directional preference regardless of which side of the association is fixed.
- **Evidence anchors:** Abstract mentions reversing the completion task; methods section states the study provides more general measurement than previous single-direction studies.
- **Break condition:** If the model's language generation is highly context-dependent or if one direction is influenced more by frequency bias in training data, the symmetry test may fail to detect bias present only in one direction.

### Mechanism 3
- **Claim:** Kendall's τ test provides a non-parametric, rank-based measure of association that is robust to the ordinal nature of positive/negative/neutral attribute categories.
- **Mechanism:** By converting attribute choices into ordinal values (negative < neutral < positive) and computing rank correlation against binary stimulus polarity, the test captures monotonic association without assuming linearity or normal distribution.
- **Core assumption:** The ordinal scale of attributes meaningfully reflects the underlying sentiment polarity the model uses in generation.
- **Evidence anchors:** Methods section reports correlations for four LLMs and calculates conditional likelihood of model to select attributes in response to positive and negative stimuli.
- **Break condition:** If the neutral category is not truly neutral in the model's embedding space, the ordinal ranking assumption breaks down and the τ statistic becomes misleading.

## Foundational Learning

- **Concept:** Conditional probability in language models
  - **Why needed:** Understanding how next-token probability distributions shift with different prompt descriptors is central to interpreting bias measurements.
  - **Quick check:** If a model assigns P("creative" | "MIT") = 0.7 and P("creative" | "community college") = 0.3, what does this imply about the model's association between institution type and creativity?

- **Concept:** Ordinal vs. nominal data
  - **Why needed:** The bias measurement relies on treating positive/negative/neutral as ordered categories to apply rank correlation tests.
  - **Quick check:** Why is it inappropriate to use a standard chi-square test of independence for this dataset, and what advantage does Kendall's τ provide?

- **Concept:** Bidirectional association testing
  - **Why needed:** Ensures that bias is not a one-sided artifact by measuring association in both SAI and ASA directions.
  - **Quick check:** If a model shows bias in SAI but not ASA, what might this indicate about the nature of the bias (e.g., frequency bias vs. genuine association)?

## Architecture Onboarding

- **Component map:** Data generation -> LLM interface -> Evaluation -> Result aggregation
- **Critical path:**
  1. Generate template instances for each descriptor-attribute pair.
  2. Query LLM with prompt and collect top-3 completions.
  3. Map completions to positive/negative/neutral categories.
  4. Compute conditional likelihoods and Kendall's τ.
  5. Interpret statistical significance and bias magnitude.
- **Design tradeoffs:**
  - Template simplicity vs. ecological validity: Simple templates ensure control but may not reflect real-world language complexity.
  - Fixed attribute sets vs. open-ended responses: Fixed sets enable statistical testing but may constrain model expression.
  - Binary stimulus coding vs. multi-level descriptors: Binary coding simplifies analysis but loses nuance in descriptor strength.
- **Failure signatures:**
  - High variance in completion probabilities across repeated prompts indicates instability.
  - Equal likelihood across all three attribute choices suggests no detectable bias or poor prompt design.
  - Significant τ only in one direction (SAI or ASA) may indicate artifact rather than true association.
- **First 3 experiments:**
  1. Run a small pilot with 10 instances per domain to verify template generation and API response consistency.
  2. Test the Kendall's τ calculation on synthetic data with known associations to validate the statistical pipeline.
  3. Compare baseline completion distributions (without bias descriptors) to ensure the attribute sets are balanced.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the strength of beauty bias in LLMs vary across different demographic groups (e.g., age, gender, socioeconomic status)?
- **Basis in paper:** The paper found strong beauty bias in both GPT-3.5 and PaLM 2 models, but did not analyze the bias across different demographic groups.
- **Why unresolved:** The dataset used in the study did not include demographic information about the individuals being described, making it impossible to analyze the bias across different groups.
- **What evidence would resolve it:** A follow-up study that collects demographic information about the individuals in the dataset and analyzes the beauty bias across different groups would provide evidence to answer this question.

### Open Question 2
- **Question:** How does the strength of nationality bias in LLMs vary across different regions of the world?
- **Basis in paper:** The paper found nationality bias in both GPT-3.5 and PaLM 2 models, but did not analyze the bias across different regions of the world.
- **Why unresolved:** The dataset used in the study included countries from all over the world, but did not group them by region, making it impossible to analyze the bias across different regions.
- **What evidence would resolve it:** A follow-up study that groups the countries in the dataset by region and analyzes the nationality bias across different regions would provide evidence to answer this question.

### Open Question 3
- **Question:** How does the strength of institutional bias in LLMs vary across different types of institutions (e.g., universities, community colleges, vocational schools)?
- **Basis in paper:** The paper found institutional bias in both GPT-3.5 and PaLM 2 models, and the dataset included both universities and community colleges.
- **Why unresolved:** The dataset used in the study did not include other types of institutions, such as vocational schools, making it impossible to analyze the bias across different types of institutions.
- **What evidence would resolve it:** A follow-up study that includes other types of institutions in the dataset and analyzes the institutional bias across different types of institutions would provide evidence to answer this question.

## Limitations
- The template-generated sentence completion tasks may not fully capture the complexity of real-world language use.
- The study does not specify exact template sentences or attribute lists, affecting reproducibility.
- The paper lacks external validation (e.g., human judgment of bias or comparison with other bias detection methods).

## Confidence
- **High Confidence:** Methodology for template generation and use of Kendall's τ test are clearly specified and grounded in prior work; statistical significance of associations in three of four model-experiment combinations is well-supported.
- **Medium Confidence:** The claim that GPT-3.5 shows stronger bias than PaLM 2 is plausible but requires further validation, as the paper does not explore why this difference exists or rule out model-specific artifacts.
- **Low Confidence:** The assertion that beauty bias exhibits the strongest effects is not robustly justified, as the paper does not compare effect sizes across domains or account for potential confounding factors.

## Next Checks
1. Conduct a pilot study with human raters to validate the neutrality of the attribute sets and the binary coding of stimuli.
2. Replicate the analysis using an alternative statistical measure (e.g., point-biserial correlation) to confirm the robustness of Kendall's τ results.
3. Test the methodology on a more diverse set of LLMs (e.g., open-source models like LLaMA) to assess whether the observed biases are model-specific or generalizable.