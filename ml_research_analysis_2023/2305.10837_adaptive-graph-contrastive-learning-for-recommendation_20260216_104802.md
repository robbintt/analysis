---
ver: rpa2
title: Adaptive Graph Contrastive Learning for Recommendation
arxiv_id: '2305.10837'
source_url: https://arxiv.org/abs/2305.10837
tags:
- graph
- learning
- contrastive
- data
- view
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel adaptive graph contrastive learning
  framework for recommendation. The method uses two trainable view generators - a
  graph generative model and a graph denoising model - to create adaptive contrastive
  views, introducing additional high-quality training signals to alleviate data sparsity
  and noise issues in recommender systems.
---

# Adaptive Graph Contrastive Learning for Recommendation

## Quick Facts
- arXiv ID: 2305.10837
- Source URL: https://arxiv.org/abs/2305.10837
- Authors: Not specified in input
- Reference count: 40
- Primary result: Achieves 14.6% Recall@20 and 18.1% NDCG@20 improvements over state-of-the-art methods

## Executive Summary
This paper introduces Adaptive Graph Contrastive Learning (AdaGCL), a novel framework for recommendation that addresses data sparsity and noise issues through adaptive contrastive views. The method employs two trainable view generators - a graph generative model and a graph denoising model - to create diverse contrastive views while preventing model collapse. The framework incorporates task-specified signals and an information bottleneck technique to improve generalizability and robustness. Extensive experiments on three real-world datasets demonstrate significant performance improvements over existing methods.

## Method Summary
AdaGCL uses LightGCN as the base encoder and employs two trainable view generators: a VGAE-based graph generative model and a graph denoising model with concrete distribution. These generators create adaptive contrastive views from different perspectives, addressing the model collapse problem common in contrastive learning. The framework incorporates task-specified signals through BPR loss and uses information bottleneck (InfoBN) to prevent the acquisition of superfluous information. Training combines three objectives: main recommendation task (BPR loss), self-supervised contrastive learning (InfoNCE loss), and InfoBN regularization.

## Key Results
- Achieves up to 14.6% relative Recall@20 improvement over best baseline
- Achieves up to 18.1% relative NDCG@20 improvement over best baseline
- Demonstrates effectiveness across three real-world datasets (Last.FM, Yelp, BeerAdvocate)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two different adaptive view generators address model collapse in contrastive learning
- Mechanism: Graph generative model and graph denoising model create views from different perspectives, preventing identical distributions
- Core assumption: Model collapse occurs when both generators produce similar distributions
- Evidence anchors: Abstract states generators address model collapse; section explains using two different generators to fix the problem
- Break condition: If generators learn to produce highly correlated outputs despite different architectures

### Mechanism 2
- Claim: Information bottleneck prevents acquisition of superfluous information
- Mechanism: InfoBN reduces information overlap between views and latent representations while maintaining view agreement in latent space
- Core assumption: BPR loss introduces noise irrelevant to original user-item graph
- Evidence anchors: Section explains BPR loss introduces extra information; abstract states InfoBN discourages superfluous information
- Break condition: If InfoBN implementation is too aggressive and removes useful information

### Mechanism 3
- Claim: Task-specified signals help view generators create task-fitting views
- Mechanism: BPR loss guides view generators to create views aligned with recommendation objective
- Core assumption: Without task guidance, generators create views good for contrastive learning but not recommendation
- Evidence anchors: Section states no signals help views adapt to CF task; abstract mentions improving generators through task-specified signals
- Break condition: If task-specified signals are too strong and bias generators excessively

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) for collaborative filtering
  - Why needed here: Framework builds on GNN-based recommendation using message passing along user-item edges
  - Quick check question: How does LightGCN simplify message passing compared to standard GCNs?

- Concept: Contrastive learning principles
  - Why needed here: Framework creates positive and negative pairs from different views of same data
  - Quick check question: What is the difference between InfoNCE loss and standard contrastive loss?

- Concept: Variational Graph Autoencoders (VGAE)
  - Why needed here: VGAE serves as graph generative model for creating adaptive contrastive views
  - Quick check question: What is the role of KL divergence term in VGAE's loss function?

## Architecture Onboarding

- Component map: Data → LightGCN → VGAE + Denoising Model → Contrastive Learning → InfoBN → Recommendations
- Critical path: Data flows through LightGCN encoder, two view generators create contrastive views, InfoBN regularization applied, final recommendations produced
- Design tradeoffs: Adaptive view generators offer flexibility but are harder to train versus simpler fixed augmentation methods
- Failure signatures: Model collapse (identical view distributions), poor generalization (overfitting), training instability (conflicting objectives)
- First 3 experiments:
  1. Test with only one view generator to demonstrate necessity of two different generators
  2. Remove InfoBN to show its impact on handling noisy data
  3. Compare adaptive view generators against fixed augmentation methods (edge dropout, feature masking) on sparse datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do graph generative model and graph denoising model compare in effectiveness across different dataset types (sparse vs. dense, different domains)?
- Basis in paper: Paper states two different contrastive views address model collapse but lacks detailed comparison of individual contributions across dataset characteristics
- Why unresolved: Only provides ablation studies on overall framework, not isolating performance differences between model types
- What evidence would resolve it: Experiments comparing framework using only graph generative model, only denoising model, and both together on diverse datasets with varying sparsity levels and domains

### Open Question 2
- Question: What is the impact of information bottleneck technique on quality and diversity of learned representations and model's generalization ability?
- Basis in paper: Paper introduces InfoBN and states it discourages superfluous information for better generalizability, but lacks detailed analysis of specific impacts
- Why unresolved: Only mentions theoretical benefits without empirically demonstrating impact on learned representations or generalization performance
- What evidence would resolve it: Experiments analyzing quality and diversity of learned representations with/without InfoBN, plus evaluation on held-out test sets or cross-domain scenarios

### Open Question 3
- Question: How does AdaptiveGCL perform compared to other self-supervised learning methods using different contrastive views (node attributes, temporal information)?
- Basis in paper: Paper compares to several self-supervised baselines but doesn't compare to methods using node attributes or temporal information
- Why unresolved: Focuses on graph structure-based contrastive views without exploring methods leveraging additional information
- What evidence would resolve it: Experiments comparing AdaptiveGCL to self-supervised methods using contrastive views based on node attributes or temporal information on relevant datasets

## Limitations
- Framework effectiveness heavily depends on balancing three loss components with careful hyperparameter tuning
- Lacks ablation studies isolating InfoBN component's individual contribution
- Claims about two generators preventing model collapse lack quantitative evidence or formal proof

## Confidence

- **High confidence**: Experimental results showing consistent improvements over baselines are well-documented and reproducible
- **Medium confidence**: Theoretical justification for InfoBN preventing information overload is sound but lacks empirical validation specific to recommendation tasks
- **Low confidence**: Claim that two different generators are necessary to prevent model collapse is based on intuition rather than quantitative evidence

## Next Checks
1. Conduct ablation studies removing InfoBN to quantify its specific contribution to performance gains
2. Measure and visualize distributional divergence between two view generators throughout training to verify distinct representations
3. Test framework on additional sparse datasets beyond the three provided to evaluate generalization across different sparsity levels