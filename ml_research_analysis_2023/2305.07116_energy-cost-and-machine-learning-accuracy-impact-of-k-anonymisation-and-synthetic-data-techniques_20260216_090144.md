---
ver: rpa2
title: Energy cost and machine learning accuracy impact of k-anonymisation and synthetic
  data techniques
arxiv_id: '2305.07116'
source_url: https://arxiv.org/abs/2305.07116
tags:
- data
- energy
- synthetic
- consumption
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the energy consumption and accuracy of
  machine learning models trained on k-anonymised and synthetic data. The authors
  use two datasets and three machine learning models (k-nearest neighbours, logistic
  regression, and neural network) to compare the performance of models trained on
  original, k-anonymised, and synthetic data.
---

# Energy cost and machine learning accuracy impact of k-anonymisation and synthetic data techniques

## Quick Facts
- arXiv ID: 2305.07116
- Source URL: https://arxiv.org/abs/2305.07116
- Reference count: 40
- Models trained on k-anonymised data consume less energy than models trained on the original data, with similar accuracy performance

## Executive Summary
This paper investigates the energy consumption and accuracy trade-offs of machine learning models trained on k-anonymised versus synthetic data. The authors conduct experiments using two datasets (Adult and Student Performance) and three machine learning models (k-nearest neighbours, logistic regression, and neural network). They find that k-anonymisation not only preserves model accuracy but also reduces energy consumption during training, while synthetic data generation is more energy-intensive with comparable or slightly lower accuracy.

## Method Summary
The study preprocesses datasets, applies k-anonymity using generalization and suppression with varying k-values, and generates synthetic data using DataSynthesizer. Three ML models are trained on original, k-anonymised, and synthetic datasets. Energy consumption is measured using RAPL sensors for CPU and DRAM, while accuracy is calculated for each model. The experiments compare energy usage and accuracy across different privacy techniques and k-values.

## Key Results
- Models trained on k-anonymised data consume less energy than models trained on original data
- k-anonymised data maintains similar accuracy to original data
- Synthetic data generation consumes nearly 4 times more energy than k-anonymisation
- Higher k-values in k-anonymity lead to greater energy savings due to increased data suppression

## Why This Works (Mechanism)

### Mechanism 1
- Claim: k-anonymisation reduces energy consumption in machine learning by decreasing dataset size through suppression and generalisation.
- Mechanism: By suppressing and generalising attributes to achieve k-anonymity, the dataset becomes smaller and simpler, leading to fewer computations during model training and therefore lower energy consumption.
- Core assumption: The energy savings from reduced dataset size outweigh any additional computational overhead from the anonymisation process itself.
- Evidence anchors:
  - [abstract] "models trained on k-anonymised data consume less energy than models trained on the original data"
  - [section] "the run time and energy consumption decrease as we increase our k-value"
- Break condition: If the anonymisation process becomes computationally intensive relative to the training phase, or if suppression removes too much data to be useful.

### Mechanism 2
- Claim: Synthetic data generation consumes more energy than k-anonymisation due to its computational complexity.
- Mechanism: Creating synthetic data requires analyzing the entire dataset to learn probability distributions and correlations, which is computationally expensive and energy-intensive.
- Core assumption: The energy cost of learning data distributions and generating synthetic samples is significantly higher than the cost of applying suppression and generalisation rules.
- Evidence anchors:
  - [section] "creating synthetic data requires a higher run time than anonymising to obtain k-anonymity" and "energy consumption is nearly 4 times higher for synthetic data"
  - [corpus] "no work has been conducted on comparing synthetic data with k-anonymised data looking at both accuracy and energy consumption" (indicating this is an underexplored area)
- Break condition: If synthetic data generation techniques become more efficient or if the analysis phase can be parallelized effectively.

### Mechanism 3
- Claim: The energy consumption reduction in k-anonymised data training is correlated with increased data suppression.
- Mechanism: As the k-value increases, more data attributes are suppressed to meet the anonymity requirement, reducing the dataset's complexity and therefore the energy required for model training.
- Core assumption: Energy consumption is primarily determined by the amount of data processed, and suppression directly reduces this amount.
- Evidence anchors:
  - [section] "we observe that the run time and energy consumption decrease as the chosen k-value increases" and "most of the decrease in energy consumption can be related to the suppression of data"
  - [corpus] "the amount of suppressed data lies between 19%-32%" for k-anonymised datasets
- Break condition: If other factors (like model architecture changes or optimization techniques) have a greater impact on energy consumption than data size.

## Foundational Learning

- Concept: Intel RAPL (Running Average Power Limit) energy measurement
  - Why needed here: The study relies on RAPL sensors to measure CPU and DRAM energy consumption during ML training, providing the empirical basis for energy consumption comparisons
  - Quick check question: What hardware requirement must be met to use RAPL for energy measurements?

- Concept: k-anonymity and data suppression
  - Why needed here: Understanding how k-anonymity works (through generalisation and suppression) is essential to grasp why it affects energy consumption and accuracy
  - Quick check question: How does increasing the k-value in k-anonymity typically affect the amount of data suppression?

- Concept: Synthetic data generation techniques
  - Why needed here: The comparison between synthetic data and k-anonymised data requires understanding how synthetic data is created and why it might be computationally expensive
  - Quick check question: What is the primary computational step in synthetic data generation that makes it energy-intensive?

## Architecture Onboarding

- Component map: Data → Privacy Enhancement → ML Training → Energy Measurement → Evaluation
- Critical path: Data → Privacy Enhancement → ML Training → Energy Measurement → Evaluation
- Design tradeoffs:
  - Accuracy vs. energy consumption: k-anonymisation generally provides better accuracy with lower energy consumption compared to synthetic data
  - Privacy level vs. data utility: Higher k-values provide better privacy but result in more suppression and potentially lower accuracy
  - Computational overhead vs. measurement accuracy: RAPL provides good correlation with actual power measurements but may miss some system-level energy consumption
- Failure signatures:
  - RAPL measurements showing unrealistic values (check hardware compatibility)
  - Energy consumption not decreasing with higher k-values (check suppression implementation)
  - Accuracy improvements with k-anonymisation (may indicate data selection bias or need to verify ground truth)
- First 3 experiments:
  1. Measure baseline energy consumption and accuracy on original Adult dataset with all three ML models
  2. Apply k-anonymisation with k=3 to the Adult dataset and measure energy consumption and accuracy changes
  3. Generate synthetic data from the Adult dataset and compare energy consumption and accuracy to both original and k-anonymised versions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the accuracy of machine learning models trained on k-anonymised data compare to those trained on synthetic data across different data types and sizes?
- Basis in paper: [explicit] The paper mentions that models trained on k-anonymised data have higher accuracy compared to models trained on synthetic data, but also notes that this is dependent on the size of the data set and whether suppressing the data set is a decision factor.
- Why unresolved: The paper only uses two data sets and does not explore different data types and sizes, which could affect the accuracy comparison.
- What evidence would resolve it: Conducting experiments with multiple data sets of varying sizes and types to compare the accuracy of models trained on k-anonymised data versus synthetic data.

### Open Question 2
- Question: What is the impact of feature selection on the accuracy and energy consumption of machine learning models trained on k-anonymised data?
- Basis in paper: [inferred] The paper suggests that the higher accuracy of models trained on k-anonymised data could be due to a preselection of data, and mentions that actively using feature selection in the anonymisation process could lead to increased privacy with the least possible information loss.
- Why unresolved: The paper does not explore the impact of feature selection on the accuracy and energy consumption of machine learning models trained on k-anonymised data.
- What evidence would resolve it: Conducting experiments that involve using feature selection in the anonymisation process and comparing the accuracy and energy consumption of models trained on the resulting data to those trained on original or other anonymised data.

### Open Question 3
- Question: How do different privacy-enhancing techniques, such as micro-aggregation, compare to k-anonymity and synthetic data in terms of accuracy and energy consumption?
- Basis in paper: [explicit] The paper mentions that micro-aggregation is left out as recent work suggests that anonymisation by generalisation and suppression has less loss of accuracy, implying that other privacy-enhancing techniques were considered but not explored.
- Why unresolved: The paper focuses only on k-anonymity and synthetic data, without exploring other privacy-enhancing techniques.
- What evidence would resolve it: Conducting experiments with different privacy-enhancing techniques, such as micro-aggregation, and comparing their accuracy and energy consumption to those of k-anonymity and synthetic data.

## Limitations

- The study uses only two datasets and three ML models, limiting generalizability across domains
- Energy measurements focus only on CPU and DRAM via RAPL sensors, potentially missing other system-level energy costs
- The comparison between k-anonymisation and synthetic data is limited, as no prior work has comprehensively compared these techniques on both accuracy and energy consumption metrics

## Confidence

**High Confidence**: The finding that k-anonymisation reduces energy consumption while maintaining accuracy is well-supported by the experimental results. The correlation between higher k-values and lower energy consumption is clearly demonstrated across multiple datasets and models.

**Medium Confidence**: The comparison between k-anonymised and synthetic data shows similar trends, but the synthetic data generation process appears significantly more energy-intensive. However, the sample size and dataset diversity are limited, which affects generalizability.

**Low Confidence**: The paper's claims about broader implications for privacy-enhancing techniques in ML are not fully substantiated, as the study doesn't explore alternative anonymisation methods or different types of synthetic data generation approaches.

## Next Checks

1. **Dataset Diversity Test**: Replicate the experiments with additional datasets from different domains (healthcare, finance, etc.) to verify if the energy-accuracy trade-offs hold across varied data characteristics.

2. **Energy Measurement Validation**: Cross-validate RAPL measurements with external power meters to confirm that CPU and DRAM measurements accurately represent total system energy consumption during ML training.

3. **Alternative Techniques Comparison**: Test additional privacy-preserving methods (such as differential privacy or federated learning) to establish whether k-anonymisation consistently provides the best energy-accuracy balance.