---
ver: rpa2
title: Follow-on Question Suggestion via Voice Hints for Voice Assistants
arxiv_id: '2310.17034'
source_url: https://arxiv.org/abs/2310.17034
tags:
- hints
- questions
- hint
- question
- voice
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the novel task of generating voice-friendly
  hints to suggest follow-up questions for voice assistants. The key insight is that
  questions should be transformed into subordinate clauses in reported speech format
  and embedded in a natural utterance.
---

# Follow-on Question Suggestion via Voice Hints for Voice Assistants

## Quick Facts
- arXiv ID: 2310.17034
- Source URL: https://arxiv.org/abs/2310.17034
- Reference count: 36
- Key outcome: A two-stage pretraining approach for generating voice-friendly hints significantly outperforms baselines, achieving up to 91% syntactic correctness and 87% question retention in human evaluations.

## Executive Summary
This paper introduces a novel task of generating voice-friendly hints to suggest follow-up questions for voice assistants. The key insight is that questions should be transformed into subordinate clauses in reported speech format and embedded in natural utterances. To address this, the authors propose a two-stage approach: pretraining a seq2seq model to convert questions into reported speech, followed by fine-tuning for full hint generation. This strategy enables the model to focus on anaphora and coherence. A new dataset of 6,681 question triples and human-written hints is created. Evaluation on automated metrics and human studies shows the pretraining approach significantly outperforms baselines, producing more natural and memorable hints.

## Method Summary
The method employs a two-stage training pipeline using a sequence-to-sequence transformer model (BART or T5). First, the model is pretrained on converting individual questions into reported speech format using a subset of the data. Then, it is fine-tuned for full hint generation, taking an initial question and related questions as input and producing a voice-friendly hint as output. The approach leverages linguistically-motivated transformations, including converting questions to subordinate clauses and resolving anaphora, to create hints that sound natural in voice interactions.

## Key Results
- The pretraining approach significantly outperformed end-to-end training baselines in human evaluations of hint naturalness and coherence.
- Generated hints achieved up to 91% syntactic correctness and 87% question retention in human assessments.
- The model successfully learned to transform questions into subordinate clauses and embed them in declarative sentences, creating voice-friendly hints.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pretraining on converting individual questions to reported speech format significantly improves hint naturalness and coherence.
- Mechanism: By first learning the complex syntactic transformations required to convert direct questions into subordinate clauses in reported speech, the model can then focus on anaphora resolution and coherence during fine-tuning.
- Core assumption: The syntactic transformations needed for reported speech are transferable to the hint generation task.
- Evidence anchors:
  - [abstract]: "Our approach, which applies a linguistically-motivated pretraining task was strongly preferred by humans for producing the most natural hints."
  - [section]: "The difference in performance between PTG and DHG, demonstrates that for complex rewriting tasks, end-to-end training may be sub-optimal."
- Break condition: If the syntactic transformations in reported speech are not applicable to the hint generation task, the pretraining would not provide benefits.

### Mechanism 2
- Claim: Voice-friendly hints require transforming questions into subordinate clauses that are embedded in declarative sentences.
- Mechanism: This transformation allows the hint to reference facts or knowledge that can be asked about, rather than explicitly stating questions.
- Core assumption: Subordinate clauses in reported speech format sound more natural and are easier to comprehend in a voice setting.
- Evidence anchors:
  - [abstract]: "questions should be transformed into subordinate clauses in reported speech format and embedded in a natural utterance."
  - [section]: "The most interesting syntactic transformation is that of converting a question to a dependent clause... This resulting subordinate clause is a syntactic unit which can be used as a direct object in a declarative sentence."
- Break condition: If subordinate clauses in reported speech format do not sound natural or are not easier to comprehend in a voice setting, the transformation would not be beneficial.

### Mechanism 3
- Claim: Anaphora resolution is crucial for reducing redundancy and improving the coherence of voice-friendly hints.
- Mechanism: By replacing repeated entity mentions with appropriate anaphoric expressions, the hint becomes more concise and easier to follow.
- Core assumption: Anaphora resolution can be learned as part of the hint generation process.
- Evidence anchors:
  - [abstract]: "Our approach, which applies a linguistically-motivated pretraining task was strongly preferred by humans for producing the most natural hints."
  - [section]: "For MULTI-HINTS, annotators need to avoid repetitions and replace them with anaphora where necessary."
- Break condition: If anaphora resolution cannot be learned as part of the hint generation process, the hints may remain redundant and less coherent.

## Foundational Learning

- Concept: Reported speech and its syntactic transformations
  - Why needed here: To convert direct questions into subordinate clauses that can be embedded in declarative hints.
  - Quick check question: Can you provide an example of a direct question and its corresponding reported speech form?

- Concept: Anaphora resolution and its role in reducing redundancy
  - Why needed here: To replace repeated entity mentions with appropriate anaphoric expressions, improving hint conciseness and coherence.
  - Quick check question: Can you identify the anaphoric expressions in a given hint and explain how they replace repeated entity mentions?

- Concept: Voice-friendly characteristics of hints
  - Why needed here: To ensure that the generated hints sound natural, are easy to comprehend, and meet the criteria outlined in Table 1.
  - Quick check question: Can you list the key characteristics of a voice-friendly hint and explain why each is important?

## Architecture Onboarding

- Component map: Question -> Reported Speech Conversion -> Hint Generation -> Voice-Friendly Hint
- Critical path: The critical path is the generation of the voice-friendly hint from the input question and related questions. This involves the transformation of questions into subordinate clauses, anaphora resolution, and ensuring hint coherence.
- Design tradeoffs: The main tradeoff is between the complexity of the hint generation task and the ability of the model to learn all necessary operations end-to-end. Pretraining on reported speech helps mitigate this tradeoff by allowing the model to focus on specific aspects of hint generation during fine-tuning.
- Failure signatures: Failure modes include syntactically incorrect hints, hints that do not cover all input questions, hints with redundant entity mentions, and hints that are too long or incoherent.
- First 3 experiments:
  1. Evaluate the performance of the model on a small subset of the data using automated metrics (BLEU, ROUGE, BERTScore) and human evaluation (syntactic correctness, question coverage, pairwise hint comparison, question retention).
  2. Analyze the types of errors made by the model and identify areas for improvement, such as anaphora resolution or hint coherence.
  3. Experiment with different pretraining strategies or fine-tuning techniques to improve the model's performance on the hint generation task.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the proposed voice-friendly hint generation approach be extended to handle multi-turn conversations, where user interests and actions after each hint impact the generated hints for follow-up turns?
- Basis in paper: Inferred from the Limitations section, which mentions that the work focused only on single-turn conversations and future steps include multi-turn conversations.
- Why unresolved: The paper does not provide any insights or experiments on handling multi-turn conversations. It only acknowledges this as a limitation and potential future direction.
- What evidence would resolve it: Experiments evaluating the proposed approach on multi-turn conversation datasets and analyzing how user interests and actions impact the generated hints.

### Open Question 2
- Question: What are the implications of extending the voice-friendly hint generation approach to other languages, such as German, Korean, and Chinese, in terms of the required syntactic and semantic operations?
- Basis in paper: Inferred from the Limitations section, which mentions that the work was limited to the English language and future steps include adding other languages.
- Why unresolved: The paper does not provide any insights or experiments on extending the approach to other languages. It only acknowledges this as a limitation and potential future direction.
- What evidence would resolve it: Experiments evaluating the proposed approach on datasets in other languages and analyzing the required syntactic and semantic operations for generating voice-friendly hints in those languages.

### Open Question 3
- Question: How can large language models (LLMs) like GPT-3.5 or ChatGPT be fine-tuned for the task of voice-friendly hint generation, considering their impractical latency requirements in voice assistants?
- Basis in paper: Inferred from the Large Language Models for Voice Friendly Hint Generation section, which compares the proposed models against ChatGPT and discusses the limitations of using such models in voice assistants.
- Why unresolved: The paper does not provide any insights or experiments on fine-tuning LLMs for the task. It only acknowledges the limitations of using such models in voice assistants.
- What evidence would resolve it: Experiments evaluating the fine-tuning of LLMs on the task of voice-friendly hint generation and analyzing their performance and latency requirements in voice assistants.

## Limitations
- The dataset creation process relies heavily on Amazon Mechanical Turk annotations, which may introduce biases in how hints are written and evaluated.
- The paper reports improvements over baselines but doesn't explore how the model performs with questions from domains not seen during training.
- The two-stage training approach, while effective, may limit the model's ability to learn more complex interactions between reported speech conversion and hint coherence during end-to-end training.

## Confidence
High confidence: The core mechanism of pretraining on reported speech conversion followed by fine-tuning for hint generation is well-supported by both automated metrics and human evaluations. The significant improvements in syntactic correctness (up to 91%) and question retention (up to 87%) provide strong evidence for the approach's effectiveness.

Medium confidence: The claim that subordinate clauses in reported speech format are inherently more voice-friendly is supported by human preference data but lacks direct comparison with alternative hint formulations. The mechanism of anaphora resolution improving hint coherence is demonstrated through human evaluations but not systematically quantified.

Low confidence: The generalizability of the approach across different voice assistant domains and question types beyond the 9 domains covered in the dataset is not fully established. The paper doesn't provide sufficient evidence about how the model would perform with longer hint sequences or more complex question relationships.

## Next Checks
1. **Domain Transfer Validation**: Test the model's performance on questions from domains not included in the original dataset to assess generalizability. This would involve collecting a small validation set from completely new domains and evaluating both automated metrics and human preferences.

2. **End-to-End Training Comparison**: Conduct a systematic comparison of the two-stage approach against various end-to-end training strategies, including different pretraining objectives and fine-tuning schedules, to better understand the optimal training methodology for this task.

3. **Long-form Hint Generation**: Evaluate the model's ability to generate longer hints that combine multiple related questions into coherent narratives, testing both the syntactic correctness and user comprehension of extended hint sequences.