---
ver: rpa2
title: An XAI framework for robust and transparent data-driven wind turbine power
  curve models
arxiv_id: '2304.09835'
source_url: https://arxiv.org/abs/2304.09835
tags:
- wind
- power
- turbine
- data
- curve
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces an explainable AI (XAI) framework to investigate
  and validate strategies learned by data-driven wind turbine power curve models.
  By combining domain-specific considerations with Shapley Values, the approach enables
  an automated evaluation of machine learning models beyond standard error metrics.
---

# An XAI framework for robust and transparent data-driven wind turbine power curve models

## Quick Facts
- arXiv ID: 2304.09835
- Source URL: https://arxiv.org/abs/2304.09835
- Reference count: 40
- Key outcome: Introduces an explainable AI framework using Shapley Values and physics-informed baselines to validate data-driven wind turbine power curve models, showing that physically reasonable model strategies are better indicators of robustness than validation/test set errors.

## Executive Summary
This work introduces an explainable AI (XAI) framework to investigate and validate strategies learned by data-driven wind turbine power curve models. By combining domain-specific considerations with Shapley Values, the approach enables an automated evaluation of machine learning models beyond standard error metrics. The framework facilitates more informed model selection, demonstrates the importance of physically reasonable strategies for model generalization, and enables explanations of deviations from expected turbine output. Results show that data-driven model strategies can be better indicators for robustness than validation or test set errors, and that highly complex models are prone to learn physically implausible strategies.

## Method Summary
The framework uses Shapley Values to quantify feature contributions in data-driven models, comparing them to a physics-informed baseline (IEC model). The physical baseline models power output using binned wind speed with corrections for air density and turbulence intensity. Data-driven models include Random Forests and Artificial Neural Networks, trained on SCADA data from 4 wind turbines. Shapley explanations are computed using domain-specific reference points: minimum training values for strategy validation, and wind-speed-conditioned expectations for explaining output deviations. Model strategies are evaluated using R²_phys, the correlation between data-driven and physical model attributions.

## Key Results
- Data-driven model strategies can be better indicators for robustness than validation or test set errors in non-stationary environments.
- Highly complex models are prone to learn physically implausible strategies, leading to poor generalization.
- The informed reference point (conditioned on wind speed) clearly outperforms standard reference points in terms of quantitative faithfulness of attributions.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Physically reasonable model strategies are better indicators for robustness than validation/test set errors in non-stationary environments.
- Mechanism: The XAI framework uses Shapley Values to quantify feature contributions relative to a physics-informed baseline, allowing comparison of data-driven model strategies to known physical principles. Models whose strategies align with physics are less likely to overfit spurious patterns and generalize better across changing conditions.
- Core assumption: Physical models encode fundamental constraints that hold across time and operating conditions.
- Evidence anchors:
  - [abstract] "learned strategies can be better indicators for model robustness than validation or test set errors"
  - [section V-B] "Low validation errors were not able to ensure robust models and model strategies were a much better indicator"
  - [corpus] Weak: No direct corpus neighbor support for this specific mechanism.
- Break condition: If the physical baseline model is itself inaccurate or missing key effects present in the data.

### Mechanism 2
- Claim: Physics-informed early stopping and data filtering improve the physical plausibility of data-driven models.
- Mechanism: By monitoring R2_phys during training and stopping when it peaks, or by filtering training data to exclude points where the IEC model error exceeds a threshold, the data-driven model is biased toward learning physically consistent patterns rather than noise.
- Core assumption: Physical plausibility correlates with robustness and generalization.
- Evidence anchors:
  - [section VI] "Physics-informed early-stopping : analogously to traditional early stopping... we propose monitoring model strategies during training and stopping at the 'physically most plausible' epoch"
  - [section VI] "Physics-informed data filtering... removing all data points from the training set where the IEC model error exceeds a certain threshold"
  - [corpus] Weak: No direct corpus neighbor support for these specific mechanisms.
- Break condition: If the filtering removes too much data, causing underfitting or if early stopping criteria are poorly tuned.

### Mechanism 3
- Claim: Appropriate reference points for Shapley explanations are critical for quantitatively faithful attributions in regression.
- Mechanism: Explaining deviations from expected output requires a reference point conditioned on wind speed and healthy parameter baselines (e.g., xrefi = E(xi|vw) for environmental parameters, zero for yaw misalignment). This ensures attributions match the magnitude of the true effect.
- Core assumption: The choice of reference point directly affects the faithfulness of attributions.
- Evidence anchors:
  - [section III-B] "The latter is an active subject of research... we advocate domain-specific settings for the application to wind turbine power curve models"
  - [section VII] "The informed reference point ( ˜xinformed ) is conditioned on vw: xrefi = E(xi|vw) for environmental parameters... This setting clearly outperforms both other reference points in terms of quantitative faithfulness"
  - [corpus] Weak: No direct corpus neighbor support for this specific mechanism.
- Break condition: If the conditional expectations or baseline values are poorly estimated.

## Foundational Learning

- Concept: Shapley Values and their application to regression
  - Why needed here: To quantify feature contributions in a way that sums to the prediction and allows comparison between physical and data-driven models.
  - Quick check question: How do Shapley Values ensure that the sum of attributions equals the model output minus a reference value?

- Concept: Domain-specific reference points for XAI
  - Why needed here: Standard reference points (mean input) fail to provide quantitatively faithful attributions; physics-informed baselines are required.
  - Quick check question: What is the difference between explaining relative to min(Xtr) versus a wind-speed-conditioned reference point?

- Concept: Power curve modeling and environmental effects
  - Why needed here: Understanding the physical relationships between wind speed, air density, turbulence, and power output is essential for interpreting model strategies and validating physical plausibility.
  - Quick check question: How does turbulence intensity affect turbine power output differently in regions I, II, and III of the power curve?

## Architecture Onboarding

- Component map: SCADA data -> preprocessing (filtering, normalization) -> train/test/validation split -> physical baseline model (IECbin, IECρ,TI) -> data-driven models (RF, ANNlarge, ANNsmall) -> Shapley Value computation -> evaluation (R2_phys, RMSE, attribution faithfulness)

- Critical path: 1. Preprocess SCADA data and split into train/test/validation sets 2. Train physical baseline model 3. Train data-driven models with hyperparameter search 4. Compute Shapley Values for both physical and data-driven models 5. Calculate R2_phys and evaluate model strategies 6. Apply physics-informed regularization or filtering if needed 7. Validate attributions with ground truth in controlled experiments

- Design tradeoffs: Model complexity vs. interpretability: Larger ANNs may perform better but learn less physical strategies. Computational cost of exact Shapley Values vs. approximations for large datasets. Rigor of physical baseline vs. flexibility to capture turbine-specific effects.

- Failure signatures: Low R2_phys indicates model strategy deviates from physical expectations. Poor generalization on test set despite good validation performance. Attributions with wrong sign or magnitude relative to known physical effects.

- First 3 experiments: 1. Compare R2_phys and RMSE for ANNsmall vs. ANNlarge on a single turbine to observe tradeoff between performance and physical plausibility. 2. Apply physics-informed early stopping to ANNlarge and measure changes in R2_phys and RMSE. 3. Use yaw misalignment augmentation to test quantitatively faithful attributions with different reference points.

## Open Questions the Paper Calls Out

- Question: How does the physical compliance of a model's strategy relate to its performance on data with significant measurement noise?
  - Basis in paper: [inferred] The paper suggests that physically plausible strategies lead to better generalization, but does not explicitly test this under high noise conditions.
  - Why unresolved: The study focuses on generalization in non-stationary environments, but the impact of measurement noise on the relationship between physical plausibility and performance is not explored.
  - What evidence would resolve it: Experimental results comparing model performance and strategy compliance on datasets with varying levels of measurement noise.

- Question: Can the proposed XAI framework be extended to multi-turbine systems to account for wake effects and turbine interactions?
  - Basis in paper: [explicit] The authors mention the potential for applying XAI to understand turbine interactions and wake modeling in future research.
  - Why unresolved: The current framework is applied to individual turbines and does not address the complexities of multi-turbine systems.
  - What evidence would resolve it: Implementation and validation of the XAI framework on a dataset containing multiple turbines with known wake effects and interactions.

- Question: What is the optimal balance between model complexity and physical plausibility for maximizing robustness in highly non-stationary environments?
  - Basis in paper: [inferred] The paper shows that highly complex models are prone to learn physically implausible strategies, but does not provide a clear guideline for balancing complexity and plausibility.
  - Why unresolved: While the study demonstrates the benefits of physical plausibility, it does not quantify the trade-off between model complexity and robustness.
  - What evidence would resolve it: A systematic study varying model complexity and measuring both physical plausibility and robustness across different non-stationary scenarios.

## Limitations

- The framework relies heavily on the quality of the physical baseline model; inaccuracies in the IEC model propagate to strategy validation.
- The proposed physics-informed regularization methods (early stopping, data filtering) lack systematic comparison against standard approaches.
- Attribution faithfulness depends on accurate estimation of conditional expectations for reference points, which may be challenging in low-data regions.

## Confidence

- **High Confidence**: Physical plausibility correlates with model robustness; Shapley values with domain-specific reference points improve attribution interpretability.
- **Medium Confidence**: Physics-informed regularization techniques (early stopping, data filtering) improve model strategies, though evidence is limited to single turbine case studies.
- **Low Confidence**: The exact mechanisms by which complex models learn spurious strategies remain unclear; corpus evidence for proposed XAI framework components is minimal.

## Next Checks

1. Benchmark physics-informed early stopping against standard early stopping across multiple turbines and wind farms to quantify generalization benefits.
2. Conduct ablation studies on reference point selection to confirm quantitative faithfulness gains in attribution magnitude.
3. Validate the framework's ability to detect known operational issues (e.g., yaw misalignment, sensor faults) in a controlled experiment with ground truth labels.