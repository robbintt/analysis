---
ver: rpa2
title: '"Guinea Pig Trials" Utilizing GPT: A Novel Smart Agent-Based Modeling Approach
  for Studying Firm Competition and Collusion'
arxiv_id: '2308.10974'
source_url: https://arxiv.org/abs/2308.10974
tags:
- price
- agents
- collusion
- prices
- rounds
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a Smart Agent-Based Modeling (SABM) framework
  that uses GPT-4 to simulate firm price competition and collusion. SABM is more cost-effective
  and flexible than human subject experiments and offers superior decision-making
  and communication capabilities compared to traditional ABM.
---

# "Guinea Pig Trials" Utilizing GPT: A Novel Smart Agent-Based Modeling Approach for Studying Firm Competition and Collusion

## Quick Facts
- **arXiv ID:** 2308.10974
- **Source URL:** https://arxiv.org/abs/2308.10974
- **Reference count:** 40
- **Primary result:** SABM using GPT-4 achieves tacit collusion in firm price competition, with communication accelerating collusion and raising prices closer to cartel levels.

## Executive Summary
This study introduces Smart Agent-Based Modeling (SABM), a framework that uses GPT-4 to simulate firm price competition and collusion in a Bertrand duopoly setting. SABM is presented as a cost-effective and flexible alternative to human subject experiments, offering superior decision-making and communication capabilities compared to traditional agent-based modeling. The framework demonstrates that smart agents can achieve tacit collusion without communication, converging to prices above the Bertrand equilibrium but below cartel prices. When communication is allowed, agents achieve higher-level collusion with prices close to cartel levels, and collusion forms more quickly. The study also explores the impact of different personas and market structures on collusion behavior.

## Method Summary
The study employs a Smart Agent-Based Modeling (SABM) framework using GPT-4-0314 to simulate firm price competition in a Bertrand duopoly with differentiable goods. Agents make pricing decisions based on historical price and profit data stored in a memory buffer (last 400 rounds), with reflection and learning occurring every 20 rounds. The framework tests scenarios with and without communication between agents, as well as different persona assignments to analyze behavioral differences. Key parameters include linear demand functions, product differentiation levels, and cost structures. The primary metric is the convergence of prices to stable levels above Bertrand equilibrium but below cartel prices.

## Key Results
- Smart agents consistently achieve tacit collusion without communication, converging to prices above Bertrand equilibrium (6) but below cartel prices (8).
- Communication between agents accelerates collusion formation and raises equilibrium prices closer to cartel levels, with prices stabilizing around 7.6.
- Different personas significantly influence agent behavior, with aggressive personas leading to oscillatory price patterns and periodic collusion-price war cycles.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Smart agents using GPT-4 can achieve tacit collusion without communication by exploring the price space and learning from historical outcomes.
- Mechanism: Agents iteratively set prices based on a bounded memory of past prices and profits. Over time, they converge to a stable price range above Bertrand equilibrium but below cartel prices through self-discovery of mutual benefit.
- Core assumption: GPT-4 agents possess sufficient reasoning capability to interpret price history and infer optimal strategies without explicit collusion rules.
- Evidence anchors:
  - [abstract] "in the absence of communication, smart agents consistently reach tacit collusion, leading to prices converging at levels higher than the Bertrand equilibrium price but lower than monopoly or cartel prices"
  - [section III] "Despite the absence of communication between the agents, the experiment demonstrates some anticompetitive outcomes... stabilize their price decisions at around 7, a price higher than the Bertrand equilibrium price of 6 but lower than the cartel price of 8"
  - [corpus] Weak - no direct comparison to traditional ABM learning methods found in corpus
- Break condition: If memory size is too small to capture price trends, agents may fail to converge or revert to competitive pricing.

### Mechanism 2
- Claim: Allowing communication between smart agents accelerates collusion formation and raises equilibrium prices closer to cartel levels.
- Mechanism: Agents exchange pricing strategies and deviation intentions, building trust that reduces the fear of triggering price wars. This trust encourages more frequent small price adjustments to explore higher profit equilibria.
- Evidence anchors:
  - [abstract] "When communication is allowed, smart agents achieve a higher-level collusion with prices close to cartel prices... Collusion forms more quickly with communication"
  - [section IV] "explicit communication on pricing strategies... enhance trust between the parties, reducing the likelihood of triggering a price war"
  - [corpus] Weak - corpus does not provide direct evidence of communication effects on collusion speed or price levels
- Break condition: If communication messages are ambiguous or misinterpreted, agents may distrust each other and revert to competitive pricing.

### Mechanism 3
- Claim: Persona assignments significantly influence agent behavior, with aggressive personas leading to oscillatory price patterns rather than stable collusion.
- Mechanism: Aggressive personas prompt agents to undercut rivals frequently in pursuit of individual profit maximization, creating cycles of collusion and price wars rather than convergence.
- Evidence anchors:
  - [section V] "with the aggressive persona, firms exhibit a high level of responsiveness to even minor price undercuts, easily triggering a price war... periodic collusion and price wars, where bounded oscillation is observed instead of steady convergence"
  - [abstract] "We also assigned different personas to firms to analyze behavioral differences"
  - [corpus] Weak - corpus lacks direct evidence of persona effects on agent price dynamics
- Break condition: If persona prompts are too weak or absent, agents may become passive and fail to actively explore pricing strategies.

## Foundational Learning

- Concept: Bertrand competition and collusion theory
  - Why needed here: The model builds on classic oligopoly theory to define equilibrium prices and collusion benchmarks
  - Quick check question: What price do two identical firms with zero marginal cost charge in Bertrand competition?

- Concept: Agent-based modeling with memory and learning
  - Why needed here: Smart agents require historical price and profit data to make informed decisions in repeated games
  - Quick check question: How does bounded memory (last k rounds) affect price convergence compared to full history?

- Concept: Large language model prompt engineering
  - Why needed here: GPT-4 agents rely on carefully crafted prompts to simulate firm decision-making and communication
  - Quick check question: What happens if the persona prompt is omitted from the agent initialization?

## Architecture Onboarding

- Component map: GPT-4 agents → Price decision engine → Memory buffer (last 400 rounds) → Reflection module (every 20 rounds) → Communication interface (optional)
- Critical path: Agent prompt → Price decision → Demand calculation → Profit computation → Memory update → Next round
- Design tradeoffs: Larger memory improves decision quality but increases token usage and cost; communication accelerates collusion but adds variance
- Failure signatures: Prices failing to converge, agents reverting to marginal cost pricing, excessive price oscillations indicating aggressive persona effects
- First 3 experiments:
  1. Base model without communication to verify tacit collusion convergence
  2. Model with communication enabled to test speed and level of collusion
  3. Variant with aggressive persona to observe oscillatory behavior patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the level of product differentiation (d/β) affect the stability and longevity of collusion in the SABM framework?
- Basis in paper: [explicit] The paper tests different levels of product differentiation (d/β = 0, 0.5, 1) and observes their impact on pricing behavior.
- Why unresolved: The paper shows different pricing outcomes at different levels of differentiation but doesn't quantify how stability or longevity of collusion varies across these levels.
- What evidence would resolve it: Additional experiments measuring the time to reach stable collusion, frequency of price wars, and resilience of collusion when subjected to external shocks at different d/β levels.

### Open Question 2
- Question: How do different learning rates or memory window sizes affect the convergence speed and quality of collusion in the SABM framework?
- Basis in paper: [inferred] The paper uses a fixed 400-round memory window and reflection every 20 rounds but doesn't explore alternative configurations.
- Why unresolved: The paper doesn't test how varying these parameters might impact the agents' ability to form and maintain collusion.
- What evidence would resolve it: Experiments comparing convergence speed, equilibrium prices, and price variance across different memory window sizes and learning frequency settings.

### Open Question 3
- Question: How robust is the SABM framework to variations in the underlying GPT-4 model version or other large language models?
- Basis in paper: [explicit] The paper uses GPT-4-0314 and mentions that OpenAI frequently updates their models.
- Why unresolved: The paper only tests one specific model version and doesn't explore how results might change with different model versions or alternative LLMs.
- What evidence would resolve it: Replicating key experiments using different GPT-4 versions or alternative LLMs (like Claude or Llama) to test consistency of results.

## Limitations

- The exact prompt engineering techniques and token management strategies for maintaining GPT-4 context are not specified, which could affect reproducibility.
- The specific implementation details of the "reflection and retrieve" learning mechanism remain unclear, potentially impacting the model's ability to achieve stable collusion.
- The study relies on simulated GPT-4 agents rather than real-world data, limiting external validity.

## Confidence

- **High confidence:** The basic SABM framework architecture and its ability to simulate firm competition are well-established.
- **Medium confidence:** The convergence to tacit collusion without communication and the acceleration of collusion with communication are supported by the results but need further validation.
- **Low confidence:** The specific influence of persona assignments on agent behavior patterns requires more rigorous testing across different market structures.

## Next Checks

1. **Prompt Engineering Validation:** Conduct controlled experiments varying the prompt format, persona strength, and context window size to identify optimal configurations for stable collusion convergence.
2. **Learning Mechanism Replication:** Implement and test the "reflection and retrieve" learning mechanism with different memory sizes and reflection frequencies to verify its contribution to price convergence.
3. **External Validity Test:** Compare SABM results with traditional human subject experiments and Q-learning agents in the same Bertrand duopoly setting to assess relative performance and generalizability.