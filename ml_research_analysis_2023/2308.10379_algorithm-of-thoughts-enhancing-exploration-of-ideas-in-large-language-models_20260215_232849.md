---
ver: rpa2
title: 'Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models'
arxiv_id: '2308.10379'
source_url: https://arxiv.org/abs/2308.10379
tags:
- fractional
- first
- step
- promising
- steps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Algorithm of Thoughts (AoT), a novel prompting
  strategy for large language models that guides them through algorithmic reasoning
  pathways using minimal queries. By incorporating algorithmic examples into the context,
  AoT enables LLMs to explore ideas recursively and efficiently, achieving performance
  comparable to or better than previous methods while using far fewer queries.
---

# Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models

## Quick Facts
- **arXiv ID**: 2308.10379
- **Source URL**: https://arxiv.org/abs/2308.10379
- **Reference count**: 40
- **Key outcome**: AoT achieves comparable performance to multi-query methods while using significantly fewer queries by guiding LLMs through algorithmic reasoning pathways.

## Executive Summary
Algorithm of Thoughts (AoT) is a novel prompting strategy that guides large language models through algorithmic reasoning pathways using minimal queries. By incorporating algorithmic examples into the context, AoT enables LLMs to explore ideas recursively and efficiently, achieving performance comparable to or better than previous methods while using far fewer queries. The approach demonstrates success on tasks like the game of 24 and 5x5 mini crosswords, surpassing single-query methods and rivaling tree search approaches that require hundreds of queries.

## Method Summary
AoT introduces algorithmic examples into the prompt context to guide LLM reasoning. Instead of making separate queries for each step of exploration, AoT presents examples showing how to systematically explore a problem space (like DFS or BFS), allowing the LLM to simulate this search behavior within a single generation. The method structures prompts to show complete search processes rather than just problem-solution pairs, enabling the model to internalize algorithmic patterns and apply them recursively to new problems.

## Key Results
- AoT outperforms standard prompting and CoT on the game of 24, achieving comparable success rates with fewer queries.
- On 5x5 mini crosswords, AoT matches or exceeds the performance of tree search methods like ToT while using significantly fewer queries.
- The approach demonstrates that LLMs can integrate algorithmic structure with their own heuristics, potentially finding more efficient solutions than the base algorithm itself.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AoT enables LLMs to explore multiple reasoning paths within a single generation by internalizing algorithmic search patterns, reducing the need for external tree search mechanisms.
- Mechanism: By providing in-context examples of algorithmic search processes, the LLM learns to simulate search behavior recursively during its own generation, effectively replacing external iterative queries with in-context exploration.
- Core assumption: LLMs can internalize and simulate algorithmic reasoning patterns when presented with appropriate in-context examples.
- Evidence anchors: [abstract], [section] on unified generation sweep.
- Break condition: The LLM fails to internalize the algorithmic pattern or the context window becomes insufficient to represent the full search space.

### Mechanism 2
- Claim: AoT improves reasoning efficiency by allowing the LLM to backtrack and explore alternative paths within the same generation, mimicking algorithmic search strategies.
- Mechanism: Through in-context examples that show both successful and failed search attempts, the LLM learns to evaluate and switch between reasoning paths dynamically.
- Core assumption: LLMs can evaluate the promise of partial reasoning paths and decide when to backtrack based on demonstrated patterns.
- Evidence anchors: [abstract], [section] on recursive capabilities.
- Break condition: The LLM fails to recognize when to backtrack or when the search space is too large to be represented within a single generation.

### Mechanism 3
- Claim: AoT allows LLMs to surpass the efficiency of the base algorithm it is patterned after by integrating its own heuristic reasoning.
- Mechanism: The LLM combines the structured exploration of the algorithmic example with its own learned heuristics, potentially finding more efficient paths than the algorithm itself.
- Core assumption: LLMs possess inherent heuristic capabilities that, when combined with algorithmic structure, can lead to more efficient search.
- Evidence anchors: [abstract], [section] on outperforming the base algorithm.
- Break condition: The LLM's heuristic reasoning does not improve upon the base algorithm, or the algorithmic structure overly constrains the LLM's natural reasoning abilities.

## Foundational Learning

- Concept: In-context learning
  - Why needed here: AoT relies on presenting algorithmic examples within the prompt context to guide the LLM's reasoning process.
  - Quick check question: What is the primary difference between standard prompting and in-context learning in the context of AoT?

- Concept: Recursive reasoning
  - Why needed here: AoT leverages the LLM's ability to generate and evaluate multiple reasoning steps within a single generation, simulating recursive search.
  - Quick check question: How does AoT's use of recursive reasoning differ from traditional chain-of-thought prompting?

- Concept: Tree search algorithms (DFS, BFS)
  - Why needed here: AoT is templated on tree search algorithms, using their structure to guide the LLM's exploration of reasoning paths.
  - Quick check question: What is the key difference between DFS and BFS, and how does this impact AoT's performance?

## Architecture Onboarding

- Component map: [Prompt design] → [LLM generation] → [Path evaluation] → [Solution synthesis]
- Critical path: [Prompt design] → [LLM generation] → [Path evaluation] → [Solution synthesis]
- Design tradeoffs:
  - Token efficiency vs. search completeness: Longer in-context examples may provide more guidance but consume more tokens.
  - Algorithmic structure vs. LLM autonomy: Stricter adherence to the algorithm may limit the LLM's ability to apply its own heuristics.
- Failure signatures:
  - Out-of-token error: The LLM reaches its maximum token limit without identifying a solution.
  - Expression misstep: The LLM has the correct logic but fails to articulate it coherently.
  - Non-finalization error: The LLM discovers the solution but continues searching without consolidating the finding.
- First 3 experiments:
  1. Compare AoT's performance with standard prompting and CoT on a simple reasoning task (e.g., arithmetic word problems).
  2. Test the impact of different algorithmic examples (DFS vs. BFS) on AoT's efficiency and solution quality.
  3. Evaluate AoT's performance on a more complex reasoning task (e.g., mini crosswords) and compare it to ToT and other multi-query methods.

## Open Questions the Paper Calls Out

- **Open Question 1**: Does AoT's ability to outperform DFS depend on the specific task or can it generalize to other algorithmic problem domains?
  - Basis in paper: The paper demonstrates AoT's performance on the game of 24 and mini crosswords, and discusses its potential for other tree-search tasks.
  - Why unresolved: Experiments are limited to a narrow set of tasks; the authors acknowledge the need for future work on designing token-efficient algorithmic examples for other domains.
  - What evidence would resolve it: Extensive testing of AoT on diverse algorithmic tasks beyond tree-search problems.

- **Open Question 2**: How does the choice of algorithmic examples impact AoT's performance and search efficiency?
  - Basis in paper: The authors discuss the importance of crafting token-efficient algorithmic examples and the impact of search step count within examples.
  - Why unresolved: Experiments only explore a few variations of algorithmic examples; no systematic analysis of how different example choices affect performance.
  - What evidence would resolve it: A comprehensive study comparing AoT's performance across various algorithmic examples.

- **Open Question 3**: Can AoT's "tunnel-vision" capability be further enhanced to improve search efficiency and reduce computational overhead?
  - Basis in paper: The authors mention the potential for developing adaptive mechanisms for "tunnel-vision" activation to expedite the search.
  - Why unresolved: The paper does not explore methods for enhancing AoT's ability to focus on promising search paths.
  - What evidence would resolve it: Development and evaluation of techniques to guide AoT's search more effectively.

## Limitations
- The reliance on in-context learning raises questions about scalability to more complex problems with larger search spaces.
- The opaque nature of the algorithmic examples used makes it difficult to assess whether success depends critically on specific formulations.
- The approach's performance on tasks requiring deeper or more abstract reasoning remains unclear, as experiments focus on specific domains.

## Confidence
**High Confidence**: The core claim that AoT can achieve comparable performance to multi-query methods while using fewer queries is well-supported by experimental results.

**Medium Confidence**: The claim that AoT can surpass the efficiency of the base algorithm is supported by results but relies on more speculative reasoning about genuine algorithmic improvement.

**Low Confidence**: The broader implications about LLMs' ability to internalize and extend algorithmic reasoning patterns are presented with high confidence but have limited empirical support.

## Next Checks
1. **Cross-task generalization test**: Evaluate AoT on a diverse set of reasoning tasks beyond arithmetic and crosswords, including problems requiring logical deduction, planning, or spatial reasoning.

2. **Algorithmic example ablation study**: Systematically vary the complexity and type of algorithmic examples provided in the prompt to determine how critical specific formulations are to performance.

3. **Token efficiency scaling analysis**: Measure how AoT's token efficiency scales with problem complexity by testing on progressively larger instances of the game of 24 and larger crossword grids.