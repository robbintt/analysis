---
ver: rpa2
title: 'NeFT: Negative Feedback Training to Improve Robustness of Compute-In-Memory
  DNN Accelerators'
arxiv_id: '2305.14561'
source_url: https://arxiv.org/abs/2305.14561
tags:
- training
- device
- negative
- noise
- feedback
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes Negative Feedback Training (NeFT), a novel approach
  to improve the robustness of compute-in-memory DNN accelerators against device variations.
  The method leverages multi-exit DNNs to implement negative feedback during training,
  suppressing noise-induced deviations from optimal model behavior.
---

# NeFT: Negative Feedback Training to Improve Robustness of Compute-In-Memory DNN Accelerators

## Quick Facts
- arXiv ID: 2305.14561
- Source URL: https://arxiv.org/abs/2305.14561
- Authors: 
- Reference count: 40
- Key outcome: Proposes Negative Feedback Training (NeFT) to improve DNN robustness against device variations, achieving up to 45.08% improvement in inference accuracy

## Executive Summary
This paper introduces Negative Feedback Training (NeFT), a novel approach to enhance the robustness of compute-in-memory DNN accelerators against device variations. The method leverages multi-exit DNNs to implement negative feedback during training, suppressing noise-induced deviations from optimal model behavior. By integrating early exits as intermediate classifiers with negative feedback coefficients in the loss function, NeFT effectively regularizes the backbone network against device variation noise. The approach is instantiated in two variants (OVF and IRS) and demonstrates superior performance compared to existing methods across multiple datasets and DNN architectures.

## Method Summary
NeFT introduces multi-exit blocks into DNNs and modifies the loss function to include negative feedback from early exits. During training, device variation noise is injected into weights using Gaussian distributions, and the outputs from early exits are multiplied by negative coefficients and added to the loss function. This creates a feedback loop that penalizes deviations from expected behavior at multiple layers. The method is instantiated in two variants: Oriented Variational Forward (OVF) with exponentially decaying negative feedback coefficients, and Intermediate Representation Snapshot (IRS) that uses intermediate feature representations. The approach is trained end-to-end using standard gradient descent optimization.

## Key Results
- Achieves up to 45.08% improvement in inference accuracy against device variations
- Reduces epistemic uncertainty compared to baseline methods
- Boosts output confidence and improves convergence probability
- Outperforms state-of-the-art techniques by up to 12.49% in addressing DNN robustness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Negative feedback training suppresses noise-induced deviations by introducing multi-exit constraints into the loss function.
- Mechanism: Early exits act as intermediate classifiers whose outputs, when multiplied by negative coefficients, are added to the loss function. This creates a feedback loop that penalizes deviations from expected behavior at multiple layers, thereby stabilizing training against device variation noise.
- Core assumption: Intermediate outputs from early exits can serve as reliable indicators of the final output's correctness and can effectively regularize the backbone network.
- Evidence anchors:
  - [abstract] "Our negative feedback training method surpasses state-of-the-art techniques by achieving an impressive improvement of up to 12.49% in addressing DNN robustness against device variation."
  - [section III.B] "By multiplying the outputs from these early exits with negative feedback coefficients and using it as a regularizer in the loss function, as shown in Figure 1 and equation (1), we can effectively enhance the robustness again the 'external noise'."
  - [corpus] Weak or missing - the neighbor papers do not directly discuss negative feedback training with multi-exit mechanisms.
- Break condition: If early exits do not correlate well with the final output or if the negative feedback coefficients are poorly tuned, the regularization effect diminishes and training may diverge.

### Mechanism 2
- Claim: Noise-injection training during training enables the model to learn robustness to device variations by exposing it to realistic noise patterns.
- Mechanism: Random noise sampled from the target conductance distribution is added to weights during feedforward and gradient calculations. This simulates device variations, forcing the network to adapt and become resilient to perturbations during inference.
- Core assumption: The noise distribution during training accurately reflects the actual device variation distribution encountered during inference.
- Evidence anchors:
  - [abstract] "introducing these non-ideal device behaviors in DNN training enhances robustness, but drawbacks include limited accuracy improvement, reduced prediction confidence, and convergence issues."
  - [section III.C] "During each iteration of the training process, we randomly sample an instance of variation from the Gaussian distribution specific to the target device variations. This sampled variation is then added to the weights in the feedforward process."
  - [corpus] Weak or missing - neighbor papers discuss noise-aware training but not specifically the integration with negative feedback training.
- Break condition: If the noise model does not match real device behavior or if the noise level is too high, the model may fail to converge or overfit to noise patterns.

### Mechanism 3
- Claim: Multi-exit mechanism enables observation and regulation of data flow within the neural network during training, providing additional constraints that improve robustness.
- Mechanism: By introducing multiple exits at different depths, the network generates intermediate outputs that capture feature information at various levels. These outputs, when used with negative feedback, provide multi-scale supervision that guides the backbone toward more stable solutions.
- Core assumption: Different depths in the network capture progressively more complex feature information, and this hierarchical information can be leveraged to improve training stability.
- Evidence anchors:
  - [section III.A] "The exits closer to the output of the backbone capture more intricate feature information. Choosing the location and number of exits in a DNN involves various principles [29], [30]."
  - [abstract] "By integrating early exits within the network, the model can swiftly generate predictions at shallower layers, leading to accelerated outcomes for less complex inputs."
  - [corpus] Weak or missing - neighbor papers do not discuss multi-exit mechanisms for negative feedback training.
- Break condition: If the exits are not properly positioned or if their outputs do not provide meaningful supervisory signals, the multi-scale constraints may not improve robustness and could even harm performance.

## Foundational Learning

- Concept: Compute-in-memory (CiM) architecture and non-volatile memory (NVM) device variations
  - Why needed here: Understanding how device variations affect DNN inference is crucial for appreciating the need for robust training methods.
  - Quick check question: What are the two main types of device variations that affect NVM-based CiM accelerators, and how do they impact inference accuracy?

- Concept: Noise-injection training and its limitations
  - Why needed here: The paper builds upon noise-injection training but addresses its shortcomings through negative feedback.
  - Quick check question: Why does noise-injection training sometimes lead to reduced prediction confidence and convergence issues, despite considering device variations during training?

- Concept: Multi-exit neural networks and their conventional use
  - Why needed here: The paper repurposes multi-exit networks for negative feedback rather than their traditional use in inference efficiency.
  - Quick check question: How do multi-exit networks typically differ in their training objectives compared to single-exit networks, and why is this distinction important for understanding the proposed method?

## Architecture Onboarding

- Component map:
  Backbone network -> Multi-exit blocks -> Modified loss function with negative feedback -> Noise injection module -> Optimizer

- Critical path:
  1. Forward pass: Input data flows through backbone and multi-exit blocks
  2. Noise application: Device variation noise is added to weights
  3. Loss calculation: Standard cross-entropy loss plus negative feedback from exits
  4. Backward pass: Gradients are computed using noisy weights
  5. Weight update: Weights are updated using gradient descent

- Design tradeoffs:
  - Number and placement of exits: More exits provide more feedback but increase computational overhead
  - Negative feedback coefficients: Larger coefficients provide stronger regularization but may destabilize training
  - Noise injection level: Higher noise levels improve robustness but may hinder convergence

- Failure signatures:
  - Accuracy degradation with increasing device variation
  - Model divergence during training (NaN values or exploding gradients)
  - Inconsistent performance across multiple training runs

- First 3 experiments:
  1. Implement basic noise-injection training on a simple DNN (e.g., VGG-8) and measure accuracy degradation with device variations
  2. Add multi-exit blocks to the network and verify that intermediate outputs are being generated correctly
  3. Implement negative feedback by modifying the loss function to include early exit outputs with negative coefficients, then tune the feedback coefficients to optimize performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical relationship between the number of exits and the optimal decay rate for negative feedback coefficients?
- Basis in paper: [explicit] The paper states "Since the deeper exits of the network handle more complex feature information, we assign smaller negative feedback coefficients to them" and mentions a decay rate of 0.1, but doesn't explore the relationship between the number of exits and optimal decay rate.
- Why unresolved: The paper doesn't provide theoretical analysis of how the number of exits affects the optimal decay rate for negative feedback coefficients.
- What evidence would resolve it: Mathematical derivation showing the relationship between the number of exits and optimal decay rate, or experimental results demonstrating optimal decay rates for different numbers of exits.

### Open Question 2
- Question: How does the proposed method perform with different types of noise distributions beyond Gaussian?
- Basis in paper: [explicit] The paper mentions that the method can be "suitably adapted to accommodate other sources of variations" but doesn't explore this.
- Why unresolved: All experiments use Gaussian noise distribution, and the paper doesn't investigate how the method performs with other noise distributions.
- What evidence would resolve it: Experimental results showing performance with various noise distributions (e.g., uniform, Poisson, or device-specific distributions).

### Open Question 3
- Question: What is the minimum number of exits required for the negative feedback mechanism to be effective?
- Basis in paper: [inferred] The paper uses three exits for VGG-8 and four for ResNet-18, but doesn't investigate if fewer exits could achieve similar results.
- Why unresolved: The paper doesn't explore whether the effectiveness of the negative feedback mechanism scales with the number of exits or if there's a minimum threshold.
- What evidence would resolve it: Experiments with varying numbers of exits showing the point at which the negative feedback mechanism becomes ineffective.

## Limitations

- Performance gains are demonstrated primarily on relatively small-scale DNNs (VGG-8, ResNet-18) and datasets (MNIST, CIFAR-10/100), raising questions about scalability
- The method's effectiveness is contingent on proper tuning of negative feedback coefficients, which may require extensive hyperparameter search across different models and datasets
- The generalizability of the approach to different hardware platforms and more complex DNN architectures has not been established

## Confidence

- High confidence: The theoretical foundation of using negative feedback for robustness improvement is sound, and the experimental methodology is rigorous
- Medium confidence: The quantitative results showing improvement over existing methods are convincing, but the absolute performance levels remain modest for some cases
- Low confidence: The generalizability of the approach to different hardware platforms and more complex DNN architectures has not been established

## Next Checks

1. Test NeFT on larger-scale models (e.g., ResNet-50, Vision Transformers) and more challenging datasets (e.g., ImageNet) to assess scalability
2. Evaluate the approach on different types of compute-in-memory hardware with varying device variation characteristics to verify hardware agnosticism
3. Conduct ablation studies to quantify the individual contributions of the OVF and IRS variants and determine optimal exit placement strategies