---
ver: rpa2
title: Neuron-Level Knowledge Attribution in Large Language Models
arxiv_id: '2312.12141'
source_url: https://arxiv.org/abs/2312.12141
tags:
- subvalues
- layers
- layer
- attention
- contribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for identifying important neurons
  in large language models by analyzing the residual stream. The authors propose using
  log probability increase as a contribution score to locate significant neurons,
  addressing the limitation of current methods that struggle to operate at the neuron
  level due to computational constraints.
---

# Neuron-Level Knowledge Attribution in Large Language Models

## Quick Facts
- arXiv ID: 2312.12141
- Source URL: https://arxiv.org/abs/2312.12141
- Reference count: 32
- One-line primary result: Method identifies important neurons in transformers by analyzing residual stream with log probability increase contribution scores

## Executive Summary
This paper introduces a method for identifying important neurons in large language models by analyzing the residual stream. The approach uses log probability increase as a contribution score to locate significant neurons, addressing computational limitations of current methods. The authors also propose a novel method for identifying "query neurons" that activate "value neurons" directly contributing to final predictions. The method is applied to analyze six types of knowledge across both attention and feed-forward network layers.

## Method Summary
The method analyzes the residual stream in transformers to identify important neurons using log probability increase as a contribution score. It applies static analysis to 1,000 random sentences from a medium-size decoder-only transformer language model (16 layers, 4096 FFN subvalues per layer). The approach identifies both "query neurons" that activate other neurons and "value neurons" that directly contribute to final predictions, with analysis performed across attention and feed-forward network layers.

## Key Results
- Method demonstrates superior performance compared to seven other methods across three metrics
- Successfully identifies "query neurons" that activate "value neurons" in both attention and FFN layers
- Analyzes six types of knowledge across the residual stream architecture

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method successfully locates important neurons by analyzing the residual stream and using log probability increase as a contribution score.
- Mechanism: The residual stream in transformers allows each layer's output to be directly added to previous layers' outputs. By examining the change in log probability when adding specific neurons or subvalues, the method can identify which neurons contribute most to the final prediction.
- Core assumption: The distribution change between vectors is caused by a direct addition on before-softmax values, and probabilities of tokens with larger before-softmax values will increase.
- Evidence anchors: [abstract] "They also introduce a method for identifying 'query neurons' that activate 'value neurons' directly contributing to final predictions."
- Break condition: If the distribution change in transformers is not primarily due to direct addition on before-softmax values, or if other factors significantly influence probability changes.

### Mechanism 2
- Claim: The method can identify "query neurons" that activate "value neurons" directly contributing to final predictions.
- Mechanism: By analyzing the inner products between layer outputs and FFN subvalue keys, the method can determine which previous layers and subvalues act as "queries" to activate upper FFN layers.
- Core assumption: Each previous layer's attention/FFN subvalue is a direct "query" to activate the coefficient scores of upper-layers' FFN subvalues.
- Evidence anchors: [abstract] "Additionally, since most static methods typically only identify 'value neurons' directly contributing to the final prediction, we propose a method for identifying 'query neurons' which activate these 'value neurons'."
- Break condition: If the relationship between previous layers and upper FFN layers is not primarily through query activation, or if other mechanisms significantly influence FFN subvalue activation.

### Mechanism 3
- Claim: The method demonstrates superior performance compared to seven other methods across three metrics.
- Mechanism: By using log probability increase as a contribution score and identifying both "query" and "value" neurons, the method provides a more comprehensive and accurate analysis of neuron importance compared to existing methods.
- Core assumption: Log probability increase is a more reasonable and fair contribution score compared to probability increase, especially for lower layers.
- Evidence anchors: [abstract] "The approach demonstrates superior performance compared to seven other methods across three metrics."
- Break condition: If the method does not actually outperform other methods in practice, or if log probability increase is not a more effective contribution score than other methods.

## Foundational Learning

- Concept: Residual connections in transformers
  - Why needed here: Understanding how each layer's output is directly added to previous layers' outputs is crucial for analyzing the contribution of individual neurons.
  - Quick check question: How does the residual connection mechanism affect the distribution of probabilities across tokens in the vocabulary?

- Concept: Before-softmax values and their relationship to probabilities
  - Why needed here: The method relies on analyzing before-softmax values to determine which neurons contribute most to the final prediction.
  - Quick check question: How do changes in before-softmax values affect the probabilities of different tokens?

- Concept: Log probability increase as a contribution score
  - Why needed here: This concept is central to the method's approach to identifying important neurons and subvalues.
  - Quick check question: Why is log probability increase considered a more reasonable contribution score than probability increase, especially for lower layers?

## Architecture Onboarding

- Component map: Input embedding -> Residual stream (16 transformer layers with attention and FFN modules) -> Output layer -> Vocabulary space

- Critical path:
  1. Input embedding
  2. Residual stream processing through 16 transformer layers
  3. Analysis of attention and FFN subvalues
  4. Identification of important neurons and subvalues
  5. Determination of "query" and "value" neurons

- Design tradeoffs:
  - Computational complexity vs. accuracy in neuron identification
  - Focus on neuron-level analysis vs. layer-level or module-level analysis
  - Static analysis vs. dynamic analysis during model operation

- Failure signatures:
  - Inability to identify meaningful patterns in neuron contributions
  - Inconsistent results across different input sequences
  - Poor performance compared to other neuron attribution methods

- First 3 experiments:
  1. Apply the method to a simple, well-understood transformer model to verify basic functionality
  2. Test the method on a variety of input sequences to assess consistency and robustness
  3. Compare the method's results with known important neurons in established transformer models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact mechanism by which attention layers influence upper FFN subvalues?
- Basis in paper: [explicit] The paper states "the 'queries' not only change attention scores, but also change attention values" and notes that this is more complicated than FFN layers where only coefficient scores change.
- Why unresolved: The authors acknowledge they haven't fully explored how attention layers affect upper attention subvalues, unlike their detailed analysis of FFN subvalue activation.
- What evidence would resolve it: Detailed analysis showing how attention queries affect both attention weights and values when activating upper FFN subvalues, similar to the coefficient score analysis done for FFN layers.

### Open Question 2
- Question: How generalizable are the findings about FFN subvalues working as both "value" and "query" across different model architectures and tasks?
- Basis in paper: [explicit] The authors state they only conducted experiments on a 16-layer decoder-only transformer and acknowledge this as a limitation.
- Why unresolved: The analysis is limited to one specific model architecture and task (next-word prediction), so broader applicability remains unknown.
- What evidence would resolve it: Replication of the subvalue analysis across different model sizes, architectures (encoder-decoder, non-autoregressive), and tasks (classification, summarization) to test if similar patterns emerge.

### Open Question 3
- Question: What is the optimal method for knowledge editing in LLMs given that FFN subvalues contain multiple features and can serve dual roles?
- Basis in paper: [explicit] The authors discuss the challenges of editing subvalues that serve as both "value" and "query" and may contain multiple features.
- Why unresolved: The paper identifies the problem but doesn't propose a solution for how to edit specific knowledge while preserving other functions of the subvalue.
- What evidence would resolve it: Development and validation of an editing methodology that can modify specific knowledge in FFN subvalues while minimizing impact on other features and their query roles across different tasks.

## Limitations
- Computational complexity remains a significant challenge for neuron-level analysis in larger models
- Method's reliance on log probability increase may not capture all relevant factors influencing neuron importance
- Limited experimental scope to one specific model architecture and task

## Confidence

- **High Confidence**: The basic premise that analyzing the residual stream can identify important neurons is well-established in transformer literature. The concept of using log probability increase as a contribution metric is theoretically sound.
- **Medium Confidence**: The claim of superior performance compared to seven other methods is stated but lacks specific details in the abstract. The identification of "query neurons" that activate "value neurons" represents an interesting extension but requires verification.
- **Low Confidence**: Without access to the full methodology and results, the practical effectiveness of the approach and its generalizability across different model architectures remains uncertain.

## Next Checks
1. **Implementation Verification**: Replicate the log probability increase calculation on a small, well-understood transformer model to verify the basic functionality and accuracy of the contribution scoring mechanism.

2. **Comparative Analysis**: Conduct a direct comparison of the method's performance against at least three commonly used neuron attribution methods (e.g., Integrated Gradients, LIME, or attention-based methods) on a standard benchmark dataset to validate the claimed superiority.

3. **Robustness Testing**: Test the method's consistency across different input sequences and model architectures by applying it to multiple transformer models of varying sizes and comparing the stability of identified important neurons.