---
ver: rpa2
title: 'Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher'
arxiv_id: '2310.12443'
source_url: https://arxiv.org/abs/2310.12443
tags:
- sources
- source
- query
- retrieval
- evidence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the reliability challenge in LLM-based web
  search systems, where generated results and their sources cannot be fully trusted
  due to limitations of traditional retrieval and LLM hallucination issues. The authors
  propose a novel generative retrieval framework consisting of three modules: Generator,
  Validator, and Optimizer.'
---

# Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher

## Quick Facts
- arXiv ID: 2310.12443
- Source URL: https://arxiv.org/abs/2310.12443
- Reference count: 40
- This paper proposes a generative retrieval framework that achieves 87.92% validity and 78.41% precision in source retrieval

## Executive Summary
This paper addresses the reliability challenge in LLM-based web search systems, where generated results and their sources cannot be fully trusted due to limitations of traditional retrieval and LLM hallucination issues. The authors propose a novel generative retrieval framework consisting of three modules: Generator, Validator, and Optimizer. The Generator uses intent recognition and constrained source generation to produce relevant and trustworthy online sources. The Validator performs web-based verification to extract reliable evidence from sources. The Optimizer refines unreliable sources using self-critique and online updates. Experiments show their method achieves 87.92% validity and 78.41% precision in source retrieval, outperforming state-of-the-art methods by 2.54% and 1.05% respectively, even with a smaller 7B model.

## Method Summary
The authors present a generative retrieval framework for web search that addresses LLM hallucination through three specialized modules. The Generator employs intent recognition to extract multiple latent intents from user queries, then uses constrained source generation to produce valid URLs based on pre-training corpus knowledge. The Validator performs web-based verification through evidence recognition and scoring to extract reliable content from retrieved sources. The Optimizer applies multi-strategy optimization (self-critical, online, and history mining) to refine sources and maintain reliability despite web changes. The framework demonstrates significant improvements in source validity and precision while using a smaller 7B model compared to larger models like GPT-4.

## Key Results
- Achieves 87.92% validity in source retrieval
- Achieves 78.41% precision in source retrieval
- Outperforms state-of-the-art methods by 2.54% and 1.05% respectively

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM's pre-training on web data enables direct generation of relevant URLs without retrieval
- Mechanism: LLMs memorize URL patterns and site names during pre-training on corpora like C4 and CommonCrawl, allowing constrained generation to produce valid sources
- Core assumption: The LLM's pre-training corpus contains sufficient web knowledge to generate valid URLs for most queries
- Evidence anchors:
  - [section] "Online Source Generation...during the pre-training phase of LLMs such as LLaMA [28] and Falcon [17], web data like C4 and CommonCrawl constitute 80% and 100% of their pretraining corpus respectively. These data retain valuable information like webpage URLs and names."
  - [section] "Generation Constraint...a random sampling of 100 queries from the MS MARCO dataset confirms that in an unconstrained setting, the actual accessibility of URLs produced by the Alpaca model stands at a mere 39.25%. Yet, with the imposition of appropriate constraints, this accessibility surges to a significant 71.07%."
  - [corpus] Weak evidence - corpus analysis shows relevant papers exist but doesn't validate URL generation mechanism directly
- Break condition: LLM's pre-training corpus lacks coverage for specific domains or URL structures, causing generation failure

### Mechanism 2
- Claim: Multi-strategy optimization (self-critical + online + history mining) maintains source reliability despite web changes
- Mechanism: Different optimization strategies handle different failure modes - self-critical fixes invalid sources, online finds alternatives, history mining reuses proven sources
- Core assumption: Each optimization strategy addresses distinct failure modes in source generation
- Evidence anchors:
  - [section] "Self-Critical Strategy...leverage the model's self-verification capability for web source generation, automatically updating the source list based on source accessibility and relevance"
  - [section] "History Mining Strategy...another efficient approach is to mine potential sources from historical records"
  - [section] "Online Strategy...we utilize the previously designed evidence verification module. This aids in exploring and discovering webpage sources, maximizing the retrieval of web content closely associated with user queries"
  - [table 9] Performance data showing different strategies have complementary strengths
- Break condition: Web changes outpace optimization capabilities, causing all strategies to fail simultaneously

### Mechanism 3
- Claim: Intent-based query expansion enables better source coverage than single-query retrieval
- Mechanism: Recognizing multiple intents per query generates diverse expansion queries, each retrieving different relevant sources
- Core assumption: User queries contain multiple latent intents that can be extracted and used for source generation
- Evidence anchors:
  - [section] "Intent-based Query Expansion...we devise a multi-level topic generation strategy to construct intent and query expansion directive data"
  - [section] "Assuming there are ùëõ implicit intentions ùêº = {ùêº1, ùêº2, ..., ùêºùëõ } in user query ùëÑ"
  - [table 6] Performance data showing intent recognition accuracy at 62.20% for multi-intent detection
- Break condition: Queries are too specific or ambiguous for intent extraction to work effectively

## Foundational Learning

- Concept: Constrained generation vs free-form generation
  - Why needed here: Free-form generation produces hallucinated URLs that don't exist, while constraints force generation of real domains
  - Quick check question: If asked to generate a URL for "cats", what constraint would prevent hallucinating "https://www.cats.com/behavior" when the site doesn't exist?

- Concept: Evidence scoring vs evidence recognition
  - Why needed here: Recognition identifies potential evidence sentences, scoring verifies their relevance to the query
  - Quick check question: If a sentence mentions both cats and dogs but the query is about cats, should scoring or recognition catch this mismatch?

- Concept: Multi-strategy optimization coordination
  - Why needed here: Different optimization strategies handle different failure modes, requiring coordination to avoid conflicting updates
  - Quick check question: If self-critical optimization flags a source as invalid but online optimization finds it still works, which should take precedence?

## Architecture Onboarding

- Component map:
  - Generator: Intent Recognition ‚Üí Query Expansion ‚Üí Source Generation ‚Üí URL Identification
  - Validator: Evidence Recognition ‚Üí Evidence Scoring ‚Üí Web Verification
  - Optimizer: Self-Critical ‚Üí Online ‚Üí History Mining
  - Source Pool: Query-Source-Evidence mapping storage

- Critical path: Query ‚Üí Generator ‚Üí Validator ‚Üí Source Pool ‚Üí Optimizer ‚Üí Final Sources

- Design tradeoffs:
  - Generation constraints reduce hallucination but may miss valid sources
  - Multiple optimization strategies increase reliability but add complexity
  - Evidence scoring is precise but slower than recognition-only approaches

- Failure signatures:
  - Low timeliness: Generator pre-training corpus lacks coverage
  - Low consistency: URL generation doesn't match website names
  - Low validity: Evidence scoring fails to identify relevant content

- First 3 experiments:
  1. Test generator constraints with 100 queries, measure URL accessibility with/without constraints
  2. Compare evidence recognition vs scoring on 50 documents, measure precision/recall
  3. Run single optimization strategy vs all three combined on 100 queries, measure final validity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the framework's performance scale with larger language models (e.g., 13B, 65B) in terms of source retrieval validity and precision?
- Basis in paper: [explicit] The paper discusses model scaling and its impact on the number and reliability of sources generated, noting that increasing model parameters from 7B to 13B and 65B affects the distribution and authority of generated sources.
- Why unresolved: The paper provides some insights but does not offer a comprehensive analysis of how significantly larger models would impact the framework's overall performance metrics.
- What evidence would resolve it: A detailed comparative study evaluating the framework's validity and precision across various model sizes, particularly focusing on larger models, would provide clearer insights.

### Open Question 2
- Question: What are the limitations of the current evidence recognition and scoring modules in handling ambiguous or complex queries?
- Basis in paper: [explicit] The paper mentions the use of evidence recognition and scoring modules but also notes that illusions may arise during model-generated evidence, indicating potential limitations in handling complex queries.
- Why unresolved: The paper does not delve deeply into specific scenarios where the modules might fail or struggle with complex queries, nor does it propose solutions to these limitations.
- What evidence would resolve it: Empirical testing of the modules on a diverse set of complex and ambiguous queries, along with a detailed analysis of failure cases, would highlight the limitations and areas for improvement.

### Open Question 3
- Question: How does the framework ensure the trustworthiness of sources when the underlying web content changes or becomes outdated?
- Basis in paper: [explicit] The paper discusses the Validator's role in examining the timeliness, accessibility, consistency, and validity of sources, but it does not fully address how the framework adapts to dynamic changes in web content.
- Why unresolved: The paper acknowledges the dynamic nature of online sources but does not provide a comprehensive strategy for maintaining source trustworthiness over time.
- What evidence would resolve it: A longitudinal study tracking the framework's performance over time, assessing how well it adapts to changes in web content, and identifying strategies for maintaining source credibility would provide clarity.

## Limitations

- The framework relies heavily on LLM pre-training corpus coverage, with 29% of unconstrained URLs being inaccessible
- Performance comparison with GPT-4 may be misleading due to model specialization and scale differences
- Implementation details for multi-strategy optimization coordination are sparse, making conflict resolution unclear

## Confidence

- **High confidence**: The core observation that unconstrained LLM generation produces mostly invalid URLs (39.25% accessibility) is well-supported by empirical data
- **Medium confidence**: The claim that the 7B model outperforms GPT-4 in source validity and precision, while true, requires context about model specialization and task design
- **Medium confidence**: The mechanism explanations are logically coherent but lack detailed ablation studies showing the individual contribution of each component

## Next Checks

1. Conduct an ablation study removing each optimization strategy (self-critical, online, history mining) to quantify their individual contributions to the 87.92% validity score
2. Test the system on queries from domains underrepresented in pre-training corpora (medical, legal, technical) to assess the limits of the URL generation mechanism
3. Implement a time-based evaluation where the same queries are run weekly to measure how quickly web changes degrade the 78.41% precision score