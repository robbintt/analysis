---
ver: rpa2
title: A Planning Ontology to Represent and Exploit Planning Knowledge for Performance
  Efficiency
arxiv_id: '2307.13549'
source_url: https://arxiv.org/abs/2307.13549
tags:
- planning
- ontology
- domain
- planner
- planners
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a planning ontology that captures concepts
  and relationships in automated planning, enabling efficient extraction of domain,
  problem, and planner properties. Two use cases demonstrate its utility: (1) selecting
  the best-performing planner for a domain using IPC-2011 data, where the ontology-based
  policy outperformed random selection in 10 out of 13 domains; and (2) extracting
  domain-specific macro operators from plan statistics to improve planner efficiency,
  reducing nodes expanded by up to 98% in blocksworld and gripper domains.'
---

# A Planning Ontology to Represent and Exploit Planning Knowledge for Performance Efficiency

## Quick Facts
- arXiv ID: 2307.13549
- Source URL: https://arxiv.org/abs/2307.13549
- Reference count: 15
- Key outcome: Planning ontology captures planning concepts and relationships, enabling efficient extraction of domain, problem, and planner properties. Demonstrated utility in planner selection (10/13 domains improved) and macro-operator extraction (up to 98% node reduction).

## Executive Summary
This paper introduces a planning ontology that captures concepts and relationships in automated planning, enabling efficient extraction of domain, problem, and planner properties. Two use cases demonstrate its utility: (1) selecting the best-performing planner for a domain using IPC-2011 data, where the ontology-based policy outperformed random selection in 10 out of 13 domains; and (2) extracting domain-specific macro operators from plan statistics to improve planner efficiency, reducing nodes expanded by up to 98% in blocksworld and gripper domains. The ontology and resources are made publicly available to support further research.

## Method Summary
The approach involves constructing a planning ontology with 19 classes and 25 object properties, then populating it with IPC competition data and PDDL domain/problem information. The system uses SPARQL queries to extract insights for planner selection and macro-operator extraction. For planner selection, the ontology maps historical performance to domain characteristics. For macro extraction, the ontology stores plans as structured data, enabling analysis of action pair frequencies and dependencies to identify valid macro-operators that can be reused in planning.

## Key Results
- Ontology-based planner selection outperformed random selection in 10 of 13 IPC domains
- Macro-operator extraction reduced nodes expanded by up to 98% in blocksworld and gripper domains
- Planning ontology and associated resources made publicly available on GitHub

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The ontology enables systematic retrieval of best-performing planners for specific domains by mapping planner performance to domain characteristics.
- Mechanism: The ontology captures planner performance metadata from IPC results, classifying planners as having low/medium/high relevance to domains based on the percentage of problems solved. SPARQL queries then retrieve the most relevant planners for a given domain.
- Core assumption: Past IPC performance correlates with future planner effectiveness on similar domains.
- Evidence anchors:
  - [abstract] "the ontology can lead to the selection of promising planners"
  - [section 5] "The ontology for planning aims to capture the connection between the Planning Domain and the Planner by indicating the relevance of a planner to a specific domain."
  - [corpus] Weak - no direct corpus evidence of planner relevance classification.
- Break condition: If domain characteristics change significantly or new planners emerge with different strengths, the historical relevance mapping becomes obsolete.

### Mechanism 2
- Claim: The ontology improves planner performance by extracting and utilizing macro-operators that represent common action sequences.
- Mechanism: The ontology stores plans as structured data, enabling analysis of action pair frequencies and dependencies. Valid macro-operators (sequences where the first action enables the precondition of the second) are extracted and stored back in the ontology as MacroAction instances.
- Core assumption: Common action sequences in successful plans represent valid, reusable planning patterns.
- Evidence anchors:
  - [abstract] "extracting domain-specific macros - which are action orderings and show that they can improve planner performance drastically"
  - [section 5] "We examined these plans to identify the sequences of action pairs and ranked them based on their frequency of occurrence."
  - [corpus] Weak - no corpus evidence of macro-operator extraction methodology.
- Break condition: If extracted macro-operators introduce too much branching (increasing search width), they may degrade performance rather than improve it.

### Mechanism 3
- Claim: The ontology enables knowledge reuse across planning domains through standardized representation and FAIR principles compliance.
- Mechanism: By representing planning concepts, domains, problems, plans, and planners in a structured ontology with persistent URLs and open resources, the system promotes interoperability and reuse of planning knowledge across research and applications.
- Core assumption: Standardized representation enables effective knowledge sharing and reuse.
- Evidence anchors:
  - [abstract] "make the planning ontology and associated resources available to the community to promote further research"
  - [section 4.3] "We have taken various measures to ensure that our planning ontology follows the FAIR principles"
  - [corpus] Weak - no corpus evidence of FAIR compliance impact.
- Break condition: If the ontology structure becomes too rigid or doesn't accommodate new planning paradigms, it may hinder rather than help knowledge sharing.

## Foundational Learning

- Concept: Automated Planning Fundamentals (planning domains, problems, actions, states)
  - Why needed here: The ontology is built around planning concepts, so understanding what planning domains, problems, actions, and states are is essential for comprehending the ontology structure and use cases.
  - Quick check question: What are the five components of the formal definition of automated planning as a tuple (S, A, T, I, G)?

- Concept: Ontology Structure and SPARQL Querying
  - Why needed here: The paper demonstrates using SPARQL queries to extract information from the planning ontology. Understanding ontology classes, properties, and SPARQL syntax is necessary to work with this system.
  - Quick check question: How would you write a SPARQL query to find all planners with high relevance to a given domain?

- Concept: International Planning Competition (IPC) Data and Benchmarks
  - Why needed here: The ontology is populated with IPC data, and the use cases rely on understanding IPC performance metrics and planner rankings.
  - Quick check question: What types of tracks and evaluation metrics are typically included in the International Planning Competition?

## Architecture Onboarding

- Component map: PDDL parsers -> JSON extraction -> RDF mapping -> Ontology knowledge graph -> SPARQL endpoint -> Evaluation utilities
- Critical path: For planner selection - Parse PDDL → Extract features → Populate ontology → Query for best planner → Execute planner. For macro extraction - Load plans → Analyze action sequences → Validate macro-operators → Store in ontology → Use in planning.
- Design tradeoffs: The ontology prioritizes comprehensiveness over simplicity, capturing many planning concepts but potentially increasing complexity. Using IPC data ensures quality benchmarks but may limit coverage of non-IPC domains. The macro extraction approach improves performance in some domains but can degrade it in others.
- Failure signatures: If SPARQL queries return no results, it indicates incomplete ontology population or incorrect class/property usage. If planner performance doesn't improve with macros, it suggests the extracted macros are invalid or introduce too much branching. If the system is slow, it may indicate inefficient query patterns or large knowledge graph size.
- First 3 experiments:
  1. Load a simple PDDL domain (like blocksworld) and verify the ontology correctly captures actions, predicates, and requirements using SPARQL queries.
  2. Populate the ontology with IPC-2011 data and test the planner selection policy by comparing random vs. ontology-based planner selection on sample problems.
  3. Extract macro-operators from plans in a domain (like blocksworld) and verify they reduce node expansion in planner performance tests.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the planning ontology be extended to handle temporal and probabilistic planning domains beyond the current PDDL representation?
- Basis in paper: [explicit] The paper states "However, the ontology is not limited to the PDDL representation or domains in IPC and can easily be extended to any."
- Why unresolved: The paper demonstrates the ontology's current capabilities but does not provide implementation details or evaluation for temporal and probabilistic extensions.
- What evidence would resolve it: A detailed specification of ontology extensions for temporal and probabilistic features, along with empirical evaluation showing improved planner selection or performance in these domains.

### Open Question 2
- Question: Under what conditions do macro-operators extracted from plan statistics improve versus degrade planner performance?
- Basis in paper: [explicit] The paper notes "the applicability of macro operators depends on the features of the domain and the planner" and shows mixed results in driverlog domain.
- Why unresolved: While the paper demonstrates macro extraction methodology, it does not establish systematic criteria for when macros will be beneficial.
- What evidence would resolve it: A comprehensive study across diverse domains identifying characteristics (e.g., branching factor, action interdependencies) that predict macro-operator effectiveness.

### Open Question 3
- Question: How can the ontology be integrated with large language models to create a hybrid reasoning system for automated planning?
- Basis in paper: [inferred] The paper mentions future work exploring "mixed reasoning strategy with both ontologies (top-down) and Large Language Models (LLMs) (bottom-up) knowledge."
- Why unresolved: The paper identifies this as a future direction but does not propose specific integration architectures or evaluate their effectiveness.
- What evidence would resolve it: Implementation and evaluation of a system combining ontology-based reasoning with LLM-generated planning knowledge, demonstrating improved performance over either approach alone.

## Limitations

- The ontology's effectiveness depends heavily on the quality and coverage of IPC data, limiting its applicability to non-IPC domains or newer planners not represented in historical competitions.
- The macro extraction approach shows significant improvements in some domains but degraded performance in others, suggesting it may not be universally beneficial and requires domain-specific tuning.
- The planner selection mechanism assumes historical performance correlates with future effectiveness, which may not hold across different problem distributions or domain variants.

## Confidence

- Planner selection claims: Medium - Results show clear improvement in 10 of 13 domains but rely on a relatively small sample size
- Macro extraction claims: Medium-Low - The 98% improvement in blocksworld is impressive but the method failed to improve performance in several other domains
- FAIR principles compliance: Low - Conceptually supported but lacks empirical validation of actual reuse or interoperability benefits

## Next Checks

1. Test the ontology's planner selection capability on non-IPC domains to assess generalization beyond competition benchmarks.
2. Conduct systematic ablation studies to determine which ontology components contribute most to performance improvements versus overhead.
3. Implement automated evaluation to measure the impact of macro-operators across a broader range of domains and problem sizes, including analysis of when they help versus hurt performance.