---
ver: rpa2
title: Improving Mandarin Prosodic Structure Prediction with Multi-level Contextual
  Information
arxiv_id: '2308.16577'
source_url: https://arxiv.org/abs/2308.16577
tags:
- encoder
- speech
- utterance
- information
- prosodic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses prosodic structure prediction (PSP) in Mandarin
  text-to-speech synthesis, focusing on predicting prosodic word (PW), prosodic phrase
  (PPH), and intonational phrase (IPH) boundaries. While prior work mainly utilized
  intra-utterance linguistic information, this study proposes leveraging inter-utterance
  linguistic information from adjacent utterances to enhance PSP performance.
---

# Improving Mandarin Prosodic Structure Prediction with Multi-level Contextual Information

## Quick Facts
- arXiv ID: 2308.16577
- Source URL: https://arxiv.org/abs/2308.16577
- Reference count: 0
- Primary result: Proposed hierarchical encoder-decoder architecture with multi-level contextual information outperforms baseline models in predicting prosodic word, phrase, and intonational phrase boundaries in Mandarin TTS.

## Executive Summary
This paper addresses prosodic structure prediction (PSP) in Mandarin text-to-speech synthesis by proposing a novel hierarchical encoder-decoder architecture that leverages inter-utterance linguistic information. The model captures contextual dependencies across utterance boundaries using character, utterance, and discourse-level encoders, combined with a multi-task learning decoder that predicts prosodic word, phrase, and intonational phrase boundaries. Experiments on MOOC and audiobook datasets demonstrate superior performance compared to strong baselines in both objective F1 scores and subjective naturalness preference tests.

## Method Summary
The proposed method uses a hierarchical encoder-decoder architecture with three encoder levels: character encoder (Transformer blocks) for intra-utterance context, utterance encoder (CNN) for utterance-level aggregation, and discourse encoder (CNN) for inter-utterance linguistic information. A multi-task learning decoder then predicts three types of prosodic boundaries (PW, PPH, IPH) using conditional dependencies where higher-level predictions depend on lower-level ones. The model uses pre-trained Chinese BERT embeddings as input and processes n consecutive utterances to capture discourse-level patterns.

## Key Results
- Hierarchical encoder-decoder architecture outperforms strong BLSTM-CRF and Transformer baselines on F1 scores for all three prosodic boundary types
- Context window size of 8 utterances provides optimal balance between performance and computation
- Subjective ABX preference tests show improved naturalness in synthesized speech using the proposed method
- Model achieves consistent improvements across both MOOC and audiobook datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-level contextual information (character, utterance, discourse) improves prosodic structure prediction by capturing dependencies across utterance boundaries.
- Mechanism: The hierarchical encoder extracts progressively aggregated representations: character encoder models intra-utterance dependencies, utterance encoder pools utterance-level information, and discourse encoder integrates inter-utterance linguistic cues. This stacked representation is then used by the MTL decoder to predict prosodic boundaries more accurately.
- Core assumption: Linguistic cues influencing prosody extend beyond the current utterance, and modeling these cues improves boundary prediction.
- Evidence anchors:
  - [abstract] "Although inter-utterance linguistic information can influence the speech interpretation of the target utterance, previous works on PSP mainly focus on utilizing intrautterance linguistic information of the current utterance only."
  - [section 2.1.3] "The discourse encoder...is responsible for producing discourse representations capturing inter-utterance linguistic information."
  - [corpus] Weak evidence; related papers focus on toxicity and sentiment, not prosodic boundaries.
- Break condition: If discourse encoder representations do not improve F1 scores beyond the character+utterance encoder alone.

### Mechanism 2
- Claim: The multi-task learning (MTL) decoder improves prosodic boundary prediction by modeling hierarchical dependencies between PW, PPH, and IPH tasks.
- Mechanism: The MTL decoder uses a conditional architecture where IPH prediction depends on PPH and PW hidden states, and PPH prediction depends on PW hidden states. This sequential conditioning leverages task interdependencies to improve overall prediction accuracy.
- Core assumption: Prosodic boundaries are hierarchically structured, so higher-level boundaries depend on lower-level ones.
- Evidence anchors:
  - [abstract] "a multi-task learning (MTL) decoder then predicts prosodic boundaries from multi-level contextual information."
  - [section 2.2] "For IPH GRU, it accepts not only MLCI pjt but also hidden states from PW and IPH GRUs, and generates its hidden state HIPH pjt."
  - [corpus] No direct evidence; the corpus contains unrelated studies.
- Break condition: If removing MTL and using independent classifiers yields similar or better performance.

### Mechanism 3
- Claim: Using a context window of adjacent utterances (size n=8) provides sufficient inter-utterance context for improved prosodic prediction.
- Mechanism: By feeding n consecutive utterances into the hierarchical encoder, the model captures discourse-level patterns such as pitch declination and pause lengthening near utterance boundaries, which are not observable in isolated utterances.
- Core assumption: Discourse-level prosodic patterns exist and can be modeled by aggregating information from adjacent utterances.
- Evidence anchors:
  - [abstract] "This work proposes to use inter-utterance linguistic information to improve the performance of PSP."
  - [section 3.4] "Generally speaking, a larger window brings better prediction performance, but with diminishing returns."
  - [corpus] No direct evidence; related studies do not address prosodic prediction.
- Break condition: If increasing context window size beyond 8 does not yield significant F1 improvements.

## Foundational Learning

- Concept: Prosodic structure in Mandarin (PW, PPH, IPH)
  - Why needed here: The model predicts three types of prosodic boundaries; understanding their hierarchy is essential for designing the MTL decoder.
  - Quick check question: What is the hierarchical relationship between prosodic word (PW), prosodic phrase (PPH), and intonational phrase (IPH) in Mandarin?

- Concept: Hierarchical encoder-decoder architecture
  - Why needed here: The model uses a three-level encoder (character, utterance, discourse) to aggregate multi-level contextual information before decoding.
  - Quick check question: How does the hierarchical encoder in this model differ from a flat Transformer encoder?

- Concept: Multi-task learning (MTL) with conditional dependencies
  - Why needed here: The MTL decoder conditions higher-level prosodic boundary predictions (IPH, PPH) on lower-level ones (PW) to leverage hierarchical structure.
  - Quick check question: In the MTL decoder, which prosodic boundary prediction depends on the hidden states of the other two tasks?

## Architecture Onboarding

- Component map:
  BERT → Character Encoder → Utterance Encoder → Discourse Encoder → Concatenation → MTL Decoder → Boundary predictions

- Critical path:
  BERT → Character Encoder → Utterance Encoder → Discourse Encoder → Concatenation → MTL Decoder → Boundary predictions

- Design tradeoffs:
  - Larger context window size improves performance but increases computation linearly.
  - MTL improves overall accuracy but adds complexity in decoder design.
  - Separate encoders for utterance and discourse allow fine-grained control over context aggregation.

- Failure signatures:
  - Poor F1 scores may indicate insufficient context window size or ineffective discourse encoder.
  - Degraded naturalness in synthesized speech suggests misalignment between predicted boundaries and actual prosody.
  - Overfitting on one dataset but not the other indicates model sensitivity to domain differences.

- First 3 experiments:
  1. Compare F1 scores with and without discourse encoder to validate its contribution.
  2. Vary context window size (n=1, 2, 4, 8, 12) to find optimal trade-off between performance and computation.
  3. Remove MTL framework and use independent classifiers to measure impact of hierarchical task dependencies.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the hierarchical encoder's performance change when using different types of discourse-level information, such as topic transitions or speaker changes, instead of just adjacent utterances?
- Basis in paper: [inferred] The paper mentions using "inter-utterance linguistic information from adjacent utterances" and explores context window size, but doesn't investigate what specific discourse-level features are most beneficial or whether other types of discourse information might be more effective.
- Why unresolved: The paper focuses on using adjacent utterances within a context window but doesn't systematically explore what specific discourse features beyond adjacency are most useful for PSP.
- What evidence would resolve it: Comparative experiments testing the model with different discourse-level features (topic transitions, speaker changes, discourse markers, etc.) and measuring their impact on PSP performance would resolve this.

### Open Question 2
- Question: What is the impact of the hierarchical encoder on computational efficiency during inference, and how does it compare to simpler models when deployed in real-time TTS systems?
- Basis in paper: [inferred] The paper mentions that "bigger context window will introduce extra computation overhead during training" and notes the trade-off between performance and computation, but doesn't report on inference-time efficiency or real-time deployment considerations.
- Why unresolved: While the paper addresses training efficiency, it doesn't report inference-time performance or discuss practical deployment considerations for real-time TTS systems.
- What evidence would resolve it: Benchmarking studies comparing inference speed, memory usage, and real-time capability of the hierarchical encoder against simpler PSP models would resolve this question.

### Open Question 3
- Question: How does the proposed method perform on other languages with different prosodic structures, such as languages with lexical stress or pitch accent systems?
- Basis in paper: [inferred] The paper focuses exclusively on Mandarin Chinese, which has a tonal system rather than lexical stress. The methodology and effectiveness for languages with different prosodic characteristics remains unexplored.
- Why unresolved: The paper validates the approach only on Mandarin Chinese and doesn't investigate cross-linguistic applicability or whether the same hierarchical approach would work for languages with different prosodic features.
- What evidence would resolve it: Cross-linguistic experiments applying the same methodology to languages with different prosodic systems (English, Japanese, German, etc.) and comparing performance would resolve this question.

## Limitations
- Study focuses exclusively on Mandarin Chinese, limiting generalizability to other languages with different prosodic structures
- Manual labeling of prosodic boundaries introduces potential subjectivity and scalability concerns
- Computational cost increases linearly with context window size, creating practical constraints for real-time applications

## Confidence
- High confidence: Superiority over baseline BLSTM-CRF and Transformer models is well-supported by quantitative F1 scores and subjective preference tests
- Medium confidence: Specific contribution of each encoder component to performance improvements, though ablation studies provide reasonable evidence
- Low confidence: Assumption that discourse-level prosodic patterns generalize across different text domains

## Next Checks
1. Systematically disable each encoder component (character, utterance, discourse) to quantify their individual contributions to performance improvements and identify potential redundancies
2. Evaluate the model on additional Mandarin text domains (news, conversational speech, poetry) to assess generalizability beyond MOOC and audiobook datasets
3. Measure inference latency with varying context window sizes to establish practical limits for deployment in production TTS systems