---
ver: rpa2
title: 'Chatbot is Not All You Need: Information-rich Prompting for More Realistic
  Responses'
arxiv_id: '2312.16233'
source_url: https://arxiv.org/abs/2312.16233
tags:
- information
- language
- arxiv
- characters
- conversation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes an information-rich prompting approach to generate
  more realistic and consistent responses from large language models (LLMs) when mimicking
  fictional characters. The method incorporates five senses, attributes, emotional
  states, relationship with the interlocutor, and memories into the prompts to provide
  richer context.
---

# Chatbot is Not All You Need: Information-rich Prompting for More Realistic Responses

## Quick Facts
- arXiv ID: 2312.16233
- Source URL: https://arxiv.org/abs/2312.16233
- Reference count: 7
- Key outcome: Information-rich prompting approach improves utterance generation from LLMs with METEOR score of 0.118 and Sentence BERT score of 0.209

## Executive Summary
This paper proposes an information-rich prompting approach to generate more realistic and consistent responses from large language models when mimicking fictional characters. The method incorporates five senses, attributes, emotional states, relationship with the interlocutor, and memories into the prompts to provide richer context. A new benchmark dataset called DEAR is introduced by augmenting the Cornell Movie-Dialog Corpus with additional character information using GPT-3.5-turbo. Experiments on GPT-3.5-turbo show that combining different components of information-rich prompting improves utterance generation compared to using raw prompts.

## Method Summary
The approach enriches prompts with comprehensive character information including five senses, attributes, emotional states, relationships, and memories. When conversation logs reach a threshold, the model summarizes them into one-line summaries that are appended to a memory list, effectively managing context window limitations. The DEAR dataset is created by augmenting the Cornell Movie-Dialog Corpus with character attributes, sensory information, background context, and emotional states using GPT-3.5-turbo. The method is evaluated using METEOR and Sentence BERT metrics to compare generated utterances against ground truth responses.

## Key Results
- Information-rich prompting achieves a METEOR score of 0.118 and Sentence BERT score of 0.209
- Combining different components (senses, attributes, emotions, relationship, memories) improves generation quality compared to raw prompts
- The DEAR dataset provides a new benchmark for evaluating dialogue generation approaches with richer character context

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adding multi-sensory context to prompts enables the LLM to generate more contextually appropriate responses by grounding dialogue in physical and emotional reality.
- Mechanism: The approach enriches prompts with five senses, attributes, emotional states, relationships, and memories, creating a richer contextual representation that the model can use to produce more consistent and realistic character responses.
- Core assumption: Language models can effectively utilize structured contextual information when provided in the prompt, and that richer context leads to better generation quality.
- Evidence anchors: [abstract]: "leverage five senses, attributes, emotional states, relationship with the interlocutor, and memories"; [section 3.1]: "Information-rich prompting provides the language model with comprehensive information about the characters involved in the conversation prior to generating the next utterance"
- Break condition: If the LLM cannot effectively process or integrate the additional contextual information, or if the added complexity overwhelms the model's context window.

### Mechanism 2
- Claim: The self-memory management system maintains conversational coherence by summarizing and preserving dialogue history within the limited context window.
- Mechanism: When the conversation log reaches a threshold, the model summarizes it into a one-line summary that's appended to a memory list, effectively transitioning information from short-term to long-term storage.
- Core assumption: Language models can generate meaningful summaries of conversation history that preserve essential context for future responses.
- Evidence anchors: [section 3.2]: "When the conversation log reaches this threshold, a summarization process is initiated. The language model is instructed to condense the contents of the conversation log into a concise one-line summary"; [abstract]: "leverage five senses, attributes, emotional states, relationship with the interlocutor, and memories"
- Break condition: If the summarization process loses critical context or if the memory list becomes too large to be effectively processed.

### Mechanism 3
- Claim: Augmenting existing dialogue datasets with additional character information creates a more comprehensive benchmark for evaluating information-rich prompting approaches.
- Mechanism: The DEAR dataset augments the Cornell Movie-Dialog Corpus with attributes, sensory information, background context, and emotional states using GPT-3.5-turbo.
- Core assumption: Additional character information improves the quality of evaluation by providing richer ground truth for comparison.
- Evidence anchors: [section 4.1]: "We present an augmented version of a small portion of Movie Dialog Corpus, which we will refer to as the Dialogue-Emotion-Attributes-Relationship (DEAR) dataset"; [abstract]: "We release a new benchmark dataset"
- Break condition: If the augmented information is unreliable or if the additional complexity doesn't translate to better evaluation metrics.

## Foundational Learning

- Concept: Prompt Engineering
  - Why needed here: The entire approach relies on carefully crafted prompts that include multiple types of contextual information
  - Quick check question: What are the key components that should be included in an information-rich prompt for character mimicry?

- Concept: Context Window Management
  - Why needed here: The self-memory management system is designed to work within the limitations of LLM context windows
  - Quick check question: How does the summarization process help maintain conversational coherence within context limits?

- Concept: Evaluation Metrics for Text Generation
  - Why needed here: The paper uses METEOR and Sentence BERT to evaluate generation quality, requiring understanding of these metrics
  - Quick check question: What do METEOR and Sentence BERT measure, and why are they appropriate for this task?

## Architecture Onboarding

- Component map:
  Prompt Construction Module -> Memory Management System -> LLM Generation -> Evaluation Module

- Critical path:
  1. Load conversation history and character information
  2. Construct information-rich prompt
  3. Generate response using LLM
  4. Update memory management system
  5. Evaluate response quality

- Design tradeoffs:
  - More comprehensive prompts improve realism but increase token usage and may hit context limits
  - Frequent summarization preserves coherence but may lose important details
  - Dataset augmentation adds valuable context but introduces potential noise from unreliable sources

- Failure signatures:
  - Inconsistent character responses across turns
  - Model generating irrelevant or off-topic responses
  - Memory summaries that don't capture essential context
  - Evaluation metrics showing minimal improvement despite added complexity

- First 3 experiments:
  1. Test basic prompt engineering with single components (e.g., only emotions) vs. raw prompts
  2. Evaluate memory management by comparing responses with and without summarization
  3. Compare DEAR dataset evaluations against the original Cornell Movie-Dialog Corpus

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the inclusion of information-rich prompts impact the long-term consistency of character portrayal across extended dialogues?
- Basis in paper: [explicit] The paper mentions that maintaining a consistent conversational memory is a challenge and proposes a self-memory management technique, but it does not evaluate the long-term consistency of character portrayal.
- Why unresolved: The paper does not provide experimental results or analysis on the impact of information-rich prompts on long-term consistency across extended dialogues.
- What evidence would resolve it: Experiments comparing character portrayal consistency over long dialogues with and without information-rich prompts, using metrics like BLEU or character consistency scores.

### Open Question 2
- Question: How does the performance of the information-rich prompting approach compare to other state-of-the-art methods for generating realistic dialogue?
- Basis in paper: [inferred] The paper mentions that a comparative analysis with other state-of-the-art models has not been conducted, and it would be valuable to assess the performance against alternative methodologies.
- Why unresolved: The paper does not include any comparisons to other existing methods for generating realistic dialogue.
- What evidence would resolve it: Experiments comparing the proposed method to other state-of-the-art dialogue generation models on the same benchmark datasets, using standard evaluation metrics.

### Open Question 3
- Question: What are the potential ethical implications of using information-rich prompts, particularly regarding the generation of inappropriate content?
- Basis in paper: [explicit] The paper acknowledges that the approach significantly weakens the ethical filtering of the GPT-3.5-turbo model, potentially leading to the generation of inappropriate content, and states that a comprehensive ethical analysis is imperative.
- Why unresolved: The paper does not provide any detailed ethical analysis or discuss potential mitigation strategies for the generation of inappropriate content.
- What evidence would resolve it: A thorough ethical analysis from multiple perspectives, including the types of inappropriate content that may be generated, the potential harm, and strategies to mitigate these risks while maintaining the benefits of the approach.

## Limitations
- Data Quality Concerns: The DEAR dataset is constructed using GPT-3.5-turbo to augment the Cornell Movie-Dialog Corpus, with no independent verification of the augmented data's reliability.
- Context Window Constraints: The paper doesn't adequately explore the tradeoff between summarization frequency and information retention in the self-memory management system.
- Generalizability Issues: The evaluation is conducted exclusively on movie dialogue data using GPT-3.5-turbo, with untested effectiveness on other domains or LLM architectures.

## Confidence
- High Confidence: The basic premise that richer contextual information in prompts can improve LLM response quality is well-supported by existing literature on prompt engineering and is demonstrated through the comparative experiments in the paper.
- Medium Confidence: The specific claim that combining all five components produces superior results compared to using individual components is supported by the experimental data, though the incremental improvements are relatively modest.
- Low Confidence: The claim that the self-memory management system effectively maintains conversational coherence over extended interactions is supported by the methodology description but lacks rigorous empirical validation through controlled experiments comparing different memory management strategies.

## Next Checks
1. Conduct a human evaluation study where participants rate the consistency and realism of responses generated with information-rich prompting versus baseline approaches.
2. Apply the information-rich prompting approach to a different dialogue corpus (e.g., literature, social media conversations) and evaluate whether the same improvements in METEOR and Sentence BERT scores are observed.
3. Perform a systematic ablation study varying the summarization frequency and threshold in the self-memory management system to quantify the tradeoff between information retention and context window constraints.