---
ver: rpa2
title: 'Time Series Predictions in Unmonitored Sites: A Survey of Machine Learning
  Techniques in Water Resources'
arxiv_id: '2308.09766'
source_url: https://arxiv.org/abs/2308.09766
tags:
- learning
- data
- prediction
- water
- lstm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey examines machine learning (ML) approaches for predicting
  dynamic environmental variables in unmonitored sites, a longstanding challenge in
  water resources science. Most of the world's freshwater lacks adequate monitoring
  of critical variables needed for management.
---

# Time Series Predictions in Unmonitored Sites: A Survey of Machine Learning Techniques in Water Resources

## Quick Facts
- arXiv ID: 2308.09766
- Source URL: https://arxiv.org/abs/2308.09766
- Reference count: 28
- Primary result: LSTM remains the dominant architecture for water resource time series predictions in unmonitored sites

## Executive Summary
This survey examines machine learning approaches for predicting dynamic environmental variables in unmonitored freshwater sites, addressing a critical gap in water resources science where most global freshwater lacks adequate monitoring. The study systematically reviews entity-aware models, transfer learning, and knowledge-guided ML frameworks applied to streamflow, water quality, and other water resource predictions. Entity-aware models differentiate between locations using site characteristics alongside dynamic inputs, while transfer learning leverages data-rich source systems to predict in data-poor target systems. Knowledge-guided ML incorporates physical understanding into ML models to improve prediction accuracy and interpretability.

## Method Summary
The survey synthesizes existing literature on ML approaches for unmonitored site predictions through a comprehensive review of entity-aware models, transfer learning frameworks, and knowledge-guided ML techniques. The methodology focuses on reviewing studies that predict environmental variables in water resources using site characteristics (static attributes like geomorphology, climatology, land cover, land use) combined with dynamic physical drivers (daily meteorology, precipitation). The review particularly emphasizes pseudounmonitored site predictions where models trained on monitored sites are evaluated on held-out locations to assess generalizability.

## Key Results
- Deep learning models benefit from diverse training data spanning multiple regions rather than homogeneous subsets
- LSTM remains the dominant architecture for time series predictions in water resources applications
- Most studies focus on daily predictions in the United States using the CAMELS dataset
- Knowledge-guided ML approaches show promise for incorporating physical understanding into predictions

## Why This Works (Mechanism)
Entity-aware models work by incorporating site characteristics that capture the unique physical properties of each location, allowing models to differentiate between sites rather than learning generic patterns. Transfer learning leverages the similarity between source and target systems to transfer learned representations, enabling predictions in data-poor regions using knowledge from data-rich systems. Knowledge-guided ML integrates domain knowledge and physical constraints into ML models, improving both prediction accuracy and interpretability by ensuring predictions align with known physical processes.

## Foundational Learning
- **Entity-aware modeling**: Why needed - Different sites have unique physical characteristics that affect predictions; Quick check - Compare performance of models with vs. without site characteristic inputs
- **Transfer learning**: Why needed - Most sites lack sufficient monitoring data; Quick check - Evaluate prediction accuracy when training on data-rich vs. data-poor sites
- **Knowledge-guided ML**: Why needed - Purely data-driven models may violate physical constraints; Quick check - Assess whether incorporating physical knowledge improves prediction accuracy and interpretability
- **Site characteristics**: Why needed - Static attributes like geomorphology and land cover influence water resource dynamics; Quick check - Test sensitivity of predictions to different site characteristic inputs
- **Dynamic forcing data**: Why needed - Temporal variations in meteorology and other drivers affect water resource predictions; Quick check - Evaluate model performance with different temporal resolutions of forcing data
- **Pseudounmonitored evaluation**: Why needed - Real unmonitored sites lack ground truth for validation; Quick check - Use cross-validation framework where some sites are held out as pseudo-unmonitored

## Architecture Onboarding

**Component Map**: Dynamic forcing data + Site characteristics -> Entity-aware LSTM -> Predictions for unmonitored sites

**Critical Path**: Data preprocessing -> Site characteristic integration -> LSTM training -> Pseudounmonitored evaluation -> Performance assessment

**Design Tradeoffs**: 
- Entity-aware vs. entity-agnostic modeling: Entity-aware models can capture site-specific patterns but require more input data and may overfit
- Transfer learning source selection: Similar source sites may transfer better but limit data availability; diverse sources provide more data but may transfer poorly
- Knowledge integration level: Hard constraints ensure physical consistency but reduce model flexibility; soft constraints allow flexibility but may not enforce physical plausibility

**Failure Signatures**:
- Poor performance on held-out sites indicates overfitting to training data or insufficient model capacity
- Inconsistent predictions across similar sites suggest entity-aware components are not properly capturing site characteristics
- Physically implausible predictions indicate insufficient knowledge integration or inappropriate model architecture

**First Experiments**:
1. Implement basic LSTM model with only dynamic forcing data, compare to entity-aware version with site characteristics
2. Test transfer learning by training on subset of sites and evaluating on held-out sites
3. Compare knowledge-guided ML with physical constraints against purely data-driven approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does incorporating dynamic site characteristics (e.g., land cover, land use) improve prediction accuracy in machine learning models for unmonitored sites?
- Basis in paper: The paper discusses that site characteristics are typically treated as static in most hydrological ML models, but in reality, properties such as land cover, land use, or even climate are dynamic in nature and evolve at different time scales.
- Why unresolved: Current geospatial datasets and methods primarily represent static characteristics, and there is a lack of research on how to incorporate dynamic characteristics into ML models for unmonitored sites.
- What evidence would resolve it: Studies comparing ML models trained with static vs. dynamic site characteristics for various environmental variables in unmonitored sites, demonstrating improved prediction accuracy with dynamic characteristics.

### Open Question 2
- Question: What is the optimal training data selection strategy for building machine learning models for unmonitored sites?
- Basis in paper: The paper discusses that the optimal approach for training data selection remains unclear, with some studies showing that using all available data across heterogeneous sites is preferred, while others suggest that selecting a subset of functionally similar entities can improve performance.
- Why unresolved: The optimal training data selection strategy depends on various factors such as the prediction task, the similarity between entities, and the quality of data, and there is a lack of standardized processes for selecting optimal training data.
- What evidence would resolve it: Comparative studies evaluating different training data selection strategies for various environmental variables in unmonitored sites, demonstrating the optimal approach for different scenarios.

### Open Question 3
- Question: How can process understanding be effectively integrated into machine learning models for unmonitored sites?
- Basis in paper: The paper discusses the potential of knowledge-guided machine learning (KGML) techniques to improve prediction accuracy by incorporating domain knowledge and process-based models, but there is a lack of research on the optimal integration of process understanding into ML models for unmonitored sites.
- Why unresolved: The effectiveness of KGML techniques depends on the specific prediction task and the availability of domain knowledge, and there is a lack of standardized frameworks for integrating process understanding into ML models.
- What evidence would resolve it: Studies comparing the performance of KGML models with traditional ML models for various environmental variables in unmonitored sites, demonstrating the benefits of integrating process understanding.

## Limitations
- Geographic bias toward United States CAMELS dataset limits generalizability to other regions
- Limited coverage of variables beyond streamflow and water quality
- Publication bias may overstate LSTM performance compared to newer architectures
- Limited quantitative comparison of knowledge-guided vs. data-driven approaches

## Confidence
- High confidence: Entity-aware models using site characteristics improve predictions in unmonitored sites
- Medium confidence: Transfer learning approaches show promise but optimal transfer strategies remain unclear
- Medium confidence: Deep learning benefits from diverse training data, though the optimal data selection strategy is not established

## Next Checks
1. **Dataset Diversity Validation**: Test entity-aware LSTM models on non-CAMELS datasets from different continents to assess geographic generalizability and identify region-specific limitations.
2. **Architecture Benchmarking**: Systematically compare LSTM against attention-based architectures (Transformers, Perceiver IO) and process-based models across multiple prediction tasks to establish true performance hierarchies.
3. **Uncertainty Quantification**: Implement and validate uncertainty quantification methods (ensemble approaches, Bayesian neural networks) on selected case studies to assess their impact on prediction reliability and decision-making utility.