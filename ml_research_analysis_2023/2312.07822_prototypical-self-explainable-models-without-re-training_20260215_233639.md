---
ver: rpa2
title: Prototypical Self-Explainable Models Without Re-training
arxiv_id: '2312.07822'
source_url: https://arxiv.org/abs/2312.07822
tags:
- kmex
- prototypes
- sems
- explanations
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces KMEx, a method to convert any pre-trained
  black-box model into a prototypical self-explainable model (PSEM) without retraining.
  KMEx uses k-means clustering in the embedding space to learn class-prototypes and
  replaces the classifier with a nearest-neighbor classifier based on prototype similarity.
---

# Prototypical Self-Explainable Models Without Re-training

## Quick Facts
- arXiv ID: 2312.07822
- Source URL: https://arxiv.org/abs/2312.07822
- Authors: 
- Reference count: 24
- Key outcome: KMEx achieves classification performance comparable to the original black-box model while providing inherent interpretability without retraining.

## Executive Summary
This paper introduces KMEx, a method to convert any pre-trained black-box model into a prototypical self-explainable model (PSEM) without retraining. KMEx uses k-means clustering in the embedding space to learn class-prototypes and replaces the classifier with a nearest-neighbor classifier based on prototype similarity. The approach achieves classification performance comparable to the original black-box model while providing inherent interpretability. A novel quantitative evaluation framework is proposed, based on three predicates for SEMs: transparency, diversity, and trustworthiness. Experiments across seven datasets show that KMEx produces faithful explanations closely matching the black-box model, with minimal ghosting of prototypes (0% vs. up to 76% in other SEMs).

## Method Summary
KMEx converts pre-trained black-box models into prototypical self-explainable models by reusing the frozen encoder and replacing the classifier with a nearest-neighbor prototype-based classifier. The method extracts embeddings from the training data using the black-box encoder, applies k-means clustering per class to learn representative prototypes, and implements a nearest-neighbor classifier using log-based similarity measures. This approach maintains the original decision boundaries in the embedding space while enabling inherent interpretability through prototype-based explanations.

## Key Results
- KMEx achieves classification accuracy on par with the original ResNet34 black-box model
- KMEx produces 0% ghosting of prototypes, compared to up to 76% in other prototypical SEMs
- KMEx generates faithful local explanations with minimal divergence from black-box LRP maps

## Why This Works (Mechanism)

### Mechanism 1
- Claim: KMEx preserves black-box performance while enabling interpretability.
- Mechanism: By reusing the frozen encoder and replacing only the classifier with a nearest-neighbor prototype-based classifier, KMEx maintains the original decision boundaries in the embedding space.
- Core assumption: The embedding space learned by the black-box model is already well-separated and discriminative for the task.
- Evidence anchors:
  - [abstract]: "KMEx uses k-means clustering in the embedding space to learn class-prototypes and replaces the classifier with a nearest-neighbor classifier based on prototype similarity."
  - [section 3.1]: "Learn prototypes for each class using k-means on the embedding of the training data."
  - [corpus]: Missing evidence. Need empirical comparison between black-box and KMEx embeddings.
- Break condition: If the black-box embedding is not discriminative (e.g., overlapping class clusters), the nearest-neighbor classifier will fail to maintain performance.

### Mechanism 2
- Claim: KMEx eliminates ghosting (unused prototypes) inherently.
- Mechanism: K-means clustering assigns each training sample to exactly one prototype per class, ensuring every prototype is activated by at least one training sample.
- Core assumption: K-means with uniform cluster priors ensures full coverage of the embedding space.
- Evidence anchors:
  - [abstract]: "KMEx performs on par with its corresponding ResNet34 black-box base model, thereby validating the change of classifier."
  - [section 4.2.2]: "In the case of a distance-based similarity measure... if k = argmax_l s(z_i, p_l), then prototype p_k is the closest to z_i."
  - [corpus]: Missing evidence. Need comparison of prototype activation frequencies across methods.
- Break condition: If k-means creates empty clusters due to poor initialization or very imbalanced data, ghosting may occur.

### Mechanism 3
- Claim: KMEx produces faithful local explanations by reusing the black-box encoder.
- Mechanism: Since the encoder is frozen from the black-box model, the feature extraction process for local explanations (e.g., relevance propagation) remains identical, minimizing divergence in explanation maps.
- Core assumption: Local explanation methods (e.g., LRP, PRP) are deterministic given the same encoder weights and input.
- Evidence anchors:
  - [section 4.2.3]: "We propose to use the Kullback-Leibler (KL) divergence between the Layer-wise Relevance Propagation (LRP) maps... for the prediction probabilities produced by the SEM and the black-box baseline."
  - [section 4.1.2]: "KMEx does not produce more robust explanations on its own... most of the operations involved in the generation of local explanation maps are common to both."
  - [corpus]: Weak evidence. Need quantitative KL divergence results between black-box and KMEx explanations.
- Break condition: If the prototype-based classifier introduces non-linearities or interactions not present in the original classifier, local explanations may diverge.

## Foundational Learning

- Concept: K-means clustering in embedding spaces
  - Why needed here: To learn representative prototypes without retraining the black-box encoder.
  - Quick check question: What happens if k-means is run on the input space instead of the embedding space?
- Concept: Nearest-neighbor classification
  - Why needed here: To replace the black-box classifier while maintaining interpretability.
  - Quick check question: How does the choice of similarity measure affect classification accuracy?
- Concept: Layer-wise Relevance Propagation (LRP)
  - Why needed here: To quantitatively evaluate faithfulness of local explanations between black-box and KMEx.
  - Quick check question: Why is LRP normalization necessary before computing KL divergence?

## Architecture Onboarding

- Component map:
  Input -> Frozen Encoder (from black-box) -> Embedding Space -> K-means Prototypes -> Nearest-Neighbor Classifier -> Output
  Local Explanations: Embedding -> PRP/LRP -> Relevance Maps
- Critical path:
  1. Load pre-trained black-box encoder
  2. Extract embeddings for training data
  3. Run k-means clustering per class
  4. Implement nearest-neighbor classifier
  5. Validate performance matches black-box
- Design tradeoffs:
  - Prototype number vs. coverage: Too few prototypes may miss subclasses; too many increase computation and risk overfitting.
  - Embedding quality: KMEx inherits the black-box's embedding limitations (e.g., bias, poor generalization).
  - Interpretability vs. accuracy: Nearest-neighbor may be less smooth than learned classifiers, affecting robustness.
- Failure signatures:
  - Performance drop: Black-box embedding not discriminative enough.
  - High ghosting: K-means not covering embedding space (rare with proper initialization).
  - Explanation divergence: Encoder fine-tuning or classifier interactions altering local decision boundaries.
- First 3 experiments:
  1. Verify KMEx matches black-box accuracy on a simple dataset (e.g., MNIST) with varying prototype counts.
  2. Measure KL divergence between black-box and KMEx LRP maps to confirm explanation faithfulness.
  3. Compute Dtsp (ghosting metric) to ensure no unused prototypes exist.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does KMEx perform on very large datasets with high-dimensional embeddings where k-means becomes computationally expensive?
- Basis in paper: [explicit] The paper mentions that k-means is computed per class and on the embedding space, which usually has a reasonable number of dimensions (512 for ResNet34). For very large datasets, it can be approximated by computing k-means on a subset of the training set or by using other efficient implementations.
- Why unresolved: The paper only mentions this as a potential solution without providing experimental validation or comparing different approximation strategies.
- What evidence would resolve it: Experimental results comparing KMEx performance using different k-means approximation methods (subset sampling, efficient implementations) on large-scale datasets with high-dimensional embeddings.

### Open Question 2
- Question: Can KMEx effectively handle datasets with significant class imbalance where certain classes have far fewer samples than others?
- Basis in paper: [inferred] The paper evaluates KMEx on several datasets but doesn't explicitly test it on imbalanced datasets. The k-means clustering approach might struggle when classes have vastly different sample sizes.
- Why unresolved: The current evaluation focuses on balanced datasets, and the k-means algorithm's performance with imbalanced class distributions isn't investigated.
- What evidence would resolve it: Experimental results showing KMEx performance on intentionally imbalanced datasets, comparing it to both black-box models and other SEMs under the same conditions.

### Open Question 3
- Question: What is the optimal number of prototypes per class for KMEx across different datasets and tasks?
- Basis in paper: [explicit] The paper fixes the number of prototypes per class as 20 for CelebA and 5 for all other datasets without exploring how this choice affects performance.
- Why unresolved: The paper uses predetermined values without analyzing the impact of varying the number of prototypes on different evaluation metrics.
- What evidence would resolve it: Systematic experiments varying the number of prototypes per class across multiple datasets, analyzing the trade-off between performance, interpretability, and computational cost.

## Limitations
- The paper lacks direct empirical evidence comparing black-box and KMEx embeddings, making it unclear whether the black-box embedding space is sufficiently discriminative for the nearest-neighbor classifier to work effectively.
- While the paper claims KMEx eliminates ghosting, there is no direct comparison of prototype activation frequencies with other SEM methods, relying instead on theoretical arguments about k-means clustering.
- The explanation faithfulness claim is supported by the KL divergence methodology but lacks quantitative results showing how closely KMEx explanations match the black-box baseline.

## Confidence

**High confidence**: The mechanism of reusing a frozen encoder to maintain classification performance is theoretically sound and aligns with standard transfer learning practices.

**Medium confidence**: The claim about eliminating ghosting is plausible given k-means' assignment properties, but lacks empirical validation against other methods.

**Low confidence**: The explanation faithfulness claim requires quantitative validation, as the shared encoder does not guarantee identical local decision boundaries due to the prototype-based classifier.

## Next Checks
1. **Quantitative faithfulness validation**: Compute and report KL divergence values between black-box and KMEx LRP maps on multiple test samples to verify explanation similarity.
2. **Embedding space analysis**: Visualize and quantify the separability of class clusters in the black-box embedding space to confirm it's discriminative enough for k-means clustering.
3. **Prototype activation comparison**: Measure and compare the frequency of prototype activation across KMEx and other SEM methods to empirically verify the ghosting elimination claim.