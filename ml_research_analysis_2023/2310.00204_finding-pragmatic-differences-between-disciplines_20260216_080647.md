---
ver: rpa2
title: Finding Pragmatic Differences Between Disciplines
arxiv_id: '2310.00204'
source_url: https://arxiv.org/abs/2310.00204
tags:
- section
- work
- document
- structural
- pragmatic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper analyzes how sections of scholarly documents vary across
  disciplines using structural vocabulary and document structures. They build a classifier
  that labels sections with one of 7 types: introduction, methods, results, discussion,
  conclusion, background, and analysis.'
---

# Finding Pragmatic Differences Between Disciplines

## Quick Facts
- arXiv ID: 2310.00204
- Source URL: https://arxiv.org/abs/2310.00204
- Reference count: 10
- This paper analyzes how sections of scholarly documents vary across disciplines using structural vocabulary and document structures.

## Executive Summary
This paper presents a method to analyze and compare the structure of scholarly documents across 19 disciplines. By retrofitting section headers to a fixed set of 7 domain-agnostic types and analyzing their frequencies and transitions, the authors reveal systematic differences in how research is presented across fields. For example, Physics articles tend to introduce methods earlier and have more methods and results sections than Political Science, while Psychology papers exhibit more cyclical experiment patterns compared to the more linear structure of Sociology papers.

## Method Summary
The authors use SciBERT to embed section text (up to 25 tokens from heading and body) and classify sections based on nearest neighbor distance to averaged embeddings of each type, with type-specific thresholds. They analyze section positions and transitions, comparing frequencies and transitions between disciplines using a sample of 1k documents per discipline from the S2ORC corpus.

## Key Results
- Physics articles introduce methods earlier and have more methods and results sections than Political Science
- Psychology papers have more cyclical experiments with transitions like method→results→discussion
- Sociology papers evaluate claims more linearly compared to Psychology

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A fixed set of domain-agnostic section types can be learned and applied across 19 diverse disciplines to enable structural comparison.
- Mechanism: The authors first identify the most frequent section headings across disciplines (e.g., "introduction", "methods", "results", "discussion", "conclusion", "background", "analysis"). These are then used as labels to train a nearest-neighbor classifier based on SciBERT embeddings of section headings and their first 25 tokens of body text. This retrofitting labels each section in each document with one of these types.
- Core assumption: Section types that are frequent and appear across many disciplines are domain-agnostic enough to serve as a structural vocabulary.
- Evidence anchors:
  - [abstract] "Using a corpus of scholarly documents across 19 disciplines and state-of-the-art language modeling techniques, we learn a fixed set of domain-agnostic descriptors for document sections..."
  - [section] "Domain Independence As pointed out by Arnold et al. (2019), there exists a 'vocabulary mismatch problem' where different disciplines talk about their work in different ways. Indeed, 62% of the sampled headings only appear once and are not good choices for section types. On the other hand, the most frequent headings are a much better choice, especially those that appear in all domains."
  - [corpus] The S2ORC corpus contains 7.5M documents from 19 disciplines, providing a large and diverse dataset for deriving and validating the structural vocabulary.
- Break condition: If section headings are too discipline-specific or the most frequent headings are not truly domain-agnostic, the retrofitting classifier will fail to generalize and will have poor F1 scores.

### Mechanism 2
- Claim: Comparing section frequencies across disciplines reveals structural differences in how research is presented.
- Mechanism: After retrofitting section types, the authors compute the aggregate frequency of each section type at each position in the document (normalized by document length). This creates a 2D visualization showing how often a section type appears at each point in the article for each discipline.
- Core assumption: The normalized position of sections within a document is meaningful and comparable across disciplines.
- Evidence anchors:
  - [abstract] "Then, we analyze the position and ordering of these descriptors across documents to understand the relationship between discipline and structure."
  - [section] "To illustrate the practicality of this analysis, consider the hypothesis that Physics articles are more empirically-motivated while Political Science articles are more conceptually-motivated, i of the concrete versus abstract spectrum. We operationalize this by claiming that Physics articles have moremethods, results, and analysis sections than Political Science. Figure 1 shows the difference between Physics and Political Science at each point in the article."
  - [corpus] The 19-discipline S2ORC corpus provides enough data to compute statistically meaningful aggregate frequencies for each discipline.
- Break condition: If the normalized position metric is not comparable across documents of different lengths or structures, the aggregate frequency analysis will be misleading.

### Mechanism 3
- Claim: Analyzing transition probabilities between section types reveals sequential patterns and disciplinary differences in research presentation.
- Mechanism: The authors compute the probability of a section of type B following a section of type A for each discipline, creating a transition matrix. This reveals patterns like "method → results → discussion" cycles in Psychology vs. more linear patterns in Sociology.
- Core assumption: The sequence of section types within a document is meaningful and reflects the author's intended rhetorical structure.
- Evidence anchors:
  - [abstract] "Then, we analyze the position and ordering of these descriptors across documents to understand the relationship between discipline and structure."
  - [section] "In Table 2, we see evidence that methods sections are more likely to be preceded by results sections in Psychology than Sociology, implying a new iteration of a cycle. We might conclude that Psychology papers are more likely to have cyclical experiments, but not that Sociology papers conduct multiple experiments in a linear fashion."
  - [corpus] The S2ORC corpus contains enough documents per discipline to compute reliable transition probabilities.
- Break condition: If the sequence of sections is too variable or random within a discipline, the transition probabilities will not reveal meaningful patterns.

## Foundational Learning

- Concept: Domain-agnostic descriptors for document sections
  - Why needed here: To enable comparison of document structures across different scholarly disciplines, the section types must be meaningful and comparable across those disciplines.
  - Quick check question: What are the 7 section types used in this paper, and why were they chosen as domain-agnostic?

- Concept: Nearest-neighbor classification with language model embeddings
  - Why needed here: To automatically retrofit the large corpus of 19k documents with the domain-agnostic section types, a scalable and accurate classification method is required.
  - Quick check question: How does the nearest-neighbor classifier work, and what role does the SciBERT language model play in it?

- Concept: Aggregate frequency and transition probability analysis
  - Why needed here: These are the two main methods used to analyze and compare the structural archetypes across disciplines, revealing patterns in both the position and ordering of section types.
  - Quick check question: What is the difference between aggregate frequency and transition probability analysis, and what type of structural insight does each provide?

## Architecture Onboarding

- Component map:
  1. Corpus Ingestion: Load and parse the S2ORC corpus of scholarly documents.
  2. Section Extraction: Extract section headings and bodies from each document.
  3. Retrofitting: Classify each section with one of the 7 domain-agnostic types using a nearest-neighbor classifier with SciBERT embeddings.
  4. Analysis: Compute aggregate frequencies and transition probabilities for each discipline.
  5. Visualization: Create plots and tables to compare structural archetypes across disciplines.

- Critical path: Corpus Ingestion → Section Extraction → Retrofitting → Analysis → Visualization

- Design tradeoffs:
  - Using a fixed set of 7 section types vs. a more granular or discipline-specific set. The 7 types enable cross-disciplinary comparison but may lose some nuance.
  - Using SciBERT embeddings vs. other representations. SciBERT is good for scientific text but may not capture all relevant features for section classification.
  - Using aggregate frequency and transition probabilities vs. other structural analysis methods. These are simple and interpretable but may miss more complex patterns.

- Failure signatures:
  - Low F1 scores in the retrofitting classifier (e.g., < 0.7) indicate the section types are not truly domain-agnostic or the classifier is not accurate enough.
  - Highly variable or no clear patterns in the aggregate frequency or transition probability plots indicate the structural archetypes are not meaningful or consistent within a discipline.

- First 3 experiments:
  1. Test the retrofitting classifier on a held-out test set of manually labeled sections to measure its F1 score and identify which section types are most challenging to classify.
  2. Create the aggregate frequency plots for a subset of disciplines (e.g., Physics, Political Science, Psychology, Sociology) to visually compare their structural archetypes.
  3. Compute and analyze the transition probability matrices for the same subset of disciplines to reveal sequential patterns and disciplinary differences.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal structural vocabulary size and composition for capturing pragmatic intent across disciplines?
- Basis in paper: [explicit] The paper discusses deriving a structural vocabulary but notes that brief headings leave room for interpretation and that future work could improve the classifier with more nuanced signals.
- Why unresolved: The current vocabulary of 7 types was derived from top section headings, but there's no systematic exploration of optimal vocabulary size or whether different disciplines require different vocabularies.
- What evidence would resolve it: Experiments comparing performance across different vocabulary sizes (e.g., 5, 10, 15 types) and compositions (domain-specific vs. domain-agnostic types) on the same dataset.

### Open Question 2
- Question: How do structural archetypes correlate with research quality metrics?
- Basis in paper: [explicit] The authors mention future directions include "learning relationships between structures and measures of research quality, such as reproducibility."
- Why unresolved: The paper establishes methods for analyzing structural archetypes but does not investigate any relationships with quality measures.
- What evidence would resolve it: Statistical analysis correlating structural features (section frequencies, transition probabilities) with established quality metrics like citation counts, reproducibility scores, or peer review ratings.

### Open Question 3
- Question: Can structural archetypes be used for cross-disciplinary knowledge transfer or style transfer?
- Basis in paper: [explicit] The authors mention "domain style transfer" as a future direction for this work.
- Why unresolved: While the paper demonstrates differences in structural archetypes between disciplines, it does not explore whether these differences can be exploited for practical applications like converting a Physics paper structure to a Political Science structure.
- What evidence would resolve it: Development and evaluation of models that can transform the structure of a paper from one discipline to another while preserving semantic content, with human evaluation of the transformed papers' comprehensibility and persuasiveness.

## Limitations

- The use of a fixed set of 7 section types may not capture all the nuance and variation in how different disciplines structure their research.
- The reliance on SciBERT embeddings and nearest-neighbor classification, while effective, may not be the optimal approach for this task.
- The analysis focuses on the position and ordering of sections, but does not consider other structural features like the content or length of sections.

## Confidence

This analysis has **medium confidence** in its core findings.

Key uncertainties:
- Optimal choice of section types
- Effectiveness of the retrofitting classifier
- Reliability of the aggregate frequency and transition probability analyses

To address these uncertainties:
1. Conduct a thorough evaluation of the retrofitting classifier on a held-out test set of manually labeled sections to measure its F1 score and identify areas for improvement.
2. Explore alternative structural analysis methods, such as topic modeling or network analysis, to complement the aggregate frequency and transition probability analyses.
3. Expand the sample size and diversity of documents within each discipline to ensure the results are robust and generalizable.

## Next Checks

1. Test the retrofitting classifier on a held-out test set of manually labeled sections to measure its F1 score and identify which section types are most challenging to classify.
2. Create the aggregate frequency plots for a subset of disciplines (e.g., Physics, Political Science, Psychology, Sociology) to visually compare their structural archetypes.
3. Compute and analyze the transition probability matrices for the same subset of disciplines to reveal sequential patterns and disciplinary differences.