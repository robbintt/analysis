---
ver: rpa2
title: 'MapperGPT: Large Language Models for Linking and Mapping Entities'
arxiv_id: '2310.03666'
source_url: https://arxiv.org/abs/2310.03666
tags:
- mappergpt
- mapping
- methods
- mappings
- ontology
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MapperGPT is a method for refining semantic entity mappings between
  ontologies using Large Language Models (LLMs) as a post-processing step after high-recall
  lexical matching. The method takes candidate mappings from tools like LOOM and uses
  GPT models to categorize and filter them into categories like exact match, broader/narrower
  match, related, or different.
---

# MapperGPT: Large Language Models for Linking and Mapping Entities

## Quick Facts
- arXiv ID: 2310.03666
- Source URL: https://arxiv.org/abs/2310.03666
- Reference count: 0
- Primary result: GPT-4-based LLM improves ontology mapping F1 score to 67% vs 53% for LogMap

## Executive Summary
MapperGPT is a method for refining semantic entity mappings between ontologies using Large Language Models (LLMs) as a post-processing step after high-recall lexical matching. The method takes candidate mappings from tools like LOOM and uses GPT models to categorize and filter them into categories like exact match, broader/narrower match, related, or different. This improves precision while maintaining high recall. On four challenging alignment tasks across anatomy, developmental biology, and renal diseases, MapperGPT with GPT-4 achieved 67% F1 score, outperforming state-of-the-art LogMap (53%) and other baselines.

## Method Summary
MapperGPT processes candidate mappings from high-recall lexical methods by generating detailed descriptions of each concept using ontology properties (definitions, synonyms, relationships), then sending these descriptions along with in-context examples to GPT-4 for categorization. The LLM returns refined mappings categorized as exact matches, broader/narrower matches, related, or different. The method iterates through all candidate mappings, using GPT-4 to filter out false positives while retaining true matches, resulting in improved precision without sacrificing much recall.

## Key Results
- GPT-4 achieves 67% F1 score on exact match predictions across four test sets
- Outperforms LogMap (53% F1) and other lexical baselines
- Maintains high recall from initial lexical matching while substantially improving precision
- Demonstrates consistent performance across anatomy, developmental biology, and renal disease domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 improves mapping precision by leveraging contextual semantic understanding beyond lexical similarity.
- Mechanism: The LLM parses rich descriptions of each concept (name, synonyms, definition, relationships) and uses this contextual information to judge semantic similarity, enabling it to detect mismatches that lexical matching would miss (e.g., "embryonic/larval Malpighian tubule Type I cell" vs. "caudal commissure").
- Core assumption: GPT-4 can extract and integrate the semantic relationships and definitions from ontology descriptions to make accurate judgments about concept similarity.
- Evidence anchors:
  - [abstract] "Large Language Models (LLMs), such as the ones employed by ChatGPT, have generalizable abilities to perform a wide range of tasks, including question-answering and information extraction."
  - [section] "The method expects a set of candidate mappings with potentially numerous false positives as an input, and then uses a GPT model to review and refine those mappings as a post-processing step, essentially for the purpose of isolating and removing false positive mappings."
  - [corpus] Weak evidence - no direct citations to GPT-4 specifically performing semantic matching tasks.

### Mechanism 2
- Claim: The method achieves high recall by starting with high-recall lexical matching tools and then refining results with LLM.
- Mechanism: The system first uses tools like LOOM to generate a comprehensive set of candidate mappings (high recall, low precision), then uses GPT-4 to filter out false positives while retaining true matches, resulting in improved precision without sacrificing much recall.
- Core assumption: The initial high-recall lexical method captures most true positive mappings, even if it also generates many false positives that can be filtered by the LLM.
- Evidence anchors:
  - [section] "The method expects a set of candidate mappings with potentially numerous false positives as an input, and then uses a GPT model to review and refine those mappings as a post-processing step."
  - [section] "We show that when used in combination with high-recall methods such as LOOM or OAK Lexmatch, MapperGPT can provide a substantial improvement in mapping accuracy, surpassing SOTA methods such as LogMap."
  - [corpus] No direct evidence - the claim about high-recall initial methods is supported by the methodology but not independently verified in the corpus.

### Mechanism 3
- Claim: GPT-4's zero-shot learning capability allows it to perform mapping tasks without task-specific training data.
- Mechanism: The LLM uses in-context examples and the detailed concept descriptions provided in the prompt to understand the mapping task and make judgments about semantic relationships between concepts.
- Core assumption: GPT-4 can generalize from a few in-context examples and the provided concept descriptions to perform the mapping task accurately.
- Evidence anchors:
  - [section] "The most recent development in LMs are instruction-tuned Large Language Models (LLMs), exemplified by ChatGPT, which involve billions of parameters and pre-training on instruction-prompting tasks. The resulting models have generalizable abilities to perform a wide range of tasks, including question-answering and information extraction."
  - [section] "Given their performance on any tasks related to the understanding and generation of natural language, it seems obvious that LLMs could be used directly as a powerful, scalable alternative to current SOTA methods for entity matching."
  - [corpus] Weak evidence - the corpus contains related entity linking papers but no direct evidence of GPT-4's zero-shot learning capabilities for ontology mapping.

## Foundational Learning

- Concept: Semantic similarity vs. lexical similarity
  - Why needed here: Understanding the difference between these two types of similarity is crucial for grasping why the LLM approach improves upon purely lexical methods. Lexical methods match based on string similarity, while semantic methods understand the meaning and relationships between concepts.
  - Quick check question: Why might "embryonic/larval Malpighian tubule Type I cell" and "caudal commissure" be lexically similar but semantically different?

- Concept: Ontology structure and relationships
  - Why needed here: The method relies on extracting and using information about concept definitions, synonyms, and relationships (like is_a, part_of) to provide context to the LLM. Understanding ontology structure is essential for implementing the Describe function and interpreting the LLM's output.
  - Quick check question: What information about a concept would you include in its description to help an LLM determine if it matches another concept?

- Concept: Precision-recall tradeoff
  - Why needed here: The method is designed to improve precision while maintaining high recall. Understanding this tradeoff is important for evaluating the method's performance and comparing it to other approaches.
  - Quick check question: If a method has high recall but low precision, what does this tell you about its performance?

## Architecture Onboarding

- Component map: Ontology pairs + candidate mappings from lexical tools -> MapperGPT algorithm -> GeneratePrompt function -> GPT-4 API -> Parse function -> Refined mappings
- Critical path:
  1. Generate candidate mappings using high-recall lexical method (e.g., LOOM)
  2. For each candidate mapping, generate detailed concept descriptions
  3. Create prompt with concept descriptions and in-context examples
  4. Send prompt to GPT-4 API and receive response
  5. Parse response to extract mapping categorization
  6. Compile refined mappings and output
- Design tradeoffs:
  - Using GPT-4 provides better performance but is expensive and has usage limits
  - Relying on high-recall lexical methods first ensures good recall but may miss some true positives
  - Providing detailed concept descriptions improves LLM accuracy but increases prompt size and cost
- Failure signatures:
  - If GPT-4 consistently misclassifies mappings despite accurate concept descriptions, the issue may be with the prompt structure or the LLM's understanding of the task
  - If the initial lexical method produces too few candidates, the LLM has less to work with and recall may suffer
  - If concept descriptions are incomplete or inaccurate, the LLM's judgments will be unreliable
- First 3 experiments:
  1. Run MapperGPT on a small, well-understood ontology pair (e.g., human and mouse anatomy) to verify basic functionality and compare results with manual curation
  2. Test the impact of different levels of detail in concept descriptions on LLM accuracy by systematically varying the information provided
  3. Evaluate the method's performance across different domains (anatomy, disease, development) to identify any domain-specific strengths or weaknesses

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal prompt structure and size for achieving maximum accuracy in ontology matching tasks?
- Basis in paper: [explicit] The paper mentions that prompt tuning and overall framework design are still challenges to be addressed, and notes that different prompt sizes and structures were explored during development.
- Why unresolved: The paper did not systematically evaluate different prompt architectures or sizes to determine optimal configurations.
- What evidence would resolve it: Systematic ablation studies testing different prompt structures, sizes, and example counts across multiple ontology matching tasks.

### Open Question 2
- Question: How can LLMs be effectively integrated into the candidate generation phase rather than just refinement?
- Basis in paper: [explicit] The paper states that current implementation focuses on refining existing candidate mappings, and mentions future work exploring LLMs for proposing suitable mapping candidates using RAG.
- Why unresolved: This represents an unexplored area where LLMs could potentially identify relevant mappings rather than just validating pre-generated candidates.
- What evidence would resolve it: Implementation and evaluation of an LLM-based candidate generation system using retrieval-augmented generation, with comparison to existing lexical methods.

### Open Question 3
- Question: Which types of ontology matching problems benefit most from LLM approaches?
- Basis in paper: [explicit] The paper notes that LLM performance improvements were modest for disease matching tasks and suggests that larger test sets and qualitative analysis are needed to determine which problems benefit most.
- Why unresolved: The current evaluation uses relatively small test sets across different domains, making it difficult to generalize findings about LLM effectiveness.
- What evidence would resolve it: Large-scale evaluation across diverse ontology matching tasks with detailed analysis of where LLM approaches provide the greatest advantage over traditional methods.

## Limitations
- Limited to domains where concept descriptions are rich and complete in source ontologies
- GPT-4 API costs and usage limits constrain scalability for large ontology mappings
- Performance gap remains between LLM-based methods and human curator accuracy (67% vs 80%+ F1)
- Evaluation based on specific biomedical ontology pairs, limiting generalizability claims

## Confidence
- High confidence: The core claim that LLMs can improve mapping precision when used as post-processing over lexical matching is well-supported by the 14-point F1 improvement over LogMap and consistent performance across four test sets.
- Medium confidence: The claim about generalizability across domains is supported by results in three different biomedical areas, but broader domain testing is needed to fully validate this claim.
- Medium confidence: The assertion that LLMs can understand and integrate semantic relationships from ontology descriptions is demonstrated through performance improvements, but the mechanism by which GPT-4 makes these judgments remains opaque.

## Next Checks
1. **Domain Generalization Test**: Apply MapperGPT to ontology pairs from non-biomedical domains (e.g., geography, product catalogs, or general knowledge) to evaluate whether the performance gains extend beyond the tested biomedical use cases.

2. **Ablation Study on Concept Descriptions**: Systematically vary the amount and type of information provided in concept descriptions (definitions only, definitions plus synonyms, full property set) to quantify the impact of different description granularities on LLM accuracy and identify the minimal effective description format.

3. **Cost-Benefit Analysis at Scale**: Measure the trade-off between mapping accuracy and operational costs by running MapperGPT on progressively larger ontology pairs, tracking both performance metrics and API costs to establish practical scaling limits and identify potential cost optimization strategies.