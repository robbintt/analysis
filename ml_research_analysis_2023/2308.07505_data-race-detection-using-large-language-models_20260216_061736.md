---
ver: rpa2
title: Data Race Detection Using Large Language Models
arxiv_id: '2308.07505'
source_url: https://arxiv.org/abs/2308.07505
tags:
- data
- race
- detection
- llms
- code
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We present a novel LLM-based approach for data race detection that
  combines prompting engineering and fine-tuning techniques. We created DRB-ML, a
  fine-grained dataset derived from DataRaceBench, to train and evaluate LLMs for
  detecting data races in OpenMP programs.
---

# Data Race Detection Using Large Language Models

## Quick Facts
- arXiv ID: 2308.07505
- Source URL: https://arxiv.org/abs/2308.07505
- Reference count: 28
- Key outcome: LLMs show promise for data race detection but cannot match traditional tools' precision in identifying specific variable pairs causing races

## Executive Summary
This paper introduces a novel approach for detecting data races in OpenMP programs using Large Language Models (LLMs). The authors created DRB-ML, a fine-grained dataset derived from DataRaceBench, and evaluated multiple prompting strategies and fine-tuning techniques on models including GPT-4, Llama2-7b, and StarChat-beta. While the results demonstrate that LLMs can be viable for data race detection with fine-tuning improving F1 scores by 6-10%, the models still lag behind traditional tools in precision and recall. The work establishes both the potential and current limitations of using LLMs for this specialized software correctness task.

## Method Summary
The authors developed DRB-ML, a dataset of 201 JSON files containing fine-grained labels for data race detection tasks, derived from DataRaceBench microbenchmarks. They employed three prompting strategies: basic prompts, data dependence-focused prompts, and Chain-of-Thought (COT) sequential prompts. The open-source models (Llama2-7b and StarChat-beta) were fine-tuned using QLoRA optimization with 5-fold cross-validation, while GPT-4 was used as a baseline without fine-tuning. Evaluation metrics included precision, recall, and F1 scores for both race detection and variable identification tasks.

## Key Results
- Fine-tuned open-source models improved F1 scores by 6-10% compared to their pre-trained versions
- GPT-4 achieved the highest overall performance with 0.74 F1 score for race detection and 0.70 for variable identification
- Traditional tools like Intel Inspector outperformed all LLM approaches in both precision and recall
- Structured JSON output formats enabled reliable extraction of race variable information from LLM responses

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning open-source LLMs with structured DRB-ML prompt-response pairs improves data race detection F1 scores by 6-10% compared to pre-trained versions. Structured training data provides explicit variable names, line numbers, and operation types that guide the model to learn precise race detection patterns beyond general language understanding. The core assumption is that the fine-tuning dataset is representative of real-world race patterns and the models can generalize from synthetic examples. Evidence shows the fine-tuned models improved F1 scores by 6-10% compared to their pre-trained versions. If the fine-tuning dataset lacks diversity in race patterns or contains noisy labels, the model may overfit to specific examples and fail on unseen code.

### Mechanism 2
Prompt engineering with Chain-of-Thought (COT) design improves data race detection accuracy compared to greedy multi-task prompts. Breaking complex detection tasks into sequential, simple prompts allows LLMs to reason step-by-step about data dependence before identifying races, reducing cognitive load and improving precision. The core assumption is that LLMs benefit from explicit reasoning steps rather than attempting to solve multi-task problems in a single response. Evidence shows preliminary results indicate that a simple and concise prompt may be more efficient, and COT facilitates step-by-step thinking. If the LLM's reasoning capability is insufficient for the intermediate steps, the sequential approach may introduce compounding errors.

### Mechanism 3
Structured output formats (JSON) enable reliable extraction of race variable information from LLM responses. By constraining LLM outputs to predefined JSON schemas, the system can automatically parse variable names, line numbers, and operation types without complex natural language processing. The core assumption is that LLMs will consistently adhere to the specified output format when prompted correctly. Evidence shows the transition to structured JSON outputs enabled automatic parsing, though not every LLM consistently maintains designated output formats. If LLMs generate format variations or natural language within structured fields, parsing will fail and require fallback NLP processing.

## Foundational Learning

- **Data dependence analysis in parallel programming**: Understanding how variables depend on each other across threads is essential for identifying race conditions. Quick check: What distinguishes a loop-carried dependence from a loop-independent dependence in OpenMP code?

- **Tokenization and context windows in transformer models**: LLMs have input length limits (e.g., 4k tokens) that constrain the size of code snippets that can be analyzed. Quick check: How does exceeding the context window affect an LLM's ability to detect data races across distant code sections?

- **Precision-recall tradeoff in classification tasks**: Data race detection requires balancing false positives (flagging non-races) against false negatives (missing actual races). Quick check: In a highly sensitive codebase, would you prioritize precision or recall for race detection, and why?

## Architecture Onboarding

- **Component map**: DRB-ML dataset -> LLM inference layer -> Fine-tuning pipeline -> Prompt engineering module -> Evaluation framework
- **Critical path**: Code → Prompt Engineering → LLM Inference → Response Parsing → Race Detection Result
- **Design tradeoffs**: Open-source vs proprietary models (trade-off between customization capability and baseline performance), dataset size vs quality (larger datasets may improve generalization but require more resources), real-time vs offline analysis (fine-tuned models may be faster but less adaptable to new patterns)
- **Failure signatures**: Low precision (model flags too many false positives, suggesting overfitting to training patterns), low recall (model misses races, indicating insufficient coverage of race patterns in training), inconsistent JSON output (model doesn't follow format constraints, requiring NLP fallback)
- **First 3 experiments**: 1) Compare baseline LLM performance on DRB-ML subset vs traditional tool (Intel Inspector) using identical code snippets, 2) Test prompt engineering variations (basic vs COT) on a small validation set to measure precision improvement, 3) Run 5-fold cross-validation on Llama2-7b with structured output format to establish baseline for fine-tuning

## Open Questions the Paper Calls Out

### Open Question 1
How can we create synthetic datasets that effectively capture diverse data race patterns while maintaining realistic code structures? The paper mentions "Generating synthetic datasets tailored for training" as a potential remedy for dataset challenges, and discusses the need for datasets that "capture more code semantics." Creating synthetic datasets that balance diversity of data race patterns with realistic code structure is challenging, as overly synthetic data may not reflect real-world scenarios while purely realistic data may miss edge cases. Empirical studies comparing detection performance of models trained on different synthetic dataset generation strategies, including both code structure preservation metrics and detection accuracy on real-world benchmarks, would resolve this question.

### Open Question 2
What are the optimal input representations (beyond text) for LLMs to detect data races, such as abstract syntax trees, dependence graphs, or control-flow graphs? The paper explicitly states interest in expanding DRB-ML to include more data items using data scraping and augmentation techniques, and will explore different modalities beyond text as input, such as abstract syntax trees, dependence graphs, and control-flow graphs. Different representations may capture different aspects of code semantics, and there is no established methodology for determining which representations work best for data race detection in LLMs. Comparative experiments evaluating LLM performance across different input representations using consistent training and evaluation protocols, with analysis of which representation types capture the most relevant information for data race detection, would resolve this question.

### Open Question 3
Can fine-tuning open-source LLMs surpass the performance of proprietary models like GPT-4 for data race detection tasks? The paper states "With the right fine-tuning, they could indeed surpass the GPT series in data race detection capabilities" regarding open-source models, and notes that "traditional tools achieve superior performance in terms of the F1 score when compared to LLMs." The paper shows that GPT-4 currently outperforms fine-tuned open-source models, but suggests potential for improvement with better training data or techniques, without definitive evidence that this potential can be realized. Head-to-head comparisons of state-of-the-art proprietary and fine-tuned open-source models on standardized data race detection benchmarks, with ablation studies isolating the impact of different fine-tuning strategies and dataset qualities, would resolve this question.

## Limitations

- DRB-ML dataset contains only 201 examples, potentially limiting model generalization to diverse real-world codebases
- Evaluation focuses exclusively on OpenMP programs, with unknown performance on other parallel programming paradigms (MPI, CUDA, etc.)
- Comparison with traditional tools like Intel Inspector is based on potentially different configurations and settings that aren't fully specified

## Confidence

- **High Confidence**: The 6-10% F1 score improvement from fine-tuning is well-supported by the 5-fold cross-validation results and clearly documented methodology
- **Medium Confidence**: The superiority of GPT-4 over fine-tuned models is demonstrated but may not generalize beyond the specific OpenMP domain tested
- **Low Confidence**: The claim that structured JSON outputs reliably enable automatic parsing is undermined by the paper's own acknowledgment that not all LLMs maintain consistent output formats

## Next Checks

1. **Dataset Generalization Test**: Evaluate the fine-tuned models on a held-out test set of OpenMP code from sources outside DataRaceBench to assess real-world applicability and check for overfitting to the training distribution.

2. **Tool Configuration Verification**: Reproduce the Intel Inspector baseline results using the exact version and configuration specified in the paper to ensure fair comparison, documenting any differences in detection criteria or sensitivity settings.

3. **Output Format Robustness**: Conduct a systematic test where models are prompted with varying formats and linguistic variations to measure consistency in JSON output adherence, quantifying the percentage of responses requiring NLP fallback parsing.