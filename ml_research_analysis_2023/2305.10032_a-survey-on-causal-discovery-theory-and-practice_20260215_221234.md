---
ver: rpa2
title: 'A Survey on Causal Discovery: Theory and Practice'
arxiv_id: '2305.10032'
source_url: https://arxiv.org/abs/2305.10032
tags:
- causal
- graph
- discovery
- data
- intervention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comprehensive survey of causal discovery
  methods, unifying recent advancements in the field. It addresses the problem of
  learning causal graphs from observational and interventional data, covering both
  linear and non-linear models, cyclic and acyclic structures, and scenarios with
  and without latent variables.
---

# A Survey on Causal Discovery: Theory and Practice

## Quick Facts
- **arXiv ID**: 2305.10032
- **Source URL**: https://arxiv.org/abs/2305.10032
- **Reference count**: 40
- **Primary result**: Comprehensive survey unifying recent advancements in causal discovery methods across observational and interventional settings

## Executive Summary
This paper provides a comprehensive survey of causal discovery methods, unifying recent advancements in the field. It addresses the problem of learning causal graphs from observational and interventional data, covering both linear and non-linear models, cyclic and acyclic structures, and scenarios with and without latent variables. The survey categorizes algorithms into constraint-based, score-based, and hybrid approaches, providing detailed descriptions and comparing their capabilities. It also discusses evaluation metrics, datasets, and practical applications in economics, medicine, and psychology.

## Method Summary
The paper systematically categorizes causal discovery algorithms into three main approaches: constraint-based methods (like PC and FCI) that use conditional independence tests to infer causal structure, score-based methods (like GES) that optimize a score function over possible DAGs, and hybrid methods that combine both approaches. The survey provides detailed theoretical foundations including d-separation, Markov properties, and faithfulness assumptions, then maps these to algorithmic implementations. For interventional settings, the paper discusses how interventions reduce equivalence classes and enable more definitive causal identification.

## Key Results
- Causal discovery algorithms can recover causal structure from observational data under Markov and faithfulness assumptions
- Interventional data reduces equivalence class size, enabling more definitive edge orientations
- Hybrid algorithms combining constraint-based and score-based methods show improved performance in high-dimensional settings

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Causal discovery algorithms can recover the underlying causal graph from observational data when the Markov and faithfulness assumptions hold.
- **Mechanism**: The algorithms use conditional independence tests to infer which variables are d-separated, and then orient edges based on v-structures and acyclicity, yielding a CPDAG that represents the equivalence class of the true DAG.
- **Core assumption**: The joint distribution is Markov w.r.t. the true DAG and satisfies the faithfulness assumption.
- **Evidence anchors**:
  - [abstract]: "It addresses the problem of learning causal graphs from observational and interventional data..."
  - [section]: "A graphical model is said to satisfy the Markov property if the associated joint probability distribution P (V) can be decomposed recursively..."
  - [corpus]: Weak. No direct evidence in corpus about faithfulness or Markov property.
- **Break condition**: If the distribution is unfaithful or violates the Markov assumption, the algorithm may infer incorrect independencies and thus a wrong structure.

### Mechanism 2
- **Claim**: Interventional data reduces the size of the equivalence class, enabling more edges to be oriented uniquely.
- **Mechanism**: By intervening on a variable and observing changes in the conditional distributions of its descendants, one can identify edges that are covered by the intervention and distinguish between graphs that are observationally equivalent.
- **Core assumption**: The intervention targets are known and the interventions are either perfect or have a known mechanism change.
- **Evidence anchors**:
  - [abstract]: "...covering both linear and non-linear models, cyclic and acyclic structures, and scenarios with and without latent variables."
  - [section]: "Deﬁnition 5.5 (Conservative Family). A family of targets I is conservative if for each vertex X in V there exists at least one intervention target in I that does not contain X..."
  - [corpus]: Weak. No direct evidence about interventional equivalence classes.
- **Break condition**: If intervention targets are unknown or interventions are soft with unknown mechanisms, the reduction in equivalence class size may not occur.

### Mechanism 3
- **Claim**: Hybrid algorithms combine the strengths of constraint-based and score-based methods to improve consistency in both low- and high-dimensional settings.
- **Mechanism**: The algorithm first uses conditional independence tests to restrict the search space to admissible edges, then applies a score-based search (e.g., GES) only over this restricted space, improving both speed and accuracy.
- **Core assumption**: The admissible edge set defined by the constraint-based step is correct, i.e., it contains all edges in the true DAG and excludes false edges.
- **Evidence anchors**:
  - [abstract]: "...providing detailed descriptions and comparing their capabilities."
  - [section]: "The novelty of this hybrid version of GES stems from the concept of admissible edge..."
  - [corpus]: Weak. No direct evidence in corpus about hybrid methods.
- **Break condition**: If the constraint-based step is inconsistent or makes errors, the hybrid method inherits those errors and may perform worse than either pure method.

## Foundational Learning

- **Concept**: d-separation and m-separation
  - Why needed here: These graphical criteria are the basis for translating statistical independence tests into structural constraints.
  - Quick check question: Given a DAG, can you identify all sets that d-separate two nodes X and Y?

- **Concept**: Markov equivalence class
  - Why needed here: Understanding that different DAGs can encode the same set of independencies is crucial for interpreting CPDAG/PAG outputs.
  - Quick check question: If two DAGs have the same skeleton and v-structures, are they necessarily Markov equivalent?

- **Concept**: Intervention graph and interventional distribution
  - Why needed here: To reason about how perfect interventions change the factorization of the joint distribution and thus the causal structure.
  - Quick check question: In a perfect intervention on variable X, what happens to the incoming edges of X in the causal graph?

## Architecture Onboarding

- **Component map**: Data ingestion -> Conditional independence testing -> Skeleton construction -> Edge orientation -> Equivalence class representation
- **Critical path**: Load data → perform CI tests → build skeleton → orient v-structures → apply orientation rules → output CPDAG/PAG. For interventional methods, insert intervention target handling before orientation.
- **Design tradeoffs**: Constraint-based methods are sound but may be slow with high-dimensional conditioning; score-based methods are faster but less reliable under causal insufficiency; hybrid methods balance both but add complexity.
- **Failure signatures**: Inconsistent CI tests leading to wrong skeletons; incorrect orientation rules yielding cycles; failure to identify v-structures under latent variables.
- **First 3 experiments**:
  1. Run PC algorithm on synthetic Gaussian data with known DAG; verify recovered CPDAG matches true equivalence class.
  2. Add a known intervention target; run IGSP and compare recovered graph to observational-only result.
  3. Test FCI on data with latent confounders; check PAG output for correct bidirected edges and circle marks.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of unobserved variables on the accuracy of causal discovery algorithms in real-world applications?
- Basis in paper: [inferred] The paper discusses the challenges of causal insufficiency and latent variables in causal discovery.
- Why unresolved: The paper provides a theoretical framework but lacks empirical evidence on the practical impact of unobserved variables in real-world scenarios.
- What evidence would resolve it: Empirical studies comparing the performance of causal discovery algorithms on datasets with and without unobserved variables in real-world applications.

### Open Question 2
- Question: How can causal discovery algorithms be extended to handle non-linear relationships in high-dimensional data?
- Basis in paper: [inferred] The paper mentions the limitations of linear models and the need for non-linear approaches, but does not provide a detailed solution for high-dimensional data.
- Why unresolved: The paper identifies the problem but does not propose a specific solution for non-linear relationships in high-dimensional settings.
- What evidence would resolve it: Development and testing of new causal discovery algorithms that can handle non-linear relationships in high-dimensional data, with empirical validation on real-world datasets.

### Open Question 3
- Question: What are the most effective evaluation metrics for assessing the performance of causal discovery algorithms in interventional settings?
- Basis in paper: [inferred] The paper discusses evaluation metrics for causal discovery but does not provide a comprehensive analysis of their effectiveness in interventional settings.
- Why unresolved: The paper introduces various evaluation metrics but does not compare their effectiveness in the context of interventional data.
- What evidence would resolve it: Comparative studies evaluating the performance of different evaluation metrics on interventional datasets, with a focus on their ability to capture the true causal relationships.

## Limitations

- The paper's discussion of faithfulness and Markov assumptions is mostly theoretical with limited empirical validation in real-world datasets
- Interventional methods assume known and perfect interventions, which rarely hold in practice
- The survey mentions cyclic structures but provides limited detail on handling them compared to acyclic cases

## Confidence

- **Theoretical foundations (High)**: Claims about d-separation, Markov properties, and faithfulness are well-established
- **Basic constraint-based methods (High)**: PC and FCI algorithms have strong theoretical guarantees
- **Hybrid algorithms (Medium)**: Performance depends heavily on correctness of constraint-based step
- **Interventional methods (Low)**: Real-world imperfect interventions may invalidate theoretical assumptions

## Next Checks

1. Benchmark PC and hybrid GES on high-dimensional synthetic data with varying sample sizes to quantify performance degradation
2. Test FCI and RFCI on benchmark datasets with known latent confounders to verify PAG accuracy
3. Implement and evaluate a hybrid algorithm that incorporates both observational and interventional data to measure improvements in equivalence class reduction