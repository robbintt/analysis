---
ver: rpa2
title: Strahler Number of Natural Language Sentences in Comparison with Random Trees
arxiv_id: '2307.02697'
source_url: https://arxiv.org/abs/2307.02697
tags:
- number
- strahler
- tree
- upper
- lower
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the Strahler number, a measure of tree
  complexity originally used in river analysis, when applied to natural language sentence
  structures. The authors define and compute the Strahler number for dependency trees
  from the Universal Dependencies corpus across 114 languages.
---

# Strahler Number of Natural Language Sentences in Comparison with Random Trees

## Quick Facts
- arXiv ID: 2307.02697
- Source URL: https://arxiv.org/abs/2307.02697
- Reference count: 40
- Key outcome: The Strahler number for natural language sentences typically ranges from 3-4 and grows logarithmically with sentence length, showing similar patterns to random trees

## Executive Summary
This paper applies the Strahler number, a measure of tree complexity from river analysis, to natural language sentence structures. Using the Universal Dependencies corpus across 114 languages, the authors calculate Strahler numbers for dependency trees after transforming them into binary structures using two different binarization methods. They establish theoretical upper and lower bounds for these numbers and demonstrate that while the Strahler number appears constant in practice, it actually grows logarithmically with sentence length. The key finding is that natural language structures show similar Strahler number patterns to random trees, suggesting this measure reflects general tree properties rather than language-specific features.

## Method Summary
The authors extracted dependency structures from the Universal Dependencies corpus (version 2.8) containing 202 corpora across 114 languages. They transformed these dependency trees into binary trees using two binarization methods: Binary1 with grammar rules from Reddy et al. (2017), and Binary2 with heuristic approaches. For each binary tree, they calculated the Strahler number using a bottom-up algorithm. The paper also derived theoretical upper and lower bounds for the Strahler number across all possible binarizations. Statistical analysis was performed to examine distributions and growth patterns, with comparisons made to random tree structures of equivalent sizes.

## Key Results
- The Strahler number for natural language sentences typically ranges from 3-4
- The Strahler number grows logarithmically with sentence length, not as a constant value
- Natural language structures show similar Strahler number patterns to random trees
- The Strahler number provides a lower bound on memory requirements for sentence processing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Strahler number grows logarithmically with sentence length, not as a constant value
- Mechanism: The authors show that the Strahler number follows logarithmic growth with respect to tree size n, and since sentence lengths have a limited range, the Strahler number appears constant in practice
- Core assumption: The range of sentence lengths in natural language is bounded, creating the illusion of a constant Strahler number
- Evidence anchors:
  - [abstract]: "we show that it is not a constant but grows logarithmically with the sentence size"
  - [section]: "it is not a constant but merely looks like a constant, because it grows very slowly with respect to n, and the range of sentence lengths is limited"
  - [corpus]: Weak evidence - the corpus shows Strahler numbers typically between 3-4, but doesn't explicitly prove the logarithmic growth relationship
- Break condition: If sentence lengths were unbounded or followed a power-law distribution instead of a bounded range, the logarithmic growth would become more apparent and the "constant" appearance would break down

### Mechanism 2
- Claim: The Strahler number provides a lower bound on memory requirements for sentence processing
- Mechanism: By transforming dependency structures into binary trees and applying the shift-reduce method, the Strahler number represents the minimum stack space needed to evaluate the tree structure
- Core assumption: Sentence understanding can be modeled as a tree traversal problem using shift-reduce operations
- Evidence anchors:
  - [abstract]: "it is one kind of lower limit on the amount of memory required to process sentences under a particular model"
  - [section]: "the Strahler number entails the memory necessary to process a sentence structure via the shift-reduce method"
  - [corpus]: Weak evidence - the corpus shows typical Strahler numbers of 3-4, but doesn't directly prove this equals memory requirements
- Break condition: If alternative parsing methods don't use stack-based evaluation, or if sentence processing involves additional memory requirements beyond tree traversal

### Mechanism 3
- Claim: The Strahler number for natural language sentences is not significantly different from random trees
- Mechanism: The authors compare the Strahler number distributions between natural language dependency structures and random trees, finding similar patterns that suggest the measure reflects general tree properties rather than language-specific features
- Core assumption: Random trees can serve as a valid baseline for comparison with natural language structures
- Evidence anchors:
  - [abstract]: "the Strahler number is not different for random trees, which could suggest that its origin is not specific to natural language"
  - [section]: "the range for R(n) is slightly narrower than the range for U(n), despite R(n) being the average of all random trees with n nodes"
  - [corpus]: Moderate evidence - the corpus shows Strahler number distributions for both natural and random trees, with R(n) having a narrower range than U(n)
- Break condition: If natural language trees had significantly different branching patterns or structural properties that would produce distinct Strahler number distributions

## Foundational Learning

- Concept: Tree binarization methods for dependency structures
  - Why needed here: The paper needs to convert non-binary dependency trees into binary trees to apply the Strahler number calculation
  - Quick check question: What are the two binarization methods proposed in the paper, and how do they differ in their approach?

- Concept: Shift-reduce parsing and its memory implications
  - Why needed here: The paper uses shift-reduce operations to establish the connection between Strahler number and memory requirements
  - Quick check question: How does the shift-reduce method work, and why does the Strahler number represent the minimum stack space needed?

- Concept: Catalan numbers and their relationship to tree enumeration
  - Why needed here: The paper uses Catalan numbers to characterize the size of tree sets and calculate statistical properties
  - Quick check question: What is the relationship between Catalan numbers and the number of possible binary trees with n leaves?

## Architecture Onboarding

- Component map: Data preprocessing -> Binarization module -> Strahler calculation -> Statistical analysis -> Comparison module -> Visualization
- Critical path: Corpus → Binarization → Strahler Calculation → Statistical Analysis → Comparison → Results
- Design tradeoffs: Binary1 vs Binary2 binarization methods - accuracy vs applicability
- Failure signatures:
  - Non-terminating binarization for complex dependency structures
  - Incorrect Strahler number calculations due to implementation errors
  - Statistical anomalies in random tree generation
- First 3 experiments:
  1. Validate binarization methods on a small set of manually checked sentences
  2. Verify Strahler number calculations against known examples
  3. Test random tree generation for different sizes and verify statistical properties

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Strahler number compare to other measures of syntactic complexity across languages, and what unique insights does it provide that other measures do not?
- Basis in paper: [explicit] The paper mentions previous work on measuring syntactic complexity, such as dependency distance, but does not compare the Strahler number directly to these measures.
- Why unresolved: The paper focuses on establishing the Strahler number as a measure and its properties, but does not conduct a comparative analysis with other complexity measures.
- What evidence would resolve it: A comparative study using the same datasets to calculate multiple complexity measures (e.g., dependency distance, depth, branching index) alongside the Strahler number, followed by statistical analysis of their correlations and unique predictive power for cognitive load or parsing difficulty.

### Open Question 2
- Question: Does the logarithmic growth of the Strahler number with sentence length hold true for extremely long sentences, or does it plateau at some point due to cognitive or structural constraints?
- Basis in paper: [inferred] The paper shows logarithmic growth within the range of typical sentence lengths but does not explore sentences beyond this range or consider potential plateaus.
- Why unresolved: The analysis is limited to the range of sentence lengths present in the Universal Dependencies corpus, which may not include extremely long sentences.
- What evidence would resolve it: Analysis of corpora containing much longer sentences (e.g., literary works, legal documents) to test if the logarithmic relationship persists or if there is a plateau effect.

### Open Question 3
- Question: How does the Strahler number relate to actual processing difficulty in real-time sentence comprehension, beyond its theoretical connection to memory requirements?
- Basis in paper: [explicit] The paper discusses the theoretical link between the Strahler number and memory requirements for tree evaluation, but does not test this against empirical measures of processing difficulty.
- Why unresolved: The paper establishes a theoretical framework but does not conduct psycholinguistic experiments to validate the practical implications for sentence processing.
- What evidence would resolve it: Eye-tracking studies, self-paced reading experiments, or ERP studies measuring processing difficulty as a function of Strahler number, controlling for other factors like word frequency and sentence length.

## Limitations
- The logarithmic growth relationship is inferred rather than directly observed due to the limited range of sentence lengths in natural language corpora
- The comparison with random trees doesn't account for potential structural differences that might affect Strahler number in ways not captured by this single metric
- The theoretical connection to memory requirements lacks empirical validation against actual cognitive processing costs

## Confidence

**Confidence Level: Medium** for the core claim that Strahler number grows logarithmically with sentence length. While the theoretical derivation appears sound, the empirical evidence is limited by the relatively small range of sentence lengths in natural language corpora.

**Confidence Level: Low** for the comparison between natural language trees and random trees. The paper shows that Strahler number distributions are similar, but doesn't account for potential structural differences between dependency trees and random trees that might affect the Strahler number in ways not captured by this single metric.

**Confidence Level: Medium** for the connection between Strahler number and memory requirements. The theoretical link via shift-reduce parsing is plausible, but the paper doesn't provide empirical evidence that this directly corresponds to actual cognitive processing costs during sentence comprehension.

## Next Checks
1. **Empirical verification of logarithmic growth**: Analyze a corpus with a wider range of sentence lengths (including very long sentences) to directly observe the logarithmic relationship between Strahler number and sentence length, rather than inferring it from the bounded range.

2. **Structural comparison beyond Strahler number**: Compare additional tree metrics (branching factors, depth distributions, node degrees) between natural language dependency structures and random trees to determine if the similarity in Strahler numbers reflects deeper structural similarities or is coincidental.

3. **Cognitive validation**: Design psycholinguistic experiments to test whether Strahler number correlates with actual processing difficulty or memory load during sentence comprehension, beyond the theoretical shift-reduce model.