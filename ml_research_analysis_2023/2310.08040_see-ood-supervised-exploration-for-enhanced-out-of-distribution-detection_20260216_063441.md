---
ver: rpa2
title: 'SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution Detection'
arxiv_id: '2310.08040'
source_url: https://arxiv.org/abs/2310.08040
tags:
- samples
- data
- training
- detection
- wasserstein
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of Out-of-Distribution (OoD)
  detection in deep neural networks, where the goal is to correctly classify InD samples
  while effectively identifying incoming OoD testing samples. The proposed method,
  SEE-OoD, introduces a Wasserstein-score-based generative adversarial training scheme
  that performs data augmentation and exploration simultaneously under the supervision
  of limited OoD samples.
---

# SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution Detection

## Quick Facts
- arXiv ID: 2310.08040
- Source URL: https://arxiv.org/abs/2310.08040
- Authors: 
- Reference count: 40
- Outperforms state-of-the-art techniques for OoD detection with superior generalizability

## Executive Summary
This paper introduces SEE-OoD, a novel method for Out-of-Distribution (OoD) detection that combines Wasserstein-score-based generative adversarial training with supervised exploration. The method uses limited OoD samples to guide a generator in exploring potential OoD spaces, creating synthetic OoD samples that enhance detection performance. The approach provides theoretical guarantees for achieving optimal separation between InD and OoD samples, and extensive experiments demonstrate superior performance compared to existing state-of-the-art methods across multiple computer vision datasets.

## Method Summary
SEE-OoD addresses OoD detection by training a Wasserstein-score-based generative adversarial network where the generator explores OoD spaces and creates synthetic OoD samples using feedback from a discriminator. The discriminator is trained on both real and synthetic OoD samples to improve OoD detection using Wasserstein scores. The method provides theoretical guarantees that optimal solutions are achievable through adversarial training in empirical settings. During training, the generator maps noise vectors to synthetic OoD samples while the discriminator outputs both class probabilities and Wasserstein scores for OoD detection. The training alternates between updating the discriminator and generator using mini-batch stochastic gradient descent.

## Key Results
- SEE-OoD outperforms state-of-the-art OoD detection methods including ODIN, Mahalanobis, Energy, VOS, and GAN-based approaches
- The method achieves superior generalizability to unseen OoD data, maintaining near-perfect detection even when OoD classes are missing during training
- Extensive experiments on MNIST, FashionMNIST, CIFAR-10, and SVHN datasets demonstrate consistent performance improvements across different OoD detection scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The generator can effectively explore OoD spaces beyond observed samples using discriminator feedback.
- Mechanism: The generator receives feedback from the discriminator in the Wasserstein score space, allowing it to generate synthetic OoD samples that are statistically distinguishable from InD samples.
- Core assumption: The Wasserstein score space provides a meaningful separation between InD and OoD distributions that the generator can exploit.
- Evidence anchors:
  - [abstract]: "the generator explores OoD spaces and generates synthetic OoD samples using feedback from the discriminator"
  - [section 2.2]: "the generator utilizes this knowledge as guidance to generate samples that retain a high Wasserstein score"
  - [corpus]: Weak - no direct mention of generator exploration mechanisms in related papers
- Break condition: If the Wasserstein score space fails to provide meaningful separation between InD and OoD distributions, the generator cannot effectively explore OoD spaces.

### Mechanism 2
- Claim: The Wasserstein-score-based training scheme can statistically achieve optimal separation of InD and OoD samples.
- Mechanism: Theoretical guarantees show that at optimality, the discriminator perfectly classifies InD data and separates InD and OoD in the Wasserstein score space, while the generator produces samples that don't overlap with InD distribution.
- Core assumption: The neural network loss generalizes well in empirical settings and optimal solutions are achievable through adversarial training.
- Evidence anchors:
  - [section 2.3]: "We provide several theoretical results that guarantee the effectiveness of our method"
  - [section 2.3]: "the discriminator perfectly classifies the InD data and separates InD and OoD data in the Wasserstein score space"
  - [corpus]: Weak - no direct mention of theoretical guarantees for OoD detection in related papers
- Break condition: If the theoretical assumptions about Lipschitz continuity or neural network generalization fail in practice, optimal separation may not be achievable.

### Mechanism 3
- Claim: Supervised exploration with limited OoD samples provides better OoD detection performance than methods using only real OoD samples.
- Mechanism: The proposed method combines data augmentation and exploration under supervision of existing OoD data, allowing it to achieve better generalization to unseen OoD data compared to methods that only use observed OoD samples.
- Core assumption: The limited OoD samples provide sufficient supervision for the generator to explore OoD spaces effectively.
- Evidence anchors:
  - [abstract]: "performs data augmentation and exploration simultaneously under the supervision of limited OoD samples"
  - [section 3.2]: "while baseline methods suffer from lower detection performance when OoD classes are missing during training, our proposed method can still achieve near-perfect detection"
  - [corpus]: Weak - no direct comparison of supervised exploration vs. real OoD sample usage in related papers
- Break condition: If the supervision from limited OoD samples is insufficient, the generator may explore irrelevant OoD spaces leading to poor detection performance.

## Foundational Learning

- Concept: Wasserstein distance and its properties
  - Why needed here: The Wasserstein score function is central to the proposed method's ability to separate InD and OoD samples
  - Quick check question: Why is the Wasserstein distance preferred over other divergence measures for this application?

- Concept: Generative adversarial networks (GANs) and their training dynamics
  - Why needed here: The proposed method builds on GAN framework where the generator and discriminator are trained in opposition
  - Quick check question: How does the Wasserstein-score-based objective differ from the traditional GAN objective?

- Concept: Out-of-distribution detection and evaluation metrics
  - Why needed here: Understanding OoD detection problem formulation and how to evaluate performance is crucial for implementing and testing the method
  - Quick check question: What is the difference between True Positive Rate and True Negative Rate in OoD detection context?

## Architecture Onboarding

- Component map:
  - Generator: CNN-based network that maps noise vectors to synthetic OoD samples
  - Discriminator: DenseNet-based classifier that outputs K-dimensional probability distribution
  - Loss function: Combines classification loss, OoD Wasserstein score mapping, and OoD adversarial training
  - Training loop: Alternates between updating discriminator and generator using minibatch SGD/SGA

- Critical path: Generator → Discriminator feedback → Wasserstein score space → Synthetic OoD generation → Improved OoD detection
- Design tradeoffs:
  - Using Wasserstein score vs. other uncertainty measures: Better theoretical properties but potentially more complex implementation
  - Generator complexity: More complex generators can generate more diverse OoD samples but increase training time and risk of mode collapse
  - Batch sizes for InD vs. OoD samples: Balancing stochasticity vs. stable training

- Failure signatures:
  - Discriminator collapses to predicting uniform distribution for all inputs
  - Generator produces samples that the discriminator classifies as InD
  - Training instability with oscillating losses or NaN values
  - Poor OoD detection performance on held-out test sets

- First 3 experiments:
  1. 2D synthetic dataset simulation to visualize Wasserstein score heatmaps and verify theoretical claims
  2. Within-Dataset OoD detection on MNIST/FashionMNIST with limited OoD samples per class
  3. Regime II experiment with imbalanced OoD classes to test generalization to unseen OoD data

## Open Questions the Paper Calls Out
None explicitly identified in the paper.

## Limitations
- The effectiveness of the method depends on the availability of sufficient OoD samples for supervision, though the paper claims to work with limited samples
- Theoretical guarantees assume Lipschitz continuity and neural network generalization properties that may not hold in all practical settings
- The method requires careful tuning of hyperparameters and training dynamics compared to simpler baseline methods

## Confidence
- High Confidence: Basic mechanism of Wasserstein-score-based feedback guiding generator exploration is sound and experimentally validated
- Medium Confidence: Theoretical guarantees are mathematically proven but may not perfectly translate to empirical settings
- Medium Confidence: Claims of superior generalizability to unseen OoD data are demonstrated but may vary with real-world complexity

## Next Checks
1. Test the method on synthetic 2D datasets with known OoD distributions to visually verify that the generator explores meaningful OoD spaces beyond observed samples.
2. Conduct ablation studies to quantify the contribution of each component (Wasserstein scoring, supervised exploration, synthetic data augmentation) to overall performance.
3. Evaluate performance on real-world datasets with naturally occurring OoD samples to assess practical generalizability beyond controlled experimental conditions.