---
ver: rpa2
title: 'StoryAnalogy: Deriving Story-level Analogies from Large Language Models to
  Unlock Analogical Understanding'
arxiv_id: '2310.12874'
source_url: https://arxiv.org/abs/2310.12874
tags:
- stories
- story
- these
- analogy
- different
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces STORYANALOGY, a first-of-its-kind large-scale
  story-level analogy corpus containing 24K story pairs with human annotations on
  entity and relation similarities. The corpus extends the Structure-Mapping Theory
  to evaluate analogies between narratives, providing a framework for studying complex
  analogical understanding.
---

# StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding

## Quick Facts
- arXiv ID: 2310.12874
- Source URL: https://arxiv.org/abs/2310.12874
- Reference count: 40
- This paper introduces STORYANALOGY, a first-of-its-kind large-scale story-level analogy corpus containing 24K story pairs with human annotations on entity and relation similarities.

## Executive Summary
This paper introduces STORYANALOGY, the first large-scale story-level analogy corpus containing 24K story pairs annotated for entity and relation similarities. The authors extend Structure-Mapping Theory to evaluate analogies between narratives by decomposing analogy quality into entity similarity (attributes) and relation similarity (relational structures). Experiments reveal that existing encoder models and LLMs struggle significantly with identifying story analogies, achieving far lower performance than humans. However, the annotated corpus can be used to fine-tune smaller models, with a fine-tuned FlanT5-xxl model achieving comparable performance to zero-shot ChatGPT in generating analogies.

## Method Summary
The paper constructs STORYANALOGY by prompting LLMs with seed analogies and diverse source data to generate candidate story pairs, which are then filtered and annotated by humans for entity similarity (EntSim) and relation similarity (RelSim). The analogy score α is computed as the ratio of RelSim to EntSim, following an extended Structure-Mapping Theory framework. Models are evaluated using Spearman correlation between predicted and human-annotated EntSim, RelSim, and α scores. Fine-tuning experiments use a regression and contrastive learning approach on RoBERTa, while generation experiments fine-tune FlanT5-xxl on the annotated corpus.

## Key Results
- STORYANALOGY contains 24K story pairs from diverse domains with human annotations
- Existing encoder models and LLMs achieve significantly lower performance than humans in identifying story analogies
- Fine-tuning smaller models (FlanT5-xxl) on STORYANALOGY improves analogy generation quality to match zero-shot ChatGPT

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Extending Structure-Mapping Theory (SMT) to story-level analogy allows decomposition of analogy quality into two measurable dimensions: entity similarity and relation similarity.
- Mechanism: By modeling stories as having attributes (entities) and relational structures (events, higher-order relations), the analogy score becomes a ratio of relational to entity similarity, enabling clear classification into analogy vs. literal similarity.
- Core assumption: The relational structure is the key determinant of analogy quality; entity overlap can dilute the analogy signal.
- Evidence anchors:
  - [abstract] "We use entity and relation similarity to characterize the level of similarity on attributes and relations between the source and target stories."
  - [section 2.1] "Analogy between a pair of objects holds when they have similar relational structures while dissimilar attributes... Based on SMT, we propose to compare stories by their entity and relation similarity..."
- Break condition: If stories lack clear relational structures or if entity and relation similarities are both high, the ratio may misclassify literal similarity as analogy.

### Mechanism 2
- Claim: Large language models can be prompted to generate candidate story analogies by conditioning on seed examples and diverse source data.
- Mechanism: Prompting LLMs with analogies and related data sources induces generation of plausible story pairs; filtering and human annotation ensures quality.
- Core assumption: LLMs trained on broad corpora have internalized patterns for analogical mapping that can be elicited through in-context examples.
- Evidence anchors:
  - [section 2.2] "We discover that LLMs can generate high-quality story analogies... We prompt large language models (LLMs) to generate story pairs that are likely to be analogies."
  - [corpus] "We obtain STORYANALOGY, which contains 24K diverse story pairs, each with human annotation guided by the extended SMT."
- Break condition: If the seed analogies are not representative or if the source data are not diverse enough, generated candidates may be repetitive or low quality.

### Mechanism 3
- Claim: Fine-tuning smaller models on STORYANALOGY improves their ability to generate analogies comparable to zero-shot large models.
- Mechanism: Exposure to annotated analogy examples allows smaller models to learn the entity-relation balance required for analogy, boosting generation quality.
- Core assumption: Analogy generation benefits from explicit training on balanced entity/relation examples rather than just unsupervised pretraining.
- Evidence anchors:
  - [abstract] "the data in STORYANALOGY can improve the quality of analogy generation in LLMs, where a fine-tuned FlanT5-xxl model achieves comparable performance to zero-shot ChatGPT."
  - [section 4] "With a few demonstrations, we observe significant improvement on the generation quality of LLaMa... Notably, finetuning smaller LMs boosted their generation quality..."
- Break condition: If the training data are too small or the fine-tuning process overfits to specific examples, generalization to new domains may suffer.

## Foundational Learning

- Concept: Structure-Mapping Theory (SMT)
  - Why needed here: Provides the theoretical foundation for decomposing analogy into entity vs. relation similarity, guiding both annotation and evaluation.
  - Quick check question: According to SMT, what distinguishes an analogy from a literal similarity?

- Concept: Spearman correlation for model evaluation
  - Why needed here: Used to quantify how well model predictions align with human similarity scores across EntSim, RelSim, and the analogy ratio.
  - Quick check question: What does a Spearman correlation of 0.7 between predicted and true analogy scores indicate about model performance?

- Concept: In-context learning with demonstrations
  - Why needed here: Allows LLMs to adapt to the analogy task without fine-tuning, using few examples to guide generation or scoring.
  - Quick check question: How does increasing the number of demonstrations typically affect LLM performance in this task?

## Architecture Onboarding

- Component map: Data collection -> LLM candidate generation -> Human annotation -> Model training/evaluation -> Fine-tuning -> Generation testing
- Critical path: Seed analogies -> LLM prompts -> Candidate filtering -> Annotated corpus -> Model evaluation -> Fine-tuning for generation
- Design tradeoffs: Larger seed sets improve candidate diversity but increase annotation cost; using in-context learning reduces compute but may yield noisier results
- Failure signatures: Low inter-annotator agreement on EntSim/RelSim suggests unclear instructions; poor model correlation on α indicates ratio sensitivity; hallucination in generations signals inadequate filtering
- First 3 experiments:
  1. Prompt LLMs with seed analogies to generate 1000 candidate pairs; measure novelty and relevance.
  2. Annotate 200 random candidates for EntSim and RelSim; compute inter-annotator agreement.
  3. Train a regression model to predict EntSim/RelSim from story embeddings; evaluate Spearman correlation on the annotated test set.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does STORYANALOGY perform on more diverse and complex story domains beyond the four domains studied (scientific scripts, social narratives, word analogies, and knowledge graph triples)?
- Basis in paper: [explicit] The paper mentions that the dataset is limited to four domains and suggests extending the annotation to other domains like biomedical stories or academic articles as future work.
- Why unresolved: The current dataset's coverage is limited, and the performance of models on more complex and diverse story domains is unknown.
- What evidence would resolve it: Evaluating models on a larger, more diverse dataset covering additional domains would provide insights into the generalizability of the findings.

### Open Question 2
- Question: Can the extended Structure-Mapping Theory (SMT) framework be further refined to better capture the nuances of story-level analogies, especially for higher-order relational structures?
- Basis in paper: [inferred] The paper extends SMT to the story level but acknowledges that it may not fully capture the complexity of story analogies, particularly higher-order relational structures.
- Why unresolved: The current framework may not be sufficient to capture all aspects of story analogies, especially those involving complex higher-order relationships.
- What evidence would resolve it: Developing and evaluating alternative frameworks or refining the existing SMT framework to better handle higher-order relational structures would provide a more comprehensive understanding of story analogies.

### Open Question 3
- Question: How can the performance gap between human and model performance on story analogy identification be reduced?
- Basis in paper: [explicit] The paper highlights the significant performance gap between humans and models, with models achieving around 30% accuracy compared to over 85% for humans.
- Why unresolved: Despite the potential of models, they still struggle to match human performance in identifying story analogies.
- What evidence would resolve it: Developing more sophisticated models, leveraging larger and more diverse training data, or exploring alternative evaluation metrics could help bridge the performance gap.

## Limitations

- The annotation framework based on extended Structure-Mapping Theory may not capture all dimensions of analogical understanding
- The performance gap between human and model performance is measured using a relatively small human baseline
- The dataset is limited to four specific domains (scientific scripts, social narratives, word analogies, and knowledge graph triples)

## Confidence

**High Confidence:**
- The STORYANALOGY corpus construction methodology and its scale (24K story pairs with human annotations) are well-documented and reproducible.
- The finding that existing encoder models and LLMs struggle with story analogy detection is supported by clear experimental evidence showing significantly lower performance compared to human baselines.

**Medium Confidence:**
- The claim that fine-tuning smaller models on STORYANALOGY improves analogy generation quality is supported by results showing FlanT5-xxl achieving comparable performance to zero-shot ChatGPT, though the exact hyperparameters and training procedures could affect reproducibility.
- The effectiveness of in-context learning with demonstrations for LLM-based similarity prediction is demonstrated, but the optimal number and selection of demonstrations remain unspecified.

**Low Confidence:**
- The assertion that STORYANALOGY is the first large-scale story-level analogy corpus may be difficult to verify without comprehensive literature review of all possible related work.
- The generalization of model improvements to domains beyond those represented in STORYANALOGY remains untested and uncertain.

## Next Checks

1. **Annotation Reliability Assessment**: Conduct an independent human annotation study on a subset of STORYANALOGY pairs to verify inter-annotator agreement rates for EntSim, RelSim, and analogy score α, ensuring the annotation framework's consistency across different annotator groups.

2. **Cross-Domain Generalization Test**: Evaluate the best-performing models from the study on a held-out test set containing story analogies from domains not represented in the original STORYANALOGY corpus (e.g., technical narratives or historical accounts) to assess robustness and generalization capabilities.

3. **Prompt Optimization Experiment**: Systematically vary the number and selection of demonstrations in the in-context learning setup for LLM similarity prediction to determine the optimal configuration that maximizes Spearman correlation with human annotations, addressing the current uncertainty about demonstration effectiveness.