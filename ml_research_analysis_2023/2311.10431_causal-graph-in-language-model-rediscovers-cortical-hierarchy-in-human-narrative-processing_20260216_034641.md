---
ver: rpa2
title: Causal Graph in Language Model Rediscovers Cortical Hierarchy in Human Narrative
  Processing
arxiv_id: '2311.10431'
source_url: https://arxiv.org/abs/2311.10431
tags:
- language
- brain
- time
- features
- hierarchy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the relationship between information processing
  in language models and the human brain, particularly focusing on the hierarchical
  organization of cortical areas involved in language processing. The authors hypothesize
  that features in language models that integrate more information from previous layers
  will better predict activity in higher hierarchical brain regions.
---

# Causal Graph in Language Model Rediscovers Cortical Hierarchy in Human Narrative Processing

## Quick Facts
- **arXiv ID**: 2311.10431
- **Source URL**: https://arxiv.org/abs/2311.10431
- **Reference count**: 28
- **Primary result**: Language model features that integrate more information from previous layers better predict activity in higher hierarchical brain regions, with Spearman's rank correlation of 0.54 (p = 0.00014) between information integration index and time constant-based hierarchy.

## Executive Summary
This study investigates the relationship between information processing in language models and the human brain, focusing on how features that integrate more information from previous layers in a language model better predict activity in higher hierarchical brain regions. Using the OPT-125m language model and fMRI data from 345 participants listening to narratives, the authors construct a causal graph to measure information integration via in-degree across model layers. They find that high in-degree features better predict higher cortical regions while low in-degree features align with lower cortical areas, matching the cortical hierarchy inferred from fMRI activity time constants. This supports the hypothesis of a shared information processing principle between language models and the human brain.

## Method Summary
The authors extracted language model features from OPT-125m (12 layers, 768 dimensions) for each token in narrative transcripts, aligned these with fMRI TRs, and averaged features per TR. They reduced dimensionality to 20 using PCA and fit brain activity using ridge regression with FIR model delays. A causal graph was constructed using random noise perturbation between layers to measure information integration (in-degree), which was then used to split features into low and high in-degree groups. Brain prediction accuracy was compared between these groups, and the resulting accuracy maps were compared with cortical hierarchy inferred from fMRI time constants. Spearman's rank correlation was used to assess the relationship between information integration and cortical hierarchy.

## Key Results
- High in-degree language model features better predict higher hierarchical brain regions, while low in-degree features align with lower cortical areas
- The Spearman's rank correlation between information integration index and time constant-based hierarchy is 0.54 (p = 0.00014)
- Language model feature time constants correlate with information integration patterns (Spearman's ρ = 0.30, p = 1e-17)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language model features that integrate more information from previous layers predict higher hierarchical brain regions.
- Mechanism: Causal graph in-degree measures information integration; higher in-degree features correspond to features receiving input from more diverse source features in earlier layers.
- Core assumption: Information integration patterns in language models mirror cortical hierarchy organization.
- Evidence anchors:
  - [abstract] "Drawing inspiration from the workspace framework for consciousness, we hypothesized that features integrating more information would more accurately predict higher hierarchical brain activity."
  - [section 3.4] "Inspired by this observation, we hypothesize that, if LM and the brain share similarity in information processing, part of the language features in the middle-late layers of LM that integrate from a more diverse range of source features, are more likely to predict activity in higher brain hierarchies, and vice versa."
  - [corpus] Weak evidence - only 25 related papers found, average FMR 0.44, suggesting limited direct research on this specific mechanism.

### Mechanism 2
- Claim: Time constants in brain activity reflect cortical hierarchy, with higher regions having longer time constants.
- Mechanism: Auto-correlation time constants computed from fMRI data capture intrinsic temporal dynamics that correlate with hierarchical position in cortical organization.
- Core assumption: Longer time constants indicate higher positions in cortical hierarchy.
- Evidence anchors:
  - [abstract] "the difference in prediction accuracy follows a hierarchical pattern, consistent with the cortical hierarchy map revealed by activity time constants."
  - [section 3.5] "Murray et al. (2014) unveiled an ascending intrinsic time scale within the cortical hierarchy, observed through auto-correlation measurements in the primate cortex."
  - [corpus] Weak evidence - no direct corpus support for this specific temporal hierarchy claim.

### Mechanism 3
- Claim: Features with longer auto-correlation time constants in language models correlate with higher information integration.
- Mechanism: Language model feature time constants reflect the persistence of information integration patterns across tokens, with longer time constants indicating more integrated information.
- Core assumption: Language model feature temporal dynamics parallel brain activity temporal dynamics.
- Evidence anchors:
  - [section 4.5] "The resultant Spearman's rank correlation is 0.30, with a significant p-value of 1e-17."
  - [section 4.4] "the resultant Spearman's rank correlation is 0.54, with a highly significant p-value of 0.00014."
  - [corpus] Weak evidence - no direct corpus support for this specific feature-level temporal correlation.

## Foundational Learning

- Concept: fMRI preprocessing and surface alignment
  - Why needed here: The study uses surface-based fMRI data (fsaverage space) requiring proper preprocessing to align brain activity across subjects
  - Quick check question: What preprocessing steps are necessary to convert volumetric fMRI data to surface representations?

- Concept: Ridge regression with regularization
  - Why needed here: Used to predict voxel-level brain activity from high-dimensional language model features while preventing overfitting
  - Quick check question: How does ridge regression differ from ordinary least squares in handling high-dimensional feature spaces?

- Concept: Principal Component Analysis for dimensionality reduction
  - Why needed here: Reduces language model feature dimensions from 768 to 20 for computational efficiency while preserving variance
  - Quick check question: What percentage of variance should be retained when using PCA for neuroimaging analysis?

## Architecture Onboarding

- Component map: fMRI data → preprocessing → alignment → language model (OPT-125m) → feature extraction → dimensionality reduction → ridge regression → causality analysis → brain prediction → hierarchy comparison
- Critical path: Feature extraction from language model → Causality graph construction → In-degree calculation → Brain activity prediction → Correlation with time constants
- Design tradeoffs: PCA dimensionality reduction (20 components) balances computational efficiency with prediction accuracy
- Failure signatures: Null prediction accuracy when using shuffled features indicates successful implementation; failure to reproduce hierarchical patterns suggests issues with causality calculation or feature grouping
- First 3 experiments:
  1. Verify basic brain prediction accuracy using all features from layer 9
  2. Test causality matrix construction between layers 4 and 9 with thresholded in-degree calculation
  3. Compare brain prediction accuracy between high and low in-degree feature groups to verify hierarchical patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the information integration principle discovered in language models apply to other domains of cognitive processing beyond language?
- Basis in paper: [explicit] The authors note that "it's noteworthy that the correlation between hierarchy and time constant appears to be a general characteristic, not exclusive to language"
- Why unresolved: The study only examined language processing. Testing this principle in other cognitive domains would require different fMRI datasets and language model adaptations.
- What evidence would resolve it: Replicating the study's methodology with fMRI data from non-language cognitive tasks and appropriate computational models.

### Open Question 2
- Question: What specific computational mechanisms in language models drive the observed hierarchical mapping to brain regions?
- Basis in paper: [inferred] The authors find that "features integrating from a broader array of source features...exhibit a higher in-degree" but don't explore why this relationship exists.
- Why unresolved: The study establishes correlation but doesn't investigate underlying computational mechanisms.
- What evidence would resolve it: Detailed analysis of how specific transformer operations (attention, feed-forward networks) contribute to information integration patterns.

### Open Question 3
- Question: How does the size and architecture of language models affect their ability to capture brain-hierarchy relationships?
- Basis in paper: [explicit] The authors test different model sizes but note "While this layer hasn't fully developed features that adeptly predict brain activity, especially in higher cortical areas"
- Why unresolved: The study only tests two model sizes and doesn't systematically explore the architectural parameter space.
- What evidence would resolve it: Comprehensive testing across multiple model sizes, architectures, and training paradigms to identify optimal configurations for brain alignment.

## Limitations

- Causal graph construction method lacks complete specification of critical parameters (perturbation magnitude, sample size, normalization)
- Temporal alignment between language model tokens and fMRI TRs is assumed to be precise without verification
- The interpretation that longer fMRI time constants indicate higher cortical hierarchy relies on a specific theoretical framework with limited exploration of alternatives

## Confidence

- High Confidence: The general finding that language model features show differential brain prediction accuracy aligned with cortical hierarchy is well-supported by multiple statistical tests (Spearman's ρ = 0.54, p = 0.00014) and the consistent pattern across brain regions.
- Medium Confidence: The interpretation that information integration (in-degree) directly corresponds to cortical hierarchy is plausible but depends on the specific implementation of the causal graph method, which has implementation uncertainties.
- Low Confidence: The mechanism by which language model feature time constants relate to information integration patterns lacks direct empirical support in the literature, with weak corpus evidence for this specific relationship.

## Next Checks

1. **Causal Graph Parameter Sensitivity**: Systematically vary the random noise perturbation magnitude and sample size in the causal graph construction to determine how sensitive the in-degree calculations are to these parameters, and whether the hierarchical brain prediction pattern persists across different settings.

2. **Temporal Alignment Verification**: Conduct robustness checks by introducing controlled temporal jitter between language model tokens and fMRI TRs to assess how sensitive the brain prediction accuracy results are to synchronization errors.

3. **Alternative Hierarchy Metrics**: Compare the causal graph-based hierarchy with alternative measures of cortical organization (such as anatomical distance from primary sensory areas) to verify that the observed patterns are specific to information integration rather than other structural factors.