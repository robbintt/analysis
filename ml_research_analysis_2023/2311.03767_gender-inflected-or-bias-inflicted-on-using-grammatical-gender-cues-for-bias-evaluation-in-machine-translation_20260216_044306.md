---
ver: rpa2
title: 'Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for Bias
  Evaluation in Machine Translation'
arxiv_id: '2311.03767'
source_url: https://arxiv.org/abs/2311.03767
tags:
- gender
- bias
- sentences
- translation
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of evaluating gender bias in machine
  translation systems for languages with grammatical gender markers, such as Hindi.
  The key issue is that existing bias evaluation methods focus on gender-neutral sentences,
  which may not reflect the true bias in real-world usage where sentences often contain
  gender information.
---

# Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for Bias Evaluation in Machine Translation

## Quick Facts
- arXiv ID: 2311.03767
- Source URL: https://arxiv.org/abs/2311.03767
- Reference count: 6
- This paper introduces gender-specific evaluation sets for Hindi-English translation to reveal hidden gender bias in NMT systems.

## Executive Summary
This paper addresses the critical limitation in current gender bias evaluation methods for machine translation, which primarily use gender-neutral sentences that may not reflect real-world usage. The authors propose a novel approach that leverages grammatical gender markers in source languages like Hindi to construct evaluation sets that can automatically assess whether translation models correctly identify gender from context. By creating OTSC-Hindi and WinoMT-Hindi test sets with explicit gender cues, the study reveals significant gender bias in popular Hindi-English translation models that was not detected by traditional gender-neutral evaluation methods.

## Method Summary
The authors construct two new evaluation sets for Hindi-English translation: OTSC-Hindi (4,284 sentences) using template-based sentences with gender-inflected verbs, possessive pronouns, and adjectives, and WinoMT-Hindi (704 sentences) based on the WinoBias coreference test set with Hindi gender markers. These sets enable automatic evaluation of gender bias by checking whether the gender identified in the Hindi source sentence is correctly reflected in the English translation through appropriate pronoun usage. The method tests four Hindi-English NMT systems (IndicTrans, Google Translate, Microsoft Translator, AWS Translate) by translating the evaluation sets and automatically detecting gender accuracy through pronoun analysis, without requiring reference translations.

## Key Results
- Existing TGBI metric using gender-neutral sentences fails to fully expose gender bias in NMT systems
- Evaluation on OTSC-Hindi and WinoMT-Hindi reveals significant gender bias in several popular Hindi-English translation models
- The study demonstrates that grammatical gender cues in source languages provide a more rigorous test of gender bias than occupation-based evaluation methods
- Automatic evaluation is possible using gender-specific sentences, eliminating the need for reference translations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gender-specific evaluation sets expose bias that gender-neutral evaluation misses
- Mechanism: By including grammatical gender markers in source sentences, the model must use context to determine gender rather than relying on biased correlations with occupation terms
- Core assumption: NMT models that appear unbiased on gender-neutral evaluation sets may still exhibit significant gender bias when forced to disambiguate gender from context
- Evidence anchors:
  - [abstract] "However, practically, many sentences that we encounter do have gender information. Therefore, it makes more sense to evaluate for bias using such sentences."
  - [section] "We propose to expose gender bias by evaluating NMT models on such source language sentences."
  - [corpus] Weak - corpus shows related work on gender evaluation but doesn't directly support this specific mechanism
- Break condition: If the model consistently uses grammatical gender cues correctly, or if the evaluation method fails to detect bias even when present

### Mechanism 2
- Claim: Template-based sentences enable automatic evaluation without reference translations
- Mechanism: By constructing sentences where gender can be determined from grammatical markers in the source language, target gender can be automatically identified by checking for specific pronouns
- Core assumption: The gender information encoded in the source sentence through grammatical markers can be reliably mapped to gender markers in the target language
- Evidence anchors:
  - [abstract] "We construct two sets of gender-specific sentences: OTSC-Hindi and WinoMT-Hindi that we use to evaluate different Hindi-English (HI-EN) NMT systems automatically for gender bias."
  - [section] "We don't need reference translations in English, as automatic evaluation is possible."
  - [corpus] Weak - corpus shows automatic evaluation methods exist but doesn't validate this specific approach
- Break condition: If the mapping between source grammatical gender and target pronouns becomes unreliable across different sentence structures or language pairs

### Mechanism 3
- Claim: Evaluation using grammatical gender markers reveals different bias patterns than occupation-based evaluation
- Mechanism: By separating gender disambiguation from occupation stereotypes, the evaluation can distinguish between bias in gender coreference resolution and bias in occupation-gender associations
- Core assumption: Bias in NMT systems manifests differently when evaluating gender disambiguation versus occupation-based gender assumptions
- Evidence anchors:
  - [abstract] "This allows us to determine if NMT models can identify the correct gender based on the grammatical gender cues in the source sentence rather than relying on biased correlations with, say, occupation terms."
  - [section] "In creating these sets, we focus on the gender markers of the source language, i.e. Hindi."
  - [corpus] Weak - corpus mentions occupation-based evaluation but doesn't compare patterns with grammatical gender evaluation
- Break condition: If the evaluation fails to separate these two types of bias, or if both evaluation methods produce identical results

## Foundational Learning

- Concept: Grammatical gender systems in languages
  - Why needed here: Understanding how Hindi uses gender inflections on verbs, adjectives, and pronouns is crucial for creating effective evaluation sets
  - Quick check question: How does Hindi mark gender on verbs versus adjectives, and why is this distinction important for evaluation set design?

- Concept: Coreference resolution in NMT
  - Why needed here: The evaluation tests whether models can correctly resolve pronouns to their antecedents based on gender cues rather than stereotypes
  - Quick check question: What are the key challenges in coreference resolution for NMT models, and how do they relate to gender bias?

- Concept: Automatic evaluation metrics for gender bias
  - Why needed here: Understanding metrics like accuracy, ∆G, and ∆S is essential for interpreting evaluation results and comparing model performance
  - Quick check question: How do accuracy, ∆G (difference in F1 scores), and ∆S (difference in macro-F1 scores) complement each other in evaluating gender bias?

## Architecture Onboarding

- Component map: Hindi sentence generation (template-based) -> NMT model interfaces (blackbox APIs and open-source) -> evaluation metrics (automatic gender detection and bias scoring)
- Critical path: Sentence generation -> NMT translation -> Gender detection in output -> Bias metric calculation
- Design tradeoffs: Template-based sentences offer reproducibility and automatic evaluation but may not capture all real-world complexity; open-source vs. blackbox models offer different levels of control and transparency
- Failure signatures: High gender-neutral translation rates may indicate avoidance behavior; consistent masculine defaults suggest strong bias; poor performance on WinoMT-Hindi compared to TGBI may reveal hidden bias
- First 3 experiments:
  1. Evaluate a simple NMT model on OTSC-Hindi to verify the template-based evaluation works as expected
  2. Compare TGBI scores with OTSC-Hindi scores for the same models to demonstrate the value of gender-specific evaluation
  3. Test the sensitivity of evaluation results to different sentence templates with varying complexity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the extent of gender bias in NMT systems when translating gender-specific sentences in languages with grammatical gender markers?
- Basis in paper: [explicit] The authors highlight the need for evaluating gender bias in NMT systems using gender-specific sentences, as opposed to gender-neutral sentences.
- Why unresolved: The study demonstrates the importance of considering the grammatical nature of source languages when designing bias evaluation benchmarks, but does not provide a comprehensive analysis of the extent of gender bias in NMT systems across different languages.
- What evidence would resolve it: A large-scale study evaluating gender bias in NMT systems across multiple languages with grammatical gender markers, using gender-specific sentences.

### Open Question 2
- Question: How can we develop evaluation methods that are more inclusive of all gender identities in NMT systems?
- Basis in paper: [explicit] The authors mention the need for developing evaluation methods that are more inclusive of all gender identities in their conclusion.
- Why unresolved: The paper does not provide specific suggestions or approaches for developing such evaluation methods.
- What evidence would resolve it: Research proposing and testing evaluation methods that consider a broader range of gender identities in NMT systems.

### Open Question 3
- Question: How can we improve the contextualization of occupation stereotypes in different languages for gender bias evaluation in NMT systems?
- Basis in paper: [inferred] The authors mention that the stereotype labels provided by Zhao et al. (2018) might not contextualize well for Hindi and that culturally relevant occupation-related statistics are required for creating stereotype labels for different occupations in Hindi.
- Why unresolved: The paper does not provide a solution or approach for improving the contextualization of occupation stereotypes in different languages.
- What evidence would resolve it: Research proposing and testing methods for improving the contextualization of occupation stereotypes in different languages for gender bias evaluation in NMT systems.

## Limitations
- The evaluation sets are limited to Hindi-English translation and may not generalize to other language pairs
- Template-based sentences may not capture the full complexity of naturally occurring language
- The study focuses on grammatical gender rather than semantic gender associations or non-binary gender identities
- The analysis relies on black-box models, limiting understanding of model behavior

## Confidence
- **High**: The core mechanism that gender-specific evaluation sets can reveal bias missed by gender-neutral evaluation is well-supported by the experimental results.
- **Medium**: The claim that grammatical gender evaluation reveals different bias patterns than occupation-based evaluation is supported but could be strengthened with more diverse test cases.
- **Low**: The assertion that existing evaluation methods "do not fully expose gender bias" is somewhat overstated, as these methods do capture certain types of bias even if not comprehensive.

## Next Checks
1. Recreate the OTSC-Hindi evaluation set using the provided templates and validate that gender markers in Hindi consistently map to expected gender pronouns in English across all sentence variations.
2. Test the evaluation methodology on naturally occurring Hindi sentences from diverse domains (news, literature, social media) to assess real-world applicability beyond template-based sentences.
3. Compare the evaluation results across multiple language pairs with grammatical gender systems (e.g., Spanish, French, Russian) to determine if the findings generalize beyond Hindi-English translation.