---
ver: rpa2
title: Contrastive Explanations of Centralized Multi-agent Optimization Solutions
arxiv_id: '2308.05984'
source_url: https://arxiv.org/abs/2308.05984
tags:
- explanations
- solution
- explanation
- each
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes MAOE, a domain-independent approach to generate
  contrastive explanations for multi-agent optimization solutions. Given a solution
  S that does not satisfy a user's desired property P, MAOE generates a new solution
  S' where P is enforced while minimizing differences between S and S'.
---

# Contrastive Explanations of Centralized Multi-agent Optimization Solutions

## Quick Facts
- arXiv ID: 2308.05984
- Source URL: https://arxiv.org/abs/2308.05984
- Reference count: 7
- Primary result: MAOE generates contrastive explanations that increase user satisfaction and reduce complaints about MAOP solutions

## Executive Summary
This paper introduces MAOE, a domain-independent approach for generating contrastive explanations in multi-agent optimization problems (MAOPs). When users are dissatisfied with a solution that doesn't satisfy their desired property, MAOE creates a hypothetical optimization problem that enforces this property while minimizing changes from the original solution. The approach uses Mixed Integer Linear Programming to balance solution quality against explanation conciseness, producing either abstract explanations (quality metrics) or full explanations (specific changes by agent). User studies across four domains demonstrate that MAOE explanations significantly increase satisfaction with original solutions and reduce complaint intentions, with more detailed explanations being preferred for complex problems.

## Method Summary
MAOE operates by first solving the original MAOP to obtain solution S, then constructing a Hypothetical MAOP (HMAOP) that enforces the user's desired property P through additional constraints. The HMAOP objective function is modified to balance the original objective value with the differences between solutions, tracked by auxiliary variables z(S). Two variants are proposed: Q-MAOE prioritizes solution quality while C-MAOE prioritizes minimal changes. The approach generates contrastive explanations by highlighting differences between the original solution S and the hypothetical solution S', either through abstract quality comparisons or detailed enumeration of specific changes grouped by agents.

## Key Results
- User satisfaction with original solutions increases significantly after receiving MAOE explanations across all four test domains
- Detailed (full) explanations are preferred over abstract explanations, particularly for complex problems like CVRP and WSP
- MAOE can generate explanations for large problems within reasonable computational time, demonstrating scalability
- The approach effectively reduces users' desire to complain about solutions that don't meet their expectations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MAOE generates contrastive explanations by constructing a hypothetical MAOP where the user's desired property is enforced while minimizing changes from the original solution.
- Mechanism: The approach adds constraints to force the property P, introduces auxiliary variables z(S) to track differences, and modifies the objective function to balance solution quality and explanation conciseness.
- Core assumption: The hypothetical MAOP remains solvable after adding property constraints, and the modified objective function can effectively trade off quality versus explanation length.
- Evidence anchors:
  - [abstract] "MAOE, a domain-independent approach to obtain contrastive explanations by: (i) generating a new solution S′ where property P is enforced, while also minimizing the differences between S and S′; and (ii) highlighting the differences between the two solutions"
  - [section] "Definition 2 A Hypothetical Multi-Agent Optimization Problem (HMAOP) is a tuple HMAOP = ⟨A, X′, C′, f, m, S, P⟩" and "min αf (x′) + βz(S) s.t. C ′"
- Break condition: If the hypothetical property P makes the MAOP unsolvable or if the trade-off parameters α and β cannot adequately balance quality and explanation length.

### Mechanism 2
- Claim: User satisfaction increases after receiving contrastive explanations because they understand why the original solution is better than their desired alternative.
- Mechanism: By showing the quality loss (abstract explanation) or specific changes (full explanation) between the original and hypothetical solutions, users gain insight into the optimization trade-offs.
- Core assumption: Users' dissatisfaction stems from not understanding the optimization trade-offs, not from the actual solution quality being poor.
- Evidence anchors:
  - [abstract] "after being presented with these explanations, humans' satisfaction with the original solution increases"
  - [section] "The main effect was statistically significant in all domains; KP ( F (1) = 41 .26, p < 0.01), WSP ( F (1) = 95 .70, p < 0.01)"
- Break condition: If users' dissatisfaction is due to fundamental issues with solution quality rather than lack of understanding.

### Mechanism 3
- Claim: More detailed explanations (full vs abstract) lead to higher user satisfaction, particularly for complex problems.
- Mechanism: Full explanations enumerate specific changes grouped by agents, providing transparency about how individual preferences were affected.
- Core assumption: Users value transparency about specific trade-offs over general quality metrics, especially when problems are complex.
- Evidence anchors:
  - [section] "users reported higher satisfaction with the abstract and full explanations rather than the baseline explanation. In CVRP and WSP, users were significantly more satisfied with the full explanation in comparison to the abstract explanation"
  - [section] "In CVRP and WSP, users were significantly more satisfied with the full explanation in comparison to the abstract explanation. However, their satisfaction with the abstract and full explanations was much closer in the KP and TAP domains"
- Break condition: If users find detailed explanations overwhelming or if the complexity of full explanations outweighs their benefits.

## Foundational Learning

- Mixed Integer Programming (MIP):
  - Why needed here: MAOE operates on MAOPs formulated as MIPs, so understanding MIP modeling is essential for implementing the approach.
  - Quick check question: What are the three key components needed to formulate a problem as a MIP?

- Contrastive vs Counterfactual Explanations:
  - Why needed here: MAOE generates contrastive explanations (comparing original vs hypothetical solutions) rather than counterfactual explanations (what could have been different).
  - Quick check question: What is the key difference between contrastive and counterfactual explanations in the context of MAOE?

- Objective Function Modification:
  - Why needed here: MAOE modifies the objective function to balance solution quality and explanation length using parameters α and β.
  - Quick check question: How do the parameters α and β in MAOE's objective function affect the trade-off between solution quality and explanation length?

## Architecture Onboarding

- Component map:
  - MAOP Solver -> HMAOP Generator -> Difference Calculator -> Explanation Generator -> User Interface

- Critical path:
  1. Solve original MAOP to get S
  2. Generate HMAOP based on user's property P
  3. Solve HMAOP to get S'
  4. Compute differences between S and S'
  5. Generate explanation
  6. Present to user

- Design tradeoffs:
  - Quality vs Explanation Length: Using Q-MAOE prioritizes solution quality while C-MAOE prioritizes concise explanations
  - Abstract vs Full Explanations: Abstract explanations are quicker to generate but less informative than full explanations
  - Computational Overhead: Generating HMAOP adds complexity but provides valuable user insights

- Failure signatures:
  - HMAOP Unsolvable: Property P makes the problem infeasible
  - Long Explanation Generation: Too many changes between S and S'
  - User Dissatisfaction: Explanations don't address user's actual concerns

- First 3 experiments:
  1. Test MAOE on a simple KP instance to verify basic functionality
  2. Compare Q-MAOE vs C-MAOE on a medium TAP problem to understand trade-offs
  3. Run user study on WSP domain to validate satisfaction improvements

## Open Questions the Paper Calls Out

- What is the impact of generating diverse explanations from multiple optimal solutions in HMAOPs on user satisfaction?
  - Basis in paper: Explicit - The paper mentions that HMAOPs often have a few optimal solutions and suggests characterizing each to present diverse explanations in future work.
  - Why unresolved: The paper does not explore the effects of presenting multiple explanations to users or how this might influence their understanding and satisfaction.
  - What evidence would resolve it: A user study comparing satisfaction levels when presented with a single explanation versus multiple diverse explanations for the same problem.

- How do privacy and fairness considerations affect the quality and acceptability of explanations in MAOE?
  - Basis in paper: Explicit - The paper notes the need to extend MAOE to consider agents' privacy or fairness when generating explanations as future work.
  - Why unresolved: The current implementation does not address how sensitive information or fairness constraints might limit the detail or type of explanations that can be provided.
  - What evidence would resolve it: An analysis of explanation quality and user acceptance under different privacy and fairness constraints applied to the optimization problem.

- How does the complexity of the objective function (number and type of terms) affect the scalability and effectiveness of MAOE?
  - Basis in paper: Inferred - The paper evaluates MAOE on four domains with different objective function structures but does not systematically analyze the effect of objective function complexity.
  - Why unresolved: While the paper shows MAOE works across different domains, it does not isolate how variations in objective function complexity (e.g., number of terms, non-linear terms) impact performance.
  - What evidence would resolve it: A controlled experiment varying the complexity of objective functions within a domain and measuring changes in solving time, explanation length, and user satisfaction.

## Limitations

- The computational evaluation demonstrates scalability but lacks rigorous analysis of how quality-explanation trade-off parameters affect solution feasibility and explanation effectiveness.
- User satisfaction improvements may be influenced by novelty effects or presentation format rather than MAOE's inherent value.
- Claims about domain-independence and scalability to "real-world" problems are not fully validated given limited domain diversity and problem sizes tested.

## Confidence

- High Confidence: MAOE's core mechanism for generating contrastive explanations through hypothetical MAOP construction is technically sound and well-implemented
- Medium Confidence: The user satisfaction improvements are real but may be influenced by novelty effects or the specific presentation format rather than MAOE's inherent value
- Low Confidence: Claims about MAOE's domain-independence and scalability to "real-world" problems are not fully validated given the limited domain diversity and problem sizes tested

## Next Checks

1. **Parameter Sensitivity Analysis:** Systematically vary α and β parameters across multiple problem instances to quantify their impact on explanation quality, solution feasibility, and computational performance, establishing recommended parameter ranges for different use cases.

2. **Longitudinal User Study:** Conduct a follow-up study with the same participants after 2-4 weeks to measure retention of satisfaction improvements and whether initial positive reactions persist over time, including qualitative interviews about explanation comprehension.

3. **Cross-Domain Stress Test:** Apply MAOE to 2-3 additional real-world MAOP domains (e.g., ride-sharing coordination, distributed energy management) with problems 2-3x larger than current test cases to validate claimed scalability and domain-independence.