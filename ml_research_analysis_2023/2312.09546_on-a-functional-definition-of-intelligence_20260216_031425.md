---
ver: rpa2
title: On a Functional Definition of Intelligence
arxiv_id: '2312.09546'
source_url: https://arxiv.org/abs/2312.09546
tags:
- intelligence
- definition
- system
- reasoning
- goal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a functional, black-box definition of intelligence
  that is testable through external observation. The authors argue that traditional
  philosophical and cognitive science approaches are insufficient for defining intelligence
  in artificial systems.
---

# On a Functional Definition of Intelligence

## Quick Facts
- arXiv ID: 2312.09546
- Source URL: https://arxiv.org/abs/2312.09546
- Reference count: 7
- This paper presents a functional, black-box definition of intelligence that is testable through external observation.

## Executive Summary
This paper proposes a functional definition of intelligence that can be measured through black-box testing rather than requiring knowledge of internal implementation. The authors argue that traditional philosophical approaches are insufficient for defining intelligence in artificial systems, and instead present intelligence as a combination of six measurable components: knowledge quality, planning quality, planning performance, world model learning, planning learning, and performance learning. The framework treats intelligence as a continuous variable rather than binary, suggesting that any system exhibiting these properties demonstrates some degree of intelligence.

The work establishes conceptual clarity by distinguishing intelligence from related concepts like sentience, sensation, agency, and skill, positioning these as orthogonal properties. This separation is particularly important for AI safety and ethics discussions, as it allows for more precise communication about what properties different AI systems possess. The authors acknowledge that while they have defined how intelligence could be measured, actually implementing these measurements remains an open challenge.

## Method Summary
The paper employs an argumentative methodology to establish a theoretical framework for intelligence measurement. Rather than conducting empirical experiments, the authors develop a mathematical formulation of intelligence that combines six components into a weighted sum. The method involves reviewing related concepts (sentience, sensation, agency, skill) and establishing their orthogonality to intelligence, then developing the mathematical equation that quantifies intelligence. The approach focuses on creating a testable definition through external observation, advocating for black-box testing approaches that evaluate system responses given inputs without requiring knowledge of internal implementation details.

## Key Results
- Intelligence can be defined as a weighted sum of six measurable components: knowledge quality, planning quality, planning performance, world model learning, planning learning, and performance learning
- The framework treats intelligence as a continuous variable rather than binary, suggesting partial intelligence is possible
- Intelligence is conceptually distinct from sentience, sensation, agency, and skill, enabling clearer AI safety and ethics discussions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Intelligence can be measured as a continuous variable rather than a binary property
- Mechanism: The paper defines intelligence as a weighted sum of six measurable components (knowledge quality, planning quality, planning performance, world model learning, planning learning, and performance learning), allowing for partial intelligence
- Core assumption: Each component can be objectively quantified and combined linearly
- Evidence anchors:
  - [abstract] "suggests intelligence is a continuous variable"
  - [section 3] "Intelligence can then be defined as: Ii = α||WiS − W*S||w + β||Wigoal − (A'(WiS) ⇒ WiS')||w/γtA' + δ ∂WiS/∂D + ε ∂f(WiS,Wigoal)/∂D − ζ ∂tA'/∂D"
  - [corpus] Weak - corpus papers discuss related concepts but don't provide measurement frameworks
- Break condition: If any component cannot be objectively measured, the entire quantification framework fails

### Mechanism 2
- Claim: Functional definitions of intelligence are testable through black-box observation
- Mechanism: By focusing on inputs and outputs rather than internal processes, intelligence can be evaluated without knowing implementation details
- Core assumption: External behavior correlates with internal intelligence regardless of implementation method
- Evidence anchors:
  - [section 2.1] "we advocate that a useful definition of intelligence must be testable through black-box testing"
  - [section 1] "our focus on functional definitions: a system should be deemed intelligent strictly by its response, given inputs"
  - [corpus] Weak - corpus papers discuss AI definitions but don't address testing methodology
- Break condition: If external behavior can be faked without actual intelligence (as with current LLMs on Turing test), black-box testing becomes insufficient

### Mechanism 3
- Claim: Distinguishing intelligence from related concepts enables clearer AI safety and ethics discussions
- Mechanism: By separating intelligence from autonomy, agency, skill, sentience, and sensations, the paper creates conceptual clarity for regulatory frameworks
- Core assumption: These concepts can be meaningfully separated in practice
- Evidence anchors:
  - [section 2.2] "Our goal here is to demonstrate that these concepts are orthogonal to intelligence"
  - [section 2.2] "Agency does not imply intelligence: a system may make nonsensical decisions (because it is not intelligent or skilled), but that still demonstrates agency"
  - [corpus] Moderate - corpus papers discuss AI alignment and ethics but don't provide orthogonal definitions
- Break condition: If these concepts are inherently intertwined in real systems, the separation becomes meaningless for practical applications

## Foundational Learning

- Concept: Mathematical formulation of intelligence
  - Why needed here: The paper uses mathematical notation to precisely define intelligence components
  - Quick check question: Can you explain what each term in the intelligence equation represents?

- Concept: World model theory
  - Why needed here: Intelligence measurement depends on comparing internal world models to reality
  - Quick check question: How does the paper define a "world model" and what components does it contain?

- Concept: Orthogonal properties
  - Why needed here: The paper separates intelligence from other concepts like sentience and autonomy
  - Quick check question: Why is it important to distinguish intelligence from skill or agency?

## Architecture Onboarding

- Component map:
  - Measurement system for each of six intelligence components
  - World model comparison framework
  - Planning evaluation module
  - Learning rate assessment tools
  - Weight parameter optimization system

- Critical path:
  1. Define world model representation for target system
  2. Establish baseline measurements for all six components
  3. Implement comparative analysis with real-world data
  4. Create learning progression tracking
  5. Optimize weight parameters for domain-specific applications

- Design tradeoffs:
  - Black-box vs. white-box measurement: Black-box enables implementation independence but may miss internal intelligence
  - Component weighting: Different domains may require different weight parameters
  - Measurement precision vs. practicality: More precise measurements may be harder to implement

- Failure signatures:
  - Over-reliance on skill measurements indicates intelligence being confused with competence
  - Binary classifications suggest the continuous nature is being ignored
  - Implementation-specific measurements indicate loss of functional definition focus

- First 3 experiments:
  1. Apply the framework to a chess engine vs. a human player to test component measurement
  2. Compare a simple control system (thermostat) against the intelligence definition
  3. Test the framework on an LLM with controlled input variations to measure learning components

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we objectively measure the components of intelligence (knowledge quality, planning quality, performance, learning rates) defined in the paper's equation?
- Basis in paper: [explicit] The authors acknowledge this as the biggest challenge, stating "we have not described how to measure the terms that make up our intelligence equation" and noting the difficulty of measuring derivatives like ∂W i S/∂D.
- Why unresolved: The authors argue that any measurement is relative to the observer, and our knowledge of the real world W* is incomplete. Additionally, defining boundaries between what should and should not be part of the world model is fuzzy.
- What evidence would resolve it: Development of standardized, objective metrics for each component that can be applied across different systems, or experimental results demonstrating consistent measurement techniques.

### Open Question 2
- Question: Can intelligence exist in systems that lack one or more of the three proposed properties (learning, knowledge, reasoning)?
- Basis in paper: [explicit] The authors state "any system that exhibits at least one of those properties is at least partially intelligent," suggesting intelligence is a continuum rather than binary.
- Why unresolved: The paper provides a theoretical framework but doesn't explore the boundaries of this continuum or whether systems with only one property could be considered intelligent.
- What evidence would resolve it: Empirical studies comparing systems with varying combinations of the three properties to determine if systems lacking certain properties can still be classified as intelligent.

### Open Question 3
- Question: How can we develop tests of intelligence that are relative to observer intelligence rather than attempting absolute measurements?
- Basis in paper: [explicit] The authors conclude that "developing an objective, absolute test of intelligence is likely impossible" but suggest "developing tests of intelligence relative to observer intelligence is likely possible."
- Why unresolved: The paper identifies this as a potential direction but doesn't provide specific methodologies for creating such relative tests.
- What evidence would resolve it: Successful implementation and validation of intelligence tests that measure relative differences between systems rather than absolute intelligence levels.

## Limitations
- The paper does not demonstrate how to actually measure the six components in real systems, leaving the practical implementation of the framework unresolved
- The framework assumes intelligence can be objectively quantified through external observation, but current AI systems can often simulate intelligent behavior without genuine understanding
- The orthogonal separation of concepts like sentience, agency, and skill from intelligence may not hold in practice as these properties may be more interconnected in real systems

## Confidence
- Practical measurement protocol development: Low confidence - The paper acknowledges this as an open challenge without providing solutions
- Cross-system applicability: Medium confidence - The black-box approach is promising but untested across different architectures
- Conceptual framework validity: High confidence - The theoretical arguments for separating intelligence from related concepts are well-reasoned

## Next Checks
1. **Practical Measurement Protocol**: Design and implement a concrete protocol to measure each of the six intelligence components in a simple AI system (e.g., a game-playing agent) to test if the components can be objectively quantified.

2. **Cross-System Comparison**: Apply the framework to compare fundamentally different AI systems (e.g., a rule-based expert system vs. a neural network) to validate whether the same measurement approach works across architectures.

3. **Edge Case Analysis**: Test the framework on systems that are clearly non-intelligent (e.g., simple calculators or thermostats) and borderline cases (e.g., current LLMs) to verify the continuous nature and identify where the framework breaks down.