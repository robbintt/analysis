---
ver: rpa2
title: 'Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents
  via Semantic-Oriented Hierarchical Graphs'
arxiv_id: '2305.01938'
source_url: https://arxiv.org/abs/2305.01938
tags:
- document
- graph
- node
- question
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses discrete reasoning over visually-rich table-text
  documents, specifically on the TAT-DQA dataset. The authors propose a novel Doc2SoarGraph
  framework that leverages element-level semantics (Question, Block, Quantity, Date)
  to enhance reasoning capabilities.
---

# Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents via Semantic-Oriented Hierarchical Graphs

## Quick Facts
- arXiv ID: 2305.01938
- Source URL: https://arxiv.org/abs/2305.01938
- Reference count: 18
- Key outcome: Achieves 59.23% EM and 67.61% F1 on TAT-DQA test set, outperforming MHST by 17.73% and 16.91% respectively

## Executive Summary
This paper introduces Doc2SoarGraph, a novel framework for discrete reasoning over visually-rich table-text documents. The key innovation is a hierarchical graph-based approach that models element-level semantics (Question, Block, Quantity, Date) rather than token-level reasoning. By constructing four types of graphs that capture magnitude comparisons, temporal sequences, text relations, and semantic dependencies, the framework significantly improves reasoning accuracy. Experiments on the TAT-DQA dataset demonstrate state-of-the-art performance, with particularly strong results on arithmetic questions where it gains the largest improvements over baseline models.

## Method Summary
Doc2SoarGraph processes multi-page visually-rich documents by first transforming them into a unified format and extracting semantic elements using LayoutLMv2. The framework constructs hierarchical graphs (QC, DC, TR, SD) where nodes represent different element types and edges capture semantic relationships. Graph Convolutional Networks learn node representations, which are then used by a node classifier to select relevant evidence. Finally, specialized decoders (span, tree, or number generators) produce answers based on the selected elements. The system is trained with Adam optimizer (learning rate 5e-4) using dropout and beam search for inference.

## Key Results
- Achieves 59.23% Exact Match (EM) and 67.61% F1 on TAT-DQA test set
- Outperforms previous state-of-the-art MHST model by 17.73% EM and 16.91% F1
- Shows largest performance gains on Arithmetic questions (19.35% EM improvement)
- Ablation studies confirm importance of node initialization and hierarchical graph modeling

## Why This Works (Mechanism)

### Mechanism 1
Modeling element-level semantics via hierarchical graphs improves discrete reasoning by capturing correlations between quantities, dates, questions, and blocks. The framework builds four types of graphs (QC, DC, TR, SD) that model magnitude comparisons, temporal sequences, text relations, and semantic dependencies among four element types. GCNs learn node representations that guide evidence selection. Core assumption: semantic relationships between elements are more informative for reasoning than token co-occurrence alone.

### Mechanism 2
Node initialization with LayoutLMv2 outputs provides richer semantic context than isolated token embeddings. The encoder produces contextualized token representations for question, document text, layout, and image. Element nodes are initialized by averaging tokens within their span, preserving richer semantics. Core assumption: token-level embeddings lose critical context when combined across different semantic elements; element-level embeddings retain this context.

### Mechanism 3
Hierarchical graph representation allows selective evidence extraction before reasoning, reducing noise. The SD graph combines QC, DC, TR, and direct edges; GCN(SD) produces node embeddings used by a node classifier to select only relevant elements. This reduces the reasoning space. Core assumption: most document elements are irrelevant to the question; selecting a small subset improves accuracy.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) / Graph Convolutional Networks (GCNs)
  - Why needed here: To learn node representations that encode local graph structure (edges) and propagate information between related elements
  - Quick check question: What is the key difference between a GCN and a standard feed-forward network when applied to graphs?

- Concept: Multi-modal pre-training (e.g., LayoutLMv2)
  - Why needed here: To fuse text, layout, and visual embeddings into a shared representation space before element extraction
  - Quick check question: How does LayoutLMv2 incorporate visual features into token embeddings?

- Concept: Tree-based expression generation (e.g., GTS)
  - Why needed here: To generate arithmetic expression trees over selected nodes for numeric reasoning
  - Quick check question: What is the advantage of using a goal-driven tree generation approach over flat decoding?

## Architecture Onboarding

- Component map: Multi-page Document Transformation -> LayoutLMv2 Encoder -> Node Initialization -> Hierarchical Graph Construction -> Node Selection (GCNs + Classifier) -> Answer Generation (Type Classifier + Specialized Decoders + Scale Classifier)
- Critical path: Document -> LayoutLMv2 -> Node Init -> GCN(SD) -> Node Classifier -> Answer Decoder
- Design tradeoffs:
  - Using four dedicated GCNs vs parameter sharing: dedicated gives best accuracy but more parameters
  - Selecting a fixed max number of nodes (12) vs dynamic: fixed is simpler but may truncate relevant nodes
- Failure signatures:
  - Node classifier misses relevant nodes -> wrong evidence -> wrong answer
  - Tree generator produces wrong signs -> arithmetic errors
  - Span classifier offset -> answer span mismatch
- First 3 experiments:
  1. Run end-to-end on a single sample with multi-page doc -> verify transformation works
  2. Print node selection counts and accuracy on dev set -> check evidence extraction quality
  3. Ablate GCN(SD) -> confirm node representations improve over raw LayoutLMv2 embeddings

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of Doc2SoarGraph compare on documents with a very large number of pages (>50)?
- Basis in paper: The paper mentions that the Multi-page Document Transformation technique may not be applicable to documents with a large number of pages (e.g., >50 pages)
- Why unresolved: The paper does not provide experimental results or analysis on the performance of Doc2SoarGraph on documents with a very large number of pages
- What evidence would resolve it: Conducting experiments on documents with a varying number of pages, including those with >50 pages, and comparing the performance of Doc2SoarGraph to other models

### Open Question 2
How does the performance of Doc2SoarGraph vary across different types of documents (e.g., pure textual documents vs. documents with tables and text)?
- Basis in paper: The paper mentions that the framework is designed for documents containing different kinds of elements, such as numerical values and dates, and may have limited advantages over documents with unique elements like pure textual documents
- Why unresolved: The paper does not provide experimental results or analysis on the performance of Doc2SoarGraph across different types of documents
- What evidence would resolve it: Conducting experiments on various types of documents (e.g., pure textual, documents with tables and text, documents with different layouts) and comparing the performance of Doc2SoarGraph to other models

### Open Question 3
How does the choice of the LayoutLMv2 model as the encoder affect the performance of Doc2SoarGraph?
- Basis in paper: The paper mentions that they build their framework based on the pre-trained LayoutLMv2 model
- Why unresolved: The paper does not provide an ablation study or comparison with other encoder models to demonstrate the impact of the choice of LayoutLMv2 on the performance of Doc2SoarGraph
- What evidence would resolve it: Conducting an ablation study where different encoder models (e.g., BERT, RoBERTa, other document understanding models) are used and comparing their performance with the LayoutLMv2-based Doc2SoarGraph

## Limitations

- The hierarchical graph construction introduces potential failure points, particularly with the fixed node selection threshold (0.5) that may not be optimal for all question types
- Edge weight determination in the QC, DC, and TR graphs is not clearly specified, leaving uncertainty about how similarity thresholds are set
- The 12-node limit for selected elements may truncate relevant information for complex multi-step reasoning problems
- Performance on documents with very large numbers of pages (>50) is not evaluated and may be problematic

## Confidence

High confidence: The EM/F1 improvements over MHST (17.73% and 16.91%) are well-supported by the experimental results. The claim that hierarchical graphs improve discrete reasoning by capturing element-level semantics is substantiated by both ablation studies and per-question-type performance analysis.

Medium confidence: The claim that node initialization with LayoutLMv2 outputs provides "surprisingly greater contributions" is supported by ablation results, but the relative importance compared to other components isn't precisely quantified.

Low confidence: The claim that the framework "effectively models the differences and correlations among quantities, dates and blocks" is somewhat vague - while the architecture supports this, the paper doesn't provide qualitative analysis showing how specific graph structures contribute to particular reasoning steps.

## Next Checks

1. **Edge Weight Sensitivity Analysis**: Run experiments varying edge weight thresholds in the QC, DC, and TR graphs (e.g., 0.3, 0.5, 0.7) and measure impact on node selection accuracy and final answer quality. This will reveal whether the current threshold is optimal or if the model is sensitive to these parameters.

2. **Node Selection Threshold Ablation**: Systematically vary the node classifier threshold from 0.3 to 0.7 and evaluate how many relevant nodes are missed at each threshold. This will quantify the tradeoff between precision and recall in evidence selection and identify if the current 0.5 threshold is suboptimal for certain question types.

3. **Cross-Dataset Generalization**: Test Doc2SoarGraph on a different visually-rich document QA dataset (e.g., TAT-QA or ChartQA) without fine-tuning to assess whether the hierarchical graph approach generalizes beyond TAT-DQA. This would validate whether the architectural improvements are dataset-specific or represent genuine methodological advances in discrete reasoning.