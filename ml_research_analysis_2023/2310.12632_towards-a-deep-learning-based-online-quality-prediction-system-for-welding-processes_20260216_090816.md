---
ver: rpa2
title: Towards a Deep Learning-based Online Quality Prediction System for Welding
  Processes
arxiv_id: '2310.12632'
source_url: https://arxiv.org/abs/2310.12632
tags:
- welding
- quality
- process
- data
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a concept for a deep learning-based online
  quality prediction system for gas metal arc welding (GMAW) processes. The approach
  addresses the challenge of economically unfeasible destructive testing in non-laboratory
  environments with frequently changing process parameters.
---

# Towards a Deep Learning-based Online Quality Prediction System for Welding Processes

## Quick Facts
- arXiv ID: 2310.12632
- Source URL: https://arxiv.org/abs/2310.12632
- Reference count: 31
- Primary result: Presents a concept for deep learning-based online quality prediction system for GMAW welding processes

## Executive Summary
This paper presents a conceptual framework for a deep learning-based online quality prediction system for gas metal arc welding (GMAW) processes. The system addresses the challenge of economically unfeasible destructive testing in non-laboratory environments by enabling real-time quality predictions during production. The approach leverages multi-sensor data collection, autoencoders for feature compression, LSTM networks for temporal modeling, and continual learning strategies to handle process variations. The concept aims to provide immediate feedback to operators and allow for ad-hoc adjustments to enhance weld quality.

## Method Summary
The proposed method involves a four-phase pipeline: (1) multi-sensor data collection and management using TimescaleDB for high-frequency time series data, (2) real-time processing and feature engineering using autoencoders to compress droplet detachment phase data and extract statistical features, (3) training and deployment of recurrent deep learning models (LSTMs) for quality predictions using sequences of feature vectors from multiple cycles, and (4) model evolution under changing conditions using continual learning with elastic weight consolidation (EWC) or memory-aware synapses (MAS) to prevent catastrophic forgetting. The system processes current and voltage time series data at 100 kHz sampling rate, extracting features from three distinct phases of each welding cycle.

## Key Results
- Proposes a deep learning-based system for online quality prediction in GMAW welding processes
- Introduces autoencoder-based feature compression of droplet detachment phase data
- Implements LSTM networks for temporal modeling across multiple welding cycles
- Incorporates continual learning strategies (EWC/MAS) to handle process variations
- Enables real-time quality predictions during running production for immediate operator feedback

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Autoencoder embeddings compress cyclic welding phase data while preserving quality-relevant features
- Mechanism: The autoencoder learns to reconstruct input sequences from the droplet detachment phase, forcing the encoder to capture the most salient features. These compressed embeddings, when concatenated with statistical features, provide a compact yet informative representation for the LSTM
- Core assumption: The droplet detachment phase contains the most quality-relevant information, and the autoencoder can learn to compress this without significant information loss
- Evidence anchors:
  - [section] "The pipeline starts by extracting the different cycles ci. Then each cycle is split into the three phases... We will primarily focus on the second phase p2i because this phase includes the detachment of the droplet which has a high impact on the resulting quality."
  - [section] "For this task, an autoencoder is used to compress the information of the data through a bottleneck by predicting the initial input in an unsupervised manner"
  - [corpus] Weak evidence for this specific approach in welding literature; autoencoders are used in related domains but not specifically for this welding phase compression
- Break condition: If the droplet detachment phase doesn't contain sufficient quality-relevant information, or if the autoencoder cannot learn meaningful compression

### Mechanism 2
- Claim: LSTM networks can capture temporal dependencies across welding cycles for quality prediction
- Mechanism: The LSTM processes sequences of feature vectors extracted from multiple cycles, using its memory cells to maintain state across time steps and capture long-term dependencies that affect weld quality
- Core assumption: Quality is determined by patterns that emerge across multiple cycles, not just individual cycle characteristics
- Evidence anchors:
  - [section] "Given that electrical power is responsible for liquification of the welding wire... sequences across multiple cycles as a whole provide valuable information and thusly relevant data to estimate the quality of the weld."
  - [section] "Long short-term memory LSTM models are known to work well on sequence processing tasks because they have an improved remembering capacity compared to standard recurrent cells"
  - [corpus] LSTM usage in similar manufacturing quality prediction contexts, though not specifically for this welding application
- Break condition: If the temporal dependencies are too short-range for LSTM to provide advantage over simpler models, or if sequence length makes training impractical

### Mechanism 3
- Claim: Elastic Weight Consolidation prevents catastrophic forgetting during continual learning of process variations
- Mechanism: EWC identifies important weights from previous tasks and adds a regularization term that penalizes changes to these weights when learning new tasks, preserving knowledge about previous process conditions
- Core assumption: The neural network weights that were important for previous process conditions remain important, and process changes are gradual enough that retaining this knowledge is beneficial
- Evidence anchors:
  - [section] "Our solution concept involves the use of regularization strategies such as elastic weight consolidation (EWC) [18] or memory-aware synapses (MAS) [19]. They ensure that the underlying neural network does not forget previous knowledge when trained on new process data."
  - [section] "As described in Section 3, continual learning methods and especially regularization strategies are suitable in this context."
  - [corpus] EWC has been successfully applied in manufacturing contexts per [20] and [21], though not specifically for welding
- Break condition: If process changes are too drastic, making retention of old knowledge counterproductive, or if the regularization strength is poorly tuned

## Foundational Learning

- Concept: Time series feature engineering for cyclical processes
  - Why needed here: Welding current and voltage data are cyclical with distinct phases that each contribute differently to quality outcomes
  - Quick check question: Can you explain why the droplet detachment phase is more important than the pulse or base current phases for quality prediction?

- Concept: Autoencoder training and feature extraction
  - Why needed here: Raw cyclic data is too high-dimensional for direct LSTM processing; autoencoders provide dimensionality reduction while preserving quality-relevant patterns
  - Quick check question: What's the difference between using an autoencoder for feature extraction versus manual statistical feature engineering?

- Concept: Continual learning and catastrophic forgetting
  - Why needed here: Welding processes change over time due to equipment wear, parameter adjustments, and material variations, requiring models to adapt without losing previous knowledge
  - Quick check question: How does EWC differ from simply fine-tuning a model on new data, and why is this important for manufacturing applications?

## Architecture Onboarding

- Component map: Data collection -> TimescaleDB storage -> Cycle/phase extraction -> Statistical feature calculation -> Autoencoder training -> Feature vector creation -> LSTM classification -> EWC regularization -> Online prediction -> Visualization
- Critical path: Real-time data ingestion -> Feature extraction pipeline -> Model inference -> Quality prediction visualization
- Design tradeoffs: Higher sampling rates capture more detail but increase storage/computation; deeper autoencoders extract more complex features but risk overfitting; stronger EWC regularization preserves knowledge but may slow adaptation to new conditions
- Failure signatures: Poor quality predictions when process parameters change significantly; slow inference times during online prediction; model degradation over time without continual learning updates
- First 3 experiments:
  1. Train autoencoder on historical droplet detachment phase data and evaluate reconstruction error to validate compression quality
  2. Train LSTM on feature vectors from multiple cycles and evaluate quality prediction accuracy on held-out test data
  3. Simulate process change by training on data from one parameter set, then evaluating on another set with EWC vs. without EWC to measure catastrophic forgetting prevention

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed deep learning-based online quality prediction system perform compared to traditional quality assessment methods (e.g., destructive testing) in terms of accuracy and economic feasibility for small batch sizes?
- Basis in paper: [explicit] The paper mentions that destructive testing is economically unfeasible for small batch sizes and proposes a deep learning-based system as an alternative.
- Why unresolved: The paper presents a concept for the system but does not provide experimental results or comparisons with traditional methods.
- What evidence would resolve it: Experimental results comparing the accuracy and cost-effectiveness of the proposed system with traditional quality assessment methods on actual welding data.

### Open Question 2
- Question: What is the optimal sequence length and sampling rate for capturing relevant information from the current and voltage time series data in the welding process?
- Basis in paper: [inferred] The paper discusses the importance of capturing information from multiple cycles and mentions a high sampling rate of 100 kHz, but does not determine the optimal sequence length or sampling rate.
- Why unresolved: The paper presents a concept for feature engineering but does not experimentally determine the optimal parameters for data preprocessing.
- What evidence would resolve it: Experimental results showing the impact of different sequence lengths and sampling rates on the performance of the quality prediction model.

### Open Question 3
- Question: How does the continual learning approach using elastic weight consolidation or memory-aware synapses perform in adapting to sudden or gradual changes in the welding process compared to retraining the model from scratch?
- Basis in paper: [explicit] The paper proposes using continual learning methods to update the model under changing process conditions but does not provide experimental results comparing different approaches.
- Why unresolved: The paper presents a concept for continual learning but does not evaluate its performance against alternative methods.
- What evidence would resolve it: Experimental results comparing the performance of the proposed continual learning approach with retraining from scratch or other continual learning methods on data with process variations.

## Limitations
- Lacks empirical validation with no reported results on real welding data
- Critical architectural details (autoencoder/LSTM specifications, sampling rates, window sizes) remain unspecified
- Assumes current and voltage time series alone are sufficient for quality prediction without considering complementary data sources

## Confidence
- High confidence: The overall pipeline architecture (data collection → feature engineering → model training → continual learning) represents a sound conceptual framework for online quality prediction
- Medium confidence: The use of autoencoders for feature compression and LSTMs for temporal modeling is appropriate based on established literature in similar domains
- Low confidence: The effectiveness of the proposed continual learning approach (EWC/MAS) for welding process adaptation without catastrophic forgetting

## Next Checks
1. Implement the autoencoder feature extraction pipeline and evaluate reconstruction quality on historical welding data to verify that the droplet detachment phase contains sufficient quality-relevant information for compression
2. Train and evaluate the complete LSTM-based quality prediction system on a benchmark welding dataset to establish baseline performance metrics and compare against traditional statistical methods
3. Design a controlled experiment simulating process variations to test the continual learning implementation, measuring catastrophic forgetting rates with and without EWC/MAS regularization across multiple task transitions