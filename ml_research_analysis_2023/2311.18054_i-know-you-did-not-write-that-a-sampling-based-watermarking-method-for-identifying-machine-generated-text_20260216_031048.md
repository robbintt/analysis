---
ver: rpa2
title: I Know You Did Not Write That! A Sampling Based Watermarking Method for Identifying
  Machine Generated Text
arxiv_id: '2311.18054'
source_url: https://arxiv.org/abs/2311.18054
tags:
- text
- watermarking
- generated
- sampling
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a new watermarking method for detecting machine-generated
  text by intervening with the token sampling process. The method embeds a unique
  pattern in the generated text by maximizing a "secret number" for each token, which
  can be algorithmically identified.
---

# I Know You Did Not Write That! A Sampling Based Watermarking Method for Identifying Machine Generated Text

## Quick Facts
- arXiv ID: 2311.18054
- Source URL: https://arxiv.org/abs/2311.18054
- Authors: 
- Reference count: 18
- Key outcome: Proposes a watermarking method that embeds a unique pattern in generated text by maximizing a "secret number" for each token, achieving near-perfect detection accuracy while maintaining text quality.

## Executive Summary
This paper introduces a novel watermarking technique for detecting machine-generated text by intervening in the token sampling process. The method generates a "secret number" for each candidate token by seeding a random number generator with the SHA256 hash of the token and its k preceding context, then selecting the token with the highest secret number. This creates a statistically detectable pattern that can be algorithmically identified through z-score analysis of the average secret number. Experiments across three language models and two datasets demonstrate high detectability rates (average z-scores >4) with minimal impact on text quality metrics like P-SP, diversity, and coherence.

## Method Summary
The watermarking method operates during text generation by modifying the token selection process. For each token to be generated, the model's probability distribution is first truncated to the top-k tokens. From these candidates, y tokens are sampled (with or without replacement) and each is assigned a secret number calculated by seeding an RNG with the SHA256 hash of the token and its k-token context. The token with the maximum secret number is selected and appended to the output. Detection involves recalculating the secret numbers for a given text and computing the z-score of the average secret number against the theoretical distribution (mean 0.5, variance 1/(12N)). Texts with z-scores above a threshold (u=4) are classified as watermarked. The method is implemented as an add-on to existing sampling strategies without requiring model modifications.

## Key Results
- The watermark is highly detectable with average z-scores exceeding 4 across all tested models and datasets
- Text quality remains largely preserved with only slight degradation in P-SP scores
- The method demonstrates robustness to token-level paraphrasing attacks
- Sampling with replacement preserves text quality better than sampling without replacement while maintaining strong detectability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The secret number computation ensures unique detectability per token.
- Mechanism: For each candidate token, a secret number is generated by seeding a random number generator with the SHA256 hash of the token and its k preceding context. The token with the highest secret number is selected. This deterministic process allows detection by recalculating the same secret numbers for any given text and checking if the average secret number is significantly above 0.5.
- Core assumption: The SHA256 hash of a token plus its context produces sufficiently random seed values for the RNG, and the highest-secret-number selection is statistically detectable against random text generation.
- Evidence anchors:
  - [abstract]: "we intervene with the token sampling process in a way which enables us to trace back our token choices during the detection phase."
  - [section]: "The secret number of any token in a candidate passage only depends on itself and the k tokens that precede it. This enables us to retrieve the same secret number for every token in a passage outside of the generation process."
  - [corpus]: "Efficiently Identifying Watermarked Segments in Mixed-Source Texts" - shows practical use of this kind of per-token statistical signal.
- Break condition: If an attacker can predict or manipulate the RNG seed (e.g., via a hash collision attack), they could spoof the watermark.

### Mechanism 2
- Claim: Sampling with/without replacement controls trade-off between watermark strength and text quality.
- Mechanism: Sampling without replacement ensures the y candidate tokens are distinct, maximizing the chance to pick a high-secret-number token, thus increasing watermark detectability. Sampling with replacement allows the same token to appear multiple times among candidates, preserving more natural token probability distributions and better text quality.
- Core assumption: Low-entropy token distributions cause sampling without replacement to select unlikely tokens, degrading quality; high-entropy distributions make sampling without replacement less harmful.
- Evidence anchors:
  - [section]: "When we sample without replacement, the secret numbers of the candidate tokens are guaranteed to be distinct values. Maximizing the use of distinct values tends to result in larger secret number values, making the watermark more detectable."
  - [section]: "On the other hand, if the entropy of the probability distribution is low, i.e., there are few plausible tokens to be generated, sampling without replacement would cause the model to pick the unlikely tokens, reducing the quality of the generated text."
  - [corpus]: "Improve the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models" - confirms sampling choice affects detection vs quality balance.
- Break condition: If token distribution entropy is always high (e.g., very diverse vocabularies), sampling without replacement may not degrade quality much, reducing the advantage of sampling with replacement.

### Mechanism 3
- Claim: Z-score threshold based detection reliably separates watermarked from non-watermarked text.
- Mechanism: For a text of N tokens, the average secret number follows a normal distribution with mean 0.5 and variance 1/(12N) if tokens are randomly selected. Watermarked text, by maximizing secret numbers, will have a much higher average. The z-score compares the observed average to the expected distribution under the null hypothesis of no watermarking.
- Core assumption: The law of large numbers ensures the average secret number converges to 0.5 for non-watermarked text; the selection mechanism for watermarked text shifts this average sufficiently far to be detectable.
- Evidence anchors:
  - [section]: "As the length of the candidate text increases, the average secret number for non-watermarked text gradually approaches this theoretical distribution with diminishing variance, thus reducing the likelihood of the text's average secret number deviating significantly from 0.5."
  - [section]: "This selection dramatically alters the distribution of the average secret number, rendering it exceedingly improbable for the text to have arisen through natural generation."
  - [corpus]: "CEFW: A Comprehensive Evaluation Framework for Watermark in Large Language Models" - shows evaluation of z-score thresholds for watermark detection.
- Break condition: If an attacker can inject many high-secret-number tokens artificially without being detected by the z-score threshold, they could spoof watermarked text.

## Foundational Learning

- Concept: Token sampling and probability distributions in language models.
  - Why needed here: Understanding how language models choose next tokens based on conditional probabilities is crucial to grasp how watermarking manipulates the sampling process.
  - Quick check question: In top-k sampling, what determines which tokens are considered candidates for selection?

- Concept: Hash functions and random number generation.
  - Why needed here: The watermark relies on hashing token-context pairs to seed RNGs for secret number generation; knowing how hashes map to pseudo-random outputs is key to understanding detectability.
  - Quick check question: If you hash the same input twice with SHA256, will you get the same output?

- Concept: Statistical hypothesis testing and z-scores.
  - Why needed here: The detection mechanism uses z-scores to decide if a text is watermarked; understanding normal distributions and thresholds is essential.
  - Quick check question: If a sample mean is 2 standard deviations above the expected mean, what is its z-score?

## Architecture Onboarding

- Component map: LLM → Token Probability Distribution → Sampling Watermarker → Token Selection → Generated Text; Detection: Tokenization → Secret Number Calculation → Average & Z-score → Decision.
- Critical path: During generation, for each token: get distribution → sample candidates → compute secret numbers → pick max → append token. During detection: tokenize → compute secret numbers → average → z-score → threshold comparison.
- Design tradeoffs: Sampling with replacement preserves text quality but weakens watermark; sampling without replacement strengthens watermark but may degrade quality; larger y increases watermark strength but reduces quality.
- Failure signatures: False positives in detection (human text flagged as watermarked); significant drop in P-SP or diversity scores; watermark not detectable despite correct generation.
- First experiments:
  1. Generate 500 samples of 200 tokens each from C4 dataset using OPT-1.3B with y=5, k=1, and measure average z-scores.
  2. Compare P-SP scores between watermarked and non-watermarked text generated by BTLM-3B.
  3. Test robustness by applying token-level paraphrasing attacks to watermarked Llama2-7B samples and measuring detection accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed watermarking method perform across different downstream tasks such as question answering and summarization, compared to its performance in text completion?
- Basis in paper: [inferred] The paper acknowledges that further evaluation across different downstream tasks is needed, as it only focuses on text completion in the current study.
- Why unresolved: The paper does not provide experimental results for tasks other than text completion, leaving a gap in understanding the method's versatility.
- What evidence would resolve it: Conducting experiments on a variety of downstream tasks and comparing the watermarking performance to that of text completion would provide insights into the method's adaptability.

### Open Question 2
- Question: How does the watermarking performance vary with different sampling counts (y) and context window sizes (k), and what is the optimal configuration for balancing detectability and text quality?
- Basis in paper: [explicit] The paper explores the impact of sampling count y on text quality and detectability, but does not exhaustively test different combinations of y and k.
- Why unresolved: The paper only tests a limited range of y values and a fixed k value, without exploring the full parameter space or determining the optimal configuration.
- What evidence would resolve it: Systematic experiments varying both y and k across a wider range of values and analyzing the trade-offs between detectability and text quality would identify the optimal configuration.

### Open Question 3
- Question: How does the proposed watermarking method handle different types of paraphrasing attacks beyond token-level paraphrasing, such as deletion, unicode attacks, and human paraphrasing?
- Basis in paper: [inferred] The paper mentions that only token-level paraphrasing attacks are explored, but acknowledges the existence of other types of attacks that could challenge the robustness of the watermarking method.
- Why unresolved: The paper does not provide experimental results for other types of paraphrasing attacks, leaving uncertainty about the method's robustness against a broader range of attacks.
- What evidence would resolve it: Conducting experiments with various types of paraphrasing attacks and evaluating the watermarking method's resilience would provide a comprehensive understanding of its robustness.

## Limitations
- Parameter sensitivity: Effectiveness depends on choosing appropriate values for sampling count y and context window size k, with limited guidance provided.
- Baseline comparison gaps: Only compared against one baseline method (MWM) without benchmarking against other contemporary watermarking approaches.
- Real-world applicability: Evaluation focuses on controlled generation from three specific models on two datasets, not testing mixed-source or multilingual scenarios.

## Confidence
**High Confidence**: The core mechanism of using secret numbers for detection is sound and mathematically justified. The z-score threshold approach for distinguishing watermarked from non-watermarked text is statistically valid, and the experimental results showing near-perfect detection accuracy are reproducible given the described methodology.

**Medium Confidence**: The trade-off between watermark strength and text quality through sampling with/without replacement is theoretically justified but may vary significantly based on model-specific token distributions. The robustness to token-level paraphrasing attacks is demonstrated but only tested on a specific type of attack with limited parameters.

**Low Confidence**: Claims about practical deployment and real-world effectiveness exceed what the experimental evidence supports. The assertion that this method is "model-agnostic" is somewhat overstated given the parameter tuning requirements and potential model-specific behaviors.

## Next Checks
1. **Parameter Sensitivity Analysis**: Systematically vary the sampling count y (e.g., y ∈ {3, 5, 10}) and context window k (e.g., k ∈ {1, 3, 5}) across different models and datasets to map the trade-off surface between detectability and quality metrics. This would validate whether the default parameters (y=5, k=1) are optimal or merely sufficient.

2. **Cross-Model Transferability Test**: Apply a watermark generated by one model (e.g., OPT-1.3B) and attempt detection using another model (e.g., Llama2-7B) to assess whether the watermark is truly model-agnostic or contains model-specific artifacts. This would test the fundamental assumption that secret numbers are solely determined by tokens and context, not model-specific generation patterns.

3. **Real-world Mixed-Source Detection**: Create synthetic mixed-source texts combining watermarked machine-generated content with human-written text (e.g., 50% each) and evaluate detection accuracy. This would validate the method's practical utility for identifying AI-generated content in realistic scenarios where clean detection is essential.