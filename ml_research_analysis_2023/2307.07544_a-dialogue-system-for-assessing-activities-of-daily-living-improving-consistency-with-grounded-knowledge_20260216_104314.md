---
ver: rpa2
title: 'A Dialogue System for Assessing Activities of Daily Living: Improving Consistency
  with Grounded Knowledge'
arxiv_id: '2307.07544'
source_url: https://arxiv.org/abs/2307.07544
tags:
- knowledge
- dialogue
- language
- system
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a dialogue system for assessing activities
  of daily living (ADL), which is a measure of functional ability in healthcare. The
  system aims to improve consistency in assessments conducted by multiple assessors
  with varying expertise levels.
---

# A Dialogue System for Assessing Activities of Daily Living: Improving Consistency with Grounded Knowledge

## Quick Facts
- arXiv ID: 2307.07544
- Source URL: https://arxiv.org/abs/2307.07544
- Reference count: 34
- Primary result: Transformer-based models (DeBERTa v3) outperform simpler models for query classification, and combining fine-tuned LLaMA with knowledge grounding improves factual consistency

## Executive Summary
This paper presents a dialogue system designed to assess Activities of Daily Living (ADL) by improving consistency across multiple assessors with varying expertise levels. The system uses a two-module architecture: natural language understanding (NLU) for query classification into 18 ADL domains, and natural language generation (NLG) that leverages a knowledge base of synthetic profiles combined with fine-tuned LLMs. Experiments demonstrate that transformer-based models achieve superior query classification performance, while the combination of knowledge-grounded generation with fine-tuned LLaMA models significantly improves factual and internal consistency compared to using the model alone.

## Method Summary
The dialogue system consists of two major modules: a natural language understanding component that classifies user queries into specific ADL domains using transformer models (primarily DeBERTa v3), and a natural language generation component that produces responses using a fine-tuned 7B LLaMA model. The system leverages a knowledge base of synthetic profiles, using similarity matching to retrieve relevant information for response generation. When close matches are found in the knowledge base, that information is used directly; otherwise, the system falls back to the LLM. The approach employs parameter-efficient fine-tuning methods like LoRA to adapt large models efficiently.

## Key Results
- Transformer-based models (DeBERTa v3) outperformed simpler models (logistic regression, BERT, RoBERTa) for query classification with accuracy improvements of several percentage points
- Combining a fine-tuned 7B LLaMA model with knowledge grounding improved factual and internal consistency compared to using the model alone
- The system maintained sensibleness and specificity while improving factual consistency, addressing a key challenge in ADL assessment consistency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Query classification maps user queries to specific ADL domains, enabling targeted response generation
- Mechanism: Transformer-based models classify incoming queries into one of 18 ADL domains, allowing selection of relevant knowledge base entries
- Core assumption: Queries can be mapped to single domains containing relevant knowledge
- Break condition: Multi-domain queries or those not fitting predefined categories may cause classification failures

### Mechanism 2
- Claim: Knowledge grounding improves factual consistency by retrieving relevant information from synthetic profiles
- Mechanism: After classification, the system searches the knowledge base and uses close matches above similarity threshold, otherwise falls back to LLM
- Core assumption: Knowledge base contains sufficient information and similarity matching effectively identifies relevant content
- Break condition: Incomplete knowledge base or poorly calibrated similarity threshold leads to failures or incorrect LLM usage

### Mechanism 3
- Claim: Fine-tuned LLMs combined with knowledge grounding achieve better factual consistency than either approach alone
- Mechanism: Fine-tuned 7B LLaMA serves as fallback when knowledge base retrieval fails, with combination improving factual accuracy
- Core assumption: LLM learned sufficient conversational ability while knowledge base provides factual grounding
- Break condition: Insufficient fine-tuning or knowledge base errors prevent improvement in factual consistency

## Foundational Learning

- **Transformer-based models for query classification**: Needed because ADL assessment requires semantic understanding beyond keyword matching; Quick check: Why would a transformer model outperform logistic regression for this task?
- **Knowledge grounding in dialogue systems**: Needed to generate responses factually consistent with specific synthetic profiles rather than just plausible responses; Quick check: What is the difference between knowledge grounding and retrieval-augmented generation?
- **Parameter-efficient fine-tuning (PEFT) methods**: Needed because fine-tuning large LLMs like LLaMA 7B is computationally expensive; Quick check: How does LoRA achieve comparable performance to full fine-tuning with fewer parameters?

## Architecture Onboarding

- **Component map**: User Interface → Query Classification (DeBERTa v3) → Knowledge Base Retrieval → LLM (Fine-tuned LLaMA 7B) → Response Generation → User Interface
- **Critical path**: User query → Domain classification → Knowledge base search → Generate response
- **Design tradeoffs**: Model size vs. inference speed, knowledge base completeness vs. system complexity, similarity threshold tuning vs. response quality
- **Failure signatures**: Incorrect domain classification, irrelevant knowledge base retrieval, LLM hallucinations, slow response times
- **First 3 experiments**: 1) Test query classification accuracy on held-out data with different models (LR, BERT, RoBERTa, DeBERTa); 2) Evaluate knowledge base retrieval accuracy with different similarity thresholds; 3) Compare response quality (SSA scores) with and without knowledge grounding

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between model size and response generation quality for the dialogue system?
- Basis in paper: [explicit] The paper discusses the trade-off between model size and generation time in the deployment environment, mentioning that smaller models pre-trained with more data can outperform larger models in some cases
- Why unresolved: The paper only briefly mentions this trade-off without providing concrete guidelines or experimental results
- What evidence would resolve it: Experiments comparing response generation quality across various model sizes and pre-training data volumes

### Open Question 2
- Question: How does the performance of the dialogue system vary across different domains of Activities of Daily Living (ADL)?
- Basis in paper: [explicit] The paper mentions that there is an imbalance in performance across domains, with the model performing poorly on domains with less available data
- Why unresolved: The paper only provides a brief overview without detailed performance metrics for each domain
- What evidence would resolve it: Detailed F1 scores for each domain and analysis of challenging domain characteristics

### Open Question 3
- Question: How can the knowledge-grounding process be improved to enhance the factual consistency of the dialogue system?
- Basis in paper: [inferred] The paper discusses the importance of factual consistency and mentions that combining a fine-tuned model with a knowledge base improved factual consistency, but does not explore other potential methods
- Why unresolved: The paper only tests one approach to knowledge grounding without exploring alternatives or comparing effectiveness
- What evidence would resolve it: Experimenting with different knowledge grounding techniques and comparing their impact on factual consistency

## Limitations
- Evaluation relies heavily on human raters, introducing subjectivity and variability
- System performance constrained by quality and completeness of synthetic knowledge base
- Query classification assumes user queries map to discrete ADL domains, which may not hold for complex queries

## Confidence

**High Confidence**: Transformer models outperforming simpler models for query classification, with DeBERTa v3 achieving best performance based on standard evaluation metrics

**Medium Confidence**: Combining fine-tuned LLaMA with knowledge grounding improves factual consistency, though subjective human ratings introduce uncertainty

**Low Confidence**: Generalizability to real-world ADL assessment scenarios is uncertain due to synthetic knowledge base and unverified similarity threshold effectiveness

## Next Checks

1. **Objective Factual Consistency Testing**: Implement automated evaluation framework using predefined knowledge base entries to test for factual errors, reducing reliance on subjective human ratings

2. **Cross-Domain Query Evaluation**: Design test set of multi-domain queries to evaluate classification system's ability to handle complex queries that don't fit neatly into single categories

3. **Knowledge Base Coverage Analysis**: Systematically evaluate knowledge base completeness by identifying gaps where queries cannot be answered and measuring fallback rate to LLM