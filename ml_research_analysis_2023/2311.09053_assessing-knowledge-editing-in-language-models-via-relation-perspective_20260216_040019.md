---
ver: rpa2
title: Assessing Knowledge Editing in Language Models via Relation Perspective
arxiv_id: '2311.09053'
source_url: https://arxiv.org/abs/2311.09053
tags:
- knowledge
- editing
- relation
- arxiv
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach to knowledge editing in
  large language models (LLMs) by focusing on relation-based editing rather than the
  traditional entity-based approach. The authors construct a new benchmark, RaKE,
  which includes datasets for both relation-based and entity-based editing.
---

# Assessing Knowledge Editing in Language Models via Relation Perspective

## Quick Facts
- arXiv ID: 2311.09053
- Source URL: https://arxiv.org/abs/2311.09053
- Authors: 
- Reference count: 6
- Key outcome: Existing knowledge editing methods perform significantly worse on relation-based editing tasks compared to entity-based ones because relational knowledge is stored in both FFN and attention layers.

## Executive Summary
This paper introduces a novel approach to knowledge editing in large language models (LLMs) by focusing on relation-based editing rather than traditional entity-based approaches. The authors construct a new benchmark called RaKE and conduct extensive experiments showing that current methods underperform on relation-based tasks. Through causal tracing analysis, they discover that relational knowledge is stored not only in feed-forward networks (FFN) but also in attention layers, suggesting that future editing methods should target both components for improved performance.

## Method Summary
The authors construct the RaKE benchmark with 21,919 editing samples for both relation-based and entity-based knowledge editing. They implement various baseline methods including Fine-tuning, Knowledge Neuron, MEND, ROME, and MEMIT. The evaluation uses efficacy metrics (Success and Magnitude), generalization metrics (Paraphrase and Neighborhood scores), and specificity metrics. Causal tracing analysis is performed to identify where relational knowledge is stored in the model, examining the effects of corrupting and restoring different model components.

## Key Results
- Existing knowledge editing methods show significant performance degradation on relation-based tasks compared to entity-based tasks
- Causal tracing reveals that relational knowledge is stored in both FFN and attention layers (layers 10-20 show pronounced effects)
- R-Efficacy (relation-based) shows significant decrease in performance compared to E-Efficacy (entity-based) in terms of EM metric
- The logical equivalence between entity-based and relation-based editing does not hold in practice due to independent storage of knowledge in different model components

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Relational knowledge in LLMs is stored not only in feed-forward networks (FFN) but also in attention layers.
- Mechanism: The attention mechanism in transformers can act as a form of sparse distributed memory, allowing relational information to be encoded and retrieved through key-value attention patterns.
- Core assumption: The attention layers can store and retrieve relational knowledge in addition to the FFN layers.
- Evidence anchors:
  - [abstract] "Our research results confirm that knowledge related to relations is not only stored in the FFN network but also in the attention layers."
  - [section] "This discovery is non-trivial and underscores the significance of the earlier layers in predicting plausibility. Furthermore, we observed a pronounced AIE in the middle attention layers of the last corrupted token."
  - [corpus] Weak evidence; corpus neighbors focus on FFN and attention but do not specifically confirm dual storage of relational knowledge.
- Break condition: If causal tracing analysis shows no significant indirect effect in attention layers when relation embeddings are corrupted.

### Mechanism 2
- Claim: Existing knowledge editing methods underperform on relation-based editing because they primarily modify parameters within the FFN and neglect attention layers.
- Mechanism: Since relational knowledge is stored in both FFN and attention layers, editing only the FFN parameters is insufficient for effective relation-based knowledge editing.
- Core assumption: The FFN-focused editing methods cannot fully capture the relational knowledge stored in attention layers.
- Evidence anchors:
  - [abstract] "Due to the fact that entity-based methods primarily modify parameters within the feed-forward network (FFN), our experiments indicate that the underperformance of current relation-based editing stems from a lack of modification to knowledge neurons associated with the attention layer."
  - [section] "Specifically, R-Efficacy shows a significant decrease in performance compared to E-Efficacy in terms of the EM metric."
  - [corpus] Weak evidence; corpus neighbors do not explicitly discuss the dual storage of relational knowledge or the need to edit attention layers.
- Break condition: If editing methods that also modify attention layers do not show improved performance on relation-based tasks.

### Mechanism 3
- Claim: The logical equivalence between entity-based and relation-based editing does not hold in practice due to the independent storage of entity and relation knowledge in different model components.
- Mechanism: Entity and relation knowledge are stored independently in different parts of the model (FFN for entities, attention for relations), leading to different editing outcomes despite logical equivalence.
- Core assumption: The independence of entity and relation knowledge storage leads to distinct editing requirements.
- Evidence anchors:
  - [abstract] "Despite the logical equivalence of the knowledge edited from the entity and relation perspectives in terms of triple representation, they exhibit surprising differences in effectiveness."
  - [section] "Specifically, entity knowledge and relation knowledge demonstrate a certain level of independence and are stored in different parts of the model."
  - [corpus] Weak evidence; corpus neighbors do not discuss the independence of entity and relation knowledge storage.
- Break condition: If editing methods that account for both entity and relation knowledge storage do not show improved performance.

## Foundational Learning

- Concept: Causal tracing
  - Why needed here: To identify the specific model components responsible for storing and recalling relational knowledge.
  - Quick check question: What is the difference between a clean run, a corrupted run, and a corrupted-with-restoration run in causal tracing?
- Concept: Sparse distributed memory (SDM)
  - Why needed here: To understand how attention layers in transformers can act as a form of memory for storing relational information.
  - Quick check question: How does the update rule of the attention module in transformers approximate SDM?
- Concept: Feed-forward networks (FFN) as key-value memories
  - Why needed here: To understand the role of FFN layers in storing and retrieving entity knowledge.
  - Quick check question: How do FFN layers in transformers operate as key-value memories?

## Architecture Onboarding

- Component map:
  - FFN layers: Store entity knowledge
  - Attention layers: Store relational knowledge
  - Causal tracing analysis: Identify responsible model components
- Critical path:
  1. Construct relation-based knowledge editing benchmark (RaKE)
  2. Conduct experiments using various baseline methods
  3. Perform causal tracing analysis to identify storage of relational knowledge
  4. Analyze the role of FFN and attention layers in storing relational knowledge
- Design tradeoffs:
  - FFN-focused editing methods: Simpler but may not fully capture relational knowledge
  - Attention layer editing: More complex but necessary for effective relation-based editing
- Failure signatures:
  - Poor performance on relation-based editing tasks
  - Inconsistent results between entity-based and relation-based editing
- First 3 experiments:
  1. Compare the performance of existing knowledge editing methods on entity-based vs. relation-based tasks
  2. Perform causal tracing analysis to identify the storage of relational knowledge in FFN and attention layers
  3. Modify attention layers and evaluate the impact on relation-based editing performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise mechanism by which relational knowledge is stored in attention layers, and how does it differ from FFN-based storage?
- Basis in paper: [explicit] The paper explicitly states that relational knowledge is stored in both FFN and attention layers, and provides causal tracing evidence showing significant effects in attention layers 10-20.
- Why unresolved: While the paper identifies the presence of relational knowledge in attention layers, it does not fully explain the mechanism or how it differs from FFN storage. The causal tracing analysis shows effects but doesn't elucidate the underlying storage process.
- What evidence would resolve it: Detailed analysis of attention layer activations and their correlation with relational knowledge, potentially through ablation studies or comparison with FFN-based storage mechanisms.

### Open Question 2
- Question: How can we develop more effective relation-based editing methods that target both FFN and attention layers simultaneously?
- Basis in paper: [explicit] The paper concludes that current editing methods focusing solely on FFN parameters are inadequate for relation-based editing, suggesting the need for methods targeting both FFN and attention layers.
- Why unresolved: While the paper identifies the need for dual-layer editing, it does not propose or test specific methods for achieving this. The challenge of effectively modifying both layers without disrupting other knowledge remains open.
- What evidence would resolve it: Development and empirical validation of a relation-based editing method that successfully modifies both FFN and attention layers, demonstrating improved performance over existing entity-based methods.

### Open Question 3
- Question: What is the relationship between entity-based and relation-based knowledge in language models, and how does this affect editing performance?
- Basis in paper: [inferred] The paper's experiments show surprising differences in effectiveness between entity-based and relation-based editing, despite their logical equivalence in triple representation. This suggests a complex relationship between entity and relation knowledge in LLMs.
- Why unresolved: The paper raises this question but does not fully explore or explain the nature of the relationship between entity and relation knowledge in LLMs, nor why editing one does not automatically affect the other.
- What evidence would resolve it: Comprehensive analysis of how changes to entity-based knowledge affect relation-based knowledge (and vice versa) in LLMs, potentially through controlled experiments and correlation studies.

## Limitations

- The findings are based on GPT-2 XL and Wikidata-derived knowledge, which may not generalize to other model architectures or knowledge sources
- The paper identifies the need for attention layer modification but doesn't provide specific methods for effectively editing attention parameters
- The RaKE benchmark construction methodology may not capture all types of relational knowledge, potentially limiting the scope of the findings

## Confidence

- High confidence: The empirical finding that relation-based editing tasks are more challenging than entity-based tasks, as demonstrated across multiple baseline methods and evaluation metrics
- Medium confidence: The conclusion that attention layers store relational knowledge, based on causal tracing evidence though the mechanism isn't fully characterized
- Medium confidence: The assertion that existing methods underperform due to insufficient attention layer modification, though alternative explanations exist

## Next Checks

1. Cross-architecture validation: Replicate the causal tracing analysis on BERT and T5 models to verify whether relational knowledge storage patterns hold across different transformer architectures.

2. Attention editing ablation: Design and test editing methods that specifically modify attention layer parameters (not just FFN) to quantify the exact contribution of attention-based modifications to relation editing performance.

3. Knowledge type decomposition: Analyze whether different relation types (symmetric, asymmetric, hierarchical) show different storage patterns in attention vs FFN layers, using the RaKE dataset's relation categorization.