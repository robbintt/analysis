---
ver: rpa2
title: 'From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting'
arxiv_id: '2309.04269'
source_url: https://arxiv.org/abs/2309.04269
tags:
- summaries
- summary
- summarization
- human
- computational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to automatically generate summaries
  with varying levels of information density, and uses this to explore the tradeoff
  between informativeness and readability. The authors present a "Chain of Density"
  prompt for GPT-4 that produces increasingly dense summaries by iteratively incorporating
  new entities without increasing length.
---

# From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting

## Quick Facts
- arXiv ID: 2309.04269
- Source URL: https://arxiv.org/abs/2309.04269
- Reference count: 16
- Primary result: Humans prefer summaries that are more dense than those generated by a vanilla prompt and almost as dense as human-written summaries

## Executive Summary
This paper proposes a method to automatically generate summaries with varying levels of information density, and uses this to explore the tradeoff between informativeness and readability. The authors present a "Chain of Density" prompt for GPT-4 that produces increasingly dense summaries by iteratively incorporating new entities without increasing length. Human evaluation of these summaries shows that humans prefer summaries that are more dense than those generated by a vanilla GPT-4 prompt, and almost as dense as human-written summaries. The authors also conduct an automatic evaluation using GPT-4 as an evaluator, and find that denser summaries are generally rated higher on dimensions like informativeness and overall quality, but that there is a limit to how dense a summary can be before it becomes difficult to follow.

## Method Summary
The Chain of Density (CoD) method uses GPT-4 to generate summaries at 5 different density levels for each article. Starting with an entity-sparse summary, each iteration adds 1-3 missing salient entities without increasing length, forcing the model to compress and abstract existing content. The method is evaluated on 100 CNN/DailyMail articles using both human preference studies and GPT-4 automatic evaluation. Human annotators rank summaries at different density levels, while GPT-4 rates summaries on 5 dimensions (Informative, Quality, Coherence, Attributable, Overall) using Likert scales.

## Key Results
- Humans prefer summaries with entity density around 0.15 over both sparser and denser alternatives
- CoD summaries achieve higher entity density than vanilla GPT-4 summaries while maintaining readability
- Denser summaries score higher on automatic evaluation metrics but show diminishing returns beyond optimal density
- There exists a clear tradeoff between informativeness (favored by more entities) and readability (favored by fewer entities)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Iterative density increase works because GPT-4 can compress and abstract while adding new entities without increasing token count.
- Mechanism: The prompt explicitly instructs the model to identify missing entities and rewrite the previous summary to incorporate them while maintaining the same length. This forces fusion, compression, and abstraction.
- Core assumption: GPT-4 has sufficient compression and abstraction ability to add new information without increasing length.
- Evidence anchors:
  - [abstract] "GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the overall length"
  - [section] "To maintain the same length while increasing the number of entities covered, abstraction, fusion, and compression is explicitly encouraged"
  - [corpus] Found 25 related papers, average neighbor FMR=0.453, suggesting moderate relatedness in the literature space
- Break condition: When the summary becomes too dense to maintain readability or when GPT-4 can no longer compress effectively without dropping entities

### Mechanism 2
- Claim: Human preference peaks at intermediate density levels because there's a tradeoff between informativeness and readability.
- Mechanism: Humans prefer summaries that balance entity density with coherence. Too few entities make summaries uninformative; too many make them hard to follow.
- Core assumption: There exists an optimal density level that balances informativeness and readability for human readers.
- Evidence anchors:
  - [abstract] "humans prefer summaries that are more dense than those generated by a vanilla prompt and almost as dense as human written summaries"
  - [section] "Qualitative analysis supports the notion that there exists a tradeoff between informativeness and readability"
  - [corpus] Weak evidence - only 25 related papers found with moderate FMR scores
- Break condition: When summaries become either too sparse (uninformative) or too dense (illegible)

### Mechanism 3
- Claim: GPT-4 can serve as a reasonable evaluator for summary quality when using Likert-scale ratings.
- Mechanism: The model is prompted to rate summaries on multiple dimensions (Informative, Quality, Coherence, Attributable, Overall) using a 1-5 scale.
- Core assumption: GPT-4's self-evaluation correlates sufficiently with human judgments to be useful.
- Evidence anchors:
  - [abstract] "we prompt GPT-4 to rate CoD summaries (1-5) along 5 dimensions"
  - [section] "As an evaluator, GPT-4 has been shown to adequately correlate to human judgments"
  - [corpus] Weak evidence - no corpus data specifically about GPT-4 as evaluator
- Break condition: When correlations between GPT-4 ratings and human preferences become too low (reported as only 0.31 Pearson correlation for Overall metric)

## Foundational Learning

- Concept: Entity density as a proxy for information density
  - Why needed here: The paper uses average number of entities per token as the primary measure of how "dense" a summary is
  - Quick check question: If a 70-token summary contains 10 entities, what is its entity density? (Answer: 10/70 = 0.143)

- Concept: Abstractiveness and extractive density
  - Why needed here: The paper measures how abstractive summaries are using extractive density - the average squared length of extractive fragments
  - Quick check question: Why would iterative rewriting to add entities increase abstractiveness? (Answer: Because each rewrite requires the model to rephrase existing content to make room for new entities)

- Concept: Fusion as a measure of summary quality
  - Why needed here: The paper proxies fusion as the average number of source sentences aligned to each summary sentence
  - Quick check question: How does fusion relate to the tradeoff between informativeness and readability? (Answer: Higher fusion indicates more information packed into fewer sentences, which increases informativeness but may decrease readability)

## Architecture Onboarding

- Component map: Input articles -> CoD prompt iterations -> 5 summaries per article -> Human evaluation + GPT-4 evaluation -> Analysis
- Critical path:
  1. Load article
  2. Generate initial sparse summary
  3. Iteratively identify missing entities and generate denser summaries
  4. Collect human preferences across all density levels
  5. Run GPT-4 automatic evaluation
  6. Analyze tradeoff between density and readability

- Design tradeoffs:
  - Fixed length vs. variable density: The prompt enforces fixed length to isolate density effects
  - Entity definition: Loose criteria (relevant, specific, novel, faithful, anywhere) vs. strict entity types
  - Evaluation method: Human preference vs. automatic metrics, with acknowledgment of low agreement

- Failure signatures:
  - Summaries becoming too dense to maintain coherence
  - GPT-4 dropping entities during compression (violating the "never drop entities" rule)
  - Human annotators showing very low agreement (kappa=0.112 reported)
  - Automatic metrics failing to correlate with human preferences

- First 3 experiments:
  1. Run CoD on a small sample of articles and verify entity density increases monotonically with each step
  2. Compare human preferences for different density levels on a small subset (e.g., 10 articles)
  3. Test GPT-4 evaluation prompts to ensure consistent scoring across multiple runs of the same summary

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal entity density for summaries that balances informativeness and readability?
- Basis in paper: [explicit] The paper discusses the tradeoff between informativeness (favoring more entities) and readability (favoring fewer entities), and finds that humans prefer summaries with an entity density of approximately 0.15.
- Why unresolved: The paper only evaluates entity density on news articles. It is unclear if this optimal density generalizes to other domains or types of text.
- What evidence would resolve it: Evaluating the same summarization method on a diverse set of domains (e.g., scientific articles, legal documents, social media posts) and comparing human preferences for entity density across domains.

### Open Question 2
- Question: How do the results change if the entity density is controlled using a different method than the Chain of Density (CoD) prompt?
- Basis in paper: [explicit] The paper uses the CoD prompt to iteratively increase entity density. It is unclear if the results would generalize to other methods of controlling entity density.
- Why unresolved: The paper only evaluates one method of controlling entity density. Other methods may produce different results.
- What evidence would resolve it: Comparing human preferences for summaries with different entity densities generated using a variety of methods (e.g., extractive summarization, abstractive summarization with different prompts).

## Limitations

- The study is limited to CNN/DailyMail articles and may not generalize to other domains or writing styles
- Very low inter-annotator agreement (kappa = 0.112) raises questions about reliability of human preference judgments
- Fixed-length constraint (200 tokens) limits applicability to scenarios requiring different summary lengths

## Confidence

**High Confidence**:
- CoD summaries achieve higher entity density than vanilla GPT-4 summaries
- Human annotators consistently prefer denser summaries over sparser ones
- Entity density increases monotonically across CoD iterations
- There exists a tradeoff between informativeness and readability at higher density levels

**Medium Confidence**:
- Denser summaries are "almost as dense as human-written summaries" (based on limited comparison)
- GPT-4 automatic evaluation provides meaningful quality assessments (given the low correlation with human judgments)
- The specific 5-step CoD process is optimal for balancing density and readability

**Low Confidence**:
- Claims about CoD being superior to all existing summarization methods (not directly compared to other approaches)
- Generalization of findings beyond the CNN/DailyMail domain
- The precise optimal density level for all summarization contexts

## Next Checks

1. **Cross-Domain Validation**: Test the CoD approach on summaries from different domains (scientific papers, legal documents, product reviews) to assess generalizability. Measure whether the same density-readability tradeoff emerges and whether human preferences remain consistent.

2. **Alternative Entity Extraction Comparison**: Implement CoD using different entity extraction methods (strict NER vs. loose relevance criteria) and compare resulting summary quality and density progression. This would validate whether the loose entity definition is crucial to CoD's success.

3. **Extended Evaluation Protocol**: Conduct a larger-scale human evaluation with more annotators and compute system-level agreement rather than individual-level agreement. Additionally, test whether breaking the fixed-length constraint (allowing variable length summaries) affects the density-readability tradeoff and human preferences.