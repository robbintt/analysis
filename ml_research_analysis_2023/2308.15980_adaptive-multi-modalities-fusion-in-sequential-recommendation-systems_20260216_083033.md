---
ver: rpa2
title: Adaptive Multi-Modalities Fusion in Sequential Recommendation Systems
arxiv_id: '2308.15980'
source_url: https://arxiv.org/abs/2308.15980
tags:
- fusion
- graph
- modality
- sequential
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of optimally fusing multi-modal
  information (text and image) in sequential recommendation. The authors propose a
  graph-based framework (MMSR) that adaptively determines the fusion order for each
  modality node, balancing sequential and cross-modal dependencies.
---

# Adaptive Multi-Modalities Fusion in Sequential Recommendation Systems

## Quick Facts
- arXiv ID: 2308.15980
- Source URL: https://arxiv.org/abs/2308.15980
- Reference count: 40
- MMSR outperforms state-of-the-art baselines by 8.6% in HR@5 and 17.2% in MRR@5 on average

## Executive Summary
This paper tackles the challenge of optimally fusing multi-modal information (text and image) in sequential recommendation. The authors propose a graph-based framework (MMSR) that adaptively determines the fusion order for each modality node, balancing sequential and cross-modal dependencies. MMSR constructs a modality-enriched sequence graph and employs a dual attention mechanism with asynchronous updating to flexibly integrate information. Experiments on six Amazon datasets show that MMSR outperforms state-of-the-art baselines by 8.6% in HR@5 and 17.2% in MRR@5 on average, demonstrating both superior accuracy and robustness to missing modalities.

## Method Summary
MMSR constructs a modality-enriched sequence graph where each user's history is represented with modality features as cross-linked nodes. The framework uses a heterogeneous attentional graph neural network (HAN-GNN) with dual attention mechanisms (content-based for homogeneous, key-value for heterogeneous edges) and asynchronous updating via an update gate. The approach employs modality codes to reduce graph sparsity and uses non-invasive fusion to prevent representation degradation. The model is trained to predict the next item in a user's interaction sequence.

## Key Results
- Outperforms state-of-the-art baselines by 8.6% in HR@5 and 17.2% in MRR@5 on average
- Demonstrates superior robustness to missing modalities compared to existing methods
- Achieves consistent improvements across six Amazon datasets (Beauty, Clothing, Sport, Toys, Kitchen, Phone)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adaptive fusion order improves recommendation performance by allowing each modality node to prioritize either sequential or cross-modal dependencies.
- Mechanism: The update gate dynamically selects between two fusion paths (homogeneous-first or heterogeneous-first) based on local neighborhood characteristics, optimizing the propagation order per node.
- Core assumption: Different nodes in the graph benefit from different fusion orders depending on their local connectivity patterns.
- Evidence anchors:
  - [abstract]: "To adaptively assign nodes with distinct fusion orders, MMSR allows each node's representation to be asynchronously updated through an update gate."
  - [section]: "We introduce an update gate to adaptively select the optimal path for each node using the following gate selection mechanism"
  - [corpus]: Weak evidence - no direct citations about update gate mechanisms in related works
- Break condition: If local neighborhood patterns don't correlate with optimal fusion order, the adaptive mechanism provides no benefit over fixed-order approaches.

### Mechanism 2
- Claim: Non-invasive fusion prevents representation degradation when combining heterogeneous modalities.
- Mechanism: Instead of updating the central node's value vector during aggregation, the method uses the original value vector for aggregation while still calculating attention based on the updated intermediate state.
- Core assumption: Direct mixing of representations from different modalities in the same space causes interference and information loss.
- Evidence anchors:
  - [section]: "We introduce a non-invasive approach during graph updating. Specifically, in Phase 2, though we calculate the attention based on the intermediate state ‚Ñé (ùëô ),‚Ñéùëí ùëñ , we continue to use the value vector of ‚Ñé (ùëô ) ùëó (instead of ‚Ñé (ùëô ),‚Ñéùëí ùëñ ) for aggregation."
  - [abstract]: "Consequently, MMSR establishes a fusion order that spans a spectrum from early to late modality fusion."
  - [corpus]: Weak evidence - no direct citations about non-invasive fusion techniques in related works
- Break condition: If the transformed value vectors from different modalities naturally align in the same space without interference, the non-invasive approach provides no benefit.

### Mechanism 3
- Claim: Modality codes reduce graph sparsity and overfitting while preserving semantic relationships.
- Mechanism: Instead of treating each modality feature as an individual node, the method clusters similar modalities and represents them with discrete indices (modality codes), reducing the number of nodes while maintaining semantic links.
- Core assumption: Multiple similar modalities can be represented by the same code without significant information loss.
- Evidence anchors:
  - [section]: "We introduce 'modality codes' [20, 36] as alternative nodes. These nodes correspond to discrete indices obtained by mapping the original modality features."
  - [abstract]: "MMSR represents each user's history as a graph, where the modality features of each item in a user's history sequence are denoted by cross-linked nodes."
  - [corpus]: Moderate evidence - related works like [20, 36] support modality code approaches
- Break condition: If modality features are too diverse or context-dependent to be effectively clustered, the modality code approach loses critical information.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: MMSR uses graph-based propagation to fuse multi-modal information while preserving sequential relationships
  - Quick check question: How does a GNN aggregate information from neighboring nodes in a graph structure?

- Concept: Attention Mechanisms
  - Why needed here: Dual attention (content-based for homogeneous, key-value for heterogeneous) is used to differentiate between node types during aggregation
  - Quick check question: What's the difference between content-based attention and key-value attention in terms of information flow?

- Concept: Sequential Recommendation Systems
  - Why needed here: The task is to predict the next item in a user's interaction sequence, requiring modeling of temporal dependencies
  - Quick check question: How do sequential recommenders typically handle long-term vs short-term user interests?

## Architecture Onboarding

- Component map: User history ‚Üí Modality code clustering ‚Üí MSGraph construction ‚Üí HAN-GNN layers (dual attention + update gate) ‚Üí Last pooling ‚Üí Prediction
- Critical path: The HAN-GNN layers with asynchronous updating are the core innovation that enables adaptive fusion
- Design tradeoffs: Modality code clustering reduces complexity but may lose fine-grained information; non-invasive fusion prevents interference but adds complexity
- Failure signatures: Performance drops on datasets where modalities have weak interdependencies; poor results when modality features are too diverse for effective clustering
- First 3 experiments:
  1. Compare synchronous vs asynchronous HAN-GNN on a single dataset to validate the update gate mechanism
  2. Test non-invasive vs invasive fusion variants to measure interference effects
  3. Evaluate different modality code clustering parameters (c and k) to find optimal graph density

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of clusters (c) and number of modality codes per modality (k) for different types of sequential recommendation datasets?
- Basis in paper: [explicit] The paper mentions that "We see that using modality codes achieves better performance over not using modality codes" and discusses how "a larger value of ùëê does not necessarily lead to better performance, as the optimal point is typically between 20 and 30" with "the optimal value of ùëò increases accordingly."
- Why unresolved: The paper only presents results for one dataset (Beauty) and shows performance variation with different c and k values, but doesn't provide a general rule or framework for determining optimal values across different dataset types or domains.
- What evidence would resolve it: Systematic experiments across diverse datasets showing performance patterns as c and k vary, potentially with an analysis of how dataset characteristics (e.g., modality diversity, sequence length, item sparsity) correlate with optimal parameter values.

### Open Question 2
- Question: How does the performance of MMSR compare to multimodal recommendation models that incorporate both sequential and collaborative signals (e.g., EgoGCN) when applied to sequential recommendation tasks?
- Basis in paper: [inferred] The paper mentions that "Existing multi-modal recommendation baselines focusing on inter-modality modeling with collaborative signals (MGCN, MGNN, BM3) do not incorporate sequential relationships, resulting in poor performance" but doesn't compare against multimodal models that do incorporate sequential relationships.
- Why unresolved: The comparison only includes collaborative multimodal models that don't consider sequential patterns, leaving open the question of how MMSR would perform against more advanced multimodal sequential recommendation models.
- What evidence would resolve it: Direct experimental comparison between MMSR and state-of-the-art multimodal sequential recommendation models on the same datasets, measuring both accuracy and robustness to missing modalities.

### Open Question 3
- Question: How does the interpretability of complex modality relationships in MMSR vary across different domains and what are the key factors that influence when sequentiality versus interdependent relationships become more important?
- Basis in paper: [explicit] The paper concludes by mentioning "exploring the interpretability of complex modal relationships in modality-enriched SR opens up new horizons for future research" and asks "how and when sequentiality or interdependent relationships become pivotal."
- Why unresolved: While the paper demonstrates MMSR's effectiveness, it doesn't provide a framework for understanding when and why certain modality relationships dominate, nor does it explore how this varies across different recommendation domains.
- What evidence would resolve it: Case studies across multiple domains (e.g., fashion, electronics, books) analyzing which modality relationships (sequential vs. interdependent) MMSR prioritizes in each domain, potentially using visualization techniques to illustrate the learned relationships.

## Limitations
- Limited ablation studies prevent isolation of individual component contributions to overall performance
- Non-invasive fusion mechanism lacks empirical comparison against invasive alternatives
- Modality code approach's effectiveness depends heavily on clustering quality, which varies across datasets

## Confidence
- High confidence in the paper's theoretical foundations and framework design
- Medium confidence in performance claims due to limited ablation studies
- Low confidence in generalizability across domains beyond Amazon datasets

## Next Checks
1. Ablation study comparing synchronous vs asynchronous HAN-GNN to isolate the update gate contribution
2. Controlled experiments with varying levels of modality missingness to quantify robustness claims
3. Cross-dataset transferability tests to assess whether optimal hyperparameters generalize beyond Amazon domains