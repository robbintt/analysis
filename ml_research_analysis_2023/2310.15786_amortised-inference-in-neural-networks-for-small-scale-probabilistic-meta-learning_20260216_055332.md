---
ver: rpa2
title: Amortised Inference in Neural Networks for Small-Scale Probabilistic Meta-Learning
arxiv_id: '2310.15786'
source_url: https://arxiv.org/abs/2310.15786
tags:
- inference
- variational
- parameters
- neural
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of meta-learning in small-scale
  settings, where traditional meta-learning approaches with shared parameters often
  overfit due to limited data. The authors propose a novel method called Amortised
  Pseudo-Observation Variational Inference for Bayesian Neural Networks (A-POVI-BNN).
---

# Amortised Inference in Neural Networks for Small-Scale Probabilistic Meta-Learning

## Quick Facts
- arXiv ID: 2310.15786
- Source URL: https://arxiv.org/abs/2310.15786
- Reference count: 10
- The paper proposes A-POVI-BNN for meta-learning in small-scale settings, outperforming other methods on synthetic data

## Executive Summary
This paper addresses the challenge of meta-learning in small-scale settings where traditional approaches with shared parameters often overfit. The authors propose A-POVI-BNN, which uses pseudo-observation variational inference for Bayesian neural networks with amortised inference. By replacing inducing inputs with actual data points and parameterizing them through an inference network, the method learns to approximate Bayesian inference over task-specific parameters without shared model parameters. The approach shows promise for effective meta-learning in data-scarce scenarios.

## Method Summary
A-POVI-BNN extends the POVI-BNN framework by incorporating amortised inference through an inference network. The method constructs variational distributions as products of per-datapoint approximate likelihoods, where each datapoint passes through the inference network to produce variational parameters. Unlike traditional meta-learning approaches that share model parameters across tasks, A-POVI-BNN maintains task-specific BNN parameters while sharing the inference network. This architecture prevents overfitting in small-scale meta-learning by removing shared model parameters while still enabling knowledge transfer through the shared inference network.

## Key Results
- A-POVI-BNN outperforms A-MFVI-BNN and ConvCNP on synthetic meta-dataset
- The method produces sensible predictive posteriors even with minimal meta-dataset (|Ξ| = 1)
- Task-specific BNN parameters with shared inference network effectively prevent overfitting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The POVI-BNN approximation with data points replacing inducing inputs creates a per-datapoint approximate likelihood structure that enables effective amortisation.
- Mechanism: By replacing global inducing inputs U0 with actual data points X, the variational approximation becomes a product of per-datapoint approximate likelihoods. Each datapoint (xn, yn) contributes its own approximate likelihood term tn(W), which can be parameterized by an inference network gℓϕ(xn, yn). This structure allows the inference network to meta-learn how to produce appropriate variational parameters for each datapoint across related datasets.
- Core assumption: The per-datapoint approximate likelihoods tn(W) can be effectively parameterized by passing datapoints through a shared inference network.
- Evidence anchors:
  - [abstract] "Our key insight is that these inducing inputs can be replaced by the actual data, such that the variational distribution consists of a set of approximate likelihoods for each datapoint."
  - [section] "This structure lends itself to amortised inference, in which the parameters of each approximate likelihood are obtained by passing each datapoint through a meta-model known as the inference network."
- Break condition: If the inference network cannot effectively map from datapoints to appropriate variational parameters, the amortisation would fail and performance would degrade to unamortised inference.

### Mechanism 2
- Claim: Removing shared model parameters while keeping shared inference network parameters prevents overfitting in small-scale meta-learning.
- Mechanism: Traditional meta-learning methods like NPs and MAML use shared model parameters across tasks, which can overfit when the meta-dataset is small. A-POVI-BNN instead uses task-specific BNN parameters but shares the inference network parameters across tasks. The inference network learns to approximate Bayesian inference over task-specific parameters without being tied to specific parameter values.
- Core assumption: The inference network can learn a general mapping from datapoints to variational parameters that works across diverse but related tasks.
- Evidence anchors:
  - [abstract] "This approach enables meta-learning of Bayesian inference over task-specific BNNs without shared model parameters, addressing overfitting in small-scale meta-learning."
  - [section] "We argue that this is a result of the large number of shared model parameters overfitting to the meta-dataset. A natural solution is to remove these shared model parameters, and instead train a meta-model to learn to approximate fully Bayesian inference over task-specific model parameters."
- Break condition: If tasks in the meta-dataset are too diverse, the shared inference network may not generalize well across all tasks.

### Mechanism 3
- Claim: The pseudo-observation structure provides a better approximation to the true posterior than mean-field variational inference.
- Mechanism: POVI-BNN constructs variational distributions that mirror the structure of the true posterior by multiplying the prior with approximate likelihoods. This is more expressive than mean-field Gaussian approximations which assume independence between weights. The pseudo-observations act as "soft data" that inform the posterior without introducing additional parameters to optimize.
- Core assumption: The approximate likelihoods tn(W) can effectively capture the dependencies in the true posterior that mean-field approximations miss.
- Evidence anchors:
  - [section] "Ober and Aitchison (2021) demonstrate the efficacy of POVI-BNNs relative to mean-field Gaussian variational approximations for BNNs, achieving state-of-the-art performance on a number of regression and classification experiments."
  - [section] "Bui (2022), who shows that the estimate of the marginal likelihood provided by the POVI-BNN approximation is close to the true value, indicating the approximation is close to the true posterior."
- Break condition: If the pseudo-observation structure cannot adequately represent the true posterior dependencies, it may not outperform simpler approximations.

## Foundational Learning

- Concept: Bayesian Neural Networks and Variational Inference
  - Why needed here: The entire method builds on variational inference for BNNs. Understanding how to approximate intractable posteriors with tractable distributions is fundamental.
  - Quick check question: What is the relationship between the ELBO and the true posterior in variational inference?

- Concept: Neural Processes and Amortised Inference
  - Why needed here: A-POVI-BNN is positioned as an alternative to neural processes. Understanding how NPs work and their limitations is crucial for appreciating the proposed solution.
  - Quick check question: How do neural processes use shared parameters, and why does this cause overfitting in small-scale settings?

- Concept: Meta-learning and Task-Specific vs Shared Parameters
  - Why needed here: The key innovation is separating task-specific model parameters from shared inference network parameters. Understanding the trade-offs between these approaches is essential.
  - Quick check question: What is the difference between meta-learning model parameters versus meta-learning inference procedures?

## Architecture Onboarding

- Component map:
  - Inference Network: Takes (xn, yn) pairs and outputs variational parameters (vℓn, log σℓn) for each layer
  - BNN Model: Task-specific weights W parameterized by the variational distribution
  - Training Loop: Passes entire datasets through inference network to compute q(W|D), then optimises ELBO
  - Meta-dataset: Collection of related datasets used to train the shared inference network

- Critical path:
  1. For each dataset Di in meta-dataset: Pass all (xn, yn) through inference network
  2. Construct variational distribution q(W|Di) from per-datapoint approximate likelihoods
  3. Compute ELBO using q(W|Di) and true likelihood p(y|W,X)
  4. Backpropagate through inference network parameters
  5. Repeat across all datasets in meta-dataset

- Design tradeoffs:
  - No mini-batching of datapoints vs. ability to handle small datasets
  - Task-specific BNN parameters vs. potential need for more computation at test time
  - Expressive pseudo-observation structure vs. increased complexity compared to mean-field

- Failure signatures:
  - Poor predictive performance indicates inference network hasn't learned useful mapping
  - Posterior collapse (σ → 0) suggests optimisation issues or poor initialisation
  - Overconfident predictions indicate the variational approximation is too restrictive

- First 3 experiments:
  1. Implement POVI-BNN without amortisation (treat vℓn, σℓn as free parameters) and verify it works on single dataset
  2. Implement inference network and verify it can learn to produce reasonable variational parameters on a small meta-dataset
  3. Compare A-POVI-BNN to A-MFVI-BNN on synthetic data to verify improved performance in small-scale setting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of A-POVI-BNN scale with increasing meta-dataset size and complexity beyond the synthetic Gaussian process data tested?
- Basis in paper: [inferred] The paper only tests on a simple synthetic meta-dataset with limited size (|Ξ| = 1 and |Ξ| = 100), stating "We intend to explore the effectiveness of A-POVI-BNNs in more diverse settings, such as image completion, in future work."
- Why unresolved: The authors acknowledge that their results are "very preliminary" and only tested on a simple synthetic dataset. They plan to explore more diverse settings in future work but haven't done so yet.
- What evidence would resolve it: Empirical results comparing A-POVI-BNN to other methods on larger and more complex meta-datasets, including real-world data and different data modalities (e.g., images, time series).

### Open Question 2
- Question: How does the computational complexity of A-POVI-BNN compare to other meta-learning methods, especially for larger datasets?
- Basis in paper: [explicit] The authors note "An important limitation of this approach is that performing stochastic optimisation through mini-batching datapoints is not possible, as to compute the q(W|D) we require passing the entire dataset D through the inference network."
- Why unresolved: While the limitation is mentioned, the paper doesn't provide a detailed analysis of the computational complexity or compare it to other methods. The impact on scalability is not fully explored.
- What evidence would resolve it: A thorough computational complexity analysis comparing A-POVI-BNN to other meta-learning methods, including time and memory requirements for different dataset sizes and model architectures.

### Open Question 3
- Question: How does the choice of inference network architecture and hyperparameters affect the performance of A-POVI-BNN?
- Basis in paper: [inferred] The paper mentions that "All NNs used in the amortised BNN architectures (both the model and inference network) consist of two layers of 50 hidden units and ReLU activation functions" but doesn't explore the impact of different architectures or hyperparameters.
- Why unresolved: The authors use a specific architecture for the inference network but don't provide any ablation studies or sensitivity analysis to show how different choices might affect performance.
- What evidence would resolve it: Empirical results showing the performance of A-POVI-BNN with different inference network architectures, layer sizes, activation functions, and other hyperparameters, along with an analysis of their impact on predictive performance and computational efficiency.

## Limitations

- Limited evaluation to synthetic data only, with no testing on real-world datasets or diverse task types
- No quantitative metrics provided for comparison, relying only on visual inspection of predictive distributions
- Computational complexity concerns due to inability to mini-batch datapoints through inference network

## Confidence

- High confidence: The mechanism of replacing inducing inputs with data points to create per-datapoint approximate likelihoods is clearly described and theoretically sound.
- Medium confidence: The claim that removing shared model parameters prevents overfitting is plausible but needs more empirical validation across diverse tasks.
- Medium confidence: The assertion that the pseudo-observation structure provides better approximations than mean-field VI is supported by cited work but not directly demonstrated in this paper.

## Next Checks

1. **Quantitative evaluation**: Implement proper evaluation metrics (e.g., log-likelihood, RMSE) to compare A-POVI-BNN against baselines on the synthetic dataset.
2. **Broader task diversity**: Test A-POVI-BNN on real-world few-shot learning tasks (e.g., Omniglot, miniImageNet) to assess performance beyond synthetic data.
3. **Ablation study**: Compare A-POVI-BNN against unamortised POVI-BNN and A-MFVI-BNN to isolate the benefits of both the pseudo-observation structure and amortisation.