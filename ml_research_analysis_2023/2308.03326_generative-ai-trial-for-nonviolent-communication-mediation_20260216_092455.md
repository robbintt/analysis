---
ver: rpa2
title: Generative AI trial for nonviolent communication mediation
arxiv_id: '2308.03326'
source_url: https://arxiv.org/abs/2308.03326
tags:
- output
- input
- needs
- sentence
- feelings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study explored the application of generative AI, specifically
  ChatGPT, to nonviolent communication (NVC) mediation to address social divisions
  and conflicts. The approach involved testing ChatGPT''s ability to mediate input
  sentences across NVC''s four processes: observation, feelings, needs, and requests.'
---

# Generative AI trial for nonviolent communication mediation

## Quick Facts
- arXiv ID: 2308.03326
- Source URL: https://arxiv.org/abs/2308.03326
- Reference count: 25
- Primary result: ChatGPT shows potential for NVC mediation but not yet at practical level

## Executive Summary
This study explores the application of generative AI, specifically ChatGPT, to nonviolent communication (NVC) mediation as a potential tool for addressing social divisions and conflicts. The research tests ChatGPT's ability to mediate input sentences across NVC's four processes: observation, feelings, needs, and requests. While the results indicate potential for AI application in NVC mediation, the current implementation falls short of practical deployment. The study proposes several improvement guidelines including adding model responses, relearning from revised responses, specifying appropriate terminology, and re-asking for required information.

## Method Summary
The study employed ChatGPT to mediate sentences across NVC's four components by setting up mediator roles with example sentences and input exercises. For each component (observation, feelings, needs, requests), the researcher configured ChatGPT with role definitions and example patterns, then input test sentences for mediation. Output responses were evaluated using a simple rating system (+: good, 0: neither good nor bad, âˆ’: bad). The approach focused on structured prompt engineering with iterative feedback to improve AI performance in distinguishing between observations and evaluations, feelings and judgments, needs and feelings, and requests and demands.

## Key Results
- ChatGPT demonstrated basic capability to restructure input sentences according to NVC's four-process framework
- The model showed particular difficulty distinguishing between observations and evaluations, and between needs and feelings
- Iterative feedback improved performance, though not to a consistently reliable level
- The research suggests AI could initially assist certified trainers in preparing for and reviewing NVC events

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPT can mediate NVC sentences by restructuring input into the four NVC processes (observation, feelings, needs, requests)
- Mechanism: The model learns from example patterns in prompts to identify and separate objective observations from evaluations, subjective feelings from judgments, needs from feelings, and specific requests from vague demands
- Core assumption: Structured prompt examples with clear role definitions enable the model to perform consistent mediation transformations
- Evidence anchors:
  - [abstract] Results showed potential for AI application in NVC mediation, though not yet at a practical level
  - [section] For each of the four processes, I first set up the mediator role and example sentences in ChatGPT at the prompt
- Break condition: Model fails to distinguish between observations and evaluations, or cannot identify needs separate from feelings when examples are provided

### Mechanism 2
- Claim: Iterative prompting with feedback improves ChatGPT's NVC mediation performance
- Mechanism: The model learns from low-rated responses when given corrective feedback, allowing it to refine its understanding of NVC terminology and structure
- Core assumption: ChatGPT can incorporate feedback from previous responses to improve subsequent outputs
- Evidence anchors:
  - [section] Point out the bad points to the low rated responses and have the AI re-answer them. This allows it to learn
  - [section] Increase the number of example sentences and model responses in the role setting prompts of generative AI
- Break condition: Model cannot incorporate feedback effectively, producing similar errors despite corrective prompts

### Mechanism 3
- Claim: Specifying appropriate terminology constraints improves ChatGPT's NVC mediation accuracy
- Mechanism: By constraining responses to use specific NVC terminology (e.g., Feelings and Needs Inventory terms), the model produces more accurate and consistent outputs aligned with NVC principles
- Core assumption: Explicit terminology constraints guide the model toward more accurate NVC responses
- Evidence anchors:
  - [section] Specify the terms to be used in the response sentence. For example, for feelings and needs, you may refer to the Feelings and Needs Inventory in the literature
  - [section] Outputs A and B are highly commendable in that the reason for feeling is inferred
- Break condition: Model ignores terminology constraints or produces responses that violate NVC principles despite explicit instructions

## Foundational Learning

- Concept: NVC Four-Component Structure
  - Why needed here: Understanding observation, feelings, needs, and requests is essential for designing effective prompts and evaluating ChatGPT's mediation performance
  - Quick check question: Can you identify which NVC component is missing from the statement "You always interrupt me"?

- Concept: Prompt Engineering for AI Mediation
  - Why needed here: The study's success depends on carefully structured prompts that define roles, provide examples, and specify desired output formats
  - Quick check question: What are the three key elements that should be included in a prompt for NVC mediation?

- Concept: Feedback Loop in AI Training
  - Why needed here: The study suggests iterative improvement through feedback on model responses, which is crucial for understanding how to refine AI mediation capabilities
  - Quick check question: How does providing corrective feedback to AI responses differ from simply giving it more examples?

## Architecture Onboarding

- Component map: Role definition -> Example sentences -> Input exercise -> Output evaluation -> Feedback loop -> Terminology constraints
- Critical path: Prompt design -> Initial response generation -> Evaluation against NVC criteria -> Iterative refinement through feedback
- Design tradeoffs: Balance between providing enough examples for learning vs. keeping prompts concise; trade-off between explicit terminology constraints and model flexibility
- Failure signatures: Inability to separate observations from evaluations; missing needs in responses; producing requests without specific behavioral components
- First 3 experiments:
  1. Test ChatGPT's ability to separate observation from evaluation using simple sentence pairs
  2. Evaluate whether providing Feelings and Needs Inventory terms improves response accuracy
  3. Measure improvement in responses after providing specific corrective feedback on initial attempts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific criteria or metrics could be used to quantitatively evaluate the effectiveness of ChatGPT-mediated NVC responses compared to human-certified trainers?
- Basis in paper: [explicit] The paper mentions rating responses as "+", "0", or "-", but suggests more systematic evaluation is needed for practical implementation
- Why unresolved: Current evaluation relies on subjective assessment without standardized metrics or comparison benchmarks against human mediators
- What evidence would resolve it: Development and validation of standardized evaluation criteria, comparison studies between AI and human mediator performance using consistent metrics

### Open Question 2
- How does ChatGPT's performance vary across different cultural contexts when mediating NVC communication, and what cultural adaptations are necessary for global deployment?
- Basis in paper: [inferred] The paper discusses NVC's application to social divisions globally but doesn't address cultural variations in AI performance
- Why unresolved: The paper doesn't explore cultural factors that might affect NVC mediation effectiveness or AI's ability to adapt to different cultural communication norms
- What evidence would resolve it: Cross-cultural studies testing ChatGPT's mediation performance across different societies, with analysis of cultural factors affecting effectiveness

### Open Question 3
- What is the optimal balance between AI automation and human oversight in NVC mediation to maximize effectiveness while maintaining the human elements of empathy and connection?
- Basis in paper: [explicit] The paper suggests AI should initially assist rather than replace certified trainers
- Why unresolved: The paper doesn't specify what proportion of mediation tasks should be automated versus human-guided for optimal outcomes
- What evidence would resolve it: Empirical studies comparing different levels of AI/human collaboration in mediation, measuring outcomes like resolution rates and participant satisfaction

## Limitations
- Study demonstrates only preliminary proof-of-concept results without systematic evaluation of ChatGPT's NVC mediation capabilities
- Assessment methodology relies on subjective ratings rather than standardized metrics
- Iterative improvement mechanisms proposed remain theoretical without empirical validation
- Study does not address potential biases in ChatGPT's responses or examine generalization across different conflict types

## Confidence

- **High confidence**: The basic feasibility of using structured prompts to guide ChatGPT toward NVC-like responses
- **Medium confidence**: The proposed improvement mechanisms (iterative feedback, terminology constraints) have theoretical plausibility but lack empirical validation
- **Low confidence**: The practical utility of AI-mediated NVC for real-world conflict resolution scenarios

## Next Checks

1. Implement a controlled experiment comparing ChatGPT's NVC mediation with human mediator outputs using standardized conflict scenarios and blinded evaluation by certified NVC trainers
2. Test the iterative feedback mechanism by measuring response quality improvements across multiple rounds of correction for a fixed set of problematic inputs
3. Conduct user studies with actual NVC practitioners to evaluate whether AI-assisted preparation and review tools improve training effectiveness and mediation outcomes compared to traditional methods