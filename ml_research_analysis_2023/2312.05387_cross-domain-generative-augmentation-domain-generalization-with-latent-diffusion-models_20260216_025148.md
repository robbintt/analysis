---
ver: rpa2
title: 'Cross Domain Generative Augmentation: Domain Generalization with Latent Diffusion
  Models'
arxiv_id: '2312.05387'
source_url: https://arxiv.org/abs/2312.05387
tags:
- domain
- cdga
- data
- domains
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Cross Domain Generative Augmentation (CDGA) is proposed to improve
  out-of-domain generalization in deep learning models by reducing domain shift. The
  method leverages latent diffusion models (LDM) to generate synthetic images that
  fill the gap between all domain pairs, thereby reducing non-iidness in the training
  data.
---

# Cross Domain Generative Augmentation: Domain Generalization with Latent Diffusion Models

## Quick Facts
- arXiv ID: 2312.05387
- Source URL: https://arxiv.org/abs/2312.05387
- Reference count: 40
- Primary result: CDGA improves OOD accuracy by 2.1% to 4.2% on DomainBed benchmarks using latent diffusion models for synthetic data augmentation

## Executive Summary
Cross Domain Generative Augmentation (CDGA) is a novel method for improving out-of-domain generalization in deep learning models. The approach uses latent diffusion models (LDM) to generate synthetic images that fill the gap between different domains, effectively reducing domain shift and non-iidness in training data. Two variants are proposed: CDGA-PG (prompt-guided) for domains with text descriptions, and CDGA-IG (image-guided) for domains without. Extensive experiments on PACS, OfficeHome, DomainNet, and VLCS datasets demonstrate significant improvements over state-of-the-art domain generalization methods.

## Method Summary
CDGA generates synthetic images to bridge the gap between different domains using latent diffusion models. For each image in a source domain, the method generates new images guided by text descriptions (CDGA-PG) or images from other domains (CDGA-IG). This creates interpolated samples that reduce the non-iidness of the training data. The synthetic data is combined with original data and used to train models using empirical risk minimization (ERM). The approach is evaluated on multiple DomainBed benchmark datasets, showing consistent improvements in out-of-domain accuracy.

## Key Results
- CDGA outperforms state-of-the-art domain generalization methods with average accuracy improvements of 2.1% to 4.2% across PACS, OfficeHome, DomainNet, and VLCS datasets
- Ablation studies show CDGA improves adversarial robustness and reduces domain shift as measured by transferability and diversity metrics
- CDGA leads to flatter loss landscapes, which correlates with better generalization performance
- CDGA-PG performs best when text prompts are available, while CDGA-IG provides competitive results when only images are available

## Why This Works (Mechanism)

### Mechanism 1
CDGA reduces domain shift by generating synthetic images that fill the gap between all domain pairs. For each image in domain i, the method uses a latent diffusion model (LDM) to generate new images guided by text descriptions or images from other domains. This creates interpolated samples between domain pairs, effectively reducing non-iidness in the training data.

### Mechanism 2
CDGA outperforms ERM by addressing the domain shift that ERM cannot fully address through simple data augmentation. While ERM minimizes the average loss across domains, it uses point-wise kernel estimates that become inaccurate under domain shift. CDGA replaces these with density estimates in the vicinity of domain pairs, effectively creating a better estimate of the true data distribution.

### Mechanism 3
CDGA improves adversarial robustness and leads to flatter loss landscapes, which correlates with better generalization. By generating synthetic samples that reduce domain shift, CDGA creates a more stable training distribution. This stability manifests as improved robustness to adversarial perturbations and flatter loss landscapes, both indicators of better generalization.

## Foundational Learning

- Concept: Vicinal Risk Minimization (VRM)
  - Why needed here: CDGA is theoretically motivated by VRM, which replaces point-wise kernel estimates with density estimates in the vicinity distribution.
  - Quick check question: What is the key difference between ERM and VRM in how they estimate the true data distribution?

- Concept: Domain Generalization (DG)
  - Why needed here: CDGA is designed specifically for the DG setting where the goal is to generalize to an unseen target domain from multiple source domains.
  - Quick check question: How does the DG setting differ from domain adaptation in terms of access to target domain data?

- Concept: Latent Diffusion Models (LDM)
  - Why needed here: CDGA uses pre-trained LDM to generate synthetic images that fill the gap between domains.
  - Quick check question: What are the key components of a latent diffusion model and how does it differ from a standard diffusion model?

## Architecture Onboarding

- Component map: Pre-trained LDM -> Image transformation pipeline -> CDGA implementation -> DomainBed integration -> Data generation pipeline
- Critical path: Load pre-trained LDM → For each training domain pair, generate synthetic images → Combine original and synthetic data → Train model on combined dataset → Evaluate using DomainBed protocol
- Design tradeoffs:
  - Offline vs online generation: CDGA uses offline generation for efficiency, but this requires significant storage for millions of synthetic images
  - Prompt-guided vs image-guided: CDGA-PG uses text prompts when available, CDGA-IG uses image mixing when prompts are not available
  - Generation batch size: Larger batch sizes create more synthetic data but increase computation time
- Failure signatures:
  - Poor OOD performance despite synthetic data generation (suggests interpolation quality issues)
  - Excessive similarity between synthetic and original images (near-duplicates indicate insufficient variation)
  - Computational bottlenecks during generation or training (generation batch size or storage issues)
- First 3 experiments:
  1. Verify synthetic image quality: Generate a small set of CDGA images and visually inspect them for realistic interpolation between domains
  2. Test basic functionality: Run CDGA on a small subset of data (e.g., one class from PACS) and verify it improves OOD accuracy
  3. Measure domain shift reduction: Use t-SNE visualization to confirm that CDGA-generated images fill the gap between original domains

## Open Questions the Paper Calls Out

### Open Question 1
Does CDGA improve domain generalization in settings beyond image classification, such as natural language processing or tabular data? The paper focuses on image classification benchmarks and leverages image-specific generative models (LDMs) and techniques (CLIP embeddings). Extending this to other data types would require different generative models and augmentation strategies.

### Open Question 2
How does CDGA's performance scale with the number of source domains? Is there a point where adding more domains yields diminishing returns? The paper evaluates on datasets with 4-6 domains but does not systematically vary the number of source domains. More domains could provide better coverage of the input space or introduce more noise.

### Open Question 3
What is the relationship between CDGA's effectiveness and the diversity of the training data? Does CDGA help more when source domains are highly dissimilar? The paper shows CDGA reduces domain shift, but doesn't establish whether it's particularly effective when initial shifts are large. This would indicate whether CDGA is a general improvement or most valuable in challenging DG scenarios.

## Limitations

- The paper doesn't validate the interpolation quality of the LDM, which is critical for the method's success
- The relationship between adversarial robustness and domain generalization is correlational without mechanistic explanation
- The approach requires significant computational resources for generating millions of synthetic images offline
- The method's effectiveness on non-image domains is unexplored

## Confidence

- Domain shift reduction claims: Medium confidence
- Performance improvement claims: High confidence (benchmarked on standard datasets)
- Adversarial robustness claims: Medium confidence
- Loss landscape claims: Low confidence

## Next Checks

1. **Interpolation quality validation**: Generate synthetic images for a small domain pair (e.g., Photo→Art from PACS) and use t-SNE to verify they fill the gap between domains while maintaining class separation. Calculate quantitative metrics like Frechet Inception Distance between original and interpolated samples.

2. **Ablation study on generation parameters**: Test how different LDM generation parameters (guidance scale, number of steps) affect both synthetic image quality and downstream generalization performance. This would help understand the sensitivity of CDGA to generation hyperparameters.

3. **Cross-dataset generalization test**: Train CDGA on one dataset (e.g., PACS) and test its effectiveness on a held-out dataset (e.g., OfficeHome) to verify that the method learns domain-agnostic interpolation strategies rather than overfitting to specific domain characteristics.