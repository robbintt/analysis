---
ver: rpa2
title: 'Can LLMs be Good Financial Advisors?: An Initial Study in Personal Decision
  Making for Optimized Outcomes'
arxiv_id: '2307.07422'
source_url: https://arxiv.org/abs/2307.07422
tags:
- credit
- chatgpt
- march
- bard
- card
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the performance of ChatGPT and Bard in providing
  financial advice across 13 queries involving credit cards, bank accounts, and certificates
  of deposit in English, African American Vernacular English, and Telugu. The chatbots
  produced fluent and plausible responses but exhibited critical gaps in accuracy,
  personalized recommendations, and mathematical reasoning.
---

# Can LLMs be Good Financial Advisors?: An Initial Study in Personal Decision Making for Optimized Outcomes

## Quick Facts
- arXiv ID: 2307.07422
- Source URL: https://arxiv.org/abs/2307.07422
- Reference count: 4
- Chatbots produce fluent but often inaccurate financial advice with critical gaps in mathematical reasoning and personalized recommendations

## Executive Summary
This study evaluates ChatGPT and Bard's performance in providing financial advice across 13 queries involving credit cards, bank accounts, and certificates of deposit. While both chatbots produced fluent and plausible responses, they exhibited critical gaps in accuracy, personalized recommendations, and mathematical reasoning. ChatGPT showed better learning from errors and fewer perceptual mistakes, while Bard provided visual aids more often. Both struggled with numeric reasoning and generating reliable financial advice, highlighting significant limitations in current LLM-based financial advisory systems.

## Method Summary
The study posed 13 financial queries to ChatGPT and Bard in English, African American Vernacular English, and Telugu, covering credit cards, bank accounts, and certificates of deposit. Researchers recorded all responses and analyzed them for accuracy, personalized recommendations, mathematical reasoning, and visual aids. Errors were categorized into five types: lack of personalized recommendations, mathematical errors, perceptual errors, grammatical errors, and lack of visual aids. The evaluation compared performance across different query categories and languages.

## Key Results
- Both chatbots produced fluent responses but made critical mathematical errors in financial calculations
- ChatGPT corrected errors more often than Bard and better understood African American Vernacular English
- Neither system provided consistently personalized recommendations or reliable financial advice

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Chatbots can produce fluent and plausible responses even when lacking accurate financial reasoning.
- Mechanism: LLMs generate text based on patterns learned from large datasets, which enables them to construct grammatically correct and contextually appropriate responses without necessarily performing the underlying calculations correctly.
- Core assumption: Fluency in language generation does not imply correctness in domain-specific reasoning.
- Evidence anchors:
  - [abstract] "Although the outputs of the chatbots are fluent and plausible, there are still critical gaps in providing accurate and reliable financial information using LLM-based chatbots."
  - [section] Table 2 shows ChatGPT gave inaccurate results for direct mathematical queries while maintaining fluent language.
- Break condition: When the response requires precise numerical computation or domain-specific validation that cannot be satisfied by pattern matching alone.

### Mechanism 2
- Claim: Chatbots exhibit learning from errors when the same query is repeated with different phrasing.
- Mechanism: The model's internal state updates through the conversation, allowing it to correct previous mistakes when given similar context or when explicitly prompted to reconsider.
- Core assumption: The chatbot's learning is limited to the current session and does not represent true retention across separate interactions.
- Evidence anchors:
  - [section] "ChatGPT corrects its errors more often than Bard" and "ChatGPT understood African-American Vernacular English (AA VE) dialect and gave a reasonable response to the query" after initial confusion.
  - [section] "ChatGPT did not understand it immediately. When we posed the same query again in the same dialect, it understood the query and gave a reasonable recommendation."
- Break condition: When the error involves fundamental misunderstanding of the domain logic that cannot be resolved through conversational context alone.

### Mechanism 3
- Claim: Different chatbots exhibit distinct strengths in handling user queries, with ChatGPT showing better personalized suggestions and Bard providing more visual aids.
- Mechanism: The underlying model architectures and training objectives lead to different response patterns - ChatGPT prioritizes conversational coherence and personalization while Bard emphasizes structured presentation and visual formatting.
- Core assumption: The observed differences reflect architectural design choices rather than random variation.
- Evidence anchors:
  - [section] Table 2 lists specific differences: "ChatGPT gives personalized suggestions more often than Bard" and "As a response to one of the queries, Bard gave a recommendation by making use of a table with different options that user could choose from."
  - [section] "ChatGPT calculates CUR and reasons using the computed CUR more often than Bard" vs "Bard does not utilize the information the user provides completely."
- Break condition: When the user's needs specifically require capabilities that fall outside the chatbot's demonstrated strengths.

## Foundational Learning

- Concept: Financial constraint satisfaction and optimization
  - Why needed here: The queries involve determining whether certain financial actions (like making purchases) satisfy constraints (like credit limits and due amounts).
  - Quick check question: Given a credit card with $2,800 limit, $2,000 due, and $1,000 purchase, can you determine if the constraint (due + purchase < limit) is satisfied?

- Concept: Basic interest and APR calculations
  - Why needed here: Several queries involve comparing interest earned on CDs versus interest charged on credit card balances.
  - Quick check question: If you have $1,000 in a CD earning 6% annually versus a credit card balance accruing 25% APR, which is more financially advantageous over one month?

- Concept: Numerical reasoning and arithmetic verification
  - Why needed here: The study found chatbots made mathematical errors, highlighting the need for accurate calculation skills.
  - Quick check question: Calculate 5% of $1,000 and verify whether this cashback amount would cover a $100 minimum credit card payment.

## Architecture Onboarding

- Component map: User interface -> Query parser -> Language model (ChatGPT/Bard) -> Response formatter -> Output display
- Critical path: Query input -> Semantic understanding -> Financial reasoning -> Constraint checking -> Response generation
- Design tradeoffs: General language fluency vs. domain-specific accuracy; conversational flexibility vs. structured reasoning; visual presentation vs. textual explanation
- Failure signatures: Mathematical errors in calculations, missing personalized recommendations, perceptual errors in interpreting constraints, lack of visual aids when needed
- First 3 experiments:
  1. Test the same financial query with both ChatGPT and Bard to observe differences in reasoning approach and accuracy
  2. Pose a query with explicit mathematical constraints to evaluate numerical reasoning capabilities
  3. Test the chatbot's ability to handle different dialects or languages to assess linguistic flexibility

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the accuracy of LLM-based financial advisory systems be improved to provide more reliable and personalized recommendations?
- Basis in paper: [explicit] The paper highlights critical gaps in providing accurate and reliable financial information using LLM-based chatbots, such as lack of personalized recommendations and mathematical errors.
- Why unresolved: The paper identifies these limitations but does not propose specific solutions to address them.
- What evidence would resolve it: Conducting further research to develop and test methods for improving the accuracy and personalization of LLM-based financial advisory systems, and evaluating their performance in real-world scenarios.

### Open Question 2
- Question: How can LLM-based systems be enhanced to better understand and process queries in different dialects and languages?
- Basis in paper: [explicit] The paper mentions challenges in evaluating LLM-based systems for finance domains, including support for languages used by customers from different population groups, such as African American Vernacular English (AA VE) and Telugu.
- Why unresolved: The paper does not explore potential solutions to enhance the language understanding capabilities of LLM-based systems.
- What evidence would resolve it: Investigating and implementing techniques to improve the language understanding capabilities of LLM-based systems, and testing their performance in handling queries in various dialects and languages.

### Open Question 3
- Question: How can LLM-based financial advisory systems be evaluated and improved to better cater to the needs of diverse user groups?
- Basis in paper: [explicit] The paper mentions the challenge of evaluating the response of users from a diverse set of backgrounds and suggests that more experiments are needed with inputs carefully modeling the characteristics of different user groups.
- Why unresolved: The paper does not provide a detailed framework or methodology for evaluating and improving LLM-based financial advisory systems for diverse user groups.
- What evidence would resolve it: Developing a comprehensive evaluation framework that considers the needs and preferences of diverse user groups, and using it to assess and enhance the performance of LLM-based financial advisory systems.

## Limitations
- Study used only 13 queries across three languages, which may not represent the full complexity of real-world financial decision-making scenarios
- Evaluation relied on researcher judgment rather than formal expert validation for determining correct answers
- Findings are limited to specific versions of ChatGPT and Bard, which have since been updated

## Confidence

**High Confidence**: The observation that both ChatGPT and Bard produce fluent but often inaccurate financial advice is well-supported by the evidence. The specific error patterns (mathematical errors, lack of personalization, perceptual mistakes) are clearly documented across multiple queries.

**Medium Confidence**: The comparative assessment showing ChatGPT corrects errors more often than Bard and handles African American Vernacular English better is supported by specific examples, but may be influenced by particular query formulations or model versions.

**Low Confidence**: The generalizability of findings to other financial domains beyond the specific products tested (credit cards, bank accounts, CDs) and to other LLM architectures remains uncertain given the limited scope of the evaluation.

## Next Checks

1. **Expert Validation Protocol**: Replicate the study with certified financial advisors scoring the chatbot responses against established financial planning standards to eliminate researcher bias in determining correctness.

2. **Cross-Version Comparison**: Test the same 13 queries against current versions of ChatGPT and Bard (post-study updates) to quantify how model improvements have affected performance on financial reasoning tasks.

3. **Expanded Domain Coverage**: Design and test 20-30 additional queries covering diverse financial products (investments, insurance, mortgages, retirement planning) to determine whether the observed limitations extend across the broader financial advisory landscape.