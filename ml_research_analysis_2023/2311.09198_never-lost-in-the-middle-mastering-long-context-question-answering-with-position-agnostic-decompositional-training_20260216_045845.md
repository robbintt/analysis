---
ver: rpa2
title: 'Never Lost in the Middle: Mastering Long-Context Question Answering with Position-Agnostic
  Decompositional Training'
arxiv_id: '2311.09198'
source_url: https://arxiv.org/abs/2311.09198
tags:
- multi-doc
- task
- arxiv
- context
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the "lost in the middle" problem, where large
  language models struggle to extract correct information from long contexts when
  relevant data is located in the middle. The authors propose Attention-Strengthening
  Multi-doc QA (ASM QA), a novel task decomposition that explicitly extracts questions
  and indexes of supporting documents before generating answers.
---

# Never Lost in the Middle: Mastering Long-Context Question Answering with Position-Agnostic Decompositional Training

## Quick Facts
- **arXiv ID**: 2311.09198
- **Source URL**: https://arxiv.org/abs/2311.09198
- **Reference count**: 15
- **Primary result**: Improves Multi-doc QA by 13.7% absolute gain using 1/4 context window size

## Executive Summary
This paper addresses the "lost in the middle" problem where large language models struggle to extract information from long contexts when relevant data is positioned in the middle. The authors propose Attention-Strengthening Multi-doc QA (ASM QA), a task decomposition method that explicitly extracts questions and indexes of supporting documents before generating answers. The approach improves information searching and reflection abilities by training on specially designed tasks. Experiments show substantial improvements in Multi-doc QA benchmarks, with 13.7% absolute gain in shuffled settings and 21.5% improvement in passage retrieval tasks, outperforming state-of-the-art models while using only 1/4 the context window size.

## Method Summary
The paper proposes Attention-Strengthening Multi-doc QA (ASM QA) which decomposes the Multi-doc QA task into three explicit steps: question repetition (QR), index prediction (IP), and answer summarization (AS). The model is first trained on general SFT data to expand context window to 8K, then fine-tuned on ASM QA data using this three-step decomposition. The approach includes generating synthetic unknown samples where all documents are negative. The training uses a learning rate schedule and Flash Attention on 16 A100 GPUs for 2 epochs.

## Key Results
- 13.7% absolute improvement on Multi-doc QA shuffled settings
- 21.5% improvement on passage retrieval tasks
- Achieves superior performance using only 1/4 the context window size of baseline models
- Outperforms state-of-the-art models including Baichuan2-13B-chat

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Attention failure on target documents is the main cause of the "lost in the middle" problem
- **Mechanism**: Attention scores decay with distance from query/instruction tokens, causing models to neglect middle tokens during self-attention
- **Evidence**: Attention visualizations show scores fading for middle-context tokens in baseline models

### Mechanism 2
- **Claim**: Decomposing QA tasks into explicit steps strengthens attention to relevant information
- **Mechanism**: Explicit question repetition and index prediction before answer generation forces earlier attention to query and supporting evidence tokens
- **Evidence**: 5.9% performance drop when removing question repetition step

### Mechanism 3
- **Claim**: Synthetic unknown samples train models to avoid unwarranted confidence
- **Mechanism**: Including samples where all documents are negative teaches the model to recognize when correct information is absent
- **Evidence**: Models trained with ASM QA show reduced hallucination compared to baselines

## Foundational Learning

- **Concept**: Attention mechanisms in Transformers
  - **Why needed**: Understanding attention score decay with distance is crucial for grasping why middle-context information gets lost
  - **Quick check**: What happens to attention scores for tokens located 500 positions away from the query token in a standard Transformer?

- **Concept**: Task decomposition and Chain-of-Thought reasoning
  - **Why needed**: The paper's core innovation relies on breaking down complex QA into explicit steps to strengthen attention
  - **Quick check**: How does explicit question repetition before answer generation change the attention distribution compared to direct answering?

- **Concept**: Positional encoding and its impact on attention
  - **Why needed**: Different positional encoding schemes affect how attention scales with distance
  - **Quick check**: How does Rotary Position Embedding (RoPE) differ from absolute positional encoding in terms of attention decay patterns?

## Architecture Onboarding

- **Component map**: Input → QR step → IP step → AS step → Answer generation
- **Critical path**: Input → QR step → IP step → AS step → Answer generation
- **Design tradeoffs**:
  - Context window size vs. attention quality: Using 1/4 context window but achieving better performance
  - Task complexity vs. training efficiency: ASM QA adds steps but improves performance significantly
  - Synthetic data vs. real data: 5% synthetic unknowns vs. 100% real data for other samples
- **Failure signatures**:
  - Performance degradation on shuffled datasets indicates "lost in middle" problem
  - Attention visualization showing fading scores for middle tokens
  - Large gap between shuffled and ordered document performance
- **First 3 experiments**:
  1. Compare attention scores for middle vs. edge tokens in baseline vs. ASM QA model
  2. Ablation study: Remove QR step and measure performance drop
  3. Ablation study: Remove IP step and measure performance drop on synthesis tasks

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions, but raises several implicit ones regarding the generalizability of the approach to other long-context tasks and the optimal balance between context window size and attention quality.

## Limitations
- Limited visualization of attention patterns in the trained ASM QA model compared to baselines
- Unclear contribution of synthetic unknown samples versus full ASM QA training pipeline
- Tradeoff between reduced context window and performance on tasks requiring very long contexts

## Confidence

- **High Confidence**: Core mechanism of explicit task decomposition improving attention is well-supported by ablation studies
- **Medium Confidence**: Claim that attention failure is the "main cause" of lost in middle problem is supported but not definitively proven
- **Low Confidence**: Specific contribution of synthetic unknown samples to overall performance remains uncertain without isolated ablation results

## Next Checks

1. Generate and compare attention visualizations for ASM QA model versus baseline models on identical examples, focusing on middle-context token attention throughout the three-step generation process

2. Train identical models with and without the 5% synthetic unknown samples while keeping all other components constant, then measure performance differences specifically on hallucination-prone tasks

3. Systematically evaluate model performance as context length increases from 2K to 32K tokens, measuring both absolute performance and the gap between ordered versus shuffled document performance