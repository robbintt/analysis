---
ver: rpa2
title: 'LLM4SGG: Large Language Models for Weakly Supervised Scene Graph Generation'
arxiv_id: '2310.10404'
source_url: https://arxiv.org/abs/2310.10404
tags:
- triplets
- predicate
- entity
- llm4sgg
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'LLM4SGG addresses the problem of weakly-supervised scene graph
  generation by tackling two overlooked issues: semantic over-simplification of predicates
  and low-density scene graphs. It leverages a pre-trained LLM to extract fine-grained
  triplets from captions and align them with target classes, using Chain-of-Thought
  prompting and in-context few-shot learning.'
---

# LLM4SGG: Large Language Models for Weakly Supervised Scene Graph Generation

## Quick Facts
- **arXiv ID**: 2310.10404
- **Source URL**: https://arxiv.org/abs/2310.10404
- **Reference count**: 33
- **Key outcome**: LLM4SGG achieves significant improvements in Recall@K and mean Recall@K over state-of-the-art methods on Visual Genome and GQA datasets by leveraging LLM-based triplet extraction and alignment.

## Executive Summary
LLM4SGG addresses two critical limitations in weakly-supervised scene graph generation: semantic over-simplification of predicates and low-density scene graphs. By using a pre-trained LLM with Chain-of-Thought prompting and in-context few-shot learning, the method extracts fine-grained triplets from captions and aligns them with target class lexicons. The approach demonstrates superior performance on standard benchmarks while requiring fewer training images, making it both more accurate and data-efficient than existing methods.

## Method Summary
LLM4SGG leverages GPT-3.5-turbo to extract and align triplets from captions through a two-step Chain-of-Thought process: first paraphrasing the caption, then extracting subject-predicate-object triplets. The extracted components are aligned with target entity and predicate lexicons using in-context few-shot learning. These localized triplets serve as pseudo-labels for training weakly-supervised scene graph generation models like SGNLS or VS3. The method operates on COCO caption data (64K images, 5 captions each) and evaluates on Visual Genome and GQA datasets using Recall@K and mean Recall@K metrics.

## Key Results
- Achieves significant improvements in Recall@K and mean Recall@K over state-of-the-art methods on Visual Genome and GQA datasets.
- Demonstrates data efficiency by achieving strong results with only 7.8% of the baseline training images.
- Shows better predicate granularity by capturing complex relationships like "lying on" instead of reducing them to "on".

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: LLM4SGG reduces semantic over-simplification by using Chain-of-Thought prompting to extract fine-grained predicates from captions.
- **Mechanism**: The LLM first paraphrases the caption, then extracts triplets in a stepwise manner. This allows the model to capture complex predicates like "lying on" instead of reducing them to "on".
- **Core assumption**: The LLM's comprehension of context enables it to retain predicate granularity that rule-based parsers lose.
- **Evidence anchors**:
  - [abstract]: "we mitigate the two issues by leveraging the LLM’s in-depth understanding of language and reasoning ability during the extraction of triplets from captions"
  - [section 3.3]: Describes the two-step Chain-of-Thought extraction process (paraphrase → extract).
- **Break condition**: If the LLM fails to paraphrase or the prompt lacks sufficient examples, it may default to coarse predicates.

### Mechanism 2
- **Claim**: LLM4SGG alleviates low-density scene graphs by increasing the number of valid triplets through LLM-based alignment.
- **Mechanism**: The LLM aligns extracted triplet components with target class lexicons, mapping synonyms/hypernyms to valid classes. Paraphrasing the caption before extraction further increases coverage.
- **Core assumption**: The LLM can accurately map between lexical variants and target classes without external KBs.
- **Evidence anchors**:
  - [abstract]: "mitigate the two issues by leveraging the LLM’s in-depth understanding of language and reasoning ability during the extraction of triplets from captions and alignment of entity/predicate classes with target data"
  - [section 3.4]: Describes alignment prompts and examples.
- **Break condition**: If the target lexicon lacks coverage, the LLM may default to "None", discarding otherwise valid triplets.

### Mechanism 3
- **Claim**: LLM4SGG improves data efficiency by expanding the training space with more diverse compositional relationships.
- **Mechanism**: The expanded triplet set from captions covers compositional relationships absent in the target dataset, increasing the variety of predicate-object-subject configurations seen during training.
- **Core assumption**: Captions contain richer relational diversity than the target dataset, and the LLM can surface this.
- **Evidence anchors**:
  - [section 4.3]: Shows performance gains with only 7.8% of the baseline training images.
  - [section D.3]: Reports higher zero-shot Recall@K, indicating broader training space.
- **Break condition**: If captions are overly repetitive or the LLM's paraphrasing is too conservative, diversity gains diminish.

## Foundational Learning

- **Concept**: Chain-of-Thought (CoT) prompting
  - **Why needed here**: Enables stepwise reasoning for complex tasks like triplet extraction and alignment, mimicking human decomposition of language tasks.
  - **Quick check question**: Why is paraphrasing a caption before extracting triplets beneficial for capturing fine-grained predicates?

- **Concept**: In-context few-shot learning
  - **Why needed here**: Allows the LLM to perform novel tasks without fine-tuning by conditioning on examples in the prompt.
  - **Quick check question**: What happens if the prompt contains too few or poorly chosen examples for triplet extraction?

- **Concept**: Semantic alignment with lexicons
  - **Why needed here**: Maps natural language entities/predicates to constrained target class sets without external KBs.
  - **Quick check question**: How does the LLM decide when to return "None" for an unaligned entity or predicate?

## Architecture Onboarding

- **Component map**: Prompt generator → LLM (ChatGPT/gpt-3.5-turbo) → Triplet parser & aligner → Grounding method (SGNLS or VS3) → SGG model trainer
- **Critical path**: 
  1. Input caption → Prompt construction
  2. LLM processes prompt → Extracts/aligns triplets
  3. Triplets grounded to image regions
  4. SGG model trained on localized triplets
- **Design tradeoffs**:
  - Using LLM vs rule-based parser: Higher accuracy and granularity but increased latency and cost.
  - Paraphrasing step: Increases coverage but doubles inference calls.
  - Prompt length limit: Constrains number of in-context examples, affecting performance.
- **Failure signatures**:
  - Low triplet yield: LLM returning "None" frequently due to poor lexicon alignment.
  - Semantic drift: Paraphrased captions losing original intent.
  - Grounding failure: LLM-generated entities not matching detector outputs.
- **First 3 experiments**:
  1. Compare triplet counts and predicate diversity between LLM4SGG and rule-based baseline on a small caption set.
  2. Measure grounding success rate after LLM-based alignment vs KB-based alignment.
  3. Test SGG performance with and without paraphrased caption step on a held-out image set.

## Open Questions the Paper Calls Out

- **Open Question 1**: What are the specific limitations of current LLMs in handling diverse caption structures and how can they be overcome?
  - **Basis in paper**: [explicit] The paper mentions that the rule-based parser fails to capture the predicate "lying on" at once and its heuristic rules fall short of accommodating the diverse range of caption's structure.
  - **Why unresolved**: The paper does not provide a detailed analysis of the limitations of current LLMs in handling diverse caption structures or propose specific solutions to overcome these limitations.
  - **What evidence would resolve it**: Further research and experimentation with different LLMs and prompt designs could provide insights into their limitations and potential solutions.

- **Open Question 2**: How can the grounding process be improved to fully utilize the unlocalized triplets generated by LLM4SGG?
  - **Basis in paper**: [explicit] The paper mentions that 100K out of 344K unlocalized triplets fail to be grounded by SGNLS, leading to insufficient supervision.
  - **Why unresolved**: The paper does not provide a detailed analysis of the reasons for the grounding failure or propose specific solutions to improve the grounding process.
  - **What evidence would resolve it**: Further research and experimentation with different grounding methods and techniques could provide insights into improving the grounding process.

- **Open Question 3**: How can the performance of LLM4SGG be further improved by incorporating additional information or techniques?
  - **Basis in paper**: [explicit] The paper mentions that LLM4SGG outperforms state-of-the-art methods but does not explore the potential for further improvements.
  - **Why unresolved**: The paper does not provide a comprehensive analysis of the potential for further improvements or propose specific techniques to enhance the performance of LLM4SGG.
  - **What evidence would resolve it**: Further research and experimentation with different techniques and additional information sources could provide insights into potential improvements.

## Limitations

- The method's performance depends heavily on the quality of captions and the LLM's ability to parse and align linguistic relationships, which may not generalize across domains with different caption styles.
- Grounding methods (SGNLS/VS3) may discard many extracted triplets, limiting the training data available for weakly-supervised learning.
- The paper doesn't explore how the method scales with larger or more diverse image datasets beyond COCO.

## Confidence

- **High confidence** in the mechanism showing LLM-based triplet extraction improves predicate granularity over rule-based methods (supported by direct comparison in Table 1 and predicate distribution analysis in Figure 4).
- **Medium confidence** in data efficiency claims (performance with 7.8% training data is impressive but could reflect dataset-specific properties of COCO captions rather than general LLM superiority).
- **Medium confidence** in the semantic alignment mechanism (the LLM mapping to target lexicons is effective but the paper doesn't test robustness when target classes are missing or when dealing with ambiguous predicates).

## Next Checks

1. Test LLM4SGG on a different caption dataset (e.g., Flickr30k) to verify that the performance gains are not COCO-specific and that the LLM can handle varied caption styles.
2. Perform an ablation study removing the paraphrasing step to quantify its exact contribution to predicate granularity versus computational cost.
3. Evaluate grounding success rates across different object detectors (not just Faster R-CNN and GLIP) to determine if triplet extraction quality or detector performance is the bottleneck.