---
ver: rpa2
title: 'ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education'
arxiv_id: '2309.13243'
source_url: https://arxiv.org/abs/2309.13243
tags:
- students
- chatgpt
- student
- writing
- education
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces ChEDDAR, a large-scale dialogue dataset capturing
  real-world interactions between college EFL students and ChatGPT during a semester-long
  essay revision task. The dataset includes conversation logs, edit histories, satisfaction
  ratings, and student intents.
---

# ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education

## Quick Facts
- arXiv ID: 2309.13243
- Source URL: https://arxiv.org/abs/2309.13243
- Reference count: 32
- Primary result: 84.08% accuracy for intent detection with multilingual BERT on ChEDDAR dataset

## Executive Summary
This study introduces ChEDDAR, a large-scale dialogue dataset capturing real-world interactions between college EFL students and ChatGPT during a semester-long essay revision task. The dataset includes conversation logs, edit histories, satisfaction ratings, and student intents. The authors analyze usage patterns, revealing that students often anthropomorphize GAI, treating it as an approachable peer rather than an instructor. They establish baseline results for two educational dialogue tasks: intent detection (achieving 84.08% accuracy with multilingual BERT) and satisfaction estimation (0.4649 MAE with ordinal classification). The work highlights the potential of GAI in language education while addressing academic integrity concerns, and proposes future applications including prompt recommendation and misuse detection systems.

## Method Summary
The study collected conversation logs, essay edit histories, satisfaction ratings, and student intents from 212 college students over a semester-long EFL writing course. The authors fine-tuned multilingual BERT and XLM-R models for intent detection and satisfaction estimation tasks, and also performed few-shot and zero-shot inference with GPT-3.5-turbo-16k and GPT-4 models. The dataset includes 1913 utterances with code-mixed English-Korean inputs, enabling analysis of cross-lingual NLP challenges in educational contexts.

## Key Results
- Achieved 84.08% accuracy for intent detection using multilingual BERT
- Established 0.4649 MAE for satisfaction estimation with ordinal classification
- Revealed students anthropomorphize GAI as approachable peer rather than instructor

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChEDDAR enables longitudinal analysis of student-GAI interaction patterns that short-term datasets cannot capture.
- Mechanism: By collecting conversation logs, edit histories, satisfaction ratings, and student intents over a semester-long experiment with 212 students, the dataset provides temporal depth for analyzing evolving student behaviors and perceptions toward GAI.
- Core assumption: Longer interaction periods reveal meaningful trends in student engagement, anthropomorphism, and intent shifts that single-session studies miss.
- Evidence anchors: [abstract] "longitudinal experiment involving 212 college students enrolled in English as Foreign Langauge (EFL) writing courses." [section] "students’ usage patterns on GAI through a sample-level analysis using the ChEDDAR dataset... interactions between EFL learners and GAI exhibited both similarities and differences compared to student-teacher interactions."

### Mechanism 2
- Claim: ChEDDAR's intent detection and satisfaction estimation tasks provide actionable feedback loops for improving GAI-integrated education systems.
- Mechanism: By establishing baseline results (84.08% accuracy for intent detection, 0.4649 MAE for satisfaction estimation), the dataset enables development of prompt recommendation, misuse detection, and learning analytics systems that adapt to student needs in real-time.
- Core assumption: Accurate intent classification and satisfaction prediction are prerequisites for personalized AI assistance in educational contexts.
- Evidence anchors: [abstract] "establish baseline results for two pivotal tasks in task-oriented dialogue systems within educational contexts: intent detection and satisfaction estimation." [section] "We suggest two subtasks for ChEDDAR: intent detection and satisfaction estimation to facilitate further advancements in the development of GAI-integrated English education."

### Mechanism 3
- Claim: ChEDDAR reveals students' anthropomorphic treatment of GAI as an "approachable peer" rather than instructor, informing pedagogical design.
- Mechanism: Qualitative analysis of interaction patterns shows students treating ChatGPT as human-like, expressing gratitude, and asking questions they wouldn't ask professors, suggesting GAI can fill supportive peer-like roles in language learning.
- Core assumption: Students' perception of GAI as peer rather than authority figure influences engagement quality and academic integrity concerns.
- Evidence anchors: [section] "students often treated GAI as if it were human, but particularly perceived it as an intelligent peer rather than a teacher... 22 samples where students heavily relied on ChatGPT, asking ChtGPT to provide answers for quizzes and assignments." [abstract] "students often anthropomorphize GAI, treating it as an approachable peer rather than an instructor."

## Foundational Learning

- Concept: Task-oriented dialogue systems
  - Why needed here: Understanding how to structure dialogue datasets for specific educational tasks (intent detection, satisfaction estimation) requires knowledge of task-oriented dialogue architectures and evaluation metrics.
  - Quick check question: What are the key differences between task-oriented and open-domain dialogue systems in terms of annotation schemes and evaluation?

- Concept: Multimodal data collection in educational contexts
  - Why needed here: ChEDDAR combines conversation logs, essay edit histories, and satisfaction ratings, requiring understanding of how to integrate different data types while preserving privacy and usability.
  - Quick check question: How would you design a data collection pipeline that captures both dialogue interactions and document edit histories while maintaining student privacy?

- Concept: Cross-lingual NLP and code-switching
  - Why needed here: The dataset includes code-mixed English-Korean utterances, necessitating understanding of multilingual models (M-BERT, XLM-R) and handling mixed-language inputs.
  - Quick check question: What are the main challenges in training multilingual models on code-switched data compared to monolingual data?

## Architecture Onboarding

- Component map: Dataset ingestion → Preprocessing (tokenization, intent labeling) → Model training (M-BERT, XLM-R, GPT variants) → Evaluation (accuracy, MAE) → Application modules (prompt recommendation, misuse detection)
- Critical path: Data collection → Annotation → Model training → Baseline establishment → Application development
- Design tradeoffs: Multilingual support vs. model performance, fine-tuning vs. few-shot learning, binary vs. ordinal satisfaction classification
- Failure signatures: Low intent classification accuracy (<70%), high MAE in satisfaction estimation (>0.6), inconsistent annotation across labelers
- First 3 experiments:
  1. Reproduce baseline intent detection results using M-BERT on ChEDDAR subset
  2. Compare few-shot vs. zero-shot performance of GPT-4 on satisfaction estimation task
  3. Analyze correlation between student satisfaction scores and actual essay improvement metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do student perceptions and usage patterns of ChatGPT evolve over longer periods (e.g., multiple semesters or academic years) beyond the single semester studied?
- Basis in paper: [explicit] The authors acknowledge that previous research has primarily focused on short-term effects and that their study is a semester-long experiment. They note the need for long-term analysis to examine trends and usage patterns.
- Why unresolved: The study only captures one semester of data, limiting understanding of how student interactions with GAI might change as they become more familiar with the technology or as educational contexts evolve.
- What evidence would resolve it: Longitudinal studies tracking the same students over multiple semesters or academic years, documenting changes in usage patterns, perceptions, and the impact on learning outcomes.

### Open Question 2
- Question: How effective are different prompting strategies in improving the quality of ChatGPT responses for educational purposes, and can these strategies be systematically recommended to students?
- Basis in paper: [explicit] The authors suggest prompt recommendation as a future application, combining intent detection and satisfaction estimation to categorize prompts and provide recommendations for better responses.
- Why unresolved: While the authors propose this application, they do not explore or evaluate the effectiveness of different prompting strategies or the impact of recommendations on student satisfaction and learning outcomes.
- What evidence would resolve it: Experimental studies comparing different prompting strategies, evaluating their impact on ChatGPT response quality, student satisfaction, and learning outcomes, and developing a systematic framework for prompt recommendation.

### Open Question 3
- Question: What are the most effective methods for detecting and mitigating academic integrity violations related to the use of GAI in educational settings?
- Basis in paper: [explicit] The authors acknowledge concerns about academic integrity and propose the development of a misuse detection system to monitor inappropriate or unproductive interactions with GAI.
- Why unresolved: The paper outlines the need for such a system but does not provide specific methods for detecting misuse or evaluating their effectiveness in preventing academic integrity violations.
- What evidence would resolve it: Development and evaluation of detection algorithms, assessment of their accuracy in identifying misuse, and studies on the impact of such systems on student behavior and academic integrity outcomes.

## Limitations
- Dataset collected at single university, limiting generalizability across cultural contexts
- Subjective satisfaction ratings and intent annotations may have inter-rater variability
- Analysis focuses on quantitative patterns without systematic validation of anthropomorphism claims

## Confidence

- **High Confidence**: Technical baseline results (84.08% accuracy, 0.4649 MAE) are reproducible with specified models and metrics
- **Medium Confidence**: Claims about student anthropomorphism are supported by observations but lack systematic validation
- **Low Confidence**: Future application predictions remain speculative without empirical validation

## Next Checks
1. Cross-Institutional Validation: Replicate data collection at 2-3 additional universities to assess generalizability
2. Inter-Rater Reliability Analysis: Conduct formal agreement study with 3-5 raters annotating intent and satisfaction
3. Learning Outcome Correlation: Track essay quality improvements and correlate with satisfaction ratings and intent categories