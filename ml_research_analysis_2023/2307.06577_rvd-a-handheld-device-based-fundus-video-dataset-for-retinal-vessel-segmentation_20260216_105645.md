---
ver: rpa2
title: 'RVD: A Handheld Device-Based Fundus Video Dataset for Retinal Vessel Segmentation'
arxiv_id: '2307.06577'
source_url: https://arxiv.org/abs/2307.06577
tags:
- retinal
- vessel
- segmentation
- dataset
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RVD, the first video-based retinal vessel
  dataset captured using handheld smartphone devices, addressing the limitations of
  existing static image datasets. RVD comprises 635 videos from 415 patients aged
  50-75, collected across four clinics.
---

# RVD: A Handheld Device-Based Fundus Video Dataset for Retinal Vessel Segmentation

## Quick Facts
- **arXiv ID**: 2307.06577
- **Source URL**: https://arxiv.org/abs/2307.06577
- **Reference count**: 40
- **Primary result**: Introduces first video-based retinal vessel dataset captured with handheld smartphone devices, showing SOTA methods struggle with ~70% mIoU for binary segmentation and significant domain gap to benchtop datasets.

## Executive Summary
This paper introduces RVD, the first video-based retinal vessel dataset captured using handheld smartphone devices, addressing the limitations of existing static image datasets. RVD comprises 635 videos from 415 patients aged 50-75, collected across four clinics. The dataset provides three levels of spatial annotations (binary vessel masks, general artery-vein masks, and fine-grained artery-vein masks) and temporal annotations for spontaneous retinal venous pulsations (SVP). The authors evaluate SOTA segmentation methods on RVD, finding that even advanced models struggle with the dataset's challenges, achieving only ~70% mIoU for binary segmentation and ~25% for fine-grained segmentation. The domain gap between RVD and existing benchtop-based datasets is significant, with performance dropping notably when models trained on RVD are tested on other datasets. The dataset offers rich annotations and data scales, potentially advancing retinal analysis and disease diagnosis.

## Method Summary
The RVD dataset was collected using handheld smartphone-based fundus cameras across four clinics, capturing 635 videos from 415 patients aged 50-75. Videos were preprocessed to stabilize the optic disc region and remove blurry frames. Three levels of spatial annotations were created: binary vessel masks, general artery-vein masks, and fine-grained artery-vein masks based on vessel width measurements. Temporal annotations were added for spontaneous retinal venous pulsations. The dataset was split into training (517 videos) and testing (118 videos) sets with no patient overlap. State-of-the-art segmentation methods including DeepLabV3, Mask2Former with ResNet and Swin Transformer backbones were evaluated, along with temporal models (LRCN, I3D, X3D, TSN, VTN) for SVP tasks.

## Key Results
- Binary vessel segmentation achieves ~70% mIoU, with significant performance drops when tested on benchtop datasets
- Fine-grained artery-vein segmentation performs poorly at ~25% mIoU, indicating substantial annotation complexity
- SOTA temporal models struggle with SVP detection and localization tasks, with Accuracy and AUROC below 0.7
- Domain gap between RVD and benchtop datasets is significant, with performance drops of 15-20% mIoU

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The dataset's video modality captures dynamic retinal vessel pulsation that static images cannot, enabling SVP detection.
- Mechanism: Video sequences allow frame-by-frame observation of vessel dilation/contraction cycles, revealing hemodynamic changes invisible in single images.
- Core assumption: Retinal vessel pulsations are periodic and visible across consecutive frames.
- Evidence anchors:
  - [abstract] "The static images naturally lose the dynamic characteristics of retina fluctuation" and "Our integration of temporal annotations thus increases its potential for ocular disease diagnosis."
  - [section 1] "The sequential frames capture the continuous changes in retinal vessels and thus significantly facilitate the analysis of subtle fluctuations in the retinal structure."
  - [corpus] Weak - corpus focuses on segmentation but not specifically on video-based pulsation analysis.
- Break condition: If pulsations occur faster than frame rate or are obscured by motion artifacts.

### Mechanism 2
- Claim: Multi-level spatial annotations (binary, general A/V, fine-grained A/V) provide hierarchical supervision matching clinical needs.
- Mechanism: Different annotation granularities allow models to learn progressively more complex vessel discrimination, from overall structure to artery-vein differentiation to width-based classification.
- Core assumption: Vessel width and morphology contain clinically relevant information that can be reliably annotated.
- Evidence anchors:
  - [abstract] "The dataset provides three levels of spatial annotations: binary vessel masks for overall retinal structure delineation, general vein-artery masks for distinguishing the vein and artery, and fine-grained vein-artery masks for further characterizing the granularities of each artery and vein."
  - [section 3.3.1] Details on how fine-grained masks are created using vessel diameter measurements.
  - [corpus] Weak - corpus papers focus on binary segmentation, not multi-level annotations.
- Break condition: If manual annotation quality varies significantly across annotators or clinical tasks don't benefit from fine-grained detail.

### Mechanism 3
- Claim: Handheld device data collection increases dataset diversity and accessibility compared to bench-top devices.
- Mechanism: Portable devices enable data collection in varied clinical settings with different operators, lighting conditions, and patient populations, creating a more representative dataset.
- Core assumption: Real-world variability improves model generalization compared to controlled bench-top imaging.
- Evidence anchors:
  - [abstract] "The usage of bench-top devices further restricts dataset scalability due to its limited accessibility" and "our dataset is constructed with portable handheld devices and is video-based."
  - [section 1] "In recent years, advances in imaging technology have enabled the usage of smartphone-based devices for retinal observation [79, 32]. They offer better flexibility and portability, allowing for scalable data collection."
  - [corpus] Weak - corpus neighbors focus on segmentation methods, not device-based data collection advantages.
- Break condition: If increased variability introduces too much noise or the domain gap between handheld and bench-top data is too large for practical model transfer.

## Foundational Learning

- Concept: Domain adaptation and generalization
  - Why needed here: The paper explicitly discusses domain gaps between handheld and bench-top datasets, showing performance drops when models are transferred.
  - Quick check question: What are two techniques to reduce domain gap when training on RVD but testing on bench-top datasets?

- Concept: Multi-class semantic segmentation evaluation
  - Why needed here: The dataset provides three levels of segmentation tasks requiring different evaluation metrics (mIoU, mAcc, mFscore for binary, general A/V, and fine-grained A/V).
  - Quick check question: How does mFscore differ from mIoU in evaluating multi-class segmentation performance?

- Concept: Video-based temporal analysis for medical diagnosis
  - Why needed here: The dataset includes SVP detection and localization tasks that require understanding temporal patterns in medical videos.
  - Quick check question: What metric would you use to evaluate both the classification of SVP presence and the temporal localization accuracy?

## Architecture Onboarding

- Component map: Data collection -> preprocessing (ODR stabilization, blur removal) -> annotation interface -> model training (segmentation/localization) -> evaluation
- Critical path: Data cleaning -> template matching for ODR stabilization -> keyframe selection -> annotation generation -> model training
- Design tradeoffs: Video data provides dynamics but increases storage/computation; handheld devices increase accessibility but introduce more noise; multi-level annotations increase clinical utility but require more expert time
- Failure signatures: Poor performance on thin vessels indicates model limitations; high domain gap indicates need for adaptation; low SVP detection accuracy suggests temporal modeling issues
- First 3 experiments:
  1. Train binary segmentation model on RVD and evaluate on DRIVE to quantify domain gap
  2. Compare segmentation performance using only binary vs. including general A/V annotations as auxiliary tasks
  3. Test different temporal models (TSN vs. VTN) on SVP detection to establish baseline performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of vessel segmentation models trained on RVD generalize to benchtop device datasets, and what are the key factors limiting this generalization?
- Basis in paper: [explicit] The authors observe significant performance drops when models trained on RVD are tested on benchtop datasets, and they hypothesize this is due to domain gaps in image characteristics.
- Why unresolved: The paper demonstrates the domain gap but does not systematically analyze which specific factors (e.g., resolution, noise characteristics, field of view) are most critical for performance degradation.
- What evidence would resolve it: Controlled experiments ablating specific RVD characteristics (e.g., using super-resolution, noise injection/removal, field of view adjustment) to quantify their impact on cross-domain performance.

### Open Question 2
- Question: What is the clinical utility of the temporal SVP annotations in RVD, and how can they be leveraged for disease diagnosis?
- Basis in paper: [explicit] The authors provide temporal annotations of SVP but only demonstrate that existing methods struggle to recognize and localize SVP, without exploring their clinical significance.
- Why unresolved: While the annotations are clinically relevant, the paper does not validate their utility for diagnosing specific ocular diseases or quantify their diagnostic value.
- What evidence would resolve it: Clinical studies correlating SVP patterns in RVD with disease diagnoses, and development of models that successfully use SVP annotations for disease detection.

### Open Question 3
- Question: How can the fine-grained vessel segmentation annotations in RVD be utilized to improve understanding of retinal vasculature and disease progression?
- Basis in paper: [explicit] The authors introduce fine-grained vessel width annotations but do not explore their potential applications beyond segmentation evaluation.
- Why unresolved: The paper establishes the annotation framework but does not demonstrate how this granularity can be used for clinical analysis or disease monitoring.
- What evidence would resolve it: Studies showing correlations between fine-grained vessel width patterns and specific diseases, and development of models that use this information for clinical decision support.

## Limitations
- Performance of SOTA methods remains suboptimal on RVD, particularly for fine-grained artery-vein segmentation and SVP tasks
- Significant domain gap exists between handheld device data and benchtop datasets, limiting cross-dataset generalization
- Limited ablation studies on the necessity of video data versus high-quality static images for segmentation tasks

## Confidence
- Claim about video-based dynamic analysis advantages: Medium confidence
- Claim about handheld device advantages for dataset diversity: Medium confidence
- Claim about multi-level annotations providing hierarchical supervision: High confidence

## Next Checks
1. Evaluate cross-dataset performance by training models on RVD and testing on DRIVE/STARE to quantify the practical impact of the domain gap.
2. Conduct ablation studies comparing video-based segmentation with carefully curated keyframe approaches to assess the value of temporal information.
3. Perform inter-annotator agreement studies on the fine-grained artery-vein annotations to establish reliability of the most complex annotation level.