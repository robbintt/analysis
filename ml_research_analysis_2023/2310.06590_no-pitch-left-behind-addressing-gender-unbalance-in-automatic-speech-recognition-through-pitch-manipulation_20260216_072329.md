---
ver: rpa2
title: 'No Pitch Left Behind: Addressing Gender Unbalance in Automatic Speech Recognition
  through Pitch Manipulation'
arxiv_id: '2310.06590'
source_url: https://arxiv.org/abs/2310.06590
tags:
- data
- gender
- speech
- male
- female
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses gender bias in automatic speech recognition
  (ASR) systems, where female speakers are under-represented in training data, leading
  to lower recognition accuracy for their voices compared to male speakers. The authors
  propose a data augmentation technique that manipulates the fundamental frequency
  (f0) and formants of audio segments to simulate voices of under-represented female
  speakers and increase variability within each gender group.
---

# No Pitch Left Behind: Addressing Gender Unbalance in Automatic Speech Recognition through Pitch Manipulation

## Quick Facts
- arXiv ID: 2310.06590
- Source URL: https://arxiv.org/abs/2310.06590
- Reference count: 0
- One-line primary result: Data augmentation via f0 and formant manipulation yields up to 9.87% relative WER improvement for female speakers in ASR.

## Executive Summary
This paper addresses gender bias in automatic speech recognition (ASR) systems, where female speakers are under-represented in training data, leading to lower recognition accuracy compared to male speakers. The authors propose a data augmentation technique that manipulates the fundamental frequency (f0) and formants of audio segments to simulate voices of under-represented female speakers and increase variability within each gender group. Experiments on spontaneous English speech using the MuST-C corpus show that this technique yields a relative WER improvement up to 9.87% for utterances by female speakers, with larger gains for the least-represented f0 ranges. The method also slightly improves recognition for male speakers without degrading their performance, resulting in fairer and more robust ASR systems.

## Method Summary
The authors propose a data augmentation technique that manipulates the fundamental frequency (f0) and formants of audio segments to address gender imbalance in ASR training data. Two policies are introduced: "Opposite" (gender switching) and "Random" (intra-gender variability). The technique uses Praat for on-the-fly pitch and formant manipulation during training. Experiments are conducted on the MuST-C corpus (English-Spanish section, 504h of English audio) using a Conformer-Transformer architecture trained with SpecAugment and CTC loss. The approach aims to reduce data unbalance among genders by simulating under-represented female voices and increasing variability within each gender group.

## Key Results
- Data augmentation via f0 and formant manipulation yields a relative WER improvement up to 9.87% for utterances by female speakers.
- Larger gains are observed for the least-represented f0 ranges, demonstrating the technique's effectiveness in addressing under-representation.
- The method slightly improves recognition for male speakers without degrading their performance, leading to fairer and more robust ASR systems.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Manipulating f0 and formants increases variability within gender groups and balances female/male representation in training data.
- Mechanism: The data augmentation technique shifts pitch and formant characteristics of audio segments toward the opposite gender, simulating under-represented female voices and increasing intra-gender variability.
- Core assumption: Male and female voices are primarily distinguished by differences in vocal tract length and anatomy, which manifest in f0 and formant frequencies.
- Evidence anchors:
  - [abstract] "This technique reduces the data unbalance among genders by simulating voices of the under-represented female speakers and increases the variability within each gender group."
  - [section 3.1] "Our approach is based on the manipulation of the fundamental frequency (f0) and the formants of a speech segment, which are critical acoustic parameters distinguishing male and female speech."
- Break condition: If the manipulated f0 and formant ranges do not adequately cover the acoustic space of the target gender, or if the perturbations introduce unnatural artifacts that degrade recognition.

### Mechanism 2
- Claim: Shifting voices from one gender to the other during training helps balance the gender distribution and improves recognition accuracy for the under-represented group.
- Mechanism: The "Opposite" policy manipulates audio samples from one gender to sound like the opposite gender, increasing the proportion of female-like voices in the training data.
- Core assumption: ASR models are biased towards more frequent patterns in training data, and under-representation of female voices leads to lower recognition accuracy for female speakers.
- Evidence anchors:
  - [abstract] "This can result in disparities in recognition accuracy between male and female speakers, primarily due to the under-representation of the latter group in the training data."
  - [section 3.1] "Specifically, we control the female/male data ratio by means of two probabilities, pf→m and pm→f, which respectively determine the probability of manipulating a segment uttered by a female voice (toward a male voice) and the probability of manipulating a segment uttered by a male voice (toward a female voice)."
- Break condition: If the gender switching does not effectively simulate the target gender's acoustic characteristics, or if the model overfits to the augmented data and fails to generalize to real female voices.

### Mechanism 3
- Claim: Increasing variability within each gender group helps the ASR model generalize better and improves recognition accuracy for both genders.
- Mechanism: The "Random" policy introduces pitch perturbations within the same gender group, increasing the diversity of training examples and helping the model handle a wider range of voice variations.
- Core assumption: ASR models benefit from increased training data variability, which helps them generalize to unseen voices and acoustic conditions.
- Evidence anchors:
  - [abstract] "Experiments on spontaneous English speech show that our technique yields a relative WER improvement up to 9.87% for utterances by female speakers, with larger gains for the least-represented f0 ranges."
  - [section 3.1] "In the second case, where manipulation takes place within the same gender group, we only shift the f0 within each gender-specific frequency range without altering the formants, as preserving the formant characteristics contributes to maintaining the distinct vocal traits of each gender."
- Break condition: If the intra-gender perturbations do not sufficiently increase variability, or if the model fails to learn the gender-specific characteristics due to excessive augmentation.

## Foundational Learning

- Concept: Automatic Speech Recognition (ASR) systems and their sensitivity to sociolinguistic variability.
  - Why needed here: Understanding how ASR systems work and their susceptibility to gender bias is crucial for addressing the problem at hand.
  - Quick check question: What are the main components of an ASR system, and how do they process and recognize speech?

- Concept: Acoustic parameters distinguishing male and female voices, particularly f0 and formants.
  - Why needed here: The proposed data augmentation technique relies on manipulating these acoustic parameters to simulate under-represented female voices and increase variability within gender groups.
  - Quick check question: How do f0 and formant frequencies differ between male and female voices, and why are they important for speech recognition?

- Concept: Data augmentation techniques in machine learning and their role in improving model generalization.
  - Why needed here: The proposed approach uses data augmentation to address the under-representation of female voices in training data and improve the ASR model's robustness to gender-related variations.
  - Quick check question: What are the main goals of data augmentation, and how can it help improve the performance of machine learning models?

## Architecture Onboarding

- Component map: Raw audio -> Log-compressed mel-filterbanks (80 channels) -> Augmentation (pitch/formant manipulation) -> 2 Conv layers -> 12 Conformer encoder layers -> 6 Transformer decoder layers -> Transcriptions

- Critical path:
  1. Load and preprocess audio data
  2. Apply data augmentation (pitch and formant manipulation)
  3. Extract mel-filterbank features
  4. Pass features through the ASR model
  5. Generate transcriptions and compute WER

- Design tradeoffs:
  - Balancing the need for gender balance in training data with the risk of overfitting to augmented examples
  - Choosing appropriate f0 and formant ranges for gender switching to avoid unnatural artifacts
  - Determining the optimal probability of applying augmentation to achieve the desired level of variability and gender balance

- Failure signatures:
  - Degraded recognition accuracy for both genders, indicating over-augmentation or unnatural perturbations
  - Limited improvement in recognition accuracy for female voices, suggesting insufficient gender switching or intra-gender variability
  - Increased model complexity and training time due to the additional data augmentation step

- First 3 experiments:
  1. Implement and test the "Opposite" policy with different probability combinations for gender switching, evaluating the impact on WER for both genders.
  2. Implement and test the "Random" policy with different augmentation probabilities, comparing the results to the "Opposite" policy and assessing the trade-off between gender balance and intra-gender variability.
  3. Perform an ablation study to isolate the effects of f0 and formant manipulation, determining the relative importance of each component in improving recognition accuracy for female voices.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the data augmentation technique perform equally well across different languages and accents beyond English-Spanish in MuST-C?
- Basis in paper: [inferred] The paper only tests the technique on the English-Spanish section of MuST-C and notes that the male/female performance difference may be due to accent variability. It does not test other language pairs or accents.
- Why unresolved: The authors only evaluate on one language pair (English-Spanish) and note that accent variability affects performance. They do not provide evidence for generalization to other languages or accents.
- What evidence would resolve it: Testing the technique on multiple language pairs from MuST-C (e.g., English-German, English-French) and on accented speech corpora to compare relative improvements across different languages and accents.

### Open Question 2
- Question: How does the proposed method compare to existing gender bias mitigation techniques like gender-dependent models or speaker normalization in end-to-end ASR systems?
- Basis in paper: [explicit] The paper mentions these approaches in related works but does not compare their proposed data augmentation technique against them, stating "the gender bias issue has not been explicitly addressed in end-to-end neural architectures."
- Why unresolved: The authors propose their method as filling a gap but do not benchmark against traditional gender-specific approaches like gender-dependent models or speaker normalization techniques that have been used in hybrid ASR systems.
- What evidence would resolve it: Direct comparison experiments between the proposed data augmentation method and traditional gender-specific approaches (gender-dependent models, speaker normalization) on the same datasets and evaluation metrics.

### Open Question 3
- Question: What is the optimal balance between f0 shifting and formant shifting for different degrees of gender imbalance in training data?
- Basis in paper: [inferred] The ablation study shows both components are important, but the paper only tests one configuration of the Random policy with fixed probabilities. It does not explore how the balance between f0 and formant manipulation affects performance under different levels of gender imbalance.
- Why unresolved: The paper uses a fixed configuration for the Random policy and shows both f0 and formant shifting contribute to improvements, but does not investigate whether different ratios of these perturbations would be optimal for different degrees of gender imbalance.
- What evidence would resolve it: Systematic experiments varying the relative contribution of f0 vs formant manipulation across datasets with different gender imbalance ratios, measuring the optimal balance for each scenario.

## Limitations
- The effectiveness of the proposed method is only demonstrated on the MuST-C corpus (English-Spanish section) and requires validation on other languages and accents.
- The paper does not compare the data augmentation approach against existing gender bias mitigation techniques, such as gender-dependent models or speaker normalization.
- The optimal balance between f0 and formant manipulation for different degrees of gender imbalance in training data is not explored.

## Confidence
- High: The observation that female speakers are under-represented in training data and experience lower recognition accuracy is well-established and directly measured in this work.
- Medium: The effectiveness of f0 and formant manipulation as a bias mitigation technique is demonstrated on the MuST-C corpus but requires broader validation.
- Low: The long-term generalization of these improvements across different ASR architectures, languages, and real-world deployment scenarios remains untested.

## Next Checks
1. Test the augmentation policies on additional ASR architectures (e.g., hybrid TDNN-HMM systems) to verify the robustness of the approach across different model families.
2. Evaluate the method on spontaneous speech corpora with different acoustic properties and gender distributions to assess generalizability.
3. Conduct a perceptual study to ensure that the f0 and formant manipulations do not introduce artifacts that could affect downstream applications or user experience.