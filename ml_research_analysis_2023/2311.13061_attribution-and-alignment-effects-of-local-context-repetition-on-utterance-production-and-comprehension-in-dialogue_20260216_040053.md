---
ver: rpa2
title: 'Attribution and Alignment: Effects of Local Context Repetition on Utterance
  Production and Comprehension in Dialogue'
arxiv_id: '2311.13061'
source_url: https://arxiv.org/abs/2311.13061
tags:
- dialogue
- repetition
- language
- human
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether language models produce human-like
  levels of repetition in dialogue and the processing mechanisms they use during comprehension.
  Using two spoken dialogue corpora and three autoregressive language models, the
  authors analyze both model production (repetition of shared constructions in generated
  utterances) and comprehension (attribution of salience to context during processing).
---

# Attribution and Alignment: Effects of Local Context Repetition on Utterance Production and Comprehension in Dialogue

## Quick Facts
- **arXiv ID**: 2311.13061
- **Source URL**: https://arxiv.org/abs/2311.13061
- **Reference count**: 36
- **Key outcome**: Fine-tuned language models generate more human-like patterns of construction repetition in dialogue, with comprehension showing sensitivity to speaker shifts and local context.

## Executive Summary
This study investigates whether language models produce human-like levels of repetition in dialogue and the processing mechanisms they use during comprehension. Using two spoken dialogue corpora and three autoregressive language models, the authors analyze both model production (repetition of shared constructions in generated utterances) and comprehension (attribution of salience to context during processing). Fine-tuned models generate more human-like patterns of construction repetition, with effects strongest in open-domain dialogue. Model comprehension shows sensitivity to speaker shifts and local context, particularly in tuned models. Reference-based metrics correlate with repetition human-likeness, but corpus-level metrics like MAUVE do not capture these local dialogue phenomena effectively.

## Method Summary
The study uses two spoken dialogue corpora (Map Task and Switchboard) and three autoregressive language models (DialoGPT, GPT-2, OPT) in both pre-trained and fine-tuned versions. Models are fine-tuned for 20 epochs with early stopping on each corpus. Construction extraction identifies shared sequences between dialogue partners using dialign. For production analysis, 10-utterance samples are extracted using sliding windows, and models generate 5 target utterances per context sample. Construction Overlap (CO), Vocabulary Overlap (VO), and locality decay are measured. For comprehension analysis, DeepLift attribution methods measure salience to context utterances during target utterance processing.

## Key Results
- Fine-tuned models generate more human-like patterns of construction repetition compared to pre-trained models, with strongest effects in open-domain dialogue
- Model comprehension shows sensitivity to speaker shifts and local context, particularly in fine-tuned models
- Reference-based generation quality metrics (BLEU, BERTScore) correlate with human-likeness of repetition, while corpus-level metrics like MAUVE do not capture these local dialogue phenomena

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning autoregressive language models on dialogue data leads to more human-like levels of construction repetition in generated utterances.
- Mechanism: Fine-tuning exposes models to the statistical patterns of local repetition found in human dialogue, enabling them to generate utterances that exhibit similar repetition decay with distance and speaker-specific effects.
- Core assumption: The fine-tuning data contains sufficient examples of local repetition patterns for the model to learn these statistical regularities.
- Evidence anchors:
  - [abstract] "Fine-tuned models generate more human-like patterns of construction repetition, with effects strongest in open-domain dialogue."
  - [section 4.2.1] "Models learn some patterns of local repetition. We find that fine-tuned models learn turn-sensitive patterns of local repetition to some extent."
  - [corpus] Switchboard and Map Task corpora contain attested local repetition patterns (section 3.1).
- Break condition: If the fine-tuning data lacks sufficient diversity or examples of local repetition, the model will not learn these patterns.

### Mechanism 2
- Claim: Language models exhibit sensitivity to speaker shifts and local context during comprehension, as measured by feature attribution methods.
- Mechanism: Models learn to attribute salience to speaker labels and nearby context utterances when processing target utterances, reflecting an understanding of turn-taking dynamics and local priming effects.
- Core assumption: The model's attention and attribution mechanisms can capture the influence of speaker identity and utterance proximity on comprehension.
- Evidence anchors:
  - [abstract] "Model comprehension shows sensitivity to speaker shifts and local context, particularly in tuned models."
  - [section 5.2.1] "We expect models to learn patterns of turn-taking from the structure and contents of the context utterances... We expect that higher salience will be assigned to repetitions with local antecedents."
  - [corpus] Speaker-labeled utterances in both corpora allow for analysis of speaker-specific effects.
- Break condition: If the model's attribution method is not sensitive to speaker labels or utterance distance, these effects will not be observable.

### Mechanism 3
- Claim: Reference-based generation quality metrics correlate with human-likeness of repetition, while corpus-level metrics like MAUVE do not capture local dialogue phenomena effectively.
- Mechanism: Metrics like BLEU and BERTScore measure local n-gram overlap and semantic similarity, which align with the human-likeness of construction repetition. MAUVE, being a corpus-level metric, averages over the entire distribution and misses local, context-dependent effects.
- Core assumption: Local repetition patterns are a key component of human-like dialogue quality, and this is captured by reference-based metrics but not by corpus-level distributional comparisons.
- Evidence anchors:
  - [abstract] "Reference-based metrics correlate with repetition human-likeness, but corpus-level metrics like MAUVE do not capture these local dialogue phenomena effectively."
  - [section 4.2.2] "We find that the closer the levels of CO and VO are to human-produced language, the higher BertF1, BLEU, and the lower the evaluation model perplexity... This tells us either that better corpus-level metrics need to be defined or, perhaps, that corpus-level evaluation is not really appropriate for dialogue where quality is determined by local and highly contextually dependent cues."
  - [corpus] Both corpora contain local repetition patterns that are not captured by MAUVE.
- Break condition: If local repetition is not a significant factor in human-likeness, or if corpus-level metrics are refined to capture local effects, this mechanism would break down.

## Foundational Learning

- Concept: Construction extraction and analysis
  - Why needed here: The study relies on identifying and measuring shared constructions between dialogue partners to quantify local repetition patterns.
  - Quick check question: Can you explain the difference between vocabulary overlap and construction overlap, and why both are used in this study?

- Concept: Feature attribution methods for model interpretation
  - Why needed here: The study uses attribution techniques to understand which parts of the dialogue context are most salient to the model when processing a target utterance.
  - Quick check question: What is the key difference between using attention heatmaps and feature attribution methods for interpreting model behavior, and why are attribution methods preferred in this study?

- Concept: Linear mixed-effects models for analyzing repeated measures data
  - Why needed here: The study uses linear mixed-effects models to account for the nested structure of the data (utterances within dialogues within speakers) when analyzing repetition and attribution patterns.
  - Quick check question: Why are linear mixed-effects models more appropriate than standard linear regression for analyzing the repetition patterns in this study?

## Architecture Onboarding

- Component map: Corpus → Construction extraction → Model fine-tuning → Repetition analysis → Attribution analysis → Statistical comparison
- Critical path: Data preprocessing (corpus selection, sample extraction, construction extraction) → Model training (fine-tuning language models on dialogue data) → Analysis (measuring repetition patterns, computing attribution scores, statistical analysis) → Evaluation (comparing model behavior to human data, assessing correlation with quality metrics)
- Design tradeoffs: Balancing model size and computational cost with the need for sufficient capacity to learn local repetition patterns; choosing between different attribution methods and their interpretability.
- Failure signatures: If models do not exhibit human-like repetition patterns after fine-tuning, it could indicate insufficient training data, model capacity, or the need for alternative fine-tuning strategies; if attribution methods do not reveal sensitivity to local context, it could suggest limitations in the chosen method or the model's comprehension capabilities.
- First 3 experiments:
  1. Fine-tune a small language model on the Map Task corpus and compare its construction overlap patterns to the human data.
  2. Apply DeepLift attribution to a fine-tuned model and analyze the salience patterns over the dialogue context during target utterance comprehension.
  3. Compute the correlation between construction overlap and reference-based quality metrics (BLEU, BERTScore) for model generations on the Switchboard corpus.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do language models learn the decay of repetition effects with distance in local contexts, and why do some models fail to exhibit this pattern?
- Basis in paper: [explicit] The paper explicitly investigates the local repetition decay effect in both human dialogue and model-generated utterances, noting that models learn this pattern to some extent, but the degree varies by model.
- Why unresolved: The paper shows that fine-tuned models learn to generate more human-like patterns of construction re-use, including local repetition decay, but it doesn't fully explain the mechanisms behind this learning process or why some models fail to exhibit this pattern.
- What evidence would resolve it: Detailed analysis of model training processes, particularly focusing on how models learn to handle context distance and repetition patterns. Comparative studies of different model architectures and training regimes to identify factors that influence the learning of local repetition decay.

### Open Question 2
- Question: How do construction repetition and vocabulary overlap interact to influence model attribution patterns during dialogue comprehension?
- Basis in paper: [explicit] The paper investigates the relationship between construction overlap (CO), vocabulary overlap (VO), and model attribution patterns, finding mixed results across models and corpora.
- Why unresolved: The paper observes that high lexical repetition between context and target boosts priming effects in models, but the precise relationship between repetitions themselves and the local attribution patterns remains unclear.
- What evidence would resolve it: Experiments isolating the effects of CO and VO on model attribution, using controlled stimuli with varying levels of each type of overlap. Analysis of model attention patterns and feature attributions to understand how different types of overlap are processed.

### Open Question 3
- Question: Why do corpus-level evaluation metrics like MAUVE fail to capture local dialogue phenomena such as human-like repetition patterns, and what alternative evaluation methods could be developed?
- Basis in paper: [explicit] The paper explicitly finds that while reference-based generation quality metrics correlate with the human-likeness of repetitions produced, corpus-level metrics like MAUVE fail to capture this important aspect of dialogue quality.
- Why unresolved: The paper suggests that either better corpus-level metrics need to be defined or that corpus-level evaluation is not appropriate for dialogue where quality is determined by local and highly contextually dependent cues, but doesn't provide a definitive answer or alternative solution.
- What evidence would resolve it: Development and testing of new evaluation metrics that focus on local and context-dependent phenomena in dialogue. Comparative studies of different evaluation approaches using human judgments and their correlation with model performance on specific dialogue tasks.

## Limitations

- Data Generalization: The study relies on two specific spoken dialogue corpora (Map Task and Switchboard) which may not fully represent the diversity of human dialogue patterns.
- Attribution Method Limitations: While DeepLift provides insights into feature importance, it may not capture all aspects of model comprehension and could introduce biases based on its own training objectives.
- Model Architecture Constraints: The study uses autoregressive models which generate tokens sequentially, potentially limiting applicability to other model architectures.

## Confidence

- High Confidence: The core finding that fine-tuned models exhibit more human-like construction repetition patterns is well-supported by the empirical analysis across both corpora.
- Medium Confidence: The attribution analysis showing model sensitivity to speaker shifts and local context is compelling but relies on a single attribution method.
- Low Confidence: The claim that corpus-level metrics like MAUVE fail to capture local dialogue phenomena is based on correlational analysis but lacks a mechanistic explanation.

## Next Checks

1. Apply the same analysis pipeline to additional dialogue corpora (e.g., DailyDialog, EmpatheticDialogues) to assess whether the observed patterns of construction repetition and attribution sensitivity generalize beyond the Map Task and Switchboard datasets.

2. Replicate the attribution analysis using alternative methods (Integrated Gradients, LIME) to verify whether DeepLift-specific properties influence the observed patterns of speaker and context sensitivity.

3. Compare the repetition and attribution patterns across different generation strategies (temperature sampling, top-k, nucleus sampling) to determine whether the observed effects are consistent across decoding approaches or specific to ancestral sampling.