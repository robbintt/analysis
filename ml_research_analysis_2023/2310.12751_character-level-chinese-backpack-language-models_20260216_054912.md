---
ver: rpa2
title: Character-level Chinese Backpack Language Models
arxiv_id: '2310.12751'
source_url: https://arxiv.org/abs/2310.12751
tags:
- word
- sense
- language
- backpack
- chinese
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper applies the recently proposed Backpack language modeling
  architecture to character-level Chinese. This architecture is designed to improve
  model interpretability and controllability, with particular benefits for non-English
  languages.
---

# Character-level Chinese Backpack Language Models

## Quick Facts
- arXiv ID: 2310.12751
- Source URL: https://arxiv.org/abs/2310.12751
- Reference count: 17
- Primary result: Character-level Chinese Backpack models achieve comparable perplexity and cloze task performance to GPT2 models, with enhanced interpretability and controllability

## Executive Summary
This paper applies the Backpack language modeling architecture to character-level Chinese, demonstrating that it achieves performance comparable to GPT2 while offering improved interpretability and controllability. The authors pretrain two Chinese Backpack models (134M and 27M parameters) and compare them to similarly sized GPT2 models, finding comparable results on perplexity and Chinese cloze tasks. The Backpack architecture decomposes character meanings into sense vectors that log-additively compose to form word meanings, enabling better representation of compound words and idioms while allowing for targeted interventions like gender bias mitigation.

## Method Summary
The paper pretrains character-level Chinese Backpack models using data from wiki2019zh, news2016zh, and webtext2019zh corpora. Two model sizes are trained (134M and 27M parameters) and compared against GPT2 models of similar size (104M and 18M parameters). The Backpack architecture uses character-level tokenization with k sense vectors per character, where contextualization weights determine how sense vectors compose to form word meanings. Performance is evaluated using perplexity scores and Chinese cloze tasks (WCPC top-1 and top-3 accuracy), with additional analysis of sense vector contributions to word meaning stability and bias mitigation capabilities.

## Key Results
- Backpack-small outperforms GPT2-small on both perplexity and Chinese cloze tasks
- Backpack sense vectors better represent compound words, idioms, and loanwords compared to GPT2 embeddings
- Gender bias can be localized to specific character senses and mitigated through sense vector removal
- Character contribution ratios to word meanings remain stable across different contexts

## Why This Works (Mechanism)

### Mechanism 1: Log-additive composition of character meanings
The Backpack model achieves comparable performance by decomposing character-level meanings into sense vectors that log-additively compose word meanings. Each character's sense vectors contribute to word meaning through a weighted sum, where consistent per-character sense weights across contexts form stable multi-character word meanings. This works when characters in Chinese compound words maintain stable contribution ratios across different contexts.

### Mechanism 2: Localized gender bias mitigation
Character-level sense vectors can mitigate gender bias by identifying and removing specific biased sense vectors. Gender bias in composed words stems from specific character sense vectors that contribute disproportionately to gendered predictions. This assumes gender bias is localized to specific character sense vectors that can be identified through differential projections of male vs female pronouns.

### Mechanism 3: Semantic property control through sense amplification
Amplifying specific character sense vectors allows control over which semantic property of a compound word is emphasized during generation. By increasing the weight of a constituent character's sense vectors while maintaining the total word contribution, the model generates text biased toward that character's semantic property. This assumes the model can be steered toward specific semantic properties by adjusting sense vector weights without breaking the overall word prediction.

## Foundational Learning

- Character-based tokenization vs word-based tokenization: Understanding why Chinese Backpack uses characters instead of words is crucial for grasping the model's approach to handling compound words. Quick check: Why would character-level tokenization be more appropriate for Chinese than word-level tokenization?

- Log-additive composition of meanings: The Backpack model relies on log-additive combination of character sense vectors to form word meanings. Quick check: How does log-additive composition differ from simple averaging of character embeddings?

- Gender bias in language models: The paper demonstrates bias mitigation through character-level interventions. Quick check: Why might gender bias manifest differently in character-based models compared to word-based models?

## Architecture Onboarding

- Component map: Character tokenizer -> Sense vector layer -> Transformer contextualization layer -> Weighted sum composition layer -> Prediction layer

- Critical path: Input characters → sense vectors (FFN transformation) → Context → attention weights (Transformer) → Weighted sum of sense vectors using attention weights → Vocabulary projection for prediction

- Design tradeoffs: More parameters for sense vectors (k × d²) vs improved interpretability; Character-level granularity vs potential loss of word-level semantic coherence; Simplified composition vs potential need for larger k to capture complex meanings

- Failure signatures: High variance in character contribution ratios across contexts; Inability to compose complex multi-character meanings; Unstable training due to lack of layer normalization in weighted sum

- First 3 experiments: Compare perplexity of Backpack vs GPT2 on Chinese test set; Visualize top vocabulary projections for each character sense vector; Test stability of character contribution ratios across different contexts for compound words

## Open Questions the Paper Calls Out

### Open Question 1
How do the sense vectors in character-level Chinese Backpack language models compare to those in word-level English Backpack models in terms of their ability to capture semantic relationships and compositional meanings? While the paper shows that character-level Chinese Backpack models can capture semantic relationships and compositional meanings, it does not provide a direct comparison with word-level English Backpack models.

### Open Question 2
What are the limitations of using character-level Backpack language models for languages with complex morphological structures, such as Korean, where many words are transliterated? The paper mentions that character-level Backpack models have limitations in handling transliterated words, but does not provide a detailed analysis for languages with complex morphological structures.

### Open Question 3
How does the stability of word compositions in character-level Chinese Backpack models compare to that in word-level English Backpack models, and what factors contribute to the stability differences? While the paper provides some insights into the stability of word compositions in character-level Chinese Backpack models, it does not provide a comprehensive comparison with word-level English Backpack models or identify contributing factors.

## Limitations
- Lack of statistical significance testing for performance comparisons between Backpack and GPT2 models
- Limited evaluation to a single Chinese benchmark dataset without validation on additional language understanding tasks
- Insufficient ablation studies showing the impact of gender bias mitigation on overall model performance

## Confidence

**High Confidence:** Comparable perplexity scores to GPT2 models on Chinese text - clearly defined experimental setup with directly measurable and reproducible results.

**Medium Confidence:** Better representation of compound words through sense vectors - thorough analysis of sense vector contributions, though evaluation metric is somewhat abstract and lacks direct comparison to word-level methods.

**Low Confidence:** Effective gender bias localization and mitigation - experimental evidence shows bias reduction but doesn't demonstrate impact on other performance aspects or whether bias might reappear in different contexts.

## Next Checks

1. **Ablation Study on Gender Bias Mitigation:** Conduct comprehensive ablation study removing different combinations of sense vectors to quantify trade-off between gender bias reduction and overall model performance, measuring impact on both gender-specific cloze tasks and general language modeling.

2. **Cross-Context Stability Analysis:** Evaluate stability of character contribution ratios across diverse contexts by testing same compound words in different syntactic positions and semantic contexts, quantifying variance and determining thresholds where log-additive composition breaks down.

3. **Statistical Significance Testing:** Perform paired t-tests on perplexity and cloze task results comparing Backpack and GPT2 models, and evaluate models on at least two additional Chinese language understanding benchmarks to validate generalizability of findings.