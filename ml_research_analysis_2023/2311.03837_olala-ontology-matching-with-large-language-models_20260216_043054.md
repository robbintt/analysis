---
ver: rpa2
title: 'OLaLa: Ontology Matching with Large Language Models'
arxiv_id: '2311.03837'
source_url: https://arxiv.org/abs/2311.03837
tags:
- matching
- language
- ontology
- large
- concept
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces OLaLa, an ontology matching system that uses
  open-source large language models (LLMs) to identify correspondences between ontology
  entities. It formulates matching as a binary or multiple-choice classification task
  using LLM-based prompting with zero-shot and few-shot examples.
---

# OLaLa: Ontology Matching with Large Language Models

## Quick Facts
- arXiv ID: 2311.03837
- Source URL: https://arxiv.org/abs/2311.03837
- Reference count: 40
- Primary result: OLaLa achieves competitive F-measures (e.g., 0.902 on anatomy) on OAEI tracks using open-source LLMs with textual features only

## Executive Summary
OLaLa is an ontology matching system that leverages open-source large language models to identify correspondences between ontology entities using only textual descriptions. The system formulates matching as a binary or multiple-choice classification task, using LLM-based prompting with zero-shot and few-shot examples. Candidate generation is performed via Sentence-BERT semantic search to retrieve top-k similar entities. Evaluated on OAEI tracks, OLaLa achieves competitive F-measures and often ranks among top three systems, despite using only textual features and minimal supervision.

## Method Summary
OLaLa extracts textual descriptions from ontology entities, generates candidate correspondences using Sentence-BERT semantic search, and classifies pairs using open-source LLMs with few-shot prompting. The system filters results by confidence thresholds and enforces cardinality constraints. It uses binary or multiple-choice classification tasks, with the LLM outputting yes/no or letter-based answers. The approach requires no fine-tuning of LLMs, relying instead on well-designed prompts and a small number of examples.

## Key Results
- Achieved 0.902 F-measure on anatomy track, ranking 2nd
- Competitive performance on biodiv, commonKG, and knowledge graph tracks
- Successfully uses only textual features without formal logical axioms
- Demonstrates effectiveness of few-shot prompting with open-source LLMs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can interpret natural language descriptions of ontology entities to judge equivalence without formal logical axioms.
- Mechanism: Transformer-based LLMs trained on large text corpora learn semantic embeddings that capture the meaning of entity labels and descriptions. When given two such descriptions in a prompt, the LLM can reason about their similarity using its internal representations of natural language semantics.
- Core assumption: The textual descriptions of ontology entities are sufficient to determine equivalence, and the LLM's training data includes enough semantic knowledge to make accurate judgments.
- Evidence anchors:
  - [abstract]: "it is possible to incorporate this knowledge in a better way into the matching pipeline" and "achieve results that are en par with supervised matching systems"
  - [section]: "computers are also able to process and interpret textual descriptions" and "achieve results that are en par with supervised matching systems using a much larger portion of the ground truth"
  - [corpus]: Weak - related work shows similar LLM-based approaches but no direct comparison of textual-only vs. formal axioms in the same system
- Break condition: If ontology entities lack descriptive text or use highly technical domain-specific language not well-represented in the LLM's training data.

### Mechanism 2
- Claim: Few-shot prompting with examples enables the LLM to perform the binary classification task of matching vs. non-matching without fine-tuning.
- Mechanism: By providing a small number of positive and negative examples in the prompt, the LLM can infer the pattern of what constitutes a match and apply this pattern to new candidate pairs. The examples serve as implicit instruction for the classification task.
- Core assumption: The few examples provided are representative of the matching patterns in the target ontologies and the LLM can generalize from these examples to unseen pairs.
- Evidence anchors:
  - [abstract]: "with only a handful of examples and a well-designed prompt, it is possible to achieve results that are en par with supervised matching systems"
  - [section]: "few-shot prompting with multiple open Large Language Models" and the table showing different prompts with varying numbers of examples
  - [corpus]: Assumption: The corpus doesn't provide direct evidence about few-shot effectiveness but related work (KROMA) suggests retrieval-augmented approaches may enhance few-shot performance
- Break condition: If the provided examples are not representative of the actual matching task or if the ontology entities are too dissimilar from the examples.

### Mechanism 3
- Claim: Semantic search using Sentence-BERT effectively generates candidate pairs that include true matches while keeping the candidate set manageable for LLM processing.
- Mechanism: Sentence-BERT creates dense vector representations of entity descriptions that capture semantic similarity beyond exact string matching. By retrieving top-k similar entities based on cosine similarity in this embedding space, the system can find potential matches including those with no lexical overlap.
- Core assumption: The Sentence-BERT model used for candidate generation is well-suited to the domain of the ontologies and can capture the relevant semantic similarities between entity descriptions.
- Evidence anchors:
  - [section]: "SBERT as well as all LLMs only process text, but the input is an ontology. Thus it is necessary to verbalize the concepts into some natural language text" and "It computes the cosine similarity between a list of query embeddings and a list of corpus embeddings and returns the top-k neighbors for each text"
  - [corpus]: Weak - The corpus doesn't evaluate the quality of Sentence-BERT candidate generation specifically, though related work mentions embedding-based retrieval
- Break condition: If the semantic search fails to retrieve true matches (low recall) or retrieves too many irrelevant candidates (low precision), overwhelming the LLM processing capacity.

## Foundational Learning

- Concept: Semantic search and embedding similarity
  - Why needed here: Understanding how Sentence-BERT generates candidate pairs through vector similarity is crucial for tuning the k parameter and interpreting recall/precision tradeoffs
  - Quick check question: What happens to the candidate generation recall if we increase k from 5 to 10, and why?

- Concept: Prompt engineering and few-shot learning
  - Why needed here: Designing effective prompts with the right number and type of examples is key to achieving good classification performance without fine-tuning
  - Quick check question: How would you modify the prompt if you noticed the LLM was consistently misclassifying certain types of entity pairs?

- Concept: Confidence extraction from LLM outputs
  - Why needed here: Understanding how the system derives confidence scores from token probabilities is important for setting appropriate thresholds and interpreting results
  - Quick check question: Why does the system normalize the maximum probability of positive tokens by the maximum probability of negative tokens to get a confidence score?

## Architecture Onboarding

- Component map: Text Extractors -> Sentence-BERT Candidate Generator -> LLM Classifier -> Post-processing Filters
- Critical path: Text Extraction → Sentence-BERT Search → LLM Classification → Post-processing
- Design tradeoffs:
  - Candidate generation recall vs. LLM processing time (larger k increases recall but slows processing)
  - Prompt complexity vs. LLM performance (more examples may help but increase prompt length)
  - Confidence threshold vs. precision/recall balance (higher threshold increases precision but may reduce recall)
- Failure signatures:
  - Low recall: Sentence-BERT not finding true matches (try larger k or different model)
  - Low precision: LLM misclassifying candidates (try different prompts or examples)
  - Slow processing: Too many candidates or complex prompts (try smaller k or simpler prompts)
- First 3 experiments:
  1. Vary k in Sentence-BERT search (1, 3, 5, 10) and measure candidate generation recall and runtime
  2. Test different prompt templates (zero-shot, few-shot with 1-3 examples) and measure classification F1
  3. Adjust confidence threshold (0.5, 0.6, 0.7) and measure precision-recall tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the runtime of OLaLa be significantly reduced without sacrificing F-measure, particularly for large-scale knowledge graphs?
- Basis in paper: [inferred] The paper notes that LLM-based systems like OLaLa often have much higher runtimes compared to other models, especially in the Biodiv track where runtime is several hours versus under a minute for other systems.
- Why unresolved: The paper mentions runtime as a challenge but does not provide concrete solutions for optimizing it beyond noting that SBERT and LLM models are computationally expensive.
- What evidence would resolve it: Experimental results showing OLaLa achieving comparable F-measures to state-of-the-art systems with significantly reduced runtime through architectural changes, model optimization, or selective application of LLMs.

### Open Question 2
- Question: What is the optimal prompt engineering strategy for different ontology matching tasks, and how does prompt structure affect model performance across various domains?
- Basis in paper: [explicit] The paper extensively evaluates different prompts (zero-shot vs few-shot, binary vs multiple choice) and notes that "model and parameter combinations can have a strong impact on the overall results" and that "there is likely no one-parameterization-fits-all solution."
- Why unresolved: While the paper tests several prompt variations, it does not provide a systematic framework for determining optimal prompts for specific task types or domains.
- What evidence would resolve it: A comprehensive study mapping prompt structures to performance outcomes across multiple ontology matching tasks, with clear guidelines for prompt selection based on task characteristics.

### Open Question 3
- Question: How can OLaLa be extended to effectively handle instance matching in large knowledge graphs, and what architectural modifications would enable scalability?
- Basis in paper: [explicit] The paper states that "the system should be more scalable such that it can also be applied to large KGs with instance matching (which is technically possible, but with large runtimes)."
- Why unresolved: The paper acknowledges the scalability challenge but only suggests potential directions like using fast high-precision matchers first, without implementing or testing these approaches.
- What evidence would resolve it: Implementation and evaluation of scalable OLaLa variants that successfully perform instance matching on large KGs, demonstrating practical runtime improvements while maintaining accuracy.

## Limitations

- The system relies entirely on the quality and availability of natural language descriptions in ontologies
- Performance on ontologies with sparse or highly technical descriptions is uncertain
- The study does not compare against systems that use structural or semantic features
- Evaluation focuses on specific OAEI tracks where textual descriptions are presumably sufficient

## Confidence

**High Confidence**: The claim that OLaLa achieves competitive F-measures on OAEI tracks is well-supported by the presented results (e.g., 0.902 F-measure on anatomy, ranking 2nd). The methodology is clearly described and reproducible.

**Medium Confidence**: The assertion that few-shot prompting enables strong performance without fine-tuning is plausible given the results, but the specific examples used are not provided, making it difficult to assess the quality of the prompting strategy. The claim that textual features alone are sufficient for matching also lacks comparison with systems using formal axioms.

**Low Confidence**: The claim that OLaLa is "en par with supervised matching systems" is difficult to verify without direct comparison to supervised approaches on the same datasets. The paper does not provide such comparisons.

## Next Checks

1. **Ablation Study on Text Quality**: Evaluate OLaLa on ontologies with varying levels of descriptive text quality to determine the minimum text requirements for effective matching.

2. **Comparison with Formal Features**: Test whether incorporating formal axioms or structural features improves performance over the pure text-based approach.

3. **Robustness to Domain Shift**: Assess OLaLa's performance on ontologies from domains not represented in the training data or OAEI tracks to evaluate generalizability.