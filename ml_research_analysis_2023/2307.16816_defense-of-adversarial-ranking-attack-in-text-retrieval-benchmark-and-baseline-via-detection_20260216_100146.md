---
ver: rpa2
title: 'Defense of Adversarial Ranking Attack in Text Retrieval: Benchmark and Baseline
  via Detection'
arxiv_id: '2307.16816'
source_url: https://arxiv.org/abs/2307.16816
tags:
- adversarial
- documents
- detection
- ranking
- document
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper constructs a benchmark dataset to support the study
  of adversarial ranking defense in text retrieval, and introduces two types of detection
  tasks in the point-wise and list-wise perspective. Specifically, this dataset contains
  around 144K, 10K, 10K adversarial examples in its train, valid and test sets, respectively,
  which are generated by three novel attack methods, namely PRADA, PAT and IDEM.
---

# Defense of Adversarial Ranking Attack in Text Retrieval: Benchmark and Baseline via Detection

## Quick Facts
- arXiv ID: 2307.16816
- Source URL: https://arxiv.org/abs/2307.16816
- Reference count: 18
- This paper constructs a benchmark dataset to support the study of adversarial ranking defense in text retrieval, and introduces two types of detection tasks in the point-wise and list-wise perspective.

## Executive Summary
This paper addresses the challenge of defending against adversarial ranking attacks in text retrieval systems. It introduces a comprehensive benchmark dataset containing approximately 144K, 10K, and 10K adversarial examples in train, validation, and test sets respectively, generated by three novel attack methods (PRADA, PAT, IDEM). The study investigates two detection tasks - point-wise (overall accuracy) and list-wise (ranking quality preservation via MRR@10) - and evaluates multiple baseline detection methods including unsupervised approaches (spamicity, perplexity, linguistic acceptability) and supervised classifiers (BERT/RoBERTa). Experimental results reveal that while supervised classifiers can effectively mitigate known attacks, they perform poorly against unseen attacks, and that incorporating query text can lead to relevance-aware detection but may harm list-wise performance.

## Method Summary
The paper constructs a benchmark dataset using the MS MARCO passage dataset, generating adversarial documents through three attack methods: PRADA, PAT, and IDEM. For detection, it explores both unsupervised methods (OSD-based spamicity detection, PPL-based perplexity detection, and LA-based linguistic acceptability detection) and supervised classifiers (BERT and RoBERTa fine-tuned on original/adversarial document pairs). The detection framework is evaluated in two contexts: point-wise detection measuring overall accuracy, and list-wise detection measuring ranking quality preservation using MRR@10, number of discarded documents before a relevant one (#DD), and number of discarded relevant documents (#DR).

## Key Results
- Supervised classifiers (BERT/RoBERTa) achieve over 95% accuracy when trained and tested on the same attack type, but performance drops to near random guessing on unseen attack types
- LA-based detectors demonstrate greater reliability against unknown adversarial documents, achieving >70% accuracy on the combined attack set
- Incorporating query text improves point-wise detection accuracy but negatively impacts list-wise detection by increasing the likelihood of misclassifying relevant documents
- The benchmark dataset provides approximately 144K, 10K, and 10K adversarial examples in train, validation, and test sets respectively

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Supervised classifiers can achieve high detection accuracy when trained on known adversarial attack types
- Mechanism: The classifier learns to distinguish between original and adversarial documents by leveraging training data from all attack types (PRADA, PAT, IDEM)
- Core assumption: The classifier has seen enough examples of all known adversarial perturbations during training
- Evidence anchors:
  - Experimental results show 95%+ accuracy when training and testing on same attack types
  - Weak direct evidence in corpus about supervised classifier performance

### Mechanism 2
- Claim: LA-based detectors are more reliable when facing unknown adversarial attacks
- Mechanism: Adversarial documents often contain grammatical inconsistencies or lack context coherence, which can be detected by linguistic acceptability models
- Core assumption: Adversarial manipulations introduce detectable grammatical or coherence issues
- Evidence anchors:
  - LA-based detector achieves >70% accuracy on combined attack set
  - Adversarial documents exhibit grammatical inconsistencies or lack context coherence

### Mechanism 3
- Claim: Using query text in supervised classification improves point-wise detection but harms list-wise detection
- Mechanism: Including query text helps the classifier distinguish adversarial documents but also makes it more likely to misclassify relevant documents as adversarial
- Core assumption: The classifier trained with query text learns relevance features rather than purely adversarial features
- Evidence anchors:
  - Query text improves detection accuracy, especially with Train IDEM or Train ALL
  - Query text negatively impacts defense effectiveness in list-wise detection

## Foundational Learning

- Concept: Adversarial attack generation in text retrieval
  - Why needed here: Understanding how PRADA, PAT, and IDEM create adversarial documents is essential for developing effective detection methods
  - Quick check question: What are the three types of perturbations used by the attack methods mentioned in the paper?

- Concept: Supervised vs unsupervised detection methods
  - Why needed here: The paper compares these two approaches to understand their relative strengths and weaknesses
  - Quick check question: Which type of detector (supervised or unsupervised) performs better on known attack types?

- Concept: Point-wise vs list-wise detection tasks
  - Why needed here: Different detection tasks have different evaluation metrics and requirements
  - Quick check question: What is the main difference between point-wise and list-wise detection in terms of their evaluation metrics?

## Architecture Onboarding

- Component map: MS MARCO passage dataset → attack generation (PRADA, PAT, IDEM) → benchmark dataset creation → detection methods (OSD, PPL, LA, BERT, RoBERTa) → evaluation (point-wise accuracy, list-wise MRR@10)
- Critical path: Train detector on known attack types → evaluate on both known and unknown attacks → analyze performance degradation patterns
- Design tradeoffs: Using query text improves detection accuracy but increases false positives on relevant documents
- Failure signatures: High accuracy on known attacks but poor performance on unseen attacks indicates overfitting to specific attack patterns
- First 3 experiments:
  1. Train supervised classifier on all attack types and test on same types to establish baseline performance
  2. Test the classifier from experiment 1 on each individual attack type to measure transfer capability
  3. Compare LA-based detector performance against supervised classifiers when facing unseen attack types

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do adversarial ranking attacks perform against different types of neural ranking models (e.g., BERT, RoBERTa, or other transformer-based models) beyond the 'msmarco-MiniLM-L-12-v2' model used in this study?
- Basis in paper: The paper employs the 'msmarco-MiniLM-L-12-v2' model as the representative victim NRM, but notes that different experimental equipment like GPU could lead to non-deterministic outputs, especially the relevance scores in float type.
- Why unresolved: The study focuses on a single NRM model, and the non-deterministic nature of relevance scores due to different hardware configurations suggests that the attack's effectiveness may vary across different models and setups.
- What evidence would resolve it: Conducting experiments with a variety of NRM models and comparing the attack success rates and detection performance across these models would provide insights into the generalizability of the attack methods and the robustness of different NRMs.

### Open Question 2
- Question: Can the proposed detection methods be adapted to handle more complex and diverse types of adversarial documents, such as those generated by more advanced attack techniques or those that combine multiple attack strategies?
- Basis in paper: The paper introduces two types of detection tasks and evaluates several baseline detection methods, but the results show that the supervised classifiers perform poorly against unseen attacks and that using query text could lead to a relevance-aware detector.
- Why unresolved: The current detection methods are limited in their ability to generalize to unseen attacks and may be influenced by the inclusion of query text, suggesting that more robust and adaptable detection methods are needed to handle diverse adversarial documents.
- What evidence would resolve it: Developing and evaluating detection methods that can effectively handle a wide range of adversarial document types, including those generated by more advanced attack techniques or those that combine multiple strategies, would demonstrate the adaptability and robustness of the proposed detection methods.

### Open Question 3
- Question: How do the proposed detection methods perform in real-world search engine environments, where adversarial documents may be more prevalent and diverse than in the controlled dataset used in this study?
- Basis in paper: The paper mentions that adversarial documents can influence the final ranking outcomes only when they are elevated to the top candidate set by the retrieval models, and that the list-wise detection task considers the impact of adversarial documents on the ranking quality.
- Why unresolved: The study uses a synthetic dataset with a limited number of adversarial examples, and the performance of the detection methods in real-world search engine environments, where the volume and diversity of adversarial documents may be higher, remains unclear.
- What evidence would resolve it: Implementing the proposed detection methods in real-world search engine environments and evaluating their performance in detecting and mitigating the impact of adversarial documents on ranking quality would provide insights into their practical effectiveness and limitations.

## Limitations

- Supervised classifiers show significant performance degradation when encountering unseen attack types, limiting their practical deployment against evolving adversarial techniques
- The benchmark dataset is built on MS MARCO passage data, which may not generalize to other retrieval domains or document types with different linguistic characteristics
- Incorporating query text creates a fundamental trade-off between detection accuracy and preservation of relevant documents, potentially limiting practical deployment where both goals are critical

## Confidence

- High Confidence: The supervised classifier's effectiveness on known attack types (95%+ accuracy) and its performance degradation on unseen attacks are well-supported by experimental results across multiple test scenarios
- Medium Confidence: The LA-based detector's reliability against unknown attacks is supported by evidence, though the exact mechanisms by which it detects novel adversarial patterns remain somewhat unclear
- Medium Confidence: The negative impact of query text on list-wise detection performance is demonstrated, but the paper could benefit from deeper analysis of why relevance features interfere with adversarial detection

## Next Checks

1. Test the supervised classifier against attack types beyond PRADA, PAT, and IDEM to quantify the exact generalization boundary and determine if performance decay follows a predictable pattern
2. Conduct ablation studies on query text inclusion across different document lengths and query-document similarity distributions to better understand the relevance-interference mechanism
3. Evaluate the LA-based detector's performance on adversarial documents that are grammatically correct but semantically manipulated to identify the specific linguistic features it relies upon