---
ver: rpa2
title: 'MoMo: Momentum Models for Adaptive Learning Rates'
arxiv_id: '2305.07583'
source_url: https://arxiv.org/abs/2305.07583
tags:
- momo
- learning
- adam
- rate
- momo-adam
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MoMo, a momentum-based adaptive learning
  rate method for stochastic optimization. The key idea is to build a model of the
  loss function using momentum estimates of past losses and gradients, and then approximately
  minimize this model at each iteration.
---

# MoMo: Momentum Models for Adaptive Learning Rates

## Quick Facts
- arXiv ID: 2305.07583
- Source URL: https://arxiv.org/abs/2305.07583
- Authors: 
- Reference count: 40
- Key outcome: MoMo is a momentum-based adaptive learning rate method that builds a model of the full loss function using momentum estimates of past losses and gradients, achieving O(1/√K) convergence rate for convex problems with interpolation and improving upon SGD-M and Adam in empirical evaluations.

## Executive Summary
This paper introduces MoMo (Momentum Models), a novel adaptive learning rate method for stochastic optimization that leverages momentum estimates of past losses and gradients to build a model of the full loss function. Unlike traditional adaptive methods that adjust learning rates based on individual stochastic samples, MoMo constructs a more stable model by averaging past function evaluations and approximately minimizing this model at each iteration. The method is particularly effective when the loss function is bounded below, which is common in machine learning tasks. Experiments across image classification, recommender systems, and machine translation demonstrate that MoMo and its Adam variant achieve better accuracy and robustness to hyperparameter tuning compared to standard optimizers.

## Method Summary
MoMo builds a model of the full loss function by maintaining momentum estimates of past losses and gradients using exponentially weighted averaging. At each iteration, it constructs a model by averaging these estimates and linearizing past function evaluations around their computation points. The model is then truncated at a lower bound (typically zero for losses) to ensure non-negativity. A proximal update is used to compute the next iterate by approximately minimizing this momentum-based model plus a regularization term that keeps the iterate close to the current point. For cases where zero is not a tight lower bound, MoMo includes an online estimation mechanism to adaptively determine the optimal loss value. The method has a closed-form solution for the update and maintains O(1/√K) convergence rate for convex problems with interpolation.

## Key Results
- MoMo and MoMo-Adam achieve improved accuracy compared to SGD-M and Adam across image classification (MNIST, CIFAR, ImageNet), recommender systems (Criteo), and machine translation (IWSLT14) tasks
- The methods demonstrate better robustness to hyperparameter tuning, particularly learning rate selection
- MoMo maintains O(1/√K) convergence rate for convex problems with interpolation
- Online estimation of the lower bound proves effective when zero is not a tight bound on the loss function

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Momentum estimates of past losses and gradients are used to build a model of the full loss function, not just a single stochastic sample.
- Mechanism: The method aggregates past loss and gradient evaluations using exponentially weighted averaging, creating a model that approximates the full expected loss. This model is then truncated at a lower bound (typically zero) to ensure non-negativity.
- Core assumption: The loss function is bounded below (typically by zero) and can be approximated well by linearizing past evaluations around where they were last computed.
- Evidence anchors:
  - [abstract] "MoMo uses momentum estimates of the losses and gradients sampled at each iteration to build a model of the loss function."
  - [section 2.1] "We can use these past samples to build a better model of f(x) by averaging past function evaluations as follows."
  - [corpus] Weak evidence - corpus lacks papers specifically discussing momentum-based model aggregation.
- Break condition: If the loss function is not bounded below or the linear approximation becomes poor (e.g., highly non-convex regions with large curvature).

### Mechanism 2
- Claim: The adaptive learning rate is computed by approximately minimizing the momentum-based model plus a proximal regularization term.
- Mechanism: At each iteration, the method solves a proximal update that minimizes the momentum-based model plus a regularization term that keeps the iterate close to the current point. The solution has a closed form involving a comparison between the user-specified learning rate and an adaptive term.
- Core assumption: The proximal update with the momentum-based model has a tractable closed-form solution that can be computed efficiently.
- Evidence anchors:
  - [abstract] "The model is then approximately minimized at each iteration to compute the next step."
  - [section 2.1] "Using the model (8), we can now define the proximal update... The following Lemma shows that update (9) can be computed in closed form."
  - [corpus] Weak evidence - corpus lacks papers discussing proximal updates with momentum-based models.
- Break condition: If the closed-form solution becomes unstable or if the proximal term dominates excessively, leading to negligible updates.

### Mechanism 3
- Claim: Online estimation of the lower bound improves performance when zero is not a tight bound on the loss function.
- Mechanism: When the optimal loss value is known to be non-zero, the method estimates this lower bound online using available information from the optimization trajectory. This estimate is incorporated into the model truncation.
- Core assumption: The optimal loss value can be estimated from the optimization trajectory using readily available information like past function values and gradients.
- Evidence anchors:
  - [abstract] "For losses with unknown lower bounds, we develop new on-the-fly estimates of the lower bound that we use in our model."
  - [section 4] "For tasks where fk∗ = 0 is too loose of a bound, in Section 4 we develop an online estimate for fk∗ based on available information."
  - [corpus] Weak evidence - corpus lacks papers discussing online estimation of optimal loss values.
- Break condition: If the online estimate becomes unstable or diverges, leading to poor model truncation and degraded performance.

## Foundational Learning

- Concept: Stochastic optimization and the difference between minimizing a single stochastic sample vs. the full expected loss.
  - Why needed here: The paper's core insight is building a model of the full loss function rather than individual stochastic samples, which requires understanding why this distinction matters.
  - Quick check question: What is the difference between minimizing f(x, s_k) for a single sample s_k versus minimizing the expected loss f(x) = E[f(x, s)]?

- Concept: Proximal methods and how they combine function approximation with regularization.
  - Why needed here: The update rule is derived from a proximal update that balances model approximation with staying close to the current iterate.
  - Quick check question: In a proximal update of the form argmin f(x) + (1/2α)||x - x_k||^2, what role does the regularization term play?

- Concept: Momentum methods and exponentially weighted averaging.
  - Why needed here: The method uses momentum to aggregate past information, so understanding how momentum works is crucial.
  - Quick check question: How does exponentially weighted averaging of gradients differ from simple averaging, and why is it useful in optimization?

## Architecture Onboarding

- Component map: Maintaining momentum estimates of past losses and gradients -> Building a model by averaging these estimates and linearizing past evaluations -> Truncating the model at a lower bound -> Solving a proximal update to get the next iterate -> Optionally updating an online estimate of the lower bound
- Critical path: The most critical sequence is: sample loss and gradient -> update momentum estimates -> build model -> truncate at lower bound -> solve proximal update -> output new iterate. Any failure in this chain breaks the algorithm.
- Design tradeoffs: Using momentum averages past information for better models but introduces bias; truncating at a lower bound ensures non-negativity but requires knowing or estimating that bound; the proximal update balances model accuracy with stability but adds computational overhead.
- Failure signatures: Poor performance when the loss is unbounded below, when the linear approximation breaks down in highly non-convex regions, or when the online lower bound estimate becomes unstable and causes inappropriate truncation.
- First 3 experiments:
  1. Run on a simple convex problem (e.g., quadratic) with known lower bound to verify basic convergence.
  2. Run on a problem where zero is a loose lower bound to test the online estimation mechanism.
  3. Compare sensitivity to learning rate on a standard image classification task against SGD-M and Adam baselines.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MoMo perform on non-convex loss functions with multiple local minima compared to SGD-M and Adam?
- Basis in paper: [inferred] The paper focuses on convex problems and demonstrates MoMo's effectiveness on image classification tasks, which often have non-convex loss landscapes. However, it does not explicitly analyze MoMo's behavior in the presence of multiple local minima.
- Why unresolved: The paper does not provide a theoretical analysis or extensive experiments to investigate MoMo's ability to escape local minima or find better global solutions compared to SGD-M and Adam.
- What evidence would resolve it: A comprehensive experimental study comparing MoMo, SGD-M, and Adam on various non-convex optimization problems with known global minima and multiple local minima. The study should analyze the convergence behavior, final solution quality, and ability to escape local minima.

### Open Question 2
- Question: What is the theoretical justification for the choice of the averaging coefficients ρj,k in MoMo, and how do different choices affect the algorithm's performance?
- Basis in paper: [explicit] The paper presents two options for the averaging coefficients ρj,k: exponentially weighted average and bias correction. However, it does not provide a theoretical justification for these choices or analyze their impact on the algorithm's convergence or performance.
- Why unresolved: The paper lacks a theoretical analysis of the averaging coefficients' role in MoMo's convergence and performance. It also does not compare the performance of different averaging schemes extensively.
- What evidence would resolve it: A theoretical analysis of the averaging coefficients' impact on MoMo's convergence properties, such as convergence rate and stability. Additionally, an experimental study comparing the performance of different averaging schemes on various tasks and datasets.

### Open Question 3
- Question: How sensitive is MoMo to the choice of the lower bound estimate fk* and the online estimation method?
- Basis in paper: [explicit] The paper proposes an online estimation method for the lower bound fk* in cases where zero is not a tight bound. However, it does not thoroughly investigate the sensitivity of MoMo to the choice of fk* or the performance of the online estimation method compared to using a fixed value.
- Why unresolved: The paper provides limited experimental evidence on the impact of the lower bound estimate and the online estimation method on MoMo's performance. It does not analyze the robustness of MoMo to different choices of fk* or the accuracy of the online estimation method.
- What evidence would resolve it: An experimental study comparing MoMo's performance using different lower bound estimates, including the online estimation method, on various tasks and datasets. The study should analyze the sensitivity of MoMo to the choice of fk* and the accuracy of the online estimation method in practice.

## Limitations
- Limited comparison against other state-of-the-art adaptive methods beyond Adam, missing potential benchmarks against AdaGrad, RMSprop, and newer variants
- Insufficient ablation studies on the lower bound estimation mechanism to quantify its impact on convergence and generalization
- Lack of theoretical analysis for non-convex problems where the linear approximation may break down

## Confidence
- **High**: The core algorithmic framework and theoretical convergence analysis for convex problems are sound and well-presented.
- **Medium**: The empirical improvements shown across tasks are promising but need more comprehensive validation against a broader set of optimizers and with more extensive hyperparameter sensitivity analysis.
- **Low**: The effectiveness of the online lower bound estimation in non-convex settings and its impact on generalization remain unclear without more targeted experiments.

## Next Checks
1. **Extended Empirical Comparison**: Run comprehensive experiments comparing MoMo against other adaptive methods like AdaGrad, RMSprop, and newer variants like Adafactor, particularly focusing on hyperparameter sensitivity and generalization gaps.
2. **Lower Bound Estimation Ablation**: Conduct targeted experiments on problems where zero is a loose lower bound to isolate the impact of the online estimation mechanism on both convergence speed and final performance.
3. **Non-Convex Analysis**: Perform experiments on highly non-convex problems (e.g., deep residual networks) to assess the robustness of the momentum-based model approximation when the loss surface is complex and the linear approximation may break down.