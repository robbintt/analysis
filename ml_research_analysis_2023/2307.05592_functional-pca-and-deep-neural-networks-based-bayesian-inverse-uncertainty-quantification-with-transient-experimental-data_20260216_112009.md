---
ver: rpa2
title: Functional PCA and Deep Neural Networks-based Bayesian Inverse Uncertainty
  Quantification with Transient Experimental Data
arxiv_id: '2307.05592'
source_url: https://arxiv.org/abs/2307.05592
tags:
- data
- surrogate
- uncertainty
- parameters
- bayesian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work develops an inverse uncertainty quantification (IUQ)
  process for time-dependent responses, using functional principal component analysis
  (fPCA) and deep neural network (DNN)-based surrogate models. The demonstration is
  based on IUQ of TRACE physical model parameters using the FEBA transient experimental
  data, where the quantity-of-interest (QoI) is time-dependent peak cladding temperature
  (PCT).
---

# Functional PCA and Deep Neural Networks-based Bayesian Inverse Uncertainty Quantification with Transient Experimental Data

## Quick Facts
- arXiv ID: 2307.05592
- Source URL: https://arxiv.org/abs/2307.05592
- Reference count: 40
- Primary result: Improves IUQ of TRACE physical model parameters using functional PCA and DNN/BNN surrogate models with FEBA transient data

## Executive Summary
This work develops an inverse uncertainty quantification (IUQ) framework for time-dependent nuclear reactor responses using functional principal component analysis (fPCA) and deep neural network (DNN) surrogate models. The approach addresses the challenge of sudden temperature drops in peak cladding temperature (PCT) profiles during quenching events by separating phase and amplitude information before dimensionality reduction. Bayesian neural networks estimate surrogate model uncertainties, enabling efficient MCMC sampling for posterior exploration. The method is demonstrated on FEBA test 216 data, showing improved agreement with experimental measurements compared to conventional PCA approaches.

## Method Summary
The IUQ process uses functional alignment to separate phase (warping functions) and amplitude (warped data) information from transient PCT profiles, followed by PCA to reduce dimensionality. Separate DNNs are trained for each principal component score to build computationally efficient surrogate models. MCMC sampling explores posterior distributions of calibration parameters using these surrogates, with Bayesian neural networks providing uncertainty estimates. The approach is validated through forward uncertainty quantification (FUQ) comparing predictions against experimental data not used in the IUQ process.

## Key Results
- Functional PCA significantly improves variance explained compared to conventional PCA for PCT profiles with quenching events
- DNN surrogate models achieve R² > 0.95 for PC score predictions, enabling efficient MCMC sampling
- FUQ validation shows better agreement with experimental data when using fPCA+DNN compared to conventional PCA methods
- BNN uncertainty quantification provides reasonable error bounds on surrogate predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Functional PCA improves dimensionality reduction for transient data with phase and amplitude information
- Mechanism: Separates phase (warping functions) and amplitude (warped data) information before PCA, avoiding phase distortion that conventional PCA introduces when aligning sudden drops
- Core assumption: Transient PCT profiles contain identifiable landmarks (tmax, tquench) that can be aligned across all samples
- Evidence anchors: Functional alignment method separates phase and amplitude information before dimensionality reduction

### Mechanism 2
- Claim: DNN surrogate models reduce MCMC computational cost while maintaining accuracy
- Mechanism: Trains separate DNNs for each PC score, capturing nonlinear relationships between calibration parameters and reduced QoI space
- Core assumption: PC scores are approximately uncorrelated and can be modeled independently with separate networks
- Evidence anchors: DNNs trained using PC scores from fPCA to build surrogate models of TRACE to reduce computational cost in MCMC sampling

### Mechanism 3
- Claim: Bayesian Neural Networks quantify code uncertainty for surrogate models in IUQ
- Mechanism: Treats DNN weights as distributions, enabling uncertainty estimation through multiple forward passes during prediction
- Core assumption: Variational inference can approximate the posterior distributions of DNN weights efficiently
- Evidence anchors: BNNs are used to estimate the uncertainties of DNN surrogate model predictions

## Foundational Learning

- Concept: Principal Component Analysis
  - Why needed here: Reduces infinite-dimensional transient responses to manageable PC scores while preserving key information
  - Quick check question: What is the minimum number of PCs needed to explain 95% of variance in the PCT data?

- Concept: Markov Chain Monte Carlo
  - Why needed here: Explores posterior distributions of calibration parameters given experimental data
  - Quick check question: How many MCMC samples are typically needed for convergence in this type of IUQ problem?

- Concept: Variational Inference
  - Why needed here: Approximates posterior distributions of BNN weights without expensive sampling
  - Quick check question: What is the Kullback-Leibler divergence term in the evidence lower bound (ELBO)?

## Architecture Onboarding

- Component map: Calibration parameters -> Functional alignment -> PCA -> DNN/BNN surrogate models -> MCMC sampling -> Posterior distributions
- Critical path: 1. Generate TRACE simulations with prior samples 2. Apply functional alignment and PCA 3. Train surrogate models (DNN/BNN) on PC scores 4. Run MCMC with surrogate models to explore posteriors 5. Validate with FUQ using posterior samples
- Design tradeoffs: DNNs vs GPs (DNNs better for high-dimensional, nonlinear relationships; GPs provide uncertainty estimates directly); Separate vs single DNN (separate models for each PC may be more accurate but require more training); BNN vs standard DNN (BNNs quantify uncertainty but increase computational cost)
- Failure signatures: Poor reconstruction quality after fPCA (oscillations near quenching time); Low R² values for surrogate model validation (<0.95); MCMC chains not converging (high autocorrelation, multimodal posteriors); FUQ results showing poor agreement with experimental data
- First 3 experiments: 1. Generate 500 TRACE simulations with LHS samples, apply fPCA, verify improved variance explained vs conventional PCA 2. Train DNN surrogate models for first 2 PCs, validate with R² > 0.95 3. Run MCMC with surrogate models, check posterior distributions and convergence diagnostics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the inclusion of model discrepancy terms affect the IUQ results when multiple experimental tests with varying boundary conditions are available?
- Basis in paper: The paper states that model discrepancy is not considered due to limited data, but suggests including it in future work
- Why unresolved: Only one experimental test is used, preventing estimation of model discrepancy
- What evidence would resolve it: IUQ results using multiple experimental tests with known boundary conditions to estimate and incorporate model discrepancy

### Open Question 2
- Question: What is the optimal number of PCs to retain in functional PCA for different types of transient data profiles?
- Basis in paper: The paper uses 2 PCs for warped data and 4 PCs for warping functions, but acknowledges this choice depends on variance explained
- Why unresolved: No systematic study on PC selection across diverse transient profiles
- What evidence would resolve it: Comparative analysis of IUQ accuracy using different numbers of PCs for various transient datasets

### Open Question 3
- Question: How does the linear approximation of BNN prediction uncertainties impact IUQ results compared to full sampling-based uncertainty quantification?
- Basis in paper: The paper uses linear regression to approximate BNN uncertainties to reduce computational cost, acknowledging this is a simplification
- Why unresolved: No comparison between linear approximation and full sampling methods
- What evidence would resolve it: IUQ results using both linear approximation and full sampling uncertainty quantification on the same dataset

### Open Question 4
- Question: How does functional PCA compare to other dimensionality reduction methods like autoencoders for time-dependent responses with phase and magnitude information?
- Basis in paper: The paper only compares conventional PCA and functional PCA, not other methods
- Why unresolved: No evaluation of alternative dimensionality reduction techniques
- What evidence would resolve it: Comparative study of IUQ performance using functional PCA, autoencoders, and other methods on transient datasets

## Limitations

- The functional alignment method depends on identifiable landmarks in transient profiles, which may not generalize to all experimental scenarios
- The assumption that PC scores can be modeled independently with separate DNNs may break down for more complex parameter-response relationships
- The BNN implementation using variational inference may not fully capture true posterior uncertainty, particularly in the tails of distributions

## Confidence

- **High Confidence**: The overall framework combining fPCA with DNN/BNN surrogate models for computational efficiency is technically sound and well-grounded in established methods
- **Medium Confidence**: The specific application to TRACE/FEBA PCT data and the claimed improvements over conventional PCA require validation on additional test cases
- **Low Confidence**: The uncertainty quantification from BNNs may be underestimated if the variational approximation is poor or if the network architecture is not sufficiently expressive

## Next Checks

1. Test the fPCA+DNN approach on synthetic transient data with known ground truth to verify accurate parameter recovery across different quenching scenarios
2. Compare BNN uncertainty estimates against MCMC-based posterior sampling for a subset of calibration parameters to assess the quality of variational inference
3. Apply the methodology to a different transient test (e.g., separate FEBA test or LOFT experiment) to evaluate generalizability beyond the single demonstration case