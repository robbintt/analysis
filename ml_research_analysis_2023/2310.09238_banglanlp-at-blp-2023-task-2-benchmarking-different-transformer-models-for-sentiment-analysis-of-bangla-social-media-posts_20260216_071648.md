---
ver: rpa2
title: 'BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models for
  Sentiment Analysis of Bangla Social Media Posts'
arxiv_id: '2310.09238'
source_url: https://arxiv.org/abs/2310.09238
tags:
- sentiment
- task
- language
- dataset
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents experiments with various Transformer-based
  models for sentiment analysis of Bangla social media posts. The authors explore
  transfer learning by fine-tuning a multilingual BERT model (XLM-RoBERTa) that was
  already pre-trained for sentiment analysis on Twitter data.
---

# BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models for Sentiment Analysis of Bangla Social Media Posts

## Quick Facts
- arXiv ID: 2310.09238
- Source URL: https://arxiv.org/abs/2310.09238
- Reference count: 11
- Key outcome: Fine-tuned Twitter-XLM-RoBERTa achieved 67.02% micro-F1, ranking 21st in the shared task.

## Executive Summary
This paper presents experiments with various Transformer-based models for sentiment analysis of Bangla social media posts. The authors explore transfer learning by fine-tuning a multilingual BERT model (XLM-RoBERTa) that was already pre-trained for sentiment analysis on Twitter data. They also experiment with finetuning BanglaBERT (a monolingual model) and P-tuning (a parameter-efficient fine-tuning method) on XLM-RoBERTa-large. The fine-tuned Twitter-XLM-RoBERTa model achieves the best performance with a micro-F1 score of 67.02% on the test set, ranking 21st in the shared task. The authors conduct error analysis and find instances where the model predictions appear correct but the ground truth labels seem incorrect. They also note that neutral class samples are often misclassified, likely due to fewer training samples compared to positive and negative classes. The results demonstrate the effectiveness of transfer learning for low-resource languages like Bangla, where monolingual pre-trained models are limited.

## Method Summary
The authors fine-tuned pre-trained transformer models on a combined dataset of Bangla social media posts (MUBASE and SentNob). They experimented with standard fine-tuning of XLM-RoBERTa and BanglaBERT, as well as P-tuning on XLM-RoBERTa-large. Models were trained using Hugging Face's AutoModelForSequenceClassification with a learning rate of 5e-5, batch size of 32, and AdamW optimizer. Early stopping was used to prevent overfitting. The best model was the Twitter-finetuned XLM-RoBERTa, which leveraged prior multilingual sentiment knowledge.

## Key Results
- Fine-tuned Twitter-XLM-RoBERTa achieved the best micro-F1 score of 67.02% on the test set.
- Neutral class samples were most frequently misclassified, likely due to fewer training samples compared to positive and negative classes.
- Error analysis revealed instances where model predictions appeared correct but ground truth labels seemed incorrect.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transfer learning from a multilingual model already fine-tuned on sentiment analysis data improves performance on low-resource Bangla.
- Mechanism: The model leverages prior knowledge of sentiment patterns from multiple languages, which transfers to Bangla despite limited monolingual training data.
- Core assumption: Linguistic features for sentiment are partially shared across languages.
- Evidence anchors:
  - [abstract] "Our quantitative results show that transfer learning really helps in better learning of the models in this low-resource language scenario."
  - [section 3.3.1] "Pre-existing knowledge of multilingual sentiment analysis helps in further extending the knowledge base of the model while getting finetuned on our bengali dataset."
- Break condition: If Bangla's morphological and syntactic features differ substantially from languages in the pre-training corpus, transfer benefit may diminish.

### Mechanism 2
- Claim: P-tuning offers competitive performance with fewer trainable parameters compared to full fine-tuning.
- Mechanism: Instead of updating all model parameters, only the parameters of continuous prompts are updated, reducing computational cost while still adapting the model to the task.
- Core assumption: Pre-trained models store relevant knowledge that can be activated through appropriate prompts.
- Evidence anchors:
  - [section 3.3.2] "P-tuning helps us to find a better continuous prompts beyond the original vocabulary of the pre-trained language model."
  - [section 3.4.1] "This approach saves a lot of compute and time when compared to finetuning of similar models, without often impacting performance to a great extent."
- Break condition: If the pre-trained model's knowledge base does not align well with the task, prompt tuning may fail to achieve adequate adaptation.

### Mechanism 3
- Claim: The neutral class suffers from poor performance due to fewer training samples compared to positive and negative classes.
- Mechanism: Imbalanced class distribution leads to the model being less exposed to neutral examples, reducing its ability to generalize for this class.
- Core assumption: Model performance is proportional to the number of training samples per class.
- Evidence anchors:
  - [section 3.4.3] "We also find that neutral sentences get misclassified the most into positive and negative class. Intuitively, this can happen due to the availability of less number of neutral samples in the training data in comparison to positive and negative samples."
- Break condition: If the model learns strong discriminative features for neutral sentiment from limited samples, class imbalance may not be the primary factor.

## Foundational Learning

- Concept: Transfer learning
  - Why needed here: Low-resource languages like Bangla lack large monolingual pre-trained models, making transfer from multilingual models essential.
  - Quick check question: What is the difference between transfer learning and traditional supervised learning in the context of NLP?

- Concept: Fine-tuning vs. P-tuning
  - Why needed here: Understanding parameter-efficient methods helps in deploying models with limited compute resources.
  - Quick check question: How does P-tuning differ from standard fine-tuning in terms of which parameters are updated?

- Concept: Class imbalance
  - Why needed here: Recognizing its impact on model performance guides data augmentation and sampling strategies.
  - Quick check question: What are common strategies to address class imbalance in classification tasks?

## Architecture Onboarding

- Component map: Text input → Tokenizer → Transformer backbone (XLM-RoBERTa/BanglaBERT) → Classification head → Sentiment class output
- Critical path: Tokenization → Model forward pass → Classification head → Output prediction
- Design tradeoffs: Full fine-tuning offers better performance but higher compute cost; P-tuning reduces cost but may slightly impact performance.
- Failure signatures: Low F1 for neutral class suggests class imbalance; degraded performance on test vs. dev indicates potential overfitting or distribution shift.
- First 3 experiments:
  1. Fine-tune XLM-RoBERTa on the Bangla dataset with standard hyperparameters.
  2. Apply P-tuning to XLM-Roberta-large to compare parameter efficiency and performance.
  3. Analyze class-wise F1 scores to identify and address class imbalance issues.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the quality of the Bangla sentiment analysis dataset be improved to reduce incorrect ground truth labels?
- Basis in paper: [explicit] The authors note that their error analysis found instances where model predictions appeared correct but ground truth labels seemed incorrect.
- Why unresolved: The paper identifies the issue but does not propose specific methods for improving data quality or validating annotations.
- What evidence would resolve it: A systematic approach to data validation, such as inter-annotator agreement studies or employing human-in-the-loop verification, would help identify and correct mislabeled instances in the dataset.

### Open Question 2
- Question: How would Large Language Models (LLMs) perform on sentiment analysis for low-resource languages like Bangla compared to traditional transformer models?
- Basis in paper: [explicit] The authors suggest that an interesting future research direction is to apply recently released LLMs to Bangla sentiment analysis.
- Why unresolved: The paper does not experiment with LLMs due to compute and pricing constraints, leaving their potential effectiveness unexplored.
- What evidence would resolve it: Experiments comparing the performance of LLMs (e.g., ChatGPT) to traditional transformer models on the Bangla sentiment analysis task would provide insights into their effectiveness for low-resource languages.

### Open Question 3
- Question: What strategies can be employed to improve the classification of neutral sentiment samples in Bangla social media posts?
- Basis in paper: [inferred] The authors observe that neutral sentences are often misclassified into positive or negative classes, likely due to fewer training samples compared to other classes.
- Why unresolved: The paper identifies the imbalance in training samples but does not explore techniques to address this issue.
- What evidence would resolve it: Experiments applying techniques such as oversampling, undersampling, or data augmentation specifically for the neutral class could demonstrate their effectiveness in improving classification accuracy for neutral sentiments.

## Limitations

- The paper does not explore data augmentation or advanced sampling strategies to address the observed class imbalance, particularly for the neutral class.
- The error analysis is qualitative and does not provide systematic metrics for the frequency or nature of label disagreements between model predictions and ground truth.
- Results are bounded by the quality and coverage of pre-training data, which may not fully capture the nuances of Bangla social media language.

## Confidence

- **High Confidence**: The observation that transfer learning from multilingual models improves performance on low-resource Bangla sentiment analysis.
- **Medium Confidence**: The assertion that P-tuning offers competitive performance with fewer trainable parameters.
- **Medium Confidence**: The explanation that the neutral class's poor performance is primarily due to fewer training samples.

## Next Checks

1. **Controlled Experiment on Class Imbalance**: Design and run an experiment where the training data is artificially balanced (e.g., via oversampling or undersampling) to quantify the impact of class distribution on the F1 scores for each sentiment class, particularly the neutral class.

2. **Comparative Study of Parameter-Efficient Methods**: Extend the current work by implementing and benchmarking P-tuning against other parameter-efficient fine-tuning methods (e.g., LoRA, adapters) on the same dataset, measuring both performance and computational efficiency (parameter count, training time, memory usage).

3. **Systematic Error Analysis with Label Correction**: Conduct a more rigorous error analysis by having multiple human annotators review a sample of instances where the model's prediction disagrees with the ground truth, to estimate the rate of annotation errors in the dataset and assess whether model predictions are indeed correct in cases currently labeled as errors.