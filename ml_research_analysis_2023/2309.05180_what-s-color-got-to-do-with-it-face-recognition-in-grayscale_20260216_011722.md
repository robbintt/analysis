---
ver: rpa2
title: What's color got to do with it? Face recognition in grayscale
arxiv_id: '2309.05180'
source_url: https://arxiv.org/abs/2309.05180
tags:
- color
- images
- grayscale
- face
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: State-of-the-art deep CNN face matchers are typically created using
  extensive training sets of color face images. Our study reveals that such matchers
  attain virtually identical accuracy when trained on either grayscale or color versions
  of the training set, even when the evaluation is done using color test images.
---

# What's color got to do with it? Face recognition in grayscale

## Quick Facts
- arXiv ID: 2309.05180
- Source URL: https://arxiv.org/abs/2309.05180
- Reference count: 40
- State-of-the-art deep CNN face matchers achieve virtually identical accuracy when trained on grayscale versus color images

## Executive Summary
This study investigates whether color information provides any accuracy advantage for state-of-the-art deep CNN face matchers. Surprisingly, models trained on grayscale images achieve essentially the same accuracy as those trained on color images when tested on color faces. The analysis reveals that deep CNNs learn primarily grayscale features in their first convolutional layer, even when processing color inputs. This color-agnostic behavior appears to stem from limited identity-specific information in the color variation of web-scraped face datasets.

## Method Summary
The researchers trained deep CNN face recognition models (ArcFace and AdaFace with ResNet-50 backbone) on various web-scraped datasets (WebFace4M, MS1MV2, Glint-360k) in different color configurations: RGB, grayscale, and HSV. They evaluated these models on benchmark test sets (MORPH, LFW, CFP-FP, AgeDB30, CALFW, CPLFW) to compare accuracy across color spaces. The study also analyzed the color variation within identities in training datasets and examined the learned filters in the first convolutional layer to understand how networks process color information.

## Key Results
- Deep CNN face matchers achieve comparable accuracy when trained on grayscale versus color images
- Grayscale versions of web-scraped training sets contain 30-60% of identities with at least one grayscale image
- The skin region of an individual's images exhibits significant color variation, suggesting limited identity-specific color information
- First convolutional layer learns grayscale conversion filters even when processing color images
- Using single-channel grayscale images reduces memory requirements by 2/3 without sacrificing accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Deep CNN face matchers learn primarily grayscale features in the first convolutional layer, even when trained on color images.
- Mechanism: The first convolutional layer learns 64 filters that are highly correlated across RGB channels, effectively performing grayscale conversion. Only a small subset of filters learn truly color-specific patterns.
- Core assumption: The identity-related information in web-scraped face images is largely independent of color, so the network optimizes for grayscale features.
- Evidence anchors:
  - "About one third of the 64 learned convolutions converged to a similar result... Most of the remaining convolutions have a weight pattern that is very similar for R, G and B."
  - "Only a few of the convolutions have a pattern of weights that appears substantially different across R, G and B."
  - Weak evidence. The corpus contains papers on general object classification that show color is important for some tasks, but none specifically address why CNNs for face recognition learn grayscale features.

### Mechanism 2
- Claim: Color information in web-scraped face datasets carries limited identity-specific information due to high variation in skin tone mapping.
- Mechanism: When analyzing the skin region of images from the same identity, the RGB values form broad, overlapping clusters rather than compact, well-separated groups. This suggests color is not a reliable identity cue.
- Core assumption: The training objective (minimizing identity classification error) drives the network to ignore features that don't consistently help distinguish identities.
- Evidence anchors:
  - "From the results in Figure 5, it is clear that none of the four identities have images where the average RGB of their skin region forms a compact cluster... the four clusters are highly overlapped."
  - "Analyzing a larger number of identities... would drive the result closer to random."
  - No direct evidence. The corpus doesn't contain studies on color variation within identities in face datasets.

### Mechanism 3
- Claim: The presence of grayscale images in supposedly color training sets drives the network to learn color-agnostic features.
- Mechanism: Popular web-scraped datasets contain 30-60% of identities with at least one grayscale image. To correctly classify all images of an identity, the network must learn features that work for both color and grayscale versions.
- Core assumption: The network optimizes for overall classification accuracy across all images, not for exploiting color when available.
- Evidence anchors:
  - "34% (WebFace4M) to 60% (MS1MV2) of the identities in each dataset have at least one grayscale image... having one or more grayscale images of an identity could lead the deep CNN to learn to ignore color in order to classify all images of an identity together."
  - "Training on the grayscale version of the training data results in essentially the same accuracy for classifying color images as does the color version of the training data."
  - No direct evidence. The corpus doesn't discuss the impact of mixed grayscale/color training sets on feature learning.

## Foundational Learning

- Concept: Color spaces and their properties (RGB vs HSV vs grayscale)
  - Why needed here: Understanding how different color spaces separate luminance and chrominance information is crucial for interpreting why HSV doesn't improve accuracy over RGB.
  - Quick check question: What is the key difference between RGB and HSV color spaces, and which channel in HSV corresponds to grayscale intensity?

- Concept: Convolutional neural network architecture, particularly the first convolutional layer
  - Why needed here: The first layer's learned filters determine what visual features are extracted from the input image, making it critical for understanding why the network learns grayscale features.
  - Quick check question: How many filters does the first convolutional layer learn in the ResNet-50 backbone used in this study, and what is the shape of each filter when processing RGB images?

- Concept: Face recognition evaluation metrics and benchmark datasets
  - Why needed here: Understanding how accuracy is measured and what constitutes a good result is essential for interpreting the experimental findings.
  - Quick check question: What are the five benchmark datasets used to evaluate face recognition accuracy in this study, and what type of images do they contain?

## Architecture Onboarding

- Component map:
  Input layer -> First convolutional layer (64 filters) -> ResNet-50 backbone -> ArcFace/AdaFace loss layer -> 512-dimensional feature vector

- Critical path:
  1. Load and preprocess images (convert to grayscale if needed)
  2. Pass through first convolutional layer (learn grayscale features)
  3. Process through ResNet-50 backbone
  4. Compute feature vectors using ArcFace/AdaFace loss
  5. Match using cosine similarity

- Design tradeoffs:
  - Memory vs. accuracy: Using grayscale reduces memory by 2/3 but doesn't sacrifice accuracy
  - Computational complexity: Single-channel first layer has 1/3 the weights of three-channel
  - Dataset size: Grayscale allows 3x more images within same memory constraints

- Failure signatures:
  - If accuracy drops significantly when switching to grayscale: The dataset might contain consistent color cues tied to identity
  - If HSV improves accuracy: The network might be able to learn useful color information when luminance and chrominance are separated
  - If mixed grayscale/color training sets hurt accuracy: The network might struggle to reconcile different feature representations

- First 3 experiments:
  1. Train ArcFace on color-cleaned WebFace4M and evaluate on grayscale MORPH: Verify that color training doesn't improve grayscale test accuracy.
  2. Train ArcFace on grayscale WebFace4M and evaluate on color MORPH: Confirm that grayscale training achieves comparable accuracy on color test images.
  3. Visualize first-layer convolution weights for RGB vs. grayscale models: Observe that both learn similar grayscale-oriented features.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific features or patterns in the skin region of face images contribute to identity recognition in deep CNN face matchers?
- Basis in paper: The paper shows that the RGB representation of visible skin pixels for the same identity is not tightly clustered and exhibits significant variation, suggesting that color may not be a crucial piece of information for the network to utilize.
- Why unresolved: While the paper demonstrates that color variation within an identity's images is significant, it does not identify which specific features or patterns in the skin region are actually used by deep CNNs for identity recognition.
- What evidence would resolve it: Detailed analysis of the learned features in the deeper layers of the CNN, focusing on how they process and utilize information from the skin region, could provide insights into the specific features that contribute to identity recognition.

### Open Question 2
- Question: How does the removal of color information from training images affect the performance of deep CNN face matchers on different demographics?
- Basis in paper: The paper acknowledges that face recognition accuracy varies across demographic groups and that this variation is not specific to using images with color content.
- Why unresolved: The paper does not provide a detailed analysis of how the removal of color information impacts the accuracy of face recognition across different demographics.
- What evidence would resolve it: Conducting experiments that train and test deep CNN face matchers on grayscale images across various demographic groups and comparing the results with those obtained using color images would provide insights into the impact of color removal on demographic accuracy differences.

### Open Question 3
- Question: What are the computational and memory benefits of using single-channel grayscale images in deep CNN face recognition systems?
- Basis in paper: The paper demonstrates that training and testing on single-channel grayscale images achieves essentially the same accuracy as using RGB color images, but with reduced memory and computational requirements.
- Why unresolved: While the paper highlights the potential benefits of using grayscale images, it does not provide a detailed analysis of the specific computational and memory advantages in real-world applications.
- What evidence would resolve it: Implementing and testing deep CNN face recognition systems using single-channel grayscale images in real-world scenarios, and comparing the computational and memory usage with systems using RGB images, would provide concrete evidence of the benefits.

## Limitations

- The study exclusively focuses on deep CNN architectures, leaving uncertainty about whether shallower models might benefit from color information in specific scenarios.
- The analysis of color variation within identities is based on a small sample (4 identities), which may not capture the full diversity present in larger populations.
- The study does not investigate potential benefits of color for specific facial regions beyond the skin (e.g., eyes, hair), nor does it examine cross-cultural variations in facial appearance that might interact with color information.

## Confidence

- **High confidence**: The core finding that deep CNN face matchers achieve comparable accuracy when trained on grayscale versus color images.
- **Medium confidence**: The hypothesis that the presence of grayscale images in web-scraped training sets drives networks to learn color-agnostic features.
- **Low confidence**: The claim that HSV color space provides no advantage over RGB for face recognition.

## Next Checks

1. **Cross-cultural validation**: Repeat the grayscale versus color training experiments on datasets with diverse ethnic representation to verify that the color-agnostic behavior holds across different demographic groups.

2. **Controlled dataset experiment**: Create a carefully curated dataset where all images of each identity are either all color or all grayscale, then train and compare models to isolate the effect of mixed training sets.

3. **Regional color analysis**: Conduct a detailed analysis of whether color information in specific facial regions (eyes, hair, lips) provides any identity-specific benefits that might be overlooked when analyzing the face as a whole.