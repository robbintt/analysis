---
ver: rpa2
title: Entity Tracking in Language Models
arxiv_id: '2305.02363'
source_url: https://arxiv.org/abs/2305.02363
tags:
- state
- contains
- entity
- language
- tracking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether language models can track discourse
  entities and their state changes. The authors create a novel task where a model
  must infer the final state of boxes containing objects after a series of operations.
---

# Entity Tracking in Language Models

## Quick Facts
- arXiv ID: 2305.02363
- Source URL: https://arxiv.org/abs/2305.02363
- Reference count: 34
- Primary result: Language models pretrained on both text and code can track entity states through operations, while text-only models cannot

## Executive Summary
This paper investigates whether language models can track discourse entities and their state changes through a novel task involving boxes containing objects that undergo a series of operations. The authors find that only GPT-3.5 models pretrained on both text and code exhibit non-trivial entity tracking abilities, while text-only models fail at this task. Through finetuning experiments with a smaller T5 model, they demonstrate that entity tracking can be learned from training data and generalizes to examples with little lexical overlap. The results suggest that pretraining on text alone does not make entity tracking capacity surface, but this ability can be learned through finetuning or encouraged by pretraining on code.

## Method Summary
The authors create a synthetic dataset where boxes contain objects and undergo operations like placing, moving, or removing objects. They evaluate GPT models using in-context learning with demonstrations and finetune T5 on this task. The evaluation uses multiple train/test splits designed to test generalization: Base (random split), NumOps (varying operation counts), Vocab (minimal lexical overlap), and AltForms (different lexical forms). Model performance is measured by accuracy in predicting final box contents after operations.

## Key Results
- GPT-3.5 models pretrained on text and code show non-trivial entity tracking abilities
- GPT-3 models pretrained only on text fail to track entities effectively
- Finetuned T5 models learn entity tracking and generalize to examples with minimal lexical overlap
- Performance degrades as the number of operations increases, revealing limitations in tracking capacity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Code pretraining provides stronger signals for entity state tracking than pure text pretraining
- Mechanism: Code execution requires precise tracking of variable states across operations, creating training signals that emphasize maintaining coherent entity representations
- Core assumption: The computational nature of code execution inherently rewards accurate entity state tracking
- Evidence anchors:
  - [abstract] "only GPT-3.5 models, which have been pretrained on large amounts of code, exhibit this ability"
  - [section 4.5] "GPT-3.5 models that have been trained on code systematically outperformed GPT-3 models"
  - [corpus] "Code Pretraining Improves Entity Tracking Abilities of Language Models" (FMR 0.628)

### Mechanism 2
- Claim: Finetuning enables smaller models to learn entity tracking through pattern recognition
- Mechanism: Supervised training on entity tracking tasks allows models to learn associations between operation descriptions and resulting state changes, even with limited lexical overlap
- Core assumption: T5's pretraining provides sufficient semantic understanding to learn entity tracking when explicitly trained on this task
- Evidence anchors:
  - [abstract] "finetuning T5 on several training/evaluation splits" and "generalizing to examples with little lexical overlap"
  - [section 5.3] "pretrained T5 can Learn to Perform Entity Tracking" and performance on Vocab and NumOps splits
  - [corpus] "LIEDER: Linguistically-Informed Evaluation for Discourse Entity Recognition" (FMR 0.532)

### Mechanism 3
- Claim: In-context learning works for entity tracking only when models have been pretrained on both text and code
- Mechanism: The combination of text and code pretraining provides the model with both linguistic understanding and state-tracking abilities necessary to infer entity states from natural language descriptions
- Core assumption: Text pretraining provides linguistic competence while code pretraining provides computational state-tracking competence
- Evidence anchors:
  - [abstract] "only GPT-3.5 models, which have been trained on large amounts of code, exhibit this ability"
  - [section 4.4] "text-davinci-003 did lead to a small drop in performance when there were more than two operations"
  - [section 4.5] Comparison showing GPT-3.5 models outperform GPT-3 models

## Foundational Learning

- Concept: State tracking as a computational problem
  - Why needed here: Understanding that entity tracking involves maintaining representations of entity states across operations is fundamental to grasping why code pretraining helps
  - Quick check question: What is the key difference between tracking states in code versus tracking states in natural language recipes?

- Concept: Transfer learning and pretraining effects
  - Why needed here: The paper demonstrates how different pretraining approaches (text-only vs. text+code) lead to different capabilities, requiring understanding of how pretraining shapes model behavior
  - Quick check question: Why might pretraining on code corpora improve a model's ability to track entity states in natural language?

- Concept: Behavioral evaluation methodology
  - Why needed here: The paper emphasizes the importance of designing evaluations that test actual capabilities rather than allowing models to use shortcuts, which requires understanding of proper experimental design
  - Quick check question: What are the four desiderata for evaluating entity tracking abilities, and why are they important?

## Architecture Onboarding

- Component map: Dataset generation -> Model selection (GPT-3.5, T5) -> Prompt design/in-context demonstrations -> Finetuning setup -> Inference execution -> Output parsing and accuracy calculation
- Critical path: Generate synthetic dataset → Select and configure models → Design prompts/demonstrations → Run inference → Parse outputs and compute accuracy
- Design tradeoffs: Cloze-style completion allows direct evaluation but requires careful output parsing; diverse scenarios prevent shortcut learning but increase complexity; in-context demonstrations reduce training costs but may introduce format bias
- Failure signatures: Models repeating initial states (not processing operations), performance degradation with longer operation sequences (memory limitations), high training accuracy but low evaluation accuracy (memorization vs. generalization)
- First 3 experiments:
  1. Evaluate GPT-3.5 text-davinci-003 on the base split with standard demonstrations to establish baseline entity tracking capability
  2. Evaluate the same model on the AltForms split to test whether entity tracking generalizes beyond specific lexical forms
  3. Finetune T5 on the NumOps split (training on sequences with max 2 operations, testing on sequences with up to 12 operations) to test generalization to longer operation sequences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does pretraining on code and text improve language models' ability to track discourse entities in other domains beyond the boxes and objects task used in this study?
- Basis in paper: Explicit - The authors state that GPT-3.5 models pretrained on both text and code exhibited entity tracking abilities, while text-only models did not.
- Why unresolved: The study only evaluated entity tracking in one specific domain (moving objects between boxes). It is unclear if the benefits of code pretraining generalize to other types of entity tracking tasks.
- What evidence would resolve it: Conducting similar experiments on entity tracking tasks in other domains (e.g., tracking characters and their states in stories, tracking ingredients and their states in recipes) using models pretrained on text vs. text+code would show if the benefits generalize.

### Open Question 2
- Question: What specific aspects of code pretraining lead to improved entity tracking abilities in language models?
- Basis in paper: Explicit - The authors speculate that code pretraining may provide stronger signals for tracking states of variables, or provide additional grounding that improves semantic abilities.
- Why unresolved: The study did not investigate what specific aspects of code pretraining are responsible for the improved entity tracking.
- What evidence would resolve it: Ablation studies that compare the effects of different aspects of code pretraining (e.g., syntax vs. semantics, variable tracking vs. other features) on entity tracking performance would identify the key factors.

### Open Question 3
- Question: Can smaller language models learn entity tracking abilities through finetuning on text data alone, without the benefits of code pretraining?
- Basis in paper: Explicit - The authors found that finetuning a T5 model on entity tracking tasks led to non-trivial entity tracking abilities, even when evaluated on examples with little lexical overlap.
- Why unresolved: While the finetuned T5 model showed entity tracking abilities, the study did not compare its performance to a model finetuned on text-only data without code pretraining.
- What evidence would resolve it: Finetuning T5 on entity tracking tasks using only text data and comparing its performance to the code-pretrained models would show if text-only finetuning can lead to similar entity tracking abilities.

## Limitations
- Synthetic evaluation dataset may not fully capture real-world entity tracking complexity
- Focus on short, structured scenarios rather than long-form discourse limits generalizability
- Code pretraining advantage demonstrated only through GPT-3.5 models without examining specific contributing factors

## Confidence
- High confidence: Text-only pretraining does not yield entity tracking capabilities
- Medium confidence: Code pretraining specifically improves entity tracking (limited to GPT-3 vs. GPT-3.5 comparison)
- Medium confidence: Finetuning results show genuine learning rather than memorization

## Next Checks
1. Test entity tracking on naturalistic text corpora (e.g., recipes, instructions) to validate synthetic task performance transfers to real-world scenarios
2. Conduct ablation studies on code pretraining data to identify whether syntactic patterns, semantic understanding, or computational reasoning drives entity tracking improvements
3. Evaluate longer operation sequences (beyond 12 operations) to determine memory and reasoning limitations of both in-context and finetuned models for entity tracking