---
ver: rpa2
title: Task Relation-aware Continual User Representation Learning
arxiv_id: '2306.01792'
source_url: https://arxiv.org/abs/2306.01792
tags:
- tasks
- task
- user
- learning
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel continual learning method for universal
  user representation, named TERACON, that learns a generalized user representation
  from a sequence of tasks while retaining learning capability and capturing task
  relationships. The method uses task embeddings to generate soft masks that allow
  the entire model parameters to be updated until the end of training, and a knowledge
  retention module with pseudo-labeling to prevent catastrophic forgetting.
---

# Task Relation-aware Continual User Representation Learning

## Quick Facts
- arXiv ID: 2306.01792
- Source URL: https://arxiv.org/abs/2306.01792
- Reference count: 40
- Key outcome: Achieves up to 15.16% improvement in accuracy for universal user representation learning while preventing catastrophic forgetting and capturing task relationships.

## Executive Summary
This paper addresses the challenge of continual learning for universal user representation, where a model must learn from a sequence of tasks without catastrophic forgetting while capturing relationships between tasks. The proposed method, TERACON, introduces task embeddings that generate soft masks to modulate layer outputs, allowing all parameters to remain learnable across all tasks. A knowledge retention module with pseudo-labeling strategy prevents forgetting, while relation-aware sampling improves training efficiency. Extensive experiments demonstrate TERACON's superiority over state-of-the-art methods, achieving significant accuracy improvements and robustness to task order changes and noisy tasks.

## Method Summary
TERACON learns universal user representations through sequential task training using task embeddings to generate soft masks for layer outputs, preventing catastrophic forgetting via a knowledge retention module with pseudo-labeling, and improving efficiency through relation-aware user sampling. The method trains a TCN backbone network sequentially on each task, applying task-specific soft masks derived from task embeddings to all layer outputs. During training on task i, the model generates pseudo-labels for previous tasks using frozen versions of the current backbone and task-specific classifiers, then trains on these pseudo-labels to retain knowledge. The relation-aware sampling strategy samples users based on task similarity to improve training efficiency.

## Key Results
- Achieves up to 15.16% improvement in accuracy compared to state-of-the-art methods
- Demonstrates robustness to task order changes and noisy tasks
- Prevents catastrophic forgetting while maintaining learning capacity across all tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task embeddings generate soft masks that allow all model parameters to remain learnable across all tasks, preventing catastrophic forgetting while retaining learning capacity.
- Mechanism: Each task has an embedding vector that is passed through a sigmoid activation (scaled by hyperparameter s) to create a soft mask. This mask is element-wise multiplied with layer outputs, allowing dynamic amplification or suppression of activations per task without freezing parameters.
- Core assumption: Soft continuous masks can effectively modulate layer outputs to capture task-specific patterns without requiring parameter isolation.
- Evidence anchors:
  - [abstract] "The main idea is to introduce an embedding for each task, i.e., task embedding, which is utilized to generate task-specific soft masks that not only allow the entire model parameters to be updated until the end of training sequence, but also facilitate the relationship between the tasks to be captured."
  - [section] "We use eð‘‡ð‘– ð‘˜ âˆˆ Rð‘“ and mð‘‡ð‘– ð‘˜ âˆˆ Rð‘“ to denote the task embedding and the task-specific mask of task ð‘‡ð‘– in layer ð‘˜, respectively, which is defined as follows: mð‘‡ð‘– ð‘˜ = ðœŽ (ð‘  Â· eð‘‡ð‘– ð‘˜ )"
- Break condition: If the task embeddings fail to capture sufficient task-specific information, the soft masks will not effectively modulate layer outputs, leading to poor performance and catastrophic forgetting.

### Mechanism 2
- Claim: Relation-aware task-specific masks capture task relationships by aggregating information from all tasks, enabling knowledge transfer and preventing negative transfer.
- Mechanism: The task embedding for task i is combined with embeddings from all other tasks in the aggregate set. A learnable MLP maps the concatenated embeddings to a new task embedding, which is then used to generate the mask. This allows the model to encode both positive and negative relationships between tasks.
- Core assumption: Task relationships can be effectively captured by combining task embeddings and learned transformations, and this information can be used to modulate layer outputs.
- Evidence anchors:
  - [abstract] "The main idea is to introduce an embedding for each task, i.e., task embedding, which is utilized to generate task-specific soft masks that not only allow the entire model parameters to be updated until the end of training sequence, but also facilitate the relationship between the tasks to be captured."
  - [section] "To provide a more nuanced understanding of task ð‘‡, instead of directly using tanh(ð‘  Â·eð‘‡ ð‘˜ ), we introduce additionaltanh(âˆ’ð‘  Â·eð‘‡ ð‘˜ ), which provides information about the opposite relatedness with tanh(ð‘  Â·eð‘‡ ð‘˜ ). Hence, ð‘“ ð‘‡ð‘– ð‘˜ learns to distinguish between the positive and negative information of tasks in ËœTð‘–."
- Break condition: If the aggregate set is not properly constructed or the MLP fails to learn meaningful transformations, the model will not capture task relationships effectively, leading to poor knowledge transfer and potential negative transfer.

### Mechanism 3
- Claim: Knowledge retention module with pseudo-labeling prevents catastrophic forgetting by transferring knowledge from previous tasks to the current model.
- Mechanism: During training on task i, the model generates pseudo-labels for previous tasks using frozen versions of the current backbone and task-specific classifiers. The model is then trained to predict these pseudo-labels, effectively retaining knowledge from previous tasks.
- Core assumption: Pseudo-labels generated by the current model for previous tasks accurately represent the knowledge learned from those tasks, and training on these pseudo-labels effectively retains that knowledge.
- Evidence anchors:
  - [abstract] "Moreover, we introduce a novel knowledge retention module with pseudo-labeling strategy that successfully alleviates the long-standing problem of continual learning, i.e., catastrophic forgetting."
  - [section] "The key idea is, while training task ð‘‡ð‘–, to utilize the current backbone network M, and ð‘– âˆ’ 1 task-specific classifiers of previous tasks, i.e., ðºð‘‡1:(ð‘– âˆ’1) , to generate the pseudo-labels for user ð‘¢ð‘™ âˆˆ U ð‘‡ð‘– âŠ‚ U as follows: Ëœy ð‘‡ð‘— ð‘¢ð‘™ = Ëœðºð‘‡ð‘— ( ËœM (xð‘¢ð‘™ ; Ëœmð‘‡ð‘— ) ) for ð‘— = 1, . . . , ð‘– âˆ’ 1"
- Break condition: If the pseudo-labels are not accurate representations of the knowledge from previous tasks, or if the model fails to learn from these pseudo-labels effectively, catastrophic forgetting will occur.

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: The paper addresses catastrophic forgetting as a key challenge in continual learning, where models forget previously learned tasks when trained on new ones.
  - Quick check question: What is the primary mechanism by which neural networks suffer from catastrophic forgetting when trained on sequential tasks?

- Concept: Task-specific representations vs. universal representations
  - Why needed here: The paper contrasts task-specific user representations with universal user representations, highlighting the limitations of the former and the need for the latter.
  - Quick check question: What are the key limitations of task-specific user representations that motivate the development of universal user representations?

- Concept: Parameter isolation vs. soft masking in continual learning
  - Why needed here: The paper compares the parameter isolation approach used in CONURE with its own soft masking approach, explaining the advantages of the latter.
  - Quick check question: What are the key differences between parameter isolation and soft masking approaches in continual learning, and what are the advantages of soft masking?

## Architecture Onboarding

- Component map:
  Backbone network (TCN) -> Task embeddings -> Task-specific masks -> Layer outputs -> Task-specific classifiers -> Final predictions
  Knowledge retention module (pseudo-labeling) -> Backbone network and classifiers -> Previous task labels -> Training loss
  Relation-aware user sampling -> Task similarity computation -> User sampling -> Training efficiency

- Critical path:
  1. For each task i in sequence:
  2. Generate task-specific masks using task embeddings
  3. Train backbone network with masks applied to layer outputs
  4. Generate pseudo-labels for previous tasks
  5. Train on pseudo-labels using knowledge retention module
  6. Update task-specific classifiers
  7. Proceed to next task

- Design tradeoffs:
  - Soft masking vs. parameter isolation: Soft masking allows all parameters to remain learnable but requires careful mask design; parameter isolation freezes parameters but limits learning capacity.
  - Relation-aware masking vs. simple masking: Relation-aware masking captures task relationships but adds complexity; simple masking is easier to implement but may not capture relationships effectively.
  - Knowledge retention with pseudo-labeling vs. other methods: Pseudo-labeling allows efficient knowledge retention but relies on the quality of pseudo-labels; other methods may be more robust but less efficient.

- Failure signatures:
  - Poor performance on new tasks: Indicates insufficient learning capacity or ineffective task embeddings.
  - Catastrophic forgetting: Indicates failure of knowledge retention module or poor pseudo-labels.
  - Inefficient training: Indicates ineffective user sampling or excessive computation in mask generation.

- First 3 experiments:
  1. Ablation study on masking strategies: Compare relation-aware masks with simple masks and masks without opposite relatedness.
  2. Evaluation of knowledge retention: Train with and without pseudo-labeling to assess its impact on preventing catastrophic forgetting.
  3. Analysis of task relationship capture: Visualize task embeddings and masks to verify that the model captures task relationships effectively.

## Open Questions the Paper Calls Out
- None explicitly called out in the paper.

## Limitations
- Limited evaluation of task relationship capture: The paper claims to capture task relationships but doesn't provide specific metrics or analysis focused on relationship modeling.
- Dataset generalization concerns: Evaluation is limited to three datasets, with proprietary NAVER Shopping dataset results difficult to verify independently.
- Hyperparameter sensitivity: The paper doesn't provide systematic sensitivity analysis for key hyperparameters.

## Confidence
- High Confidence: The core mechanisms of soft masking with task embeddings and knowledge retention with pseudo-labeling are well-established and clearly specified.
- Medium Confidence: The claim about preventing catastrophic forgetting is supported by comparison with baselines, but the specific contribution of the knowledge retention module is not isolated.
- Low Confidence: The claim about "capturing task relationships" is asserted but not empirically validated with specific metrics focused on relationship modeling.

## Next Checks
1. **Ablation on Relationship Capture**: Conduct experiments comparing TERACON with and without the relation-aware component (the tanh(-sÂ·e) term and aggregate set) to quantify the specific contribution of task relationship modeling to overall performance.

2. **Catastrophic Forgetting Analysis**: Design a controlled experiment that specifically measures forgetting on previously learned tasks after training on new tasks, using metrics like backward transfer and task accuracy retention over time.

3. **Hyperparameter Sensitivity Analysis**: Perform a grid search or sensitivity analysis across key hyperparameters (s, Î±, learning rate) to understand their impact on performance and identify whether the reported results are robust to hyperparameter variations.