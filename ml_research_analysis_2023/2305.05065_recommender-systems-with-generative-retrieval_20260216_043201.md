---
ver: rpa2
title: Recommender Systems with Generative Retrieval
arxiv_id: '2305.05065'
source_url: https://arxiv.org/abs/2305.05065
tags:
- semantic
- item
- items
- retrieval
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes TIGER, a generative retrieval-based recommender
  system that predicts the next item's Semantic ID directly using a sequence-to-sequence
  model. Instead of traditional nearest-neighbor search, TIGER uses a hierarchical
  quantization method (RQ-VAE) to generate semantically meaningful IDs for items.
---

# Recommender Systems with Generative Retrieval

## Quick Facts
- arXiv ID: 2305.05065
- Source URL: https://arxiv.org/abs/2305.05065
- Reference count: 40
- Key outcome: Achieves up to 29% improvement in NDCG@5 and 17.3% improvement in Recall@5 on Amazon Beauty dataset using generative retrieval with Semantic IDs

## Executive Summary
This paper introduces TIGER, a generative retrieval-based sequential recommender system that predicts the next item's Semantic ID directly using a sequence-to-sequence model. Instead of traditional nearest-neighbor search, TIGER uses hierarchical quantization (RQ-VAE) to generate semantically meaningful IDs for items. The method significantly outperforms state-of-the-art models on Amazon datasets and enables cold-start recommendations and diversity through tunable parameters.

## Method Summary
TIGER uses RQ-VAE to encode item content embeddings into hierarchical codewords, creating compact Semantic IDs. A sequence-to-sequence Transformer model is trained to predict the next item's Semantic ID from user interaction history. During inference, beam search generates candidate Semantic IDs, which are matched to actual items or cold-start groups. The approach dispenses with discrete inner-product search systems entirely, learning an end-to-end differentiable mapping from user history to target items.

## Key Results
- Achieves up to 29% improvement in NDCG@5 and 17.3% improvement in Recall@5 on Amazon Beauty dataset
- Outperforms state-of-the-art models on Amazon Sports and Outdoors and Toys and Games datasets
- Demonstrates effective cold-start recommendations through semantically meaningful ID collisions
- Enables recommendation diversity through tunable decoding parameters

## Why This Works (Mechanism)

### Mechanism 1
Semantic IDs created via RQ-VAE provide a compact, hierarchical representation that captures item semantics more effectively than atomic IDs. RQ-VAE encodes item content embeddings into a tuple of codewords by iteratively quantizing residuals at multiple levels. Each codeword corresponds to a codebook vector, and the tuple as a whole preserves coarse-to-fine semantic granularity. The core assumption is that hierarchical quantization preserves semantic similarity better than flat hashing or random assignment, so similar items share overlapping codewords.

### Mechanism 2
Generative retrieval with Semantic IDs outperforms ANN-based dual-encoder retrieval because the model learns an end-to-end differentiable mapping from user history to target items without relying on fixed vector embeddings. A sequence-to-sequence Transformer directly predicts the Semantic ID tuple token-by-token. During inference, beam search retrieves items matching the generated Semantic ID or sharing its prefix codes. The core assumption is that autoregressive decoding of Semantic IDs can approximate the selection of relevant items as well as or better than MIPS/ANN in the same semantic space.

### Mechanism 3
Semantic IDs enable cold-start and diversity capabilities because the quantization hierarchy allows grouping unseen items with semantically similar seen items. Unseen items inherit their first k codewords from their RQ-VAE embedding; during retrieval, these partial codes match any seen item with the same prefix, and a tunable parameter controls the fraction of such cold-start candidates. The core assumption is that content embeddings of new items remain in the same semantic space as training items, so their codewords meaningfully overlap with existing clusters.

## Foundational Learning

- **Vector quantization (VQ) and hierarchical quantization**: Why needed here - Semantic IDs are generated by quantizing dense embeddings into discrete codewords; understanding VQ ensures correct hyperparameter choices (codebook size, levels). Quick check: If codebook size is 256 and we use 4 levels, how many unique IDs can we represent? Answer: 256^4 = 4,294,967,296 unique IDs.

- **Sequence-to-sequence modeling with Transformers**: Why needed here - The generative retrieval model is a seq2seq Transformer that maps user history (as Semantic IDs) to the next item's Semantic ID. Quick check: What is the difference between causal masking and bidirectional masking in this context? Answer: Causal masking ensures the model only attends to past items in the sequence, preserving the sequential recommendation task; bidirectional masking would leak future information.

- **Approximate nearest neighbor (ANN) search vs. generative retrieval**: Why needed here - To understand why TIGER dispenses with ANN entirely and the trade-offs in inference latency vs. embedding storage. Quick check: In ANN retrieval, what is stored in the index and what is computed at query time? Answer: Item embeddings are precomputed and stored; query embedding is computed at query time and ANN is run over stored embeddings.

## Architecture Onboarding

- **Component map**: RQ-VAE Encoder -> RQ-VAE Quantizer -> RQ-VAE Decoder -> Semantic ID Generator -> Seq2Seq Transformer -> Beam Search Engine
- **Critical path**: 1) Preprocess item content ‚Üí Sentence-T5 embedding, 2) Train RQ-VAE on embeddings ‚Üí learn codebooks and encoder, 3) Generate Semantic IDs for all items, 4) Prepare sequences: user token + item Semantic ID tokens, 5) Train Transformer seq2seq on sequences, 6) Inference: beam search ‚Üí candidate Semantic IDs ‚Üí item lookup
- **Design tradeoffs**: Longer Semantic IDs ‚Üí higher recall but longer input sequences ‚Üí more compute; Larger codebooks ‚Üí lower collision rate but higher memory for codebooks; Beam size vs. inference latency: larger beam improves recall but slows inference
- **Failure signatures**: Low recall: likely codebook too small or model underfitting; check codeword usage distribution; High invalid ID rate: autoregressive model generating out-of-vocabulary codes; check decoding constraints; Cold-start not working: new items' embeddings too far from training distribution; check embedding quality
- **First 3 experiments**: 1) Ablation: Replace RQ-VAE with LSH-based Semantic IDs; compare recall/NDCG, 2) Cold-start simulation: Remove 5% of test items from training; measure recall with ùúñ tuning, 3) Diversity study: Vary decoding temperature; measure entropy@K of predicted categories

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of content features (e.g., text description, images, metadata) impact the quality of Semantic IDs and downstream recommendation performance? The paper mentions using textual descriptions and Sentence-T5 for generating semantic embeddings but does not explore the impact of different content features. Comparative experiments using different content features to generate Semantic IDs would resolve this.

### Open Question 2
What is the optimal length and codebook size for Semantic IDs in terms of recommendation performance and computational efficiency? The paper mentions trying different ID lengths and codebook sizes but does not provide a systematic study of the optimal configuration. A comprehensive ablation study varying ID length and codebook size while measuring both recommendation metrics and computational costs would resolve this.

### Open Question 3
How does TIGER's performance scale with extremely large item catalogs (e.g., millions or billions of items)? The paper discusses the benefits of Semantic IDs for large catalogs but does not test with extremely large datasets. Experiments on datasets with millions or billions of items to evaluate scalability and performance degradation would resolve this.

### Open Question 4
Can the Semantic ID generation process be improved by incorporating user feedback or interaction patterns? The paper uses content features for Semantic ID generation but does not consider user interaction data. Experiments incorporating user interaction patterns into the Semantic ID generation process and measuring the impact on recommendation performance would resolve this.

## Limitations
- Generalization to non-Amazon domains is uncertain as evaluation is limited to e-commerce recommendation
- Scalability concerns exist regarding runtime benchmarks and memory usage for large-scale deployment
- Semantic ID collision handling impact on long-term recommendation quality is not quantified
- Cold-start mechanism robustness is questionable if new items fall outside training distribution

## Confidence
- **High Confidence**: TIGER achieves state-of-the-art performance on Amazon datasets (29% NDCG@5 improvement on Beauty)
- **Medium Confidence**: Hierarchical quantization mechanism is theoretically sound but lacks direct ablation comparisons
- **Low Confidence**: Cold-start and diversity capability claims are demonstrated but not rigorously quantified

## Next Checks
1. **Ablation study on quantization method**: Compare RQ-VAE with alternative semantic ID generation approaches (LSH, random assignment, flat quantization) on the same datasets to isolate the contribution of hierarchical quantization to performance gains.

2. **Cold-start stress test**: Systematically remove varying percentages of items from training (5%, 10%, 20%) and measure how TIGER's recall@5 degrades compared to baseline models, particularly focusing on the effectiveness of the Œµ parameter in maintaining recommendation quality.

3. **Inference latency benchmarking**: Measure end-to-end inference time for TIGER versus ANN-based baselines across different beam sizes and codebook configurations to quantify the practical trade-offs between the generative approach and traditional retrieval methods.