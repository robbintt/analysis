---
ver: rpa2
title: Corporate Bankruptcy Prediction with Domain-Adapted BERT
arxiv_id: '2312.03194'
source_url: https://arxiv.org/abs/2312.03194
tags:
- domain
- variables
- financial
- bert
- corporate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study uses a domain-adapted BERT model to analyze MD&A disclosures
  for bankruptcy prediction, outperforming traditional dictionary-based and Word2Vec
  methods. It achieves 91.56% accuracy by fine-tuning BERT on corporate data with
  self-learning and confidence-based filtering.
---

# Corporate Bankruptcy Prediction with Domain-Adapted BERT

## Quick Facts
- arXiv ID: 2312.03194
- Source URL: https://arxiv.org/abs/2312.03194
- Authors: 
- Reference count: 22
- Primary result: Achieves 91.56% accuracy using domain-adapted BERT for bankruptcy prediction from MD&A disclosures

## Executive Summary
This study presents a domain-adapted BERT approach for predicting corporate bankruptcy using MD&A (Management's Discussion and Analysis) sections from 10-K filings. The method fine-tunes BERT on corporate disclosure data through self-learning with confidence-based filtering, capturing contextual sentiment that traditional dictionary-based approaches miss. By combining BERT-derived sentiment features with financial variables and using linear SVM classification, the model achieves 91.56% accuracy, significantly outperforming dictionary-based and Word2Vec methods.

## Method Summary
The approach extracts MD&A text from 10-K filings (1995-2020) and combines it with five financial variables (working capital, retained earnings, EBITDA, market value of equity, and sales) and bankruptcy labels from Compustat. BERT-based sentiment analysis is performed on the MD&A sections, with the model fine-tuned using self-learning and confidence-based filtering to adapt to the corporate disclosure domain. The resulting sentiment features are combined with financial variables and used as input to classification models including discrete-time logistic hazard models, k-nearest neighbors (kNN-5), and linear kernel SVM.

## Key Results
- Domain-adapted BERT achieves 91.56% accuracy in bankruptcy prediction, outperforming dictionary-based and Word2Vec approaches
- Linear SVM provides the highest accuracy when combined with BERT sentiment features and financial variables
- Self-learning with confidence-based filtering significantly improves prediction accuracy by adapting BERT to corporate disclosure domain
- The method captures contextual sentiment in MD&A sections that traditional approaches miss, providing orthogonal predictive signal to financial variables

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-adapted BERT outperforms dictionary-based and Word2Vec approaches because it captures contextual sentiment rather than relying on keyword frequency.
- Mechanism: BERT's self-attention mechanism generates contextualized embeddings for each token in MD&A sections, allowing the model to infer nuanced managerial sentiment beyond surface-level word counts.
- Core assumption: Managerial sentiment in MD&A sections contains predictive signal for bankruptcy risk that is orthogonal to financial variables.
- Evidence anchors:
  - [abstract] "BERT outperforms dictionary-based predictions and Word2Vec-based predictions under time-discrete logistic hazard model, k-nearest neighbor (kNN-5), and linear kernel support vector machine (SVM)."
  - [section] "Unsophisticated investors have difficulty in understanding corporate disclosures since the disclosures are complex in nature... the traditional dictionary-based approach displays a trivial limitation in analyzing disclosure texts."
  - [corpus] Weak - only 8 related papers found, none directly comparing BERT-based sentiment analysis to dictionary methods in bankruptcy prediction.
- Break condition: If MD&A sections become heavily templated or standardized, reducing linguistic nuance, contextual models may not outperform simpler keyword-based approaches.

### Mechanism 2
- Claim: Self-learning with confidence-based filtering enables effective domain adaptation without labeled target data, significantly improving prediction accuracy.
- Mechanism: The model generates pseudo-labels for MD&A sentences, filters out low-confidence predictions using entropy thresholding, and fine-tunes on the remaining high-quality samples to adapt to the corporate disclosure domain.
- Core assumption: The distance between the source domain (financial news) and target domain (corporate disclosures) is small enough that high-confidence pseudo-labels are reliable.
- Evidence anchors:
  - [abstract] "we apply self-learning with confidence-based filtering to corporate disclosure data... We achieve the accuracy rate of 91.56% and demonstrate that the domain adaptation procedure brings a significant improvement in prediction accuracy."
  - [section] "if the distance between the source and target domains is close enough, supervising a BERT-based classification model with self-generated pseudo-labels filtered with confidence level leads to a significant improvement in performance."
  - [corpus] Missing - no direct corpus evidence found for this specific self-learning mechanism.
- Break condition: If pseudo-label quality is poor due to domain shift or ambiguous sentiment, the fine-tuning process may converge to a suboptimal model.

### Mechanism 3
- Claim: Linear SVM achieves the highest bankruptcy prediction accuracy (91.56%) when combined with domain-adapted BERT sentiment features because it effectively separates the classes in the transformed feature space.
- Mechanism: Domain-adapted BERT extracts high-quality sentiment features that create a linearly separable representation of bankrupt vs. non-bankrupt firms when combined with financial variables.
- Core assumption: The combination of financial variables and BERT-derived sentiment features creates a feature space where a linear decision boundary suffices for accurate classification.
- Evidence anchors:
  - [abstract] "We achieve the accuracy rate of 91.56% and demonstrate that the domain adaptation procedure brings a significant improvement in prediction accuracy."
  - [section] "We choose linear kernel for SVM classification... linear kernel is acceptable to classify the dataset."
  - [corpus] Weak - only 8 related papers found, none specifically validating linear SVM performance on this dataset.
- Break condition: If the relationship between sentiment features and bankruptcy risk becomes non-linear, linear SVM may underperform compared to more complex models.

## Foundational Learning

- Concept: Self-attention mechanism in transformers
  - Why needed here: BERT's self-attention enables it to capture long-range dependencies and context in MD&A sections, which is critical for understanding nuanced managerial sentiment that predicts bankruptcy.
  - Quick check question: How does self-attention differ from recurrent neural networks in processing sequential text data?

- Concept: Domain adaptation through self-learning
  - Why needed here: Labeled data for corporate disclosure sentiment analysis is scarce, making unsupervised domain adaptation essential for adapting pre-trained language models to this specific task.
  - Quick check question: What is the primary challenge in unsupervised domain adaptation that confidence-based filtering addresses?

- Concept: Logistic regression and survival analysis
  - Why needed here: The discrete-time logistic hazard model provides a probabilistic framework for estimating bankruptcy risk over time, incorporating both financial and sentiment variables.
  - Quick check question: How does the discrete-time logistic regression model handle right-censored observations in bankruptcy prediction?

## Architecture Onboarding

- Component map: MD&A text extraction → Sentiment analysis (dictionary, Word2Vec, BERT, domain-adapted BERT) → Feature engineering → Classification (logistic regression, kNN, SVM) → Accuracy evaluation
- Critical path: Domain-adapted BERT sentiment extraction → Linear SVM classification → Accuracy calculation (A1, A2)
- Design tradeoffs: Simpler dictionary-based methods are interpretable but less accurate; complex BERT models capture nuance but require more computational resources and domain adaptation
- Failure signatures: High entropy in pseudo-labels during self-learning indicates poor domain adaptation; low A2 accuracy suggests BERT sentiment features aren't predictive of bankruptcy
- First 3 experiments:
  1. Run dictionary-based sentiment analysis on MD&A sections and measure baseline accuracy
  2. Implement domain adaptation with confidence threshold of 0.2 and evaluate pseudo-label quality
  3. Compare linear SVM accuracy with and without domain-adapted BERT features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would BERT-based bankruptcy prediction performance change if trained on industry-specific corpora rather than general financial news data?
- Basis in paper: [explicit] The paper notes that FinBERT is trained on financial news data, which is "similar but different" from corporate disclosures, and demonstrates domain adaptation improves results
- Why unresolved: The paper only tests adaptation from general financial news to corporate disclosures, not from industry-specific financial corpora
- What evidence would resolve it: Training BERT on industry-specific financial corpora (e.g., banking, technology, manufacturing) and comparing bankruptcy prediction accuracy against the current domain adaptation approach

### Open Question 2
- Question: Does the self-learning domain adaptation approach maintain its performance advantage when applied to time-series forecasting beyond the 12-month horizon tested?
- Basis in paper: [explicit] The study specifically predicts bankruptcies within 12 months and notes this is a common timeframe in bankruptcy prediction literature
- Why unresolved: The paper only evaluates 12-month prediction accuracy and doesn't explore longer-term forecasting capabilities of the domain-adapted model
- What evidence would resolve it: Testing the domain-adapted BERT model's bankruptcy prediction accuracy at 24-month, 36-month, and longer time horizons using the same methodology

### Open Question 3
- Question: How do the contextual embeddings from domain-adapted BERT capture sentiment in cases where managers use hedging language or mixed sentiment that human analysts might miss?
- Basis in paper: [explicit] The paper demonstrates that dictionary-based methods miss contextual sentiment, particularly in cases where negative implications are accompanied by positive explanations, and shows BERT captures this better
- Why unresolved: The paper doesn't provide specific examples of complex linguistic constructions (e.g., sarcasm, irony, or sophisticated hedging) that BERT successfully interprets but dictionaries fail to capture
- What evidence would resolve it: Detailed case studies comparing BERT sentiment analysis with human expert interpretation on complex MD&A passages containing sophisticated linguistic devices that mask true sentiment

## Limitations

- The specific implementation details of the self-learning domain adaptation procedure (entropy threshold, iteration count, learning rate) are not clearly specified, making exact reproduction challenging.
- The BERT-based sentiment analysis implementation lacks details on pre-trained model choice and fine-tuning hyperparameters.
- Performance comparison with other BERT-based methods is limited, and robustness across different datasets remains unclear.

## Confidence

**High Confidence:** The core claim that domain-adapted BERT outperforms traditional dictionary-based and Word2Vec methods in bankruptcy prediction is well-supported by empirical results and comparison across multiple classification models.

**Medium Confidence:** The mechanism of self-learning with confidence-based filtering is theoretically sound, but specific implementation details and their impact on final performance are not fully disclosed.

**Medium Confidence:** The claim that linear SVM achieves the highest accuracy (91.56%) is supported by results, but robustness across different datasets and parameter settings is not thoroughly explored.

## Next Checks

1. **Parameter Sensitivity Analysis:** Conduct experiments varying the self-entropy threshold (0.1, 0.2, 0.3) and iteration count in the self-learning procedure to assess their impact on prediction accuracy and pseudo-label quality.

2. **Model Architecture Comparison:** Implement and compare the performance of domain-adapted BERT with other state-of-the-art BERT-based methods for bankruptcy prediction, including models with different pre-training objectives and fine-tuning strategies.

3. **Dataset Robustness Test:** Validate the approach on a different corporate bankruptcy dataset (e.g., using a different industry or time period) to assess the generalizability of the 91.56% accuracy claim and identify potential overfitting to the original dataset.