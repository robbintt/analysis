---
ver: rpa2
title: Alternative Pseudo-Labeling for Semi-Supervised Automatic Speech Recognition
arxiv_id: '2308.06547'
source_url: https://arxiv.org/abs/2308.06547
tags:
- tokens
- confidence
- pseudo-labels
- data
- incorrect
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of noisy pseudo-labels in semi-supervised
  automatic speech recognition (ASR), where incorrect tokens in pseudo-labels degrade
  model performance. The core method introduces Alternative Pseudo-Labeling (APL),
  which modifies the training objective to handle noisy pseudo-labels by accepting
  alternative tokens at incorrect positions.
---

# Alternative Pseudo-Labeling for Semi-Supervised Automatic Speech Recognition

## Quick Facts
- arXiv ID: 2308.06547
- Source URL: https://arxiv.org/abs/2308.06547
- Reference count: 40
- Key outcome: APL reduces WER by 23.4% and 7.2% on average compared to IPL and MPL baselines

## Executive Summary
This paper addresses the problem of noisy pseudo-labels in semi-supervised automatic speech recognition (ASR), where incorrect tokens in pseudo-labels degrade model performance. The core method introduces Alternative Pseudo-Labeling (APL), which modifies the training objective to handle noisy pseudo-labels by accepting alternative tokens at incorrect positions. APL comprises three key components: (1) Alternative Temporal Classification (ATC) loss, which allows alternative tokens at incorrect positions; (2) Contrastive CTC, which improves confidence estimation by widening the gap between correct and incorrect tokens; and (3) Automatic thresholding, which dynamically determines confidence thresholds without manual tuning. Experiments on English and Chinese datasets show APL outperforms existing methods, achieving 23.4% and 7.2% average relative word error rate (WER) reduction compared to Iterative Pseudo-Labeling (IPL) and Momentum Pseudo-Labeling (MPL), respectively.

## Method Summary
APL introduces Alternative Temporal Classification (ATC) loss to handle noisy pseudo-labels by accepting alternative tokens at detected incorrect positions, improving upon standard CTC's rigidity. The method also incorporates Contrastive CTC to improve confidence estimation by widening the gap between correct and incorrect tokens, and Automatic Thresholding to dynamically determine confidence thresholds without manual tuning. These components work together to mitigate the degradation caused by noisy pseudo-labels in semi-supervised ASR, leading to improved WER reduction compared to baseline methods like IPL and MPL.

## Key Results
- APL achieves 23.4% average relative WER reduction compared to Iterative Pseudo-Labeling (IPL) on English and Chinese datasets
- APL achieves 7.2% average relative WER reduction compared to Momentum Pseudo-Labeling (MPL) on English and Chinese datasets
- APL demonstrates effectiveness across domain-mismatched datasets, outperforming baseline methods in most experimental conditions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Alternative Temporal Classification (ATC) loss enables the model to accept alternative tokens at positions where pseudo-labels are incorrect, preventing degradation from noisy labels.
- Mechanism: ATC replaces the probability of a suspected incorrect token with a weighted sum of probabilities of all other tokens except the blank, allowing the model to "correct" itself during training without explicit label correction.
- Core assumption: Confidence scores can reliably identify which tokens in pseudo-labels are incorrect.
- Evidence anchors:
  - [abstract]: "ATC loss function, which allows alternative tokens at incorrect positions"
  - [section III-C]: "the general form of ATC is to replace the probability ytπ′t as a weighted sum of probabilities of all tokens, except for the blank token"
  - [corpus]: Weak - the corpus neighbors focus on pseudo-labeling but do not discuss alternative tokens in the loss function directly.
- Break condition: If confidence scores are unreliable or uniformly low, ATC cannot distinguish incorrect tokens, and the loss becomes equivalent to standard CTC, offering no benefit.

### Mechanism 2
- Claim: Contrastive CTC loss improves confidence estimation by widening the confidence gap between correct and incorrect tokens, enabling better error detection.
- Mechanism: Contrastive CTC adds a negative term to the loss that decreases the probability of tokens in the pseudo-label (which likely contains errors) while maintaining the standard CTC objective for the ground truth, forcing the model to assign lower confidence to incorrect predictions.
- Core assumption: Incorrect tokens in pseudo-labels can be reliably detected via greedy decoding with dropout, and this set can be used to train the confidence gap.
- Evidence anchors:
  - [abstract]: "Contrastive CTC, which improves confidence estimation by widening the gap between correct and incorrect tokens"
  - [section III-D]: "the proposed contrastive CTC loss function will not only increase the probabilities of ground-truth tokens but also decrease the probabilities of incorrectly predicted tokens"
  - [corpus]: Weak - corpus neighbors discuss pseudo-labeling but not contrastive training for confidence calibration.
- Break condition: If the dropout-based pseudo-label contains too few errors or the errors are not representative, the contrastive term may not effectively widen the confidence gap.

### Mechanism 3
- Claim: Automatic thresholding uses labeled data to estimate a dynamic confidence threshold for unlabeled data, eliminating manual tuning and adapting to dataset differences.
- Mechanism: It computes the EMA of average confidence scores for incorrectly predicted tokens in labeled data and adjusts it based on the relative confidence distribution between labeled and unlabeled data.
- Core assumption: The confidence distribution of incorrect predictions on labeled data is indicative of the threshold needed for unlabeled data, even across domain shifts.
- Evidence anchors:
  - [abstract]: "Automatic thresholding, which dynamically determines confidence thresholds without manual tuning"
  - [section III-E]: "The main idea is to use the labeled data as the proxy to determine the threshold of the unlabeled data"
  - [corpus]: Weak - corpus neighbors discuss thresholds in SSL but not the specific EMA-based relative correction method.
- Break condition: If the labeled and unlabeled data have drastically different confidence distributions (e.g., severe domain mismatch), the relative correction may fail to set an appropriate threshold.

## Foundational Learning

- Concept: Connectionist Temporal Classification (CTC) loss and its implementation via Weighted Finite-State Transducers (WFST)
  - Why needed here: ATC is a variant of CTC, and understanding CTC's mechanics is essential to grasp how ATC modifies the loss and label graph.
  - Quick check question: How does CTC handle unaligned input and output sequences, and what role does the blank token play in this process?

- Concept: Confidence-based error detection and its reliance on model calibration
  - Why needed here: ATC's effectiveness depends on accurately identifying incorrect tokens using confidence scores, which requires understanding how confidence is computed and calibrated in ASR models.
  - Quick check question: How are token-level confidence scores computed in CTC models, and why might over-confident predictions be problematic for error detection?

- Concept: Semi-supervised learning via pseudo-labeling and the impact of noisy labels
  - Why needed here: APL is a semi-supervised method, and understanding the challenges of noisy pseudo-labels is key to appreciating why ATC and contrastive CTC are necessary.
  - Quick check question: What are the typical error patterns in pseudo-labels for ASR, and how do they differ from random label noise?

## Architecture Onboarding

- Component map: Seed model training -> Teacher generates pseudo-labels -> Student updates with ATC -> EMA updates teacher -> repeat
- Critical path: Seed model → Teacher generates pseudo-labels → Student updates with ATC → EMA updates teacher → repeat. The quality of pseudo-labels and error detection directly impacts the student's learning.
- Design tradeoffs:
  - ATC variants (ATC-R vs ATC-A): ATC-R is simpler but sensitive to false alarms; ATC-A is more robust but introduces an additional hyperparameter.
  - One-step vs two-step optimization: One-step applies ATC throughout training but may degrade error detection; two-step switches to CTC later to avoid this.
  - Scale factor η in ATC: Controls the trade-off between fitting the original token and allowing alternatives; too high reduces ATC's benefit, too low may ignore correct tokens.
- Failure signatures:
  - WER increases or plateaus during later training updates: Likely due to degraded error detection and false alarm detection in ATC.
  - No improvement over supervised baseline: Could indicate poor confidence estimation, incorrect threshold setting, or insufficient unlabeled data.
  - High variance in performance across datasets: May suggest the automatic threshold or ATC variant is not well-suited to the data domain.
- First 3 experiments:
  1. Implement and validate ATC-R with two-step optimization on a small English ASR dataset (e.g., LibriSpeech 100h) and compare WER to standard PL and CTC baselines.
  2. Test the impact of contrastive CTC during seed model training by comparing error detection AUC and final WER with and without contrastive training.
  3. Evaluate the automatic thresholding method by comparing performance across multiple fixed thresholds and analyzing the sensitivity to the EMA decay factor λ.

## Open Questions the Paper Calls Out
- The authors suggest applying APL to AED and RNN-T based E2E-ASR models as a future direction, as the ideas in APL are not model-specific.
- The paper does not explore the optimal confidence threshold values for different datasets and domains, as it uses a fixed set of hyperparameters for APL.

## Limitations
- The core claims rely heavily on the assumption that confidence scores can reliably identify incorrect tokens in pseudo-labels, which may not hold in practice when model calibration is poor or confidence scores are uniformly low.
- The ATC loss mechanism introduces additional complexity in implementation, particularly with the k2 WFST toolkit, which is not fully detailed in the paper.
- The effectiveness of the automatic thresholding method across diverse datasets and domains is not thoroughly validated, and its sensitivity to hyperparameters like the EMA decay factor is unclear.

## Confidence
- High confidence: The experimental results showing WER reduction compared to IPL and MPL baselines are well-supported by the provided data and methodology.
- Medium confidence: The theoretical framework of ATC and contrastive CTC is sound, but the practical implementation details and their impact on performance are not fully elaborated.
- Low confidence: The generalizability of the automatic thresholding method across diverse datasets and domains is not thoroughly validated, and its sensitivity to hyperparameters like the EMA decay factor is unclear.

## Next Checks
1. Validate ATC-R with Two-Step Optimization: Implement and test the ATC-R variant with a two-step optimization schedule (ATC in early updates, CTC in later updates) on a small English ASR dataset (e.g., LibriSpeech 100h) to assess its robustness to false alarms and compare WER to standard PL and CTC baselines.
2. Test Contrastive CTC Impact: Conduct an ablation study to compare error detection AUC and final WER with and without contrastive CTC during seed model training, to quantify its contribution to confidence calibration and pseudo-label quality.
3. Evaluate Automatic Thresholding Sensitivity: Analyze the performance of the automatic thresholding method across multiple fixed thresholds and varying EMA decay factors to understand its sensitivity to hyperparameters and its adaptability to domain shifts.