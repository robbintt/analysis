---
ver: rpa2
title: Personalized Transformer-based Ranking for e-Commerce at Yandex
arxiv_id: '2310.03481'
source_url: https://arxiv.org/abs/2310.03481
tags:
- user
- item
- e-commerce
- conference
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of optimizing personalized recommendation
  systems for e-commerce platforms, specifically focusing on improving the ranking
  stage. The authors propose a two-stage training process for transformer-based two-tower
  models, which includes retrieval-oriented pre-training and ranking-oriented fine-tuning.
---

# Personalized Transformer-based Ranking for e-Commerce at Yandex

## Quick Facts
- arXiv ID: 2310.03481
- Source URL: https://arxiv.org/abs/2310.03481
- Reference count: 40
- One-line primary result: Two-stage transformer-based two-tower model with context debiasing and web-search query integration achieves 6% increase in attributed orders on homepage and 5% on cart page at Yandex Market

## Executive Summary
This paper presents a personalized transformer-based ranking system for e-commerce that addresses the challenge of sparse positive feedback in ranking scenarios. The authors propose a two-stage training approach combining retrieval-oriented pre-training with ranking-oriented fine-tuning, along with a novel context debiasing technique. The model has been successfully deployed at Yandex Market, serving millions of users daily, and demonstrates significant improvements in both offline metrics and online A/B testing.

## Method Summary
The approach uses a transformer-based two-tower architecture with a two-stage training process. First, the model undergoes retrieval-oriented pre-training on large-scale interaction data using sampled softmax loss. Then, it is fine-tuned on ranking-specific data using pairwise and calibrated losses while incorporating a context debiasing technique. The context debiasing involves a separate context tower that learns context-specific parameters during training but is detached during deployment. The model also enriches user histories with web-search queries to capture additional user intent signals.

## Key Results
- 6% increase in attributed orders on homepage and 5% on cart page in online A/B testing
- Significant improvements in NDCG for both retargeting and discovery modules
- Model successfully deployed at Yandex Market serving millions of users daily
- Context debiasing technique effectively removes redundant context information

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-stage training significantly improves ranking performance by addressing data sparsity
- Mechanism: Pre-training on retrieval data provides rich user-item interaction patterns, while fine-tuning adapts the model to handle sparse positive feedback
- Core assumption: Pre-training transfers useful representations that can be effectively adapted for ranking tasks
- Evidence anchors:
  - [abstract] "two-stage training technique that combines recall-oriented pre-training with ranking-oriented fine-tuning"
  - [section] "pre-training on the retrieval task mitigates this effect"

### Mechanism 2
- Claim: Context debiasing removes redundant context information from offline models
- Mechanism: Separate context tower learns context-specific parameters during training, then detached during deployment
- Core assumption: Downstream ranker efficiently uses context information, making context redundancy in similarity model detrimental
- Evidence anchors:
  - [abstract] "context debiasing technique to remove context-related signal from offline models"
  - [section] "context debiasing technique for alleviating redundancy of context information"

### Mechanism 3
- Claim: Web-search query integration significantly improves ranking quality
- Mechanism: Web-search queries capture explicit user intent and are fused with e-commerce activity
- Core assumption: Web-search queries contain valuable information about user interests that complements e-commerce interactions
- Evidence anchors:
  - [abstract] "integrating web-search history into e-commerce recommendations significantly improves ranking quality"
  - [section] "quality gains from enriching user histories with web-search queries"

## Foundational Learning

- Concept: Transformer-based two-tower models
  - Why needed here: Enable efficient computation of user-item similarities at scale for large e-commerce platforms
  - Quick check question: What is the main advantage of using a two-tower architecture over a cross-encoder for large-scale recommendation systems?

- Concept: Two-stage training (pre-training + fine-tuning)
  - Why needed here: Addresses data sparsity problem by leveraging large-scale retrieval data for pre-training
  - Quick check question: How does pre-training on retrieval data help improve ranking performance?

- Concept: Context debiasing
  - Why needed here: Prevents model from implicitly inferring context from user history
  - Quick check question: What is the purpose of detaching the context tower during deployment?

## Architecture Onboarding

- Component map:
  Item tower -> User tower (with context tower) -> Similarity function (cosine similarity) -> Two-stage training pipeline

- Critical path:
  Pre-training: Large-scale retrieval data → Item and user towers → Softmax loss
  Fine-tuning: Ranking data → Item and user towers → Pairwise and pointwise losses
  Context debiasing: Context tower learns context-specific parameters during training, detached during deployment

- Design tradeoffs:
  - Two-tower vs. cross-encoder: Two-tower models are more efficient but may sacrifice some accuracy
  - Single vs. multiple user embeddings: Single embeddings simplify maintenance but may limit diversity enforcement
  - Context debiasing: Prevents context redundancy but may remove useful context information

- Failure signatures:
  - Poor ranking performance: Check if pre-training data captures sufficient diversity and if fine-tuning data is large enough and unbiased
  - Context debiasing not working: Verify if context tower is correctly detached during deployment
  - Web-search queries not improving quality: Check if queries are relevant to e-commerce domain

- First 3 experiments:
  1. Compare ranking performance of model trained only on ranking data vs. two-stage training approach
  2. Evaluate impact of context debiasing by comparing models with and without context tower detachment
  3. Assess benefits of web-search query integration by comparing models with and without query enrichment

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does model performance scale with increasing sequence length beyond 1024 events?
- Basis in paper: [explicit] Authors tested up to 1024 events but did not explore longer sequences
- Why unresolved: Only tested up to 1024 events without investigating longer sequences
- What evidence would resolve it: Experiments with varying sequence lengths (2048, 4096) measuring performance gains and computational overhead

### Open Question 2
- Question: How does model perform in real-time serving scenarios vs. batch serving?
- Basis in paper: [explicit] Paper describes batch-serving deployment but mentions real-time serving typically uses multiple user embeddings
- Why unresolved: Only discusses batch serving without real-time deployment data
- What evidence would resolve it: Implementation and testing in real-time serving environment comparing latency, throughput, and user engagement

### Open Question 3
- Question: What is impact of using different types of context information beyond recommendation module ID and device ID?
- Basis in paper: [explicit] Uses only two context features but suggests other context features could be explored
- Why unresolved: Only experimented with two specific context features
- What evidence would resolve it: Experimenting with various context features (time, location, search queries) and measuring impact on ranking quality

## Limitations

- Specific hyperparameter values used in final deployed model are not disclosed, limiting exact reproduction
- Implementation details of context debiasing technique, particularly context tower parameter merging during deployment, remain unclear
- Model performance validation is primarily on Yandex Market data, raising questions about generalizability to other e-commerce platforms

## Confidence

- High confidence in two-stage training mechanism and its effectiveness for addressing data sparsity in ranking scenarios
- Medium confidence in context debiasing technique's contribution to ranking quality due to sparse implementation details
- Medium confidence in web-search query integration benefits without detailed ablation studies on query relevance filtering

## Next Checks

1. Conduct systematic ablation study on context debiasing technique, varying context tower complexity and measuring impact on ranking performance
2. Test model generalizability by deploying same architecture on different e-commerce platform with distinct user behavior patterns
3. Perform detailed analysis of web-search query integration by varying ratio of query-to-product interactions and measuring point of diminishing returns on ranking quality