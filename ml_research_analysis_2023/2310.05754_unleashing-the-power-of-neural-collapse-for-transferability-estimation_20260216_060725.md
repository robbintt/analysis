---
ver: rpa2
title: Unleashing the power of Neural Collapse for Transferability Estimation
arxiv_id: '2310.05754'
source_url: https://arxiv.org/abs/2310.05754
tags:
- class
- pre-trained
- collapse
- face
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel transferability estimation method called
  Fair Collapse (FaCe), which is inspired by the Neural Collapse (NC) phenomenon observed
  in well-trained models. The key idea is to assess the degree of NC in pre-trained
  models to estimate their transferability to downstream tasks.
---

# Unleashing the power of Neural Collapse for Transferability Estimation

## Quick Facts
- arXiv ID: 2310.05754
- Source URL: https://arxiv.org/abs/2310.05754
- Reference count: 13
- This paper proposes FaCe, a novel transferability estimation method based on Neural Collapse, achieving state-of-the-art performance across image classification, semantic segmentation, and text classification tasks.

## Executive Summary
This paper introduces Fair Collapse (FaCe), a novel transferability estimation method inspired by the Neural Collapse (NC) phenomenon observed in well-trained models. The method assesses the degree of NC in pre-trained models to estimate their transferability to downstream tasks. FaCe combines two terms: variance collapse term measuring class separation and within-class compactness, and class fairness term quantifying equidistance between class distributions. Extensive experiments demonstrate that FaCe outperforms existing methods across various tasks, network architectures, source datasets, and training loss functions.

## Method Summary
FaCe is a transferability estimation method that leverages Neural Collapse characteristics to rank pre-trained models for downstream tasks. The method extracts last-layer features from pre-trained models on target data, then computes two terms: variance collapse (measuring between-class and within-class covariance) and class fairness (measuring entropy of overlap matrix between class distributions). These terms are normalized and combined to produce a final transferability score. The approach assumes that models exhibiting stronger NC characteristics are more transferable, and that the relative NC scores remain stable during fine-tuning.

## Key Results
- FaCe achieves state-of-the-art performance in transferability estimation across image classification, semantic segmentation, and text classification tasks
- The method demonstrates good generalization across different network architectures, source datasets, and training loss functions
- FaCe shows strong correlation between NC scores and fine-tuned model performance, validating the core assumption

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pre-trained models retain a stable rank ordering of Neural Collapse (NC) scores even after fine-tuning on different target datasets.
- Mechanism: During fine-tuning, the relative NC scores of pre-trained models remain mostly consistent, implying NC characteristics can predict performance after fine-tuning.
- Core assumption: NC scores are stable across fine-tuning epochs and transferable between source and target domains.
- Evidence anchors: Strong correlation observed between pre-trained and fine-tuned NC scores; consistent ranking maintained during fine-tuning.

### Mechanism 2
- Claim: Variance collapse term measures class separation and within-class compactness, key indicators of model transferability.
- Mechanism: Computed as ratio of between-class covariance to within-class covariance, with higher scores indicating better class separability.
- Core assumption: Pre-trained models with better class separability on target data are more transferable.
- Evidence anchors: Variance collapse score directly measures the fundamental NC characteristics of class separation and compactness.

### Mechanism 3
- Claim: Class fairness term quantifies equidistance between class distributions, addressing model bias towards specific classes.
- Mechanism: Computed using entropy of overlap matrix between all pairs of class distributions, with higher entropy indicating fairer treatment.
- Core assumption: Pre-trained models that are fair to all classes are more transferable.
- Evidence anchors: Extends NC's equiangularity concept to equidistance for more accurate fairness assessment.

## Foundational Learning

- Concept: Neural Collapse (NC) phenomenon in well-trained models
  - Why needed here: FaCe is inspired by NC and uses its characteristics to estimate transferability
  - Quick check question: What are the four manifestations of NC in well-trained models?

- Concept: Transferability estimation in pre-trained models
  - Why needed here: FaCe is a transferability estimation method that aims to select the most suitable pre-trained model for a downstream task
  - Quick check question: What are the challenges in transferability estimation, and how does FaCe address them?

- Concept: Feature space analysis and class separability
  - Why needed here: FaCe uses feature space analysis to measure class separation and within-class compactness, key indicators of transferability
  - Quick check question: How is the variance collapse score computed, and what does it represent?

## Architecture Onboarding

- Component map: Model zoo and target dataset -> Feature extraction -> Variance collapse term computation -> Class fairness term computation -> Normalization and combination -> Transferability ranking

- Critical path:
  1. Extract last-layer features from pre-trained models on target dataset
  2. Compute variance collapse score using between-class and within-class covariance
  3. Compute class fairness score using overlap matrix and entropy
  4. Normalize and combine variance collapse and class fairness scores
  5. Rank pre-trained models based on final FaCe scores

- Design tradeoffs:
  - Complexity vs. interpretability: Combining two terms increases complexity but provides more comprehensive assessment
  - Generalization vs. specificity: Designed for cross-architecture generalization, potentially sacrificing some specificity

- Failure signatures:
  - Low correlation between FaCe scores and fine-tuned accuracy
  - Unstable FaCe scores across different target datasets or pre-trained models
  - High variance in FaCe scores due to noisy feature extraction or class overlap

- First 3 experiments:
  1. Validate FaCe on a heterogeneous model zoo with a single source dataset and multiple target datasets
  2. Compare FaCe with existing transferability estimation methods (e.g., LogME, NCE) on the same model zoo and target datasets
  3. Analyze the contribution of each term (variance collapse and class fairness) to the overall FaCe score and transferability estimation performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FaCe perform when applied to transfer learning scenarios involving multi-modal datasets, such as combining images and text?
- Basis in paper: The paper primarily focuses on image and text classification tasks separately, but does not explore scenarios involving multi-modal datasets.
- Why unresolved: No experimental results or analysis on multi-modal transfer learning scenarios are provided.
- What evidence would resolve it: Conducting experiments using FaCe on multi-modal transfer learning tasks and comparing its performance with other methods.

### Open Question 2
- Question: How does the choice of temperature scaling (t) in the class fairness term affect the performance of the FaCe method?
- Basis in paper: The paper mentions that the temperature t is empirically set to 0.05, but does not explore the impact of different temperature values on the method's performance.
- Why unresolved: No systematic analysis of how varying the temperature scaling parameter influences the results is provided.
- What evidence would resolve it: Conducting experiments with different temperature values and analyzing their impact on the performance of FaCe.

### Open Question 3
- Question: How does FaCe compare to other state-of-the-art transferability estimation methods when applied to transfer learning tasks involving large-scale datasets or complex model architectures?
- Basis in paper: The paper demonstrates effectiveness on various tasks and model architectures, but does not specifically compare performance on large-scale datasets or complex architectures.
- Why unresolved: No comprehensive comparison with other methods in the context of large-scale datasets or complex model architectures is provided.
- What evidence would resolve it: Conducting experiments comparing FaCe with other state-of-the-art methods on large-scale datasets or complex model architectures.

## Limitations
- The method requires access to labeled data from the target task, which may not always be available in real-world scenarios
- The assumption that NC characteristics are universally preserved across all types of domain shifts may not hold for extreme cases
- The reliance on Neural Collapse assumes well-trained models consistently exhibit NC characteristics across diverse architectures and datasets

## Confidence
- High confidence: The empirical validation across multiple benchmarks and the clear correlation between FaCe scores and fine-tuned accuracy
- Medium confidence: The generalizability claims across different architectures and loss functions, as the evaluation was primarily conducted on standard vision datasets
- Low confidence: The assumption that NC characteristics are universally preserved across all types of domain shifts and extreme class imbalances

## Next Checks
1. Test FaCe's performance on highly imbalanced target datasets where class fairness might be compromised
2. Evaluate FaCe on non-vision domains (e.g., speech, time series) to verify cross-domain generalizability
3. Investigate FaCe's behavior with models trained using self-supervised learning objectives that may not exhibit traditional NC characteristics