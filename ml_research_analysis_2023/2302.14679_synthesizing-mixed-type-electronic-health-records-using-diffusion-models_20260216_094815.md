---
ver: rpa2
title: Synthesizing Mixed-type Electronic Health Records using Diffusion Models
arxiv_id: '2302.14679'
source_url: https://arxiv.org/abs/2302.14679
tags:
- data
- diffusion
- synthetic
- real
- privacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TabDDPM, a diffusion model for generating
  mixed-type tabular electronic health records (EHRs) with both continuous and categorical
  features. The method uses Gaussian diffusion for continuous features and Multinomial
  diffusion for categorical features, trained via a denoising objective.
---

# Synthesizing Mixed-type Electronic Health Records using Diffusion Models

## Quick Facts
- arXiv ID: 2302.14679
- Source URL: https://arxiv.org/abs/2302.14679
- Reference count: 32
- Primary result: TabDDPM outperforms VAE, medGAN, and corGAN on multiple metrics for mixed-type EHR generation, but reveals privacy-utility trade-offs

## Executive Summary
This paper introduces TabDDPM, a diffusion model for generating synthetic electronic health records (EHRs) containing both continuous and categorical features. The method combines Gaussian diffusion for continuous features and Multinomial diffusion for categorical features, trained via a denoising objective. Experiments on four datasets (MIMIC-III, Pima Indians Diabetes, Indian Liver Patient, and Stroke Prediction) demonstrate that TabDDPM consistently outperforms baseline models (VAE, medGAN, corGAN) across multiple evaluation metrics including data quality, utility, and data augmentation performance. However, the study reveals a fundamental trade-off between data quality and privacy, with more realistic synthetic data showing higher privacy leakage risks. This work is notable as the first to highlight privacy concerns specifically in diffusion-based EHR generation.

## Method Summary
TabDDPM combines Gaussian diffusion for continuous features and Multinomial diffusion for categorical features to generate mixed-type EHR data. The model uses an MLP architecture with sinusoidal time embeddings and class embeddings, trained via a denoising objective that combines mean-squared error for continuous features and KL divergence for categorical features. The method directly generates realistic mixed-type data without post-processing steps. Training involves iteratively denoising both feature types while learning their joint distribution, enabling the model to capture complex inter-dimensional relationships in the data.

## Key Results
- TabDDPM consistently generates more realistic synthetic EHR samples than VAE, medGAN, and corGAN across all tested datasets
- The model achieves superior performance in data augmentation tasks, improving downstream classifier performance with synthetic data
- TabDDPM reveals a privacy-utility trade-off, generating higher quality data at the cost of lower privacy metrics compared to baseline methods
- First study to highlight privacy concerns specifically in diffusion-based EHR generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The combination of Gaussian and Multinomial diffusion processes allows TabDDPM to generate mixed-type tabular EHRs without post-processing steps.
- Mechanism: Gaussian diffusion handles continuous features by iteratively adding and removing Gaussian noise, while Multinomial diffusion handles categorical features by iteratively resampling categories uniformly. This dual-process architecture directly generates realistic mixed-type data.
- Core assumption: Continuous features follow Gaussian distributions and categorical features follow categorical distributions that can be modeled via multinomial resampling.
- Evidence anchors:
  - [abstract] "TabDDPM, a diffusion model for generating mixed-type tabular electronic health records (EHRs) with both continuous and categorical features. The method uses Gaussian diffusion for continuous features and Multinomial diffusion for categorical features"
  - [section II.A] "TabDDPM adapts the reverse process to the categorical data by applying the softmax function to the outputs of MLP. Additionally, it learns a class-conditional model for classification tasks"
- Break condition: If continuous features are not Gaussian-distributed or categorical features have highly imbalanced categories, the diffusion processes may fail to capture the true data distribution.

### Mechanism 2
- Claim: The denoising objective with combined mean-squared error and KL divergence losses enables stable training and superior data quality.
- Mechanism: The model minimizes LTabDDPM = Lsimple + ΣLiC where Lsimple is the mean-squared error between true and predicted noise for continuous features, and LiC are KL divergences for categorical features. This combined objective trains the model to accurately denoise both feature types.
- Core assumption: The denoising objective with this specific combination of loss terms provides stable gradients for training.
- Evidence anchors:
  - [section II.A] "MLP is trained by minimizing a sum of mean-squared error Lsimple for the continuous features and the KL divergences Lit for each categorical feature"
  - [section IV.B] "TabDDPM consistently generates more realistic samples than the baseline models across all datasets, as evidenced by the lower root mean square error (RMSE) values"
- Break condition: If the variance schedule or noise schedule is poorly chosen, the model may fail to converge or generate low-quality samples.

### Mechanism 3
- Claim: TabDDPM's architecture with sinusoidal time embeddings and class embeddings captures temporal dependencies and class-conditional relationships.
- Mechanism: The MLP architecture incorporates sinusoidal time embeddings (SinTimeEmb) to capture timestep dependencies and class embeddings for conditional generation. This allows the model to learn complex relationships between features and target variables.
- Core assumption: Sinusoidal time embeddings effectively capture the temporal structure needed for diffusion processes.
- Evidence anchors:
  - [section II.B] "temb = Linear(SiLU(Linear(SinTimeEmb(t))))" and "yemb = Embedding(y)" showing the incorporation of time and class embeddings
  - [section IV.B] "TabDDPM outperforms the competitor models in this aspect, too. These results confirm the superior capability of diffusion models to VAE and GANs in modeling the inter-dimensional relationships of the real data"
- Break condition: If the time embedding dimension or class embedding size is insufficient, the model may fail to capture important temporal or class-conditional patterns.

## Foundational Learning

- Concept: Diffusion models as latent variable models
  - Why needed here: Understanding that TabDDPM learns by transforming data to noise and back is crucial for grasping the denoising objective and reverse process
  - Quick check question: What are the two Markovian processes in diffusion models and what do they do?

- Concept: KL divergence as a measure of distribution difference
  - Why needed here: The KL divergence losses for categorical features require understanding how to measure similarity between probability distributions
  - Quick check question: What does KL divergence measure and why is it appropriate for comparing categorical distributions?

- Concept: Data augmentation techniques and their impact on model performance
  - Why needed here: The paper shows TabDDPM's effectiveness in data augmentation, which requires understanding how synthetic data can improve downstream task performance
  - Quick check question: How does augmenting real training data with synthetic data typically affect classifier performance, especially for imbalanced datasets?

## Architecture Onboarding

- Component map: MLP backbone with sinusoidal time embeddings and class embeddings → Gaussian diffusion for continuous features → Multinomial diffusion for categorical features → Combined loss function (MSE + KL) → Synthetic data generation
- Critical path: Data → Preprocessing (normalization, one-hot encoding) → TabDDPM training (loss optimization) → Synthetic data generation → Evaluation (quality, privacy, utility metrics)
- Design tradeoffs: Using sinusoidal time embeddings vs learned positional embeddings; combining Gaussian and Multinomial diffusion vs separate models; trade-off between data quality and privacy
- Failure signatures: Poor data quality metrics (high RMSE, low MMD); privacy concerns (low DCR, high MIR); training instability (diverging loss); class imbalance in synthetic data
- First 3 experiments:
  1. Train TabDDPM on MIMIC-III dataset and evaluate dimension-wise probability and prediction metrics
  2. Compare TabDDPM with VAE, medGAN, and corGAN on Pima Indians Diabetes dataset for data quality metrics
  3. Evaluate TabDDPM's data augmentation capabilities on ILPD dataset by measuring F2-score improvement with varying amounts of synthetic data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does TabDDPM's performance on privacy metrics compare to other synthetic data generation methods when evaluated on larger, more complex EHR datasets?
- Basis in paper: [explicit] The paper mentions TabDDPM performs worse on privacy metrics (DCR and MIR) compared to baselines on the MIMIC-III, ILPD, Pima, and Stroke datasets.
- Why unresolved: The paper only tests on four datasets, and the privacy metrics may vary significantly with dataset size and complexity. The authors do not provide a comprehensive comparison across a wide range of EHR datasets.
- What evidence would resolve it: Testing TabDDPM on larger and more diverse EHR datasets (e.g., containing millions of records, multiple hospitals, or longitudinal data) and comparing its privacy metrics with other methods would clarify its relative performance.

### Open Question 2
- Question: Can TabDDPM be adapted to handle missing data and irregularly sampled EHR data effectively?
- Basis in paper: [inferred] The authors mention that future work could adapt diffusion models to handle missing data and irregularly sampled data, similar to existing GAN and VAE approaches.
- Why unresolved: The current TabDDPM implementation does not address missing data or irregularly sampled data, which are common challenges in real-world EHR data.
- What evidence would resolve it: Modifying TabDDPM to handle missing data (e.g., through data imputation or masking) and irregularly sampled data (e.g., through temporal modeling) and evaluating its performance on datasets with these characteristics would provide insights.

### Open Question 3
- Question: What is the optimal trade-off between data quality and privacy when using TabDDPM for EHR generation?
- Basis in paper: [explicit] The paper explicitly states that TabDDPM achieves better data quality but worse privacy metrics compared to baselines, confirming a trade-off between privacy and utility.
- Why unresolved: The paper does not provide a quantitative analysis of how to balance the trade-off or identify the optimal point where the synthetic data is both high-quality and sufficiently private.
- What evidence would resolve it: Conducting experiments to measure the relationship between data quality (e.g., MMD, dimension-wise probability) and privacy (e.g., DCR, MIR) metrics across different TabDDPM configurations and identifying the configuration that maximizes both would clarify the optimal trade-off.

## Limitations
- Privacy-Utility Trade-off: More realistic synthetic data generated by TabDDPM shows higher privacy leakage risks, raising concerns about practical healthcare deployment
- Dataset Specificity: Experiments limited to four specific datasets, with MIMIC-III only containing binary features, limiting generalizability to real-world EHR complexity
- Privacy Metrics Limitation: The paper uses MIR and DCR as privacy metrics, which may not capture all privacy risks associated with synthetic EHR generation

## Confidence
- High Confidence: The TabDDPM architecture and training methodology, supported by detailed mathematical formulation and implementation details
- Medium Confidence: Experimental results showing superior performance over baselines, though limited to specific datasets
- Low Confidence: Long-term implications of privacy-utility trade-offs and real-world applicability in healthcare settings

## Next Checks
1. Cross-dataset Validation: Evaluate TabDDPM on additional diverse EHR datasets with varying feature types and distributions to assess generalizability beyond the four tested datasets
2. Privacy Metric Expansion: Implement and compare additional privacy metrics (e.g., attribute inference, differential privacy guarantees) to provide a more comprehensive privacy assessment
3. Real-world Deployment Test: Conduct a small-scale clinical trial or user study to evaluate TabDDPM-generated data's utility in actual healthcare applications while measuring practical privacy risks