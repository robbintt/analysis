---
ver: rpa2
title: 'Tell2Design: A Dataset for Language-Guided Floor Plan Generation'
arxiv_id: '2311.15941'
source_url: https://arxiv.org/abs/2311.15941
tags:
- room
- floor
- plan
- instructions
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes the task of generating floor plans directly
  from natural language instructions and introduces a novel dataset, Tell2Design,
  containing 80k+ floor plans with human- and artificially-generated instructions.
  The authors formulate this as a sequence-to-sequence problem and propose a baseline
  model that encodes instructions and outputs structured target sequences for room
  bounding boxes, incorporating floor plan boundaries as box sequences.
---

# Tell2Design: A Dataset for Language-Guided Floor Plan Generation

## Quick Facts
- arXiv ID: 2311.15941
- Source URL: https://arxiv.org/abs/2311.15941
- Reference count: 16
- Key outcome: Proposed baseline achieves micro IoU of 54.34 and macro IoU of 53.30 on floor plan generation task

## Executive Summary
This paper introduces the task of generating floor plans directly from natural language instructions and presents Tell2Design, a novel dataset containing over 80,000 floor plans with both human- and artificially-generated instructions. The authors formulate this as a sequence-to-sequence problem and propose a baseline model that encodes instructions and outputs structured target sequences for room bounding boxes, incorporating floor plan boundaries as box sequences. The model outperforms several text-to-image baselines and achieves strong performance metrics, though human evaluations indicate challenges with capturing room relationships.

## Method Summary
The paper proposes a sequence-to-sequence approach where floor plan generation is treated as predicting structured token sequences representing room types and bounding box coordinates. The model incorporates floor plan boundaries by transforming outlines into sequences of enclosing and exterior boxes, which are prepended to the language instructions. The authors employ a warm-up and fine-tuning strategy, first pre-training on artificial instructions with structured expressions before adapting to more diverse human instructions. The Tell2Design dataset is created with a focus on high-quality floor plans and language instructions, featuring two distinct portions: human-written instructions with varied expressions and artificial instructions with complete, structured information.

## Key Results
- Proposed baseline achieves micro IoU of 54.34 and macro IoU of 53.30
- Outperforms text-to-image baselines (e.g., Imagen) on floor plan generation task
- Human evaluations show model captures key room attributes but struggles with room relationships
- Pre-training on artificial instructions significantly improves performance (over 10 IoU score increment)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Representing floor plan boundaries as sequences of enclosing and exterior boxes enables the model to incorporate spatial constraints during generation.
- **Mechanism**: The model encodes boundary information by transforming the irregular outline into structured box sequences, where the enclosing box defines the maximum extent and exterior boxes mark excluded regions. This sequence is prepended to language instructions, allowing the transformer to learn spatial relationships between rooms and boundaries during training.
- **Core assumption**: The boundary can be adequately represented by a minimal set of enclosing and exterior boxes without losing critical spatial information needed for valid floor plan generation.
- **Evidence anchors**:
  - [abstract]: "Second, we propose a Sequence-to-Sequence model that can serve as a strong baseline for future research. Our approach is strengthened by a new strategy to explicitly incorporate the floor plan boundary constraint by transforming the outline into a box sequence."
  - [section 4.2]: "The idea is to encode the boundary information by an enclosing box that is the minimum bounding region containing the entire floor plan and several exterior boxes that are inside the enclosing box but excluded from the floor plan."
- **Break condition**: If the floor plan boundary contains complex concave shapes or features that cannot be captured by simple box representations, the model may generate rooms that violate spatial constraints.

### Mechanism 2
- **Claim**: Formulating floor plan generation as a sequence-to-sequence problem with structured target sequences enables precise control over room attributes.
- **Mechanism**: The model treats the entire floor plan as a sequence of structured tokens, where each room is represented by its type and bounding box coordinates. By predicting these tokens autoregressively, the model can maintain consistency between room attributes (type, position, size) and relationships across the entire layout.
- **Core assumption**: The discrete representation of continuous bounding box values (x, y, h, w) into integer tokens between 0-255 preserves sufficient precision for valid floor plan generation.
- **Evidence anchors**:
  - [abstract]: "We propose a Sequence-to-Sequence model that can serve as a strong baseline for future research."
  - [section 4.1]: "Each of the continuous values (x, y, h, w) is discretized into integers between [0, 255], and the room type is given by the plain text in natural language, so that they can be naturally represented as a sequence of tokens."
- **Break condition**: If the discretization granularity is too coarse, the model may generate rooms with imprecise dimensions or positions that don't satisfy the language instructions.

### Mechanism 3
- **Claim**: Pre-training on artificial instructions followed by fine-tuning on human instructions bridges the language distribution gap and improves model performance.
- **Mechanism**: The model first learns general patterns from large-scale artificial instructions with structured expressions, then adapts to the more diverse and sometimes ambiguous human instructions through fine-tuning, leveraging the complementary strengths of both data portions.
- **Core assumption**: The structural similarity between artificial and human instructions allows knowledge transfer, despite differences in expression diversity and potential ambiguity.
- **Evidence anchors**:
  - [section 5.3]: "when artificial instructions are used for warming up before training on human instructions, the performance of our method is significantly improved with over 10 IoU scores increment."
  - [section 3.5]: "Artificial instructions always exhibit complete information... However, human instructions are more diverse in expression but suffer from ambiguity and missing components."
- **Break condition**: If the distribution gap between artificial and human instructions is too large, the pre-training may not provide useful initialization and could even hinder fine-tuning.

## Foundational Learning

- **Concept: Sequence-to-sequence modeling**
  - Why needed here: Floor plan generation requires mapping variable-length language instructions to structured output sequences representing room layouts.
  - Quick check question: Can you explain how the encoder-decoder architecture handles variable-length input and output sequences in this context?

- **Concept: Transformer architecture**
  - Why needed here: The model needs to capture long-range dependencies between different room descriptions in the language instructions and maintain spatial relationships in the generated layout.
  - Quick check question: How does the self-attention mechanism in transformers help the model understand relationships between different parts of the floor plan description?

- **Concept: Diffusion models vs. autoregressive models**
  - Why needed here: Understanding why diffusion-based approaches like Imagen struggle with structured design tasks while autoregressive approaches like T2D succeed.
  - Quick check question: What are the key differences in how diffusion models and autoregressive models handle conditional generation tasks?

## Architecture Onboarding

- **Component map**: Language instructions → T5 encoder → boundary box encoder → decoder → token sequence → floor plan
- **Critical path**: Language instructions → T5 encoder → boundary box encoder → decoder → token sequence → floor plan
- **Design tradeoffs**:
  - Using T5-base vs. larger models: Better generalization vs. computational cost
  - Box discretization granularity: Precision vs. sequence length
  - Training on artificial vs. human instructions: Data quality vs. diversity
- **Failure signatures**:
  - Rooms generated outside floor plan boundaries
  - Incorrect room types or sizes
  - Missing or extra rooms
  - Inconsistent room relationships
- **First 3 experiments**:
  1. Test the model with simplified instructions containing only room types and basic locations
  2. Evaluate the impact of boundary box sequence representation by comparing with boundary-less generation
  3. Assess the importance of pre-training by comparing training from scratch vs. warm-up + fine-tuning approach

## Open Questions the Paper Calls Out
- How does the performance of language-guided floor plan generation models vary with different levels of ambiguity and noise in human instructions?
- Can the proposed Seq2Seq approach be extended to generate diverse floor plan designs while adhering to the given language instructions?
- How well do language-guided floor plan generation models generalize to unseen room types or architectural styles?
- How does the performance of language-guided floor plan generation models compare to that of human architects when given the same language instructions?

## Limitations
- The model's reliance on box-based boundary representation may struggle with complex floor plan geometries containing concave shapes or irregular features.
- The discretization of continuous coordinates into 256 discrete values could limit the precision of generated layouts.
- The evaluation metrics (IoU) primarily measure spatial overlap rather than semantic correctness or functional plausibility of the generated floor plans.

## Confidence
- **High confidence** in the dataset contribution and task formulation
- **Medium confidence** in the proposed baseline model architecture
- **Medium confidence** in the reported performance metrics

## Next Checks
1. Generate floor plans with increasingly complex boundary shapes (concave, L-shaped, U-shaped) to evaluate whether the box sequence representation can handle diverse architectural geometries without violating spatial constraints.
2. Systematically vary the discretization granularity of bounding box coordinates (e.g., 128, 256, 512 discrete values) and measure the impact on IoU scores and layout precision to determine the optimal tradeoff between accuracy and sequence length.
3. Test the pre-trained model on floor plans from other datasets (e.g., RPLAN, RPLAN+) using the same instruction format to assess whether the learned representations generalize beyond the Tell2Design distribution.