---
ver: rpa2
title: Adapting Self-Supervised Representations to Multi-Domain Setups
arxiv_id: '2309.03999'
source_url: https://arxiv.org/abs/2309.03999
tags:
- domain
- self-supervised
- domains
- learning
- representations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Self-supervised learning methods often fail to generalize across
  diverse domains, necessitating separate model training for each domain. This work
  addresses this limitation by introducing a lightweight Domain Disentanglement Module
  (DDM) that can be plugged into any self-supervised encoder.
---

# Adapting Self-Supervised Representations to Multi-Domain Setups

## Quick Facts
- arXiv ID: 2309.03999
- Source URL: https://arxiv.org/abs/2309.03999
- Authors: 
- Reference count: 40
- Key outcome: Self-supervised learning methods often fail to generalize across diverse domains, necessitating separate model training for each domain.

## Executive Summary
This work addresses the challenge of poor generalization across domains in self-supervised learning by introducing a lightweight Domain Disentanglement Module (DDM). DDM can be plugged into any self-supervised encoder to split the representation space into domain-variant and domain-invariant portions during pre-training. The method employs robust clustering to discover pseudo-domain labels for unlabeled multi-domain setups. Experimental results demonstrate significant improvements in linear probing accuracy on multiple benchmarks including PACS, DomainNet, and WILDS, showing consistent gains across various state-of-the-art self-supervised models.

## Method Summary
The Domain Disentanglement Module (DDM) is designed to enable multi-domain training with a single self-supervised encoder by splitting the representation space into domain-variant and domain-invariant portions. During pre-training, DDM uses Wasserstein distance to ensure the domain-invariant portion has no domain information while the domain-variant prefix captures domain-specific features. For unlabeled multi-domain setups, DDM employs robust clustering to discover pseudo-domain labels. The method is tested across multiple self-supervised learning frameworks including SimCLR, MoCo, BYOL, DINO, SimSiam, and Barlow Twins on datasets such as PACS, DomainNet, and WILDS.

## Key Results
- Significant improvement in linear probing accuracy on PACS benchmark: 6.1% gain
- DomainNet benchmark shows 7.4% improvement in generalization to unseen domains
- WILDS dataset demonstrates 5.9% improvement, validating effectiveness across diverse domain generalization scenarios

## Why This Works (Mechanism)

### Mechanism 1
The domain prefix is trained to be distinguishable across domains while the remaining portion is trained to be invariant to domain information. DDM splits the representation space into two parts - a domain-variant prefix and a domain-invariant remainder. The domain prefix is trained with a contrastive loss to maximize similarity within domains and minimize similarity across domains. The domain-invariant portion is trained to minimize Wasserstein distance between predicted and true domain distributions, ensuring domain information is removed from this portion. This works under the assumption that domain and content information can be effectively separated in the representation space.

### Mechanism 2
Robust clustering can discover pseudo-domain labels when true domain labels are unavailable. When domain labels are unknown, DDM uses K-Means clustering on representations to identify pseudo-domains. A robust clustering approach iteratively refines clusters by removing outlier samples that are equidistant from multiple centroids, improving cluster quality over time. This relies on the assumption that samples from the same domain will cluster together in the representation space.

### Mechanism 3
The disentangled representation structure improves generalization to unseen domains. By separating domain-variant and domain-invariant information, the domain-invariant portion becomes focused purely on content features that generalize across domains. This structure allows the model to learn representations that are less affected by domain shifts, improving performance on unseen domains. This assumes that domain-invariant representations are more generalizable than mixed representations.

## Foundational Learning

- Concept: Self-supervised learning and contrastive learning
  - Why needed here: Understanding how SimCLR, MoCo, BYOL, etc. work is essential to grasp why DDM improves them. These methods rely on creating similar representations for augmented views of the same image.
  - Quick check question: What is the core objective of contrastive learning methods like SimCLR?

- Concept: Domain generalization and domain adaptation
  - Why needed here: The paper addresses the problem of models failing to generalize across domains. Understanding the difference between domain adaptation (labeled target domain) and domain generalization (unseen target domain) is crucial.
  - Quick check question: How does domain generalization differ from domain adaptation in terms of available data?

- Concept: Wasserstein distance and optimal transport
  - Why needed here: DDM uses Wasserstein distance to ensure the domain-invariant portion has no domain information. Understanding this metric helps explain why it's effective for this purpose.
  - Quick check question: Why might Wasserstein distance be preferred over KL divergence for measuring domain invariance?

## Architecture Onboarding

- Component map: Base encoder (ViT-S or other self-supervised model) -> Domain discriminator (MLP with LeakyReLU) -> DDM module (splits representation, applies two loss terms) -> Optional: K-Means clustering for pseudo-domain discovery

- Critical path:
  1. Initialize base encoder and domain discriminator
  2. Split representation into domain prefix and invariant portion
  3. Apply self-supervised loss to full representation
  4. Apply domain-variant loss to prefix
  5. Apply domain-invariant loss to remainder
  6. Optimize using alternating gradient descent/ascent

- Design tradeoffs:
  - Size of domain prefix (24 dimensions chosen) vs. amount of domain information captured
  - Outlier threshold ε in robust clustering vs. cluster purity
  - λ weight for balancing self-supervised and DDM losses
  - Choice of base encoder architecture and self-supervised method

- Failure signatures:
  - Poor performance on training domains: domain prefix may be too small or losses unbalanced
  - No improvement on unseen domains: disentanglement may not be effective or representation space not suitable for splitting
  - Clustering fails to discover meaningful domains: domains may be too similar or outlier threshold inappropriate

- First 3 experiments:
  1. Implement DDM on SimCLR with PACS dataset, compare performance with and without DDM on training and unseen domains
  2. Test different domain prefix sizes (e.g., 12, 24, 48 dimensions) to find optimal trade-off
  3. Evaluate DDM with robust clustering on unlabeled multi-domain dataset (e.g., mixture of CIFAR-10, CIFAR-100, STL-10)

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of DDM scale with the number of domains in a multi-domain setup? The paper demonstrates DDM's effectiveness on benchmarks with varying numbers of domains but does not systematically study how performance changes as the number of domains increases.

### Open Question 2
What is the optimal value of the domain prefix length (k) in the representation space, and how does it vary across different self-supervised methods and datasets? The paper uses a fixed 24-dimensional domain prefix for all experiments without exploring sensitivity to different prefix lengths.

### Open Question 3
How does DDM perform in continual learning scenarios where new domains are introduced over time? The paper focuses on static multi-domain datasets rather than dynamic scenarios where domains are added sequentially.

## Limitations
- Method requires access to domain labels during training, which may not always be available in real-world scenarios
- Computational overhead introduced by DDM is not fully characterized
- Optimal size of domain prefix (24 dimensions) may vary across different datasets and tasks

## Confidence
- **High confidence**: The core mechanism of splitting representation space and the experimental results showing consistent improvements across multiple self-supervised methods and benchmarks
- **Medium confidence**: The effectiveness of the robust clustering approach for discovering pseudo-domain labels in unlabeled setups
- **Medium confidence**: The generalization claims to unseen domains, as the evaluation is limited to the specific datasets used in the experiments

## Next Checks
1. Test the robust clustering approach on datasets with varying degrees of domain overlap to determine its limits and identify conditions under which it fails to discover meaningful pseudo-domains
2. Systematically vary the size of the domain prefix across a wider range of values and datasets to determine if 24 dimensions is universally optimal or dataset-dependent
3. Evaluate DDM's performance when applied to vision transformers of different sizes (e.g., ViT-B, ViT-L) and with different base self-supervised methods to verify the claimed generalizability