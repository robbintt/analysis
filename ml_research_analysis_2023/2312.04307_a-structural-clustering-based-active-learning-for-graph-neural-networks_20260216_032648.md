---
ver: rpa2
title: A Structural-Clustering Based Active Learning for Graph Neural Networks
arxiv_id: '2312.04307'
source_url: https://arxiv.org/abs/2312.04307
tags:
- learning
- active
- graph
- nodes
- uni00000044
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SPA, a structural-clustering-based active
  learning method for Graph Neural Networks (GNNs). SPA combines community detection
  using the SCAN algorithm with PageRank scoring to prioritize nodes that are both
  informative and central in the graph's structure.
---

# A Structural-Clustering Based Active Learning for Graph Neural Networks

## Quick Facts
- arXiv ID: 2312.04307
- Source URL: https://arxiv.org/abs/2312.04307
- Authors: Multiple authors
- Reference count: 19
- Key outcome: SPA reduces query time from 319/397 seconds to 25 seconds on Corafull while improving accuracy

## Executive Summary
This paper introduces SPA (Structural-clustering based PageRank Active learning), a novel active learning method for Graph Neural Networks that combines community detection using the SCAN algorithm with PageRank scoring. The method identifies structurally meaningful communities in graphs and selects representative nodes with high PageRank scores within each community for labeling. SPA demonstrates superior accuracy and macro-F1 scores compared to baseline methods across multiple datasets including Citeseer, Pubmed, Corafull, WikiCS, Minesweeper, and Tolokers, while achieving significant reductions in computational complexity.

## Method Summary
SPA integrates community detection using the SCAN algorithm with PageRank scoring to prioritize nodes that are both informative and central in the graph's structure. The method first partitions the graph into meaningful communities based on structural similarity (shared neighbors normalized by geometric mean of node degrees), then computes PageRank scores within each community to identify central nodes. For each community, the node with the highest PageRank score is selected for labeling, and remaining budget is filled with globally top PageRank nodes. The approach was evaluated using 2-layer GCN and GraphSAGE models trained with Adam optimizer on standard node classification datasets.

## Key Results
- SPA achieved superior accuracy and macro-F1 scores compared to baseline methods across all tested annotation budgets
- On Corafull dataset, SPA reduced query time from 319 seconds (GraphPart) and 397 seconds (GraphPartFar) to just 25 seconds
- The method demonstrated consistent performance improvements across diverse datasets including heterophilous graphs like Minesweeper and Tolokers
- SPA showed lower computational costs compared to recent state-of-the-art models like GraphPart and GraphPartFar

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SCAN algorithm effectively partitions graph into meaningful communities that reflect both structural and feature-based similarities.
- Mechanism: SCAN uses structural similarity measure based on shared neighbors, normalized by geometric mean of node degrees. Communities are formed when similarity exceeds threshold ε and shared neighbors exceed minimum µ.
- Core assumption: Local structural patterns captured by shared neighbors are representative of meaningful node groupings.
- Evidence anchors:
  - [abstract] "SPA integrates community detection using the SCAN algorithm with the PageRank scoring method"
  - [section] "The SCAN algorithm employs two parameters, ϵ and µ, to determine community membership"
  - [corpus] Weak - corpus papers don't discuss SCAN specifically
- Break condition: If graph has very low clustering coefficient or highly random structure, SCAN may fail to find meaningful communities.

### Mechanism 2
- Claim: PageRank scores within communities identify nodes that are both locally relevant and globally important.
- Mechanism: PageRank assigns scores based on probability of random walk arrival, capturing global importance. Nodes with highest PageRank in each community are selected as representatives.
- Core assumption: Nodes with high PageRank within communities balance local specificity with global relevance.
- Evidence anchors:
  - [abstract] "SPA prioritizes nodes that are not only informative but also central in structure"
  - [section] "For each community detected by the SCAN algorithm, the node with the highest PageRank score is selected"
  - [corpus] Weak - corpus papers don't discuss PageRank in active learning context
- Break condition: If PageRank converges slowly or graph has disconnected components, centrality scores may not reflect true importance.

### Mechanism 3
- Claim: Combining community detection with PageRank reduces query time compared to partition-based methods.
- Mechanism: SCAN + PageRank approach avoids expensive clustering over entire feature space, focusing instead on structural communities.
- Core assumption: Structural communities are computationally cheaper to identify than feature-space partitions.
- Evidence anchors:
  - [abstract] "the proposed method shows a notable reduction in computational complexity compared to recent active learning approaches for GNNs"
  - [section] "When compared with recent state-of-the-art models like GraphPart and GraphPartFar, the proposed method demonstrates lower computational costs"
  - [corpus] Weak - corpus papers don't discuss computational complexity comparisons
- Break condition: If SCAN implementation is inefficient or graph is extremely large, computational advantage may disappear.

## Foundational Learning

- Concept: Graph Neural Networks and message passing
  - Why needed here: SPA is specifically designed for GNNs and relies on understanding how they aggregate neighborhood information
  - Quick check question: What happens to node representations after k layers of message passing in a GNN?

- Concept: Community detection algorithms
  - Why needed here: SCAN is the core algorithm for identifying structural communities in the graph
  - Quick check question: How does SCAN's structural similarity measure differ from modularity-based approaches?

- Concept: PageRank algorithm and random walks
  - Why needed here: PageRank is used to identify central nodes within each community
  - Quick check question: What role does the damping factor play in PageRank's random walk model?

## Architecture Onboarding

- Component map: Graph → SCAN communities → PageRank scores → Node selection → Labeled data → GNN training
- Critical path: Graph → SCAN communities → PageRank scores → Node selection → Labeled data → GNN training
- Design tradeoffs:
  - SCAN parameters ε and µ vs. community quality
  - PageRank damping factor vs. convergence speed
  - Number of communities vs. budget utilization
  - Structural vs. feature-based similarity
- Failure signatures:
  - Too many/few communities (adjust ε, µ)
  - Slow PageRank convergence (adjust damping factor)
  - Poor accuracy despite good structure (features may be more important)
  - High query time (graph too large for SCAN efficiency)
- First 3 experiments:
  1. Run SPA on Citeseer with budget=10, compare accuracy vs. Random baseline
  2. Vary ε and µ parameters on Corafull, measure impact on number of communities
  3. Measure query time on WikiCS with increasing graph size, compare to GraphPart

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of SPA degrade or adapt on graphs with extreme heterophily (e.g., community structures where nodes in the same community have different labels)?
- Basis in paper: [inferred] The paper mentions testing on heterophilous datasets (Minesweeper, Tolokers) but doesn't explicitly analyze performance degradation on highly heterophilous graphs.
- Why unresolved: The paper only mentions testing on heterophilous datasets without providing detailed analysis of performance under extreme heterophily conditions.
- What evidence would resolve it: Detailed experimental results showing SPA's performance on graphs with varying levels of heterophily, particularly extreme cases where nodes in the same community have different labels.

### Open Question 2
- Question: What is the optimal strategy for selecting the SCAN parameters ε and μ in practice, especially when the graph structure is unknown beforehand?
- Basis in paper: [explicit] The paper mentions that ε and μ are hyperparameters to balance structural learning and node selection, but doesn't provide a practical method for selecting them.
- Why unresolved: The paper acknowledges these are hyperparameters but doesn't offer guidance on how to set them in practice, especially for unknown graph structures.
- What evidence would resolve it: Empirical studies or theoretical analysis showing the relationship between ε, μ, and graph properties, along with practical guidelines for hyperparameter selection.

### Open Question 3
- Question: How does SPA's performance compare to active learning methods that use deep graph representations (e.g., contrastive learning embeddings) rather than just structural information?
- Basis in paper: [inferred] The paper focuses on structural information and doesn't compare SPA with methods using deep representations or contrastive learning.
- Why unresolved: The paper's comparison is limited to methods using structural or feature information, not those using learned deep representations.
- What evidence would resolve it: Comparative experiments between SPA and active learning methods that incorporate deep graph representations or contrastive learning embeddings.

## Limitations
- The SCAN algorithm parameters (ε and μ) are not fully specified, which could significantly impact reproducibility
- Computational complexity analysis focuses on query time but doesn't provide comprehensive runtime comparisons across all datasets and budgets
- Method's performance on graphs with different structural properties (e.g., scale-free vs. small-world networks) is not explored

## Confidence
- **High confidence**: The PageRank-based centrality scoring mechanism within communities is well-established and the accuracy improvements over baselines are consistent across multiple datasets
- **Medium confidence**: The computational efficiency claims, particularly the 25-second query time on Corafull, need independent verification given the lack of detailed implementation specifications
- **Low confidence**: The generalizability of SCAN's effectiveness across diverse graph structures remains uncertain without testing on more varied graph types

## Next Checks
1. **Parameter sensitivity analysis**: Systematically vary ε and μ parameters on Corafull to determine their impact on community quality and final accuracy
2. **Runtime benchmarking**: Measure end-to-end training time (including community detection and GNN training) across all six datasets to validate computational efficiency claims
3. **Structural robustness test**: Evaluate SPA performance on graphs with controlled structural properties (varying clustering coefficients and degree distributions) to assess its limitations