---
ver: rpa2
title: 'Future-proofing geotechnics workflows: accelerating problem-solving with large
  language models'
arxiv_id: '2312.12411'
source_url: https://arxiv.org/abs/2312.12411
tags:
- llms
- geotechnical
- data
- engineering
- site
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'A two-day workshop explored applications of large language models
  (LLMs) like ChatGPT in geotechnical engineering, bringing together 20 participants
  from academia, industry, and government sectors. Four case studies demonstrated
  LLMs'' proficiency in handling diverse tasks: multimodal data analysis for slope
  stability assessment, seismic risk microzoning, simulation parameter recommendation,
  and site similarity prediction.'
---

# Future-proofing geotechnics workflows: accelerating problem-solving with large language models

## Quick Facts
- arXiv ID: 2312.12411
- Source URL: https://arxiv.org/abs/2312.12411
- Reference count: 36
- A two-day workshop explored applications of large language models (LLMs) like ChatGPT in geotechnical engineering, bringing together 20 participants from academia, industry, and government sectors. Four case studies demonstrated LLMs' proficiency in handling diverse tasks: multimodal data analysis for slope stability assessment, seismic risk microzoning, simulation parameter recommendation, and site similarity prediction. Results showed LLMs effectively process complex, multimodal datasets and provide context-based predictions, though their probabilistic nature and need for expert oversight limit their use for final engineering decisions. The studies highlighted LLMs' potential to streamline geotechnical workflows, offering insights into more efficient, data-driven approaches in the field. This work sets a precedent for broader LLM applications in interdisciplinary engineering research and practice.

## Executive Summary
This workshop report demonstrates the application of large language models to accelerate geotechnical problem-solving across four diverse case studies. The research team explored how LLMs like ChatGPT can process multimodal data, provide context-based predictions, and support decision-making in slope stability assessment, seismic risk microzoning, simulation parameter recommendation, and site similarity prediction. The findings reveal both the potential and limitations of LLMs in geotechnical engineering, highlighting their ability to streamline workflows while emphasizing the need for expert oversight in final engineering decisions.

## Method Summary
The study employed a workshop format with 20 participants from academia, industry, and government sectors. Four case studies were conducted using ChatGPT with few-shot learning approaches. The tasks included slope stability assessment using photographs, seismic risk microzoning with HVSR data, simulation parameter recommendation for soils, and site similarity prediction. Custom prompts and examples were provided to guide the LLM's reasoning for each specialized task, with results evaluated against expert assessments and known values.

## Key Results
- LLMs effectively processed multimodal geotechnical data including images, text descriptions, and numerical measurements
- Few-shot learning enabled rapid adaptation to specialized geotechnical reasoning without full fine-tuning
- LLM predictions showed reasonable correlation with expert assessments but required validation for engineering decisions
- Uncertainty quantification through LLM outputs demonstrated potential as a decision support tool

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can bridge multimodal data interpretation in geotechnical workflows by integrating text, images, and time series into unified reasoning.
- Mechanism: Text embedding vectors capture semantic context from descriptions, while multimodal processing pipelines feed both visual and numerical inputs into the same reasoning engine.
- Core assumption: The semantic space generated by embeddings is sufficient to preserve critical distinctions between geotechnical categories (e.g., soil types, risk levels).
- Evidence anchors:
  - [abstract] "LLMs effectively process complex, multimodal datasets and provide context-based predictions."
  - [section] "Our analysis of text embeddings from GPT's descriptions showed a clear correlation between predicted collapse probabilities and principal components of the embedding vectors."
  - [corpus] Weak - no corpus evidence directly validates embedding performance for geotechnical categories.
- Break condition: If embedding dimensions collapse distinct geotechnical concepts into similar vectors, predictions lose accuracy.

### Mechanism 2
- Claim: Few-shot learning in LLMs can adapt to specialized geotechnical reasoning without full fine-tuning.
- Mechanism: Pre-prompted examples guide the model to mimic expert judgment patterns, allowing rapid domain-specific inference.
- Core assumption: The few examples provided are representative enough to capture the variability in geotechnical decision criteria.
- Evidence anchors:
  - [abstract] "LLMs' proficiency in handling a range of tasks from basic data analysis to complex, multimodal problem-solving."
  - [section] "The few-shot model showed more stable and expert-aligned risk predictions, highlighting GPT's ability in in-context learning and adjustment with minimal examples."
  - [corpus] Weak - no corpus evidence on few-shot success rates for geotechnical tasks.
- Break condition: If provided examples are too narrow or domain-specific, model predictions drift outside expert expectations.

### Mechanism 3
- Claim: LLM-driven uncertainty quantification can replace or complement traditional statistical methods in sparse geotechnical datasets.
- Mechanism: Generative outputs naturally model uncertainty through distributional sampling, exposing prediction confidence implicitly.
- Core assumption: The probabilistic nature of LLM outputs reflects true epistemic uncertainty in geotechnical predictions.
- Evidence anchors:
  - [abstract] "Their probabilistic nature and need for expert oversight limit their use for final engineering decisions."
  - [section] "GPT is a generative model, for which its output is uncertain in nature. On one hand, such feature can be used as a natural tool for uncertainty quantification."
  - [corpus] Weak - no corpus evidence of LLM uncertainty calibration for geotechnical tasks.
- Break condition: If output uncertainty is overconfident or misaligned with real-world variability, decision quality degrades.

## Foundational Learning

- Concept: Text embedding and semantic vector space construction.
  - Why needed here: Enables conversion of qualitative geotechnical descriptions into numerical features for ML integration.
  - Quick check question: Given two descriptions of slope conditions, can you generate embeddings and measure their cosine similarity?
- Concept: Few-shot learning vs fine-tuning tradeoffs.
  - Why needed here: Determines whether rapid prototyping or higher precision is needed for a given task.
  - Quick check question: If you have 5 labeled slope photos, which method would you choose to adapt the model to your dataset?
- Concept: Multimodal data fusion principles.
  - Why needed here: Critical for combining HVSR curves, sensor locations, and textual summaries into a single decision framework.
  - Quick check question: How would you align a time series image and its textual description for joint model input?

## Architecture Onboarding

- Component map:
  Input preprocessor (image + text + numerical) -> Embedding generator (text → vector) -> Multimodal reasoning engine (LLM) -> Context store (few-shot examples) -> Output interpreter (risk score + explanation)
- Critical path:
  Prompt construction → embedding generation → model inference → result post-processing → expert validation
- Design tradeoffs:
  - Few-shot vs fine-tuning: speed vs precision
  - Embedding dimensionality: richer semantic space vs computational cost
  - Multimodal vs unimodal: broader data coverage vs simpler pipeline
- Failure signatures:
  - Inconsistent outputs across trials → LLM memory contamination
  - High variance in predictions → insufficient context examples
  - Misalignment with expert labels → embedding semantic mismatch
- First 3 experiments:
  1. Generate embeddings for 10 slope descriptions and cluster by predicted risk
  2. Compare zero-shot vs few-shot performance on 6 test photos with 4 training photos
  3. Integrate HVSR image + location data and measure clustering accuracy vs expert grouping

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the context control within text embeddings be improved to focus on specific keywords relevant to geotechnical properties in soil analysis reports?
- Basis in paper: [inferred] The paper discusses the challenge of controlling the focus of context within text embeddings, particularly in geotechnical engineering where specific details can be crucial.
- Why unresolved: Current text embedding techniques may not allow precise control over which aspects of the context are emphasized, leading to incomplete or misleading interpretations in specialized fields like geotechnical engineering.
- What evidence would resolve it: Research demonstrating methods to enhance context control in text embeddings, particularly for geotechnical data analysis, with examples showing improved accuracy in property extraction from soil reports.

### Open Question 2
- Question: What are the limitations of current fine-tuning techniques for LLMs in achieving high precision in specialized geotechnical tasks?
- Basis in paper: [explicit] The paper mentions that fine-tuning LLMs for highly accurate and specialized responses in geotechnical engineering remains a complex task.
- Why unresolved: The complexity of LLM training and the vastness of their data sources make it challenging to achieve precision in outputs for specialized fields like geotechnical engineering.
- What evidence would resolve it: Studies comparing different fine-tuning approaches for LLMs in geotechnical applications, with benchmarks showing improvements in task-specific accuracy and reliability.

### Open Question 3
- Question: How can the interface between LLMs and specialized geotechnical databases be designed to ensure precise data retrieval and interpretation?
- Basis in paper: [inferred] The paper highlights the importance of effective interface design to ensure that LLMs can interact appropriately with other systems and tools for accurate data retrieval and interpretation.
- Why unresolved: Designing interfaces that allow seamless and precise interaction between LLMs and specialized databases is complex, especially when exact numerical data for soil properties is required.
- What evidence would resolve it: Development and testing of prototype interfaces between LLMs and geotechnical databases, with case studies demonstrating improved data accuracy and usability in engineering applications.

## Limitations
- The study relies heavily on few-shot learning without systematic evaluation of how prompt quality affects outcomes across tasks
- No validation of embedding semantic space preservation for geotechnical categories, risking misalignment between LLM reasoning and domain-specific requirements
- Uncertainty quantification claims remain untested against ground truth variability in sparse geotechnical datasets

## Confidence
- **High**: LLMs can process multimodal geotechnical data when properly prompted
- **Medium**: Few-shot learning provides reasonable adaptation without full fine-tuning
- **Low**: LLM uncertainty modeling meaningfully captures epistemic uncertainty in geotechnical predictions

## Next Checks
1. Test embedding cosine similarity preservation across geotechnical description pairs to verify semantic alignment
2. Run ablation studies varying prompt examples and measure prediction stability across multiple trials
3. Compare LLM-generated uncertainty distributions against statistical bootstrapping results on synthetic geotechnical datasets