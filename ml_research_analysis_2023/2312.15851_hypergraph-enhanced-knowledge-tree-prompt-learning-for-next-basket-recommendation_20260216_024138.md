---
ver: rpa2
title: Hypergraph Enhanced Knowledge Tree Prompt Learning for Next-Basket Recommendation
arxiv_id: '2312.15851'
source_url: https://arxiv.org/abs/2312.15851
tags:
- basket
- item
- items
- recommendation
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes HEKP4NBR, a hypergraph enhanced knowledge tree
  prompt learning method for next-basket recommendation. The method transforms the
  knowledge graph into prompts to help the pretrained language model encode out-of-vocabulary
  item IDs, and uses a hypergraph convolutional module to model correlations among
  multiple items.
---

# Hypergraph Enhanced Knowledge Tree Prompt Learning for Next-Basket Recommendation

## Quick Facts
- arXiv ID: 2312.15851
- Source URL: https://arxiv.org/abs/2312.15851
- Reference count: 40
- Key outcome: Achieves 22.94% improvement in F1@5 and 35.85% improvement in NDCG@5 on the Poultry dataset compared to best baseline

## Executive Summary
This paper proposes HEKP4NBR, a hypergraph enhanced knowledge tree prompt learning method for next-basket recommendation. The method transforms the knowledge graph into prompts to help the pretrained language model encode out-of-vocabulary item IDs, and uses a hypergraph convolutional module to model correlations among multiple items. Experiments on two real-world datasets show that HEKP4NBR outperforms state-of-the-art methods on multiple metrics.

## Method Summary
HEKP4NBR transforms knowledge graphs into natural language prompts (Knowledge Tree Prompts) to help PLMs encode OOV item IDs. The method constructs a knowledge tree via beam search in an augmented KG, converts it to natural language strings using a fixed template, and concatenates these with Masked User Prompts. It also employs hypergraph convolution to model higher-order item dependencies, using an MoE model to compute multi-aspect similarities and build hyperedges. A frequency-based gating mechanism dynamically weights items according to user interaction history.

## Key Results
- Achieves 22.94% improvement in F1@5 and 35.85% improvement in NDCG@5 on Poultry dataset
- Outperforms state-of-the-art methods on multiple metrics across two real-world datasets
- Demonstrates effectiveness of knowledge tree prompts in mitigating OOV item issues

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Knowledge Tree Prompt (KTP) mitigates Out-Of-Vocabulary (OOV) item issues by transforming structured knowledge graph into natural language prompts.
- Mechanism: The model constructs a knowledge tree by performing beam search in an augmented KG starting from the user's basket sequence entity. It then traverses this tree breadth-first to generate a triplet sequence, which is converted into natural language strings using a fixed template ("The r of h is t"). This sequence is concatenated into KTP and fed to the PLM alongside the Masked User Prompt (MUP).
- Core assumption: PLMs can better encode item semantics when provided as natural language descriptions rather than as opaque IDs or tokens.
- Evidence anchors:
  - [abstract] "transforms the knowledge graph (KG) into prompts, namely Knowledge Tree Prompt (KTP), to help PLM encode the OOV item IDs"
  - [section 3.3.2] "we proposed to readout KTP from KG by constructing a knowledge tree based on basket sequence S_u"
  - [corpus] "Found 25 related papers... Average neighbor FMR=0.385" (weak signal, only generic KG-Prompt mentions)

### Mechanism 2
- Claim: Hypergraph convolution models higher-order item dependencies beyond pairwise relations.
- Mechanism: The model first encodes item embeddings via GCN on a basket-item bipartite graph. It then uses an MoE model to compute pairwise similarities across multiple aspects, builds a hypergraph where hyperedges connect top-k similar items, and applies hypergraph convolution to aggregate multi-item interactions.
- Core assumption: Real-world item dependencies (e.g., complementary medicines) are inherently higher-order and cannot be captured by simple graph edges.
- Evidence anchors:
  - [abstract] "employs an MoE model to measure item similarity from multiple aspects and builds a hypergraph based on item similarity"
  - [section 3.4.2] "build a hypergraph based on item similarities measured by an MoE model from multiple aspects and then employ convolution on the hypergraph to model correlations among multiple items"
  - [corpus] "Basket-Enhanced Heterogenous Hypergraph..." (relevant but not directly cited in paper)

### Mechanism 3
- Claim: Frequency-based gating dynamically weights items according to user interaction history.
- Mechanism: A gating vector α_u is computed from normalized interaction frequencies γ_u, modulating the influence of refined item embeddings v'_i when matched against the basket sequence embedding v_S_u. This biases predictions toward frequently interacted items while still allowing exploration.
- Core assumption: Users have stable preferences that manifest as repeated purchases, and this can be leveraged to prioritize recommendation scores.
- Evidence anchors:
  - [section 3.5] "a gating mechanism based on user's interaction frequency to dynamically match the basket sequence to each item"
  - [section 3.5] "the probability of item i containing in the next basket... computed as Equation 13" (shows the gating formula)
  - [corpus] "Repeat-bias-aware Optimization..." (related but not directly used in paper)

## Foundational Learning

- Concept: Prompt learning paradigm in PLMs
  - Why needed here: The paper transforms the NBR task into a mask prediction task using manually designed templates, enabling transfer of PLM's pre-training capabilities to recommendation.
  - Quick check question: How does the MUP template convert a basket sequence into a prompt that the PLM can process?

- Concept: Hypergraph representation and convolution
  - Why needed here: Hypergraphs allow modeling of multi-item interactions (e.g., co-purchased sets) that cannot be expressed as simple pairwise edges, enabling richer correlation modeling.
  - Quick check question: What is the difference between a standard graph adjacency matrix and the hypergraph adjacency matrix M defined in the paper?

- Concept: Mixture-of-Experts (MoE) for multi-aspect similarity
  - Why needed here: MoE learns item similarities from multiple independent "expert" subnetworks, capturing different semantic aspects (e.g., brand, category, function) before aggregation.
  - Quick check question: In Equation 7-8, how is the final similarity π_ij computed from the N expert outputs?

## Architecture Onboarding

- Component map:
  PLM backbone (T5-small) -> encodes MUP+KTP -> outputs sequence embedding v_S_u -> GCN layers on basket-item bipartite graph -> initial item embeddings v_i -> MoE model -> similarity matrix Π -> hypergraph construction -> hypergraph convolution -> refined item embeddings v'_i -> Frequency-based gating module -> dynamic matching -> recommendation scores ˆy_S_u,i

- Critical path:
  1. Build MUP and KTP from user's basket sequence and KG
  2. PLM encodes them -> v_S_u
  3. GCN -> initial item embeddings
  4. MoE -> similarity matrix -> hypergraph -> hypergraph convolution -> v'_i
  5. Frequency-based gating matches v_S_u to v'_i -> scores
  6. Loss computation and backprop

- Design tradeoffs:
  - KTP vs direct KG embedding: KTP preserves structure but is token-length limited; direct embedding can be noisier but more scalable.
  - Hypergraph vs pairwise GCN: Hypergraph captures multi-item sets but adds complexity; GCN is simpler but may miss higher-order patterns.
  - Frequency gating vs pure similarity: Gating biases toward known items (good for stability) but may suppress novel recommendations.

- Failure signatures:
  - PLM fails to attend to [MASK] tokens -> likely KTP/MUP template issue or token limit exceeded
  - Hypergraph degenerates to star topology -> MoE similarity scores too peaked or k too large
  - Frequency gating collapses scores -> γ_u is nearly uniform or cold-start

- First 3 experiments:
  1. Ablation: Remove KTP and feed only MUP -> verify OOV mitigation effect
  2. Ablation: Replace hypergraph convolution with additional GCN layers -> compare multi-item vs pairwise modeling
  3. Hyperparameter sweep: Vary maximum basket sequence length (3,5,10,15,20) while keeping PLM input fixed -> observe tradeoff between history depth and KTP richness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the proposed hypergraph convolutional module be extended to capture even higher-order item dependencies beyond triadic relations?
- Basis in paper: [explicit] The paper mentions that existing methods only model point-to-point binary item relations while real-world item dependencies are often triadic or higher order. They propose a hypergraph convolutional module to model correlations among multiple items.
- Why unresolved: The paper does not explore the limits of their hypergraph approach in capturing higher-order dependencies or compare it to other methods for modeling complex item relationships.
- What evidence would resolve it: Experiments comparing the proposed method's ability to capture higher-order dependencies against alternative approaches, such as hypergraph neural networks with more complex hyperedge definitions or tensor factorization methods.

### Open Question 2
- Question: What is the impact of incorporating additional types of side information beyond knowledge graphs, such as user reviews or item attributes, on the performance of HEKP4NBR?
- Basis in paper: [inferred] The paper incorporates knowledge graphs as side information to alleviate data sparsity and improve item representations. However, it does not explore the potential benefits of incorporating other types of side information.
- Why unresolved: The paper focuses solely on knowledge graphs as side information and does not investigate the impact of incorporating other types of information that could potentially improve recommendation performance.
- What evidence would resolve it: Experiments incorporating different types of side information, such as user reviews, item attributes, or social network data, and comparing their impact on the performance of HEKP4NBR against the baseline model.

### Open Question 3
- Question: How does the performance of HEKP4NBR vary across different recommendation scenarios, such as long-tail items, cold-start users, or different levels of data sparsity?
- Basis in paper: [explicit] The paper mentions that data sparsity is a common issue in next-basket recommendation and that their method aims to alleviate this issue by incorporating knowledge graphs and hypergraph convolutional modules.
- Why unresolved: The paper does not provide a detailed analysis of the performance of HEKP4NBR across different recommendation scenarios or investigate how the proposed method handles challenges such as long-tail items, cold-start users, or varying levels of data sparsity.
- What evidence would resolve it: Experiments evaluating the performance of HEKP4NBR across different recommendation scenarios, such as long-tail items, cold-start users, or different levels of data sparsity, and comparing it to baseline methods. Additionally, analyzing the impact of the proposed components on handling these specific challenges.

## Limitations
- Heavy reliance on knowledge graph quality and coverage; performance degrades with sparse or irrelevant KG
- Hypergraph construction depends on MoE similarity accuracy; noisy similarities lead to ineffective correlation modeling
- Frequency-based gating may suppress novel recommendations and struggle with cold-start scenarios

## Confidence
- KTP mitigating OOV issues: High confidence
- Hypergraph modeling higher-order dependencies: Medium confidence
- Frequency gating improving recommendation accuracy: Medium confidence

## Next Checks
1. Ablation on KTP quality: Remove KTP entirely and compare performance on in-vocabulary vs out-of-vocabulary items to quantify the actual OOV mitigation effect.
2. Hypergraph structure analysis: Visualize and compare the hypergraph connectivity patterns (e.g., edge density, hyperedge sizes) against standard bipartite graph to verify that higher-order correlations are actually being captured.
3. Frequency gating robustness test: Simulate cold-start scenarios by masking frequent items and measuring how quickly the gating mechanism recovers prediction accuracy as interaction history accumulates.