---
ver: rpa2
title: Learning to Correct Noisy Labels for Fine-Grained Entity Typing via Co-Prediction
  Prompt Tuning
arxiv_id: '2310.14596'
source_url: https://arxiv.org/abs/2310.14596
tags:
- labels
- uni00000013
- training
- noise
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of noisy labels in fine-grained
  entity typing (FET), where current methods rely on estimating noise distribution
  to identify noisy labels but are confused by diverse noise distribution deviation.
  The authors propose a novel noise correction method for FET using the co-prediction
  prompt-tuning technique, which leverages multiple prediction results to identify
  and correct noisy labels.
---

# Learning to Correct Noisy Labels for Fine-Grained Entity Typing via Co-Prediction Prompt Tuning

## Quick Facts
- arXiv ID: 2310.14596
- Source URL: https://arxiv.org/abs/2310.14596
- Reference count: 17
- Key outcome: A novel noise correction method for fine-grained entity typing using co-prediction prompt tuning, which leverages multiple prediction results to identify and correct noisy labels.

## Executive Summary
This paper addresses the challenge of noisy labels in fine-grained entity typing (FET) by proposing a novel noise correction method using co-prediction prompt tuning. The approach integrates prediction results to recall labeled labels and utilizes a differentiated margin to identify inaccurate labels. The method also designs an optimization objective concerning divergent co-predictions during fine-tuning, ensuring the model captures sufficient information and maintains robustness in noise identification. Experimental results on three widely-used FET datasets demonstrate that the noise correction approach significantly enhances the quality of various types of training samples, including those annotated using distant supervision, ChatGPT, and crowdsourcing.

## Method Summary
The method uses a co-prediction prompt with two mask tokens ([PMASK] and [NMASK]) that are trained to focus on different predictive abilities. When trained on noisy data, one mask may fit the noise before the other, leading to divergent predictions on noisy labels. The loss function is adjusted to downweight labels with divergent co-predictions, preventing the model from overfitting to noisy labels. The divergence score (absolute difference between the prediction scores of [PMASK] and [NMASK]) is used to identify and eliminate inaccurate labels. The method is evaluated on three FET datasets (OntoNotes, WiKi, Ultra-Fine) with various types of noisy training samples.

## Key Results
- The noise correction approach significantly enhances the quality of various types of training samples, including those annotated using distant supervision, ChatGPT, and crowdsourcing.
- Experimental results on three widely-used FET datasets demonstrate the effectiveness of the proposed method in improving strict accuracy, macro F1, and micro F1 scores.
- The method shows robustness in noise identification and maintains good performance even when dealing with diverse noise distribution deviation.

## Why This Works (Mechanism)

### Mechanism 1: Divergent Co-Prediction for Noise Detection
- Claim: Using two mask tokens with different predictive focuses allows the model to generate divergent predictions on noisy labels, enabling their identification.
- Mechanism: The co-prediction prompt contains [PMASK] and [NMASK] tokens that are trained to focus on different predictive abilities. When trained on noisy data, one mask may fit the noise before the other, leading to divergent predictions on noisy labels.
- Core assumption: The "memory effect" (Arpit et al., 2017) holds - deep models tend to memorize clean labels before fitting to noisy labels when trained on data with noise.

### Mechanism 2: Loss Adjustment for Noise Robustness
- Claim: Adjusting the loss function to downweight labels with divergent co-predictions helps the model maintain robustness in noise identification.
- Mechanism: The loss function is adjusted to give less weight to labels with divergent co-predictions during training. This prevents the model from overfitting to noisy labels too quickly.
- Core assumption: Labels with divergent co-predictions are more likely to be noisy.

### Mechanism 3: Divergent Margin for Inaccurate Label Elimination
- Claim: Measuring the absolute difference in co-prediction scores between the two masks allows for the identification and elimination of inaccurate labels.
- Mechanism: The divergence score δy for each label y is calculated as the absolute difference between the prediction scores of [PMASK] and [NMASK]. Labels with δy greater than a threshold ϵ are classified as inaccurate and removed.
- Core assumption: Inaccurate labels are more likely to have divergent co-prediction scores.

## Foundational Learning

- Concept: Fine-grained entity typing (FET)
  - Why needed here: The paper focuses on improving FET by addressing the noisy label problem in training data.
  - Quick check question: What is the difference between coarse-grained and fine-grained entity typing?

- Concept: Distant supervision and weak supervision
  - Why needed here: The paper deals with training data annotated using distant supervision (OntoNotes, WiKi) and ChatGPT (weak supervision).
  - Quick check question: What are the advantages and disadvantages of distant supervision compared to manual annotation?

- Concept: Noise-robust learning
  - Why needed here: The paper proposes a method to correct noisy labels in FET, which is a form of noise-robust learning.
  - Quick check question: What are some common techniques used in noise-robust learning?

## Architecture Onboarding

- Component map: Co-prediction prompt ([PMASK], [NMASK]) -> Pre-trained masked language model (BERT-base) -> Loss adjustment mechanism -> Divergent margin-based label correction

- Critical path:
  1. Fine-tune BERT-base with co-prediction prompt on noisy training data
  2. Adjust loss function to downweight labels with divergent co-predictions
  3. Generate co-prediction results for training data
  4. Identify and eliminate inaccurate labels using divergent margin
  5. Recall unlabeled labels by integrating co-prediction results

- Design tradeoffs:
  - Number of mask tokens: More tokens could provide more diverse predictions but increase computational cost
  - Loss adjustment strategy: Different strategies may be needed for different types of noise
  - Divergent margin threshold: Needs to be tuned for different datasets and noise levels

- Failure signatures:
  - Model performance not improving after noise correction
  - Too many clean labels being incorrectly removed
  - Too few noisy labels being identified and corrected

- First 3 experiments:
  1. Fine-tune BERT-base with co-prediction prompt on OntoNotes training data, evaluate on test set
  2. Apply noise correction to OntoNotes training data, fine-tune BERT-base on corrected data, evaluate on test set
  3. Repeat experiment 2 with different loss adjustment strategies and divergent margin thresholds to find optimal settings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the proposed noise correction method vary with different pre-trained language models, such as RoBERTa or T5?
- Basis in paper: [inferred] The paper uses BERT-base as the backbone for the co-prediction model, but does not explore the performance with other pre-trained language models.
- Why unresolved: The paper focuses on evaluating the effectiveness of the proposed method using BERT-base, and does not provide a comparative analysis with other pre-trained language models.
- What evidence would resolve it: Conducting experiments using different pre-trained language models (e.g., RoBERTa, T5) and comparing their performance with the proposed method using BERT-base would provide insights into the impact of the choice of pre-trained language model on the noise correction method's effectiveness.

### Open Question 2
- Question: How does the proposed noise correction method perform on datasets with different levels of label noise, such as those with higher or lower noise rates?
- Basis in paper: [inferred] The paper evaluates the method on three datasets with varying levels of label noise, but does not explicitly analyze the performance across different noise levels.
- Why unresolved: The paper provides a general evaluation of the method's effectiveness on the three datasets, but does not delve into the specific impact of different noise levels on the method's performance.
- What evidence would resolve it: Conducting experiments on datasets with varying levels of label noise (e.g., high, medium, low) and analyzing the method's performance across these noise levels would provide insights into the method's robustness and adaptability to different noise scenarios.

### Open Question 3
- Question: How does the proposed noise correction method compare to other noise correction techniques in terms of computational efficiency and scalability?
- Basis in paper: [inferred] The paper presents the proposed method as straightforward and effective, but does not provide a detailed comparison with other noise correction techniques in terms of computational efficiency and scalability.
- Why unresolved: The paper focuses on demonstrating the effectiveness of the proposed method, but does not explore its efficiency and scalability compared to other noise correction techniques.
- What evidence would resolve it: Conducting a comparative analysis of the proposed method with other noise correction techniques in terms of computational efficiency (e.g., training time, memory usage) and scalability (e.g., performance on larger datasets) would provide insights into the method's practical applicability and potential limitations.

## Limitations

- The effectiveness of the divergent co-prediction mechanism heavily depends on the "memory effect" assumption, which may not hold uniformly across different model architectures or noise distributions.
- The optimal values for hyper-parameters (γ for loss adjustment and ϵ for divergent margin) are not theoretically derived but empirically tuned, potentially limiting generalizability.
- The method's performance on real-world noisy datasets may differ from synthetic noise experiments due to unknown noise patterns.

## Confidence

- High Confidence: The core mechanism of using co-prediction divergence for noise detection is technically sound and well-supported by experimental results
- Medium Confidence: The loss adjustment strategy and its impact on noise robustness requires further validation across diverse noise patterns
- Medium Confidence: The effectiveness of recalling unlabeled labels through co-prediction integration needs more empirical verification

## Next Checks

1. Cross-dataset generalization test: Apply the method to additional FET datasets with different noise patterns (e.g., different distant supervision sources or annotation schemes) to validate robustness beyond the three studied datasets.

2. Ablation study on hyper-parameters: Systematically vary γ (loss weight) and ϵ (divergent margin threshold) across a wider range to establish more robust guidelines for hyper-parameter selection and understand their sensitivity.

3. Comparison with alternative noise detection methods: Implement and compare against other state-of-the-art noisy label detection techniques (e.g., small-loss trick, co-teaching) under identical experimental conditions to better contextualize the proposed method's advantages.