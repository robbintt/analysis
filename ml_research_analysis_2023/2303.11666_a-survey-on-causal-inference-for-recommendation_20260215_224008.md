---
ver: rpa2
title: A Survey on Causal Inference for Recommendation
arxiv_id: '2303.11666'
source_url: https://arxiv.org/abs/2303.11666
tags:
- causal
- recommendation
- data
- recommender
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey systematically reviews causal inference methods for
  recommendation systems, addressing the problem of biased data and inaccurate effect
  estimation in RS. It categorizes approaches into three frameworks: Potential Outcome,
  Structural Causal Model, and general counterfactuals.'
---

# A Survey on Causal Inference for Recommendation

## Quick Facts
- arXiv ID: 2303.11666
- Source URL: https://arxiv.org/abs/2303.11666
- Reference count: 40
- One-line primary result: Comprehensive taxonomy of over 120 causal inference methods for recommendation systems, organized by theoretical framework and application

## Executive Summary
This survey provides the first comprehensive review of causal inference methods applied to recommendation systems, systematically organizing over 120 papers into a taxonomy based on causal theory frameworks. It addresses the fundamental problem of biased observational data in recommendation systems and presents methods for debiasing, policy evaluation, and counterfactual reasoning. The paper bridges causal inference theory with practical recommendation challenges, offering guidance for researchers and practitioners navigating this emerging intersection of fields.

## Method Summary
The survey introduces fundamental causal inference concepts and categorizes methods based on the causal framework employed: Potential Outcome framework with propensity score strategies and causal effect estimation, Structural Causal Model framework with collider, mediator, and confounder structures, and general counterfactuals for domain adaptation, data augmentation, fairness, and explanation. It systematically analyzes technical details of how existing methods apply causal inference to address specific recommender issues like selection bias, confounding, and missing data, while highlighting future research directions including transfer learning, out-of-distribution recommendation, and dynamic systems with feedback loops.

## Key Results
- Comprehensive taxonomy of over 120 papers organized by three major causal frameworks (PO, SCM, general counterfactuals)
- Detailed analysis of methods for handling selection bias, confounding, and missing data in recommendation contexts
- Identification of future research directions including transfer learning, OOD recommendation, and dynamic systems with feedback loops
- Systematic categorization of approaches by both theoretical framework and practical application perspective

## Why This Works (Mechanism)

### Mechanism 1
Categorizing causal recommendation methods by causal framework provides more unified guidance than issue-based taxonomies. Different causal frameworks (PO, SCM, general counterfactuals) impose different theoretical assumptions and technical constraints. Grouping methods by framework helps practitioners understand what assumptions are required, what methods are compatible, and what limitations exist. Core assumption: Causal framework determines the theoretical properties and practical applicability of recommendation methods.

### Mechanism 2
Propensity score methods enable unbiased offline evaluation and learning in recommendation systems. Inverse propensity scoring reweights observed data to simulate random assignment, allowing causal effect estimation from biased observational data. This enables policy evaluation and learning without expensive online experiments. Core assumption: The unconfoundedness assumption holds - all confounders are observed and included in the propensity score estimation.

### Mechanism 3
SCM-based methods with causal graphs can handle unobserved confounding by modeling known causal structures. By explicitly modeling causal relationships, SCM approaches can use techniques like back-door adjustment, front-door adjustment, and instrumental variables to estimate causal effects even when some confounders are unobserved. Core assumption: The assumed causal graph structure is correct and complete enough to enable valid causal identification.

## Foundational Learning

- **Concept: Counterfactual reasoning**
  - Why needed here: Understanding counterfactuals is essential for evaluating what would happen under different recommendation policies, which is central to causal inference in recommendation systems.
  - Quick check question: What is the difference between Pr(Y=1|T=1) and Pr(Y=1|do(T=1)) in recommendation contexts?

- **Concept: Confounding bias**
  - Why needed here: Confounding bias is the primary threat to valid causal inference in recommendation systems, arising when factors affect both treatment (recommendation) and outcome (user behavior).
  - Quick check question: How can popularity bias in recommendation systems create confounding bias?

- **Concept: Propensity score estimation**
  - Why needed here: Propensity scores are the foundation for many causal inference methods in recommendation, enabling unbiased estimation from biased observational data.
  - Quick check question: What assumptions must hold for inverse propensity scoring to produce unbiased estimates?

## Architecture Onboarding

- **Component map**: Potential Outcome framework (propensity score strategies, causal effect estimation) → Structural Causal Model framework (collider, mediator, confounder structures) → General counterfactuals (domain adaptation, data augmentation, fairness, explanation)
- **Critical path**: Understanding the theoretical framework (PO vs SCM vs general counterfactuals) → Identifying the recommendation problem type → Selecting appropriate causal inference methods → Implementing with consideration for assumptions and limitations
- **Design tradeoffs**: PO methods are more flexible but require strong ignorability assumptions, while SCM methods provide more structure but require correct causal graphs. General counterfactual methods offer practical solutions but may lack theoretical guarantees.
- **Failure signatures**: High variance in propensity score estimates, violation of causal assumptions leading to biased estimates, incorrect causal graph structures leading to invalid identification, and mismatch between theoretical framework and practical recommendation problem.
- **First 3 experiments**:
  1. Implement a simple inverse propensity score estimator for a simulated recommendation dataset with known confounding structure.
  2. Compare PO-based and SCM-based approaches on a recommendation problem with observable confounders.
  3. Evaluate the impact of violating positivity assumption on causal effect estimates in a controlled simulation.

## Open Questions the Paper Calls Out

### Open Question 1
How can we effectively estimate the impact of violations of causal assumptions (like positivity and unconfoundedness) on recommendation accuracy, given that even small accuracy differences can lead to significant revenue changes? The paper discusses the importance of causal assumptions but does not provide a concrete method for quantifying the impact of these violations on recommendation performance.

### Open Question 2
How can causal inference be effectively integrated with transfer learning and out-of-distribution (OOD) recommendation to improve robustness and generalization in scenarios with data sparsity or domain shifts? While the paper proposes the idea of using causal inference for transfer learning and OOD recommendation, it does not provide specific methods or frameworks for achieving this integration.

### Open Question 3
How can feedback loops and dynamic updates in modern recommender systems be incorporated into causal inference models to accurately capture the iterative data collection process and mitigate issues like the Matthew effect and bias amplification? The paper highlights the need to incorporate feedback loops but does not provide specific methods for modeling these loops within causal inference models.

## Limitations

- Limited empirical evidence comparing the practical effectiveness of different causal inference approaches in real recommendation systems
- Many claims about method superiority are supported primarily by theoretical arguments rather than comparative experimental results
- Specific implementation details and open-source resources for representative methods are not yet available

## Confidence

- Theoretical framework taxonomy: High
- Method effectiveness claims: Medium
- Future research direction predictions: Low-Medium

## Next Checks

1. **Empirical comparison**: Implement and compare PO-based and SCM-based methods on a real-world recommendation dataset with known confounding structure to validate the practical advantages of different causal frameworks.

2. **Assumption sensitivity analysis**: Systematically test how violations of key causal assumptions (unconfoundedness, positivity, correct causal graph structure) affect the performance of different causal inference methods in recommendation contexts.

3. **Reproducibility validation**: Replicate the survey's taxonomy and method categorization independently using a different selection of papers to verify the robustness of the proposed classification scheme.