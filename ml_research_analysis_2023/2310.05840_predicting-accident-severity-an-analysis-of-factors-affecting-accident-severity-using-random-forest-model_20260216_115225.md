---
ver: rpa2
title: 'Predicting Accident Severity: An Analysis Of Factors Affecting Accident Severity
  Using Random Forest Model'
arxiv_id: '2310.05840'
source_url: https://arxiv.org/abs/2310.05840
tags:
- severity
- accident
- random
- forest
- accidents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the Random Forest machine learning algorithm
  for predicting accident severity using accident records from a large metropolitan
  area. The model achieves over 80% accuracy, with an Area Under the Curve of 80%,
  recall of 79.2%, precision of 97.1%, and F1 score of 87.3%.
---

# Predicting Accident Severity: An Analysis Of Factors Affecting Accident Severity Using Random Forest Model

## Quick Facts
- arXiv ID: 2310.05840
- Source URL: https://arxiv.org/abs/2310.05840
- Reference count: 26
- Primary result: Random Forest achieves 80%+ accuracy and 87.3% F1 score in predicting accident severity

## Executive Summary
This study applies Random Forest machine learning to predict accident severity using weather and road condition data from California accident records. The model achieves over 80% accuracy with strong precision (97.1%) and recall (79.2%) metrics. Key environmental factors identified include wind speed, pressure, humidity, visibility, clear conditions, and cloud cover. The Random Forest approach outperforms Decision Trees, demonstrating its effectiveness for traffic safety applications and potential to guide preventive measures.

## Method Summary
The study uses the Kaggle US Accidents dataset (2.8M+ records) filtered to California records, with 47 original features reduced through preprocessing. Data is split 67/33 for training and testing, with class imbalance addressed through over/under sampling. A Random Forest classifier with 500 trees is trained using optimized hyperparameters and evaluated against accuracy, AUC, precision, recall, and F1 score metrics. Feature importance is extracted via Mean Decrease Gini to identify key predictors of accident severity.

## Key Results
- Random Forest achieves 81.2% accuracy versus Decision Tree's 78.6%
- Model demonstrates strong precision (97.1%) and recall (79.2%) for severe accident prediction
- Top six predictive variables: wind speed, pressure, humidity, visibility, clear conditions, and cloud cover

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Random Forest outperforms Decision Trees by aggregating many trees to reduce overfitting and capture nonlinear interactions among weather and road condition variables
- Mechanism: Each tree is trained on bootstrap samples with random feature subsets; votes are averaged to handle complex, non-linear relationships between variables like wind speed, humidity, and visibility
- Core assumption: Accident severity depends on nonlinear, high-dimensional interactions among environmental and infrastructural features
- Evidence anchors:
  - [abstract] Random Forest outperforms Decision Tree in accuracy, precision, and F1 score
  - [section] Table 6 shows Random Forest achieving 0.812 accuracy vs Decision Tree's 0.786
- Break condition: If key environmental variables are removed or dataset is extremely small, the Random Forest advantage may diminish

### Mechanism 2
- Claim: Feature importance via Mean Decrease Gini correctly identifies most influential predictors
- Mechanism: Mean Decrease Gini quantifies how much each feature reduces impurity across all trees; higher values indicate stronger predictive power
- Core assumption: Gini importance reliably proxies real-world impact of variables on accident severity
- Evidence anchors:
  - [section] Top six variables identified as 'Wind_Speed', 'Pressure', 'Humidity', 'Clear', 'Visibility', 'Cloud' via Mean Decrease Gini
  - [corpus] Random Forest importance metrics are widely validated in similar domains
- Break condition: If dataset is imbalanced or contains correlated features, Gini importance may over/under-estimate variables' influence

### Mechanism 3
- Claim: Class imbalance handling improves identification of severe accidents without sacrificing precision
- Mechanism: Resampling techniques adjust severe vs. non-severe class distribution so classifier isn't biased toward majority class
- Core assumption: Original 90.7% non-severe vs. 9.3% severe distribution skews predictions unless corrected
- Evidence anchors:
  - [section] "existence of unbalanced classification problem... Over and Under sampling approach will be adopted"
  - [corpus] Resampling is standard practice for imbalanced classification problems
- Break condition: If resampling is done incorrectly, may lead to overfitting and poor generalization

## Foundational Learning

- Concept: Random Forest ensemble learning
  - Why needed here: To aggregate predictions from multiple decision trees and reduce variance with complex weather-road interactions
  - Quick check question: How does bootstrap aggregating in Random Forest help reduce overfitting compared to a single decision tree?

- Concept: Mean Decrease Gini importance metric
  - Why needed here: To rank features by their contribution to reducing classification error, guiding domain experts
  - Quick check question: What does a high Mean Decrease Gini value indicate about a feature's role in the model?

- Concept: Handling class imbalance in classification
  - Why needed here: To ensure model can accurately predict minority class (severe accidents) without being overwhelmed by majority class
  - Quick check question: What is the effect of class imbalance on recall and precision, and how can resampling address it?

## Architecture Onboarding

- Component map: Data ingestion -> Preprocessing -> Train/test split -> Random Forest training -> Evaluation -> Feature importance extraction -> Model comparison
- Critical path: 1) Clean and prepare data, 2) Partition data into training and test sets, 3) Train Random Forest with optimized hyperparameters, 4) Evaluate using multiple metrics, 5) Extract and interpret feature importance
- Design tradeoffs:
  - Random Forest provides robustness but is less interpretable than single tree; feature importance mitigates this
  - Imbalanced classes require resampling, which may introduce synthetic data and risk overfitting
  - High-dimensional weather data increases model complexity; careful feature selection is essential
- Failure signatures:
  - Low recall despite high accuracy suggests class imbalance not fully addressed
  - Overfitting indicated by large gap between training and test performance
  - Unstable feature importance rankings may indicate multicollinearity or insufficient data
- First 3 experiments:
  1. Train baseline Decision Tree model and compare accuracy, precision, recall, and F1 score
  2. Apply SMOTE or random oversampling to training set and retrain Random Forest; compare recall and F1
  3. Remove top feature (e.g., wind speed) and retrain; observe impact on Mean Decrease Gini rankings and overall performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Random Forest model's performance vary across different states or regions in the US?
- Basis in paper: [inferred] Study limited to California State only, no comparison across different states or regions
- Why unresolved: Authors did not explore model's performance in other states or regions
- What evidence would resolve it: Applying model to accident data from other states or regions and comparing performance metrics across locations

### Open Question 2
- Question: How does Random Forest model perform when incorporating additional variables not included in this study?
- Basis in paper: [inferred] Study identifies top six important variables but does not explore impact of other excluded variables
- Why unresolved: Limited to variables available in dataset; authors did not investigate potential benefits of additional data sources
- What evidence would resolve it: Collecting and analyzing accident data with additional variables (road infrastructure, driver behavior) and evaluating model performance with expanded dataset

### Open Question 3
- Question: How does Random Forest model's performance compare to other ensemble methods like gradient boosting or stacking?
- Basis in paper: [explicit] Paper mentions other studies have explored ensemble methods but does not provide direct comparison with Random Forest
- Why unresolved: Study focuses on Random Forest model and does not compare its performance to other ensemble methods
- What evidence would resolve it: Implementing and evaluating performance of other ensemble methods using same dataset and comparing results with Random Forest model

## Limitations
- Limited to California data, restricting generalizability to other regions
- Unclear preprocessing details for Wind_Direction restructuring and weather condition variables
- Class imbalance handling mentioned but not fully specified, raising overfitting concerns

## Confidence
- High confidence in model's overall predictive capability (81.2% accuracy, 87.3% F1 score)
- Medium confidence in specific mechanism attributions and generalizability claims
- Medium confidence in feature importance rankings due to potential multicollinearity

## Next Checks
1. Conduct k-fold cross-validation to assess model stability and generalization beyond single train/test split
2. Perform ablation studies removing top features to quantify their individual contribution to model performance
3. Test model on accident data from different state or country to evaluate geographic generalizability and identify regional variations in feature importance