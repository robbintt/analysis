---
ver: rpa2
title: From Fake to Hyperpartisan News Detection Using Domain Adaptation
arxiv_id: '2308.02185'
source_url: https://arxiv.org/abs/2308.02185
tags:
- news
- domain
- fake
- source
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses unsupervised domain adaptation for fake and
  hyperpartisan news detection. It proposes several methods: (1) standard UDA with
  adversarial domain discrimination, (2) cluster alignment with a teacher (CAT) using
  pseudo-labels from an ensemble, and (3) cross-domain contrastive learning (CDCL)
  that minimizes distances between same-category features across domains.'
---

# From Fake to Hyperpartisan News Detection Using Domain Adaptation

## Quick Facts
- arXiv ID: 2308.02185
- Source URL: https://arxiv.org/abs/2308.02185
- Authors: 
- Reference count: 40
- Primary result: CDCL outperforms UDA and CAT for fake to hyperpartisan news detection, achieving 63.9-64.4% accuracy on Hyperpartisan-L dataset with data augmentation.

## Executive Summary
This paper addresses unsupervised domain adaptation for fake and hyperpartisan news detection by proposing several methods: standard UDA with adversarial domain discrimination, cluster alignment with a teacher (CAT) using pseudo-labels from an ensemble, and cross-domain contrastive learning (CDCL) that minimizes distances between same-category features across domains. The authors also introduce clustering and topic modeling to generate domain labels for adaptation. Experiments on datasets (ISOT, BuzzFeed, Hyperpartisan) show that CDCL outperforms UDA and CAT, with data augmentation further improving results.

## Method Summary
The paper proposes three main unsupervised domain adaptation methods for fake and hyperpartisan news detection: (1) UDA with adversarial domain discrimination, (2) CAT using pseudo-labels from an ensemble, and (3) CDCL that minimizes distances between same-category features across domains. Additionally, the authors introduce clustering and topic modeling to generate domain labels for adaptation. They evaluate these methods on ISOT, BuzzFeed, and Hyperpartisan datasets using RoBERTa as the base model, with data augmentation techniques including TF-IDF replacement and GPT-2 text generation.

## Key Results
- CDCL outperforms UDA and CAT on Hyperpartisan-L dataset
- Data augmentation via TF-IDF replacement or GPT-2 further improves results
- Accuracy on Hyperpartisan-L dataset reaches 63.9-64.4% with CDCL and augmentation
- Outperforms baseline RoBERTa accuracy of 62.1%

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Cross-domain contrastive learning (CDCL) improves domain adaptation by aligning feature representations of same-category examples across domains.
- **Mechanism:** CDCL minimizes the l2-norm distance between features from the same category, regardless of their source or target domain. It uses pseudo-labels generated by K-Means to identify positive pairs for contrastive loss computation.
- **Core assumption:** Samples from the same category should have similar feature representations, regardless of domain.
- **Evidence anchors:**
  - [abstract]: "cross-domain contrastive learning (CDCL) that minimizes distances between same-category features across domains"
  - [section]: "Since there is no clear way to construct positive and negative pairs in an unsupervised domain adaptation framework, Wang et al. (2022) argued that samples from the same category should be similar. In contrast, samples from different categories should have other feature representations, regardless of the domain from which they come."
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism.
- **Break condition:** If the pseudo-labeling step fails to accurately group same-category examples across domains, the contrastive loss may push apart features that should be similar, degrading performance.

### Mechanism 2
- **Claim:** Data augmentation using TF-IDF-based word replacement improves adaptation by creating additional training examples that are semantically similar but syntactically varied.
- **Mechanism:** High TF-IDF score tokens are replaced with non-keywords from the vocabulary, controlled by a hyperparameter p that determines the augmentation level. This helps the model learn more robust and invariant features.
- **Core assumption:** Replacing high TF-IDF score words with non-keywords preserves the semantic content while introducing syntactic variation that improves generalization.
- **Evidence anchors:**
  - [section]: "We explore a data augmentation technique based on TF-IDF as proposed by Oord et al. (2018) for consistency training. Thus, we compute the TF-IDF score for every token from the corpus and associate it with the probability of it being changed."
  - [section]: "Using more augmentations (e.g., p ∈ {0.1, 0.2, 0.3}) on the CDCL and CAT frameworks yields better overall results"
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism.
- **Break condition:** If too many tokens are replaced or the replacements are not semantically appropriate, the augmented text may become incoherent, confusing the model and harming performance.

### Mechanism 3
- **Claim:** Cluster and topic-based UDA improves performance by using cluster/topic labels as additional domain information for adaptation.
- **Mechanism:** Clustering or topic modeling algorithms are applied to the feature space or TF-IDF features to identify k clusters or topics, which are then used as domain labels in the UDA framework. This helps compact the latent representation and learn domain-invariant features.
- **Core assumption:** The data can be meaningfully clustered or partitioned into topics that correspond to underlying domain characteristics relevant for adaptation.
- **Evidence anchors:**
  - [abstract]: "we combine clustering and topic modeling algorithms with UDA, resulting in improved performances compared to the initial UDA setup."
  - [section]: "We propose an addition to the UDA approach, considering the supervised setting (i.e., we have access to the labeled source dataset). First, we represent the input text using TF-IDF or a pre-trained RoBERTa model. We employ a clustering/topic modeling algorithm in this feature space to identify k clusters or topics, which will be assigned as domain labels."
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism.
- **Break condition:** If the clustering or topic modeling algorithms fail to identify meaningful groupings or if the number of clusters/topics is not appropriate, the additional domain labels may not provide useful information and could even introduce noise.

## Foundational Learning

- **Concept:** Unsupervised Domain Adaptation (UDA)
  - Why needed here: The paper addresses the problem of adapting a fake news detection model to a hyperpartisan news detection task without using target labels during training.
  - Quick check question: What is the main goal of UDA and how does it differ from supervised domain adaptation?

- **Concept:** Contrastive Learning
  - Why needed here: CDCL, one of the proposed methods, is based on contrastive learning principles to align features across domains.
  - Quick check question: What is the main idea behind contrastive learning and how is it applied in the CDCL method?

- **Concept:** Clustering and Topic Modeling
  - Why needed here: These techniques are used to generate additional domain labels for the cluster and topic-based UDA approach.
  - Quick check question: What are the main differences between clustering and topic modeling, and why might each be useful for generating domain labels?

## Architecture Onboarding

- **Component map:** RoBERTa -> Label Predictor -> Domain Discriminator -> UDA Loss; RoBERTa -> K-Means -> Contrastive Loss (CDCL); RoBERTa -> Clustering/Topic Modeling -> Domain Labels (Cluster/Topic UDA)

- **Critical path:**
  1. Preprocess and split datasets
  2. Fine-tune RoBERTa on source dataset
  3. For each UDA method:
     - Set up model architecture with RoBERTa as feature encoder
     - Train on source dataset with corresponding loss function (UDA, CAT, CDCL, or cluster/topic-based UDA)
     - Evaluate on target dataset

- **Design tradeoffs:**
  - Using RoBERTa as feature encoder vs. fine-tuning it for the specific task
  - Number of clusters/topics for cluster and topic-based UDA
  - Hyperparameters for UDA methods (λ, α, γ, τ, p)
  - Choice of clustering and topic modeling algorithms

- **Failure signatures:**
  - Poor performance on source dataset: model is not learning the source task well
  - Large gap between source and target performance: domain shift is not being effectively addressed
  - Overfitting on target dataset: model is memorizing target examples rather than learning domain-invariant features
  - Inconsistent pseudo-labels: clustering or topic modeling is not producing stable or meaningful groupings

- **First 3 experiments:**
  1. Fine-tune RoBERTa on source dataset and evaluate on both source and target datasets to establish baseline performance.
  2. Implement and train the UDA method with default hyperparameters and evaluate on target dataset.
  3. Implement and train the CDCL method with default hyperparameters and evaluate on target dataset, comparing performance with UDA.

## Open Questions the Paper Calls Out

- **Open Question 1:** How does the performance of cross-domain contrastive learning (CDCL) vary when applied to other fake news datasets beyond BuzzFeed and ISOT, such as PolitiFact or GossipCop?
  - Basis in paper: [explicit] The authors state, "For future work, we aim to investigate our approaches on other fake news datasets."
  - Why unresolved: The current experiments are limited to BuzzFeed, ISOT, and Hyperpartisan datasets, and the authors did not explore other widely used fake news datasets.
  - What evidence would resolve it: Experiments applying CDCL to PolitiFact, GossipCop, or other fake news datasets, with performance metrics compared to current results.

- **Open Question 2:** What is the impact of different decoding strategies (e.g., greedy, beam search, top-k, top-p) on the quality and diversity of text generated by GPT-2 for data augmentation in fake news detection?
  - Basis in paper: [explicit] The authors compare decoding strategies in Appendix A.1, noting differences in performance metrics.
  - Why unresolved: While the authors provide results, they do not analyze the qualitative aspects of generated text, such as coherence or diversity.
  - What evidence would resolve it: A detailed analysis of generated text samples using each decoding strategy, assessing coherence, diversity, and alignment with original news content.

- **Open Question 3:** How does the choice of clustering or topic modeling algorithm affect the effectiveness of cluster- and topic-based unsupervised domain adaptation (UDA) in fake and hyperpartisan news detection?
  - Basis in paper: [explicit] The authors compare clustering algorithms (K-Means, K-Medoids, Gaussian Mixture, HDBSCAN) and topic modeling algorithms (LDA, NMF, LSA, pLSA) but do not provide a comprehensive analysis of their relative performance.
  - Why unresolved: The paper does not thoroughly analyze the impact of different clustering and topic modeling algorithms on the effectiveness of cluster- and topic-based UDA.
  - What evidence would resolve it: A systematic comparison of the performance of cluster- and topic-based UDA using different clustering and topic modeling algorithms, with ablation studies to isolate the contribution of each algorithm.

## Limitations
- Limited evaluation to specific source-target domain pairs (ISOT/BuzzFeed to Hyperpartisan-L), which may limit generalizability
- Heavy reliance on pseudo-labeling techniques that may introduce noise if feature similarity assumptions do not hold
- Lack of detailed implementation specifics for GPT-2 data augmentation, making it difficult to reproduce results

## Confidence
- High confidence in the overall experimental methodology and the superiority of CDCL over baseline UDA and CAT methods on the tested datasets.
- Medium confidence in the effectiveness of cluster and topic-based UDA, as the paper provides limited discussion on the impact of different clustering/topic modeling algorithms and hyperparameters.
- Low confidence in the exact implementation details of data augmentation techniques, particularly GPT-2 generation, which are crucial for reproducing the results.

## Next Checks
1. Conduct ablation studies to quantify the contribution of each component (UDA, CAT, CDCL, cluster/topic-based UDA, data augmentation) to the overall performance.
2. Test the proposed methods on additional source-target domain pairs to assess generalizability and identify potential limitations in different adaptation scenarios.
3. Provide detailed implementation guidelines for data augmentation techniques, especially GPT-2 generation, to facilitate reproduction and fair comparison with other methods.