---
ver: rpa2
title: Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation
arxiv_id: '2311.15100'
source_url: https://arxiv.org/abs/2311.15100
tags:
- monge
- unbalanced
- uot-fm
- transport
- translation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a method to incorporate unbalancedness into
  neural Monge map estimators, addressing the limitation of classical optimal transport
  that enforces mass conservation. The approach involves re-weighting source and target
  distributions using solutions from unbalanced optimal transport, enabling the computation
  of Monge maps between measures of unequal mass.
---

# Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation

## Quick Facts
- arXiv ID: 2311.15100
- Source URL: https://arxiv.org/abs/2311.15100
- Reference count: 40
- Primary result: Incorporating unbalancedness into neural Monge maps improves unpaired domain translation tasks including single-cell trajectory inference, cellular perturbation modeling, and image translation.

## Executive Summary
This paper addresses a fundamental limitation of classical optimal transport by introducing unbalancedness into neural Monge map estimators. Classical OT requires mass conservation between distributions, which is often unrealistic in practical applications. The authors propose a method that reweights source and target distributions using solutions from unbalanced optimal transport, enabling the computation of Monge maps between measures of unequal mass. The framework is validated across three distinct domains: single-cell trajectory inference showing more biologically plausible cell transitions, cellular perturbation response modeling, and unpaired image translation where it outperforms existing approaches in FID score and transport cost.

## Method Summary
The method extends neural Monge map estimators by incorporating unbalanced optimal transport (UOT) coupling computation. The key innovation involves computing reweighting functions u and v through entropy-regularized UOT that implicitly rescale source and target measures to have equal mass, after which a balanced Monge map estimator is applied to the reweighted measures. The framework is designed to be universally applicable across different neural Monge map estimators (OT-ICNN, OT-MG, OT-FM) and seamlessly integrates with OT flow matching to create UOT-FM. The hyperparameter τ controls the penalty for mass deviation, with the framework mitigating class imbalance and outlier issues within batches during training.

## Key Results
- Demonstrated significant improvements in single-cell trajectory inference with more biologically plausible cell type transitions
- Achieved better feature preservation in unpaired image translation tasks compared to established methods like CycleGAN and UVCGAN
- Successfully extended OT flow matching to the unbalanced setting (UOT-FM), lowering transport costs and improving generation quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: UOT allows learning Monge maps between distributions of unequal mass by reweighting source and target measures
- Mechanism: The UOT coupling computes reweighting functions u and v that scale the source and target measures to have equal mass, enabling a balanced Monge map estimator to be applied to the reweighted measures
- Core assumption: The reweighting functions from UOT coupling correctly approximate optimal reweighting for the Monge map problem
- Evidence anchors: Proposition 3.1 proves the reformulation of computing Monge maps between unequal mass measures as computing maps between rescaled measures

### Mechanism 2
- Claim: Unbalanced Monge maps improve unpaired domain translation by mitigating batch-level class imbalance
- Mechanism: Batch-wise training can create class imbalance at the batch level, and unbalancedness helps remove outliers and address imbalances within individual batches
- Core assumption: Batch-level class imbalance significantly impacts balanced Monge map estimator performance
- Evidence anchors: The paper discusses how unbalancedness helps with outliers and class imbalances across datasets and at the batch level

### Mechanism 3
- Claim: The framework seamlessly integrates with OT flow matching (OT-FM) to create UOT-FM
- Mechanism: The universal applicability allows extending OT-FM to the unbalanced setting by applying the same reweighting procedure, improving performance in unpaired image translation
- Core assumption: OT-FM can be extended to unbalanced setting by applying the same reweighting procedure
- Evidence anchors: The paper demonstrates UOT-FM improves upon OT-FM in unpaired image translation tasks

## Foundational Learning

- Concept: Unbalanced optimal transport (UOT)
  - Why needed here: UOT is the core concept that allows learning Monge maps between distributions of unequal mass by relaxing mass conservation
  - Quick check question: What is the main difference between balanced and unbalanced optimal transport, and how does UOT handle distributions of unequal mass?

- Concept: Neural Monge map estimators
  - Why needed here: These tools learn Monge maps between reweighted measures obtained from UOT
  - Quick check question: What are the main types of neural Monge map estimators used in the paper, and how do they differ in their approach to learning Monge maps?

- Concept: Flow matching and OT flow matching (OT-FM)
  - Why needed here: OT-FM is a simulation-free technique for training continuous normalizing flows that can approximate Monge maps
  - Quick check question: How does OT-FM differ from traditional flow matching, and what are the advantages of using OT-FM for learning Monge maps?

## Architecture Onboarding

- Component map: UOT coupling computation -> Reweighting function estimation -> Neural Monge map estimator -> Loss function computation -> Model training and evaluation

- Critical path: Computing UOT coupling, estimating reweighting functions, applying neural Monge map estimator to reweighted measures, and computing loss for backpropagation

- Design tradeoffs:
  - Choice of neural Monge map estimator depends on task and data characteristics
  - Hyperparameter τ requires grid search and varies by task
  - Computational overhead is often negligible compared to overall training time

- Failure signatures:
  - Poor performance in unpaired domain translation if learned Monge maps don't capture desired transformations
  - Unstable training if τ is inappropriate or UOT coupling computation has issues

- First 3 experiments:
  1. Implement UOT coupling computation using ott-jax library and verify correct reweighting of source and target measures
  2. Integrate UOT coupling with OT-ICNN and train on toy dataset with known class imbalance
  3. Extend implementation to OT-FM and compare UOT-FM against OT-FM on small image translation task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of τ in unbalanced optimal transport affect the robustness of neural Monge map estimators to outliers in different types of data distributions?
- Basis in paper: The paper discusses that τ choice is a limitation affecting outlier removal but lacks detailed analysis across distributions
- Why unresolved: While τ's importance is mentioned, the paper doesn't explore its impact in depth or provide systematic analysis
- What evidence would resolve it: Comprehensive study comparing performance with different τ values on datasets with varying outlier degrees and distribution shifts

### Open Question 2
- Question: Can the method be extended to handle more complex cost functions beyond squared Euclidean distance?
- Basis in paper: The method is demonstrated with squared Euclidean distance, with exploring more meaningful costs suggested as future work
- Why unresolved: Applicability to other cost functions capturing specific data geometry is not explored
- What evidence would resolve it: Extending framework to broader cost functions and evaluating on tasks where squared Euclidean distance is inappropriate

### Open Question 3
- Question: How does UOT-FM performance compare to other state-of-the-art methods in terms of computational efficiency and scalability?
- Basis in paper: UOT-FM is compared to CycleGAN and UVCGAN but lacks detailed analysis of computational efficiency
- Why unresolved: While image quality results are shown, computational resources and scalability comparisons are not addressed
- What evidence would resolve it: Thorough comparison of UOT-FM's runtime, memory usage, and scalability with other methods on large-scale tasks

## Limitations

- The choice of hyperparameter τ is task-dependent and lacks a principled selection method
- Theoretical understanding of why unbalancedness helps in specific settings remains incomplete
- Computational overhead compared to balanced approaches, though often negligible

## Confidence

- High: Empirical results are compelling across diverse domains (single-cell, cellular perturbation, image translation)
- Medium: Theoretical justification is incomplete despite mathematical foundation from Proposition 3.1
- Low: No clear guidance provided for optimal τ selection across different tasks

## Next Checks

1. Test method's robustness to initialization and hyperparameter sensitivity by systematically varying τ across multiple random seeds for each task
2. Compare against alternative approaches for handling mass imbalance (instance weighting, class rebalancing) to isolate UOT-based reweighting benefits
3. Evaluate whether improvements persist when source and target distributions have similar mass but differ in other characteristics (support overlap, dimensionality)