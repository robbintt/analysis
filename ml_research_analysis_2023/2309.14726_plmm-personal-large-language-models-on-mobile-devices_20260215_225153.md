---
ver: rpa2
title: 'PLMM: Personal Large Language Models on Mobile Devices'
arxiv_id: '2309.14726'
source_url: https://arxiv.org/abs/2309.14726
tags:
- language
- personal
- large
- users
- level
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes personal large language models (P-models)
  that are compact enough to run on mobile devices while maintaining user privacy
  by keeping personal data local. The system uses a three-level architecture: personal
  (P), expert (E), and traditional (T) models, where P-models interact with users
  and E-models, and are updated dynamically based on user input.'
---

# PLMM: Personal Large Language Models on Mobile Devices

## Quick Facts
- arXiv ID: 2309.14726
- Source URL: https://arxiv.org/abs/2309.14726
- Authors: 
- Reference count: 40
- Key outcome: This paper proposes personal large language models (P-models) that are compact enough to run on mobile devices while maintaining user privacy by keeping personal data local. The system uses a three-level architecture: personal (P), expert (E), and traditional (T) models, where P-models interact with users and E-models, and are updated dynamically based on user input.

## Executive Summary
This paper introduces PLMM (Personal Large Language Models), a novel architecture that enables sophisticated language models to run on mobile devices while preserving user privacy. The system addresses the fundamental tension between the computational demands of large language models and the privacy requirements of personal data. By decomposing functionality into three levels—personal, expert, and traditional models—the architecture keeps sensitive user information encrypted on the device while still enabling access to specialized knowledge and universal information through secure interactions with remote models.

The proposed system represents a significant departure from current large language model deployments, which typically require cloud-based processing and expose user data to third parties. PLMM's three-tier approach allows for real-time personalization and adaptation while maintaining computational feasibility on resource-constrained mobile devices. The architecture also introduces an economic model that incentivizes both users and developers to contribute to the system's improvement, creating a sustainable ecosystem for personalized AI assistance.

## Method Summary
The method proposes a three-level architecture consisting of personal (P), expert (E), and traditional (T) models. P-models are compact language models that run directly on user devices, handling encrypted personal data and interacting with users. E-models are specialized domain experts hosted on servers, providing knowledge in areas like finance, IT, and medicine. T-models maintain universal knowledge and periodically update E-models. The system uses model distillation techniques to compress traditional large language models into the smaller P-models while preserving essential functionality. Dynamic parameter updates allow P-models to adapt to user preferences in real-time, while encrypted communication protocols ensure privacy during interactions with remote E and T models.

## Key Results
- Introduces a three-level architecture (P-E-T) enabling large language models to run on mobile devices
- Proposes dynamic update mechanisms for real-time personalization while maintaining privacy
- Develops an economic incentive model for sustainable user and developer participation
- Addresses key limitations of traditional large language models: size, privacy, and adaptability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The P-E-T model decomposition allows privacy-preserving personalization while leveraging remote expert and traditional models for scale and domain expertise.
- Mechanism: By splitting functionality into personal (P), expert (E), and traditional (T) levels, personal data remains encrypted on the user's device while P-models interact with remote E/T models for specialized knowledge without exposing raw personal information.
- Core assumption: The cryptographic boundary between P-models and remote E/T models is secure and the interaction protocol does not leak sensitive data.
- Evidence anchors:
  - [abstract] states "P-models interact with users and E-models, and are updated dynamically based on user input" and "user privacy by keeping personal data local"
  - [section II-A] explains "The personal level models are adaptive to users' personal information. They encrypt the users' input and protect their privacy"
  - [corpus] shows related work on mobile privacy (e.g., "Eye-Shield: Real-Time Protection of Mobile Device Screen Information from Shoulder Surfing") supporting the privacy focus
- Break condition: If the encryption or interaction protocol is compromised, personal data could be exposed to remote models.

### Mechanism 2
- Claim: The dynamic update mechanism allows P-models to adapt in real-time to user needs while maintaining computational feasibility on mobile devices.
- Mechanism: P-models receive user input and update their parameters locally, while periodically synchronizing with E-models for domain expertise, creating a feedback loop that improves personalization without requiring full model retraining.
- Core assumption: The update frequency and model size are balanced such that real-time responsiveness is maintained without overwhelming mobile device resources.
- Evidence anchors:
  - [abstract] mentions "updated dynamically based on user input" and "real-time responses"
  - [section II-B] states "P-model operates in tandem with the E-model, constantly exchanging information and updating its parameters"
  - [section I-A] notes the limitation that "traditional large language models... may not provide real-time responses"
- Break condition: If update frequency is too high or model size too large, mobile devices cannot maintain real-time performance.

### Mechanism 3
- Claim: The economic model creates sustainable incentives for both users and developers to contribute to model improvement.
- Mechanism: Users pay for service access and earn rewards for valuable input, while developers monetize their model expertise but must compensate users for contributions, creating a closed-loop economy.
- Core assumption: The monetary value of user contributions and developer expertise can be accurately assessed and exchanged through the system.
- Evidence anchors:
  - [section III] explicitly describes "two roles" for both users (pay and earn) and developers (earn and pay)
  - [section III-A] states "users can also earn money from the system for their valuable input"
  - [section III-B] explains developers "can earn money from their models" but "have to pay money for the (valuable) input from users"
- Break condition: If valuation mechanisms fail or economic incentives become misaligned, participation may drop.

## Foundational Learning

- Concept: Model distillation and compression
  - Why needed here: P-models must be "small enough to be performed on personal computers or mobile devices" while maintaining capability
  - Quick check question: What techniques could be used to reduce a 175B parameter model to run on a mobile device while preserving key functionality?

- Concept: Federated learning principles
  - Why needed here: The architecture is "Inspired by Federated Learning" to keep personal data local while enabling collaborative model improvement
  - Quick check question: How does federated learning differ from centralized training in terms of data privacy and model updates?

- Concept: Multi-level system design
  - Why needed here: The three-tier P-E-T architecture balances personalization, expertise, and universal knowledge while managing computational constraints
  - Quick check question: What are the tradeoffs between having separate models versus a single monolithic model for different functionality levels?

## Architecture Onboarding

- Component map: P-model (user device) -> E-model (server) -> T-model (server) -> E-model (update) -> P-model (sync)

- Critical path:
  1. User query → P-model on device
  2. P-model processes and determines if expert knowledge needed
  3. If needed, P-model requests E-model consultation (encrypted)
  4. E-model responds with expertise
  5. P-model combines response with personal context
  6. Response delivered to user in real-time

- Design tradeoffs:
  - Model size vs. responsiveness: Smaller P-models enable real-time performance but may sacrifice some capability
  - Update frequency vs. resource usage: More frequent updates improve personalization but consume more battery and bandwidth
  - Encryption strength vs. latency: Stronger encryption provides better privacy but may slow interactions
  - Specialization vs. generalization: More E-models provide better domain expertise but increase system complexity

- Failure signatures:
  - Slow response times: May indicate P-model is too large or updates are too frequent
  - Inaccurate personal responses: Could mean P-model hasn't been updated with sufficient user data
  - Privacy breaches: Suggests encryption or interaction protocol has been compromised
  - Domain expertise gaps: Indicates E-models are outdated or insufficient for user needs

- First 3 experiments:
  1. Benchmark P-model inference time and memory usage on target mobile devices with varying model sizes
  2. Test encryption overhead and data leakage potential in P-to-E model communication
  3. Measure user satisfaction and personalization quality with different update frequencies and personalization strategies

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the dynamic interaction between personal models (P-models) and expert models (E-models) be optimized to ensure real-time responsiveness while maintaining high-quality responses?
- Basis in paper: [explicit] The paper mentions that P-models must interact with E-models dynamically and respond in real-time, but it does not provide details on how this interaction is optimized.
- Why unresolved: The paper introduces the concept of dynamic interaction but lacks specifics on the mechanisms or algorithms used to balance real-time performance with response quality.
- What evidence would resolve it: Experimental results demonstrating the performance of the P-E interaction under different conditions, including response times and accuracy metrics.

### Open Question 2
- Question: What are the security measures in place to ensure that encrypted personal information in P-models is not leaked during interactions with E-models or T-models?
- Basis in paper: [explicit] The paper states that P-models encrypt user input and protect privacy, but it does not detail the encryption methods or security protocols used.
- Why unresolved: While privacy is a stated goal, the paper does not provide technical details on how encryption and data protection are implemented.
- What evidence would resolve it: Technical specifications of the encryption algorithms and security protocols, along with validation of their effectiveness through security audits or penetration testing.

### Open Question 3
- Question: How does the proposed multi-level architecture compare to existing federated learning approaches in terms of efficiency, scalability, and user privacy?
- Basis in paper: [inferred] The paper draws inspiration from federated learning but does not compare its proposed architecture to existing federated learning systems.
- Why unresolved: The paper introduces a novel architecture but does not benchmark it against established federated learning methods.
- What evidence would resolve it: Comparative studies showing the performance of the proposed architecture versus federated learning systems in terms of computational efficiency, scalability, and privacy preservation.

## Limitations
- The paper presents a conceptual framework without implementation details or empirical validation
- Key uncertainties include specific model compression techniques and cryptographic protocols
- The economic incentive model's sustainability and real-world viability are not explored
- No benchmarks or performance measurements are provided for the proposed architecture

## Confidence

- **High confidence**: The core insight that traditional large language models are too large for mobile devices and pose privacy concerns. The three-level P-E-T architecture is conceptually sound and addresses known limitations.
- **Medium confidence**: The dynamic update mechanism and real-time responsiveness claims, as these depend heavily on implementation details not provided. The privacy preservation through local processing is theoretically valid but implementation-dependent.
- **Low confidence**: The economic incentive model and its sustainability, as this requires complex market mechanisms and user behavior patterns not explored in the paper.

## Next Checks

1. **Performance validation**: Benchmark P-model inference time and memory usage on representative mobile devices across different model compression levels to verify real-time capability claims.
2. **Privacy verification**: Conduct penetration testing on the P-to-E model communication protocol to ensure encrypted personal data cannot be extracted or inferred by remote models.
3. **Economic sustainability test**: Model the economic incentive system with realistic user participation rates and value assessment algorithms to verify long-term viability.