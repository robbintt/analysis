---
ver: rpa2
title: Bridging Generative and Discriminative Noisy-Label Learning via Direction-Agnostic
  EM Formulation
arxiv_id: '2308.01184'
source_url: https://arxiv.org/abs/2308.01184
tags:
- label
- learning
- training
- clean
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a single-stage generative noisy-label learning
  framework that is direction-agnostic and avoids explicit image synthesis. It derives
  an Expectation-Maximization (EM) objective where the E-step adapts to either causal
  orientation without changing the overall optimization.
---

# Bridging Generative and Discriminative Noisy-Label Learning via Direction-Agnostic EM Formulation

## Quick Facts
- arXiv ID: 2308.01184
- Source URL: https://arxiv.org/abs/2308.01184
- Reference count: 40
- Primary result: Achieves state-of-the-art accuracy on noisy-label benchmarks while reducing training compute compared to generative and discriminative baselines.

## Executive Summary
This paper presents a novel single-stage framework that bridges generative and discriminative approaches for learning with noisy labels. The method introduces a direction-agnostic EM objective that adapts to different causal orientations without requiring explicit image synthesis. By using a dataset-normalized discriminative proxy for the intractable p(X|Y) and introducing Partial-Label Supervision (PLS) for instance-specific priors, the framework achieves competitive results on both synthetic and real-world noisy-label benchmarks while significantly reducing computational costs.

## Method Summary
The proposed framework addresses noisy label learning through a direction-agnostic EM formulation that unifies generative and discriminative modeling. Instead of explicit image synthesis, it uses a discriminative proxy p(x|y) ≈ q(y|x)/Σq(y|xi) computed via a classifier on finite training data. The method introduces PLS, an instance-specific prior over clean labels that balances coverage and uncertainty to improve regularization. The training objective combines cross-entropy, KL divergence terms, and PLS regularization, optimized through a three-term loss function. This approach avoids the need to choose a fixed causal direction while retaining generative benefits at lower computational cost.

## Key Results
- Achieves state-of-the-art accuracy on vision and NLP benchmarks for noisy-label learning
- Demonstrates lower transition-matrix estimation error compared to existing methods
- Shows substantially reduced training compute requirements versus current generative and discriminative baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Direction-agnostic EM objective avoids the need to choose a fixed causal direction (Y→X or X→Y), improving robustness to different noise structures.
- Mechanism: The single EM objective is formulated such that the E-step can be specialized to either causal orientation without changing the overall optimization. This is achieved by constructing a unified objective that treats the generative process symmetrically.
- Core assumption: The generative model's likelihood can be expressed in a form that is invariant to the causal direction, and the E-step can adapt accordingly.
- Evidence anchors:
  - [abstract] "First, we derive a single Expectation-Maximization (EM) objective whose E-step specializes to either causal orientation without changing the overall optimization."
  - [section] "Based on Eq. (5) and (6), the expected log likelihood of p(x|y) is defined as Eq(y|x) [logp(x|y)] = Eq(y|x) [logp(˜y|x, y)] − KL[q(y|x)∥p(x|y)p(y)] +KL[q(y|x)∥p(˜y|x, y)p(y)] ."
- Break condition: If the generative model cannot be expressed symmetrically, or if the E-step cannot adapt to different causal orientations without changing the objective.

### Mechanism 2
- Claim: Using a dataset-normalized discriminative proxy for p(X|Y) avoids the computational cost of training a generative model while retaining generative benefits.
- Mechanism: Instead of modeling p(X|Y) explicitly with a generative model, the method defines p(x|y) only on the training set using the discriminative model q(Y|X), with p(x|y) = q(y|x)/Σ_i q(y|x_i). This implicitly approximates the generative model.
- Core assumption: The discriminative model q(Y|X) can effectively approximate the intractable p(X|Y) when normalized over the training set.
- Evidence anchors:
  - [section] "However, since noisy label learning is a discriminative task and classification performance is our primary goal, the generation can be approximated with with finite training samples, which is the given training set. More specifically, we defines p(x|y) only on data points {xi}|D| i=1 by maximising −KL [q(y|x)∥p(x|y)p(y)] for a fixed q(y|x), with the optimum achieved by: p(x|y) = q(y|x)/P|D| i=1 q(y|xi) ."
- Break condition: If the discriminative model q(Y|X) is not a good approximation of p(X|Y), or if the training set is not representative of the data distribution.

### Mechanism 3
- Claim: Partial-Label Supervision (PLS) dynamically adjusts the clean label prior based on instance-level uncertainty, improving regularization and coverage.
- Mechanism: PLS constructs an instance-specific prior p(Y) that balances coverage and uncertainty. For samples where the model is certain, p(Y) focuses on few candidates; for uncertain samples, p(Y) covers more candidates, acting as regularization.
- Core assumption: The model's uncertainty about a sample's label can be effectively estimated using loss-based methods, and this uncertainty is correlated with the need for broader label coverage.
- Evidence anchors:
  - [section] "The minimisation of uncertainty depends on our ability to detect clean-label and noisy-label samples. For clean samples, p(yi) should converge to a one-hot distribution, maintaining the label prior focused on few candidate labels. For noisy samples, p(yi) should be close to a uniform distribution to keep a large coverage of candidate labels."
- Break condition: If the uncertainty estimation is inaccurate, or if the correlation between uncertainty and the need for broader label coverage does not hold.

## Foundational Learning

- Concept: Expectation-Maximization (EM) algorithm
  - Why needed here: The method uses an EM-style optimization to handle the latent clean label variable Y, alternating between estimating the posterior q(Y|X) and updating the model parameters.
  - Quick check question: What are the E-step and M-step in the context of noisy label learning, and how do they differ from standard EM?

- Concept: Variational inference
  - Why needed here: The method uses a variational posterior q(Y|X) to approximate the true posterior p(Y|X), and optimizes a lower bound on the log-likelihood.
  - Quick check question: How does the KL divergence term in the objective function relate to the quality of the variational approximation?

- Concept: Label transition matrix
  - Why needed here: The method estimates a label transition matrix p(˜Y|Y,X) to model the noise process, which is crucial for disentangling clean and noisy labels.
  - Quick check question: How does the method estimate the label transition matrix, and what are the challenges in doing so?

## Architecture Onboarding

- Component map: Input (X, ˜Y) -> Discriminative model q(Y|X) -> Label transition model p(˜Y|Y,X) -> PLS module -> Loss function (CE + KL + PLS) -> Output (predicted clean label distribution)

- Critical path:
  1. Forward pass through q(Y|X) to get clean label distribution
  2. Forward pass through p(˜Y|Y,X) to get noisy label distribution
  3. Compute PLS prior p(Y)
  4. Compute loss function
  5. Backward pass to update model parameters

- Design tradeoffs:
  - Using a discriminative proxy for p(X|Y) trades off some generative modeling capability for computational efficiency
  - PLS trades off some label purity for better regularization and coverage
  - The method is more flexible than fixed causal direction approaches but may be more complex to implement

- Failure signatures:
  - If the discriminative model q(Y|X) is not a good approximation of p(X|Y), the method may not work well
  - If the PLS prior is not constructed correctly, it may not provide the desired regularization and coverage
  - If the label transition matrix is not estimated accurately, the method may not disentangle clean and noisy labels effectively

- First 3 experiments:
  1. Implement the discriminative model q(Y|X) and test it on a simple noisy label dataset to verify that it can learn to predict clean labels.
  2. Implement the label transition model p(˜Y|Y,X) and test it on a simple noisy label dataset to verify that it can learn to model the noise process.
  3. Implement the PLS prior and test it on a simple noisy label dataset to verify that it can construct an effective instance-specific prior.

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the choice of model architecture for the discriminative model q(Y|X) affect the performance of the proposed generative noisy-label learning framework?
  - Basis in paper: [inferred] The paper mentions that the competitive results are obtained using fairly standard models for q(Y|X) without exploring sophisticated noisy-label learning techniques, indicating that the choice of model architecture is an area for further exploration.
  - Why unresolved: The paper does not provide a comprehensive study of the model for q(Y|X), leaving the impact of different architectures on performance unexplored.
  - What evidence would resolve it: Comparative experiments using different architectures for q(Y|X) on standard benchmarks, analyzing the impact on accuracy and training efficiency.

- **Open Question 2**: How can the proposed method be extended to handle real-world datasets with high-resolution images?
  - Basis in paper: [explicit] The paper mentions that a limitation is the difficulty in estimating p(X|Y) in real-world datasets containing high-resolution images, and suggests exploring data augmentation strategies to increase the scale of the dataset.
  - Why unresolved: The paper does not provide a concrete solution or experimental results for handling high-resolution images, leaving the extension of the method to such datasets an open question.
  - What evidence would resolve it: Experimental results on high-resolution image datasets, demonstrating the effectiveness of the proposed method with appropriate data augmentation strategies.

- **Open Question 3**: How does the proposed method compare to other state-of-the-art methods when dealing with instance-dependent label noise in real-world scenarios?
  - Basis in paper: [explicit] The paper mentions that the proposed method achieves state-of-the-art results on synthetic and real-world noisy-label benchmarks, but does not provide a comprehensive comparison with other state-of-the-art methods in real-world scenarios with instance-dependent label noise.
  - Why unresolved: The paper focuses on synthetic and specific real-world benchmarks, and does not extensively compare the proposed method with other state-of-the-art methods in diverse real-world scenarios with instance-dependent label noise.
  - What evidence would resolve it: Comparative experiments on a wide range of real-world datasets with instance-dependent label noise, using other state-of-the-art methods as baselines, to evaluate the effectiveness and robustness of the proposed method in diverse scenarios.

## Limitations

- The method assumes that the discriminative proxy p(x|y) ≈ q(y|x)/Σq(y|xi) effectively approximates the generative model, which may not hold for all data distributions
- The PLS uncertainty estimation may not always accurately reflect the need for broader label coverage
- The method's flexibility in causal direction may introduce implementation complexity

## Confidence

- Direction-agnostic EM formulation: High
- Use of discriminative proxy for computational efficiency: High
- PLS effectiveness: Medium
- Generalizability to all noise structures: Low

## Next Checks

1. Implement the discriminative model q(Y|X) and test it on a simple noisy label dataset to verify its ability to predict clean labels
2. Implement the label transition model p(˜Y|Y,X) and test it on a simple noisy label dataset to verify its ability to model the noise process
3. Implement the PLS prior and test it on a simple noisy label dataset to verify its ability to construct an effective instance-specific prior