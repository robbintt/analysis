---
ver: rpa2
title: Information Flow Control in Machine Learning through Modular Model Architecture
arxiv_id: '2306.03235'
source_url: https://arxiv.org/abs/2306.03235
tags:
- domains
- experts
- data
- domain
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces information flow control (IFC) for machine
  learning, ensuring that outputs depend only on training data accessible to a user.
  The authors propose a secure MoE-based Transformer architecture where each security
  domain has a dedicated expert module, and only a subset of experts is activated
  at inference based on the user's access policy.
---

# Information Flow Control in Machine Learning through Modular Model Architecture

## Quick Facts
- arXiv ID: 2306.03235
- Source URL: https://arxiv.org/abs/2306.03235
- Authors: 
- Reference count: 40
- Primary result: MoE-based Transformer with domain-specific experts achieves 37% accuracy improvement while providing information flow control with only 1.9% performance overhead

## Executive Summary
This paper introduces information flow control (IFC) for machine learning to ensure model outputs depend only on training data accessible to a user. The authors propose a secure MoE-based Transformer architecture where each security domain has a dedicated expert module, and only a subset of experts is activated at inference based on the user's access policy. Experiments on a large Reddit dataset with 50 simulated security domains show that the approach incurs only a 1.9% performance overhead while improving accuracy (perplexity) by up to 37% compared to a public-data-only baseline, and by 20% even with just two accessible domains.

## Method Summary
The approach uses a mixture-of-experts Transformer architecture with one expert per security domain. Training involves creating adapter-based expert modules for each domain while maintaining a base GPT-2 model trained on public data. At inference, a gating function selects the top-k most relevant experts from the user's accessible domains using either cosine similarity between input vectors and domain vectors (gate-pairwise), pre-computed perplexity matrices (gate-known), or clustered domain vectors for scalability (gate-cluster). The selected expert outputs are then ensembled to produce the final prediction.

## Key Results
- 1.9% performance overhead compared to baseline approach
- 37% improvement in perplexity over public-data-only baseline
- 20% accuracy improvement even with only 2 accessible domains
- Scalable gating approach (gate-cluster) maintains performance with large numbers of domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Non-interference is achieved by isolating expert modules per security domain.
- Mechanism: Each security domain's data influences only one expert; gating selects experts based on access policy, ensuring outputs depend only on accessible data.
- Core assumption: Training each expert independently guarantees that inaccessible domain data cannot influence the gating or ensemble decisions.
- Evidence anchors:
  - [abstract]: "controls information flow by limiting the influence of training data from each security domain to a single expert module"
  - [section 4.3]: "training algorithm to produce an expert only depends on the domain data for that expert"
  - [corpus]: No direct evidence; assumption is derived from architecture description.
- Break condition: If gating or ensembling inadvertently uses information from inaccessible domains, non-interference is violated.

### Mechanism 2
- Claim: Security and accuracy are balanced by activating only top-k relevant experts.
- Mechanism: Gating function identifies k experts from accessible domains most relevant to input; irrelevant experts are excluded to avoid accuracy degradation and reduce resource usage.
- Core assumption: Relevance estimation via cosine similarity and domain size adjustment accurately reflects expert utility for a given input.
- Evidence anchors:
  - [section 4.5]: "we only activate a small number (k) of experts that are accessible in the user's access policy and relevant to the given input"
  - [section 4.5.4]: "penalizing small domains" to adjust similarity scores
  - [corpus]: No direct evidence; assumption is derived from evaluation results showing improved accuracy with k=3.
- Break condition: If relevance estimation fails, the wrong experts may be activated, harming accuracy or security.

### Mechanism 3
- Claim: Scalability is achieved via modular gating with hierarchical search.
- Mechanism: gate-cluster uses clustering to reduce pairwise comparisons when m is large; gate-pairwise remains viable for moderate m.
- Core assumption: Clustering domains into s clusters preserves relevance ranking while reducing computation.
- Evidence anchors:
  - [section 4.5.3]: "gate-cluster adds an additional offline step—instead of simply computing vectors for each of the m domains, we cluster these vectors into s clusters"
  - [table 2]: Runtime comparison showing gate-cluster faster for large m
  - [corpus]: No direct evidence; assumption is based on algorithmic complexity analysis.
- Break condition: If clustering is poor, relevant experts may be missed, degrading accuracy or security.

## Foundational Learning

- Concept: Non-interference in information flow control.
  - Why needed here: Ensures outputs depend only on accessible training data, preventing leakage from inaccessible domains.
  - Quick check question: If a user has access to domains {1,2}, can the model output depend on data from domain 3? (Answer: No)

- Concept: Mixture of Experts (MoE) architecture.
  - Why needed here: Allows modular training and inference where each expert handles one security domain, enabling selective activation.
  - Quick check question: How many experts are activated at inference? (Answer: k, the top-k most relevant and accessible)

- Concept: Cosine similarity for relevance estimation.
  - Why needed here: Provides a fast, vector-based method to compare input sample text with domain representations to select experts.
  - Quick check question: What does a higher cosine similarity score between sample text and domain vector indicate? (Answer: Higher relevance of that domain's expert)

## Architecture Onboarding

- Component map: Base GPT-2 model -> Expert modules (one per domain) -> Gating function (gate-known/gate-pairwise/gate-cluster) -> Ensemble layer -> Output
- Critical path: User input → vectorize sample text → gating (select k experts) → forward pass through k experts → ensemble → output
- Design tradeoffs: More experts (higher m) improve accuracy but increase memory and gating overhead; larger k improves accuracy but increases latency.
- Failure signatures: Accuracy drops when gating selects irrelevant experts; security breach if gating uses inaccessible domain data; latency spikes if k or m is too large.
- First 3 experiments:
  1. Test gating accuracy: Provide input with known domain label and verify top-k experts match expected domains.
  2. Test security: Simulate access policy {1,2}, input from domain 3, confirm output does not leak domain 3 information.
  3. Test scalability: Increase m from 10 to 1000, measure gating latency and accuracy degradation.

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions, but based on the content, three significant unresolved questions emerge:

1. How does the proposed information flow control approach perform when applied to non-text data modalities like images, audio, or video?
2. What is the optimal balance between the number of clusters (s) and the number of domains (m) for the gate-cluster algorithm when scaling to very large numbers of security domains?
3. How does the proposed approach handle adversarial attempts to infer information about inaccessible domains through carefully crafted inputs?

## Limitations

- Security guarantees rely on architectural assumptions rather than formal proofs of non-interference
- Limited evaluation to Reddit dataset and language modeling tasks, unclear generalizability to other domains
- Trade-off between accuracy and security not fully characterized across different access policy configurations

## Confidence

High confidence in: The architectural design of MoE-based Transformer with domain-specific experts and the empirical results showing 1.9% performance overhead and 37% accuracy improvement over public-data-only baseline.

Medium confidence in: The claim that the approach provides information flow control through expert isolation, as this relies on unverified assumptions about gating function security rather than formal proofs.

Low confidence in: The scalability claims for gate-cluster, as the evaluation only compares two gating methods without exploring the full parameter space or providing formal complexity analysis.

## Next Checks

1. **Security validation**: Implement a white-box attack where an adversary tries to infer information about inaccessible domains through carefully crafted inputs, measuring whether the gating function can be manipulated to reveal domain-specific patterns.

2. **Generalization testing**: Apply the architecture to a different ML task (e.g., text classification) with real-world security domains from an organization's internal data, comparing performance to the Reddit-based evaluation.

3. **Parameter sensitivity analysis**: Systematically vary the number of experts (m), number of activated experts (k), and domain sizes to characterize the full trade-off surface between accuracy, latency, and memory usage across different access policy configurations.