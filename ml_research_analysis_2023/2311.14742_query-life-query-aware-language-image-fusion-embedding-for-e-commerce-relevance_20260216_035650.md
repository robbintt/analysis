---
ver: rpa2
title: 'Query-LIFE: Query-aware Language Image Fusion Embedding for E-Commerce Relevance'
arxiv_id: '2311.14742'
source_url: https://arxiv.org/abs/2311.14742
tags:
- image
- query
- relevance
- query-life
- product
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Query-LIFE improves e-commerce search relevance by incorporating
  image and text product information through a query-aware multimodal fusion approach.
  The method uses contrastive learning to align query, title, and image representations,
  with dynamic weighting of modalities based on product type.
---

# Query-LIFE: Query-aware Language Image Fusion Embedding for E-Commerce Relevance

## Quick Facts
- arXiv ID: 2311.14742
- Source URL: https://arxiv.org/abs/2311.14742
- Reference count: 31
- Key outcome: Query-LIFE improves e-commerce search relevance by incorporating image and text product information through a query-aware multimodal fusion approach.

## Executive Summary
Query-LIFE addresses the challenge of e-commerce search relevance by integrating both textual and visual product information through a query-aware multimodal fusion approach. The method leverages contrastive learning to align query, title, and image representations while dynamically weighting modalities based on product type. A key innovation is GenFilt, which uses large language models to filter false negative samples during training. The model was evaluated on Miravia's e-commerce platform, demonstrating significant improvements over existing baselines in both offline metrics and human evaluation, with successful deployment and improved conversion rates in production.

## Method Summary
Query-LIFE uses a three-stage training framework with query-aware modal alignment and fusion. It employs ViT-g/14 for image feature extraction and a transformer-based universal modal encoder. The model uses supervised contrastive learning for alignment and dynamically weights image and text modalities based on product type. GenFilt leverages LLM and InstructBLIP to filter false negatives during training. The approach was evaluated on large-scale industrial datasets including 5M product title-image pairs and 1.3M <query,title,image> positive pairs.

## Key Results
- AUC increased by 0.021 compared to existing baselines
- Human evaluation showed 4.42% increase in "Excellent" relevance ratings
- Successfully deployed with demonstrated improved conversion rates in production
- Ablation studies show GenFilt contributes 0.042 AUC improvement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Query-LIFE improves relevance by dynamically fusing text and image representations based on product type rather than using equal weighting across all products.
- Mechanism: The model uses a query-aware multi-modal fusion module that learns to adjust the relative contribution of image and text features for each product type, leveraging the query to determine the optimal weighting.
- Core assumption: Different product categories require different relative emphasis on visual versus textual information for accurate relevance matching.
- Evidence anchors: [abstract], [section 3.4], [corpus]

### Mechanism 2
- Claim: Supervised contrastive learning with query-aware alignment improves the quality of multimodal representations compared to unsupervised contrastive learning.
- Mechanism: The model uses query-based modal alignment (QMA) with supervised contrastive loss to align query representations with multimodal product representations, creating tighter clusters of positive pairs and greater separation from negative samples.
- Core assumption: Labeled positive and negative samples in the contrastive learning framework provide better guidance for representation learning than unlabeled data.
- Evidence anchors: [abstract], [section 3.3], [section 4.5]

### Mechanism 3
- Claim: GenFilt improves training quality by filtering out false negative samples that arise from in-batch sampling in triplet data.
- Mechanism: GenFilt uses LLM and InstructBLIP to generate features from titles and images, then applies similarity thresholds to identify and correct false negative pairs during training.
- Core assumption: In-batch sampling introduces false negatives when different products can be relevant to the same query, and these can be identified through feature similarity.
- Evidence anchors: [abstract], [section 3.5], [section 4.5]

## Foundational Learning

- Concept: Contrastive learning and its variants (supervised vs unsupervised)
  - Why needed here: Query-LIFE uses supervised contrastive learning for query-product alignment, which requires understanding the differences between supervised and unsupervised approaches.
  - Quick check question: What is the key difference between supervised and unsupervised contrastive learning in terms of available labels?

- Concept: Vision-Language Pre-training (VLP) models and their limitations
  - Why needed here: The paper builds upon existing VLP models but addresses their shortcomings in query-aware alignment.
  - Quick check question: Why do general VLP models like CLIP and BLIP2 perform worse than BERT on e-commerce relevance tasks according to the ablation studies?

- Concept: Multimodal fusion techniques and their applications
  - Why needed here: Query-LIFE introduces a query-aware multimodal fusion approach that dynamically weights different modalities.
  - Quick check question: How does the query-aware fusion in Query-LIFE differ from the traditional divide-and-conquer approach?

## Architecture Onboarding

- Component map: ViT-g/14 → Universal Modal Encoder → GenFilt → Fusion Representation
- Critical path: Query → Universal Modal Encoder → Fusion Representation → Relevance Score → Ranking
- Design tradeoffs:
  - Dynamic vs fixed modality weighting: More accurate but computationally heavier
  - Supervised vs unsupervised contrastive learning: Better alignment but requires labeled data
  - GenFilt complexity: Improves training quality but adds computational overhead
- Failure signatures:
  - Poor relevance scores: Check modality fusion weights and contrastive learning alignment
  - Slow inference: Check ViT backbone and modal encoder efficiency
  - Training instability: Check GenFilt threshold calibration and false negative filtering
- First 3 experiments:
  1. Ablation study: Remove GenFilt and compare AUC to measure false negative filtering impact
  2. Modality ablation: Compare query→title, query→image, and query→M relevance scores
  3. Weight analysis: Analyze modality weight distributions across different product types to verify dynamic fusion behavior

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Query-LIFE perform on non-fashion e-commerce domains like electronics or home goods, and what domain-specific adaptations might be necessary?
- Basis in paper: [explicit] The paper mentions product types (e.g., dresses, monitors, phones) but doesn't test on broader e-commerce domains beyond Miravia's fashion-oriented platform
- Why unresolved: The evaluation was conducted on Miravia Search, which may have different product characteristics than general e-commerce platforms. The dynamic fusion approach's effectiveness across diverse product categories remains unexplored.
- What evidence would resolve it: Comparative experiments showing Query-LIFE performance on multiple e-commerce domains (fashion, electronics, home goods) with domain-specific evaluation metrics and fusion weight analysis

### Open Question 2
- Question: What is the long-term impact of GenFilt on model training efficiency and convergence, and how does it scale with increasing dataset sizes?
- Basis in paper: [inferred] GenFilt is introduced as a solution for false negative filtering, but its computational overhead, scalability properties, and impact on training dynamics are not analyzed
- Why unresolved: The paper demonstrates GenFilt's effectiveness but doesn't provide detailed analysis of its computational cost, memory requirements, or how it affects training time and convergence rates as dataset size grows
- What evidence would resolve it: Empirical studies measuring training time, memory usage, and convergence behavior with varying dataset sizes, comparing GenFilt-enabled vs. disabled training

### Open Question 3
- Question: How robust is Query-LIFE to adversarial queries or deliberately misleading product titles/images, and what defensive mechanisms could be implemented?
- Basis in paper: [inferred] The paper addresses the problem of misleading titles and insufficient information but doesn't evaluate model robustness against adversarial attacks or explore defensive strategies
- Why unresolved: While Query-LIFE improves relevance scoring, its vulnerability to manipulated inputs (e.g., keyword stuffing, deceptive images) hasn't been tested, which is critical for real-world deployment
- What evidence would resolve it: Adversarial testing framework with systematically manipulated queries and product data, measuring Query-LIFE's resilience and proposing defensive modifications to enhance robustness

## Limitations
- Study focuses primarily on Miravia platform, limiting generalizability across different e-commerce ecosystems
- GenFilt introduces additional computational overhead and complexity that may impact practical deployment scalability
- Limited real-world deployment data beyond Miravia's platform

## Confidence
- **High Confidence**: Core claim that query-aware multimodal fusion improves e-commerce relevance is well-supported by offline metrics (AUC improvement of 0.021) and human evaluation (4.42% increase in "Excellent" ratings)
- **Medium Confidence**: Effectiveness of GenFilt in filtering false negatives is supported by quantitative metrics but lacks detailed precision and recall analysis
- **Medium Confidence**: Dynamic weighting being superior to fixed weighting across all product types is supported by results but would benefit from more granular category performance analysis

## Next Checks
1. **Cross-platform validation**: Test Query-LIFE on at least two additional e-commerce platforms with different product distributions to assess generalizability of the dynamic fusion approach.

2. **Ablation of GenFilt precision**: Measure the precision and recall of GenFilt's false negative filtering across different product categories and query types to understand its reliability and potential for introducing noise.

3. **Computational efficiency analysis**: Compare the inference time and resource requirements of Query-LIFE against baseline models across varying query loads to quantify the practical deployment costs of the additional complexity.