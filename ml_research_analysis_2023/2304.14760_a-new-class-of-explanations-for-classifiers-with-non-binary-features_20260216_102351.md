---
ver: rpa2
title: A New Class of Explanations for Classifiers with Non-Binary Features
arxiv_id: '2304.14760'
source_url: https://arxiv.org/abs/2304.14760
tags:
- prime
- vars
- reason
- general
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new class of explanations for classifiers
  with non-binary features, called general sufficient and necessary reasons. These
  explanations reveal more information about why a classifier made a particular decision
  or why it did not make some other decision.
---

# A New Class of Explanations for Classifiers with Non-Binary Features

## Quick Facts
- arXiv ID: 2304.14760
- Source URL: https://arxiv.org/abs/2304.14760
- Reference count: 26
- Key outcome: Introduces general sufficient and necessary reasons for classifiers with non-binary features, providing more informative explanations than classical reasons

## Executive Summary
This paper introduces a new class of explanations for classifiers with non-binary features, called general sufficient and necessary reasons. These explanations reveal more information about why a classifier made a particular decision or why it did not make some other decision. The authors define a new quantification operator that can be used to compute the general reason for a decision, and show that its prime implicates and implicants contain the general necessary and sufficient reasons. They also provide closed-form general reasons for a broad class of classifiers and discuss the computation of general necessary and sufficient reasons based on general reasons.

## Method Summary
The method introduces general sufficient reasons (GSRs) and general necessary reasons (GNRs) as a new class of explanations for classifiers with non-binary features. It uses a new selection operator to compute general reasons from class formulas, then extracts variable-minimal prime implicants/implicates as explanations. For decision graphs, closed-form general reasons are provided. The approach leverages the properties of monotone and fixated formulas to develop efficient computation algorithms for prime implicants and implicates.

## Key Results
- General reasons provide more informative explanations than classical reasons by allowing non-binary feature values
- General necessary reasons guarantee that any violation will flip the decision, unlike classical necessary reasons
- Closed-form general reasons are provided for decision graphs using the selection operator

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** General reasons provide more informative explanations than classical reasons by allowing non-binary feature values in explanations.
- **Mechanism:** When features are non-binary, a general reason can reference a set of values (e.g., BloodType ∈ {A, B}) instead of a single value, capturing more information about classifier behavior.
- **Core assumption:** The classifier's decision boundary depends on feature value ranges rather than single values.
- **Evidence anchors:**
  - [abstract]: "These explanations can be significantly improved in the presence of non-binary features, leading to a new class of explanations that relay more information about decisions and the underlying classifiers."
  - [section 4.1]: "What is really relevant is that BloodType ∈ { A, B}. Clearly, this kind of explanation reveals more information about why the classifier made its decision."
- **Break condition:** If the classifier's decision boundary only depends on exact feature values, not ranges, then general reasons provide no additional benefit.

### Mechanism 2
- **Claim:** General necessary reasons guarantee that any violation will flip the decision, unlike classical necessary reasons.
- **Mechanism:** A general necessary reason identifies a property that, when violated in any way, will change the decision. This provides stronger guarantees than classical necessary reasons which only guarantee some violations will flip the decision.
- **Core assumption:** The classifier's decision boundary is such that violating a general necessary reason property always changes the decision.
- **Evidence anchors:**
  - [section 4.2]: "The notion of a general necessary reason comes with a stronger guarantee as shown next."
  - [section 4.2]: "The general necessary reason BMI ≥ 25 tells us that changing BMI to < 25, while keeping Age the same, is guaranteed to flip the decision."
- **Break condition:** If the classifier's decision boundary is such that some violations of a necessary reason property don't change the decision, then general necessary reasons provide no advantage.

### Mechanism 3
- **Claim:** The new quantification operator allows computing general reasons efficiently for decision graphs.
- **Mechanism:** The operator ∀ (selection) can be applied to decision graphs to compute general reasons in linear time while preserving structural properties like local fixation.
- **Core assumption:** Decision graphs have a structure that allows the new operator to be applied efficiently.
- **Evidence anchors:**
  - [section 5]: "Proposition 12. Let T be a decision graph... The general reason ∀ I · ∆c[T ] is given by the NNF..."
  - [section 6.1]: "Our first result is Algorithm 1 which computes the prime implicants of an NNF whose disjunctions satisfy the property in Proposition 13."
- **Break condition:** If the decision graph structure is too complex or doesn't satisfy the required properties, the operator may not apply efficiently.

## Foundational Learning

- **Concept: Prime implicants and prime implicates**
  - Why needed here: General sufficient reasons are prime implicants of the general reason, and general necessary reasons are prime implicates. Understanding these concepts is crucial for grasping the paper's main contributions.
  - Quick check question: What is the difference between a prime implicant and a regular implicant?

- **Concept: Monotone and fixated formulas**
  - Why needed here: Complete reasons are monotone, while general reasons are fixated. Understanding these properties is important for computational implications discussed in the paper.
  - Quick check question: How does the fixation property differ from monotonicity?

- **Concept: Decision graphs and their compilation**
  - Why needed here: The paper provides closed-form general reasons for decision graphs, which are a key application. Understanding decision graphs and their compilation is essential for appreciating the practical significance.
  - Quick check question: How are decision graphs different from decision trees?

## Architecture Onboarding

- **Component map:**
  - Formula representation system (discrete variables)
  - Universal literal quantification operator (∀)
  - Selection operator (∀)
  - Decision graph structure
  - Prime implicant/implicate computation algorithms

- **Critical path:**
  1. Parse classifier into class formulas
  2. Apply selection operator to get general reason
  3. Compute prime implicants/implicates of general reason
  4. Extract variable-minimal prime implicants/implicates as explanations

- **Design tradeoffs:**
  - Using general reasons vs. classical reasons: more informative but potentially more complex
  - Computing all variable-minimal prime implicants vs. just one: more complete but potentially slower
  - Using decision graphs vs. other representations: efficient computation but may not cover all classifier types

- **Failure signatures:**
  - If the classifier has only binary features, general reasons provide no additional benefit
  - If the decision boundary is such that violations don't always flip the decision, general necessary reasons provide no advantage
  - If the decision graph structure is too complex, the selection operator may not apply efficiently

- **First 3 experiments:**
  1. Implement the selection operator and test on simple decision trees
  2. Compare explanations generated by classical vs. general reasons on a dataset with non-binary features
  3. Benchmark computation time of general reasons vs. classical reasons on various decision graph structures

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the selection operator ∀ be generalized beyond state selection to capture other types of variable abstractions?
  - Basis in paper: [explicit] The paper introduces a new selection operator ∀ for computing general reasons, which generalizes the universal literal quantification operator ∀.
  - Why unresolved: The paper focuses on applying the selection operator to states, but doesn't explore whether it can be generalized to other types of variable abstractions.
  - What evidence would resolve it: Extending the selection operator to other abstractions (e.g., intervals for numeric features, higher-order predicates) and demonstrating its effectiveness in computing more informative explanations.

- **Open Question 2:** Are there more efficient algorithms for computing general necessary and sufficient reasons beyond the incremental pruning techniques described in the paper?
  - Basis in paper: [inferred] The paper discusses incremental pruning techniques for computing prime implicants and implicates, but doesn't explore alternative approaches.
  - Why unresolved: The paper acknowledges the computational challenges in computing prime implicants and implicates, but doesn't propose more efficient algorithms.
  - What evidence would resolve it: Developing new algorithms that leverage the properties of general reasons (e.g., fixation, variable minimality) to improve computational efficiency.

- **Open Question 3:** How can the concepts of general reasons and explanations be extended to handle continuous features or more complex data types?
  - Basis in paper: [inferred] The paper focuses on classifiers with discrete features and discretizes numeric features for explanation purposes.
  - Why unresolved: The paper doesn't address the challenges of explaining classifiers with continuous features or other complex data types.
  - What evidence would resolve it: Developing methods to compute general reasons and explanations for classifiers with continuous features or other complex data types, and evaluating their effectiveness in providing informative explanations.

## Limitations

- Computational complexity of finding variable-minimal prime implicants and implicates is a significant limitation
- The resolution-based method for computing prime implicates may blow up in size for complex formulas
- The approach is limited to classifiers with discrete features, requiring discretization of numeric features

## Confidence

- High confidence in the theoretical framework and definitions of general reasons (Section 3-4)
- Medium confidence in the closed-form general reasons for decision graphs (Section 5)
- Low confidence in the scalability of the computational methods for prime implicants/implicates (Section 6)

## Next Checks

1. Benchmark the computational methods on real-world classifiers with non-binary features to assess scalability.
2. Conduct user studies to evaluate the practical value of general reasons compared to classical reasons in explaining classifier decisions.
3. Investigate approximation methods or heuristics for finding variable-minimal prime implicants/implicates when exact computation is intractable.