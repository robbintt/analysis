---
ver: rpa2
title: Exploring the Reversal Curse and Other Deductive Logical Reasoning in BERT
  and GPT-Based Large Language Models
arxiv_id: '2312.03633'
source_url: https://arxiv.org/abs/2312.03633
tags:
- bert
- llama
- language
- union
- sets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated the "Reversal Curse" phenomenon in large
  language models (LLMs), where models trained on "A is B" fail to infer "B is A".
  While previous research focused on autoregressive models like GPT, this study examined
  bidirectional models like BERT and found that BERT is immune to the reversal curse.
---

# Exploring the Reversal Curse and Other Deductive Logical Reasoning in BERT and GPT-Based Large Language Models

## Quick Facts
- arXiv ID: 2312.03633
- Source URL: https://arxiv.org/abs/2312.03633
- Authors: 
- Reference count: 30
- Primary result: BERT is immune to the reversal curse while GPT models are not, and both model types struggle with complex logical operations involving three sets despite performing well on simple two-set operations.

## Executive Summary
This study investigates the "Reversal Curse" phenomenon in large language models, where models trained on "A is B" fail to infer "B is A." While previous research focused on autoregressive models like GPT, this study examines bidirectional models like BERT and finds that BERT is immune to the reversal curse. The research also evaluates both BERT and GPT models' abilities to perform logical reasoning tasks involving intersection and union operations on sets. Results show that while both model types perform well on simple tasks involving two sets, they struggle with more complex operations involving three sets.

## Method Summary
The study fine-tunes BERT (bidirectional encoder) and Llama 2 (unidirectional decoder) on synthetic datasets containing logical relationships and set operations. BERT uses binary classification with cross-entropy loss, while Llama 2 uses next-token prediction with LoRA fine-tuning. Evaluation includes accuracy on forward and reverse logical deductions, exact entity-match accuracy, and 80% match thresholds. The datasets consist of four name categories (Superhero, Dinosaur, Mammal, Bird), each with 30 unique names, with positive and negative samples constructed for intersection (∩) and union (∪) operations on two sets, and complex scenarios with three sets.

## Key Results
- BERT achieves high accuracy on both forward and reverse logical deductions, demonstrating immunity to the reversal curse
- Both BERT and Llama 2 models perform well on simple set operations involving two sets but struggle with complex operations involving three sets
- BERT shows slightly higher average accuracy than Llama 2 on logical reasoning tasks, though both models demonstrate strong performance on simpler operations

## Why This Works (Mechanism)

### Mechanism 1
BERT's bidirectional architecture prevents the reversal curse by allowing joint updating of embeddings for both directions of a relation. Unlike autoregressive models, BERT uses masked self-attention where all tokens interact during training, updating embeddings for both "A is B" and "B is A" simultaneously. This joint embedding allows BERT to learn symmetric relationships regardless of token order.

### Mechanism 2
Linear regression models demonstrate that the reversal curse can occur even in simple supervised learning when the covariance structure between variables differs significantly. When predicting Y from X versus X from Y, the regression coefficients differ due to different variance structures, leading to poor generalization in reverse directions. This mathematical foundation explains why unidirectional models struggle with reverse relationships.

### Mechanism 3
Encoder models like BERT excel at classification tasks involving logical relationships, while decoder models like GPT excel at sequence prediction tasks. BERT's architecture optimizes for understanding bidirectional context, making it effective for binary classification of logical relationships, while GPT's architecture optimizes for next-token prediction, making it better suited for generating sequences.

## Foundational Learning

- Concept: Bidirectional vs. unidirectional attention mechanisms
  - Why needed here: Understanding why BERT avoids the reversal curse while GPT does not requires grasping how bidirectional attention differs from masked self-attention in decoder models.
  - Quick check question: What is the key architectural difference between BERT and GPT that allows BERT to learn "B is A" from "A is B"?

- Concept: Set operations (intersection, union) and their logical properties
  - Why needed here: The paper evaluates models' ability to learn and apply set operations, requiring understanding of how these operations work mathematically and logically.
  - Quick check question: What is the result of (A ∩ B) ∪ C when C contains elements not in A or B?

- Concept: Text classification vs. sequence generation tasks
  - Why needed here: Different evaluation metrics are used for BERT (classification) versus Llama 2 (sequence generation), requiring understanding of these task types and their appropriate metrics.
  - Quick check question: How does the accuracy metric differ between a binary classification task and a sequence generation task?

## Architecture Onboarding

- Component map: BERT encoder model with bidirectional attention, classification head; GPT/Llama 2 decoder model with masked self-attention, autoregressive generation head
- Critical path: Data preparation → Model fine-tuning → Evaluation on simple tasks → Evaluation on complex tasks → Analysis of failure patterns
- Design tradeoffs: BERT trades sequential generation capability for bidirectional understanding; GPT trades bidirectional understanding for sequential generation capability
- Failure signatures: BERT fails when encountering entirely new entities outside training sets; GPT fails on complex logical operations involving multiple sets
- First 3 experiments:
  1. Fine-tune BERT on the reversal curse dataset and evaluate accuracy on both forward and reverse directions
  2. Fine-tune BERT and Llama 2 on simple set operations (two sets) and compare performance
  3. Apply fine-tuned models to complex set operations (three sets) and analyze failure patterns

## Open Questions the Paper Calls Out

### Open Question 1
How does BERT's bidirectional architecture specifically enable it to overcome the reversal curse that affects GPT models? While the paper explains that BERT's bidirectional nature helps it overcome the reversal curse, it does not provide a detailed analysis of the specific mechanisms or architectural features that enable this capability.

### Open Question 2
Can BERT and GPT models be further improved to handle more complex logical reasoning tasks involving three sets or more? The paper identifies the limitation but does not explore potential methods or architectures that could enhance the models' ability to perform more complex logical reasoning.

### Open Question 3
How does the choice between BERT and GPT impact their effectiveness in real-world applications, such as constructing biomedical knowledge graphs? While the paper highlights the strengths of each model, it does not provide empirical evidence or case studies demonstrating their effectiveness in specific real-world applications.

## Limitations
- The synthetic nature of the datasets limits generalizability to real-world applications
- The paper does not explore whether these findings extend to other bidirectional models beyond BERT or other logical reasoning tasks beyond set operations
- The underlying mechanism explaining BERT's immunity to the reversal curse requires further theoretical validation

## Confidence
- **High Confidence:** Both BERT and Llama 2 models struggle with complex set operations involving three sets, supported by consistent performance drops across multiple evaluation metrics
- **Medium Confidence:** BERT is immune to the reversal curse, supported by experimental results but lacking theoretical explanation for the underlying mechanism
- **Low Confidence:** BERT's superiority in logical reasoning tasks makes it more suitable for certain applications than GPT models, requiring additional validation across diverse real-world scenarios

## Next Checks
1. Develop mathematical proofs or theoretical analysis explaining why bidirectional attention prevents the reversal curse
2. Apply the same experimental framework to naturally occurring text datasets with logical relationships to validate findings outside synthetic data
3. Test additional bidirectional encoder models (e.g., RoBERTa, DeBERTa) and decoder models (e.g., GPT-3, PaLM) on the same tasks to determine if patterns represent broader architectural differences