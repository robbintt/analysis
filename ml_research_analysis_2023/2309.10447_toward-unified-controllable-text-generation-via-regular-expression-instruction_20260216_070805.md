---
ver: rpa2
title: Toward Unified Controllable Text Generation via Regular Expression Instruction
arxiv_id: '2309.10447'
source_url: https://arxiv.org/abs/2309.10447
tags:
- expression
- language
- length
- text
- constraint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a unified method for controllable text generation
  using regular expression-style instructions (REI). REI models various fine-grained
  constraints (lexical, positional, length) and their combinations through a regular
  expression-based instruction language, enabling both fine-tuning on medium-sized
  models and few-shot in-context learning on large models.
---

# Toward Unified Controllable Text Generation via Regular Expression Instruction

## Quick Facts
- arXiv ID: 2309.10447
- Source URL: https://arxiv.org/abs/2309.10447
- Reference count: 29
- Primary result: REI achieves high success rates across lexicon, positional, and length constraints, with FLAN-T5-xl maintaining >95% success and outperforming most baselines.

## Executive Summary
This paper introduces REI (Regular Expression Instruction), a unified method for controllable text generation that encodes fine-grained constraints using a regular expression-style instruction language. REI supports lexicon, positional, and length constraints, as well as their combinations, through HTML-like markup that helps models distinguish instructions from data. The method is validated through fine-tuning medium-sized models (FLAN-T5-xl) and few-shot in-context learning on large models (GPT-3.5), achieving high success rates while maintaining text quality and outperforming most previous baselines.

## Method Summary
REI uses HTML-like markup to create regular expression-style instructions that encode lexicon, positional, and length constraints. The method involves parsing REI expressions into regular expressions, generating text via fine-tuned FLAN-T5-xl or few-shot GPT-3.5, and using rejection sampling to ensure constraint satisfaction. For fine-tuning, FLAN-T5-xl is trained on datasets like αNLG, αNLI, and CommonGen for 3 epochs with batch size 16 and learning rate 3e-5. For few-shot learning, GPT-3.5 uses 8 examples per prompt with temperature 0.7 and up to 8 retries. The approach handles constraint combinations through regular expression expressiveness and validates outputs via pattern matching.

## Key Results
- REI achieves >95% success rate for all constraint types with FLAN-T5-xl, demonstrating strong performance across lexicon, positional, and length constraints.
- GPT-3.5 performs well in few-shot settings for simpler constraints, though success rates drop for composite constraints.
- REI outperforms most previous baselines in both success rate and automatic evaluation metrics (BLEU-4, CIDEr, SPICE, ROUGE-L, BERTScore) across multiple datasets.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: REI's HTML-like markup helps models distinguish instructions from data, improving accuracy.
- Mechanism: Markup labels act as syntactic boundaries, signaling where instructions begin and end to reduce ambiguity.
- Core assumption: Models can learn to parse and respect markup-based instruction boundaries during training or in-context learning.
- Evidence anchors: Abstract and section 2.1 discuss markup language use; corpus neighbors don't directly validate this mechanism.
- Break condition: If models fail to generalize markup meaning beyond training examples or if tags interfere with language understanding.

### Mechanism 2
- Claim: REI unifies multiple constraint types via regular expression-style instructions, eliminating need for separate architectures.
- Mechanism: Regular expression format allows same model and inference process to handle any constraint combination without architectural changes.
- Core assumption: Regular expressions are expressive enough to encode all relevant constraint combinations without precision loss.
- Evidence anchors: Abstract and section 2.1 describe regular expression expressiveness; corpus neighbors discuss unified instruction-tuning but not REI's specific encoding.
- Break condition: If certain constraint combinations cannot be represented in regular expression form or models cannot interpret complex nested expressions.

### Mechanism 3
- Claim: REI's instruction-based approach achieves high success rates while maintaining text quality, outperforming most baselines.
- Mechanism: Clear instruction syntax, flexible constraint encoding, and rejection sampling for validation lead to high constraint satisfaction without sacrificing quality.
- Core assumption: Rejection sampling is computationally feasible and doesn't degrade performance in practice.
- Evidence anchors: Abstract and section 2.3 discuss high success rates and rejection sampling; corpus neighbors don't report on rejection sampling effectiveness.
- Break condition: If rejection sampling becomes too inefficient for longer or more complex constraints, or leads to mode collapse.

## Foundational Learning

- Concept: Regular expressions and their expressive power for pattern matching.
  - Why needed here: REI's instruction language is based on regular expression syntax; understanding this is essential for designing or modifying constraints.
  - Quick check question: Can you write a regular expression that matches any string containing "dance" and "stage" in that order with any number of words in between?

- Concept: Text generation constraints (lexical, positional, length) and their practical implications.
  - Why needed here: REI supports these three constraint types; knowing their differences helps in constructing appropriate expressions.
  - Quick check question: What's the difference between a lexical constraint ("include word X") and a positional constraint ("place word X after position Y")?

- Concept: Rejection sampling and its trade-offs in constrained generation.
  - Why needed here: REI uses rejection sampling to enforce constraints; understanding its efficiency and failure modes is important for deployment.
  - Quick check question: What happens to the expected number of generations if constraint satisfaction probability is very low?

## Architecture Onboarding

- Component map: Instruction parser -> Model interface (FLAN-T5-xl or GPT-3.5) -> Rejection sampler -> Evaluation module

- Critical path: 1) Parse REI expression → regular expression. 2) Generate candidate text using model. 3) Validate candidate against regular expression and length constraint. 4) Return valid text or retry up to k times.

- Design tradeoffs: Fine-tuning vs few-shot (higher success vs more flexibility), rejection sampling vs constrained decoding (simpler vs potentially more efficient), regular expression expressiveness vs model interpretability (more complex expressions may be harder to follow).

- Failure signatures: Low success rate despite valid outputs (overly strict or ambiguous REI expressions), high retry count (constraint satisfaction probability too low), degraded text quality (model overfitting to REI syntax).

- First 3 experiments: 1) Validate simple REI expression with FLAN-T5-xl produces valid output. 2) Test GPT-3.5 few-shot performance on same expression with 8 examples. 3) Combine two constraints and measure success rate drop and text quality impact.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does REI perform when applied to multi-hop reasoning tasks requiring chaining multiple constraints?
- Basis in paper: Inferred from discussion of various constraint types and combinations, but no specific experiments on multi-hop reasoning.
- Why unresolved: Paper doesn't provide experiments or results on multi-hop reasoning tasks.
- What evidence would resolve it: Experiments evaluating REI performance on multi-hop reasoning tasks with multiple chained constraints.

### Open Question 2
- Question: Can REI be extended to handle semantic-level constraints like sentiment or topic?
- Basis in paper: Explicit mention that REI focuses on lexical level while approaches exist for semantic level.
- Why unresolved: Paper doesn't discuss extensions of REI to handle semantic-level constraints.
- What evidence would resolve it: Experiments demonstrating REI's effectiveness with semantic-level constraints like sentiment or topic.

### Open Question 3
- Question: How does REI compare to other approaches in terms of computational efficiency and scalability?
- Basis in paper: Explicit mention that REI requires only fine-tuning or few-shot learning, but no direct comparison with other approaches.
- Why unresolved: Paper doesn't provide comprehensive comparison of REI with other approaches in computational efficiency and scalability.
- What evidence would resolve it: Thorough analysis comparing computational efficiency and scalability of REI with other state-of-the-art approaches.

## Limitations
- Rejection sampling may become computationally expensive for longer texts or complex constraint combinations, especially in few-shot settings.
- Evaluation relies heavily on automatic metrics and success rate without human evaluation of text quality and coherence.
- Paper doesn't thoroughly explore scalability of REI expressions for very complex or nested constraints, and recursive decoding for multiple options isn't fully evaluated.

## Confidence
- **High confidence**: REI achieves high success rates across constraint types (well-supported by extensive experimental results).
- **Medium confidence**: REI outperforms most previous baselines (supported by comparisons but lacks exploration of all relevant methods and human evaluation).
- **Medium confidence**: HTML-like markup helps model distinguish instructions from data (plausible but not directly validated).

## Next Checks
1. Measure average number of rejection sampling attempts for different constraint types and combinations to quantify computational overhead.
2. Conduct human evaluation comparing REI-generated text with baselines on coherence, naturalness, and constraint satisfaction for multiple constraints.
3. Design and test REI expressions with deeply nested or highly complex constraint combinations to evaluate scalability of regular expression format and model's instruction-following capability.