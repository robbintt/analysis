---
ver: rpa2
title: 'Natural Language Processing for Drug Discovery Knowledge Graphs: promises
  and pitfalls'
arxiv_id: '2310.15572'
source_url: https://arxiv.org/abs/2310.15572
tags:
- data
- drug
- knowledge
- such
- biomedical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The authors discuss how natural language processing (NLP) can\
  \ expand biomedical knowledge graphs (KGs) for drug discovery. They highlight the\
  \ potential of NLP to extract valuable relationships (e.g., causative verbs like\
  \ \u201Cactivates\u201D) from millions of scientific documents, which would be impossible\
  \ to do manually."
---

# Natural Language Processing for Drug Discovery Knowledge Graphs: promises and pitfalls

## Quick Facts
- arXiv ID: 2310.15572
- Source URL: https://arxiv.org/abs/2310.15572
- Reference count: 40
- The authors discuss how natural language processing (NLP) can expand biomedical knowledge graphs (KGs) for drug discovery, highlighting both potential benefits and pitfalls.

## Executive Summary
The article explores how natural language processing can expand biomedical knowledge graphs for drug discovery by extracting relationships from scientific literature. While NLP offers the promise of automating data extraction from millions of documents, the authors identify several critical pitfalls including incorrect named entity recognition, missing context in extracted triples, and the introduction of overly generic or misleading information. The authors emphasize that successful KG expansion requires careful filtering, domain-specific queries, and iterative refinement to maintain data quality while avoiding corruption of the knowledge graph's integrity.

## Method Summary
The method involves using NLP to extract triples from unstructured biomedical text (primarily MEDLINE) and integrate them with structured data from sources like STRING and DrugBank. The approach employs domain-specific NLP queries with high disambiguation thresholds to identify precise relationships (e.g., drug-TREATS-disease). Entities are mapped to standardized ontologies like UMLS, and triples are generated with metadata including factuality scores. The method also proposes schema enhancements like ProteinFeature nodes to preserve context that might otherwise be lost. Manual review is suggested for high-precision applications, though scalability concerns are noted.

## Key Results
- NLP-derived triples can add biologically meaningful relationship verbs (e.g., "activates", "phosphorylates") to protein-protein interaction data from structured sources.
- Strict, domain-specific NLP queries with high disambiguation thresholds can yield high-precision triples for KG expansion while avoiding noise.
- Introducing ProteinFeature nodes in the KG schema mitigates errors from NLP triples that omit critical context (e.g., "gene CAUSES disease" instead of "mutated gene CAUSES disease").

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** NLP-derived triples can add biologically meaningful relationship verbs (e.g., "activates", "phosphorylates") to protein-protein interaction data from structured sources.
- **Mechanism:** Structured sources like STRING typically only provide binary links (e.g., MAP2K1 ↔ MAPK3) without directional or mechanistic detail. NLP extracts causative verbs from literature that specify the direction and type of interaction, enabling more precise causal reasoning in the KG.
- **Core assumption:** Sentences in biomedical literature contain explicit causative verbs that can be reliably extracted and mapped to protein interactions.
- **Evidence anchors:**
  - [section] "In this case, we have evidence from NLP that MAP2K1 phosphorylates and activates MAPK3 from sentences such as: 'Mek1/2 are direct substrates of Raf kinases and phosphorylated Mek1/2 activate downstream Erk1/2.'"
  - [abstract] "The fundamental promise of NLP for KGs is the automated extraction of data from millions of documents – a task practically impossible to do via human curation alone."
- **Break condition:** If causative verbs are not explicitly stated in text, or NLP misidentifies the subject/object roles, the directionality information will be incorrect, potentially misleading downstream drug target inference.

### Mechanism 2
- **Claim:** Strict, domain-specific NLP queries with high disambiguation thresholds can yield high-precision triples for KG expansion while avoiding noise.
- **Mechanism:** By setting stringent matching criteria (e.g., entity within one word of "treat*", within twenty words of "conclusion*"), and tuning disambiguation scores to favor precision, the NLP pipeline reduces false positives from ambiguous entity recognition or generic parent terms.
- **Core assumption:** The biomedical literature contains sufficient high-quality, domain-relevant evidence in well-structured sentences to support precise triple extraction.
- **Evidence anchors:**
  - [section] "Typically, we would then manually check the results for false positives and filter the data appropriately."
  - [section] "At Evotec we are working towards incorporating such a system into our pipeline for extracting triples. Currently, we exclude sentences that contain trigger words like 'not' or 'investigated'."
- **Break condition:** If the literature corpus is sparse or inconsistent in expressing relationships in the required form, recall will drop dramatically, missing valid triples and reducing KG coverage.

### Mechanism 3
- **Claim:** Introducing ProteinFeature nodes in the KG schema mitigates errors from NLP triples that omit critical context (e.g., "gene CAUSES disease" instead of "mutated gene CAUSES disease").
- **Mechanism:** By representing mutations or other protein features as separate nodes linked to genes and diseases, the KG preserves the necessary context that would otherwise be lost in a flat triple representation.
- **Core assumption:** Protein features (mutations, modifications) are distinct entities that can be modeled as nodes, and the relationship between these features and diseases is both explicit and reliable in the literature.
- **Evidence anchors:**
  - [section] "With Evotec's KG schema, we mitigate against this sort of error by including ProteinFeature nodes that can, in turn, be linked to diseases."
  - [section] "Here, the 'TP53 gene mutation' is the ProteinFeature. The 'Relationship properties' box shows the evidence for this link in the sentence..."
- **Break condition:** If the literature does not consistently describe the mutation-disease relationship in a form that can be reliably extracted, the added schema complexity may not improve accuracy.

## Foundational Learning

- **Concept:** Named Entity Recognition (NER) and entity linking in biomedical NLP.
  - **Why needed here:** Errors in NER (e.g., COX1 → cytochrome c oxidase instead of cyclo-oxygenase) directly lead to incorrect triples in the KG, corrupting downstream analyses.
  - **Quick check question:** What are the two different proteins that share the synonym "COX1", and why is this ambiguity problematic?

- **Concept:** Disambiguation score tuning (precision vs recall) in NLP pipelines.
  - **Why needed here:** High recall increases coverage but introduces noise; high precision reduces errors but may miss valid triples. Balancing these affects KG data quality.
  - **Quick check question:** How does adjusting the disambiguation threshold affect the number of hits for a given entity, and what trade-off does this represent?

- **Concept:** Knowledge graph schema design and canonicalization (e.g., BIOLINK).
  - **Why needed here:** Different KG schemas can yield different predictions; standardization efforts aim to improve interoperability and consistency across biomedical KGs.
  - **Quick check question:** What is the difference between a "Gene-HAS_FEATURE-ProteinFeature" schema and a "Gene-MUTANT_VERSION-Disease" schema, and why might one be preferred over the other?

## Architecture Onboarding

- **Component map:** NLP Engine (commercial or custom) -> Entity Recognition & Disambiguation -> Relationship Extraction -> Triple Formation -> KG Ingestion
- **Critical path:** Input: Biomedical literature corpus (e.g., MEDLINE) -> Process: NLP extraction -> Disambiguation -> Triple generation -> Output: KG triples with provenance and metadata (factuality score, source, disambiguation confidence)
- **Design tradeoffs:** Precision vs Recall: High disambiguation thresholds reduce false positives but may miss valid triples; Schema Granularity: Adding ProteinFeature nodes increases expressiveness but adds complexity; Factuality vs Coverage: Excluding speculative sentences improves reliability but reduces KG size
- **Failure signatures:** Incorrect entity linking -> wrong triples (e.g., COX1 error); Missing context -> misleading assertions (e.g., "TP53 CAUSES neuroblastoma"); Overly generic terms -> noisy triples (e.g., "vasoactive agent TREATS shock"); Speculative language -> false facts (e.g., "Whether X is responsible... deserves further investigation")
- **First 3 experiments:** 1) Run a domain-specific NLP query for "protein-TREATS-disease" triples with high disambiguation threshold; compare precision and recall against a manually curated gold standard; 2) Implement a ProteinFeature node schema and extract mutation-disease triples; measure improvement in contextual accuracy over flat gene-disease triples; 3) Apply a factuality scoring system to filter speculative sentences; assess impact on downstream link prediction accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can NLP pipelines be optimized to reduce false positives and negatives in named entity recognition and ontology linking for biomedical knowledge graphs?
- **Basis in paper:** [explicit] The authors discuss the challenges of incorrect named entity recognition and ontology linking, which can lead to erroneous inferences and conclusions.
- **Why unresolved:** The paper highlights the complexity of biomedical text and the variety of synonyms and acronyms, which make accurate NER challenging. It also mentions that the prevalence of NER errors depends on the NLP tool used, but does not provide a specific solution to reduce these errors.
- **What evidence would resolve it:** Comparative studies evaluating the performance of different NLP tools on biomedical text, or the development of new NLP techniques specifically designed to handle the complexities of biomedical language.

### Open Question 2
- **Question:** How can the context of extracted relationships be preserved to avoid misrepresentation of assertions in biomedical knowledge graphs?
- **Basis in paper:** [explicit] The authors provide examples of how the lack of context in extracted relationships can lead to misleading assertions, such as the incorrect association of TP53 gene with neuroblastoma.
- **Why unresolved:** The paper highlights the importance of context but does not provide a specific method for preserving context during the extraction process.
- **What evidence would resolve it:** Development and evaluation of NLP techniques that can accurately capture and preserve the context of relationships in biomedical text.

### Open Question 3
- **Question:** How can the granularity of extracted information be balanced to avoid adding noise to biomedical knowledge graphs?
- **Basis in paper:** [explicit] The authors discuss the challenge of adding noise to knowledge graphs due to the inclusion of overly generic or unhelpful information, such as the triple "vasoactive agent-TREATS-shock."
- **Why unresolved:** The paper suggests filtering out parent terms manually or using ontology hierarchies, but does not provide a systematic approach to determine the optimal level of granularity for different tasks.
- **What evidence would resolve it:** Studies evaluating the impact of different levels of granularity on the performance of knowledge graphs for specific tasks, or the development of automated methods to determine the optimal level of granularity based on the task and domain.

## Limitations

- The specific NLP queries and disambiguation thresholds used by Evotec are proprietary and not disclosed, limiting reproducibility.
- The exact schema and embedding models used for Evotec's KG are not fully detailed, making it difficult to assess generalizability.
- The article does not provide quantitative metrics (e.g., precision, recall, F1 scores) for NLP-derived triples, relying instead on qualitative examples.
- The scalability of manual review pipelines for large-scale KG expansion is not addressed.

## Confidence

- **High Confidence:** The promise of NLP to extract causative verbs and add mechanistic detail to structured KG data is well-supported by examples (e.g., MAP2K1 phosphorylates and activates MAPK3).
- **Medium Confidence:** The effectiveness of strict, domain-specific queries with high disambiguation thresholds to reduce noise is plausible but lacks quantitative validation.
- **Low Confidence:** The claim that introducing ProteinFeature nodes universally mitigates context errors is theoretical and not empirically validated across diverse datasets.

## Next Checks

1. **Quantitative Evaluation:** Measure precision, recall, and F1 scores of NLP-derived triples against a manually curated gold standard for protein-protein interaction relationships.
2. **Schema Comparison:** Implement both flat and ProteinFeature-based schemas, then compare downstream link prediction accuracy to assess the impact of schema complexity.
3. **Factuality Filtering:** Apply a factuality scoring system to filter speculative sentences and evaluate its impact on KG reliability and downstream drug target inference.