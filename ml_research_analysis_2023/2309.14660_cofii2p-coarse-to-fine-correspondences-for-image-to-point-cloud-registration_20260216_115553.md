---
ver: rpa2
title: 'CoFiI2P: Coarse-to-Fine Correspondences for Image-to-Point Cloud Registration'
arxiv_id: '2309.14660'
source_url: https://arxiv.org/abs/2309.14660
tags:
- registration
- matching
- point
- cloud
- cofii2p
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes CoFiI2P, a novel coarse-to-fine image-to-point
  cloud (I2P) registration network. The key innovation is to establish correspondences
  in a progressive manner, first at the coarse super-point/super-pixel level using
  a novel I2P transformer module, then at the fine pixel/point level guided by the
  coarse correspondences.
---

# CoFiI2P: Coarse-to-Fine Correspondences for Image-to-Point Cloud Registration

## Quick Facts
- arXiv ID: 2309.14660
- Source URL: https://arxiv.org/abs/2309.14660
- Reference count: 40
- Key outcome: Proposes a coarse-to-fine image-to-point cloud registration network that achieves state-of-the-art performance on KITTI with 1.14° RRE and 0.29m RTE.

## Executive Summary
CoFiI2P introduces a novel coarse-to-fine strategy for image-to-point cloud registration, addressing the local optima problem common in one-stage methods. The approach first establishes coarse correspondences at the super-point/super-pixel level using a novel I2P transformer module, then refines these matches at the fine pixel/point level guided by the coarse matches. This progressive matching strategy filters out most mismatches early and provides global guidance, significantly improving registration accuracy. Experiments on KITTI demonstrate state-of-the-art performance, with strong generalizability shown on the NuScenes dataset.

## Method Summary
CoFiI2P implements a two-stage registration pipeline. The coarse matching (CM) stage extracts multi-scale features from both image and point cloud using ResNet-34 and KPConv-FPN, then applies an I2P transformer to capture homogeneous and heterogeneous global context through self-attention and cross-attention mechanisms. This produces super-point/super-pixel correspondences. The fine matching (FM) stage uses these coarse matches to define local patches and employs a pyramid-matching strategy to establish dense point-pixel correspondences. Finally, EPnP-RANSAC estimates the 6-DoF transformation from the dense matches.

## Key Results
- Achieves 1.14° relative rotation error and 0.29m relative translation error on KITTI test set
- Demonstrates strong generalizability with consistent performance on NuScenes dataset
- Shows significant improvements over state-of-the-art methods in registration recall and inlier ratio

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Coarse-to-fine matching filters mismatches early and reduces local optima risk
- Mechanism: By first matching super-points/super-pixels at coarse resolution, the method rejects obvious mismatches before fine matching. This global guidance prevents the fine stage from converging to local minima caused by outlier correspondences.
- Core assumption: Super-points/super-pixels carry enough discriminative information to form reliable coarse matches that guide fine matching.
- Evidence anchors:
  - [abstract] "first at the coarse super-point/super-pixel level... then at the fine pixel/point level guided by the coarse correspondences"
  - [section] "CM constructs coarse matching at super-pixel/super-point level... FM constructs fine matching at pixel/point level sequentially with super-pixel/super-point correspondences' guidance"
- Break condition: If the coarse descriptors are too noisy or ambiguous, coarse matches will mislead the fine stage instead of guiding it.

### Mechanism 2
- Claim: I2P transformer captures both homogeneous and heterogeneous global context
- Mechanism: Self-attention within each modality learns long-range spatial dependencies; cross-attention fuses heterogeneous features between image and point cloud. This hybrid feature extraction strengthens descriptors for matching.
- Core assumption: Global attention in both modalities and cross-modality attention can encode complementary information for registration.
- Evidence anchors:
  - [abstract] "a novel I2P transformer module is employed to capture both homogeneous and heterogeneous global information"
  - [section] "self-attention modules for inter-modality long-range context and cross-attention modules for intra-modality feature exchange"
- Break condition: If attention weights are not well balanced, the transformer may overemphasize irrelevant global context and harm local detail matching.

### Mechanism 3
- Claim: Pyramid matching strategy in fine matching efficiently aligns local patches
- Mechanism: In each coarse super-point/super-pixel pair, a local patch is defined. Node points from the point patch are matched to pixels within the pixel patch in feature space. This restricts the search space and improves matching precision.
- Core assumption: Local patches centered on coarse matches contain true correspondences and are small enough to avoid introducing false matches.
- Evidence anchors:
  - [section] "taking the super-point-to-super-pixel correspondences from CM as input, point-to-pixel correspondences are generated with a pyramid-matching strategy"
  - [section] "only the node points pn in local patch group Gep are selected to establish correspondences"
- Break condition: If patches are too large, many false matches enter the fine stage; if too small, true matches are missed.

## Foundational Learning

- Concept: Cross-modality feature extraction and fusion
  - Why needed here: Image and point cloud are heterogeneous data; extracting meaningful descriptors in a shared feature space is essential for matching.
  - Quick check question: How do you ensure the image and point cloud features are in comparable scales for cosine similarity computation?

- Concept: Coarse-to-fine registration pipeline design
  - Why needed here: Direct dense matching often suffers from local optima; progressive refinement with global guidance improves robustness.
  - Quick check question: What criteria determine when the coarse stage is "good enough" to proceed to fine matching?

- Concept: Self-attention and cross-attention in transformers
  - Why needed here: Self-attention captures intra-modal spatial context; cross-attention learns cross-modal relationships, both crucial for I2P registration.
  - Quick check question: How does the number of transformer layers affect the balance between global context and computational cost?

## Architecture Onboarding

- Component map: Feature Extraction -> Coarse Matching -> Fine Matching -> Pose Estimation
- Critical path: Feature Extraction → Coarse Matching → Fine Matching → Pose Estimation
- Design tradeoffs:
  - Coarse matching reduces search space but may miss subtle correspondences
  - Self-attention increases global context but adds computation
  - EPnP-RANSAC is robust but slow for very large outlier sets
- Failure signatures:
  - High inlier ratio but poor RRE/RTE: fine matching fails to refine coarse matches
  - Low recall in frustum classification: coarse matching misses in-frustum super-points
  - RMSE grows with threshold: correspondences are not sufficiently precise
- First 3 experiments:
  1. Ablate self-attention only in I2P transformer → verify global context impact
  2. Replace coarse matching with direct dense matching → compare robustness
  3. Vary local patch radius in fine matching → tune precision vs. recall tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the CoFiI2P method perform on datasets other than KITTI and NuScenes, such as more diverse urban or rural environments?
- Basis in paper: [explicit] The paper mentions experiments on KITTI and NuScenes datasets, but does not explore performance on other datasets.
- Why unresolved: The paper focuses on two specific datasets, limiting the generalizability of the results.
- What evidence would resolve it: Testing CoFiI2P on a wider range of datasets with different environmental conditions would provide a clearer picture of its robustness and adaptability.

### Open Question 2
- Question: Can the coarse-to-fine strategy be further optimized to reduce computational complexity while maintaining or improving accuracy?
- Basis in paper: [inferred] The paper discusses the coarse-to-fine approach but does not explore potential optimizations for computational efficiency.
- Why unresolved: While the method is effective, there may be opportunities to streamline the process without sacrificing performance.
- What evidence would resolve it: Investigating alternative strategies or optimizations that reduce computational load while preserving accuracy would be valuable.

### Open Question 3
- Question: How does the performance of CoFiI2P compare to other registration methods when dealing with extreme lighting or weather conditions?
- Basis in paper: [explicit] The paper mentions testing in various environments but does not specifically address extreme conditions like fog or nighttime.
- Why unresolved: The robustness of the method under challenging conditions is not fully explored.
- What evidence would resolve it: Conducting experiments in extreme weather or lighting scenarios would help assess the method's reliability in real-world applications.

## Limitations

- Dependency on high-quality super-point/super-pixel segmentation for the coarse stage
- Performance on very sparse or noisy point clouds remains untested
- Computational cost of I2P transformer with full attention mechanisms poses scalability challenges

## Confidence

- **High Confidence**: The coarse-to-fine matching strategy effectively reduces local optima risk, as demonstrated by improved RRE/RTE metrics on KITTI.
- **Medium Confidence**: The I2P transformer's ability to capture both homogeneous and heterogeneous global context is theoretically sound, but empirical validation on diverse datasets is needed.
- **Low Confidence**: The generalizability to NuScenes dataset is promising but limited by the lack of direct comparison with other methods on the same scenes.

## Next Checks

1. **Cross-dataset Robustness**: Evaluate CoFiI2P on datasets with varying point cloud densities (e.g., nuScenes vs. KITTI) to quantify robustness to sparsity and noise.
2. **Ablation of Coarse Stage**: Remove the coarse matching stage and directly perform fine matching to isolate its contribution to overall performance.
3. **Computational Complexity Analysis**: Measure runtime and memory usage for different scene sizes to assess scalability for real-time applications.