---
ver: rpa2
title: Towards A Scalable Solution for Improving Multi-Group Fairness in Compositional
  Classification
arxiv_id: '2307.05728'
source_url: https://arxiv.org/abs/2307.05728
tags:
- fairness
- group
- each
- where
- groups
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies scalable multi-group multi-label fairness in
  compositional classification, where the final prediction is a combination of multiple
  binary classifiers. Existing in-processing methods like MinDiff scale linearly with
  the number of groups and labels, making them impractical for large systems.
---

# Towards A Scalable Solution for Improving Multi-Group Fairness in Compositional Classification

## Quick Facts
- arXiv ID: 2307.05728
- Source URL: https://arxiv.org/abs/2307.05728
- Reference count: 18
- This paper proposes task-overconditioning and group-interleaving techniques to improve the scalability of multi-group multi-label fairness methods in compositional classification.

## Executive Summary
This paper addresses the scalability challenges of in-processing fairness methods for compositional classification systems where the final prediction is a combination of multiple binary classifiers. The authors focus on MinDiff, a method that uses Maximum Mean Discrepancy (MMD) regularization to achieve equal opportunity fairness, but scales poorly with the number of groups and labels. They propose two optimization techniques: task-overconditioning, which aligns the training objective more closely with overall fairness goals, and group-interleaving, which reduces batch size requirements. Experiments on Civil Comments and a real-world policy compliance dataset demonstrate that the proposed MinDiff-IO method achieves similar fairness and performance to baseline MinDiff while significantly improving training speed and scaling better with system size.

## Method Summary
The paper studies scalable multi-group multi-label fairness in compositional classification where predictions are combinations of multiple binary classifiers. The authors propose two optimization techniques: task-overconditioning, which conditions on all labels being negative to align the training objective with overall fairness goals, and group-interleaving, which reduces batch size by presenting only one group per batch. These techniques are applied to the MinDiff approach, which uses MMD-based regularization to promote conditional independence between predictions and sensitive group membership. The method trains comment classifiers on selected labels using a single hidden layer deep neural network, evaluating fairness gap, classification performance, and training speed.

## Key Results
- MinDiff-IO achieves similar fairness and performance to baseline MinDiff while significantly improving training speed
- The proposed method scales better with the number of groups and labels compared to standard MinDiff
- Task-overconditioning reduces the number of required data streams from O(T 路 |G|) to O(|G|)
- Group-interleaving reduces batch size scaling from O(T 路 |G|) to O(1)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task-overconditioning aligns the training objective more closely with the overall fairness goal by conditioning on all labels being negative, rather than individual label negatives.
- Mechanism: Instead of computing the MMD loss for each classifier/label pair separately (requiring all combinations of positive/negative instances), task-overconditioning uses a single batch of instances where all labels are negative. This reduces the number of data streams from O(T 路 |G|) to O(|G|).
- Core assumption: The overall equal opportunity fairness goal is better served by optimizing a loss that conditions on the full set of labels being negative rather than individual labels.
- Evidence anchors:
  - [abstract]: "task-overconditioning, which aligns the training objective with the overall fairness goal by conditioning on all labels being negative"
  - [section 4.1]: "Notice that, unlike Equation (4), we condition on all labels having negative truth. This has the effect of requiring only one dataset for all tasks when computing loss rather than T datasets."
- Break condition: If the assumption that classifiers can trigger simultaneously (violating Assumption 4.2) is violated, the alignment guarantee may not hold, though empirical results still show improvement.

### Mechanism 2
- Claim: Group-interleaving reduces batch size scaling from O(T 路 |G|) to O(1) by presenting only one group per batch.
- Mechanism: Instead of creating separate data streams for each group and classifier, group-interleaving randomly selects one group per batch to include in the MinDiff regularization. This makes the optimization stochastic with respect to groups.
- Core assumption: The MinDiff loss computed with a random group per batch converges to the same objective as using all groups, just with more variance.
- Evidence anchors:
  - [section 4.2]: "Instead, group-interleaving makes the optimization objective stochastic with respect to groups at each iteration, allowing a constant scaling with the number of groups."
  - [section 4.2]: "Notice that the new loss is the same as the task-overconditioned loss in expectation, and is expected to converge to a stationary point of the same objective."
- Break condition: If the variance introduced by random group selection is too high relative to the batch size, convergence may be slower or require more iterations.

### Mechanism 3
- Claim: The combination of task-overconditioning and group-interleaving achieves similar fairness/performance to baseline MinDiff while significantly improving training speed.
- Mechanism: By reducing the number of required data streams and batch size dependencies, the proposed method can train faster while maintaining the same fairness objective.
- Core assumption: The reduced computational complexity does not compromise the quality of the learned representation or fairness metrics.
- Evidence anchors:
  - [abstract]: "Experiments on Civil Comments and a real-world policy compliance dataset show that the proposed MinDiff-IO method achieves similar fairness and performance to baseline MinDiff while significantly improving training speed and scaling better"
  - [section 6.2]: "The fourth approach adds Group Interleaving to mitigate the speed impact while maintaining similar fairness and performance characteristics."
- Break condition: If the speed improvement comes at the cost of fairness (which the experiments show it does not), the mechanism would break.

## Foundational Learning

- Concept: Multi-label classification with compositional decisions
  - Why needed here: The paper deals with systems where the final prediction is a combination (logical OR) of multiple binary classifiers, which is the core problem setup.
  - Quick check question: What is the relationship between the individual classifier predictions and the final system prediction in this compositional setup?

- Concept: Equal opportunity fairness metric
  - Why needed here: The paper focuses on remediating equal opportunity fairness gaps, specifically false positive rate differences across groups.
  - Quick check question: How is equal opportunity fairness defined for the overall compositional classifier versus individual component classifiers?

- Concept: Maximum Mean Discrepancy (MMD) for fairness regularization
  - Why needed here: The MinDiff technique uses MMD to promote conditional independence between predictions and sensitive group membership.
  - Quick check question: What role does the MMD estimator play in the MinDiff regularization approach for achieving fairness?

## Architecture Onboarding

- Component map:
  - Data preprocessing pipeline: Tokenization and vectorization of text comments
  - Model architecture: Single hidden layer neural network with 64 hidden units
  - MinDiff regularization: MMD-based loss computed on group-labeled instances
  - Task-overconditioning: Conditioning on all labels being negative for MMD computation
  - Group-interleaving: Random group selection per batch for MinDiff regularization
  - Training loop: Standard SGD with learning rate 0.1 for 25 epochs

- Critical path:
  1. Load and preprocess data (tokenize, vectorize)
  2. Initialize model parameters
  3. For each batch:
     - Sample instances with all labels negative for MinDiff
     - Randomly select one group for interleaving
     - Compute cross-entropy loss
     - Compute MinDiff loss with selected group
     - Backpropagate combined loss
  4. Evaluate fairness and performance metrics

- Design tradeoffs:
  - Task-overconditioning trades requiring T separate datasets for one unified dataset, potentially reducing sample efficiency but improving computational efficiency
  - Group-interleaving trades deterministic group representation per batch for reduced memory/compute requirements and introduces stochasticity
  - The choice of kernel and kernel parameters in MMD affects both fairness improvement quality and computational cost

- Failure signatures:
  - If task-overconditioning is applied incorrectly, it may optimize for the wrong fairness objective (individual vs compositional)
  - If group-interleaving is implemented without proper random sampling, it may introduce bias toward certain groups
  - If the batch size is too small relative to the number of groups, group-interleaving may lead to high variance in the MinDiff estimates

- First 3 experiments:
  1. Verify that task-overconditioning produces similar fairness metrics to baseline MinDiff on a small dataset with 2-3 labels and groups
  2. Test group-interleaving independently to confirm it reduces batch size requirements without degrading fairness metrics
  3. Run the full MinDiff-IO method on the Civil Comments dataset and compare fairness/performance/speed against baseline MinDiff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what conditions does overconditioning (Definition 4.1) become ineffective or provide no benefit over standard task-level fairness regularization?
- Basis in paper: [explicit] The paper mentions that overconditioning requires instances with negative ground truth for all labels, and that it assumes non-overlapping classifier outputs (Assumption 4.2), which is often unrealistic.
- Why unresolved: The paper only provides theoretical motivation under Assumption 4.2 and shows empirical results, but doesn't systematically study when the assumption breaks down or when overconditioning fails.
- What evidence would resolve it: Systematic experiments varying label overlap and positive label prevalence to identify thresholds where overconditioning's benefits disappear.

### Open Question 2
- Question: How does the interleaving approach affect convergence speed and stability compared to batch-based MinDiff, especially for large numbers of groups?
- Basis in paper: [explicit] The paper states that interleaving makes the objective stochastic with respect to groups, but doesn't provide convergence analysis or compare convergence rates.
- Why unresolved: While the paper shows final performance is similar, it doesn't examine the training dynamics or whether interleaving leads to noisier gradients or slower convergence.
- What evidence would resolve it: Training curves comparing convergence speed, variance in gradients, and final objective values for MinDiff vs. MinDiff-IO across different numbers of groups.

### Open Question 3
- Question: Can the overconditioning and interleaving techniques be generalized to other fairness regularization methods beyond MinDiff?
- Basis in paper: [inferred] The paper focuses specifically on MinDiff but mentions that future work could test application to other in-processing methods.
- Why unresolved: The paper only demonstrates these techniques with MinDiff and doesn't explore whether the core insights about batch structure and conditioning apply more broadly.
- What evidence would resolve it: Applying overconditioning and interleaving concepts to other fairness regularizers (e.g., adversarial debiasing, distributionally robust optimization) and comparing results.

## Limitations
- The approach assumes classifiers can trigger simultaneously for task-overconditioning to work correctly, which may not hold in practice
- Results are demonstrated on text classification tasks; scalability benefits for other data types or domains remain unproven
- The choice of kernel and kernel parameters in MMD significantly affects fairness improvement quality and computational cost, but this sensitivity isn't thoroughly explored

## Confidence
- **High confidence**: The core scalability improvements (task-overconditioning and group-interleaving) are mathematically sound and the experimental results showing speed improvements are robust
- **Medium confidence**: The fairness metric improvements are consistent across experiments, but the paper doesn't explore edge cases where the assumptions might break
- **Low confidence**: Claims about the "simplicity" of implementation and generalizability to other domains beyond text classification

## Next Checks
1. **Assumption stress testing**: Systematically vary the degree of classifier independence in synthetic datasets to identify the breaking point where Assumption 4.2 is violated and measure the impact on fairness performance
2. **Kernel sensitivity analysis**: Conduct experiments with different kernel types (RBF, linear, etc.) and kernel parameters to determine their impact on both fairness improvement quality and computational efficiency, providing concrete recommendations for practitioners
3. **Cross-domain validation**: Apply MinDiff-IO to non-text classification tasks (e.g., tabular data, image classification with demographic attributes) to verify the claimed scalability benefits and fairness improvements generalize beyond the demonstrated use cases