---
ver: rpa2
title: 'COPR: Consistency-Oriented Pre-Ranking for Online Advertising'
arxiv_id: '2306.03516'
source_url: https://arxiv.org/abs/2306.03516
tags:
- pre-ranking
- ranking
- copr
- online
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a consistency-oriented pre-ranking framework
  (COPR) for online advertising systems. It addresses the inconsistency between pre-ranking
  and ranking models in cascading architectures, which leads to suboptimal ad selection.
---

# COPR: Consistency-Oriented Pre-Ranking for Online Advertising

## Quick Facts
- arXiv ID: 2306.03516
- Source URL: https://arxiv.org/abs/2306.03516
- Reference count: 30
- Key outcome: COPR framework achieves up to +12.3% CTR and +5.6% RPM improvement in Taobao's display advertising system

## Executive Summary
This paper introduces COPR, a consistency-oriented pre-ranking framework that addresses the inconsistency between pre-ranking and ranking models in cascading advertising architectures. Traditional score alignment methods often fail due to error amplification by bid values, leading to suboptimal ad selection. COPR employs chunk-based sampling and a plug-and-play rank alignment module with ΔNDCG-based weighting to explicitly optimize ECPM rank consistency. The framework demonstrates significant improvements in both consistency metrics (HR@10, NDCG@10, MAP@10) and overall system performance when deployed in industrial settings.

## Method Summary
COPR introduces a chunk-based sampling module that partitions ranked lists into fixed-sized chunks to reduce learning complexity, combined with a rank alignment module that optimizes consistency at the rank level rather than the score level. The framework uses a relaxation factor to adjust pCTR scores so that ECPM ranks align, avoiding the error amplification problem of traditional score alignment methods. A ΔNDCG-based weighting mechanism emphasizes important inter-chunk pairs during optimization, particularly focusing on top-ranked positions that have the most impact on final ad selection. The method is evaluated on both public and industrial datasets, showing consistent improvements in both consistency metrics and system performance.

## Key Results
- COPR achieves up to +12.3% CTR and +5.6% RPM improvement in Taobao's display advertising system
- Consistency metrics improve significantly: HR@10, NDCG@10, and MAP@10 show consistent gains across datasets
- COPR outperforms traditional score alignment methods by reducing error amplification through rank-level optimization
- Chunk-based sampling reduces training data size by K times while maintaining effectiveness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: COPR achieves more consistent ECPM-ranked results by optimizing rank alignment instead of raw score alignment.
- Mechanism: Instead of forcing pre-ranking model scores to match ranking model scores, COPR uses a relaxation factor to adjust pCTR scores so that ECPM ranks align. This explicitly considers bid values during training, avoiding amplification of score alignment errors.
- Core assumption: The pre-ranking model has limited capacity, making exact score matching infeasible; rank-level consistency is sufficient for good system performance.
- Evidence anchors: [abstract]: "relax the objective of score alignment to rank alignment, where bids of ads are incorporated and consistency of ranked results between two phases can be explicitly optimized in an effective manner." [section]: "we propose to relax the objective to rank alignment on a properly-adjusted pCTR score."

### Mechanism 2
- Claim: Chunk-based sampling reduces learning difficulty and improves training efficiency by coarse-graining consistency objectives.
- Mechanism: The ranked list is partitioned into fixed-sized chunks. Within each chunk, ads are considered equivalent in priority. The pre-ranking model only needs to distinguish inter-chunk priorities, not exact positions, making the task more tractable.
- Core assumption: Distinguishing coarse-grained chunks is easier for lightweight models than fine-grained ranking, and chunk boundaries align with meaningful priority levels.
- Evidence anchors: [section]: "it could be hard to rank hundreds of ad all in correct positions. To reduce the learning difficulty, we partition the ranked list into fixed-sized chunks." [abstract]: "employs a chunk-based sampling module and a plug-and-play rank alignment module to explicitly optimize consistency of ECPM-ranked results."

### Mechanism 3
- Claim: ΔNDCG-based weighting emphasizes more important inter-chunk pairs, improving top-k ranking consistency.
- Mechanism: Inter-chunk pairs are weighted by the expected NDCG loss if misranked, prioritizing consistency for top-ranked chunks that influence final ad selection.
- Core assumption: Higher-ranked ads have disproportionate impact on system performance, so consistency optimization should focus on these positions.
- Evidence anchors: [section]: "consistently ranking ads from chunk 1 and chunk 10 is more important than ranking chunk 11 and chunk 20, since only the top ads will be sent to the ranking phase and displayed to users." [abstract]: "A ΔNDCG-based weighting mechanism is adopted to better distinguish the importance of inter-chunk samples in optimization."

## Foundational Learning

- Concept: Expected Cost Per Mille (ECPM) and its role in cascading ad systems
  - Why needed here: Understanding ECPM is critical because the paper's consistency objective is defined at the ECPM ranking level, not raw CTR scores.
  - Quick check question: What components make up ECPM, and why does it matter for ad ranking?

- Concept: Knowledge distillation and score alignment limitations
  - Why needed here: COPR is positioned as an improvement over score alignment methods; understanding their limitations helps explain COPR's design choices.
  - Quick check question: What problem does COPR solve that traditional score alignment methods (like RankFlow) cannot?

- Concept: Pairwise ranking loss and its application
  - Why needed here: The rank alignment module uses pairwise logistic loss to encourage consistent ECPM ranking between pre-ranking and ranking phases.
  - Quick check question: How does pairwise logistic loss work in the context of rank alignment, and why is it appropriate here?

## Architecture Onboarding

- Component map: Ranking logs → Chunk sampling → Pre-ranking model training with rank alignment → Online deployment
- Critical path: Ranking logs → Chunk sampling → Pre-ranking model training with rank alignment → Online deployment
- Design tradeoffs:
  - Chunk size (K): Larger chunks reduce learning difficulty but lose ranking granularity; smaller chunks increase complexity
  - Relaxation factor range: Too narrow limits adjustment capability; too wide may overfit
  - ΔNDCG weighting: Emphasizes top positions but may neglect consistency in lower positions
- Failure signatures:
  - Poor HR@K/NDCG@K despite good CTR/RPM: Rank alignment not working
  - Significant drop in CTR/RPM: Chunk sampling or rank alignment causing poor candidate selection
  - Training instability: Relaxation factor learning rate or chunk configuration issues
- First 3 experiments:
  1. Ablation study: COPR vs COPR w/o ΔNDCG on public dataset to verify weighting importance
  2. Chunk size sensitivity: Test different K values on production dataset to find optimal balance
  3. Bid incorporation test: Compare with score alignment methods to demonstrate error amplification reduction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the chunk size K affect the trade-off between consistency optimization granularity and training efficiency in different advertising scenarios?
- Basis in paper: [explicit] The paper mentions chunk-based sampling reduces training data size by K times and states K is set to 2 and 10 for public and production datasets respectively, but doesn't systematically explore the relationship between chunk size and performance.
- Why unresolved: The paper only provides limited experimental results with specific K values (2 and 10) without exploring the full spectrum of possible chunk sizes or analyzing the impact on both consistency metrics and system efficiency across different scenarios.
- What evidence would resolve it: Systematic experiments varying K from small (e.g., 2) to large (e.g., 50) values on multiple datasets, showing how HR@K, NDCG@K, MAP@K, CTR, and RPM change with different chunk sizes, along with analysis of computational cost and convergence speed.

### Open Question 2
- Question: How does COPR's consistency-oriented approach compare with other alignment methods when the ranking model architecture changes (e.g., from DIN to transformer-based models)?
- Basis in paper: [inferred] The paper compares COPR with score alignment methods (Distillation, RankFlow) on specific ranking models but doesn't explore how these methods perform when ranking models have different architectures or capacities.
- Why unresolved: The experiments use DIN as the ranking model for the public dataset, but the paper doesn't investigate whether the observed advantages of COPR over score alignment methods persist when the ranking model architecture changes significantly.
- What evidence would resolve it: Head-to-head comparisons of COPR and baseline methods when ranking models use different architectures (transformer-based, attention-based, etc.) while keeping the pre-ranking architecture fixed, measuring both consistency metrics and system performance.

### Open Question 3
- Question: What is the impact of bid distribution skewness on the effectiveness of rank alignment versus score alignment in the cascading architecture?
- Basis in paper: [explicit] The paper emphasizes that error amplification occurs when alignment errors are multiplied by bids, and that COPR incorporates bids into the optimization objective, but doesn't analyze how different bid distributions affect method performance.
- Why unresolved: While the paper demonstrates COPR's effectiveness, it doesn't explore scenarios with different bid distribution characteristics (e.g., highly skewed vs. uniform) to understand when rank alignment is most beneficial compared to score alignment.
- What evidence would resolve it: Experiments with synthetic datasets having controlled bid distributions (varying skewness, range, and variance), showing how HR@K, NDCG@K, MAP@K, CTR, and RPM of COPR versus score alignment methods change as bid distribution characteristics vary.

## Limitations

- Scalability uncertainty: The chunk-based approach's effectiveness for extremely large candidate pools remains unproven
- Robustness question: The relaxation mechanism's performance across diverse bid distributions needs further validation
- Alternative weighting: ΔNDCG weighting hasn't been compared against other potential weighting schemes
- Statistical significance: Industrial deployment results lack detailed statistical significance testing and long-term stability analysis

## Confidence

- High confidence in the core observation that pre-ranking/ranking inconsistency degrades system performance
- Medium confidence in chunk-based sampling reducing learning complexity based on theoretical reasoning
- Medium confidence in relaxation factor improving alignment robustness, though the optimal range is not explored
- Medium confidence in ΔNDCG weighting importance based on the logical argument about top-K prioritization

## Next Checks

1. Conduct ablation studies varying chunk sizes systematically to quantify the tradeoff between learning difficulty and ranking granularity
2. Test the relaxation mechanism across datasets with different bid distributions to assess robustness to bid variance
3. Compare ΔNDCG weighting against alternative schemes (uniform, position-based, or learnable weights) to validate its effectiveness for this specific use case