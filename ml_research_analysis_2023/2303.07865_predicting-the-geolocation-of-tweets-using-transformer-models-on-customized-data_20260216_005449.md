---
ver: rpa2
title: Predicting the Geolocation of Tweets Using transformer models on Customized
  Data
arxiv_id: '2303.07865'
source_url: https://arxiv.org/abs/2303.07865
tags:
- location
- user
- geolocation
- text
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method for predicting tweet and user geolocation
  using transformer-based models fine-tuned on customized Twitter datasets. The approach
  uses BERT models to estimate location as coordinate pairs and two-dimensional Gaussian
  Mixture Models (GMMs) based on tweet content and metadata.
---

# Predicting the Geolocation of Tweets Using transformer models on Customized Data

## Quick Facts
- **arXiv ID**: 2303.07865
- **Source URL**: https://arxiv.org/abs/2303.07865
- **Reference count**: 40
- **Primary result**: BERT models fine-tuned on Twitter datasets achieve <30 km median geolocation error worldwide and <15 km in the US using multitask learning with GMM-based probabilistic outputs

## Executive Summary
This paper introduces a transformer-based approach for predicting tweet and user geolocation using BERT models fine-tuned on customized Twitter datasets. The method estimates location as coordinate pairs and two-dimensional Gaussian Mixture Models (GMMs) based on tweet content and metadata. By employing multitask learning with separate wrapper layers for key (tweet text + user context) and minor (place metadata) features, the model achieves median geolocation error of less than 30 km worldwide and less than 15 km in the US. The approach outperforms previous methods while maintaining transparency through publicly available source code and data.

## Method Summary
The method fine-tunes BERT (base-multilingual-cased or base-cased) with multitask learning, using separate wrapper layers for key features (tweet text + user context) and minor features (place metadata). The model outputs Gaussian Mixture Models with spherical covariance matrices, trained with a custom loss combining spatial (squared Euclidean distance) and probabilistic (negative log-likelihood) components. Training uses a lower bound on covariance parameters to prevent negative loss values, with 3 epochs and batch sizes of 10-16. Evaluation employs geospatial metrics (median/mean SAE, Acc@161) and probabilistic metrics (CAE, PRA, COV) on a filtered dataset of 300K test tweets from 143K users across 63 languages.

## Key Results
- Median geolocation error <30 km worldwide and <15 km in the US
- Outperforms previous methods on Twitter geolocation prediction
- Achieves 15.97 km median SAE in top-performing PMOP model
- Demonstrates effectiveness of GMM-based probabilistic outputs over direct coordinate regression

## Why This Works (Mechanism)

### Mechanism 1
The model uses multitask learning with key and minor features to improve geolocation accuracy by learning from both tweet content and geographic metadata. By training separate wrapper layers for the key feature (tweet content + user context) and minor feature (place metadata), the model leverages both noisy user-generated data and cleaner geographic descriptors without directly including place context in the evaluation input. Core assumption: Place metadata provides useful geographic terms without introducing evaluation bias, and separating it into a minor feature improves learning efficiency.

### Mechanism 2
Using probabilistic outputs in the form of Gaussian Mixture Models (GMMs) with spherical covariance matrices yields better median geolocation error than direct coordinate regression. The model outputs multiple weighted geographic points (GMM peaks) instead of a single coordinate pair, capturing uncertainty and allowing for a more robust estimation by considering multiple possible locations. Core assumption: Real-world tweet locations are inherently uncertain and multimodal, so a single coordinate is insufficient; GMMs better model this uncertainty.

### Mechanism 3
Lower-bounding the covariance parameter in GMMs prevents negative log-likelihood loss values and improves model stability during training. By applying a lower bound of 1/(2π) to the covariance parameter using a modified SoftPlus function, the model ensures that the probability density function (PDF) remains in the range [0,1], avoiding negative loss values and maintaining stable training. Core assumption: Without a lower bound, small covariance values lead to PDFs exceeding 1, causing negative log-likelihood values that destabilize training.

## Foundational Learning

- **Masked Language Modeling (MLM) and Next Sentence Prediction (NSP) pretraining in BERT**: Why needed here: MLM enables the model to learn bidirectional representations of sentences, which is crucial for understanding context in tweets. NSP helps capture relationships between sentences, useful for understanding tweet threads or related posts. Quick check question: How does MLM differ from traditional left-to-right language modeling, and why is this difference important for geolocation prediction?

- **Gaussian Mixture Models (GMMs) and probability density functions**: Why needed here: GMMs allow the model to output multiple possible locations with associated weights, capturing the uncertainty inherent in geolocation from text. Understanding PDFs is essential for computing the probabilistic loss function. Quick check question: Why is a spherical covariance matrix chosen over diagonal or full matrices, and what are the trade-offs?

- **Multitask learning and wrapper layers in neural networks**: Why needed here: Multitask learning with separate wrapper layers for key and minor features allows the model to learn from both tweet content and geographic metadata without introducing evaluation bias. Understanding wrapper layers is crucial for modifying BERT outputs. Quick check question: How does the per-feature loss computation work in multitask learning, and why is averaging the losses beneficial?

## Architecture Onboarding

- **Component map**: BERT base model (768 hidden size) -> Wrapper layers (linear regression) for key and minor features -> Custom loss functions (spatial and probabilistic components) -> Data preprocessing pipeline (text filtering, tokenization, feature engineering)

- **Critical path**: 1. Data preprocessing and feature engineering, 2. Model fine-tuning with multitask learning, 3. Evaluation using geospatial and probabilistic metrics

- **Design tradeoffs**: Using GMMs vs. direct coordinate regression: GMMs capture uncertainty but increase computational cost; Number of GMM peaks: More peaks increase accuracy but also computational cost and risk of overfitting; Lower bound on covariance: Prevents negative loss values but may limit representation of high-uncertainty predictions

- **Failure signatures**: High median SAE but low Acc@161: Model predictions are often far from true location but sometimes very close; Negative loss values during training: Covariance parameter not properly bounded; Underfitting: Too few training samples or overly simple model architecture

- **First 3 experiments**: 1. Compare single coordinate regression (GSOP) vs. GMM-based probabilistic output (PSOP) on a small dataset to verify the benefit of probabilistic modeling; 2. Test different numbers of GMM peaks (e.g., 3, 5, 10) to find the optimal balance between accuracy and computational cost; 3. Evaluate the impact of lower-bounding the covariance parameter by comparing models with and without the bound on a validation set

## Open Questions the Paper Calls Out

### Open Question 1
How would the performance of the proposed BERT-based models change if the user network features (friends, mentions, replies) were incorporated alongside the text and metadata features? Basis in paper: The paper notes that many previous works achieve higher accuracy by utilizing user network connections in addition to textual data, and it specifically states that the proposed approach focuses primarily on textual data analysis. Why unresolved: The paper does not evaluate or compare models that incorporate user network features, leaving open the question of whether such features would improve performance.

### Open Question 2
What is the optimal number of prediction outcomes (M) for the Probabilistic Multiple Outcomes Prediction (PMOP) model across different geographical granularities (worldwide, country, city-level)? Basis in paper: The paper mentions that the optimal number of prediction outcomes varied during experiments, and it evaluated models with different numbers of outcomes (1 to 100). However, it does not provide a definitive answer for the optimal number across different granularities. Why unresolved: The paper only reports results for worldwide-level datasets and does not explore how the optimal number of outcomes might differ for country or city-level predictions.

### Open Question 3
How would the proposed approach perform on languages other than English and the 104 largest Wikipedia languages supported by the multilingual BERT model? Basis in paper: The paper acknowledges that the multilingual BERT model used was pretrained on 104 largest Wikipedia languages, and it notes that language-specific BERT models outperformed the multilingual counterpart in previous studies. However, it does not evaluate the performance on languages outside of these 104. Why unresolved: The paper does not provide any evaluation or discussion of the model's performance on languages not included in the multilingual BERT's pretraining.

## Limitations

- The reliance on multitask learning with separate key and minor features introduces complexity that may not generalize well to datasets with different characteristics
- The custom loss function combining spatial and probabilistic components lacks comprehensive ablation studies to demonstrate its superiority over simpler alternatives
- The dataset filtering criteria (≤20 tweets/day for "real users") may exclude active but legitimate users, potentially skewing geographic distributions

## Confidence

- **Geolocation Accuracy Claims** - Medium Confidence: Supported by reported metrics but limited by dataset characteristics and lack of extensive ablation studies
- **Multitask Learning Effectiveness** - Medium Confidence: Theoretically sound but not thoroughly validated against alternative approaches
- **GMM-Based Probabilistic Modeling** - Low Confidence: Innovative approach but lacks comparative analysis with simpler alternatives

## Next Checks

**Validation Check 1**: Conduct an ablation study comparing the full multitask model against a model using only the key feature, a model using only the minor feature, and a simple regression model without GMM components. This will quantify the contribution of each component and validate the effectiveness of the multitask approach.

**Validation Check 2**: Test the model's generalization by evaluating performance on datasets from different time periods (pre-2020) to assess temporal robustness, regions with sparse data coverage to identify geographic limitations, and different language groups to examine multilingual performance consistency.

**Validation Check 3**: Implement and test alternative GMM configurations by varying the number of GMM peaks (3, 7, 10) to find optimal performance, comparing spherical covariance with diagonal and full covariance matrices, and evaluating the impact of different lower-bound values on the covariance parameter.