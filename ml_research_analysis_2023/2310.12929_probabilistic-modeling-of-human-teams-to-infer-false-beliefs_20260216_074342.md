---
ver: rpa2
title: Probabilistic Modeling of Human Teams to Infer False Beliefs
arxiv_id: '2310.12929'
source_url: https://arxiv.org/abs/2310.12929
tags:
- players
- human
- about
- agent
- legend
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We develop a probabilistic graphical model (PGM) for an AI agent
  to infer human beliefs during a simulated urban search and rescue (USAR) scenario
  in Minecraft. The agent, ToMCAT, reasons about individual and shared mental states
  of human teammates, updating beliefs based on observed actions and perceptions.
---

# Probabilistic Modeling of Human Teams to Infer False Beliefs

## Quick Facts
- arXiv ID: 2310.12929
- Source URL: https://arxiv.org/abs/2310.12929
- Reference count: 13
- Key outcome: ToMCAT achieves 65% ± 17% accuracy in inferring which player holds a false belief about marker block meanings in a Minecraft USAR scenario

## Executive Summary
This paper presents ToMCAT, an AI agent that uses a probabilistic graphical model to infer false beliefs among human teammates during a simulated urban search and rescue mission in Minecraft. The agent reasons about individual and shared mental states by tracking players' marker placements and victim perceptions over time. When one team member receives a different marker legend than the other two, creating false beliefs, ToMCAT can identify the outlier player with accuracy significantly better than chance. The interpretable probabilistic framework enables understanding of the reasoning process and potential for timely interventions.

## Method Summary
ToMCAT employs a dynamic Bayesian network with latent variables representing each player's original marker legend, the team's adopted legend, and each player's victim perceptions. The model updates beliefs using a particle filter (Rao-Blackwellized) that processes sequential evidence of players' field of view and marker placements. Model parameters are trained using Gibbs sampling for 600 iterations. The system was evaluated on 12 annotated test trials from a dataset of 52 training missions, comparing performance against chance level (33%) and human observers.

## Key Results
- ToMCAT achieves 65% ± 17% accuracy in identifying which player holds the false belief
- Performance is significantly better than chance level (33%)
- Model correctly adapts beliefs about team and individual marker meanings as players place markers
- ToMCAT's performance is comparable to human observers at 65% accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The probabilistic model can distinguish which player received the false marker legend by integrating observed marker placements with inferred victim perceptions over time.
- Mechanism: The model maintains latent beliefs about each player's original legend (O(i)), the team's adopted legend (T), and each player's perception of victims (P(i)). It updates these beliefs using sequential Bayesian inference (particle filter) grounded in evidence of victims in the player's field of view (F(i)) and markers placed (M(i)). As players place markers consistent with their perceived victim locations, the model adjusts beliefs about which legend each player holds.
- Core assumption: Players place markers based on the legend they believe is in effect, and their victim perception is accurate and persistent for ~5 seconds.
- Evidence anchors:
  - [abstract] "ToMCAT achieves accuracy significantly better than chance (65% ± 17%) in inferring which player holds the false belief"
  - [section] "ToMCAT correctly adjusts its belief about the marker meaning adopted by each player as they place markers in the game given their perception about a nearby victim"
- Break condition: If players use markers for purposes other than signaling victim presence/absence, or if their victim perception is unreliable or delayed, the model's inference degrades.

### Mechanism 2
- Claim: The model can infer the team's adopted legend even when individual players initially hold conflicting beliefs, by observing marker consistency over time.
- Mechanism: The model represents the team's shared mental model (T) as a latent variable separate from individual beliefs. As players place markers, the model computes the likelihood of each team legend given the observed pattern. If most players are consistent with one legend, the model's belief in that team legend increases, even if one player's original legend differs.
- Core assumption: The team will converge on a single marker legend through implicit coordination, and this adopted legend remains stable during the mission.
- Evidence anchors:
  - [abstract] "The model correctly adapts its beliefs about team and individual marker meanings as players place markers and perceive victims"
  - [section] "the team might collectively follow a specific legend; this will explain situations in which players place markers that differ in meaning from the players' original legends"
- Break condition: If the team fails to adopt a consistent legend, or if the adopted legend changes mid-mission, the model cannot accurately infer the team's mental state.

### Mechanism 3
- Claim: The model's probabilistic framework allows it to quantify uncertainty about beliefs, enabling targeted interventions when confidence is high.
- Mechanism: The model outputs probability distributions over possible legend assignments. When one assignment has high probability (e.g., >0.9), the model has high confidence in that inference. This confidence measure can trigger interventions to correct false beliefs. The model also shows how beliefs evolve over time, revealing when and why confidence increases or decreases.
- Core assumption: Interventions are most effective when the model has high confidence in its inference, and the confidence threshold for intervention is appropriately set.
- Evidence anchors:
  - [abstract] "ToMCAT's interpretable probabilistic framework enables understanding of its reasoning process and potential for timely interventions to correct misaligned mental models"
  - [section] "Importantly, it is able to infer false beliefs for some trials with high levels of confidence...thus making it a viable proposition to intervene at these points"
- Break condition: If the model's confidence measure is miscalibrated (over/under-confident), interventions may be mistimed or unnecessary.

## Foundational Learning

- Concept: Bayesian inference and probabilistic graphical models
  - Why needed here: The core mechanism relies on representing beliefs as probability distributions and updating them with evidence using Bayes' rule
  - Quick check question: How does the model update its belief about a player's original legend when that player places a marker inconsistent with their current inferred legend?

- Concept: Particle filtering for sequential inference
  - Why needed here: The model must update beliefs in real-time as new evidence arrives, and particle filtering is used for approximate inference in this dynamic Bayesian network
  - Quick check question: What happens to the particle set when a player places a marker that is highly unlikely given their current inferred legend?

- Concept: Theory of mind and mental state attribution
  - Why needed here: The model is explicitly designed to reason about human teammates' beliefs, desires, and intentions to detect false beliefs
  - Quick check question: How does the model distinguish between a player holding a false belief versus a player simply making a mistake?

## Architecture Onboarding

- Component map: Minecraft plugin captures F(i) and M(i) → Dynamic Bayes net processes evidence → Particle filter updates beliefs → Output confidence and belief evolution
- Critical path: Evidence capture → Probabilistic model update → Belief inference → Output confidence → (Optional) Intervention trigger
- Design tradeoffs:
  - Model complexity vs. interpretability: More detailed models might capture nuances but become harder to understand
  - Real-time performance vs. inference accuracy: More particles improve accuracy but increase computation time
  - Assumption strictness vs. robustness: Strong assumptions (e.g., 5-second perception) simplify the model but may break in edge cases
- Failure signatures:
  - Low confidence across all trials: Model cannot distinguish legends (evidence too ambiguous or model assumptions violated)
  - Systematic bias in one direction: Model consistently misattributes legends (evidence capture error or model misspecification)
  - Oscillating beliefs: Model cannot converge on stable inferences (evidence contradictory or particle filter degeneracy)
- First 3 experiments:
  1. Run the model on a trial where one player clearly uses markers inconsistent with the other two; verify it correctly identifies the outlier
  2. Run the model on a trial where no one uses markers; verify it maintains high uncertainty throughout
  3. Run the model on a trial where players use markers for a non-standard purpose (e.g., tracking rubble); verify it misattributes legends as expected

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How sensitive is ToMCAT's performance to the assumed perception duration of 5 seconds for victims in the players' field of view?
- Basis in paper: [explicit] The paper mentions this is a key assumption in their model and notes that performance is not very sensitive to this parameter in the range of 3 to 10 seconds, but doesn't explore the full sensitivity.
- Why unresolved: The paper only tested a limited range of perception durations and didn't perform a comprehensive sensitivity analysis across the full plausible range.
- What evidence would resolve it: Systematic testing of ToMCAT's accuracy across a wider range of perception duration assumptions, from very short (1-2 seconds) to very long (20+ seconds).

### Open Question 2
- Question: How would ToMCAT perform if players could freely define their own marker meanings rather than being constrained to legends A and B?
- Basis in paper: [inferred] The paper notes that ToMCAT fails when players use marker meanings inconsistent with legends A and B, suggesting it would struggle with fully free-form marker usage.
- Why unresolved: The experimental design deliberately constrained marker meanings to create false beliefs, so the model was never tested on open-ended marker usage.
- What evidence would resolve it: Running ToMCAT on missions where players can freely define marker meanings, and measuring accuracy in inferring these user-defined meanings.

### Open Question 3
- Question: How would incorporating natural language communication between players affect ToMCAT's ability to infer false beliefs?
- Basis in paper: [explicit] The paper notes that player speech is captured but not currently used as evidence in the model, suggesting this could be a promising extension.
- Why unresolved: The current model only uses visual evidence (victim perception and marker placement), ignoring the verbal communication channel that could provide additional information.
- What evidence would resolve it: Testing ToMCAT's accuracy with and without incorporating automatic speech recognition and information extraction from player communications.

## Limitations

- Small test set of only 12 trials limits statistical confidence in performance claims
- Model assumes players' victim perceptions remain stable for approximately 5 seconds, which may not hold in all scenarios
- Performance heavily depends on players using markers consistently with their perceived legend

## Confidence

**High Confidence**: The model's basic architecture and inference approach are sound, and the reported accuracy (65% ± 17%) represents a genuine improvement over chance level (33%). The probabilistic framework's ability to track belief evolution over time is well-established.

**Medium Confidence**: The claim that ToMCAT's performance is "comparable to human observers" is based on a single reported human performance metric (65% accuracy) from a single observer. Without multiple human observers or confidence intervals for human performance, this comparison is limited.

**Medium Confidence**: The model's ability to infer team legends when individual players initially hold conflicting beliefs relies on the assumption that teams converge on a single legend. While this is supported by observed marker consistency, the mechanism for how this convergence occurs is not explicitly modeled.

## Next Checks

1. **Human Observer Replication**: Conduct a study with multiple human observers evaluating the same test trials to establish confidence intervals for human performance, enabling a more robust comparison with ToMCAT's accuracy.

2. **Model Robustness Testing**: Evaluate the model on scenarios where players deliberately use markers for non-standard purposes (e.g., tracking rubble or coordinating movement) to assess how well it handles evidence that violates its core assumptions.

3. **Confidence Calibration Analysis**: Analyze the relationship between the model's reported confidence levels and its actual accuracy across different trials to determine if the confidence measure is well-calibrated and can reliably trigger interventions.