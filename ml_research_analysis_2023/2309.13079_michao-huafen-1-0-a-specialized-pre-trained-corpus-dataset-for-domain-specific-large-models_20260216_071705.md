---
ver: rpa2
title: 'MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific
  Large Models'
arxiv_id: '2309.13079'
source_url: https://arxiv.org/abs/2309.13079
tags:
- data
- dataset
- corpus
- large
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the MiChao-HuaFen 1.0 dataset, a specialized
  pre-trained corpus for domain-specific large models, focusing on the news and governmental
  sectors. The dataset consists of over 70 million entries, including over 1 million
  image links, sourced from publicly available Chinese internet data from 2022.
---

# MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models

## Quick Facts
- arXiv ID: 2309.13079
- Source URL: https://arxiv.org/abs/2309.13079
- Reference count: 11
- This paper introduces a specialized pre-trained corpus for news and governmental domains with over 70 million entries

## Executive Summary
This paper introduces the MiChao-HuaFen 1.0 dataset, a specialized pre-trained corpus for domain-specific large models focusing on news and governmental sectors. The dataset consists of over 70 million entries sourced from publicly available Chinese internet data from 2022, including over 1 million image links. The data underwent multiple rounds of cleansing and processing to ensure high quality and reliable origins. The dataset aims to support the pre-training of large models for Chinese vertical domains, addressing the limitations of general-purpose models in domain-specific knowledge.

## Method Summary
The MiChao-HuaFen 1.0 dataset was created through a multi-stage cleansing pipeline applied to Chinese internet sources from 2022. The process included keyword filtering to remove sensitive content, image extraction using xpath to store image links, rule-based filtering to remove short documents (under 200 characters), quality inspection combining manual sampling and automated model scanning, rule refinement, and formatting. The dataset is available for download at OpenDataLab and can be used for pre-training large language models in Chinese news and governmental domains.

## Key Results
- Dataset contains over 70 million entries with more than 1 million image links
- Data sourced from publicly available Chinese internet sources from 2022
- Multi-round cleansing process ensures high quality and reliable origins
- Specifically tailored for news and governmental sectors in Chinese vertical domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Specialized pre-training on domain-specific corpora improves model performance in targeted domains compared to general-purpose models.
- Mechanism: General-purpose models like GPT-4 have broad capabilities but lack depth in domain-specific knowledge areas such as healthcare, law, and finance. By pre-training on specialized datasets like MiChao-HuaFen 1.0, models can develop domain-specific expertise that general models cannot achieve through fine-tuning alone.
- Core assumption: Pre-training on domain-specific data is more effective than post-hoc fine-tuning for achieving expert-level performance in specialized domains.
- Evidence anchors:
  - [abstract]: "This paper first evaluates the existing large models for specialized domains and discusses their limitations. To cater to the specific needs of certain domains, we introduce the 'MiChao-HuaFen 1.0' pre-trained corpus dataset, tailored for the news and governmental sectors."
  - [section 1]: "Studies have shown[8] that without incorporating relevant corpora during the pre-training phase and relying solely on fine-tuning, optimal model performance cannot be achieved."
- Break condition: If the domain-specific corpus lacks sufficient coverage or quality, the pre-training advantage disappears and general models may perform comparably.

### Mechanism 2
- Claim: Multi-round cleansing and processing ensures higher quality training data, leading to better model outputs.
- Mechanism: The dataset underwent keyword filtering, image extraction, rule-based filtering, quality inspection, and formatting to remove noise, sensitive information, and ensure content quality. This systematic cleaning process creates a purer training corpus.
- Core assumption: Cleaner, higher-quality training data directly translates to better model performance and more reliable outputs.
- Evidence anchors:
  - [section 3]: "The data processing methods for 'MiChao-HuaFen 1.0' largely adhere to existing pre-trained corpus cleaning methodologies, primarily following these principles: Source compliance, Corpus diversity, Sensitive information removal, Ensuring corpus quality."
  - [section 3]: "Based on these principles, the corpus underwent the following processing: Keyword Filtering, Image Extraction, Rule-based Filtering, Quality Inspection, Rule Refinement, Formatting."
- Break condition: If the cleaning process removes too much domain-relevant content or introduces bias, the resulting model may lack important domain knowledge.

### Mechanism 3
- Claim: Focusing on Chinese vertical domains addresses a specific market need where general-purpose models underperform.
- Mechanism: The dataset specifically targets Chinese news and governmental sectors, providing content in Chinese language with cultural and contextual relevance that Western-trained models cannot adequately capture.
- Core assumption: Language and cultural specificity are critical factors in domain model performance, and Chinese-specific datasets are necessary for effective Chinese domain applications.
- Evidence anchors:
  - [abstract]: "This dataset not only supports the pre-training of large models for Chinese vertical domains but also aids in propelling deep learning research and applications in related fields."
  - [section 1]: "This necessitates large models tailored for specific domains to achieve outputs that align with domain expertise, especially in the Chinese context."
- Break condition: If the dataset doesn't adequately represent the full breadth of the target domain or contains significant biases, the model may perform poorly on real-world Chinese domain tasks.

## Foundational Learning

- Concept: Pre-training vs. Fine-tuning
  - Why needed here: The paper explicitly contrasts pre-training on specialized corpora with fine-tuning general models, citing studies showing pre-training is superior for domain-specific performance.
  - Quick check question: What is the key difference between pre-training and fine-tuning, and why does the paper argue pre-training is necessary for domain-specific models?

- Concept: Data cleansing and quality assurance
  - Why needed here: The dataset underwent multiple rounds of cleansing including keyword filtering, rule-based filtering, and quality inspection. Understanding these processes is essential for implementing similar datasets.
  - Quick check question: What are the main steps in the MiChao-HuaFen 1.0 data cleansing pipeline, and why is each step important?

- Concept: Domain adaptation in NLP
  - Why needed here: The entire paper focuses on adapting large language models to specific domains (news, governmental) rather than general-purpose applications.
  - Quick check question: What challenges arise when adapting general language models to specific domains, and how does domain-specific pre-training address these challenges?

## Architecture Onboarding

- Component map: Data collection (Chinese internet sources, 2022) -> Keyword filtering -> Image extraction -> Rule-based filtering -> Quality inspection -> Rule refinement -> Formatting -> Model pre-training

- Critical path: Data collection → Keyword filtering → Image extraction → Rule-based filtering → Quality inspection → Rule refinement → Formatting → Model pre-training. The quality inspection step is critical as it combines manual and automated checks to ensure corpus purity.

- Design tradeoffs: The dataset focuses on Chinese news and governmental sectors, which provides depth in these areas but limits applicability to other domains. The multi-round cleansing ensures quality but may reduce dataset size. The inclusion of image links adds multimodal capability but increases complexity.

- Failure signatures: Poor domain performance (model fails on domain-specific tasks), inconsistent outputs (lack of stable updates mentioned in abstract), or compliance issues (insufficient source screening). These failures would manifest as reduced accuracy on domain benchmarks or user reports of poor performance.

- First 3 experiments:
  1. Baseline comparison: Train a model using MiChao-HuaFen 1.0 and compare performance against a general-purpose model fine-tuned on the same data to validate the pre-training advantage claim.
  2. Ablation study: Remove one cleaning step at a time (e.g., skip keyword filtering) to measure the impact of each processing stage on final model quality.
  3. Domain transfer test: Evaluate the trained model on related domains (e.g., financial news) to assess the breadth of domain knowledge captured versus the depth in target domains.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the MiChao-HuaFen 1.0 dataset's performance compare to existing domain-specific datasets like WanJuan 1.0 in terms of model accuracy and domain relevance?
- Basis in paper: [explicit] The paper mentions WanJuan 1.0 as an existing open-source pre-trained corpus dataset but does not provide a direct comparison of performance metrics between the two datasets.
- Why unresolved: The paper introduces MiChao-HuaFen 1.0 as a specialized dataset for news and governmental sectors but lacks comparative analysis with other datasets in terms of model performance and domain specificity.
- What evidence would resolve it: A comparative study showing model performance metrics (e.g., accuracy, relevance) when trained on MiChao-HuaFen 1.0 versus WanJuan 1.0 or other similar datasets would provide clarity.

### Open Question 2
- Question: What are the specific challenges and limitations encountered during the keyword filtering and rule-based filtering processes, and how were they addressed?
- Basis in paper: [inferred] The paper outlines the data processing methods, including keyword filtering and rule-based filtering, but does not detail the specific challenges or limitations faced during these processes.
- Why unresolved: While the paper describes the steps taken to ensure data quality, it does not provide insights into the difficulties encountered or how they were resolved during the filtering processes.
- What evidence would resolve it: Detailed documentation of the challenges faced during filtering, along with the solutions implemented, would provide a comprehensive understanding of the dataset's robustness.

### Open Question 3
- Question: How does the inclusion of over 1 million image links enhance the dataset's utility for pre-training large models, and what are the specific benefits observed in model outputs?
- Basis in paper: [explicit] The paper mentions the extraction of image links and their storage in an array field, indicating their potential utility for model pre-training.
- Why unresolved: The paper does not elaborate on how the inclusion of image links impacts model performance or the specific benefits observed in model outputs.
- What evidence would resolve it: Empirical studies comparing model performance with and without the inclusion of image links would highlight the benefits and utility of this feature.

### Open Question 4
- Question: What are the future plans for updating and expanding the MiChao-HuaFen dataset, and how will these updates address emerging needs in the news and governmental sectors?
- Basis in paper: [explicit] The paper mentions provisions for consistent and stable updates, suggesting ongoing development.
- Why unresolved: The paper does not provide details on the frequency of updates, criteria for inclusion of new data, or how these updates will address evolving needs in the specified domains.
- What evidence would resolve it: A detailed update roadmap outlining the criteria for data inclusion, frequency of updates, and alignment with sector-specific needs would clarify future directions.

### Open Question 5
- Question: How does the dataset ensure compliance with data privacy regulations, particularly concerning the removal of personally identifiable information (PII)?
- Basis in paper: [inferred] The paper mentions sensitive information removal and the use of keyword filtering and model classification to filter out sensitive data sources.
- Why unresolved: While the paper indicates measures for sensitive information removal, it does not specify the methods used to identify and remove PII or how compliance with data privacy regulations is ensured.
- What evidence would resolve it: A detailed description of the PII removal process and compliance measures with relevant data privacy regulations would provide assurance of the dataset's adherence to privacy standards.

## Limitations
- The paper lacks empirical validation of the dataset's effectiveness through performance comparisons with baseline models
- Claims about pre-training advantages over fine-tuning rely on cited studies rather than original experiments with this specific dataset
- The dataset's representativeness for all Chinese news and governmental domains remains unclear

## Confidence
- High Confidence: The dataset construction methodology (data collection from Chinese internet sources, multi-stage cleansing pipeline) is clearly specified and follows established practices in corpus preparation.
- Medium Confidence: The claims about the necessity of domain-specific pre-training are supported by cited literature but not directly validated with this dataset.
- Low Confidence: The assertion that this specific dataset will significantly improve model performance in Chinese news and governmental domains lacks empirical backing in the paper.

## Next Checks
1. Conduct benchmark experiments comparing model performance on domain-specific tasks when trained on MiChao-HuaFen 1.0 versus general-purpose pre-training corpora.
2. Perform ablation studies removing individual cleaning steps to quantify their impact on downstream model performance and identify potential over-filtering.
3. Evaluate the dataset's coverage and potential biases by analyzing topic distribution, time period representation, and cross-checking against independent sources of Chinese news and governmental content.