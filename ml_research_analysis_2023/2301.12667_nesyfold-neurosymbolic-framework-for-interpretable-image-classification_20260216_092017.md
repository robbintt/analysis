---
ver: rpa2
title: 'NeSyFOLD: Neurosymbolic Framework for Interpretable Image Classification'
arxiv_id: '2301.12667'
source_url: https://arxiv.org/abs/2301.12667
tags:
- 'true'
- target
- rules
- rule-set
- nesyfold
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents NeSyFOLD, a neurosymbolic framework that generates
  interpretable explanations for image classification by combining a CNN with a stratified
  answer set program (ASP) extracted using the FOLD-SE-M rule-based machine learning
  algorithm. The system achieves comparable or better accuracy and fidelity than the
  ERIC system while generating significantly smaller rule-sets (at least 50% smaller)
  for datasets with fewer classes.
---

# NeSyFOLD: Neurosymbolic Framework for Interpretable Image Classification

## Quick Facts
- arXiv ID: 2301.12667
- Source URL: https://arxiv.org/abs/2301.12667
- Reference count: 10
- Primary result: Combines CNN with stratified ASP rules to generate interpretable explanations with comparable/better accuracy and fidelity than ERIC while producing 50% smaller rule-sets

## Executive Summary
NeSyFOLD presents a neurosymbolic framework that generates interpretable explanations for image classification by combining a CNN with stratified answer set programs extracted using the FOLD-SE-M rule-based machine learning algorithm. The system achieves comparable or better accuracy and fidelity than the ERIC system while generating significantly smaller rule-sets (at least 50% smaller) for datasets with fewer classes. The extracted ASP rules are highly interpretable, with predicates corresponding to significant CNN kernels automatically mapped to semantic concepts using a novel semantic labeling algorithm.

## Method Summary
NeSyFOLD trains a CNN on image datasets, extracts binarized activations from the last convolutional layer, and applies the FOLD-SE-M algorithm to generate stratified answer set programs. The system includes an optional semantic labeling module that maps significant kernel predicates to semantic concepts using ADE20k segmentation masks. The framework achieves interpretable rule-based classification while maintaining high accuracy and fidelity, particularly effective on datasets with fewer classes.

## Key Results
- Achieves comparable or better accuracy and fidelity than ERIC system on tested datasets
- Generates rule-sets at least 50% smaller than ERIC for datasets with fewer classes
- Automatically maps kernel predicates to semantic concepts using novel labeling algorithm
- Maintains fidelity above 0.89 for most tested datasets with fewer classes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FOLD-SE-M generates interpretable default rules by identifying significant kernels and creating stratified answer set programs
- Mechanism: FOLD-SE-M learns default rules incrementally by covering positive examples while avoiding negative ones, then recursively learns exceptions, producing normal logic programs where significant kernels appear as predicates
- Core assumption: Most influential kernels in last convolutional layer can be reliably identified and used as predicates to represent decision logic
- Evidence anchors:
  - [abstract] "A rule-based machine learning algorithm called FOLD-SE-M is used to derive the stratified answer set program from binarized filter activations of the last convolutional layer."
  - [section] "The FOLD-SE-M algorithm has 2 tunable hyperparameters, ratio, and tail. The ratio controls the upper bound on the number of false positive examples to the number of true positive examples implied by the default part of a rule."
  - [corpus] No direct evidence found in corpus neighbors.

### Mechanism 2
- Claim: Semantic labeling algorithm automatically maps kernel activations to interpretable concepts using semantic segmentation masks
- Mechanism: For each significant kernel, selects top activating images, applies feature masks, intersects with semantic segmentation masks, and counts pixel distributions across concepts. Kernels labeled with most frequent concept(s) within margin threshold
- Core assumption: Kernel activations correspond to specific visual concepts identifiable through intersection with semantic segmentation data
- Evidence anchors:
  - [abstract] "The extracted ASP rules are highly interpretable, with predicates corresponding to significant CNN kernels automatically mapped to semantic concepts using a novel semantic labeling algorithm."
  - [section] "We then resize the corresponding feature maps and use them to mask each of the 10 images to obtain the field of view of that kernel for each image."
  - [corpus] No direct evidence found in corpus neighbors.

### Mechanism 3
- Claim: Binarization of kernel activations enables rule extraction while maintaining high fidelity
- Mechanism: Kernel outputs converted to binary values using thresholds calculated from activation distributions. Discretized representation allows FOLD-SE-M to work with boolean logic while preserving essential decision boundaries
- Core assumption: Continuous activation values can be effectively thresholded without losing discriminative information needed for classification
- Evidence anchors:
  - [abstract] "The system achieves high accuracy (e.g., 93% on MNIST) while maintaining fidelity above 0.89 for most tested datasets"
  - [section] "Quantization is the process of binarization of the kernel outputs. The quantization function is defined in eq. (3). θk is the threshold for a specific kernel k."
  - [corpus] No direct evidence found in corpus neighbors.

## Foundational Learning

- Concept: Default Logic and Normal Logic Programs
  - Why needed here: FOLD-SE-M uses default logic to create rules with exceptions represented as normal logic programs. Essential for interpreting generated rule-sets
  - Quick check question: How does negation-as-failure in normal logic programs relate to exception handling in default rules?

- Concept: Convolutional Neural Networks and Feature Extraction
  - Why needed here: Framework relies on extracting activations from last convolutional layer. Understanding how CNNs learn hierarchical features is essential for grasping why certain kernels become "significant"
  - Quick check question: What properties of last convolutional layer make it suitable for rule extraction rather than earlier layers?

- Concept: Semantic Segmentation and Pixel-Level Annotation
  - Why needed here: Semantic labeling algorithm requires semantic segmentation masks to map kernels to concepts. Understanding how these masks work is crucial for automatic labeling process
  - Quick check question: How does algorithm determine which semantic concepts a kernel is detecting based on pixel counts in masked regions?

## Architecture Onboarding

- Component map: CNN (feature extractor) → Binarization layer → FOLD-SE-M rule extractor → Semantic labeling module → Rule interpreter (s(CASP) or FOLD-SE-M interpreter)
- Critical path: Image → CNN forward pass → Feature map extraction → Binarization → Rule application → Classification
- Design tradeoffs: Accuracy vs interpretability (smaller rule-sets more interpretable but may lose some accuracy), binarization threshold selection (affects both accuracy and fidelity), semantic labeling margin (affects concept assignment precision)
- Failure signatures: Low fidelity indicates poor binarization or rule extraction; overly large rule-sets suggest insufficient pruning; semantic labels that don't match visual inspection indicate labeling algorithm issues
- First 3 experiments:
  1. Run on simple binary classification dataset (like MNIST 0 vs 1) to verify complete pipeline works end-to-end
  2. Test different binarization thresholds on validation set to find optimal balance between accuracy and rule-set size
  3. Apply semantic labeling to small subset of filters and manually verify assigned concepts match visual inspection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does performance scale with increasing number of classes beyond 10, particularly for datasets with 20+ classes?
- Basis in paper: [explicit] Paper notes NeSyFOLD's performance drops as number of classes increases, with particularly poor results on PLACES10 and GTSRB datasets, but doesn't explore performance beyond 10 classes
- Why unresolved: Paper only tested up to 10 classes, leaving uncertainty about system's limits and whether threshold exists where performance becomes unusable
- What evidence would resolve it: Experimental results testing NeSyFOLD on datasets with 20+ classes, showing accuracy, fidelity, and rule-set size metrics to determine scalability ceiling

### Open Question 2
- Question: Can semantic labeling algorithm be made fully automated without requiring semantic segmentation masks for training?
- Basis in paper: [inferred] Semantic labeling algorithm requires ADE20k dataset's semantic segmentation masks, which are manually annotated, creating dependency that limits scalability and automation
- Why unresolved: Paper presents novel semantic labeling algorithm but relies on manually annotated semantic segmentation masks, which are not always available for new datasets
- What evidence would resolve it: Demonstration of semantic labeling accuracy using only CNN's feature maps and perhaps unsupervised clustering or other automated techniques, without requiring manual segmentation masks

### Open Question 3
- Question: What is impact of backpropagating knowledge from generated rules to improve CNN performance, as mentioned as future work?
- Basis in paper: [explicit] Paper mentions investigating how rule-based knowledge can be backpropagated to improve CNN performance as future work, but provides no experimental evidence
- Why unresolved: Authors propose this as future work but haven't implemented or tested this bidirectional knowledge transfer between symbolic rules and neural networks
- What evidence would resolve it: Experimental results showing accuracy improvements in CNN performance after incorporating rule-based knowledge through backpropagation, with comparisons to baseline CNN training

## Limitations
- Performance degrades significantly on datasets with 10+ classes, limiting applicability to complex classification tasks
- Semantic labeling depends on availability of semantic segmentation masks, which may not exist for all datasets
- Exact implementation details for FOLD-SE-M algorithm and semantic labeling pipeline are not fully specified

## Confidence
- High confidence: Core mechanism of combining CNN with FOLD-SE-M for rule extraction is well-established and paper provides sufficient detail
- Medium confidence: Claims about 50% smaller rule-sets supported by comparisons to ERIC but generalizability needs more validation
- Medium confidence: Semantic labeling algorithm's effectiveness demonstrated on specific datasets but margin threshold selection appears somewhat arbitrary

## Next Checks
1. Test complete pipeline on binary classification task with known interpretable features to verify semantic labels match human visual inspection of kernel activations
2. Systematically vary binarization threshold parameters (α and γ) across validation set to quantify trade-off between accuracy, fidelity, and rule-set size
3. Apply semantic labeling algorithm to small subset of kernels and conduct blind human evaluation to assess whether automatically assigned concepts align with human interpretations of what those filters detect