---
ver: rpa2
title: Large Language Models are Not Stable Recommender Systems
arxiv_id: '2312.15746'
source_url: https://arxiv.org/abs/2312.15746
tags:
- uni00000013
- recommendation
- position
- uni00000011
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores using large language models (LLMs) as recommender
  systems and identifies significant position bias issues affecting performance. The
  authors propose a Bayesian probabilistic framework called STELLA, which consists
  of a two-stage pipeline: a probing stage to detect position bias patterns using
  a transition matrix, and a recommendation stage that applies Bayesian updating to
  correct biased outputs with an entropy indicator.'
---

# Large Language Models are Not Stable Recommender Systems
## Quick Facts
- arXiv ID: 2312.15746
- Source URL: https://arxiv.org/abs/2312.15746
- Reference count: 9
- Key outcome: STELLA framework achieves over 15% improvement in recommendation accuracy while addressing LLM position bias issues

## Executive Summary
This paper addresses the critical issue of position bias in large language models (LLMs) when used as recommender systems. The authors identify that LLM outputs are highly unstable and vary significantly based on the order of candidate items in the input prompt. To solve this, they propose STELLA, a Bayesian probabilistic framework that first detects position bias patterns through a probing stage using a transition matrix, then applies Bayesian updating with an entropy indicator to correct biased outputs. Experiments across four datasets (Books, Movies, Music, News) demonstrate that STELLA significantly outperforms raw LLM outputs and baseline methods, achieving over 15% improvement in recommendation accuracy while maintaining stability.

## Method Summary
The paper introduces STELLA, a two-stage Bayesian probabilistic framework designed to address position bias in LLM-based recommender systems. The first stage is a probing phase that constructs a transition matrix by analyzing how the LLM ranks ground truth items when they appear at different positions across various permutations. The second stage applies Bayesian updating to correct the biased outputs, using entropy as a convergence indicator to select the most stable ranking. The framework operates without requiring LLM retraining and maintains low computational costs while significantly improving recommendation accuracy and stability.

## Key Results
- STELLA achieves over 15% improvement in recommendation accuracy compared to raw LLM outputs
- The framework successfully addresses position bias, with accuracy dropping to only 0.1 for 25 candidate items versus 0.42 for raw LLMs
- STELLA outperforms baseline bootstrapping methods while maintaining low computational costs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Position bias causes LLMs to produce highly variable rankings that depend on the order of items in the prompt.
- Mechanism: When items are listed in different orders, the LLM's attention and output shift systematically, leading to different ground-truth item rankings. This is captured by the transition matrix, which quantifies how often the model ranks an item at position j first when the ground truth is actually at position i.
- Core assumption: The position bias is consistent and reproducible across different runs with the same input order.
- Evidence anchors:
  - [abstract] "directly using LLMs as a recommender system is usually unstable due to its inherent position bias"
  - [section: Position Bias] "the recommendation performance will vary significantly when changing the position of ground truth items"
  - [corpus] Weak: No direct mention of position bias patterns in corpus papers; corpus focuses on other biases (popularity, cognitive).

### Mechanism 2
- Claim: Bayesian updating with entropy-based convergence can recalibrate the biased LLM outputs into stable, accurate rankings.
- Mechanism: After obtaining the transition matrix from the probing stage, the recommendation stage applies Bayesian updating to iteratively refine the prior distribution of ground-truth positions. The entropy of the posterior distribution guides convergence; the lowest-entropy ranking is selected.
- Core assumption: The transition matrix captures enough of the bias pattern that Bayesian updating can effectively correct it.
- Evidence anchors:
  - [abstract] "Bayesian strategy is employed to adjust the biased output of LLMs with an entropy indicator"
  - [section: Recommendation Stage] "We apply Bayesian updating to correct the biased output of the model for ranking candidates, using entropy as an indicator"
  - [corpus] Weak: No mention of Bayesian updating in corpus papers; they focus on simulation or contextual adaptation.

### Mechanism 3
- Claim: The two-stage pipeline (probing then recommendation) decouples bias detection from ranking, allowing the model to use bias-corrected rankings without retraining.
- Mechanism: The probing stage generates a transition matrix from a small, labeled probing dataset that is independent of the target recommendation data. This matrix is then reused in the recommendation stage for any user with the same candidate set size, avoiding the need for costly LLM retraining.
- Core assumption: The bias patterns learned from the probing dataset generalize to the target recommendation scenarios.
- Evidence anchors:
  - [abstract] "introduce a probing dataset specifically designed for detecting position bias patterns within LLMs"
  - [section: Probing Stage] "The probing dataset is capable of capturing some user preferences from the histories"
  - [corpus] Weak: No mention of probing datasets or two-stage pipelines in corpus papers.

## Foundational Learning

- Concept: Transition matrices as bias quantification
  - Why needed here: They provide a compact, data-driven model of how the LLM's position bias affects rankings, which is essential for the Bayesian correction step.
  - Quick check question: How would you construct a transition matrix from a set of probing inputs and outputs?

- Concept: Bayesian updating and entropy convergence
  - Why needed here: Bayesian updating allows iterative refinement of position probabilities, while entropy guides when to stop and which ranking to trust.
  - Quick check question: What does it mean for the entropy to stop decreasing in the Bayesian updating loop?

- Concept: Leave-one-out evaluation with candidate permutations
  - Why needed here: It simulates realistic recommendation scenarios where one item is the ground truth and the rest are negatives, and tests the model's stability across all possible orderings.
  - Quick check question: Why is it important to permute the ground truth across all candidate positions in the probing set?

## Architecture Onboarding

- Component map: LLM → Prompt formatter → Raw ranking output → Probing stage (transition matrix construction) ← Probing dataset → Recommendation stage (Bayesian updating) → Final ranking
- Critical path: Probing stage must complete before recommendation stage; the transition matrix is the key shared artifact.
- Design tradeoffs: Using a transition matrix simplifies the bias model but may miss higher-order interactions; Bayesian updating adds computational cost but improves stability.
- Failure signatures: High variance in raw LLM outputs, low improvement after Bayesian updating, entropy not converging, transition matrix entries near uniform.
- First 3 experiments:
  1. Run the LLM on the probing dataset with all permutations of candidate orders and verify the transition matrix entries match expected position bias trends.
  2. Apply Bayesian updating on a small synthetic example and confirm entropy decreases and the correct ranking is recovered.
  3. Measure raw LLM variance vs. STELLA variance on the Books dataset to quantify stability improvement.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of STELLA scale with larger candidate sets beyond 25 items, and what is the theoretical limit of its effectiveness?
- Basis in paper: [inferred] The paper shows performance degradation as candidate set size increases from 2 to 25, with accuracy dropping to 0.1 for 25 items. This suggests a need to understand scalability limits.
- Why unresolved: The experiments only tested up to 25 candidate items, leaving open questions about performance at much larger scales typical in real-world recommender systems.
- What evidence would resolve it: Additional experiments testing candidate sets of 50, 100, and 200 items would reveal whether the performance continues to degrade linearly, plateaus, or exhibits some other pattern.

### Open Question 2
- Question: Can STELLA be effectively adapted for cold-start scenarios where users have minimal historical interaction data?
- Basis in paper: [inferred] The paper focuses on sequential recommendation with established user histories, but real-world recommender systems often face cold-start problems with new users or items.
- Why unresolved: The paper doesn't address how the probing stage and transition matrix would function with sparse or non-existent historical data.
- What evidence would resolve it: Experiments applying STELLA to scenarios with limited historical data (e.g., 1-3 interactions per user) and comparing performance to baseline methods would demonstrate its cold-start capabilities.

### Open Question 3
- Question: What is the optimal frequency for updating the transition matrix in STELLA to maintain accuracy without excessive computational overhead?
- Basis in paper: [explicit] The paper mentions "The probing dataset is capable of capturing some user preferences from the histories" but doesn't specify how often this probing should be performed or how the transition matrix should be updated over time.
- Why unresolved: User preferences and LLM behavior may drift over time, but frequent updates could be computationally expensive. The paper doesn't address this trade-off.
- What evidence would resolve it: A series of experiments varying the update frequency (e.g., daily, weekly, monthly) while monitoring both accuracy and computational costs would identify the optimal update schedule.

## Limitations
- The probing stage assumes position bias is stable and reproducible, but no analysis is provided for how the transition matrix changes with different probing datasets or across domains.
- The framework requires a labeled probing dataset for each candidate set size, which may not always be available or representative of target user behaviors.
- The Bayesian updating process uses entropy as a convergence indicator, but the stopping criteria and sensitivity to initialization are not specified.

## Confidence

- High: Position bias exists and affects LLM-based recommender stability; STELLA improves recommendation accuracy over raw LLM outputs.
- Medium: The two-stage pipeline with probing and Bayesian updating is effective at correcting position bias; the improvement is robust across datasets.
- Low: The entropy indicator reliably guides convergence; the transition matrix generalizes across domains and candidate set sizes.

## Next Checks
1. Conduct a sensitivity analysis on the probing dataset size and composition to determine how many permutations and what data diversity are needed for a stable transition matrix.
2. Perform ablation experiments to quantify the contribution of the Bayesian updating stage versus the raw LLM's ability to rank, isolating the impact of the entropy-based convergence.
3. Test the framework on a dataset with known, complex bias patterns (e.g., popularity bias) to evaluate whether the transition matrix approach can capture and correct non-position biases.