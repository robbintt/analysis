---
ver: rpa2
title: Evaluating the Robustness of Interpretability Methods through Explanation Invariance
  and Equivariance
arxiv_id: '2304.06715'
source_url: https://arxiv.org/abs/2304.06715
tags:
- methods
- interpretability
- robustness
- invariance
- explanation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work formalizes the robustness of interpretability methods\
  \ for models that are invariant under symmetry groups (e.g., translation, permutation).\
  \ The authors introduce two metrics\u2014explanation invariance and equivariance\u2014\
  to measure robustness against such symmetries."
---

# Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance

## Quick Facts
- arXiv ID: 2304.06715
- Source URL: https://arxiv.org/abs/2304.06715
- Reference count: 40
- Key outcome: The paper introduces metrics to evaluate interpretability method robustness against model symmetries, showing that baseline invariance and aggregation over symmetry transformations are crucial for robust explanations.

## Executive Summary
This work formalizes the robustness of interpretability methods for models invariant under symmetry groups through two metrics: explanation invariance and equivariance. The authors demonstrate that popular interpretability methods vary significantly in their robustness properties and provide a systematic approach to improve invariance through symmetry aggregation. Empirical evaluation across three modalities (ECG, Mutagenicity, ModelNet40) reveals that baseline selection critically affects robustness, particularly for gradient-based methods. The paper establishes 5 guidelines for improving robustness and bridges geometric deep learning with interpretability research.

## Method Summary
The paper introduces explanation invariance (InvG) and equivariance (EquivG) metrics to measure how well interpretability methods respect model symmetries. The method involves: (1) defining symmetry groups and their representations for each dataset, (2) training invariant models (CNN, GNN, Deep Set) with specific architectures, (3) applying various interpretability methods (feature importance, example importance, concept-based), and (4) evaluating robustness using the proposed metrics. The authors also propose an aggregation procedure to enforce invariance by averaging explanations over all symmetry transformations. Experiments use ECG (MIT-BIH), Mutagenicity, and ModelNet40 datasets with their respective symmetry groups.

## Key Results
- Not all interpretability methods are robust to model symmetries, with gradient-based methods requiring invariant baselines for equivariance
- Aggregation over symmetry transformations guarantees explanation invariance (Proposition 2.3)
- Baseline invariance is critical for gradient-based methods' equivariance (Proposition B.6)
- Concept-based methods show good robustness across all evaluated datasets
- The proposed metrics effectively identify robustness failures in existing interpretability methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Invariance/equivariance metrics directly measure how well explanations respect model symmetries.
- Mechanism: The paper defines two metrics (InvG and EquivG) that quantify the violation of explanation invariance and equivariance with respect to a symmetry group G. These metrics compare explanation outputs before and after applying symmetry transformations, using similarity scores (cosine similarity for real-valued explanations, accuracy for categorical ones).
- Core assumption: Symmetry groups and their representations are properly formalized and computable.
- Evidence anchors:
  - [abstract] "two metrics to measure the robustness of any interpretability method with respect to the model symmetry group"
  - [section] "We measure the invariance of e with respect to G for some x∈X(Ω,C) with the metric InvG(e,x)≡1/|G|∑g∈GsE[e(ρ[g]x),e(x)]"
  - [corpus] Weak evidence - corpus papers discuss symmetry discovery but don't provide concrete metrics for explanation invariance.

### Mechanism 2
- Claim: Aggregation over symmetry transformations enforces explanation invariance.
- Mechanism: Proposition 2.3 shows that averaging explanations over all symmetry transformations creates a G-invariant explanation. This works by constructing einv(x) = 1/|G|∑g∈Ge(ρ[g]x), which mathematically guarantees invariance.
- Core assumption: The original explanation method is well-defined for all symmetry-transformed inputs.
- Evidence anchors:
  - [abstract] "a systematic approach to increase the invariance of any interpretability method with respect to a symmetry group"
  - [section] "Proposition 2.3. [Enforce Invariance] Consider a neural network f:X(Ω,C)→Y that is invariant with respect to the symmetry group G... The auxiliary explanation einv is invariant under the symmetry group G."
  - [corpus] Weak evidence - corpus papers discuss invariance learning but don't provide aggregation-based invariance enforcement methods.

### Mechanism 3
- Claim: The choice of baseline signal critically affects feature importance method robustness.
- Mechanism: Proposition B.6 shows that gradient-based methods are equivariant only when using G-invariant baselines (ρ[g]¯x = ¯x for all g∈G). The proof demonstrates that the invariance of the baseline propagates through the gradient computation to ensure equivariance.
- Core assumption: Gradient-based methods can be expressed in terms of a baseline signal and a functional ϕ.
- Evidence anchors:
  - [abstract] "empirical results support our theoretical analysis" regarding baseline importance
  - [section] "If ρ is a permutation representation and the baseline signal is G-invariant... then the explanation e is G-equivariant"
  - [corpus] Weak evidence - corpus papers discuss symmetry in explanations but don't specifically address baseline selection.

## Foundational Learning

- Concept: Group theory and group representations
  - Why needed here: The entire framework relies on formalizing symmetries as groups and their actions on data spaces through representations.
  - Quick check question: What is the difference between a permutation representation and an orthogonal representation?

- Concept: Geometric deep learning formalism
  - Why needed here: Provides the mathematical framework for defining invariance/equivariance properties of models and explanations.
  - Quick check question: How does the G-invariance property of a model differ from G-equivariance?

- Concept: Feature importance attribution methods
  - Why needed here: The paper evaluates multiple types of interpretability methods, with feature importance being a primary focus.
  - Quick check question: What is the key difference between gradient-based and perturbation-based feature importance methods?

## Architecture Onboarding

- Component map: Symmetry group definition -> Invariant model training -> Interpretability method application -> InvG/EquivG metric computation -> Aggregation procedure (if needed)
- Critical path: Define symmetry group → Train invariant model → Apply interpretability method → Compute InvG/EquivG metrics → If needed, apply aggregation → Re-compute metrics
- Design tradeoffs: Complete aggregation over all symmetries guarantees invariance but is computationally expensive; Monte Carlo sampling provides approximation at lower cost but with potential variance
- Failure signatures: Low InvG/EquivG scores indicate explanations not respecting model symmetries; baseline-dependent methods failing suggests need for invariant baselines; representation-based methods failing suggests need for invariant layers
- First 3 experiments:
  1. Apply Integrated Gradients with invariant baseline (zero signal) to a CNN on ECG data and compute EquivG metric
  2. Apply Influence Functions to a GNN on Mutagenicity data and compute InvG metric
  3. Apply aggregation procedure to a concept-based method on ModelNet40 data and measure improvement in InvG

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the robustness metrics InvG and EquivG behave for interpretability methods applied to models with infinite symmetry groups, such as those used in spherical CNNs or other continuous transformation groups?
- Basis in paper: [inferred] The paper mentions that extending the analysis to infinite or uncountable groups would require a more sophisticated sampling technique, such as importance sampling.
- Why unresolved: The current framework and experiments focus on finite symmetry groups, leaving the behavior of the metrics for infinite groups unexplored.
- What evidence would resolve it: Developing and applying the metrics to models with infinite symmetry groups, and comparing the results with finite group cases to understand the differences and challenges.

### Open Question 2
- Question: To what extent does the choice of baseline signal in gradient-based feature importance methods affect the robustness of explanations beyond the requirement of invariance under the symmetry group?
- Basis in paper: [explicit] The paper discusses that gradient-based methods require invariant baselines to guarantee equivariance and mentions the impact of baseline choice on explanations.
- Why unresolved: While the paper establishes the need for invariant baselines, it does not explore how different types of invariant baselines might further influence the robustness of explanations.
- What evidence would resolve it: Conducting experiments with various invariant baselines and analyzing their impact on the robustness metrics to identify optimal baseline choices for different model types and symmetry groups.

## Limitations

- The framework assumes exact symmetry groups and representations, which may be computationally intractable for continuous or complex transformations
- Aggregation-based invariance enforcement requires complete enumeration of all symmetry transformations, making it infeasible for infinite groups
- Empirical validation is limited to three datasets and specific model architectures, potentially missing failure modes in other domains or architectures

## Confidence

**High Confidence**: The mathematical formulation of InvG and EquivG metrics, the proof that aggregation enforces invariance, and the relationship between baseline invariance and gradient method equivariance.

**Medium Confidence**: The empirical findings that baseline selection affects robustness and that certain methods consistently show better invariance properties across datasets.

**Low Confidence**: The generalizability of the proposed guidelines to all interpretability methods and the assumption that Monte Carlo sampling provides sufficient approximation for large symmetry groups.

## Next Checks

1. **Scalability Test**: Evaluate the aggregation approach on continuous symmetry groups (e.g., rotations in 3D) using Monte Carlo sampling to determine the required sample size for stable metrics.

2. **Architecture Transfer**: Apply the framework to attention-based models and test whether the baseline invariance requirement holds for self-attention mechanisms.

3. **Cross-Domain Robustness**: Test the metrics on natural language processing tasks with permutation-invariant transformers to verify the framework's applicability beyond the three evaluated modalities.