---
ver: rpa2
title: Local Large Language Models for Complex Structured Medical Tasks
arxiv_id: '2308.01727'
source_url: https://arxiv.org/abs/2308.01727
tags:
- language
- llms
- arxiv
- training
- codes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that local large language models (LLMs)
  can outperform BERT-style models for extracting structured condition codes from
  pathology reports, a complex multi-label classification task. The authors fine-tuned
  LLaMA-based models using over 150k uncurated pathology reports, achieving significantly
  higher accuracy, AUC, precision, recall, and F1 scores compared to BERT, BioClinicalBERT,
  and LongFormer models.
---

# Local Large Language Models for Complex Structured Medical Tasks

## Quick Facts
- arXiv ID: 2308.01727
- Source URL: https://arxiv.org/abs/2308.01727
- Reference count: 40
- Local LLMs (LLaMA) outperform BERT-style models for extracting structured condition codes from pathology reports

## Executive Summary
This paper demonstrates that local large language models can significantly outperform traditional BERT-style models for extracting structured condition codes from pathology reports. Using over 150k uncurated surgical pathology reports, the authors fine-tuned LLaMA-based models and achieved substantially higher accuracy, AUC, precision, recall, and F1 scores compared to BERT, BioClinicalBERT, and LongFormer models. The 13-billion parameter LLaMA model achieved an F1 score of 0.785 on the largest dataset, showing particular strength with large datasets while BERT models excel with smaller, simpler tasks.

## Method Summary
The authors fine-tuned LLaMA-based models using instruction-based JSON format with concatenated gross and final pathology reports as input and ICD codes as output labels. They compared performance against BERT, BioClinicalBERT, PathologyBERT, UKPathBERT, and LongFormer models across three dataset sizes (2.5k, 25k, and 150k reports). Models were trained using FastChat framework on 4xA100 80G GPUs, with evaluation using sklearn metrics for multi-label classification. The approach focused on domain adaptation of general language representations to capture specialized medical terminology and multi-label associations in pathology reports.

## Key Results
- LLaMA-based models significantly outperformed BERT-style models across all evaluated metrics (F1 scores of 0.785 vs 0.549 on largest dataset)
- Both 7B and 13B parameter LLaMA models showed consistent improvement over traditional models, with larger models performing better on larger datasets
- Instruction-based fine-tuning successfully prevented format deviation or hallucination in structured output generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning LLaMA on domain-specific medical data improves multi-label classification accuracy beyond BERT-style models.
- Mechanism: Domain adaptation of general language representations allows the model to capture specialized medical terminology and multi-label associations present in pathology reports.
- Core assumption: Medical terminology and report structure are sufficiently distinct from general language that fine-tuning yields better performance than pre-trained medical BERT variants.
- Evidence anchors:
  - [abstract] "LLaMA-based models significantly outperform BERT-style models across all evaluated metrics"
  - [section 2.1] "We derived our dataset from over 150k uncurated surgical pathology reports"
  - [corpus] No corpus evidence available for this specific mechanism.
- Break condition: If medical terminology overlap with pre-trained models is high, fine-tuning advantage may diminish.

### Mechanism 2
- Claim: Large parameter count (13B vs 7B) provides performance gains when training data is abundant.
- Mechanism: Larger models have more capacity to learn complex multi-label relationships and capture nuanced associations in large datasets.
- Core assumption: The complexity of multi-label pathology coding requires model capacity beyond what smaller models can provide.
- Evidence anchors:
  - [section 3.1] "Both Path-LLaMA models performed significantly better than any other model"
  - [section 3.3] "The LLaMA models performed best on the largest dataset"
  - [corpus] No corpus evidence available for this specific mechanism.
- Break condition: If dataset is too small, larger models may overfit and underperform smaller models.

### Mechanism 3
- Claim: Instruction-based fine-tuning with structured output formats improves task-specific performance.
- Mechanism: Training on JSON instruction-response pairs conditions the model to generate structured outputs (ICD codes) rather than free text.
- Core assumption: The model can learn to follow structured output instructions when trained with appropriate examples.
- Evidence anchors:
  - [section 2.1] "LLMs are typically trained using an instruction-based format"
  - [section 3] "With the exception of single epoch training of the Path-LLaMA 7b model, deviation (hallucination) from the intended format was not experienced"
  - [corpus] No corpus evidence available for this specific mechanism.
- Break condition: If instruction format is ambiguous or inconsistent, model may produce incorrect output structures.

## Foundational Learning

- Concept: Multi-label classification metrics (precision, recall, F1, AUC)
  - Why needed here: To evaluate model performance on tasks where each instance can have multiple correct labels
  - Quick check question: If a pathology report has 3 correct ICD codes and the model predicts 2 correctly, what is the accuracy?
- Concept: Fine-tuning vs. pre-training vs. language modeling
  - Why needed here: To understand the different approaches to adapting models for domain-specific tasks
  - Quick check question: What is the key difference between fine-tuning a BERT model and training a new language model on pathology reports?
- Concept: Tokenization and context window limitations
  - Why needed here: To understand why LongFormer was included and how input length affects model performance
  - Quick check question: If a pathology report is 2000 tokens and BERT's max context is 512, what happens to the remaining tokens?

## Architecture Onboarding

- Component map:
  - Dataset preparation → Model training (BERT, LongFormer, LLaMA) → Evaluation metrics → Deployment (vLLM, LLaMA.cpp)
  - Input: Concatenated gross + final reports with associated ICD codes
  - Output: Structured list of condition codes
- Critical path:
  - Prepare dataset in correct format for each model type
  - Train models with appropriate epochs based on performance plateau
  - Evaluate using multi-label classification metrics
  - Deploy using vLLM for GPU or LLaMA.cpp for CPU inference
- Design tradeoffs:
  - Model size vs. hardware requirements (7B vs 13B parameters)
  - Precision (fp16 vs int4) vs. inference speed and accuracy
  - Dataset size vs. code diversity and model generalization
- Failure signatures:
  - BERT models: Poor performance on large datasets with many code combinations
  - LongFormer: May still miss context if report exceeds 4096 tokens
  - LLaMA: Potential hallucination if training data is insufficient or instruction format is unclear
- First 3 experiments:
  1. Train BERT-base-uncased on small dataset (10% of data) and evaluate metrics
  2. Train LLaMA-7B on same small dataset and compare performance
  3. Train LLaMA-13B on large dataset and evaluate improvement over 7B model

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of local LLMs for structured medical data extraction compare to commercial LLM services like ChatGPT when given the same task and context?
- Basis in paper: [inferred] The paper notes that ChatGPT cannot perform specific queries to extract ICD codes from pathology reports, while local LLMs can achieve high accuracy.
- Why unresolved: The study does not directly compare local LLMs against commercial LLM services on the same task.
- What evidence would resolve it: Direct benchmarking of local LLMs against ChatGPT/GPT-4 on identical medical structured data extraction tasks with controlled prompts and contexts.

### Open Question 2
- Question: What is the optimal context window size for pathology report analysis using local LLMs?
- Basis in paper: [explicit] The paper mentions that LongFormer models with 4096 token context outperformed BERT models with 512 tokens, but doesn't explore intermediate sizes or context extension techniques.
- Why unresolved: The study only tested LongFormer's extended context versus standard BERT, without exploring optimal window sizes or the impact of context extension methods.
- What evidence would resolve it: Systematic testing of local LLMs across varying context window sizes (512-4096 tokens) and with context extension techniques to identify performance sweet spots.

### Open Question 3
- Question: How does quantization level affect the accuracy of local LLMs for medical structured data extraction?
- Basis in paper: [explicit] The paper tested GGML int4 quantization with nearly identical results to fp16 but significantly slower inference times.
- Why unresolved: The study only tested one quantization level (int4) and didn't explore the full range of quantization levels or their impact on different model sizes.
- What evidence would resolve it: Comprehensive testing of local LLMs across multiple quantization levels (fp16, int8, int4, int3, int2) to quantify the accuracy-speed tradeoff for medical NLP tasks.

## Limitations

- Uncurated dataset may contain annotation inconsistencies and label quality issues across different institutions and time periods
- Performance evaluation focuses on exact code matches rather than clinical validity or appropriateness of extracted codes
- Hardware requirements for 13B parameter model still demand substantial GPU resources, limiting true "local" deployment

## Confidence

**High Confidence:**
- LLaMA models outperform BERT-style models on this specific multi-label pathology coding task with the evaluated datasets
- Larger LLaMA models (13B) provide performance gains when sufficient training data is available
- Local deployment is technically feasible using vLLM or LLaMA.cpp frameworks

**Medium Confidence:**
- The performance advantage generalizes to other complex structured medical NLP tasks
- The instruction-based fine-tuning approach reliably prevents hallucination in production settings
- The 7B parameter model represents a practical balance of performance and resource requirements for most medical institutions

**Low Confidence:**
- Claims about accessibility for "medical institutions with modest computational resources" are sufficiently qualified
- The evaluation metrics fully capture clinical utility of the extracted codes
- Results would generalize to other medical specialties beyond pathology

## Next Checks

1. **Cross-institutional validation**: Test the trained models on pathology reports from different healthcare systems to assess generalizability and identify potential overfitting to the original institution's coding patterns.

2. **Clinical validation study**: Have clinical experts evaluate the accuracy and clinical appropriateness of extracted codes compared to the original clinical coding, measuring both precision and clinical relevance rather than just exact matches.

3. **Resource requirement analysis**: Conduct comprehensive benchmarking of inference latency and memory usage across different hardware configurations (CPU vs GPU, varying RAM sizes) to provide clearer guidance on true resource requirements for "local" deployment.