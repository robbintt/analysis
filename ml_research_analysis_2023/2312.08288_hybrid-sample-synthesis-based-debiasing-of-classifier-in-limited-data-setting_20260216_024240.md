---
ver: rpa2
title: Hybrid Sample Synthesis-based Debiasing of Classifier in Limited Data Setting
arxiv_id: '2312.08288'
source_url: https://arxiv.org/abs/2312.08288
tags:
- samples
- data
- training
- bias
- bias-conflicting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of debiasing deep learning models
  when trained on limited data without prior knowledge of the bias present. The proposed
  method synthesizes hybrid samples by combining likely bias-conflicting samples with
  likely bias-aligned samples to reduce the impact of bias-aligned samples on model
  predictions while maintaining sufficient diversity to prevent overfitting to the
  few bias-conflicting samples.
---

# Hybrid Sample Synthesis-based Debiasing of Classifier in Limited Data Setting

## Quick Facts
- arXiv ID: 2312.08288
- Source URL: https://arxiv.org/abs/2312.08288
- Authors: 
- Reference count: 33
- Key outcome: The proposed method significantly outperforms existing debiasing methods in limited data settings, achieving absolute margins of 10.39%, 9.08%, 8.07%, and 9.67% on Corrupted CIFAR-10 Type 1 dataset with 10% training data and 0.05 bias-conflicting ratio.

## Executive Summary
This paper addresses the challenge of debiasing deep learning models when trained on limited data without prior knowledge of the bias present. The proposed method synthesizes hybrid samples by combining likely bias-conflicting samples with likely bias-aligned samples to reduce the impact of bias-aligned samples on model predictions while maintaining sufficient diversity to prevent overfitting to the few bias-conflicting samples. The approach involves training two models in parallel, where one model is trained to be biased and the other focuses more on likely bias-conflicting samples. Extensive experiments on benchmark datasets demonstrate that the proposed approach significantly outperforms existing debiasing methods in the limited data setting.

## Method Summary
The method trains two models in parallel - a biased model MB (using Generalized Cross Entropy loss) and a debiased model MD (using Cross Entropy loss with reweighting). Hybrid samples are synthesized by combining likely bias-conflicting samples (identified through MB's difficulty) with bias-aligned samples from the same class. The reweighting factor, computed as the ratio of losses between MB and MD, identifies samples that MB finds difficult (likely bias-conflicting). These samples are combined with bias-aligned samples using a weighted interpolation to create hybrids that preserve class identity while diluting bias influence. The MD model is trained with both original and hybrid samples, with the loss reweighted by the inverse difficulty MB experiences.

## Key Results
- Outperforms existing methods by absolute margins of 10.39%, 9.08%, 8.07%, and 9.67% on Corrupted CIFAR-10 Type 1 with 10% training data and 0.05 bias-conflicting ratio
- Shows consistent improvement across multiple benchmark datasets (Colored MNIST, Corrupted CIFAR-10, BFFHQ)
- Maintains performance gains even with very limited training data (1-10% of original datasets)
- Demonstrates effectiveness across different bias types and configurations

## Why This Works (Mechanism)

### Mechanism 1
The method reduces overfitting to rare bias-conflicting samples by synthesizing hybrid samples that blend bias-conflicting content with bias-aligned samples from the same class. Hybrid samples are created using a weighted combination of a likely bias-conflicting sample and a bias-aligned sample from the same class. The reweighting factor from a biased model MB identifies likely bias-conflicting samples, and their combination with bias-aligned samples ensures sufficient diversity while preserving bias-conflicting content. Core assumption: Bias-conflicting samples are rare but contain class-relevant features independent of the bias attribute; blending them with bias-aligned samples maintains class identity while diluting bias.

### Mechanism 2
Training two models in parallel (MB biased, MD debiased) allows MD to focus on hard-to-learn bias-conflicting samples while MB learns to predict based on biased shortcuts. MB is trained with GCE loss to emphasize bias-aligned samples (easier to learn), while MD is trained with CE loss and reweighted by the inverse difficulty MB experiences. This reweighting factor is higher for samples MB struggles with, which are likely bias-conflicting. Core assumption: Bias-aligned samples are easier for a biased model to learn; thus, samples that MB finds difficult are likely bias-conflicting.

### Mechanism 3
The hybrid synthesis increases the effective population of bias-conflicting samples without overfitting because each hybrid is a mix of rare and common samples. For each batch, top N*(1-tbc) samples by reweighting factor are selected as likely bias-conflicting; these are combined with bias-aligned samples from the same class to form hybrids. This increases the number of training samples containing bias-conflicting content while keeping diversity. Core assumption: Combining bias-conflicting and bias-aligned samples preserves class identity and dilutes bias influence, and the diversity in hybrids prevents overfitting.

## Foundational Learning

- Concept: Generalized Cross Entropy (GCE) loss
  - Why needed here: GCE loss is used to train the biased model MB because it emphasizes easy-to-learn samples, which in this context are the bias-aligned samples. This makes MB more biased and helps identify bias-conflicting samples via difficulty.
  - Quick check question: How does GCE loss differ from standard cross-entropy in terms of sample weighting during training?

- Concept: Reweighting based on model difficulty
  - Why needed here: Reweighting factors are computed as the ratio of losses between MB and MD. Samples that MB finds hard (high reweighting) are likely bias-conflicting and should be emphasized in MD training.
  - Quick check question: Why does a high reweighting factor indicate that a sample is likely bias-conflicting rather than just hard in general?

- Concept: Sample mixing / interpolation in feature space
  - Why needed here: Hybrid samples are formed by interpolating between bias-conflicting and bias-aligned samples, which requires understanding of how interpolation affects both content and label consistency.
  - Quick check question: What property must hold for a linear interpolation between two samples to preserve the class label?

## Architecture Onboarding

- Component map: MB (GCE loss) -> MD (CE loss + reweighting) -> Hybrid synthesis module -> Loss computation -> Parameter updates

- Critical path:
  1. Forward pass: MB and MD process same batch
  2. Compute losses: GCE(MB), CE(MD), and hybrid CE
  3. Compute reweighting factors R(x) = LB(x)/(LB(x)+LD(x)) for each sample and hybrid
  4. Select likely bias-conflicting samples using tbc
  5. Synthesize hybrids: xh = alpha*xbc + (1-alpha)*xba
  6. Compute hybrid reweighting R(xh)
  7. Backward pass: update MB with GCE loss, MD with weighted CE + hybrid CE
  8. Discard MB after training, use MD for evaluation

- Design tradeoffs:
  - GCE vs CE for MB: GCE emphasizes easy samples (bias-aligned), making MB biased; CE would not create this effect
  - tbc filtering ratio: Higher tbc selects fewer bias-conflicting samples (less hybrid synthesis), lower tbc selects more (risk of overfitting to mislabeled bias-aligned)
  - Alpha mixing coefficient: Higher alpha gives more weight to bias-conflicting content (stronger debiasing), lower alpha dilutes it more

- Failure signatures:
  - MB loss for bias-conflicting samples remains low → tbc too low or bias not learnable via shortcuts
  - MD overfits to hybrids → alpha too high or tbc too low
  - Performance similar to vanilla → reweighting not effective or hybrids not diverse enough
  - False positive rate for bias-conflicting identification high → reweighting factor threshold not calibrated

- First 3 experiments:
  1. Train MB and MD on reduced Colored MNIST (p=5%, sigma=0.05) with default tbc=0.9, alpha=0.9, beta=1.0; compare MD accuracy to vanilla
  2. Vary tbc from 0.7 to 0.95 on Corrupted CIFAR-10 Type 1; plot accuracy vs tbc to find optimal filtering ratio
  3. Replace hybrid synthesis with simple Mixup between all samples; compare performance to proposed hybrid method on BFFHQ

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed hybrid sample synthesis method scale to high-dimensional datasets with complex feature interactions, such as medical imaging or genomics data? The paper demonstrates effectiveness on relatively simple datasets (MNIST, CIFAR-10, BFFHQ) but doesn't explore high-dimensional, complex data scenarios. The method's reliance on linear interpolation (Eq. 2) and reweighting factors may not capture complex interactions in high-dimensional spaces, potentially limiting its generalizability.

### Open Question 2
What is the impact of hyperparameter sensitivity (α, β, tbc) on the proposed method's performance across diverse bias types and dataset characteristics? The paper identifies hyperparameters through ablation experiments but doesn't provide systematic sensitivity analysis or guidelines for hyperparameter selection. Different bias types and dataset characteristics might require substantially different hyperparameter settings, making the method difficult to apply without extensive tuning.

### Open Question 3
How does the proposed method perform when multiple biases with different strengths coexist in the training data? The paper focuses on single bias scenarios and doesn't explore multi-bias settings where biases might interact or compete. The current approach identifies and addresses one bias at a time, but real-world datasets often contain multiple, potentially conflicting biases that may require different handling strategies.

## Limitations
- The method's effectiveness relies on the assumption that bias-aligned samples are easier for MB to learn, which may not hold for all bias types
- The hybrid synthesis mechanism assumes linear interpolation preserves class identity, requiring further validation
- Lacks implementation details for the BFFHQ dataset and specific hyperparameter tuning procedures

## Confidence

**High confidence**: The dual-model architecture with GCE loss for MB and CE loss for MD is clearly specified and experimentally validated

**Medium confidence**: The hybrid synthesis approach improves performance over baselines, though exact mechanisms could be more rigorously proven

**Low confidence**: The generalization of results to real-world scenarios with unknown bias types and the stability of the method across different datasets

## Next Checks

1. Test the method on a real-world dataset with known bias (e.g., CelebA) to validate performance beyond synthetic benchmarks
2. Conduct ablation studies on the tbc parameter to determine optimal filtering ratios for different bias types
3. Analyze the feature space representations of hybrid samples to verify they preserve class identity while reducing bias alignment