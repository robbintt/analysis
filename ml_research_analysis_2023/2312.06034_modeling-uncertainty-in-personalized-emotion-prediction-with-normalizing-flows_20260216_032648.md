---
ver: rpa2
title: Modeling Uncertainty in Personalized Emotion Prediction with Normalizing Flows
arxiv_id: '2312.06034'
source_url: https://arxiv.org/abs/2312.06034
tags:
- text
- normalizing
- emotion
- emotions
- flow
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a novel approach for personalized emotion prediction
  in natural language processing using conditional normalizing flows. It addresses
  the challenge of modeling uncertainty in subjective NLP tasks, where different humans
  may perceive the same content differently.
---

# Modeling Uncertainty in Personalized Emotion Prediction with Normalizing Flows

## Quick Facts
- arXiv ID: 2312.06034
- Source URL: https://arxiv.org/abs/2312.06034
- Reference count: 40
- Primary result: Hybrid model combining deterministic and probabilistic approaches achieves new state-of-the-art performance on hate speech and emotion recognition tasks

## Executive Summary
This paper addresses the challenge of modeling uncertainty in subjective natural language processing tasks where different humans may perceive the same content differently. The authors propose using conditional normalizing flows to model complex multimodal distributions of subjective annotations, enabling probabilistic predictions that capture individual perception differences. The approach incorporates personalization by conditioning on user profiles, significantly improving prediction accuracy and uncertainty estimation compared to non-personalized models.

## Method Summary
The method uses conditional normalizing flows to transform a simple base distribution into complex conditional distributions of subjective annotations given both text and user profile information. The model employs various flow architectures (MAF, CNF, RealNVP, NICE) and personalization approaches (TXT-Baseline, OneHot, HuBi-Formula, HuBi-Medium) to capture individual differences in perception. Training is performed by optimizing negative log-likelihood directly, allowing comparison of different probabilistic models. A hybrid approach combines sampled probabilities from the flow with deterministic predictions to achieve superior performance.

## Key Results
- Personalized models significantly reduce model uncertainty compared to non-personalized approaches
- The hybrid approach combining deterministic and probabilistic predictions achieves new state-of-the-art performance on hate speech and emotion recognition tasks
- Negative log-likelihood optimization enables direct comparison between different probabilistic models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Conditional normalizing flows can model complex multimodal distributions of subjective annotations by transforming a simple base distribution through invertible functions.
- Mechanism: The model uses a series of K invertible transformations (f1...fK) to map from a base distribution pZ(z) (typically Gaussian) to the complex conditional distribution pY(y|ep, et) of subjective annotations. The change-of-variable formula allows computation of the likelihood, enabling direct optimization of negative log-likelihood.
- Core assumption: The subjective annotation space can be represented as a complex but structured distribution that can be transformed from a simple base distribution.
- Evidence anchors:
  - [abstract] "This allows us to model complex multimodal distributions and to compare various models using negative log-likelihood (NLL)."
  - [section] "Normalizing Flows [53] are a class of generative models that enables estimation of the uncertainty of prediction thanks to the access to log probability function and thus enable direct optimization of negative log-likelihood (NLL)."
- Break condition: If the subjective annotation space is too irregular or discontinuous for smooth transformations to capture, the flow-based approach would fail to model it effectively.

### Mechanism 2
- Claim: Personalization reduces model uncertainty by incorporating individual-specific information that captures how different annotators perceive the same content differently.
- Mechanism: By adding profile extractor that creates user representation ep, the model conditions the probability distribution on both text embedding et and user profile ep. This allows the flow to model individual differences in perception, leading to more accurate and certain predictions for each specific user.
- Core assumption: Individual differences in perception are systematic enough to be captured by learned user representations and improve prediction accuracy.
- Evidence anchors:
  - [abstract] "The comparative analysis of generalized and personalized approaches revealed that our personalized solutions significantly outperform the baseline and provide more precise uncertainty estimates."
  - [section] "It may be solved by Personalized Natural Language Processing (PNLP), where the model exploits additional information about the reader to make more accurate predictions."
- Break condition: If individual differences are too random or if user representations don't capture meaningful patterns, personalization would add noise without improving performance.

### Mechanism 3
- Claim: The hybrid approach combining deterministic and probabilistic predictions outperforms pure approaches by leveraging both point estimates and uncertainty information.
- Mechanism: The hybrid model uses sampled probabilities from the flow as additional features to a deterministic model. This combines the interpretability and precision of deterministic predictions with the uncertainty modeling capabilities of the probabilistic approach.
- Core assumption: Uncertainty information captured by the flow provides valuable context that improves deterministic predictions when used as additional features.
- Evidence anchors:
  - [abstract] "The information brought by the developed methods makes it possible to build hybrid models whose effectiveness surpasses classic solutions."
  - [section] "In the fourth experiment, we mixed the deterministic approach with the probabilistic, to create a hybrid model, Tab. IV. In both Aggression & Attack and Emotion Simple tasks, the results obtained by the hybrid approach outperformed previous methods by a large margin."
- Break condition: If the sampled probabilities don't capture meaningful uncertainty or if the deterministic model cannot effectively utilize this information, the hybrid approach would not improve over either pure approach.

## Foundational Learning

- Concept: Conditional normalizing flows and their change-of-variable formula
  - Why needed here: The entire probabilistic modeling approach relies on the mathematical framework of normalizing flows to transform simple distributions into complex conditional distributions of subjective annotations.
  - Quick check question: How does the change-of-variable formula in equation (1) enable density estimation in normalizing flows?

- Concept: Personalized representations and their integration with text embeddings
  - Why needed here: The personalization component requires understanding how user profiles can be represented and combined with text embeddings to condition the flow transformations.
  - Quick check question: What are the three personalization architectures mentioned (OneHot, HuBi-Formula, HuBi-Medium) and how do they differ in representing user information?

- Concept: Negative log-likelihood optimization for probabilistic models
  - Why needed here: Direct optimization of NLL is the core training objective for the flow-based model, distinguishing it from traditional classification approaches.
  - Quick check question: Why is negative log-likelihood a suitable objective for comparing different probabilistic models of subjective annotations?

## Architecture Onboarding

- Component map:
  - Profile extractor: Creates user representation ep from user features (one-hot encoding, deviation metrics, learned embeddings)
  - Text encoder: Transforms input text into embedding et using a Transformer-based language model
  - Conditional normalizing flow: Maps (ep, et) to probability distribution pY(y|ep, et) through invertible transformations
  - Base distribution: Simple distribution (typically Gaussian) in latent space that gets transformed
  - Training loop: Optimizes flow parameters to minimize negative log-likelihood on training data

- Critical path: Text → Text encoder → Text embedding → Flow → Conditional distribution → Loss computation → Backpropagation
- Design tradeoffs:
  - Flow complexity vs. computational efficiency: More complex flows (more layers, blocks) can model richer distributions but increase computation time
  - Personalization granularity vs. data requirements: More detailed user representations require more data per user to learn effectively
  - End-to-end vs. two-stage training: End-to-end allows better integration but may be harder to optimize; two-stage is more modular but may miss joint optimization benefits

- Failure signatures:
  - Poor NLL on validation set: Flow architecture may be too simple or too complex for the data distribution
  - No improvement with personalization: User representations may not capture meaningful individual differences
  - Mode collapse in generated samples: Flow may not be flexible enough to capture the full distribution

- First 3 experiments:
  1. Train a basic conditional flow without personalization on a simple dataset (e.g., Wikipedia Detox Toxicity) to verify the basic flow implementation works
  2. Add a simple personalization approach (OneHot) to the flow and compare NLL improvement on the same dataset
  3. Implement the hybrid approach by sampling from the flow and using those samples as features in a deterministic model, comparing performance to both pure approaches

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the Emotional Normalizing Flow model change when trained on datasets where the same annotator has marked the same text multiple times over a period?
- Basis in paper: [explicit] The paper mentions that due to cost constraints, there are no reference datasets available that contain text and annotator information simultaneously with multiple markings of the same text by the same person. The authors express interest in conducting in-depth studies on such datasets if they become available.
- Why unresolved: The paper does not have access to such datasets and therefore cannot experimentally validate the model's performance on them.
- What evidence would resolve it: Performance metrics (e.g., negative log-likelihood, F1-score) from experiments using datasets with multiple annotations by the same annotator over time.

### Open Question 2
- Question: What is the impact of using different language models on the performance of the Emotional Normalizing Flow model?
- Basis in paper: [explicit] The paper mentions that a multilingual model was used to embed the text due to one of the datasets being in a language other than English. The authors suggest that experimenting with other language models using the provided source codes could be a potential direction.
- Why unresolved: The paper does not explore the performance of the model with different language models, limiting the generalizability of the results.
- What evidence would resolve it: Comparative results of the model's performance using various language models on the same datasets.

### Open Question 3
- Question: How does the Emotional Normalizing Flow model perform on other subjective NLP tasks beyond emotion recognition and hate speech detection?
- Basis in paper: [explicit] The paper validates the model on emotion recognition and hate speech tasks, but the authors mention future work focusing on applications to other tasks such as active or reinforcement learning.
- Why unresolved: The paper does not experiment with other subjective NLP tasks, leaving the model's applicability to these areas untested.
- What evidence would resolve it: Performance metrics and comparative analysis of the model on a diverse set of subjective NLP tasks, such as sarcasm detection or sentiment analysis.

## Limitations
- The approach requires substantial data per user to learn effective personalization, which may not be available in many real-world applications
- Computational cost of normalizing flows is significantly higher than standard classification models, potentially limiting scalability
- The study focuses on relatively short text sequences (under 200 words), and performance on longer documents remains untested

## Confidence
- **High confidence**: The core mechanism of using conditional normalizing flows to model uncertainty in subjective annotations is well-established and mathematically sound. The empirical improvements over baselines on two datasets are substantial and clearly demonstrated.
- **Medium confidence**: The claim that personalization significantly reduces model uncertainty is supported by evidence but could benefit from more extensive ablation studies across different types of personalization architectures.
- **Low confidence**: The hybrid approach's superiority is demonstrated on the tested datasets, but the general principle that sampled probabilities from flows will consistently improve deterministic models across different NLP tasks is not yet established.

## Next Checks
1. Apply the approach to longer documents (500+ words) and different subjective NLP tasks (e.g., irony detection, stance classification) to verify the method's robustness beyond the tested domains
2. Conduct experiments varying the amount of data per user to determine the minimum requirements for effective personalization and identify when the approach becomes impractical
3. Systematically vary the number of flow layers and types of transformations to determine the optimal balance between modeling capacity and computational efficiency