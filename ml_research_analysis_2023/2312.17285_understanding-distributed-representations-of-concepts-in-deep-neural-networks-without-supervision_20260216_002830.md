---
ver: rpa2
title: Understanding Distributed Representations of Concepts in Deep Neural Networks
  without Supervision
arxiv_id: '2312.17285'
source_url: https://arxiv.org/abs/2312.17285
tags:
- instances
- concepts
- decision
- concept
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an unsupervised method for discovering distributed
  representations of concepts in deep neural networks by selecting principal subsets
  of neurons. The key idea is to leverage activation states to identify concept sets,
  using a novel Configuration distance metric that effectively captures semantic similarity
  in the feature space.
---

# Understanding Distributed Representations of Concepts in Deep Neural Networks without Supervision

## Quick Facts
- arXiv ID: 2312.17285
- Source URL: https://arxiv.org/abs/2312.17285
- Reference count: 20
- Key outcome: Unsupervised method discovers distributed concept representations using activation states and Configuration distance, enabling subclass detection and misclassification analysis

## Executive Summary
This paper introduces an unsupervised approach for discovering distributed representations of concepts in deep neural networks without requiring pre-defined concept sets or segmentation processes. The method leverages activation states and a novel Configuration distance metric to identify principal neurons that construct Relaxed Decision Regions (RDRs) encompassing instances with coherent concepts. Through experiments on multiple datasets including Mini-ImageNet, Flowers Recognition, and CIFAR-10, the approach demonstrates superior performance in purity and entropy metrics for subclass detection compared to existing methods, while providing interpretable insights into layer-wise concept learning mechanisms.

## Method Summary
The proposed method constructs Relaxed Decision Regions by first computing a Configuration distance matrix using Hamming distance between activation states from a target network layer. For a given instance, the algorithm selects k nearest neighbors as a positive set and remaining instances as a negative set. A greedy algorithm then iteratively selects t principal neurons that maximize frequency differences between these sets, identifying neurons most informative for explaining the target concept. The RDR consists of all instances with identical activation states on these principal neurons, creating interpretable regions where encompassed instances share learned concepts. The method operates without human supervision and can identify unlabeled subclasses and detect causes of misclassification.

## Key Results
- RDRs outperform existing methods in purity and entropy metrics for subclass detection across multiple datasets
- The Configuration distance metric effectively captures semantic similarity in the feature space by measuring Hamming distance between activation states
- The approach successfully reveals layer-wise differences in concept learning, with earlier layers capturing spatial concepts and later layers capturing class-specific features

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The Configuration distance metric effectively captures semantic similarity in the feature space by measuring Hamming distance between activation states.
- **Mechanism**: In piecewise linear neural networks, each neuron activation creates a linear region in the feature space. The Configuration distance counts how many of these internal decision boundaries differ between two instances. Since similar concepts should follow similar activation patterns across neurons, a low Configuration distance indicates shared semantic meaning.
- **Core assumption**: Activation states are reliable indicators of learned concepts, and the Hamming distance between activation vectors correlates with semantic similarity.
- **Evidence anchors**: [abstract]: "The key idea is to leverage activation states to identify concept sets, using a novel Configuration distance metric that effectively captures semantic similarity in the feature space." [section]: "Our empirical findings demonstrate that instances with similar neuron activation states tend to share coherent concepts."

### Mechanism 2
- **Claim**: The greedy algorithm for selecting principal neurons finds an optimal subset that best represents the target concept.
- **Mechanism**: The algorithm iteratively selects neurons that maximize the frequency difference between the positive set (concept neighbors) and negative set (non-concept instances). This creates a configuration that is both coherent with the target concept and discriminative from other concepts.
- **Core assumption**: The frequency difference of neuron activations between concept and non-concept sets is a valid proxy for concept relevance.
- **Evidence anchors**: [section]: "Our greedy algorithm then iteratively selects a neuron that has the largest frequency difference between S and Sneg, indicating a high information gain to explain S." [section]: Theorem 1 states the optimal solution can be obtained by the greedy algorithm.

### Mechanism 3
- **Claim**: Relaxed Decision Regions (RDRs) capture coherent concept groups by encompassing instances with similar activation states across selected principal neurons.
- **Mechanism**: By selecting principal neurons and finding all instances with identical activation states on those neurons, RDRs create interpretable regions in the feature space where all instances share learned concepts. The "relaxed" aspect comes from including all instances matching the principal configuration, not just the nearest neighbors.
- **Core assumption**: A shared activation pattern across principal neurons implies shared semantic meaning.
- **Evidence anchors**: [abstract]: "The proposed method selects principal neurons that construct an interpretable region, namely a Relaxed Decision Region (RDR), encompassing instances with coherent concepts in the feature space." [section]: "The activation states of these neurons construct an integrated decision region in the feature space where encompassed instances share the learned concept."

## Foundational Learning

- **Concept**: Piecewise linear activation functions and their effect on feature space partitioning
  - **Why needed here**: Understanding how ReLU and similar activations create linear regions is fundamental to grasping why Configuration distance works
  - **Quick check question**: Why does the paper assume piecewise linear activations rather than using networks with sigmoid or tanh activations?

- **Concept**: Hamming distance and its application to binary vectors
  - **Why needed here**: The Configuration distance is defined as Hamming distance between activation state vectors
  - **Quick check question**: How does Hamming distance differ from Euclidean distance when applied to binary activation vectors?

- **Concept**: Distributed representations and their implications for concept learning
  - **Why needed here**: The paper's approach is based on the principle that concepts are distributed across multiple neurons rather than localized to single neurons
  - **Quick check question**: What evidence does the paper provide that concepts are distributed rather than localized in the network?

## Architecture Onboarding

- **Component map**: Input -> Forward pass to extract feature maps -> Compute Configuration distance -> Build positive/negative sets -> Greedy selection of principal neurons -> Construct RDR -> Visualize results
- **Critical path**: Input -> Forward pass to extract feature maps -> Compute Configuration distance -> Build positive/negative sets -> Greedy selection of principal neurons -> Construct RDR -> Visualize results
- **Design tradeoffs**: 
  - Parameter k (number of neighbors) vs. concept specificity: higher k captures more general concepts but may include noise
  - Parameter t (number of principal neurons) vs. interpretability: fewer neurons make concepts more interpretable but may miss nuance
  - Layer selection vs. concept granularity: earlier layers capture spatial/shape concepts, later layers capture class-specific features
- **Failure signatures**: 
  - RDR includes semantically unrelated instances → likely issues with Configuration distance or principal neuron selection
  - RDR is too small or empty → k or t parameters too restrictive, or feature space too sparse
  - Visualization shows inconsistent concepts → activation states may not reliably encode semantics
- **First 3 experiments**:
  1. Verify Configuration distance correlates with human-perceived similarity by comparing to manual concept annotations
  2. Test sensitivity of RDR to parameter choices (k, t) across different layers and datasets
  3. Compare RDR's concept discovery ability against supervised concept discovery methods using established metrics (purity, entropy)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between t (number of principal neurons) and k (size of the positive set) for constructing Relaxed Decision Regions across different layers and model architectures?
- Basis in paper: [explicit] The paper discusses how t and k affect RDR tightness and general concept capture, recommending ranges but acknowledging variations across layers.
- Why unresolved: The paper only provides general recommendations (k ∈ [5,10], t ∈ [9,15]) without a systematic study of optimal values across different layers, models, or datasets.
- What evidence would resolve it: A comprehensive ablation study showing RDR performance (purity, entropy) across different (t,k) combinations for multiple layers, architectures, and datasets would identify optimal settings.

### Open Question 2
- Question: Why does the Configuration distance metric outperform Euclidean and Cosine distances in capturing learned concepts, and what is the theoretical relationship between these metrics in the context of neural network decision regions?
- Basis in paper: [explicit] The paper demonstrates Configuration distance's superiority through empirical comparisons and conjectures that this is related to the geometry of decision regions in neural networks.
- Why unresolved: While the paper shows empirical evidence, it only conjectures about the relationship between Configuration distance and Cosine similarity without providing theoretical justification or deeper analysis.
- What evidence would resolve it: A formal mathematical analysis connecting the geometry of piecewise linear neural networks to distance metrics, explaining why Configuration distance better captures semantic similarity.

### Open Question 3
- Question: Can the Relaxed Decision Region framework be extended to detect temporal or sequential concepts in recurrent neural networks or transformer architectures?
- Basis in paper: [inferred] The paper focuses on convolutional and feedforward networks, but the concept of activation states and distributed representations could theoretically apply to other architectures.
- Why unresolved: The current framework is designed for static image classification, and its applicability to sequence modeling or temporal data remains unexplored.
- What evidence would resolve it: Experiments applying RDR to recurrent or transformer models on sequential data tasks, demonstrating whether the framework can capture temporal concepts or dependencies.

## Limitations
- The paper's core claims rely heavily on the assumption that activation states reliably encode semantic concepts, but this is not empirically validated across diverse architectures or tasks
- The greedy algorithm's optimality proof depends on specific problem formulations that may not generalize
- The method's performance on highly imbalanced or noisy datasets remains unexplored

## Confidence
- **High**: The RDR construction methodology and its application to identifying unlabeled subclasses (supported by purity/entropy metrics on multiple datasets)
- **Medium**: The Configuration distance metric's effectiveness in capturing semantic similarity (based on correlation with concept coherence, but limited human validation)
- **Low**: The claim that this approach provides deep insights into internal model mechanisms without supervision (largely qualitative assertions without systematic analysis)

## Next Checks
1. **Cross-architecture validation**: Test the method on transformer-based architectures (BERT, ViT) where piecewise linear assumptions may not hold
2. **Human-in-the-loop evaluation**: Conduct user studies comparing RDR-identified concepts against human-labeled semantic clusters
3. **Adversarial robustness test**: Evaluate whether RDRs remain coherent when networks are attacked with adversarial examples targeting the principal neurons