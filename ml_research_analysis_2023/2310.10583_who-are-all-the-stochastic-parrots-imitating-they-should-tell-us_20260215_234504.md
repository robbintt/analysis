---
ver: rpa2
title: Who Are All The Stochastic Parrots Imitating? They Should Tell Us!
arxiv_id: '2310.10583'
source_url: https://arxiv.org/abs/2310.10583
tags:
- text
- citation
- language
- computational
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper identifies a critical problem: large language models\
  \ generate factually incorrect statements, especially for low-resource languages\
  \ where training data is scarce and unreliable. The authors propose a novel solution\u2014\
  building language models that can cite their sources by pointing to specific parts\
  \ of their training data that back up their outputs."
---

# Who Are All The Stochastic Parrots Imitating? They Should Tell Us!

## Quick Facts
- **arXiv ID**: 2310.10583
- **Source URL**: https://arxiv.org/abs/2310.10583
- **Reference count**: 20
- **Primary result**: Proposes building language models that cite their sources to improve trustworthiness, particularly for low-resource languages

## Executive Summary
This paper identifies a critical problem: large language models frequently generate factually incorrect statements, with low-resource languages suffering most due to scarce and unreliable training data. The authors propose a novel solution—building language models that can cite their sources by pointing to specific parts of their training data that back up their outputs. This approach aims to increase trustworthiness by enabling quick verifiability of statements. The paper outlines a roadmap for developing such models, including tasks like simultaneous text and citation generation, subjectivity classification, and citation-text correctness. The authors argue that this approach would benefit various NLP tasks, such as question answering and dialogue generation, by providing users with the ability to verify the factual accuracy of model outputs.

## Method Summary
The paper proposes building language models that generate citations during text generation rather than as post-processing. This involves modifying pretraining to include citation information alongside text, developing simultaneous text and citation generation (STANCE), implementing subjectivity classification to determine when citations are needed, and creating citation-text correctness validation. The approach transforms citation generation from a retrieval problem to a generation problem, potentially reducing computational complexity from O(n*m) to O(n) where n is the number of statements and m is the number of source documents.

## Key Results
- Identifies low-resource languages as particularly vulnerable to factual errors due to poor quality training data
- Proposes STANCE (Simultaneous Text ANd Citation gEneration) to integrate citation generation into the text generation process
- Outlines three key technical challenges: generating appropriate citations, determining when citations are needed, and validating citation correctness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Simultaneous Text and Citation Generation (STANCE) reduces citation retrieval complexity from O(n*m) to O(n)
- Mechanism: By generating citations during text generation rather than as post-processing, the model avoids searching through millions of documents for each generated statement
- Core assumption: The model can learn to associate statements with source documents during training when provided with proper metadata
- Evidence anchors: Abstract states "we propose STANCE: the task of Simultaneous Text ANd Citation gEneration"
- Break condition: If the model cannot learn the association between text spans and sources during training

### Mechanism 2
- Claim: Subjectivity Classification filters which statements require citations, reducing computational overhead by ~30-50%
- Mechanism: By distinguishing between objective facts and subjective statements, the system only generates citations for factual claims
- Core assumption: The distinction between objective and subjective content is clear enough for accurate classification
- Evidence anchors: Abstract states "we propose to utilize the existing subjectivity classification task"
- Break condition: If subjectivity classification models are inaccurate

### Mechanism 3
- Claim: Citation-Text Correctness validation ensures generated citations actually support the associated statements
- Mechanism: Two validation approaches: identifying which part of generated text refers to the citation, and validating that the citation is appropriate
- Core assumption: Existing tasks like text span identification can be adapted for automated citation verification
- Evidence anchors: Abstract states "we need to identify whether the statement appears in the source"
- Break condition: If automated validation cannot reliably distinguish true from false citations

## Foundational Learning

- **Concept: Citation generation as a structured prediction task**
  - Why needed here: Citation generation requires learning to output structured references that can be verified
  - Quick check question: Can you explain why citation generation differs from standard text generation in terms of output constraints?

- **Concept: Metadata-augmented pretraining**
  - Why needed here: The model needs access to source-document relationships during training
  - Quick check question: What type of metadata would be most useful for training a model to generate citations, and why?

- **Concept: Subjectivity detection and its role in conditional generation**
  - Why needed here: Determines when citations are necessary versus when they can be omitted
  - Quick check question: How would you design a system to decide when a generated statement needs a citation versus when it doesn't?

## Architecture Onboarding

- **Component map**: Text generation module → Subjectivity classification module → Conditional citation generation → Citation validation → Output
- **Critical path**: Text generation → Subjectivity classification → Conditional citation generation → Citation validation → Output
- **Design tradeoffs**:
  - Always cite vs. conditional citation: Always citing simplifies implementation but increases noise; conditional citation requires accurate classification but improves readability
  - Real-time vs. batch citation validation: Real-time provides immediate feedback but increases latency; batch processing allows for more thorough validation but delays output
  - Citation granularity: Fine-grained citations (sentence-level) provide better verifiability but increase complexity; coarse-grained citations (paragraph-level) are simpler but less precise
- **Failure signatures**:
  - High citation false positive rate: Indicates issues with either STANCE or citation validation
  - Low citation coverage: Suggests subjectivity classification is too conservative or STANCE is failing
  - Performance degradation: May indicate the citation generation process is adding too much computational overhead
- **First 3 experiments**:
  1. Train a baseline STANCE model on a small dataset with perfect metadata and measure citation accuracy vs. retrieval-based approaches
  2. Evaluate subjectivity classification accuracy on mixed-content generation tasks to determine optimal citation thresholds
  3. Implement a simple citation validation pipeline and measure false positive/negative rates compared to human annotation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective would citation-based language models be in improving factual accuracy for low-resource languages?
- Basis in paper: The paper highlights that low-resource languages suffer from scarce and low-quality training data
- Why unresolved: The effectiveness of citation models specifically for low-resource languages has not been tested
- What evidence would resolve it: Comparative studies showing factual accuracy improvements in low-resource language models with and without citation capabilities

### Open Question 2
- Question: What are the potential privacy risks associated with training language models on data containing personal information?
- Basis in paper: The paper mentions that training data may contain private user information, such as patient records
- Why unresolved: The extent of privacy risks and effective mitigation strategies are not fully explored
- What evidence would resolve it: Case studies or experiments demonstrating privacy breaches and successful mitigation techniques

### Open Question 3
- Question: How can the readability of text be maintained when incorporating citations for every statement?
- Basis in paper: The paper discusses the risk of decreased readability when backing up every statement with citations
- Why unresolved: Balancing the need for citations with maintaining text readability is a challenge that has not been addressed
- What evidence would resolve it: User studies or readability assessments comparing texts with varying levels of citation density

## Limitations

- The approach relies heavily on the availability and quality of metadata-augmented training data, which is not well-specified for low-resource languages
- Computational overhead of real-time citation generation and validation could be substantial, potentially limiting practical deployment
- The paper does not provide evidence that current subjectivity classifiers are accurate enough for conditional citation generation in mixed-content tasks

## Confidence

- **High Confidence**: The identification of the core problem (LLMs generating factually incorrect statements without verifiable sources) is well-established
- **Medium Confidence**: The proposed mechanism of simultaneous text and citation generation (STANCE) is theoretically sound but depends on data quality
- **Medium Confidence**: Subjectivity classification as a gating mechanism is reasonable but lacks validation evidence

## Next Checks

1. **Citation Accuracy Benchmark**: Evaluate a prototype STANCE model on a controlled dataset with perfect metadata to measure citation accuracy rates and compare against traditional retrieval-based citation approaches across multiple language pairs

2. **Subjectivity Classification Validation**: Test the accuracy of state-of-the-art subjectivity classifiers on mixed-content generation tasks to determine optimal citation thresholds that balance factuality verification with output readability

3. **Citation Validation False Positive Analysis**: Implement a citation validation pipeline and measure false positive and negative rates on a diverse set of generated statements, comparing automated validation results against human annotation to establish reliability benchmarks