---
ver: rpa2
title: Learning Dissipative Neural Dynamical Systems
arxiv_id: '2309.16032'
source_url: https://arxiv.org/abs/2309.16032
tags:
- neural
- system
- dynamical
- dissipativity
- dissipative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of learning a dissipative neural
  dynamical system model for an unknown nonlinear system that is known to be dissipative.
  The core method involves first training an unconstrained neural ODE model to approximate
  the system dynamics, then deriving sufficient conditions to perturb the weights
  of the model to enforce dissipativity, and finally adjusting the biases to retain
  the fit of the model to the true system dynamics.
---

# Learning Dissipative Neural Dynamical Systems

## Quick Facts
- **arXiv ID**: 2309.16032
- **Source URL**: https://arxiv.org/abs/2309.16032
- **Reference count**: 32
- **One-line primary result**: Two-stage post-training weight and bias adjustment enables learning a dissipative neural ODE model that approximates an unknown nonlinear system while preserving incremental dissipativity.

## Executive Summary
This paper presents a method for learning dissipative neural dynamical system models from data. The approach addresses the challenge of ensuring that learned models preserve the dissipativity property of the original system, which is crucial for control-theoretic guarantees. The method involves first training an unconstrained neural ODE model to fit the system dynamics, then perturbing the weights to enforce dissipativity conditions, and finally adjusting the biases to recover model accuracy. The approach is demonstrated on a second-order Duffing oscillator, showing that the learned model closely matches ground truth trajectories while guaranteeing incremental dissipativity.

## Method Summary
The method consists of a two-stage approach: First, an unconstrained neural ODE is trained on input-output trajectory data from the unknown system. Second, the weights are perturbed via an optimization problem that enforces incremental dissipativity through a sufficient condition based on slope-restricted activation functions and the S-procedure. Third, the biases are retrained on fresh data while keeping weights fixed to recover model fit. The key insight is that dissipativity constraints depend only on weights, not biases, when formulated in terms of incremental differences, allowing bias adjustment without breaking dissipativity.

## Key Results
- Successfully learned a dissipative neural ODE model for the Duffing oscillator that closely matches ground truth trajectories
- The two-stage approach (weight perturbation then bias adjustment) preserves dissipativity while maintaining model accuracy
- Demonstrated that slope-restricted activation functions enable tractable sufficient conditions for enforcing incremental dissipativity

## Why This Works (Mechanism)

### Mechanism 1
Two-stage weight-then-bias adjustment preserves dissipativity while maintaining model fit. Stage 1 enforces dissipativity via weight perturbation alone, using a sufficient condition (ML ≥ 0) derived from slope-restricted activation functions. Stage 2 retrains biases on fresh data to recover model accuracy, knowing that dissipativity is invariant to bias changes.

### Mechanism 2
Slope-restricted activation functions enable convex sufficient conditions for incremental dissipativity. By assuming activation functions satisfy α ≤ φ'(x) ≤ β, the difference of activations can be bounded in terms of input differences. This allows construction of a block-matrix inequality (ML ≥ 0) that, if satisfied, guarantees the incremental dissipativity condition.

### Mechanism 3
Post-training optimization of weights (not during training) avoids the hardness of imposing matrix inequality constraints in deep learning. Training first yields a baseline model that fits the data. Then a separate optimization problem minimizes the perturbation to enforce dissipativity, sidestepping the need for custom constrained training algorithms.

## Foundational Learning

- **Concept: Incremental dissipativity (Q, S, R)-dissipativity**
  - Why needed here: The paper targets learning a model that preserves this property from an unknown dissipative system. Without understanding this definition, one cannot verify or enforce it in the learned model.
  - Quick check question: For a system with Q = -I, S = cI, R = (r² - c²)I, what control-theoretic property does this represent?

- **Concept: Slope-restricted activation functions**
  - Why needed here: The sufficient condition for dissipativity relies on bounding the difference of activations by a linear function of input differences. This is only possible under slope-restriction.
  - Quick check question: For ReLU, what are α and β in the slope-restriction?

- **Concept: S-procedure for quadratic forms**
  - Why needed here: The proof of the sufficient condition uses the S-procedure to relate the incremental dissipativity inequality to the network's weight structure. Without this, the derivation would not close.
  - Quick check question: If F0 ≥ λF1 for some λ ≥ 0, what implication does the S-procedure give for zT F1z ≥ 0?

## Architecture Onboarding

- **Component map**: Trajectory data generation → Baseline neural ODE training → Weight perturbation optimization (ML ≥ 0) → Bias retraining → Dissipativity validation → Trajectory fit validation
- **Critical path**: 
  1. Generate noisy trajectory data from the unknown system
  2. Train baseline neural ODE (no constraints)
  3. Solve weight perturbation problem to enforce dissipativity
  4. Retrain biases on fresh data
  5. Validate dissipativity and fit
- **Design tradeoffs**:
  - Post-training perturbation vs. constrained training: Simpler to implement but may require larger perturbations if the baseline is far from the feasible set
  - Use of fresh data D2: Avoids overfitting but doubles data requirement
  - Choice of Q, S, R: Affects the difficulty of the weight perturbation problem; some choices may make ML ≥ 0 infeasible
- **Failure signatures**:
  - Large weight perturbation norm → baseline far from feasible dissipative models
  - Bias retraining fails to recover fit → optimization stuck or insufficient capacity
  - Dissipativity test fails → either the sufficient condition is not necessary, or the optimization did not converge to a feasible point
- **First 3 experiments**:
  1. Verify baseline model fit on held-out data from the unknown system
  2. Solve the weight perturbation problem with Q = -I, S = 0, R = I (L2 gain constraint) and check ML feasibility
  3. After bias adjustment, test both dissipativity (incremental QSR inequality) and trajectory fit on a new input

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can compositional approaches for weight adjustments be developed to decrease the computational cost of learning dissipative neural dynamical systems?
- Basis in paper: The paper mentions "compositional approaches for weight adjustments to decrease computational cost" as a future direction in the conclusion.
- Why unresolved: The paper only mentions this as a future direction without providing any details on how to implement such approaches or what the potential benefits would be.
- What evidence would resolve it: A proposed algorithm or framework for compositional weight adjustment, along with simulation results demonstrating reduced computational cost compared to the current approach.

### Open Question 2
- Question: How can the design of Q, S, and R matrices be optimized to strengthen closed-loop dissipativity guarantees for learned neural dynamical models?
- Basis in paper: The paper suggests "design of the Q, S, and R matrices to strengthen closed-loop dissipativity guarantees" as a future direction in the conclusion.
- Why unresolved: The paper does not provide any guidance on how to choose or optimize these matrices beyond the initial choice for the incremental dissipativity property. It is unclear how different choices would impact the closed-loop behavior of the learned model.
- What evidence would resolve it: A method for optimizing the Q, S, and R matrices based on the specific properties of the learned neural dynamical model and the desired closed-loop behavior, along with simulation or experimental results demonstrating improved closed-loop performance.

### Open Question 3
- Question: How can the proposed approach be extended to handle more complex nonlinear systems with higher-dimensional state spaces?
- Basis in paper: The paper only demonstrates the approach on a second-order Duffing oscillator, which is a relatively simple nonlinear system. It is unclear how the approach would scale to more complex systems.
- Why unresolved: The paper does not provide any analysis or discussion on the scalability of the approach to higher-dimensional systems or systems with more complex dynamics.
- What evidence would resolve it: Application of the proposed approach to a more complex nonlinear system, such as a multi-link robotic manipulator or a chemical process with multiple coupled reactions, along with an analysis of the computational cost and performance compared to simpler systems.

## Limitations

- The method relies on a sufficient (not necessary) condition for incremental dissipativity, which may fail to find feasible weight perturbations even when dissipative models exist
- The approach requires double the data (D1 for baseline, D2 for bias adjustment), which may be prohibitive in data-scarce scenarios
- No analysis is provided on how far the baseline model can be from feasible dissipative models before the method fails

## Confidence

- **High Confidence**: The two-stage approach of weight-then-bias adjustment is correctly described and the mathematical framework for enforcing dissipativity via weight perturbation is sound
- **Medium Confidence**: The assumption that dissipativity constraints depend only on weights (not biases) when formulated in terms of incremental differences is reasonable but not rigorously proven for all cases
- **Low Confidence**: The method's robustness to different choices of Q, S, R parameters and its behavior when the baseline model is far from any dissipative model

## Next Checks

1. Test the weight perturbation optimization with multiple different Q, S, R parameter choices to assess sensitivity and identify which configurations make the problem infeasible
2. Measure the distribution of weight perturbation norms across multiple runs with different random seeds to quantify how often the baseline model is far from feasible dissipative models
3. Validate the method on a second dissipative system (e.g., Lorenz system with appropriate parameters) to test generalizability beyond the Duffing oscillator