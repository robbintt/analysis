---
ver: rpa2
title: Benchmarking Algorithms for Federated Domain Generalization
arxiv_id: '2307.04942'
source_url: https://arxiv.org/abs/2307.04942
tags:
- domain
- uni00000087
- federated
- adam
- client
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a comprehensive benchmark for Federated Domain
  Generalization (FDG) that addresses challenges in federated learning such as client
  heterogeneity and train-test dataset heterogeneity. The authors develop a novel
  methodology for splitting datasets across clients to control the degree of heterogeneity
  and evaluate 13 methods across 5 diverse datasets.
---

# Benchmarking Algorithms for Federated Domain Generalization

## Quick Facts
- arXiv ID: 2307.04942
- Source URL: https://arxiv.org/abs/2307.04942
- Reference count: 14
- Key outcome: Comprehensive benchmark reveals FedAvg-ERM is strong baseline, centralized DG methods degrade in FL setting, and realistic datasets show largest performance gaps

## Executive Summary
This paper establishes the first comprehensive benchmark for Federated Domain Generalization (FDG), addressing the critical challenge of training models that generalize across domains in federated learning settings. The authors develop a novel methodology for splitting datasets across clients to control heterogeneity, evaluating 13 methods across 5 diverse datasets. Their benchmark reveals that simple baselines like FedAvg-ERM are surprisingly strong, while centralized domain generalization methods struggle in federated settings. The work identifies significant unresolved challenges, particularly when dealing with large numbers of heterogeneous clients and realistic datasets, and provides recommendations for future research in this emerging field.

## Method Summary
The paper introduces a novel methodology to split any dataset with domain labels across any number of clients using a heterogeneity parameter λ. The algorithm controls the degree of domain-based client heterogeneity through a convex combination between homogeneous clients (λ=1) and domain separation (λ=0). They evaluate 13 methods from three categories (centralized DG, FL, and FDG) across four dimensions: client heterogeneity (λ), number of clients, dataset difficulty (RDG and RFL metrics), and dataset type (synthetic vs. realistic). All methods are tested using held-out domain validation for model selection, with performance measured on test accuracy across different domain splits.

## Key Results
- FedAvg-ERM emerges as a strong baseline that is challenging to beat across datasets
- Centralized DG methods show significant degradation when adapted to federated settings
- FL methods designed for client heterogeneity (FedProx, Scaffold) perform surprisingly well on FDG tasks
- Realistic datasets (IWildCam, Py150) demonstrate the largest performance gaps between methods
- Domain separation scenario (λ=0) remains particularly challenging, limiting information exchange between domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-based client heterogeneity interpolation via λ balances generalization vs. personalization.
- Mechanism: The algorithm splits each domain's samples across clients using λ·nd/C + (1-λ)·indicator terms, smoothly transitioning from homogeneous (λ=1) to domain separation (λ=0).
- Core assumption: Clients can share domain data when λ>0, but λ=0 forces domain separation where each client owns one domain.
- Evidence anchors:
  - [abstract]: "We develop a novel method to split any dataset with domain labels across any number of clients."
  - [section 3.2]: "This is simply a convex combination between homogeneous clients (λ=1) and domain separation (λ=0)."
  - [corpus]: Weak evidence - no direct citation found.
- Break condition: When λ=0 and C≠D, the domain splitting algorithm must assign multiple clients to single domains, which may create imbalanced sample counts.

### Mechanism 2
- Claim: FedAvg-ERM serves as a strong baseline because it ignores heterogeneity, making it robust to domain shifts.
- Mechanism: Simple averaging of client updates without any domain-specific adaptation allows the model to learn general features that transfer across domains.
- Core assumption: Domain shift is handled implicitly by ERM's focus on overall loss minimization rather than domain-specific optimization.
- Evidence anchors:
  - [abstract]: "FedAvg-ERM is a strong baseline, centralized DG methods degrade in the FL setting."
  - [section 4, Remark 4.1]: "Simple FedAvg with an ERM objective is a strong baseline that is challenging to beat across datasets."
  - [corpus]: Weak evidence - no direct citation found.
- Break condition: When domain shifts are severe (high RDG), ignoring heterogeneity may prevent learning domain-specific features needed for good generalization.

### Mechanism 3
- Claim: FL methods designed for client heterogeneity (FedProx, Scaffold) perform surprisingly well on Federated DG because they handle statistical heterogeneity.
- Mechanism: These methods add regularization (proximal term) or variance reduction to stabilize training across heterogeneous clients, which indirectly helps with domain generalization.
- Core assumption: Statistical heterogeneity and domain heterogeneity share similar underlying distribution shift patterns.
- Evidence anchors:
  - [abstract]: "FL methods designed for client heterogeneity perform surprisingly well on FDG tasks."
  - [section 4, Remark 4.3]: "FedProx and Scaffold... perform quite well in the Federated DG setting and even perform the best for IWildCam and Py150."
  - [corpus]: Weak evidence - no direct citation found.
- Break condition: When domain separation is extreme (λ=0), these methods may not provide sufficient domain-specific adaptation.

## Foundational Learning

- Concept: Domain Generalization vs. Federated Learning
  - Why needed here: Understanding the difference between train-test domain shift and client heterogeneity is crucial for designing appropriate methods.
  - Quick check question: What's the key difference between domain generalization and standard federated learning?

- Concept: Convex Combination for Heterogeneity Control
  - Why needed here: The λ parameter controls the interpolation between homogeneous and domain separation settings.
  - Quick check question: How does changing λ from 1 to 0 affect the distribution of samples across clients?

- Concept: Dataset Difficulty Metrics (RDG and RFL)
  - Why needed here: These metrics help evaluate how challenging a dataset is for domain generalization and federated learning respectively.
  - Quick check question: What does a high RDG value indicate about a dataset's difficulty for domain generalization?

## Architecture Onboarding

- Component map: Data splitting -> Client training -> Server aggregation -> Model selection -> Evaluation
- Critical path: Domain splitting algorithm -> Federated training loop -> Held-out domain validation -> Test evaluation
- Design tradeoffs: Homogeneous vs. heterogeneous clients, number of clients vs. domain separation, communication rounds vs. convergence
- Failure signatures: Poor performance on held-out domains, slow convergence, sensitivity to client number
- First 3 experiments:
  1. Run FedAvg-ERM on PACS with varying λ values to establish baseline performance
  2. Test FedProx with different client numbers on IWildCam to measure scalability
  3. Evaluate GroupDRO with in-domain vs. held-out validation to compare early stopping strategies

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the number of clients in federated learning affect the convergence and performance of domain generalization methods?
- Basis in paper: [explicit] "The number of clients C strongly affects on the overall performance. The DG performance drops from 90% to 50% or even 10% when varying C from 1 to 200."
- Why unresolved: The paper shows that increasing the number of clients degrades performance, but does not explain the underlying mechanisms or provide theoretical guarantees on convergence rates.
- What evidence would resolve it: Empirical studies varying client numbers across different datasets and theoretical analysis of convergence bounds in relation to client heterogeneity and communication rounds.

### Open Question 2
- Question: Why does increasing communication frequency sometimes hurt domain generalization performance in federated learning?
- Basis in paper: [explicit] "The number of communications does not monotonically affect DG performance. We observe an interesting implicit regularization phenomena in the FL context: different methods achieve their best performance when the communication rounds is relatively low."
- Why unresolved: The paper observes this phenomenon but does not explain the mechanism behind it or determine whether it's due to implicit regularization, early stopping effects, or other factors.
- What evidence would resolve it: Detailed ablation studies varying communication frequency, theoretical analysis of the relationship between communication rounds and generalization, and investigation of regularization effects.

### Open Question 3
- Question: How can domain generalization methods be adapted to handle the domain separation case (λ = 0) in federated learning?
- Basis in paper: [explicit] "The domain separation scenario (λ = 0) limits the exchange of information between domains... Centralized approaches cannot be adapted to this setting and current methods still struggle under this realistic client heterogeneity setting."
- Why unresolved: The paper identifies this as a significant challenge but doesn't propose solutions, as centralized methods require data from multiple domains which violates FL privacy constraints.
- What evidence would resolve it: Development of new algorithms that can learn domain-invariant representations without requiring cross-domain data exchange, or theoretical analysis of the fundamental limitations in this setting.

### Open Question 4
- Question: What makes realistic datasets (IWildCam, Py150, CivilComments) significantly more challenging for federated domain generalization than synthetic ones (FEMNIST, PACS)?
- Basis in paper: [explicit] "The performance of real-world data significantly degrades as λ decreases... While it is challenging and expensive to run models for IWildCam and Py150, they show the largest differences between methods and demonstrates the real-world challenge of Federated DG."
- Why unresolved: The paper observes performance differences but doesn't analyze the specific characteristics of realistic datasets that make them harder, such as subpopulation shifts, domain complexity, or data distribution properties.
- What evidence would resolve it: Detailed analysis of dataset characteristics, experiments isolating specific factors (e.g., domain complexity, class imbalance, subpopulation shifts), and development of methods specifically designed for realistic dataset challenges.

## Limitations
- The benchmark covers only 5 datasets, which may not capture the full diversity of real-world federated domain generalization scenarios
- Feature- and gradient-based privacy guarantees are not included, limiting the practical applicability of the benchmark
- The effectiveness of simple baselines like FedAvg-ERM raises questions about whether more sophisticated methods are truly needed for practical applications

## Confidence
- **High confidence**: FedAvg-ERM serves as a strong baseline across diverse datasets (supported by consistent experimental results across all five datasets)
- **Medium confidence**: FL methods designed for client heterogeneity generalize well to FDG tasks (supported by performance on IWildCam and Py150, but mechanism remains unclear)
- **Low confidence**: Centralized DG methods will degrade in FL setting for all possible datasets (based on limited dataset coverage and potential dataset-specific factors)

## Next Checks
1. **Replication across additional domains**: Test the benchmark with more datasets including those with continuous domain shifts rather than discrete domains to verify generalizability of findings
2. **Ablation of λ parameter**: Systematically evaluate how different λ values affect method performance to better understand the trade-off between generalization and personalization
3. **Privacy-utility analysis**: Incorporate differential privacy mechanisms into the benchmark to assess the trade-off between privacy guarantees and domain generalization performance