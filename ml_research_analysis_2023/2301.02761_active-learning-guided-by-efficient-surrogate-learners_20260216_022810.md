---
ver: rpa2
title: Active Learning Guided by Efficient Surrogate Learners
arxiv_id: '2301.02761'
source_url: https://arxiv.org/abs/2301.02761
tags:
- learning
- data
- active
- learner
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new active learning algorithm that combines
  exploration and exploitation based on a single Gaussian process surrogate for the
  neural network learner. The surrogate is continuously updated per new label, enabling
  it to simulate the continuous learning behavior of the neural network without requiring
  complete retraining.
---

# Active Learning Guided by Efficient Surrogate Learners

## Quick Facts
- arXiv ID: 2301.02761
- Source URL: https://arxiv.org/abs/2301.02761
- Authors: 
- Reference count: 14
- Primary result: Novel active learning algorithm combining exploration and exploitation using a continuously updated Gaussian process surrogate to efficiently select informative data points for labeling, achieving significant performance gains on benchmark datasets.

## Executive Summary
This paper introduces a new active learning algorithm that combines exploration and exploitation based on a single Gaussian process surrogate for the neural network learner. The surrogate is continuously updated per new label, enabling it to simulate the continuous learning behavior of the neural network without requiring complete retraining. Experiments on four benchmark datasets demonstrate that this approach yields significant performance gains, either rivaling or aligning with the performance of state-of-the-art techniques.

## Method Summary
The method uses a ResNet101 backbone pre-trained on ImageNet, with a Gaussian Process (GP) surrogate to simulate the continuous learning of the neural network. The GP surrogate is updated incrementally with each new label, allowing it to track the neural network's evolving predictions. Two utility functions are defined: one based on predictive variance (u1) for exploration and another based on calibrated class-conditional entropy (u2) for exploitation. The algorithm automatically switches between these utilities based on the neural network's recent performance. A product kernel combining input and output kernels is used to improve the GP surrogate's ability to capture the neural network's behavior.

## Key Results
- Significant performance gains on CIFAR10, CIFAR100, FashionMNIST, and Caltech256 datasets
- Achieves performance on par with or better than state-of-the-art active learning techniques
- Demonstrates improved exploration and exploitation balance compared to existing methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gaussian process surrogate continuously updates per label, enabling efficient simulation of neural network behavior without full retraining.
- Mechanism: A GP surrogate is initialized to match the neural network's predictions at training intervals (I). Between these intervals, the GP is updated incrementally using the difference between the surrogate's prediction and the ground truth for each newly labeled instance. This allows the surrogate to track the evolving behavior of the neural network in near real-time.
- Core assumption: The GP surrogate's predictions remain sufficiently close to the neural network's predictions between training intervals, and the computational cost of updating the GP is much lower than retraining the neural network.
- Evidence anchors:
  - [abstract] "Our proposed model adeptly updates the surrogate learner for every new data instance, enabling it to emulate and capitalize on the continuous learning dynamics of the neural network without necessitating a complete retraining of the principal model for each individual label."
  - [section] "Our GP prior is instantiated based on a combination of Gaussian kernels constructed based on the inputs x and x', and the corresponding outputs of the latest learner f (x) and f (x')."
  - [corpus] Weak evidence. The corpus papers focus on physics-enhanced deep surrogates and protein design, which are different domains and don't directly address the continuous update mechanism described here.
- Break condition: The GP surrogate's predictions diverge significantly from the neural network's predictions, or the computational cost of updating the GP becomes prohibitive for very large datasets.

### Mechanism 2
- Claim: Exploration and exploitation are combined by selecting a utility function (u1 or u2) based on the baseline learner's recent performance.
- Mechanism: Two utility functions are defined: u1, based on predictive variance reduction, is used for exploration (populating sparsely labeled areas), while u2, based on entropy of the neural network's predictions, is used for exploitation (selecting uncertain points). The algorithm automatically switches between u1 and u2 based on comparing the recent average accuracy increase (St) to an initial value (S0). If S0/St < T (a threshold), u1 is selected; otherwise, u2 is selected.
- Core assumption: The baseline learner's accuracy increase is a reliable indicator of its confidence in its predictions. When accuracy increase is low, exploration is more beneficial, and when it is high, exploitation is more effective.
- Evidence anchors:
  - [abstract] "Our approach offers unique advantages in both exploration and exploitation: 1) By adopting well-established Bayesian approaches, it offers computationally efficient and optimal exploration. At each stage, a new data instance is selected to maximize the resulting information gain on the entire dataset; 2) For exploitation, our model can quickly identify the most uncertain data points..."
  - [section] "We combine the strengths of u1 and u2 by automatically selecting one at each stage. At each stage t, u1 or u2 is selected based on comparing the testing accuracy increases St averaged over the time window of [t-100, t] with the initial value S0..."
  - [corpus] Weak evidence. The corpus papers focus on active learning for different domains (software engineering, physics) and don't directly address the specific utility function switching mechanism described here.
- Break condition: The accuracy increase metric (St) becomes unreliable due to noise or non-stationary learning dynamics, or the threshold T is poorly chosen for the specific dataset.

### Mechanism 3
- Claim: The product kernel (combining input and output kernels) improves the GP surrogate's ability to capture the neural network's behavior and avoid smoothing over class boundaries.
- Mechanism: The kernel function is defined as a product of an input kernel (kx) and an output kernel (kf), where kx measures similarity between input features and kf measures similarity between the neural network's output predictions. This product kernel allows the GP surrogate to capture both the input space structure and the learned decision boundaries of the neural network.
- Core assumption: The neural network's output predictions contain useful information about the underlying class structure, and incorporating this information into the GP kernel improves its predictive performance.
- Evidence anchors:
  - [section] "Our GP prior is instantiated based on a combination of Gaussian kernels constructed based on the inputs x and x', and the corresponding outputs of the latest learner f (x) and f (x')."
  - [section] "When we train a separate baseline network at an intermediate stage of 4,500 labels (for the CIFAR10 dataset; see Sec. 4 for details), experiments on 10 different random initializations showed that the mean absolute deviation between ˆf and f on a training set was reduced by 42% (at around 0.012) from the case of using only the standard kernel kx."
  - [corpus] Weak evidence. The corpus papers focus on physics-enhanced deep surrogates and protein design, which are different domains and don't directly address the specific product kernel design described here.
- Break condition: The neural network's output predictions are unreliable or uninformative, or the computational cost of evaluating the product kernel becomes prohibitive for very high-dimensional inputs.

## Foundational Learning

- Concept: Gaussian Processes
  - Why needed here: GPs provide a probabilistic framework for regression and classification, allowing the algorithm to quantify uncertainty and select informative points for labeling. They are also computationally efficient to update incrementally, which is crucial for the continuous learning behavior required in active learning.
  - Quick check question: What is the key difference between a Gaussian process and a traditional parametric regression model, and why is this difference important for active learning?

- Concept: Active Learning
  - Why needed here: Active learning aims to reduce the labeling cost by selecting the most informative data points to label, rather than labeling a random subset. This is particularly important in domains where labeling is expensive or time-consuming, such as medical imaging or natural language processing.
  - Quick check question: What are the two main strategies in active learning (exploration and exploitation), and how do they differ in terms of their goals and methods?

- Concept: Bayesian Inference
  - Why needed here: Bayesian inference provides a principled framework for updating beliefs based on new evidence. In this algorithm, Bayesian inference is used to update the GP surrogate's predictions as new labels are acquired, allowing it to track the evolving behavior of the neural network.
  - Quick check question: How does Bayesian inference differ from frequentist inference, and what are the advantages of using Bayesian inference in active learning?

## Architecture Onboarding

- Component map:
  - Neural Network (f) -> Gaussian Process Surrogate (ˆf) -> Utility Functions (u1, u2) -> Label Selection Module -> Training Interval (I)

- Critical path:
  1. Initialize the neural network and GP surrogate.
  2. Select initial labeled data points randomly.
  3. Train the neural network on the initial labeled data.
  4. Update the GP surrogate to match the neural network's predictions.
  5. For each active learning iteration:
     a. Calculate the utility values for all unlabeled data points.
     b. Select the data point with the highest utility.
     c. Query the label for the selected data point.
     d. Update the GP surrogate with the new label.
     e. If the iteration number is a multiple of I, retrain the neural network and update the GP surrogate to match its predictions.
  6. Repeat step 5 until the labeling budget is exhausted.

- Design tradeoffs:
  - Exploration vs. Exploitation: The algorithm must balance the need to explore sparsely labeled areas (u1) with the need to exploit the neural network's learned knowledge (u2). The threshold T controls this tradeoff.
  - GP Surrogate Complexity: The complexity of the GP surrogate (controlled by the number of basis points K) must be balanced with its approximation accuracy and computational cost.
  - Training Interval (I): The frequency of neural network retraining (I) affects the computational cost and the accuracy of the GP surrogate's approximation.

- Failure signatures:
  - GP Surrogate Divergence: If the GP surrogate's predictions diverge significantly from the neural network's predictions, the active learning performance will degrade.
  - Poor Utility Function Selection: If the threshold T is poorly chosen, the algorithm may select too many exploration or exploitation points, leading to suboptimal performance.
  - Computational Bottlenecks: If the GP surrogate's complexity or the training interval is not properly tuned, the algorithm may become computationally intractable for large datasets.

- First 3 experiments:
  1. Verify the GP surrogate's ability to track the neural network's behavior: Train a simple neural network on a small dataset and compare its predictions to those of a GP surrogate initialized to match its predictions. Update the GP surrogate incrementally with new labels and observe how well it tracks the neural network's evolving behavior.
  2. Test the exploration and exploitation utilities: Generate a synthetic dataset with known class boundaries and sparse labels. Apply the active learning algorithm with different threshold T values and observe how the selected points change as the algorithm switches between exploration (u1) and exploitation (u2).
  3. Evaluate the impact of the product kernel: Train a GP surrogate with and without the product kernel on a small dataset. Compare the surrogate's ability to capture the neural network's decision boundaries and its predictive accuracy on unlabeled data.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the theoretical rigor of the utility function switching mechanism between exploration (u1) and exploitation (u2) be improved beyond the current ad hoc approach?
- Basis in paper: [explicit] The paper mentions that the current approach of selecting between u1 and u2 based on comparing average accuracy increases (S0/St < T) is ad hoc and leaves room for improvement.
- Why unresolved: The paper does not provide a detailed theoretical framework for an improved switching mechanism, and it acknowledges that this is an area for future work.
- What evidence would resolve it: A rigorous mathematical formulation or experimental results demonstrating the effectiveness of an improved switching mechanism would resolve this question.

### Open Question 2
- Question: Can the sequential selection scheme be extended to joint optimization to ensure the optimality of all selected labels at the very early stages of active learning?
- Basis in paper: [explicit] The paper states that the greedy optimization strategy of u1 does not guarantee the joint optimality of all selected labels, particularly at the very early stages of CIFAR10.
- Why unresolved: The paper does not provide a solution or experimental results for extending the sequential selection to joint optimization.
- What evidence would resolve it: A method for extending the sequential selection to joint optimization and experimental results showing improved performance at early stages would resolve this question.

### Open Question 3
- Question: How can the quality of the GP surrogate (f) as a surrogate of the deep learner (f) be theoretically analyzed to understand its impact on active learning performance?
- Basis in paper: [explicit] The paper mentions that a theoretical analysis of the quality of the GP surrogate as a surrogate of the deep learner and its impact on active learning performance would help gain deeper insights into the utility of the algorithm.
- Why unresolved: The paper does not provide a theoretical framework or experimental results for analyzing the quality of the GP surrogate.
- What evidence would resolve it: A theoretical framework for analyzing the quality of the GP surrogate and experimental results demonstrating its impact on active learning performance would resolve this question.

## Limitations

- The automatic switching mechanism between exploration and exploitation utilities is ad hoc and lacks theoretical rigor.
- The algorithm's performance on large-scale datasets and its computational cost are not fully explored.
- The paper does not provide a theoretical analysis of the GP surrogate's quality as a surrogate for the deep learner and its impact on active learning performance.

## Confidence

- Mechanism 1 (GP surrogate tracking): Medium - The continuous update mechanism is plausible but lacks extensive validation across different datasets and neural network architectures.
- Mechanism 2 (Utility function switching): Medium - The automatic switching based on accuracy increase is a reasonable approach, but the choice of threshold T and its sensitivity to dataset characteristics needs further investigation.
- Mechanism 3 (Product kernel): Medium - The product kernel design is innovative, but its superiority over standard kernels needs to be demonstrated on a wider range of datasets and tasks.

## Next Checks

1. Evaluate the algorithm on additional datasets with varying characteristics (e.g., different image sizes, class distributions, and noise levels) to assess its generalizability and robustness.
2. Conduct an ablation study to quantify the individual contributions of the product kernel, the automatic utility function switching, and the sparse GP approximation to the overall performance.
3. Analyze the computational cost of the algorithm on large-scale datasets and explore potential optimizations or approximations to improve scalability.