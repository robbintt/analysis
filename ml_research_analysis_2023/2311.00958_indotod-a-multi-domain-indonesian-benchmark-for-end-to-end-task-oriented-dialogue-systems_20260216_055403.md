---
ver: rpa2
title: 'IndoToD: A Multi-Domain Indonesian Benchmark For End-to-End Task-Oriented
  Dialogue Systems'
arxiv_id: '2311.00958'
source_url: https://arxiv.org/abs/2311.00958
tags:
- indonesian
- english
- datasets
- dialogue
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces IndoToD, an end-to-end multi-domain Indonesian
  Task-Oriented Dialogue (ToD) benchmark covering four domains. The authors extended
  two English ToD datasets to Indonesian using delexicalization and manual translation
  by native speakers.
---

# IndoToD: A Multi-Domain Indonesian Benchmark For End-to-End Task-Oriented Dialogue Systems

## Quick Facts
- arXiv ID: 2311.00958
- Source URL: https://arxiv.org/abs/2311.00958
- Authors: 
- Reference count: 19
- Key outcome: Introduced IndoToD, a multi-domain Indonesian ToD benchmark, and showed bilingual training improves performance on low-resource languages

## Executive Summary
This paper introduces IndoToD, the first end-to-end multi-domain Indonesian Task-Oriented Dialogue (ToD) benchmark covering four domains (restaurant search, POI navigation, calendar scheduling, and weather information). The authors extended two English ToD datasets (CamRest676 and SMD) to Indonesian using delexicalization and manual translation by native speakers. They evaluated four existing ToD frameworks (Sequicity, LABES, MinTL, and GALAXY) on monolingual, cross-lingual, and bilingual settings. The results showed that bilingual training generally improved performance compared to monolingual settings, especially for underrepresented languages like Indonesian, with MinTL outperforming others on cross-lingual and bilingual settings.

## Method Summary
The authors created IndoToD by extending English ToD datasets through a delexicalization process that replaced entities with placeholders, reducing translation workload by 30-34%. Native Indonesian speakers translated the delexicalized templates, which were then lexicalized using a knowledge base to generate Indonesian dialogues. Four ToD frameworks (Sequicity, LABES, MinTL, and GALAXY) were evaluated on monolingual English, monolingual Indonesian, cross-lingual (English training, Indonesian testing), and bilingual (combined training) settings using BLEU, match rate, and success F1 as evaluation metrics.

## Key Results
- Bilingual training consistently improved performance on Indonesian compared to monolingual settings
- MinTL achieved the best performance in cross-lingual and bilingual settings
- mT5-small outperformed T5-small in bilingual Indonesian ToD tasks
- Cross-lingual transfer from English to Indonesian showed limited success, highlighting challenges in zero-shot learning for low-resource languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Delexicalization reduces annotation burden and enables efficient translation.
- Mechanism: By replacing entities with placeholders, the number of unique sentences needing translation is reduced by 30-34%, making the annotation process more efficient while preserving semantic structure.
- Core assumption: The delexicalized templates maintain sufficient context for accurate translation and reconstruction.
- Evidence anchors:
  - [section 2.2] "This pre-processing method is effective because the number of sentences that need to be translated is reduced by 30% and 34% for CamRest676 and SMD, respectively."
  - [section 2.2] "The output of this step is a list of pre-processed, entity-less sentences for each dataset."
- Break condition: If delexicalization removes too much contextual information, making accurate translation impossible or if the reconstruction process fails to correctly restore entities.

### Mechanism 2
- Claim: Bilingual training improves performance on underrepresented languages like Indonesian.
- Mechanism: Combining English and Indonesian datasets during training provides more training data and exposes the model to both languages, leading to better understanding and generation in the target language.
- Core assumption: The model can effectively learn cross-lingual representations and transfer knowledge between languages.
- Evidence anchors:
  - [section 4.2] "The results demonstrate that, in most cases, the bilingual setting yields higher scores than the monolingual... especially in the Indonesian test set."
  - [section 4.2] "The bilingual setting has the advantage of using a larger amount of training data and performing tasks in both languages"
- Break condition: If the model overfits to the high-resource language (English) and fails to improve on the low-resource language (Indonesian).

### Mechanism 3
- Claim: mT5 outperforms T5 for bilingual Indonesian ToD tasks.
- Mechanism: mT5's multilingual training provides better cross-lingual transfer capabilities compared to T5's monolingual training, leading to improved performance on Indonesian tasks.
- Core assumption: mT5's multilingual pre-training provides relevant linguistic knowledge for Indonesian that T5 lacks.
- Evidence anchors:
  - [section 4.2] "We observe that mT5-small is more effective than T5-small in end-to-end ToD tasks."
  - [section 4.2] "The bilingual training is beneficial for training end-to-end ToD, especially to improve the performance on non-English languages."
- Break condition: If the multilingual pre-training of mT5 doesn't provide relevant linguistic features for Indonesian, or if the task-specific fine-tuning overwhelms the multilingual benefits.

## Foundational Learning

- Concept: Delexicalization and lexicalization process
  - Why needed here: Essential for efficiently creating parallel datasets by reducing translation workload while maintaining semantic structure.
  - Quick check question: How does delexicalization help reduce the number of sentences that need translation?

- Concept: Cross-lingual transfer learning
  - Why needed here: Critical for understanding how knowledge from high-resource languages (English) can be applied to low-resource languages (Indonesian).
  - Quick check question: Why did the cross-lingual setting perform poorly despite using English training data?

- Concept: Bilingual model training
  - Why needed here: Key to understanding how combining datasets from multiple languages can improve performance on underrepresented languages.
  - Quick check question: What are the potential benefits and drawbacks of bilingual training for ToD systems?

## Architecture Onboarding

- Component map: Delexicalization -> Translation -> KB Retrieval -> Lexicalization -> Evaluation. ToD frameworks (Sequicity, LABES, MinTL, GALAXY) serve as baselines.

- Critical path: Delexicalization → Translation → KB Retrieval → Lexicalization → Evaluation. This pipeline transforms English datasets into Indonesian while maintaining semantic consistency.

- Design tradeoffs: Using delexicalization reduces annotation cost but may lose some contextual information. Bilingual training improves Indonesian performance but may introduce language interference. Using mT5 vs T5 involves balancing multilingual capabilities against task-specific fine-tuning.

- Failure signatures: Poor BLEU scores indicate generation quality issues. Low match rates suggest entity extraction problems. Low success rates point to task completion failures. Template-like responses indicate overfitting to training patterns.

- First 3 experiments:
  1. Compare monolingual English vs Indonesian performance to establish baseline language gap.
  2. Test cross-lingual transfer from English to Indonesian to measure zero-shot capabilities.
  3. Evaluate bilingual training impact by comparing monolingual vs bilingual settings on Indonesian test set.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would larger-scale training data for Indonesian ToD systems impact performance compared to the current datasets?
- Basis in paper: [inferred] The paper notes that expanding dataset size would "significantly contribute to advancing the Indonesian ToD system" and mentions limitations in only translating 10% of the SMD dataset due to annotator constraints.
- Why unresolved: The paper only evaluated on the current limited dataset size due to practical constraints, without exploring the potential performance gains from larger-scale training data.
- What evidence would resolve it: Conducting experiments with significantly larger Indonesian ToD datasets (e.g., comparable in size to MultiWOZ) and comparing performance metrics to the current smaller-scale experiments.

### Open Question 2
- Question: Would using recently developed larger multilingual language models (e.g., mT5-XXL, BLOOMZ) improve cross-lingual transfer performance compared to mT5-small used in the paper?
- Basis in paper: [inferred] The paper used mT5-small as the multilingual backbone and noted it performed better than T5-small, but larger multilingual models have been released since this research was conducted.
- Why unresolved: The paper only evaluated mT5-small due to computational constraints and availability at the time, not testing whether larger multilingual models would provide additional benefits.
- What evidence would resolve it: Re-running the cross-lingual experiments using larger multilingual models and comparing performance metrics against the mT5-small results.

### Open Question 3
- Question: How would incorporating Indonesian-specific linguistic features (e.g., agglutination, reduplication) into the ToD frameworks affect performance?
- Basis in paper: [inferred] The paper treats Indonesian as a general low-resource language without addressing specific linguistic characteristics that might require specialized handling in ToD systems.
- Why unresolved: The experiments used standard approaches without adapting them to Indonesian's unique morphological and syntactic features.
- What evidence would resolve it: Developing and testing ToD frameworks specifically designed to handle Indonesian linguistic features and comparing their performance to the standard approaches used in the paper.

## Limitations
- Data coverage limited to two domains with limited utterance diversity compared to large-scale English benchmarks
- Translation quality concerns due to lack of reported inter-annotator agreement scores
- Evaluation limited to T5-based architectures, missing other ToD architectural paradigms

## Confidence
- High confidence: Bilingual training improves Indonesian ToD performance across multiple metrics and frameworks
- Medium confidence: mT5 outperforms T5 for bilingual Indonesian ToD tasks based on single comparison
- Low confidence: Delexicalization reduces annotation burden by 30-34% without empirical validation of quality impact

## Next Checks
1. Calculate and report inter-annotator agreement for translation annotations to quantify translation consistency
2. Evaluate additional ToD architectures beyond T5-based models to test bilingual advantage generalization
3. Extend IndoToD to additional domains and conduct systematic performance comparisons across domains