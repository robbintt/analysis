---
ver: rpa2
title: Towards dialogue based, computer aided software requirements elicitation
arxiv_id: '2310.13953'
source_url: https://arxiv.org/abs/2310.13953
tags:
- requirements
- interaction
- customer
- engineer
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a dialogue-based approach for computer-aided
  software requirements elicitation, addressing the limitations of current model extraction
  methods that assume perfect initial understanding and lack feedback mechanisms.
  The core idea is to simulate a real-world collaboration between a requirements engineer
  and a customer, where both parties iteratively refine their understanding through
  dialogue and mutual learning.
---

# Towards dialogue based, computer aided software requirements elicitation

## Quick Facts
- arXiv ID: 2310.13953
- Source URL: https://arxiv.org/abs/2310.13953
- Reference count: 3
- Primary result: Dialogue-based requirements elicitation produces mutual understanding through iterative feedback and concept refinement

## Executive Summary
This paper proposes a novel dialogue-based approach for computer-aided software requirements elicitation that addresses the limitations of current model extraction methods. Traditional approaches assume perfect initial understanding and lack feedback mechanisms, whereas this method simulates real-world collaboration between a requirements engineer and customer through iterative dialogue. The approach enables both parties to learn from each other, with higher cooperation factors leading to more homogeneous interaction results across similar problem scenarios.

## Method Summary
The experiment used four texts about "Akita dog" topic from different sources, extracting nouns using Stanford Core NLP API POS tagging and lemmatization. Three imaginary customers and one virtual requirements engineer were created with initial noun sets. The interaction followed a specific pattern: customers sent all their nouns to the engineer, who returned mutual nouns and sent all their nouns back. Customers created interaction results using a formula incorporating cooperation factors, and the engineer learned by appending these results to their knowledge base. One-hot encoded vectors represented the nouns, and cosine similarity measured understanding alignment.

## Key Results
- Both parties learn from each other throughout interaction, increasing vector similarity
- Higher cooperation factors lead to more homogeneous interaction results across customers
- The interaction blueprint encourages individuality, creativity, and genuine compromise

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dialogue-based requirements elicitation produces mutual understanding through iterative feedback and concept refinement
- Mechanism: The interaction involves alternating steps where the customer shares nouns, the virtual requirements engineer identifies commonalities, proposes additional concepts, and both parties iteratively update their knowledge representations through cooperation factor-based merging
- Core assumption: Both parties are willing to learn from each other and adjust their initial understanding based on feedback
- Evidence anchors:
  - [abstract]: "Both parties learn from each other throughout the interaction, increasing the similarity of their resulting vectors"
  - [section]: "This interaction blueprint encourages individuality, creativity and genuine compromise"
  - [corpus]: Weak evidence - related works focus on automated extraction rather than dialogue-based learning
- Break condition: If either party refuses to accept new concepts (cooperation factor approaches zero) or if the vocabulary sets become disjoint with no overlapping concepts

### Mechanism 2
- Claim: Higher cooperation factors lead to more homogeneous interaction results across customers with similar underlying problem scenarios
- Mechanism: As cooperation factor increases, the interaction result increasingly incorporates the virtual requirements engineer's concepts, leading to convergence of results across different customers facing similar problems
- Core assumption: Similar problem scenarios will have overlapping concepts that can be identified and shared across customers
- Evidence anchors:
  - [abstract]: "A higher cooperation factor leads to more homogeneous interaction results across customers"
  - [section]: "This polarity maps to real world scenarios, in which (even for individual software solutions) best practices and reoccurring concept structures might be beneficial"
  - [corpus]: Weak evidence - related works don't address cooperation factors or result homogeneity
- Break condition: If problem scenarios are fundamentally different (no overlapping concepts) or if cooperation factors vary significantly across customers

### Mechanism 3
- Claim: One-hot encoded noun vectors can effectively represent semantic similarity in requirements engineering contexts
- Mechanism: By creating vocabulary sets from customer and engineer nouns, then encoding as one-hot vectors, cosine similarity can measure how aligned their understanding has become through interaction
- Core assumption: The set of nouns extracted from requirements descriptions adequately captures the semantic content needed for requirements engineering
- Evidence anchors:
  - [section]: "These One Hot Encoded vectors are a mathematical representation of the nouns in this experiment"
  - [abstract]: "Both parties learn from each other throughout the interaction. Their resulting vectors will be more similar to each other after the interaction"
  - [corpus]: Weak evidence - related works focus on NLP techniques but don't validate one-hot encoding for requirements similarity
- Break condition: If noun extraction misses critical semantic relationships or if the vocabulary set becomes too large relative to actual overlap

## Foundational Learning

- Concept: Part-of-Speech (POS) tagging and noun extraction
  - Why needed here: The experiment relies on extracting nouns from natural language requirements descriptions to create vocabulary sets for interaction
  - Quick check question: What POS tag would you look for to identify nouns in a sentence like "The Akita dog is friendly"?

- Concept: Vector similarity measures (cosine similarity)
  - Why needed here: The experiment uses cosine similarity to measure how aligned customer and engineer understanding has become through interaction
  - Quick check question: If two one-hot encoded vectors have 3 matching 1s out of 10 total dimensions, what is their cosine similarity?

- Concept: One-hot encoding
  - Why needed here: The experiment represents nouns as one-hot vectors to enable mathematical comparison of semantic similarity
  - Quick check question: How would you represent the word "dog" as a one-hot vector in a vocabulary of 5 words: ["cat", "dog", "bird", "fish", "horse"]?

## Architecture Onboarding

- Component map:
  - Natural language input processor (Stanford Core NLP for POS tagging) -> Noun extraction and lemmatization module -> Vocabulary set manager -> One-hot encoder -> Similarity calculator -> Interaction manager -> Result generator

- Critical path:
  1. Extract nouns from customer input using POS tagging
  2. Lemmatize and add to vocabulary set
  3. Encode as one-hot vectors
  4. Compute similarity with engineer's vector
  5. Apply cooperation factor to generate interaction result
  6. Update engineer's knowledge base with customer's result

- Design tradeoffs:
  - One-hot encoding vs. word embeddings: One-hot is simpler but loses semantic relationships; word embeddings capture meaning but add complexity
  - Cooperation factor granularity: Continuous vs. discrete levels affects implementation complexity
  - Vocabulary management: Static vs. dynamic vocabulary sets impacts memory usage and computational efficiency

- Failure signatures:
  - Zero overlap between customer and engineer vocabulary sets (cosine similarity = 0)
  - Vocabulary set explosion (thousands of unique nouns with minimal overlap)
  - Cooperation factor edge cases (0 or 1 leading to trivial results)
  - POS tagging errors misclassifying important concepts as non-nouns

- First 3 experiments:
  1. Test noun extraction accuracy with simple sentences and verify POS tagging works as expected
  2. Verify one-hot encoding produces correct vectors for known vocabulary sets
  3. Test similarity calculation with hand-crafted vector pairs of known similarity values

## Open Questions the Paper Calls Out

- How can the proposed interaction blueprint be evaluated and compared across different research approaches, given its emphasis on individuality and creativity? The paper argues that defining a learning problem and corresponding metrics for evaluation might be difficult due to the blueprint's promotion of individuality, creativity, and compromise.

- What potential technologies could be relevant for realizing the proposed interaction blueprint in practice? The paper acknowledges the need for further research and development in this area but does not explore specific technological solutions.

- How can the proposed interaction blueprint be adapted to handle more complex and diverse software requirements scenarios beyond the simplified experiment conducted in the paper? The paper presents a basic experiment to illustrate the concept but does not explore how the blueprint can be extended to handle more complex real-world scenarios.

## Limitations
- The experiment uses a highly simplified setup with only four texts on a single topic (Akita dogs)
- One-hot encoding may miss critical semantic relationships and contextual dependencies
- The cooperation factor mechanism lacks empirical validation on real customer-engineer interactions

## Confidence
- Medium: Core hypothesis that dialogue-based approaches can improve mutual understanding in requirements elicitation
- Low: Practical applicability of specific implementation details (one-hot encoding, noun-only extraction) to real-world requirements engineering scenarios

## Next Checks
1. Test the interaction mechanism with multi-sentence requirements descriptions containing both nouns and verbs to assess if noun-only encoding captures sufficient semantic content
2. Implement the cooperation factor mechanism with real user study participants to validate whether the simulated learning behavior matches actual human collaboration patterns
3. Compare the dialogue-based approach against existing automated requirements extraction methods using benchmark requirements engineering datasets to quantify practical benefits