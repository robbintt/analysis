---
ver: rpa2
title: Multivariate Probabilistic CRPS Learning with an Application to Day-Ahead Electricity
  Prices
arxiv_id: '2303.10019'
source_url: https://arxiv.org/abs/2303.10019
tags:
- online
- learning
- weights
- algorithm
- crps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a novel multivariate probabilistic forecast
  combination method using online learning with smoothing techniques to account for
  dependencies between quantiles and marginals. The approach extends CRPS learning
  to multivariate settings using Bernstein Online Aggregation (BOA) with two smoothing
  methods: dimensionality reduction via basis matrices and penalized smoothing.'
---

# Multivariate Probabilistic CRPS Learning with an Application to Day-Ahead Electricity Prices

## Quick Facts
- arXiv ID: 2303.10019
- Source URL: https://arxiv.org/abs/2303.10019
- Reference count: 16
- Key outcome: Multivariate probabilistic forecast combination using CRPS learning with penalized smoothing and forgetting achieves CRPS of 1.2844 vs 1.2950 for naive combination

## Executive Summary
This paper introduces a novel multivariate probabilistic forecast combination method that extends CRPS learning to account for dependencies between quantiles and marginals through smoothing techniques. The approach uses Bernstein Online Aggregation (BOA) with two smoothing methods: dimensionality reduction via basis matrices and penalized smoothing. Applied to day-ahead electricity price forecasting, the method significantly improves CRPS scores compared to uniform combination, with the best variant achieving a CRPS of 1.2844 versus 1.2950 for naive combination.

## Method Summary
The method combines 8 neural network models' probabilistic forecasts for 24 hours of day-ahead electricity prices using online learning. It minimizes cumulative CRPS through time-varying weights that depend on both quantile and hour, with penalized smoothing to prevent overfitting while maintaining flexibility. The algorithm uses exponential forgetting to adapt to changing market conditions and applies shrinkage operators to regularize weight updates. A fast C++ implementation is provided in the R-package profoc.

## Key Results
- CRPS score of 1.2844 achieved using penalized smoothing with forgetting, compared to 1.2950 for naive uniform combination
- Superior performance to popular weighting schemes like ML-Poly and EWA
- Weights are consistently smoothed across both probabilities and hours, with more smoothing across probabilities
- Bayesian online hyperparameter tuning effectively optimizes smoothing penalties and forgetting rates

## Why This Works (Mechanism)

### Mechanism 1
The algorithm improves forecast accuracy by exploiting the metric structure of electricity prices across both quantiles and time periods. The smoothing procedure via penalized splines and basis matrices reduces estimation variance while preserving flexibility, allowing weights to vary across both probabilities and hours while still borrowing strength from neighboring values. This works because electricity price forecasts exhibit spatial correlation in both temporal and probability dimensions.

### Mechanism 2
Online learning with forgetting and shrinkage operators prevents overfitting to historical data while adapting to changing market conditions. The exponential forgetting factor downweights older observations, while shrinkage operators like fixed share and soft/hard thresholding regularize the weight updates. This is effective because electricity price forecast performance exhibits non-stationarity and structural breaks over time.

### Mechanism 3
The combination of penalized smoothing and online learning achieves superior CRPS scores by optimizing weights pointwise across the distribution. The algorithm minimizes cumulative CRPS across all hours by computing time-varying weights that depend on both the quantile and hour, using penalized smoothing to prevent overfitting while maintaining flexibility. This works because optimal combination weights vary across both quantiles and hours rather than being constant.

## Foundational Learning

- **Continuous Ranked Probability Score (CRPS)**: The paper uses CRPS as the evaluation metric and optimization objective for forecast combination. *Why needed*: CRPS measures the difference between the forecast distribution and the observation, making it ideal for evaluating probabilistic forecasts. *Quick check*: What does CRPS measure and why is it preferred over other scoring rules for probabilistic forecasts?

- **Quantile regression and pinball loss**: The algorithm approximates CRPS using sum over quantile losses and optimizes weights based on pinball scores. *Why needed*: Quantile regression provides a way to estimate the entire conditional distribution of the target variable. *Quick check*: How does the pinball loss relate to quantile regression and why is it used in this context?

- **Online learning and regret minimization**: The algorithm is based on Bernstein Online Aggregation (BOA) which uses cumulative regret to update weights. *Why needed*: Online learning allows the model to adapt to changing data distributions over time. *Quick check*: What is the relationship between regret minimization and convergence to optimal weights in online learning?

## Architecture Onboarding

- **Component map**: Expert forecasts (8 neural network models) -> CRPS calculation module -> weight optimization engine using BOA with smoothing -> combined forecast -> evaluation -> hyperparameter adjustment
- **Critical path**: Expert forecasts → CRPS calculation → weight updates via BOA → combined forecast → evaluation → hyperparameter adjustment
- **Design tradeoffs**: Smoothing methods trade estimation variance for bias, while online learning with forgetting trades adaptation speed for stability. The choice between basis matrices and penalized smoothing affects computational complexity.
- **Failure signatures**: Poor performance may indicate inappropriate smoothing that oversmooths or undersmooths, forgetting rate too high/low for the market regime, or hyperparameter tuning strategy not adapting to structural changes.
- **First 3 experiments**:
  1. Compare performance with/without smoothing on a subset of data to validate the metric structure assumption
  2. Test different forgetting rates on recent data to find optimal adaptation speed
  3. Evaluate the impact of knot placement strategies on forecast accuracy

## Open Questions the Paper Calls Out
- **Open Question 1**: How does the proposed multivariate CRPS learning algorithm perform on non-equidistant time series or spatial data structures, such as those found in meteorological forecasting along the equator?
- **Open Question 2**: What is the optimal balance between the smoothing penalties across quantiles and marginals (λpr vs. λmv) for different types of forecasting problems?
- **Open Question 3**: How can dependency structures between marginals be reintroduced when experts provide joint predictive distributions rather than just quantiles?

## Limitations
- Claims about superior performance rely on a specific market context (German EPEX day-ahead prices) and may not generalize to other electricity markets or domains
- Effectiveness of smoothing methods depends critically on the assumed metric structure of the forecast errors
- Computational complexity of penalized smoothing approach could become prohibitive for higher-dimensional problems

## Confidence
- **High confidence**: The theoretical foundation of CRPS learning and online aggregation is well-established in the forecasting literature
- **Medium confidence**: The specific implementation details for multivariate smoothing and the empirical results on electricity price data are sound but require careful reproduction
- **Low confidence**: The generalizability of the method to other domains and the robustness to different market regimes have not been extensively tested

## Next Checks
1. **Robustness to Market Regimes**: Test the algorithm's performance during periods of high price volatility or market stress to assess whether the smoothing approach maintains its advantage under different market conditions
2. **Cross-Domain Validation**: Apply the method to another sequential decision-making problem with multivariate probabilistic forecasts (e.g., wind power forecasting or financial risk assessment) to evaluate generalizability
3. **Computational Scaling Analysis**: Systematically evaluate how the penalized smoothing method scales with increasing dimensionality and number of experts to establish practical limits of the approach