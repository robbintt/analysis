---
ver: rpa2
title: Retrieving Continuous Time Event Sequences using Neural Temporal Point Processes
  with Learnable Hashing
arxiv_id: '2307.09613'
source_url: https://arxiv.org/abs/2307.09613
tags:
- sequence
- query
- sequences
- retrieval
- corpus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of retrieving relevant continuous-time
  event sequences (CTES) from large datasets, which is crucial for various applications
  like healthcare and social networks. The authors propose NeuroSeqRet, a framework
  that uses neural temporal point processes with learnable hashing for efficient CTES
  retrieval.
---

# Retrieving Continuous Time Event Sequences using Neural Temporal Point Processes with Learnable Hashing

## Quick Facts
- arXiv ID: 2307.09613
- Source URL: https://arxiv.org/abs/2307.09613
- Reference count: 40
- Key outcome: Introduces NeuroSeqRet, a framework using neural temporal point processes with learnable hashing for efficient CTES retrieval, achieving significant improvements over baselines

## Executive Summary
This paper addresses the challenge of retrieving relevant continuous-time event sequences (CTES) from large datasets, a task critical for applications in healthcare, social networks, and other domains. The authors propose NeuroSeqRet, a novel framework that combines neural temporal point processes with learnable hashing to enable efficient and accurate retrieval. The system introduces a trainable unwarping function to align sequences with different temporal distortions and employs MTPP-guided neural relevance models to compute similarity scores. Experiments demonstrate that NeuroSeqRet significantly outperforms several baselines in both retrieval accuracy and efficiency, showcasing the effectiveness of the hashing mechanism.

## Method Summary
NeuroSeqRet is a framework for retrieving relevant CTES from large datasets using neural temporal point processes with learnable hashing. The system first applies a trainable unwarping function to the query sequence to align it with corpus sequences, especially when relevant pairs have different temporal attributes. It then uses MTPP-guided neural relevance models (SelfAttn-NeuroSeqRet and CrossAttn-NeuroSeqRet) to compute relevance scores using either Fisher kernel or KL divergence similarity. The framework includes a hashing network that learns binary embeddings from the relevance scores, suitable for locality-sensitive hashing. This allows efficient retrieval by reducing the number of pairwise comparisons needed. The system is optimized using a pairwise ranking loss to learn the hash codes from data, ensuring they preserve similarity structure for accurate retrieval.

## Key Results
- NeuroSeqRet significantly outperforms several baselines in retrieval accuracy, measured by MAP, NDCG@10, MRR, and NDCG@20
- The hashing mechanism reduces the number of comparisons needed for retrieval, improving efficiency while maintaining accuracy
- The trainable unwarping function enhances compatibility between query and corpus sequences, especially when they have different individual factors
- Four variants of the relevance model are introduced, balancing accuracy and efficiency, with CrossAttn-NeuroSeqRet being more accurate but not directly hashable

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural temporal point processes with learnable hashing can efficiently retrieve relevant CTES by transforming sequence comparison into a similarity search problem.
- Mechanism: The system learns a differentiable embedding space for sequences using neural MTPP models. These embeddings are then compressed into binary hash codes via a trainable hashing network. Locality-sensitive hashing buckets sequences with similar embeddings, reducing the number of pairwise comparisons needed during retrieval.
- Core assumption: The neural embedding captures the true relevance between sequences, and the binary hashing preserves this relevance structure well enough for accurate retrieval.
- Evidence anchors:
  - [abstract] "propose an optimization framework to learn binary sequence embeddings from the relevance scores, suitable for the locality-sensitive hashing"
  - [section 6.2] "we propose to learn the hash codes from data, so that they can be optimized for performance"
  - [corpus] Weak: No direct empirical evidence in the corpus that hash codes alone are sufficient for CTES retrieval.

### Mechanism 2
- Claim: Trainable unwarping functions align sequences that have undergone different temporal distortions, making them comparable for relevance scoring.
- Mechanism: The unwarping function is a monotonic, differentiable transformation applied to the arrival times of a query sequence. This transformation is learned to map observed sequences to a canonical form, undoing individual-specific temporal warping.
- Core assumption: A relevant query-corpus pair may have been generated from the same latent sequence but with different warping transformations; the unwarping function can learn to reverse this effect.
- Evidence anchors:
  - [abstract] "first applies a trainable unwarping function on the query sequence which makes it comparable with corpus sequences, especially when a relevant query-corpus pair has individually different attributes"
  - [section 5.1] "unwarping function ð‘ˆ (Â·) on the arrival times of a query sequence, which enhances its compatibility for comparing it with the corpus sequences"
  - [section 5.2] "such a sequence transformation learns to capture the similarity between two sequences, even if it is not apparent due to different individual factors"

### Mechanism 3
- Claim: Fisher kernel similarity between sequence embeddings provides a natural and effective relevance score for retrieval.
- Mechanism: The Fisher kernel computes the cosine similarity between the gradients of the log-likelihoods of two sequences under the same MTPP model. This captures the similarity of their generative processes, which is hypothesized to correlate with relevance.
- Core assumption: The relevance between two sequences depends on their underlying generative distributions; the Fisher kernel is a good proxy for this similarity.
- Evidence anchors:
  - [abstract] "computes the relevance score between the unwarped query sequence and the corpus sequence using two approaches, namely, (i) a Fisher kernel"
  - [section 5.1] "we compute the relevance score between the unwarped query sequence ð‘ˆ (Hð‘ž) and the corpus sequence Hð‘ as follows: ðœ…ð‘ðœƒ (Hð‘ž, Hð‘) = ð’—ð‘ðœƒ (ð‘ˆ (Hð‘ž)) âŠ¤ð’—ð‘ðœƒ (Hð‘)"
  - [section 5.1] "we choose the Fisher similarity kernel because of two reasons: (i) it is known to be a natural similarity measure that allows us to use the underlying generative model in a discriminative learning task"

## Foundational Learning

- Concept: Temporal Point Processes
  - Why needed here: The retrieval task operates on continuous-time event sequences, which are naturally modeled as marked temporal point processes.
  - Quick check question: What is the difference between an intensity-based and an intensity-free MTPP model?

- Concept: Locality-Sensitive Hashing (LSH)
  - Why needed here: To achieve efficient retrieval, the system must reduce the number of sequence comparisons; LSH enables this by grouping similar sequences into buckets.
  - Quick check question: How does the choice of hash function affect the probability that two similar sequences fall into the same bucket?

- Concept: Fisher Kernel
  - Why needed here: The relevance score between sequences is computed using Fisher kernel similarity, which requires understanding how gradients of log-likelihoods encode distributional similarity.
  - Quick check question: What property of the Fisher information matrix makes the Fisher kernel invariant to reparameterization of the model?

## Architecture Onboarding

- Component map: Input sequence -> Unwarping function -> MTPP embedding -> Relevance scoring -> Hashing network -> LSH bucketing -> Retrieval engine
- Critical path: Query sequence â†’ unwarping â†’ MTPP embedding â†’ relevance score â†’ hash code â†’ bucket â†’ retrieval of candidates
- Design tradeoffs:
  - Accuracy vs efficiency: CrossAttn-NeuroSeqRet is more accurate but not directly hashable; SelfAttn-NeuroSeqRet is hashable but less accurate
  - Hash code quality vs compression: More bits in the hash code improve accuracy but reduce efficiency gains
  - Model complexity vs training time: More complex MTPP models improve accuracy but increase training time
- Failure signatures:
  - Poor retrieval accuracy: Likely due to inadequate hash code quality, incorrect unwarping, or weak MTPP model
  - Slow retrieval: Likely due to hash buckets being too large or inefficient LSH implementation
  - Unstable training: Likely due to poor hyperparameter choices or data issues
- First 3 experiments:
  1. Train SelfAttn-NeuroSeqRet on a small dataset and verify retrieval accuracy on a held-out set
  2. Train the hashing network and evaluate the quality of hash codes by checking bucket uniformity
  3. Compare retrieval accuracy and efficiency of NeuroSeqRet against a baseline using exhaustive comparison

## Open Questions the Paper Calls Out
- How can we design generative models specifically for continuous-time event sequence retrieval, and what would be the optimal architecture for such models?
- How can we provide counter-factual explanations for relevance label predictions in CTES retrieval systems, and what are the key factors that influence these predictions?
- How can we design privacy-preserving retrieval systems for continuous-time event sequences, considering the potential privacy risks associated with user-specific data?

## Limitations
- Lack of ablation studies on the necessity of the trainable unwarping function, making it difficult to assess its true contribution to performance gains
- No theoretical analysis of how well the learned hash codes preserve the similarity structure of the original embedding space
- Limited evaluation on real-world datasets with ground-truth relevance labels, relying heavily on synthetic data

## Confidence
- High confidence: The overall framework design and architectural components are well-specified and technically sound
- Medium confidence: The retrieval accuracy improvements over baselines, though results may be dataset-dependent
- Low confidence: Claims about efficiency gains from hashing, as the reduction factor appears modest in practice

## Next Checks
1. Perform ablation studies removing the unwarping function and/or hashing to quantify their individual contributions to performance
2. Conduct a sensitivity analysis on the number of hash bits to determine the optimal tradeoff between accuracy and efficiency
3. Test the framework on a real-world dataset with ground-truth relevance labels (e.g., healthcare event sequences) to validate practical utility