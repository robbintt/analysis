---
ver: rpa2
title: Pushing the Limits of ChatGPT on NLP Tasks
arxiv_id: '2306.09719'
source_url: https://arxiv.org/abs/2306.09719
tags:
- chatgpt
- arxiv
- task
- strategy
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the problem that ChatGPT performs significantly
  worse than supervised models on many NLP tasks due to token limits, task formalization
  mismatches, and LLM-specific issues like hallucination. The core method idea is
  to use a collection of strategies to push ChatGPT''s limits, including: One-input-multiple-prompts:
  Using multiple prompts per input to fit more demonstrations within the token limit
  Fine-tuned model retrieval: Using fine-tuned models for demonstration retrieval
  to make each token count Proper task formalization: Transforming tasks to formats
  better suited to ChatGPT''s generative nature Reasoning strategies: Employing task-specific
  reasoning strategies Self-verification: Validating ChatGPT''s outputs to address
  hallucination Paraphrase: Paraphrasing inputs to reduce surface word domination
  The primary results show that with these strategies, ChatGPT achieves performances
  comparable to or better than supervised baselines on 17 of 21 datasets across 10
  representative NLP tasks.'
---

# Pushing the Limits of ChatGPT on NLP Tasks

## Quick Facts
- **arXiv ID:** 2306.09719
- **Source URL:** https://arxiv.org/abs/2306.09719
- **Reference count:** 40
- **One-line primary result:** ChatGPT achieves performances comparable to or better than supervised baselines on 17 of 21 datasets across 10 representative NLP tasks

## Executive Summary
This paper addresses the challenge that ChatGPT performs significantly worse than supervised models on many NLP tasks due to token limits, task formalization mismatches, and LLM-specific issues like hallucination. The authors propose a comprehensive collection of strategies to push ChatGPT's limits, including multiple prompts per input, fine-tuned model retrieval, task formalization, reasoning strategies, self-verification, and paraphrase. Their approach enables ChatGPT to achieve state-of-the-art or comparable performance across diverse NLP tasks, significantly narrowing the gap with traditional supervised methods.

## Method Summary
The paper employs a collection of strategies to enhance ChatGPT's performance on NLP tasks. The core approach includes using multiple prompts per input to fit more demonstrations within the token limit, fine-tuned model retrieval for better demonstration quality, proper task formalization to leverage ChatGPT's generative nature, reasoning strategies for complex tasks, self-verification to address hallucination, and paraphrase to reduce surface word domination. These strategies are applied across 21 datasets spanning 10 NLP tasks including question answering, NER, event extraction, and dependency parsing.

## Key Results
- ChatGPT achieves comparable performance to RoBERTa on question answering tasks, with significant improvements in out-of-domain settings
- Span-F1 scores for Named Entity Recognition improve from 68.4 to 88.9 on CoNLL 2003
- Event extraction performance surpasses supervised baselines on ACE 2005
- Part-of-Speech Tagging outperforms RoBERTa on both WSJ and Tweets datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multiple prompts per input compensate for token limit by leveraging more training data
- **Mechanism:** Each input processed with N different prompts, each containing distinct demonstrations retrieved via kNN or random selection, with final prediction determined by voting
- **Core assumption:** Different demonstrations provide complementary information and voting improves accuracy
- **Evidence anchors:** Abstract mentions one-input-multiple-prompts strategy; section describes voting among N predictions
- **Break condition:** If demonstrations are too similar or voting leads to majority error, performance gains disappear

### Mechanism 2
- **Claim:** Fine-tuned model retrieval improves demonstration quality by tailoring representations to specific NLP tasks
- **Mechanism:** Fine-tune supervised model on full training set, then use its token/sentence representations for kNN retrieval to find task-relevant demonstrations
- **Core assumption:** Task-specific representations capture more relevant features than general-purpose embeddings
- **Evidence anchors:** Abstract mentions using fine-tuned models for better demonstration retrieval; section describes bridging gap between ChatGPT and supervised models
- **Break condition:** If fine-tuned model overfits or representations don't generalize well to test inputs, retrieval quality degrades

### Mechanism 3
- **Claim:** Self-verification strategy reduces hallucination by validating ChatGPT's outputs in a second round
- **Mechanism:** After generating predictions, prompt ChatGPT again with original task description and generated output to verify correctness using yes/no responses
- **Core assumption:** ChatGPT can accurately self-assess its predictions when prompted appropriately
- **Evidence anchors:** Abstract mentions self-verification strategy to address hallucination; section describes validating LOC results
- **Break condition:** If ChatGPT's self-assessment is unreliable or overconfident, verification adds no value and may propagate errors

## Foundational Learning

- **Concept:** In-context learning (ICL)
  - **Why needed here:** ChatGPT relies on ICL rather than fine-tuning, so demonstration quality directly impacts performance
  - **Quick check question:** What is the maximum number of tokens ChatGPT can process in a single prompt?

- **Concept:** Token limit constraints
  - **Why needed here:** The 4096 token limit restricts how many demonstrations can be included, necessitating strategies like multiple prompts
  - **Quick check question:** How does splitting input across multiple prompts help bypass the token limit?

- **Concept:** Task formalization mismatch
  - **Why needed here:** Many NLP tasks (NER, parsing) aren't naturally generative, requiring transformation to fit ChatGPT's strengths
  - **Quick check question:** What is the main challenge in adapting sequence labeling tasks to text generation?

## Architecture Onboarding

- **Component map:** Input preprocessor → Prompt generator (with multiple variants) → Demonstration retriever (kNN with FT model) → ChatGPT API calls → Voter/aggregator → Output formatter
- **Critical path:** Prompt generation → API call → Result aggregation
- **Design tradeoffs:** Multiple prompts increase coverage but multiply API costs; FT retrieval improves quality but requires training time
- **Failure signatures:** Low diversity in retrieved demonstrations → voting provides no benefit; FT model overfits → poor generalization in retrieval; self-verification unreliable → no improvement over baseline
- **First 3 experiments:**
  1. Compare random vs kNN vs FT retrieval on a single task to measure demonstration quality impact
  2. Test single prompt vs multiple prompts with voting on the same task to quantify coverage benefits
  3. Evaluate self-verification on tasks with known hallucination rates to measure correction effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What is the theoretical limit of ChatGPT's performance on NLP tasks when using the proposed strategies, and can this limit be quantified?
- **Basis in paper:** [explicit] The paper discusses pushing the limits of ChatGPT's performance on NLP tasks but does not provide a clear quantification of the theoretical limit
- **Why unresolved:** The paper focuses on demonstrating improvements but does not establish a theoretical framework for quantifying the ultimate performance limit
- **What evidence would resolve it:** Experiments comparing ChatGPT's performance with the proposed strategies to theoretical upper bounds derived from human-level performance or the best possible model architecture

### Open Question 2
- **Question:** How do the proposed strategies perform when applied to other large language models (LLMs) beyond ChatGPT?
- **Basis in paper:** [inferred] The paper focuses on ChatGPT but does not explore the generalizability of the strategies to other LLMs
- **Why unresolved:** The strategies might be specific to ChatGPT's architecture and capabilities, and their effectiveness on other models is unknown
- **What evidence would resolve it:** Replicating the experiments with the proposed strategies on other state-of-the-art LLMs and comparing their performance gains

### Open Question 3
- **Question:** What is the impact of the token limit on ChatGPT's performance, and how does it vary across different NLP tasks?
- **Basis in paper:** [explicit] The paper acknowledges the token limit as a constraint but does not provide a detailed analysis of its impact on different tasks
- **Why unresolved:** The token limit is a fundamental constraint, and its impact on performance might vary depending on the complexity and length of the tasks
- **What evidence would resolve it:** Conducting experiments that systematically vary the token limit and measure its impact on performance across a range of NLP tasks

## Limitations

- The paper lacks rigorous validation of the self-verification mechanism's effectiveness in reducing hallucination
- The voting mechanism across multiple prompts is described but lacks empirical comparison showing actual performance improvements
- Weak evidence supports the core mechanisms, with related works primarily discussing general strategies rather than specific implementations

## Confidence

- **High Confidence:** The general observation that ChatGPT faces token limits and task formalization challenges is well-established in the literature
- **Medium Confidence:** The claim that these specific strategies collectively push ChatGPT to match or exceed supervised baselines on 17 of 21 datasets is supported by the paper's results
- **Low Confidence:** The effectiveness of the self-verification strategy to address hallucination lacks rigorous validation

## Next Checks

1. **Verify Self-Verification Reliability:** Conduct a systematic study where ChatGPT's outputs are verified by both its own self-assessment mechanism and human annotators. Measure the agreement rate and false positive/false negative rates of the self-verification process.

2. **Test Voting Mechanism Efficacy:** Run controlled experiments comparing single-prompt versus multiple-prompt approaches with voting on the same tasks and datasets. Measure not just end-to-end accuracy but also demonstration diversity.

3. **Validate Fine-Tuned Retrieval Quality:** Compare demonstration retrieval quality between general-purpose embeddings, kNN with supervised models, and kNN with fine-tuned models. Use human evaluation or quantitative metrics to assess whether fine-tuned model representations consistently produce more relevant demonstrations.