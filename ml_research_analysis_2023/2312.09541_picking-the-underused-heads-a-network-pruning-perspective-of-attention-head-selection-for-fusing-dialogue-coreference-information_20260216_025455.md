---
ver: rpa2
title: 'Picking the Underused Heads: A Network Pruning Perspective of Attention Head
  Selection for Fusing Dialogue Coreference Information'
arxiv_id: '2312.09541'
source_url: https://arxiv.org/abs/2312.09541
tags:
- heads
- attention
- head
- dialogue
- summarization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates attention head selection and manipulation
  in Transformer models for dialogue summarization. The authors rank attention heads
  by importance and find that some heads are underused and can be pruned without significant
  performance loss.
---

# Picking the Underused Heads: A Network Pruning Perspective of Attention Head Selection for Fusing Dialogue Coreference Information

## Quick Facts
- arXiv ID: 2312.09541
- Source URL: https://arxiv.org/abs/2312.09541
- Reference count: 0
- This paper improves dialogue summarization by repurposing underused attention heads with coreference information, achieving 1.6% ROUGE-1, 2.0% ROUGE-2, and 2.1% ROUGE-L improvements.

## Executive Summary
This paper introduces a novel approach to dialogue summarization that leverages network pruning insights to identify and repurpose underused attention heads in Transformer models. By calculating gradient-based importance scores for each attention head, the authors identify redundant heads that can be pruned without performance loss. Instead of removing these heads, they inject coreference information by replacing the attention weights with structure-aware matrices, improving summarization performance. The method provides a computationally efficient alternative to adding extra neural components while maintaining model architecture.

## Method Summary
The method fine-tunes BART-large on the SAMSum dialogue summarization corpus, then calculates attention head importance scores using gradient-based methods. Underused heads (lowest importance scores) are identified per layer, and coreference resolution is performed on dialogue inputs to create structure-aware matrices. These matrices replace the weights of selected underused heads during inference, injecting coreference information without adding parameters. The approach is evaluated using standard ROUGE metrics, showing consistent improvements across different coreference injection strategies.

## Key Results
- BART-large with head manipulation achieves 1.6% ROUGE-1, 2.0% ROUGE-2, and 2.1% ROUGE-L improvements on SAMSum test set
- Masking lowest-ranking heads only causes 0.5% performance drop, confirming they are truly underused
- Higher layers show better performance when manipulated, suggesting different abstraction levels across layers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Some attention heads are underused and can be pruned without harming performance
- Mechanism: Gradient-based importance scoring identifies attention heads that contribute minimally to downstream task loss. These heads can be removed or repurposed with negligible impact on ROUGE metrics
- Core assumption: Multi-head attention contains redundancy, and some heads capture features not essential for the specific downstream task
- Evidence anchors:
  - [abstract] "masking a set of lowest-ranking heads does not affect the model performance on the downstream task, regardless of different training settings"
  - [section] "masking lowest-ranking heads only brings a 0.5% drop" and "the evaluation performance upon masking lowest-ranking (underused) heads even becomes slightly higher"
  - [corpus] Weak evidence - no direct corpus support for this claim
- Break condition: If the downstream task requires diverse attention patterns that all heads contribute to, or if the model is not over-parameterized

### Mechanism 2
- Claim: Underused attention heads can be repurposed to inject linguistic features
- Mechanism: Instead of removing underused heads, their attention weights are replaced with structure-aware matrices (e.g., coreference chains) to enhance feature representation without adding parameters
- Core assumption: The model architecture can accommodate modified attention patterns that encode linguistic structure
- Evidence anchors:
  - [abstract] "inject structure-aware features by manipulating the selected heads" and "the manipulated heads are effectively utilized with higher importance"
  - [section] "we modify it with weights from Ax that present coreference information" and "the previously underused heads weigh much higher"
  - [corpus] Weak evidence - no direct corpus support for this claim
- Break condition: If the linguistic features conflict with existing attention patterns or if the model cannot effectively utilize the injected features

### Mechanism 3
- Claim: Incorporating coreference information improves dialogue summarization
- Mechanism: Coreference resolution provides explicit links between referring expressions, which when injected into attention heads helps track speaker references and improve factual consistency in summaries
- Core assumption: Dialogue summarization benefits from explicit modeling of coreference relationships that are implicit in raw text
- Evidence anchors:
  - [abstract] "dialogue summarization can be improved by incorporating coreference information via head manipulation" with specific ROUGE improvements
  - [section] "enhancing the model with coreference information is beneficial for dialogue summarization to more appropriately context comprehension"
  - [corpus] Strong evidence - the paper shows 1.6% ROUGE-1, 2.0% ROUGE-2, and 2.1% ROUGE-L improvements
- Break condition: If coreference resolution quality is poor or if the summarization task doesn't require tracking references across speakers

## Foundational Learning

- Concept: Multi-head self-attention mechanism
  - Why needed here: Understanding how attention heads work is crucial to grasp why some can be pruned and others repurposed
  - Quick check question: How does multi-head attention allow a model to capture different types of information in parallel?

- Concept: Network pruning and importance scoring
  - Why needed here: The paper's approach relies on identifying and removing unimportant components based on their contribution to task performance
  - Quick check question: What does it mean when an attention head has low gradient-based importance score?

- Concept: Coreference resolution and its role in dialogue
  - Why needed here: The paper injects coreference information into underused heads, so understanding what coreference is and why it matters for dialogue is essential
  - Quick check question: Why is coreference resolution particularly important for dialogue summarization compared to document summarization?

## Architecture Onboarding

- Component map:
  - BART-large encoder with 12 layers, each with 16 attention heads
  - Coreference resolution module that creates structure-aware matrices
  - Gradient-based importance scoring mechanism
  - Head manipulation layer that replaces underused heads with coreference weights
  - Standard BART decoder for sequence generation

- Critical path:
  1. Fine-tune BART-large on SAMSum corpus
  2. Calculate attention head importance scores using gradient-based method
  3. Select underused heads (lowest importance scores)
  4. Perform coreference resolution on dialogue inputs
  5. Create structure-aware matrices (full-link or adjacent-link)
  6. Replace underused heads with coreference matrices during inference
  7. Generate summaries using modified model

- Design tradeoffs:
  - Pruning vs. repurposing: Complete removal of heads saves computation but loses potential feature injection opportunity
  - Full-link vs. adjacent-link matrices: Full-link captures all relationships but may cause gradient vanishing; adjacent-link is more local but preserves stronger weights
  - Layer selection: Higher layers showed better performance when manipulated, suggesting different layers capture different abstraction levels

- Failure signatures:
  - Performance degradation when pruning heads that appear unimportant but are actually capturing task-specific patterns
  - Coreference matrix weights overwhelming original attention patterns if not properly normalized
  - Gradient vanishing when using full-link matrices with large clusters
  - Inconsistent results across different random seeds indicating sensitivity to training initialization

- First 3 experiments:
  1. Implement gradient-based importance scoring and verify that pruning lowest-ranking heads doesn't hurt performance on validation set
  2. Create coreference resolution pipeline and test on sample dialogues to ensure quality
  3. Replace one underused head with coreference matrix and measure impact on a small validation subset before full implementation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the importance-based head selection strategy perform compared to other pruning strategies, such as L1 regularization or random pruning, in terms of model compression and task performance?
- Basis in paper: [explicit] The paper mentions that importance-based head selection is effective for feature injection, but does not compare it to other pruning strategies.
- Why unresolved: The paper focuses on comparing importance-based head selection to probing-based head selection and does not explore other pruning strategies.
- What evidence would resolve it: Experimental results comparing importance-based head selection to other pruning strategies in terms of model compression and task performance.

### Open Question 2
- Question: How does the proposed method perform on other natural language tasks, such as machine translation or text classification, and how does it compare to other feature injection methods?
- Basis in paper: [inferred] The paper mentions that the proposed method is a general and computationally efficient approach that can be extended to other Transformer-based models and natural language tasks.
- Why unresolved: The paper only evaluates the proposed method on dialogue summarization and does not explore its performance on other tasks.
- What evidence would resolve it: Experimental results evaluating the proposed method on other natural language tasks and comparing it to other feature injection methods.

### Open Question 3
- Question: How does the choice of coreference resolution method affect the performance of the proposed method on dialogue summarization?
- Basis in paper: [inferred] The paper mentions that the proposed method incorporates coreference information into the Transformer-based summarizer, but does not explore the impact of different coreference resolution methods.
- Why unresolved: The paper uses a specific coreference resolution method but does not investigate the impact of using different methods.
- What evidence would resolve it: Experimental results comparing the performance of the proposed method using different coreference resolution methods on dialogue summarization.

## Limitations

- Layer-level vs. head-level effects: The paper reports layer-wise importance patterns but doesn't clearly distinguish whether improvements come from specific head positions within layers or from layer-level modifications
- Coreference resolution quality dependency: The reported ROUGE improvements depend entirely on the quality of coreference resolution outputs, which is not rigorously evaluated
- Cross-corpus generalizability: All experiments use SAMSum corpus, limiting confidence in effectiveness across domains with different coreference patterns

## Confidence

- High confidence: The fundamental claim that some attention heads are underused and can be pruned without significant performance loss. This is well-established in network pruning literature and the paper provides direct evidence through controlled experiments showing <0.5% performance drop.
- Medium confidence: The coreference injection mechanism improves dialogue summarization. While ROUGE scores show improvement, the causal relationship between specific coreference patterns and summary quality is not rigorously established through ablation studies or error analysis.
- Low confidence: The claim that "manipulating underused heads is more effective than adding extra neural components." This comparison is mentioned but not empirically validated against alternative approaches like adding explicit coreference modules.

## Next Checks

1. Layer-wise ablation study: Systematically test all 16 heads per layer across all 12 layers to create a complete importance heatmap, verifying that the reported layer-wise patterns hold consistently across multiple random seeds.

2. Coreference quality impact analysis: Measure coreference resolution F1 scores on the dialogue test set and correlate these with summarization ROUGE improvements to quantify how much performance gains depend on coreference quality.

3. Alternative head selection comparison: Compare the gradient-based head selection method against random selection and top-importance head selection to confirm that choosing underused heads specifically provides benefits beyond simply manipulating any heads.