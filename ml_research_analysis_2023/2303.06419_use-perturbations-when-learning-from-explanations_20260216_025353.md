---
ver: rpa2
title: Use Perturbations when Learning from Explanations
arxiv_id: '2303.06419'
source_url: https://arxiv.org/abs/2303.06419
tags:
- features
- ibp-ex
- learning
- dataset
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose to address the problem of shortcut learning
  in neural networks by recasting it as an adversarial robustness problem, where human-provided
  explanations specify a lower-dimensional manifold from which perturbations can be
  drawn. They show that this approach alleviates the need for strong model smoothing
  and parameter regularization required by existing methods.
---

# Use Perturbations when Learning from Explanations

## Quick Facts
- arXiv ID: 2303.06419
- Source URL: https://arxiv.org/abs/2303.06419
- Reference count: 40
- One-line primary result: IBP-Ex+RRR consistently yields significant performance gains, achieving state-of-the-art results on evaluated datasets by recasting MLX as an adversarial robustness problem.

## Executive Summary
This paper proposes a novel approach to address shortcut learning in neural networks by interpreting human-provided explanations as specifications for adversarial perturbations. The authors recast the problem of learning from explanations (MLX) as an adversarial robustness problem, where perturbations are drawn from a lower-dimensional manifold defined by human masks. This approach alleviates the need for strong model smoothing and parameter regularization required by existing methods. The key contribution is IBP-Ex+RRR, which combines Interval Bound Propagation (IBP) with Right for the Right Reasons (RRR) regularization, consistently achieving state-of-the-art performance on both synthetic and real-world benchmarks.

## Method Summary
The method recasts MLX as an adversarial robustness problem where human-provided masks specify a lower-dimensional manifold from which perturbations are drawn. The authors consider three approaches: PGD-Ex (using Projected Gradient Descent), IBP-Ex (using Interval Bound Propagation), and IBP-Ex+RRR (combining IBP-Ex with RRR). The training objective combines task loss with adversarial/robustness loss derived from perturbations within the masked region. The perturbation magnitude (kappa) starts small and gradually increases during training to address cold-start issues. The IBP-Ex+RRR algorithm provides certified robustness guarantees while maintaining good generalization performance.

## Key Results
- IBP-Ex+RRR achieves state-of-the-art results on decoy-MNIST, ISIC skin cancer detection, and plant phenotyping datasets
- The method consistently outperforms existing MLX approaches including ERM, RRR, CDEP, and CoRM
- IBP-Ex+RRR shows significant improvements in worst-group accuracy (Wg Acc) while maintaining high macro-averaged accuracy (Avg Acc)
- The approach scales well as long as the number of irrelevant features remains relatively small

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Human-provided explanations can be interpreted as specifications of a lower-dimensional manifold from which perturbations are drawn, enabling adversarial robustness methods to directly target shortcut features.
- **Mechanism**: The mask identifies irrelevant features; perturbing only these features (via PGD-Ex or IBP-Ex) ensures the model learns invariance to shortcuts without over-regularizing relevant features.
- **Core assumption**: The mask accurately identifies all and only the shortcut features, and perturbations within this low-dimensional space are sufficient to expose and correct shortcut reliance.
- **Evidence anchors**:
  - [abstract] "human explanations specify a lower dimensional manifold from which perturbations can be drawn"
  - [section] "we notice that a model whose prediction is invariant to perturbations drawn from the manifold ought to also be robust to irrelevant features"
  - [corpus] Weak - no direct citations on manifold-based perturbation theory in MLX context.
- **Break condition**: If the mask misses shortcut features or includes relevant ones, robustness training will either fail to correct shortcuts or harm accuracy.

### Mechanism 2
- **Claim**: IBP-Ex provides certified robustness guarantees by computing exact worst-case bounds within the perturbation manifold, avoiding the local attack bias of PGD.
- **Mechanism**: IBP propagates interval bounds through the network to guarantee that the worst-case output over all perturbations in the mask-specified space is considered during training.
- **Core assumption**: The interval bounds computed by IBP tightly over-approximate the true worst-case output within the perturbation space.
- **Evidence anchors**:
  - [abstract] "we use the method set out in the literature on bound propagation"
  - [section] "These upper and lower bounds represent an over-approximate output interval meaning that ∀x∗∈ [x(n)−κ× m(n), x(n) +κ× m(n)] we have f(x∗)∈ [l, u]"
  - [corpus] Weak - no citations showing IBP performance specifically on MLX tasks.
- **Break condition**: If the interval bounds are too loose, the certified guarantees become vacuous and training may not effectively reduce shortcut reliance.

### Mechanism 3
- **Claim**: Combining IBP-Ex with RRR (IBP-Ex+RRR) addresses the cold-start problem in IBP training by using RRR to guide early learning when perturbations are small.
- **Mechanism**: RRR provides gradient-based regularization on irrelevant features, ensuring the model starts learning to ignore shortcuts before IBP's perturbations become large enough to cover the relevant directions.
- **Core assumption**: RRR's gradient regularization effectively dampens dependence on irrelevant features in early training phases.
- **Evidence anchors**:
  - [section] "we saw advantage in combining IBP-Ex with RRR to even greater effect"
  - [section] "when combined, IBP-Ex+RRR has low s1,s 2, which explains the increased performance when they are combined"
  - [corpus] Weak - no citations on combining IBP with gradient regularization for MLX.
- **Break condition**: If RRR's regularization is too strong, it may prevent the model from learning useful features; if too weak, it won't help IBP-Ex overcome cold start.

## Foundational Learning

- **Concept**: Adversarial robustness and projected gradient descent (PGD)
  - **Why needed here**: The paper recasts MLX as a robustness problem where perturbations are drawn from a human-specified manifold. Understanding PGD is essential for implementing PGD-Ex.
  - **Quick check question**: How does PGD find adversarial examples, and why might it be insufficient for MLX tasks with structured perturbations?

- **Concept**: Interval Bound Propagation (IBP)
  - **Why needed here**: IBP is the certified robustness method used in IBP-Ex to provide provable guarantees on worst-case performance over the perturbation manifold.
  - **Quick check question**: What is the key difference between IBP and PGD in terms of the optimization problem they solve, and how does this affect their guarantees?

- **Concept**: Gradient-based saliency and model interpretation
  - **Why needed here**: The paper discusses how existing MLX methods (like RRR) use gradient-based explanations to regularize irrelevant features, and how IBP-Ex+RRR combines this with robustness.
  - **Quick check question**: How do gradient-based saliency methods identify irrelevant features, and what are their limitations compared to perturbation-based methods?

## Architecture Onboarding

- **Component map**: Input preprocessing -> Apply mask -> Perturbation generation (PGD-Ex/IBP-Ex) -> Model training with combined loss -> Evaluation
- **Critical path**:
  1. Load dataset with masks
  2. Initialize model and hyperparameters
  3. For each batch:
     - Forward pass with clean inputs
     - Generate perturbations using mask
     - Forward pass with perturbed inputs
     - Compute combined loss
     - Backward pass and optimization
  4. Evaluate on validation/test sets
- **Design tradeoffs**:
  - PGD-Ex vs IBP-Ex: PGD-Ex is faster but provides no guarantees; IBP-Ex is slower but certified
  - Mask granularity: Finer masks provide more targeted perturbations but increase computational cost
  - Perturbation magnitude (kappa): Larger values increase robustness but may harm clean accuracy
- **Failure signatures**:
  - Model performance drops on relevant features: Mask may be too aggressive or perturbation magnitude too high
  - No improvement in worst-group accuracy: Mask may not capture the true shortcut features
  - Training instability: Perturbation magnitude may be too large for early training phases
- **First 3 experiments**:
  1. Implement PGD-Ex on a simple synthetic dataset with known shortcuts to verify it can learn to ignore masked features
  2. Compare PGD-Ex and IBP-Ex on the same dataset to observe differences in convergence and final performance
  3. Implement IBP-Ex+RRR and test whether it outperforms both individual methods on a dataset with complex shortcuts

## Open Questions the Paper Calls Out
- **Question**: How does the performance of IBP-Ex+RRR compare to other methods when the number of irrelevant features is significantly larger?
- **Question**: How does the performance of IBP-Ex+RRR change when using different model architectures, such as deeper networks or architectures with skip connections?
- **Question**: How does the performance of IBP-Ex+RRR change when using different human-provided explanations, such as explanations at the concept level rather than pixel level?

## Limitations
- The method's effectiveness is contingent on the quality of human-provided masks, which may be noisy or incomplete in real-world applications
- IBP-Ex has higher computational cost compared to PGD-Ex, potentially limiting scalability to larger models and datasets
- The certified guarantees provided by IBP-Ex depend on the tightness of interval bounds, which may become vacuous for complex models

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Recasting MLX as a robustness problem is valid and effective | High |
| IBP-Ex+RRR outperforms existing MLX methods empirically | High |
| IBP-Ex+RRR addresses the cold-start problem effectively | Medium |
| Human masks perfectly capture all shortcut features | Low |

## Next Checks
1. Conduct ablation studies varying mask quality (noisy vs clean) to quantify the sensitivity of IBP-Ex performance to mask accuracy
2. Derive bounds on the gap between IBP's approximate worst-case and the true worst-case to better understand when IBP-Ex's guarantees are meaningful
3. Evaluate IBP-Ex+RRR on larger datasets and deeper architectures to assess computational feasibility and identify potential bottlenecks