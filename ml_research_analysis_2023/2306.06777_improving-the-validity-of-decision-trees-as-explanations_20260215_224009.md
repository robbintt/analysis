---
ver: rpa2
title: Improving the Validity of Decision Trees as Explanations
arxiv_id: '2306.06777'
source_url: https://arxiv.org/abs/2306.06777
tags:
- accuracy
- leaf
- trees
- tree
- cart
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper identifies that decision trees with low-accuracy leaves
  can provide misleading explanations, particularly in high-stakes domains like credit
  scoring and medical diagnosis. To address this, the authors propose training shallow
  trees that maximize the minimum leaf accuracy using mixed-integer programming, ensuring
  that every leaf in the tree has comparable predictive validity.
---

# Improving the Validity of Decision Trees as Explanations

## Quick Facts
- arXiv ID: 2306.06777
- Source URL: https://arxiv.org/abs/2306.06777
- Authors: 
- Reference count: 40
- One-line primary result: Hybrid decision trees with maximum minimum leaf accuracy improve leaf validity by up to 21.16 percentage points while maintaining competitive overall accuracy.

## Executive Summary
Decision trees are widely used for their interpretability in high-stakes domains, but low-accuracy leaves can provide misleading explanations. This paper addresses the problem by training shallow trees that maximize the minimum leaf accuracy across all outcomes, ensuring each leaf provides a valid explanation. The authors formulate this as a mixed-integer programming problem and further enhance the approach by attaching more complex tree-based models (like XGBoost) to each leaf, creating hybrid trees that maintain interpretability while improving accuracy.

## Method Summary
The method uses mixed-integer programming to train shallow decision trees (depth â‰¤ 4) that maximize the minimum leaf accuracy across all leaves. After training the shallow tree, XGBoost models are trained on the subset of data in each leaf, creating hybrid trees that combine interpretability with improved accuracy. The approach includes warmstarting the MIP solver with CART solutions, pruning empty leaves, and merging sibling leaves with the same class. The method is evaluated on 23 tabular classification datasets, comparing against CART and warmstarted OCT models.

## Key Results
- Minimum leaf accuracy improved by up to 21.16 percentage points compared to CART
- Overall classification accuracy remains close to state-of-the-art methods like XGBoost
- The hybrid tree approach maintains interpretability while achieving competitive performance
- Shallow trees (depth 4) were sufficient to match state-of-the-art accuracy when extended with leaf-based models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Maximizing the minimum leaf accuracy ensures every leaf provides a valid explanation
- Mechanism: MIP formulation optimizes minimum leaf accuracy across all leaf nodes using variables `sit` and `rt` to track and enforce minimum accuracy
- Core assumption: All leaves are equally important for providing valid explanations regardless of position or sample count
- Evidence anchors: [abstract] "minimize the maximum misclassification error across each leaf node"; [section 3] "maximize the minimum leaf accuracy"

### Mechanism 2
- Claim: Extending shallow trees with XGBoost models improves accuracy without sacrificing interpretability
- Mechanism: XGBoost models trained on each leaf's data leverage higher accuracy while shallow tree provides global explanations
- Core assumption: Shallow tree correctly partitions data into meaningful regions for XGBoost to improve locally
- Evidence anchors: [abstract] "by extending the leaves with further models"; [section 1] "hybridizing the tree"

### Mechanism 3
- Claim: Warmstarting MIP with CART solution improves optimization efficiency
- Mechanism: CART solution (depth 4, min_samples_leaf 50) provides feasible starting point for MIP solver
- Core assumption: CART solution provides reasonable initial approximation for optimal tree structure
- Evidence anchors: [section 4] "warmstarted using a CART solution...with default scikit-learn parameters"

## Foundational Learning

- Concept: Mixed-Integer Programming (MIP)
  - Why needed here: Formulates and solves optimization problem for trees maximizing minimum leaf accuracy
  - Quick check question: What is the difference between a linear programming problem and a mixed-integer programming problem?

- Concept: Decision Tree Interpretability
  - Why needed here: Understanding relationship between tree depth, leaf accuracy, and interpretability for evaluating proposed method
  - Quick check question: How does increasing the depth of a decision tree affect its interpretability and accuracy?

- Concept: Model Extraction and Explainable AI
  - Why needed here: Decision trees used as interpretable models or for extracting explanations from black-box models
  - Quick check question: What is the difference between a global explanation and a local explanation in explainable AI?

## Architecture Onboarding

- Component map: Data preprocessing -> MIP formulation -> Gurobi solver -> Tree reduction -> XGBoost extension -> Evaluation

- Critical path:
  1. Preprocess data and initialize MIP formulation with CART warmstart
  2. Solve MIP to obtain shallow tree with maximum minimum leaf accuracy
  3. Reduce tree by pruning and merging leaves
  4. Train XGBoost models on each leaf's data
  5. Evaluate hybrid tree's accuracy and minimum leaf accuracy

- Design tradeoffs:
  - Depth vs. interpretability: Shallower trees more interpretable but may have lower accuracy
  - Minimum samples per leaf vs. overfitting: Higher values reduce overfitting but limit complex pattern capture
  - MIP solver time vs. solution quality: Longer optimization may lead to better solutions but increases computational cost

- Failure signatures:
  - Low minimum leaf accuracy: Tree may not capture meaningful data patterns
  - High memory usage: MIP formulation too complex for dataset size
  - Slow optimization: MIP solver struggles to find good solutions within time limit

- First 3 experiments:
  1. Test MIP formulation on small synthetic dataset to verify correctness
  2. Compare warmstarted vs non-warmstarted MIP solver on medium-sized dataset
  3. Evaluate hybrid tree performance on real-world dataset vs CART and XGBoost

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does increasing maximum depth beyond 4 significantly improve minimum leaf accuracy while maintaining interpretability?
- Basis in paper: [explicit] Authors note depth-4 trees suffice to match state-of-the-art accuracy, but depth-5 led to worse results possibly due to exponential memory increases
- Why unresolved: Only tested depths 4 and 5; unclear if trend continues or if optimal depth exists
- What evidence would resolve it: Test range of depths (3-6) and analyze trade-off between minimum leaf accuracy and interpretability

### Open Question 2
- Question: How does proposed method compare to Random Forests or well-tuned XGBoost with same leaf-extension approach?
- Basis in paper: [explicit] Authors compare to CART and OCT but not other tree-based ensemble methods with leaf extensions
- Why unresolved: Unclear if improvements are unique to proposed method or achievable by extending other tree-based models
- What evidence would resolve it: Extend Random Forests and XGBoost with same leaf-based models and compare performance

### Open Question 3
- Question: How sensitive is method's performance to hyperparameters like Nmin and tree depth?
- Basis in paper: [explicit] Authors note Nmin is critical hyperparameter and suggest further testing; show depth 4 outperforms depth 5
- Why unresolved: Only tested limited range of Nmin values (50 and 1) and depths (4 and 5)
- What evidence would resolve it: Comprehensive hyperparameter search over wider range and analyze sensitivity

## Limitations
- Computational complexity of MIP formulations may limit scalability to larger datasets
- Warmstarting approach introduces dependency on CART's initial partitioning quality
- Assumption that all leaves are equally important for explanation validity may not hold for critical outcomes

## Confidence
- Core mechanism (maximizing minimum leaf accuracy via MIP): High
- Computational scalability claims: Medium
- Generalization across diverse datasets: Medium
- Warmstarting benefits quantification: Low

## Next Checks
1. Test MIP formulation on datasets with class imbalance to verify minimum leaf accuracy remains meaningful with few samples per leaf
2. Compare warmstarted MIP approach against random and heuristic-based initialization strategies
3. Evaluate hybrid tree approach on datasets where XGBoost underperforms CART to determine if shallow tree structure limits leaf extension effectiveness