---
ver: rpa2
title: 'MinT: Boosting Generalization in Mathematical Reasoning via Multi-View Fine-Tuning'
arxiv_id: '2307.07951'
source_url: https://arxiv.org/abs/2307.07951
tags:
- datasets
- views
- view
- reasoning
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Mathematical reasoning remains a significant challenge for relatively
  small language models. Many current approaches rely heavily on knowledge distillation
  from powerful but inefficient large language models (LLMs).
---

# MinT: Boosting Generalization in Mathematical Reasoning via Multi-View Fine-Tuning

## Quick Facts
- arXiv ID: 2307.07951
- Source URL: https://arxiv.org/abs/2307.07951
- Authors: Jinze Bai, Shuai Bai, Xun Zhou, Shuo Zhang, Chaojun Xiao, Yunhai Tong, Rong Jin, Tong Zhang
- Reference count: 6
- Primary result: LLaMA-7B model outperforms prior approaches using knowledge distillation on mathematical reasoning tasks

## Executive Summary
This paper introduces Multi-View Fine-Tuning (MinT), a novel approach to enhance mathematical reasoning in language models without relying on knowledge distillation from large language models. The method treats different annotation formats (Chain-of-Thought, Equation, and Tree views) as complementary perspectives and leverages them through view-specific instructions during training. By transforming data across multiple views and incorporating noisy datasets as distinct views, the approach achieves superior generalization performance across various mathematical reasoning datasets while maintaining efficiency.

## Method Summary
The method involves multi-view fine-tuning where mathematical problems are annotated in different formats (CoT, EQN, TREE) and each view is treated as a distinct training perspective. The approach concatenates view-specific instructions to input questions, transforming data across views to enhance reasoning generalization. Key techniques include converting EQN to TREE views through pre-order traversal to simplify grammar, incorporating noisy data as an additional view with specific postfix instructions, and using parameter offloading, optimizer offloading, gradient checkpointing, and gradient accumulation for efficient training on resource-constrained hardware.

## Key Results
- LLaMA-7B with MinT outperforms prior knowledge distillation approaches on mathematical reasoning benchmarks
- Models trained with multi-view fine-tuning show improved generalization across different solution formats
- Incorporating noisy data as a separate view improves robustness without degrading performance on clean views
- TREE view demonstrates best performance due to its simplified grammar structure

## Why This Works (Mechanism)

### Mechanism 1
Multi-view fine-tuning enables models to generalize across different solution formats without explicit instruction tuning. By concatenating view-specific instructions to each input question and training on multiple transformed views, the model learns to flexibly generate solutions in various formats (e.g., CoT, EQN, TREE). The core assumption is that different annotation formats represent complementary perspectives on the same underlying mathematical reasoning, and learning them jointly strengthens the model's overall reasoning ability.

### Mechanism 2
View transformation between EQN and TREE views reduces grammar complexity and enhances learning efficiency. Converting equations into pre-order traversal trees simplifies the solution structure by removing parentheses and aligning with human goal-driven reasoning strategies. The TREE notation captures the essential structure of solutions in a more compact and learnable form than EQN.

### Mechanism 3
Incorporating noisy data as an additional view improves generalization by teaching the model robustness to imperfect solutions. By treating noisy CoT explanations as a separate view and training with specific postfix instructions, the model learns to handle incomplete or incorrect reasoning patterns without degrading performance on clean views. Exposure to noisy data during training helps the model develop resilience to real-world data imperfections.

## Foundational Learning

- Concept: Chain-of-thought reasoning
  - Why needed here: Mathematical problem solving requires step-by-step logical reasoning that CoT explanations provide explicitly.
  - Quick check question: What is the difference between clean and noisy CoT views, and why does the model need to distinguish between them?

- Concept: Mathematical expression parsing
  - Why needed here: Different views use different syntactic structures (e.g., infix EQN vs prefix TREE), and the model must parse and generate all of them.
  - Quick check question: How does the TREE view differ structurally from the EQN view, and what parsing advantages does it offer?

- Concept: Multi-view learning theory
  - Why needed here: The paper's approach builds on multi-view learning principles, treating different annotation formats as complementary views of the same problem space.
  - Quick check question: In what ways does multi-view fine-tuning differ from traditional ensemble methods in machine learning?

## Architecture Onboarding

- Component map: Input processing → View-specific instruction concatenation → LLaMA-7B backbone → View-specific output generation → Loss calculation (only on answer tokens) → Parameter update
- Critical path: Data loading → View transformation → Instruction concatenation → Forward pass → Token prediction → Answer extraction → Loss computation → Backpropagation
- Design tradeoffs: Simpler view instructions vs. more complex instructions; training on all views simultaneously vs. curriculum learning; including noisy data vs. cleaner datasets only
- Failure signatures: Degraded performance on specific views; failure to generate coherent solutions; overfitting to one view at the expense of others
- First 3 experiments:
  1. Train on GSM8k with CoT clean only, evaluate on all three views (CoT, EQN, TREE)
  2. Add EQN view to GSM8k training, evaluate performance changes on each view
  3. Include TREE view in training, measure overall accuracy improvement and cross-view generalization

## Open Questions the Paper Calls Out

1. What is the optimal combination and proportion of data across different views to maximize mathematical reasoning performance?
2. How do multiple views augment each other through shared learning to enhance overall accuracy?
3. Can the multi-view training approach be effectively applied to other domains beyond mathematical reasoning?

## Limitations

- Limited ablation studies to isolate individual contributions of different components
- Data quality concerns with noisy or incomplete solutions in some datasets
- Limited model diversity with experiments primarily on LLaMA-7B and BLOOMz-7B
- Evaluation scope limited to accuracy scores without deeper analysis of reasoning quality

## Confidence

**High confidence** (Mechanistic soundness):
- The core multi-view fine-tuning approach is well-grounded in established machine learning principles
- The view transformation mechanism (concatenating instructions to inputs) is straightforward and implementable

**Medium confidence** (Empirical support):
- Claims about improved generalization across views are supported by experimental results
- Claims about handling noisy data are supported but require more rigorous validation

**Low confidence** (Scope and scalability):
- Claims about the approach being applicable beyond mathematical reasoning to other domains
- Claims about the approach being effective for models substantially different from LLaMA-7B

## Next Checks

1. Conduct ablation studies on view components by training models with individual views (CoT, EQN, TREE) separately, then in pairs, then all three together to measure marginal contributions and interaction effects.

2. Perform systematic noise injection experiments by varying the amount and type of noise in training data to determine thresholds where noisy data becomes detrimental versus beneficial.

3. Apply the same multi-view fine-tuning approach to a non-mathematical reasoning task (e.g., logical reasoning, commonsense reasoning) using datasets with multiple annotation formats to validate cross-domain generalization.