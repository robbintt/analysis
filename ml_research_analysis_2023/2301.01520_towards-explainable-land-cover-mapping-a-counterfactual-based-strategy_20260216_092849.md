---
ver: rpa2
title: 'Towards Explainable Land Cover Mapping: a Counterfactual-based Strategy'
arxiv_id: '2301.01520'
source_url: https://arxiv.org/abs/2301.01520
tags:
- counterfactual
- time
- data
- class
- series
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes a generative adversarial counterfactual approach
  for satellite image time series in a multi-class land cover classification setting.
  The method generates counterfactual explanations that are plausible and differ from
  the original data only in a small and compact temporal segment.
---

# Towards Explainable Land Cover Mapping: a Counterfactual-based Strategy

## Quick Facts
- arXiv ID: 2301.01520
- Source URL: https://arxiv.org/abs/2301.01520
- Authors: 
- Reference count: 21
- Key outcome: Generative adversarial counterfactual approach for satellite image time series achieves 98.6% accuracy and 0.808 NMI on Burkina Faso dataset

## Executive Summary
This paper introduces a generative adversarial counterfactual approach for explaining land cover classification decisions using satellite image time series. The method generates counterfactual explanations that are plausible and differ from the original data only in small, contiguous temporal segments. A key innovation is the ability to discover class relationships without pre-specifying target classes, allowing for the identification of interesting transitions between land cover types. The approach is evaluated on a Sentinel-2 dataset from Burkina Faso, demonstrating its effectiveness in generating realistic counterfactuals that can be used to visualize class relationships.

## Method Summary
The method employs a generative adversarial network architecture consisting of a Noiser (generator), a pre-trained classifier, and a Discriminator. The Noiser generates perturbations that are applied to the original time series to create counterfactuals that change the classifier's prediction. The Discriminator is trained to identify unrealistic counterfactuals, while the Noiser aims to fool it, creating an adversarial game that enforces plausibility. A weighted L1-norm regularization encourages perturbations to be concentrated in a contiguous temporal segment. The approach is trained in two phases: first pre-training the classifier on the original data, then training the Noiser and Discriminator together while keeping the classifier frozen.

## Key Results
- Achieves 98.6% accuracy and 0.808 normalized mutual information using isolation forest anomaly detection
- Generated counterfactuals are realistic and differ from original data only in small, contiguous temporal segments
- Enables discovery of class relationships without pre-specifying target classes for counterfactual explanations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Counterfactual plausibility is enforced through adversarial learning between a generator (Noiser) and a discriminator.
- Mechanism: The Noiser generates perturbations that the discriminator must classify as fake. The Noiser is trained to minimize the log-probability that the discriminator correctly identifies the counterfactual as fake, thus encouraging realistic perturbations.
- Core assumption: The discriminator can effectively distinguish between real and fake time series, and the generator can learn to fool it while preserving class-swapping behavior.
- Evidence anchors:
  - [abstract] "plausibility/realism of the generated counterfactual explanations is enforced via the proposed adversarial learning strategy."
  - [section] "A GAN-inspired architecture, where a discriminator is trained to identify unrealistic counterfactuals while, simultaneously, the Noiser module acts as a generator with the goal to fool the discriminator in a two player game."
  - [corpus] Weak: corpus neighbors focus on land cover mapping but not counterfactual plausibility enforcement.

### Mechanism 2
- Claim: Time-contiguity of perturbations is enforced via weighted L1 regularization with quadratic distance weights.
- Mechanism: A weighted L1-norm penalizes perturbations based on their distance from a dynamically chosen center point in the time series, encouraging perturbations to be concentrated in a contiguous temporal segment.
- Core assumption: Perturbations that are sparse and time-contiguous are more interpretable and align with semantic temporal events in the data.
- Evidence anchors:
  - [abstract] "encouraging the counterfactual to differ from the original sample only in a small and compact temporal segment."
  - [section] "To generate perturbations concentrated around a contiguous time frame we employ a weighted L1-norm penalization, with weights growing quadratically around a central time t(i) chosen independently for each sample."
  - [corpus] Missing: corpus does not provide direct evidence for time-contiguity enforcement.

### Mechanism 3
- Claim: Class transitions are discovered without pre-specifying a target class, allowing for the discovery of relationships between land cover classes.
- Mechanism: The Noiser is trained to minimize the class-swapping loss without enforcing a specific target class, allowing the model to freely change the classifier's prediction to any other class.
- Core assumption: Allowing free class transitions reveals meaningful relationships between classes that are not obvious from the data structure alone.
- Evidence anchors:
  - [abstract] "One of the distinctive features of the proposed approach is the lack of prior assumption on the targeted class for a given counterfactual explanation."
  - [section] "Here we purposely do not enforce the prediction of a predefined target class. Instead, we let the Noiser free to generate a perturbation δ that will change the classi-fier output to any other class different from yi."
  - [corpus] Weak: corpus neighbors focus on classification but not on class relationship discovery through counterfactuals.

## Foundational Learning

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: The counterfactual generation relies on a GAN-like architecture where a generator (Noiser) and discriminator work adversarially to produce realistic counterfactuals.
  - Quick check question: What is the role of the discriminator in the counterfactual generation process?

- Concept: Adversarial training and loss functions
  - Why needed here: The method uses multiple loss functions (class-swapping, generator, weighted L1) that must be balanced during training to achieve the desired counterfactual properties.
  - Quick check question: How do the different loss functions (Lcl, Lgen, Lw-ℓ1) contribute to the counterfactual generation?

- Concept: Time series analysis and temporal patterns
  - Why needed here: The method operates on satellite image time series and enforces temporal contiguity in perturbations, requiring understanding of temporal data characteristics.
  - Quick check question: Why is enforcing temporal contiguity important for interpretability in time series counterfactuals?

## Architecture Onboarding

- Component map: Noiser -> Classifier (frozen) -> Discriminator (adversarial feedback)
- Critical path: Noiser generates perturbations → perturbations applied to original time series → perturbed time series classified → Discriminator evaluates realism
- Design tradeoffs:
  - Class-swapping success rate vs. plausibility: Higher success rates may reduce plausibility if generator loss is reduced
  - Time-contiguity vs. perturbation magnitude: Stronger temporal regularization may limit the ability to change predictions
  - Multiple loss functions require careful balancing of hyperparameters
- Failure signatures:
  - Noiser produces unrealistic counterfactuals: Discriminator becomes too strong or generator loss is ineffective
  - Counterfactuals fail to change predictions: Class-swapping loss is too weak or temporal regularization is too strong
  - Training instability: Imbalanced loss weights or learning rates between Noiser and Discriminator
- First 3 experiments:
  1. Verify Noiser can generate perturbations that change classifier predictions without adversarial training
  2. Test discriminator's ability to distinguish real from fake counterfactuals
  3. Evaluate the effect of weighted L1 regularization on perturbation contiguity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the proposed counterfactual generation approach be extended to multivariate satellite image time series data?
- Basis in paper: [explicit] The paper mentions this as a possible future work, stating "we would extend the framework to the case of multivariate time series satellite data."
- Why unresolved: The current method is designed for univariate NDVI time series. Extending it to multivariate data would require addressing how to generate counterfactuals that modify multiple variables while maintaining plausibility and time-contiguity.
- What evidence would resolve it: A follow-up study demonstrating the extension of the method to multivariate satellite data, showing generated counterfactuals that are realistic, time-contiguous, and effective at changing classifier predictions across multiple variables.

### Open Question 2
- Question: How can the feedback from counterfactual explanations be leveraged to improve the robustness of the land cover classifier against frequent class confusions?
- Basis in paper: [explicit] The paper suggests this as a future direction, stating "leverage the feedback provided by the generated counterfactual samples to improve the robustness of the land cover classifier regarding the most frequent class confusions."
- Why unresolved: While the method generates counterfactuals that reveal class relationships and confusions, it does not directly address how to use this information to improve the classifier's performance on confused classes.
- What evidence would resolve it: An experiment showing that incorporating information from counterfactual explanations (e.g., by augmenting the training data with counterfactuals or modifying the loss function) leads to improved classification accuracy, particularly for classes that are frequently confused.

### Open Question 3
- Question: How sensitive is the proposed method to the choice of hyperparameters, particularly the regularization parameters λgen and λw-ℓ1?
- Basis in paper: [explicit] The paper discusses the impact of these parameters on the success rate of counterfactual generation and the quality of the generated counterfactuals, stating "Increasing these weights implies in further constraining the set of admissible perturbations which, in turn, leads to a smaller rate of successful counterfactual samples."
- Why unresolved: The paper only explores a limited range of hyperparameter values and does not provide a comprehensive sensitivity analysis. The optimal values for these parameters may vary depending on the dataset and the specific application.
- What evidence would resolve it: A systematic study varying λgen and λw-ℓ1 across a wide range of values, analyzing the impact on the success rate of counterfactual generation, the plausibility of the generated counterfactuals, and the time-contiguity of the perturbations.

## Limitations

- The method's effectiveness depends on the delicate training dynamics between the Noiser and Discriminator, which are not fully characterized
- The choice of central time point for weighted L1 regularization is heuristic and may not lead to optimal temporal clustering
- While the method enables free class transitions, there's limited evidence these transitions reveal interpretable class relationships

## Confidence

- Mechanism 1 (Adversarial plausibility enforcement): Medium confidence
- Mechanism 2 (Time-contiguity via weighted L1): Medium confidence
- Mechanism 3 (Class relationship discovery): Low confidence

## Next Checks

1. **Discriminator effectiveness test**: Generate counterfactuals with the Noiser trained with and without the Discriminator component, then compare their realism scores using the isolation forest. This would validate whether adversarial training actually improves plausibility.

2. **Central time point sensitivity**: Run the counterfactual generation with different strategies for selecting t(i) (fixed vs. random vs. learned) and analyze how this affects perturbation contiguity and class transition patterns.

3. **Class relationship validation**: For each generated counterfactual, record both the original and target classes, then construct a transition matrix. Analyze whether certain class transitions occur more frequently and whether these align with known land cover succession patterns in the study area.