---
ver: rpa2
title: Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer
arxiv_id: '2307.04895'
source_url: https://arxiv.org/abs/2307.04895
tags:
- constraint
- sudoku
- transformer
- accuracy
- recurrent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Recurrent Transformer, a novel approach for
  solving constraint satisfaction problems (CSPs) using transformer architectures
  with recurrence. The method extends transformers with recurrence to enable multi-step
  reasoning and applies constraint loss functions to inject logical knowledge.
---

# Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer

## Quick Facts
- arXiv ID: 2307.04895
- Source URL: https://arxiv.org/abs/2307.04895
- Authors: 
- Reference count: 28
- Primary result: Achieves 93.5% accuracy on visual Sudoku, outperforming state-of-the-art approaches

## Executive Summary
This paper introduces Recurrent Transformer, a novel approach for solving constraint satisfaction problems (CSPs) by extending transformer architectures with recurrence mechanisms. The method enables multi-step reasoning through iterative refinement and incorporates constraint loss functions to inject logical knowledge during training. The approach demonstrates state-of-the-art performance on visual Sudoku tasks, achieving 93.5% accuracy while addressing the symbol grounding problem without explicit supervision. The model also shows strong performance on semi-supervised learning scenarios and generalizes to various CSP domains including 16x16 Sudoku, MNIST mapping, shortest path, and nonogram problems.

## Method Summary
The Recurrent Transformer extends standard transformer architectures by adding recurrence mechanisms that enable iterative refinement of solutions. The model processes input through token and positional embeddings, followed by multiple self-attention blocks with recurrence steps that feed output back as input for gradual improvement. Constraint loss functions (LSudoku and Lattention) are incorporated to enforce problem-specific logical rules during training. The architecture supports both textual and visual inputs, with visual inputs being processed through appropriate embedding layers. Training combines cross-entropy loss with constraint losses, and the approach enables semi-supervised learning by leveraging unlabeled data through constraint enforcement.

## Key Results
- Achieves 93.5% accuracy on SATNet visual Sudoku test set, outperforming enhanced SATNet's 64.8% accuracy
- Demonstrates effective symbol grounding without supervised input classification
- Shows semi-supervised learning capabilities with up to 87% accuracy on textual Sudoku using limited labeled data
- Generalizes to 16x16 Sudoku, MNIST mapping, shortest path, and nonogram problems

## Why This Works (Mechanism)

### Mechanism 1: Recurrence Enables Multi-Step Reasoning
The recurrence mechanism allows the Transformer to perform iterative refinement by feeding output back as input over multiple steps. This incremental approach enables solving problems requiring sequential reasoning, similar to how humans solve complex problems gradually. The core assumption is that problem structures can be decomposed into simpler subproblems solvable through iterative updates. Evidence shows improved accuracy with more recurrence steps, though the approach may fail if problems cannot be decomposed sequentially or if early predictions cause overfitting.

### Mechanism 2: Constraint Loss Functions Guide Learning
Incorporating discrete constraint loss functions during training provides explicit feedback about whether predictions satisfy problem rules. This approach helps the model learn underlying logical structures more efficiently without requiring labeled data for every variable. The core assumption is that constraints can be represented as differentiable loss functions providing meaningful gradients. Evidence demonstrates improved sample efficiency and semi-supervised learning capabilities, though constraints that are too complex to encode effectively may limit this approach.

### Mechanism 3: Symbol Grounding Through Joint Learning
The model learns to map visual inputs to symbolic representations without explicit supervision by training on visual puzzles where only final solutions are labeled. This forces the model to simultaneously learn digit recognition and puzzle solving, developing its own symbol grounding. The core assumption is that visual features are sufficiently discriminative for learning the mapping. Evidence shows successful symbol grounding on visual Sudoku tasks, though performance may degrade with ambiguous visual features.

## Foundational Learning

- **Constraint Satisfaction Problems (CSPs)**: Understanding variables, domains, and constraints is essential for designing model architecture and loss functions. Quick check: What are the three components of a CSP, and how do they relate to Sudoku?

- **Transformer Architecture**: Knowledge of self-attention, positional encoding, and layer normalization is crucial since Recurrent Transformer builds on standard transformers. Quick check: How does multi-head attention work in a Transformer, and why is it useful for CSPs?

- **Recurrent Neural Networks**: Understanding recurrence mechanisms is key since this is the primary innovation enabling multi-step reasoning. Quick check: What is the difference between recurrence in this model and in a standard RNN?

## Architecture Onboarding

- **Component map**: Token embedding layer -> Positional embedding layer -> Self-attention blocks -> Recurrence mechanism -> Constraint loss functions -> Output layer

- **Critical path**: 1) Input encoding (token + positional embeddings) 2) Self-attention processing (multiple blocks) 3) Recurrent refinement (multiple steps) 4) Constraint enforcement (via loss functions) 5) Output prediction

- **Design tradeoffs**: More recurrent steps improve accuracy but increase computation time; more attention heads capture different patterns but increase model size; constraint losses improve sample efficiency but may dominate training signal

- **Failure signatures**: Overfitting to training data (high train accuracy, low test accuracy); failure to converge (loss plateaus or oscillates); poor symbol grounding (visual inputs not properly mapped to symbols)

- **First 3 experiments**: 1) Train on textual Sudoku with varying numbers of recurrent steps (R) to find optimal value 2) Test different numbers of attention heads (H) to find optimal value 3) Compare performance with and without constraint losses on a small dataset

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the Recurrent Transformer's performance scale with problem size beyond 16x16 Sudoku?
- **Basis in paper**: [explicit] The paper tested up to 16x16 Sudoku and mentions inability to test harder boards due to lack of larger puzzle generators
- **Why unresolved**: The paper only evaluates on 9x9 and 16x16 Sudoku puzzles, with no analysis of scalability to larger constraint satisfaction problems
- **What evidence would resolve it**: Systematic testing on larger Sudoku variants (25x25, 36x36) and other CSPs like larger nonograms or map coloring problems

### Open Question 2
- **Question**: What is the theoretical limit of recurrence steps for optimal performance?
- **Basis in paper**: [inferred] The paper shows improvements up to 64 recurrences but doesn't establish convergence criteria or diminishing returns
- **Why unresolved**: The paper demonstrates benefits of additional recurrences but doesn't analyze when added recurrence steps stop providing meaningful improvements
- **What evidence would resolve it**: Empirical analysis showing accuracy plateaus vs. recurrence steps, and theoretical bounds on recurrence requirements for different CSP classes

### Open Question 3
- **Question**: How does the constraint loss weighting (α, β) affect semi-supervised learning performance?
- **Basis in paper**: [explicit] The paper mentions using fixed weights [1,0] for constraint losses in semi-supervised experiments but acknowledges this was to reduce hyperparameter tuning effects
- **Why unresolved**: The paper uses fixed constraint loss weights rather than optimizing them for semi-supervised learning scenarios
- **What evidence would resolve it**: Systematic experiments varying α and β in semi-supervised settings to find optimal weight combinations for different amounts of labeled data

## Limitations

- The visual Sudoku experiments rely on specific datasets with particular preprocessing requirements, limiting direct application to other visual CSPs
- Constraint loss functions are specifically designed for Sudoku-like problems and may not transfer directly to other CSP domains without significant modification
- The semi-supervised learning approach assumes unlabeled data can be easily generated or obtained, which may not hold for many real-world CSP applications

## Confidence

**High Confidence Claims:**
- Recurrence mechanism improves solving accuracy on textual Sudoku (based on extensive ablation studies)
- Constraint losses contribute to improved performance on visual Sudoku (demonstrated through controlled experiments)
- Model achieves state-of-the-art results on SATNet visual Sudoku benchmark (93.5% accuracy)

**Medium Confidence Claims:**
- Symbol grounding effectiveness without explicit supervision (based on visual Sudoku results, but limited to digit recognition tasks)
- Semi-supervised learning benefits (shown on limited datasets, generalizability uncertain)
- Cross-domain applicability to nonogram and shortest path problems (fewer experiments, less extensive validation)

**Low Confidence Claims:**
- Generalizability to arbitrary CSP domains (only tested on 4 specific problem types)
- Scalability to larger CSP instances (16x16 Sudoku results promising but limited)
- Real-world applicability without significant adaptation

## Next Checks

1. **Cross-Domain Transfer Test**: Apply the Recurrent Transformer architecture to a fundamentally different CSP domain (e.g., scheduling or graph coloring problems) to validate general applicability. Measure performance degradation compared to domain-specific baselines.

2. **Scaling Experiment**: Test the model on larger Sudoku variants (e.g., 25x25 or 36x36) to evaluate scalability claims and identify computational bottlenecks in the recurrence mechanism.

3. **Constraint Loss Generalization**: Design and implement constraint loss functions for a non-Sudoku CSP (e.g., shortest path with additional constraints) to test the framework's flexibility and identify limitations in encoding complex logical relationships.