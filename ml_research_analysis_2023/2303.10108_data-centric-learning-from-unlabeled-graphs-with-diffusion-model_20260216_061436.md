---
ver: rpa2
title: Data-Centric Learning from Unlabeled Graphs with Diffusion Model
arxiv_id: '2303.10108'
source_url: https://arxiv.org/abs/2303.10108
tags:
- graphs
- graph
- data
- unlabeled
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a data-centric approach to learning from unlabeled
  graphs for property prediction tasks. The core idea is to use a diffusion model
  to capture the data distribution of unlabeled graphs, and then generate task-specific
  labeled examples by guiding the reverse process with task-related optimization objectives.
---

# Data-Centric Learning from Unlabeled Graphs with Diffusion Model

## Quick Facts
- arXiv ID: 2303.10108
- Source URL: https://arxiv.org/abs/2303.10108
- Reference count: 25
- Primary result: Reduces mean absolute error by 13.4% and 10.2% on molecule and polymer graph regression tasks respectively

## Executive Summary
This paper proposes a data-centric approach for learning from unlabeled graphs in property prediction tasks. The method uses a diffusion model to capture the data distribution of unlabeled graphs, then generates task-specific labeled examples by guiding the reverse diffusion process with task-related optimization objectives. Unlike traditional self-supervised approaches, this method directly operates on graph structures rather than task-specific objectives. The framework is evaluated on 15 graph property prediction tasks from chemistry, material science, and biology, demonstrating significant improvements over existing methods.

## Method Summary
The approach trains a diffusion model on unlabeled graphs to learn their data distribution using stochastic differential equations. For each labeled graph in a target task, the model generates augmented graphs through a reverse denoising process guided by two optimization objectives: preserving the original label and maximizing diversity from the original graph. The prediction model is then trained on the augmented dataset, with an iterative training loop that progressively improves both the model and the quality of augmented data. The framework uses graph neural networks to encode graph structures and learn the score function for the diffusion process.

## Key Results
- Reduces mean absolute error by 13.4% on molecule graph regression tasks compared to best baseline
- Reduces mean absolute error by 10.2% on polymer graph regression tasks compared to best baseline
- Demonstrates consistent improvement across 15 graph property prediction tasks from chemistry, material science, and biology

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Diffusion models capture graph data distribution more effectively than self-supervised tasks because they operate directly on graph structures
- Core assumption: Graph space structure is sufficiently smooth under diffusion process for gradient-based generation
- Evidence anchors: [abstract] mentions diffusion model utilization; [section] describes gradual noise addition and score function learning
- Break condition: Discrete structures not smoothly connected would cause generation failure

### Mechanism 2
- Claim: Two task-related optimization objectives ensure minimal sufficient knowledge transfer
- Core assumption: Mutual information bounds effectively control diversity-task relevance tradeoff
- Evidence anchors: [section] describes objectives minimizing mutual information between augmented and original graphs while maximizing label preservation probability
- Break condition: Small labeled datasets or highly specific tasks may cause bounds to be ineffective

### Mechanism 3
- Claim: Iterative training creates virtuous cycle improving both model and augmentation quality
- Core assumption: Prediction model performance on augmented data reliably indicates augmentation quality
- Evidence anchors: [section] describes mutual enhancement between data augmentation and predictor training
- Break condition: Quick overfitting to augmented data reinforces biases rather than learning generalizable patterns

## Foundational Learning

- Concept: Stochastic differential equations (SDEs) and score matching
  - Why needed here: Diffusion model is based on SDEs describing gradual noise addition process, score matching learns reverse denoising
  - Quick check question: Can you explain the difference between forward diffusion SDE and reverse-time SDE in mathematical form and purpose?

- Concept: Mutual information and its variational bounds
  - Why needed here: Optimization objectives use mutual information to control diversity-task relevance tradeoff
  - Quick check question: How does InfoNCE upper bound for mutual information work, and why suitable for this application?

- Concept: Graph neural networks and architectural choices
  - Why needed here: Prediction model uses GNNs to encode graph structures; diffusion model uses GNNs to learn score function
  - Quick check question: What are key differences between dense adjacency matrices versus sparse edge indices in GNNs, and how does this affect diffusion model implementation?

## Architecture Onboarding

- Component map: Diffusion model -> Score function (GNN) -> Task-related objectives (I1, I2) -> Prediction model (GNN) -> Augmentation pipeline

- Critical path: 1. Train diffusion model on unlabeled graphs; 2. For each labeled graph: a) Perturb with D steps; b) Apply task objectives to guide reverse process; c) Generate augmented graph; 3. Train prediction model on augmented dataset; 4. Repeat until convergence

- Design tradeoffs:
  - Perturbation steps D vs. augmented graph quality: More steps increase diversity but may compromise task relevance preservation
  - Number of negative samples M in InfoNCE: More samples improve mutual information bound but increase computational cost
  - Choice of GNN architecture: Deeper networks capture complex patterns but are harder to train and more prone to overfitting

- Failure signatures:
  - Chemically invalid or structurally implausible augmented graphs
  - Prediction performance plateaus or degrades after several iterations
  - High variance in results across runs indicating augmentation process instability

- First 3 experiments:
  1. Train diffusion model on QM9 dataset and visualize generated graphs at different noise levels to verify data distribution capture
  2. Implement task-related objectives and test on simple molecule classification task with small labeled dataset to verify guidance of generation process
  3. Run full iterative augmentation pipeline on single regression task and monitor prediction performance and diversity of augmented graphs over iterations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does performance vary with size and complexity of unlabeled graph dataset used to train diffusion model?
- Basis in paper: Authors note replacing QM9 with ZINC did not improve performance, suggesting diffusion model capacity constraints with larger, complex graphs
- Why unresolved: Paper lacks systematic experiments varying unlabeled dataset characteristics
- What evidence would resolve it: Experiments training with varying sizes and complexities of unlabeled graph datasets, measuring downstream task performance

### Open Question 2
- Question: How does performance compare to semi-supervised learning methods using consistency regularization (FixMatch, Mean Teacher)?
- Basis in paper: Authors mention semi-supervised methods like self-training and InfoGraph as baselines but don't include consistency regularization methods
- Why unresolved: Paper doesn't compare to consistency regularization approaches
- What evidence would resolve it: Experiments comparing DCT performance to FixMatch or Mean Teacher on same graph property prediction tasks

### Open Question 3
- Question: How does choice of graph neural network architecture impact DCT's performance?
- Basis in paper: Authors note DCT allows flexible GNN architectures unlike pre-training methods, but only use GIN in experiments
- Why unresolved: Paper doesn't investigate different GNN architectures with DCT
- What evidence would resolve it: Experiments applying DCT with different GNN architectures (GCN, GAT) and comparing performance on same tasks

## Limitations

- Effectiveness depends on smoothness of graph space under diffusion process, which may not hold for discrete molecular structures
- Mutual information bounds may become loose when labeled dataset is small or task is highly specific
- Iterative training process could reinforce biases if prediction model overfits to augmented data too quickly

## Confidence

- High confidence: Empirical results showing 13.4% and 10.2% MAE reduction on molecule and polymer tasks respectively are well-supported by experimental setup and comparison to strong baselines
- Medium confidence: Theoretical claims about minimal sufficient knowledge transfer through optimization objectives are plausible but depend on mutual information bound tightness in practice
- Low confidence: Generalizability to highly specific tasks or very small labeled datasets remains uncertain; computational efficiency compared to simpler augmentation techniques needs more evaluation

## Next Checks

1. Generate graphs at multiple noise levels from trained diffusion model and evaluate chemical validity using molecular property prediction models; compare generated graphs' properties to real molecules to verify effective data distribution capture

2. Conduct experiments varying number of negative samples M in InfoNCE bound to measure how bound tightness affects augmentation quality and downstream prediction performance; validate whether mutual information formulation provides meaningful diversity-task relevance tradeoff control

3. Track prediction performance and augmented graph diversity metrics across multiple iterations of training loop; identify plateau or degradation points and analyze whether due to overfitting to augmented data or diminishing returns from augmentation process