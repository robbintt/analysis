---
ver: rpa2
title: 'Towards Large-scale Building Attribute Mapping using Crowdsourced Images:
  Scene Text Recognition on Flickr and Problems to be Solved'
arxiv_id: '2309.08042'
source_url: https://arxiv.org/abs/2309.08042
tags:
- images
- building
- flickr
- text
- texts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of mapping building attributes
  using crowdsourced street-view images, specifically focusing on recognizing text
  on building facades in Flickr images. The authors create a Berlin Flickr dataset
  and apply pre-trained Scene Text Recognition (STR) models to detect and recognize
  text.
---

# Towards Large-scale Building Attribute Mapping using Crowdsourced Images: Scene Text Recognition on Flickr and Problems to be Solved

## Quick Facts
- arXiv ID: 2309.08042
- Source URL: https://arxiv.org/abs/2309.08042
- Reference count: 13
- One-line primary result: Scene text recognition on crowdsourced street-view images shows promise for building attribute mapping but faces challenges with text visibility, matching accuracy, and data representativeness.

## Executive Summary
This paper explores the use of crowdsourced street-view images from Flickr for large-scale building attribute mapping by recognizing text on building facades. The authors create a Berlin Flickr dataset and apply pre-trained Scene Text Recognition (STR) models to detect and recognize text, finding high accuracy when text is clearly visible. However, the study reveals significant challenges including small text regions, mismatches between Flickr images and OpenStreetMap building footprints, and the limited correlation between recognized text and building functions. The results suggest STR is effective only for buildings with visible texts, highlighting the need for alternative approaches or data sources for comprehensive large-scale mapping.

## Method Summary
The authors filter Flickr images to retain street-view building images with valid geotags and compass directions, then extract OSM building footprints and functions in the study area. They match each Flickr image to an OSM building using a line-of-sight method based on EXIF metadata, apply pre-trained STR models (TextSnake for detection, SAR for recognition) to extract text from matched images, and filter STR results based on confidence scores and stopwords. The recognized text is then analyzed for correlation with building functions, with manual checking performed on a subset to verify accuracy.

## Key Results
- STR models achieve high accuracy (90.62%) on a manually checked subset of 29 images
- Recognized text shows no clear correlation with building functions across the dataset
- Small text regions in street-view images and mismatches between Flickr images and OSM footprints pose significant challenges
- Only 0.5% of the dataset was manually validated, limiting confidence in overall accuracy claims

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Scene Text Recognition (STR) can accurately extract text from building facades in crowdsourced street-view images when image quality and text visibility are sufficient.
- Mechanism: Pre-trained STR models (TextSnake for detection, SAR for recognition) process cropped image regions containing text, using visual attention and sequence modeling to decode irregular text.
- Core assumption: Texts on building facades are large enough, unobstructed, and in clear lighting to be detected and recognized by existing models.
- Evidence anchors:
  - [abstract] Manual checking on a subset of STR-recognized images demonstrates high accuracy.
  - [section] "Manual comparison confirmed that STR results on 29 images are correct. Although we could not manually label the whole dataset, the correctness of the recognized numbers, i.e., 90.62%, for the small subset, indicates an overall high accuracy of the STR results."
- Break condition: If text regions are small, occluded, or in poor lighting, STR models fail to detect or correctly recognize the text.

### Mechanism 2
- Claim: Flickr images can be reliably matched to OpenStreetMap (OSM) building footprints using geotag and compass direction metadata.
- Mechanism: EXIF metadata provides GPS coordinates and compass direction to create a line of sight, which intersects with OSM building polygons to identify the corresponding building.
- Core assumption: The geotag is accurate and the compass direction reliably indicates the building being photographed.
- Evidence anchors:
  - [section] "We utilize the imageâ€™s position and compass direction from the EXIF data, which is essential for creating a line of sight. The line of sight identifies possible building candidates by intersecting with their polygons in OSM."
- Break condition: If the geotag is inaccurate or the image contains multiple buildings, the matching becomes unreliable.

### Mechanism 3
- Claim: Building attributes can be inferred from recognized text on building facades when the text contains relevant information.
- Mechanism: Extracted text strings (e.g., shop names, house numbers, construction years) are mapped to building attributes based on context and predefined classification schemes.
- Core assumption: The recognized text directly relates to the building's function or attributes.
- Evidence anchors:
  - [abstract] "We examined the correlation between STR results and building functions, and analysed instances where texts were recognized on residential buildings but not on commercial ones."
- Break condition: If recognized text is unrelated to building attributes or the building function is not explicitly stated, attribute inference is not possible.

## Foundational Learning

- Concept: Scene Text Recognition (STR)
  - Why needed here: STR is the core technology for extracting textual information from building facades in street-view images.
  - Quick check question: What are the two main steps in STR, and what is the purpose of each?

- Concept: Geotagging and EXIF Metadata
  - Why needed here: Accurate geotags and compass directions are essential for matching Flickr images to OSM building footprints.
  - Quick check question: How can you determine if a Flickr image's geotag is likely manually added rather than from GPS?

- Concept: Building Attribute Classification
  - Why needed here: Mapping recognized text to building attributes requires understanding the classification schemes used in OSM and the types of information typically found on building facades.
  - Quick check question: What are the three OSM tags used to indicate building functions, and how are they classified in this study?

## Architecture Onboarding

- Component map:
  - Flickr image filtering pipeline (content + metadata filtering) -> OSM building footprint and function extraction -> Flickr-to-OSM building matching (geotag + compass direction) -> STR processing (TextSnake detection + SAR recognition) -> STR result filtering (score thresholds, stopwords, repetitive letters) -> Attribute inference from recognized text

- Critical path:
  1. Filter Flickr images to retain street-view building images with valid geotags and compass direction.
  2. Extract OSM building footprints and functions in the study area.
  3. Match each Flickr image to an OSM building using the line of sight method.
  4. Apply STR models to extract text from the matched Flickr images.
  5. Filter STR results and infer building attributes from the recognized text.

- Design tradeoffs:
  - Using pre-trained STR models vs. fine-tuning on street-view specific data: Pre-trained models are readily available but may not generalize well to the unique characteristics of street-view images.
  - Strict vs. lenient filtering of STR results: Strict filtering ensures high accuracy but may miss relevant information; lenient filtering captures more information but risks including noise.

- Failure signatures:
  - Low STR recognition rates: Indicates issues with image quality, text visibility, or model suitability.
  - Mismatches between Flickr images and OSM buildings: Suggests problems with geotag accuracy, compass direction reliability, or building detection in images.
  - Inability to infer attributes from recognized text: Implies that the text is not relevant to building attributes or the classification scheme is inadequate.

- First 3 experiments:
  1. Apply STR to a small, manually labeled subset of Flickr images to assess recognition accuracy and identify failure modes.
  2. Test the Flickr-to-OSM matching algorithm on a set of images with known building locations to evaluate its reliability.
  3. Analyze the types of recognized text on buildings with different functions to understand the relationship between text and attributes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the accuracy of Scene Text Recognition (STR) models be improved for small text regions in street-view images?
- Basis in paper: [explicit] The paper highlights that texts in street-view images are often small and challenging to recognize due to complex and cluttered scenes.
- Why unresolved: Current STR models are primarily trained on text-centric datasets, which do not adequately represent the challenges of street-view images.
- What evidence would resolve it: Developing and testing STR models specifically trained on street-view images with small text regions and evaluating their performance against existing models.

### Open Question 2
- Question: What alternative approaches or data sources could complement STR for building attribute mapping in cases where texts are not visible or buildings are occluded?
- Basis in paper: [explicit] The paper identifies scenarios where STR is ineffective, such as buildings without visible texts or those occluded by other objects.
- Why unresolved: The paper suggests the need for alternative methods but does not specify what these might be or how they could be integrated.
- What evidence would resolve it: Exploring and validating alternative data sources (e.g., aerial imagery, LiDAR) or methods (e.g., object detection, deep learning models) that can infer building attributes in the absence of visible text.

### Open Question 3
- Question: How can the matching between Flickr images and OpenStreetMap (OSM) building footprints be improved to ensure accurate attribute mapping?
- Basis in paper: [explicit] The paper notes that mismatches between Flickr images and OSM building footprints lead to errors in mapping building attributes.
- Why unresolved: Current methods associate each Flickr image with only one building footprint, which is insufficient for images containing multiple buildings or non-building objects.
- What evidence would resolve it: Developing and testing improved algorithms for associating Flickr images with multiple building footprints or refining the matching process to account for non-building objects in the images.

## Limitations

- STR accuracy assessment based on manual checking of only 29 images (0.5% of dataset), limiting confidence in overall performance claims
- Correlation analysis between recognized text and building functions lacks statistical rigor and sufficient sample sizes
- Geotag accuracy and image-building correspondence issues affect the reliability of the Flickr-to-OSM matching process

## Confidence

**High Confidence**: The technical pipeline for STR processing (TextSnake detection + SAR recognition) and the filtering methodology are well-established and reproducible. The observation that STR performs well when text is clearly visible and large enough on building facades is supported by direct evidence.

**Medium Confidence**: The Flickr-to-OSM matching approach shows promise but faces practical challenges with geotag accuracy and image-building correspondence. The analysis of building function-text relationships provides interesting insights but lacks sufficient sample sizes and statistical validation to support strong conclusions.

**Low Confidence**: The overall effectiveness of using crowdsourced street-view images for large-scale building attribute mapping remains uncertain due to the small fraction of images containing usable text and the challenges in reliably matching images to building footprints.

## Next Checks

1. **Expand Manual Validation**: Manually verify STR accuracy on a stratified random sample of at least 200 images across different building types and visibility conditions to establish more reliable performance metrics.

2. **Statistical Correlation Analysis**: Conduct rigorous statistical analysis of the relationship between recognized text and building functions using appropriate significance testing and confidence intervals on larger sample sizes.

3. **Alternative Data Source Testing**: Test the STR pipeline on images from alternative crowdsourced platforms (e.g., Mapillary) to assess whether Flickr-specific characteristics affect the generalizability of the approach.