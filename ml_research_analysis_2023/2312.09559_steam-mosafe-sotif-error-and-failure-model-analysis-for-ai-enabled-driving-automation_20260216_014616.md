---
ver: rpa2
title: 'STEAM & MoSAFE: SOTIF Error-and-Failure Model & Analysis for AI-Enabled Driving
  Automation'
arxiv_id: '2312.09559'
source_url: https://arxiv.org/abs/2312.09559
tags:
- braking
- which
- hazardous
- scenario
- error
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces STEAM, a refinement of the SOTIF cause-and-effect
  model, and MoSAFE, a model-based method for identifying and evaluating hazardous
  behavior and error patterns. STEAM adds the concepts of hazardous error sequences,
  hazardous behavior patterns (HBPs), and hazardous error patterns (HEPs), and classifies
  scenario conditions as HB-sensitive or insensitive and input-relevant or irrelevant.
---

# STEAM & MoSAFE: SOTIF Error-and-Failure Model & Analysis for AI-Enabled Driving Automation

## Quick Facts
- **arXiv ID:** 2312.09559
- **Source URL:** https://arxiv.org/abs/2312.09559
- **Reference count:** 40
- **Key outcome:** Introduces STEAM refinement of SOTIF model and MoSAFE method for identifying hazardous error and behavior patterns in AI-enabled driving automation.

## Executive Summary
This paper presents STEAM, a refinement of the SOTIF cause-and-effect model, and MoSAFE, a model-based method for identifying and evaluating hazardous behavior and error patterns in AI-enabled driving automation systems. STEAM introduces Hazardous Behavior Patterns (HBPs) and Hazardous Error Patterns (HEPs) to provide a modular abstraction that separates vehicle-level behavior hazards from element-level error sequences. MoSAFE leverages weakest precondition reasoning to derive HEPs from HBPs in a backward, modular fashion, enabling systematic safety analysis of complex AI-based systems.

## Method Summary
The method combines high-level scenario models (HLSMs) for severity evaluation and detailed scenario models (DSMs) for likelihood estimation. HLSMs capture intended driving policy and HB-sensitive scenario conditions to identify HBPs by injecting hazardous behaviors. DSMs refine HLSMs with input-relevant scenario conditions and detailed DAS design to identify HEPs through causal chain analysis. Weakest precondition reasoning derives HEPs from HBPs by computing the largest input error pattern that guarantees a given HBP, propagating backward through conventional components with over-approximation for AI-based components.

## Key Results
- STEAM introduces modular abstraction separating HBPs (vehicle-level) from HEPs (element-level) via temporal error sequence patterns
- MoSAFE uses weakest precondition reasoning to derive HEPs from HBPs in a backward, modular fashion
- Scenario conditions classified as HB-sensitive/Insensitive and Input-relevant/Irrelevant enable progressive refinement from high-level to detailed models
- Case study demonstrates practical applicability to automated speed-control feature

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** STEAM introduces Hazardous Error Patterns (HEPs) and Hazardous Behavior Patterns (HBPs) to provide a modular abstraction that separates vehicle-level behavior hazards from element-level error sequences.
- **Mechanism:** HBPs capture deviations from intended behavior under HBSCs; HEPs capture temporal error sequences that cause HBPs. This two-layer separation allows hazard identification without getting lost in implementation detail, then drill down to causal chains via weakest precondition analysis.
- **Core assumption:** The same HB can arise from many HEP sequences; conversely, the same HEP can lead to multiple HBPs in different scenarios.
- **Evidence anchors:**
  - [abstract] "STEAM refines error definitions, introduces error sequences, and classifies them as error sequence patterns..."
  - [section] "On the vehicle-level (Clause 6), STEAM introduces the concept of a hazardous behavior pattern (HBP)... On the element-level (Clause 7), STEAM introduces the concept of a hazardous error sequence (HES)..."
- **Break condition:** If HBPs and HEPs are not properly aligned, or if error patterns are too coarse to distinguish meaningful safety differences, the abstraction collapses.

### Mechanism 2
- **Claim:** MoSAFE leverages weakest precondition (WPP) reasoning to derive HEPs from HBPs in a backward, modular fashion.
- **Mechanism:** Starting from an HBP at the DAS output, the method computes the largest input error pattern that guarantees the HBP; this is the WPP. The WPP is propagated backward through conventional components, over-approximating at AI-based components where exact computation is infeasible.
- **Core assumption:** Conventional components have deterministic behavior models; AI components require probabilistic modeling but still allow bounding error rates.
- **Evidence anchors:**
  - [section] "The key idea is to determine error patterns on the input of each component in the DAS’ that could lead to a given HBP... This is phrased as determining the weakest precondition..."
  - [section] "Given a UBI pattern... its weakest precondition at ˜d is the same pattern..."
- **Break condition:** If component models are inaccurate or if AI component error patterns cannot be bounded, WPP-based reasoning fails to produce actionable safety requirements.

### Mechanism 3
- **Claim:** The categorization of scenario conditions into HB-sensitive/Insensitive and Input-relevant/Irrelevant enables progressive refinement from high-level to detailed models.
- **Mechanism:** HBSCs guide the high-level severity evaluation (Clause 6), while IRCs inform the detailed DSM needed for likelihood estimation (Clause 7). This separation prevents premature complexity and focuses analysis effort where it matters.
- **Core assumption:** Scenario conditions affecting both HB-to-harm translation and DAS inputs are a strict subset of all IRCs; irrelevant conditions can be safely ignored.
- **Evidence anchors:**
  - [section] "First, scenario conditions are categorizes whether they influence the translation of an HB into harm... Second, scenario conditions are classified whether they affect the input into the DAS..."
  - [section] "The classification of scenario conditions enables a gradual refinement of scenario behavior models..."
- **Break condition:** If an IRC is incorrectly classified as HB-insensitive, or if HBSC boundaries are wrong, the risk estimation becomes invalid.

## Foundational Learning

- **Concept:** Weakest Precondition (WPP) reasoning in hybrid systems.
  - Why needed here: To formally derive the largest error pattern at an element input that guarantees a given hazard pattern at its output.
  - Quick check question: Given a policy that outputs a braking command only when distance < threshold, what is the WPP for a hazardous braking pattern?

- **Concept:** Fault Tree Analysis (FTA) with temporal nodes.
  - Why needed here: To represent causal chains among HBPs and HEPs as Boolean events linked by temporal patterns.
  - Quick check question: How would you model "either FN detection or speed underestimation" as an OR gate in the FTA?

- **Concept:** Scenario-based safety quantification (exposure, severity, controllability).
  - Why needed here: To convert pattern occurrence rates into actionable risk estimates aligned with ISO 26262 SOTIF clauses.
  - Quick check question: If a UBI pattern occurs 0.1% of braking scenarios and causes 2% S2 collisions, what is the expected S2 collision rate?

## Architecture Onboarding

- **Component map:** RVE model (road, vehicle kinematics) → sensor → object detector → tracker → odometry → policy → actuator
- **Critical path:** Error injection at perception → tracker compensation → policy decision → actuation → collision outcome. HBPs are evaluated at the policy output; HEPs at each perception block.
- **Design tradeoffs:** High abstraction in HLSM for speed vs. detail in DSM for accuracy; conservative over-approximation vs. exact WPP computation; simulation validation vs. formal proof.
- **Failure signatures:** Too many FNs → tracking failures → unsafe braking; underestimation of speed → reduced braking → overshoot; perception delays → delayed reaction → collision.
- **First 3 experiments:**
  1. Inject single FN detection at time t=50 and verify tracker FN pattern count and resulting UBI.
  2. Vary UBI duration τtotal in HLSM and map to severity classes via vimpact calculation.
  3. Replace tracker with Kalman filter model and recompute WPP for FN detection patterns.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can STEAM be extended to handle scenarios where multiple hazardous error patterns (HEPs) interact or overlap in complex ways?
- **Basis in paper:** [inferred] The paper discusses single-input failures in the fault tree derivation, but mentions the need for further research on multi-input failures.
- **Why unresolved:** The current model and method focus on single-input failures, and the paper acknowledges the need for further research on handling multi-input failures.
- **What evidence would resolve it:** Development and validation of a comprehensive model that can handle complex interactions between multiple HEPs, including formal methods for deriving weakest preconditions in such scenarios.

### Open Question 2
- **Question:** What are the most effective methods for validating the accuracy and completeness of the scenario models (HLSM and DSM) used in MoSAFE?
- **Basis in paper:** [explicit] The paper discusses the importance of model validation using simulation testing but acknowledges that simulation testing alone may not be sufficient for comprehensive validation.
- **Why unresolved:** While the paper mentions simulation testing, it does not provide a detailed methodology for validating the accuracy and completeness of the scenario models, especially for complex scenarios and behaviors.
- **What evidence would resolve it:** Development and validation of a systematic approach for model validation that combines simulation testing with formal methods, including techniques for identifying and addressing model inadequacies.

### Open Question 3
- **Question:** How can MoSAFE be adapted to handle the increasing complexity of end-to-end AI systems, where modularity is achieved through latent representations rather than human-interpretable interfaces?
- **Basis in paper:** [explicit] The paper discusses the limitations of MoSAFE when applied to end-to-end AI systems and suggests the need for further research on developing effective modular reasoning approaches for such systems.
- **Why unresolved:** The current approach relies on human-interpretable specifications and interfaces, which may not be feasible for end-to-end AI systems with latent representations.
- **What evidence would resolve it:** Development and validation of new techniques for reasoning about the safety of end-to-end AI systems, including methods for extracting interpretable information from latent representations and establishing causal links between errors and system failures.

## Limitations
- Model fidelity depends heavily on accuracy of underlying design models; errors propagate directly into HBP/HEP identification
- Abstraction boundaries between HB-sensitive and HB-insensitive conditions may blur in practice, leading to missed or spurious hazards
- Scalability concerns for backward WPP computation in complex policies; full production DAS stack applicability unproven

## Confidence
- STEAM model refinement (introducing HBPs/HEPs): **High** — well-grounded in ISO 21448 and supported by explicit textual evidence
- MoSAFE method using weakest precondition: **Medium** — concept is clear, but implementation details and scalability are under-specified
- Classification of scenario conditions: **Medium** — logical structure is sound, but empirical validation across varied scenarios is lacking

## Next Checks
1. **Cross-scenario consistency test:** Apply STEAM/MoSAFE to a second DAS feature (e.g., automated lane-keeping) and verify whether HBPs/HEPs align with those found in speed control, checking for consistency in abstraction layers
2. **WPP scalability benchmark:** Instrument the backward computation for a more complex decision policy and measure runtime/accuracy degradation compared to exact methods on small cases
3. **Sensitivity analysis on condition classification:** Systematically perturb scenario condition definitions and measure impact on HBP identification to quantify robustness of HB-sensitive/Insensitive boundaries