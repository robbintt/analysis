---
ver: rpa2
title: 'Knowledge Editing for Large Language Models: A Survey'
arxiv_id: '2310.16218'
source_url: https://arxiv.org/abs/2310.16218
tags:
- knowledge
- language
- editing
- llms
- pre-trained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey comprehensively reviews knowledge editing (KME) techniques
  for large language models (LLMs), categorizing them into three main approaches:
  external memorization, global optimization, and local modification. The survey introduces
  a general formulation of the KME problem as a constrained optimization task, emphasizing
  the importance of balancing locality (preserving unrelated knowledge) and generality
  (generalizing to related knowledge).'
---

# Knowledge Editing for Large Language Models: A Survey

## Quick Facts
- arXiv ID: 2310.16218
- Source URL: https://arxiv.org/abs/2310.16218
- Reference count: 40
- Key outcome: Comprehensive survey categorizing KME techniques into external memorization, global optimization, and local modification, with formulation as constrained optimization problem

## Executive Summary
This survey provides a comprehensive review of knowledge editing (KME) techniques for large language models (LLMs), systematically categorizing existing approaches into three main strategies: external memorization, global optimization, and local modification. The authors introduce a general formulation of KME as a constrained optimization problem, emphasizing the critical trade-off between locality (preserving unrelated knowledge) and generality (generalizing to related knowledge). The survey covers evaluation metrics, datasets, practical applications, and identifies key challenges including the locality-generality trade-off, lack of theoretical analysis, and scaling limitations.

## Method Summary
The survey categorizes KME approaches into three strategies: external memorization uses additional parameters or memory to store edited knowledge without modifying original model weights; global optimization employs constrained fine-tuning to inject new knowledge while preserving unrelated information; and local modification identifies and updates specific knowledge-relevant parameters through techniques like knowledge neuron localization. The general formulation frames KME as minimizing an objective function subject to constraints that ensure edited knowledge is correctly incorporated while preserving unrelated knowledge. Evaluation considers accuracy, locality, generality, retainability, and scalability metrics across datasets like zsRE, CounterFact, and FEVER.

## Key Results
- KME techniques enable efficient knowledge updates without full model retraining
- External memorization strategies preserve locality by keeping original weights unchanged
- Local modification methods achieve high generality by fine-tuning only parameters related to edited knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: KME techniques can efficiently update LLMs with new knowledge without full retraining.
- Mechanism: KME modifies a small fraction of model parameters or uses external memory to store new knowledge, preserving most pre-trained knowledge while achieving high accuracy on edited facts.
- Core assumption: LLMs store factual knowledge in specific neurons or parameters that can be localized and edited without disrupting unrelated knowledge.
- Evidence anchors:
  - [abstract] "aims to precisely modify the LLMs to incorporate specific knowledge, without negatively influencing other irrelevant knowledge"
  - [section 5.4.2] "KD [16] proposes to change each weight ... that store the knowledge in a pre-trained model"
  - [corpus] Weak - neighbor papers focus on pitfalls rather than supporting mechanisms

### Mechanism 2
- Claim: External memorization strategies preserve locality by keeping original model weights unchanged.
- Mechanism: Edited knowledge is stored in external parameters or memory, and the model retrieves it during inference without modifying core LLM weights.
- Core assumption: External storage can be efficiently accessed and integrated during inference without significant latency or accuracy loss.
- Evidence anchors:
  - [section 5.2.2] "SERAC [75] ... stores the edited samples ... without performing modifications on the original model"
  - [section 5.2.1] "The rationale behind the external memorization strategy is that storing new knowledge in additional parameters is intuitive and straightforward"
  - [corpus] Weak - neighbor papers don't validate external memory efficiency

### Mechanism 3
- Claim: Local modification methods achieve high generality by fine-tuning only parameters related to the edited knowledge.
- Mechanism: Gradient-based or prompt-based strategies locate knowledge neurons and update them to encode new facts while keeping other parameters fixed.
- Core assumption: Knowledge is localized enough in specific neurons that targeted updates can generalize to related prompts.
- Evidence anchors:
  - [section 5.4.2] "KD [16] proposes to change each weight ... with a high cumulative probability are considered relevant"
  - [section 5.4.3] "ROME [70] proposes a corruption-and-restore based strategy to identify relevant layers"
  - [corpus] Weak - neighbor papers discuss pitfalls rather than supporting evidence

## Foundational Learning

- Concept: Transformer architecture and self-attention mechanism
  - Why needed here: KME methods rely on understanding how LLMs store and retrieve knowledge in transformer layers
  - Quick check question: How do query, key, and value vectors interact in self-attention to produce the final representation?

- Concept: Knowledge neurons and parameter localization
  - Why needed here: Local modification strategies depend on identifying which parameters store specific knowledge
  - Quick check question: What distinguishes knowledge neurons from other parameters in the FFN layers?

- Concept: Constrained optimization and regularization
  - Why needed here: Global optimization KME methods use constraints to preserve unrelated knowledge during updates
  - Quick check question: How does adding a norm constraint on parameter updates help maintain locality?

## Architecture Onboarding

- Component map: Input prompt -> tokenizer -> model embedding -> transformer layers -> knowledge localization module -> update mechanism -> edited model output

- Critical path:
  1. Input prompt → tokenizer → model embedding
  2. Model processes input through layers
  3. Knowledge localization identifies relevant parameters
  4. Update mechanism modifies identified parameters or external memory
  5. Edited model generates output

- Design tradeoffs:
  - Memory vs. computation: External memory increases storage needs but reduces computation
  - Locality vs. generality: Tighter constraints improve locality but may reduce generalization
  - Scalability vs. precision: Mass editing requires different strategies than single-edit approaches

- Failure signatures:
  - Knowledge distortion: Edited model produces incorrect answers on related prompts
  - Catastrophic forgetting: Model loses previously known facts
  - Slow inference: External memory retrieval adds significant latency

- First 3 experiments:
  1. Single-edit accuracy test on zsRE dataset using ROME method
  2. Locality test comparing original vs. edited model on out-of-scope inputs
  3. Scalability test with increasing number of edits using MEMIT approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the fundamental theoretical principles that explain why certain KME techniques preserve locality while others do not?
- Basis in paper: [explicit] The paper identifies a gap in theoretical analysis of KME, noting that while many methods focus on effectiveness, there is a lack of comprehensive theoretical framework explaining the foundations of KME.
- Why unresolved: Current KME research lacks a unified theoretical framework that explains the behavior of different techniques, particularly regarding locality preservation.
- What evidence would resolve it: A formal theoretical model that predicts locality and generality outcomes based on method characteristics and architectural properties.

### Open Question 2
- Question: How can KME methods be designed to maintain coherence and performance when editing thousands of facts simultaneously?
- Basis in paper: [explicit] The paper identifies scalability as a major challenge, noting that current methods show decreased performance when multiple edits are applied, with potential contradictions between edited and pre-existing knowledge.
- Why unresolved: Current KME techniques struggle with coherence maintenance when scaling to large numbers of edits, as multiple edits can contradict pre-existing knowledge.
- What evidence would resolve it: Experimental results demonstrating successful editing of thousands of facts while maintaining both accuracy and consistency across all edits.

### Open Question 3
- Question: Can KME techniques be developed that automatically discover and prioritize which knowledge needs updating without human intervention?
- Basis in paper: [explicit] The paper identifies auto-discovery of editing targets as an open problem, noting that current methods rely on human expertise to identify knowledge that needs updating.
- Why unresolved: Current KME methods require manual identification of knowledge to update, which is labor-intensive and doesn't scale to the vast amount of information that needs to be maintained.
- What evidence would resolve it: A system that can automatically identify outdated or incorrect knowledge from raw sources and prioritize updates based on importance and impact.

## Limitations

- Limited empirical validation of efficiency claims across different KME methods
- Lack of comprehensive theoretical framework explaining locality preservation mechanisms
- Scalability challenges when applying multiple edits simultaneously remain unresolved

## Confidence

- KME Problem Formulation: High confidence
- Evaluation Metrics: High confidence  
- Practical Applications: Medium confidence
- Future Directions: Medium confidence
- Mechanism 1 (Single-edit efficiency): Medium confidence
- Mechanism 2 (External memorization): Low confidence
- Mechanism 3 (Local modification): Medium confidence

## Next Checks

1. **Empirical locality test:** Implement a controlled experiment comparing locality preservation across different KME methods (external memorization, global optimization, local modification) using the same base LLM and editing tasks, measuring performance degradation on unrelated knowledge.

2. **Scalability benchmark:** Design a benchmark testing KME methods with increasing numbers of simultaneous edits (10, 100, 1000 edits) to measure how accuracy, locality, and inference speed degrade as edit count increases.

3. **Knowledge distribution analysis:** Use techniques like activation patching or knowledge neuron identification across multiple KME methods to empirically validate whether factual knowledge is indeed localized in specific parameters as assumed by local modification approaches.