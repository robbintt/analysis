---
ver: rpa2
title: Restricted Generative Projection for One-Class Classification and Anomaly Detection
arxiv_id: '2307.04097'
source_url: https://arxiv.org/abs/2307.04097
tags:
- data
- distribution
- anomaly
- samples
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Restricted Generative Projection (RGP) for
  one-class classification and anomaly detection. The method aims to learn a mapping
  that transforms the distribution of normal training data to a target distribution
  that is simple, compact, and informative, which provides a reliable decision boundary
  for anomaly detection.
---

# Restricted Generative Projection for One-Class Classification and Anomaly Detection

## Quick Facts
- arXiv ID: 2307.04097
- Source URL: https://arxiv.org/abs/2307.04097
- Reference count: 40
- Primary result: RGP achieves competitive performance compared to state-of-the-art methods, with significant improvements on tabular datasets.

## Executive Summary
This paper proposes Restricted Generative Projection (RGP), a novel method for one-class classification and anomaly detection that transforms normal training data distributions to simple, compact, and informative target distributions. The method uses maximum mean discrepancy (MMD) to measure the distance between the transformed data distribution and the target distribution while maintaining reconstruction accuracy. RGP demonstrates competitive performance on multiple benchmark datasets, particularly showing significant improvements on tabular data compared to existing state-of-the-art approaches.

## Method Summary
RGP learns a mapping that transforms the distribution of normal training data to a target distribution that is simple, compact, and informative. The method uses deep neural networks to model the transformation and its inverse, minimizing the MMD between the transformed data and the target distribution while keeping reconstruction error small. Four target distributions are proposed: truncated Gaussian, uniform in hypersphere, uniform on hypersphere, and uniform between hyperspheres. The anomaly score is calculated based on the distance of a test sample from the target distribution in the transformed space.

## Key Results
- RGP achieves competitive performance on MNIST, Fashion-MNIST, and CIFAR-10 image datasets
- Significant improvements over state-of-the-art methods on tabular datasets (Abalone, Arrhythmia, Thyroid, KDD, KDDRev)
- Uniform on hypersphere (UoHS) target distribution generally performs best across different datasets
- Performance is sensitive to the choice of regularization coefficient λ and kernel bandwidth γ

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Learning a restricted generative projection transforms the distribution of normal training data to a target distribution that is simple, compact, and informative, providing a reliable decision boundary for anomaly detection.
- Mechanism: The method learns a mapping T that transforms the unknown distribution of normal data Dx to a known target distribution Dz. This is achieved by minimizing the maximum mean discrepancy (MMD) between the transformed data distribution and the target distribution, while keeping the reconstruction error for the original data small. The target distribution is chosen to be simple (easy to sample from), compact (provides a clear decision boundary), and informative (preserves important information of the original data).
- Core assumption: The normal data distribution can be transformed to a simple, compact, and informative target distribution, and abnormal data will have a different distribution in the transformed space.
- Evidence anchors:
  - [abstract] "The core idea is to learn a mapping to transform the unknown distribution of training (normal) data to a known target distribution."
  - [section III-A] "Suppose we have a set of m-dimensional training data X = {x1, x2, ..., xn} drawn from an unknown bounded distribution Dx and any samples drawn from Dx are normal data. We want to train a model M on X to determine whether a test data xnew is drawn from Dx or not."
  - [corpus] Found 25 related papers with average FMR=0.41, indicating moderate relevance to anomaly detection and one-class classification.
- Break condition: If the normal data distribution cannot be transformed to a simple, compact, and informative target distribution, or if abnormal data have a similar distribution to the target distribution in the transformed space.

### Mechanism 2
- Claim: Using bounded target distributions like truncated Gaussian, uniform in hypersphere, uniform on hypersphere, or uniform between hyperspheres provides a reliable decision boundary for anomaly detection.
- Mechanism: The bounded target distributions are chosen to be compact, which ensures that the decision boundary between normal data and abnormal data is clear and reliable. The method minimizes the distance between the transformed data distribution and the target distribution while keeping the reconstruction error for the original data small. Anomaly scores are calculated based on the distance of a test sample from the target distribution.
- Core assumption: The bounded target distributions are compact enough to provide a clear decision boundary between normal data and abnormal data in the transformed space.
- Evidence anchors:
  - [abstract] "Crucially, the target distribution should be sufficiently simple, compact, and informative. The simplicity is to ensure that we can sample from the distribution easily, the compactness is to ensure that the decision boundary between normal data and abnormal data is clear and reliable, and the informativeness is to ensure that the transformed data preserve the important information of the original data."
  - [section III-B] "We provide four simple, compact, and informative target distributions, analyze their properties theoretically, and show how to sample from them efficiently."
  - [corpus] Found 25 related papers with average FMR=0.41, indicating moderate relevance to anomaly detection and one-class classification.
- Break condition: If the bounded target distributions are not compact enough to provide a clear decision boundary between normal data and abnormal data in the transformed space.

### Mechanism 3
- Claim: Using the kernel maximum mean discrepancy (MMD) as the distance metric between the transformed data distribution and the target distribution enables efficient training and accurate anomaly detection.
- Mechanism: The MMD is used to measure the distance between the transformed data distribution and the target distribution using their finite samples. This allows the method to efficiently train the model by minimizing the MMD while keeping the reconstruction error for the original data small. The MMD is computed using the Gaussian kernel function.
- Core assumption: The MMD is an effective distance metric for measuring the difference between the transformed data distribution and the target distribution using their finite samples.
- Evidence anchors:
  - [section III-A] "Based on the universal approximation theorems [43], [44] and substantial success of neural networks, we use deep neural networks (DNN) to model T and T′ respectively. Let fθ and gϕ be two DNNs with parameters θ and ϕ respectively. We solve minimize θ, ϕ M[Dfθ(x), Dz] + λM[Dgϕ(fθ(x)), Dx]."
  - [section III-A] "Then the metric M in the first term of the objective of (4) should be able to measure the distance between two distributions using their finite samples. To this end, we propose to use the kernel maximum mean discrepancy (MMD) [39] to measure the distance between Dfθ(x) and Dz."
  - [corpus] Found 25 related papers with average FMR=0.41, indicating moderate relevance to anomaly detection and one-class classification.
- Break condition: If the MMD is not an effective distance metric for measuring the difference between the transformed data distribution and the target distribution using their finite samples.

## Foundational Learning

- Concept: Maximum Mean Discrepancy (MMD)
  - Why needed here: MMD is used as the distance metric between the transformed data distribution and the target distribution in the optimization objective.
  - Quick check question: What is the main advantage of using MMD as the distance metric in this method?

- Concept: One-Class Classification
  - Why needed here: The method is designed for one-class classification and anomaly detection, where the goal is to distinguish normal data from abnormal data using a model trained on only normal data.
  - Quick check question: What is the key challenge in one-class classification that this method aims to address?

- Concept: Generative Models
  - Why needed here: The method uses a generative approach to learn a mapping that transforms the distribution of normal training data to a target distribution.
  - Quick check question: How does the generative approach in this method differ from traditional generative models like GANs?

## Architecture Onboarding

- Component map: Input Data -> Encoder (fθ) -> Latent Space -> Decoder (gϕ) -> Reconstructed Data
- Critical path: Input Data → Encoder → Latent Space → Decoder → Reconstructed Data
- Design tradeoffs:
  - Compactness vs. Informativeness: The target distribution should be compact to provide a clear decision boundary, but also informative to preserve important information of the original data.
  - Bounded vs. Unbounded: Bounded target distributions are used to ensure a clear decision boundary, but may limit the expressiveness of the model.
- Failure signatures:
  - Poor anomaly detection performance: The method may fail to distinguish normal data from abnormal data if the target distribution is not chosen appropriately or if the model is not trained properly.
  - High reconstruction error: If the reconstruction error is too high, it may indicate that the model is not learning a good mapping between the input data and the target distribution.
- First 3 experiments:
  1. Train the model on a simple dataset (e.g., MNIST) with a known target distribution (e.g., uniform on hypersphere) and evaluate the anomaly detection performance.
  2. Vary the target distribution (e.g., truncated Gaussian, uniform in hypersphere) and evaluate the impact on anomaly detection performance.
  3. Vary the hyperparameters (e.g., regularization coefficient λ, kernel bandwidth γ) and evaluate the impact on anomaly detection performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of target distribution (GiHS, UiHS, UbHS, UoHS) affect the robustness of RGP to different types of anomalies?
- Basis in paper: [explicit] The paper compares four target distributions and finds that UoHS generally performs best, but notes that the choice may depend on the specific dataset and anomaly type.
- Why unresolved: The paper does not conduct a detailed analysis of how different target distributions perform against various anomaly types (e.g., point anomalies, contextual anomalies, collective anomalies).
- What evidence would resolve it: Systematic experiments on diverse datasets with labeled anomaly types, comparing the performance of each target distribution against each anomaly type.

### Open Question 2
- Question: Can RGP be extended to handle streaming data or non-stationary distributions where the concept of "normal" changes over time?
- Basis in paper: [inferred] The paper focuses on static datasets and does not address temporal aspects or concept drift.
- Why unresolved: The current formulation assumes a fixed training set and does not account for evolving data distributions or the need for online adaptation.
- What evidence would resolve it: Development and evaluation of an online version of RGP that can incrementally update the model as new data arrives, with experiments demonstrating its performance on datasets with concept drift.

### Open Question 3
- Question: What is the theoretical justification for the choice of kernel function (Gaussian kernel) in the MMD computation, and how does its performance vary with different kernels?
- Basis in paper: [explicit] The paper uses a Gaussian kernel for MMD but does not explore alternative kernels or provide theoretical analysis of its impact.
- Why unresolved: The paper does not compare the performance of RGP with different kernel functions in the MMD computation or provide theoretical insights into the choice of kernel.
- What evidence would resolve it: Empirical comparison of RGP using different kernel functions (e.g., Laplacian, rational quadratic) in the MMD computation, along with theoretical analysis of how the choice of kernel affects the approximation of the distance between distributions.

## Limitations

- Performance on image datasets is competitive but not substantially better than existing methods
- Sensitivity to hyperparameter choices (λ, γ, network architectures) requires careful tuning
- Theoretical guarantees for optimal target distribution selection remain partially developed

## Confidence

- Core claims about transforming distributions: **High confidence**
- Use of MMD as distance metric: **High confidence**
- Choice of bounded target distributions: **Medium confidence**
- Generalization to complex real-world datasets: **Lower confidence**

## Next Checks

1. Test the method on more diverse real-world datasets with varying dimensionality and feature types to assess generalization limits
2. Conduct ablation studies varying target distributions and hyperparameters systematically to identify optimal configurations for different data types
3. Compare theoretical anomaly detection error bounds with empirical performance across all tested datasets to validate the theoretical framework