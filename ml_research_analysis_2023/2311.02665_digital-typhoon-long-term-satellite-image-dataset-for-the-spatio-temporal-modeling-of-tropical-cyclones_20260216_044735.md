---
ver: rpa2
title: 'Digital Typhoon: Long-term Satellite Image Dataset for the Spatio-Temporal
  Modeling of Tropical Cyclones'
arxiv_id: '2311.02665'
source_url: https://arxiv.org/abs/2311.02665
tags:
- dataset
- data
- typhoon
- tropical
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Digital Typhoon dataset is the longest tropical cyclone satellite
  image dataset spanning 40+ years, designed to benchmark machine learning models
  for long-term spatio-temporal data. To create a homogeneous dataset, a workflow
  was developed to generate typhoon-centered images using Lambert azimuthal equal-area
  projection and best track data, with inter-satellite calibration to address data
  quality issues.
---

# Digital Typhoon: Long-term Satellite Image Dataset for the Spatio-Temporal Modeling of Tropical Cyclones

## Quick Facts
- arXiv ID: 2311.02665
- Source URL: https://arxiv.org/abs/2311.02665
- Reference count: 40
- The Digital Typhoon dataset is the longest tropical cyclone satellite image dataset spanning 40+ years

## Executive Summary
The Digital Typhoon dataset provides a homogeneous, long-term collection of tropical cyclone satellite images designed to benchmark machine learning models for spatio-temporal prediction tasks. Spanning 40+ years and covering 1,099 typhoons in the Western North Pacific basin, the dataset addresses key challenges in creating consistent training data across multiple satellite generations through careful calibration and projection techniques. The dataset enables research on typhoon intensity analysis, forecasting, and reanalysis, with benchmarking results showing that recent deep learning models still struggle with the dataset's complexity, highlighting its value as a challenging testbed for ML approaches to tropical cyclone prediction.

## Method Summary
The Digital Typhoon dataset was created by processing infrared satellite imagery from 1978-2022 using Lambert azimuthal equal-area projection centered on each typhoon, with inter-satellite calibration applied to maintain homogeneity across different satellite generations. The dataset contains 189,364 images at 5km resolution, with brightness temperature as the primary feature after calibration using polar-orbiting infrared sounders. A workflow utilizing the pyphoon2 library handles HDF5 data loading, map projection, and preprocessing, with data split by typhoon sequence (80/20) to avoid temporal leakage. The dataset is publicly available at http://agora.ex.nii.ac.jp/digital-typhoon/dataset/ and https://github.com/kitamoto-lab/digital-typhoon/.

## Key Results
- ML models show degraded performance on strong typhoons, with RMSE increasing from 6.6 hPa for central pressure estimation on weaker storms to higher values on stronger systems
- Different train/test split strategies (sequence vs. season) yield significantly different performance metrics, with sequence-level splitting providing more realistic estimates
- Recent deep learning architectures (ResNet18/50, ViT) achieve RMSE around 6.6 hPa for central pressure estimation, demonstrating the dataset's challenging nature

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Lambert azimuthal equal-area projection centered on typhoon improves ML performance by preserving shape and area without distortion.
- Mechanism: The projection places the typhoon at the image center and minimizes geometric distortion, which aligns with the Dvorak technique's focus on features near the typhoon center. Cropping to the center region further reduces irrelevant spatial information.
- Core assumption: Machine learning models benefit more from shape-accurate, centered images than from raw satellite projections with edge distortion.
- Evidence anchors:
  - [abstract] "create an infrared typhoon-centered image for cropping using Lambert azimuthal equal-area projection"
  - [section] "The Digital Typhoon dataset utilizes the Lambert azimuthal equal-area projection, maintaining the spherical shape of the tropical cyclone, while the HURSAT dataset employs the equirectangular (lat/long) grid, causing shape distortion in higher latitude or peripheral areas."
  - [corpus] Weak: no direct empirical comparison in related papers, but the projection choice is unique to this dataset.
- Break condition: If ML performance is not significantly better with centered, equal-area projection versus other projections or raw images.

### Mechanism 2
- Claim: Inter-satellite calibration removes systematic biases across different satellite generations, enabling a homogeneous long-term dataset.
- Mechanism: Recalibration using polar orbiting infrared sounders (e.g., ISCCP) adjusts brightness temperatures from different satellite sensors to a common scale, reducing inter-satellite variability.
- Core assumption: Brightness temperature biases across satellites are systematic and can be corrected to a sufficient degree for ML training.
- Evidence anchors:
  - [abstract] "address data quality issues such as inter-satellite calibration to create a homogeneous dataset"
  - [section] "recalibration method is effective for inter-calibration across satellite sensors to obtain even better homogeneous long-term observation data for climate change research"
  - [corpus] Weak: the HURSAT dataset also uses ISCCP recalibration, but no direct comparison is provided in related work.
- Break condition: If remaining inter-satellite biases after recalibration are large enough to degrade ML model generalization across satellite generations.

### Mechanism 3
- Claim: Random split-by-sequence avoids data leakage in time-series while preserving statistical independence across typhoons.
- Mechanism: Treating each typhoon sequence as independent allows random sampling without temporal autocorrelation, unlike random split-by-image which would leak information within the same sequence.
- Core assumption: Typhoons are independent events and do not influence each other's intensity evolution in a way that would bias the model.
- Evidence anchors:
  - [abstract] "we apply random splits to the sequence level (split-by-sequence) or the season level (split-by-season)"
  - [section] "At least, a random split for the image level must not be used to avoid overestimating the performance due to data leakage in the same typhoon sequence"
  - [corpus] Weak: no explicit mention in related papers, but this is a standard practice in time-series ML.
- Break condition: If typhoon sequences exhibit long-range dependencies that violate the independence assumption.

## Foundational Learning

- Concept: Map projections and their properties (equal-area, conformal, equidistant)
  - Why needed here: Understanding why Lambert azimuthal equal-area projection is chosen over others (e.g., Mercator, equirectangular) requires knowledge of how different projections preserve or distort area, shape, and distance.
  - Quick check question: Which map projection preserves area but not shape, and is often used for thematic world maps?

- Concept: Brightness temperature and satellite remote sensing
  - Why needed here: The dataset uses infrared brightness temperature as the primary feature; understanding how it relates to cloud top temperature and typhoon intensity is essential for interpreting ML results.
  - Quick check question: What physical quantity does infrared brightness temperature measure in satellite imagery?

- Concept: Time-series cross-validation and data leakage
  - Why needed here: Proper train/test splitting in time-series data (e.g., split-by-sequence vs. split-by-image) is critical to avoid overestimating model performance.
  - Quick check question: What is the main risk of using a random split-by-image in a time-series dataset?

## Architecture Onboarding

- Component map:
  pyphoon2 library -> HDF5 image and metadata loading -> Map projection and calibration -> Normalization -> Train/test split -> Model training (ResNet/ViT) -> Evaluation

- Critical path:
  1. Load HDF5 image and metadata
  2. Apply map projection and calibration
  3. Normalize brightness temperature (170-300K → 0-1)
  4. Split data by sequence (random 80/20)
  5. Train model (ResNet18/50 or ViT)
  6. Evaluate on held-out sequences

- Design tradeoffs:
  - Resolution vs. homogeneity: 5km resolution chosen for long-term consistency over newer 2km data
  - Spectral channels: IR1 only for homogeneity, despite VIS/IR2/WV available on website
  - Temporal resolution: 1-hour chosen as representative, despite 10-minute available in recent satellites

- Failure signatures:
  - High RMSE on strong typhoons: suggests model struggles with extreme intensity patterns
  - Large performance gap between split-by-sequence and split-by-image: indicates data leakage
  - Degraded performance on older satellite generations: suggests remaining inter-satellite bias

- First 3 experiments:
  1. Train ResNet18 on full-resolution (512×512) images, evaluate RMSE on central pressure
  2. Train ViT on cropped (224×224) images, compare classification accuracy vs. ResNet18
  3. Train ConvLSTM for 12-hour forecasting, evaluate RMSE on predicted vs. true pressure

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of machine learning models on the Digital Typhoon dataset compare to traditional meteorological methods like the Dvorak technique and SHIPS for intensity estimation?
- Basis in paper: [explicit] The paper mentions comparing machine learning approaches to traditional methods like the Dvorak technique and SHIPS in the context of real-world solutions for tropical cyclones, but does not provide specific comparative results.
- Why unresolved: The paper focuses on benchmarking machine learning models using the Digital Typhoon dataset but does not include direct comparisons with traditional meteorological methods' performance on the same dataset.
- What evidence would resolve it: Conducting experiments where both machine learning models trained on the Digital Typhoon dataset and traditional methods like the Dvorak technique and SHIPS are applied to the same set of historical typhoon cases, comparing their accuracy in intensity estimation.

### Open Question 2
- Question: What is the impact of different map projections on the performance of machine learning models trained on typhoon satellite images?
- Basis in paper: [explicit] The paper discusses the choice of Lambert azimuthal equal-area projection for the Digital Typhoon dataset but notes that other projections exist and could potentially affect model performance.
- Why unresolved: The paper does not experimentally compare the performance of machine learning models trained on images using different map projections.
- What evidence would resolve it: Training and testing machine learning models on the Digital Typhoon dataset using images processed with different map projections (e.g., Lambert azimuthal equal-area, equirectangular, Mercator) and comparing their performance in tasks like intensity estimation.

### Open Question 3
- Question: How transferable are machine learning models trained on the Digital Typhoon dataset (Western North Pacific basin) to other basins like the Atlantic or Indian Ocean?
- Basis in paper: [explicit] The paper mentions that the Digital Typhoon dataset covers the Western North Pacific basin and raises the question of how models trained on this dataset might transfer to other basins.
- Why unresolved: The paper does not provide experimental results on the performance of models trained on the Digital Typhoon dataset when applied to typhoon data from other basins.
- What evidence would resolve it: Training machine learning models on the Digital Typhoon dataset and evaluating their performance on typhoon data from other basins (e.g., Atlantic, Indian Ocean), potentially after fine-tuning or domain adaptation.

## Limitations
- Remaining inter-satellite biases may affect ML model generalization across satellite generations despite calibration efforts
- Dataset focuses on Western North Pacific basin, limiting generalizability to other tropical cyclone basins
- Tradeoff between homogeneity and resolution: 5km resolution chosen over available 2km data for consistency

## Confidence
- Dataset creation methodology (High): The workflow for generating typhoon-centered images with Lambert projection and calibration is well-specified and reproducible.
- ML performance results (Medium): Results show clear trends but are sensitive to architectural and preprocessing choices.
- Generalization claims (Low): Limited evaluation on other tropical cyclone basins or datasets prevents strong claims about broader applicability.

## Next Checks
1. Test model performance across different satellite generations to quantify remaining inter-satellite biases
2. Evaluate whether split-by-sequence assumption holds by testing for residual temporal autocorrelation within typhoon sequences
3. Compare ML performance using the Digital Typhoon dataset against raw satellite imagery without projection or calibration to quantify the benefit of preprocessing steps