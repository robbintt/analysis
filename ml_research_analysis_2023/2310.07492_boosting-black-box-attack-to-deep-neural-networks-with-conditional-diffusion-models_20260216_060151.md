---
ver: rpa2
title: Boosting Black-box Attack to Deep Neural Networks with Conditional Diffusion
  Models
arxiv_id: '2310.07492'
source_url: https://arxiv.org/abs/2310.07492
tags:
- attack
- cdma
- adversarial
- attacks
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel black-box attack strategy called Conditional
  Diffusion Model Attack (CDMA) to improve the query efficiency of generating adversarial
  examples (AEs) under query-limited situations. The key insight of CDMA is to formulate
  the task of AE synthesis as a distribution transformation problem, i.e., benign
  examples and their corresponding AEs can be regarded as coming from two distinctive
  distributions and can transform from each other with a particular converter.
---

# Boosting Black-box Attack to Deep Neural Networks with Conditional Diffusion Models

## Quick Facts
- arXiv ID: 2310.07492
- Source URL: https://arxiv.org/abs/2310.07492
- Authors: 
- Reference count: 40
- One-line primary result: Proposes a conditional diffusion model attack that achieves >99% untargeted attack success rate with only ONE query on average

## Executive Summary
This paper introduces a novel black-box adversarial attack method called Conditional Diffusion Model Attack (CDMA) that significantly improves query efficiency by transforming adversarial example generation into a conditional sampling problem. Unlike traditional optimization-based approaches, CDMA leverages a conditional denoising diffusion probabilistic model (DDPM) to directly synthesize adversarial examples in a single query. The method demonstrates exceptional performance across multiple datasets and models, achieving high attack success rates with minimal queries while maintaining robustness against various defense strategies.

## Method Summary
CDMA formulates adversarial example generation as a distribution transformation problem where clean images and their adversarial counterparts are treated as coming from adjacent but distinct distributions. The method trains a conditional diffusion model (U-Net architecture) on paired clean-adversarial examples generated by white-box attacks on shadow models. During inference, the model generates adversarial examples by performing conditional sampling guided by the clean image, effectively reversing the diffusion process to produce perturbations that fool target models. The approach uses cosine sampling schedule with T=50 steps and noise budgets of ε=8/255 or 16/255.

## Key Results
- Achieves >99% attack success rate for untargeted attacks across all datasets
- Reduces query count to ONE query in most cases, compared to thousands for traditional methods
- Maintains effectiveness against multiple defense strategies including JPEG, NRP, and MedianSmoothing
- Demonstrates superior performance on CIFAR-10, CIFAR-100, and Tiny-ImageNet-200

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The diffusion model learns a distribution transformation between clean images and their adversarial counterparts, allowing direct conditional sampling of adversarial examples.
- Mechanism: By training a conditional diffusion model on paired clean-adversarial examples, the model learns to reverse the diffusion process conditioned on the clean image, effectively transforming it into an adversarial example in one step.
- Core assumption: Clean images and their corresponding adversarial examples come from two adjacent but distinct distributions that can be connected by a learned transformation.
- Evidence anchors:
  - [abstract] "The key insight of CDMA is to formulate the task of AE synthesis as a distribution transformation problem, i.e., benign examples and their corresponding AEs can be regarded as coming from two distinctive distributions and can transform from each other with a particular converter."
  - [section] "The core of CDMA is to convert the AE generation task into an image translation task, and adopt a conditional diffusion model (i.e., the converter) to directly synthesize high-quality AEs."
- Break condition: If the paired clean-adversarial examples do not adequately represent the transformation (e.g., if white-box attacks produce highly non-transferable AEs), the diffusion model may fail to learn a meaningful mapping.

### Mechanism 2
- Claim: Conditional sampling guided by the clean image ensures that generated adversarial examples stay within the perturbation budget and maintain high attack success rate.
- Mechanism: The diffusion model's reverse process starts from random noise and iteratively denoises toward the clean image's conditional distribution, producing adversarial examples that are close to the original image and still fool the model.
- Core assumption: The conditional diffusion model can generate diverse adversarial examples that remain effective across different victim models and datasets.
- Evidence anchors:
  - [abstract] "CDMA adopts the conditional Denoising Diffusion Probabilistic Model as the converter, which can learn the transformation from clean samples to AEs, and ensure the smooth development of perturbed noise resistant to various defense strategies."
  - [section] "Unlike [23], we need to consider the additional conditional variable x. We use δ to represent the real noise added to xadv at each step t, and use ˆδθ to represent the noise predicted by model f(·) (U-NET in this paper)."
- Break condition: If the noise budget constraint is violated during sampling, or if the conditional guidance is too restrictive, the generated AEs may not be effective.

### Mechanism 3
- Claim: The diffusion model's ability to generate diverse adversarial examples improves transferability across different models and datasets.
- Mechanism: By learning the general transformation from clean to adversarial examples rather than optimizing for a specific model, the diffusion model generates AEs that are less tailored to any single surrogate and thus more transferable.
- Core assumption: Adversarial examples generated by learning a general transformation are more transferable than those optimized for a specific model.
- Evidence anchors:
  - [abstract] "AEs generated from CDMA exhibit higher robustness to several mainstream defense strategies."
  - [section] "The final objective function can be written as: L = Et,{x,xadv0 },δ ‖δ − ˆδθ(xadv t , t, x)‖p where t ∼ [1, 2, ..., T], {x, xadv0 } ∼ D{ x, xadv}, xadv t ∼ q(xadv t |xadv 0 , x), δ ∼ N (0, I), ‖ · ‖ p represents the Lp-norm and p ∈ { 0, 1, 2, L∞}."
- Break condition: If the transformation learned is too general, the generated AEs may not be adversarial enough for any specific model.

## Foundational Learning

- Concept: Diffusion models and the denoising process
  - Why needed here: Understanding how diffusion models learn to reverse a noising process is crucial to grasping how CDMA generates adversarial examples directly.
  - Quick check question: What is the role of the noise schedule in diffusion models, and how does it affect the quality of generated samples?

- Concept: Conditional generation in diffusion models
  - Why needed here: CDMA uses conditional diffusion models, where the clean image acts as a condition to guide the generation of adversarial examples.
  - Quick check question: How does conditioning on the clean image influence the reverse diffusion process in CDMA?

- Concept: Adversarial example generation and transferability
  - Why needed here: Understanding the relationship between AE generation methods and their transferability is key to appreciating CDMA's advantage.
  - Quick check question: Why are AEs generated by learning a general transformation more transferable than those optimized for a specific model?

## Architecture Onboarding

- Component map: Data collection module -> Conditional diffusion model (U-Net) -> Sampling module -> Attack evaluation module
- Critical path:
  1. Collect paired clean-adversarial examples from shadow models
  2. Train the conditional diffusion model on the collected data
  3. Generate adversarial examples by sampling from the trained model
  4. Evaluate the AEs against victim models
- Design tradeoffs:
  - Using a diffusion model for AE generation trades off the need for extensive model queries with the computational cost of training the diffusion model
  - The choice of noise schedule and sampling steps affects the quality and diversity of generated AEs
  - The effectiveness of CDMA depends on the quality and transferability of the white-box AEs used for training
- Failure signatures:
  - Low attack success rate: The diffusion model may not have learned a meaningful transformation, or the generated AEs may not be adversarial enough
  - High query counts: The sampling process may be inefficient, or the generated AEs may not fool the victim model
  - Poor transferability: The generated AEs may be too tailored to the shadow models used for training
- First 3 experiments:
  1. Train the diffusion model on a small dataset (e.g., CIFAR-10) and evaluate its ability to generate AEs on the same dataset
  2. Test the transferability of AEs generated by CDMA on a different model than the one used for training
  3. Compare the query efficiency of CDMA with a baseline black-box attack method on a larger dataset (e.g., Tiny-ImageNet)

## Open Questions the Paper Calls Out

- Question: How does the performance of CDMA compare to other generative-based adversarial attack methods like GAN-based approaches in terms of both attack success rate and query efficiency?
  - Basis in paper: [explicit] The paper mentions that CDMA achieves a much higher attack success rate within 1,000 queries compared to other methods like AdvFlow, Bayes Attack, and TA. It also states that CDMA needs fewer queries to achieve the attack results.
  - Why unresolved: While the paper provides a comparison with some generative-based methods, it doesn't directly compare CDMA with other GAN-based approaches in terms of attack success rate and query efficiency.
  - What evidence would resolve it: A direct comparison between CDMA and other GAN-based adversarial attack methods, such as AdvGAN, in terms of attack success rate and query efficiency on the same datasets and models.

- Question: How does the choice of noise budget (epsilon) affect the performance of CDMA in terms of attack success rate and query efficiency?
  - Basis in paper: [explicit] The paper mentions that the noise budget is set to epsilon = 8 and epsilon = 16, but it doesn't explore how different noise budget values affect the performance of CDMA.
  - Why unresolved: The paper only evaluates CDMA with two specific noise budget values, so it's unclear how the method would perform with other noise budget values.
  - What evidence would resolve it: An evaluation of CDMA's performance with a range of noise budget values to determine the optimal value for achieving high attack success rate and query efficiency.

- Question: How does CDMA perform against more advanced defense strategies that are specifically designed to counter diffusion-based attacks?
  - Basis in paper: [explicit] The paper evaluates CDMA against some mainstream defense strategies like JPEG compression, NRP, pixel deflection, GuidedDiffusionPur, RP-Regularizer, BitDepthReduce, and MedianSmoothing2D. However, it doesn't explore how CDMA performs against more advanced defense strategies that are specifically designed to counter diffusion-based attacks.
  - Why unresolved: The paper only evaluates CDMA against some common defense strategies, so it's unclear how the method would perform against more advanced defenses that are specifically designed to counter diffusion-based attacks.
  - What evidence would resolve it: An evaluation of CDMA's performance against more advanced defense strategies that are specifically designed to counter diffusion-based attacks, such as adversarial training with diffusion-based examples or specialized diffusion-based purification methods.

## Limitations
- Scalability concerns on larger, more complex datasets beyond CIFAR-10, CIFAR-100, and Tiny-ImageNet-200
- Reliance on paired clean-adversarial examples may introduce biases if white-box attacks are not sufficiently transferable
- Computational overhead of training the diffusion model for high-resolution images is not thoroughly addressed

## Confidence
- **High Confidence**: The core mechanism of using a conditional diffusion model to generate adversarial examples is well-supported by the experimental results and aligns with established diffusion model principles
- **Medium Confidence**: The claim of improved query efficiency and robustness across various defense strategies is supported by the experiments, but the extent of these improvements may vary depending on the specific models and datasets
- **Low Confidence**: The generalizability of CDMA to real-world, large-scale applications and its performance against state-of-the-art defense mechanisms are not fully established

## Next Checks
1. Evaluate CDMA's performance on ImageNet to assess scalability and generalization capabilities
2. Test the robustness of CDMA-generated adversarial examples against the latest and most effective defense strategies beyond those mentioned in the paper
3. Analyze the computational overhead of training the diffusion model and compare it with the query efficiency gains in real-world scenarios to determine practical viability