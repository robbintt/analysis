---
ver: rpa2
title: Implicit Regularization in Feedback Alignment Learning Mechanisms for Neural
  Networks
arxiv_id: '2306.01870'
source_url: https://arxiv.org/abs/2306.01870
tags:
- alignment
- learning
- feedback
- networks
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes conservation laws for feedback alignment\
  \ (FA), a biologically plausible learning rule that replaces backward pass weights\
  \ with random matrices. The authors prove a key theorem showing that under FA, the\
  \ quantity \xBD||Wi(t)||\xB2F - \u27E8Wi+1(t), Bi+1\u27E9 remains invariant throughout\
  \ training, where Wi are feedforward weights and Bi are fixed random feedback matrices."
---

# Implicit Regularization in Feedback Alignment Learning Mechanisms for Neural Networks

## Quick Facts
- **arXiv ID:** 2306.01870
- **Source URL:** https://arxiv.org/abs/2306.01870
- **Reference count:** 13
- **Primary result:** Feedback alignment conserves a specific quantity during training, leading to implicit bias toward minimum-norm solutions

## Executive Summary
This paper establishes conservation laws for feedback alignment (FA), a biologically plausible learning rule that replaces backward pass weights with random matrices. The authors prove that under FA, a specific quantity remains invariant throughout training, revealing an implicit bias analogous to but distinct from gradient descent. This conservation law explains why FA exhibits layer-wise alignment and converges to minimum-norm solutions in over-parameterized networks. The findings bridge biological plausibility with theoretical understanding of deep learning optimization.

## Method Summary
The authors analyze feedback alignment by proving conservation laws through trace inner product manipulations. They generate synthetic data from a multivariate normal distribution and implement FA weight updates for two-layer linear and ReLU networks. The method tracks a conserved quantity (½||Wi(t)||²_F - ⟨Wi+1(t), Bi+1⟩) across training iterations and compares FA-learned weights with Moore-Penrose pseudoinverse solutions to verify convergence properties.

## Key Results
- Proved a conservation law showing ½||Wi(t)||²_F - ⟨Wi+1(t), Bi+1⟩ remains invariant during FA training
- Demonstrated that FA has an implicit bias analogous to but distinct from gradient descent
- Proved that over-parameterized two-layer linear networks trained with FA converge to minimum-norm solutions
- Validated conservation law experimentally for both linear and ReLU networks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Feedback alignment maintains a conserved quantity during training
- Mechanism: The trace inner product ⟨Ẇi, Wi⟩ equals ⟨Ẇi+1, Bi+1⟩ for all layers, leading to conservation of ½‖Wi(t)‖²_F - ⟨Wi+1(t), Bi+1⟩
- Core assumption: The learning dynamics follow direct feedback alignment with fixed random feedback matrices
- Evidence anchors:
  - [abstract] "The authors prove a key theorem showing that under FA, the quantity ½‖Wi(t)‖²_F - ⟨Wi+1(t), Bi+1⟩ remains invariant throughout training"
  - [section] Theorem 5.1 proves this conservation law explicitly through trace manipulations
  - [corpus] Related works like "Learning Fair and Preferable Allocations through Neural Network" show similar conservation principles in different contexts
- Break condition: If feedback matrices become time-dependent or if the trace inner product relationship fails

### Mechanism 2
- Claim: FA exhibits implicit bias toward minimum-norm solutions
- Mechanism: The conservation law constrains the solution space such that over-parameterized two-layer linear networks converge to minimum-norm solutions
- Core assumption: The network is over-parameterized with linearly independent data rows and uses squared loss
- Evidence anchors:
  - [abstract] "the authors demonstrate that this law implies sufficient conditions for layer-wise alignment and proves that two-layer linear networks trained with FA converge to minimum-norm solutions"
  - [section] Theorem 5.2 proves convergence to minimum-norm solution using the conservation law
  - [corpus] Weak - no direct corpus evidence found for minimum-norm bias in FA specifically
- Break condition: If the over-parameterization assumption fails or data becomes linearly dependent

### Mechanism 3
- Claim: Layer-wise alignment emerges naturally from the conservation law
- Mechanism: The conservation law creates a relationship between feedforward and feedback weights that drives alignment when properly initialized
- Core assumption: Initial weights satisfy ∥Wi(0)‖ ≤ ‖Wi+1(0)‖ with Wi+1(0) = Bi+1
- Evidence anchors:
  - [abstract] "This conservation law reveals that FA has an implicit bias analogous to, but distinct from, gradient descent"
  - [section] The paper states "if we initialize Wi+1(0) = Bi+1 such that ∥Wi(0)‖ ≤ ‖Wi+1(0)‖ then the conservation law simplifies to ⟨Wi+1(t), Bi+1⟩ ≥ 0"
  - [corpus] Related works like "Oja's plasticity rule" show similar alignment phenomena in biological learning
- Break condition: If initialization doesn't satisfy the alignment dominance condition

## Foundational Learning

- Concept: Trace inner product and its cyclic property
  - Why needed here: The proof relies on trace manipulations to establish the conservation law
  - Quick check question: Why does Tr(AB) = Tr(BA) hold for compatible matrices A and B?

- Concept: Over-parameterization and minimum-norm solutions
  - Why needed here: The convergence result depends on the network having more parameters than necessary
  - Quick check question: What mathematical property ensures that minimum-norm solutions generalize well?

- Concept: Fixed random feedback matrices vs learned feedback
  - Why needed here: The conservation law specifically requires fixed random feedback matrices
  - Quick check question: How would the analysis change if Bi(t) = Wi(t) as in backpropagation?

## Architecture Onboarding

- Component map: Input x ∈ Rn₀ -> Hidden layers (Wl ∈ Rⁿˡ⁺¹×ⁿˡ, al = ϕ(hl)) -> Output aL -> Loss function -> Error computation -> FA weight updates

- Critical path: Forward pass → Error computation → Layer-wise alignment via conservation law → Weight updates via FA rule

- Design tradeoffs:
  - Fixed random feedback matrices provide biological plausibility but may limit expressivity
  - The conservation law requires careful initialization for alignment
  - Computational efficiency comes at the cost of potential slower convergence

- Failure signatures:
  - Divergence in training loss
  - Breakdown of the conservation law (tracked quantity becomes non-constant)
  - Layer-wise alignment fails to emerge

- First 3 experiments:
  1. Verify the conservation law numerically by tracking ½‖Wi(t)‖²_F - ⟨Wi+1(t), Bi+1⟩ during training
  2. Test different initialization schemes to find conditions that guarantee layer-wise alignment
  3. Compare convergence speed and generalization between FA and gradient descent on over-parameterized linear networks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what specific conditions does the conservation law in Theorem 5.1 guarantee convergence of FA to a global optimum in multi-layer non-linear networks?
- Basis in paper: [explicit] The paper establishes the conservation law for scalar output ReLU networks and shows convergence to global optimum for two-layer linear networks, but does not extend these results to deeper non-linear architectures.
- Why unresolved: The proof of Theorem 5.2 relies heavily on the linear structure and over-parameterization of two-layer networks. Extending this to non-linear networks would require understanding how layer-wise alignment interacts with non-linear activation functions and the resulting optimization landscape.
- What evidence would resolve it: Formal proof showing that under conditions of sustained layer-wise alignment and certain properties of the activation function, FA converges to a global optimum in multi-layer non-linear networks, supported by empirical validation on benchmark datasets.

### Open Question 2
- Question: How does the implicit bias induced by FA differ quantitatively from that of gradient descent in deep networks, and what are the implications for generalization?
- Basis in paper: [explicit] The paper states that FA harbors an implicit bias analogous to but distinct from gradient descent, and mentions that the minimum-norm solution found by FA has good generalization properties, but does not provide a detailed comparison.
- Why unresolved: While the conservation law reveals the existence of an implicit bias in FA, the paper does not characterize its exact nature or compare it quantitatively to the bias of gradient descent. Understanding these differences is crucial for predicting when FA might outperform or underperform gradient descent.
- What evidence would resolve it: Rigorous analysis establishing the mathematical relationship between the implicit biases of FA and gradient descent, including conditions under which they align or diverge, and experimental results demonstrating the impact on generalization error across various network architectures and datasets.

### Open Question 3
- Question: Can the conservation law framework be extended to analyze other bio-plausible learning rules beyond FA, such as direct random target projection or Kolen-Pollack alignment?
- Basis in paper: [inferred] The conservation law reveals fundamental principles governing FA dynamics, suggesting that similar mathematical structures might exist for other bio-plausible learning rules that modify the backward pass.
- Why unresolved: The paper focuses exclusively on FA and its conservation laws. While the mathematical framework appears general, extending it to other learning rules would require deriving their specific conservation laws and analyzing the resulting dynamics.
- What evidence would resolve it: Derivation of conservation laws for other bio-plausible learning rules, followed by theoretical analysis of their convergence properties and empirical validation showing how these laws predict the behavior of these algorithms in practice.

## Limitations
- Conservation law proof assumes exact adherence to FA update rule, which may break under finite precision arithmetic
- Alignment conditions require specific initialization schemes that may not generalize to deeper networks
- Limited theoretical guarantees for non-linear activation functions beyond ReLU

## Confidence
- Conservation law proof: High
- Minimum-norm convergence for linear networks: Medium
- Alignment in non-linear networks: Low

## Next Checks
1. **Numerical robustness testing**: Verify the conservation law holds under finite precision arithmetic and with different learning rates and batch sizes
2. **Generalization to deeper architectures**: Test whether the conservation law and alignment properties extend to networks with 3+ layers and alternative activation functions
3. **Comparison with adaptive feedback schemes**: Evaluate performance against variants where feedback matrices evolve during training rather than remaining fixed