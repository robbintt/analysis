---
ver: rpa2
title: Responsible AI Research Needs Impact Statements Too
arxiv_id: '2311.11776'
source_url: https://arxiv.org/abs/2311.11776
tags:
- work
- research
- conference
- statements
- might
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Responsible AI research lacks explicit requirements to address
  possible adverse impacts, despite similar mandates in other AI communities. The
  authors argue for four key statements: researcher positionality (how background
  shapes work), ethical considerations (ethical issues during research), limitations
  (methodological constraints), and adverse impacts (potential harm once published).'
---

# Responsible AI Research Needs Impact Statements Too

## Quick Facts
- arXiv ID: 2311.11776
- Source URL: https://arxiv.org/abs/2311.11776
- Reference count: 12
- Primary result: RAI research lacks explicit adverse impact requirements despite similar mandates in other AI communities

## Executive Summary
This paper argues that responsible AI (RAI) research needs explicit impact statements similar to those required in other AI communities. The authors propose four key statements that RAI researchers should include: researcher positionality (how background shapes work), ethical considerations (ethical issues during research), limitations (methodological constraints), and adverse impacts (potential harm once published). These elements aim to improve critical reflection and transparency in RAI research. The authors also share their own positionality and impact statements to model the practice, acknowledging the risks and limitations of such requirements.

## Method Summary
The paper synthesizes existing practices from AI conferences that already require impact statements and proposes a framework for RAI research. It draws on guidelines from NeurIPS, ICML, ICLR, ACL, and RAI conferences like FAccT, AIES, FORC, and EAAMO. The authors provide examples and discuss how these four elements can be implemented in practice, while also modeling the approach by including their own statements in the paper.

## Key Results
- RAI research lacks explicit requirements to address possible adverse impacts
- Four key statements proposed: positionality, ethical considerations, limitations, and adverse impacts
- Authors model the practice by including their own positionality and impact statements
- Framework aims to improve critical reflection and transparency in RAI research

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Requiring explicit adverse impact statements in RAI papers improves critical reflection on potential harms.
- Mechanism: By making researchers articulate potential negative consequences, the requirement forces deeper engagement with possible societal harms that might otherwise be overlooked.
- Core assumption: Researchers can meaningfully anticipate adverse impacts of their work even without knowing exactly how it will be deployed.
- Evidence anchors:
  - [abstract] "We believe responsible AI research needs impact statements, too" - directly states the paper's central claim
  - [section] "To help others understand not only the benefits or positive outcomes, but also the possible harmful outcomes or adverse impacts of our own research" - explains the motivation
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.345, average citations=0.0. - weak corpus support
- Break condition: If researchers lack training in impact assessment, the statements become checkbox exercises rather than meaningful reflection.

### Mechanism 2
- Claim: Distinguishing between researcher positionality, ethical considerations, limitations, and adverse impacts creates clearer frameworks for critical reflection.
- Mechanism: Separating these elements helps researchers avoid conflating different types of reflection and ensures comprehensive coverage of potential issues.
- Core assumption: These four elements are distinct enough to warrant separate treatment and collectively capture the key dimensions of responsible research reflection.
- Evidence anchors:
  - [section] "By distinguishing between these four different elements of research practice and outcomes—which have at times been conflated—without being too prescriptive, we hope to provide both some clarity and guidance" - explicitly states the mechanism
  - [abstract] "The authors argue for four key statements: researcher positionality... ethical considerations... limitations... and adverse impacts" - lists the four elements
  - [corpus] Weak support - related papers focus on broader impact statements rather than this specific framework
- Break condition: If the distinctions between these elements are not meaningful in practice, researchers may struggle to categorize their reflections appropriately.

### Mechanism 3
- Claim: Modeling the practice by including positionality and impact statements in the paper itself demonstrates commitment and provides practical examples.
- Mechanism: Authors practicing what they preach increases credibility and shows how the recommendations can be implemented.
- Core assumption: Including these statements in the paper doesn't introduce excessive bias or create undue burden on authors.
- Evidence anchors:
  - [section] "We, however, recognize that authors might also be concerned about how such statements may end up disclosing axes of their identity that might negatively impact how their work is being perceived and evaluated" - acknowledges a key concern
  - [abstract] "The authors also share their own positionality and impact statements to model the practice" - states the modeling approach
  - [corpus] No direct corpus support for this specific modeling approach
- Break condition: If positionality statements inadvertently harm marginalized researchers or create reviewer bias, the modeling approach backfires.

## Foundational Learning

- Concept: Critical reflection in research
  - Why needed here: The paper's core argument is that RAI researchers need to develop better critical reflection practices about potential harms
  - Quick check question: Can you identify at least three different types of reflection that RAI researchers should engage in according to this paper?

- Concept: Research positionality
  - Why needed here: The paper introduces positionality statements as a distinct element that researchers should include
  - Quick check question: How does researcher positionality differ from ethical considerations in the framework proposed by this paper?

- Concept: Impact assessment in AI research
  - Why needed here: The paper draws on practices from other AI communities (NeurIPS, ICML, ACL) that already require impact statements
  - Quick check question: What are two key differences between how other AI communities handle impact statements versus what this paper proposes for RAI research?

## Architecture Onboarding

- Component map: Positionality statements -> Ethical considerations -> Limitations discussions -> Adverse impact statements
- Critical path: The most important sequence is: 1) develop positionality understanding → 2) identify ethical concerns during research → 3) document methodological limitations → 4) anticipate adverse impacts based on the previous three.
- Design tradeoffs: Requiring all four elements provides comprehensive coverage but may overwhelm researchers; making them optional risks incomplete reflection. The paper suggests venues could explore different formats to balance these concerns.
- Failure signatures: The approach fails when statements become checkbox exercises, when positionality statements inadvertently harm authors, or when the distinctions between elements become confusing rather than clarifying.
- First 3 experiments:
  1. Implement positionality statements only in a small subset of papers to test for unintended consequences before full rollout
  2. Compare quality of adverse impact statements when researchers receive training versus when they don't
  3. Test different formats (dedicated sections vs. integrated discussions) to determine which produces more meaningful reflection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can adverse impact statements be designed to minimize the psychological burden on researchers from marginalized backgrounds while maintaining their effectiveness?
- Basis in paper: [explicit] The paper acknowledges concerns about how positionality statements might inadvertently affect marginalized researchers and practitioners, and notes the psychological toll of RAI work on these individuals.
- Why unresolved: The paper identifies the risk but does not propose specific mechanisms to balance the need for impact statements with the well-being of marginalized researchers.
- What evidence would resolve it: Empirical studies comparing the impact of different impact statement formats on researchers from various backgrounds, or case studies of successful implementations that minimize burden while maintaining effectiveness.

### Open Question 2
- Question: What specific criteria should be used to determine when it is inappropriate to require adverse impact statements for certain types of RAI research?
- Basis in paper: [explicit] The paper notes that there might be situations where it is not appropriate to ask authors to include some or any of the statements, but does not specify what these situations might be.
- Why unresolved: The paper raises the possibility of inappropriate contexts but does not provide a framework for identifying them.
- What evidence would resolve it: Development and validation of a set of criteria or decision tree that researchers and reviewers can use to determine when impact statements are not suitable for a given research context.

### Open Question 3
- Question: How can the effectiveness of adverse impact statements be measured and evaluated over time?
- Basis in paper: [inferred] The paper argues for the importance of adverse impact statements but does not discuss methods for assessing their impact or effectiveness.
- Why unresolved: While the paper advocates for impact statements, it does not address how to determine if they are achieving their intended purpose of improving critical reflection and transparency.
- What evidence would resolve it: Longitudinal studies tracking changes in research practices, harm mitigation, and community discourse following the implementation of impact statement requirements, or development of metrics to assess the quality and depth of impact statements.

## Limitations
- Weak empirical evidence supporting the framework's effectiveness
- No concrete data on whether similar impact statement requirements have improved research quality in other communities
- Limited discussion of how to handle cases where researchers cannot anticipate certain adverse impacts
- Potential burden on researchers, particularly those from marginalized backgrounds

## Confidence

**High confidence**: The observation that responsible AI research lacks explicit adverse impact requirements, despite similar mandates in other AI communities

**Medium confidence**: The four-element framework (positionality, ethical considerations, limitations, adverse impacts) provides useful structure for research reflection

**Low confidence**: The proposed approach will significantly improve RAI research quality without creating unintended consequences like researcher burden or bias

## Next Checks
1. Conduct a systematic review of papers from conferences with mandatory impact statements (NeurIPS, ICML) to assess whether these requirements have demonstrably improved critical reflection on harms
2. Pilot the four-element framework with a diverse group of RAI researchers and measure both the quality of their statements and any changes in their research design process
3. Survey RAI conference organizers about their willingness to adopt impact statement requirements and their concerns about implementation