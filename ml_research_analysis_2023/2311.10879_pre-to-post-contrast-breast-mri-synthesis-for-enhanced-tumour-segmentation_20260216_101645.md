---
ver: rpa2
title: Pre- to Post-Contrast Breast MRI Synthesis for Enhanced Tumour Segmentation
arxiv_id: '2311.10879'
source_url: https://arxiv.org/abs/2311.10879
tags:
- post-contrast
- real
- synthetic
- image
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates the feasibility of generating synthetic
  contrast-enhanced breast MRI from pre-contrast images using a Pix2PixHD GAN model.
  The proposed Scaled Aggregate Measure (SAMe) combines perceptual and pixel-level
  metrics to evaluate synthetic data quality and select optimal model checkpoints.
---

# Pre- to Post-Contrast Breast MRI Synthesis for Enhanced Tumour Segmentation

## Quick Facts
- arXiv ID: 2311.10879
- Source URL: https://arxiv.org/abs/2311.10879
- Reference count: 39
- Key outcome: Synthetic contrast-enhanced breast MRI from pre-contrast images improves tumour segmentation robustness, particularly in domain shift scenarios.

## Executive Summary
This study demonstrates the feasibility of generating synthetic contrast-enhanced breast MRI from pre-contrast images using a Pix2PixHD GAN model. The proposed Scaled Aggregate Measure (SAMe) combines perceptual and pixel-level metrics to evaluate synthetic data quality and select optimal model checkpoints. The generated synthetic DCE-MRI improves breast tumour segmentation robustness, particularly in domain shift scenarios where only pre-contrast images are available for testing. Quantitative image quality metrics and downstream segmentation results show that synthetic images are semantically and perceptually close to real post-contrast images, enabling enhanced tumour segmentation performance without the need for contrast agent administration.

## Method Summary
The study uses a Pix2PixHD GAN to translate pre-contrast T1-weighted fat-saturated breast MRI to post-contrast DCE-MRI sequences. The model is trained on 668 cases from the Duke-Breast-Cancer-MRI Dataset, with 254 cases containing segmentation masks for validation and testing. Synthetic image quality is evaluated using a novel Scaled Aggregate Measure (SAMe) that combines SSIM, MSE, MAE, FID Img, and FID Rad metrics. A 3D U-Net segmentation model (nnU-Net framework) is trained with and without synthetic data augmentation to assess downstream performance improvements. The study employs 5-fold cross-validation and evaluates performance using Dice coefficient in both pre-contrast and post-contrast test domains.

## Key Results
- SAMe effectively combines multiple quality metrics to select optimal GAN checkpoints and evaluate synthetic image quality
- Synthetic post-contrast augmentations improve post-contrast Dice coefficient by 0.179 compared to baseline
- Synthetic data augmentation demonstrates more substantial Dice score improvement of 0.245 in pre-contrast test domain
- Quantitative metrics (FID, SSIM, MSE, MAE) confirm synthetic images are semantically and perceptually close to real post-contrast images

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Pix2PixHD GAN architecture is effective for translating pre-contrast breast MRI to post-contrast images.
- Mechanism: Pix2PixHD employs a global generator for overall image consistency and a local enhancer for fine details, paired with two discriminators at different image scales. This dual-scale approach allows the model to capture both global structural context and localized contrast enhancement patterns necessary for realistic synthetic post-contrast images.
- Core assumption: Pre-contrast and post-contrast breast MRI share sufficient structural similarity for effective paired translation, with contrast enhancement being a consistent local modification.
- Evidence anchors:
  - [abstract] "translating pre-contrast T1-weighted fat-saturated breast MRI to their corresponding first DCE-MRI sequence leveraging the capabilities of a generative adversarial network (GAN)"
  - [section] "Pix2PixHD is chosen due to its capabilities of generating high-quality cancer imaging data 12 and due to its network architecture and methodological setup specifically designed for paired image-to-image (i.e., pre-to-post-contrast) translation."
- Break condition: If pre-contrast and post-contrast images differ too greatly in structure or if contrast enhancement patterns are highly variable across patients, the paired translation approach may fail to produce realistic synthetic images.

### Mechanism 2
- Claim: The Scaled Aggregate Measure (SAMe) effectively combines perceptual and pixel-level metrics for synthetic data quality assessment and model checkpoint selection.
- Mechanism: SAMe normalizes and averages multiple complementary metrics (SSIM, MSE, MAE, FID Img, FID Rad) to create a unified quality measure. This approach balances perceptual similarity, pixel-level accuracy, and domain-specific feature distributions, addressing the inconsistency between different individual metrics.
- Core assumption: Different quality metrics capture different aspects of image similarity, and their combination provides a more comprehensive and reliable assessment than any single metric alone.
- Evidence anchors:
  - [abstract] "we introduce a Scaled Aggregate Measure (SAMe) designed for quantitatively evaluating the quality of synthetic data in a principled manner and serving as a basis for selecting the optimal generative model"
  - [section] "SAMe combines analytical measures (SSIM, MAE, MSE) with latent features of neural networks (FID), with the latter being further divided into domain-agnostic (FID Img) and radiology domain-specific (FID Rad) features to capture different pieces of relevant information in the evaluated synthetic images."
- Break condition: If the selected metrics are not representative of the aspects of image quality most relevant to the downstream task, SAMe may not provide an optimal basis for model selection.

### Mechanism 3
- Claim: Synthetic post-contrast DCE-MRI data improves breast tumour segmentation robustness, particularly in domain shift scenarios.
- Mechanism: By augmenting real pre-contrast training data with synthetic post-contrast images, the segmentation model learns to generalize better to post-contrast test data even when trained only on pre-contrast images. This addresses the domain shift between training and testing distributions.
- Core assumption: Synthetic post-contrast images are sufficiently similar to real post-contrast images in terms of tumour characteristics and contrast enhancement patterns to enable effective learning transfer.
- Evidence anchors:
  - [abstract] "Our results highlight the potential of post-contrast DCE-MRI synthesis in enhancing the robustness of breast tumour segmentation models via data augmentation."
  - [section] "training with real pre-contrast augmented by synthetic post-contrast images improves the post-contrast Dice coefficient by 0.179 (i.e., from 0.484 to 0.663) compared to the baseline while maintaining a comparative level of performance in the pre-contrast domain."
- Break condition: If synthetic images contain significant artefacts or fail to accurately represent tumour contrast enhancement, the augmented training data may degrade rather than improve segmentation performance.

## Foundational Learning

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: The core technology for generating synthetic post-contrast breast MRI images is based on GANs, specifically Pix2PixHD for paired image-to-image translation.
  - Quick check question: What are the two main components of a GAN and what are their respective objectives during training?

- Concept: Image quality metrics (FID, SSIM, MSE, MAE)
  - Why needed here: These metrics are essential for evaluating the quality of synthetic images and selecting the optimal model checkpoint, as demonstrated by the introduction of SAMe.
  - Quick check question: How does the Frchet Inception Distance (FID) differ from pixel-level metrics like MSE in assessing image quality?

- Concept: Domain adaptation and domain shift
  - Why needed here: The study explicitly addresses the challenge of training segmentation models on pre-contrast data but testing on post-contrast data, highlighting the importance of domain adaptation techniques.
  - Quick check question: What is the difference between in-domain and cross-domain generalization in medical image analysis?

## Architecture Onboarding

- Component map:
  Duke-Breast-Cancer-MRI Dataset (922 cases, pre-contrast and post-contrast sequences) -> Pix2PixHD GAN (global generator + local enhancer + two discriminators) -> SAMe (ensemble of SSIM, MSE, MAE, FID Img, FID Rad) -> 3D U-Net segmentation model (nnU-Net framework, 5-fold cross-validation)

- Critical path:
  1. Preprocess and prepare paired pre-contrast and post-contrast image slices
  2. Train Pix2PixHD GAN to generate synthetic post-contrast images
  3. Evaluate synthetic image quality using SAMe and individual metrics
  4. Select optimal model checkpoint based on SAMe
  5. Generate synthetic post-contrast images for segmentation experiments
  6. Train and evaluate 3D U-Net segmentation models with and without synthetic data augmentation

- Design tradeoffs:
  - 2D vs. 3D synthesis: The study uses 2D slice-based synthesis for computational efficiency, but 3D synthesis could capture more comprehensive tumour characteristics
  - Single vs. multiple modalities: The approach focuses on T1-weighted MRI, but incorporating additional modalities (e.g., DWI) could provide more information
  - Synthetic vs. real augmentation: While synthetic data augmentation improves performance in domain shift scenarios, it may introduce artefacts that could negatively impact segmentation

- Failure signatures:
  - Poor FID scores indicating synthetic images are not similar to real post-contrast images
  - Low SSIM scores suggesting poor perceptual quality
  - High MSE/MAE scores indicating significant pixel-level differences
  - Segmentation performance worse than baseline when using synthetic data augmentation
  - Hallucinations or false-positive contrast regions in synthetic images

- First 3 experiments:
  1. Train Pix2PixHD GAN on the full training set (668 cases) for 200 epochs, evaluating SAMe at each epoch to select the optimal checkpoint
  2. Generate synthetic post-contrast images for the validation set (224 cases) and evaluate image quality metrics (FID, SSIM, MSE, MAE)
  3. Perform ablation study comparing segmentation performance with and without synthetic data augmentation in different domain shift scenarios (pre-contrast training to post-contrast testing)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the quality of synthetic post-contrast images generated from pre-contrast images compare to real post-contrast images in terms of tumor detection accuracy, and what are the specific characteristics of the synthetic images that contribute to this accuracy?
- Basis in paper: [explicit] The paper discusses the potential of synthetic DCE-MRI to enhance breast tumour segmentation robustness, particularly in domain shift scenarios where only pre-contrast images are available for testing. It mentions that synthetic images are semantically and perceptually close to real post-contrast images.
- Why unresolved: The paper does not provide a detailed comparison of tumor detection accuracy between synthetic and real post-contrast images, nor does it delve into the specific characteristics of the synthetic images that contribute to this accuracy.
- What evidence would resolve it: A detailed study comparing the tumor detection accuracy of synthetic post-contrast images to real post-contrast images, along with an analysis of the specific characteristics of the synthetic images that contribute to this accuracy.

### Open Question 2
- Question: What is the optimal ratio of pre-contrast to synthetic post-contrast images in the training dataset to maximize the performance of the tumor segmentation model?
- Basis in paper: [explicit] The paper mentions that synthetic post-contrast augmentations improve the post-contrast Dice coefficient by 0.179 compared to the baseline, and that synthetic post-contrast augmentations demonstrate a more substantial Dice score improvement of 0.245 in the pre-contrast test domain.
- Why unresolved: The paper does not specify the optimal ratio of pre-contrast to synthetic post-contrast images in the training dataset to maximize the performance of the tumor segmentation model.
- What evidence would resolve it: An experimental study varying the ratio of pre-contrast to synthetic post-contrast images in the training dataset and evaluating the performance of the tumor segmentation model for each ratio.

### Open Question 3
- Question: How does the performance of the tumor segmentation model trained on synthetic post-contrast images compare to the model trained on real post-contrast images in terms of generalizability to unseen data?
- Basis in paper: [explicit] The paper mentions that the synthetic post-contrast data provides relevant pre-contrast signals that allow the post-contrast segmentation model to better generalise to pre-contrast test data.
- Why unresolved: The paper does not provide a direct comparison of the generalizability of the tumor segmentation model trained on synthetic post-contrast images to the model trained on real post-contrast images.
- What evidence would resolve it: A comparative study evaluating the generalizability of the tumor segmentation model trained on synthetic post-contrast images to the model trained on real post-contrast images using a separate, unseen dataset.

## Limitations
- Reliance on single institutional dataset (Duke-Breast-Cancer-MRI) limits generalizability to other MRI scanners and protocols
- 2D slice-based synthesis approach may miss 3D volumetric tumour characteristics
- Study does not evaluate synthetic image quality from clinical perspective (e.g., radiologist assessment)

## Confidence
- **High confidence**: The feasibility of generating synthetic DCE-MRI using Pix2PixHD GAN and the improvement in tumour segmentation performance with synthetic data augmentation in domain shift scenarios
- **Medium confidence**: The effectiveness of SAMe as a comprehensive metric for synthetic data quality assessment and the clinical relevance of the generated synthetic images
- **Low confidence**: The generalizability of the approach to other MRI scanners, protocols, and institutions, and the impact of synthetic data augmentation on downstream clinical tasks beyond tumour segmentation

## Next Checks
1. Evaluate synthetic image quality and segmentation performance on an external dataset with different MRI scanner models and acquisition protocols to assess generalizability
2. Conduct a reader study with radiologists to assess the clinical relevance and potential diagnostic utility of the generated synthetic post-contrast images
3. Investigate the impact of synthetic data augmentation on other downstream clinical tasks, such as lesion characterization and treatment response prediction, to evaluate broader applicability