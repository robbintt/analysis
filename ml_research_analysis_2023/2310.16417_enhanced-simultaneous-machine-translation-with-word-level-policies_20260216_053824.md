---
ver: rpa2
title: Enhanced Simultaneous Machine Translation with Word-level Policies
arxiv_id: '2310.16417'
source_url: https://arxiv.org/abs/2310.16417
tags:
- word-level
- word
- wait-k
- translation
- simt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that policies designed and validated at
  the subword level in simultaneous machine translation (SiMT) can be surpassed by
  word-level policies, which process multiple subwords to form a complete word in
  a single step. It proposes word-level latency metric calculation to enable consistent
  comparisons across different systems and a conversion process to transform token-level
  policies into word-level policies.
---

# Enhanced Simultaneous Machine Translation with Word-level Policies

## Quick Facts
- **arXiv ID:** 2310.16417
- **Source URL:** https://arxiv.org/abs/2310.16417
- **Reference count:** 40
- **Key outcome:** Word-level policies in simultaneous machine translation consistently outperform token-level policies by up to 2.0 BLEU points while reducing latency.

## Executive Summary
This paper introduces word-level policies for simultaneous machine translation (SiMT), demonstrating that processing entire words rather than individual subwords significantly improves both translation quality and latency. The authors show that token-level policies devised for subword tokenization are outperformed by word-level alternatives that make decisions at word boundaries. They propose a word-level latency metric to enable fair comparisons across different systems and demonstrate how word-level policies enable effective integration of language models by addressing vocabulary mismatch issues. Experiments across three SiMT policy types (Wait-k, MoE Wait-k, and ITST) and two language pairs (English-French and German-English) show consistent improvements in BLEU scores of up to 2.0 points.

## Method Summary
The authors propose three main contributions: (1) word-level policies that make READ/WRITE decisions at word boundaries rather than subword tokens, (2) a word-level latency metric (Average Lagging) for fair system comparisons, and (3) a method for integrating language models into SiMT systems using word-level policies to address vocabulary mismatch. The approach involves converting token-level policies to word-level equivalents, implementing intra-word bidirectional encoding to handle incomplete words during encoding, and fusing language model representations at word boundaries. The experiments use Transformer-based models with SentencePiece BPE tokenization (32k vocabulary) trained on IWSLT17 En-Fr and WMT15 De-En datasets.

## Key Results
- Word-level policies outperform token-level counterparts by 0.8-2.0 BLEU points across all tested SiMT policy types
- LM integration using word-level policies further improves translation quality while addressing vocabulary mismatch issues
- Word-level latency metrics provide more accurate and comparable measurements than token-level metrics
- The proposed method is effective across different SiMT policy architectures including Wait-k, MoE Wait-k, and ITST

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Word-level policies reduce latency and improve BLEU scores compared to token-level policies in SiMT.
- Mechanism: By processing entire words rather than individual subwords, word-level policies minimize the number of read/write operations required to produce translations. This reduces latency because the system doesn't need to wait for each subword boundary to make a translation decision. Additionally, word-level policies improve translation quality by providing more complete contextual information for each decision, as the model can access the full semantic content of a word before translating it.
- Core assumption: The latency experienced in SiMT applications is primarily determined by the number of read/write operations, and that complete word information is necessary for accurate translation.
- Evidence anchors:
  - [abstract] "This paper demonstrates that policies devised and validated at the subword level are surpassed by those operating at the word level, which process multiple subwords to form a complete word in a single step."
  - [section 3.3] "The proposed word-level policy restricts a SiMT policy's transition from READ to WRITE or vice versa to occur exclusively at the boundaries of words."
  - [corpus] Weak evidence - the corpus does not contain specific studies comparing word-level and token-level policies in SiMT.

### Mechanism 2
- Claim: Word-level latency metric calculation enables consistent comparisons between different SiMT systems.
- Mechanism: By measuring latency at the word level, rather than the subword level, the latency metric calculation becomes independent of the specific tokenization and encoding schemes used by different systems. This allows for fair and accurate comparisons of latency performance across different SiMT systems, regardless of their internal implementation details.
- Core assumption: The actual latency experienced by users of SiMT applications is primarily determined by the time it takes to process and display complete words, rather than individual subwords.
- Evidence anchors:
  - [section 3.2] "Specifically, when the first token of a source word is processed through a READ operation, we consider it as reading the corresponding word."
  - [section 3.2] "This ensures that results from different systems can be compared fairly."
  - [corpus] Weak evidence - the corpus does not contain studies specifically addressing the need for consistent latency metric calculation in SiMT.

### Mechanism 3
- Claim: Integrating language models (LMs) into SiMT systems using word-level policies effectively addresses vocabulary mismatch issues.
- Mechanism: By using word-level policies, the SiMT system can process and align with the LM at word boundaries, ensuring that both models are working with the same amount of input prefix at each translation step. This synchronization allows the SiMT system to use an in-domain vocabulary while the LM can continue to use its original vocabulary, without requiring additional training or vocabulary bridging techniques.
- Core assumption: The vocabulary mismatch between LMs and SiMT models is a significant obstacle to their integration, and that word-level policies can effectively synchronize the processing of both models.
- Evidence anchors:
  - [section 3.5] "Our study demonstrates that our proposed word-level policy effectively tackles this challenge, enabling a successful integration of LMs into SiMT systems."
  - [section 5.2] "The models with word-level policies consistently outperform those with token-level policies by a significant margin in both LM-fused attention and LM embedding settings."
  - [corpus] Weak evidence - the corpus does not contain studies specifically addressing the integration of LMs into SiMT systems using word-level policies.

## Foundational Learning

- Concept: Simultaneous Machine Translation (SiMT)
  - Why needed here: Understanding the basic principles of SiMT is crucial for grasping the significance of the proposed word-level policies and their impact on latency and translation quality.
  - Quick check question: What is the main challenge in SiMT that the proposed word-level policies aim to address?

- Concept: Byte Pair Encoding (BPE) and subword tokenization
  - Why needed here: Familiarity with BPE and subword tokenization is essential for understanding the context in which word-level policies are proposed as an improvement over token-level policies.
  - Quick check question: How does BPE tokenization affect the granularity of decisions made by SiMT policies?

- Concept: Language model (LM) integration in machine translation
  - Why needed here: Understanding the challenges and benefits of integrating LMs into machine translation systems is crucial for appreciating the role of word-level policies in addressing vocabulary mismatch issues.
  - Quick check question: What are the main obstacles to integrating LMs into SiMT systems, and how do word-level policies help overcome them?

## Architecture Onboarding

- Component map: SiMT model with word-level policy -> Language model (LM) -> Word-level latency metric calculation -> Intra-word bidirectional encoding
- Critical path: The SiMT model processes source words using the word-level policy, integrates LM representations when necessary, and generates target words while minimizing latency.
- Design tradeoffs: The main tradeoff is between latency and translation quality. Word-level policies may introduce slightly higher latency compared to token-level policies, but they significantly improve translation quality by providing more complete contextual information.
- Failure signatures: If the word segmentation is not aligned with semantic boundaries, the word-level policies may introduce unnecessary latency without improving translation quality. Additionally, if the LM's vocabulary is too dissimilar from the in-domain vocabulary, the LM integration may not be effective.
- First 3 experiments:
  1. Compare the performance of a token-level Wait-k policy and its word-level counterpart on a standard SiMT benchmark dataset, measuring both latency and BLEU scores.
  2. Implement the word-level latency metric calculation and compare the latency scores of different SiMT systems using both token-level and word-level metrics.
  3. Integrate an LM into a SiMT system using word-level policies and compare its performance to a system without LM integration, as well as to a system using token-level policies for LM integration.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would word-level policies perform on languages with writing systems that lack clear word boundaries (e.g., Chinese)?
- Basis in paper: [explicit] The paper explicitly states that word-level policies cannot be applied to languages like Chinese due to the lack of spaces or other delimiters between words.
- Why unresolved: The paper does not explore alternative approaches or modifications to word-level policies that could potentially work for such languages.
- What evidence would resolve it: Experimental results comparing word-level policies with alternative approaches (e.g., character-level or subword-level policies) on Chinese simultaneous translation tasks would provide insight into the feasibility of adapting word-level policies for such languages.

### Open Question 2
- Question: What is the optimal trade-off between the size of the language model and the computational efficiency of the SiMT system?
- Basis in paper: [inferred] The paper mentions that integrating a large language model may require faster compute capabilities to meet the low-latency demands of SiMT, suggesting a trade-off between model size and efficiency.
- Why unresolved: The paper does not provide a systematic analysis of how different language model sizes impact both translation quality and latency across various SiMT systems.
- What evidence would resolve it: A comprehensive study evaluating the performance of SiMT systems with different language model sizes on both translation quality and latency metrics would help determine the optimal balance.

### Open Question 3
- Question: How do word-level policies impact the robustness of SiMT systems to noisy or out-of-domain input?
- Basis in paper: [inferred] The paper focuses on improving translation quality and latency but does not investigate the impact of word-level policies on the system's ability to handle noisy or out-of-domain input.
- Why unresolved: The robustness of SiMT systems to such input is crucial for real-world applications, and it remains unclear how word-level policies influence this aspect.
- What evidence would resolve it: Experiments evaluating the performance of word-level and token-level policies on noisy or out-of-domain data would provide insights into the robustness of word-level policies.

## Limitations
- The evaluation focuses primarily on two language pairs (En-Fr and De-En) with relatively clean segmentation, limiting generalizability to languages with complex morphology or non-space-delimited scripts.
- The word-level latency metric relies on SentencePiece BPE tokenization which may not align with natural word boundaries in all languages.
- The LM integration experiments lack comprehensive ablation studies to isolate the contribution of word-level policies versus other architectural choices.

## Confidence
- **High confidence**: Word-level policies improve BLEU scores over token-level counterparts within the tested language pairs and domains.
- **Medium confidence**: Word-level latency metric provides fairer comparisons across systems.
- **Medium confidence**: LM integration via word-level policies effectively addresses vocabulary mismatch.

## Next Checks
1. **Cross-linguistic generalization test**: Evaluate word-level policies on languages with non-space-delimited scripts (e.g., Chinese, Japanese) or rich morphology (e.g., Turkish, Finnish) to assess performance beyond the tested European language pairs.

2. **Ablation study on LM integration**: Systematically compare LM-fused attention with alternative integration methods (shallow fusion, deep fusion) while keeping the word-level policy constant to isolate the specific contribution of the word-level approach.

3. **Real-time user experience validation**: Implement a live demo comparing token-level and word-level policies with human users performing realistic tasks (chat translation, live subtitling) to measure actual perceived latency versus calculated AL metrics.