---
ver: rpa2
title: Evaluating Self-supervised Speech Models on a Taiwanese Hokkien Corpus
arxiv_id: '2312.06668'
source_url: https://arxiv.org/abs/2312.06668
tags:
- taiwanese
- speech
- dataset
- mandarin
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a 1.5-hour dataset of Taiwanese Hokkien drama
  speech, contributing to ML-SUPERB's hidden set. The authors evaluate various self-supervised
  speech models on this low-resource language, finding that model size does not consistently
  determine performance.
---

# Evaluating Self-supervised Speech Models on a Taiwanese Hokkien Corpus

## Quick Facts
- arXiv ID: 2312.06668
- Source URL: https://arxiv.org/abs/2312.06668
- Reference count: 0
- Key outcome: 1.5-hour Taiwanese Hokkien drama dataset contributes to ML-SUPERB's hidden set; smaller models like HuBERT-base-cmn and XLSR-128 sometimes outperform larger ones

## Executive Summary
This paper presents a 1.5-hour dataset of Taiwanese Hokkien drama speech and evaluates various self-supervised speech models on this low-resource language. The study finds that model size does not consistently determine performance, with smaller models like HuBERT-base-cmn and XLSR-128 outperforming larger ones in some cases. The key determinant of success is the quality and linguistic alignment of the pretraining data, particularly the similarity between pretraining and target languages. The research identifies tone sandhi errors and phonetically similar phones as primary sources of prediction errors.

## Method Summary
The study uses a 1.5-hour Taiwanese Hokkien drama dataset with gold Mandarin subtitles and Taiwanese annotations. Data is preprocessed by converting diacritics to number tones, removing dashes, and tokenizing syllables into initials and finals. The researchers fine-tune ML-SUPERB's suite of self-supervised learning (SSL) speech representations using the ESPnet toolkit, evaluating performance using Character Error Rate (CER) and Syllable Error Rate (SER).

## Key Results
- Model size does not consistently determine performance in low-resource settings
- Linguistic alignment between pretraining data and target language is crucial for model success
- Tone sandhi errors and phonetically similar phone confusion are primary sources of prediction errors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linguistic alignment between pretraining data and target language is the primary determinant of model performance
- Mechanism: When pretraining data shares similar phonological, morphological, and syntactic features with the target language, the learned representations transfer more effectively
- Core assumption: Speech models can leverage structural similarities across related languages for better performance
- Evidence anchors:
  - [abstract]: "linguistic alignment between pretraining data and the target language plays a crucial role"
  - [section]: "This finding suggests that merely increasing the quantity of pretraining data is not the sole determinant of better performance; the linguistic alignment between the pretraining data and the target language plays a crucial role"
  - [corpus]: Weak - no direct corpus evidence, but related papers show similar patterns
- Break condition: When pretraining and target languages share minimal linguistic features (e.g., Mandarin vs. completely unrelated language)

### Mechanism 2
- Claim: Model size does not consistently determine performance for low-resource languages
- Mechanism: In low-resource settings, the quality and relevance of pretraining data outweighs the benefits of larger model capacity
- Core assumption: Larger models require proportionally more relevant data to realize their performance advantages
- Evidence anchors:
  - [abstract]: "model size does not consistently determine performance. In fact, certain smaller models outperform larger ones"
  - [section]: "wav2vec2-base-23, built on a larger and diverse multilingual dataset, underperforms on our specific dataset"
  - [corpus]: Weak - corpus doesn't directly test this mechanism but supports the claim
- Break condition: When sufficient high-quality, linguistically-aligned data becomes available

### Mechanism 3
- Claim: Phonetic similarity between pretraining and target languages causes confusion in speech recognition
- Mechanism: Models trained on phonetically similar languages may confuse phones that are acoustically close, leading to prediction errors
- Core assumption: Speech models rely on acoustic-phonetic features that can be confused across similar languages
- Evidence anchors:
  - [section]: "the model tends to confuse phonetically similar sounds, such as predicting 'tsi' [t͡ ɕi] instead of 'ji' [d ͡ ʑi] (both of which include affricates)"
  - [section]: "we observed tone errors in the predictions, with some errors aligning with tone sandhi rules"
  - [corpus]: Weak - corpus doesn't directly test this but provides context for why it occurs
- Break condition: When pretraining data includes sufficient diversity to distinguish similar phones or when explicit phonetic distinctions are modeled

## Foundational Learning

- Concept: Tone sandhi in Sinitic languages
  - Why needed here: Taiwanese Hokkien has complex tone sandhi rules that affect syllable pronunciation, and models must learn to map sandhi tones back to base tones for correct romanization
  - Quick check question: How does tone sandhi in Taiwanese Hokkien differ from Mandarin, and why is this important for romanization?

- Concept: Cross-lingual transfer in speech representation learning
  - Why needed here: The paper relies on pretraining models on Mandarin or multilingual data and transferring to Taiwanese Hokkien, requiring understanding of when and how cross-lingual transfer works
  - Quick check question: What linguistic features enable effective cross-lingual transfer between Mandarin and Taiwanese Hokkien?

- Concept: Self-supervised learning for speech
  - Why needed here: The paper evaluates multiple SSL models (wav2vec2, HuBERT, XLSR) and their effectiveness depends on understanding how these models learn from unlabeled speech
  - Quick check question: How do SSL speech models like HuBERT and wav2vec2 learn meaningful representations without transcribed data?

## Architecture Onboarding

- Component map: YouTube crawling → audio extraction → music removal → manual alignment → machine translation-assisted annotation → human transcription → Preprocessing (diacritics to numbers, tokenization) → Model training (weighted SSL representations + SpecAugment + downsampling + Transformer + CTC) → Evaluation (CER/SER)
- Critical path: Data collection → annotation → preprocessing → model training → evaluation → analysis
- Design tradeoffs: Using Taiwanese romanization vs. Han characters enables syllable-level modeling but requires handling tone sandhi; machine translation assistance speeds annotation but introduces segmentation errors; preprocessing choices affect tokenization and error metrics
- Failure signatures: High CER/SER across all models suggests data quality issues; specific phonetic confusion patterns suggest pretraining data limitations; tone errors suggest inadequate handling of tone sandhi
- First 3 experiments:
  1. Test different tokenization strategies (syllable-level vs. initial-final) on a small subset to determine optimal granularity
  2. Compare model performance with and without music source separation to quantify its impact
  3. Evaluate a model trained only on Mandarin data vs. one trained on multilingual data to isolate the effect of pretraining language diversity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do smaller models like HuBERT-base-cmn and XLSR-128 outperform larger models in some cases?
- Basis in paper: [explicit] The paper states that "model size does not consistently determine performance" and that "certain smaller models outperform larger ones."
- Why unresolved: The paper suggests that the quality and linguistic alignment of pretraining data play a crucial role, but does not provide a definitive explanation for the performance differences between smaller and larger models.
- What evidence would resolve it: Comparative studies analyzing the pretraining data quality, linguistic alignment, and architectural differences between smaller and larger models could provide insights into the performance disparities.

### Open Question 2
- Question: How can tone sandhi errors be effectively addressed in Taiwanese ASR?
- Basis in paper: [explicit] The paper identifies tone sandhi errors as a primary source of prediction errors and suggests that future research should prioritize improving tone accuracy.
- Why unresolved: While the paper acknowledges the importance of addressing tone sandhi errors, it does not provide specific solutions or methodologies for improving tone accuracy in Taiwanese ASR.
- What evidence would resolve it: Development and evaluation of specialized models or techniques for tone sandhi prediction and handling in Taiwanese ASR could provide evidence for effective solutions.

### Open Question 3
- Question: What are the primary sources of phonetically similar phone confusion in Taiwanese ASR?
- Basis in paper: [explicit] The paper mentions that the model tends to confuse phonetically similar sounds, such as "tsi" [t͡ ɕi] instead of "ji" [d ͡ ʑi], "o" [o] instead of "oo" [ɔ], and "h" [ʔ] instead of "p" [p].
- Why unresolved: The paper does not provide a detailed analysis of the specific factors contributing to the confusion of phonetically similar phones in Taiwanese ASR.
- What evidence would resolve it: In-depth phonetic and phonological analysis of Taiwanese, along with experimental studies isolating the effects of different factors (e.g., speaker variation, audio quality) on phone confusion, could provide insights into the primary sources of this issue.

## Limitations

- Small dataset size (1.5 hours) limits statistical power and may not capture full linguistic diversity
- Dataset consists exclusively of drama speech, which may not represent other domains like news or conversations
- Manual annotation process introduces potential human error and inconsistency

## Confidence

- **High Confidence**: The finding that linguistic alignment between pretraining and target languages is crucial for performance
- **Medium Confidence**: The analysis of error patterns (tone sandhi errors and phonetically similar phones) based on qualitative examination
- **Low Confidence**: Broader implications for low-resource ASR development across all languages

## Next Checks

1. **Cross-linguistic generalization test**: Evaluate the same model family (e.g., HuBERT-base-cmn) on another Sinitic language (like Cantonese or Hakka) to determine if the linguistic alignment principle generalizes beyond the Mandarin-Taiwanese Hokkien pair.

2. **Controlled pretraining data experiment**: Create a controlled experiment where models are trained on Mandarin data with varying degrees of phonological similarity to Taiwanese Hokkien (e.g., Mandarin with and without certain tone sandhi patterns) to isolate which linguistic features most impact transfer performance.

3. **Data augmentation impact assessment**: Implement data augmentation techniques (speed perturbation, noise injection, vocal tract length perturbation) on the 1.5-hour dataset and measure whether these techniques can partially compensate for the lack of linguistically-aligned pretraining data.