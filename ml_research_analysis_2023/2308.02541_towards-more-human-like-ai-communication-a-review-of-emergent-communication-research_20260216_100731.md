---
ver: rpa2
title: 'Towards More Human-like AI Communication: A Review of Emergent Communication
  Research'
arxiv_id: '2308.02541'
source_url: https://arxiv.org/abs/2308.02541
tags:
- communication
- learning
- language
- agents
- emergent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper reviews emergent communication (EmCom) research, which
  aims to develop artificial agents capable of using natural language in complex environments.
  The author argues that while large language models are commonly used, they may not
  capture the underlying structure and reasoning humans employ in using natural language.
---

# Towards More Human-like AI Communication: A Review of Emergent Communication Research

## Quick Facts
- arXiv ID: 2308.02541
- Source URL: https://arxiv.org/abs/2308.02541
- Reference count: 40
- One-line primary result: Reviews emergent communication research and categorizes approaches into machine-centered and human-centered frameworks

## Executive Summary
This paper provides a comprehensive review of emergent communication (EmCom) research, examining how artificial agents can develop communication protocols that mirror human language capabilities. The author argues that while large language models excel at pattern recognition, they may not capture the underlying structure and reasoning humans employ in natural language use. The review identifies four key properties in EmCom literature—game environment, learning paradigm, interaction type, and theory of mind—and distinguishes between machine-centered approaches that focus on artificial emergent languages and human-centered approaches that emphasize natural language use. The paper calls for greater collaboration between researchers and emphasizes the importance of including diverse perspectives in advancing the field.

## Method Summary
The paper employs a systematic literature review approach, analyzing 40 references across emergent communication research to identify common patterns and frameworks. The methodology involves categorizing research based on game environments, learning paradigms (supervised vs. reinforcement learning), interaction types (cooperation vs. competition), and theory of mind modeling. The review synthesizes findings across these dimensions to develop a conceptual framework for understanding different approaches to emergent communication, distinguishing between machine-centered and human-centered methodologies while highlighting their respective strengths and limitations.

## Key Results
- Emergent communication research can be categorized into machine-centered approaches (artificial emergent languages) and human-centered approaches (natural language focus)
- Four common properties define EmCom research: game environment design, learning paradigm selection, interaction type, and theory of mind implementation
- The balance between supervised and reinforcement learning significantly impacts whether emergent languages remain human-like or drift toward degenerate forms
- Theory of mind modeling enables more sophisticated and adaptive communication protocols between agents

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Game environments shape emergent communication by forcing agents to develop languages that solve specific tasks
- Mechanism: The environment defines input representations and communication roles that create pressure for agents to develop compositional, generalizable languages
- Core assumption: Agents learn to communicate effectively when environmental constraints require coordination beyond simple pattern matching
- Evidence anchors:
  - [abstract] "the need for machines to accurately use natural language has become increasingly important"
  - [section 2.1] "Game design is an essential aspect of emergent communication research, as it defines the environment in which agents interact and communicate"
  - [corpus] Weak - no direct corpus evidence for this specific mechanism, though related papers discuss environment design
- Break condition: If agents can solve tasks through memorization rather than communication, or if input representations are too simple to require language development

### Mechanism 2
- Claim: The balance between supervised and reinforcement learning determines whether emergent languages drift toward human-like or degenerate forms
- Mechanism: Supervised learning provides grounding in human language structure while reinforcement learning enables adaptation to task-specific communication needs
- Core assumption: Language drift occurs when agents optimize only for task completion without maintaining connection to human language patterns
- Evidence anchors:
  - [abstract] "this method presents a form of learning misalignment where the model may not capture the underlying structure and reasoning humans employ"
  - [section 3.2.2] "balance between the two" referring to supervised and reinforcement learning
  - [corpus] Weak - corpus doesn't directly address this specific balance mechanism
- Break condition: If either learning paradigm dominates completely, or if the balance cannot be maintained during training

### Mechanism 3
- Claim: Theory of Mind enables emergent communication to develop protocols that are interpretable and adaptive to different agents
- Mechanism: Agents that model other agents' beliefs and behaviors can develop more sophisticated communication strategies that generalize across different partners
- Core assumption: Understanding and influencing other agents' cognitive states is necessary for developing flexible communication protocols
- Evidence anchors:
  - [section 2.4] "The concept of Theory of Mind is a crucial aspect of human behavior that has been modeled in the EmCom field"
  - [section 2.4.1] "modeling other agents is well-established in the field of multi-agent reinforcement learning"
  - [corpus] Weak - corpus evidence doesn't directly support this mechanism
- Break condition: If agents cannot effectively model other agents' states, or if communication protocols become too specialized to individual partners

## Foundational Learning

- Concept: Multi-agent reinforcement learning
  - Why needed here: EmCom fundamentally involves multiple agents learning to communicate through interaction in shared environments
  - Quick check question: Can you explain the difference between single-agent and multi-agent reinforcement learning and why it matters for communication emergence?

- Concept: Information bottleneck principle
  - Why needed here: The tradeoff between compression and accuracy in language emergence directly relates to how agents balance expressiveness with efficiency
  - Quick check question: How does the information bottleneck relate to the emergence of compositional language in artificial agents?

- Concept: Theory of Mind in artificial agents
  - Why needed here: Modeling other agents' beliefs and behaviors is crucial for developing adaptive and interpretable communication protocols
  - Quick check question: What are the two main approaches to implementing Theory of Mind in emergent communication systems?

## Architecture Onboarding

- Component map: Game environment -> Sender agent -> Communication channel -> Receiver agent -> Learning algorithm module -> Evaluation metrics
- Critical path: Environment setup → Agent initialization → Communication channel definition → Learning algorithm selection → Training loop → Evaluation and analysis
- Design tradeoffs: Discrete vs continuous communication channels, symbolic vs natural language, task-specific vs general communication protocols
- Failure signatures: Language drift from human patterns, degenerate communication protocols, failure to generalize to new concepts, excessive memorization
- First 3 experiments:
  1. Simple referential game with symbolic inputs and discrete communication to establish baseline performance
  2. Same game with natural language inputs and continuous communication to compare emergence patterns
  3. Multi-step communication game with varying agent populations to study iterative learning effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we design learning paradigms and neural networks that inherently favor generalization over memorization in artificial agents?
- Basis in paper: [explicit] The paper suggests that artificial agents possess exceptional memory capabilities, enabling them to discover communicative shortcuts and resulting in degenerate languages that are more akin to holistic languages rather than compositional ones. The author argues that researchers should focus on preventing memorization by using smaller, more manageable neural networks that necessitate generalization in order to solve the task.
- Why unresolved: The paper acknowledges the problem of memorization but does not provide a definitive solution. It suggests that a balance between increasing environmental complexity and limiting an agent's communication capacity could be a potential approach, but further research is needed to determine the optimal strategy.
- What evidence would resolve it: Experimental results demonstrating the effectiveness of various neural network architectures and learning paradigms in promoting generalization over memorization in emergent communication tasks.

### Open Question 2
- Question: What is the optimal balance between cooperation and competition in mixed human-robot teams to improve overall performance and effectiveness?
- Basis in paper: [inferred] The paper discusses the importance of cooperation and competition in emergent communication, highlighting that competition can lead to improved communication protocols and general performance. However, it also notes that there is limited work on investigating the effects of competition and balancing cooperation and competition in mixed human-robot teams.
- Why unresolved: The paper acknowledges the potential benefits of competition but does not provide a clear answer on how to achieve the optimal balance between cooperation and competition in mixed human-robot teams. Further research is needed to explore this aspect of emergent communication.
- What evidence would resolve it: Empirical studies comparing the performance and effectiveness of mixed human-robot teams with different levels of cooperation and competition, as well as theoretical models that can predict the optimal balance based on the specific task and team composition.

### Open Question 3
- Question: How can non-verbal communication be effectively incorporated into artificial agents to enhance human-machine communication?
- Basis in paper: [explicit] The paper mentions that non-verbal communication is fundamental in human-human communication and that developing artificial agents that can both interpret and produce non-verbal cues remains an open challenge for enhancing human-machine communication.
- Why unresolved: The paper acknowledges the importance of non-verbal communication but does not provide a definitive solution for incorporating it into artificial agents. It suggests that this is an area for future research, as it could significantly improve human-machine communication.
- What evidence would resolve it: Successful implementations of artificial agents capable of interpreting and producing non-verbal cues in various communication tasks, as well as empirical studies demonstrating the improvement in human-machine communication when non-verbal cues are incorporated.

## Limitations
- The review is primarily conceptual rather than empirical, lacking direct experimental validation of proposed mechanisms
- Limited corpus evidence directly supports the specific mechanisms explaining why certain approaches work
- The paper does not provide specific code or datasets for reproduction of the reviewed methods
- Hyperparameter choices and their impact on results are not thoroughly explored or specified

## Confidence

- High confidence: The categorization of EmCom into machine-centered and human-centered approaches is well-supported by the literature
- Medium confidence: The identified properties (game environment, learning paradigm, interaction type, theory of mind) are commonly discussed in EmCom literature
- Low confidence: Specific mechanisms explaining why certain approaches work (particularly the balance between learning paradigms and the role of theory of mind) lack direct empirical validation in the corpus

## Next Checks

1. Implement a controlled experiment testing the impact of supervised vs. reinforcement learning balance on language drift in a standard referential game
2. Compare emergent communication protocols in environments with vs. without explicit theory of mind requirements
3. Conduct a systematic review of existing literature to quantify the frequency and success rates of different learning paradigm combinations in EmCom research