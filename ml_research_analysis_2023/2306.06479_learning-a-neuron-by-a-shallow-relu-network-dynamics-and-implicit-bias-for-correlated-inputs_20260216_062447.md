---
ver: rpa2
title: 'Learning a Neuron by a Shallow ReLU Network: Dynamics and Implicit Bias for
  Correlated Inputs'
arxiv_id: '2306.06479'
source_url: https://arxiv.org/abs/2306.06479
tags:
- training
- have
- part
- then
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies the problem of learning a single ReLU neuron\
  \ using a shallow one-hidden-layer ReLU network of any width, focusing on how gradient\
  \ flow from a small initialisation converges to zero loss and exhibits implicit\
  \ bias towards rank minimisation of the network parameters. The authors analyze\
  \ a setting where training points are correlated with the teacher neuron (angles\
  \ between them are less than \u03C0/4), which complements previous work that considered\
  \ orthogonal datasets."
---

# Learning a Neuron by a Shallow ReLU Network: Dynamics and Implicit Bias for Correlated Inputs

## Quick Facts
- arXiv ID: 2306.06479
- Source URL: https://arxiv.org/abs/2306.06479
- Authors: 
- Reference count: 40
- Primary result: Gradient flow from small initialization converges to zero loss and is implicitly biased to minimize rank of network parameters for correlated inputs

## Executive Summary
This paper analyzes how gradient flow trains a shallow one-hidden-layer ReLU network to learn a single ReLU neuron. The key finding is that with correlated training inputs (angles < π/4) and small initialization, the network converges to zero loss while being implicitly biased to select minimum-rank interpolator solutions. The analysis reveals a two-phase training dynamic: initial alignment/deactivation of hidden neurons followed by coordinated growth of aligned neurons toward the teacher neuron.

## Method Summary
The method involves analyzing gradient flow dynamics for a one-hidden-layer ReLU network with balanced initialization. The network is trained to fit data generated by a single teacher ReLU neuron, with the critical constraint that all training points have angles less than π/4 with the teacher. The analysis tracks each hidden neuron's trajectory throughout training, identifying phases of alignment, deactivation, and coordinated growth. The implicit bias toward rank minimization emerges from the geometric constraints on neuron trajectories during training.

## Key Results
- Gradient flow from small initialization converges to zero loss with probability 1
- The converged solution is implicitly biased to minimize the rank of network parameters
- Networks converge to rank-1 solutions where all non-zero hidden neurons are positive scalings of the teacher neuron
- A distinction exists between minimum-rank and minimum-norm interpolator networks under certain dataset conditions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient flow from small initialization converges to zero loss and minimizes rank of network parameters
- Mechanism: The dynamics separate into two phases: initial alignment/deactivation of hidden neurons based on their last-layer sign, followed by coordinated growth of aligned neurons toward the teacher neuron. The trajectory remains in a constrained set ensuring neurons stay aligned.
- Core assumption: Training points are correlated with the teacher neuron (angles < π/4), balanced initialization with small scale λ, and sufficient overparameterization.
- Evidence anchors:
  - [abstract]: "training a one-hidden layer ReLU network of any width by gradient flow from a small initialisation converges to zero loss and is implicitly biased to minimise the rank of network parameters"
  - [section 3]: "balanced initialisation" and "neuron-labelled correlated inputs" with angle constraints
  - [corpus]: Weak evidence - related works focus on orthogonal datasets or different activation functions
- Break condition: If training points are not sufficiently correlated with teacher neuron, or initialization scale is too large, the alignment mechanism fails.

### Mechanism 2
- Claim: The first phase separates neurons into aligned (positive sign) and deactivated (negative sign) groups
- Mechanism: Each hidden neuron follows a yardstick trajectory; positive-sign neurons align to include all training points, negative-sign neurons turn away and deactivate. The order of boundary crossings matches the yardstick dynamics.
- Core assumption: No training points lie on ReLU boundaries initially, and each neuron's dynamics are governed by its last-layer sign and active training points.
- Evidence anchors:
  - [section 4]: "during a first phase of the training, all active hidden neurons with a positive last-layer weight get aligned to a single direction... whereas all active hidden neurons with a negative last-layer weight get turned away"
  - [section 5]: Detailed proof of alignment and deactivation using yardstick trajectories
  - [corpus]: Strong evidence from Boursier et al. [2022] on orthogonal datasets supports the mechanism conceptually
- Break condition: If multiple neurons cross ReLU boundaries simultaneously, or training points are too close to boundaries, the separation may not occur cleanly.

### Mechanism 3
- Claim: After alignment, the bundle of positive neurons grows while maintaining low-rank structure and converges to teacher neuron
- Mechanism: The bundle vector stays within a constrained set S that ensures all neurons remain aligned (cosines > 1-4λε). The dynamics satisfy Polyak-Łojasiewicz inequality, ensuring exponential loss convergence.
- Core assumption: The set S is repelling on its boundary, preventing neurons from separating; gradient flow remains in the linear regime after alignment.
- Evidence anchors:
  - [section 5]: "the bundle of aligned hidden neurons... grows and turns as it travels from near the origin to near the teacher neuron, and does not separate"
  - [section F]: Proof that S is repelling on all faces except the ellipsoid constraint, and PL inequality for loss convergence
  - [corpus]: Weak evidence - most related works don't analyze the post-alignment dynamics in detail
- Break condition: If neurons separate during growth phase, or if PL inequality conditions fail, the convergence to rank-1 solution breaks down.

## Foundational Learning

- Concept: Clarke subdifferential for non-differentiable ReLU activation
  - Why needed here: The ReLU activation is not differentiable at zero, requiring generalized gradient concepts for rigorous analysis of gradient flow dynamics.
  - Quick check question: What is the Clarke subdifferential of ReLU at zero, and why does this matter for training analysis?

- Concept: Implicit bias in overparameterized models
  - Why needed here: The paper's main contribution is showing that gradient flow implicitly selects minimum-rank interpolators, which is crucial for understanding generalization in overparameterized networks.
  - Quick check question: How does implicit bias differ from explicit regularization, and why is it particularly important in the overparameterized regime?

- Concept: Rank minimization vs Euclidean norm minimization
  - Why needed here: The paper establishes a surprising distinction between minimum-rank and minimum-norm interpolators, which has implications for understanding what geometric properties are actually being optimized.
  - Quick check question: Under what conditions do rank minimization and norm minimization coincide for interpolator networks, and when do they diverge?

## Architecture Onboarding

- Component map: Teacher neuron -> Balanced initialization -> Two-phase dynamics (alignment + growth) -> Zero loss convergence with rank-1 bias

- Critical path:
  1. Initialize balanced network with small scale
  2. First phase: Neurons align or deactivate based on last-layer sign
  3. Second phase: Aligned bundle grows toward teacher neuron
  4. Convergence: Loss → 0 and rank → 1 as λ → 0

- Design tradeoffs:
  - Small initialization scale λ: Ensures proper alignment but slows convergence
  - Overparameterization (large m): Guarantees initial diversity but adds complexity
  - Correlation constraint (angles < π/4): Enables alignment mechanism but limits applicability

- Failure signatures:
  - Neurons fail to align: Check if training points are sufficiently correlated with teacher
  - Bundle separates during growth: Verify the set S constraints are properly maintained
  - Convergence to non-rank-1 solution: Ensure initialization scale λ is sufficiently small

- First 3 experiments:
  1. Verify alignment phase: Plot neuron trajectories during first phase for various λ values
  2. Test bundle cohesion: Monitor angles between neurons during growth phase
  3. Validate rank minimization: Compare final rank for different initialization scales and network widths

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the implicit bias towards rank minimization extend to teacher neurons with angles between π/4 and π/2?
- Basis in paper: [explicit] The authors state that relaxing the π/4 correlation bound to π/2 is an open question, and that the implicit bias in that extended setting is unknown.
- Why unresolved: The current analysis relies on geometric properties specific to acute angles, and handling obtuse angles would require new techniques.
- What evidence would resolve it: Numerical experiments with datasets having teacher neurons at various angles up to π/2, combined with theoretical analysis showing the training dynamics and implicit bias.

### Open Question 2
- Question: How does the implicit bias behave for multi-neuron teacher networks or student networks with more than one hidden layer?
- Basis in paper: [inferred] The paper focuses on a single-neuron teacher and a shallow one-hidden-layer network. The authors mention that extending to multi-neuron teachers and deeper networks is a direction for future work.
- Why unresolved: The dynamics and implicit bias for more complex network architectures are expected to be significantly different and require new analytical tools.
- What evidence would resolve it: Theoretical proofs or extensive numerical experiments demonstrating convergence to zero loss and characterizing the implicit bias for these more complex settings.

### Open Question 3
- Question: Can the bounds on the initialization scale λ and the convergence time be improved?
- Basis in paper: [explicit] The authors provide polynomial bounds in the network width m and exponential bounds in the dataset cardinality n for λ, and logarithmic bounds in λ for the convergence time. They mention that refining these bounds is a direction for future work.
- Why unresolved: The current bounds may be loose, and tighter bounds would provide a better understanding of the practical implications of the theory.
- What evidence would resolve it: New analytical techniques that yield tighter bounds, or numerical experiments showing faster convergence with smaller initialization scales than predicted by the current theory.

## Limitations

- The correlation constraint (angles < π/4) significantly limits the applicability compared to previous work on orthogonal datasets
- Small initialization scale λ introduces a problematic separation of scales that may not hold in practical implementations
- The geometric arguments for maintaining neuron alignment during growth phase rely on specific repelling properties that may not generalize to other architectures

## Confidence

**High Confidence:** The convergence to zero loss from small initialization and the identification of two distinct training phases (alignment/deactivation followed by coordinated growth)

**Medium Confidence:** The implicit bias toward rank minimization, specifically that the converged solution has rank 1 with all active neurons being positive scalings of the teacher

**Low Confidence:** The practical significance of the distinction between minimal-rank and minimal-norm interpolators, given the complex dataset dependencies

## Next Checks

1. **Dataset Correlation Sensitivity:** Systematically vary the correlation level between training points and teacher neuron (angles from 0 to π/2) and measure how the implicit bias toward rank minimization degrades as correlation decreases.

2. **Initialization Scale Sweep:** Implement the full algorithm and sweep across initialization scales λ to identify the precise threshold where rank-1 convergence breaks down, comparing theoretical bounds with empirical observations.

3. **Comparison with Orthogonal Datasets:** Reproduce the analysis on orthogonal datasets (where previous work applies) to explicitly verify that the correlation constraint fundamentally changes the implicit bias from weight decay to rank minimization.