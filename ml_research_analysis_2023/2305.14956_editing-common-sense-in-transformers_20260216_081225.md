---
ver: rpa2
title: Editing Common Sense in Transformers
arxiv_id: '2305.14956'
source_url: https://arxiv.org/abs/2305.14956
tags:
- editing
- token
- last
- object
- subject
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether commonsense knowledge in transformers
  can be edited using localized parameter updates. The authors adapt the MEMIT algorithm
  for commonsense knowledge (MEMIT CSK) by extending editing to subject, verb, and
  object tokens, employing robust layer selection, and improving hyper-parameter tuning.
---

# Editing Common Sense in Transformers

## Quick Facts
- **arXiv ID**: 2305.14956
- **Source URL**: https://arxiv.org/abs/2305.14956
- **Reference count**: 33
- **Primary result**: MEMIT-CSK achieves 10.97% and 10.73% F1 score improvements over fine-tuned baselines on PEP3k and 20Q datasets

## Executive Summary
This paper investigates whether commonsense knowledge in transformer models can be edited using localized parameter updates. The authors adapt the MEMIT algorithm for commonsense knowledge (MEMIT CSK) by extending editing to subject, verb, and object tokens, employing robust layer selection, and improving hyper-parameter tuning. Through causal mediation analysis, they identify which MLP layers store commonsense knowledge and demonstrate that targeted editing of these layers can correct plausibility predictions while preserving unrelated knowledge. The method shows substantial improvements over fine-tuning baselines on both standard benchmarks and a new evaluation dataset designed to test semantic generalization.

## Method Summary
The authors adapt the MEMIT editing algorithm for commonsense knowledge by fine-tuning GPT-2 Large and XL models on commonsense reasoning datasets, then performing causal mediation analysis to identify editable layers. They extend editing to subject, verb, and object tokens (rather than just subject-object pairs), use robust layer selection strategies based on average indirect effect, and optimize hyperparameters through fine-tuning first. The method employs residual updates to MLP layers identified through causal analysis, with validation on both configuration generalization and semantic generalization tasks.

## Key Results
- GPT-2 Large and XL models edited with MEMIT CSK outperform fine-tuned baselines by 10.97% and 10.73% F1 scores on PEP3k and 20Q datasets
- MEMIT CSK achieves better semantic generalization, outperforming fine-tuning by 13.72% and 5.57% overall scores on the new MEMIT-CSK-PROBE evaluation set
- The method demonstrates strong configuration generalization by successfully transferring hyperparameters between inference sets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Localized parameter updates in MLP layers can effectively edit commonsense knowledge without extensive retraining.
- Mechanism: The model uses causal mediation analysis to identify which MLP layers store knowledge relevant to subject, verb, and object tokens. By editing these specific layers with residual updates, the model corrects plausibility predictions while preserving unrelated knowledge.
- Core assumption: Commonsense knowledge is localized in specific MLP layers, and editing these layers with minimal changes will propagate corrections through the model's inference process.
- Evidence anchors:
  - [abstract] "We find that directly applying the MEMIT editing algorithm results in sub-par performance and improve it for the commonsense domain by varying edit tokens and improving the layer selection strategy"
  - [section] "In causal mediation analyses, we corrupt each of the three token types due to their critical importance in plausibility assessment"
  - [corpus] Weak - the corpus neighbors discuss model editing but don't specifically address the MLP layer localization mechanism for commonsense knowledge

### Mechanism 2
- Claim: Fine-tuning the base model first creates clearer causal patterns for effective editing.
- Mechanism: The initial fine-tuning establishes strong causal relationships between neural activations and predictions. This makes the subsequent causal mediation analysis more reliable for identifying which layers to edit.
- Core assumption: Zero-shot models lack the localized causal patterns needed for effective editing, while fine-tuned models exhibit clear layer-specific causal effects.
- Evidence anchors:
  - [abstract] "We initially fine-tune the GPT-2 Large and GPT-2 XL models on the training set with the next token prediction objective"
  - [section] "We anticipate seeing improvements in causal graphs after editing... If the verb was noised, a higher IE was observed at the verb token"
  - [corpus] Weak - corpus mentions fine-tuning in general but doesn't specifically address its role in establishing causal patterns for editing

### Mechanism 3
- Claim: Editing multiple token types (subject, verb, object) captures the full context of commonsense plausibility.
- Mechanism: Unlike encyclopedic knowledge which focuses on subject-object relationships, commonsense plausibility depends on all three elements. By editing all three token types, the method captures the full semantic context.
- Core assumption: Commonsense knowledge is distributed across subject, verb, and object tokens rather than being localized to a single token type.
- Evidence anchors:
  - [abstract] "In contrast, commonsense knowledge is about concepts, and a subject-verb pair can match many objects to form plausible statements"
  - [section] "Therefore, in MEMIT CSK we analyzed three types of corruption: subject, object, and verb"
  - [corpus] Moderate - corpus mentions commonsense knowledge editing but doesn't specifically discuss the multi-token approach

## Foundational Learning

- **Concept: Causal mediation analysis**
  - Why needed here: Identifies which model layers store the knowledge to be edited, enabling targeted parameter updates
  - Quick check question: What's the difference between total effect and indirect effect in causal mediation analysis?

- **Concept: Transformer architecture and attention mechanisms**
  - Why needed here: Understanding how information flows through the model is crucial for interpreting causal analysis results and designing effective edits
  - Quick check question: How do MLP layers differ from attention layers in terms of their role in knowledge storage?

- **Concept: Fine-tuning vs. zero-shot prompting**
  - Why needed here: Determines whether the model has established the causal patterns necessary for effective editing
  - Quick check question: Why might zero-shot models lack the clear causal patterns needed for editing?

## Architecture Onboarding

- **Component map**: Base GPT-2 model → Fine-tuning layer → Causal analysis module → Layer selection algorithm → MEMIT CSK editing module → Evaluation pipeline
- **Critical path**: Causal analysis → Layer selection → Parameter editing → Evaluation
- **Design tradeoffs**: Targeted editing vs. comprehensive updates; specificity vs. generalization; computational efficiency vs. thoroughness
- **Failure signatures**: Poor causal analysis patterns; low configuration generalization; high relapse rates; poor performance on semantic generalization tests
- **First 3 experiments**:
  1. Run causal mediation analysis on fine-tuned model to verify clear patterns exist
  2. Test layer selection strategy with different window sizes and positions
  3. Validate configuration generalization by applying hyperparameters from Inference Set #1 to Inference Set #2

## Open Questions the Paper Calls Out

Open Question 1
- Question: Can the MEMIT CSK method be effectively applied to edit commonsense knowledge in transformer models of different architectures beyond GPT-2, such as BERT or T5?
- Basis in paper: The paper demonstrates the effectiveness of MEMIT CSK on GPT-2 Large and XL models, but does not explore its applicability to other transformer architectures.
- Why unresolved: The paper focuses specifically on GPT-2 models, and it remains unclear whether the observed causal patterns and editing strategies would generalize to other transformer architectures with different attention mechanisms or layer configurations.
- What evidence would resolve it: Conducting experiments on other transformer architectures (e.g., BERT, T5) using the MEMIT CSK method and comparing the results to the GPT-2 models would provide evidence for the method's generalizability across different transformer architectures.

Open Question 2
- Question: How does the performance of MEMIT CSK compare to other model editing techniques, such as low-rank adaptation (LoRA) or prefix tuning, when applied to commonsense knowledge editing?
- Basis in paper: The paper focuses on comparing MEMIT CSK to fine-tuning baselines but does not explore other model editing techniques that have been proposed in recent literature.
- Why unresolved: While MEMIT CSK shows promising results, it is unclear whether it outperforms or is outperformed by other model editing techniques that may have different strengths and weaknesses in terms of efficacy, specificity, and generalization.
- What evidence would resolve it: Conducting experiments comparing MEMIT CSK to other model editing techniques (e.g., LoRA, prefix tuning) on the same commonsense knowledge editing tasks would provide insights into the relative performance and trade-offs of these methods.

Open Question 3
- Question: How does the performance of MEMIT CSK vary across different domains of commonsense knowledge, such as physical, social, or temporal commonsense?
- Basis in paper: The paper focuses on commonsense knowledge editing using the PEP3k and 20Q datasets, which cover a range of commonsense domains, but does not analyze the performance of MEMIT CSK across these specific domains.
- Why unresolved: Commonsense knowledge encompasses various domains, and it remains unclear whether the effectiveness of MEMIT CSK varies depending on the specific domain being edited.
- What evidence would resolve it: Conducting experiments on commonsense knowledge datasets that are specifically categorized by domain (e.g., physical, social, temporal) and analyzing the performance of MEMIT CSK on each domain would provide insights into its effectiveness across different types of commonsense knowledge.

Open Question 4
- Question: Can the MEMIT CSK method be extended to edit commonsense knowledge in multilingual transformer models, and how would its performance compare to monolingual models?
- Basis in paper: The paper focuses on editing commonsense knowledge in English transformer models (GPT-2), but does not explore its applicability to multilingual models or compare its performance across languages.
- Why unresolved: Commonsense knowledge is language-agnostic, and it remains unclear whether the MEMIT CSK method can effectively edit commonsense knowledge in multilingual transformer models or if there are language-specific challenges that need to be addressed.
- What evidence would resolve it: Conducting experiments on multilingual transformer models (e.g., mBERT, XLM-R) using the MEMIT CSK method and comparing the results to monolingual models would provide insights into its effectiveness across languages and its potential for multilingual commonsense knowledge editing.

Open Question 5
- Question: How does the performance of MEMIT CSK vary when editing commonsense knowledge in transformer models of different sizes, such as GPT-3 or GPT-4, and what are the implications for model scaling?
- Basis in paper: The paper demonstrates the effectiveness of MEMIT CSK on GPT-2 Large and XL models, but does not explore its performance on larger transformer models or analyze the implications of model scaling.
- Why unresolved: As transformer models continue to scale in size, it remains unclear whether the effectiveness of MEMIT CSK would improve, degrade, or remain consistent, and what the implications are for editing commonsense knowledge in larger models.
- What evidence would resolve it: Conducting experiments on larger transformer models (e.g., GPT-3, GPT-4) using the MEMIT CSK method and analyzing the performance trends as the model size increases would provide insights into the scalability of the method and its potential for editing commonsense knowledge in future, larger models.

## Limitations

- The method relies on causal mediation analysis that only considers MLP layers, potentially missing distributed knowledge representations across attention mechanisms
- The custom MEMIT-CSK-PROBE dataset construction using GPT-3 API prompts introduces variability without human validation of dataset quality
- Results are limited to two specific datasets (PEP3k and 20Q) and model sizes (GPT-2 Large and XL), raising questions about broader applicability

## Confidence

- **Causal analysis methodology**: Medium - well-specified but relies on assumptions about knowledge localization without thorough validation
- **Performance improvements**: Medium - substantial improvements shown but limited to specific datasets and model sizes
- **Semantic generalization claims**: Medium - new evaluation protocol is rigorous but depends on automatically generated data quality

## Next Checks

1. **Causal Pattern Robustness**: Validate that causal mediation analysis identifies consistent, high-impact layers across multiple random seeds and noise injection patterns. Compare layer importance rankings when using different corruption magnitudes (e.g., 2x vs 5x standard deviation).

2. **Cross-Dataset Generalization**: Test MEMIT-CSK on additional commonsense reasoning datasets beyond PEP3k and 20Q, particularly those with different knowledge distributions (temporal reasoning, physical reasoning, social commonsense).

3. **Attention Layer Contribution**: Conduct a systematic ablation study examining whether attention layers contain complementary or redundant knowledge compared to MLP layers, and whether editing both layer types improves performance on more complex reasoning tasks.