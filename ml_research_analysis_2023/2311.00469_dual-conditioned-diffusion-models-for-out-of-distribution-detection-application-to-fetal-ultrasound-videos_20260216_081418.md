---
ver: rpa2
title: 'Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application
  to Fetal Ultrasound Videos'
arxiv_id: '2311.00469'
source_url: https://arxiv.org/abs/2311.00469
tags:
- diffusion
- detection
- image
- in-distribution
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces dual-conditioned diffusion models (DCDM)
  for detecting out-of-distribution (OOD) samples in fetal ultrasound videos. The
  challenge addressed is detecting OOD samples when in-distribution data has high
  structural similarity to OOD classes and significant intra-class variation, as seen
  in heart views within fetal ultrasound.
---

# Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application to Fetal Ultrasound Videos

## Quick Facts
- **arXiv ID:** 2311.00469
- **Source URL:** https://arxiv.org/abs/2311.00469
- **Reference count:** 34
- **Primary result:** 12% improvement in accuracy, 22% higher precision, and 8% better F1 score for OOD detection in fetal ultrasound

## Executive Summary
This paper introduces dual-conditioned diffusion models (DCDM) to detect out-of-distribution (OOD) samples in fetal ultrasound videos. The challenge is distinguishing OOD samples when in-distribution data has high structural similarity to OOD classes and significant intra-class variation. The proposed method conditions a diffusion model on both in-distribution class labels and latent image features to constrain the generative manifold. This dual conditioning ensures generated images are structurally and semantically similar to the input for in-distribution samples but dissimilar for OOD samples. The model outperforms existing approaches with significant improvements in accuracy, precision, and F1 score.

## Method Summary
The method uses dual conditioning in diffusion models for OOD detection. It conditions the denoising process on both in-distribution class labels (IDCC) and latent image features (LIFC) via cross-attention. The IDCC handles high inter-class variance within in-distribution classes and high spatial similarity between ID and OOD classes, while LIFC counters intra-class variance. During inference, OOD samples are misclassified into ID classes, causing the model to generate structurally mismatched samples. The OOD score is computed as the cosine similarity between input and generated features extracted by the ID classifier.

## Key Results
- DCDM outperforms existing approaches with a 12% improvement in accuracy
- Achieves 22% higher precision compared to state-of-the-art methods
- Shows an 8% better F1 score for OOD detection
- Demonstrates effective separation of heart views from other anatomies in fetal ultrasound

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual conditioning constrains the generative manifold to produce ID-like samples for ID inputs and OOD-like samples for OOD inputs.
- Mechanism: The model uses both latent image feature conditioning (LIFC) and in-distribution class conditioning (IDCC) via cross-attention to guide denoising. LIFC ensures structural similarity to the input image, while IDCC ensures semantic alignment with the ID class distribution. During inference, the ID classifier's predicted label is used as IDCC input, causing OOD samples to be misclassified into ID classes, which leads the model to generate structurally mismatched samples.
- Core assumption: The pretrained encoder can extract meaningful latent features that preserve structural and semantic information, and the ID classifier can reliably predict class labels for ID samples while misclassifying OOD samples.
- Evidence anchors:
  - [abstract] "This constrains the generative manifold of the model to generate images structurally and semantically similar to those within the in-distribution."
  - [section 3.2] "IDCC is proposed to handle high inter-class variance within in-distribution classes and high spatial similarity between ID and OOD classes. LIFC is introduced to counter the intra-class variance within each class."
  - [corpus] No direct evidence in corpus; the mechanism is specific to this paper.
- Break condition: If the encoder fails to preserve discriminative features or the ID classifier's confidence on OOD samples is too low, the dual conditioning will not produce the desired generative behavior.

### Mechanism 2
- Claim: Cross-attention integration of dual conditioning is more effective than simple concatenation for guiding the denoising process.
- Mechanism: The concatenated LIFC and IDCC vectors (dimension 256) are used as side inputs to each UNet block. Cross-attention fuses these conditioning features with the UNet block features, allowing the model to attend to relevant conditioning information at each denoising step.
- Core assumption: Cross-attention provides better conditioning integration than concatenation alone, as supported by prior work on diffusion models.
- Evidence anchors:
  - [section 3.2] "To integrate the dual-conditioning guidance into the diffusion model, we use a cross-attention [27] mechanism inside the denoising U-Net rather than just concatenation [24] as it is more effective [13,20,17] and allows condition diffusion models on various input modalities [22]."
  - [corpus] No direct evidence in corpus; the mechanism is specific to this paper.
- Break condition: If the cross-attention mechanism is poorly implemented or the conditioning features are not aligned with the denoising process, the conditioning will have minimal impact on generation quality.

### Mechanism 3
- Claim: The cosine similarity between input and generated features provides an effective OOD score.
- Mechanism: After generating the denoised latent z0 and decoding it to pixel space, the features of the input x0 and generated x'0 are extracted using the ID classifier (CFR). The cosine similarity between these features serves as the OOD score; low similarity indicates OOD.
- Core assumption: The ID classifier's features are discriminative enough to capture semantic differences between ID and OOD samples, and the denoising process preserves these features.
- Evidence anchors:
  - [section 3.3] "The cosine similarity between features of the input image x0 and the generated image x'0 from the in-distribution classifier is calculated and is referred as an OOD score."
  - [section 4.1] "We evaluated the performance of the dual-conditioned diffusion models (DCDMs) for OOD detection by comparing them with two current state-of-the-art unsupervised reconstruction-based approaches and one likelihood-based approach."
  - [corpus] No direct evidence in corpus; the mechanism is specific to this paper.
- Break condition: If the ID classifier's features are not discriminative or the denoising process corrupts feature information, the cosine similarity will not be a reliable OOD indicator.

## Foundational Learning

- Concept: Diffusion models and denoising process
  - Why needed here: The entire approach relies on diffusion models to gradually denoise latent vectors conditioned on input features and class labels.
  - Quick check question: What is the role of the variance schedule {βt} in the forward diffusion process?

- Concept: Cross-attention mechanism
  - Why needed here: Cross-attention is used to integrate dual conditioning into the denoising U-Net, allowing the model to attend to relevant conditioning information.
  - Quick check question: How does cross-attention differ from simple concatenation in conditioning diffusion models?

- Concept: Feature-based OOD detection
  - Why needed here: The OOD score is computed as the cosine similarity between input and generated features extracted by the ID classifier.
  - Quick check question: Why is cosine similarity used instead of Euclidean distance for the OOD score?

## Architecture Onboarding

- Component map:
  - Pretrained encoder E: Extracts latent features z0 from input images
  - Pretrained ID classifier CFR: Predicts class labels for IDCC and extracts features for OOD scoring
  - Dual-conditioned diffusion model (DCDM): Consists of a denoising U-Net with cross-attention for LIFC and IDCC
  - Decoder D: Maps denoised latent z0 back to pixel space

- Critical path:
  1. Input image → Encoder E → Latent z0
  2. Latent z0 → Forward diffusion → Noised zt
  3. Noised zt + Dual conditioning (via cross-attention) → Backward diffusion → Denoised z0
  4. Denoised z0 → Decoder D → Generated image x'0
  5. Input image x0 and generated image x'0 → ID classifier CFR → Cosine similarity → OOD score

- Design tradeoffs:
  - Using cross-attention vs. concatenation for conditioning: Cross-attention is more effective but computationally more expensive
  - Using cosine similarity vs. other distance metrics for OOD scoring: Cosine similarity is scale-invariant but may not capture all relevant differences
  - Using a separate ID classifier vs. integrating classification into the diffusion model: Separation allows for better modularity but requires additional components

- Failure signatures:
  - High OOD scores for ID samples: Indicates poor conditioning or feature extraction
  - Low OOD scores for OOD samples: Indicates insufficient discriminative power of the OOD score or poor generation quality
  - Unstable training or poor generation quality: Indicates issues with the diffusion model architecture or conditioning mechanism

- First 3 experiments:
  1. Train and evaluate the unconditional diffusion model (no conditioning) to establish a baseline
  2. Train and evaluate the model with only IDCC or only LIFC to assess the impact of each conditioning mechanism
  3. Train and evaluate the full DCDM model and compare its performance to the baselines using the OOD detection metrics (AUC, F1-score, accuracy, precision)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DCDM scale when applied to datasets with a much larger number of heterogeneous classes (e.g., 20+ classes) compared to the 5 heart views used in the paper?
- Basis in paper: [inferred] The paper demonstrates DCDM on 5 heart views and mentions it's not ultrasound-specific, but doesn't explore scalability to datasets with more classes.
- Why unresolved: The paper only tests DCDM on a relatively small number of classes (5 heart views). Performance with many more heterogeneous classes is unknown.
- What evidence would resolve it: Testing DCDM on datasets with 20+ heterogeneous classes and comparing performance metrics (AUC, F1-score, precision) to baseline methods.

### Open Question 2
- Question: What is the computational overhead of DCDM compared to baseline methods during both training and inference, and how does this impact its practical deployment in real-time applications?
- Basis in paper: [explicit] The paper mentions that Graham et al.'s method is "time-consuming and impractical for settings where shorter inference times are needed," but doesn't provide specific computational comparisons for DCDM.
- Why unresolved: While the paper notes that other methods are computationally expensive, it doesn't quantify DCDM's computational requirements or compare them directly to baseline methods.
- What evidence would resolve it: Detailed timing analysis comparing training and inference times of DCDM versus baseline methods, including GPU memory usage and total processing time per image.

### Open Question 3
- Question: How sensitive is DCDM to the choice of threshold τ for OOD detection, and what methods could be used to automatically determine the optimal threshold for different datasets?
- Basis in paper: [explicit] The paper mentions using a "pre-defined threshold" τ but doesn't discuss how this threshold is selected or how sensitive the model is to its value.
- Why unresolved: The paper treats τ as a given parameter without exploring its impact on detection performance or discussing methods for threshold selection.
- What evidence would resolve it: Analysis of DCDM performance across a range of τ values, ROC curves, and investigation of automated threshold selection methods (e.g., using validation data or statistical approaches).

### Open Question 4
- Question: How does DCDM perform on OOD detection tasks where the OOD classes are semantically closer to the in-distribution classes than the non-heart anatomies used in this study?
- Basis in paper: [inferred] The paper uses non-heart anatomies as OOD classes, which are visually distinct from heart views, but doesn't test scenarios where OOD classes are more similar to ID classes.
- Why unresolved: The current experimental setup uses anatomically distinct OOD classes, which may not represent the most challenging OOD detection scenarios.
- What evidence would resolve it: Testing DCDM on datasets where OOD classes are semantically similar to ID classes (e.g., different types of cardiac abnormalities vs. normal heart views) and comparing performance to baseline methods.

## Limitations
- The study focuses on a single medical domain (fetal ultrasound), limiting generalizability claims
- Architecture details of the U-Net denoising model and label encoder are not fully specified
- The specific noise schedule parameters and sampling method for inference are not provided

## Confidence
- **High Confidence:** The core methodology of dual conditioning (IDCC + LIFC) and the empirical performance improvements (12% accuracy, 22% precision, 8% F1) are well-supported by the presented results
- **Medium Confidence:** The claim that cross-attention is superior to concatenation for conditioning integration is supported by references but not directly validated in this work
- **Medium Confidence:** The assumption that cosine similarity between classifier features is an effective OOD score is reasonable but not extensively validated against alternative scoring methods

## Next Checks
1. **Architecture replication test:** Implement the exact U-Net architecture and conditioning mechanism to verify the claimed performance improvements are reproducible
2. **Ablation study:** Train models with only IDCC, only LIFC, and with concatenation instead of cross-attention to quantify the contribution of each component
3. **Cross-domain validation:** Apply the DCDM approach to a different medical imaging domain (e.g., chest X-rays or retinal images) to assess generalizability beyond fetal ultrasound