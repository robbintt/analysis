---
ver: rpa2
title: 'Autonomous Driving using Spiking Neural Networks on Dynamic Vision Sensor
  Data: A Case Study of Traffic Light Change Detection'
arxiv_id: '2311.09225'
source_url: https://arxiv.org/abs/2311.09225
tags:
- data
- snns
- neural
- driving
- spiking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigated the application of Spiking Neural Networks
  (SNNs) with Dynamic Vision Sensor (DVS) data for autonomous driving, specifically
  for traffic light change detection. The main goal was to assess the effectiveness
  and generalizability of SNNs in photo-realistic driving scenes using the CARLA simulator.
---

# Autonomous Driving using Spiking Neural Networks on Dynamic Vision Sensor Data: A Case Study of Traffic Light Change Detection

## Quick Facts
- arXiv ID: 2311.09225
- Source URL: https://arxiv.org/abs/2311.09225
- Reference count: 25
- CNNs with DVS data achieved high testing accuracy, while SNNs with DVS data did not show acceptable testing accuracy.

## Executive Summary
This paper investigates the application of Spiking Neural Networks (SNNs) with Dynamic Vision Sensor (DVS) data for autonomous driving, specifically for traffic light change detection in the CARLA simulator. The study compares SNN and CNN performance on binary classification tasks (stop or drive) using both DVS and RGB data. While CNNs with DVS data performed well, achieving high testing accuracy, SNNs with DVS data failed to show acceptable performance. The computational efficiency of SNNs was also found to be lower than that of CNNs, contrary to expectations based on the event-driven nature of SNNs.

## Method Summary
The study used the CARLA simulator to collect DVS and RGB data across four weather conditions for training, in-domain testing, and out-of-domain testing. SNN and CNN models were implemented using PyTorch and SpikingJelly, with LIF neurons and surrogate gradient methods for SNNs. The training objective was mean squared error (MSE) loss for SNNs and binary cross-entropy (BCE) loss for CNNs. The models performed binary classification based on traffic light observations, with performance evaluated using accuracy curves and computational time metrics.

## Key Results
- CNNs with DVS data achieved high testing accuracy on traffic light change detection
- SNNs with DVS data failed to achieve acceptable testing accuracy
- SNNs showed lower computational efficiency compared to CNNs
- DVS data was found to be more suitable for change detection tasks compared to RGB data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SNNs with DVS data are theoretically more energy-efficient and have lower latency than CNNs for autonomous driving tasks.
- Mechanism: SNNs process information using sparse, event-driven spike sequences rather than dense frame-based data. DVS sensors detect only changes in brightness, producing sparse temporal data that aligns well with SNN's event-driven processing.
- Core assumption: The temporal sparsity of DVS data translates directly to computational savings when processed by SNNs.
- Evidence anchors:
  - [abstract]: "Spiking neural networks (SNNs) provide an alternative computational model to process information and make decisions. This biologically plausible model has the advantage of low latency and energy efficiency."
  - [section]: "Biologically inspired spiking neural networks (SNNs) [1] can circumvent these problems. SNNs are sometimes also referred to as the third generation of the neural network."

### Mechanism 2
- Claim: DVS data is inherently more suitable for change detection tasks like traffic light detection compared to RGB data because it directly encodes temporal changes.
- Mechanism: DVS sensors output events only when pixel intensity changes exceed a threshold, making them naturally sensitive to state changes such as traffic lights switching from red to green.
- Core assumption: Traffic light changes produce sufficient contrast in the scene to generate detectable DVS events.
- Evidence anchors:
  - [abstract]: "The results indicated that while CNNs with DVS data performed well, achieving high testing accuracy, SNNs with DVS data did not show acceptable testing accuracy."
  - [section]: "DVSs are known for detecting changes. Our task is essentially a change detection task that aims to detect the traffic light turning green from red effectively."

### Mechanism 3
- Claim: The training methodology using surrogate gradients allows SNNs to be optimized with gradient-based methods despite the non-differentiability of spike functions.
- Mechanism: Standard backpropagation cannot be applied directly to SNNs due to binary spike outputs. Surrogate gradient methods replace the non-differentiable step function with a smooth approximation (e.g., arctan), enabling gradient flow during training.
- Core assumption: The chosen surrogate gradient function provides a reasonable approximation of the true gradient.
- Evidence anchors:
  - [section]: "Due to the success of deep learning in many fields, we also want to use gradient-based optimization techniques like back-propagation on SNNs. A workaround is to use a differentiable function to approximate the binary all-or-nothing-style output of SNNs."
  - [section]: "The surrogate gradient method is used at LIF Neuron nodes. During the back-propagation, the gradient of arctan() is used as the surrogate gradient."

## Foundational Learning

- Concept: Understanding the Leaky-Integrate-and-Fire (LIF) neuron dynamics
  - Why needed here: The LIF model is the core computational unit in SNNs, and understanding its temporal integration properties is essential for designing and debugging SNN architectures.
  - Quick check question: How does the membrane potential decay over time in an LIF neuron when no input spikes are received?

- Concept: Event-based vision and DVS data characteristics
  - Why needed here: DVS data has fundamentally different properties from frame-based RGB data (sparse, asynchronous, polarity-based), which affects how networks should be designed and what tasks they're suited for.
  - Quick check question: What information is encoded in the polarity of DVS events, and how does this relate to the change detection task?

- Concept: Surrogate gradient methods for training SNNs
  - Why needed here: Since standard backpropagation cannot be applied to SNNs due to non-differentiable spike functions, surrogate gradients are essential for training these networks effectively.
  - Quick check question: What mathematical function is typically used as a surrogate gradient, and why is it chosen over other alternatives?

## Architecture Onboarding

- Component map: Input DVS events -> Convolutional layers -> LIF neurons -> MaxPooling layers -> Voting layer -> Binary classification
- Critical path: 1) Convert DVS event sequences to tensor format 2) Forward pass through convolutional and LIF layers 3) Apply surrogate gradients during backpropagation 4) Optimize membrane time constants and other parameters
- Design tradeoffs: SNNs offer potential energy efficiency but require careful handling of temporal dynamics; DVS data provides sparsity benefits but may miss information in static or low-contrast scenes; surrogate gradient methods enable training but may introduce approximation errors
- Failure signatures: Poor accuracy on DVS data may indicate insufficient event density or inappropriate network architecture for temporal processing; slow convergence or instability during training may suggest issues with surrogate gradient choice or learning rate; computational inefficiency compared to CNNs may indicate the task doesn't benefit from SNN's event-driven nature
- First 3 experiments:
  1. Test SNN performance on a simple change detection task using synthetic DVS data to isolate the impact of network architecture
  2. Compare SNN and CNN performance on the same DVS data to quantify any efficiency or accuracy advantages
  3. Evaluate the impact of different surrogate gradient functions on SNN training stability and convergence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can Spiking Neural Networks (SNNs) achieve better performance than Convolutional Neural Networks (CNNs) on DVS data for autonomous driving tasks?
- Basis in paper: [explicit] The paper directly compares SNNs and CNNs using DVS data for traffic light change detection, finding that CNNs outperformed SNNs on this task.
- Why unresolved: While the paper shows CNNs performing better than SNNs for this specific task, it doesn't explore whether SNNs might excel under different conditions or with different architectures.
- What evidence would resolve it: Systematic testing of various SNN architectures and parameters on a range of autonomous driving tasks, comparing results to CNNs under identical conditions.

### Open Question 2
- Question: What is the optimal sensor fusion strategy for combining DVS data with other sensor modalities in autonomous driving systems?
- Basis in paper: [explicit] The paper mentions that DVS data alone is not sufficient for guiding driving behavior due to noisy road marking information, and suggests that combining DVS data with other sensors could be promising.
- Why unresolved: The paper does not implement or test any sensor fusion strategies, only suggesting this as a future direction.
- What evidence would resolve it: Implementation and testing of various sensor fusion approaches combining DVS data with RGB cameras, LiDAR, or other modalities, comparing their performance to single-sensor systems.

### Open Question 3
- Question: How can the computational efficiency of SNNs be improved for real-time autonomous driving applications?
- Basis in paper: [explicit] The paper notes that SNNs are less computationally efficient than CNNs due to their special inference mechanism, but doesn't explore potential optimizations or hardware acceleration.
- Why unresolved: The paper only observes the current computational inefficiency without investigating potential solutions or optimizations.
- What evidence would resolve it: Comparative studies of SNN performance with and without hardware acceleration (e.g., neuromorphic chips), or with various optimization techniques applied to reduce computational complexity.

## Limitations
- SNNs failed to achieve acceptable testing accuracy on DVS data for traffic light change detection
- SNNs showed lower computational efficiency compared to CNNs, contrary to theoretical expectations
- The study only tested one specific SNN architecture and one autonomous driving task

## Confidence
- DVS data suitability for change detection tasks: Medium-High
- SNN computational efficiency claims: Low
- SNN accuracy performance: Low

## Next Checks
1. Test the SNN architecture on a simpler change detection task with synthetic DVS data to isolate whether the failure stems from network design or task complexity.

2. Conduct ablation studies varying surrogate gradient functions and membrane time constants to identify if specific hyperparameters are causing poor SNN performance.

3. Compare energy consumption measurements between SNN and CNN implementations during inference to verify computational efficiency claims rather than relying solely on computational time metrics.