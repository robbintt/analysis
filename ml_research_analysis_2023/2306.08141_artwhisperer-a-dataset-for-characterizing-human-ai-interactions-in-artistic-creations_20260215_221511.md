---
ver: rpa2
title: 'ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic
  Creations'
arxiv_id: '2306.08141'
source_url: https://arxiv.org/abs/2306.08141
tags:
- images
- image
- target
- prompt
- steerability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces ArtWhisperer, a dataset of 50,000+ human-AI
  interactions from an online game where users iteratively generate images to match
  target images using text prompts. The dataset enables analysis of prompt diversity,
  showing users find many different high-scoring prompts without convergence.
---

# ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic Creations

## Quick Facts
- **arXiv ID:** 2306.08141
- **Source URL:** https://arxiv.org/abs/2306.08141
- **Reference count:** 40
- **Primary result:** A dataset of 50,000+ human-AI interactions showing users find diverse prompts for similar images, with steerability varying by image type and model version.

## Executive Summary
This paper introduces ArtWhisperer, a dataset of over 50,000 human-AI interactions from an online game where users iteratively generate images to match target images using text prompts. The dataset enables analysis of prompt diversity and introduces a new metric for AI steerability based on expected interactions to reach an adequate score. The authors find that users can discover multiple distinct prompts achieving similar high scores without convergence, and that steerability varies significantly across image categories and Stable Diffusion versions.

## Method Summary
The ArtWhisperer dataset was collected through an online game where users iteratively generate images using Stable Diffusion, receiving CLIP-based similarity scores to guide prompt refinement. The steerability metric was developed by modeling user interactions as a Markov chain between score bins and calculating expected stopping time to reach high scores. The analysis compares steerability across different image categories and Stable Diffusion model versions (v2.1 vs v1.5).

## Key Results
- Users discover diverse prompts that produce similar high-scoring images without convergence
- Steerability varies by image type, with natural and city scenes being more steerable than artistic or fantasy images
- Stable Diffusion v2.1 shows higher steerability than v1.5 for natural images and city scenes
- The Markov chain-based steerability metric provides quantitative measure of model controllability

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Users can find diverse prompts that produce similar images without convergence
- **Mechanism:** The scoring function based on CLIP embeddings creates a continuous, multi-modal fitness landscape where different textual descriptions map to similar visual outputs
- **Core assumption:** CLIP embeddings capture perceptual similarity between images in a way that allows multiple distinct prompts to achieve high scores
- **Evidence anchors:**
  - [abstract]: "People submit diverse prompts and are able to discover a variety of text descriptions that generate similar images"
  - [section]: "In the left of Figure 5, we plot the distribution of distances between the first prompt (in blue) and the last prompt (in orange) to the average prompt for the corresponding target image. Despite the average score improving from 51.9 to 70.3 (out of 100) indicating a significant improvement in score, prompt diversity does not significantly diminish."
- **Break condition:** If CLIP embeddings poorly align with human perception, or if the scoring function has sharp, narrow optima that only accept very specific prompts

### Mechanism 2
- **Claim:** Steerability can be quantified using Markov chain analysis of score transitions
- **Mechanism:** User interactions form a Markov process where each score bin transitions to another based on empirical probabilities, and expected stopping time to reach high scores measures steerability
- **Core assumption:** User prompt updates are memoryless with respect to scores (future score depends only on current score, not history)
- **Evidence anchors:**
  - [abstract]: "We define steerability as the expected number of interactions required to adequately complete a task. We estimate this value by fitting a Markov chain for each target task and calculating the expected time to reach an adequate score in the Markov chain."
  - [section]: "We use this observation as a basis for creating a steerability metric. We define a Markov chain between scores... We use the expected time taken to reach the last score bin, [81, 100], as our steerability score"
- **Break condition:** If users employ non-Markovian strategies (e.g., learning patterns across multiple interactions) or if the score bins are too coarse to capture meaningful transitions

### Mechanism 3
- **Claim:** Image category affects steerability due to training data distribution and user familiarity
- **Mechanism:** Stable Diffusion v2.1 was trained on LAION5B which predominantly contains real-world images, making natural and city scenes more steerable than artistic or fantasy images; user unfamiliarity with specific art styles also reduces steerability for those categories
- **Core assumption:** Training data distribution influences how well the model responds to prompts in different categories
- **Evidence anchors:**
  - [section]: "The model we are assessing here, SDv2.1, as well as its text encoder OpenCLIP, are trained on subsets of LAION5B [27]. The contents of LAION5B are predominantly real world images, indicating why these images may be more steerable"
  - [section]: "Moreover, the prompts for AI-generated images and fantasy images generally include specific internet artists and/or art styles which may not be known to most users making achieving the desired target image more difficult"
- **Break condition:** If user expertise in specific domains is controlled for, or if the training data distribution doesn't significantly impact generation quality

## Foundational Learning

- **Concept: Markov chains and expected stopping time**
  - Why needed here: The steerability metric relies on modeling user interactions as a Markov process and computing expected time to reach target states
  - Quick check question: If a Markov chain has transition matrix [[0.9, 0.1], [0.5, 0.5]] with states A and B, and we want to reach B from A, what is the expected number of steps?

- **Concept: CLIP embeddings and cosine similarity**
  - Why needed here: The scoring function and prompt diversity analysis both use CLIP embeddings to measure similarity between images and prompts
  - Quick check question: If CLIP(img1) = [0.3, 0.4] and CLIP(img2) = [0.6, 0.8], what is their cosine similarity?

- **Concept: Empirical transition probability estimation**
  - Why needed here: The Markov chain model requires estimating transition probabilities from user interaction data
  - Quick check question: Given user transitions from scores 40→60, 60→80, 40→60, 60→40, what are the empirical transition probabilities from bin [41,60]?

## Architecture Onboarding

- **Component map:** Web interface (React) -> Backend API (Python/Flask) -> Stable Diffusion generation -> CLIP scoring -> Database storage -> Analysis pipeline
- **Critical path:** 1. User submits prompt → 2. Generate image with Stable Diffusion → 3. Compute CLIP similarity → 4. Store interaction → 5. Return score and image to user
- **Design tradeoffs:** Fixed random seed improves reproducibility but limits exploration of seed variation; Fixed model parameters simplify analysis but don't reflect real-world prompt engineering; Five score bins balance granularity with data sufficiency for Markov estimation
- **Failure signatures:** Very high steerability scores (>15) suggest the task is too easy or the scoring function is misaligned; Very low score variance across interactions indicates poor prompt exploration; High correlation between prompt embeddings suggests convergence that shouldn't occur
- **First 3 experiments:** 1. Verify Markov chain assumptions by testing if score transitions depend only on current state, not history; 2. Test sensitivity of steerability scores to different bin numbers and sizes; 3. Compare steerability using human ratings vs. automated CLIP-based scoring to validate the metric

## Open Questions the Paper Calls Out

The paper identifies several open questions regarding the relationship between prompt strategies and steerability across different image categories, the impact of model-specific guidance on prompt diversity, and how the steerability metric correlates with human-perceived difficulty across user skill levels. These questions remain unresolved and suggest directions for future research.

## Limitations

- The Markov chain assumption of memoryless transitions may not capture all user behavior patterns
- CLIP embeddings may not perfectly align with human aesthetic judgments
- Fixed model parameters and random seeds limit generalizability to real-world prompt engineering scenarios

## Confidence

- **High confidence:** Finding that users can discover diverse prompts achieving similar scores
- **Medium confidence:** Steerability metric validity and category-specific differences
- **Medium confidence:** CLIP-based scoring system's alignment with perceptual similarity

## Next Checks

1. Test the Markov chain assumption by analyzing whether score transitions depend on more than just the current state - specifically, check if user behavior shows patterns that violate memorylessness.

2. Validate the steerability metric by comparing automated CLIP-based scores with human-rated similarity scores across the same interactions.

3. Examine the impact of bin size and number on steerability estimates by systematically varying these parameters and measuring stability of results.