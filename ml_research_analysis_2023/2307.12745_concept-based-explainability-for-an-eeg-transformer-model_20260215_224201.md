---
ver: rpa2
title: Concept-based explainability for an EEG transformer model
arxiv_id: '2307.12745'
source_url: https://arxiv.org/abs/2307.12745
tags:
- data
- concepts
- classi
- movement
- concept
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study extends concept-based explainability methods to EEG\
  \ data, demonstrating two workflows for defining human-aligned concepts: (1) using\
  \ labeled EEG datasets and (2) applying anatomically defined cortical activity concepts.\
  \ The authors apply the TCAV method to a transformer-based EEG model (BENDR) and\
  \ show that both concept types provide insights into the model\u2019s learned representations."
---

# Concept-based explainability for an EEG transformer model

## Quick Facts
- arXiv ID: 2307.12745
- Source URL: https://arxiv.org/abs/2307.12745
- Reference count: 0
- Primary result: Extends TCAV concept-based explainability to EEG, showing that both labeled and anatomically-defined concepts reveal how transformer models use EEG features for seizure detection and motor imagery classification

## Executive Summary
This study introduces concept-based explainability to EEG analysis by applying the TCAV method to a transformer-based EEG model (BENDR). The authors demonstrate two approaches for defining human-aligned EEG concepts: using labeled EEG datasets and applying anatomically defined cortical activity concepts. Applied to seizure classification and motor imagery tasks, the method reveals that the model leverages epilepsy-related discharge patterns and lateralization in alpha-band activity in motor and somatosensory cortices, respectively.

## Method Summary
The study applies TCAV to a pre-trained BENDR transformer model for EEG analysis. The method involves fine-tuning BENDR on two classification tasks (seizure detection and motor imagery), defining concepts from labeled EEG data (artifacts, seizures, motor movements) and anatomical EEG data (source-localized cortical activity in frequency bands), extracting layer activations from fine-tuned models, training binary classifiers to obtain CAVs, and computing TCAV scores to measure alignment between concept activation vectors and class data. Statistical significance is assessed via Mann-Whitney U test with Bonferroni correction.

## Key Results
- TCAV successfully reveals epilepsy-related discharge patterns in seizure classification
- Motor imagery classification shows lateralization in alpha-band activity in somatosensory and motor cortices
- Both labeled and anatomically-defined concepts provide interpretable insights into model behavior

## Why This Works (Mechanism)

### Mechanism 1
TCAV scores provide interpretable alignment between human-defined EEG concepts and model internal representations by computing the directional derivative of model predictions along concept activation vectors (CAVs), quantifying how much the model relies on specific EEG features for classification.

### Mechanism 2
Anatomical EEG concepts capture meaningful model behavior by localizing EEG signals to cortical regions, frequency-filtering, and comparing to baseline activity to identify concept windows with maximal deviation.

### Mechanism 3
Self-supervised pre-training (BENDR) enables generalizable EEG representations for downstream tasks by using wav2vec 2.0-style architecture to learn rich representations from unlabeled EEG, which are then fine-tuned for specific classification tasks.

## Foundational Learning

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: BENDR uses transformer encoders to process EEG sequences; understanding attention helps debug and interpret model behavior
  - Quick check question: What is the role of multi-head self-attention in transformer models?

- Concept: EEG preprocessing and artifact handling
  - Why needed here: EEG data requires filtering, re-referencing, and artifact removal before model input; preprocessing choices affect concept definition
  - Quick check question: Why is high-pass filtering (0.1 Hz) applied to EEG signals?

- Concept: Source localization and cortical parcellation
  - Why needed here: Anatomical concepts require mapping scalp EEG to brain regions; HCPMMP1 parcellation defines cortical areas for analysis
  - Quick check question: What is the difference between eLORETA and beamforming approaches in source localization?

## Architecture Onboarding

- Component map: Feature encoder (6 conv blocks) -> Encoding augment (masking/contextualization) -> Summarizer (adaptive avg pooling) -> Extended classifier (dim reduction) -> Classifier (linear layer)

- Critical path: 1) Pre-train BENDR on large unlabeled EEG corpus, 2) Fine-tune Linear Head BENDR on target task, 3) Extract layer activations for TCAV analysis, 4) Define concepts (labeled or anatomical), 5) Compute TCAV scores and statistical significance

- Design tradeoffs: Using linear head vs. fine-tuning entire transformer (faster training but potentially less expressive), 4-second vs. 60-second windows (balances temporal resolution and computational cost), anatomical vs. labeled concepts (anatomical is more general but requires source localization)

- Failure signatures: TCAV scores near 0.5 for all concepts (concepts not aligned with model representations), poor fine-tuning performance (pre-trained representations not useful for target task), high variance in TCAV scores across runs (need more concept examples or better regularization)

- First 3 experiments: 1) Run TCAV with left/right motor imagery as concepts on fine-tuned model (expect lateralization in alpha band), 2) Use seizure vs. non-seizure labels as concepts (expect positive evidence for epilepsy-related discharge patterns), 3) Apply anatomical concepts (e.g., alpha in motor cortex) to motor imagery task (expect lateralized activation patterns)

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of window size (4 seconds vs 60 seconds) affect the validity and interpretability of concept activation vectors in EEG data? The paper uses both 4-second and 60-second windows but does not systematically compare their impact on TCAV results.

### Open Question 2
To what extent do anatomically-defined EEG concepts generalize across different subjects and recording conditions? The paper constructs anatomical concepts using resting-state EEG data but does not evaluate transfer to different subjects, equipment, or task contexts.

### Open Question 3
How do the pre-training objectives and architectures of transformer-based EEG models influence the types of concepts they learn to represent? The paper demonstrates concept-based explainability on one specific model architecture without exploring how design choices impact concept formation.

## Limitations
- Anatomical concept construction assumes accurate source localization from scalp EEG, which can be affected by individual anatomical differences and noise
- TCAV method assumes linear separability between concept and random examples, which may not hold for complex EEG patterns
- Limited number of datasets (5) and tasks (2) restricts generalizability of findings

## Confidence
- High confidence: The overall methodology of applying TCAV to EEG models is sound, and the transformer architecture is well-established
- Medium confidence: The anatomical concept construction approach is reasonable but depends on accurate source localization
- Medium confidence: The seizure classification results are based on a large dataset (TUSZ) but the motor imagery task uses a single dataset (MMIDB)

## Next Checks
1. Validate anatomical concepts by comparing source-localized activations to known neurophysiological patterns in the literature
2. Test TCAV robustness by varying the number of concept examples and random concepts to ensure results are stable
3. Apply the anatomical concept approach to a third, independent EEG dataset to assess generalizability beyond the two tasks presented