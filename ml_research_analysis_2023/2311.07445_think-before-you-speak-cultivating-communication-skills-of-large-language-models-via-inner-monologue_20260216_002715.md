---
ver: rpa2
title: 'Think Before You Speak: Cultivating Communication Skills of Large Language
  Models via Inner Monologue'
arxiv_id: '2311.07445'
source_url: https://arxiv.org/abs/2311.07445
tags:
- chatgpt
- human
- topic
- conversation
- communication
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitation of large language models (LLMs)
  in communication skills, making them less anthropomorphic and proactive during conversations.
  To overcome this, the authors propose a method called CSIM that adds five communication
  skills (topic transition, proactively asking questions, concept guidance, empathy,
  and summarizing often) to LLMs through inner monologues.
---

# Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue

## Quick Facts
- arXiv ID: 2311.07445
- Source URL: https://arxiv.org/abs/2311.07445
- Reference count: 13
- Key outcome: CSIM improves communication skills of LLMs through inner monologue prompting, outperforming CoT baselines on Cskills benchmark

## Executive Summary
This paper addresses the limitation of large language models in communication skills by proposing the CSIM method, which adds five communication skills (topic transition, proactively asking questions, concept guidance, empathy, and summarizing often) through inner monologues. The authors construct a benchmark called Cskills to evaluate these skills and demonstrate that CSIM improves performance on both automatic and human evaluation metrics compared to baseline methods.

## Method Summary
The CSIM method uses prompt engineering and in-context learning to endow LLMs with communication skills through inner monologues. It involves designing prompts that make LLMs think before generating responses and providing specific prompts for different communication skills. The approach is evaluated on a benchmark called Cskills consisting of 789 assessment dialogues covering various communication skills, using both automatic metrics (Rounds, AvgLen) and human evaluation (Humanness, Proactivity, Engagingness, Goal).

## Key Results
- CSIM improves backbone models (ChatGPT and Vicuna) performance on Cskills benchmark
- Outperforms baselines (CoT and CoT+CS) in both automatic and human evaluations
- The addition of communication skills makes LLM responses longer and more engaging
- Human evaluation shows improvements in humanness, proactivity, and engagingness metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Inner monologue prompts help LLMs understand and apply communication skills more effectively than simple CoT instructions
- Mechanism: The inner monologue process forces the model to explicitly reason about whether and why to use a communication skill before generating a response, creating a structured decision-making framework
- Core assumption: LLMs can follow multi-step reasoning processes when properly prompted, and explicit reasoning about communication skill usage improves skill application
- Evidence anchors: [abstract] "LLMs can be endowed with communication skills and inner monologue through prompt engineering" and [section 3.1] "LLMs need to think about whether communication skills are needed"

### Mechanism 2
- Claim: In-context learning with skill-specific examples improves communication skill application compared to generic CoT
- Mechanism: Providing examples of inner monologue reasoning and communication skill usage teaches the model the specific contexts and reasoning patterns needed for each skill
- Core assumption: LLMs can learn task-specific patterns from a few examples when those examples demonstrate the complete reasoning process
- Evidence anchors: [abstract] "We design the prompt that makes LLMs use inner monologue to think before generating a response" and [section 3.2] "Through the designed examples, LLMs can better understand the use scenarios"

### Mechanism 3
- Claim: The combination of inner monologue and skill-specific prompts creates more anthropomorphic and proactive responses than either technique alone
- Mechanism: Inner monologue provides the reasoning framework while skill-specific prompts guide the content and style of responses, resulting in more human-like conversation patterns
- Core assumption: Communication skills and inner monologue are complementary techniques that together produce better results than either alone
- Evidence anchors: [abstract] "Experimental results show that the proposed CSIM strategy improves the backbone models" and [section 5.2] "Our method surpasses backbone models and baselines on all human-evaluated metrics"

## Foundational Learning

- Concept: Prompt engineering techniques for LLMs
  - Why needed here: The entire CSIM method relies on carefully crafted prompts to guide LLM behavior without model retraining
  - Quick check question: Can you explain the difference between zero-shot prompting and few-shot prompting with examples?

- Concept: In-context learning (ICL) and few-shot learning
  - Why needed here: ICL is used to teach LLMs the specific patterns for using communication skills through examples
  - Quick check question: How does ICL enable LLMs to learn new tasks without parameter updates, and what are its limitations?

- Concept: Communication theory and conversational skills
  - Why needed here: Understanding what makes communication "effective" is crucial for designing appropriate communication skills
  - Quick check question: What are the key differences between topic transition and concept guidance in conversational contexts?

## Architecture Onboarding

- Component map: Prompt Generator -> Example Library -> LLM Core -> Self-Chat Simulator -> Human Evaluator Interface
- Critical path: 1. Receive user input 2. Apply communication skill evaluation logic 3. Generate inner monologue reasoning 4. Produce final response 5. Update conversation context
- Design tradeoffs: Complexity vs. effectiveness (more detailed prompts improve results but increase latency), example quantity vs. quality (more examples help but can cause overfitting), skill granularity vs. generalization (more specific skills are more effective but harder to apply broadly)
- Failure signatures: Model ignores inner monologue instructions, communication skills applied inappropriately or not at all, responses become too formulaic or repetitive, self-chat simulation fails to maintain conversation coherence
- First 3 experiments: 1. Compare CSIM vs. CoT on a simple communication skill (empathy) to validate inner monologue advantage 2. Test different example quantities in ICL to find optimal balance between performance and overhead 3. Evaluate cross-skill transfer by applying empathy examples to topic transition scenarios

## Open Questions the Paper Calls Out
- How does the performance of CSIM scale with larger language models beyond ChatGPT and Vicuna?
- What is the long-term impact of CSIM on user engagement compared to baseline models?
- How does CSIM handle cultural differences in communication styles across different user demographics?

## Limitations
- Automatic evaluation metrics may not fully capture nuanced aspects of effective communication
- Human evaluation relies on subjective judgments that could vary based on evaluator backgrounds
- Effectiveness depends heavily on prompt engineering quality which may not generalize across different LLM architectures

## Confidence
- **High Confidence**: Core claim that inner monologue improves communication skill application is well-supported by experimental results
- **Medium Confidence**: CSIM makes LLMs more anthropomorphic and proactive, though subjective measures are harder to verify objectively
- **Low Confidence**: Scalability and generalizability of CSIM to domains beyond the Cskills benchmark remains unproven

## Next Checks
1. Apply CSIM to conversations in different domains (technical support, casual chat, professional communication) to verify cross-domain generalization
2. Conduct experiments measuring CSIM performance across extended conversations (50+ turns) to assess long-term effectiveness
3. Systematically remove different elements of the CSIM prompts to quantify the individual contribution of each component to performance improvements