---
ver: rpa2
title: Federated Learning Based Multilingual Emoji Prediction In Clean and Attack
  Scenarios
arxiv_id: '2304.01005'
source_url: https://arxiv.org/abs/2304.01005
tags:
- federated
- learning
- data
- emoji
- multilingual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates federated learning (FL) for multilingual
  emoji prediction under clean and attack scenarios. Using 2M+ tweets and the SemEval
  dataset, they train transformer models (dense and sparse) in centralized and FL
  settings across seen/unseen languages with IID and non-IID distributions.
---

# Federated Learning Based Multilingual Emoji Prediction In Clean and Attack Scenarios

## Quick Facts
- arXiv ID: 2304.01005
- Source URL: https://arxiv.org/abs/2304.01005
- Reference count: 14
- Primary result: Federated learning achieves emoji prediction accuracy comparable to centralized training across seen/unseen languages, with Krum aggregation effectively mitigating label-flipping attacks

## Executive Summary
This paper investigates federated learning for multilingual emoji prediction using transformer models across clean and attack scenarios. The authors train dense and sparse transformers (M-MiniLM, Bert-Base, XLM-R, Switch-MoE) on over 2M tweets and SemEval data, evaluating performance in both centralized and federated settings with IID and non-IID distributions across seen/unseen languages. Results demonstrate that federated learning achieves accuracy comparable to centralized training while providing privacy benefits, with Krum aggregation outperforming FedAvg in attack scenarios. The models generalize effectively to unseen languages and exceed prior work on the SemEval dataset.

## Method Summary
The authors collect and preprocess over 2M tweets containing single emojis from Spanish, Italian, and French, filtering to 20 popular emojis, and combine with 500k SemEval English data. They partition data into 4 clients under IID and non-IID distributions, training transformer models using Flower framework with FedAvg and Krum aggregation. The study evaluates performance under clean conditions and label-flipping attacks (25% and 50% of clients), measuring Macro-F1 accuracy across seen/unseen languages. Experiments compare centralized training baselines with federated approaches using various model sizes from 21M to 619M parameters.

## Key Results
- Federated learning achieves emoji prediction accuracy comparable to centralized training across both seen and unseen languages
- Krum aggregation restores accuracy in label-flipping attack scenarios where FedAvg fails
- Multilingual models generalize effectively to unseen languages with only modest performance degradation compared to unilingual models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Krum aggregation outperforms FedAvg in label-flipping attack scenarios by selecting model updates closest to the median of other updates.
- Mechanism: Krum identifies and excludes malicious updates by computing the sum of distances from each update to all others, selecting the one with the smallest total distance. This effectively filters out poisoned gradients that are far from the majority.
- Core assumption: Label-flipping attacks cause model updates to deviate significantly from clean updates, making them identifiable by distance metrics.
- Evidence anchors:
  - [abstract] "FL's K-representative unweighted median (Krum) aggregation scheme can restore the accuracy of the clean setting."
  - [section] "Krum is more computationally demanding than FedAvg because it requires distance calculations to select the best model updates. However, Krum can produce a more precise final model in attack scenarios where FedAvg may not be effective."
  - [corpus] Weak corpus support; neighbors discuss Byzantine attacks but don't specifically validate Krum's effectiveness for label-flipping.
- Break condition: Attackers can craft gradients that are close to clean gradients in distance space while still being malicious, evading Krum's detection.

### Mechanism 2
- Claim: Multilingual emoji prediction performance degrades less than expected when moving from unilingual to multilingual training due to shared semantic features across languages.
- Mechanism: Transformer models pre-trained on multilingual corpora learn cross-lingual representations that transfer effectively, allowing emoji prediction models to leverage semantic similarities across languages.
- Core assumption: Emoji usage patterns and associated sentiments have enough cross-lingual consistency for transfer learning to be effective.
- Evidence anchors:
  - [abstract] "FL accuracy performance is confirmed in seen or unseen languages with IID and Non-IID data distributions in both unilingual and multilingual settings."
  - [section] "When comparing the unilingual and multilingual models via SemEval, we can see a drop in the Macro-F1 scores due to the mixed languages in the multilingual dataset. However, the drop was not significant, indicating that the models can handle multiple languages to a certain extent."
  - [corpus] Weak corpus support; neighbors discuss multilingual FL but don't specifically validate emoji prediction performance.
- Break condition: Languages have vastly different emoji usage patterns or cultural interpretations that prevent effective transfer learning.

### Mechanism 3
- Claim: Federated learning with appropriate aggregation can achieve accuracy comparable to centralized training without requiring raw data access.
- Mechanism: Clients train local models on their private data, then aggregate updates through weighted averaging (FedAvg) or robust methods (Krum), achieving global model quality without centralizing data.
- Core assumption: Local training followed by aggregation preserves the statistical properties needed for accurate emoji prediction while maintaining data privacy.
- Evidence anchors:
  - [abstract] "Our experimental results show that federated learning in either clean or attacked scenarios performs similarly to centralized training in multilingual emoji prediction on seen and unseen languages under different data sources and distributions."
  - [section] "FL training on emoji data achieves similar accuracy performance to traditional centralized setup."
  - [corpus] Moderate corpus support; neighbors discuss privacy benefits of FL but don't specifically validate emoji prediction accuracy.
- Break condition: Client data distributions are too heterogeneous or data quantity per client is too small for effective local training.

## Foundational Learning

- Concept: Label-flipping attack
  - Why needed here: Understanding how attackers poison data by changing labels is crucial for evaluating defense mechanisms like Krum.
  - Quick check question: If an attacker flips labels for class 1 to class 11 in a 20-class emoji prediction task, what percentage of the dataset is affected if they attack 10% of samples from class 1?

- Concept: Non-IID data distribution
  - Why needed here: The paper explicitly tests both IID and Non-IID settings, making it essential to understand how data heterogeneity across clients affects model performance.
  - Quick check question: In a 4-client FL system with Non-IID distribution where each client only has data from one language, what happens to model performance when testing on an unseen language?

- Concept: Macro-F1 vs Micro-F1 metrics
  - Why needed here: The paper uses both metrics to evaluate emoji prediction, and understanding their differences is key to interpreting results correctly.
  - Quick check question: If a model predicts all emojis as the most frequent class, what would its Macro-F1 and Micro-F1 scores be in a highly imbalanced dataset?

## Architecture Onboarding

- Component map:
  - Data pipeline: Twitter API crawler → preprocessing (stop words, hyperlinks, duplicates) → client partitioning
  - Model zoo: M-MiniLM (21M), Bert-Base (280M), XLM-R (278M), Switch-MoE (619M)
  - FL framework: Flower for orchestration, PyTorch for training, Hugging Face for model loading
  - Aggregation strategies: FedAvg (simple averaging), Krum (distance-based selection)
  - Attack simulation: Label-flipping procedure applied to 25% or 50% of clients

- Critical path:
  1. Data collection and preprocessing
  2. Client partitioning into IID/Non-IID and clean/attacked scenarios
  3. Local model training on clients
  4. Aggregation at server using FedAvg or Krum
  5. Evaluation on test sets (seen/unseen languages)

- Design tradeoffs:
  - Krum vs FedAvg: Krum provides better attack resilience but requires O(n²) distance computations per round
  - Model size vs communication efficiency: Larger models like Switch-MoE achieve better performance but increase communication overhead
  - IID vs Non-IID: IID provides better convergence but Non-IID better reflects real-world data heterogeneity

- Failure signatures:
  - Krum performance degradation: Attackers craft gradients that appear similar to clean updates
  - Accuracy collapse in Non-IID: Client data distributions are too dissimilar for effective aggregation
  - Communication bottleneck: Model sizes too large for network constraints

- First 3 experiments:
  1. Reproduce centralized training baseline with Bert-Base on SemEval dataset to establish performance floor
  2. Run IID FL with FedAvg on same dataset to verify comparable performance without attacks
  3. Introduce 25% label-flipping attack and compare FedAvg vs Krum aggregation performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different federated learning algorithms compare in their resilience to label-flipping attacks across various attack ratios (e.g., 25%, 50%, 75%)?
- Basis in paper: [explicit] The paper evaluates Krum and FedAvg under 25% and 50% label-flipping attacks, showing Krum's superiority, but does not explore other ratios or algorithms.
- Why unresolved: The study only tests two specific attack ratios and two aggregation schemes, leaving the impact of other ratios and algorithms unexamined.
- What evidence would resolve it: Systematic evaluation of Krum, FedAvg, and other algorithms (e.g., FedNova, SCAFFOLD) across a range of attack ratios (e.g., 10%, 25%, 50%, 75%) on multiple datasets.

### Open Question 2
- Question: How does federated learning performance scale with the number of clients, especially in multilingual settings with non-IID data distributions?
- Basis in paper: [explicit] The paper uses 4 clients due to resource constraints and acknowledges that findings may extend to any number of clients, but does not empirically test scalability.
- Why unresolved: The experimental setup is limited to 4 clients, so the impact of increasing client count on model accuracy and communication efficiency remains unknown.
- What evidence would resolve it: Experiments varying the number of clients (e.g., 10, 50, 100) while measuring macro-F1 scores and communication costs in multilingual, non-IID scenarios.

### Open Question 3
- Question: Can federated learning maintain competitive performance in emoji prediction when clients have highly imbalanced or domain-specific data distributions?
- Basis in paper: [inferred] The paper tests IID and non-IID distributions but does not explicitly address extreme imbalances or domain shifts, which are common in real-world multilingual emoji usage.
- Why unresolved: The non-IID setup is limited to per-language splits, not reflecting more complex imbalances or domain-specific variations in emoji usage.
- What evidence would resolve it: Experiments with artificially skewed or domain-shifted client data (e.g., varying emoji class distributions, topic-specific corpora) and assessment of federated model robustness.

### Open Question 4
- Question: How does federated learning for multilingual emoji prediction perform under more sophisticated poisoning attacks (e.g., backdoor attacks, model replacement) compared to centralized training?
- Basis in paper: [explicit] The paper focuses on label-flipping attacks and compares federated and centralized settings, but does not test more advanced poisoning strategies.
- Why unresolved: Only label-flipping is considered, missing other realistic attack vectors that could compromise federated learning in multilingual contexts.
- What evidence would resolve it: Comparative experiments introducing backdoor triggers or model replacement attacks in federated and centralized emoji prediction tasks, measuring accuracy and detection capabilities.

## Limitations

- Krum aggregation effectiveness depends on attacker sophistication - more advanced gradient-based attacks could evade distance-based detection
- The 20-emoji constraint may not generalize to full emoji sets where cultural differences in interpretation become more pronounced
- Experiments limited to 4 clients due to resource constraints, leaving scalability questions unanswered

## Confidence

- FL performance claims (Centralized vs Federated): **High** - Multiple models show consistent performance parity across different settings
- Krum attack resilience: **Medium** - Demonstrated effectiveness against label-flipping, but limited evaluation against more sophisticated attacks
- Multilingual transfer: **Medium** - Performance degradation is modest, but limited to European languages with shared emoji usage patterns

## Next Checks

1. Test Krum against gradient-based poisoning attacks where malicious updates are crafted to appear similar to clean updates in distance space
2. Evaluate on emoji prediction tasks with full Unicode emoji sets (1000+ emojis) to test scalability of the approach
3. Run ablation studies varying K parameter in Krum aggregation and attack client percentage to establish robustness bounds