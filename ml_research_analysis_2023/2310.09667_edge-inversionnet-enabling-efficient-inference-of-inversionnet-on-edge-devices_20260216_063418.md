---
ver: rpa2
title: 'Edge-InversionNet: Enabling Efficient Inference of InversionNet on Edge Devices'
arxiv_id: '2310.09667'
source_url: https://arxiv.org/abs/2310.09667
tags:
- inversionnet
- pruning
- learning
- ieee
- pages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Seismic full waveform inversion (FWI) is a key geophysical technique
  for inferring subsurface structures from seismic data. However, the high computational
  cost of existing models like InversionNet makes them challenging to deploy on resource-constrained
  edge devices, limiting their use in scenarios requiring on-device processing for
  privacy and real-time decision-making.
---

# Edge-InversionNet: Enabling Efficient Inference of InversionNet on Edge Devices

## Quick Facts
- arXiv ID: 2310.09667
- Source URL: https://arxiv.org/abs/2310.09667
- Reference count: 40
- Key outcome: Achieved up to 98.2% reduction in computational resources and 73.0% reduction in latency while maintaining moderate to negligible performance degradation

## Executive Summary
This paper addresses the challenge of deploying seismic full waveform inversion (FWI) models on resource-constrained edge devices by proposing a structured pruning algorithm for InversionNet. The approach progressively prunes filters at each layer based on their ℓ1-norm importance, fine-tunes the pruned model, and optionally retrains it to recover performance. A prototype implementation called Edge-InversionNet on a Raspberry Pi demonstrates real-time inference capabilities. Experimental results show significant computational savings with acceptable performance trade-offs, enabling efficient on-device processing for privacy and real-time decision-making in geophysical applications.

## Method Summary
The paper proposes a progressive layerwise filter pruning algorithm that reduces the computational cost of InversionNet by removing filters based on their ℓ1-norm importance scores. The pruning process is iterative, with the model being fine-tuned after each pruning step to recover performance. If performance degradation exceeds a threshold, the model is retrained from scratch with reinitialized parameters. The pruned model is then deployed on a Raspberry Pi with a graphical user interface for real-time inference and visualization. The approach is evaluated on the OpenFWI benchmark dataset using metrics such as MAE, RMSE, and SSIM to assess performance retention.

## Key Results
- Achieved up to 98.2% reduction in computational resources (parameters, FLOPs)
- Reduced latency by up to 73.0% while maintaining moderate to negligible performance degradation
- Demonstrated real-time inference on a Raspberry Pi with graphical user interface
- Validated effectiveness across multiple OpenFWI benchmark datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pruning filters based on ℓ1-norm of weights effectively reduces computational cost while preserving model performance.
- Mechanism: The pruning algorithm calculates the importance score of each filter as the ℓ1-norm of its weights. Filters with the smallest scores are removed, reducing the number of parameters and computational operations (FLOPs) quadratically with increasing pruning ratio.
- Core assumption: The ℓ1-norm of weights is a reliable proxy for filter importance, meaning filters with smaller ℓ1-norms contribute less to the model's performance.
- Evidence anchors:
  - [abstract] "Experimental results show that the pruned model achieves up to 98.2% reduction in computational resources, with up to 73.0% reduction in latency, while maintaining moderate to negligible performance degradation depending on the pruning ratio."
  - [section] "Therefore, we utilize ℓ1-norm of the weights within the filter to serve as a proxy metric to quantify the importance score of the filter. And its computation cost is small."
  - [corpus] Weak - no direct corpus evidence on ℓ1-norm as a proxy metric for filter importance in seismic FWI models.
- Break condition: If the ℓ1-norm of weights does not correlate with filter importance, pruning may remove critical filters, leading to significant performance degradation.

### Mechanism 2
- Claim: Progressive layerwise filter pruning maintains model performance by gradually reducing the number of filters.
- Mechanism: The pruning algorithm removes filters at each layer in a progressive manner, iteratively fine-tuning the model to recover performance. This approach prevents drastic performance drops that might occur with aggressive, non-progressive pruning.
- Core assumption: Gradual reduction of filters allows the model to adapt and maintain its performance, as opposed to sudden, large-scale pruning.
- Evidence anchors:
  - [abstract] "Experimental results show that the pruned model achieves up to 98.2% reduction in computational resources, with up to 73.0% reduction in latency, while maintaining moderate to negligible performance degradation depending on the pruning ratio."
  - [section] "The pruning algorithm prunes the filters at each layer of M at a ratio of R uniformly (i.e., only 1 − R filters are preserved) and aims to maintain the performance of the lightweight InversionNet M′."
  - [corpus] Weak - no direct corpus evidence on the effectiveness of progressive layerwise pruning in seismic FWI models.
- Break condition: If the model's performance degrades significantly after progressive pruning, it suggests that the gradual approach is insufficient to maintain performance.

### Mechanism 3
- Claim: Fine-tuning and retraining after pruning helps recover model performance by adjusting the remaining parameters.
- Mechanism: After pruning, the model is fine-tuned on the training set to recover performance. If the performance loss exceeds a threshold, the model is retrained from scratch with reinitialized parameters to find a better local minimum.
- Core assumption: Fine-tuning and retraining can effectively adjust the remaining parameters to compensate for the removed filters and maintain or improve performance.
- Evidence anchors:
  - [abstract] "The parameters of the pruned InversionNet will then be fine-tuned or retrained to further recover the model performance."
  - [section] "By fine-tuning on the training set, the performance of the model on the validation set can usually be recovered. If the loss L ≤ T, then the fine-tuned model will be the output of the pruning algorithm."
  - [corpus] Weak - no direct corpus evidence on the effectiveness of fine-tuning and retraining in seismic FWI models.
- Break condition: If fine-tuning and retraining fail to recover performance, it suggests that the remaining parameters are not sufficient to maintain the model's capabilities.

## Foundational Learning

- Concept: Structured pruning in neural networks
  - Why needed here: To reduce the computational cost of InversionNet, making it suitable for deployment on edge devices with limited resources.
  - Quick check question: What is the difference between structured and unstructured pruning, and why is structured pruning preferred for edge device deployment?

- Concept: Full Waveform Inversion (FWI) in geophysics
  - Why needed here: To understand the context and application of InversionNet, which is a data-driven machine learning model used for solving the FWI problem.
  - Quick check question: How does FWI differ from traditional seismic imaging techniques, and what are the advantages of using a data-driven approach like InversionNet?

- Concept: Edge computing and resource-constrained devices
  - Why needed here: To appreciate the challenges and requirements of deploying machine learning models on edge devices, which have limited computational resources, memory, and energy.
  - Quick check question: What are the key considerations when deploying machine learning models on edge devices, and how does structured pruning address these challenges?

## Architecture Onboarding

- Component map: Pre-trained InversionNet model -> Structured pruning algorithm -> Fine-tuned/retrained pruned model -> Raspberry Pi with GUI -> OpenFWI benchmark datasets

- Critical path: 1. Load pre-trained InversionNet model 2. Apply structured pruning algorithm with specified pruning ratio 3. Fine-tune or retrain pruned model to recover performance 4. Deploy pruned model on Raspberry Pi 5. Run inference on seismic data and visualize results using GUI

- Design tradeoffs:
  - Pruning ratio vs. model performance: Higher pruning ratios lead to greater computational savings but may result in more significant performance degradation.
  - Fine-tuning vs. retraining: Fine-tuning is faster and requires less computational resources, but retraining from scratch may be necessary if performance loss exceeds a threshold.
  - Real-time inference vs. model accuracy: Optimizing for real-time inference on edge devices may require accepting some loss in model accuracy.

- Failure signatures:
  - Significant performance degradation after pruning, indicating that critical filters were removed or that fine-tuning/retraining was insufficient.
  - Inability to deploy pruned model on edge device due to memory or computational constraints.
  - GUI not displaying input or output correctly, suggesting issues with data preprocessing or model inference.

- First 3 experiments:
  1. Apply structured pruning with a moderate pruning ratio (e.g., 0.5) and evaluate the reduction in computational resources and the impact on model performance.
  2. Test the pruned model on a subset of the OpenFWI benchmark datasets and compare the results with the baseline (unpruned) model in terms of MAE, RMSE, and SSIM.
  3. Deploy the pruned model on the Raspberry Pi and measure the inference latency, ensuring that it meets the real-time requirements for the target application.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can unsupervised learning be effectively applied to seismic full waveform inversion on edge devices?
- Basis in paper: [explicit] The paper mentions unsupervised learning as a potential future direction, noting that it is more practical for real applications since obtaining labeled data is costly.
- Why unresolved: While the paper acknowledges the importance of unsupervised learning, it does not provide any specific methods or techniques for implementing it in the context of seismic FWI on edge devices.
- What evidence would resolve it: Developing and demonstrating an effective unsupervised learning algorithm for seismic FWI that can be deployed on edge devices, showing comparable performance to supervised methods.

### Open Question 2
- Question: How can on-device learning be implemented for seismic FWI on resource-constrained edge devices?
- Basis in paper: [explicit] The paper identifies on-device learning as a future direction, highlighting the challenges of implementing it on resource-constrained devices due to computational, storage, and memory constraints.
- Why unresolved: The paper does not provide any specific strategies or techniques for implementing on-device learning for seismic FWI on edge devices.
- What evidence would resolve it: Developing and demonstrating an on-device learning algorithm for seismic FWI that can be effectively deployed on resource-constrained edge devices, showing improved performance and reduced latency compared to centralized training.

### Open Question 3
- Question: How can federated learning be applied to solve seismic FWI problems on distributed edge devices?
- Basis in paper: [explicit] The paper mentions federated learning as a potential future direction for addressing the lack of labeled data in seismic FWI by leveraging distributed devices.
- Why unresolved: The paper does not provide any specific methods or techniques for implementing federated learning for seismic FWI on edge devices.
- What evidence would resolve it: Developing and demonstrating a federated learning algorithm for seismic FWI that can be effectively deployed on distributed edge devices, showing improved performance and reduced data privacy concerns compared to centralized training.

## Limitations

- The paper's evaluation is limited to synthetic datasets from the OpenFWI benchmark, which may not capture the complexity and noise characteristics of real-world seismic data.
- The 98.2% reduction in computational resources is achieved at pruning ratios that may not be practical for all deployment scenarios, as performance degradation becomes more pronounced at higher pruning ratios.
- The study does not address the potential impact of model quantization or other optimization techniques that could further improve edge deployment efficiency.

## Confidence

- **High Confidence**: The claim that structured pruning can reduce computational resources by up to 98.2% is supported by experimental results and the mathematical basis of the pruning algorithm. The methodology for progressive layerwise pruning is clearly specified and reproducible.
- **Medium Confidence**: The assertion that fine-tuning and retraining can recover model performance after pruning is based on reasonable assumptions and common practice in neural network pruning, but lacks specific validation for seismic FWI models.
- **Low Confidence**: The claim that the pruned model maintains "moderate to negligible performance degradation" is not uniformly supported across all pruning ratios and evaluation metrics, with some degradation being more significant than others.

## Next Checks

1. **Real-world Data Validation**: Test the pruned models on real seismic datasets from field acquisitions to verify that the performance degradation observed on synthetic data does not become prohibitive in practical applications.

2. **Cross-model Generalization**: Apply the same pruning methodology to other data-driven FWI models (e.g., U-Net, ResNet) to assess whether the effectiveness of ℓ1-norm pruning is model-specific or generalizable across different architectures.

3. **Edge Deployment Benchmarking**: Conduct a comprehensive evaluation of the pruned models on multiple edge devices with varying computational capabilities to establish performance-latency tradeoffs and identify optimal pruning ratios for different hardware constraints.