---
ver: rpa2
title: 'InstructAlign: High-and-Low Resource Language Alignment via Continual Crosslingual
  Instruction Tuning'
arxiv_id: '2305.13627'
source_url: https://arxiv.org/abs/2305.13627
tags:
- languages
- language
- cross-lingual
- data
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Instruct-Align (IA), a framework that enables
  large language models to learn new languages through cross-lingual alignment with
  previously learned languages, addressing the challenge of catastrophic forgetting
  when adapting instruction-tuned models to underrepresented languages. The method
  uses alignment-based cross-lingual instructions at word, span, and sentence levels,
  combined with continual learning via experience replay to retain past knowledge.
---

# InstructAlign: High-and-Low Resource Language Alignment via Continual Crosslingual Instruction Tuning

## Quick Facts
- arXiv ID: 2305.13627
- Source URL: https://arxiv.org/abs/2305.13627
- Reference count: 14
- Key outcome: IA improves zero-shot performance on 7 Indonesian local languages by ~5% accuracy/F1-score compared to baselines while preventing catastrophic forgetting

## Executive Summary
InstructAlign (IA) addresses the challenge of adapting instruction-tuned large language models to underrepresented languages without losing existing multilingual capabilities. The framework uses cross-lingual alignment through instruction tuning at word, span, and sentence levels, combined with continual learning via experience replay. Experiments on BLOOMZ-560M show IA significantly outperforms monolingual denoising baselines for learning new languages with limited parallel data, achieving ~5% improvement in accuracy and F1-score on Indonesian local languages.

## Method Summary
InstructAlign adapts BLOOMZ models to new languages through continual cross-lingual instruction tuning. The method generates alignment-based instructions from parallel corpora at three levels: word-level conditional denoising, span-level conditional denoising, and sentence-level machine translation. During optimization, experience replay interleaves newly generated cross-lingual instruction data with randomly sampled past instruction-tuning samples to prevent catastrophic forgetting. The framework is evaluated on zero-shot cross-lingual inference tasks using Indonesian and 7 Indonesian local languages.

## Key Results
- IA improves zero-shot performance on 7 Indonesian local languages by ~5% accuracy and F1-score compared to baselines
- Cross-lingual alignment is more effective than monolingual denoising for learning new languages with limited data
- Experience replay with 1000 samples prevents catastrophic forgetting while maintaining adaptation effectiveness

## Why This Works (Mechanism)

### Mechanism 1
Cross-lingual alignment through instruction tuning allows models to learn new languages using limited parallel data while maintaining existing multilingual capabilities. The framework generates alignment-based cross-lingual instructions at word, span, and sentence levels from parallel corpora, forcing the model to map between seen and unseen languages through conditional denoising and machine translation tasks.

### Mechanism 2
Experience replay prevents catastrophic forgetting by interleaving past and new instruction data during continual tuning. The model samples balanced batches containing both newly generated cross-lingual instruction data and randomly selected samples from the original instruction-tuning dataset, maintaining performance on previously learned languages.

### Mechanism 3
Conditional denoising at multiple granularities is more effective than monolingual denoising for learning new languages with limited data. By masking tokens in target language sentences conditioned on source language context, the model learns to predict missing elements based on cross-lingual alignment rather than pure language modeling.

## Foundational Learning

- **Catastrophic forgetting in continual learning**: Directly addresses the core problem of adapting instruction-tuned models to new languages without losing existing multilingual capabilities. Quick check: What happens to model performance on previously learned tasks when you fine-tune on new tasks without any regularization?
- **Cross-lingual alignment learning**: Forms the theoretical foundation for how the model transfers knowledge between languages through parallel data. Quick check: How does token-level alignment in translation language modeling (TLM) differ from sentence-level alignment in machine translation?
- **Continual learning through experience replay**: Explains the specific mechanism used to prevent forgetting while adapting to new languages. Quick check: Why does interleaving past and present data samples during training help maintain performance on older tasks?

## Architecture Onboarding

- **Component map**: BLOOMZ backbone → Instruction tuning dataset generator → Continual learning module → Evaluation pipeline
- **Critical path**: Generate parallel data → Create alignment-based instructions → Tune with experience replay → Evaluate zero-shot performance
- **Design tradeoffs**: Model size vs. adaptation effectiveness (larger models perform better but cost more); replay buffer size vs. catastrophic forgetting (r=1000 optimal vs r=10000 suboptimal)
- **Failure signatures**: Catastrophic forgetting (performance drop on seen languages); poor adaptation (low accuracy on new languages); overfitting (high training loss but low validation loss)
- **First 3 experiments**: 1) Run IA1 with r=0 to observe catastrophic forgetting baseline; 2) Run IA1 with r=1000 to verify optimal replay buffer size; 3) Run IA1 with r=10000 to test upper bound of replay effectiveness

## Open Questions the Paper Calls Out

- How does InstructAlign's performance scale when applied to larger language models beyond BLOOMZ-560M?
- What is the optimal number of experience replay samples to balance catastrophic forgetting prevention with learning efficiency?
- How well does InstructAlign generalize to languages that are typologically distant from the pre-training languages rather than closely related Indonesian languages?
- What alternative continual learning methods could improve upon InstructAlign's experience replay approach for preventing catastrophic forgetting?

## Limitations

- Results only tested on Indonesian and 7 Indonesian local languages, limiting cross-linguistic generalizability
- Only evaluated on BLOOMZ-560M model size, raising questions about scalability to larger models
- Does not explore scenarios with extremely limited parallel data (<<1000 sentence pairs)

## Confidence

**High Confidence (80-100%)**: Experience replay with 1000 samples effectively prevents catastrophic forgetting for this model size and dataset configuration; The three-task alignment framework can be implemented as described; Zero-shot evaluation methodology using multiple prompts is sound and reproducible

**Medium Confidence (50-80%)**: Cross-lingual alignment is more effective than monolingual denoising for this specific language family; The r=1000 replay buffer size represents an optimal balance for this particular model and task; Results generalize to other language families with similar typological characteristics

**Low Confidence (0-50%)**: The approach scales effectively to much larger models (e.g., BLOOMZ-7B, 13B) without modification; Performance improvements (~5%) are consistent across all language pairs and task types; The method works equally well with minimal parallel data (<<1000 sentence pairs)

## Next Checks

1. Apply the IA framework to a different language family (e.g., Romance languages) with varying degrees of linguistic similarity to evaluate whether the 5% improvement generalizes beyond Indonesian-related languages.

2. Systematically reduce the amount of parallel training data (e.g., 100, 500, 1000, 5000 sentence pairs) to determine the minimum viable data requirement for effective cross-lingual alignment and identify breaking points.

3. Replicate the study using BLOOMZ-1.3B and BLOOMZ-7.1B to assess how catastrophic forgetting and alignment effectiveness scale with model size, and whether the optimal replay buffer size (r=1000) remains effective.