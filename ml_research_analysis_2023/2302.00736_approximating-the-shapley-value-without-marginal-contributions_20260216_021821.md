---
ver: rpa2
title: Approximating the Shapley Value without Marginal Contributions
arxiv_id: '2302.00736'
source_url: https://arxiv.org/abs/2302.00736
tags:
- shapley
- value
- player
- each
- marginal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents two parameter-free, domain-independent approximation
  algorithms for Shapley values, SVARM and Stratified SVARM, which do not rely on
  marginal contributions. Instead, they sample coalitions directly and update multiple
  Shapley value estimates at once.
---

# Approximating the Shapley Value without Marginal Contributions

## Quick Facts
- arXiv ID: 2302.00736
- Source URL: https://arxiv.org/abs/2302.00736
- Reference count: 40
- Key outcome: Parameter-free algorithms (SVARM, Stratified SVARM) approximate Shapley values without marginal contributions, achieving logarithmic dependence on player count n and outperforming state-of-the-art methods

## Executive Summary
This paper introduces two novel algorithms for approximating Shapley values that avoid computing marginal contributions. Instead, they sample coalitions directly from tailored distributions and update multiple Shapley value estimates simultaneously. The key innovation is reformulating the Shapley value as a difference between signed Shapley values, enabling efficient sampling and updating strategies. Theoretical analysis shows variance bounds with logarithmic dependence on player count n, improving upon existing linear dependencies. Empirical results demonstrate superior performance compared to state-of-the-art methods like KernelSHAP and ApproShapley, especially for larger n.

## Method Summary
The paper presents SVARM and Stratified SVARM, two parameter-free approximation algorithms that reformulate the Shapley value without relying on marginal contributions. SVARM samples coalitions from two distributions P+ and P- and updates multiple Shapley value estimates simultaneously. Stratified SVARM further decomposes the approximation by coalition size, creating strata with lower variance. Both algorithms use paired sampling to maximize information extraction from each value function evaluation. Theoretical analysis provides variance bounds showing O(log n) dependence on player count, while empirical results demonstrate superior performance on synthetic games compared to existing methods.

## Key Results
- Stratified SVARM achieves variance bounds with O(log n) dependence on player count n, improving upon existing O(n) bounds
- Empirical results show Stratified SVARM outperforms state-of-the-art methods like KernelSHAP and ApproShapley on synthetic games
- Both algorithms are unbiased, incremental, and don't require knowledge of the value function
- Paired sampling doubles efficiency by updating all players simultaneously with each single coalition sampled

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Shapley value can be reformulated without marginal contributions, enabling more efficient approximation.
- Mechanism: Instead of computing weighted averages of marginal contributions, the Shapley value is expressed as the difference between two signed Shapley values (φ⁺ and φ⁻), each an expected value over coalitions. This allows sampling coalitions directly and updating multiple estimates simultaneously.
- Core assumption: The weights w_S = 1/(n·(n-1 choose |S|)) for S⊆N_i satisfy probability distribution conditions needed for unbiased estimation.
- Evidence anchors:
  - [abstract]: "two parameter-free and domain-independent approximation algorithms based on a representation of the Shapley value detached from the notion of marginal contributions"
  - [section]: "The Shapley value of i is a weighted average of all its marginal contributions... We call the increase in worth that comes with the inclusion of player i to a coalition S, i.e., the difference ν(S∪{i})−ν(S), player i's marginal contribution to S⊆N_i"
- Break condition: If the weight distribution doesn't satisfy probability conditions, the algorithm becomes biased.

### Mechanism 2
- Claim: Stratified sampling of coalitions by size reduces variance compared to uniform sampling.
- Mechanism: The positive and negative Shapley values are decomposed into ℓ-th positive and negative Shapley subvalues (φ⁺ᵢ,ℓ and φ⁻ᵢ,ℓ) for each coalition size ℓ. This creates strata with lower variance than the original distributions, leading to better approximation quality.
- Core assumption: Coalitions of the same size have more similar worths than coalitions of different sizes, making stratification effective.
- Evidence anchors:
  - [abstract]: "Based on a partitioning of the set of all coalitions according to their size, we develop with Stratified SVARM a refinement of SV ARM"
  - [section]: "We call φ⁺ᵢ,ℓ the ℓ-th positive Shapley subvalue and φ⁻ᵢ,ℓ the ℓ-th negative Shapley subvalue"
- Break condition: If coalition worths don't vary systematically with size, stratification provides no variance reduction.

### Mechanism 3
- Claim: Paired sampling with coalition complements doubles the efficiency of each evaluation.
- Mechanism: When sampling a coalition A, both A and its complement N\A are used to update Shapley value estimates. This paired sampling approach updates all players simultaneously with each single coalition sampled, maximizing information extraction from each value function evaluation.
- Core assumption: The value function is defined for all coalitions and their complements, and paired sampling maintains unbiasedness.
- Evidence anchors:
  - [abstract]: "empirical results including synthetic games as well as common explainability use cases comparing ourselves with state-of-the-art methods"
  - [section]: "Utilizing a representation of the Shapley value as an integral (Owen, 1972), Owen Sampling (Okhrati & Lipani, 2020) approximates this integral by sampling marginal contributions using antithetic sampling"
- Break condition: If the value function evaluation is asymmetric for coalitions and their complements, paired sampling introduces bias.

## Foundational Learning

- Concept: Cooperative game theory and the Shapley value
  - Why needed here: The entire paper builds on understanding how to fairly allocate collective benefits among players in cooperative games
  - Quick check question: What are the four Shapley axioms that uniquely characterize the Shapley value?

- Concept: Variance reduction through stratification
  - Why needed here: The key innovation is decomposing the approximation problem into strata to achieve logarithmic rather than linear dependence on player count
  - Quick check question: How does the variance of a stratified estimator compare to a simple random sample estimator?

- Concept: Monte Carlo estimation and unbiased sampling
  - Why needed here: Both algorithms rely on sampling coalitions from carefully designed distributions to produce unbiased estimates
  - Quick check question: What conditions must a sampling distribution satisfy to produce an unbiased estimator of an expected value?

## Architecture Onboarding

- Component map:
  - Core algorithms: SVARM and Stratified SVARM
  - Supporting components: Warm-up phase, paired sampling, normalization
  - Theoretical analysis: Variance bounds, MSE bounds, probabilistic bounds
  - Empirical evaluation: Game implementations, comparison metrics

- Critical path:
  1. Initialize all Shapley value estimates to zero
  2. Execute warm-up phase to ensure each estimate has at least one sample
  3. Alternate between sampling coalitions from P+ and P- distributions
  4. Update multiple estimates simultaneously based on sampled coalitions
  5. Compute final Shapley value estimates from signed components

- Design tradeoffs:
  - Space complexity: SVARM uses O(n) space while Stratified SVARM uses O(n²) space for storing per-stratum estimates
  - Variance vs. computational cost: Stratified approach has lower variance but requires more complex sampling
  - Exact vs. approximate: The algorithms sacrifice exact computation for tractable approximation with provable guarantees

- Failure signatures:
  - High variance in estimates: May indicate poor choice of sampling distribution or insufficient budget
  - Bias in estimates: Could result from incorrect weight calculations or violation of probability distribution conditions
  - Slow convergence: Might suggest the game has high variance across coalitions or the sampling strategy isn't well-matched to the value function structure

- First 3 experiments:
  1. Implement the Shoe game and verify that both algorithms produce estimates close to the known Shapley value of 0.5 for all players
  2. Test SVARM on the Airport game and measure variance reduction compared to ApproShapley as budget increases
  3. Implement Stratified SVARM on a synthetic SOUG game and verify the logarithmic variance bound empirically by varying n and T

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can structural properties of the value function (such as monotonicity or supermodularity) be leveraged to improve the approximation quality of SVARM and Stratified SVARM?
- Basis in paper: Explicit - The authors suggest this as a direction for future work in the conclusion.
- Why unresolved: The theoretical analysis and empirical evaluation in the paper do not explore how specific structural properties of the value function might affect the performance of the proposed algorithms.
- What evidence would resolve it: Empirical studies comparing the performance of SVARM and Stratified SVARM on games with varying structural properties, or theoretical analysis deriving bounds that incorporate such properties.

### Open Question 2
- Question: What are the lower bounds on the mean squared error and probability of deviation for approximating Shapley values, and can they be used to assess the tightness of the proposed algorithms' theoretical guarantees?
- Basis in paper: Explicit - The authors mention deriving lower bounds as a desirable goal for future work in the conclusion.
- Why unresolved: The paper provides upper bounds on the mean squared error and probability of deviation for the proposed algorithms but does not establish corresponding lower bounds to determine the algorithms' optimality.
- What evidence would resolve it: Formal proofs of lower bounds on the mean squared error and probability of deviation for any algorithm approximating Shapley values under a fixed budget, and comparison with the proposed algorithms' upper bounds.

### Open Question 3
- Question: How does the performance of Stratified SVARM+ compare to other state-of-the-art methods in terms of mean squared error and variance across different types of cooperative games?
- Basis in paper: Explicit - The authors mention using an empirical version of Stratified SVARM+ in their experiments but do not provide a detailed comparison with other methods.
- Why unresolved: The paper includes a brief mention of Stratified SVARM+ but does not present a comprehensive evaluation of its performance relative to other algorithms.
- What evidence would resolve it: Detailed empirical results comparing the mean squared error and variance of Stratified SVARM+ with other state-of-the-art methods across various cooperative games, including different budget sizes and player counts.

## Limitations
- Empirical evaluation focuses on synthetic games rather than real-world explainability use cases
- Paired sampling assumes value function symmetry between coalitions and their complements
- O(n²) space complexity of Stratified SVARM could become prohibitive for large n
- Performance gains may be less pronounced when coalition worths don't vary systematically with size

## Confidence
- **High Confidence**: The algorithmic framework and mathematical derivations are sound, with clear pseudocode and rigorous theoretical analysis supporting the O(log n) variance bounds
- **Medium Confidence**: The empirical results show Stratified SVARM outperforming competitors on synthetic games, but the limited scope of experiments prevents strong claims about real-world applicability
- **Low Confidence**: The claimed advantage of Stratified sampling over simpler approaches in practice, particularly for games where coalition worths don't correlate strongly with coalition size

## Next Checks
1. **Variance Bound Verification**: Implement the theoretical variance bound O(∑ᵢ E[(φ⁺ᵢ)² + (φ⁻ᵢ)²]/T) and empirically verify the logarithmic dependence on n by testing across different player counts (n=5, 10, 20, 50) with fixed T.

2. **Paired Sampling Bias Test**: Construct a game where ν(S) ≠ ν(N\S) and verify that paired sampling doesn't introduce bias in the estimates, confirming the theoretical unbiasedness claim holds even with asymmetric value functions.

3. **Stratification Effectiveness**: Test Stratified SVARM on a game where coalition worths are independent of size to verify whether the variance reduction from stratification still provides benefits, or if it degrades to performance similar to SVARM.