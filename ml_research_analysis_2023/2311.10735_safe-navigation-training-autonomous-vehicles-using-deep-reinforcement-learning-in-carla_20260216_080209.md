---
ver: rpa2
title: 'Safe Navigation: Training Autonomous Vehicles using Deep Reinforcement Learning
  in CARLA'
arxiv_id: '2311.10735'
source_url: https://arxiv.org/abs/2311.10735
tags:
- driving
- deep
- agent
- vehicles
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of training autonomous vehicles
  to navigate safely in complex urban environments using deep reinforcement learning.
  The authors propose a method that combines Deep Q-Networks (DQN) with pre-processing
  of sensor data to reduce the state space and improve training efficiency.
---

# Safe Navigation: Training Autonomous Vehicles using Deep Reinforcement Learning in CARLA

## Quick Facts
- arXiv ID: 2311.10735
- Source URL: https://arxiv.org/abs/2311.10735
- Reference count: 8
- Primary result: 94% success rate navigating to destination without collisions in CARLA

## Executive Summary
This paper presents a deep reinforcement learning approach for autonomous vehicle navigation in complex urban environments. The method uses pre-processed sensor data to reduce state space complexity and employs two specialized DQN models for braking and driving decisions. Tested in the CARLA simulator with traffic scenarios, the approach achieves high success rates while maintaining safety standards.

## Method Summary
The approach combines Deep Q-Networks with sensor data pre-processing to reduce state space and improve training efficiency. Two separate DQN models are trained - one for braking and one for driving - using four key variables: lateral distance to road centerline, vehicle orientation, minimum obstacle distance, and velocity. The models are trained on 40 episodes each and combined hierarchically based on traffic light status and obstacle proximity.

## Key Results
- 94% success rate in navigating to destination without collisions
- Effective navigation through traffic scenarios with vehicles and pedestrians
- Successful performance across 4 different test trajectories in CARLA

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sensor pre-processing reduces state space while preserving navigational accuracy.
- Mechanism: Segmentation and depth images are processed to extract minimal relevant variables, replacing raw image inputs with compact numeric state vectors.
- Core assumption: Four selected variables fully capture necessary information for safe navigation.
- Evidence anchors: Abstract mentions pre-processing step; section details variable selection; corpus shows weak comparative evidence.
- Break condition: Missing critical variable (e.g., pedestrian speed) may cause failures in complex scenarios.

### Mechanism 2
- Claim: Hierarchical DQN architecture separates safety-critical braking from path-following driving.
- Mechanism: Braking DQN handles collision avoidance using obstacle distance and velocity, while driving DQN handles path adherence using lateral offset and orientation.
- Core assumption: Decoupling allows each model to specialize without interference.
- Evidence anchors: Section describes two separate models; abstract mentions hierarchical approach; corpus shows few similar studies.
- Break condition: Permissive braking thresholds may allow collisions before braking is triggered.

### Mechanism 3
- Claim: Epsilon-greedy policy with experience replay stabilizes training in sparse-reward traffic environments.
- Mechanism: Experience replay stores past transitions, breaking temporal correlations; epsilon-greedy balances exploration/exploitation.
- Core assumption: Sufficient replay buffer diversity prevents overfitting to short trajectories.
- Evidence anchors: Section mentions epsilon-greedy and experience replay; corpus shows moderate evidence of standard DQN techniques.
- Break condition: Small replay buffer may cause training divergence due to correlated samples.

## Foundational Learning

- Concept: Markov Decision Process (MDP) formulation of autonomous driving.
  - Why needed here: Models navigation as sequential decision-making where state determines next action probabilities.
  - Quick check question: What constitutes the state, action, and reward in this MDP? (Answer: State = [d, φ, dobs, v]; Action = discrete throttle/steer/brake; Reward = safety and progress signals.)

- Concept: Function approximation in high-dimensional spaces.
  - Why needed here: Raw sensor images are high-dimensional; DQN approximates Q(s,a) over compact state vectors.
  - Quick check question: Why is direct image input to DQN problematic? (Answer: Large state space leads to poor generalization on unseen trajectories.)

- Concept: Reward shaping for safe navigation.
  - Why needed here: Shaped rewards guide behavior earlier than sparse rewards (only at goal or collision).
  - Quick check question: What reward components encourage staying on road vs. avoiding collisions? (Answer: d, φ penalties for off-road; dobs penalties for close obstacles; collision penalties.)

## Architecture Onboarding

- Component map: CARLA simulator -> Sensors -> Pre-processing pipeline -> State vector [d, φ, dobs, v] -> Braking DQN -> Driving DQN -> Traffic light check -> Action executor
- Critical path: Pre-processing -> State vector -> Hierarchical DQN decision -> CARLA action -> Reward -> Experience replay
- Design tradeoffs:
  - State reduction vs. loss of fine-grained detail
  - Discrete action space vs. smooth control
  - Two separate DQNs vs. single unified model
- Failure signatures:
  - High collision rate -> braking model too slow or thresholds mis-tuned
  - Drifting off road -> driving model fails to correct φ or d
  - Deadlock at intersections -> traffic light logic or obstacle classification fails
- First 3 experiments:
  1. Train braking model alone on straight road with front vehicle; verify collision-free stopping
  2. Train driving model alone on left/right turn episodes; verify staying within 1.5m of center
  3. Combine models with traffic light gating; test on simple intersection; measure success rate and collision frequency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance compare to other state-of-the-art autonomous driving approaches?
- Basis in paper: The paper mentions high success rate but provides no comparative analysis.
- Why unresolved: No comparative experiments or benchmarks against other methods.
- What evidence would resolve it: Comparative experiments with metrics like collision rate, success rate, and accuracy against other state-of-the-art approaches.

### Open Question 2
- Question: How does the method generalize to more complex traffic scenarios?
- Basis in paper: Tests on 4 trajectories with vehicles and pedestrians but doesn't explore complex scenarios.
- Why unresolved: No results or analysis on performance in highways, intersections, or roundabouts.
- What evidence would resolve it: Experimental results in diverse scenarios like highways, intersections, and roundabouts to evaluate generalizability.

### Open Question 3
- Question: How does the method handle dynamic and unpredictable obstacles?
- Basis in paper: Uses segmentation and depth cameras but provides no details on handling dynamic obstacles.
- Why unresolved: No analysis or results on performance with pedestrians crossing or vehicles changing lanes.
- What evidence would resolve it: Experimental results with dynamic obstacles like crossing pedestrians or lane-changing vehicles.

## Limitations
- Narrow validation scope with only 4 test trajectories
- No ablation study confirming all four state variables are necessary
- Limited analysis of failure modes when braking and driving models conflict

## Confidence
- Sensor pre-processing mechanism: Medium
- Hierarchical DQN architecture: Medium
- MDP formulation and reward shaping: High
- Overall approach: Medium

## Next Checks
1. Test model performance across 20+ diverse trajectories with varying traffic densities
2. Conduct ablation studies removing each of the four state variables
3. Implement stress tests with unexpected scenarios (sudden pedestrian crossings, occluded vehicles)