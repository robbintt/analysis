---
ver: rpa2
title: 'BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional
  decomposition'
arxiv_id: '2308.14906'
source_url: https://arxiv.org/abs/2308.14906
tags:
- time
- imputation
- series
- bayotide
- kernel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BayOTIDE is a Bayesian online method for multivariate time series
  imputation with continuous-time modeling. It decomposes series into weighted combinations
  of low-rank temporal factors modeled with GPs, converted into state-space form for
  efficient online inference.
---

# BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional decomposition

## Quick Facts
- arXiv ID: 2308.14906
- Source URL: https://arxiv.org/abs/2308.14906
- Reference count: 39
- BayOTIDE outperforms offline and deterministic baselines in both accuracy and uncertainty quantification

## Executive Summary
BayOTIDE is a Bayesian online method for multivariate time series imputation that models data as weighted combinations of low-rank temporal factors. It uses Gaussian Processes (GPs) with continuous-time modeling to handle arbitrary timestamps and quantify uncertainty. The method converts GPs to state-space form for efficient online inference, enabling scalable processing of high-dimensional time series. Experiments on synthetic and real-world datasets demonstrate superior performance compared to both offline and deterministic baselines.

## Method Summary
BayOTIDE decomposes multivariate time series into weighted combinations of trend and seasonality factors modeled with GPs. The GPs are converted to equivalent stochastic differential equations (SDEs) for efficient online inference using Kalman filtering. The method employs conditional expectation propagation with moment matching for posterior updates, allowing it to handle arbitrary timestamps and provide uncertainty quantification. The approach scales linearly with the number of channels and can process data streams in real-time.

## Key Results
- BayOTIDE outperforms offline and deterministic baselines in imputation accuracy
- Provides reliable uncertainty quantification with well-calibrated predictions
- Scales linearly to datasets with over 4000 channels
- Handles irregular timestamps and missing values effectively

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The decomposition into weighted trend and seasonality factors allows the model to capture global patterns missed by local-sequence methods.
- Mechanism: The multivariate time series is modeled as a weighted combination of low-rank temporal factors (trends and periodic components). This global decomposition means the model does not lose long-range dependencies when training, unlike patch-based methods.
- Core assumption: The true data generating process can be approximated as a linear combination of a small number of global temporal patterns.
- Evidence anchors:
  - [abstract] "decomposes series into weighted combinations of low-rank temporal factors modeled with GPs"
  - [section] "The motivation of BayOTIDE is based on the fact that the different channels of real-world multivariate time series X(t) are always correlated, and there may exist shared temporal patterns across channels."
- Break condition: If the underlying patterns are highly localized or non-stationary in a way that cannot be represented by smooth, global factors, the model will miss those patterns.

### Mechanism 2
- Claim: The continuous-time GP formulation allows imputation at arbitrary timestamps, not just observed ones.
- Mechanism: Gaussian Processes are used as functional priors over the factor functions. Because GPs are defined over continuous time, predictions can be made at any timestamp, even those not seen during training.
- Core assumption: The temporal factors are smooth and can be interpolated/extrapolated using a GP prior.
- Evidence anchors:
  - [abstract] "handle imputation over arbitrary time stamps"
  - [section] "As it is a Bayesian model, BayOTIDE can offer uncertainty quantification and robustness against noise. The learned functional factors can provide not only interpretability but also imputation over arbitrary time stamps."
- Break condition: If the underlying function is not smooth (e.g., abrupt jumps or discontinuities), the GP prior will produce poor predictions.

### Mechanism 3
- Claim: The SDE/state-space conversion of GPs enables efficient online inference for streaming data.
- Mechanism: GPs are converted to equivalent linear time-invariant stochastic differential equations (SDEs). This allows the use of Kalman filtering/smoothing for online updates with linear time complexity.
- Core assumption: The stationary kernels used (Matern, periodic) admit SDE representations, and the online inference approximations remain accurate.
- Evidence anchors:
  - [abstract] "convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE), and developing a scalable algorithm for online inference."
  - [section] "For computational efficiency, we further convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE), and developing a scalable algorithm for online inference."
- Break condition: If the posterior updates accumulate error over time or if the SDE approximation loses important GP properties, the online performance degrades.

## Foundational Learning

- Concept: Gaussian Processes and their kernel functions
  - Why needed here: The method relies on GPs as priors for modeling temporal factors. Understanding kernel choices (Matern for trends, periodic for seasonality) is crucial.
  - Quick check question: What kernel would you choose if the data had a weekly seasonality and why?

- Concept: State-space models and Kalman filtering
  - Why needed here: The GP-to-SDE conversion yields a state-space model. Efficient online inference uses Kalman filter updates.
  - Quick check question: How does the Kalman filter update its estimate when a new observation arrives?

- Concept: Expectation Propagation and moment matching
  - Why needed here: The online inference uses conditional expectation propagation with moment matching to approximate the posterior.
  - Quick check question: In EP, what is the role of the "tilted distribution"?

## Architecture Onboarding

- Component map: Input -> Decomposition layer -> GP priors -> SDE conversion -> Online inference (Kalman + EP) -> Imputation -> Output
- Critical path: Time series → decomposition → GP priors → SDE → online update (Kalman + EP) → prediction
- Design tradeoffs:
  - Number of factors (Dr, Ds) vs. model complexity and overfitting
  - Choice of kernel smoothness (Matern ν) vs. flexibility vs. computational cost
  - Damping in CEP updates vs. convergence speed vs. stability
  - Online update frequency vs. real-time requirements vs. accuracy
- Failure signatures:
  - Poor imputation accuracy: Too few factors, wrong kernel choice, excessive damping
  - Unstable online updates: Numerical issues in CEP, ill-conditioned matrices
  - High uncertainty: Noise model mis-specified, insufficient data coverage
  - Slow inference: Too many factors, inefficient implementation
- First 3 experiments:
  1. Synthetic data with known trend+seasonal components → check recovery accuracy and uncertainty calibration
  2. Real dataset with irregular timestamps → compare imputation vs. fixed-interval methods
  3. Streaming simulation → measure online RMSE over time as more data arrives

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does BayOTIDE's performance scale when the number of channels (D) increases beyond 4000, particularly in terms of both computational efficiency and imputation accuracy?
- Basis in paper: [inferred] The paper demonstrates linear scalability with respect to the number of channels up to 4000, but does not test beyond this point.
- Why unresolved: The experiments only tested scalability up to 4000 channels, leaving uncertainty about performance at larger scales.
- What evidence would resolve it: Additional experiments testing BayOTIDE on datasets with more than 4000 channels, measuring both training/inference time and imputation accuracy metrics (RMSE, MAE, CRPS).

### Open Question 2
- Question: What is the impact of using different kernel combinations (e.g., Matérn with different smoothness parameters or alternative kernels) on BayOTIDE's imputation performance and uncertainty quantification?
- Basis in paper: [explicit] The paper only tests Matérn kernels with ν=1/2 and ν=3/2, and periodic kernels, but mentions that different kernel types could be explored.
- Why unresolved: The experiments are limited to specific kernel combinations, and the paper does not explore the full space of possible kernel choices.
- What evidence would resolve it: Systematic experiments varying kernel types and parameters, comparing imputation accuracy and uncertainty quantification across different kernel combinations.

### Open Question 3
- Question: How does BayOTIDE's online inference algorithm perform in real-time streaming scenarios with high-frequency data arrivals, and what are the practical limitations?
- Basis in paper: [explicit] The paper presents an online inference algorithm but does not test it in real-time streaming scenarios or discuss practical limitations.
- Why unresolved: The experiments focus on offline evaluation of the online algorithm, without testing its performance in true streaming conditions.
- What evidence would resolve it: Implementation and testing of BayOTIDE in a real-time streaming environment, measuring latency, memory usage, and imputation accuracy under various data arrival rates.

## Limitations
- Scalability constraints: Method requires storing and updating posterior for all observations, limiting streaming scenarios
- Smoothness assumption: GP priors assume smooth functions, making method less suitable for data with abrupt changes
- Kernel selection dependency: Performance heavily depends on appropriate kernel choice requiring domain expertise

## Confidence
- Mechanism 1: Medium - Decomposition approach is sound but assumption of smooth global patterns may not hold for all data
- Mechanism 2: High - GP continuous-time formulation is well-established with direct imputation capabilities
- Mechanism 3: Medium - SDE conversion enables efficiency but lacks detailed analysis of approximation errors

## Next Checks
1. Sensitivity analysis: Systematically vary the number of factors (Dr, Ds) and kernel parameters across datasets to quantify their impact on imputation accuracy and computational cost.
2. Non-smooth data testing: Evaluate BayOTIDE on datasets with known discontinuities or abrupt changes to assess performance degradation and identify failure modes.
3. Online update stability: Simulate streaming scenarios with varying arrival rates and missingness patterns to measure error accumulation and convergence behavior over extended time periods.