---
ver: rpa2
title: 'RelBERT: Embedding Relations with Language Models'
arxiv_id: '2310.00299'
source_url: https://arxiv.org/abs/2310.00299
tags:
- relation
- word
- relbert
- language
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes RelBERT, a method for extracting relation embeddings
  from fine-tuned language models. The key idea is to feed word pairs to a masked
  language model like RoBERTa using fixed templates and aggregate the contextualised
  embeddings to obtain relation embeddings.
---

# RelBERT: Embedding Relations with Language Models

## Quick Facts
- arXiv ID: 2310.00299
- Source URL: https://arxiv.org/abs/2310.00299
- Reference count: 40
- Key outcome: RelBERT achieves 73% accuracy on SAT analogy benchmark, outperforming much larger language models by 17 percentage points

## Executive Summary
This paper proposes RelBERT, a method for extracting relation embeddings from fine-tuned language models. The key innovation is using fixed templates to feed word pairs into masked language models like RoBERTa, then aggregating contextual embeddings to obtain relation representations. These embeddings are fine-tuned using contrastive loss to ensure similar relations have close embeddings. The resulting model sets new state-of-the-art results on analogy benchmarks while being two orders of magnitude smaller than competing approaches. Remarkably, RelBERT generalizes to relations not seen during training, including morphological relations and relations between named entities.

## Method Summary
RelBERT extracts relation embeddings by fine-tuning RoBERTa on relational similarity data using contrastive losses (InfoNCE, InfoLOOB, triplet). The process involves feeding word pairs through fixed prompt templates into the masked language model, extracting contextualized embeddings from the mask token, and aggregating them to form relation vectors. During training, contrastive loss aligns embeddings of word pairs with similar relationships while pushing apart dissimilar pairs. The model is evaluated on analogy benchmarks by computing cosine similarity between query and candidate relation embeddings, and on lexical relation classification by training MLPs on the embeddings.

## Key Results
- Achieves 73% accuracy on SAT analogy benchmark, 17 percentage points higher than previous best
- Outperforms GPT-3 and OPT-IML despite being two orders of magnitude smaller (140M vs 175B parameters)
- Generalizes to relations not seen during training, including morphological relations and named entity relations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RelBERT achieves superior analogy benchmark performance by fine-tuning RoBERTa on relational similarity data using contrastive loss
- Mechanism: Fine-tuning RoBERTa with contrastive losses aligns relation embeddings of word pairs with similar relationships, enabling accurate analogy prediction through cosine similarity
- Core assumption: Relational similarity data captures enough semantic variation to train effective relation embeddings
- Evidence anchors:
  - [abstract]: "RelBERT achieves 73% accuracy on the SAT analogy benchmark, a 17 percentage point improvement over the previous best result."
  - [section]: "The resulting model, which we call RelBERT, captures relational similarity in a surprisingly fine-grained way, allowing us to set a new state-of-the-art in analogy benchmarks."
  - [corpus]: Weak evidence. Related papers focus on knowledge graph embeddings, not analogy benchmarks
- Break condition: If relational similarity data is insufficient or noisy, the embeddings may not capture meaningful relational patterns

### Mechanism 2
- Claim: RelBERT generalizes to unseen relations by extracting relational knowledge from pre-trained LM rather than memorizing training examples
- Mechanism: The LM's pre-trained knowledge is distilled into relation embeddings during fine-tuning, allowing the model to infer relations not explicitly present in training data
- Core assumption: Pre-trained LM encodes sufficient relational knowledge across diverse domains
- Evidence anchors:
  - [section]: "Crucially, RelBERT is capable of modelling relations that go well beyond what the model has seen during training... even if we remove all training examples for a given lexical relation (e.g. hypernymy), we find that the resulting model is still capable of modelling that relationship."
  - [corpus]: Weak evidence. Corpus focuses on knowledge graph embeddings, not generalization to unseen relations
- Break condition: If pre-trained LM lacks relevant relational knowledge, generalization will fail

### Mechanism 3
- Claim: RelBERT outperforms much larger language models despite being two orders of magnitude smaller
- Mechanism: The contrastive fine-tuning process extracts relational knowledge more efficiently than prompting larger models, and fixed-length relation embeddings are more suitable for analogy tasks than raw LM outputs
- Core assumption: Fixed-length relation embeddings are more effective for analogy tasks than LM-generated text
- Evidence anchors:
  - [abstract]: "RelBERT significantly outperforms strategies based on prompting language models that are several orders of magnitude larger, including recent GPT-based models and open source models."
  - [section]: "The strong performance of RelBERT is especially remarkable given the small size of the considered training set... the version of RelBERT based on RoBERTaBASE has 140 million parameters, but already outperforms GPT-3, which has 175 billion parameters, across all the considered benchmarks."
  - [corpus]: Weak evidence. Related papers focus on knowledge graph embeddings, not direct comparisons with large LMs
- Break condition: If analogy tasks require more complex reasoning than captured by fixed-length embeddings, larger models may eventually outperform

## Foundational Learning

- Concept: Contrastive learning and loss functions (InfoNCE, InfoLOOB, triplet loss)
  - Why needed here: These losses train the model to align embeddings of word pairs with similar relations while pushing apart dissimilar pairs
  - Quick check question: What is the key difference between InfoNCE and InfoLOOB losses?

- Concept: Masked Language Models (MLMs) and their embeddings
  - Why needed here: RelBERT uses RoBERTa (an MLM) to generate contextualized embeddings for word pairs
  - Quick check question: How does an MLM differ from a causal language model (CLM) in processing input?

- Concept: Knowledge Graph (KG) completion and link prediction
  - Why needed here: Understanding KGs helps contextualize why relational embeddings are useful for tasks like analogy questions
  - Quick check question: What is the main limitation of traditional KGs that RelBERT aims to address?

## Architecture Onboarding

- Component map: RoBERTa base LM → Prompt template → Mask token embedding → Aggregation → Contrastive loss → Relation embedding
- Critical path: Fine-tuning process: Prepare data → Select prompt template → Fine-tune RoBERTa → Evaluate on analogy benchmarks
- Design tradeoffs: Smaller model size vs. larger LMs, fixed-length embeddings vs. flexible LM outputs, explicit relation representation vs. implicit knowledge in LMs
- Failure signatures: Poor analogy performance indicates issues with fine-tuning, prompt template, or insufficient relational similarity data
- First 3 experiments:
  1. Fine-tune RelBERT on RelSim with different prompt templates and evaluate on SAT analogy benchmark
  2. Compare RelBERT performance using different contrastive loss functions (InfoNCE, InfoLOOB, triplet)
  3. Test RelBERT generalization by training on RelSim without specific relation types and evaluating on lexical relation classification datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does RelBERT perform on relation embeddings for entities that are not named entities (e.g. events, abstract concepts)?
- Basis in paper: [explicit] The paper mentions evaluating RelBERT on NELL-One and T-REX datasets, which contain named entities, but does not explicitly explore other entity types
- Why unresolved: The paper focuses on the performance of RelBERT on named entities, leaving the performance on other entity types unexplored
- What evidence would resolve it: Conducting experiments on datasets containing events, abstract concepts, and other non-named entity types to evaluate the generalization capability of RelBERT

### Open Question 2
- Question: What is the impact of different prompt template lengths on the performance of RelBERT?
- Basis in paper: [explicit] The paper mentions experimenting with different prompt templates, including variations in length, but does not provide a comprehensive analysis of the impact of template length
- Why unresolved: The paper only briefly touches upon the impact of prompt template length and does not provide a detailed analysis of its effect on RelBERT's performance
- What evidence would resolve it: Conducting experiments with a wider range of prompt template lengths and analyzing the impact on RelBERT's performance across different datasets and relation types

### Open Question 3
- Question: How does the performance of RelBERT compare to other relation embedding methods when trained on larger datasets?
- Basis in paper: [explicit] The paper mentions training RelBERT on smaller datasets like RelSim, but does not explore the performance when trained on larger datasets
- Why unresolved: The paper does not provide a comparison of RelBERT's performance with other relation embedding methods when trained on larger datasets, which could provide insights into the scalability and efficiency of RelBERT
- What evidence would resolve it: Conducting experiments to train RelBERT on larger datasets and comparing its performance with other relation embedding methods, such as word embedding differences or knowledge graph embeddings, to assess its scalability and efficiency

## Limitations
- Limited evidence of RelBERT's effectiveness beyond analogy tasks and lexical relation classification
- Insufficient ablation studies to determine which components contribute most to the 17 percentage point improvement
- Limited analysis of computational efficiency during training and inference compared to larger models

## Confidence
High confidence in: The core mechanism of using masked language models with contrastive fine-tuning to generate relation embeddings, and the demonstration that this approach outperforms prompting much larger language models on analogy tasks

Medium confidence in: The claim that RelBERT can generalize to relations not seen during training, as the evidence provided is limited to a few specific examples without comprehensive quantitative analysis

Medium confidence in: The efficiency claims regarding model size versus performance, though the comparisons are clear, the paper does not address computational efficiency during inference or training time differences

## Next Checks
1. Conduct systematic ablation studies to determine the contribution of each component (prompt templates, aggregation methods, contrastive loss functions) to overall performance, isolating which factors drive the 17 percentage point improvement

2. Test RelBERT embeddings on a broader range of downstream NLP tasks beyond analogy benchmarks and lexical relation classification, including relation extraction from text, question answering, and commonsense reasoning tasks

3. Evaluate the computational efficiency of RelBERT during both training and inference, comparing wall-clock time and memory usage against the larger language models it outperforms, to fully validate the efficiency claims