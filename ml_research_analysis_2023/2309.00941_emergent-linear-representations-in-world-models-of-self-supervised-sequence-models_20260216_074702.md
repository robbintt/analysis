---
ver: rpa2
title: Emergent Linear Representations in World Models of Self-Supervised Sequence
  Models
arxiv_id: '2309.00941'
source_url: https://arxiv.org/abs/2309.00941
tags:
- board
- linear
- layer
- state
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that Othello-playing transformer models
  encode board state as a linear representation relative to the current player (MINE,
  YOURS, EMPTY) rather than absolute colors (BLACK, WHITE). Using linear probes, they
  achieve near-perfect accuracy in recovering the board state and show that simple
  vector arithmetic can control model predictions.
---

# Emergent Linear Representations in World Models of Self-Supervised Sequence Models

## Quick Facts
- **arXiv ID**: 2309.00941
- **Source URL**: https://arxiv.org/abs/2309.00941
- **Reference count**: 20
- **Primary result**: Othello-playing transformer models encode board state as relative positions (MINE/YOURS/EMPTY) rather than absolute colors (BLACK/WHITE/EMPTY), enabling simple linear interventions that are as effective as complex gradient-based editing methods.

## Executive Summary
This paper investigates the internal representations of Othello-playing transformer models and discovers that they encode board state as relative positions (MINE/YOURS/EMPTY) rather than absolute colors (BLACK/WHITE/EMPTY). Using linear probes, the authors achieve near-perfect accuracy in recovering the board state from activation patterns across multiple layers. They demonstrate that simple vector arithmetic interventions can control model predictions by altering these linear representations, showing that these interventions are as effective as complex gradient-based editing methods. The study also reveals evidence of multiple prediction circuits, particularly in endgame scenarios where simpler circuits can predict legal moves without computing the full board state.

## Method Summary
The authors train an 8-layer transformer model (OthelloGPT) using self-supervised learning on 3.5 million game sequences to predict legal moves. They apply linear probes to intermediate layers to classify board state representations as MINE/YOURS/EMPTY versus BLACK/WHITE/EMPTY. Vector arithmetic interventions are conducted by adding learned direction vectors to residual streams at multiple layers. The model is evaluated on a test set of 1,000 games, with probe accuracy measured for board state classification and intervention effectiveness measured through error rate reduction. Additional experiments analyze attention head behavior and investigate potential multiple circuits in endgame scenarios.

## Key Results
- Linear probes achieve near-perfect accuracy in classifying board state as MINE/YOURS/EMPTY relative to the current player
- Simple vector addition interventions to residual streams are as effective as complex gradient-based editing methods
- Evidence suggests multiple circuits exist, with simpler circuits handling endgame scenarios where board state computation may be bypassed
- Attention heads broadcast played moves information and compute empty tile representations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: OthelloGPT encodes board state as relative positions (MINE/YOURS/EMPTY) rather than absolute colors (BLACK/WHITE/EMPTY).
- Mechanism: The model uses the current player's turn to determine which color is "mine" vs "yours", creating a linear representation in activation space.
- Core assumption: The model can infer the current player's turn from the sequence position and uses this to transform absolute colors into relative positions.
- Evidence anchors:
  - [abstract] "we show that probing for 'my colour' vs. 'opponent's colour' may be a simple yet powerful way to interpret the model's internal state"
  - [section 3] "Rather than encoding the colour of each tile (BLACK, WHITE, EMPTY), OthelloGPT encodes each tile relative to the player of each timestep (MINE, YOURS, EMPTY)"
  - [corpus] Found 25 related papers with average FMR=0.467, suggesting this is a novel approach to board state representation
- Break condition: If the model cannot reliably determine the current player's turn from the sequence position, or if the model uses a different reference frame for relative positioning.

### Mechanism 2
- Claim: Simple vector addition interventions can control model predictions by altering the board state representation.
- Mechanism: Adding MINE/YOURS/EMPTY direction vectors to residual streams at multiple layers changes the model's belief about the board state, which directly affects move predictions.
- Core assumption: The board state representation is used causally for move prediction, not just correlated with it.
- Evidence anchors:
  - [section 4] "we demonstrate that we can steer the sequence model's predictions by simply conducting vectoral arithmetics using our linear vectors"
  - [section 4.3] "Our interventions are equally effective as that of gradient-based editing, and confirms that our interpretation of each linear direction matches how the model uses such directions"
  - [corpus] No direct corpus evidence for intervention effectiveness, but related work exists on activation editing in language models
- Break condition: If the board state representation is not used causally for predictions, or if the representation is non-linear and cannot be altered by simple vector addition.

### Mechanism 3
- Claim: Multiple circuits exist in the model, with simpler circuits handling endgame scenarios.
- Mechanism: For early/mid-game, the model uses a complex board state circuit to predict moves, but for endgames, simpler circuits can predict legal moves without full board state computation.
- Core assumption: The model can compute legal moves through alternative pathways that don't require the full board state, particularly when the number of empty tiles is small.
- Evidence anchors:
  - [section 5.4] "we find that in end games, the model often computes legal moves before the board state (black bars)"
  - [section 5.4] "One possible explanation for this phenomenon is that in the end game, it may be possible to predict legal moves with simpler circuits that do not require the entire board state"
  - [corpus] No direct corpus evidence for multiple circuits, but related work exists on circuit analysis in neural networks
- Break condition: If endgame move predictions actually require the full board state, or if the simpler circuits are not sufficient for accurate predictions.

## Foundational Learning

- Concept: Linear representations in neural networks
  - Why needed here: The paper demonstrates that board state is encoded as linear directions in activation space, which enables simple intervention methods
  - Quick check question: Why would a linear representation be more useful for interpretability than a non-linear one?

- Concept: Self-supervised learning in sequence models
  - Why needed here: OthelloGPT is trained with self-supervised learning to predict legal moves, without explicit board state labels
  - Quick check question: How does self-supervised learning enable the model to learn implicit representations of the game state?

- Concept: Transformer architecture and residual connections
  - Why needed here: The intervention method relies on residual connections to propagate altered representations through layers
  - Quick check question: How do residual connections enable the linear vectors to influence the model's predictions?

## Architecture Onboarding

- Component map:
  - 8-layer GPT model with 8 attention heads per layer
  - Embedding layer (Emb) and unembedding layer (Unemb)
  - Residual stream that carries information between layers
  - Linear probe for board state classification (3-way: MINE/YOURS/EMPTY)
  - Attention heads that broadcast played moves information

- Critical path:
  1. Input move sequence → Emb → residual stream
  2. Each layer: attention heads → MLP → residual addition
  3. Final layer → Unemb → move prediction
  4. Linear probe applied to intermediate layers for board state

- Design tradeoffs:
  - Simple linear probes vs complex non-linear probes for board state
  - Single vector addition intervention vs iterative gradient-based editing
  - Multiple circuit hypothesis vs single unified circuit explanation

- Failure signatures:
  - Low linear probe accuracy indicates non-linear board representation
  - Intervention ineffectiveness indicates board state not used causally
  - Board accuracy drop in endgame indicates circuit failure or alternative circuits

- First 3 experiments:
  1. Train linear probe on intermediate layers to classify board state as MINE/YOURS/EMPTY vs BLACK/WHITE/EMPTY
  2. Apply MINE/YOURS/EMPTY vectors to residual streams and measure change in move predictions
  3. Analyze attention head behavior to understand how empty tiles and flipped tiles are computed

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do linear representations emerge in sequence models like OthelloGPT?
- Basis in paper: [explicit] The authors state "One reason might be simply that matrix multiplication can easily extract a different subset of linear features for each neuron."
- Why unresolved: The paper only offers a hypothesis about matrix multiplication, but does not explore or test alternative explanations.
- What evidence would resolve it: Experiments comparing linear representations across different architectures, training objectives, and data distributions. Analysis of whether linear representations emerge in non-sequential models or with different activation functions.

### Open Question 2
- Question: Do multiple circuits exist in OthelloGPT for predicting legal moves throughout the game?
- Basis in paper: [explicit] The authors find evidence of "multiple circuits" in end games where the model sometimes computes moves before board states.
- Why unresolved: The authors hypothesize about end game circuits but do not conclusively prove their existence or understand their mechanisms.
- What evidence would resolve it: Ablation studies removing different layers or attention heads to isolate end game circuits. Analysis of whether the same linear representations are used across different game phases.

### Open Question 3
- Question: Are linear representations a general phenomenon across different game-playing models?
- Basis in paper: [explicit] The authors state "we leave a complete explanation to future work" regarding why linear representations emerge.
- Why unresolved: The study only examines one specific Othello-playing transformer model.
- What evidence would resolve it: Systematic investigation of linear representations in models trained on different games, with varying architectures and training objectives. Comparison of linear vs non-linear representations across multiple domains.

## Limitations

- The findings are specific to an 8-layer OthelloGPT model and may not generalize to deeper transformers or different game environments
- The causal relationship between board state representations and move predictions is not fully established, with interventions showing correlation but not definitive causation
- Evidence for multiple circuits, particularly in endgame scenarios, is suggestive but not conclusive, lacking rigorous validation through ablation studies

## Confidence

**High Confidence**: The existence of linear representations for board state (MINE/YOURS/EMPTY vs BLACK/WHITE/EMPTY) is well-supported by the linear probe results showing high accuracy across layers. The geometric interpretation of these representations is also strongly evidenced.

**Medium Confidence**: The effectiveness of simple vector interventions is demonstrated, but the extent to which this generalizes to more complex manipulations or different types of interventions remains uncertain. The comparison to gradient-based methods shows promise but doesn't establish superiority or broad applicability.

**Low Confidence**: The multiple circuits hypothesis for endgame scenarios has suggestive evidence but lacks definitive proof. The claim that simpler circuits can predict legal moves without full board state computation needs more rigorous validation.

## Next Checks

**Check 1: Ablation Study on Model Depth** - Train and analyze Othello models with varying depths (4, 12, 16 layers) to determine whether the linear representation phenomenon scales with model size or is specific to the 8-layer architecture. This would test the generalizability of the findings.

**Check 2: Causal Intervention Analysis** - Design experiments that systematically disable or modify the board state representations at different layers and measure the impact on both move predictions and other model capabilities. This would provide stronger causal evidence for how the model uses these representations.

**Check 3: Endgame Circuit Verification** - Conduct controlled experiments where the model is tested on endgame scenarios with varying numbers of empty tiles, measuring whether simpler circuits consistently emerge and whether they can be independently verified through circuit analysis techniques like activation patching or feature visualization.