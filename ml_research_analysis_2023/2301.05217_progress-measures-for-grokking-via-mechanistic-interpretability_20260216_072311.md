---
ver: rpa2
title: Progress measures for grokking via mechanistic interpretability
arxiv_id: '2301.05217'
source_url: https://arxiv.org/abs/2301.05217
tags:
- loss
- fourier
- test
- grokking
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We reverse engineer a one-layer transformer trained on modular
  addition to understand how it implements the task. The network learns to embed inputs
  onto a circle using discrete Fourier transforms, then uses trigonometric identities
  to perform addition on the circle.
---

# Progress measures for grokking via mechanistic interpretability

## Quick Facts
- arXiv ID: 2301.05217
- Source URL: https://arxiv.org/abs/2301.05217
- Authors: 
- Reference count: 40
- Key outcome: We reverse engineer a one-layer transformer trained on modular addition to understand how it implements the task. The network learns to embed inputs onto a circle using discrete Fourier transforms, then uses trigonometric identities to perform addition on the circle. We validate this by analyzing the network's weights and activations, and confirm it with targeted ablations. Using our understanding, we construct progress measures that track the model's improvement prior to grokking. We find grokking arises from three phases: memorization, circuit formation, and cleanup. The generalizing algorithm is learned during circuit formation, before the sudden improvement in test accuracy during cleanup. This shows grokking is not a sudden shift, but gradual amplification of structured mechanisms followed by removal of memorizing components.

## Executive Summary
This paper reverse engineers a one-layer transformer trained on modular addition to understand how it implements the task. The network learns to embed inputs onto a circle using discrete Fourier transforms, then uses trigonometric identities to perform addition on the circle. The authors validate this by analyzing the network's weights and activations, and confirm it with targeted ablations. Using their understanding, they construct progress measures that track the model's improvement prior to grokking. They find grokking arises from three phases: memorization, circuit formation, and cleanup. The generalizing algorithm is learned during circuit formation, before the sudden improvement in test accuracy during cleanup. This shows grokking is not a sudden shift, but gradual amplification of structured mechanisms followed by removal of memorizing components.

## Method Summary
The authors trained a one-layer ReLU transformer on modular addition with prime modulus P=113, using 30% of all possible input pairs. The model has embedding size d=128, 4 attention heads of dimension 32, and 512 hidden units in the MLP. They analyze the trained model by computing Fourier transforms of the embedding matrix and neuron-logit map to identify key frequencies. They verify that the model's weights and activations exhibit periodic structure in the Fourier domain, with sparsity concentrated on specific frequencies. They confirm the algorithm by performing ablations in Fourier space - removing key frequencies to check performance degradation, and removing all non-key frequencies to check performance improvement. They use these ablations to construct restricted and excluded loss measures that track progress toward the generalizing algorithm.

## Key Results
- The network implements modular addition using discrete Fourier transforms and trigonometric identities
- Grokking arises from three phases: memorization, circuit formation, and cleanup
- Progress measures (restricted and excluded loss) improve continuously prior to grokking
- The generalizing algorithm is learned during circuit formation, before the sudden improvement in test accuracy during cleanup

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The network learns to embed inputs onto a circle using discrete Fourier transforms, then uses trigonometric identities to perform addition on the circle.
- Mechanism: The embedding matrix maps inputs a,b to sines and cosines at key frequencies wk. Attention heads and MLP layer compute cos(wk(a+b)) and sin(wk(a+b)) using trigonometric identities. Output matrix reads these and combines them for each possible output c.
- Core assumption: The sparsity of WE in the Fourier basis is evidence that the network is operating in this basis.
- Evidence anchors:
  - [abstract] We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle.
  - [section 4.1] The embedding matrix WE is sparse in the Fourier basis--it only has significant nonnegligible norm at 6 frequencies.
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.489, average citations=0.0.
- Break condition: If the embedding matrix is not sparse in the Fourier basis, or if the key frequencies do not appear in later parts of the network.

### Mechanism 2
- Claim: Grokking arises from three phases: memorization, circuit formation, and cleanup.
- Mechanism: During memorization, the model memorizes the training data. During circuit formation, the network learns a mechanism that generalizes. During cleanup, weight decay removes the memorization components.
- Core assumption: Weight decay is necessary for grokking to occur.
- Evidence anchors:
  - [abstract] We find grokking arises from three phases: memorization, circuit formation, and cleanup. The generalizing algorithm is learned during circuit formation, before the sudden improvement in test accuracy during cleanup.
  - [section 5.2] We find that training splits into three phases, which we call the memorization, circuit formation, and cleanup phases.
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.489, average citations=0.0.
- Break condition: If weight decay is removed and grokking still occurs, or if the three phases are not observed.

### Mechanism 3
- Claim: The progress measures allow us to study the dynamics of training and split training into three continuous phases.
- Mechanism: Restricted loss ablates every non-key frequency, while excluded loss ablates all key frequencies. Both metrics improve continuously prior to when grokking occurs.
- Core assumption: The network's behavior on the train set transitions smoothly from the memorizing solution to the Fourier multiplication algorithm.
- Evidence anchors:
  - [abstract] Using our understanding, we construct progress measures that allow us to study the dynamics of training and split training into three continuous phases.
  - [section 5.1] We translate the ablations in Section 4.4 into two progress measures: restricted and excluded loss.
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.489, average citations=0.0.
- Break condition: If the progress measures do not improve continuously prior to grokking, or if they do not split training into three phases.

## Foundational Learning

- Concept: Discrete Fourier transforms
  - Why needed here: The network uses discrete Fourier transforms to embed inputs onto a circle.
  - Quick check question: How does a discrete Fourier transform work?
- Concept: Trigonometric identities
  - Why needed here: The network uses trigonometric identities to perform addition on the circle.
  - Quick check question: What are some common trigonometric identities used for addition?
- Concept: Mechanistic interpretability
  - Why needed here: The paper uses mechanistic interpretability to reverse engineer the algorithm learned by the network.
  - Quick check question: What is mechanistic interpretability and how is it used in this paper?

## Architecture Onboarding

- Component map: WE -> Attention heads -> MLP layer -> Output matrix
- Critical path: Embedding matrix WE maps inputs to sines and cosines at key frequencies, which are then processed by attention heads and MLP layer to compute trigonometric identities, and finally combined by the output matrix to produce the final logits.
- Design tradeoffs: Using discrete Fourier transforms and trigonometric identities allows for efficient computation of modular addition, but requires the network to learn a specific algorithm.
- Failure signatures: If the embedding matrix is not sparse in the Fourier basis, or if the key frequencies do not appear in later parts of the network, the algorithm will not work correctly.
- First 3 experiments:
  1. Check the sparsity of the embedding matrix in the Fourier basis
  2. Identify the key frequencies used by the network
  3. Verify that the attention heads and MLP layer compute the correct trigonometric identities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the number of key frequencies in the Fourier multiplication algorithm relate to the model's performance and generalization?
- Basis in paper: [explicit] The paper shows that different models use varying numbers of key frequencies, and the number of key frequencies is not consistent across different runs.
- Why unresolved: The paper does not explore the relationship between the number of key frequencies and model performance in detail. It is unclear if there is an optimal number of key frequencies for a given task or if the number of key frequencies is task-dependent.
- What evidence would resolve it: Experiments varying the number of key frequencies in the Fourier multiplication algorithm and measuring the resulting model performance and generalization could provide insight into this relationship.

### Open Question 2
- Question: Can the Fourier multiplication algorithm be generalized to other mathematical operations beyond modular addition?
- Basis in paper: [inferred] The paper focuses on the Fourier multiplication algorithm for modular addition, but the algorithm's core concept of mapping inputs onto a circle and performing operations using trigonometric identities could potentially be applied to other operations.
- Why unresolved: The paper does not explore the applicability of the Fourier multiplication algorithm to other mathematical operations. It is unclear if the algorithm's core concept can be generalized to other operations or if it is specific to modular addition.
- What evidence would resolve it: Experiments applying the Fourier multiplication algorithm to other mathematical operations and measuring the resulting model performance and generalization could provide insight into its generalizability.

### Open Question 3
- Question: How do the progress measures defined in the paper (restricted loss and excluded loss) relate to the model's overall performance and generalization?
- Basis in paper: [explicit] The paper defines restricted loss and excluded loss as progress measures and shows that they improve continuously prior to grokking. However, the relationship between these measures and the model's overall performance and generalization is not fully explored.
- Why unresolved: The paper does not investigate the relationship between the progress measures and the model's overall performance and generalization in detail. It is unclear if these measures are sufficient to capture the model's progress towards generalization or if additional measures are needed.
- What evidence would resolve it: Experiments measuring the model's performance and generalization on various tasks and comparing them to the progress measures could provide insight into their relationship. Additionally, exploring alternative progress measures and comparing them to the ones defined in the paper could be informative.

## Limitations

- The necessity of weight decay for grokking is not definitively proven, as alternative regularization methods were not explored
- The findings are based on a single-layer transformer with a specific configuration (P=113, 4 heads, etc.), limiting generalizability
- The identified Fourier-based algorithm may not be the only solution the network could learn, as different random seeds might lead to alternative generalizing mechanisms

## Confidence

- High confidence: The Fourier-based algorithm for modular addition is well-supported by weight analysis, ablation studies, and activation patterns. The three-phase grokking model (memorization, circuit formation, cleanup) is clearly observable in the training dynamics.
- Medium confidence: The progress measures (restricted and excluded loss) reliably track the transition from memorization to generalization, though their quantitative relationship to actual test accuracy could be more precisely characterized.
- Low confidence: Claims about weight decay being the sole mechanism enabling grokking cleanup are suggestive but not definitively proven, as alternative regularization methods were not explored.

## Next Checks

1. Reproduce the experiment with different weight decay values (including zero) and alternative regularization methods (dropout, early stopping) to determine whether the three-phase grokking pattern persists without weight decay.

2. Apply the same mechanistic interpretability analysis to two-layer transformers and attention-only models to verify whether the Fourier-based algorithm and three-phase grokking emerge in more complex architectures.

3. Train multiple models with different random seeds and perform systematic comparison of their learned algorithms to determine whether the Fourier-based solution is universal or one of multiple possible generalizing mechanisms.