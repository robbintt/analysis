---
ver: rpa2
title: 'DISC-MedLLM: Bridging General Large Language Models and Real-World Medical
  Consultation'
arxiv_id: '2308.14346'
source_url: https://arxiv.org/abs/2308.14346
tags:
- gid00001
- medical
- gid00032
- gid00047
- gid00042
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces DISC-MedLLM, a framework for fine-tuning
  large language models to handle real-world medical consultations. The authors construct
  a high-quality supervised fine-tuning dataset using three strategies: leveraging
  medical knowledge graphs, reconstructing real-world dialogues, and incorporating
  human-guided preference rephrasing.'
---

# DISC-MedLLM: Bridging General Large Language Models and Real-World Medical Consultation

## Quick Facts
- arXiv ID: 2308.14346
- Source URL: https://arxiv.org/abs/2308.14346
- Reference count: 14
- Primary result: DISC-MedLLM achieves 39.79% few-shot accuracy on medical MCQs, outperforming HuatuoGPT-13B baseline

## Executive Summary
DISC-MedLLM introduces a framework for fine-tuning large language models specifically for medical consultation tasks. The authors construct a high-quality supervised fine-tuning dataset using three complementary strategies: leveraging medical knowledge graphs, reconstructing real-world dialogues, and incorporating human-guided preference rephrasing. The model is evaluated on both single-turn multiple-choice questions and multi-turn simulated consultations. Results show that DISC-MedLLM achieves strong performance across benchmarks, demonstrating that targeted fine-tuning with curated medical dialogue and knowledge data can significantly improve medical consultation capabilities of general LLMs.

## Method Summary
DISC-MedLLM uses a two-stage supervised fine-tuning approach on the Baichuan-13B-Base model. Stage 1 trains on a large-scale dataset combining knowledge graph QA pairs, reconstructed real-world dialogues, medical question answering data, and general instruction data. Stage 2 fine-tunes on a smaller human preference-guided dataset alongside general data to align model behavior with desired consultation patterns. The framework integrates medical knowledge from CMeKG, real consultation data from MedDialog and cMedQA2, and preference samples manually selected and rewritten by human experts.

## Key Results
- Achieves 39.79% few-shot accuracy on medical multiple-choice benchmarks, outperforming HuatuoGPT-13B (28.87%) but trailing GPT-3.5 (49.64%)
- Attains highest overall score (4.69/5) on CMB-Clin multi-turn evaluation, leading in proactivity and linguistic quality
- Demonstrates effectiveness of combining knowledge graphs, real-world dialogues, and human preferences in medical LLM fine-tuning

## Why This Works (Mechanism)

### Mechanism 1: Knowledge Graph Grounding
- **Claim:** Knowledge-intensive responses are ensured by sourcing all medical knowledge from verified external datasets
- **Mechanism:** Medical knowledge triples are sampled from a medical knowledge graph and transformed into QA pairs using GPT-3.5
- **Core assumption:** Medical knowledge graphs contain comprehensive and accurate information that can be reliably transformed into dialogue format
- **Evidence anchors:** Abstract mentions department-oriented strategy for sampling knowledge triples; section describes construction of QA pairs from CMeKG with 10k+ diseases, 20k+ medications, and 10k+ symptoms
- **Break condition:** If the knowledge graph contains outdated or incorrect medical information, or if the transformation from triples to dialogue introduces errors

### Mechanism 2: Real-world Dialogue Reconstruction
- **Claim:** Multi-turn inquiry capability is learned from actual doctor-patient interaction patterns
- **Mechanism:** Real-world medical dialogues are reconstructed using GPT-3.5 to create uniform responses while preserving essential medical content
- **Core assumption:** Real-world medical dialogues contain valid multi-turn patterns that can be extracted and generalized
- **Evidence anchors:** Abstract identifies reconstructing real-world dialogues as one of three strategies; section explains using GPT-3.5 to re-generate dialogue based on real cases
- **Break condition:** If reconstruction over-sanitizes dialogues, removing important contextual nuances, or if real-world dialogues contain problematic patterns

### Mechanism 3: Human-guided Preference Alignment
- **Claim:** Model behavior aligns with human preferences through manually curated high-quality samples
- **Mechanism:** Small set of high-quality dialogue samples are manually selected and reconstructed by human experts for fine-tuning
- **Core assumption:** Human experts can identify and reconstruct high-quality dialogue samples representing desired behavioral patterns
- **Evidence anchors:** Abstract mentions incorporating human-guided preference rephrasing; section describes manual selection and rewriting of samples from real-world records
- **Break condition:** If manual selection introduces bias, or if human-preferred responses don't improve clinical utility

## Foundational Learning

- **Concept: Knowledge Graph Construction and Utilization**
  - Why needed here: Understanding how medical knowledge graphs are structured and how to extract meaningful triples for dialogue generation is crucial for implementing the knowledge-intensive component
  - Quick check question: What are the three main node types in the medical knowledge graph used by DISC-MedLLM, and how are they connected?

- **Concept: Multi-turn Dialogue Systems**
  - Why needed here: The ability to understand and generate multi-turn medical consultations requires knowledge of dialogue state tracking and intent recognition across conversation turns
  - Quick check question: How does DISC-MedLLM ensure the model learns to ask clarifying questions across multiple turns rather than providing single-turn responses?

- **Concept: Supervised Fine-Tuning (SFT) with Instruction Tuning**
  - Why needed here: The entire framework relies on creating high-quality SFT datasets using different strategies, which requires understanding how instruction tuning works with LLMs
  - Quick check question: What are the two stages of training in DISC-MedLLM, and what distinct capabilities does each stage target?

## Architecture Onboarding

- **Component map:** Knowledge Graph Processor → GPT-3.5 QA Pair Generator → SFT Dataset (50k samples) → Base LLM → Stage 1 Training → Human Preference Dataset → Stage 2 Training → DISC-MedLLM
- **Critical path:** Knowledge Graph → GPT-3.5 QA Generation → Stage 1 Training → Human Preference Dataset → Stage 2 Training → Evaluation
- **Design tradeoffs:**
  - Using GPT-3.5 for reconstruction vs. manual annotation: Tradeoff between scalability and quality control
  - Knowledge graph vs. real-world data: Tradeoff between reliability and practical relevance
  - Two-stage training: Tradeoff between domain knowledge acquisition and behavioral alignment
- **Failure signatures:**
  - Knowledge hallucination in generated responses
  - Inability to maintain conversation context across multiple turns
  - Responses that don't align with human medical consultation preferences
  - Performance degradation on non-medical tasks after fine-tuning
- **First 3 experiments:**
  1. Test GPT-3.5 reconstruction quality by comparing generated samples against original real-world dialogues using semantic similarity metrics
  2. Evaluate knowledge graph QA generation by checking if generated questions can be correctly answered by the knowledge graph
  3. Measure the impact of human preference samples by comparing model performance with and without the 2k human-guided samples in Stage 2

## Open Questions the Paper Calls Out
- How can retrieval-enhanced DISC-MedLLM improve accuracy for complex and rare medical cases?
- What is the optimal balance between medical knowledge graphs and real-world dialogues for training medical LLMs?
- How does the performance of DISC-MedLLM compare to other medical LLMs on clinical tasks like diagnosis and treatment recommendation?

## Limitations
- Heavy reliance on the quality and comprehensiveness of medical knowledge graphs, real-world dialogues, and human preference data
- Reconstruction methodology using GPT-3.5 is critical but not extensively validated for quality
- Limited testing of generalization beyond Chinese medical consultation context

## Confidence
- **High Confidence:** Two-stage training methodology and performance improvements are well-supported
- **Medium Confidence:** Specific contribution of each data source and generalizability to other contexts
- **Low Confidence:** Reconstruction quality, human sample selection process, and performance on rare/complex cases

## Next Checks
1. Conduct systematic evaluation of GPT-3.5 reconstruction quality against original sources using semantic similarity and medical accuracy metrics
2. Perform ablation study removing each data source (knowledge graph, real-world dialogues, human preference) to quantify relative contributions
3. Evaluate DISC-MedLLM on medical consultation tasks from different specialties or languages to assess cross-domain adaptability