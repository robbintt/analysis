---
ver: rpa2
title: Generative Pre-trained Transformer for Vietnamese Community-based COVID-19
  Question Answering
arxiv_id: '2310.14602'
source_url: https://arxiv.org/abs/2310.14602
tags:
- question
- answering
- vietnamese
- language
- transformer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an application of GPT-2 for community-based
  question answering focused on COVID-19 queries in Vietnamese. The authors conduct
  a comparative analysis of GPT-2 against other neural network and transformer models
  using the UIT-ViCoV19QA dataset.
---

# Generative Pre-trained Transformer for Vietnamese Community-based COVID-19 Question Answering

## Quick Facts
- arXiv ID: 2310.14602
- Source URL: https://arxiv.org/abs/2310.14602
- Authors: 
- Reference count: 20
- This paper applies GPT-2 for Vietnamese COVID-19 community question answering, showing GPT-2 outperforms other neural networks on ROUGE-L while generating more natural answers.

## Executive Summary
This paper presents a comparative analysis of GPT-2 against other neural network and transformer models for Vietnamese community-based question answering focused on COVID-19 queries. Using the UIT-ViCoV19QA dataset with 4,500 question-answer pairs, the authors demonstrate that GPT-2 models outperform traditional approaches like RNNs and CNNs, particularly excelling on ROUGE-L scores which indicate stronger performance in capturing long-range dependencies and contextual relevance. While GPT-2 underperforms on BLEU and METEOR metrics due to longer answer generation, its outputs are judged to be more natural, suggesting a trade-off between exact lexical matching and answer fluency.

## Method Summary
The study compares GPT-2 against traditional neural networks (RNN with Bahdanau and Luong attention, CNN), Transformer, and two Vietnamese-specific GPT-2 models using the UIT-ViCoV19QA dataset. The models are evaluated using BLEU-1, BLEU-4, METEOR, and ROUGE-L metrics. GPT-2 variants were fine-tuned using the HuggingFace library with standard hyperparameters including embedding size 512, hidden size 512, dropout 0.5, and maximum sequence length 500. The dataset contains up to four paraphrased answers per question to reduce overfitting and encourage semantic equivalence learning.

## Key Results
- GPT-2 models outperform other state-of-the-art models and previous Vietnamese COVID-19 CQA approaches
- GPT-2 excels on ROUGE-L scores, indicating superior performance in capturing long-range dependencies and contextual coherence
- GPT-2 generates more natural answers despite lower BLEU and METEOR scores due to longer answer generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-2's superior ROUGE-L scores indicate it better captures long-range dependencies in Vietnamese text compared to traditional neural networks.
- Mechanism: GPT-2 uses transformer self-attention to build rich contextual representations over entire sequences, allowing it to track semantic continuity even when key answer words are separated by intervening text.
- Core assumption: The dataset contains answers where context coherence relies on non-local dependencies that require more than local n-gram overlap.
- Evidence anchors:
  - [abstract] "experimental findings demonstrate that the GPT-2 models exhibit highly promising outcomes, outperforming other SOTA models as well as previous community-based COVID-19 question answering models"
  - [section] "In terms of ROUGE-L score, it consistently outperformed all other approaches, including the Transformer, RNN-1, RNN-2, and CNN"
  - [corpus] No direct evidence, but corpus shows related papers focus on Vietnamese language modeling, suggesting domain relevance
- Break condition: If the task shifts to very short, factoid-style answers where exact word matches dominate, BLEU and METEOR may become better indicators and GPT-2's advantage could diminish.

### Mechanism 2
- Claim: Pre-training on general Vietnamese text enables GPT-2 to generalize better to COVID-19 domain than models trained only on task-specific data.
- Mechanism: Exposure to diverse linguistic patterns during pre-training equips the model with robust syntax and semantics that transfer to unseen topics like pandemic terminology.
- Core assumption: COVID-19 terminology and discourse patterns overlap sufficiently with general Vietnamese language patterns learned during pre-training.
- Evidence anchors:
  - [abstract] "pre-trained on a large corpus of English text data" (adapted for Vietnamese in this work)
  - [section] "The limitations of the Vietnamese GPT model in question answering can indeed be attributed to its pre-training on data that does not specifically target this task"
  - [corpus] Related work shows multiple Vietnamese pre-trained models (ViDeBERTa, etc.), suggesting community interest in transfer learning
- Break condition: If the domain vocabulary is highly specialized and disjoint from pre-training data, fine-tuning may not overcome the mismatch and performance could degrade.

### Mechanism 3
- Claim: The dataset's design with up to four paraphrased answers per question reduces overfitting and encourages models to learn semantic equivalence rather than surface forms.
- Mechanism: Multiple reference answers force the model to focus on meaning preservation instead of memorizing exact phrases, which benefits generative models like GPT-2 that naturally produce varied outputs.
- Core assumption: Paraphrased references are semantically equivalent and equally valid, so matching any one is acceptable.
- Evidence anchors:
  - [section] "The dataset consists of 4,500 question-answer pairs, ensuring each question has at least one answer and can have up to four distinct paraphrased answers"
  - [abstract] "outperforming other SOTA models as well as previous community-based COVID-19 question answering models developed for Vietnamese"
  - [corpus] No direct evidence, but multi-reference datasets are common in QA research
- Break condition: If paraphrases introduce ambiguity or conflicting information, the model might struggle to identify the correct answer pattern, reducing evaluation reliability.

## Foundational Learning

- **Concept: Self-attention in transformers**
  - Why needed here: Core to GPT-2's ability to weigh the importance of each token relative to others across the full sequence, enabling context-aware generation.
  - Quick check question: What does the attention score between two tokens represent in a transformer layer?

- **Concept: Fine-tuning pre-trained language models**
  - Why needed here: Adapts the general linguistic knowledge from pre-training to the specific domain and task without losing learned representations.
  - Quick check question: Why is gradual unfreezing sometimes used during fine-tuning of large models?

- **Concept: Evaluation metrics for generative QA**
  - Why needed here: Different metrics (BLEU, METEOR, ROUGE-L) capture different aspects of quality; understanding their biases guides model selection and error analysis.
  - Quick check question: Which metric would you prioritize if the task emphasizes fluency over exact wording?

## Architecture Onboarding

- **Component map**: Input embedding → Positional encoding → Multi-head self-attention → Feed-forward → Layer norm → Output projection → Generation loop (for GPT-2); for baselines: RNN/CNN encoder → attention decoder.
- **Critical path**: Token embedding → self-attention → feed-forward → output logits → sampling/greedy decoding.
- **Design tradeoffs**: GPT-2 trades exact lexical matching for natural fluency; requires large pre-training data; less interpretable than attention-based RNNs.
- **Failure signatures**: Low BLEU/METEOR but high ROUGE-L suggests over-generation or paraphrasing; very low scores across metrics suggest training instability or vocabulary mismatch.
- **First 3 experiments**:
  1. Train baseline RNN with Bahdanau attention on 10% of data, measure BLEU-1 vs ROUGE-L to establish lower bound.
  2. Fine-tune Vietnamese GPT-2 on full dataset, compare all three metrics to baseline.
  3. Ablate the pre-training step by training a randomly initialized transformer from scratch on the same data, compare convergence speed and final scores.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does GPT-3 perform compared to GPT-2 on the Vietnamese CQA task, and what specific improvements or limitations does it demonstrate?
- Basis in paper: [explicit] The paper explicitly states that future work includes extending the analysis to GPT-3 to perform a more comprehensive evaluation.
- Why unresolved: The current study only evaluates GPT-2 models and does not include GPT-3 in its comparative analysis, leaving a gap in understanding the relative performance and capabilities of GPT-3 for this specific task.
- What evidence would resolve it: Conducting experiments with GPT-3 on the same dataset (UIT-ViCoV19QA) and comparing its performance metrics (BLEU, METEOR, ROUGE-L) against the GPT-2 results would provide concrete evidence of its relative strengths and weaknesses.

### Open Question 2
- Question: What are the specific reasons behind GPT-2's superior ROUGE-L scores but lower BLEU and METEOR scores in the Vietnamese CQA task?
- Basis in paper: [explicit] The paper notes that GPT-2 models outperform other models on ROUGE-L scores but underperform on BLEU and METEOR due to longer answer generation, yet still produce more natural results.
- Why unresolved: While the paper observes these trends, it does not delve into the underlying linguistic or structural reasons for the discrepancy in metric performance, nor does it explore how these differences impact the practical utility of the generated answers.
- What evidence would resolve it: A detailed qualitative analysis of the generated answers, including their length, coherence, and contextual relevance, alongside a breakdown of how each metric evaluates these aspects, would clarify the trade-offs between different evaluation metrics and the practical implications for answer quality.

### Open Question 3
- Question: How does the performance of Vietnamese-specific GPT-2 models (pretrained on news and Wikipedia data) compare to the original multilingual GPT-2 model on the CQA task, and what factors contribute to any differences observed?
- Basis in paper: [explicit] The paper compares the original GPT-2 model with two Vietnamese-specific pretrained models (tuanle and danghuy1999) and notes differences in performance, particularly in the ROUGE-L metric.
- Why unresolved: The paper does not provide a detailed analysis of why the Vietnamese-specific models perform differently from the multilingual model, such as the impact of domain-specific pretraining data (news vs. Wikipedia) or the amount of training data on the models' ability to handle COVID-19 related queries.
- What evidence would resolve it: A comparative study analyzing the pretraining data characteristics, domain relevance, and model architectures of the Vietnamese-specific models versus the multilingual model, coupled with experiments varying the amount and type of pretraining data, would elucidate the factors influencing their performance differences.

## Limitations

- The study relies on automatic evaluation metrics that may not fully capture answer quality, particularly the trade-off between exact lexical matching and answer naturalness
- The dataset contains only 4,500 question-answer pairs, which may limit generalization to more diverse Vietnamese COVID-19 queries
- The evaluation framework doesn't incorporate human judgment to validate whether GPT-2's longer answers are genuinely more useful despite lower lexical overlap scores

## Confidence

- **High Confidence**: GPT-2 outperforms other neural network and transformer models on ROUGE-L scores for Vietnamese CQA.
- **Medium Confidence**: GPT-2 generates more natural answers despite lower BLEU/METEOR scores.
- **Low Confidence**: Pre-training on general Vietnamese text significantly contributes to GPT-2's domain transfer capabilities.

## Next Checks

1. **Human Evaluation Study**: Conduct blinded human assessments comparing GPT-2 outputs against baseline model answers on criteria like relevance, fluency, and informativeness to validate whether lower BLEU/METEOR scores correspond to better user-perceived quality.

2. **Domain Adaptation Analysis**: Perform controlled experiments training a randomly initialized transformer from scratch on the same Vietnamese COVID-19 data to quantify how much pre-training contributes to GPT-2's performance versus fine-tuning alone.

3. **Dataset Expansion Validation**: Test the best-performing models on an expanded dataset with 10,000+ Vietnamese COVID-19 question-answer pairs to assess whether current performance trends hold with increased linguistic diversity and query complexity.