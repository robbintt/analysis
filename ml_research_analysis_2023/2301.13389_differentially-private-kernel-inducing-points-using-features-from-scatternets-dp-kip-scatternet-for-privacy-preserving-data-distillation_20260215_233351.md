---
ver: rpa2
title: Differentially Private Kernel Inducing Points using features from ScatterNets
  (DP-KIP-ScatterNet) for Privacy Preserving Data Distillation
arxiv_id: '2301.13389'
source_url: https://arxiv.org/abs/2301.13389
tags:
- data
- dp-kip
- private
- distilled
- privacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DP-KIP-ScatterNet, a differentially private
  method for data distillation using kernel inducing points with wavelet features
  from Scattering networks. The method addresses the challenge of creating privacy-preserving
  distilled datasets by applying DP-SGD to the KIP framework.
---

# Differentially Private Kernel Inducing Points using features from ScatterNets (DP-KIP-ScatterNet) for Privacy Preserving Data Distillation

## Quick Facts
- arXiv ID: 2301.13389
- Source URL: https://arxiv.org/abs/2301.13389
- Reference count: 40
- Primary result: Introduces DP-KIP-ScatterNet, a differentially private data distillation method using kernel inducing points with wavelet features from Scattering networks

## Executive Summary
This paper presents DP-KIP-ScatterNet, a novel approach to privacy-preserving data distillation that combines kernel inducing points (KIP) with wavelet features from Scattering networks. The method addresses the challenge of creating privacy-preserving distilled datasets by applying differentially private stochastic gradient descent (DP-SGD) to the KIP framework. By replacing computationally expensive convolutional neural tangent kernels (conv-NTKs) with more efficient ScatterNet features, the approach achieves a favorable privacy-utility tradeoff while maintaining formal differential privacy guarantees.

## Method Summary
DP-KIP-ScatterNet extends the kernel inducing points framework by incorporating wavelet features from Scattering networks and applying differential privacy through DP-SGD. The method distills a small set of representative datapoints that approximate the original dataset's distribution while preserving privacy. The optimization uses an infinitely-wide neural tangent kernel (NTK) to compare distributions between original and distilled data, with regularization through kernel ridge regression. Gradient clipping and Gaussian noise addition ensure formal privacy guarantees while maintaining distilled dataset quality for downstream classification tasks.

## Key Results
- DP-KIP-ScatterNet outperforms existing private data generation methods on image and tabular datasets
- Achieves high classification accuracy while providing formal differential privacy guarantees
- Successfully balances privacy and utility, demonstrating superior performance compared to state-of-the-art techniques at the same privacy levels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DP-KIP-ScatterNet reduces computational complexity while maintaining privacy-utility tradeoff
- Mechanism: Replaces convolutional neural tangent kernels (conv-NTKs) with wavelet features from Scattering networks (ScatterNet) to avoid heavy convolutional operations
- Core assumption: ScatterNet features can capture complex image information as effectively as conv-NTK features
- Evidence anchors:
  - [abstract] "we propose an alternative that does not require pre-training (to avoid a privacy loss) and can well capture complex information on images, as those features from conv-NKTs do"
  - [section] "we find that KIP using infinitely-wide convolutional neural tangent kernels (conv-NTKs) performs better compared to KIP using fully-connected NTKs. However, KIP with conv-NTKs, due to its convolutional and pooling operations, introduces an unbearable computational complexity"

### Mechanism 2
- Claim: DP-SGD on kernel ridge regression preserves privacy while maintaining distilled dataset quality
- Mechanism: Applies differentially private stochastic gradient descent to optimize kernel inducing points while adding calibrated Gaussian noise to gradients
- Core assumption: The number of distilled datapoints is small enough that gradient clipping and noise addition preserve meaningful information
- Evidence anchors:
  - [abstract] "we apply DP-SGD to the forementioned KIP framework for DD developed by Nguyen et al. (2021a;b)"
  - [section] "the gradients that DP-SGD privatize are the distilled datapoints. Typically, we consider only a few distilled datapoints"

### Mechanism 3
- Claim: Using NTK as kernel enables better distribution matching than neural network gradients
- Mechanism: Employs infinite-dimensional features from neural tangent kernels to compare distributions between original and distilled datasets
- Core assumption: NTK features provide a more stable and generalizable representation than finite-width neural network gradients
- Evidence anchors:
  - [section] "we use an infinitely-wide NTK as features in comparing the distilled and original data distributions"
  - [section] "in KIP we use infinite-dimensional features via an infinitely-wide neural tangent kernel (NTK)"

## Foundational Learning

- Concept: Kernel Ridge Regression (KRR)
  - Why needed here: Forms the optimization objective for finding kernel inducing points that approximate the original dataset
  - Quick check question: What is the role of the regularization parameter λ in the KRR loss function?

- Concept: Differential Privacy (DP) and Gaussian Mechanism
  - Why needed here: Provides the mathematical framework for ensuring formal privacy guarantees when optimizing the distilled dataset
  - Quick check question: How does the noise scale σ in the Gaussian mechanism depend on the privacy parameters (ε, δ)?

- Concept: Neural Tangent Kernel (NTK) and its infinite-width limit
  - Why needed here: Provides the kernel function that captures the behavior of infinitely-wide neural networks for distribution matching
  - Quick check question: What is the key property of NTK in the infinite-width limit that makes it useful for understanding neural network training?

## Architecture Onboarding

- Component map: Original dataset → ScatterNet features → NTK kernel → KRR loss → DP-SGD optimization → Distilled dataset
- Critical path: Original dataset → ScatterNet features → NTK kernel → KRR loss → DP-SGD optimization → Distilled dataset
- Design tradeoffs:
  - ScatterNet vs conv-NTK: Computational efficiency vs potential performance gain
  - Number of distilled points vs privacy budget: More points improve utility but increase gradient sensitivity
  - Clipping norm C vs noise scale σ: Higher C preserves more information but requires more noise for same privacy
- Failure signatures:
  - Poor classification accuracy on distilled data: Could indicate inadequate feature representation or excessive noise
  - Training instability or divergence: May suggest incorrect gradient clipping or learning rate issues
  - Privacy budget exhaustion: Indicates gradient sensitivity too high or too many optimization steps
- First 3 experiments:
  1. Implement DP-KIP with fully-connected NTK on MNIST to verify basic functionality and compare with non-private KIP
  2. Add ScatterNet feature extraction and test on a small image dataset to validate computational efficiency claims
  3. Perform privacy-utility tradeoff analysis by varying ε and measuring classification accuracy on the distilled dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DP-KIP scale with different kernel choices beyond NTK and fully connected NTK, particularly for more complex data distributions?
- Basis in paper: [inferred] The paper mentions potential for improvement using different NTK architectures including ConvNets, but this was not implemented due to computational constraints.
- Why unresolved: The authors explicitly state they could not implement ConvNet NTK due to memory requirements that were only feasible with distributed computing resources inaccessible to them.
- What evidence would resolve it: Experimental results comparing DP-KIP performance using different kernel architectures (ConvNet NTK, RBF kernels, polynomial kernels) on the same datasets, showing performance trade-offs and computational requirements.

### Open Question 2
- Question: What is the optimal strategy for balancing privacy-accuracy trade-offs in DP-KIP through the clipping norm C parameter across different dataset types and sizes?
- Basis in paper: [explicit] The paper discusses the importance of setting the clipping norm C as a hyperparameter, noting that small values may discard important information while large values increase noise variance.
- Why unresolved: The paper only demonstrates the sensitivity of C through discussion but does not provide systematic experiments or theoretical guidance on how to set this parameter optimally for different scenarios.
- What evidence would resolve it: A comprehensive sensitivity analysis showing DP-KIP performance across different values of C for various dataset characteristics (dimensionality, sample size, noise levels), potentially with theoretical bounds or practical guidelines.

### Open Question 3
- Question: How does DP-KIP's privacy-utility trade-off compare to other privacy-preserving data generation methods when considering broader downstream tasks beyond classification?
- Basis in paper: [explicit] The paper acknowledges that their method aims for task-specific distillation while other methods aim for general-purpose data generation, making classification comparisons potentially unfair.
- Why unresolved: The experiments only compare DP-KIP to other methods on classification tasks, without exploring how these methods perform on regression, clustering, or other machine learning tasks.
- What evidence would resolve it: Experimental comparisons of DP-KIP and other private data generation methods across multiple downstream tasks (regression, clustering, anomaly detection) using the same privacy budget, showing task-specific performance differences.

## Limitations
- Performance heavily depends on quality of ScatterNet feature extraction, which may not generalize well to datasets with different characteristics
- Privacy-utility tradeoff is sensitive to hyperparameter choices (clipping norm C, noise scale σ), requiring careful tuning for each dataset
- Computational complexity, while reduced, may still be prohibitive for very large-scale datasets

## Confidence
- Confidence: Medium - The claim that ScatterNet features can match conv-NTK performance while reducing computational complexity is supported by theoretical arguments but lacks extensive empirical validation across diverse datasets
- Confidence: Medium - The privacy guarantees rely on DP-SGD with kernel ridge regression, but the analysis assumes the distilled dataset remains small
- Confidence: Low - The claim of superior performance over state-of-the-art private data generation techniques is based on comparisons with specific baselines and may not include more recent methods

## Next Checks
1. **Runtime Complexity Verification**: Implement both DP-KIP-ScatterNet and DP-KIP-conv-NTK on the same hardware and measure actual training times across different dataset sizes to verify the claimed computational efficiency improvements
2. **Feature Representation Analysis**: Conduct ablation studies comparing ScatterNet features with other feature extraction methods (e.g., PCA, autoencoders) to isolate the contribution of ScatterNet to the overall performance
3. **Privacy Budget Sensitivity**: Systematically vary the number of distilled points and measure how the privacy budget ε changes, testing whether the method maintains its privacy guarantees as the distilled dataset size increases