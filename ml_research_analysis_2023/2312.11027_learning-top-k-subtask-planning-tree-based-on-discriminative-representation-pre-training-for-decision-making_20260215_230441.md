---
ver: rpa2
title: Learning Top-k Subtask Planning Tree based on Discriminative Representation
  Pre-training for Decision Making
arxiv_id: '2312.11027'
source_url: https://arxiv.org/abs/2312.11027
tags:
- subtask
- learning
- tree
- planning
- subtasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of learning task representations
  and planning for complex decision-making in reinforcement learning. The authors
  propose a two-stage framework: (1) a multiple-encoder and individual-predictor regime
  to learn discriminative subtask representations from simple tasks, and (2) a top-k
  subtask planning tree generation algorithm to guide policy learning on complex tasks.'
---

# Learning Top-k Subtask Planning Tree based on Discriminative Representation Pre-training for Decision Making

## Quick Facts
- arXiv ID: 2312.11027
- Source URL: https://arxiv.org/abs/2312.11027
- Reference count: 40
- Key outcome: A two-stage framework combining discriminative subtask representation learning with top-k planning tree generation outperforms PPO, SAC, and CORRO on BabyAI complex tasks.

## Executive Summary
This paper addresses the challenge of learning task representations and planning for complex decision-making in reinforcement learning. The authors propose a two-stage framework that first learns discriminative subtask representations from simple tasks using multiple encoders and contrastive learning, then uses these representations to guide policy learning on complex tasks through a top-k subtask planning tree generation algorithm. The method is evaluated on the BabyAI platform, showing superior performance compared to baselines across various challenging scenarios. The approach enables agents to learn proper knowledge representations, recombine existing subtasks, and apply them to solve previously unseen, complicated tasks more effectively.

## Method Summary
The method consists of two stages: First, a multiple-encoder and individual-predictor regime learns discriminative subtask representations from simple tasks using contrastive learning and prediction loss. Each subtask has its own encoder to reduce representation interference. Second, a top-k subtask planning tree generation algorithm uses attention over pre-trained subtask embeddings combined with m-step prediction to generate diverse execution paths, then selects the optimal path using discounted upper confidence bounds. The planning tree guides a policy network to make decisions on complex tasks.

## Key Results
- The proposed method achieves superior performance compared to PPO, SAC, and CORRO baselines on BabyAI complex tasks including GoToSeq, GoToSeqS5R2, SynthSeq, BossLevel, BossLevelNoUnlock, and MiniBossLevel
- Optimal performance is achieved with a planning tree depth of 2-3 and width of 2-3, demonstrating the effectiveness of the planning tree design
- Ablation studies show that the method enables agents to learn proper knowledge representations and recombine existing subtasks to solve previously unseen, complicated tasks more effectively

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multiple encoders reduce representation interference between subtasks
- Mechanism: Each subtask has its own encoder, so state-action pairs from different subtasks are processed separately, preventing their reward and transition distributions from being conflated into similar abstractions
- Core assumption: Different subtasks have distinct reward and transition dynamics that should be kept separate in latent space
- Evidence anchors:
  - [abstract]: "Multiple encoders can extract adequate task-relevant dynamics without confusion"
  - [section 3.2]: "Each encoder corresponds to each subtask, which alleviates the disturbing burden of other subtasks on representation extraction"
  - [corpus]: Weak - no direct citation, but consistent with Split-Ensemble's approach to task separation
- Break condition: If subtasks share similar dynamics, separate encoders may unnecessarily increase model complexity without benefit

### Mechanism 2
- Claim: Contrastive learning between subtasks improves discrimination
- Mechanism: By treating samples from other subtasks as negative pairs, the contrastive loss pushes embeddings from different subtasks apart while pulling embeddings from the same subtask together
- Core assumption: The subtask boundary is the primary source of variation in the data
- Evidence anchors:
  - [section 3.2]: "For better distinguishment, a contrastive loss is applied, where samples from the other subtasks act as negative pairs"
  - [section 4.2]: Visual comparison shows clear clusters for our method versus blurred boundaries for shared encoder approach
  - [corpus]: Assumption - not explicitly cited, but consistent with general contrastive learning principles
- Break condition: If subtasks are not well-separated in state-action space, contrastive learning may create artificial boundaries

### Mechanism 3
- Claim: Tree planning enables forward-looking decision making
- Mechanism: The top-k subtask planning tree uses attention over pre-trained subtask embeddings combined with m-step prediction to generate diverse execution paths, then selects the optimal path using discounted upper confidence bounds
- Core assumption: Planning depth and width can be tuned to balance foresight and computational tractability
- Evidence anchors:
  - [abstract]: "We also use the attention mechanism to generate a top-k subtask planning tree, which customizes subtask execution plans"
  - [section 3.3]: Detailed description of tree construction, attention scoring, and sampling without replacement
  - [corpus]: Weak - closest is ProTIP's sequential tool retrieval, but not directly comparable to subtask planning
- Break condition: If m-step prediction is inaccurate, planning errors accumulate and degrade performance

## Foundational Learning

- Concept: Contrastive representation learning
  - Why needed here: To create distinct embeddings for different subtasks so the planner can discriminate between them
  - Quick check question: What would happen if we removed the contrastive loss and only used prediction loss?

- Concept: Attention mechanisms for multi-task selection
  - Why needed here: To score and select the most relevant subtasks for the current state when expanding the planning tree
  - Quick check question: How does the attention mechanism handle cases where multiple subtasks are equally relevant?

- Concept: Hierarchical planning with discounted rewards
  - Why needed here: To break down complex tasks into manageable subtasks while maintaining a long-term view of the optimal execution path
  - Quick check question: What trade-off does the discounted factor κ = 0.8 represent in the UCB calculation?

## Architecture Onboarding

- Component map:
  - Data Collection → Multiple Encoders + Shared Predictor → Contrastive + Prediction Loss → Subtask Embeddings
  - Embeddings + Query Encoder + Attention → Top-k Planning Tree → Discounted UCB → Subtask Execution Plan
  - Plan + Policy Network → Action Selection → Environment Interaction → Reward Collection

- Critical path: Data collection → representation pre-training → tree generation → policy execution
  - Each stage must complete successfully before the next can begin
  - The policy depends entirely on the quality of the pre-trained embeddings and the generated tree

- Design tradeoffs:
  - Encoder count vs. interference: More encoders reduce interference but increase parameters
  - Tree width vs. diversity: Wider trees offer more options but may dilute focus
  - Planning depth vs. accuracy: Deeper planning provides foresight but suffers from prediction error accumulation

- Failure signatures:
  - If embeddings cluster poorly: Subtasks won't be discriminable, planner will make confused selections
  - If tree generation produces uniform probabilities: Attention mechanism isn't distinguishing subtasks effectively
  - If policy performs no better than random: Either embeddings are wrong or tree selection isn't providing useful guidance

- First 3 experiments:
  1. Train with shared encoder vs. multiple encoders on 2 subtasks, compare t-SNE visualizations
  2. Fix tree width=2, vary depth from 1 to 4, measure reward on GoToSeq
  3. Remove contrastive loss, keep prediction loss, measure impact on execution performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the model change when using different numbers of negative pairs in the contrastive learning loss?
- Basis in paper: [inferred] The paper mentions using 16 negative pairs in the experimental settings, but does not explore the impact of varying this hyperparameter.
- Why unresolved: The paper does not provide an ablation study on the effect of negative pair count in the contrastive loss.
- What evidence would resolve it: Conducting experiments with different negative pair counts and comparing the performance on downstream tasks would reveal the optimal number of negative pairs for the contrastive learning objective.

### Open Question 2
- Question: Can the tree generation process be made more efficient by incorporating a learned termination condition instead of relying on similarity thresholds?
- Basis in paper: [inferred] The paper uses a cosine similarity threshold to determine when to terminate a subtask, but does not explore learning this termination condition.
- Why unresolved: The paper does not investigate alternative methods for determining subtask termination, such as learning a termination policy.
- What evidence would resolve it: Comparing the performance of the current similarity-based termination with a learned termination policy on downstream tasks would indicate whether a learned approach is beneficial.

### Open Question 3
- Question: How does the model's performance scale when applied to real-world, high-dimensional environments beyond the BabyAI platform?
- Basis in paper: [inferred] The paper evaluates the method on BabyAI, a 2D grid world environment, but does not test its performance in more complex, high-dimensional settings.
- Why unresolved: The paper does not provide experiments in real-world or high-dimensional environments, limiting the understanding of the method's scalability.
- What evidence would resolve it: Applying the method to real-world robotics tasks or high-dimensional simulated environments and comparing the performance to other approaches would demonstrate its scalability.

## Limitations
- The method assumes subtask boundaries are well-defined and distinct, which may not hold for all complex tasks where subtasks have overlapping or ambiguous boundaries
- Performance degrades with deeper planning trees (N > 3) due to accumulated prediction errors, limiting the method's ability to handle tasks requiring long-term foresight
- The approach requires collecting diverse trajectories from optimal, intermediate, and random policies for each subtask, which may be impractical in real-world applications where subtask demonstrations are limited

## Confidence
- High confidence: The effectiveness of multiple encoders in reducing representation interference and the benefits of contrastive learning for subtask discrimination
- Medium confidence: The optimal tree depth (2-3) and width (2-3) parameters, as these were validated only within the BabyAI platform and may not generalize to other domains
- Low confidence: The scalability of the approach to tasks with many more than 4 subtasks or to continuous action spaces without modification

## Next Checks
1. Test the sensitivity of performance to the number of subtasks (beyond 4) by incrementally adding new subtasks and measuring the degradation in representation quality and planning effectiveness
2. Evaluate the method on continuous control tasks (e.g., MuJoCo or PyBullet environments) to assess its applicability beyond discrete action spaces
3. Conduct a thorough ablation study removing the attention mechanism to determine whether simpler selection methods could achieve comparable results with reduced computational overhead