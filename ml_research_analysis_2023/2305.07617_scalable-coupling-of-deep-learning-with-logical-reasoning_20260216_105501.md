---
ver: rpa2
title: Scalable Coupling of Deep Learning with Logical Reasoning
arxiv_id: '2305.07617'
source_url: https://arxiv.org/abs/2305.07617
tags:
- learning
- loss
- sudoku
- training
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of coupling deep learning with
  logical reasoning for hybrid models. The authors introduce a scalable neural architecture
  that can learn NP-hard reasoning problems expressed as discrete graphical models
  from natural inputs.
---

# Scalable Coupling of Deep Learning with Logical Reasoning

## Quick Facts
- arXiv ID: 2305.07617
- Source URL: https://arxiv.org/abs/2305.07617
- Authors: David Salinas, Mathieu Fabre, Guillaume Simonin, Simon Roburin, Thomas Serriere, Edouard Leurent, Pierre Ménard, Jean-Bastien Grill, Patrick Pihlaja, Jean Ponce, Olivier Teytaud
- Reference count: 19
- Key outcome: E-NPLL loss enables learning of NP-hard reasoning problems with 100% accuracy on 17-hint Sudoku using only 200 training samples

## Executive Summary
This paper introduces a scalable neural architecture that couples deep learning with discrete graphical models to learn NP-hard reasoning problems from natural inputs. The key innovation is the Emmental Negative Pseudo-LogLikelihood (E-NPLL) loss, which enables learning high-energy graphical models by randomly dropping out incident functions during training to prevent gradient blocking from redundant constraints. The architecture achieves state-of-the-art results on Sudoku, visual Sudoku with MNIST digits, and protein design problems while being more data-efficient than previous approaches.

## Method Summary
The authors propose a hybrid architecture where a deep neural network predicts pairwise cost functions for a discrete graphical model, which can then be optimized with any solver at inference time. During training, they use the E-NPLL loss function instead of requiring exact solver calls, making the approach computationally tractable. The E-NPLL is a stochastic variant of the standard NPLL that randomly drops out some incident functions to prevent early-learned high costs from blocking gradients for other significant costs. The architecture is combined with L1 regularization on output cost matrices to promote exact zero costs, making the graphical model optimization problem easier to solve.

## Key Results
- Achieves 100% accuracy on 17-hint Sudoku grids with only 200 training samples using E-NPLL, compared to 9,000 samples for previous approaches
- Successfully learns to recognize MNIST digits while solving visual Sudoku, demonstrating hybrid perception-reasoning capabilities
- Outperforms existing energy functions in protein design tasks by learning geometry-dependent pairwise decomposable functions
- Shows superior data efficiency compared to previous neurosymbolic approaches across all tested domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The E-NPLL loss prevents gradient blocking caused by redundant constraints in discrete graphical models.
- Mechanism: By randomly dropping out incident functions during training, the E-NPLL prevents early-learned high costs from blocking gradients for other significant costs, enabling learning of all constraints even when some become redundant in context.
- Core assumption: Redundant constraints in the context of observed solutions block gradient-based learning in the standard NPLL.
- Evidence anchors: [abstract] "Our loss function solves one of the main limitations of Besag's pseudo-loglikelihood, enabling learning of high energies."

### Mechanism 2
- Claim: The hybrid architecture enables scalable learning by avoiding exact solver calls during training.
- Mechanism: The architecture outputs a full graphical model that can be optimized with any solver at inference, but during training uses the E-NPLL loss instead of requiring solver calls, avoiding computational intractability.
- Core assumption: Exact solvers become intractable on early training epochs when predicted GMs are essentially random.
- Evidence anchors: [section] "Using an exact optimization during learning seems inadequate: even if the finally predicted GMs may be empirically easy to solve... the GMs predicted in the early epochs of learning are essentially random."

### Mechanism 3
- Claim: L1 regularization on output cost matrices promotes exact zero costs, making the GM optimization problem easier to solve.
- Mechanism: By favoring sparse cost matrices with exact zeros, the L1 regularization simplifies the resulting graphical models and improves solver efficiency.
- Core assumption: Sparse cost matrices with exact zeros lead to easier optimization problems.
- Evidence anchors: [section] "This is used in combination with an L1 regularization on the output of the learned networkN(ω) to favour the prediction of exact zero costs which makes the GM optimization problem easier to solve."

## Foundational Learning

- Concept: Discrete Graphical Models as reasoning language
  - Why needed here: GMs provide a concise representation of joint functions through elementary cost functions, covering constraint networks, propositional logic, and numerical variants.
  - Quick check question: What are the three main types of reasoning problems that discrete graphical models can represent?

- Concept: Pseudo-loglikelihood for scalable training
  - Why needed here: The negative pseudo-loglikelihood (NPLL) provides a tractable approximation to the intractable negative loglikelihood, enabling scalable training from natural inputs.
  - Quick check question: Why is the standard negative loglikelihood intractable for graphical models?

- Concept: Redundancy in logical constraints
  - Why needed here: Understanding how constraints can become redundant in context is crucial for designing loss functions that can learn all necessary constraints.
  - Quick check question: How does context-dependent redundancy affect the learnability of constraints in graphical models?

## Architecture Onboarding

- Component map: Natural inputs (ω) → Deep learning layers → Pairwise cost function predictions (N(ω)) → Discrete graphical model → E-NPLL loss → Backpropagation

- Critical path: Natural inputs → Deep learning layers → Cost function predictions → E-NPLL loss computation → Gradients → Weight updates

- Design tradeoffs:
  - Exact solver vs. relaxation: Exact solvers provide guarantees but are intractable for early training epochs; relaxations are scalable but sacrifice guarantees
  - Dropout rate in E-NPLL: Higher rates prevent blocking but may reduce information; lower rates preserve information but risk blocking
  - L1 regularization strength: Stronger regularization promotes sparsity but may prevent learning necessary costs

- Failure signatures:
  - Training fails to converge: May indicate dropout rate too high or loss function not properly guiding learning
  - 100% accuracy on training but poor test performance: May indicate overfitting or insufficient generalization
  - Extremely slow training: May indicate computational bottleneck in deep learning layers or inefficient E-NPLL computation

- First 3 experiments:
  1. Train on symbolic Sudoku with varying E-NPLL dropout rates (k=0, 10, 20) to observe effect on learning all constraints
  2. Test on visual Sudoku with MNIST hints to verify digit recognition and Sudoku solving capabilities
  3. Apply to protein design problem with variable geometry to test scalability and real-world applicability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the E-NPLL loss be extended to handle non-pairwise graphical models and higher-order interactions?
- Basis in paper: [explicit] The authors mention that the use of other languages (e.g. weighted clauses) in replacement of, or addition to, pairwise functions would enhance the capacity of the architecture to capture many-bodies interactions.
- Why unresolved: The paper focuses on pairwise graphical models and does not explore extensions to handle higher-order interactions or other graphical model languages.
- What evidence would resolve it: Experiments demonstrating the effectiveness of the E-NPLL loss on non-pairwise graphical models and its ability to capture higher-order interactions.

### Open Question 2
- Question: How does the E-NPLL loss perform on other NP-hard reasoning problems beyond Sudoku and protein design?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of the E-NPLL loss on Sudoku and protein design problems, but does not explore its performance on other NP-hard reasoning problems.
- Why unresolved: The paper focuses on specific problems and does not provide a comprehensive evaluation of the E-NPLL loss on a diverse set of NP-hard reasoning problems.
- What evidence would resolve it: Experiments demonstrating the effectiveness of the E-NPLL loss on a wide range of NP-hard reasoning problems, including but not limited to Sudoku and protein design.

### Open Question 3
- Question: Can the E-NPLL loss be used to learn constraints from incomplete or noisy data?
- Basis in paper: [inferred] The paper does not explicitly address the issue of learning constraints from incomplete or noisy data, but the ability to handle many-solutions Sudoku problems suggests that the E-NPLL loss may be robust to some degree of incompleteness or noise.
- Why unresolved: The paper focuses on learning constraints from complete and accurate data, but does not explore its performance on incomplete or noisy data.
- What evidence would resolve it: Experiments demonstrating the effectiveness of the E-NPLL loss on learning constraints from incomplete or noisy data, and comparing its performance to other approaches.

## Limitations
- The E-NPLL loss function's effectiveness depends heavily on the choice of dropout parameter k, which is not extensively explored across different problem domains
- The architecture assumes pairwise decomposable functions, which may not capture all types of reasoning problems
- The L1 regularization's impact on learning non-zero costs requires careful tuning and may limit the expressiveness of learned models

## Confidence

- High confidence: The E-NPLL loss function's ability to prevent gradient blocking through random dropout is well-supported by the Sudoku experiments and the logical reasoning about constraint redundancy
- Medium confidence: The claim that the hybrid architecture enables scalable learning without exact solver calls during training is supported by empirical results but relies on the assumption that predicted GMs become easier to solve as training progresses
- Low confidence: The protein design application's superiority over existing energy functions, while promising, is demonstrated on a limited set of protein backbones and may not generalize to all protein design scenarios

## Next Checks

1. **Cross-domain robustness**: Test the E-NPLL loss function with varying dropout rates (k=0, 10, 20) on symbolic Sudoku to systematically evaluate its effect on learning all constraints and preventing gradient blocking

2. **Generalization to non-pairwise problems**: Apply the architecture to a non-pairwise reasoning problem (e.g., higher-order logic constraints or non-decomposable functions) to assess whether the approach scales beyond the pairwise assumption

3. **Ablation study on regularization**: Perform an ablation study on the L1 regularization strength in the protein design task, comparing learned cost functions with and without sparsity constraints to determine its true impact on optimization efficiency and model expressiveness