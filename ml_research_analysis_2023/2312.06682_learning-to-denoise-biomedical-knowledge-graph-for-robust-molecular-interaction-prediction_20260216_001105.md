---
ver: rpa2
title: Learning to Denoise Biomedical Knowledge Graph for Robust Molecular Interaction
  Prediction
arxiv_id: '2312.06682'
source_url: https://arxiv.org/abs/2312.06682
tags:
- semantic
- relations
- prediction
- subgraph
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of molecular interaction prediction
  in biomedical knowledge graphs (KGs), which is crucial for drug discovery and therapeutics.
  Existing methods often suffer from noise and unreliable interactions in KGs, limiting
  their effectiveness.
---

# Learning to Denoise Biomedical Knowledge Graph for Robust Molecular Interaction Prediction

## Quick Facts
- **arXiv ID**: 2312.06682
- **Source URL**: https://arxiv.org/abs/2312.06682
- **Reference count**: 10
- **Primary result**: BioKDN surpasses state-of-the-art models in drug-target interaction (DTI) and drug-drug interaction (DDI) prediction tasks

## Executive Summary
This paper addresses the challenge of molecular interaction prediction in biomedical knowledge graphs (KGs), which is crucial for drug discovery and therapeutics. Existing methods often suffer from noise and unreliable interactions in KGs, limiting their effectiveness. To overcome this limitation, the authors propose BioKDN, a novel denoising model for robust molecular interaction prediction. BioKDN refines the local subgraph structure by denoising noisy links in a learnable manner, providing a general module for extracting task-relevant interactions. It also maintains consistent and robust semantics by smoothing relations around the target interaction. By maximizing the mutual information between reliable structure and smoothed relations, BioKDN emphasizes informative semantics to enable precise predictions. Experimental results on real-world datasets demonstrate that BioKDN surpasses state-of-the-art models in drug-target interaction (DTI) and drug-drug interaction (DDI) prediction tasks, confirming its effectiveness and robustness in denoising unreliable interactions within contaminated KGs.

## Method Summary
BioKDN is a novel denoising model for robust molecular interaction prediction in biomedical knowledge graphs. The method initializes KG embeddings using RotatE, then denoises local subgraph structure using structure reliability learning to filter out unreliable edges. It smooths semantic relations by generalizing interaction types into broader categories (positive, interaction, negative) to reduce conflicts. The model maximizes mutual information between reliable structure and smoothed semantic subgraphs using InfoNCE, encouraging alignment between the two views. Finally, it jointly optimizes link prediction and MI maximization to improve prediction accuracy on DTI and DDI tasks.

## Key Results
- BioKDN achieves state-of-the-art performance on drug-target interaction (DTI) and drug-drug interaction (DDI) prediction tasks
- The model demonstrates robustness to noise in biomedical knowledge graphs by effectively denoising unreliable interactions
- BioKDN maintains consistent and robust semantics by smoothing relations around target interactions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Denoising unreliable links in local subgraphs improves prediction accuracy for molecular interactions.
- Mechanism: The model learns edge reliability weights using a task-guided attention mechanism, filtering out low-weight edges that likely represent noise.
- Core assumption: Nodes with similar features or structures are more likely to interact, so unreliable edges can be identified by their weight.
- Evidence anchors:
  - [abstract] "refines the local subgraph structure by denoising noisy links in a learnable manner"
  - [section] "assigns weights to all edges between the set of nodes using a reliability estimation function"
  - [corpus] No direct evidence found; this is a novel contribution.
- Break condition: If the attention mechanism fails to differentiate reliable from unreliable edges, or if noise is uniformly distributed, the filtering becomes ineffective.

### Mechanism 2
- Claim: Smoothing relations around predicted links reduces the impact of conflicting semantics in KGs.
- Mechanism: The model generalizes interaction types into broader categories (positive, interaction, negative) and blurs sparse relations, reducing noise from conflicting triples.
- Core assumption: Conflicting relations introduce semantic noise that can be mitigated by relation generalization and smoothing.
- Evidence anchors:
  - [abstract] "maintains consistent and robust semantics by smoothing relations around the target interaction"
  - [section] "smooth the KG by leveraging prior knowledge to generalize the interactions into positive, interaction, and negative"
  - [corpus] No direct evidence found; this is a novel contribution.
- Break condition: If the smoothing is too aggressive, it may erase important distinctions between relation types, harming prediction accuracy.

### Mechanism 3
- Claim: Maximizing mutual information between reliable structure and smoothed semantics emphasizes informative interactions.
- Mechanism: A contrastive learning objective aligns the representations of denoised local subgraphs and smoothed semantic subgraphs, encouraging the model to focus on consistent patterns.
- Core assumption: Reliable structure and smoothed semantics contain complementary information that can be aligned to highlight task-relevant interactions.
- Evidence anchors:
  - [abstract] "maximizing the mutual information between reliable structure and smoothed relations"
  - [section] "utilize InfoNCE to estimate mutual information between the representations of local structure and semantic subgraphs"
  - [corpus] No direct evidence found; this is a novel contribution.
- Break condition: If the MI maximization does not effectively align the two views, or if one view is dominated by noise, the contrastive signal becomes uninformative.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) for learning node and edge representations from graph-structured data.
  - Why needed here: The method relies on GNNs to extract local subgraph structures and semantic subgraphs for denoising.
  - Quick check question: What is the difference between GCN and RGCN in handling multi-relational graphs?

- Concept: Knowledge Graph Embeddings (e.g., RotatE) for initializing entity and relation features.
  - Why needed here: The model uses RotatE embeddings as input features for the denoising modules.
  - Quick check question: How does RotatE model relations differently from TransE or DistMult?

- Concept: Contrastive Learning and Mutual Information Maximization for representation alignment.
  - Why needed here: MI maximization is used to align denoised structure and smoothed semantics.
  - Quick check question: What is the difference between InfoNCE and other MI estimation methods like MINE?

## Architecture Onboarding

- Component map: RotatE -> Structure Reliability Learning -> Smooth Semantic Preservation -> MI Maximization -> Link Prediction
- Critical path: Local subgraph extraction -> Reliability estimation -> Semantic subgraph extraction -> Contrastive alignment -> Prediction
- Design tradeoffs: (1) Tradeoff between denoising aggressiveness and preserving useful edges; (2) Tradeoff between smoothing semantic relations and retaining fine-grained distinctions.
- Failure signatures: (1) AUC-ROC drops with increasing noise if reliability estimation fails; (2) Performance degrades if MI maximization does not align the two views.
- First 3 experiments:
  1. Test reliability estimation with varying noise ratios on a synthetic graph.
  2. Compare smoothing strategies (generalization vs. no smoothing) on DDI datasets.
  3. Evaluate MI maximization by ablating it and measuring the gap in link prediction performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of different reliability estimation functions (e.g., Attention, MLP, Weighted_Cosine, Cosine) impact the performance of DenoisedLP?
- Basis in paper: [explicit] The paper mentions that they conducted experiments with different reliability estimation functions and found that Attention with linear attention modeling the reliability weight between nodes set had the best performance.
- Why unresolved: While the paper provides a comparison of different reliability estimation functions, it does not delve into the reasons behind the performance differences or the potential trade-offs between these functions.
- What evidence would resolve it: A detailed analysis of the performance of different reliability estimation functions on various datasets and link prediction tasks would provide insights into their strengths and weaknesses.

### Open Question 2
- Question: How does DenoisedLP handle the challenge of entity misalignment in biomedical knowledge graphs?
- Basis in paper: [explicit] The paper mentions that entity misalignment can result in missing facts and noisy interactions in the knowledge graph, but it does not provide a specific solution to address this issue.
- Why unresolved: While the paper acknowledges the problem of entity misalignment, it does not provide a detailed explanation of how DenoisedLP addresses this challenge.
- What evidence would resolve it: An evaluation of DenoisedLP's performance on datasets with known entity misalignment issues would demonstrate its effectiveness in handling this challenge.

### Open Question 3
- Question: How does the choice of metapaths in the smooth semantic preservation module impact the performance of DenoisedLP?
- Basis in paper: [explicit] The paper mentions that the smooth semantic preservation module uses predefined metapaths to extract relational paths, but it does not provide a detailed analysis of the impact of different metapaths on the model's performance.
- Why unresolved: While the paper acknowledges the importance of metapaths in the smooth semantic preservation module, it does not explore the impact of different metapaths on the model's performance.
- What evidence would resolve it: An evaluation of DenoisedLP's performance using different sets of metapaths would provide insights into the impact of metapaths on the model's effectiveness.

## Limitations
- The reliability estimation function for structure denoising is not fully specified, creating potential reproducibility challenges
- The concrete relaxation parameters for the edge reliability weights are not explicitly detailed
- The specific smoothing strategy for generalizing interaction types (positive, interaction, negative) lacks implementation details

## Confidence
- **High confidence**: The overall framework design and the three proposed mechanisms are logically coherent and address well-known challenges in KG denoising
- **Medium confidence**: The experimental results demonstrate strong performance, but the lack of implementation details makes full validation difficult
- **Medium confidence**: The theoretical justification for MI maximization between structure and semantics is sound, but empirical validation of this specific contribution is limited

## Next Checks
1. Implement and test the structure reliability learning module with synthetic KGs containing controlled noise levels to validate edge filtering effectiveness
2. Conduct ablation studies comparing different semantic smoothing strategies to quantify the impact on prediction performance
3. Evaluate the MI maximization component by measuring representation alignment quality between denoised structure and smoothed semantics using established metrics like NMI or downstream classification accuracy