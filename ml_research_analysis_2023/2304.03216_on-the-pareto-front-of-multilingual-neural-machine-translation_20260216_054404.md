---
ver: rpa2
title: On the Pareto Front of Multilingual Neural Machine Translation
arxiv_id: '2304.03216'
source_url: https://arxiv.org/abs/2304.03216
tags:
- performance
- sampling
- directions
- training
- ratio
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies how sampling ratios affect performance in multilingual
  neural machine translation (MNMT). It identifies that scalarization methods can
  lead to a collapsed Pareto front when data is imbalanced across language pairs,
  challenging overall optimization.
---

# On the Pareto Front of Multilingual Neural Machine Translation

## Quick Facts
- arXiv ID: 2304.03216
- Source URL: https://arxiv.org/abs/2304.03216
- Reference count: 6
- Primary result: Double Power Law-based sampling achieves +0.3 to +2.3 BLEU improvement over baselines in multilingual NMT

## Executive Summary
This paper investigates how sampling ratios affect performance in multilingual neural machine translation (MNMT) and identifies that scalarization methods can lead to collapsed Pareto fronts when data is imbalanced across language pairs. The authors propose the Double Power Law to model how performance changes with sampling ratio, accounting for both capacity occupation and overfitting risk. Based on this law, they formulate an optimization problem to compute optimal sampling ratios, achieving better average BLEU scores than temperature-based and gradient manipulation baselines while using the same or less computational budget.

## Method Summary
The authors propose a Double Power Law to predict performance trade-offs in MNMT by modeling how sampling ratios affect each translation direction through two power-law terms: capacity occupation (which improves with more sampling) and intrinsic overfitting (which eventually degrades performance for low-resource directions). They formulate an optimization problem to compute optimal sampling ratios based on this law and compare their method against temperature-based and gradient manipulation baselines across 200 multilingual models with varying sizes, directions, and task numbers.

## Key Results
- Temperature-based and gradient manipulation baselines fail to produce Pareto optimal solutions in imbalanced MNMT settings
- The Double Power Law accurately predicts performance curves across different language pairs and data sizes
- Optimal sampling ratios computed via DPL achieve +0.3 to +2.3 BLEU improvement over baselines
- Larger models show more severe overfitting issues for low-resource directions (higher β parameter)

## Why This Works (Mechanism)

### Mechanism 1
The Double Power Law captures how sampling ratio affects performance by separating capacity occupation from overfitting risk, explaining Pareto front collapse. Performance for each direction is modeled as a sum of two power-law terms: capacity occupation (increases with sampling ratio) and intrinsic overfitting (increases with sampling ratio but decreases with more training examples). This formulation predicts when increasing a low-resource direction's weight will actually harm performance. Core assumption: power-law relationships between sampling ratio, training data size, and performance are predictable and parameterizable. Evidence: Figure 5 shows the law reflects performance changes for both high-resource and low-resource directions. Break condition: if power-law relationship doesn't hold with extremely small datasets or highly non-convex loss landscapes.

### Mechanism 2
Pareto front collapse occurs because increasing sampling ratio for low-resource directions eventually increases overfitting, outweighing capacity occupation benefits. For low-resource directions, the intrinsic overfitting term dominates at high sampling ratios, creating a U-shaped performance curve with an optimal sampling ratio. High-resource directions don't show this behavior due to sufficient data preventing overfitting. Core assumption: capacity allocation and overfitting patterns follow predictable power-law patterns. Evidence: When increasing sampling ratio from 10% to 90%, low-resource direction performance first improves then degrades. Break condition: if model architecture changes significantly, capacity allocation and overfitting patterns may change.

### Mechanism 3
The Double Power Law can be estimated from limited experiments and generalized to predict performance across different language pairs, data sizes, and model configurations. By conducting experiments with few language pairs and data sizes, power-law parameters can be estimated and then generalized because the underlying relationship is consistent. Core assumption: power-law parameters are consistent across different language pairs and model sizes, requiring only bias term adjustments. Evidence: The law shows good generalization across tested settings with consistent power terms. Break condition: if the relationship between sampling ratio and performance changes significantly with new training techniques or architectures.

## Foundational Learning

- **Concept**: Pareto optimality and Pareto front
  - Why needed here: The paper's core contribution is identifying when scalarization methods fail to produce Pareto optimal solutions in MNMT
  - Quick check question: What is the difference between a Pareto optimal solution and a Pareto front?

- **Concept**: Power-law relationships in machine learning
  - Why needed here: The Double Power Law is based on the observation that certain relationships in machine learning follow power-law patterns
  - Quick check question: What is a power law, and can you give an example of where it appears in machine learning?

- **Concept**: Overfitting and regularization
  - Why needed here: The analysis of why increasing sampling ratio can harm performance for low-resource directions relies on understanding overfitting and how sampling acts as regularization
  - Quick check question: How does increasing the amount of training data typically affect a model's tendency to overfit?

## Architecture Onboarding

- **Component map**: Data pipeline (loads parallel corpora) -> Model (Transformer-based MNMT) -> Training loop (implements sampling strategies) -> Evaluation (computes loss and BLEU) -> Analysis (fits DPL parameters and computes optimal ratios)

- **Critical path**:
  1. Load and preprocess data for multiple language pairs
  2. Train baseline models with different sampling strategies
  3. Fit Double Power Law parameters from experimental results
  4. Compute optimal sampling ratios using the fitted model
  5. Train final model with computed optimal ratios and evaluate

- **Design tradeoffs**:
  - Temperature-based sampling vs. DPL: Temperature requires grid search over temperature values, while DPL requires fitting parameters but then directly computes optimal ratios
  - Model size: Larger models have more severe overfitting issues for low-resource directions (higher β parameter)
  - Number of language pairs: More pairs increase computational cost and complexity of the optimization problem

- **Failure signatures**:
  - Poor fit of Double Power Law to experimental data (high residuals)
  - Optimal sampling ratios that are extreme (close to 0 or 1) or don't make intuitive sense
  - Performance degradation when increasing sampling ratio for low-resource directions beyond a certain point
  - Inconsistent results across different random seeds

- **First 3 experiments**:
  1. Train a 2-language MNMT model (high-resource + low-resource) with varying sampling ratios (10% to 90%) and record performance
  2. Fit the Double Power Law parameters using the results from experiment 1
  3. Compute optimal sampling ratios using the fitted model and train a new model with these ratios to verify improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Double Power Law generalize to non-English-centric MNMT settings?
- Basis in paper: [explicit] The paper states the law is robust across different languages but does not test non-English-centric scenarios
- Why unresolved: Experiments only use English-to-X directions, leaving applicability to other pivot languages untested
- What evidence would resolve it: Experiments showing performance predictions and sampling ratio optimizations for multilingual settings without English as the pivot language

### Open Question 2
- Question: What is the impact of using larger-scale models (e.g., GPT-3-sized or beyond) on the collapse of Pareto front and the applicability of the Double Power Law?
- Basis in paper: [inferred] The paper only tests models up to 317M parameters and notes that intrinsic overfitting power increases with model size
- Why unresolved: No empirical data on how extremely large models handle low-resource direction trade-offs
- What evidence would resolve it: Scaling experiments with models >1B parameters showing performance curves and Pareto front behavior

### Open Question 3
- Question: How sensitive is the Double Power Law to domain shifts in training data (e.g., news vs. conversational)?
- Basis in paper: [inferred] The law is validated on WMT datasets but domain robustness is not discussed
- Why unresolved: The model is trained and evaluated on parallel news translation data; no cross-domain validation is provided
- What evidence would resolve it: Experiments showing prediction accuracy and optimal sampling ratios across multiple domains with varying data sizes

## Limitations

- The empirical validation is primarily conducted on a limited set of language pairs (English-to-French, English-to-Chinese, English-to-German, and English-to-Hindi) and specific dataset sizes
- The generalizability to other language families, script systems, or extremely low-resource scenarios (less than 100K training examples) remains uncertain
- The paper does not extensively explore the impact of different model architectures beyond the Transformer baseline

## Confidence

- **High Confidence**: The empirical observation that scalarization methods can lead to collapsed Pareto fronts in imbalanced MNMT settings is well-supported by experimental results
- **Medium Confidence**: The mathematical formulation of the Double Power Law and its ability to accurately predict performance trade-off curves across different language pairs and data sizes is reasonably well-supported
- **Low Confidence**: The claim that the Double Power Law is "robust across various languages, data adequacy and number of tasks" is based on a relatively small experimental scope

## Next Checks

1. **Cross-linguistic validation**: Test the Double Power Law's predictive accuracy on a more diverse set of language pairs, including low-resource languages from different families (e.g., African, indigenous American, or Polynesian languages) and non-Latin scripts to assess generalizability

2. **Architecture robustness test**: Evaluate the method's effectiveness when applied to different model architectures (e.g., RNN-based, convolutional, or more recent efficient architectures) to determine if the power-law relationships hold across architectural choices

3. **Real-world deployment simulation**: Implement the method in a production-like setting with dynamically changing data distributions and continuously updating models to assess the practical utility and computational overhead of the parameter estimation process