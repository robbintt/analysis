---
ver: rpa2
title: 'Finding Paths for Explainable MOOC Recommendation: A Learner Perspective'
arxiv_id: '2312.10082'
source_url: https://arxiv.org/abs/2312.10082
tags:
- recommendation
- course
- path
- participants
- learner
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an explainable MOOC recommendation system using
  reinforcement learning over knowledge graphs (KGs). The authors adapt Policy-Guided
  Path Reasoning (PGPR) to educational contexts by introducing Unrestricted PGPR (UPGPR),
  which removes manually defined path patterns and employs a binary reward function.
---

# Finding Paths for Explainable MOOC Recommendation: A Learner Perspective

## Quick Facts
- arXiv ID: 2312.10082
- Source URL: https://arxiv.org/abs/2312.10082
- Reference count: 40
- Primary result: RL-based path reasoning achieves 6.66-20.85 NDCG with learner preference for category/teacher explanations over popularity-based ones

## Executive Summary
This paper introduces UPGPR (Unrestricted Policy-Guided Path Reasoning), an explainable MOOC recommendation system that uses reinforcement learning to find interpretable paths through knowledge graphs. By removing manually defined path patterns and employing a binary reward function, UPGPR discovers meaningful multi-hop connections between learners and courses. The system achieves competitive recommendation performance while providing transparent explanations that users prefer over traditional popularity-based approaches.

## Method Summary
UPGPR adapts Policy-Guided Path Reasoning to educational contexts by using a binary reward function that encourages exploration of multi-hop paths in knowledge graphs. The system trains entity and relation embeddings, then uses RL agents to find paths connecting learners to courses they've enrolled in. Experiments on COCO and Xuetang MOOC datasets show UPGPR achieves NDCG scores of 6.66-20.85 depending on path length. A user study with 25 participants reveals preferences for category and teacher-based explanations over learner-based ones, with longer paths perceived as more complex and less trustworthy.

## Key Results
- UPGPR achieves NDCG scores ranging from 6.66-20.85 depending on path length
- Learners prefer path-based explanations over popularity-based explanations
- Category and Teacher relation paths are favored over Learner relation paths
- Longer paths are perceived as more complex and less trustworthy
- Users in skill development conditions prefer category explanations, while credit-seekers prefer teacher explanations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RL agents find meaningful recommendation paths when rewarded for connecting learners to courses they are enrolled in via multi-hop paths.
- Mechanism: The binary reward encourages exploration of paths longer than one hop that terminate at a course the learner has enrolled in, avoiding trivial direct edges.
- Core assumption: Longer, multi-hop paths capture richer context for recommendations and generalize better than single-hop paths.
- Evidence anchors:
  - [abstract]: "removes manually defined path patterns and employs a binary reward function"
  - [section]: "Our binary reward thus encourages the agent to seek out more complex paths that could potentially lead to courses not yet explored by the learner"
- Break condition: If the KG structure lacks sufficient diversity in relations, agents may default to repetitive patterns like "learner → course → learner" that provide little new information.

### Mechanism 2
- Claim: Path-based explanations increase user trust and satisfaction compared to popularity-based explanations.
- Mechanism: Users perceive logical, step-by-step reasoning (e.g., "Learner A completed Course B, which is taught by Teacher C, who also teaches the recommended course") as more trustworthy than simple popularity rankings.
- Core assumption: Transparency in recommendation reasoning directly correlates with user trust and perceived usefulness.
- Evidence anchors:
  - [abstract]: "learners prefer path-based explanations over popularity-based ones"
  - [section]: "the path-based explanation was rated the highest in trust (μ = 4.00)"
- Break condition: If paths become too long or complex, users may find them confusing rather than informative, reducing trust.

### Mechanism 3
- Claim: Different user motivations (skill development vs. credit fulfillment) influence preference for specific path relations.
- Mechanism: Learners focused on skill development prefer paths emphasizing course categories, while those seeking credits favor paths highlighting teachers or institutions.
- Core assumption: Alignment between explanation content and user goals enhances perceived relevance and satisfaction.
- Evidence anchors:
  - [abstract]: "explanations using 'Category' and 'Teacher' relations being favored over 'Learner' relations"
  - [section]: "participants in the Credits condition were more satisfied with the degree of detail provided by the teacher and category explanations"
- Break condition: If user motivations are not correctly identified or the KG lacks sufficient relation diversity, explanations may fail to align with user expectations.

## Foundational Learning

- Concept: Reinforcement Learning (RL) basics
  - Why needed here: The system uses RL agents to explore KG paths and learn optimal recommendation strategies.
  - Quick check question: What is the role of the reward function in RL-based recommendation systems?

- Concept: Knowledge Graphs (KGs)
  - Why needed here: The system represents MOOCs, learners, courses, teachers, and concepts as nodes and relations in a KG to enable path reasoning.
  - Quick check question: How do entities and relations in a KG enable explainable recommendations?

- Concept: Path reasoning
  - Why needed here: The system generates explanations by finding interpretable paths between learners and recommended courses.
  - Quick check question: Why might multi-hop paths provide richer context than single-hop paths?

## Architecture Onboarding

- Component map: KG Construction -> Embedding Training -> RL Agent -> Path Generation -> Recommendation + Explanation -> User Study Evaluation
- Critical path: KG Construction → Embedding Training → RL Agent Training → Path Generation → Recommendation + Explanation → User Study Evaluation
- Design tradeoffs:
  - Accuracy vs. Interpretability: Longer paths improve accuracy but may reduce interpretability
  - KG Richness vs. Model Complexity: Richer KGs enable more diverse paths but increase computational cost
  - User Control vs. Automation: Allowing users to select explanation types increases satisfaction but complicates the UI
- Failure signatures:
  - Agents converge to trivial paths (e.g., direct enrollment edges)
  - Users rate explanations as confusing or overly complex
  - Performance metrics degrade significantly with increased path length
- First 3 experiments:
  1. Validate that the binary reward function prevents trivial path selection by comparing path distributions with and without the reward
  2. Test user preferences for different explanation types (category, teacher, learner) across motivation conditions
  3. Measure the impact of path length on both recommendation accuracy and user satisfaction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of reward function in UPGPR affect the diversity and novelty of recommended courses compared to traditional collaborative filtering approaches?
- Basis in paper: [explicit] The paper introduces a binary reward function for UPGPR and discusses its impact on the agent's exploration and generalization capabilities.
- Why unresolved: The paper does not provide a detailed analysis of the diversity and novelty of recommendations made by UPGPR compared to traditional collaborative filtering methods.
- What evidence would resolve it: A comparative study analyzing the diversity and novelty metrics of recommendations from UPGPR and traditional collaborative filtering methods, using the same datasets and evaluation metrics.

### Open Question 2
- Question: What are the long-term effects of using path-based explanations on learner trust and satisfaction in MOOC recommendation systems?
- Basis in paper: [inferred] The paper mentions that learners showed a preference for path-based explanations and discusses the importance of trust in educational recommendation systems, but does not explore long-term effects.
- Why unresolved: The user study conducted in the paper is limited to a single session, and there is no follow-up to assess the long-term impact of path-based explanations on learner trust and satisfaction.
- What evidence would resolve it: A longitudinal study tracking learner trust and satisfaction over time with MOOC recommendation systems using path-based explanations, comparing it to systems using other types of explanations.

### Open Question 3
- Question: How does the complexity of the knowledge graph (KG) structure influence the interpretability and performance of UPGPR in MOOC recommendation?
- Basis in paper: [explicit] The paper discusses the impact of KG structure on the patterns discovered by UPGPR and mentions the limitations due to the limited number of relations involving concepts and categories in the KG.
- Why unresolved: The paper does not provide a detailed analysis of how different KG structures affect the interpretability and performance of UPGPR, nor does it explore strategies to optimize the KG for better performance.
- What evidence would resolve it: An empirical study comparing the performance and interpretability of UPGPR on KGs with varying structures, including those with a higher number of diverse relations, and an analysis of strategies to optimize the KG for improved recommendation quality.

## Limitations

- Small user study sample (25 participants) limits generalizability of preference findings
- KG structure dependencies may constrain path diversity and recommendation quality
- Limited analysis of long-term effects on learner trust and satisfaction
- Binary reward function may oversimplify complex recommendation scenarios

## Confidence

- Recommendation performance claims: High
- User preference findings: Medium
- RL mechanism effectiveness: Medium

## Next Checks

1. **Ablation study on reward function**: Compare UPGPR performance with different reward formulations (e.g., continuous vs. binary, varying thresholds) to quantify the impact on path diversity and recommendation quality.

2. **Larger-scale user study**: Replicate the user preference experiment with 100+ participants across diverse educational backgrounds and MOOC usage patterns to test generalizability.

3. **KG structure sensitivity analysis**: Systematically vary relation types and entity connectivity in the KG to measure how structural changes affect both recommendation performance and path interpretability.