---
ver: rpa2
title: Twice Class Bias Correction for Imbalanced Semi-Supervised Learning
arxiv_id: '2312.16604'
source_url: https://arxiv.org/abs/2312.16604
tags:
- class
- unlabeled
- data
- samples
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces Twice Class Bias Correction (TCBC), a novel
  approach to address class imbalance challenges in semi-supervised learning (SSL).
  The method tackles two key issues: model bias due to imbalanced labeled data and
  biased pseudo-labels during training.'
---

# Twice Class Bias Correction for Imbalanced Semi-Supervised Learning

## Quick Facts
- arXiv ID: 2312.16604
- Source URL: https://arxiv.org/abs/2312.16604
- Authors: 
- Reference count: 8
- This paper introduces Twice Class Bias Correction (TCBC), a novel approach to address class imbalance challenges in semi-supervised learning (SSL).

## Executive Summary
This paper introduces Twice Class Bias Correction (TCBC), a novel approach to address class imbalance challenges in semi-supervised learning (SSL). The method tackles two key issues: model bias due to imbalanced labeled data and biased pseudo-labels during training. TCBC employs a two-stage correction strategy: first, it adjusts the model's learning objectives using an estimate of the training sample class distribution to learn balanced posterior probabilities; second, it refines pseudo-labels by estimating and correcting the model's class bias under current parameters during training. Extensive experiments on CIFAR10/100-LT, STL10-LT, and SUN397 datasets demonstrate that TCBC significantly outperforms state-of-the-art methods, achieving up to 4% higher accuracy in highly imbalanced scenarios.

## Method Summary
Twice Class Bias Correction (TCBC) addresses class imbalance in semi-supervised learning through a two-stage correction process. First, it estimates the class distribution of training samples and applies logit adjustment to learn balanced posterior probabilities. Second, it estimates the current model parameter class bias and applies a secondary correction to refine pseudo-labels for unlabeled samples. The method integrates with existing SSL frameworks like FixMatch and is evaluated on CIFAR10-LT, CIFAR100-LT, STL10-LT, and SUN397 datasets with varying imbalance ratios.

## Key Results
- TCBC achieves up to 4% higher accuracy compared to state-of-the-art methods on highly imbalanced datasets
- The method effectively handles varying unlabeled data distributions (γu=1 vs γu=100)
- TCBC demonstrates significant improvements on CIFAR100-LT, STL10-LT, and SUN397 datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic estimation of training sample class distribution corrects model bias in learning objectives
- Mechanism: The method estimates the marginal distribution ptr(y) of the combined labeled and pseudo-labeled data over recent iterations, then applies logit adjustment to learn posterior probabilities under a class-balanced prior
- Core assumption: Training samples from labeled and unlabeled data share the same class-conditional distribution p(x|y)
- Evidence anchors:
  - [abstract]: "We begin by utilizing an estimate of the class distribution from the participating training samples to correct the model, enabling it to learn the posterior probabilities of samples under a class-balanced prior."
  - [section]: "we need to estimate ptr(y). We use the class distribution of the participating training samples in the most recent T iterations as an estimate of ptr(y)"
  - [corpus]: Weak - no direct corpus evidence of this specific dynamic estimation approach
- Break condition: If class-conditional distributions differ between labeled and unlabeled data, the correction becomes suboptimal

### Mechanism 2
- Claim: Estimation of current model parameter class bias enables effective pseudo-label refinement
- Mechanism: The method estimates the model's class bias under current parameters dy(θt) by computing momentum-updated expectations over recent iterations, then applies this bias estimate to refine pseudo-labels
- Core assumption: The model's class bias can be reliably estimated through its outputs on training samples
- Evidence anchors:
  - [abstract]: "we further estimate the class bias of the current model parameters during the training process. We apply a secondary correction to the model's pseudo-labels for unlabeled samples"
  - [section]: "We introduce a method based on the model's output on samples to estimate the model's class bias under current parameters"
  - [corpus]: Missing - no corpus evidence supporting this specific momentum-based bias estimation approach
- Break condition: If model outputs become unreliable due to poor training dynamics or catastrophic forgetting

### Mechanism 3
- Claim: Two-stage correction process ensures equitable pseudo-label assignment across all classes
- Mechanism: First corrects model learning objectives, then uses refined model to generate improved pseudo-labels that reduce class bias in subsequent training
- Core assumption: Improving model's posterior probability estimation leads to better pseudo-label quality
- Evidence anchors:
  - [abstract]: "This correction serves to alleviate the inherent class bias of the model. Building upon this foundation, we further estimate the class bias of the current model parameters during the training process"
  - [section]: "To address these two challenges within imbalance SSL, we introduce a novel approach termed 'Twice Class Bias Correction' (TCBC)"
  - [corpus]: Weak - limited corpus evidence of this specific two-stage approach being validated
- Break condition: If pseudo-label quality degrades over time despite corrections, or if corrections interfere with each other

## Foundational Learning

- Concept: Semi-supervised learning with pseudo-labeling
  - Why needed here: TCBC builds upon standard SSL frameworks like FixMatch, extending them to handle class imbalance
  - Quick check question: How does FixMatch generate and use pseudo-labels for unlabeled data?

- Concept: Class imbalance and its effects on model training
  - Why needed here: The entire approach addresses how class imbalance introduces bias in both model learning and pseudo-label generation
  - Quick check question: What happens to model performance when training on imbalanced data without correction?

- Concept: Logit adjustment and class-balanced loss functions
  - Why needed here: TCBC uses logit adjustment based on estimated class distributions to learn balanced posteriors
  - Quick check question: How does logit adjustment modify the cross-entropy loss to account for class imbalance?

## Architecture Onboarding

- Component map: TCBC consists of two main correction components - model bias correction (estimates ptr(y) and applies logit adjustment) and pseudo-label refinement (estimates dy(θt) and refines pseudo-labels). These integrate with existing SSL frameworks like FixMatch.
- Critical path: 1) Estimate class distribution ptr(y) from recent training data, 2) Apply logit adjustment to model learning objectives, 3) Estimate current parameter bias dy(θt), 4) Refine pseudo-labels using bias estimate, 5) Train with corrected objectives and refined pseudo-labels
- Design tradeoffs: TCBC adds computational overhead from estimating distributions and biases, but this is offset by improved performance on imbalanced data. The momentum mechanism trades some bias estimation accuracy for stability.
- Failure signatures: If ptr(y) estimation is poor, model bias correction fails. If dy(θt) estimation is unstable, pseudo-label refinement degrades. If corrections interfere, training may diverge or performance may plateau.
- First 3 experiments:
  1. Replicate CIFAR-10-LT results with N1=500, M1=4000, γl=100, γu=1 to verify basic functionality
  2. Test TCBC with consistent vs inconsistent labeled/unlabeled distributions (γu=100 vs γu=1) to validate adaptation
  3. Perform ablation study removing either model bias correction or pseudo-label refinement to confirm both components are necessary

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- The momentum-based estimation of ptr(y) and dy(θt) introduces approximation errors that are not thoroughly characterized
- The assumption that labeled and unlabeled data share the same class-conditional distribution p(x|y) may not hold in real-world scenarios
- The evaluation focuses on controlled synthetic long-tailed datasets rather than naturally occurring imbalanced data, limiting generalizability

## Confidence

**High Confidence**: The mathematical formulation of logit adjustment and bias correction is sound. The experimental setup (dataset preparation, evaluation protocol) is clearly specified and reproducible.

**Medium Confidence**: The effectiveness of the two-stage correction process relies heavily on the stability of ptr(y) and dy(θt) estimates. While empirical results show improvement, the theoretical guarantees are limited.

**Low Confidence**: Claims about TCBC's ability to handle arbitrary unlabeled data distributions are not fully validated. The paper doesn't address potential negative interactions between the two correction stages.

## Next Checks

1. **Distribution Estimation Stability**: Track the L2 distance between estimated ptr(y) and true distribution across training epochs to verify convergence behavior and estimation quality.

2. **Component Ablation Study**: Remove either the model bias correction or pseudo-label refinement component to quantify their individual contributions and verify that both are necessary for performance gains.

3. **Domain Shift Sensitivity**: Evaluate TCBC performance when labeled and unlabeled data follow different class distributions (γl ≠ γu) to test robustness to distribution mismatch, particularly with extreme imbalance ratios (γl >> γu).