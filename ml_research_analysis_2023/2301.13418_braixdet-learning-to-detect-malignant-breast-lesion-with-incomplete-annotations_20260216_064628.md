---
ver: rpa2
title: 'BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations'
arxiv_id: '2301.13418'
source_url: https://arxiv.org/abs/2301.13418
tags:
- detection
- teacher
- learning
- training
- classi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of detecting malignant breast
  lesions in screening mammograms when training data contains incomplete annotations
  - a subset with full lesion localisation and classification, and another subset
  with only global image classification. The proposed BRAIxDet method uses a two-stage
  learning strategy: 1) pre-training a multi-view classifier on the weakly-annotated
  subset using global classification labels, and 2) extending this classifier to a
  detector using semi-supervised student-teacher learning that leverages both fully
  and weakly-annotated data.'
---

# BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations

## Quick Facts
- arXiv ID: 2301.13418
- Source URL: https://arxiv.org/abs/2301.13418
- Reference count: 13
- Primary result: State-of-the-art performance with mAP of 0.9294 and Recall@0.5 of 0.9531 on ADMANI dataset

## Executive Summary
BRAIxDet addresses the challenge of detecting malignant breast lesions in mammography when training data contains incomplete annotations - a common real-world scenario where some images have full lesion localization while others only have global classification labels. The method employs a two-stage learning strategy: first pre-training a multi-view classifier on weakly-annotated data to learn robust feature representations, then extending this classifier to a detector using semi-supervised student-teacher learning that leverages both fully and weakly-annotated data. Extensive experiments on two real-world datasets (ADMANI and CBIS-DDSM) demonstrate superior performance compared to state-of-the-art methods, achieving mAP of 0.9294 and Recall@0.5 of 0.9531 on ADMANI.

## Method Summary
BRAIxDet uses a two-stage learning approach to handle incomplete annotations in breast cancer screening mammograms. In stage 1, a multi-view classifier (BRAIxMVCCL) is pre-trained on the weakly-annotated subset using global classification labels, learning robust feature representations and producing Grad-CAM localization maps. In stage 2, this classifier is converted to a detector (BRAIxDet) using Faster R-CNN architecture, and trained using semi-supervised student-teacher learning. The student network is trained on both fully-labeled data and weakly-labeled data with pseudo-labels generated by combining teacher detections with Grad-CAM outputs. The teacher network is updated via exponential moving average of student parameters with frozen batch normalization statistics to ensure stable training and avoid confirmation bias.

## Key Results
- Achieved state-of-the-art performance with mAP of 0.9294 and Recall@0.5 of 0.9531 on ADMANI dataset
- Outperformed existing methods on both ADMANI and CBIS-DDSM datasets
- Successfully leveraged incomplete annotations to improve detection performance compared to using only fully-labeled data

## Why This Works (Mechanism)

### Mechanism 1: Two-Stage Training Strategy
- **Claim**: Pre-training on weak labels produces meaningful feature representations that transfer to detection task
- **Mechanism**: First stage trains classifier on weak labels to learn robust features and Grad-CAM maps, then uses these as initialization for detector
- **Core assumption**: Weak labels contain sufficient information to learn useful features for localization
- **Evidence anchors**: Pre-training on whole weakly-supervised training set where images have only global labels
- **Break condition**: If weak labels are too noisy or dataset too small, pre-training may not produce useful features

### Mechanism 2: Student-Teacher Semi-Supervised Learning
- **Claim**: EMA-based teacher updates with Grad-CAM combination mitigate confirmation bias
- **Mechanism**: Teacher generates pseudo-labels combined with Grad-CAM, student trains on both fully-labeled and pseudo-labeled data, teacher updated via EMA
- **Core assumption**: EMA provides stable pseudo-labels and Grad-CAM improves early training quality
- **Evidence anchors**: Pseudo-labels generated by combining teacher's detections with Grad-CAM outputs, teacher updated via exponential moving average
- **Break condition**: If EMA rate is too fast/slow or Grad-CAM and teacher predictions highly inconsistent

### Mechanism 3: Frozen Batch Normalization Statistics
- **Claim**: Freezing BN statistics after pre-training addresses parameter mismatch during EMA updates
- **Mechanism**: BN statistics computed during pre-training are frozen for both student and teacher during stage 2
- **Core assumption**: Pre-training BN statistics are representative enough to generalize to stage 2
- **Evidence anchors**: Batch normalization statistic frozen after pre-training to alleviate issues related to dependency on samples and parameter mismatch
- **Break condition**: If pre-training dataset not representative of stage 2 data, freezing BN may hurt performance

## Foundational Learning

- **Concept: Semi-supervised learning**
  - Why needed here: Dataset has incomplete annotations with large portion only having image-level labels
  - Quick check question: What are the two main strategies for semi-supervised learning, and which one is used in BRAIxDet?

- **Concept: Teacher-student learning with EMA**
  - Why needed here: Avoid confirmation bias where student overfits to incorrect pseudo-labels
  - Quick check question: How does EMA of student parameters help the teacher provide more stable pseudo-labels?

- **Concept: Grad-CAM for weak localization**
  - Why needed here: Grad-CAM provides coarse localization maps from classifier for pseudo-label generation
  - Quick check question: How does Grad-CAM generate localization maps from a classifier, and what are its limitations for precise localization?

## Architecture Onboarding

- **Component map**: Pre-training BRAIxMVCCL (classifier) -> Stage 2 BRAIxDet (detector based on Faster R-CNN) -> Student-teacher learning with EMA updates

- **Critical path**: 
  1. Pre-train BRAIxMVCCL on weak labels
  2. Generate Grad-CAM pseudo-labels for weakly annotated data
  3. Convert BRAIxMVCCL to BRAIxDet detector
  4. Train student BRAIxDet on fully labeled and pseudo-labeled data
  5. Update teacher via EMA of student parameters
  6. Freeze BN statistics after pre-training

- **Design tradeoffs**: Two-stage approach adds complexity but enables effective use of weak labels; combining teacher predictions with Grad-CAM improves pseudo-label quality but adds computational overhead; freezing BN simplifies EMA updates but may limit adaptability

- **Failure signatures**: Poor pre-training performance → inadequate feature representations; high confirmation bias → student overfits to incorrect pseudo-labels; mismatched BN statistics → unstable training or poor generalization; Grad-CAM outputs too coarse → inaccurate pseudo-labels

- **First 3 experiments**: 
  1. Train BRAIxMVCCL on weak labels only and evaluate classification performance
  2. Generate Grad-CAM pseudo-labels and visualize them
  3. Train BRAIxDet with student-teacher learning using only fully labeled data for baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does BRAIxDet perform on datasets with higher proportion of weakly annotated samples?
- Basis in paper: Paper tests on datasets with up to 50% weakly annotated samples
- Why unresolved: Only tested on datasets with up to 50% weakly annotated samples
- What evidence would resolve it: Testing on datasets with higher proportion of weakly annotated samples

### Open Question 2
- Question: How does BRAIxDet compare to state-of-the-art methods when trained on fully annotated datasets?
- Basis in paper: Paper compares to state-of-the-art methods only when trained on incomplete annotations
- Why unresolved: No comparison when trained on fully annotated datasets
- What evidence would resolve it: Comparing to state-of-the-art methods on fully annotated datasets

### Open Question 3
- Question: How does BRAIxDet perform on datasets with different types of lesions (calcifications, asymmetries)?
- Basis in paper: Paper focuses on masses but doesn't explore other lesion types
- Why unresolved: Method not tested on datasets with different lesion types
- What evidence would resolve it: Testing on datasets with different types of lesions

## Limitations

- Dependence on quality of weak labels and assumption that Grad-CAM provides meaningful localization hints
- Two-stage training approach adds complexity and computational overhead
- Effectiveness of freezing batch normalization statistics may be dataset-specific
- Lacks thorough exploration of sensitivity to EMA update rate and pseudo-label combination strategy

## Confidence

- **High confidence**: Overall methodology of two-stage approach with student-teacher learning is sound and well-justified
- **Medium confidence**: Specific design choices like freezing BN statistics and pseudo-label combination are reasonable but may not be optimal
- **Low confidence**: Generalizability to other medical imaging tasks or datasets with different annotation patterns is unclear

## Next Checks

1. Conduct ablation study to assess impact of freezing batch normalization statistics versus allowing them to update during student-teacher training
2. Evaluate sensitivity of detection performance to EMA update rate and relative weighting of teacher predictions versus Grad-CAM outputs in pseudo-label generation
3. Test method on a different medical imaging dataset with incomplete annotations (e.g., brain tumor detection in MRI) to assess generalizability