---
ver: rpa2
title: 'The Weisfeiler-Lehman Distance: Reinterpretation and Connection with GNNs'
arxiv_id: '2302.00713'
source_url: https://arxiv.org/abs/2302.00713
tags:
- distance
- then
- coupling
- theorem
- given
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a novel interpretation of the Weisfeiler-Lehman
  (WL) distance using concepts from stochastic processes, which offers a more intuitive
  understanding of the distance. The WL distance aims to compare graphs with node
  features, has the same discriminative power as the classic WL graph isomorphism
  test, and connects to the Gromov-Wasserstein distance.
---

# The Weisfeiler-Lehman Distance: Reinterpretation and Connection with GNNs

## Quick Facts
- **arXiv ID:** 2302.00713
- **Source URL:** https://arxiv.org/abs/2302.00713
- **Reference count:** 38
- **Primary result:** The WL distance is interpretable as a Wasserstein distance between path distributions via Markovian couplings, connecting it to stochastic processes and causal optimal transport theory.

## Executive Summary
This paper provides a novel interpretation of the Weisfeiler-Lehman (WL) distance using concepts from stochastic processes, making it more accessible and intuitive. The authors show that the WL distance can be understood as a Wasserstein distance between path distributions via Markovian couplings between measure Markov chains. This new perspective connects the WL distance to the literature on distances for stochastic processes and causal optimal transport. The paper also explores connections between the WL distance and Message Passing Neural Networks (MP-GNNs), establishing that MP-GNNs are Lipschitz continuous with respect to the WL distance and satisfy universal approximation properties.

## Method Summary
The paper reformulates the WL distance by interpreting measure Markov chains as stochastic processes and constructing Markovian couplings between their transition kernels. The WL distance of depth k is characterized as the Wasserstein distance between k-step path distributions of the coupled processes. The authors then explore connections to Causal Optimal Transport by restricting to finite time steps and bicausal couplings. For MP-GNNs, they show that these networks can be viewed as restrictions of Markov Channel Neural Networks to graph-induced measure Markov chains, establishing their Lipschitz continuity and universal approximation properties with respect to the WL distance.

## Key Results
- The WL distance of depth k is interpretable as a Wasserstein distance between path distributions via Markovian couplings
- The WL distance connects to Causal Optimal Transport theory through bicausal couplings
- MP-GNNs are Lipschitz continuous with respect to the WL distance and satisfy universal approximation properties

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The WL distance is interpretable as a Wasserstein distance between path distributions via Markovian couplings.
- **Mechanism:** By constructing Markovian couplings between two measure Markov chains, the WL distance of depth k becomes the Wasserstein distance between the distributions of the two random walks at step k, with cost defined by the distance between labels at that step.
- **Core assumption:** The Markovian coupling construction preserves the structure of both input Markov chains while allowing comparison of their k-step distributions.
- **Evidence anchors:**
  - [abstract] "This new interpretation connects the WL distance to the literature on distances for stochastic processes, which also makes the interpretation of the distance more accessible and intuitive."
  - [section] "In this way, we have interpreted the WL distance of depth k as a variant of the Wasserstein distance between the distributions of paths corresponding to the input Markov chains."
  - [corpus] Weak evidence - corpus papers focus on GNN expressiveness rather than the stochastic process interpretation of WL distance.
- **Break condition:** If the Markovian coupling construction fails to preserve the k-step distribution structure, the interpretation breaks down.

### Mechanism 2
- **Claim:** The WL distance connects to Causal Optimal Transport (COT) theory.
- **Mechanism:** Markovian couplings between path distributions naturally give rise to bicausal couplings when restricted to finite time steps, allowing the WL distance to be expressed as a COT problem.
- **Core assumption:** The Markovian coupling construction satisfies the causality conditions required for COT.
- **Evidence anchors:**
  - [abstract] "This new interpretation connects the WL distance to the literature on distances for stochastic processes... We further explore the connections between the WL distance and certain Message Passing Neural Networks."
  - [section] "This naturally leads to the following definition of Markovian couplings which helps to provide an intuitive characterization of the WL distance."
  - [corpus] Weak evidence - corpus papers discuss WL test connections to GNNs but not specifically COT connections.
- **Break condition:** If the coupling fails to satisfy causality conditions, the COT interpretation fails.

### Mechanism 3
- **Claim:** MP-GNNs are Lipschitz continuous with respect to the WL distance.
- **Mechanism:** Each layer of the MP-GNN involves Lipschitz-continuous operations (MLP mappings and message passing), and the composition of these operations preserves Lipschitz continuity, bounded by the product of individual Lipschitz constants and the WL distance.
- **Core assumption:** All component functions (MLPs, message aggregation) are Lipschitz continuous.
- **Evidence anchors:**
  - [abstract] "We further explore the connections between the WL distance and certain Message Passing Neural Networks, and discuss the implications of the WL distance for understanding the Lipschitz property and the universal approximation results for these networks."
  - [section] "Then, by Lemma B.7 again and the fact that ψ is C-Lipschitz, one has that |h((G1, ℓG1)) - h((G2, ℓG2))| ≤ C · Πk+1 i=1 Ci · d(k) G,q((G1, ℓG1), (G2, ℓG2))."
  - [corpus] Weak evidence - corpus papers discuss WL test and GNN expressiveness but not specifically Lipschitz properties.
- **Break condition:** If any component function fails to be Lipschitz continuous, the overall Lipschitz property breaks.

## Foundational Learning

- **Concept:** Measure Markov Chains and their relationship to labeled graphs
  - Why needed here: The WL distance operates on measure Markov chains, which generalize labeled graphs by incorporating probabilistic transitions and stationary distributions.
  - Quick check question: How does a labeled graph induce a measure Markov chain, and what role does the edge weight function play in this construction?

- **Concept:** Optimal Transport and Wasserstein distances
  - Why needed here: The WL distance is fundamentally a Wasserstein distance between probability measures, requiring understanding of couplings, pushforwards, and the Kantorovich formulation.
  - Quick check question: What is the relationship between couplings of probability measures and the Wasserstein distance, and how does this apply to comparing distributions of random walks?

- **Concept:** Stochastic processes and Markov properties
  - Why needed here: The WL distance interpretation relies on viewing the input as stochastic processes with Markov properties, requiring understanding of path spaces, random variables, and conditional probabilities.
  - Quick check question: How does the Markov property manifest in the path distribution of a measure Markov chain, and why is this crucial for the WL distance interpretation?

## Architecture Onboarding

- **Component map:**
  - Measure Markov Chain representation (X, m•, µ)
  - Label function ℓ: X → Z
  - k-step coupling construction
  - Path space representation (X^N or stochastic realizations)
  - Markovian coupling construction
  - COT formulation (optional)
  - MP-GNN architecture (for GNN connections)
  - Lipschitz analysis framework

- **Critical path:** For implementing WL distance computation:
  1. Parse input graphs into measure Markov chains
  2. Construct k-step couplings between transition kernels
  3. Compute optimal coupling using Wasserstein formulation
  4. (Optional) Implement COT-based algorithm for efficiency

- **Design tradeoffs:**
  - Exact vs. approximate WL distance computation (computational complexity)
  - Path space vs. stochastic realization representation (memory vs. flexibility)
  - COT vs. direct coupling approach (algorithmic efficiency vs. conceptual clarity)

- **Failure signatures:**
  - Non-convergence of coupling optimization (check cost function convexity)
  - Memory overflow in path space representation (consider stochastic realizations)
  - Numerical instability in Wasserstein computation (verify probability measure validity)

- **First 3 experiments:**
  1. Implement WL distance for simple 2-node graphs with known isomorphism status
  2. Compare exact vs. approximate coupling computation on small graphs
  3. Test Lipschitz property empirically by adding small perturbations to graph structure

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can we efficiently differentiate the Weisfeiler-Lehman (WL) distance to make it useful for graph generative models?
- **Basis in paper:** The paper explicitly states that differentiating a loss function depending on the WL distance will be an important future direction to explore.
- **Why unresolved:** The WL distance is a complex measure involving Wasserstein distances and optimal transport, which are generally difficult to differentiate efficiently.
- **What evidence would resolve it:** Developing a practical algorithm or method that allows for efficient differentiation of the WL distance, potentially through connections with existing OT algorithms or new approximations.

### Open Question 2
- **Question:** Can the WL distance be extended to compare LMMCs with different labeling spaces Z?
- **Basis in paper:** The paper mentions that connections to causal optimal transport (COT) may eventually result in extending the WL distance to cases when input LMMCs have different label spaces.
- **Why unresolved:** The current formulation of the WL distance assumes a common labeling space Z for the compared LMMCs, limiting its applicability.
- **What evidence would resolve it:** Developing a theoretical framework or practical method that allows the WL distance to handle LMMCs with different labeling spaces, potentially leveraging insights from COT theory.

### Open Question 3
- **Question:** What are the implications of the WL distance for understanding the generalization power of message passing graph neural networks (MP-GNNs)?
- **Basis in paper:** The paper suggests that the WL distance can serve as a suitable metric for the space of graphs to study questions such as the generalization power of MP-GNNs.
- **Why unresolved:** While the paper establishes connections between the WL distance and MP-GNNs, it does not explicitly investigate how the WL distance relates to the generalization capabilities of these networks.
- **What evidence would resolve it:** Conducting empirical studies or theoretical analyses that demonstrate how the WL distance can be used to characterize or bound the generalization error of MP-GNNs on graph classification tasks.

## Limitations

- The paper does not provide concrete algorithms for efficient computation of the WL distance via the new stochastic process interpretation
- The connection to Causal Optimal Transport is theoretical but lacks practical implementation details
- The universal approximation result for MP-GNNs lacks empirical validation on benchmark datasets

## Confidence

- **Stochastic process interpretation:** Medium - theoretically sound but requires experimental validation
- **Connection to Causal Optimal Transport:** Medium-Low - theoretical linkage exists but practical implementation unclear
- **Lipschitz property of MP-GNNs:** Medium - theoretically established but complex nested functions need verification

## Next Checks

1. Implement the WL distance using the stochastic process interpretation on small graphs and verify against known isomorphism cases
2. Benchmark the computational efficiency of the new interpretation against existing WL distance implementations
3. Experimentally verify the Lipschitz property by measuring output changes under controlled graph perturbations