---
ver: rpa2
title: Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop
  Reasoning
arxiv_id: '2310.13552'
source_url: https://arxiv.org/abs/2310.13552
tags:
- llms
- question
- reasoning
- sp-cot
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces open-domain multi-hop reasoning (ODMR) as
  an extension of open-domain question-answering (ODQA) that requires answering multi-hop
  questions with explicit reasoning steps. The authors propose Self-prompted Chain-of-Thought
  (SP-CoT), an automated framework that mass-produces high-quality chain-of-thoughts
  for LLMs by leveraging their instruction-following capabilities.
---

# Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning

## Quick Facts
- arXiv ID: 2310.13552
- Source URL: https://arxiv.org/abs/2310.13552
- Authors: 
- Reference count: 31
- Key outcome: SP-CoT achieves 14.5% EM and 22.6% F1 on MuSiQue-Ans, doubling zero-shot performance of small LLMs and surpassing previous automated CoT methods by 6.4% F1 on average

## Executive Summary
This paper introduces Self-prompted Chain-of-Thought (SP-CoT), an automated framework that mass-produces high-quality chain-of-thoughts for large language models (LLMs) to improve open-domain multi-hop reasoning (ODMR). SP-CoT addresses the limitation of previous CoT methods that require manual effort or struggle with ODMR tasks by automatically generating intermediate reasoning steps with explanations. The framework introduces an automated generation pipeline for ODMR datasets, an adaptive sampler for in-context CoT selection, and self-prompted inference via in-context learning. Extensive experiments on four multi-hop QA benchmarks demonstrate that SP-CoT significantly outperforms previous state-of-the-art methods on large-scale (175B) LLMs and nearly doubles the zero-shot performance of small-scale (13B) LLMs.

## Method Summary
SP-CoT is an automated framework that generates high-quality chain-of-thought reasoning chains for open-domain multi-hop reasoning tasks. The method operates in three stages: (1) automated generation of 2-hop QA quadruplets with explanations using instruction-following LLMs, (2) composition of multi-hop reasoning chains by connecting 2-hop pairs following six reasoning graph types while ensuring composability criteria and duplication control, and (3) adaptive sampling of diverse in-context demonstrations through clustering-based retrieval combined with self-prompted inference during few-shot learning. The framework leverages LLMs' instruction-following capabilities to generate reliable explanations containing correct intermediate answers, uses Sentence-BERT embeddings with k-means clustering to ensure diverse and relevant demonstrations, and composes reasoning chains from 2-hop QA pairs using strict criteria that prevent shortcuts while ensuring valid reasoning paths.

## Key Results
- SP-CoT achieves 14.5% exact match and 22.6% F1 on MuSiQue-Ans, nearly doubling zero-shot performance of small-scale (13B) LLMs
- The method significantly outperforms previous state-of-the-art methods on large-scale (175B) LLMs across all four benchmarks
- SP-CoT surpasses previous automated CoT methods by 6.4% F1 on average while achieving around 50% recall of intermediate answers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SP-CoT leverages LLMs' instruction-following capability to generate high-quality intermediate reasoning steps that improve multi-hop reasoning performance.
- Mechanism: The method uses self-prompting to break down complex questions into step-by-step reasoning chains, where each step includes a question, answer, and explanation. These reasoning chains are constructed from 2-hop QA pairs that are composable according to strict criteria ensuring no shortcuts exist.
- Core assumption: LLMs can generate reliable explanations for each reasoning step when prompted with appropriate instructions, and these explanations will contain the correct intermediate answers needed for subsequent reasoning steps.
- Evidence anchors: Abstract mentions automated generation pipeline of high quality ODMR datasets; section discusses ensuring second-hop question contains first-hop answer for connected reasoning.

### Mechanism 2
- Claim: Clustering-based retrieval with adaptive sampling improves the diversity and relevance of in-context demonstrations for few-shot learning.
- Mechanism: Questions are embedded using Sentence-BERT and clustered with k-means. For each cluster, the question most similar to the test question is retrieved, ensuring demonstrations are both diverse (from different clusters) and relevant (high similarity within cluster).
- Core assumption: Questions with similar semantic embeddings belong to similar reasoning types, and having one demonstration per reasoning type cluster provides optimal diversity for few-shot learning.
- Evidence anchors: Section describes using k-means to cluster question embeddings into n clusters and adaptively retrieve questions with highest cosine similarity to the test question.

### Mechanism 3
- Claim: Composing multi-hop questions from 2-hop QA pairs with composability criteria ensures high-quality reasoning chains without shortcuts.
- Mechanism: Two single-hop QA pairs (q1, a1) and (q2, a2) are composable if a1 is a named entity mentioned in q2. This ensures the answer to one question appears in the next question, creating a valid reasoning chain. The method uses 6 reasoning graphs with 2-4 hops to build different reasoning types.
- Core assumption: The composability criteria (answer from previous hop must be named entity and mentioned in next hop) guarantees valid reasoning chains without allowing shortcuts that would bypass intermediate reasoning steps.
- Evidence anchors: Section ensures that in each reasoning chain the answer to an intermediate question will appear and ONLY appear in its next-hop question to avoid shortcuts.

## Foundational Learning

- Concept: Chain-of-Thought (CoT) prompting
  - Why needed here: The entire method relies on generating and using CoT reasoning chains to improve multi-hop reasoning performance on LLMs.
  - Quick check question: What are the key differences between zero-shot-CoT, manual-CoT, and automated CoT approaches?

- Concept: In-context learning (ICL)
  - Why needed here: SP-CoT uses ICL by providing demonstrations as in-context examples to guide the LLM's reasoning during inference.
  - Quick check question: How does ICL differ from fine-tuning, and what are the advantages and limitations of using ICL for multi-hop reasoning?

- Concept: Compositional reasoning
  - Why needed here: The method composes multi-hop questions from 2-hop QA pairs using specific criteria to ensure valid reasoning chains without shortcuts.
  - Quick check question: What makes a composition of two single-hop QA pairs valid for multi-hop reasoning, and how can invalid compositions be identified?

## Architecture Onboarding

- Component map: Dataset generation pipeline -> Composition engine -> Clustering sampler -> Inference engine -> Quality control
- Critical path: 1) Generate 2-hop QA pairs with explanations (Stage 1) -> 2) Compose multi-hop reasoning chains (Stage 2) -> 3) Cluster and sample demonstrations (Stage 3) -> 4) Apply demonstrations during inference
- Design tradeoffs: Quality vs. scale (more generated data increases scale but may decrease quality); Diversity vs. relevance (more clusters increases diversity but may reduce demonstration relevance); Complexity vs. performance (more complex reasoning chains may improve performance but increase failure risk)
- Failure signatures: Low intermediate answer recall indicates poor explanation quality or incorrect intermediate answers; High duplicate reasoning chains suggests insufficient duplication control; Poor clustering performance indicates embeddings don't capture relevant semantic features
- First 3 experiments: 1) Test dataset generation quality by manually inspecting 100 generated 2-hop QA pairs; 2) Validate clustering effectiveness by checking if similar questions are grouped together; 3) Measure intermediate answer recall on a small subset to assess reasoning chain quality

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several important questions emerge from the research:

1. What is the impact of dataset size and composition strategy on the performance of SP-CoT across different LLMs?
2. How does SP-CoT perform on more complex multi-hop reasoning tasks beyond 4 hops?
3. How does the quality of self-generated explanations affect downstream performance, and can this quality be improved?

## Limitations

- Quality of Generated Reasoning Chains: While reporting 50% intermediate answer recall, this means half of intermediate reasoning steps may contain incorrect information, and quality thresholds for filtering chains are not fully specified.
- Scalability to More Complex Reasoning: The method is tested only on 2-4 hop reasoning graphs, leaving uncertainty about performance on longer reasoning chains.
- Dependence on Instruction-Following LLMs: Performance gains on smaller models (13B) are modest compared to large models (175B), suggesting the method may not be equally effective across all model scales.

## Confidence

- High Confidence: The general framework design and methodology are well-articulated with clear implementation details
- Medium Confidence: Reported performance improvements are significant but evaluation is limited to four specific benchmarks
- Low Confidence: Quality thresholds for filtering reasoning chains and exact prompt templates are not fully specified, making exact reproduction challenging

## Next Checks

1. Conduct detailed manual evaluation of 100 randomly selected intermediate answers to assess actual quality of generated reasoning chains beyond reported 50% recall metric.
2. Apply SP-CoT to a new, unseen multi-hop reasoning dataset to evaluate performance beyond the four benchmarks used and assess generalizability.
3. Systematically relax or modify the composability criteria to understand their impact on reasoning chain quality and identify potential trade-offs between strict criteria and generation flexibility.