---
ver: rpa2
title: Representation Learning Dynamics of Self-Supervised Models
arxiv_id: '2309.02011'
source_url: https://arxiv.org/abs/2309.02011
tags:
- learning
- dynamics
- neural
- linear
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes the learning dynamics of self-supervised learning
  (SSL) models under contrastive and non-contrastive losses. It shows that a naive
  extension of multivariate regression dynamics to SSL leads to dimension collapse,
  where the learned representations become trivial scalars.
---

# Representation Learning Dynamics of Self-Supervised Models

## Quick Facts
- arXiv ID: 2309.02011
- Source URL: https://arxiv.org/abs/2309.02011
- Reference count: 40
- Key outcome: This paper analyzes SSL learning dynamics under contrastive and non-contrastive losses, showing that orthogonality constraints prevent dimension collapse and deriving exact dynamics on the Grassmannian manifold.

## Executive Summary
This paper addresses a fundamental problem in self-supervised learning: dimension collapse, where learned representations become trivial scalars. The authors show that naive extensions of multivariate regression dynamics to SSL lead to this collapse. To solve this, they introduce orthogonality constraints on weight matrices and derive exact learning dynamics using gradient descent on the Grassmannian manifold. Their theoretical framework bridges the gap between supervised learning theory and SSL, providing new insights into how SSL models learn meaningful representations.

## Method Summary
The authors formulate SSL objectives with orthogonality constraints on weight matrices (W₁W₁ᵀ = I and W₂W₂ᵀ = I) and derive exact learning dynamics using gradient descent on the Grassmannian manifold. They show that naive SSL losses lead to dimension collapse, while orthogonality constraints maintain full-dimensional representations. The theoretical analysis is validated through numerical experiments on MNIST, comparing the derived differential equations with standard SGD training.

## Key Results
- Dimension collapse occurs in naive SSL models, causing representations to become trivial scalars
- Orthogonality constraints on weight matrices prevent dimension collapse and maintain full-dimensional representations
- The learning dynamics under orthogonality constraints can be expressed as differential equations on the Grassmannian manifold
- Numerical experiments on MNIST validate the theoretical predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adding orthogonality constraints to weight matrices in SSL models prevents dimension collapse during training.
- Mechanism: Orthogonality constraints ensure learned representations remain in full-dimensional subspaces, avoiding trivial scalar collapse.
- Core assumption: SSL loss alone doesn't provide sufficient signal to maintain dimensional diversity.
- Evidence anchors: [abstract] shows formulation with orthogonality constraints and exact dynamics derivation.
- Break condition: If orthogonality constraints aren't properly enforced during optimization.

### Mechanism 2
- Claim: Learning dynamics of SSL models under orthogonality constraints can be accurately approximated by linear dynamics.
- Mechanism: For wide networks with smooth activation functions, the difference between nonlinear and linear outputs becomes negligible.
- Core assumption: Network is sufficiently wide and activation function satisfies smoothness conditions.
- Evidence anchors: [abstract] shows deviation from NTK approximations; theorem demonstrates linear approximation at initialization.
- Break condition: If network isn't wide enough or activation function lacks smoothness.

### Mechanism 3
- Claim: Learning dynamics under orthogonality constraints can be expressed as differential equations on the Grassmannian manifold.
- Mechanism: Orthogonality constraints transform optimization into finding optimal subspace, enabling differential geometry analysis.
- Core assumption: Orthogonality constraints are strictly enforced during optimization.
- Evidence anchors: [abstract] derives exact dynamics on Grassmannian manifold; theorem provides differential equation formulation.
- Break condition: If orthogonality constraints aren't strictly enforced or optimization doesn't respect manifold structure.

## Foundational Learning

- **Gradient flow and its relationship to gradient descent**: Why needed - paper derives learning dynamics under gradient flow, continuous-time limit of gradient descent. Quick check - what's the main difference between gradient flow and gradient descent?

- **Neural Tangent Kernel (NTK) and its role in analyzing wide neural networks**: Why needed - paper compares infinite-width SSL approximations to NTK approximations of supervised models. Quick check - how does NTK approximation simplify analysis of wide networks?

- **Orthogonality constraints and their implementation in optimization**: Why needed - paper introduces orthogonality constraints to prevent dimension collapse. Quick check - what are main approaches for enforcing orthogonality constraints in neural network optimization?

## Architecture Onboarding

- **Component map**: Input data (x, x+) -> 2-layer neural network (W₁, W₂) with orthogonality constraints -> Loss function Tr(W₂ᵀW₁CW₁ᵀW₂) -> Optimization on Grassmannian manifold

- **Critical path**: 
  1. Initialize W₁ and W₂ as random orthogonal matrices
  2. Compute data-dependent matrix C from input data
  3. Perform gradient descent updates maintaining orthogonality constraints
  4. Monitor learning dynamics and convergence

- **Design tradeoffs**:
  - Width of hidden layer: Wider networks better approximate linear dynamics but increase computational cost
  - Choice of activation function: Some functions (e.g., tanh) may lead to better linear approximations than others (e.g., ReLU)
  - Enforcement of orthogonality constraints: Strict enforcement may slow optimization but prevents dimension collapse

- **Failure signatures**:
  - Dimension collapse: Representations become scalar, indicating improper orthogonality constraint enforcement
  - Divergence: Loss increases during training, suggesting optimization issues
  - Slow convergence: Learning dynamics approach fixed points very slowly

- **First 3 experiments**:
  1. Verify linear approximation: Train wide SSL network with orthogonality constraints and compare outputs to linear network
  2. Test different activation functions: Train SSL networks with different activations and compare convergence behavior
  3. Validate Grassmannian dynamics: Implement differential equation from Theorem 2 and compare predictions to actual training dynamics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we integrate orthogonality or operator norm constraints into the NTK regime for SSL models?
- Basis in paper: Authors mention this as open problem in conclusion
- Why unresolved: NTK assumes infinite width networks, but adding constraints like orthogonality isn't straightforward in this setting
- What evidence would resolve it: Theoretical framework incorporating constraints into NTK analysis with empirical validation

### Open Question 2
- Question: How do non-linear SSL models with orthogonal constraints behave during training compared to linear counterparts?
- Basis in paper: Authors conjecture same behavior holds during evolution but only prove for initialization
- Why unresolved: Only provide numerical evidence during training, not formal proof
- What evidence would resolve it: Rigorous mathematical proof showing non-linear models remain close to linear counterparts throughout training

### Open Question 3
- Question: Can we develop more precise characterizations of learning dynamics for SSL models beyond linear approximation?
- Basis in paper: Authors suggest more precise characterization in terms of kernel approximation may be possible
- Why unresolved: Analysis based on linear approximations that may not capture all nuances of deep SSL models
- What evidence would resolve it: Theoretical framework beyond linear approximations with empirical validation on deep SSL models

## Limitations

- Theoretical framework relies heavily on strict orthogonality constraint enforcement, which is challenging in practice
- Analysis is limited to linear networks and may not fully capture nonlinear network complexities
- Derived learning dynamics on Grassmannian manifold lack extensive validation beyond simple datasets like MNIST

## Confidence

- High confidence: Dimension collapse phenomenon and need for orthogonality constraints
- Medium confidence: Exact learning dynamics on Grassmannian manifold and practical relevance
- Low confidence: Comparison between infinite-width SSL approximations and NTK approximations

## Next Checks

1. Test orthogonality constraint approach on larger-scale SSL benchmarks (ImageNet, CIFAR-100) to assess scalability
2. Implement and compare different methods for enforcing orthogonality constraints to identify most effective approach
3. Extend theoretical analysis to include nonlinear activation functions and assess validity of linear approximation in complex settings