---
ver: rpa2
title: Robust Distortion-free Watermarks for Language Models
arxiv_id: '2307.15593'
source_url: https://arxiv.org/abs/2307.15593
tags:
- language
- watermarking
- text
- watermark
- watermarks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first distortion-free and robust watermarking
  strategy for text generated from language models. The key idea is to map a sequence
  of random numbers (encoded in a watermark key) to a sample from the language model
  using inverse transform sampling or exponential minimum sampling.
---

# Robust Distortion-free Watermarks for Language Models

## Quick Facts
- arXiv ID: 2307.15593
- Source URL: https://arxiv.org/abs/2307.15593
- Authors: Albert Gu, Jean-Stanislas Denain, Karan Goel, Christopher Ré
- Reference count: 40
- Key outcome: First distortion-free and robust watermarking strategy for language model text, with statistical power (p ≤ 0.01) for text as short as 35 tokens

## Executive Summary
This paper presents the first distortion-free watermarking strategy for language models that remains detectable even after substantial corruption (40-50% of tokens substituted, inserted, or deleted). The key innovation is mapping a sequence of random numbers encoded in a watermark key to language model samples using inverse transform sampling or exponential minimum sampling. Unlike prior approaches that require modifying token probabilities, this method preserves the original text distribution while creating correlation patterns that enable robust detection through alignment-based statistical tests.

## Method Summary
The method uses two main components: a watermark generator that maps uniform random numbers through the language model's CDF (using either inverse transform sampling or exponential minimum sampling), and a detector that aligns text with watermark key subsequences to compute an alignment cost. The generate() function creates watermarked text by sampling from the language model conditioned on the watermark key sequence, while detect() computes a p-value by finding the minimum alignment cost between text blocks and key subsequences. The system includes a shift-generate() wrapper to avoid key reuse across queries.

## Key Results
- Statistical power (p ≤ 0.01) for text as short as 35 tokens on OPT-1.3B and LLaMA-7B
- Robust detection even after 40-50% token corruption through substitution, insertion, or deletion
- For Alpaca-7B instruction-following model, only ~25% of responses are detectable due to lower entropy
- ITS watermark generation takes 15.4% longer than baseline but maintains distortion-free property

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Inverse transform sampling creates distortion-free watermarks by mapping uniform random numbers through permuted CDF
- Mechanism: The decoder Γ maps (u, π) to token y by finding smallest π(i) such that CDF(μ) ≥ u, ensuring P(Γ(ξ,μ)=y) = μ(y)
- Core assumption: Permutation π can be arbitrary and watermark key elements are i.i.d. uniform
- Evidence anchors:
  - [abstract] "generate watermarked text by mapping a sequence of random numbers—which we compute using a randomized watermark key—to a sample from the language model"
  - [section 2.3] "Theorem 1. Define Γ by equation (1). Let π ∈ Π be arbitrary and let U ∼ Unif([0, 1]), with ξ := (U, π). Then Γ is distortion-free with respect to ξ"
- Break condition: If permutation π is not truly random or watermark key elements not i.i.d. uniform

### Mechanism 2
- Claim: Alignment cost based on covariance between uniform random numbers and permuted token indices enables robust detection
- Mechanism: Test statistic computes minimum alignment cost between text blocks and watermark key subsequences, leveraging correlation between {η(πi(Yi))} and U
- Core assumption: Permuted token indices and uniform random numbers are correlated for watermarked text but not for non-watermarked text
- Evidence anchors:
  - [abstract] "To detect watermarked text, any party who knows the key can align the text to the random number sequence"
  - [section 2.3] "Thus, for the sake of analysis, we define alignment cost d : (V × Ξ)∗ → R by d(y, (u, π)) := − Σ (ui − 1/2) · (η(πi(yi)) − 1/2)"
- Break condition: If user edits enough tokens to destroy correlation pattern, or block size k too small relative to corruption level

### Mechanism 3
- Claim: Exponential minimum sampling provides alternative distortion-free watermarking strategy
- Mechanism: Decoder Γ(ξ,μ) = arg min{-log(ξi)/μ(i)} over vocabulary, mapping uniform random numbers to tokens via exponential minimum sampling
- Core assumption: Exponential minimum sampling preserves original distribution while creating watermark correlation
- Evidence anchors:
  - [abstract] "We instantiate our watermark methodology with two sampling schemes: inverse transform sampling and exponential minimum sampling"
  - [section 2.4] "Theorem 2. Define the decoder Γ by equation (4) and let ξ ∼ Unif([0, 1]N). Then Γ is distortion-free with respect to ξ"
- Break condition: If language model's token probabilities are deterministic (zero entropy)

## Foundational Learning

- Concept: Inverse transform sampling
  - Why needed here: Core technique for creating distortion-free watermarks by mapping uniform random numbers through CDF
  - Quick check question: Why does inverse transform sampling preserve original distribution when using arbitrary permutation?

- Concept: Sequence alignment and Levenshtein distance
  - Why needed here: Robust detection requires aligning watermarked text with watermark key subsequences even after corruption
  - Quick check question: How does incorporating Levenshtein distance into alignment cost improve robustness to insertions and deletions?

- Concept: Exponential minimum sampling
  - Why needed here: Provides alternative distortion-free watermarking strategy to inverse transform sampling
  - Quick check question: What property of exponential minimum sampling ensures it preserves original distribution while creating watermark correlation?

## Architecture Onboarding

- Component map: shift-generate() -> generate() -> language model -> detect() -> alignment cost computation -> p-value calculation

- Critical path:
  1. User sends prompt to LM provider
  2. LM provider calls shift-generate() with watermark key sequence
  3. User publishes edited watermarked text
  4. Detector calls detect() with published text and watermark key
  5. Detector returns p-value indicating watermark presence

- Design tradeoffs:
  - Block size k vs. detection power: Larger k improves detection but increases computational cost
  - Watermark key length n vs. total watermarked tokens: Larger n allows more watermarked tokens but increases detection overhead
  - Alignment cost function complexity vs. runtime: More sophisticated costs improve robustness but slow detection

- Failure signatures:
  - Low watermark potential in language model → weak detection regardless of watermark strength
  - Key reuse across queries → reduced statistical power due to correlation between texts
  - Excessive corruption (>50% tokens) → alignment fails to find correct match

- First 3 experiments:
  1. Test ITS watermark on OPT-1.3B with varying text lengths (m=35, 70, 100) and fixed key length (n=256)
  2. Evaluate EXP watermark robustness to substitution attacks with 10%, 30%, 50% token replacement
  3. Compare KGW-2.0 vs EXP-edit on Alpaca-7B instruction-following responses with varying prompt types

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the statistical power of watermarking strategies vary with the length of the watermark key sequence for different language model architectures?
- Basis in paper: [explicit] The paper discusses how statistical power improves exponentially with text length and diminishes only linearly with watermark key length
- Why unresolved: While providing experimental results for specific models, the paper doesn't explore a wide range of language model architectures to determine if the relationship between watermark key length and statistical power is consistent across different architectures
- What evidence would resolve it: Conducting experiments with diverse language model architectures and varying watermark key sequence lengths would provide insights into generalizability

### Open Question 2
- Question: What is the impact of watermark potential on the effectiveness of watermarking strategies for different types of text (e.g., technical, creative, or conversational)?
- Basis in paper: [explicit] The paper introduces watermark potential and shows that the degree to which detector can reliably distinguish watermarked from unwatermarked text depends on the watermark potential of the LM provider's language model
- Why unresolved: The paper focuses on watermark potential for language models but doesn't investigate how this applies to different types of text which may have varying levels of entropy and predictability
- What evidence would resolve it: Analyzing watermark potential for different types of text and comparing watermarking strategy effectiveness across these types would provide insights into generalizability

### Open Question 3
- Question: How do advanced paraphrasing techniques (e.g., semantic-preserving transformations, style transfer) affect the robustness of watermarking strategies compared to basic paraphrasing attacks evaluated in the paper?
- Basis in paper: [inferred] The paper evaluates robustness against basic paraphrasing attacks (substitutions, insertions, deletions, roundtrip translations) but doesn't explore more advanced paraphrasing techniques that aim to preserve semantic meaning while altering surface form
- Why unresolved: The paper's evaluation provides baseline understanding but doesn't account for potential effectiveness of more sophisticated paraphrasing techniques that may be employed by adversaries
- What evidence would resolve it: Developing and testing advanced paraphrasing techniques that preserve semantic meaning while altering surface form, and evaluating their impact on watermark strategy robustness, would provide insights into limitations of current approaches

## Limitations

- Trade-off between watermark robustness and detectability in low-entropy text, particularly for instruction-following models like Alpaca-7B where only ~25% of responses are detectable
- Experimental evaluation focuses primarily on synthetic corruption scenarios rather than comprehensive real-world watermark attacks
- Computational overhead not thoroughly analyzed - while generation takes 15.4% longer, detection algorithm complexity is unclear

## Confidence

**High Confidence Claims:**
- Distortion-free property of both inverse transform sampling and exponential minimum sampling decoders is mathematically proven
- Statistical power of watermark for base language models (OPT-1.3B, LLaMA-7B) is empirically validated with p ≤ 0.01 for text as short as 35 tokens
- Robustness to token-level corruption up to 50% is experimentally demonstrated

**Medium Confidence Claims:**
- Effectiveness of incorporating Levenshtein distance into alignment cost for improving robustness to insertions and deletions
- Relative performance comparison between different watermark strategies (ITS vs EXP, with and without edit capabilities)
- Claim that watermark remains effective after paraphrasing attacks based on round-trip translation experiments

**Low Confidence Claims:**
- Generalizability of watermark effectiveness to other instruction-following models beyond Alpaca-7B
- Scalability of detection algorithm for very long texts or high-throughput scenarios
- Robustness against sophisticated watermark removal techniques not tested in the paper

## Next Checks

1. **Evaluate watermark effectiveness across diverse instruction-following models**: Replicate Experiment 1 using a broader range of instruction-tuned models (e.g., Vicuna, Dolly, Alpaca with different instruction sets) to assess how model architecture and training data affect watermark detectability.

2. **Benchmark detection computational complexity**: Implement the detect() algorithm and measure its runtime complexity as a function of text length (m), watermark key length (n), and block size (k). Compare this against the claimed 15.4% generation overhead.

3. **Test against adversarial watermark removal techniques**: Design and implement more sophisticated watermark removal attacks beyond substitution, insertion, deletion, and paraphrasing scenarios tested, such as adversarial prompting, fine-tuning on watermarked text, or post-hoc text editing algorithms specifically designed to break the alignment cost structure.