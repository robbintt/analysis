---
ver: rpa2
title: 'MarioGPT: Open-Ended Text2Level Generation through Large Language Models'
arxiv_id: '2302.05981'
source_url: https://arxiv.org/abs/2302.05981
tags:
- levels
- mariogpt
- level
- generation
- diverse
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MarioGPT is a fine-tuned GPT2 model for controllable generation
  of Super Mario Bros levels based on natural language prompts. The model tokenizes
  levels as strings and uses a frozen BART encoder to incorporate text prompts into
  its cross-attention layers.
---

# MarioGPT: Open-Ended Text2Level Generation through Large Language Models

## Quick Facts
- arXiv ID: 2302.05981
- Source URL: https://arxiv.org/abs/2302.05981
- Authors: 
- Reference count: 40
- Key outcome: GPT2-based model for controllable Super Mario Bros level generation using natural language prompts with 93% tile accuracy and 88% playability rate

## Executive Summary
MarioGPT is a fine-tuned GPT2 model that generates controllable Super Mario Bros levels from natural language prompts. The system uses a frozen BART encoder to incorporate prompt information into cross-attention layers during generation, enabling text-to-level synthesis. Combined with novelty search, it achieves open-ended generation of diverse levels with varying play-style dynamics while maintaining high playability rates (88% of generated levels are playable).

## Method Summary
The method involves fine-tuning DistilGPT2 on tokenized Super Mario Bros level data from the Video Game Level Corpus (VGLC). Prompts are processed through a frozen BART encoder and incorporated into the model's cross-attention layers during generation. The system uses Byte-Pair Encoding for tokenization and generates levels as text strings. For open-ended generation, novelty search is employed where behavioral characteristics based on normalized average path coordinates guide diversity exploration. Generated levels are evaluated for playability using an A* agent, with the model simultaneously predicting feasible agent paths.

## Key Results
- Achieved 93% tile prediction accuracy on validation data
- 88% of generated levels were found to be playable by A* agent
- Model-predicted paths closely matched actual agent paths (MAE of 1.14 tiles for playable levels)
- Successfully generated levels matching prompts 81-92% of the time depending on prompt component
- Can generate levels from prompts not present in training data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MarioGPT's path prediction ability reduces the need for expensive external agent evaluations during level generation.
- Mechanism: The model generates levels and simultaneously predicts a feasible agent path through them using its trained sequence modeling capabilities.
- Core assumption: The model's predicted paths accurately approximate actual agent behavior in playable levels.
- Evidence anchors:
  - [abstract]: "88% of generated levels were found to be playable, with model-predicted paths closely matching actual agent paths (MAE of 1.14 tiles for playable levels)"
  - [section]: "we can conclude that in the majority of the cases, the path generated by the model is similar to the path taken by an actual agent"
- Break condition: If the MAE between predicted and actual paths increases significantly beyond 1.14 tiles for playable levels, or if the proportion of playable levels drops below acceptable thresholds.

### Mechanism 2
- Claim: The combination of fine-tuned GPT2 with frozen BART encoder enables controllable level generation through natural language prompts.
- Mechanism: The frozen BART encoder processes text prompts into averaged hidden states, which are then used in the cross-attention layers of the GPT2 architecture alongside the level sequence being generated.
- Core assumption: The averaged BART hidden states effectively encode prompt semantics that influence the generation process.
- Evidence anchors:
  - [abstract]: "MarioGPT is a fine-tuned GPT2 model for controllable generation of Super Mario Bros levels based on natural language prompts"
  - [section]: "To incorporate prompt information, we fine-tune the attention layers' cross attention weights... Prompts are passed through the frozen language model and the hidden states from the forward pass are averaged into a single vector"
- Break condition: If prompt-conditioned generations show no significant improvement over unconditioned generation in matching prompt specifications.

### Mechanism 3
- Claim: Novelty search with MarioGPT as mutation operator enables open-ended generation of diverse levels with varying play-style dynamics.
- Mechanism: The system iteratively samples elite levels, mutates them using MarioGPT with random prompts, and selects novel levels based on behavioral characteristics (normalized average path coordinates).
- Core assumption: Path diversity in generated levels correlates with overall level diversity and novelty.
- Evidence anchors:
  - [abstract]: "Combined with novelty search, it enables open-ended generation of diverse levels with varying play-style dynamics"
  - [section]: "we use predicted player paths as our basis for these behavior characteristics... we represent the behavior characteristic as the normalized average of the predicted path's coordinates"
- Break condition: If the behavioral characteristic space becomes saturated with overlapping patterns, or if novelty search fails to discover new regions of the space over time.

## Foundational Learning

- Concept: Sequence modeling with transformers
  - Why needed here: MarioGPT uses GPT2 architecture to predict next tokens in level sequences, requiring understanding of how transformers handle long-range dependencies
  - Quick check question: What is the key architectural difference between transformers and RNNs that makes transformers more suitable for level generation?

- Concept: Behavioral characteristics for novelty search
  - Why needed here: The system uses normalized average path coordinates as behavioral characteristics to measure diversity between generated levels
  - Quick check question: How does normalizing path coordinates help ensure that different elevation paths are considered similar in behavior space?

- Concept: Cross-attention mechanisms
  - Why needed here: MarioGPT incorporates prompt information through cross-attention layers that combine BART-encoded prompt representations with level generation
  - Quick check question: What is the role of the cross-attention mechanism in combining prompt information with level generation?

## Architecture Onboarding

- Component map: Prompt → BART encoding → GPT2 generation → path prediction → novelty evaluation
- Critical path: Prompt → BART encoding → GPT2 generation → path prediction → novelty evaluation
- Design tradeoffs:
  - Using frozen BART encoder limits prompt adaptation but speeds up training
  - Path prediction via model vs external agent evaluation trades accuracy for computational efficiency
  - Unidirectional generation requires border inpainting for consistency
- Failure signatures:
  - High MAE between predicted and actual paths (>2 tiles) indicates path prediction issues
  - Low tile prediction accuracy (<90%) suggests generation quality problems
  - Novelty search archive saturation indicates exploration limitations
- First 3 experiments:
  1. Test tile prediction accuracy on validation set to establish baseline performance
  2. Generate levels with varied prompts and measure prompt adherence accuracy
  3. Run novelty search for 100 iterations and visualize behavioral characteristic space coverage

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can MarioGPT's path generation be improved to better match actual agent physics rather than solver-based paths?
- Basis in paper: [explicit] The paper notes that MarioGPT's generated paths tend to have more airtime than actual agents due to training on solver-based paths rather than agent trajectories, and suggests annotating training data with actual agent trajectories as a potential solution.
- Why unresolved: The current training data uses solver-based paths, leading to discrepancies between generated and actual agent paths.
- What evidence would resolve it: Experiments comparing MarioGPT performance when trained on agent-trajectory data versus solver-based data, measuring path accuracy and playability rates.

### Open Question 2
- Question: What are the most effective methods for balancing diversity and quality in MarioGPT's level generation?
- Basis in paper: [inferred] The paper discusses challenges with temperature scaling - higher temperatures increase diversity but reduce quality, and mentions potential improvements like constrained beam search and dataset augmented search.
- Why unresolved: Current methods show a clear trade-off between diversity and quality that needs optimization.
- What evidence would resolve it: Comparative studies of different search methods (temperature scaling, constrained beam search, dataset augmented search) measuring both diversity metrics and quality assessments.

### Open Question 3
- Question: How can prompt importance be effectively incorporated into MarioGPT to improve controllability?
- Basis in paper: [explicit] The paper mentions exploring more ways to incorporate prompt importance, such as editing levels with tiles to create more samples or prompt tuning, but these remain unexplored.
- Why unresolved: Current prompting system works well but could be improved for better control over specific features.
- What evidence would resolve it: Experiments testing different prompt tuning methods and their impact on generation accuracy for specific level features.

## Limitations
- Path prediction accuracy (MAE of 1.14 tiles) may degrade with more complex level designs
- Evaluation relies on Super Mario Bros levels from VGLC, limiting generalizability to other games
- Novelty search implementation lacks specific algorithmic details affecting reproducibility
- Behavioral characteristic space based on normalized path coordinates may not capture all relevant aspects of level diversity

## Confidence

- **High confidence**: The core architecture combining GPT2 with frozen BART encoder for prompt incorporation is well-established in the literature and the technical implementation details are clearly specified. The tile prediction accuracy (93%) and playability rate (88%) are directly measurable outcomes with clear evaluation procedures.

- **Medium confidence**: The path prediction mechanism's accuracy and its correlation with actual agent behavior is demonstrated but may be sensitive to level complexity and game-specific dynamics. The novelty search approach for open-ended generation is conceptually sound but the specific implementation details and long-term effectiveness remain to be fully validated.

- **Low confidence**: The generalizability of the approach to other games, level types, or prompt structures is not extensively tested. The behavioral characteristic space may not fully capture level diversity, and the system's performance with prompts outside the training distribution requires further investigation.

## Next Checks

1. **Behavioral characteristic space analysis**: Generate 1000 levels using novelty search and visualize the coverage of the normalized path coordinate space over time. Measure whether the search consistently discovers new regions or converges to a limited set of patterns.

2. **Cross-game generalization test**: Apply the trained MarioGPT model to generate levels for a different platformer game (e.g., Mega Man or Castlevania) and evaluate tile prediction accuracy and playability rates. Compare performance degradation to establish the model's transferability limits.

3. **Prompt robustness evaluation**: Systematically test the model with prompts containing combinations of features not present in the training data. Measure prompt matching accuracy and level playability to assess the model's ability to extrapolate beyond its training distribution.