---
ver: rpa2
title: Speed Limits for Deep Learning
arxiv_id: '2307.14653'
source_url: https://arxiv.org/abs/2307.14653
tags:
- where
- speed
- limit
- equation
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the thermodynamic efficiency of deep learning
  training by applying speed limits from stochastic thermodynamics to neural network
  training dynamics. The authors derive analytical expressions for speed limits in
  both gradient-flow and Langevin dynamics, showing that under plausible scaling assumptions
  on Neural Tangent Kernel spectra, learning is optimal in a scaling sense - the actual
  speed is within a constant factor of the theoretical bound.
---

# Speed Limits for Deep Learning

## Quick Facts
- arXiv ID: 2307.14653
- Source URL: https://arxiv.org/abs/2307.14653
- Reference count: 40
- Key outcome: Deep learning training achieves near-optimal efficiency under plausible NTK scaling assumptions, with inefficiency ratio growing at most logarithmically with dataset size

## Executive Summary
This paper establishes a theoretical framework for analyzing deep learning training efficiency using thermodynamic speed limits from stochastic thermodynamics. The authors derive analytical expressions for optimal training speed bounds in both gradient-flow and Langevin dynamics regimes, and show that neural networks trained in the Neural Tangent Kernel (NTK) regime achieve near-optimal efficiency under plausible scaling assumptions. They validate their theoretical predictions with experiments on CIFAR-10 using small-scale CNN architectures.

## Method Summary
The paper applies thermodynamic speed limits to neural network training by analyzing Wasserstein-2 distance between initial and final weight distributions alongside entropy production during training. Under NTK dynamics with power-law eigenvalue scaling (λ_k = k^(-α)), they derive analytical expressions for optimal training speed and prove near-optimal efficiency. The experimental validation uses Myrtle-5 CNN architecture trained on CIFAR-10 subsets with MSE loss, full batch gradient descent, and small learning rates, measuring the ratio of actual training time to theoretical speed limits.

## Key Results
- Under power-law NTK eigenvalue scaling, the inefficiency ratio T/T_SL scales as O(1) rather than growing with dataset size
- The path length in weight space during training scales identically to the optimal straight-line path under the same scaling assumptions
- CIFAR-10 experiments validate theoretical predictions, showing near-optimal efficiency after initial non-optimal regime with geometric inefficiency ratio l_NTK/l_geo close to optimal

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural Tangent Kernel (NTK) dynamics achieve near-optimal learning speed in the scaling sense
- Mechanism: The paper derives that under power-law scaling assumptions on NTK eigenvalues (λ_k = k^(-α)) and residue projections (Δ²_λ_k = k^(-δ)), the inefficiency ratio T/T_SL scales as O(1) rather than growing with dataset size or training time. This occurs because the Wasserstein-2 distance and entropy production scale with the same power of time, making their ratio constant.
- Core assumption: NTK spectrum follows power-law distribution and residue projections have specific scaling properties (α > 0, δ ≥ 0, and α-1(1-δ) < 1)
- Evidence anchors:
  - [abstract]: "remarkably, given some plausible scaling assumptions on the NTK spectra... learning is optimal in a scaling sense"
  - [section 3.2]: Detailed derivation showing T_SL(T) ∝ T under these assumptions
  - [corpus]: No direct corpus evidence for this specific scaling claim
- Break condition: If the NTK spectrum deviates significantly from power-law scaling or if residue projections have different scaling properties (δ > 1), the efficiency factor grows with dataset size

### Mechanism 2
- Claim: Entropy production during training can be directly related to geometric properties of the loss landscape
- Mechanism: The paper shows that entropy production R can be expressed as an integral involving the squared gradient norm, Hessian terms, and gradient of log-probability. This connects the thermodynamic irreversibility to the geometry of the loss landscape through the velocity field in weight space.
- Core assumption: The conservative force structure of the learning dynamics and the Fokker-Planck framework
- Evidence anchors:
  - [section 2.1]: "entropy production... contains the average squared length of the gradient"
  - [appendix A.2]: Detailed derivation linking entropy production to loss landscape geometry
  - [corpus]: No direct corpus evidence for this specific thermodynamic-geometry connection
- Break condition: When the learning dynamics deviate from conservative force structure or when high noise levels dominate the dynamics

### Mechanism 3
- Claim: The optimal path length in weight space is proportional to the actual path length traveled during training
- Mechanism: The paper demonstrates that the length of the curve traveled in weight space during NTK training (l_γ) scales identically to the length of the optimal straight-line path (l_geo) with the same power of time, making their ratio O(1).
- Core assumption: Power-law scaling of NTK eigenvalues and residue projections
- Evidence anchors:
  - [section 3.2]: "interestingly, we find the same asymptotic for the lengths, independent of α and δ"
  - [appendix B.1]: Mathematical derivation showing l_γ(T) ∝ T^((α-1+1-δ/α)/2)
  - [corpus]: No direct corpus evidence for this geometric property
- Break condition: If the power-law scaling assumptions break down or if the learning dynamics become highly non-linear

## Foundational Learning

- Concept: Wasserstein-2 distance
  - Why needed here: Used as the measure of distance between initial and final weight distributions in the speed limit formula
  - Quick check question: How does the Wasserstein-2 distance differ from standard Euclidean distance in probability space?

- Concept: Neural Tangent Kernel (NTK)
  - Why needed here: NTK regime allows for analytical tractability of the training dynamics and provides the framework for the power-law scaling assumptions
  - Quick check question: What makes the NTK regime particularly amenable to theoretical analysis compared to finite-width networks?

- Concept: Entropy production in stochastic thermodynamics
  - Why needed here: Central to deriving the speed limits and understanding the irreversibility of the learning process
  - Quick check question: How does entropy production relate to the efficiency of a thermodynamic process?

## Architecture Onboarding

- Component map: NTK analysis -> Wasserstein geometry -> Entropy production -> Speed limits -> CIFAR-10 validation
- Critical path: 1) Derive analytical expressions for Wasserstein-2 distance and entropy production in NTK regime, 2) Establish scaling assumptions on NTK spectra, 3) Prove near-optimal efficiency under these assumptions, 4) Validate with CIFAR-10 experiments, 5) Analyze geometric properties of weight space trajectories.
- Design tradeoffs: The analytical tractability of NTK comes at the cost of assuming infinite width and linearizability. The power-law scaling assumptions, while plausible, may not hold for all architectures or datasets. The CIFAR-10 experiments use small networks and datasets to enable tractability.
- Failure signatures: If the NTK approximation breaks down (finite width effects), if the power-law scaling assumptions are violated, or if the noise levels are too high (β⁻¹ dominates), the theoretical predictions may fail. Experimental validation would show inefficiency factors growing with dataset size.
- First 3 experiments:
  1. Train a linear perceptron on synthetic data to verify the analytical expressions for speed limits in the linear case
  2. Test the NTK scaling assumptions on a small MLP with varying widths to see how the infinite width approximation holds
  3. Vary the dataset size in CIFAR-10 experiments to empirically test whether the O(1) inefficiency factor remains constant

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the efficiency of NTK dynamics persist for non-power-law eigenvalue spectra in realistic deep networks?
- Basis in paper: [inferred] The paper assumes power-law spectra (λk = k^-α) for analytical tractability and finds optimal scaling behavior, but real NTK spectra may differ.
- Why unresolved: The paper only analyzes power-law spectra theoretically and provides limited empirical validation on small CNNs.
- What evidence would resolve it: Systematic experiments measuring inefficiency ratios across different architectures (ResNets, Transformers) with varying dataset sizes, and comparing to theoretical predictions for different spectral profiles.

### Open Question 2
- Question: How do discretization effects and finite learning rates impact the thermodynamic speed limits?
- Basis in paper: [explicit] The paper acknowledges it considers only low learning rates where discrete GD approximates continuum dynamics, and notes that finite learning rates could be important for practical relevance.
- Why unresolved: The analysis is restricted to gradient flow with implicit unit learning rate, leaving open how discrete dynamics with practical learning rates would behave.
- What evidence would resolve it: Experiments varying learning rates across orders of magnitude on the same architectures, measuring whether the O(1) efficiency factor persists or degrades.

### Open Question 3
- Question: What are the thermodynamic implications of feature learning in finite-width networks beyond the NTK regime?
- Basis in paper: [explicit] The discussion section explicitly calls for extending results to finite-width networks using kernel-adaptation methods to study feature-learning effects.
- Why unresolved: The paper only analyzes networks in the NTK regime where weights don't move much and feature learning is absent.
- What evidence would resolve it: Analysis of speed limits for finite-width networks showing whether feature learning creates additional inefficiencies or modifies the scaling behavior.

## Limitations
- The theoretical predictions rely on power-law scaling assumptions for NTK spectra that may not hold for all architectures
- Experimental validation is limited to small-scale CIFAR-10 experiments with simple CNN architectures
- The infinite-width NTK approximation breaks down for finite-width networks where feature learning occurs

## Confidence

- **High Confidence**: The mathematical framework connecting stochastic thermodynamics to deep learning training is sound and the analytical expressions for Wasserstein-2 distance and entropy production are correctly derived.
- **Medium Confidence**: The theoretical prediction of O(1) inefficiency under power-law scaling assumptions is mathematically rigorous but relies on unverified empirical assumptions about NTK spectra.
- **Low Confidence**: The practical implications of thermodynamic efficiency for actual deep learning practice and generalization performance remain speculative without further experimental validation.

## Next Checks

1. **Scaling Verification**: Empirically measure the NTK eigenvalue spectrum and residue projections across different architectures and widths to verify whether power-law scaling holds and characterize the scaling exponents α and δ.

2. **Generalization Study**: Test whether networks trained under near-optimal thermodynamic efficiency (as measured by the speed limits) show different generalization behavior compared to standard training, across multiple datasets and architectures.

3. **Finite-Width Analysis**: Quantify the deviation from theoretical predictions as a function of network width to establish when and how the infinite-width NTK approximation breaks down, and how this affects the speed limit bounds.