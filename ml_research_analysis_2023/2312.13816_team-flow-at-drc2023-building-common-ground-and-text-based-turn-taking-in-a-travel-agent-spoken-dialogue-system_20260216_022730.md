---
ver: rpa2
title: 'Team Flow at DRC2023: Building Common Ground and Text-based Turn-taking in
  a Travel Agent Spoken Dialogue System'
arxiv_id: '2312.13816'
source_url: https://arxiv.org/abs/2312.13816
tags:
- system
- user
- dialogue
- module
- common
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper describes a dialogue system developed for the Dialogue
  Robot Competition 2023 that focuses on building common ground and enabling natural
  turn-taking in travel planning dialogues. The system extracts user preferences from
  utterances, updates common ground in a tree structure, and generates appropriate
  responses and queries for sightseeing spot searches.
---

# Team Flow at DRC2023: Building Common Ground and Text-based Turn-taking in a Travel Agent Spoken Dialogue System

## Quick Facts
- arXiv ID: 2312.13816
- Source URL: https://arxiv.org/abs/2312.13816
- Reference count: 5
- Average user satisfaction rating: 2.78/7

## Executive Summary
This paper presents a spoken dialogue system for a travel planning task developed for the Dialogue Robot Competition 2023. The system focuses on building common ground between the user and system while enabling natural turn-taking through a voice action selection module. The architecture uses GPT-4 for preference extraction, response generation, and voice action selection, with a tree-based common ground structure to track dialogue topics and user preferences. The system was evaluated in a preliminary round with 18 participants, achieving moderate user satisfaction and travel plan feasibility scores.

## Method Summary
The system architecture consists of four main modules: ASR/TTS using Web Speech API and Amazon Polly, common ground update using GPT-4 to extract and filter user preferences stored in a tree structure, response generation using rule-based dialogue act generation selected by GPT-4, and voice action selection using ChatGPT with few-shot learning to determine whether to respond, nod, or take other actions. The system also includes expression/motion control using a fine-tuned Japanese BERT-v2 model. The common ground tree structure enables topic tracking and preference management, while the voice action selection module aims to create more natural turn-taking beyond simple alternation.

## Key Results
- Average user satisfaction rating of 2.78 on a 7-point scale
- Travel plan feasibility rating of 0.28
- Expression/motion prediction accuracy of 81% and 77% respectively
- System successfully engaged in dialogues while waiting for user comprehension through nodding and backchannel actions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The system builds and updates common ground dynamically during the dialogue.
- Mechanism: User preferences extracted by GPT-4 are filtered through the common ground update module, which selects accepted preferences and stores them in a tree structure for topic tracking.
- Core assumption: GPT-4 can accurately extract and filter user preferences relevant to sightseeing spots.
- Evidence anchors:
  - [abstract] states the system "generates queries for sightseeing spot searches using the common ground"
  - [section A] describes using GPT-4 to extract user preferences and then selecting which preferences the system has "accepted" before storing them in a tree structure
  - [corpus] has no direct evidence about the effectiveness of this mechanism

### Mechanism 2
- Claim: The voice action selection module enables more natural turn-taking by choosing appropriate responses beyond simple alternation.
- Mechanism: The module estimates voice action types (response, nod, nod & backchannel, or none) based on dialogue history and ASR results, allowing the system to nod or give feedback while waiting for user comprehension.
- Core assumption: Few-shot learning with ChatGPT can reliably determine when to respond versus when to provide non-verbal feedback.
- Evidence anchors:
  - [abstract] states the system "could make utterances at the proper moment" and "engaged in dialogue while waiting for user comprehension"
  - [section C] describes the implementation using OpenAI's ChatGPT with few-shot learning to estimate voice action types
  - [corpus] shows related work on turn-taking but no direct evidence about this specific implementation

### Mechanism 3
- Claim: Response generation using GPT-4 with dialogue acts produces contextually appropriate system utterances.
- Mechanism: The system first generates all possible dialogue acts via rule-based generation, selects the most appropriate one using GPT-4 considering dialogue history, then generates the response.
- Core assumption: GPT-4 can effectively select from generated dialogue acts based on both current user utterance and dialogue context.
- Evidence anchors:
  - [section B] describes the three-step process: rule-based DA generation, DA selection by GPT-4, and response generation by GPT-4
  - [abstract] mentions the system "could build common ground and take more natural turns based on user utterance texts"
  - [corpus] has no direct evidence about this specific DA-based response generation approach

## Foundational Learning

- Concept: Common ground theory in dialogue systems
  - Why needed here: The system explicitly builds and maintains common ground as a core mechanism for managing dialogue topics and user preferences
  - Quick check question: What is the difference between "common ground" and "grounding" in dialogue systems, and how does this system implement both?

- Concept: Dialogue act (DA) selection and generation
  - Why needed here: The response generation module uses a DA-based approach where possible acts are generated and then selected based on context
  - Quick check question: How does the rule-based DA generation module determine which dialogue acts are possible at each turn?

- Concept: Voice action selection for turn-taking
  - Why needed here: The system implements non-traditional turn-taking by choosing between responding, nodding, or other actions based on dialogue state
  - Quick check question: What specific features from ASR results and dialogue history does the voice action selection module use to make its decisions?

## Architecture Onboarding

- Component map: ASR → Common Ground Update + Voice Action Selection → Response Generation → TTS/Robot Control, with the Common Ground tree structure maintained across turns
- Critical path: User speech → ASR → Common Ground Update → Voice Action Selection → Response Generation → TTS/Robot Control (when voice action is "response")
- Design tradeoffs: Uses GPT-4 for multiple components (common ground, response generation, voice action) which provides flexibility but introduces dependency on external API costs and potential latency
- Failure signatures: If the system fails to extract preferences correctly, the common ground tree will be inaccurate; if voice action selection fails, turn-taking will feel unnatural; if response generation fails, the dialogue will lose coherence
- First 3 experiments:
  1. Test the common ground extraction and tree update with sample dialogues to verify preference extraction accuracy
  2. Evaluate voice action selection decisions on a test set of dialogue histories to ensure appropriate action selection
  3. Verify the end-to-end flow by running simple dialogues and checking that the system appropriately updates common ground, selects voice actions, and generates responses

## Open Questions the Paper Calls Out

- Question: How can the system effectively utilize common ground built from system utterances to improve dialogue coherence and user satisfaction?
  - Basis in paper: [explicit] The authors mention in the conclusion that they aim to explore "utilizing the common ground built from system utterances" in future work.
  - Why unresolved: The current system only uses user utterances to update common ground, missing an opportunity to leverage system-generated information for better dialogue management.
  - What evidence would resolve it: Implementation and evaluation of a system that incorporates system utterances into common ground updates, with comparative user satisfaction metrics.

- Question: What impact would incorporating multimodal information (e.g., speech prosody, facial expressions) have on the naturalness of turn-taking in the dialogue system?
  - Basis in paper: [explicit] The authors state in the conclusion that they aim to "leverage multimodal information to achieve more natural turn-taking."
  - Why unresolved: The current system relies solely on textual information for voice action selection, potentially missing important non-verbal cues that influence turn-taking.
  - What evidence would resolve it: Comparative studies measuring turn-taking naturalness and user satisfaction between text-only and multimodal input systems.

## Limitations
- Heavy reliance on GPT-4 for critical functions creates a single point of failure that isn't thoroughly evaluated
- Small sample size (18 participants, 40 dialogues) provides limited statistical power for robust conclusions
- Moderate satisfaction ratings (2.78/7) and low travel plan feasibility (0.28) indicate significant room for improvement

## Confidence
- **High Confidence**: The system architecture description and implementation details are clearly specified, including the three-step response generation process and the tree-based common ground structure.
- **Medium Confidence**: The evaluation results are presented with specific metrics, but the small sample size and lack of comparison to baselines limits generalizability of the findings.
- **Medium Confidence**: The mechanism descriptions (common ground building, voice action selection) are logically sound, but the paper doesn't provide sufficient empirical evidence about the effectiveness of these mechanisms in isolation.

## Next Checks
1. **A/B Testing with Alternative Models**: Conduct controlled experiments comparing GPT-4-based modules against rule-based or smaller language model alternatives to quantify the actual contribution of GPT-4 to system performance.

2. **Long Dialogue Evaluation**: Test the system with extended dialogues (30+ turns) to evaluate whether the common ground tree structure and voice action selection maintain coherence and natural flow over longer interactions.

3. **Component Isolation Testing**: Evaluate each module independently (common ground extraction accuracy, voice action selection appropriateness, response generation coherence) to identify which components contribute most to the observed satisfaction scores and plan feasibility issues.