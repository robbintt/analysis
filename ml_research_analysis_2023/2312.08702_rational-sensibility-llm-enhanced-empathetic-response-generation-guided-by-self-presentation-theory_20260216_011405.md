---
ver: rpa2
title: 'Rational Sensibility: LLM Enhanced Empathetic Response Generation Guided by
  Self-presentation Theory'
arxiv_id: '2312.08702'
source_url: https://arxiv.org/abs/2312.08702
tags:
- knowledge
- empathetic
- response
- generation
- lamb
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Lamb, an LLM-enhanced model for empathetic
  response generation guided by self-presentation theory. It addresses the limitations
  of existing methods in capturing the sensibility and rationality of conversations,
  which are crucial components of cognitive empathy.
---

# Rational Sensibility: LLM Enhanced Empathetic Response Generation Guided by Self-presentation Theory

## Quick Facts
- arXiv ID: 2312.08702
- Source URL: https://arxiv.org/abs/2312.08702
- Reference count: 20
- One-line primary result: Lamb outperforms state-of-the-art methods in both automatic and human evaluations for empathetic response generation

## Executive Summary
This paper proposes Lamb, an LLM-enhanced model for empathetic response generation guided by self-presentation theory. It addresses limitations of existing methods in capturing both sensibility and rationality in conversations, which are crucial for cognitive empathy. The model separates historical dialogues into sensible and rational sentences using a designed attention mechanism and employs LLaMA2-70b as a "rational brain" to analyze profound logical information. Experimental results demonstrate Lamb's effectiveness in generating high-quality empathetic responses.

## Method Summary
Lamb is an LLM-enhanced model that uses self-presentation theory to categorize dialogue sentences into sensible (emotional) and rational (logical) components. It employs a Bart encoder with attention fusion for the two categories, uses LLaMA2-70b (via CoNECT) for global emotional reasoning, and integrates COMET commonsense knowledge. The decoder fuses these representations with a knowledge selection mechanism to generate empathetic responses, balancing sensibility and rationality.

## Key Results
- Lamb outperforms state-of-the-art methods in both automatic and human evaluations
- Effective balance of sensibility and rationality in generated responses
- High performance in empathy classification and generation tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Separating sensible and rational sentences via self-presentation theory improves semantic representation.
- **Mechanism**: Sentences are classified into sensible (emotional) and rational (logical) groups using RECCON, then encoded separately and merged via attention.
- **Core assumption**: Self-presentation theory's categorization maps cleanly onto empathy expression in conversation.
- **Evidence anchors**: [abstract] innovative categorical approach that segregates historical dialogues; [section 3.2] segregate the historical context into two groups.
- **Break condition**: If emotional and rational content overlap significantly, attention-based fusion may degrade performance.

### Mechanism 2
- **Claim**: CoNECT provides globally coherent emotional reasoning beyond local commonsense.
- **Mechanism**: Chain-of-thought prompting with LLaMA2-70b analyzes full conversation context with global sentiment label for deeper emotional reasoning.
- **Core assumption**: LLaMA2-70b can reliably infer emotional reasoning from context when prompted appropriately.
- **Evidence anchors**: [abstract] employ LLaMA2-70b as a rational brain to analyze profound logical information; [section 3.3.2] CoNECT provides contextually semantically coherent information.
- **Break condition**: If LLM prompt fails to extract meaningful reasoning or introduces irrelevant context, performance degrades.

### Mechanism 3
- **Claim**: Combining sensible, rational, and commonsense knowledge improves empathy classification and generation.
- **Mechanism**: Decoder fuses representations from sensible/rational context, COMET knowledge, and CoNECT data using cross-attention and knowledge selection.
- **Core assumption**: Multi-source knowledge fusion enhances decoder's ability to generate empathetic responses.
- **Evidence anchors**: [section 3.5] cross-attention mechanism allows decoder to perceive multiple knowledge sources; [section 3.6] parameters optimized with emotion and NLL loss.
- **Break condition**: If cross-attention or knowledge selection introduces too much noise or conflicting information, response quality suffers.

## Foundational Learning

- **Concept: Self-presentation theory in sociology**
  - Why needed here: Provides theoretical justification for categorizing dialogue into sensible (emotional) and rational (logical) sentences.
  - Quick check question: What are the two main sentence categories according to self-presentation theory, and why are they important for empathy modeling?

- **Concept: Chain-of-thought prompting in LLMs**
  - Why needed here: Enables deeper emotional reasoning over full conversation context rather than surface-level inference.
  - Quick check question: How does CoNECT use LLaMA2-70b to generate globally coherent emotional reasoning?

- **Concept: Cross-attention and knowledge fusion in transformers**
  - Why needed here: Allows decoder to integrate multiple knowledge sources without losing coherence.
  - Quick check question: What are the three knowledge sources fused in the decoder, and how is semantic collision mitigated?

## Architecture Onboarding

- **Component map**: Context → Sentiment Label (SEEK) → Sensible/Rational Split (RECCON) → Attention Fusion → CoNECT + COMET → Cross-Attention Decoder → Response

- **Critical path**: Context → Sentiment Label → Sensible/Rational Split → Attention Fusion → CoNECT + COMET → Cross-Attention Decoder → Response

- **Design tradeoffs**:
  - Using heavy LLM (LLaMA2-70b) increases computational cost but improves global emotional reasoning
  - Splitting sentences into sensible/rational may lose nuanced mixed cases but gains clearer modeling focus
  - Multiple knowledge sources risk semantic collision; knowledge selection mechanism is crucial

- **Failure signatures**:
  - Low emotion classification accuracy → RECCON or SEEK may be misclassifying context
  - High perplexity or low BLEU → Decoder fusion may be introducing noise
  - Reduced diversity in outputs → Knowledge selection may be too conservative

- **First 3 experiments**:
  1. Run ablation without CoNECT to measure loss of global reasoning vs. speed gain
  2. Run ablation without sensible/rational split to see if unified context is sufficient
  3. Replace LLaMA2-70b with smaller LLM to evaluate performance vs. efficiency tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed model handle cases where sensible and rational sentences in a dialogue conflict with each other?
- Basis in paper: [inferred] The paper mentions designed attention mechanism to jointly model sensible and rational sentences, but doesn't provide details on conflict resolution.
- Why unresolved: No detailed explanation of conflict resolution mechanism crucial for understanding model behavior in complex scenarios.
- What evidence would resolve it: Detailed description of conflict resolution mechanism with empirical results demonstrating effectiveness.

### Open Question 2
- Question: How does the proposed model perform in generating empathetic responses for dialogues with multiple speakers?
- Basis in paper: [explicit] The paper focuses on dialogues with two roles (speaker and listener) and doesn't discuss multi-speaker performance.
- Why unresolved: No insights into model's ability to handle dialogues with multiple speakers, a common real-world scenario.
- What evidence would resolve it: Empirical results comparing single-speaker and multi-speaker dialogue performance with discussion of challenges and solutions.

### Open Question 3
- Question: How does the proposed model compare to other state-of-the-art models in terms of computational efficiency and resource requirements?
- Basis in paper: [explicit] The paper mentions using LLaMA2-70b but doesn't provide information on computational efficiency or resource requirements.
- Why unresolved: No insights into model's resource utilization, an important consideration for real-world applications.
- What evidence would resolve it: Comparison of computational efficiency and resource requirements with other state-of-the-art models with discussion of performance-resource tradeoffs.

## Limitations

- **Theoretical grounding gap**: Limited direct evidence that self-presentation theory cleanly applies to conversational empathy modeling; no prior work using this specific framework.
- **Knowledge source integration risks**: Multi-source fusion approach has inherent risks of introducing conflicting or noisy information that could degrade response quality.
- **LLM dependency and computational cost**: Significant computational overhead from LLaMA2-70b with unclear tradeoff between performance gains and inference efficiency.

## Confidence

**High confidence**: Overall architecture design is coherent and well-specified; experimental methodology follows standard practices.

**Medium confidence**: Claimed performance improvements over baselines, though actual magnitude and statistical significance aren't fully clear from abstract alone.

**Low confidence**: Theoretical justification for self-presentation theory's applicability to conversational empathy, and robustness of knowledge selection mechanism to prevent semantic collision.

## Next Checks

1. **Ablation on knowledge sources**: Remove each knowledge source (sensible/rational split, CoNECT, COMET) individually and measure performance degradation to quantify each component's contribution and identify potential semantic collision issues.

2. **Cross-theoretical validation**: Test whether self-presentation theory-based sentence categorization actually improves performance compared to simpler emotional vs. informational classification, or if theory provides post-hoc justification for arbitrary split.

3. **Computational efficiency analysis**: Replace LLaMA2-70b with smaller model (e.g., LLaMA2-13b) in CoNECT and measure performance drop vs. inference speed improvement to determine if heavy LLM is truly necessary for claimed gains.