---
ver: rpa2
title: Dirichlet-based Uncertainty Quantification for Personalized Federated Learning
  with Improved Posterior Networks
arxiv_id: '2312.11230'
source_url: https://arxiv.org/abs/2312.11230
tags:
- data
- uncertainty
- local
- global
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of selecting between local and
  global models in federated learning, especially when dealing with heterogeneous
  data distributions. The proposed framework uses uncertainty quantification to decide
  which model to use for a given input, aiming to improve performance on both in-distribution
  (InD) and out-of-distribution (OOD) data.
---

# Dirichlet-based Uncertainty Quantification for Personalized Federated Learning with Improved Posterior Networks

## Quick Facts
- arXiv ID: 2312.11230
- Source URL: https://arxiv.org/abs/2312.11230
- Reference count: 40
- Primary result: A federated learning framework that uses uncertainty quantification to intelligently switch between local and global models, outperforming state-of-the-art personalized federated learning algorithms on mixed in-distribution and out-of-distribution data.

## Executive Summary
This paper addresses the challenge of selecting between local and global models in federated learning, especially when dealing with heterogeneous data distributions. The proposed framework uses uncertainty quantification to decide which model to use for a given input, aiming to improve performance on both in-distribution (InD) and out-of-distribution (OOD) data. The core idea is to employ Dirichlet-based models (specifically, Natural Posterior Networks) to estimate aleatoric and epistemic uncertainties. By analyzing these uncertainties, the framework can determine whether to use the local model, the global model, or abstain from prediction altogether. The authors also identify and fix an issue in the loss function of Natural Posterior Networks that hindered proper disentanglement of aleatoric and epistemic uncertainties. Experiments on various image datasets show that the proposed method, FedPN, outperforms state-of-the-art personalized federated learning algorithms on mixed InD and OOD data while maintaining competitive performance on InD data alone.

## Method Summary
The method involves federated training using FedAvg with a shared encoder across clients and separate local/global classifiers and density models. Local density models and classifiers are trained on each client's data using a corrected loss function that includes a StopGrad term for density estimation. During inference, epistemic uncertainty (entropy of Dirichlet posterior) is computed for the local model; if high, the global model is used, otherwise the local model is used. Uncertainty thresholds are set using a calibration subset. The approach uses Dirichlet-based models to estimate aleatoric and epistemic uncertainties, and switches between local and global models based on these uncertainty estimates.

## Key Results
- FedPN outperforms state-of-the-art personalized federated learning algorithms on mixed InD and OOD data
- The corrected loss function resolves issues with uncertainty disentanglement in high-aleatoric regions
- The framework maintains competitive performance on InD data alone while improving OOD performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Uncertainty quantification enables reliable switching between local and global models in federated learning
- **Mechanism:** The framework uses epistemic and aleatoric uncertainty estimates to determine whether a local model is confident enough to make predictions or should defer to the global model. Low epistemic uncertainty indicates the local model has sufficient knowledge, while high epistemic uncertainty triggers fallback to the global model
- **Core assumption:** The local model is more reliable than the global model when it has low epistemic uncertainty about an input, even if the global model might be more accurate in aggregate
- **Evidence anchors:**
  - [abstract]: "It is achieved through a careful modeling of predictive uncertainties that helps to detect local and global in- and out-of-distribution data and use this information to select the model that is confident in a prediction"
  - [section 2.2]: "If the local model has low epistemic and high aleatoric uncertainty at some point, the model is confident that the predicted label is ambiguous, and the model should abstain from prediction. However, if the epistemic uncertainty is high, it means that the model doesn't have enough knowledge to make the prediction"
  - [corpus]: Weak evidence - no direct citations found about this specific switching mechanism in federated learning literature
- **Break condition:** The switching mechanism fails when the uncertainty estimates are poorly calibrated or when the distinction between epistemic and aleatoric uncertainty breaks down due to model misspecification

### Mechanism 2
- **Claim:** Dirichlet-based models enable accurate disentanglement of aleatoric and epistemic uncertainty
- **Mechanism:** Dirichlet posterior networks parameterize uncertainty using Dirichlet distributions over class probabilities, allowing closed-form computation of both uncertainty types. The density model over embeddings helps distinguish between lack of knowledge (epistemic) and inherent data ambiguity (aleatoric)
- **Core assumption:** The density model accurately captures the distribution of training embeddings, enabling reliable epistemic uncertainty estimation
- **Evidence anchors:**
  - [section 3.2]: "Epistemic uncertainty...can be estimated...as the entropy of a posterior Dirichlet distribution...Aleatoric uncertainty can be measured using the average entropy"
  - [section 3.1]: "This parameterization offers several advantages...as the density is properly normalized, embeddings that lie far from the training ones will result in lower values of p(g(x)), thus leading to lower α(x)"
  - [corpus]: Moderate evidence - related works on Dirichlet-based uncertainty quantification exist but specific application to federated learning switching is novel
- **Break condition:** The density model fails to properly capture the embedding distribution, leading to confusion between high-aleatoric and high-epistemic regions

### Mechanism 3
- **Claim:** The corrected loss function resolves issues with uncertainty disentanglement in high-aleatoric regions
- **Mechanism:** The proposed loss function (equation 8) explicitly maximizes the likelihood of embeddings while preventing gradient flow to density model parameters during classification loss computation. This ensures the density model properly represents training data density even in ambiguous regions
- **Core assumption:** The StopGrad operation effectively isolates density model learning from classification objectives
- **Evidence anchors:**
  - [section 3.3]: "We propose to still use parametric model to estimate density, but now our goal is to ensure that p(·) accurately represents the density of our training embeddings...Thus, we suggest the following loss function: L[y, StopGradp(g(x))αpost(x)] − λH[Dir µ | αpost(x)] − γ log p[g(x)]"
  - [section 3.3]: "Figure 2-right...we observe the different picture with 'density' estimate at the central cluster decreasing when one increases the number of clusters...While for our proposed trick it behaves as expected"
  - [corpus]: Limited evidence - the specific loss function modification appears novel to this work
- **Break condition:** The hyperparameter γ is poorly tuned, causing either underfitting of the density model or interference with classification objectives

## Foundational Learning

- **Concept: Dirichlet distributions and their properties**
  - Why needed here: Dirichlet distributions are the foundation for representing uncertainty over probability vectors in classification tasks, enabling both uncertainty quantification and the switching mechanism
  - Quick check question: How does the concentration parameter of a Dirichlet distribution affect the variance of the resulting probability vector?

- **Concept: Aleatoric vs epistemic uncertainty**
  - Why needed here: The framework explicitly distinguishes between these two types of uncertainty to make intelligent switching decisions between local and global models
  - Quick check question: In what scenarios would high aleatoric uncertainty be preferable to high epistemic uncertainty for making predictions?

- **Concept: Normalizing flows for density estimation**
  - Why needed here: Normalizing flows are used to model the density of embeddings in the feature space, which is critical for computing epistemic uncertainty and enabling the switching mechanism
  - Quick check question: What properties make normalizing flows suitable for learning complex density functions in high-dimensional spaces?

## Architecture Onboarding

- **Component map:** Raw input -> Encoder -> Embedding -> Density model + Classifier -> Uncertainty estimates -> Switching decision -> Final prediction
- **Critical path:** Raw input → Encoder → Embedding → Density model + Classifier → Uncertainty estimates → Switching decision → Final prediction
- **Design tradeoffs:**
  - Using a single density model per client vs per-class density models (simpler but potentially less expressive)
  - Fixed encoder vs fine-tuned encoder after federated training (stability vs adaptability)
  - Explicit threshold calibration vs learned threshold selection (control vs automation)
- **Failure signatures:**
  - High switching rate between models indicates poor uncertainty calibration
  - Density model collapse manifests as uniform uncertainty estimates across all inputs
  - Poor performance on OOD data suggests the density model doesn't properly capture the data manifold
- **First 3 experiments:**
  1. Train the federated encoder and global classifier on MNIST with 20 clients, each having 2-3 classes
  2. Implement the density model with normalizing flows and verify it captures the embedding distribution
  3. Test the switching mechanism on a held-out validation set, comparing local-only, global-only, and switching performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of density model (e.g., Radial Flow, Gaussian Mixture Model) affect the performance and robustness of the switching framework in heterogeneous federated learning scenarios?
- Basis in paper: [explicit] The paper mentions that any density model could theoretically be used, but only Radial Flow is explored.
- Why unresolved: The paper focuses on Radial Flow due to its simplicity, but does not compare its performance to other density models like Gaussian Mixture Models or more complex normalizing flows.
- What evidence would resolve it: A comparative study evaluating different density models (e.g., Radial Flow, Gaussian Mixture Models, more complex normalizing flows) on the same federated learning tasks, measuring both accuracy and computational overhead.

### Open Question 2
- Question: What is the impact of the threshold selection strategy on the overall performance of the switching model, especially in scenarios with varying degrees of data heterogeneity and label noise?
- Basis in paper: [explicit] The paper discusses a threshold selection procedure based on epistemic uncertainty scores, but acknowledges its subjectivity and the lack of explicit OOD data for calibration.
- Why unresolved: The paper proposes a heuristic threshold selection method but does not explore its sensitivity to different data distributions or label noise levels.
- What evidence would resolve it: An ablation study systematically varying the threshold selection method and evaluating its impact on accuracy across different datasets with controlled levels of data heterogeneity and label noise.

### Open Question 3
- Question: How does the proposed framework handle scenarios where both local and global models exhibit high epistemic uncertainty for a given input, and what are the implications for prediction reliability?
- Basis in paper: [inferred] The paper focuses on cases where either the local or global model has low epistemic uncertainty, but does not explicitly address scenarios where both models are uncertain.
- Why unresolved: The paper does not provide a clear strategy for handling cases where both models lack confidence, which could be common in highly heterogeneous federated learning settings.
- What evidence would resolve it: Experiments designed to specifically test the framework's behavior when both local and global models exhibit high epistemic uncertainty, along with a proposed strategy for handling such cases (e.g., abstaining from prediction, using an ensemble of models).

## Limitations
- The framework's effectiveness may degrade when client data distributions are highly overlapping or when the number of clients becomes very large
- The fixed nature of encoder weights after federated training may not capture evolving data distributions
- The evaluation is limited to specific datasets (MNIST, Fashion-MNIST, CIFAR-10) with controlled levels of heterogeneity

## Confidence
- **Medium**: The mechanism of using epistemic uncertainty to trigger fallback to global models is well-supported by the literature on Bayesian neural networks, but the specific implementation details for federated settings introduce uncertainties
- **Medium**: The experimental results show promising improvements, but the evaluation is limited to specific datasets with controlled levels of heterogeneity

## Next Checks
1. **Uncertainty calibration validation**: Systematically evaluate how well the Dirichlet-based uncertainty estimates correlate with actual prediction errors across different data heterogeneity levels, using reliability diagrams and expected calibration error metrics.
2. **Robustness to hyperparameter sensitivity**: Conduct ablation studies on the γ hyperparameter controlling density model learning, and test sensitivity to different encoder architectures and normalizing flow configurations.
3. **Scalability testing**: Evaluate the framework's performance with increasing numbers of clients (beyond the 20-client setup used in experiments) and with more complex data distributions that better reflect real-world federated learning scenarios.