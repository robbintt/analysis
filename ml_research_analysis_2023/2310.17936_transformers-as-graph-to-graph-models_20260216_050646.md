---
ver: rpa2
title: Transformers as Graph-to-Graph Models
arxiv_id: '2310.17936'
source_url: https://arxiv.org/abs/2310.17936
tags:
- graph
- computational
- linguistics
- association
- pages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that Transformers are fundamentally graph-to-graph
  models, with sequences being a special case. Attention weights are functionally
  equivalent to graph edges.
---

# Transformers as Graph-to-Graph Models

## Quick Facts
- arXiv ID: 2310.17936
- Source URL: https://arxiv.org/abs/2310.17936
- Reference count: 33
- Primary result: G2GT achieves state-of-the-art accuracies for modeling various linguistic structures by integrating explicit graphs into latent graphs learned by pretrained Transformers

## Executive Summary
This paper presents a novel perspective on Transformers, arguing that they are fundamentally graph-to-graph models where attention weights function as learned graph edges. The authors introduce the Graph-to-Graph Transformer (G2GT) architecture, which explicitly incorporates graph edges into attention weight computations and predicts graph edges using attention-like functions. By integrating explicit graph structures with the latent representations learned through pretraining, G2GT enables non-autoregressive graph prediction with iterative refinement, achieving state-of-the-art performance across various linguistic structure modeling tasks.

## Method Summary
The Graph-to-Graph Transformer (G2GT) extends standard Transformers by modifying the attention mechanism to accept explicit graph edges as input and predict graph edges as output. Edge labels are mapped to learned embedding vectors that are incorporated into attention score calculations through various architectural configurations. The model employs iterative refinement, where predicted graphs are fed back as input for subsequent iterations, enabling joint modeling of complete graph structures without autoregressive decoding. This approach leverages pretrained Transformer representations while adding explicit graph structure awareness through relation embeddings.

## Key Results
- G2GT achieves state-of-the-art accuracies for modeling various linguistic structures including syntactic parsing, semantic role labeling, and coreference resolution
- The architecture effectively integrates explicit graphs into the latent graphs learned by pretrained Transformers
- Iterative graph refinement enables non-autoregressive graph prediction while optimizing the complete graph structure without bespoke decoding strategies

## Why This Works (Mechanism)

### Mechanism 1
Attention weights in Transformers function as learned graph edges. The self-attention mechanism computes a full nÃ—n attention matrix where each cell's weight represents the strength of connection between two nodes, encoding the latent graph structure over the input sequence. This captures meaningful locality and dependency relations in the data equivalent to traditional linguistic structures.

### Mechanism 2
Explicit graph edges can be integrated into attention computation via learned relation embeddings. Edge labels are mapped to embedding vectors that are incorporated into attention score calculation by reweighting keys/queries or adding as a bias. This allows the model to condition attention on known graph structure while maintaining flexibility in learning combinations.

### Mechanism 3
Iterative refinement of predicted graphs enables non-autoregressive joint modeling of all edges. The model predicts the full graph in parallel, then feeds this prediction back as input for the next iteration. Each refinement step updates the graph by conditioning on the previous prediction, allowing global consistency without sequential decoding.

## Foundational Learning

- **Graph neural networks and message passing**: Understanding how graphs are traditionally processed (node features aggregated over edges) helps grasp why Transformers can emulate this via attention. Quick check: In a GNN, how is information from a node's neighbors incorporated into that node's representation?

- **Attention mechanisms and positional encodings**: Transformers use self-attention with positional encodings to model sequences; G2GT extends this to arbitrary graphs by replacing or augmenting positional info with edge labels. Quick check: What role do positional encodings play in standard Transformers, and how might edge embeddings serve a similar purpose in G2GT?

- **Non-autoregressive vs autoregressive modeling**: G2GT predicts entire graphs in parallel (non-autoregressive) but uses iterative refinement to capture dependencies between edges, combining speed with accuracy. Quick check: What is the key advantage of non-autoregressive prediction, and what challenge does it face that iterative refinement addresses?

## Architecture Onboarding

- **Component map**: Input (token sequence + optional explicit graph) -> G2GT Layer (modified self-attention with edge embeddings) -> Decoder (classification mapping output vectors to edge labels) -> Iterative Refinement Loop (repeated encoding and decoding)

- **Critical path**: 1) Embed input tokens and optional graph edges 2) Apply G2GT layers to produce sequence of vectors 3) Use decoder to predict graph edges from vector pairs 4) Feed predicted graph back as input for next refinement iteration 5) Output final predicted graph

- **Design tradeoffs**: Edge embeddings increase model capacity but add parameters and memory; iterative refinement adds computation but enables non-autoregressive joint modeling; removing edge-key interactions can improve efficiency but may lose structural information

- **Failure signatures**: Attention weights collapse to uniform values indicating poor edge integration; predicted graphs don't improve across refinement iterations suggesting inability to leverage prior predictions; overfitting on small datasets due to high capacity from relation embeddings

- **First 3 experiments**: 1) Implement basic G2GT layer with edge embeddings only in attention scores on small synthetic graph task 2) Compare iterative refinement vs single-pass prediction on simple structured prediction task 3) Ablate edge embedding size and number of refinement steps on medium-sized NLP task

## Open Questions the Paper Calls Out

### Open Question 1
How exactly do attention weights correspond to graph edges in transformers? The paper states "Attention weights are functionally equivalent to graph edges" but doesn't provide a detailed formal proof or mathematical framework showing the exact correspondence. Evidence needed: rigorous mathematical framework demonstrating the correspondence between attention weights and graph edges, including edge weights and directions.

### Open Question 2
What is the optimal number of iterative refinement steps for different graph-to-graph tasks? The paper mentions iterative refinement as a solution but doesn't provide concrete guidelines for determining optimal iterations. Evidence needed: empirical studies comparing performance across different numbers of iterations for various tasks and graph sizes.

### Open Question 3
How does the Graph-to-Graph Transformer architecture scale to very large graphs? The paper acknowledges scalability as an open problem but doesn't provide concrete solutions or empirical results. Evidence needed: empirical results showing performance degradation with increasing graph size and proposed solutions for scaling to large graphs.

## Limitations

- The mechanistic explanations for attention-as-graph-edges equivalence are primarily theoretical with limited corpus-based empirical validation
- Integration of explicit graph edges through relation embeddings raises concerns about scalability when edge label spaces become large or complex
- Computational overhead of incorporating explicit graph structures may limit practical applicability for large-scale or real-time applications

## Confidence

**High Confidence**: Architectural design and basic implementation details are well-specified and reproducible. Attention-as-graph-edges claim is supported by mathematical formulation.

**Medium Confidence**: Iterative refinement effectiveness demonstrated on specific linguistic tasks, but generalizability to other domains uncertain. Explicit graph edge integration shows promise but lacks comprehensive ablation studies.

**Low Confidence**: Broader claim that all Transformer operations are fundamentally graph-based requires more extensive empirical validation. State-of-the-art performance claims would benefit from more rigorous comparison with specialized GNN architectures.

## Next Checks

1. **Attention Pattern Analysis**: Compare attention weight distributions in standard Transformers versus G2GT on same tasks. Measure whether G2GT attention patterns align more closely with ground-truth graph structures and correlate with performance improvements.

2. **Iterative Refinement Convergence**: Systematically evaluate convergence properties across different numbers of iterations and task types. Track prediction stability, measure convergence rates, and identify conditions where refinement helps versus harms performance.

3. **Edge Label Embedding Sensitivity**: Perform comprehensive ablation study varying edge label embedding dimensions, relation types, and integration methods. Assess impact on training efficiency and final task performance to identify optimal configurations and failure modes.