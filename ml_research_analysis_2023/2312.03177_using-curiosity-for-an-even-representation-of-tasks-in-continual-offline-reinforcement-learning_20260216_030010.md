---
ver: rpa2
title: Using Curiosity for an Even Representation of Tasks in Continual Offline Reinforcement
  Learning
arxiv_id: '2312.03177'
source_url: https://arxiv.org/abs/2312.03177
tags:
- task
- tasks
- learning
- buffer
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses catastrophic forgetting in continual offline
  reinforcement learning, where tasks are non-labeled and non-evenly exposed to the
  learner over time. The authors propose two novel replay buffers that leverage curiosity:
  the Hybrid Curious Buffer (HCB) uses curiosity as a priority metric for retaining
  old transition tuples, and the Hybrid Reservoir Buffer with Task Separation (HRBTS)
  uses curiosity for task boundary detection.'
---

# Using Curiosity for an Even Representation of Tasks in Continual Offline Reinforcement Learning

## Quick Facts
- arXiv ID: 2312.03177
- Source URL: https://arxiv.org/abs/2312.03177
- Reference count: 40
- The paper addresses catastrophic forgetting in continual offline reinforcement learning using curiosity-driven replay buffers

## Executive Summary
This paper proposes two novel replay buffers that leverage curiosity to maintain balanced task representation in continual offline reinforcement learning. The authors introduce the Hybrid Curious Buffer (HCB) which uses curiosity as a priority metric for retaining old transition tuples, and the Hybrid Reservoir Buffer with Task Separation (HRBTS) which uses curiosity for task boundary detection. Both buffers are designed to preserve knowledge from all tasks encountered during training, regardless of their duration or exposure frequency. Experiments on classical control tasks and Metaworld environment demonstrate superior performance compared to existing methods in most settings.

## Method Summary
The paper addresses continual offline reinforcement learning with non-labeled tasks and uneven exposure over time by proposing two curiosity-driven replay buffers. The Hybrid Curious Buffer (HCB) uses curiosity as a priority metric in a reservoir buffer architecture to retain samples from short-lived tasks that might otherwise be forgotten. The Hybrid Reservoir Buffer with Task Separation (HRBTS) employs curiosity-based signal-to-noise ratio filtering to detect task boundaries and maintain separate sub-buffers for different tasks. Both approaches pair these specialized buffers with a smaller FIFO buffer for recent experiences, and are evaluated using Soft Actor-Critic on classical control tasks and Metaworld environments.

## Key Results
- HCB and HRBTS outperform Hybrid Reservoir Buffer (HRB) and Multi-Time Scale Replay Buffer (MTR) in most experimental settings
- Both buffers show better immunity to catastrophic forgetting across varying task durations
- HCB and HRBTS perform worse than MTR in settings with frequent task changes and small task drift, where curiosity becomes less effective as a measure
- The buffers successfully maintain balanced representation of tasks regardless of their duration or exposure frequency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Curiosity as priority metric ensures short-lived tasks retain samples despite low exposure time
- Mechanism: HCB uses curiosity-based reservoir buffer to prioritize transitions that most surprised the agent. Since short tasks cause higher prediction errors (curiosity), their samples are more likely retained
- Core assumption: Curiosity effectively captures unexpectedness in task transitions, especially during abrupt changes
- Evidence anchors:
  - [abstract] "curiosity as a priority metric when it comes to retaining old transition tuples"
  - [section] "we formulate the buffer similar to the reservoir buffer [37]. However, in our case curiosity acts as the priority factor to decide whether to retain an old transition tuple"
  - [corpus] Weak - no direct evidence in corpus about curiosity-based prioritization in CL settings
- Break condition: When task changes are gradual and continuous, curiosity becomes constant across all samples, eliminating its discriminatory power

### Mechanism 2
- Claim: Curiosity-based task boundary detection enables buffer separation for different tasks
- Mechanism: HRBTS uses signal-to-noise ratio filtering on curiosity signal to hypothesize task boundaries, then creates separate sub-buffers for each detected task
- Core assumption: Task changes produce detectable spikes in curiosity signal that can be filtered
- Evidence anchors:
  - [section] "we use curiosity as a measure to hypothesize a task change when the tasks are not labeled... we rely on curiosity to draw task boundaries when they are not explicitly given"
  - [section] "The filter we use to hypothesize the task boundaries... is an adaptive threshold filter which is a slight modification of a Signal to Noise ratio (SNR) based filter"
  - [corpus] Weak - corpus shows curiosity in RL but not for task boundary detection in CL
- Break condition: When tasks change too frequently or gradually, curiosity signal becomes too noisy to reliably detect boundaries

### Mechanism 3
- Claim: Hybrid architecture balances exploration of new tasks with retention of old task knowledge
- Mechanism: Both HCB and HRBTS combine FIFO buffer (for recent experiences) with specialized buffer(s) (for old task preservation), creating time-scale diversity
- Core assumption: Recent experiences are valuable for current task learning while older experiences preserve past task knowledge
- Evidence anchors:
  - [section] "A FIFO buffer smaller than the primary reservoir buffer [37] is maintained along with a reservoir buffer"
  - [section] "In the context of continual reinforcement learning rehearsal strategies have shown to be an efficient way of retaining knowledge"
  - [corpus] Moderate - TEAL paper discusses selection strategies for small buffers in CL
- Break condition: When task changes are so frequent that FIFO buffer dominates, the specialized buffer becomes irrelevant

## Foundational Learning

- Concept: Reservoir sampling algorithms
  - Why needed here: HCB and HRBTS are based on reservoir buffer architecture for maintaining fixed-size memory with uniform/priority-based sampling
  - Quick check question: What is the probability that any specific transition tuple remains in a reservoir buffer after n insertions?

- Concept: Signal processing for change detection
  - Why needed here: HRBTS uses SNR-based filtering on curiosity signal to detect task boundaries
  - Quick check question: How does signal-to-noise ratio help distinguish between gradual drift and abrupt task changes?

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: The paper's core problem is preventing forgetting when training on sequential tasks
  - Quick check question: What happens to a neural network's weights when trained on a new task without any mechanism to preserve old task knowledge?

## Architecture Onboarding

- Component map: FIFO buffer (5% capacity) → Main buffer (95% capacity) where main buffer is either curiosity-based reservoir (HCB) or task-separated reservoir collection (HRBTS)
- Critical path: Curiosity calculation → Buffer insertion decision → Task boundary detection (HRBTS only) → Training sample selection
- Design tradeoffs: HCB trades task boundary accuracy for simpler implementation; HRBTS trades complexity for potentially better task separation
- Failure signatures: Poor performance on gradually changing tasks (curiosity becomes constant), task boundary detection failures (HRBTS), buffer overflow/underflow issues
- First 3 experiments:
  1. Test curiosity signal behavior during task changes in Pendulum environment
  2. Validate HRBTS task boundary detection on synthetic curiosity signal with known changes
  3. Compare buffer composition ratios between HCB and HRBTS after single task change

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective is curiosity-based task boundary detection in scenarios with frequent, short-lived task changes?
- Basis in paper: [explicit] The paper discusses the use of curiosity as a task boundary detector in HRBTS and notes that it struggles in settings with frequent, short-lived task changes.
- Why unresolved: The paper does not provide a detailed analysis of the performance of curiosity-based task boundary detection in such scenarios, only mentioning that it becomes harder to detect changes accurately.
- What evidence would resolve it: A detailed experimental comparison of HRBTS's performance with and without curiosity-based task boundary detection in environments with frequent, short-lived task changes.

### Open Question 2
- Question: How does the volatility of curiosity as a priority metric affect the performance of HCB in scenarios with gradual task drift?
- Basis in paper: [explicit] The paper notes that curiosity becomes less effective as a measure when task changes happen at every timestep, leading to HCB performing similarly to HRB.
- Why unresolved: The paper does not explore the underlying reasons for curiosity's volatility in gradual task drift scenarios or how this affects the long-term performance of HCB.
- What evidence would resolve it: An analysis of the curiosity signal's behavior over time in environments with gradual task drift and its correlation with HCB's performance.

### Open Question 3
- Question: Can a hybrid approach combining curiosity-based and time-based priority metrics improve the performance of replay buffers in CL settings?
- Basis in paper: [inferred] The paper introduces two buffers, HCB and HRBTS, that leverage curiosity in different ways but does not explore hybrid approaches combining curiosity with other metrics.
- Why unresolved: The paper focuses on the individual strengths of curiosity-based approaches but does not investigate the potential benefits of combining them with other metrics like time-based prioritization.
- What evidence would resolve it: Experiments comparing the performance of hybrid buffers that combine curiosity-based and time-based priority metrics against the individual approaches in various CL settings.

## Limitations

- The mechanisms show significant performance degradation in settings with frequent task changes and small task drift
- Curiosity calculation computational overhead is not addressed, potentially limiting practical applicability
- Task boundary detection in HRBTS may fail in scenarios with gradual or noisy task transitions

## Confidence

- High Confidence: The experimental methodology and comparison framework are well-defined with clear baselines and evaluation metrics
- Medium Confidence: The curiosity-based prioritization mechanism in HCB is plausible given experimental results, though sensitivity to task change characteristics is not fully characterized
- Low Confidence: The task boundary detection mechanism in HRBTS relies heavily on the assumption that curiosity spikes reliably indicate task changes, which may not hold for gradual or noisy transitions

## Next Checks

1. Conduct ablation studies on the curiosity calculation method (forward vs. inverse vs. reward-based) to determine which variant provides the most reliable task boundary detection
2. Test the buffers on environments with controlled gradual task drift to quantify performance degradation as the rate of change varies
3. Evaluate the computational overhead of curiosity-based mechanisms compared to simpler baseline approaches to assess practical scalability