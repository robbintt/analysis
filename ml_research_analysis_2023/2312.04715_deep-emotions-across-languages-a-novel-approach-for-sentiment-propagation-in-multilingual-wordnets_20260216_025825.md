---
ver: rpa2
title: 'Deep Emotions Across Languages: A Novel Approach for Sentiment Propagation
  in Multilingual WordNets'
arxiv_id: '2312.04715'
source_url: https://arxiv.org/abs/2312.04715
tags:
- sentiment
- wordnet
- msse
- language
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of automatic sentiment propagation
  in multilingual WordNets, where manual annotation is time-consuming and expensive.
  The authors introduce two novel techniques: Multilingual Structured Synset Embeddings
  (MSSE) and Cross-Lingual Deep Neural Sentiment Propagation (CLDNS).'
---

# Deep Emotions Across Languages: A Novel Approach for Sentiment Propagation in Multilingual WordNets

## Quick Facts
- arXiv ID: 2312.04715
- Source URL: https://arxiv.org/abs/2312.04715
- Reference count: 40
- Primary result: MSSE+CLDNS significantly outperforms existing methods for cross-lingual sentiment propagation in WordNets

## Executive Summary
This paper addresses the challenge of automatic sentiment propagation in multilingual WordNets, where manual annotation is time-consuming and expensive. The authors introduce two novel techniques: Multilingual Structured Synset Embeddings (MSSE) and Cross-Lingual Deep Neural Sentiment Propagation (CLDNS). MSSE extends traditional embedding methods to capture multilingual semantics and structural information within WordNet graphs, while CLDNS uses deep neural networks to propagate sentiment annotations across languages. The evaluation using Princeton WordNet and Polish WordNet shows that the MSSE+CLDNS method significantly outperforms existing approaches, achieving improved precision, recall, and F1-scores across multiple sentiment dimensions.

## Method Summary
The approach combines two key innovations: MSSE creates embeddings from random walks on WordNet graphs, capturing structural and semantic relationships, while CLDNS uses deep neural networks to classify and propagate sentiment labels across languages. The method leverages the dense interlingual relations between Princeton WordNet and Polish WordNet to enable cross-lingual sentiment transfer. The pipeline involves generating MSSE embeddings from WordNet structure, training CLDNS classifiers on seed sentiment annotations, and iteratively propagating sentiment labels to unannotated nodes using nearest neighbor relationships.

## Key Results
- MSSE+CLDNS significantly outperforms existing propagation methods, achieving improved precision, recall, and F1-scores across multiple sentiment dimensions
- The method successfully propagates sentiment annotations from one language to another using interlingual WordNet relations
- Deep neural network configurations show superior performance compared to logistic regression baselines

## Why This Works (Mechanism)

### Mechanism 1
Multilingual embeddings trained from WordNet structure itself (MSSE) outperform pre-trained multilingual embeddings for cross-lingual sentiment propagation. MSSE creates an artificial corpus via random walks on WordNet graphs, capturing structural and semantic relationships within and across languages. Interlingual links between Princeton WordNet and Polish WordNet ensure aligned embeddings for corresponding synsets.

### Mechanism 2
Deep neural networks (CLDNS) outperform logistic regression for sentiment propagation across multilingual WordNets. CLDNS uses multiple hidden layers with dropout for regularization, learning complex non-linear mappings from structured embeddings to multi-dimensional sentiment labels.

### Mechanism 3
Cross-lingual propagation is effective when WordNets share dense interlingual relations, enabling sentiment transfer between languages. The Polish WordNet and Princeton WordNet share approximately 300k manually annotated interlingual relations. MSSE leverages these links during random walks, creating aligned embeddings that enable sentiment propagation from one language to another.

## Foundational Learning

- **Concept**: Graph-based random walks for embedding generation
  - Why needed here: MSSE relies on random walks through WordNet structure to create artificial training corpora that capture semantic relationships
  - Quick check question: How does the random walk length parameter affect the contextual information captured in MSSE embeddings?

- **Concept**: Multilingual alignment through interlingual links
  - Why needed here: Cross-lingual sentiment propagation requires embeddings that represent the same concepts across languages, achieved through WordNet interlingual relations
  - Quick check question: What happens to sentiment propagation accuracy when interlingual link density drops below a critical threshold?

- **Concept**: Deep neural network architectures for multi-label classification
  - Why needed here: Sentiment propagation involves predicting multiple emotional dimensions simultaneously, requiring models that can capture complex relationships between features and labels
  - Quick check question: Why does CLDNS use a linear activation function in the output layer rather than softmax?

## Architecture Onboarding

- **Component map**: WordNet Graph -> MSSE Embedding Generator -> CLDNS Classifier -> Iterative Propagation -> Evaluation Metrics
- **Critical path**: WordNet Graph → MSSE Embeddings → CLDNS Training → Iterative Propagation → Evaluation Metrics
- **Design tradeoffs**:
  - MSSE vs pre-trained embeddings: Training from scratch captures WordNet-specific structure but requires more computation
  - Deep vs Base CLDNS: More layers capture complex patterns but increase overfitting risk and training time
  - Random walk parameters: Longer walks capture broader context but may dilute local semantic relationships
- **Failure signatures**:
  - Poor precision/recall indicates either embedding quality issues or insufficient training data
  - High variance across folds suggests overfitting or unstable random walk sampling
  - Cross-lingual propagation failure indicates interlingual relation quality problems
- **First 3 experiments**:
  1. Train MSSE embeddings with varying random walk lengths (5, 10, 20 steps) and compare sentiment propagation performance
  2. Compare CLDNS Base vs Deep configurations on a small subset of data to assess overfitting risk
  3. Test propagation with different percentages of seed annotations (10%, 30%, 50%) to find minimum viable training data

## Open Questions the Paper Calls Out
None explicitly stated in the provided content.

## Limitations
- Evaluation limited to single language pair (English-Polish), limiting generalizability to other language combinations
- Interlingual link density (300k relations) appears unusually high, raising questions about scalability to language pairs with sparser connections
- Lack of ablation studies isolating contributions of MSSE embeddings, CLDNS architecture, and interlingual link quality

## Confidence
- **High**: MSSE captures structural information better than pre-trained embeddings
- **Medium**: CLDNS outperforms logistic regression for multi-label sentiment propagation
- **Medium**: Cross-lingual propagation effectiveness depends on interlingual relation density

## Next Checks
1. Test sentiment propagation performance across multiple language pairs with varying interlingual link densities to assess generalizability
2. Conduct ablation studies comparing MSSE embeddings with pre-trained multilingual embeddings while keeping CLDNS architecture constant
3. Evaluate performance with different seed annotation percentages to determine minimum viable training data requirements