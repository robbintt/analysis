---
ver: rpa2
title: Improving Factuality of Abstractive Summarization via Contrastive Reward Learning
arxiv_id: '2307.04507'
source_url: https://arxiv.org/abs/2307.04507
tags:
- factuality
- learning
- summarization
- contrastive
- metrics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a simple but effective contrastive learning
  framework that enables abstractive summarization models to learn from feedback of
  factuality metrics. Unlike other contrastive learning frameworks that require complex
  construction of negative samples, our framework directly utilizes candidate summaries
  generated from pre-trained models using diverse beam search.
---

# Improving Factuality of Abstractive Summarization via Contrastive Reward Learning

## Quick Facts
- arXiv ID: 2307.04507
- Source URL: https://arxiv.org/abs/2307.04507
- Reference count: 9
- Key outcome: Contrastive reward learning framework improves factuality of abstractive summarization without sacrificing coherence or relevance

## Executive Summary
This paper introduces a simple but effective contrastive learning framework that enables abstractive summarization models to learn from factuality metric feedback. Unlike complex negative sample construction methods, the approach uses diverse beam search to generate candidate summaries and incorporates quality metrics for fine-grained ranking. Empirical studies demonstrate that the proposed framework significantly improves factual consistency while maintaining coherence and relevance in generated summaries.

## Method Summary
The framework fine-tunes pre-trained summarization models (BART or PEGASUS) using a combined MLE and contrastive loss. Candidate summaries are generated using diverse beam search, then ranked by factuality metrics (BARTScore, DAE). The contrastive loss penalizes discrepancies between log-probability estimates and metric evaluations, with rank differences providing proportional penalties. The model is trained on CNN/Daily Mail or XSUM datasets with specific learning rates (1e-5 for CNNDM, 1e-4 for XSUM) and contrastive loss weight γ=100.

## Key Results
- CRL framework significantly improves factuality metrics (BARTScore, DAE) on CNNDM and XSUM datasets
- Human evaluation shows improved factuality without sacrificing coherence or relevance
- CRL-COM (B) achieves best performance on CNNDM with BERTScore F1 of 47.30 and improved factuality scores

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive reward learning improves factuality by directly aligning model gradients with factuality metric feedback
- Mechanism: The contrastive loss penalizes length-normalized log-probability discrepancies between summaries with different factuality scores
- Core assumption: Factuality metrics provide reliable signal about factual consistency that correlates with human judgment
- Evidence anchors: Empirical studies demonstrate learning from factuality metric feedback; contrastive loss penalizes dis-coordination between log-probability and quality metric evaluation
- Break condition: If factuality metrics become saturated or lose correlation with human judgment

### Mechanism 2
- Claim: Using diverse beam search for candidate generation provides rich positive and negative examples without manual negative sample construction
- Mechanism: Pre-trained models generate multiple candidate summaries using diverse beam search, creating quality variations for ranking
- Core assumption: Diverse beam search generates meaningful quality variations that factuality metrics can distinguish
- Evidence anchors: All candidate summaries generated from pretrained models using diverse beam search; contrast with complex negative sample construction methods
- Break condition: If diverse beam search fails to generate sufficiently varied candidates

### Mechanism 3
- Claim: Incorporating quality metrics in ranking provides more fine-grained contrastive signal than binary positive/negative separation
- Mechanism: Contrastive loss uses rank differences (λij = (j - i) × λ) to create proportional penalties based on candidate quality gaps
- Core assumption: Ordering of candidates by factuality metrics reflects gradations in factual consistency
- Evidence anchors: Framework incorporates quality metrics for fine-grained ranking information; rank difference provides proportional penalties
- Break condition: If factuality metrics provide noisy or inconsistent rankings

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: Framework relies on learning from pairs of candidate summaries with different factuality scores to improve factual consistency
  - Quick check question: How does the contrastive loss differ from standard cross-entropy loss in terms of what it optimizes for?

- Concept: Reinforcement learning and reward shaping
  - Why needed here: Approach uses factuality metrics as rewards to guide the summarization model, similar to RL but with contrastive optimization
  - Quick check question: What is the key difference between using rewards in reinforcement learning versus contrastive reward learning?

- Concept: Factuality evaluation metrics
  - Why needed here: Framework depends on reliable factuality metrics (BARTScore, DAE) to provide the learning signal for contrastive optimization
  - Quick check question: How do reference-free factuality metrics like BARTScore differ from reference-based metrics in their evaluation approach?

## Architecture Onboarding

- Component map: Pre-trained summarization model -> Factuality metrics (BARTScore, DAE) -> Contrastive loss module -> Fine-tuning pipeline

- Critical path: 1) Generate candidate summaries using diverse beam search 2) Score candidates with factuality metrics 3) Compute contrastive loss based on ranking 4) Backpropagate combined loss (MLE + contrastive) 5) Update model parameters

- Design tradeoffs:
  - Computational cost: Evaluating factuality metrics for many candidates increases computation vs standard fine-tuning
  - Metric dependence: Performance tied to reliability of chosen factuality metrics
  - Candidate diversity: Relies on diverse beam search to provide meaningful ranking signal

- Failure signatures:
  - Contrastive loss dominates and model loses generation quality
  - Factuality metrics provide inconsistent rankings leading to noisy gradients
  - Model overfits to factuality metrics at expense of coherence and relevance

- First 3 experiments:
  1. Run ablation study: Compare CRL-COM (B) vs CRL-COM (R) on CNNDM to verify factuality improvement
  2. Test candidate diversity: Vary beam width in diverse beam search and measure impact on contrastive signal quality
  3. Cross-metric evaluation: Fine-tune with BARTScore but evaluate with DAE to test metric generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective are other factuality metrics (e.g., QA-based or entailment-based metrics) in contrastive reward learning for abstractive summarization?
- Basis in paper: Paper discusses using BARTScore and DAE but mentions QA-based metrics are computationally inefficient
- Why unresolved: Only experiments with two specific factuality metrics without exploring other potential metrics
- What evidence would resolve it: Experiments comparing performance with different factuality metrics (QA-based, entailment-based)

### Open Question 2
- Question: How does the performance of contrastive reward learning compare to RL-based reward learning in improving the factuality of abstractive summarization models?
- Basis in paper: Paper mentions possibility of comparing RL-based and contrastive reward learning but doesn't conduct comparison
- Why unresolved: Focuses on contrastive reward learning without direct comparison to RL-based approaches
- What evidence would resolve it: Experiments comparing models fine-tuned with contrastive reward learning and RL-based reward learning using same factuality metrics

### Open Question 3
- Question: Can contrastive reward learning be effectively applied to non-news abstractive summarization datasets?
- Basis in paper: Experiments only on news-related CNNDM and XSUM datasets, mentions including more non-news datasets in future
- Why unresolved: Only evaluates framework on news-related datasets without exploring other types of summarization tasks
- What evidence would resolve it: Experiments applying contrastive reward learning to non-news datasets (scientific articles, books, movie reviews)

## Limitations
- Framework's performance fundamentally constrained by accuracy of factuality metrics
- Contrastive learning signal depends on diverse beam search generating meaningful quality variations
- High weight (γ=100) on contrastive loss may create optimization instability

## Confidence
- High confidence: CRL framework improves factuality metrics (BARTScore, DAE) on CNNDM and XSUM datasets
- Medium confidence: Approach maintains coherence and relevance while improving factuality (based on limited human evaluation samples)
- Medium confidence: Diverse beam search provides sufficient candidate diversity for effective contrastive learning

## Next Checks
1. **Metric robustness test**: Fine-tune using BARTScore rewards but evaluate with DAE (and vice versa) to assess whether improvements transfer across factuality metrics
2. **Candidate diversity analysis**: Systematically vary beam width in diverse beam search and measure the correlation between candidate diversity and contrastive learning effectiveness
3. **Human evaluation expansion**: Conduct comprehensive human evaluation (n=500+) across multiple dimensions to validate that coherence and relevance are maintained while factuality improves