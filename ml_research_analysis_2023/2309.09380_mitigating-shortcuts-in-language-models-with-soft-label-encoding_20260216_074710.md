---
ver: rpa2
title: Mitigating Shortcuts in Language Models with Soft Label Encoding
arxiv_id: '2309.09380'
source_url: https://arxiv.org/abs/2309.09380
tags:
- training
- debiasing
- label
- shortcut
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes SoftLE, a debiasing framework that improves
  out-of-distribution generalization of language models on natural language understanding
  tasks. The key idea is to reduce spurious correlations by modifying ground truth
  labels: a teacher model first quantifies each sample''s reliance on shortcuts via
  softmax confidence; a dummy class is then added to encode this shortcut degree,
  smoothing other label dimensions to generate soft labels for training a more robust
  student model.'
---

# Mitigating Shortcuts in Language Models with Soft Label Encoding

## Quick Facts
- arXiv ID: 2309.09380
- Source URL: https://arxiv.org/abs/2309.09380
- Reference count: 10
- Primary result: SoftLE improves out-of-distribution generalization in NLU tasks by reducing shortcut reliance through soft label encoding

## Executive Summary
This paper introduces SoftLE, a debiasing framework that addresses shortcut learning in language models by modifying ground truth labels. The method uses a teacher model to quantify each sample's reliance on spurious correlations via softmax confidence, then adds a dummy class to encode this shortcut degree. This transforms hard labels into soft labels that smooth out shortcut-related correlations, allowing a student model to learn more robust representations. Experiments on MNLI and FEVER tasks show significant improvements on out-of-distribution test sets while maintaining in-distribution accuracy, outperforming several baseline debiasing methods.

## Method Summary
SoftLE operates through a teacher-student framework where a fine-tuned teacher model first identifies shortcut-reliant samples using softmax confidence thresholds. For over-confident predictions (above threshold ξ), the method adds a dummy class to encode shortcut degree and transforms original labels from one-hot to smoothed form (1-si,j). The student model is then trained using a mixed loss strategy: hard label loss for initial epochs followed by soft label loss. This approach reduces the correlation between shortcut features and target labels while preserving semantic understanding, improving generalization to out-of-distribution data.

## Key Results
- SoftLE significantly improves out-of-distribution test performance on MNLI HANS and FEVER symmetric datasets
- The method maintains in-distribution accuracy while achieving debiasing gains
- SoftLE outperforms several baseline debiasing methods on both tasks
- Soft label encoding effectively reduces spurious correlation learning compared to hard labels

## Why This Works (Mechanism)

### Mechanism 1
Over-confident predictions from the teacher model indicate higher reliance on spurious correlations. When the teacher model achieves high softmax confidence (exceeding threshold ξ=0.9), it suggests the prediction relies heavily on shortcut features rather than semantic understanding. This works because samples using shortcut features will consistently yield higher confidence scores than samples requiring deeper reasoning.

### Mechanism 2
Smoothing labels based on shortcut degree reduces spurious correlation learning. By introducing a dummy class with value si,j (shortcut degree) and transforming original labels from one-hot to smoothed form (1-si,j), the method reduces the correlation between shortcut features and target labels. This forces the model to rely more on non-shortcut features by lowering the predictive probability given biased features.

### Mechanism 3
Alternating between hard and soft label losses during training achieves better balance. Using hard label loss (LHL) for initial epochs allows the model to establish basic task understanding, then switching to soft label loss (LSL) reduces shortcut reliance while preserving in-distribution performance. This prevents the model from becoming overly confident in shortcut-based predictions while maintaining task accuracy.

## Foundational Learning

- Concept: Softmax confidence as shortcut indicator
  - Why needed here: The method relies on softmax confidence from the teacher model to quantify shortcut reliance
  - Quick check question: How does softmax confidence differ between samples using shortcuts versus those requiring deeper reasoning?

- Concept: Knowledge distillation framework
  - Why needed here: SoftLE operates within a teacher-student paradigm where the teacher identifies biases and the student learns to avoid them
  - Quick check question: What distinguishes SoftLE's approach from traditional knowledge distillation?

- Concept: Label smoothing regularization
  - Why needed here: The method transforms hard labels into soft labels by reducing confidence on samples with high shortcut degrees
  - Quick check question: How does label smoothing typically affect model calibration and generalization?

## Architecture Onboarding

- Component map: Teacher model (fine-tuned on NLU task) → Shortcut degree calculator (softmax confidence threshold) → Soft label encoder (dummy class addition and smoothing) → Student model (trained with mixed loss)
- Critical path: Teacher model training → Confidence thresholding → Label transformation → Student model training → Inference (ignoring dummy class)
- Design tradeoffs: Higher threshold ξ reduces false positives but may miss subtle shortcuts; earlier loss switching preserves ID performance but may reduce OOD gains
- Failure signatures: ID performance drops significantly; OOD performance doesn't improve; training instability with mixed losses
- First 3 experiments:
  1. Verify teacher model confidence distribution differs between ID and OOD sets
  2. Test label smoothing impact on model calibration without dummy class
  3. Compare performance with fixed hard labels versus alternating hard/soft label strategy

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of the threshold value ξ affect the debiasing performance of SoftLE? The paper only mentions that a value of 0.9 was chosen and that changing it slightly did not significantly affect the results, but doesn't provide a detailed analysis of how different threshold values impact performance.

### Open Question 2
Can SoftLE be extended to more NLU tasks and additional types of LLMs beyond BERT and RoBERTa? The paper mentions plans to extend the framework but doesn't provide experimental results or analysis on effectiveness for other NLU tasks or LLMs.

### Open Question 3
How does the hyperparameter tuning of α and β affect the debiasing performance of SoftLE? The paper mentions chosen values (α = 1.48, β = 0.2) but doesn't provide a systematic study of how different values affect debiasing performance.

## Limitations
- The method's effectiveness depends heavily on accurate shortcut degree quantification, which may not generalize across different model architectures or tasks
- The teacher-student framework requires training two separate models, increasing computational cost and potential failure points
- The specific threshold values and hyperparameters appear arbitrary and may require task-specific tuning

## Confidence

- **High Confidence**: SoftLE improves OOD performance while maintaining ID accuracy (well-supported by experimental results on MNLI and FEVER)
- **Medium Confidence**: Softmax confidence from teacher model reliably indicates shortcut reliance (moderate support, needs more extensive validation)
- **Low Confidence**: Specific mechanism by which dummy class and label smoothing reduce shortcut learning (limited detailed analysis of optimal formulation)

## Next Checks

1. Test SoftLE on additional NLU tasks beyond MNLI and FEVER to verify generalization across different types of language understanding tasks and whether threshold values need task-specific tuning.

2. Evaluate whether different teacher model architectures (e.g., RoBERTa, DeBERTa) produce similar confidence patterns for shortcut samples to establish method's robustness to teacher model quality.

3. Conduct a comprehensive ablation study removing individual components (dummy class, label smoothing, hard-to-soft loss switching) to quantify their individual contributions and identify essential versus complementary components.