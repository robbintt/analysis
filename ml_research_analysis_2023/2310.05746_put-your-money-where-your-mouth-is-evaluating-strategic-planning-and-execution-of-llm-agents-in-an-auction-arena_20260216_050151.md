---
ver: rpa2
title: 'Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution
  of LLM Agents in an Auction Arena'
arxiv_id: '2310.05746'
source_url: https://arxiv.org/abs/2310.05746
tags:
- item
- bidder
- items
- agents
- bidding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AUCARENA, a novel simulation environment
  for evaluating LLM agents in auctions. The authors design bidder agents based on
  the Belief-Desire-Intention model and use LLMs to power their planning, bidding,
  and replanning functions.
---

# Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena

## Quick Facts
- arXiv ID: 2310.05746
- Source URL: https://arxiv.org/abs/2310.05746
- Reference count: 40
- Primary result: LLM agents demonstrate auction planning and execution skills, with GPT-4 outperforming others but still occasionally surpassed by heuristics and humans

## Executive Summary
This paper introduces AUCARENA, a novel simulation environment for evaluating LLM agents in auctions. The authors design bidder agents based on the Belief-Desire-Intention model and use LLMs to power their planning, bidding, and replanning functions. Experiments show that LLM agents demonstrate many skills needed for effective auction participation, such as budget management and goal adherence, which improve with adaptive strategies. GPT-4 outperforms other LLMs, but even it is occasionally surpassed by heuristic baselines and human agents. The authors also observe niche separation behavior among agents with different objectives. AUCARENA provides a valuable test-bed for further research on LLM agents in dynamic, competitive environments.

## Method Summary
The paper develops AUCARENA, an auction simulation environment where LLM agents use a Belief-Desire-Intention architecture to plan, bid, update beliefs, and replan in response to auction dynamics. Agents are implemented using zero-shot prompting across four key functions, with performance evaluated across 30 runs per experiment. The environment features open ascending-price auctions with items valued at $2,000 and $10,000, testing agents' ability to manage budgets, follow plans, and adapt strategies. Performance metrics include failed bid rates, belief error rates, Spearman correlation between priorities and actions, total profit, and TrueSkill scores.

## Key Results
- LLM agents show effective budget management and goal adherence in auctions
- Adaptive planning improves performance over static or no planning strategies
- GPT-4 outperforms other LLMs but can be surpassed by heuristic baselines and human agents
- Niche separation emerges among agents with different objectives in multi-agent settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The BDI (Belief-Desire-Intention) agent architecture enables structured reasoning in auction environments
- Mechanism: The BDI model provides a systematic framework where agents maintain beliefs about auction state, form intentions through planning, and update beliefs based on auction outcomes to refine future intentions
- Core assumption: LLMs can maintain coherent belief states and translate them into actionable plans through structured prompting
- Evidence anchors:
  - [section]: "This model offers a structured way of understanding how bidders strategize, react to new information, and adjust their plans."
  - [abstract]: "We develop a bidder agent architecture that enables LLMs to skillfully strategize, execute, and modify their plans in response to the environment"
- Break condition: If LLM context windows are insufficient to maintain coherent belief states across auction rounds, or if belief updates become inconsistent with auction reality

### Mechanism 2
- Claim: Adaptive planning significantly improves auction performance compared to static or no planning
- Mechanism: Agents that update their priority scores and bidding strategies after each round can respond to changing competitive dynamics, while static planners remain locked into suboptimal initial strategies
- Core assumption: Auction dynamics are sufficiently unpredictable that initial plans become obsolete, requiring real-time adaptation
- Evidence anchors:
  - [section]: "An important characteristic of AUCARENA is its dynamics and ever-changing nature, making earlier agent plans prone to becoming outdated"
  - [section]: "We observe a consistent trend that having a plan uniformly benefits all and updating the plans can further improve the performance"
- Break condition: If auction environments are sufficiently predictable that static strategies perform as well as adaptive ones, or if replanning introduces more errors than benefits

### Mechanism 3
- Claim: Niche separation emerges in multi-agent auctions with different objectives
- Mechanism: When agents have heterogeneous goals (profit maximization vs item acquisition), they naturally specialize in different market segments, reducing direct competition and improving overall efficiency
- Core assumption: Different objectives create divergent utility functions that can be satisfied by targeting different items or bidding strategies
- Evidence anchors:
  - [section]: "Each group starts to find its own niche, i.e., growing dominance over cheap or expensive items"
  - [abstract]: "We uncover new dynamics of niche separation in diverse multi-agent scenarios"
- Break condition: If objective heterogeneity doesn't create meaningful strategic differentiation, or if budget constraints force all agents to compete for the same high-value items

## Foundational Learning

- Concept: Belief-Desire-Intention agent architecture
  - Why needed here: Provides the conceptual framework for structuring LLM reasoning about auctions, enabling systematic belief tracking and plan updating
  - Quick check question: What are the three core components of BDI architecture and how do they map to auction decision-making?

- Concept: Spearman correlation for plan-execution alignment
  - Why needed here: Quantifies whether agents' actual bidding behavior aligns with their stated priorities, providing objective measure of plan-following
  - Quick check question: If an agent assigns high priority to expensive items but consistently wins cheap ones, what would the Spearman correlation indicate?

- Concept: TrueSkill rating system
  - Why needed here: Provides Bayesian skill estimation for comparing agent performance in competitive auctions while accounting for uncertainty
  - Quick check question: How does TrueSkill differ from simple win/loss records when comparing agents with limited head-to-head matchups?

## Architecture Onboarding

- Component map: LLM prompt interface → BDI state manager → Auction environment → Performance metrics → Learning module
- Critical path: Planning → Bidding → Belief Update → Replanning → Auction progression
- Design tradeoffs: Context window limitations vs. comprehensive belief tracking; prompt complexity vs. LLM reliability; adaptation frequency vs. replanning errors
- Failure signatures: Belief errors manifest as budget miscalculations or item ownership confusion; plan-following failures show as random bidding; adaptation failures appear as static strategies despite changing conditions
- First 3 experiments:
  1. Compare CFR (corrected failure rate) across different LLM models with identical planning instructions
  2. Test Spearman correlation between stated priorities and actual bidding outcomes under static vs adaptive planning
  3. Measure TrueSkill score progression for agents with different budget levels in intraspecific competition

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can LLM agents be designed to effectively negotiate and collaborate with other bidders in auctions, while also being able to detect and respond to deceptive or malicious strategies?
- Basis in paper: [inferred] The paper mentions the potential for bidders to have malicious desires, such as deliberately elevating the bidding war to make others pay more. It also suggests that the ability to detect shill bidders would test the Theory-of-Mind abilities of autonomous agents.
- Why unresolved: The paper does not explore negotiation and collaboration between bidders, nor does it investigate the ability of LLM agents to detect and respond to deceptive strategies.
- What evidence would resolve it: Experiments demonstrating LLM agents' ability to negotiate and collaborate with other bidders, as well as their ability to detect and respond to deceptive or malicious strategies in auctions.

### Open Question 2
- Question: Can LLM agents learn from past auction experiences and develop novel bidding strategies that outperform human-designed strategies?
- Basis in paper: [explicit] The paper mentions the potential for LLM agents to learn from previous auction experiences and discover novel bidding strategies. It also notes that humans can learn from past auctions and improve their strategies.
- Why unresolved: The paper only explores a simple learning mechanism for GPT-4, which shows some improvement but not consistently. It does not investigate the potential for LLM agents to develop novel strategies that surpass human-designed ones.
- What evidence would resolve it: Experiments demonstrating LLM agents' ability to learn from past auctions and develop novel bidding strategies that outperform human-designed strategies.

### Open Question 3
- Question: How can the auction simulation environment be extended to include diverse item values, different bidder desires, and autonomous seller agents, to create a more realistic and challenging setting for LLM agents?
- Basis in paper: [explicit] The paper discusses several ways to extend the auction simulation environment, such as introducing diverse item values, different bidder desires, and autonomous seller agents. It also mentions the potential for life-long learning for LLM agents.
- Why unresolved: The paper keeps the simulation simple and controllable for better understanding and evaluation of LLM agents. It does not explore the more complex and realistic settings that could be created by extending the environment.
- What evidence would resolve it: Experiments demonstrating LLM agents' performance and strategic abilities in more complex and realistic auction simulation environments that include diverse item values, different bidder desires, and autonomous seller agents.

## Limitations

- Results are based on simplified auction simulations that may not capture real-world complexities
- Performance depends heavily on prompt engineering quality and may not generalize across domains
- GPT-4's superior performance may reflect its general capabilities rather than auction-specific optimization

## Confidence

- **High confidence**: LLM agents can follow plans and update strategies in structured auction environments (supported by quantitative metrics like Spearman correlation and CFR)
- **Medium confidence**: GPT-4 outperforms other LLMs in auction settings (consistent across experiments but limited to specific auction types)
- **Low confidence**: Niche separation emerges as a fundamental property of multi-agent auctions (observed in controlled experiments but may be environment-specific)

## Next Checks

1. Test agent performance when auction parameters are systematically varied (item value distributions, budget constraints, number of participants) to identify breaking points
2. Implement a blind evaluation where human experts assess agent decision quality without knowing which system generated the bids
3. Create a transfer learning experiment where agents trained in AUCARENA are evaluated on real auction datasets to measure practical applicability