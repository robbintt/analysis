---
ver: rpa2
title: Towards Trustworthy Dataset Distillation
arxiv_id: '2307.09165'
source_url: https://arxiv.org/abs/2307.09165
tags:
- dataset
- trustdd
- detection
- performance
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes Trustworthy Dataset Distillation (TrustDD),
  which addresses the problem of dataset distillation (DD) being limited to in-distribution
  (InD) classification without considering out-of-distribution (OOD) detection. TrustDD
  distills both InD samples and outliers into a tiny dataset to train models that
  are competent in both InD classification and OOD detection.
---

# Towards Trustworthy Dataset Distillation

## Quick Facts
- arXiv ID: 2307.09165
- Source URL: https://arxiv.org/abs/2307.09165
- Reference count: 40
- Key outcome: Proposes TrustDD to distill both in-distribution and pseudo-outlier data for models competent in both InD classification and OOD detection.

## Executive Summary
This paper addresses the limitation of dataset distillation (DD) being confined to in-distribution (InD) classification by proposing Trustworthy Dataset Distillation (TrustDD). TrustDD distills both InD samples and outliers into a tiny dataset to train models that excel in both InD classification and out-of-distribution (OOD) detection. To eliminate the need for real outlier data, the authors introduce Pseudo-Outlier Exposure (POE), which generates pseudo-outliers by corrupting InD samples. Experiments demonstrate that TrustDD with POE significantly improves OOD detection performance without sacrificing InD classification accuracy.

## Method Summary
TrustDD extends dataset distillation by incorporating both InD classification and OOD detection into the objective. It distills a large dataset T into a tiny synthetic dataset S = Sin + Sout, where Sin contains InD samples and Sout contains pseudo-outliers generated by corrupting InD samples. The framework uses integrated loss functions LT and LS for InD classification and OOD detection. POE generates pseudo-outliers through corruption transformations (jigsaw, invert, mosaic, speckle) applied to InD samples, eliminating the need for real outlier datasets. This approach makes DD more trustworthy and applicable to open-world scenarios.

## Key Results
- TrustDD with POE achieves superior OOD detection performance compared to state-of-the-art Outlier Exposure (OE) methods.
- The distilled dataset enables models to maintain high InD classification accuracy while significantly improving OOD detection capabilities.
- TrustDD demonstrates good cross-architecture generalization across ConvNet, AlexNet, VGG, and ResNet models.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TrustDD improves OOD detection by distilling both in-distribution and pseudo-outlier data into a tiny synthetic dataset.
- Mechanism: By extending dataset distillation to include OOD detection loss, the distilled dataset provides richer information for training models competent in both tasks. The bi-level optimization ensures model parameters minimize both InD classification loss and OOD detection loss.
- Core assumption: Information about OOD samples can be effectively captured and distilled from the original dataset or through appropriate corruption of InD samples.
- Evidence anchors: Abstract states the condensed datasets are capable of training models competent in both InD classification and OOD detection.
- Break condition: If pseudo-outliers don't effectively represent OOD samples or the distilled dataset becomes too small to retain sufficient information.

### Mechanism 2
- Claim: POE surpasses OE by generating pseudo-outliers through InD corruption, eliminating the need for real outlier data.
- Mechanism: POE applies corruption transformations to InD samples to create pseudo-outliers with semantic shifts. By maximizing output uncertainty of these pseudo-outliers, the model learns to generalize better to unseen OOD samples.
- Core assumption: Corrupted InD samples can effectively simulate OOD samples with appropriate semantic distance.
- Evidence anchors: Abstract mentions POE generates pseudo-outliers from in-distribution data to relax the requirement for auxiliary outlier datasets.
- Break condition: If corruption transformations don't create meaningful semantic shifts or pseudo-outliers are too easily distinguishable from real OOD samples.

### Mechanism 3
- Claim: TrustDD with POE is more applicable to real-world scenarios by eliminating the need for curated outlier datasets.
- Mechanism: TrustDD provides a general framework that can be applied to various matching-based DD methods by adding the OOD detection loss term. POE further enhances this by generating pseudo-outliers from InD data.
- Core assumption: The additional computational cost is outweighed by the benefits of improved trustworthiness and broader applicability.
- Evidence anchors: Abstract states TrustDD is more trustworthy and applicable to open-world scenarios compared to preceding DD.
- Break condition: If computational overhead becomes prohibitive or improved trustworthiness doesn't translate to meaningful real-world performance gains.

## Foundational Learning

- Concept: Dataset Distillation (DD)
  - Why needed here: DD is the foundation upon which TrustDD is built. Understanding DD is crucial for grasping how TrustDD extends it to handle both InD classification and OOD detection.
  - Quick check question: What is the primary goal of dataset distillation, and how does it differ from traditional data compression techniques?

- Concept: Out-of-Distribution (OOD) Detection
  - Why needed here: OOD detection is the other key component of TrustDD. Understanding the challenges of OOD detection and the limitations of existing methods is essential to appreciate TrustDD's contribution.
  - Quick check question: What are the main challenges in OOD detection, and why is it difficult to achieve high performance without labeled outlier data?

- Concept: Meta-learning and Bi-level Optimization
  - Why needed here: The formulation of TrustDD involves a bi-level optimization problem, similar to some DD methods. Understanding meta-learning concepts helps in understanding the optimization process.
  - Quick check question: What is bi-level optimization, and how is it used in the context of dataset distillation?

## Architecture Onboarding

- Component map: TrustDD framework -> POE pseudo-outlier generation -> Matching-based DD methods (DSA, MTT) -> OOD detection scores (MSP, MLS, Energy)
- Critical path: 1) Prepare original dataset with InD samples and optional real outlier data, 2) Generate pseudo-outliers using POE if real outlier data unavailable, 3) Implement TrustDD framework by modifying DD method to include OOD detection loss, 4) Distill dataset using modified DD method, 5) Train model on distilled dataset, 6) Evaluate on InD classification and OOD detection tasks
- Design tradeoffs: Size of distilled dataset (balancing Sin and Sout), number and type of corruption transformations, trade-off weight Î» balancing InD classification and OOD detection importance
- Failure signatures: Poor OOD detection performance (pseudo-outliers not representative), degradation in InD classification (OOD loss too dominant), computational infeasibility (dataset size or transformations too large)
- First 3 experiments: 1) Implement TrustDD with simple DD method (DSA) on CIFAR-10 with 10 IPC to validate basic functionality, 2) Compare TrustDD with POE against baseline DD and OE on CIFAR-100 to assess POE effectiveness, 3) Evaluate cross-architecture generalization by training different architectures on distilled dataset and comparing performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does TrustDD with POE generalize to more complex architectures like transformers or larger-scale models?
- Basis in paper: The paper mentions cross-architecture generalization experiments on smaller networks (ConvNet, AlexNet, VGG, ResNet), but does not explore transformers or very large models.
- Why unresolved: The paper only tests on relatively small-scale architectures, leaving the scalability of TrustDD to larger, more complex models unexplored.
- What evidence would resolve it: Experiments demonstrating TrustDD's performance on transformers or very large-scale models, showing consistent improvements in OOD detection without sacrificing InD accuracy.

### Open Question 2
- Question: What is the impact of different outlier corruption techniques on the effectiveness of POE?
- Basis in paper: The paper mentions using jigsaw, invert, mosaic, and speckle as corruption transformations, but does not explore other potential techniques or combinations.
- Why unresolved: The paper only uses a specific set of corruption techniques, leaving the exploration of other methods or combinations unexplored.
- What evidence would resolve it: Experiments testing various outlier corruption techniques and combinations, showing their impact on the effectiveness of POE in improving OOD detection.

### Open Question 3
- Question: How does TrustDD perform in real-world scenarios with noisy or incomplete data?
- Basis in paper: The paper focuses on synthetic datasets and controlled experiments, without addressing real-world scenarios with noisy or incomplete data.
- Why unresolved: The paper does not explore the performance of TrustDD in real-world scenarios with noisy or incomplete data, which is crucial for practical applications.
- What evidence would resolve it: Experiments testing TrustDD on real-world datasets with varying levels of noise or incompleteness, showing its robustness and effectiveness in such scenarios.

## Limitations

- The effectiveness of pseudo-outliers in truly representing OOD samples needs further validation across diverse datasets and scenarios.
- The computational overhead of generating pseudo-outliers and training on both InD and OOD tasks may limit practical applicability in resource-constrained settings.
- The generalizability of TrustDD across different network architectures and OOD detection scores is claimed but not thoroughly validated for very large or complex models.

## Confidence

- High: The core concept of extending dataset distillation to include OOD detection is well-founded and builds on established techniques.
- Medium: The effectiveness of POE in generating representative pseudo-outliers and its superiority over OE requires more extensive empirical validation.
- Low: The generalizability of TrustDD across different network architectures and OOD detection scores is claimed but not thoroughly validated in the paper.

## Next Checks

1. Conduct a comprehensive ablation study to assess the impact of different corruption transformations and their parameters on OOD detection performance.
2. Evaluate TrustDD with POE on a wider range of OOD detection scores and network architectures to validate its generalizability claims.
3. Compare the computational cost and performance trade-offs of TrustDD with POE against other OOD detection methods that do not rely on dataset distillation.