---
ver: rpa2
title: Assessing Systematic Weaknesses of DNNs using Counterfactuals
arxiv_id: '2308.01614'
source_url: https://arxiv.org/abs/2308.01614
tags:
- data
- performance
- semantic
- asset
- counterfactual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of identifying systematic weaknesses
  in deep neural networks (DNNs) for safety-critical applications, specifically focusing
  on semantic segmentation in autonomous driving. The authors propose a counterfactual-based
  algorithm to validate whether performance differences between semantically distinguished
  subsets can be attributed to the identified attribute or other unmeasured factors.
---

# Assessing Systematic Weaknesses of DNNs using Counterfactuals

## Quick Facts
- **arXiv ID:** 2308.01614
- **Source URL:** https://arxiv.org/abs/2308.01614
- **Reference count:** 18
- **Primary result:** Counterfactual-based method identifies which semantic features genuinely cause performance weaknesses in DNNs, revealing that some assets appear weak due to other semantic properties rather than the asset type itself.

## Executive Summary
This work addresses the critical challenge of identifying systematic weaknesses in deep neural networks for safety-critical applications like autonomous driving. The authors propose a counterfactual-based algorithm that goes beyond simple performance metrics by determining whether performance differences between semantically distinguished subsets can be attributed to the identified attribute or other unmeasured factors. Using synthetic data from the CARLA simulator with detailed pedestrian metadata, they analyze DeepLabv3+ performance across different pedestrian assets. The method reveals that while performance differences exist among assets, only some can be attributed to the asset type itself. For instance, the performance gap for asset 23 is likely due to its membership, whereas for asset 9, the weakness stems from other semantic properties. This approach enables more precise identification of root causes, guiding targeted data generation for improvement and demonstrating the utility of counterfactual reasoning in systematically evaluating and mitigating DNN weaknesses.

## Method Summary
The method uses a counterfactual-based algorithm to validate whether performance differences between semantically distinguished subsets can be attributed to the identified attribute or other unmeasured factors. It pairs elements from two subsets based on similarity across all semantic features except the distinguishing attribute, then calculates performance differences between these pairs. The approach uses synthetic data from CARLA simulator with detailed pedestrian metadata and a pre-trained DeepLabv3+ model with per-pedestrian IoU scores. The counterfactual difference metric compares performance of semantically similar pairs to determine if the semantic-feature-under-test is the true cause of weakness or if other semantic properties are responsible.

## Key Results
- The method successfully distinguishes between asset-specific weaknesses and weaknesses due to other semantic properties, as demonstrated with DeepLabv3+ on CARLA pedestrian segmentation.
- For asset 23, the large conventional performance difference is maintained in counterfactual analysis, indicating the asset type itself causes weakness; for asset 9, the counterfactual difference is much smaller, suggesting other semantic properties are responsible.
- The approach identifies residual subsets where nearest neighbor matching fails, which are likely to contain the true causal factors for performance differences.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Counterfactual pairing reduces the influence of non-tested semantic dimensions on performance differences
- Mechanism: By finding nearest neighbors in the n-1 dimensional space (excluding the semantic-feature-under-test), the method isolates the tested feature's effect by controlling for other semantic dimensions through similarity matching
- Core assumption: Semantic dimensions are sufficiently expressive to predict performance, and nearest neighbor matching in semantic space correlates with performance similarity
- Evidence anchors:
  - [abstract] "we pair the elements of X only to those elements in Y, which are most similar w.r.t. all other known attributes"
  - [section] "Figure 1: Left: The histogram depicting the difference in performance for samples between two datasets using three matching techniques"
  - [corpus] Weak - corpus neighbors don't directly address the mechanism, though they mention related concepts like "systematic weaknesses" and "counterfactual explanations"
- Break condition: When semantic dimensions don't capture relevant performance-influencing factors, or when nearest neighbor matching fails to find truly similar samples due to high-dimensional sparsity

### Mechanism 2
- Claim: Performance differences between semantically similar pairs reveal true systematic weaknesses
- Mechanism: The counterfactual difference metric compares performance of semantically similar pairs; if this difference is much smaller than the conventional difference, the semantic-feature-under-test is not the true cause of weakness
- Core assumption: Large performance differences between semantically similar samples indicate that the tested semantic feature is not the root cause
- Evidence anchors:
  - [abstract] "only in some cases is the asset type itself the reason for this reduction in the performance"
  - [section] "Table 1: For different X, Y combinations, the difference in mean performance using the conventional, random, and nearest neighbor pairing is shown"
  - [corpus] Weak - corpus neighbors don't directly address this mechanism, though they mention "systematic weaknesses" which is related
- Break condition: When semantic similarity doesn't correlate with performance similarity, or when the tested semantic feature genuinely interacts with other features in complex ways

### Mechanism 3
- Claim: Residual subsets help identify true causal factors by isolating samples where nearest neighbor matching fails
- Mechanism: Samples that cannot be paired with sufficiently similar neighbors likely contain the true causal factors for performance differences; these residual sets can be analyzed further
- Core assumption: Samples that cannot be matched to semantically similar counterparts are more likely to contain the true causal factors for performance differences
- Evidence anchors:
  - [abstract] "If not, the method allows for identifying semantic subsets of X or Y, respectively, that are likely to contain the true cause of the performance gap"
  - [section] "Table 2: The average performance of residual and nearest neighbor subsets of Y"
  - [corpus] Weak - corpus neighbors don't directly address this mechanism, though they mention "systematic weaknesses" which is related
- Break condition: When semantic similarity is too coarse to identify meaningful residual subsets, or when the true causal factors are not captured by any semantic dimension

## Foundational Learning

- Concept: Semantic feature space and distance metrics
  - Why needed here: The algorithm relies on calculating distances between samples across multiple semantic dimensions to find nearest neighbors
  - Quick check question: How would you calculate the distance between two samples with mixed categorical (one-hot encoded) and numerical semantic features?

- Concept: Counterfactual reasoning and its application to model evaluation
  - Why needed here: The method is inspired by counterfactual explanations but adapted for performance evaluation rather than decision explanation
  - Quick check question: What's the key difference between using counterfactuals for explaining individual predictions versus using them to identify systematic model weaknesses?

- Concept: Performance metrics for semantic segmentation
  - Why needed here: The method uses Intersection-over-Union (IoU) as the performance metric, which is standard for semantic segmentation tasks
  - Quick check question: How does IoU differ from accuracy in semantic segmentation, and why is it more appropriate for this task?

## Architecture Onboarding

- Component map: Data preprocessing pipeline (metadata extraction, normalization) -> Semantic feature distance calculator (with configurable metrics) -> Counterfactual pair matcher (ball-tree or brute-force implementation) -> Performance difference calculator (conventional vs counterfactual) -> Residual subset extractor -> Visualization components for results interpretation

- Critical path: Data preprocessing → Counterfactual pair matching → Performance difference calculation → Residual subset extraction → Analysis

- Design tradeoffs:
  - Ball-tree vs brute-force nearest neighbor search (efficiency vs memory)
  - Choice of semantic features to include in distance calculation
  - Threshold τ for accepting counterfactual pairs
  - Handling of categorical vs numerical features in distance metric

- Failure signatures:
  - Counterfactual and conventional differences are similar for all tested features (method not working)
  - Very few samples can be paired (semantic space too sparse or τ too strict)
  - Residual subsets are too small to analyze (semantic features too discriminative)

- First 3 experiments:
  1. Test the expressiveness of semantic features by comparing σ[Acf] for increasing numbers of features
  2. Validate the method on a synthetic dataset with known systematic weaknesses
  3. Apply the method to identify weaknesses in a new semantic feature (e.g., pedestrian visibility) and compare results with conventional analysis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of τ (distance threshold) impact the validity and reliability of counterfactual analysis in identifying systematic weaknesses?
- Basis in paper: [explicit] The paper mentions τ is chosen as 0.2 but does not systematically evaluate its impact on results.
- Why unresolved: The paper does not explore how varying τ affects the ability to correctly attribute performance differences to specific semantic features.
- What evidence would resolve it: Systematic experiments varying τ values and measuring their effect on false positive/negative rates in identifying true systematic weaknesses.

### Open Question 2
- Question: Can the counterfactual method be extended to handle higher-order interactions between semantic features without computational explosion?
- Basis in paper: [inferred] The paper acknowledges that considering all attribute interactions leads to "combinatorial explosion" but doesn't propose solutions.
- Why unresolved: The current method only considers one semantic feature at a time (the "semantic-feature-under-test") while excluding others from the distance metric.
- What evidence would resolve it: Development and demonstration of a method that can efficiently handle multi-feature interactions while maintaining computational feasibility.

### Open Question 3
- Question: How does the performance of counterfactual analysis differ between synthetic and real-world data with varying levels of metadata completeness?
- Basis in paper: [explicit] The method is demonstrated on highly-annotated synthetic data from CARLA, with the authors noting challenges of obtaining metadata for unstructured real-world data.
- Why unresolved: The paper doesn't validate whether the approach generalizes to real-world scenarios where metadata may be incomplete or noisy.
- What evidence would resolve it: Comparative studies applying the method to both synthetic and real-world datasets with different levels of semantic annotation quality.

## Limitations
- The method's effectiveness depends heavily on the expressiveness of available semantic features, which may be limited in real-world datasets.
- The choice of distance metric and threshold τ for pairing introduces additional uncertainty, as these parameters were tuned for this specific dataset and may not generalize.
- The study focuses on pedestrian segmentation in autonomous driving, limiting generalizability to other domains or tasks.

## Confidence

- **High Confidence**: The core mechanism of using counterfactual pairs to control for confounding semantic factors is theoretically sound and validated through the synthetic CARLA dataset.
- **Medium Confidence**: The specific numerical results (performance differences, residual subset analyses) are likely accurate for the tested configuration but may vary with different datasets or model architectures.
- **Low Confidence**: Generalization of the method to real-world data without comprehensive metadata, and the robustness of findings across different semantic segmentation models.

## Next Checks

1. **Expressiveness Validation**: Test the method on synthetic data with known systematic weaknesses, varying the number and type of semantic features to quantify the minimum expressiveness required for reliable results.

2. **Real-world Application**: Apply the approach to a real autonomous driving dataset with partial metadata to assess performance degradation and identify which semantic features are most critical for reliable counterfactual matching.

3. **Cross-model Consistency**: Validate whether the identified systematic weaknesses persist across different semantic segmentation architectures (e.g., SegFormer, EfficientPS) to distinguish between model-specific and dataset-specific vulnerabilities.