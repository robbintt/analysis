---
ver: rpa2
title: Control in Hybrid Chatbots
arxiv_id: '2311.11701'
source_url: https://arxiv.org/abs/2311.11701
tags:
- control
- system
- language
- chatbot
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This technical report addresses the challenge of maintaining control
  over chatbot responses to avoid "hallucinations" and ensure factual accuracy. The
  authors propose a hybrid approach combining a commercial rule engine with an integrated
  neural language model.
---

# Control in Hybrid Chatbots

## Quick Facts
- arXiv ID: 2311.11701
- Source URL: https://arxiv.org/abs/2311.11701
- Reference count: 30
- Primary result: A hybrid chatbot platform combining rule-based and neural language models to maintain control and avoid hallucinations through configurable retrieval and generation strategies

## Executive Summary
This technical report introduces a hybrid chatbot architecture designed to maintain control over responses and prevent hallucinations in customer-facing applications. The Kauz platform combines a commercial rule engine with an integrated neural language model, using Retrieval-Augmented Generation (RAG) as a foundational paradigm. The system offers a spectrum of operational models ranging from maximum control (rule-based Q&A) to lower control (standard prompt with LLM), enabling fine-tuning based on specific use cases and the tradeoff between control and eloquence.

## Method Summary
The Kauz platform uses RAG as a paradigm where company documents are retrieved and used to augment queries before generation. The system allows configurable weights for metadata versus text in retrieval, supports dynamic prompting based on context, and can suppress generation for sensitive information. Documents can be tagged with metadata or annotated with domain-specific labels, and the retrieval system can be configured to weigh these elements differently to filter the answer space effectively.

## Key Results
- Retrieval-Augmented Generation (RAG) reduces hallucination by sourcing answers from company-provided documents rather than pre-training data
- Metadata and annotations in retrieval allow for more precise control over the knowledge base used for generation
- Selective suppression of generation for sensitive information provides an additional control layer beyond retrieval

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RAG reduces hallucination by forcing the model to source answers from company-provided documents
- Mechanism: Query is used to retrieve relevant documents from a controlled corpus via vector search, then retrieved snippets are appended to the original query before being passed to the LLM
- Core assumption: Retrieved documents are relevant, accurate, and sufficient to answer the user's question
- Evidence anchors: [abstract] "The starting point for all approaches is the use of Retrieval-Augmented Generation (RAG) as a paradigm"

### Mechanism 2
- Claim: Metadata and annotations in retrieval allow for more precise control over the knowledge base
- Mechanism: Documents can be tagged with metadata or annotated with domain-specific labels, and retrieval can be configured to weigh metadata vs. document text differently
- Core assumption: Metadata and annotations are comprehensive, accurate, and maintained consistently
- Evidence anchors: [abstract] "Key methods include using metadata and annotations for retrieval, configurable weights for metadata versus text"

### Mechanism 3
- Claim: Selective suppression of generation for sensitive information provides additional control
- Mechanism: System can be configured to bypass LLM generation for certain topics, providing pre-written responses or deflecting to human agents
- Core assumption: System can accurately classify which queries require this level of control
- Evidence anchors: [abstract] "The option to suppress generation for sensitive information"

## Foundational Learning

- Concept: Vector Space Model for Retrieval
  - Why needed here: Kauz platform uses vector-based search by an LLM as one retrieval method
  - Quick check question: How does the choice of embedding model affect the relevance of retrieved documents?

- Concept: Rule-Based NLU vs. Statistical NLU
  - Why needed here: Kauz NLU Engine is rule-based and maintains confidence levels for matches
  - Quick check question: What are the advantages and disadvantages of rule-based NLU for maintaining control over chatbot responses?

- Concept: Confidence Calibration in Hybrid Systems
  - Why needed here: System can be configured to invoke LLM only when NLU Engine hasn't found conclusive information
  - Quick check question: How would you tune the threshold for invoking the LLM to minimize hallucination while maintaining response coverage?

## Architecture Onboarding

- Component map: CMS -> NLU Engine -> LLM Manager -> Conversation Manager -> Frontend
- Critical path: User query → NLU Engine (optional) → Retrieval (text and/or metadata) → LLM Manager (optional, based on config) → Response
- Design tradeoffs:
  - Control vs. Eloquence: Higher control may result in less natural responses
  - Coverage vs. Accuracy: Broader retrieval may increase coverage but also risk of hallucination
  - Effort vs. Performance: More comprehensive metadata requires more setup effort but improves control
- Failure signatures:
  - High rate of "I don't know" responses - may indicate overly strict NLU confidence thresholds
  - Factual errors in responses - may indicate issues with retrieval ranking
  - Off-topic responses - may indicate issues with document embeddings
- First 3 experiments:
  1. Configure system to use only rule-based NLU with no LLM generation for a small, well-defined domain
  2. Configure system to use RAG with metadata filtering and LLM generation, compare hallucination rate vs. pure LLM
  3. Configure system to suppress generation for a predefined set of sensitive topics, measure user satisfaction and error rate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the balance between control and eloquence be optimally tuned for different use cases?
- Basis in paper: [explicit] The authors discuss the tradeoff between control and effort/cost
- Why unresolved: The paper does not provide specific guidelines or metrics for determining the optimal balance
- What evidence would resolve it: Empirical studies comparing performance and user satisfaction across various domains

### Open Question 2
- Question: What are the long-term effects of using metadata and annotations for retrieval on accuracy and relevance?
- Basis in paper: [explicit] The authors mention that using metadata and annotations can increase control over the search outcome
- Why unresolved: The paper does not discuss long-term implications or potential drawbacks
- What evidence would resolve it: Longitudinal studies tracking performance over extended periods

### Open Question 3
- Question: How can the internal analytics functionality be further enhanced to better support AI-engineers and chatbot editors?
- Basis in paper: [explicit] The authors emphasize the importance of building internal analytics functionality
- Why unresolved: The paper does not provide specific recommendations for enhancement
- What evidence would resolve it: Case studies and user feedback from AI-engineers and chatbot editors

## Limitations
- Framework-level description without empirical validation data
- Effectiveness relies heavily on proper configuration of metadata and annotation systems
- Specific implementation details of Kauz NLU engine remain undisclosed

## Confidence
- High confidence: The conceptual framework of using RAG for controlled generation is well-established
- Medium confidence: The claim that metadata and annotations can enhance control over retrieval is plausible but lacks empirical validation
- Low confidence: The assertion that this particular hybrid approach significantly outperforms other hallucination mitigation strategies cannot be verified

## Next Checks
1. Conduct a controlled experiment comparing hallucination rates between the Kauz platform's hybrid approach and a pure LLM baseline
2. Measure precision and recall of retrieval when using different weight configurations for metadata versus document text
3. Perform user studies to evaluate whether the spectrum of control levels translates to meaningful differences in user satisfaction and factual accuracy