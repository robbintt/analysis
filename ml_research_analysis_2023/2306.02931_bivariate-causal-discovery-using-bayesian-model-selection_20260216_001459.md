---
ver: rpa2
title: Bivariate Causal Discovery using Bayesian Model Selection
arxiv_id: '2306.02931'
source_url: https://arxiv.org/abs/2306.02931
tags:
- causal
- bayesian
- datasets
- data
- direction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses causal discovery in the bivariate case, aiming
  to identify the causal direction between two variables using only observational
  data. The core method idea is to formulate causal discovery as a Bayesian model
  selection problem, where each causal direction is treated as a separate model with
  priors that encode the independent causal mechanisms (ICM) assumption.
---

# Bivariate Causal Discovery using Bayesian Model Selection

## Quick Facts
- arXiv ID: 2306.02931
- Source URL: https://arxiv.org/abs/2306.02931
- Reference count: 40
- Primary result: Achieves average ROC AUC of 87.7% across benchmark datasets for identifying causal direction between two variables

## Executive Summary
This paper addresses the fundamental problem of determining causal direction between two variables using only observational data. The authors propose a novel approach that formulates causal discovery as a Bayesian model selection problem, where each causal direction is treated as a separate model with priors encoding the independent causal mechanisms (ICM) assumption. This framework allows for flexible models that can minimize misspecification while maintaining asymmetry between causal directions, enabling differentiation even when maximum likelihood methods fail.

The approach is demonstrated using a Gaussian process latent variable model (GPLVM), which can flexibly model joint distributions while preserving the causal factorization asymmetry. The method outperforms previous approaches on a wide range of benchmark datasets with varying data generating assumptions, achieving high accuracy across diverse scenarios. The theoretical analysis provides guarantees even under model misspecification, with error bounds based on total variation distance between true and model data densities.

## Method Summary
The method formulates bivariate causal discovery as a Bayesian model selection problem, where each causal direction (X→Y and Y→X) is treated as a separate probabilistic model. The models are constructed using Gaussian Process Latent Variable Models (GPLVM) with priors that encode the independent causal mechanisms (ICM) assumption, making parameters independent across cause and effect mechanisms. Marginal likelihoods are computed using variational inference with inducing points approximation and evidence approximation for hyperparameters. The causal direction is determined by comparing the marginal likelihoods of the two models, with the direction having higher marginal likelihood being selected as the predicted causal direction.

## Key Results
- Achieves average ROC AUC of 87.7% across all tested benchmark datasets
- Outperforms previous methods on datasets with varying data generating assumptions
- Demonstrates robustness to model misspecification with bounded error probability
- Shows that Bayesian model selection can distinguish causal directions when maximum likelihood cannot

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bayesian model selection distinguishes causal directions even when maximum likelihood cannot, due to the marginal likelihood incorporating a complexity penalty that favors the correct causal factorization.
- Mechanism: The marginal likelihood integrates over parameters and priors, which creates asymmetry between causal models. Even when both models can fit the data equally well (maximum likelihood is indifferent), the prior and integration over parameters make the marginal likelihoods different.
- Core assumption: The Independent Causal Mechanisms (ICM) assumption is encoded in the priors, making parameters independent across causal and effect mechanisms.

### Mechanism 2
- Claim: The method achieves high accuracy across diverse datasets because the Gaussian Process Latent Variable Model (GPLVM) can flexibly model joint distributions while maintaining the causal factorization asymmetry.
- Mechanism: The GPLVM uses flexible priors on non-linear functions with Gaussian process priors, allowing it to model a wide range of densities. This flexibility means that the method doesn't require restrictive assumptions about the data generating process.
- Core assumption: The data generating process can be approximated by a GPLVM, and the causal factorization has a different dataset density than the anticausal factorization.

### Mechanism 3
- Claim: The method provides correctness guarantees even under model misspecification, with the probability of error bounded by the total variation distance between the true and model data densities.
- Mechanism: When the model assumptions don't perfectly match reality, the difference between the true probability of error and the model-predicted probability of error is bounded by the total variation distance between the true data density and the model's data density.
- Core assumption: The model can approximate the true data generating process sufficiently well that the total variation distance is small.

## Foundational Learning

- Concept: Bayesian model selection and marginal likelihood
  - Why needed here: The method fundamentally relies on computing and comparing marginal likelihoods of different causal models rather than just maximum likelihood.
  - Quick check question: Can you explain why the marginal likelihood (integrating over parameters) can distinguish causal direction when maximum likelihood cannot?

- Concept: Independent Causal Mechanisms (ICM) assumption
  - Why needed here: The method encodes the ICM assumption in the model structure and priors, which is crucial for creating asymmetry between causal and anticausal factorizations.
  - Quick check question: How does the ICM assumption imply that the parameters for cause and effect mechanisms should be independent in the prior?

- Concept: Gaussian Process Latent Variable Models (GPLVM)
  - Why needed here: This is the specific flexible model chosen for the method, allowing it to handle diverse data generating assumptions.
  - Quick check question: What are the key components of a GPLVM and how does it differ from standard Gaussian process regression?

## Architecture Onboarding

- Component map: Data preprocessing -> Model construction (GPLVM for both causal directions) -> Variational inference (ELBO optimization) -> Hyperparameter optimization (evidence approximation) -> Model selection (compare marginal likelihoods)

- Critical path:
  1. Preprocess data (normalize, split)
  2. Construct GPLVM models for both causal directions
  3. Optimize variational parameters and inducing points
  4. Approximate hyperparameters using evidence approximation
  5. Compute lower bounds for both models
  6. Compare scores and select causal direction

- Design tradeoffs:
  - Flexibility vs. computational cost: GPLVM is more flexible but slower than restricted models
  - Prior specification: Need to balance between realistic assumptions and identifiability
  - Variational approximation: Introduces additional approximation error but enables scalability

- Failure signatures:
  - Very similar scores for both causal directions: Model may be misspecified or data may not contain sufficient causal signal
  - High variance across random restarts: Optimization may be stuck in local optima
  - Poor performance on specific dataset types: Model assumptions may not match data generating process

- First 3 experiments:
  1. Implement GPLVM with closed-form variational inference on a simple synthetic dataset (e.g., ANM with known parameters)
  2. Compare causal direction scores for both models on a dataset with known ground truth
  3. Test the method on a real-world dataset with approximately linear relationships to validate basic functionality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact contribution of the ICM assumption to causal identification in Bayesian model selection?
- Basis in paper: The paper mentions that the ICM assumption is encoded in the causal models but does not quantify its specific contribution.
- Why unresolved: The paper does not provide a detailed analysis of how much the ICM assumption alone contributes to identifying causal direction, as opposed to other factors like model flexibility.
- What evidence would resolve it: Controlled experiments varying the strength of the ICM assumption in the prior while keeping other factors constant would show its isolated effect.

### Open Question 2
- Question: How does the performance of Bayesian model selection scale with the dimensionality of the data?
- Basis in paper: The paper focuses on bivariate causal discovery and does not discuss performance in higher dimensions.
- Why unresolved: The experiments are limited to two variables, and there is no theoretical analysis of how the method would perform with more variables.
- What evidence would resolve it: Empirical tests on datasets with more than two variables and theoretical bounds on performance as dimensionality increases.

### Open Question 3
- Question: What is the impact of different prior choices on the accuracy of causal direction identification?
- Basis in paper: The paper mentions that priors influence performance but does not systematically explore different prior choices.
- Why unresolved: The experiments use specific priors but do not compare their impact against alternative prior specifications.
- What evidence would resolve it: Systematic experiments varying the prior distributions and measuring the resulting accuracy in causal direction identification.

### Open Question 4
- Question: How sensitive is the method to the choice of kernel in the Gaussian process model?
- Basis in paper: The paper uses specific kernels but does not analyze the sensitivity to kernel choice.
- Why unresolved: Different kernels can capture different types of relationships, and their impact on causal discovery is not explored.
- What evidence would resolve it: Experiments comparing performance using different kernel functions while keeping other aspects of the model constant.

## Limitations
- Method's effectiveness depends critically on appropriateness of GPLVM model class for true data generating process
- Theoretical guarantees rely on total variation bounds that may not hold for highly complex or high-dimensional data
- Computational cost of GPLVM with inducing points can be substantial for very large datasets

## Confidence

- High confidence: The theoretical framework for Bayesian model selection distinguishing causal directions when maximum likelihood cannot (Mechanism 1)
- Medium confidence: The empirical performance claims across benchmark datasets, as the exact experimental conditions and dataset specifications are not fully detailed
- Medium confidence: The claim about handling model misspecification with bounded error, as the practical implications depend heavily on the specific misspecification scenarios

## Next Checks
1. Test the method on synthetic datasets where the true data generating process is explicitly known to be outside the GPLVM model class to assess robustness to model misspecification
2. Conduct ablation studies varying the prior specifications to understand how sensitive the method is to the encoding of independent causal mechanisms
3. Compare computational efficiency and accuracy against alternative approaches (e.g., regression with independence testing) on datasets of increasing size to identify scalability limits