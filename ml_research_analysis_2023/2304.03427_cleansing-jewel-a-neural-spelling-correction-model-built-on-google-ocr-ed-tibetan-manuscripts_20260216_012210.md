---
ver: rpa2
title: 'Cleansing Jewel: A Neural Spelling Correction Model Built On Google OCR-ed
  Tibetan Manuscripts'
arxiv_id: '2304.03427'
source_url: https://arxiv.org/abs/2304.03427
tags:
- dence
- score
- transformer
- data
- mechanism
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a neural spelling correction model built on
  Google OCR-ed Tibetan Manuscripts to auto-correct OCR-ed noisy output. We feature-engineered
  our raw Tibetan etext corpus into two sets of structured data frames -- a set of
  paired toy data and a set of paired real data.
---

# Cleansing Jewel: A Neural Spelling Correction Model Built On Google OCR-ed Tibetan Manuscripts

## Quick Facts
- arXiv ID: 2304.03427
- Source URL: https://arxiv.org/abs/2304.03427
- Reference count: 7
- Key outcome: A Transformer-based spelling correction model with confidence score mechanism outperforms LSTM and GRU architectures on Tibetan OCR post-processing

## Executive Summary
This work presents a neural spelling correction model for Tibetan manuscripts that leverages confidence scores from Google OCR to improve correction accuracy. The authors developed a paired corpus of clean and OCR-ed Tibetan text, then implemented a Confidence Score mechanism within a Transformer architecture to guide correction decisions. Their approach demonstrates superior performance compared to LSTM and GRU baselines, achieving lower Character Error Rates through the integration of confidence scores with attention mechanisms.

## Method Summary
The authors feature-engineered Tibetan etext corpus into paired toy and real data, then trained Transformer-based seq2seq models with a Confidence Score mechanism. The approach involved BPE tokenization (vocab size 300-500), confidence score embedding (0-1 manually mapped), and training on paired clean-noisy Tibetan text. Models were evaluated using KL divergence loss and Character Error Rate (CER), with attention visualizations used to analyze model behavior.

## Key Results
- Transformer + Confidence Score mechanism architecture outperforms Transformer, LSTM-2-LSTM, and GRU-2-GRU baselines
- Optimal BPE vocabulary size identified as 300-500 for Tibetan spelling correction
- Attention heatmaps show strong awareness of nearest neighbors in both encoder and decoder
- Character Error Rate effectively measures spelling correction quality for OCR post-processing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Confidence scores from OCR improve Transformer's ability to correct spelling errors by guiding token modification decisions.
- Mechanism: The model concatenates input embeddings with confidence score embeddings, where confidence scores (0-1) are manually mapped to embedding weights. This allows the model to differentiate between highly confident correct characters (score > 0.8) and low-confidence questionable characters.
- Core assumption: Confidence scores directly correlate with character correctness, and the model can learn to use this signal to make better correction decisions.
- Evidence anchors:
  - [abstract] "Through the Confidence Score mechanism, the model is able to take in both OCR-ed noisy sentences and the confidence score corresponding to each token in the encoder, and outputs corrected sentences in the decoder."
  - [section 4] "The OCR-ed noisy data comes from Google OCR, and it contains a confidence score for each character."
  - [corpus] Weak evidence - corpus shows related work uses confidence scores but doesn't validate this specific implementation

### Mechanism 2
- Claim: Transformer architecture with attention mechanisms can effectively learn Tibetan character dependencies for spelling correction.
- Mechanism: Multi-head self-attention in encoder and decoder layers allows the model to capture both local character relationships (within words) and broader context dependencies. The attention weights show which characters influence correction decisions.
- Core assumption: Tibetan orthography follows patterns where characters have strong dependencies with their immediate neighbors and broader context provides disambiguating information.
- Evidence anchors:
  - [abstract] "Our Transformer + Confidence score mechanism architecture proves to be superior to Transformer, LSTM-2-LSTM and GRU-2-GRU architectures."
  - [section 6.2] "Figure 5(b) and 5(c) show Self-Attention weights in the encoder and decoder, respectively. One phenomenon the Self-Attention figures tended to exhibit is a strong awareness of its nearest neighbors"
  - [corpus] Weak evidence - corpus shows Transformer works for spelling correction but doesn't specifically validate Tibetan character dependencies

### Mechanism 3
- Claim: Byte Pair Encoding (BPE) with appropriate vocabulary size balances character-level precision and word-level semantic understanding for Tibetan spelling correction.
- Mechanism: BPE tokenization creates a vocabulary that can represent common character sequences while maintaining flexibility to handle rare words. The optimal vocab size (300-500) was found through experimentation to avoid underfitting (too large) or overfitting (too small).
- Core assumption: Tibetan spelling errors can be effectively modeled at the subword level, and the vocabulary size can capture sufficient semantic relationships without requiring excessive computational resources.
- Evidence anchors:
  - [section 5.2.1] "Given the success of the noising function prior to the GEC models, we propose a similar methodology for creating a toy Tibetan dataset" - shows methodology transfer
  - [section 5.2.1] "As Table. 2 shows, given other parameters set the same, the best BPE tokenizer vocab sizes are 300 and 500"
  - [corpus] Moderate evidence - corpus shows related work uses BPE for spelling correction, but specific vocab size optimization for Tibetan is novel

## Foundational Learning

- Byte Pair Encoding (BPE) tokenization
  - Why needed here: BPE allows the model to handle rare words and character sequences efficiently while maintaining a manageable vocabulary size. For Tibetan with its complex character combinations, BPE provides the right balance between granularity and generalization.
  - Quick check question: What happens to model performance if vocab size is set to 30 (character-level) vs 2000 (word-level) for Tibetan spelling correction?

- Attention mechanisms in Transformers
  - Why needed here: Attention allows the model to focus on relevant characters when making correction decisions, both locally (within words) and globally (across sentence context). This is crucial for disambiguating between valid but contextually incorrect spellings.
  - Quick check question: How does the attention heatmap visualization help identify whether the model is correctly attending to contextually relevant characters?

- Character Error Rate (CER) as evaluation metric
  - Why needed here: CER measures the proportion of incorrect characters in the model output compared to ground truth, providing a granular assessment of spelling correction quality that's appropriate for OCR post-processing tasks.
  - Quick check question: Why might CER be more appropriate than word-level metrics for evaluating OCR spelling correction?

## Architecture Onboarding

- Component map: Input (Tibetan text + confidence scores) -> Tokenizer (BPE) -> Encoder (Self-Attention + Confidence Embeddings) -> Decoder (Self-Attention + Source-Attention) -> Output (Corrected Tibetan text)
- Critical path: Input → Tokenizer → Encoder (Self-Attention + Confidence Embeddings) → Decoder (Self-Attention + Source-Attention) → Output
- Design tradeoffs:
  - Confidence score vocabulary size: 101 (fine-grained) vs 5 vs 2 (binary) - impacts model capacity and training efficiency
  - BPE vocabulary size: 300-500 balances between capturing semantic relationships and computational efficiency
  - Maximum sentence length: 512 tokens based on original Transformer paper recommendations
- Failure signatures:
  - High CER but low loss: Model is overconfident in incorrect predictions
  - Low CER but high loss: Model is uncertain but making correct predictions
  - Attention heatmaps showing uniform weights: Model isn't learning character dependencies
  - Systematic errors on common characters: Vocabulary size may be too small

- First 3 experiments:
  1. Baseline Transformer without confidence scores to establish performance floor
  2. Confidence score mechanism with vocab size 101 vs 2 to test binary vs continuous confidence representation
  3. BPE vocabulary size ablation study (100, 300, 500, 1000, 2000) to find optimal balance for Tibetan

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would increasing the BPE tokenizer vocabulary size from 500 to 2000-3000 impact the model's ability to correct semantic errors based on context?
- Basis in paper: [inferred] The authors noted that the current small tokenizer size (500) limits the model's ability to capture meaningful semantic relationships and suggested increasing it as a potential solution to address the model's short-sightedness in correcting semantic errors.
- Why unresolved: The authors did not have sufficient computing resources to test this hypothesis, leaving it as an exercise for future research.
- What evidence would resolve it: Experimental results showing changes in Character Error Rate (CER) and model performance on semantic error correction tasks when using larger tokenizer vocabulary sizes.

### Open Question 2
- Question: Would integrating a pre-trained Tibetan BERT model at the end of the current architecture improve the model's ability to handle semantically inconsistent and ambiguous words?
- Basis in paper: [explicit] The authors suggested this as a potential solution in the conclusion section, noting that the current model suffers from short-sightedness in correcting words based on word context.
- Why unresolved: This integration was not implemented or tested in the current study.
- What evidence would resolve it: Comparative performance metrics (CER, loss) between the current model and the same model with BERT integration on the same test datasets.

### Open Question 3
- Question: How would combining computer vision algorithms to enhance scan quality and denoising models to improve image quality affect OCR accuracy and downstream spelling correction performance?
- Basis in paper: [explicit] The authors explicitly mentioned this as a future research direction in the conclusion, noting that the current project focused specifically on NLP methods for post-processing OCR-ed texts.
- Why unresolved: The paper focused on NLP methods rather than CV methods, so this combination was not explored.
- What evidence would resolve it: Comparative results showing OCR accuracy improvements and downstream spelling correction performance when using enhanced images versus standard OCR input.

## Limitations

- Confidence score reliability: The core mechanism assumes OCR confidence scores accurately reflect character correctness, but OCR systems can produce high-confidence errors, particularly with Tibetan script's complex characters.
- Tibetan-specific character dependencies: While attention mechanisms are theoretically well-suited for capturing character relationships, Tibetan orthography may have unique patterns not well-represented in training data.
- BPE vocabulary optimization: The identified optimal range (300-500) may be dataset-specific and may not generalize across different Tibetan text domains.

## Confidence

**High confidence claims**:
- Transformer architecture with attention mechanisms can effectively process Tibetan text for spelling correction tasks
- BPE tokenization provides reasonable subword representation for Tibetan spelling correction
- Character Error Rate is an appropriate evaluation metric for OCR post-processing tasks

**Medium confidence claims**:
- Confidence score mechanism improves spelling correction performance when OCR confidence scores are reliable
- The specific vocabulary size range (300-500) is optimal for Tibetan spelling correction across different datasets
- Attention heatmaps provide meaningful insights into model decision-making processes

**Low confidence claims**:
- Confidence scores from Google OCR directly correlate with character correctness and can be effectively used as training signals
- The superiority of Transformer + Confidence over baseline architectures generalizes beyond the tested dataset
- The noising function used to create toy data adequately represents real OCR error patterns

## Next Checks

**Check 1: Confidence score correlation validation**
Correlate OCR confidence scores with actual character correctness in the test set to measure the reliability of confidence scores as a signal. Calculate Pearson correlation coefficients between confidence scores and character accuracy, and test model performance when confidence scores are randomly shuffled versus when they're preserved.

**Check 2: Vocabulary size robustness testing**
Perform systematic ablation studies across a broader range of BPE vocabulary sizes (50, 100, 200, 300, 500, 1000, 2000) on multiple Tibetan text domains (religious texts, modern documents, poetry) to test whether the 300-500 range is truly optimal or dataset-dependent.

**Check 3: Cross-architectural generalization**
Test the confidence score mechanism across different architectural variants beyond the three tested (Transformer, LSTM-2-LSTM, GRU-2-GRU) including BERT-based architectures and character-level models to determine whether the confidence mechanism provides consistent benefits across different model families.