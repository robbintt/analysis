---
ver: rpa2
title: Entropy-driven Fair and Effective Federated Learning
arxiv_id: '2301.12407'
source_url: https://arxiv.org/abs/2301.12407
tags:
- fairness
- fedeba
- performance
- global
- aggregation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FedEBA+, a novel federated learning algorithm
  that simultaneously improves global model performance and fairness. The method employs
  entropy-based aggregation (EBA) to assign higher weights to underperforming clients,
  promoting fairness, while also introducing a new model update strategy incorporating
  model and gradient alignments.
---

# Entropy-driven Fair and Effective Federated Learning

## Quick Facts
- arXiv ID: 2301.12407
- Source URL: https://arxiv.org/abs/2301.12407
- Reference count: 40
- Key outcome: FedEBA+ improves both global model performance and fairness in federated learning by assigning higher weights to underperforming clients through entropy-based aggregation and gradient alignment.

## Executive Summary
This paper introduces FedEBA+, a novel federated learning algorithm that simultaneously improves global model performance and fairness. The method employs entropy-based aggregation (EBA) to assign higher weights to underperforming clients, promoting fairness, while also introducing a new model update strategy incorporating model and gradient alignments. Theoretical analysis proves convergence to near-optimal solutions and demonstrates fairness improvements in regression models. Experiments on MNIST, FashionMNIST, and CIFAR10 datasets show FedEBA+ consistently achieves smaller variance in accuracy compared to state-of-the-art fairness baselines, significantly improves the performance of the worst 5% of clients, and maintains or improves global accuracy.

## Method Summary
FedEBA+ uses entropy-based aggregation (EBA) to compute aggregation probabilities that balance model performance and entropy, assigning higher weights to underperforming clients. The algorithm incorporates a model update method that balances global performance and fairness through model and gradient alignment, using both global gradient alignment and fair gradient alignment. An annealing schedule for the temperature parameter T is employed, decreasing over time to allow more uniform aggregation weights initially and more concentrated weights later. The algorithm is theoretically proven to converge to near-optimal solutions and has been validated on multiple datasets including MNIST, FashionMNIST, and CIFAR10.

## Key Results
- FedEBA+ achieves smaller variance in accuracy compared to state-of-the-art fairness baselines
- The algorithm significantly improves the performance of the worst 5% of clients
- FedEBA+ maintains or improves global accuracy while enhancing fairness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Entropy-based aggregation (EBA) assigns higher weights to underperforming clients, improving fairness.
- Mechanism: Uses a constrained maximum entropy optimization to compute aggregation probabilities that balance model performance and entropy. The aggregation probability for client i is computed as: p_i = exp[f_i(x)/T] / Σ_j exp[f_j(x)/T], where T is a temperature parameter controlling fairness level.
- Core assumption: The entropy maximization approach effectively balances fairness and performance without requiring extensive prior knowledge about client distributions.
- Evidence anchors:
  - [abstract] "Our method employs entropy-based aggregation (EBA) to assign higher weights to underperforming clients, promoting fairness"
  - [section 4.1] "Inspired by the Shannon entropy approach to fairness [38], an optimization problem with unique constraints on the aggregation of FL is formulated"
  - [corpus] Weak - no direct corpus evidence supporting this specific mechanism
- Break condition: If the temperature parameter T is not properly tuned, the algorithm may either become too uniform (T too high) or too concentrated (T too low), reducing effectiveness.

### Mechanism 2
- Claim: The model update method balances global performance and fairness through model and gradient alignment.
- Mechanism: The update incorporates both global gradient alignment (to maintain performance) and fair gradient alignment (to improve fairness). The update rule is: ∆t = (1 - α) Σ_i p_i ∆i_t + α ˜∆t, where ˜∆t approximates the global gradient.
- Core assumption: The fair gradient alignment improves performance of underperforming clients without significantly degrading overall model performance.
- Evidence anchors:
  - [abstract] "introducing a new model update strategy incorporating model and gradient alignments"
  - [section 4.2] "We introduce a novel model update method that balances both global model performance and fairness by aligning the global model and fair gradient"
  - [corpus] Weak - no direct corpus evidence supporting this specific mechanism
- Break condition: If the alignment coefficient α is not properly tuned, the algorithm may either become too focused on fairness (α too high) or too focused on performance (α too low).

### Mechanism 3
- Claim: The annealing schedule for temperature T improves fairness while maintaining performance.
- Mechanism: T decreases over time following a linear schedule: T_K = T_0/(1 + β(K - 1)), where K is the total communication rounds. This allows more uniform aggregation weights initially and more concentrated weights later.
- Core assumption: The annealing schedule effectively balances fairness and performance throughout the training process.
- Evidence anchors:
  - [section 4.3] "We propose to use the following annealing manner for T in FL: T_K = T_0/(1 + β(K - 1))"
  - [section 6.4] "Figure 7 shows that the annealing schedule has advantages in reducing the variance compared with constant T"
  - [corpus] Weak - no direct corpus evidence supporting this specific mechanism
- Break condition: If the annealing rate β is not properly tuned, the algorithm may either converge too slowly (β too low) or lose fairness too quickly (β too high).

## Foundational Learning

- Concept: Maximum entropy principle
  - Why needed here: Provides a theoretical foundation for the entropy-based aggregation approach, ensuring the aggregation probabilities are unbiased and fair.
  - Quick check question: How does the maximum entropy principle relate to fairness in federated learning?

- Concept: Federated learning fundamentals
  - Why needed here: Understanding the basic FL setup (client-server architecture, local training, global aggregation) is crucial for implementing and modifying the FedEBA+ algorithm.
  - Quick check question: What are the key components of a standard federated learning system?

- Concept: Gradient descent and SGD
  - Why needed here: The algorithm relies on gradient-based updates for both local training and global aggregation, requiring understanding of these optimization techniques.
  - Quick check question: How does stochastic gradient descent differ from standard gradient descent in federated learning?

## Architecture Onboarding

- Component map:
  - Clients -> Local training and gradient computation -> Server
  - Server -> Aggregation probability computation -> Global model update -> Gradient alignment
  - Server -> Temperature annealing schedule -> Communication with clients

- Critical path:
  1. Server initializes global model and broadcasts to clients
  2. Clients perform local training and compute gradients
  3. Server computes aggregation probabilities using entropy-based method
  4. Server updates global model using aligned gradients
  5. Repeat until convergence

- Design tradeoffs:
  - Temperature T vs. fairness: Higher T promotes more uniform aggregation but may reduce performance
  - Alignment coefficient α vs. performance: Higher α promotes fairness but may reduce global accuracy
  - Annealing rate β vs. convergence: Slower annealing may improve fairness but increase training time

- Failure signatures:
  - Poor fairness: High variance in client accuracy, underperforming clients not improving
  - Poor performance: Global accuracy not improving, model not converging
  - Communication issues: Clients not receiving updates, gradients not being properly aggregated

- First 3 experiments:
  1. Implement basic FedAvg baseline to establish performance and fairness metrics
  2. Add entropy-based aggregation (EBA) component to test fairness improvements
  3. Add gradient alignment component to test performance improvements while maintaining fairness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of FedEBA+ compare to other state-of-the-art fairness algorithms when the amount of local data is limited?
- Basis in paper: [inferred] The paper mentions that some existing fairness algorithms require personalized models that are distinct from the global model, which may not be effective in improving the performance of the global model in non-attack scenarios.
- Why unresolved: The paper does not provide any experimental results or theoretical analysis on the performance of FedEBA+ when the amount of local data is limited.
- What evidence would resolve it: Experimental results comparing the performance of FedEBA+ and other fairness algorithms on datasets with limited local data.

### Open Question 2
- Question: How does the choice of the hyperparameter T in the aggregation formulation affect the fairness and global model performance of FedEBA+?
- Basis in paper: [explicit] The paper mentions that the hyperparameter T controls the spreading of weights assigned to each client and affects the fairness level. It also mentions that tuning T is crucial for the model's performance.
- Why unresolved: The paper does not provide any systematic analysis or experimental results on the impact of different values of T on the fairness and global model performance of FedEBA+.
- What evidence would resolve it: Experimental results showing the impact of different values of T on the fairness and global model performance of FedEBA+ on various datasets.

### Open Question 3
- Question: How does the annealing schedule for T in FedEBA+ affect its fairness and global model performance?
- Basis in paper: [explicit] The paper mentions that the annealing schedule proposed in Section 4.3 has advantages in reducing the variance compared with constant T.
- Why unresolved: The paper does not provide any experimental results or theoretical analysis on the impact of the annealing schedule on the fairness and global model performance of FedEBA+.
- What evidence would resolve it: Experimental results comparing the fairness and global model performance of FedEBA+ with different annealing schedules for T on various datasets.

### Open Question 4
- Question: How does FedEBA+ perform in the presence of user attacks in federated learning?
- Basis in paper: [inferred] The paper mentions that it would be interesting to devise a strategy based on FedEBA+ to address user attacks.
- Why unresolved: The paper does not provide any experimental results or theoretical analysis on the performance of FedEBA+ in the presence of user attacks.
- What evidence would resolve it: Experimental results comparing the performance of FedEBA+ and other fairness algorithms in the presence of user attacks on various datasets.

## Limitations

- The theoretical convergence proof assumes convexity of the global loss function, which may not hold for deep neural networks used in experiments
- The computational complexity of the entropy-based aggregation method is not analyzed, raising concerns about scalability to larger models and datasets
- The hyperparameter tuning process is not fully specified, particularly for temperature T, alignment coefficient α, and annealing rate β

## Confidence

- **Medium confidence** in the fairness improvements claimed by FedEBA+, as these are primarily demonstrated through empirical results without extensive ablation studies
- **High confidence** in the theoretical framework for entropy-based aggregation, as it builds on established maximum entropy principles
- **Low confidence** in the practical significance of the improvements, given the lack of comparison with state-of-the-art fairness techniques in related work

## Next Checks

1. Implement an ablation study to isolate the impact of each component (EBA, gradient alignment, annealing schedule) on fairness and performance
2. Conduct experiments on larger, more heterogeneous datasets to test the scalability and robustness of FedEBA+
3. Perform a sensitivity analysis on hyperparameters (T, α, β) to determine their optimal ranges and impact on convergence