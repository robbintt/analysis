---
ver: rpa2
title: Benchmarking Continuous Time Models for Predicting Multiple Sclerosis Progression
arxiv_id: '2302.07854'
source_url: https://arxiv.org/abs/2302.07854
tags:
- time
- continuous
- interpolation
- multiple
- sclerosis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work benchmarks continuous time models for predicting multiple
  sclerosis progression using performance outcome measures and demographic data. The
  authors adapt continuous models (Neural Controlled Differential Equations, ODE-RNN,
  Latent ODE, and GRU-ODE) to handle irregular time-series through interpolation-based
  control signals and pseudo-time batching.
---

# Benchmarking Continuous Time Models for Predicting Multiple Sclerosis Progression

## Quick Facts
- arXiv ID: 2302.07854
- Source URL: https://arxiv.org/abs/2302.07854
- Reference count: 40
- Primary result: Neural Controlled Differential Equations outperform discrete models (TCN) in 10 of 16 MS progression prediction tasks

## Executive Summary
This work benchmarks continuous time models for predicting multiple sclerosis progression using performance outcome measures and demographic data. The authors adapt Neural Controlled Differential Equations, ODE-RNN, Latent ODE, and GRU-ODE to handle irregular time-series through interpolation-based control signals and pseudo-time batching. Experiments on the MSOAC dataset demonstrate that Neural CDEs outperform the best discrete model (TCN) in 10 out of 16 prediction tasks, with RMSE ranging from 1.264 to 2.312 and AUPRC from 0.552 to 0.909. The study reveals that feature standardization is crucial for performance gains, while interpolation scheme choice has minimal impact.

## Method Summary
The study preprocesses the MSOAC dataset by standardizing features, imputing missing values with zeros, and padding sequences to equal length. Four continuous time models (Neural CDE, ODE-RNN, Latent ODE, GRU-ODE) are implemented with preprocessing pipelines and trained using 10-fold cross-validation and Adam optimizer for 50 epochs. Models are evaluated on four prediction tasks (EDSS mean, EDSS > 3, EDSS > 5, EDSS severity category) and compared against the best discrete model (TCN) from Roy et al. (2022).

## Key Results
- Neural CDEs achieve best performance in 10 out of 16 prediction tasks
- RMSE ranges from 1.264 to 2.312 across all tasks and models
- AUPRC ranges from 0.552 to 0.909 for binary and multi-class classification tasks
- Feature standardization provides the largest performance improvement for Neural CDEs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Standardizing features is crucial for performance gains in Neural Controlled Differential Equations
- Mechanism: Feature standardization transforms input data to have mean 0 and standard deviation 1, making the dynamics function's input more manageable and well-regularized. This is particularly important for Neural CDEs because their dynamics function explicitly includes dX/ds, which can be large if features are not standardized.
- Core assumption: The dynamics function's input distribution significantly affects model performance
- Evidence anchors:
  - [section]: "we see that for Neural CDEs standardizing the values has the largest positive effect on performance. This is likely due to standardization transforming X into a manageable range, and by extension dX/ds, so that the dynamics of the Neural CDE are well regularized."
  - [corpus]: Weak evidence - no related papers specifically address standardization in continuous time models
- Break condition: If features are already in a manageable range or if the model's dynamics function does not directly depend on the input scale

### Mechanism 2
- Claim: Continuous time models naturally handle irregular time-series without the need for bucketing
- Mechanism: By modeling the instantaneous rate of change of the hidden state with respect to time, continuous time models can process data at any timestamp, unlike discrete models that require fixed time intervals
- Core assumption: The underlying disease progression follows a continuous dynamical process
- Evidence anchors:
  - [abstract]: "they naturally handle irregular time-series; via the use of control signals missing features can be interpolated and therefore are imputed with more physically plausible values"
  - [section]: "Crucially, we can differentiate the solutions of the ODE solve with respect to the parameters Î¸, the initial state h0, initial time t0 and the solution times t."
- Break condition: If the disease progression is not continuous or if the model cannot accurately learn the underlying dynamics

### Mechanism 3
- Claim: Interpolation scheme choice has minimal impact on model performance
- Mechanism: Different interpolation schemes (linear, Hermite cubic, natural cubic, monotonic cubic, rectilinear, recticubic) all provide similar predictive performance when used with continuous time models
- Core assumption: The model can learn to extract relevant information from the time-series regardless of the specific interpolation method
- Evidence anchors:
  - [section]: "We see that there is essentially no difference between the interpolation choice. Each one performs best on a task, and all values are within a standard deviation of each other."
  - [corpus]: Weak evidence - no related papers specifically compare different interpolation schemes in continuous time models
- Break condition: If the interpolation scheme significantly misrepresents the underlying data distribution or if the model is particularly sensitive to input smoothness

## Foundational Learning

- Concept: Neural Ordinary Differential Equations (Neural ODEs)
  - Why needed here: Neural ODEs form the basis for continuous time models used in this work
  - Quick check question: What is the key advantage of using Neural ODEs over traditional RNNs for irregular time-series data?

- Concept: Control signals in continuous time models
  - Why needed here: Control signals are used to interpolate missing values and provide continuous input to the model
  - Quick check question: How do control signals enable continuous time models to handle missing data?

- Concept: Monotonic interpolation
  - Why needed here: Monotonic interpolation is necessary for interpolating time and observation count channels to ensure increasing functions
  - Quick check question: Why is monotonic interpolation crucial for the time channel in continuous time models?

## Architecture Onboarding

- Component map: Raw data -> Preprocessing pipeline (standardization, missing value imputation, padding) -> Interpolation coefficients calculation -> Continuous time model (Neural CDE/ODE-RNN/Latent ODE/GRU-ODE) -> ODE solver -> Hidden state -> Prediction output

- Critical path:
  1. Preprocess raw data into standardized, padded format
  2. Calculate interpolation coefficients for each feature
  3. Pass coefficients and context to continuous time model
  4. Model processes data through ODE solver
  5. Decode hidden state to obtain predictions
  6. Evaluate predictions against ground truth

- Design tradeoffs:
  - Feature selection vs. model stability: Using fewer features improves continuous model stability
  - Interpolation scheme choice: Smooth causal splines preferred for speed, but minimal performance impact observed
  - Causality enforcement: Dataset reprocessing increases size but ensures model correctness

- Failure signatures:
  - Poor performance despite correct implementation: May indicate need for feature standardization
  - Numerical instability during ODE solving: Check input scaling and model architecture
  - Unexpected prediction patterns: Verify causality enforcement and interpolation scheme

- First 3 experiments:
  1. Compare performance with and without feature standardization
  2. Test different interpolation schemes (linear, Hermite cubic, monotonic cubic)
  3. Evaluate impact of causality enforcement methods (dataset reprocessing vs. recti method)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal feature set size for continuous time models in MS progression prediction, and how does performance scale with increasing feature dimensionality?
- Basis in paper: [inferred] The paper mentions that feature selection was necessary for continuous models to reach peak performance, but does not explore the impact of varying feature set sizes systematically.
- Why unresolved: The study used a reduced feature set of 5 features for computational efficiency and stability, but did not investigate how performance changes with more features.
- What evidence would resolve it: Systematic experiments varying the number of input features (e.g., 5, 10, 20, 50) and measuring model performance (RMSE, AUPRC) across all prediction tasks.

### Open Question 2
- Question: How do continuous time models compare to discrete models when handling missing data imputation methods other than interpolation (e.g., multiple imputation, generative models)?
- Basis in paper: [explicit] The paper found that standardization had a larger impact than interpolation choice, but only tested interpolation-based imputation for missing values.
- Why unresolved: The study focused on interpolation-based imputation and did not explore alternative missing data techniques that might be more suitable for continuous models.
- What evidence would resolve it: Comparative experiments using multiple imputation, generative adversarial imputation, or other advanced imputation techniques alongside interpolation methods.

### Open Question 3
- Question: What are the computational bottlenecks in continuous time models for MS progression prediction, and how can they be addressed for real-time clinical deployment?
- Basis in paper: [inferred] The paper mentions that interpolation is computationally expensive and that the TensorFlow ODE solver had specific implementation challenges.
- Why unresolved: While the paper discusses computational challenges, it does not provide detailed analysis of bottlenecks or propose solutions for real-time clinical applications.
- What evidence would resolve it: Profiling studies identifying specific computational bottlenecks (e.g., ODE solving, interpolation calculation, batching) and proposing optimized implementations or approximations.

## Limitations

- Limited generalizability to other disease progression datasets due to focus on a single MS dataset
- Potential overfitting to specific characteristics of the MSOAC dataset
- Computational complexity of ODE solving may limit real-time clinical deployment

## Confidence

- Feature standardization's crucial role: High
- Continuous models outperforming discrete models: Medium
- Interpolation scheme choice having minimal impact: Low

## Next Checks

1. Test the models on multiple sclerosis datasets from different populations to verify generalizability
2. Conduct ablation studies with alternative interpolation schemes and regularization methods
3. Implement cross-dataset validation using related neurological progression datasets to assess robustness