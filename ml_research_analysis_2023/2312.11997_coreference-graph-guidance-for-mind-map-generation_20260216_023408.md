---
ver: rpa2
title: Coreference Graph Guidance for Mind-Map Generation
arxiv_id: '2312.11997'
source_url: https://arxiv.org/abs/2312.11997
tags:
- graph
- document
- mind-map
- coreference
- sentences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a coreference-guided mind-map generation network
  (CMGN) to process documents into hierarchical structures. It constructs a coreference
  graph based on semantic relationships between sentences, and employs a coreference
  graph encoder to mine potential governing relations.
---

# Coreference Graph Guidance for Mind-Map Generation

## Quick Facts
- arXiv ID: 2312.11997
- Source URL: https://arxiv.org/abs/2312.11997
- Reference count: 8
- Primary result: CMGN outperforms existing approaches on both salient-sentence-based and key-snippet-based mind-map generation tasks

## Executive Summary
This paper introduces a coreference-guided mind-map generation network (CMGN) that processes documents into hierarchical mind-map structures by constructing coreference graphs based on semantic relationships between sentences. The method employs a coreference graph encoder to mine potential governing relations and uses a graph enhancement module with contrastive learning to address noise in the coreference graph. The proposed approach demonstrates superior accuracy and conciseness in revealing document structure and semantics compared to existing methods.

## Method Summary
The CMGN framework constructs a coreference graph by extracting coreference clusters from documents, then building edges from the first sentence containing a mention to all other sentences with the same mention. A coreference graph encoder with GCN layers propagates information and updates sentence representations based on this graph structure. The method combines contrastive learning through encoder perturbation with mean square error loss for pseudo graph fitting, using DistilBERT-generated annotations as training targets. The model is trained on CNN news articles using ROUGE metrics for evaluation.

## Key Results
- CMGN achieves superior ROUGE scores compared to existing mind-map generation approaches
- The method demonstrates improved performance on both salient-sentence-based (SSM) and key-snippet-based (KSM) mind-map generation tasks
- Coreference graph guidance enables better perception of long-distance semantic relations in documents

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Coreference graph construction introduces explicit structural information that captures long-range semantic relationships missed by sequential encoders
- Mechanism: The algorithm extracts all coreference clusters, matches mentions to their originating sentences, and builds edges from the first sentence containing a mention to all other sentences with the same mention
- Core assumption: Mentions of the same entity in different sentences imply a semantic or logical governing relationship between those sentences
- Evidence anchors: [abstract] "construct a coreference graph based on the coreference semantic relationship to introduce the graph structure information"; [section] "we employ the coreference graph (Xu et al. 2020) to model the documents"

### Mechanism 2
- Claim: Graph enhancement via contrastive learning improves representation quality by creating correlated views through encoder perturbation
- Mechanism: The method perturbs encoder parameters with Gaussian noise, generates two views (original and perturbed), and maximizes agreement between positive pairs while treating other graph data as negative pairs
- Core assumption: Perturbing encoder parameters creates a valid "different view" of the same input for contrastive learning
- Evidence anchors: [abstract] "we adopt a graph enhancement module in a contrastive learning manner"; [section] "we employ a graph enhancement module based on GCL to address this issue"

### Mechanism 3
- Claim: Combining contrastive loss with MSE loss for pseudo graph fitting creates a balanced training objective
- Mechanism: The overall loss function L = Lg + λLc combines mean square error loss for fitting pseudo graph Y (generated by DistilBERT) with contrastive loss from the graph enhancement module
- Core assumption: The pseudo graph annotations from DistilBERT are reliable enough to serve as training targets while contrastive learning provides additional regularization
- Evidence anchors: [abstract] "we adopt a graph enhancement module in a contrastive learning manner"; [section] "We combine the final loss Lc and the training loss of coreference graph encoder Lg"

## Foundational Learning

- Concept: Coreference resolution and coreference chain extraction
  - Why needed here: The entire method depends on identifying mentions of the same entity across sentences to build the coreference graph
  - Quick check question: What tool or library does the paper use to extract coreference clusters from the document?

- Concept: Graph Neural Networks (GCN/GIN) for node representation learning
  - Why needed here: The coreference graph encoder uses GCN layers to propagate information and update sentence representations based on graph structure
  - Quick check question: What is the main operation in a GCN layer that allows information to flow from neighboring nodes?

- Concept: Contrastive learning framework and positive/negative pair construction
  - Why needed here: The graph enhancement module uses contrastive learning where perturbed encoder outputs serve as positive pairs
  - Quick check question: In the NT-Xent loss formulation, how are negative pairs typically selected in this method?

## Architecture Onboarding

- Component map: Document Encoder → Coreference Graph Encoder → Relation Graph Generation → Graph Enhancement Module → Final Output
- Critical path: The document encoder produces initial sentence representations, which are then refined by the coreference graph encoder using graph structure, then passed through relation graph generation, and finally enhanced by contrastive learning
- Design tradeoffs: Uses pseudo labels from DistilBERT for training (faster but potentially noisier) vs. using human-annotated labels (more accurate but expensive); employs encoder perturbation for contrastive learning (avoids data augmentation complexity but may introduce instability)
- Failure signatures: Performance degradation when document length increases; sensitivity to λ hyperparameter; poor performance on documents with many unrelated coreference mentions
- First 3 experiments:
  1. Verify coreference graph construction by running on a sample document and checking that edges connect sentences with the same entity mentions
  2. Test the graph encoder by feeding it the coreference graph and checking that node representations change based on graph structure
  3. Validate the contrastive learning module by checking that perturbed and original encoder outputs have higher similarity than random pairs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the coreference graph construction method perform on documents with complex coreference structures or ambiguous mentions?
- Basis in paper: [explicit] The paper mentions using Allennlp to find coreference mentions and construct the graph, but does not evaluate the accuracy of this process or discuss limitations with complex coreference structures
- Why unresolved: The paper focuses on the downstream task of mind-map generation rather than evaluating the quality of the coreference graph construction itself
- What evidence would resolve it: Experiments comparing coreference graph accuracy against human annotations for documents with varying coreference complexity

### Open Question 2
- Question: How sensitive is the graph enhancement module to different types of perturbations or alternative contrastive learning strategies?
- Basis in paper: [explicit] The paper uses Gaussian noise to perturb encoder parameters and NT-Xent loss, but notes that performance is sensitive to the λ hyperparameter balancing the contrastive loss
- Why unresolved: The paper only explores one perturbation method and one contrastive loss function, without comparing alternatives or analyzing sensitivity to perturbation magnitude
- What evidence would resolve it: Experiments comparing different perturbation strategies and contrastive losses, along with ablation studies on perturbation magnitude

### Open Question 3
- Question: How does the model handle documents with different writing styles or domains (e.g., scientific papers vs. news articles)?
- Basis in paper: [inferred] The experiments are conducted on CNN news articles, and the paper does not discuss performance on other domains or writing styles
- Why unresolved: The paper does not provide evidence that the approach generalizes beyond the tested domain of news articles
- What evidence would resolve it: Experiments evaluating the model on documents from diverse domains, along with analysis of performance differences across domains

## Limitations
- The core assumption that coreference relationships directly imply governing relations between sentences is not empirically validated
- Reliance on pseudo labels from DistilBERT without validation against human annotations raises concerns about training target reliability
- The effectiveness of encoder parameter perturbation for contrastive learning lacks theoretical justification and may introduce training instability

## Confidence

- **Medium**: Claims about coreference graph improving long-range semantic relationship perception - while coreference resolution is well-established, its direct application to mind-map generation governing relations is novel and unproven
- **Low**: Claims about contrastive learning effectiveness through encoder perturbation - lacks corpus evidence and theoretical foundation for why parameter noise creates valid positive pairs
- **Medium**: Claims about combined loss function effectiveness - reasonable approach but lacks ablation studies to isolate individual component contributions

## Next Checks

1. **Coreference Graph Validation**: Run the coreference graph construction on 10 diverse documents and manually verify whether coreference-based edges actually correspond to meaningful governing relationships in the mind-map structure
2. **Contrastive Learning Ablation**: Conduct controlled experiments removing the graph enhancement module to quantify its actual contribution versus the base coreference graph encoder performance
3. **Pseudo Label Quality Assessment**: Compare DistilBERT-generated pseudo graphs against a small set of human-annotated mind-maps to measure annotation accuracy and its impact on downstream performance