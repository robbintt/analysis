---
ver: rpa2
title: 'BeLLM: Backward Dependency Enhanced Large Language Model for Sentence Embeddings'
arxiv_id: '2311.05296'
source_url: https://arxiv.org/abs/2311.05296
tags:
- sentence
- llms
- language
- embeddings
- deelm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the lack of backward dependency modeling
  in autoregressive large language models (LLMs) for sentence embeddings. The authors
  propose a novel method, DeeLM, which extracts and transforms certain LLM layers
  into bidirectional ones by removing causal masks, allowing learning of both forward
  and backward dependencies.
---

# BeLLM: Backward Dependency Enhanced Large Language Model for Sentence Embeddings

## Quick Facts
- arXiv ID: 2311.05296
- Source URL: https://arxiv.org/abs/2311.05296
- Reference count: 23
- Key outcome: DeeLM achieves state-of-the-art performance on STS tasks with 1.10-2.24% improvements over baseline LLM models

## Executive Summary
This paper addresses the limitation of autoregressive LLMs in modeling backward dependencies for sentence embeddings. The authors propose DeeLM, a novel method that transforms specific LLM layers into bidirectional ones by removing causal masks, enabling learning of both forward and backward dependencies. Through degradation experiments, they identify a "turning point" where exceeding certain LLM layers degrades STS performance, and extract layers after this point to make them bidirectional. DeeLM achieves state-of-the-art performance on both standard and conditional semantic textual similarity tasks.

## Method Summary
DeeLM modifies LLaMA2 models by splitting them into two components: LLM1:t (autoregressive layers retaining generation ability) and BiLLMt+1:n (bidirectional layers capturing backward dependencies). The turning point t is identified through degradation experiments showing performance degradation when exceeding specific layers. The bidirectional layers are created by removing causal masks, allowing attention to all tokens. Angle optimization is used for learning sentence embeddings, and LoRA enables efficient fine-tuning. The method leverages prompt engineering with representative words to generate sentence embeddings.

## Key Results
- DeeLM achieves 1.10-2.24% improvements over baseline LLM models on STS tasks
- Turning point identified at layer 31 for LLaMA2-7B and layer 39 for LLaMA2-13B
- Performance improvements observed on both standard and conditional semantic textual similarity tasks
- Ablation studies confirm the importance of bidirectional layers and turning point selection

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Transforming LLM layers beyond a turning point into bidirectional ones improves sentence embeddings by capturing backward dependencies.
- **Mechanism:** The authors identify a "turning point" in LLM layers where exceeding that point leads to performance degradation in semantic textual similarity tasks. They extract layers after this turning point and remove causal masks, making them bidirectional. This allows the model to attend to all tokens bidirectionally, capturing both forward and backward dependencies.
- **Core assumption:** There exists a layer-specific turning point where generation ability no longer benefits STS performance and may even harm it.
- **Evidence anchors:**
  - [abstract] "We first conducted a degradation experiment investigating the relationship between LLM layers (associated with generation ability) and STS performance. We discovered a turning point where exceeding specific LLM layers leads to dramatically decreased STS performance."
  - [section 4.3] "We discovered a turning point where exceeding specific LLM layers leads to dramatically decreased STS performance. Based on this finding, we extract the layers after the turning point and make them bidirectional by removing the causal mask."
  - [corpus] Weak - only 5 neighbor papers found, average FMR=0.373, no citations. This suggests limited direct evidence from corpus about backward dependency mechanisms specifically.

### Mechanism 2
- **Claim:** Removing causal masks in specific LLM layers introduces backward dependencies without compromising generation ability.
- **Mechanism:** The DeeLM approach removes causal masks only from layers after the turning point, while preserving the autoregressive structure in earlier layers. This maintains generation ability for prompt engineering while enhancing dependency capture in later layers.
- **Core assumption:** Generation ability is primarily associated with earlier layers, and removing causal masks from later layers won't significantly impact generation performance.
- **Evidence anchors:**
  - [abstract] "DeeLM achieves state-of-the-art performance on both the standard semantic textual similarity tasks and the conditional semantic textual similarity task."
  - [section 3] "The LLM1:t(x) component of DeeLM retains the generation ability of LLMs. It is still the autoregressive architecture. The generation ability is crucial for DeeLM as it utilizes prompt engineering..."
  - [corpus] Weak - no direct evidence in corpus about causal mask removal strategies.

### Mechanism 3
- **Claim:** Sentence embeddings benefit from backward dependencies because semantic similarity requires understanding both preceding and following context.
- **Mechanism:** The bidirectional layers learn to attend to both forward and backward context, creating more comprehensive token representations that better capture semantic relationships within sentences.
- **Core assumption:** Semantic similarity is not fully captured by forward-only attention because relationships between tokens often depend on bidirectional context.
- **Evidence anchors:**
  - [abstract] "Many widely used prior works (Reimers and Gurevych, 2019; Gao et al., 2021) have employed bidirectional networks and achieved remarkable performance in STS tasks, indicating the importance of backward dependencies."
  - [section 1] "Learning sentence embeddings does not raise concerns about information leakage, making it possible to incorporate backward dependencies to improve sentence embeddings."
  - [corpus] Weak - only indirect evidence from STS task performance, no direct corpus analysis of backward dependency effects.

## Foundational Learning

- **Concept:** Turning point identification through degradation experiments
  - Why needed here: To determine which layers can be safely converted to bidirectional without harming generation ability
  - Quick check question: How would you systematically determine the turning point if you had a different LLM architecture with a different number of layers?

- **Concept:** LoRA (Low-Rank Adaptation) for efficient fine-tuning
  - Why needed here: The paper mentions using LoRA to fine-tune DeeLM-based models due to GPU memory limitations with full-rank fine-tuning
  - Quick check question: What would be the memory requirements difference between full-rank fine-tuning and LoRA for a 7B parameter model?

- **Concept:** Angle optimization for sentence embeddings
  - Why needed here: The paper uses angle optimization (Li and Li, 2023) to learn sentence embeddings and set hyperparameters
  - Quick check question: How does angle optimization differ from standard contrastive learning approaches for sentence embeddings?

## Architecture Onboarding

- **Component map:** Input tokens → LLM1:t (autoregressive) → BiLLMt+1:n (bidirectional) → Combined output → Prompt engineering → Sentence embedding
- **Critical path:** Token input → LLM1:t → BiLLMt+1:n → combined output → prompt engineering → sentence embedding
- **Design tradeoffs:**
  - Parameter efficiency vs. performance: Using existing layers vs. adding new bidirectional layers
  - Generation ability vs. dependency capture: Balancing autoregressive and bidirectional components
  - Turning point selection: Affects both generation quality and dependency capture
- **Failure signatures:**
  - Poor STS performance: Turning point too early/late or insufficient bidirectional layers
  - Generation failure: Too many bidirectional layers affecting prompt engineering
  - Memory issues: Full-rank fine-tuning instead of LoRA
- **First 3 experiments:**
  1. Run degradation experiment to identify turning point for your specific LLM variant
  2. Test STS performance with turning point at identified layer vs. adjacent layers (t-1, t, t+1)
  3. Compare full-rank vs. LoRA fine-tuning performance and memory usage

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact turning point layer for different LLM sizes and architectures?
- Basis in paper: [explicit] The paper identifies specific turning points for LLaMA2-7B (layer 31) and LLaMA2-13B (layer 39) through degradation experiments.
- Why unresolved: The paper only tests LLaMA2 models. Other LLM architectures (GPT-3, OPT, BLOOM, etc.) and different model sizes may have different turning points.
- What evidence would resolve it: Conduct degradation experiments on multiple LLM architectures and sizes to identify their respective turning points.

### Open Question 2
- Question: Can the turning point be learned dynamically during training rather than identified through pre-training degradation experiments?
- Basis in paper: [inferred] The paper mentions this as a limitation in section 6, noting that the current method requires an additional degradation experiment to identify the turning point.
- Why unresolved: The paper proposes the concept of a turning point but does not implement a method to learn it dynamically during training.
- What evidence would resolve it: Develop and evaluate a training method that can dynamically identify and adjust the turning point during the fine-tuning process.

### Open Question 3
- Question: How does the performance of DeeLM scale with increasing model size and parameter count?
- Basis in paper: [inferred] The paper only tests DeeLM on LLaMA2-7B and LLaMA2-13B models. It does not explore how the approach performs on larger models.
- Why unresolved: The paper demonstrates effectiveness on 7B and 13B parameter models but does not test whether the approach maintains its advantage as model size increases.
- What evidence would resolve it: Evaluate DeeLM on larger LLM variants (70B, 175B parameters) and compare performance scaling relative to baseline models.

## Limitations
- The turning point identification requires additional degradation experiments, adding complexity to the fine-tuning process
- The method's effectiveness on other LLM architectures beyond LLaMA2 remains unverified
- Limited analysis of how bidirectional dependencies specifically improve semantic similarity beyond performance metrics

## Confidence

- **High confidence:** The empirical finding of a turning point where additional LLM layers degrade STS performance
- **Medium confidence:** The effectiveness of DeeLM architecture in improving STS tasks through bidirectional layer conversion
- **Low confidence:** The generalizability of the turning point phenomenon across different LLM architectures and the precise mechanism by which backward dependencies improve sentence embeddings

## Next Checks
1. Conduct degradation experiments with LLaMA2-13B and other LLM variants to verify turning point consistency across model sizes and architectures
2. Perform controlled experiments comparing DeeLM with alternative bidirectional integration strategies (e.g., dual-encoder architectures or cross-attention mechanisms) on the same STS benchmarks
3. Analyze attention patterns in DeeLM's bidirectional layers to empirically verify that backward dependencies are being captured and correlate these patterns with STS performance improvements across different sentence types