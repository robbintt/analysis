---
ver: rpa2
title: Feature Attribution Explanations for Spiking Neural Networks
arxiv_id: '2311.02110'
source_url: https://arxiv.org/abs/2311.02110
tags:
- data
- explanation
- time
- snns
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces Temporal Spike Attribution (TSA), a method
  for generating local explanations for Spiking Neural Networks (SNNs) by leveraging
  all model internal variables: spike times, weights, and membrane potentials. TSA
  is designed to address the lack of transparency in SNNs, which is a barrier to their
  deployment in critical applications such as autonomous control and biomedical devices.'
---

# Feature Attribution Explanations for Spiking Neural Networks

## Quick Facts
- arXiv ID: 2311.02110
- Source URL: https://arxiv.org/abs/2311.02110
- Reference count: 38
- Key outcome: TSA improves SNN explanation quality by incorporating weights and absent spikes, but performance degrades in deeper networks

## Executive Summary
This paper introduces Temporal Spike Attribution (TSA), a method for generating local explanations for Spiking Neural Networks (SNNs) by leveraging all model internal variables: spike times, weights, and membrane potentials. TSA addresses the transparency challenge in SNNs, which limits their deployment in critical applications like autonomous control and biomedical devices. The authors evaluate TSA using synthetic and real-world time series data, comparing it to a baseline method (SAM) that uses only spike times. TSA shows significant improvements in explanation quality, particularly in terms of correctness and output-completeness, by incorporating the influence of absent spikes. However, performance decreases for deeper SNNs, indicating the need for further refinement.

## Method Summary
TSA generates feature attribution explanations for SNNs by aggregating spike times, model weights, and output layer information through a forward pass. The method computes spike contributions using exponential decay based on a decay parameter γ, then multiplies these contributions with weights layer by layer before combining with softmax probabilities to produce final attributions. TSA includes two variants: TSA S (considering only present spikes) and TSA NS (also incorporating absent spikes with negative attributions scaled by the inverse of layer size). The method is evaluated against a baseline SAM approach that uses only spike times, on both synthetic binary time series data and real-world ADL sensor data using SNNs with 1-3 hidden layers.

## Key Results
- TSA significantly improves explanation correctness and output-completeness compared to SAM baseline
- Incorporating absent spikes enhances output-completeness by capturing the model's reasoning about inactivity
- TSA performance degrades for deeper SNNs (3+ layers) due to repeated multiplication of values in [-1, 1] across layers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating model weights directly into explanation computation improves correctness and continuity
- Mechanism: TSA multiplies spike time contributions with learned weights during forward pass, capturing learned connection strengths
- Core assumption: Weights contain meaningful feature importance information lost when using only spike times
- Evidence anchors: Abstract states TSA improves correctness; section notes SAM slightly better than TSA S in output-completeness but TSA S better in ADL experiments
- Break condition: Very large/small weights cause vanishing/exploding attribution values across layers

### Mechanism 2
- Claim: Considering absent spikes improves output-completeness by capturing model reasoning about inactivity
- Mechanism: TSA NS assigns negative attribution to absent spikes scaled by inverse layer size
- Core assumption: Model uses absence of spikes as informative features, not just active spikes
- Evidence anchors: Abstract mentions absent spikes improve explanation quality; section describes synthetic OR task designed to test absent spike reasoning
- Break condition: Inappropriate scaling factor over/under-weights absent spike attributions

### Mechanism 3
- Claim: Using all model-internal variables yields more complete and continuous explanations than spike times alone
- Mechanism: TSA aggregates spike times, weights, and softmax output probabilities in forward pass
- Core assumption: Model prediction depends on combined effect of all internal variables
- Evidence anchors: Abstract states TSA addresses SNN transparency barrier; section describes TSA combining neuron spike times, model weights, and output layer information
- Break condition: Aggregation method causes sign cancellations or value decay in deep networks

## Foundational Learning

- Concept: Spiking Neural Networks (SNNs) and leaky integrate-and-fire (LIF) dynamics
  - Why needed here: TSA is designed specifically for SNNs; understanding LIF neuron behavior is essential to interpret spike times and membrane potentials
  - Quick check question: In a LIF neuron, what happens to the membrane potential when a spike is generated?

- Concept: Temporal coding and spike train interpretation
  - Why needed here: TSA relies on assumption that spike timing carries information; misinterpreting temporal patterns leads to wrong attributions
  - Quick check question: How does TSA differentiate between influence of spike at time t vs. absence of spike at time t?

- Concept: Feature attribution and explanation metrics (correctness, output-completeness, continuity, compactness)
  - Why needed here: TSA is evaluated using these metrics; understanding them is critical to interpret experimental results and improve method
  - Quick check question: Why does TSA use absolute values when computing compactness?

## Architecture Onboarding

- Component map: Input layer → Spike encoder → Hidden layers (with weights) → Output layer (membrane potentials) → Explanation generator (TSA)
- Critical path: 1) Forward pass collects spike times S(l), membrane potentials U(L), and weights W(l) 2) Compute spike contribution matrix using exponential decay based on γ 3) Multiply spike contributions with weights layer by layer 4) Multiply final contributions with softmax probabilities 5) Output attribution map A(x, t)
- Design tradeoffs: Including absent spikes improves completeness but adds complexity; using weights improves correctness but risks instability in deep networks; discretized LIF dynamics enable efficient simulation but limit continuous gradient flow
- Failure signatures: Alternating positive/negative attributions in deep models → weight sign cancellations; uniform attributions across all input dimensions → decay parameter γ too large; explanations dominated by bias neuron → input scaling or weight initialization issues
- First 3 experiments: 1) Verify TSA S vs TSA NS on synthetic OR task: check if absent spike attributions capture correct class logic 2) Test continuity by perturbing input spike durations by ±10% and measuring explanation stability 3) Compare TSA S vs SAM on ADL data: measure correctness via incremental feature deletion and output-completeness via permutation importance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does TSA's explanation quality degrade for very deep SNNs (e.g., >3 hidden layers) and what are underlying causes?
- Basis in paper: [explicit] Authors observe explanation quality decreases for deeper SNNs due to repeated multiplication of values in [-1, 1] during aggregation across layers
- Why unresolved: Paper only provides preliminary observations for SNN-2L and SNN-3L models; exact mathematical relationship between network depth and explanation degradation not established
- What evidence would resolve it: Systematic experiments varying network depth beyond 3 layers while measuring explanation quality metrics, combined with mathematical analysis of how weight values and spike patterns interact across multiple layers

### Open Question 2
- Question: Can TSA be adapted to work with other spiking neuron models beyond LIF neurons, and what modifications would be necessary?
- Basis in paper: [explicit] Authors state TSA is applicable to any spike generation mechanism but note NCS computation requires specified decay parameter γ, which is straightforward for LIF but must be defined for more complex models
- Why unresolved: Paper only demonstrates TSA with LIF neurons and doesn't explore how explanation method would need to be modified for other neuron models or whether it would remain effective
- What evidence would resolve it: Implementation and evaluation of TSA using different spiking neuron models (e.g., Hodgkin-Huxley, Izhikevich) with appropriate decay parameter definitions, followed by comparative analysis of explanation quality

### Open Question 3
- Question: What is optimal decay parameter γ for TSA when applied to different types of time series data beyond tested synthetic and ADL datasets?
- Basis in paper: [inferred] Authors use γ equal to membrane potential decay rate for LIF neurons, but this choice is specific to experimental setup and may not generalize to other data types
- Why unresolved: Paper only demonstrates one fixed choice of γ and doesn't explore how sensitive TSA's performance is to this parameter or whether different data characteristics would warrant different γ values
- What evidence would resolve it: Systematic parameter sensitivity analysis across diverse time series datasets (e.g., medical time series, financial data, sensor networks) to identify patterns in optimal γ selection or whether adaptive γ selection is necessary

## Limitations

- No ablation studies isolate weight vs. spike-time contributions to explanation quality
- Scaling factor (1/B) for absent spikes is heuristic with no theoretical justification
- Performance degradation in deeper SNNs suggests repeated multiplication mechanism may be fundamentally unstable
- No comparisons against non-spiking explanation methods to establish relative advantages

## Confidence

- **High confidence**: TSA successfully generates explanations for SNNs; absent spike consideration improves output-completeness in synthetic tasks
- **Medium confidence**: Weight inclusion improves correctness and continuity; TSA outperforms SAM baseline on ADL data
- **Low confidence**: TSA's mechanisms generalize to deeper networks; weight-based explanations are fundamentally superior to spike-only approaches

## Next Checks

1. Perform ablation study: Compare TSA variants using only spike times, only weights, and combined to isolate each mechanism's contribution
2. Test scaling sensitivity: Systematically vary absent spike scaling factor (1/B) across layer sizes to find optimal values
3. Evaluate deep network stability: Apply TSA to 5+ layer SNNs and analyze attribution patterns for sign cancellations or vanishing values