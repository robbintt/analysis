---
ver: rpa2
title: What Makes Pre-Trained Visual Representations Successful for Robust Manipulation?
arxiv_id: '2312.12444'
source_url: https://arxiv.org/abs/2312.12444
tags:
- learning
- visual
- training
- performance
- pre-trained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We investigate the robustness of pre-trained visual representations
  for robotic manipulation under distribution shifts. We evaluate 15 pre-trained models
  on 10 manipulation tasks across two simulated environments with shifts in lighting,
  textures, and distractors.
---

# What Makes Pre-Trained Visual Representations Successful for Robust Manipulation?

## Quick Facts
- arXiv ID: 2312.12444
- Source URL: https://arxiv.org/abs/2312.12444
- Authors: 
- Reference count: 28
- Pre-trained visual representations designed for manipulation do not necessarily outperform standard models under distribution shifts

## Executive Summary
This paper investigates the robustness of pre-trained visual representations for robotic manipulation under distribution shifts. The authors evaluate 15 pre-trained models on 10 manipulation tasks across two simulated environments with shifts in lighting, textures, and distractors. Surprisingly, models designed specifically for manipulation do not outperform standard pre-trained models under these shifts. The key finding is that the emergent segmentation ability of Vision Transformer (ViT) models, measured by Jaccard index, strongly predicts out-of-distribution generalization performance. This metric outperforms other established metrics like ImageNet accuracy, in-domain accuracy, and shape-bias in predicting robustness for manipulation tasks.

## Method Summary
The study evaluates 15 pre-trained vision models on 10 manipulation tasks across two simulated environments (FrankaKitchen and Meta-World) with distribution shifts. A 2-layer MLP is trained on top of frozen, pre-trained encoders using imitation learning with 10 demonstrations. Policies are evaluated zero-shot under distribution shifts (lighting, textures, distractors). For ViT models, Jaccard index is calculated by computing mIoU on PASCAL VOC validation set. The correlation between segmentation ability and out-of-distribution performance is analyzed across all evaluated models.

## Key Results
- Manipulation-specific pre-trained models do not outperform standard pre-trained models under distribution shifts
- Emergent segmentation ability (Jaccard index) of ViT models strongly predicts out-of-distribution generalization performance
- The choice of augmentations during pre-training outweighs the importance of supervision for robustness under distribution shifts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Manipulation-specific pre-training does not provide robust generalization under distribution shifts
- Mechanism: Manipulation-specific datasets (e.g., Ego4D) are more diverse in viewpoints but less curated, which doesn't translate to improved robustness under lighting, texture, and distractor shifts
- Core assumption: Robustness under distribution shifts depends more on object segmentation/localization than on pre-training data relevance to manipulation
- Evidence anchors: [abstract] manipulation models struggle under subtle changes; [section 4] supervised ImageNet training outperforms R3M and MVP under OOD shifts

### Mechanism 2
- Claim: Emergent segmentation ability predicts out-of-distribution generalization in ViT models
- Mechanism: ViTs with higher Jaccard indices better localize and segment objects in the presence of distractors and under distribution shifts, leading to more robust manipulation performance
- Core assumption: Object segmentation/localization ability is more critical for robust manipulation than shape-bias or ImageNet accuracy
- Evidence anchors: [abstract] Jaccard index is a strong predictor of OOD generalization; [section 5] strong positive correlation between Jaccard index and OOD performance

### Mechanism 3
- Claim: Augmentation diversity during pre-training outweighs supervision importance for robustness
- Mechanism: Models trained with extensive augmentations (color-jittering, Gaussian blur, solarization) show better generalization regardless of supervised vs. self-supervised objectives
- Core assumption: Robustness to distribution shifts is driven by learning invariant features through augmentation diversity
- Evidence anchors: [section 4] supervision presence doesn't matter as much as other factors; [section 4] supervised ImageNet training remains strong baseline

## Foundational Learning

- Concept: Vision Transformer (ViT) architecture and attention mechanisms
  - Why needed here: ViTs are primary models evaluated, and their emergent segmentation ability is key finding
  - Quick check question: How do attention heads in ViTs contribute to object segmentation and localization?

- Concept: Distribution shifts and their impact on model performance
  - Why needed here: Paper focuses on evaluating model robustness under various distribution shifts
  - Quick check question: What types of distribution shifts are evaluated and how do they affect model performance?

- Concept: Jaccard index as metric for object segmentation
  - Why needed here: Jaccard index measures emergent segmentation ability and predicts OOD generalization
  - Quick check question: How is Jaccard index calculated and why is it suitable for evaluating object segmentation in this context?

## Architecture Onboarding

- Component map: Pre-trained visual models (15 total) -> Policy training (imitation learning) -> Distribution shifts (lighting, textures, distractors) -> Evaluation metrics (success rate, Jaccard index, shape-bias, ImageNet accuracy)

- Critical path: 1) Select pre-trained model, 2) Train 2-layer MLP on frozen features using imitation learning with 10 demonstrations, 3) Evaluate policies zero-shot under distribution shifts, 4) Correlate performance with metrics like Jaccard index

- Design tradeoffs: ViT vs. ResNet (ViTs have slight OOD edge but ResNets more efficient); Supervised vs. self-supervised (supervision doesn't significantly impact robustness); Manipulation-specific vs. standard pre-training (manipulation-specific doesn't necessarily improve robustness)

- Failure signatures: Poor performance under distribution shifts (model may not have learned robust features); Low Jaccard index (weak emergent segmentation ability correlated with OOD performance); Low shape-bias (model may rely more on texture than shape)

- First 3 experiments: 1) Evaluate ViT with high Jaccard index under various distribution shifts to confirm segmentation-robustness correlation, 2) Compare ViT and ResNet with similar pre-training under distribution shifts to assess architecture impact, 3) Fine-tune pre-trained model on small manipulation dataset and evaluate under distribution shifts to test if fine-tuning improves robustness vs. frozen features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do emergent segmentation scores correlate with performance across different manipulation task types?
- Basis in paper: [explicit] Paper shows segmentation score correlates with OOD performance but only tests on 10 manipulation tasks
- Why unresolved: Tested tasks may not represent full diversity of manipulation challenges
- What evidence would resolve it: Systematic evaluation across diverse manipulation taxonomies

### Open Question 2
- Question: Does segmentation advantage of ViTs persist when comparing models with similar parameter counts and training data diversity?
- Basis in paper: [inferred] Paper notes ViTs have slight edge but doesn't control for model size and data diversity
- Why unresolved: Could be confounding effects of architecture, size, or data
- What evidence would resolve it: Ablation studies matching models on size and data diversity

### Open Question 3
- Question: What is the minimal amount of data needed to achieve same level of OOD performance as large pre-training datasets?
- Basis in paper: [explicit] Paper finds manipulation models don't outperform standard models despite larger datasets
- Why unresolved: Unclear if scale or relevance of data matters more for OOD performance
- What evidence would resolve it: Systematic scaling studies with controlled data diversity

## Limitations

- Correlation between Jaccard index and OOD generalization may not hold for architectures beyond ViTs
- Manipulation-specific pre-training datasets evaluated may not be representative of all possible approaches
- Limited to simulated environments, may not fully capture real-world complexity

## Confidence

- High confidence: Supervised ImageNet pre-training remains strong baseline for model generalization under distribution shifts
- Medium confidence: Emergent segmentation ability (Jaccard index) is strong predictor of OOD generalization for ViT models
- Medium confidence: Manipulation-specific pre-training does not necessarily improve robustness under distribution shifts

## Next Checks

1. Evaluate correlation between Jaccard index and OOD generalization for broader range of model architectures (ConvNeXt, Swin Transformer) to assess generalizability
2. Conduct experiments with more diverse manipulation-specific pre-training datasets to determine if conclusion holds across wider range of data
3. Investigate relationship between other emergent properties (attention patterns, feature representations) and robustness to identify alternative predictors of generalization