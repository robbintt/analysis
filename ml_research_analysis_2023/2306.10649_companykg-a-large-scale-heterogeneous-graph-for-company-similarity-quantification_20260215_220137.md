---
ver: rpa2
title: 'CompanyKG: A Large-Scale Heterogeneous Graph for Company Similarity Quantification'
arxiv_id: '2306.10649'
source_url: https://arxiv.org/abs/2306.10649
tags:
- company
- companies
- graph
- edge
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'CompanyKG is a large-scale heterogeneous graph dataset for company
  similarity quantification, containing 1.17 million nodes and 51.06 million edges
  across 15 relation types. The dataset includes three evaluation tasks: similarity
  prediction (AUC 0.8060), competitor retrieval (Recall@100 54.65%), and similarity
  ranking (accuracy 67.52%).'
---

# CompanyKG: A Large-Scale Heterogeneous Graph for Company Similarity Quantification

## Quick Facts
- arXiv ID: 2306.10649
- Source URL: https://arxiv.org/abs/2306.10649
- Reference count: 40
- Key outcome: Large-scale heterogeneous graph dataset for company similarity quantification with 1.17M nodes, 51.06M edges across 15 relation types

## Executive Summary
CompanyKG introduces a heterogeneous graph dataset for quantifying company similarity, containing 1.17 million nodes and 51.06 million weighted edges across 15 relation types. The dataset supports three evaluation tasks: similarity prediction (AUC 0.8060), competitor retrieval (Recall@100 54.65%), and similarity ranking (accuracy 67.52%). Benchmarking results demonstrate that graph-based methods like GraphMAE outperform node-only approaches, while edge-only heuristics excel in retrieval tasks. CompanyKG serves as a benchmark for unsupervised graph learning and real-world company similarity analysis.

## Method Summary
CompanyKG is a heterogeneous graph dataset constructed from company descriptions and 15 inter-company relation types, resulting in 1.17M nodes and 51.06M weighted edges. The dataset supports three evaluation tasks: similarity prediction, competitor retrieval, and similarity ranking. Eleven baseline methods are implemented and categorized as node-only (using company embeddings), edge-only (using graph structure), and node+edge (combining both). GraphMAE and eGraphMAE show the strongest performance by learning to reconstruct masked node features while preserving graph structure.

## Key Results
- Similarity prediction achieves AUC of 0.8060 using graph-based methods
- Competitor retrieval achieves Recall@100 of 54.65% with edge-only heuristics
- Similarity ranking achieves accuracy of 67.52% with GraphMAE approach
- GraphMAE outperforms node-only methods, while edge-only heuristics excel in retrieval tasks

## Why This Works (Mechanism)

### Mechanism 1
CompanyKG's heterogeneous graph structure enables superior company similarity quantification compared to node-only or edge-only approaches. The graph integrates 15 different inter-company relations across 51.06 million edges, creating a rich representation of company relationships that captures both direct and indirect similarities through network structure.

### Mechanism 2
Self-supervised graph learning methods (GraphMAE, eGraphMAE) outperform simpler baselines by learning to reconstruct masked node features while preserving graph structure. These methods use masked graph autoencoders to learn node representations that capture both node features and graph topology, enabling better similarity quantification than methods using only raw features or simple heuristics.

### Mechanism 3
Edge weights encode meaningful similarity strength that improves retrieval and ranking tasks when incorporated into path-based heuristics. Weighted shortest path (WSP) and weighted neighbor heuristics use edge weights to prioritize stronger relationships, leading to better performance in competitor retrieval and similarity ranking.

## Foundational Learning

- **Graph Neural Networks**: Why needed here: To learn node representations that incorporate both company features and graph structure for similarity quantification. Quick check question: How does a GAT layer differ from a GCN layer in handling edge information?
- **Knowledge Graph Embeddings**: Why needed here: To represent companies and their relationships in a continuous vector space for similarity measurement. Quick check question: What is the difference between translational distance models and semantic matching models for knowledge graph embeddings?
- **Self-Supervised Learning**: Why needed here: To learn useful representations without labeled similarity data, crucial for scaling to large graphs like CompanyKG. Quick check question: How does contrastive learning differ from masked autoencoding in self-supervised graph learning?

## Architecture Onboarding

- **Component map**: Company descriptions → NLP embeddings → graph construction with 15 edge types → baseline method application → evaluation on three tasks
- **Critical path**: Raw company descriptions → NLP embeddings → graph construction with weighted edges → baseline method application → evaluation on three tasks. The most critical path is ensuring high-quality embeddings and meaningful edge weight calculation.
- **Design tradeoffs**: Node-only methods are simpler but miss graph structure; edge-only methods miss node features; node+edge methods are complex but potentially most effective. The tradeoff is between model complexity and performance gains.
- **Failure signatures**: Poor performance on similarity prediction suggests embedding quality issues; poor competitor retrieval suggests edge weight problems; poor similarity ranking suggests graph structure issues or inadequate model capacity.
- **First 3 experiments**:
  1. Evaluate cosine similarity between mSBERT embeddings on the similarity prediction task to establish baseline performance
  2. Implement and test the weighted shortest path heuristic on competitor retrieval to validate edge weight utility
  3. Train GraphMAE with mSBERT embeddings and evaluate on similarity ranking to test node+edge approach

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of CompanyKG change when incorporating temporal dynamics, such as company growth trajectories or evolving relationships over time? The paper focuses on static graph representations and does not explore dynamic or temporal aspects of company relationships.

### Open Question 2
What is the impact of edge weight calibration on the performance of graph-based methods in CompanyKG? The paper mentions that edge weights are calculated differently depending on the edge type, but does not explore the sensitivity of model performance to edge weight calibration.

### Open Question 3
How do different embedding dimensions affect the performance of node-only methods in CompanyKG? The paper tests different embedding types but does not explore the impact of varying embedding dimensions within each type.

## Limitations
- Domain-specific nature may limit generalizability to other company types or use cases
- Dataset construction relies on proprietary data sources, limiting independent verification
- Limited validation of whether 15 different edge types provide truly complementary information

## Confidence

**High Confidence**: Dataset construction methodology and evaluation task design are well-specified with code availability.

**Medium Confidence**: Benchmarking results showing GraphMAE outperforming baselines are plausible but require careful hyperparameter tuning.

**Low Confidence**: Assumption that 15 edge types provide complementary information needs further validation through ablation studies.

## Next Checks

1. **Edge Type Redundancy Analysis**: Conduct ablation studies removing individual edge types to quantify their unique contribution to similarity quantification performance across all three tasks.

2. **Cross-Domain Generalization**: Evaluate CompanyKG's methods on a different domain (e.g., academic institution similarity) to test the generalizability of heterogeneous graph approaches.

3. **Weight Quality Validation**: Implement an independent verification of edge weights by comparing with alternative similarity measures (e.g., mutual information, correlation coefficients) for selected edge types.