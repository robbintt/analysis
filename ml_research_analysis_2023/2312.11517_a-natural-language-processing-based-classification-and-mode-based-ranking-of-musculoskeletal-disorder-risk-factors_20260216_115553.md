---
ver: rpa2
title: A Natural Language Processing-Based Classification and Mode-Based Ranking of
  Musculoskeletal Disorder Risk Factors
arxiv_id: '2312.11517'
source_url: https://arxiv.org/abs/2312.11517
tags:
- risk
- factors
- problems
- distance
- factor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study applies Natural Language Processing (NLP) techniques
  to classify and rank risk factors of Musculoskeletal Disorders (MSDs). Eight NLP
  models combining pre-trained transformers, cosine similarity, and distance metrics
  were used to categorize 25 MSD risk factors into personal, biomechanical, workplace,
  psychological, and organizational classes.
---

# A Natural Language Processing-Based Classification and Mode-Based Ranking of Musculoskeletal Disorder Risk Factors

## Quick Facts
- arXiv ID: 2312.11517
- Source URL: https://arxiv.org/abs/2312.11517
- Reference count: 31
- Primary result: NLP models combined with distance metrics achieved 100% classification accuracy for MSD risk factors; survey data showed "working posture" as the most severe risk factor.

## Executive Summary
This study applies Natural Language Processing techniques to classify and rank risk factors of Musculoskeletal Disorders (MSDs). Eight NLP models combining pre-trained transformers, cosine similarity, and distance metrics were used to categorize 25 MSD risk factors into personal, biomechanical, workplace, psychological, and organizational classes. The sentence transformer with Euclidean, Bray-Curtis, and Minkowski distances achieved perfect classification accuracy (100%), while BERT with cosine similarity achieved 28%. Survey data from 1050 participants was analyzed using mode-based ranking to determine severity hierarchy. The findings showed that "working posture" was the most severe risk factor, consistent with literature rankings. "Job insecurity," "effort reward imbalance," and "poor employee facility" were also identified as significant contributors. This approach offers actionable insights for MSD prevention and workplace improvements.

## Method Summary
The study employed eight NLP models combining pre-trained transformers (BERT and SentenceTransformer) with various similarity and distance metrics to classify 25 MSD risk factors into five categories. Classification accuracy was evaluated using F1-scores and accuracy metrics. A survey of 1050 participants ranked each risk factor on a severity scale from 1 to 25, with mode-based ranking used to determine the final severity hierarchy. The classification results were validated against literature-based rankings to ensure consistency and reliability.

## Key Results
- SentenceTransformer with Euclidean, Bray-Curtis, and Minkowski distances achieved 100% classification accuracy
- BERT with cosine similarity achieved only 28% classification accuracy
- "Working posture" was identified as the most severe risk factor through mode-based ranking
- Survey results aligned precisely with existing literature rankings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: NLP models can classify MSD risk factors with high accuracy when combined with appropriate similarity or distance metrics.
- Mechanism: Pre-trained transformers generate contextual embeddings of risk factor text. These embeddings are then compared to label embeddings using cosine similarity or distance metrics (Euclidean, Bray-Curtis, Minkowski, Mahalanobis). The model predicts the label whose embedding is most similar to the risk factor embedding.
- Core assumption: The semantic content of risk factor descriptions is sufficiently captured by transformer embeddings to allow accurate classification when paired with an appropriate similarity/distance measure.
- Evidence anchors:
  - [abstract] "Eight NLP models combining pre-trained transformers, cosine similarity, and distance metrics were used to categorize 25 MSD risk factors into personal, biomechanical, workplace, psychological, and organizational classes."
  - [section] "BERT with cosine similarity achieves 28% accuracy; sentence transformer with Euclidean, Bray-Curtis, and Minkowski distances scores 100%."
  - [corpus] Weak evidence; no directly related papers found.
- Break condition: If risk factor descriptions are too short, vague, or highly overlapping in semantics, embeddings may not distinguish classes, leading to misclassification regardless of similarity metric choice.

### Mechanism 2
- Claim: Mode-based ranking of severity aligns with literature-based rankings and reflects collective participant perception.
- Mechanism: Survey participants rate each risk factor on a 1-25 severity scale. The mode (most frequent ranking) for each factor is taken as the final severity score, representing the consensus view.
- Core assumption: Individual subjective severity ratings are sufficiently consistent across participants to make the mode a stable and representative measure of perceived severity.
- Evidence anchors:
  - [abstract] "Survey data and mode-based ranking determine severity hierarchy, aligning with the literature."
  - [section] "The rankings align precisely with the previous literature, reaffirming the consistency and reliability of the approach."
  - [corpus] No related papers identified.
- Break condition: If participant ratings are highly dispersed (low inter-rater agreement), the mode may not represent a stable consensus, reducing reliability of the severity hierarchy.

### Mechanism 3
- Claim: Integrating NLP classification with empirical severity ranking provides actionable insights for targeted MSD prevention.
- Mechanism: Classification identifies which risk factors belong to which category, while ranking reveals which factors are perceived as most severe. This dual output enables organizations to prioritize interventions by both type and impact.
- Core assumption: The combination of objective classification and subjective severity ranking provides a more complete and actionable understanding than either alone.
- Evidence anchors:
  - [abstract] "Rankings offer actionable insights for MSD prevention."
  - [section] "The convergence of rankings provides actionable insights for organizations aiming to reduce the prevalence of MSDs."
  - [corpus] No related papers identified.
- Break condition: If classification errors are high or severity rankings lack consensus, the integrated insights may be misleading, leading to ineffective or misdirected interventions.

## Foundational Learning

- Concept: Natural Language Processing (NLP) and transformer models
  - Why needed here: To convert unstructured risk factor text descriptions into structured, machine-readable embeddings that can be compared for classification.
  - Quick check question: What is the role of pre-trained transformer models like BERT or SentenceTransformer in this study?

- Concept: Cosine similarity and distance metrics (Euclidean, Bray-Curtis, Minkowski, Mahalanobis)
  - Why needed here: To quantify the semantic similarity or dissimilarity between risk factor embeddings and label embeddings for classification purposes.
  - Quick check question: How does cosine similarity differ from Euclidean distance when comparing text embeddings?

- Concept: Mode-based statistical analysis
  - Why needed here: To derive a consensus-based severity ranking from individual participant ratings.
  - Quick check question: Why might the mode be preferred over the mean for ranking severity in this context?

## Architecture Onboarding

- Component map: Literature review -> 25 risk factor phrases -> manual labeling -> survey data collection -> embedding generation (BERT/SentenceTransformer) -> similarity/distance calculation -> classification -> mode calculation from survey responses -> ranking output

- Critical path: Risk factor text -> embeddings -> similarity measure -> predicted class -> validated against survey-derived severity ranking

- Design tradeoffs:
  - BERT + cosine similarity: simpler, but lower accuracy (28%)
  - SentenceTransformer + distance metrics: more complex, higher accuracy (100% for Euclidean/Bray-Curtis/Minkowski)
  - Mode ranking: robust to outliers, but sensitive to low agreement

- Failure signatures:
  - Low classification accuracy -> risk factor descriptions too ambiguous or embeddings not capturing relevant semantics
  - High variance in survey rankings -> participants lack shared understanding of risk factor severity
  - Misalignment between classification and ranking -> either model is not capturing the intended distinctions

- First 3 experiments:
  1. Validate that transformer embeddings capture semantic similarity by clustering risk factors and inspecting cluster composition.
  2. Test classification accuracy on a held-out validation set with varying embedding dimensions and similarity measures.
  3. Run a pilot survey with a small group to check inter-rater reliability before full deployment.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do individual factors like age, gender, and anthropometry interact with biomechanical and workplace factors to influence MSD risk?
- Basis in paper: [explicit] The paper discusses personal, biomechanical, and workplace risk factors separately but notes their complex interplay.
- Why unresolved: The study classified risk factors but did not analyze interactions between categories or quantify combined effects.
- What evidence would resolve it: Empirical data examining how personal characteristics modify the impact of biomechanical/workplace factors on MSD outcomes, ideally through multivariate modeling.

### Open Question 2
- Question: Would incorporating qualitative data improve the accuracy of MSD risk factor classification and severity rankings?
- Basis in paper: [inferred] The study relied solely on quantitative survey data and NLP analysis, noting limitations of this approach.
- Why unresolved: The study acknowledges potential subjectivity in survey responses but did not explore qualitative methods to complement the findings.
- What evidence would resolve it: Comparative analysis of classification/ranking accuracy using both quantitative and qualitative data from the same population.

### Open Question 3
- Question: How do cultural and occupational differences affect the perceived severity of MSD risk factors across different populations?
- Basis in paper: [explicit] The study notes geographical representation in survey participants but does not analyze cultural/occupational variations.
- Why unresolved: While the study included diverse participants, it did not examine how cultural or occupational contexts might influence risk perception.
- What evidence would resolve it: Cross-cultural studies comparing risk factor severity rankings across different countries and occupational sectors.

## Limitations
- Unusually high 100% classification accuracy may indicate overfitting or insufficient validation
- Mode-based ranking assumes consistent participant responses without reporting inter-rater reliability metrics
- No statistical measures of agreement between NLP-derived classifications and literature-based rankings

## Confidence

- Classification accuracy claims: Medium - 100% accuracy appears unusually high and may indicate overfitting
- Mode-based ranking methodology: Low - no inter-rater reliability metrics reported to validate consensus
- Alignment with literature: Medium - claimed alignment not quantified with statistical measures

## Next Checks

1. Reproduce classification results with cross-validation to verify the 100% performance is not an artifact of data leakage or overfitting.

2. Assess inter-rater reliability by calculating ICC or Fleiss' kappa for survey responses to quantify participant agreement.

3. Compare mode-based rankings with mean and median-based approaches to test whether mode is the most appropriate measure.