---
ver: rpa2
title: Synthetic images aid the recognition of human-made art forgeries
arxiv_id: '2312.14998'
source_url: https://arxiv.org/abs/2312.14998
tags:
- forgeries
- gans
- synthetic
- training
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that synthetic forgeries generated by Stable
  Diffusion and StyleGAN can significantly improve the accuracy of AI-based art forgery
  detection. The authors augment training datasets of known forgeries with synthetic
  images in the style of specific artists and show that this consistently improves
  the classification of human-made forgeries.
---

# Synthetic images aid the recognition of human-made art forgeries

## Quick Facts
- arXiv ID: 2312.14998
- Source URL: https://arxiv.org/abs/2312.14998
- Reference count: 40
- Synthetic forgeries generated by Stable Diffusion and StyleGAN improve AI-based art forgery detection accuracy

## Executive Summary
This study demonstrates that synthetic forgeries generated by Stable Diffusion and StyleGAN can significantly improve the accuracy of AI-based art forgery detection. The authors augment training datasets of known forgeries with synthetic images in the style of specific artists and show that this consistently improves the classification of human-made forgeries. The best results are achieved when using Stable Diffusion-generated images. The approach is validated across multiple artists including van Gogh, Modigliani, and Raphael, and using different classifier architectures. Additionally, the study confirms that training on synthetic forgeries enables the detection of AI-generated forgeries, especially when the same generative model is used.

## Method Summary
The study uses human-made forgeries and imitations in the style of well-known artists (van Gogh, Modigliani, and Raphael) and augments training sets with images in a similar style generated by Stable Diffusion and StyleGAN. The authors train Swin Base and EfficientNet B0 models on binary classification tasks, comparing performance with and without synthetic data. They evaluate detection accuracy using confusion matrices and cross-validated median values with 68% uncertainty across different synthetic data types (raw GANs, tuned GANs, diffusion).

## Key Results
- Synthetic forgeries generated by Stable Diffusion consistently improve classification accuracy for detecting human-made forgeries
- Training with synthetic forgeries enables detection of AI-generated forgeries, especially when created using similar generative models
- The quality and diversity of synthetic data significantly impact classifier performance, with high-quality synthetic data leading to better generalization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic forgeries capture key stylistic features of an artist's work, allowing classifiers to learn finer distinctions between authentic and forged styles
- Mechanism: By augmenting training datasets with synthetic images in the style of specific artists, the classifier learns subtle stylistic cues that differentiate genuine works from imitations
- Core assumption: The synthetic forgeries share enough stylistic similarity with human forgeries to act as effective proxies in training
- Evidence anchors: Abstract states "The best results are achieved when using Stable Diffusion-generated images" and section notes using "human-made forgeries and imitations in the style of well-known artists"

### Mechanism 2
- Claim: Including synthetic forgeries in training enables classifiers to detect AI-generated forgeries
- Mechanism: Training on synthetic images generated by specific AI models allows the classifier to learn unique patterns and artifacts associated with that model's output
- Core assumption: AI-generated forgeries have identifiable patterns that can be learned by the classifier
- Evidence anchors: Abstract states "inclusion of synthetic forgeries in the training also enables the detection of AI-generated forgeries" and section notes "highest authentication accuracy is obtained if the classifier had already seen synthetic images by the same generator architecture"

### Mechanism 3
- Claim: Quality and diversity of synthetic data influence classifier generalization
- Mechanism: High-quality, diverse synthetic datasets provide richer learning experience, allowing classifiers to recognize broader range of stylistic variations
- Core assumption: Greater diversity and quality in synthetic data lead to better generalization and detection performance
- Evidence anchors: Section states "quality of synthetic data plays a crucial role in training success" and notes that "training solely on 'raw GAN' images resulted in minor or no improvement"

## Foundational Learning

- Concept: Understanding of Generative Adversarial Networks (GANs) and diffusion models
  - Why needed here: The study relies on using StyleGAN and Stable Diffusion to generate synthetic forgeries
  - Quick check question: Can you explain the basic working principles of GANs and diffusion models?

- Concept: Knowledge of image classification and feature extraction in machine learning
  - Why needed here: The study involves training classifiers to distinguish between authentic and forged artworks
  - Quick check question: How do convolutional neural networks (CNNs) extract features from images?

- Concept: Familiarity with cross-validation and performance metrics in machine learning
  - Why needed here: The study uses cross-validation to assess reliability and employs metrics like accuracy and confusion matrices
  - Quick check question: What is the purpose of cross-validation, and how does it help in assessing model performance?

## Architecture Onboarding

- Component map: Data Generation -> Data Preparation -> Classification Models -> Evaluation
- Critical path: Generate synthetic forgeries -> Augment training datasets -> Train classifiers -> Evaluate performance
- Design tradeoffs: Larger models improve performance but increase computational costs; balancing synthetic to human-made forgery ratios; ensuring synthetic data diversity
- Failure signatures: Poor test performance indicates generalization issues; inability to detect synthetic forgeries suggests lack of learned patterns; high false positives indicate overfitting
- First 3 experiments:
  1. Train classifier on dataset with only human-made forgeries and evaluate performance
  2. Augment training dataset with Stable Diffusion synthetic forgeries and retrain classifier
  3. Test classifier's ability to detect synthetic forgeries generated by both Stable Diffusion and StyleGAN

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal ratio of human-made forgeries to synthetic data for improving art forgery detection accuracy?
- Basis in paper: The paper mentions this as a direction for future exploration but does not investigate it experimentally
- Why unresolved: The study focuses on demonstrating the benefit of adding synthetic data, but does not systematically vary the proportion
- What evidence would resolve it: Experiments testing different ratios of synthetic to human-made forgeries in training datasets

### Open Question 2
- Question: How does image resolution affect the performance of both generative models and classifiers in art forgery detection?
- Basis in paper: The paper notes this as a limitation and potential area for future work requiring more computational resources
- Why unresolved: The study uses fixed resolutions (256x256 and 224x224) without exploring impact of different resolutions
- What evidence would resolve it: Comparative studies using different image resolutions for both synthetic data generation and classifier training

### Open Question 3
- Question: Can dedicated post-training of generative models like Stable Diffusion on authentic artworks of specific artists further enhance synthetic data quality?
- Basis in paper: The authors suggest this as a potential improvement requiring more computational resources
- Why unresolved: The study uses general-purpose generative models without artist-specific fine-tuning
- What evidence would resolve it: Experiments comparing forgery detection accuracy using synthetic data from general-purpose vs. artist-specific fine-tuned generative models

## Limitations
- Limited validation to three artists (van Gogh, Modigliani, and Raphael) may not generalize to other artistic styles
- Exact prompt templates and hyperparameters for synthetic image generation are not fully detailed
- Performance metrics focus on binary classification accuracy without addressing potential biases or robustness to novel forgery techniques

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Stable Diffusion-generated images improve forgery detection accuracy | High |
| Results generalize to other artists and artistic styles | Medium |
| Approach is robust to evolving forgery techniques and new generative models | Low |

## Next Checks

1. **Cross-Style Validation**: Test the approach on a broader range of artistic styles and periods to assess generalizability beyond the current dataset
2. **Adversarial Testing**: Evaluate the classifier's performance against deliberately crafted adversarial examples or emerging forgery techniques to assess robustness
3. **Real-World Deployment**: Conduct a pilot study in a real-world art authentication scenario to measure practical effectiveness and identify potential deployment challenges