---
ver: rpa2
title: Primacy Effect of ChatGPT
arxiv_id: '2310.13206'
source_url: https://arxiv.org/abs/2310.13206
tags:
- chatgpt
- label
- arxiv
- primacy
- effect
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates whether ChatGPT exhibits the primacy effect,
  a cognitive bias where humans tend to select items at the beginning of a list. To
  test this, the authors shuffle the labels in the prompt before each prediction and
  observe how ChatGPT's predictions change.
---

# Primacy Effect of ChatGPT

## Quick Facts
- arXiv ID: 2310.13206
- Source URL: https://arxiv.org/abs/2310.13206
- Authors: 
- Reference count: 18
- Key outcome: ChatGPT exhibits primacy effect, showing label order sensitivity and preference for earlier-positioned labels in predictions

## Executive Summary
This paper investigates whether ChatGPT exhibits the primacy effect, a cognitive bias where humans tend to select items at the beginning of a list. Through systematic experiments across multiple natural language understanding tasks, the authors demonstrate that ChatGPT's predictions are highly sensitive to the order of labels presented in the prompt. When labels are shuffled, ChatGPT's predictions change in over 85% of cases, and it shows a clear bias towards selecting labels at earlier positions. The magnitude of this effect increases with task difficulty, suggesting that the model relies more on positional cues when semantic understanding is insufficient.

## Method Summary
The authors test ChatGPT's sensitivity to label order by shuffling label definitions in prompts before each prediction. They use the OpenAI API with gpt-3.5-turbo (temperature 0.0) across multiple datasets including TACRED for relation extraction, Banking77 for intent detection, and others. For each instance, they generate predictions with original label order and shuffled label order, then compare the results. They measure sensitivity by calculating the percentage of instances where predictions change after shuffling, and assess fairness using JS divergence between predicted and uniform label distributions. The experiments span both relation extraction and intent detection tasks to examine how task difficulty affects the primacy effect.

## Key Results
- ChatGPT's predictions change after label shuffling on 87.9% of instances in TACRED
- ChatGPT shows clear bias towards selecting labels at earlier positions in the prompt
- The magnitude of primacy effect increases with task difficulty, being more pronounced in relation extraction than intent detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPT's predictions are sensitive to the order of labels in the prompt, with over 85% of instances showing different predictions after shuffling.
- Mechanism: The model's understanding of the prompt is influenced by the sequence in which labels are presented, leading to different outputs when the order is changed.
- Core assumption: ChatGPT's decision-making process is affected by the position of labels in the prompt, not just their semantic content.
- Evidence anchors:
  - [abstract]: "ChatGPT's decision is sensitive to the order of labels in the prompt"
  - [section]: "Specifically, ChatGPT's prediction changes after a label shuffling on 87.9% of the instances in TACRED"
  - [corpus]: Found related papers discussing primacy effect in LLMs, but specific evidence for this claim is primarily from the paper's own experiments.
- Break condition: If the model's predictions were based solely on the semantic content of labels, shuffling would not affect outcomes.

### Mechanism 2
- Claim: ChatGPT exhibits a clear bias towards selecting labels at earlier positions in the prompt.
- Mechanism: The model has a preference for labels presented first, leading to higher selection rates for earlier-positioned labels.
- Core assumption: The model's attention or processing is influenced by the order of information presentation.
- Evidence anchors:
  - [abstract]: "ChatGPT has a clearly higher chance to select the labels at earlier positions as the answer"
  - [section]: "ChatGPT tends to select labels in earlier positions in the prompt (see Fig. 1)"
  - [corpus]: Related work on primacy effect in AI, but specific evidence for this bias in ChatGPT comes from the paper's analysis.
- Break condition: If the model's predictions were uniformly distributed across all label positions.

### Mechanism 3
- Claim: The magnitude of ChatGPT's primacy effect increases with task difficulty.
- Mechanism: In more challenging tasks, the model relies more heavily on positional cues due to insufficient semantic understanding.
- Core assumption: The model's performance degrades in difficult tasks, leading to increased reliance on non-semantic factors.
- Evidence anchors:
  - [section]: "Notably, the influence of primacy effects is higher in more challenging tasks"
  - [section]: "In more difficult tasks, ChatGPT lacks sufficient discriminative semantic understanding from the input text and may be more affected by the label order"
  - [corpus]: Weak evidence; the paper doesn't cite external studies on this specific relationship.
- Break condition: If the model's performance improved with task difficulty, or if positional bias remained constant across task complexities.

## Foundational Learning

- Concept: Primacy Effect
  - Why needed here: Understanding this cognitive bias is crucial to interpreting the model's behavior and the significance of the findings.
  - Quick check question: What is the primacy effect, and how does it relate to human decision-making?

- Concept: Zero-shot learning
  - Why needed here: The study examines ChatGPT's performance in zero-shot settings, which is important for understanding its capabilities and limitations.
  - Quick check question: How does zero-shot learning differ from few-shot or fine-tuned learning approaches?

- Concept: Label shuffling as a debiasing technique
  - Why needed here: This method is used to isolate and measure the impact of label order on model predictions.
  - Quick check question: How does random label shuffling help in identifying positional biases in model predictions?

## Architecture Onboarding

- Component map: Text preprocessing -> Prompt construction (task + input + labels) -> Model inference (ChatGPT) -> Output processing and analysis
- Critical path:
  1. Prepare input text and label definitions
  2. Construct prompt with labels in specific order
  3. Send prompt to ChatGPT API
  4. Receive and process model's prediction
  5. Analyze prediction in relation to label order
- Design tradeoffs:
  - Using zero-shot learning allows for flexibility but may introduce biases
  - Label shuffling provides insights but increases computational cost
  - The study focuses on ChatGPT, limiting generalizability to other models
- Failure signatures:
  - High variance in predictions across different label orders
  - Consistent preference for labels in specific positions
  - Correlation between task difficulty and magnitude of positional bias
- First 3 experiments:
  1. Reproduce the label shuffling experiment on a simple intent detection dataset
  2. Test the effect of different prompt formulations on the magnitude of the primacy effect
  3. Compare ChatGPT's performance with fine-tuned models on the same tasks to quantify the impact of the bias

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do other large language models, such as Google Bard or Vicuna, exhibit similar primacy effects when presented with label-shuffled prompts?
- Basis in paper: [inferred] The paper focuses on ChatGPT and suggests that its cognitive biases may be due to training on human-labeled data. It would be beneficial to assess this effect on other LLMs.
- Why unresolved: The study only tested ChatGPT and did not compare its behavior with other LLMs.
- What evidence would resolve it: Conducting experiments with other LLMs using the same label shuffling method to see if they also exhibit primacy effects.

### Open Question 2
- Question: Can the negative impacts of the primacy effect in ChatGPT be mitigated through fine-tuning or prompt engineering techniques?
- Basis in paper: [inferred] The paper mentions the need for further studies to propose effective solutions that can mitigate the negative impacts associated with the primacy effect.
- Why unresolved: The paper only analyzed the existence of the primacy effect and did not explore potential solutions to mitigate it.
- What evidence would resolve it: Developing and testing methods to reduce the primacy effect's influence on ChatGPT's predictions and evaluating their effectiveness.

### Open Question 3
- Question: How does the difficulty of a task affect the magnitude of the primacy effect in ChatGPT?
- Basis in paper: [explicit] The paper notes that the influence of primacy effects is higher in more challenging tasks, such as relation extraction compared to intent detection.
- Why unresolved: While the paper observes a correlation between task difficulty and primacy effect magnitude, it does not explore the underlying reasons for this relationship.
- What evidence would resolve it: Conducting experiments with tasks of varying difficulty levels to quantify the relationship between task complexity and the strength of the primacy effect.

## Limitations

- The study focuses specifically on ChatGPT (gpt-3.5-turbo) and may not generalize to other LLM architectures or sizes
- The analysis primarily examines English language tasks, leaving open questions about cross-linguistic consistency
- The paper does not explore potential mitigation strategies or the underlying mechanisms driving this behavior

## Confidence

**Major Claims Confidence:**
- Primacy effect exists in ChatGPT's predictions: **High**
- Effect magnitude correlates with task difficulty: **Medium**
- Impact on fairness and reliability of predictions: **High**

## Next Checks

1. Test whether other LLM families (Claude, LLaMA, PaLM) exhibit similar primacy effects under controlled conditions
2. Conduct ablation studies to isolate whether this behavior stems from attention mechanisms, tokenization, or prompt formatting
3. Implement and evaluate debiasing techniques (e.g., random label presentation, ensemble methods) to quantify the practical impact on downstream task performance