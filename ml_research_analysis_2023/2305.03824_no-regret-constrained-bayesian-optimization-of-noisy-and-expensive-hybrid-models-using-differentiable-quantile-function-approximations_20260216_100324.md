---
ver: rpa2
title: No-Regret Constrained Bayesian Optimization of Noisy and Expensive Hybrid Models
  using Differentiable Quantile Function Approximations
arxiv_id: '2305.03824'
source_url: https://arxiv.org/abs/2305.03824
tags:
- function
- optimization
- cuqb
- functions
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses constrained global optimization of composite
  functions, which are common in real-world science and engineering applications.
  The authors propose a novel algorithm, Constrained Upper Quantile Bound (CUQB),
  that exploits the composite structure of the objective and constraint functions
  to improve sampling efficiency.
---

# No-Regret Constrained Bayesian Optimization of Noisy and Expensive Hybrid Models using Differentiable Quantile Function Approximations

## Quick Facts
- arXiv ID: 2305.03824
- Source URL: https://arxiv.org/abs/2305.03824
- Reference count: 40
- This paper proposes CUQB, a novel algorithm for constrained global optimization of composite functions that exploits composite structure to improve sampling efficiency while providing theoretical guarantees on regret and constraint violation.

## Executive Summary
This paper addresses the challenge of constrained global optimization of composite functions, which are common in real-world science and engineering applications where the objective and constraints are compositions of known functions and an expensive black-box function. The authors propose CUQB (Constrained Upper Quantile Bound), a deterministic approach that exploits the composite structure by modeling the black-box function as a multi-output Gaussian process and analytically propagating its uncertainty through the known composite functions. CUQB uses a novel differentiable sample average approximation of the quantile function to efficiently maximize its acquisition function, and incorporates a finite-time infeasibility detection scheme. The authors derive bounds on cumulative regret and constraint violation, and demonstrate through numerical experiments that CUQB significantly outperforms traditional Bayesian optimization and achieves competitive empirical performance compared to state-of-the-art methods while providing substantially improved theoretical guarantees.

## Method Summary
CUQB models the expensive black-box function h(x) as a multi-output Gaussian process and constructs quantile bounds for the composite objective and constraint functions by analytically propagating the GP uncertainty through the known composite functions. At each iteration, CUQB solves an auxiliary constrained optimization problem to select the next query point, using a differentiable sample average approximation of the quantile function based on a soft sorting operator. The method includes an infeasibility detection scheme that triggers in finite time with high probability when the original problem is infeasible. CUQB returns the point with the largest penalized lower quantile bound as the final recommendation.

## Key Results
- CUQB achieves significantly lower cumulative regret and constraint violation compared to traditional Bayesian optimization on test problems
- CUQB's infeasibility detection scheme triggers in finite time with high probability when the original problem is infeasible
- Numerical experiments show CUQB achieves competitive empirical performance compared to state-of-the-art methods that exploit composite structure while providing substantially improved theoretical guarantees

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CUQB exploits composite structure to achieve tighter quantile bounds and faster convergence than black-box methods.
- Mechanism: By modeling h(x) as a multi-output GP and analytically propagating its uncertainty through the known composite functions gi(x,y), CUQB constructs tighter upper and lower quantile bounds than black-box methods that model f(x)=gi(x,h(x)) directly as a single GP.
- Core assumption: The composite functions gi(x,y) are Lipschitz continuous in y and can be cheaply evaluated.
- Evidence anchors:
  - [abstract] "CUQB is a conceptually simple, deterministic approach that avoid constraint approximations used by previous methods."
  - [section 3.4] "it has been shown that the former approach necessarily leads to a reduction in variance compared to the latter approach [52, Theorem 1]"
  - [corpus] Weak - corpus neighbors focus on general Bayesian optimization rather than composite structure exploitation
- Break condition: If gi(x,y) are highly nonlinear or discontinuous in y, the quantile bound tightness degrades and convergence slows.

### Mechanism 2
- Claim: The differentiable soft sorting approximation enables efficient gradient-based optimization of CUQB's acquisition function.
- Mechanism: Instead of using exact sorting in the empirical quantile estimation, CUQB uses the SoftSort operator which is strongly convex and differentiable, allowing gradients to be computed via backpropagation and enabling use of gradient-based solvers like IPOPT.
- Core assumption: The regularization parameter in SoftSort is sufficiently large to approximate exact sorting while maintaining differentiability.
- Evidence anchors:
  - [section 3.3] "By replacing Sort with SoftSort in (15), one can efficiently compute derivatives of ui,t(x) with respect to x"
  - [section 3.3] "It has been shown that SoftSort converges to the exact Sort function as the regularization strength tends to infinity"
  - [corpus] Weak - corpus neighbors do not discuss differentiable sorting approximations
- Break condition: If the regularization parameter is too small, SoftSort fails to approximate exact sorting; if too large, gradients become unstable.

### Mechanism 3
- Claim: CUQB's infeasibility detection triggers in finite time with high probability when the original problem is infeasible.
- Mechanism: By monitoring whether maxx∈X ui,t(x) < 0 for any constraint i, CUQB can declare infeasibility when the upper quantile bound for all constraints is strictly negative, which occurs with high probability after finite iterations if the problem is truly infeasible.
- Core assumption: The quantile bounds ui,t(x) converge to the true function values as t increases, and the problem is infeasible.
- Evidence anchors:
  - [abstract] "CUQB further incorporates a simple infeasibility detection scheme, which we prove triggers in a finite number of iterations (with high probability) when the original problem is infeasible."
  - [section 4.5] "Given a desired confidence level δ∈(0,1), the CUQB method (Algorithm 1) will declare infeasibility in Line 3 within a finite number of iterations"
  - [corpus] Weak - corpus neighbors focus on general Bayesian optimization rather than infeasibility detection
- Break condition: If the quantile bounds are too conservative or the problem is barely feasible, infeasibility may be declared incorrectly.

## Foundational Learning

- Concept: Multi-output Gaussian processes with Kronecker structure
  - Why needed here: CUQB models h(x) as a multi-output GP to capture correlations between outputs and reduce computational complexity compared to modeling each output independently.
  - Quick check question: What is the computational complexity of predicting m outputs using a multi-output GP with Kronecker structure versus m independent GPs?

- Concept: Quantile functions and their relationship to confidence intervals
  - Why needed here: CUQB uses quantile bounds (upper and lower) to construct optimistic and pessimistic estimates of the composite functions, which are used in the acquisition function and constraint handling.
  - Quick check question: How do you compute the α-level upper quantile bound QY(x)(1-α/2) for a transformed Gaussian random variable Y=g(X) where X~N(µ,Σ)?

- Concept: Lipschitz continuity and its role in bounding transformed random variables
  - Why needed here: The Lipschitz assumption on the composite functions gi(x,y) allows CUQB to bound the width of the quantile intervals in terms of the Lipschitz constants and the standard deviations of the underlying GP predictions.
  - Quick check question: If Y=g(X) where g is L-Lipschitz and X~N(µ,Σ), what is an upper bound on Pr(|Y-E[Y]| > t) for any t > 0?

## Architecture Onboarding

- Component map: Multi-output GP model for h(x) with posterior mean µt(x) and covariance Σt(x) -> Quantile bound functions li,t(x) and ui,t(x) computed via Monte Carlo sampling and soft sorting -> Auxiliary constrained optimization problem to select next query point xt+1 -> Recommendation procedure to select final solution from evaluated points -> Infeasibility detection based on maxx∈X ui,t(x) < 0

- Critical path: 1. Initialize GP model with Ninit random samples 2. At each iteration t: a. Check for infeasibility (maxx∈X ui,t(x) < 0 for any i) b. Solve auxiliary optimization problem to select xt+1 c. Query h at xt+1 to get noisy observation yt+1 d. Update GP model with new data 3. After T iterations, select final solution using recommendation procedure

- Design tradeoffs:
  - Monte Carlo sample size L vs. quantile estimation accuracy
  - Soft sorting regularization strength vs. approximation quality and gradient stability
  - Number of random restarts for IPOPT vs. probability of finding global optimum
  - Choice of GP kernel (linear, squared exponential, Matern) vs. convergence rate

- Failure signatures:
  - Flat regions in acquisition function due to linearization approximations (COBALT)
  - Slow convergence due to conservative quantile bounds or poor GP modeling
  - Premature infeasibility declaration due to overly optimistic upper bounds
  - Numerical instability in gradient computation for soft sorting

- First 3 experiments:
  1. Compare CUQB to EPBO and EIC on the Mystery problem with d=5, m=2, n=1; measure penalized regret vs. iterations
  2. Evaluate CUQB's infeasibility detection on a problem with no feasible solutions; record iteration when infeasibility is declared
  3. Study the impact of Monte Carlo sample size L on CUQB's performance by running experiments with L ∈ {100, 500, 1000} on the Rosen-Suzuki problem

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- The theoretical guarantees rely on Lipschitz continuity of the composite functions, which may not hold for many real-world applications.
- Empirical evaluation focuses on relatively low-dimensional problems (d ≤ 10) and small numbers of constraints (n ≤ 2), leaving uncertainty about scalability.
- The differentiable sorting approximation introduces an additional hyperparameter (regularization strength) that may require problem-specific tuning.
- Computational complexity of solving the auxiliary constrained optimization problem at each iteration using IPOPT with random restarts could become prohibitive for expensive function evaluations.

## Confidence
- Theoretical Regret Bounds: Medium confidence - The bounds are derived under idealized assumptions (known Lipschitz constants, perfect quantile estimation) that may not hold in practice.
- Empirical Performance Claims: Medium confidence - The benchmarks show competitive results but are limited to synthetic test functions with known structure.
- Infeasibility Detection: Low confidence - The finite-time detection guarantee relies on quantile bounds converging to true values, which may be slow in practice.

## Next Checks
1. **Scalability Study**: Evaluate CUQB on benchmark problems with d ≥ 20 and n ≥ 5 to assess computational scalability and performance degradation with increasing dimensionality and constraint complexity.

2. **Robustness to Function Structure**: Test CUQB on problems where the composite functions violate Lipschitz continuity assumptions (e.g., discontinuous or highly nonlinear transformations) to identify failure modes and degradation in performance.

3. **Regularization Parameter Sensitivity**: Conduct a systematic sensitivity analysis of CUQB's performance with respect to the soft sorting regularization strength parameter across different problem classes to provide practical guidance for hyperparameter selection.