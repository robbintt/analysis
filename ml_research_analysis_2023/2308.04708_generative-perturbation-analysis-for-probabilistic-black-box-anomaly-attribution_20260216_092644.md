---
ver: rpa2
title: Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution
arxiv_id: '2308.04708'
source_url: https://arxiv.org/abs/2308.04708
tags:
- attribution
- anomaly
- distribution
- uni00000014
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles anomaly attribution in the doubly black-box
  regression setting, where the goal is to compute the probability distribution of
  input variable contributions given an anomalous observation, without access to training
  data. The authors show that existing methods like Shapley values and integrated
  gradients are "deviation-agnostic" - they explain the model itself rather than the
  observed deviation.
---

# Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution

## Quick Facts
- **arXiv ID:** 2308.04708
- **Source URL:** https://arxiv.org/abs/2308.04708
- **Reference count:** 40
- **Primary result:** Introduces GPA framework for probabilistic black-box anomaly attribution with uncertainty quantification

## Executive Summary
This paper addresses the challenge of computing probability distributions of input variable contributions for anomalous observations in doubly black-box regression settings, where neither training data nor model internals are accessible. The authors demonstrate that existing attribution methods like Shapley values and integrated gradients are "deviation-agnostic" - they explain model behavior rather than the observed deviation from normalcy. They propose Generative Perturbation Analysis (GPA), which models perturbations as parameters and uses variational inference to derive attribution score distributions that quantify each input's responsibility for the anomaly.

## Method Summary
GPA tackles anomaly attribution by considering a counterfactual generative process where perturbations are introduced to bring anomalous observations back to normalcy. The method treats the perturbation vector as a model parameter and employs variational Bayesian inference to approximate the posterior distribution of these perturbations. Through MAP estimation with proximal gradient descent, GPA computes per-variable attribution score distributions that capture both the magnitude and uncertainty of each input's contribution to the anomaly. The framework provides deviation sensitivity - attribution scores change based on the magnitude of the observed anomaly - unlike baseline methods that remain constant regardless of deviation size.

## Key Results
- GPA achieves high consistency with baseline methods (LC, LIME, IG, SV, Z-score) while providing uncertainty quantification
- Successfully identifies top contributors on multiple real-world datasets (Diabetes, BostonHousing, CaliforniaHousing)
- Demonstrates deviation sensitivity on synthetic 2Dsinusoidal data where baseline methods fail to distinguish between different anomaly magnitudes
- Derives analytical solutions for synthetic models, validating GPA's theoretical framework

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** GPA explains deviations by modeling perturbations as model parameters and using variational inference to derive attribution score distributions
- **Mechanism:** The generative model treats perturbation vector δ as a parameter, with observed anomaly (x_t, y_t) generated through a process that can be explained by finding the posterior distribution of δ. Variational Bayes decomposes this into per-variable distributions q_k(δ_k) that directly quantify each input's responsibility
- **Core assumption:** The deviation from normalcy can be modeled as a zero-mean Gaussian perturbation around the normal regression surface
- **Evidence anchors:**
  - [abstract]: "This is done by considering a generative process for perturbations that counter-factually bring the observed anomalous observation back to normalcy"
  - [section]: "The key idea is to consider a counterfactual data generative process including perturbation δ as a model parameter"
  - [corpus]: Weak evidence - no direct corpus mentions of GPA's variational decomposition approach
- **Break condition:** If the perturbation distribution is multi-modal or highly non-Gaussian, the factorized approximation in Eq.(12) may fail to capture the true posterior structure

### Mechanism 2
- **Claim:** Existing methods (LIME, IG, SV) are "deviation-agnostic" because they explain model behavior rather than observed deviations
- **Mechanism:** These methods compute attributions based on local gradients or increments from baseline points, which remain constant regardless of the observed anomaly magnitude. They fail to distinguish between normal predictions and anomalous observations
- **Core assumption:** The black-box function f(x) can be locally approximated by linear or polynomial expansions
- **Evidence anchors:**
  - [abstract]: "We begin by showing that mainstream model-agnostic explanation methods, such as the Shapley values, are not suitable for this task because of their 'deviation-agnostic property'"
  - [section]: "Theorem 1. LIME is deviation-agnostic: LIME_i(x_t, y_t) = LIME_i(x_t)"
  - [corpus]: Strong evidence - Black-Box Anomaly Attribution paper explicitly discusses this limitation
- **Break condition:** If the black-box function has discontinuous gradients or non-smooth behavior, local approximation methods may produce unreliable attributions

### Mechanism 3
- **Claim:** GPA provides uncertainty quantification through posterior distributions while maintaining locality of explanation
- **Mechanism:** The t-distribution posterior naturally incorporates both the regression noise and the prior uncertainty about perturbations. Each variable's contribution is represented as a probability distribution q_k(δ_k) that captures the range of plausible values
- **Core assumption:** The noise in the regression function follows a t-distribution with conjugate gamma prior on precision
- **Evidence anchors:**
  - [abstract]: "This is done by considering a generative process for perturbations that counter-factually bring the observed anomalous observation back to normalcy"
  - [section]: "The integration can be performed analytically, yielding the following form of the likelihood: Q(δ) ∝ p(δ) Π_t ∫_0^∞ dλ p(y_t|x_t, δ, λ)p(λ)"
  - [corpus]: Weak evidence - no direct corpus mentions of GPA's uncertainty quantification mechanism
- **Break condition:** If the regression function has high-frequency oscillations, the local gradient estimates may be too noisy for stable MAP optimization

## Foundational Learning

- **Concept:** Variational Bayesian inference for approximate posterior estimation
  - **Why needed here:** GPA requires computing intractable posterior distributions over high-dimensional perturbation spaces, which is solved through variational approximation with factorized form
  - **Quick check question:** What is the key difference between variational inference and MCMC sampling in terms of computational efficiency?

- **Concept:** Proximal gradient descent for ℓ1-regularized optimization
  - **Why needed here:** MAP estimation in GPA involves minimizing a non-differentiable objective with ℓ1 regularization, requiring specialized optimization techniques
  - **Quick check question:** How does the soft-thresholding operation in Eq.(24) relate to the subgradient of the ℓ1 norm?

- **Concept:** Counterfactual reasoning in anomaly attribution
  - **Why needed here:** GPA's core insight is that anomalies can be explained by finding perturbations that would make the observation normal, rather than explaining model behavior
  - **Quick check question:** What is the fundamental difference between explaining "why this prediction" vs "why this deviation"?

## Architecture Onboarding

- **Component map:** Test sample (x_t, y_t) -> MAP optimization -> Perturbation distribution -> Attribution scores
- **Critical path:** Test sample → MAP optimization → Perturbation distribution → Attribution scores
  - Each step depends on the previous one; failure in MAP optimization prevents distribution construction

- **Design tradeoffs:**
  - Factorized posterior vs joint posterior: Computational efficiency vs accuracy
  - ℓ1 vs ℓ2 regularization: Sparsity vs stability in MAP estimation
  - Fixed vs adaptive hyperparameters: Simplicity vs optimal performance

- **Failure signatures:**
  - MAP optimization fails to converge: Check gradient estimation quality and step size κ
  - Distributions are too narrow/wide: Adjust precision parameter η and virtual sample count c_b
  - Inconsistency with baselines: Verify deviation-sensitivity vs deviation-agnostic behavior

- **First 3 experiments:**
  1. Verify deviation-sensitivity on 2Dsinusoidal synthetic data with varying y_t values
  2. Compare GPA distributions with BayLIME on BostonHousing to validate uncertainty quantification
  3. Test MAP optimization convergence across different regularization strengths on Diabetes dataset

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the choice of the hyperparameter c_b (number of virtual samples) affect the accuracy and reliability of GPA's attribution score distributions?
- **Basis in paper:** [explicit] The paper discusses c_b as a tunable parameter that simulates the situation where there are abundant test samples, with a typical value of c_b ~ 10 giving a reasonable distribution.
- **Why unresolved:** The paper only provides a general guideline for choosing c_b and does not present a systematic study of its impact on GPA's performance across different datasets and anomaly types.
- **What evidence would resolve it:** Empirical results showing GPA's performance (e.g., attribution accuracy, uncertainty quantification) for different values of c_b on multiple datasets with varying characteristics.

### Open Question 2
- **Question:** Can GPA be extended to handle categorical input variables, and if so, what modifications would be necessary?
- **Basis in paper:** [inferred] The paper focuses on real-valued input variables and does not address categorical variables. However, many real-world datasets contain categorical features.
- **Why unresolved:** The paper does not discuss the applicability of GPA to datasets with mixed data types (continuous and categorical).
- **What evidence would resolve it:** A modified version of GPA that can handle categorical variables, along with experimental results demonstrating its effectiveness on datasets with mixed data types.

### Open Question 3
- **Question:** How does GPA's performance compare to other state-of-the-art anomaly attribution methods when applied to high-dimensional datasets with complex relationships between variables?
- **Basis in paper:** [explicit] The paper evaluates GPA on three real-world datasets (Diabetes, BostonHousing, CaliforniaHousing) with up to 13 input variables, but does not explore its performance on high-dimensional data.
- **Why unresolved:** The paper does not provide a comprehensive comparison of GPA's performance with other methods on high-dimensional datasets, which are common in many real-world applications.
- **What evidence would resolve it:** Experimental results comparing GPA's attribution accuracy and uncertainty quantification to other methods on high-dimensional datasets (e.g., image data, text data) with complex variable relationships.

## Limitations

- The factorized posterior approximation may not capture complex dependencies between input variables when perturbations are highly correlated
- The assumption of zero-mean Gaussian perturbations could fail for anomalies with systematic biases rather than random deviations
- ℓ1 regularization in MAP estimation might introduce bias toward sparsity even when multiple variables contribute meaningfully to the anomaly

## Confidence

- Deviation-agnostic property of baseline methods: **High** - proven analytically in Theorem 1 with clear counterexample in synthetic data
- GPA's deviation sensitivity: **Medium** - demonstrated on synthetic 2Dsinusoidal data but limited real-world validation
- Uncertainty quantification accuracy: **Low** - qualitative assessment only, no quantitative calibration or comparison to ground truth distributions

## Next Checks

1. Test GPA on multi-modal anomaly distributions where the factorized posterior approximation may fail to capture the true structure
2. Evaluate calibration of GPA's uncertainty estimates by comparing predicted score distributions to bootstrap confidence intervals on held-out data
3. Investigate sensitivity to ℓ1 regularization strength by varying ν and measuring impact on both sparsity and attribution accuracy across different anomaly types