---
ver: rpa2
title: Missing-modality Enabled Multi-modal Fusion Architecture for Medical Data
arxiv_id: '2309.15529'
source_url: https://arxiv.org/abs/2309.15529
tags:
- modalities
- fusion
- data
- modality
- were
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposed a Transformer-based tri-modal fusion (TriMF)
  architecture to address the problem of missing modalities in medical data fusion.
  The architecture combined three feature embedding networks for individual modalities
  (chest radiographs, radiology reports, and structured tabular data) with a multi-modal
  fusion framework using multivariate loss functions.
---

# Missing-modality Enabled Multi-modal Fusion Architecture for Medical Data

## Quick Facts
- arXiv ID: 2309.15529
- Source URL: https://arxiv.org/abs/2309.15529
- Reference count: 40
- Primary result: Proposed TriMF architecture achieves 0.914 AUROC and 0.552 AUPRC on 14-label disease diagnosis with robust performance to missing modalities

## Executive Summary
This study addresses the challenge of missing modalities in medical data fusion by proposing a Transformer-based tri-modal fusion (TriMF) architecture. The framework combines three feature embedding networks for chest radiographs, radiology reports, and structured tabular data with a multi-modal fusion mechanism that uses stacked self-attention and co-attention units. The architecture achieves strong performance (0.914 AUROC, 0.552 AUPRC) on a 14-label disease diagnosis task using MIMIC-IV and MIMIC-CXR datasets while demonstrating superior robustness to missing modalities compared to existing fusion methods like MedViLL.

## Method Summary
The TriMF architecture consists of three feature embedding networks (DenseNet-121 for images, PubMedBERT for text, shallow NN for tabular data) feeding into three BiMF modules, each fusing a different pair of modalities using stacked self-attention and co-attention units with low-rank multimodal fusion. The BiMF outputs are combined into a TriMF representation that feeds into a linear classifier. Training employs a multivariate loss function combining classification loss with fusion representation contrastive loss terms to improve robustness to missing modalities. The model was trained using Adam optimizer with specific weight decay and batch size parameters.

## Key Results
- Achieved 0.914 average AUROC and 0.552 AUPRC across 14 disease labels
- Demonstrated strong robustness to missing modalities with minimal performance degradation
- Outperformed MedViLL and other fusion methods in classification accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Stacked SA/CA units enable effective intra-modality and inter-modality information interaction
- Mechanism: SA units learn relationships within each modality independently, while CA units learn pairwise relationships across modalities. Alternating stacking captures both low-level and high-level semantics.
- Core assumption: Alternating SA and CA layers improve representation quality compared to using only one type of attention mechanism.
- Evidence anchors: Abstract mentions SA/CA units; section 2.2.2 cites Li et al. on SA/CA effectiveness for aligning semantics; corpus shows limited direct evidence for this specific application.

### Mechanism 2
- Claim: Low-rank multimodal fusion (LMF) effectively fuses modality representations while controlling parameter growth
- Mechanism: LMF decomposes tensor fusion weights into low-rank factors, allowing efficient fusion of two modality representations into a single vector.
- Core assumption: Decomposing fusion weights into low-rank factors maintains fusion effectiveness while reducing computational complexity.
- Evidence anchors: Abstract describes LMF as improvement over tensor fusion network; section 2.2.2 explains LMF allows arbitrary fusion vector dimensions; limited direct evidence for LMF in medical multimodal fusion.

### Mechanism 3
- Claim: Fusion representation contrastive loss (FRCL) improves robustness to missing modalities by aligning fusion representations
- Mechanism: FRCL encourages similarity between complete modality fusion representations and partial modality fusion representations.
- Core assumption: Making fusion representations from complete and incomplete modalities similar will maintain classification performance when modalities are missing.
- Evidence anchors: Abstract mentions FRCL mechanism to improve similarity between TriMF and BiMF representations; section 2.3.1 provides loss function equation; limited direct evidence for contrastive loss specifically for missing modality robustness.

## Foundational Learning

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: The model relies on self-attention and co-attention units for information interaction between and within modalities
  - Quick check question: What is the difference between self-attention and co-attention, and why would you use both in a multimodal fusion context?

- Concept: Multimodal fusion techniques
  - Why needed here: The study compares various fusion approaches (concatenation, LMF, etc.) and their effectiveness for medical data
  - Quick check question: How does low-rank multimodal fusion differ from simple concatenation or tensor fusion in terms of computational efficiency and representation quality?

- Concept: Handling missing data in machine learning
  - Why needed here: The model specifically addresses missing modalities, a common issue in medical datasets
  - Quick check question: What are the advantages and disadvantages of generating missing data versus designing models that can handle missing inputs directly?

## Architecture Onboarding

- Component map: Image/text/tabular feature embeddings -> Three BiMF modules (each with SA/CA stacking + LMF) -> TriMF representation -> Linear classifier -> 14 disease labels

- Critical path: 1) Embed each modality into appropriate dimensional space 2) Process each modality pair through BiMF module (SA/CA stacking + LMF) 3) Sum BiMF outputs to create TriMF representation 4) Classify using linear layer 5) Compute combined loss (classification + FRCL terms)

- Design tradeoffs: Separate BiMF modules for each modality pair allow flexible handling of missing modalities but increase parameter count; LMF controls parameter growth but may limit representational capacity; contrastive loss improves robustness but adds training complexity

- Failure signatures: Performance degrades significantly when any single modality is missing (insufficient robustness); training instability or convergence issues (loss function imbalance); no improvement over unimodal or bimodal baselines (fusion isn't effective)

- First 3 experiments: 1) Ablation study: Remove SA units, replace with CA only, measure performance change 2) Ablation study: Replace LMF with simple concatenation, measure parameter count and performance 3) Ablation study: Remove FRCL from training, test robustness on missing modality test sets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed TriMF architecture scale to more than three modalities in terms of computational complexity and parameter count?
- Basis in paper: [explicit] The paper mentions that "this architecture could fuse more modalities by using more BiMF modules, this would lead to a massive increase in the number of parameters" and that this is a limitation of the study.
- Why unresolved: The paper identifies this as a limitation but does not provide quantitative analysis or solutions for scaling to more modalities.
- What evidence would resolve it: Empirical studies comparing computational complexity and parameter count when extending the TriMF architecture to four or more modalities, along with proposed solutions to mitigate the increase in parameters.

### Open Question 2
- Question: How robust is the TriMF architecture to missing more than one modality simultaneously?
- Basis in paper: [inferred] The paper tests robustness to missing one modality at a time, but the real-world scenario of multiple missing modalities is not explored.
- Why unresolved: The paper only evaluates the model's performance when one modality is missing, leaving uncertainty about its behavior with multiple missing modalities.
- What evidence would resolve it: Experimental results showing classification performance when two or more modalities are missing simultaneously, along with analysis of how performance degrades.

### Open Question 3
- Question: How does the TriMF architecture perform on non-English medical datasets, particularly Chinese?
- Basis in paper: [explicit] The paper states "this study only conducted experiments on an English public dataset" and suggests validation on a Chinese dataset.
- Why unresolved: The current evaluation is limited to English data, and the model's performance on other languages is unknown.
- What evidence would resolve it: Experimental results demonstrating the TriMF architecture's performance on Chinese medical datasets, including comparisons with existing models.

## Limitations

- The architecture may face scalability challenges when extended to more than three modalities due to exponential parameter growth
- Performance evaluation is limited to synthetically generated missing modalities rather than naturally occurring missingness patterns
- The study only tested on English medical datasets, leaving performance on non-English data (particularly Chinese) unknown

## Confidence

- **High Confidence:** The overall architecture design and fusion mechanism are technically sound and well-grounded in established multimodal learning principles
- **Medium Confidence:** The reported performance metrics are plausible given the architecture, but lack of detailed hyperparameter tuning information and exact data preprocessing steps limits full verification
- **Medium Confidence:** The contrastive loss mechanism for improving missing-modality robustness is theoretically reasonable but lacks extensive ablation studies to isolate its specific contribution

## Next Checks

1. Conduct ablation studies to quantify the individual contributions of SA/CA alternating layers, LMF fusion, and FRCL loss to overall performance and robustness
2. Test the model on real-world clinical datasets with naturally occurring missing modalities rather than synthetically generated missingness
3. Implement and compare against the exact MedViLL baseline architecture and training procedure to validate the claimed performance improvements