---
ver: rpa2
title: Automatic Data Visualization Generation from Chinese Natural Language Questions
arxiv_id: '2309.07650'
source_url: https://arxiv.org/abs/2309.07650
tags:
- data
- visualization
- chinese
- text-to-vis
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of generating data visualizations
  from Chinese natural language questions, a task that requires cross-lingual understanding
  and handling of Chinese semantics. The authors propose CNvBench, the first large-scale
  Chinese Text-to-Vis dataset, constructed by translating an existing English dataset.
---

# Automatic Data Visualization Generation from Chinese Natural Language Questions

## Quick Facts
- arXiv ID: 2309.07650
- Source URL: https://arxiv.org/abs/2309.07650
- Reference count: 12
- Primary result: 81.2% tree matching accuracy on Chinese Text-to-Vis task

## Executive Summary
This paper introduces CNvBench, the first large-scale Chinese Text-to-Vis dataset, addressing the challenge of generating data visualizations from Chinese natural language questions. The authors propose a BRIDGE-based model that integrates multilingual BERT as the encoder to handle cross-lingual challenges and injects n-gram information to better capture Chinese word semantics. Experimental results demonstrate that their model outperforms baseline approaches, achieving 81.2% tree matching accuracy and validating the effectiveness of incorporating n-grams for Chinese encoding in Text-to-Vis tasks.

## Method Summary
The proposed approach uses a BRIDGE-based architecture with multilingual BERT as the encoder, augmented with n-gram injection to handle Chinese word segmentation challenges. The model takes Chinese natural language questions and English database schemas as input, encodes them using multilingual BERT with extracted n-grams, and generates Vega-Lite specifications through an LSTM-based pointer-generator decoder. The decoder combines generation of VQL keywords with copying of schema elements, enabling structured output generation. The entire model is trained end-to-end on the CNvBench dataset, which consists of 25,750 Chinese questions paired with visualization specifications.

## Key Results
- Achieves 81.2% tree matching accuracy on CNvBench test set
- Outperforms baseline models on Chinese Text-to-Vis task
- Demonstrates effectiveness of n-gram injection for Chinese word semantics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multilingual BERT encoder improves cross-lingual semantic understanding between Chinese questions and English database schema.
- Mechanism: Leverages pre-trained multilingual representations to map semantically similar concepts across languages into proximate vector spaces.
- Core assumption: Semantic similarity is preserved across languages in multilingual BERT embeddings.
- Evidence anchors: Abstract mentions boosting cross-lingual ability; section 4 explicitly states adoption of multilingual BERT for this purpose.

### Mechanism 2
- Claim: N-gram injection improves Chinese word boundary recognition and semantic understanding.
- Mechanism: Extracts and encodes n-grams from Chinese text, injecting these representations into character-level encoding to gain awareness of word boundaries.
- Core assumption: Chinese semantic units are better captured by n-grams than individual characters or wordpiece tokens.
- Evidence anchors: Abstract mentions infusing n-gram information; section 4.1 describes the ZEN model-based n-gram extraction and encoding.

### Mechanism 3
- Claim: LSTM-based pointer-generator decoder enables generation of correct visualization query language (VQL) syntax.
- Mechanism: Uses LSTM to generate VQL keywords while employing pointer networks to copy schema elements from input.
- Core assumption: Decoder can effectively balance between generating keywords and copying schema elements based on context.
- Evidence anchors: Section 4.2 explains pointer network ability to selectively incorporate input sequence parts; mentions Tencent multilingual embeddings.

## Foundational Learning

- Concept: Cross-lingual semantic alignment
  - Why needed here: Task requires understanding Chinese questions while referencing English database schemas
  - Quick check question: How does multilingual BERT handle semantic similarity between Chinese and English terms?

- Concept: Chinese word segmentation challenges
  - Why needed here: Chinese text lacks explicit word boundaries, making accurate semantic parsing difficult
  - Quick check question: Why might WordPiece tokenization fail for Chinese text segmentation?

- Concept: Pointer-generator architectures
  - Why needed here: Decoder must generate structured VQL while incorporating schema elements from input
  - Quick check question: What's the difference between generating keywords and copying schema elements in a pointer-generator decoder?

## Architecture Onboarding

- Component map: Chinese question + English database schema → Multilingual BERT with n-gram injection → LSTM pointer-generator decoder → VQL specification

- Critical path: Chinese question → multilingual BERT encoding → n-gram injection → LSTM decoder → VQL output

- Design tradeoffs: N-gram injection improves semantic understanding but adds computational complexity; pointer-generator decoder handles schema copying but may struggle with long sequences.

- Failure signatures:
  - Incorrect table/column names in output: Likely encoding issue
  - Wrong visualization types: Likely decoding or semantic understanding issue
  - Syntax errors in VQL: Likely decoding or generation issue

- First 3 experiments:
  1. Compare BRIDGEM vs BRIDGEM N on tree matching accuracy to validate n-gram benefit
  2. Test different n-gram sizes (bigrams, trigrams) to find optimal configuration
  3. Evaluate on a subset with explicit visualization type mentions to isolate encoding vs decoding issues

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of cross-lingual Text-to-Vis models degrade when translating from Chinese to other languages (e.g., Japanese, Korean) beyond just English?
- Basis in paper: Paper focuses on translating English datasets to Chinese but doesn't explore translation to other languages.
- Why unresolved: Authors only constructed a Chinese dataset and didn't test cross-lingual generalization to other languages.
- What evidence would resolve it: Training and evaluating models on datasets translated to multiple target languages beyond Chinese.

### Open Question 2
- Question: What is the impact of using different word segmentation tools (e.g., Jieba vs. HanNLP) on the performance of Text-to-Vis models for Chinese?
- Basis in paper: Paper compares performance of two different word segmentation tools (Jieba and HanNLP) on human-translated dataset.
- Why unresolved: Paper only provides results for two specific segmentation tools, leaving impact of other tools unexplored.
- What evidence would resolve it: Conducting experiments with wider range of word segmentation tools and comparing their performance.

### Open Question 3
- Question: How does the performance of Text-to-Vis models vary when using different types of visualization grammars beyond Vega-Lite?
- Basis in paper: Paper mentions Vega-Lite is primarily used due to widespread usage, but methodology is easily adaptable to other DVLs.
- Why unresolved: Authors only focus on Vega-Lite and don't explore performance with other visualization grammars.
- What evidence would resolve it: Training and evaluating models using different visualization grammars and comparing their performance.

## Limitations
- Dataset size of 25,750 instances is relatively small compared to larger cross-lingual NLP datasets
- Translation quality for technical visualization terminology from English to Chinese remains unverified
- Evaluation focuses on structural accuracy rather than practical usability or visualization quality

## Confidence
- High Confidence: Cross-lingual alignment using multilingual BERT is well-established with strong empirical support (81.2% tree matching accuracy)
- Medium Confidence: N-gram injection approach shows promise but lacks comparative analysis against alternative segmentation methods
- Low Confidence: Practical utility of generated visualizations remains unassessed - doesn't evaluate whether VQL outputs produce meaningful, interpretable visualizations

## Next Checks
1. **Ablation study on n-gram contribution**: Train and evaluate models with varying n-gram configurations (no n-grams, bigrams only, trigrams only, combined) to isolate specific benefit of n-gram injection versus baseline multilingual BERT encoding.

2. **Human evaluation of visualization quality**: Conduct user studies comparing visualizations generated by proposed model against baseline approaches on real-world datasets, measuring interpretability, accuracy, and user preference rather than just structural matching.

3. **Cross-lingual robustness testing**: Evaluate model performance on Chinese questions containing English loanwords, technical terms, or mixed-language expressions commonly found in technical domains to assess real-world cross-lingual handling beyond clean dataset conditions.