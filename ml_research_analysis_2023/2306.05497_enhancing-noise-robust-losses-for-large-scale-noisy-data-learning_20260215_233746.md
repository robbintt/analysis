---
ver: rpa2
title: Enhancing Noise-Robust Losses for Large-Scale Noisy Data Learning
arxiv_id: '2306.05497'
source_url: https://arxiv.org/abs/2306.05497
tags:
- loss
- noise
- learning
- label
- functions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates the performance of various noise-robust
  loss functions for training deep neural networks on datasets with label noise. It
  identifies that bounded loss functions, while more robust to noise, struggle with
  many-class problems due to vanishing gradients.
---

# Enhancing Noise-Robust Losses for Large-Scale Noisy Data Learning

## Quick Facts
- arXiv ID: 2306.05497
- Source URL: https://arxiv.org/abs/2306.05497
- Reference count: 37
- Primary result: Introduces logit bias technique to improve bounded loss functions for noisy data learning

## Executive Summary
This paper investigates noise-robust loss functions for training deep neural networks on datasets with label noise. The authors identify that bounded loss functions, while more robust to noise, struggle with many-class problems due to vanishing gradients. They propose a novel technique called "logit bias" that adds a real number ε to the pre-activation of the correct class neuron, significantly improving the learning performance of bounded losses. This simple modification allows bounded losses to outperform standard Cross Entropy loss even on clean datasets like Cifar-100.

## Method Summary
The method introduces a logit bias technique that adds a real number ε to the pre-activation of the correct class neuron during loss computation. This shift compensates for vanishing gradients in bounded loss functions when dealing with many-class problems. The authors also propose a new loss function called Bounded Cross Entropy (boundCE). The approach is evaluated on Cifar-10, Fashion-MNIST, and Cifar-100 datasets with various noise levels, demonstrating improved performance over traditional methods in both noisy and clean data scenarios.

## Key Results
- Logit bias technique significantly improves learning performance of bounded loss functions
- Bounded losses with logit bias outperform standard Cross Entropy loss even on clean datasets
- The method successfully addresses vanishing gradients in many-class problems
- Extensive empirical results demonstrate effectiveness across different noise levels and datasets

## Why This Works (Mechanism)

### Mechanism 1
Bounded loss functions struggle with many-class problems due to vanishing gradients when pre-activation values fall into regions where gradients are near zero. When a network is initialized, activations zk are drawn from a normal distribution centered around zero. For bounded losses like MAE and boundCE, the gradient δk = ∂zk L decays rapidly as ak → 0, causing gradients to vanish in regions frequently occupied by randomly initialized activations in many-class scenarios.

### Mechanism 2
Adding a logit bias ε to the correct class neuron shifts the initial activation distribution into a region where gradients are non-zero, enabling learning even with bounded losses in many-class problems. By adding ε to zk for the correct class, the initial activation distribution moves rightward along the learning curve δk(zk), entering regions where |δk| is large and gradients drive learning. This simple shift compensates for the low-gradient problem without changing the fundamental bounded nature of the loss.

### Mechanism 3
The logit bias ε can be computed analytically by ensuring the expected activation after bias addition matches a target value ⟨ak⟩ that empirically yields good learning behavior. The authors derive an implicit equation based on the fact that gradients in activation space a are independent of class count c. Solving ⟨exp(zk + ε)/∑i exp(zi + δikε)⟩ = ⟨ak⟩ yields ε values that maintain consistent learning behavior across different numbers of classes.

## Foundational Learning

- **Concept:** Cross Entropy loss and its unbounded nature
  - **Why needed here:** Understanding why CE is sensitive to label noise and why bounded losses were proposed as alternatives requires knowing how CE behaves when predictions are wrong.
  - **Quick check question:** What happens to the gradient of CE when the predicted probability for the correct class approaches zero?

- **Concept:** Softmax activation and its effect on pre-activation distributions
  - **Why needed here:** The paper relies on understanding how random initial pre-activations zk are transformed into probabilities ak, and how this transformation affects gradient flow.
  - **Quick check question:** If pre-activations are drawn from N(0,1), what is the approximate probability assigned to any single class before training?

- **Concept:** Label noise robustness and the bias-variance tradeoff in loss design
  - **Why needed here:** The paper's central contribution is balancing noise robustness with learning capability, which requires understanding the fundamental tradeoff.
  - **Quick check question:** Why do bounded losses resist label noise but potentially learn more slowly than unbounded losses?

## Architecture Onboarding

- **Component map:**
  Input layer → Normalization → Data augmentation (for ResNets) → Convolutional/MLP layers → Final linear layer (pre-activation z) → Softmax → Loss computation (with optional logit bias) → Backpropagation

- **Critical path:**
  1. Initialize network with Glorot-uniform weights and zero biases
  2. For each training batch: normalize, augment (if ResNet), forward pass to get z
  3. Apply logit bias: z[k] ← z[k] + ε where k = argmax(label)
  4. Compute loss (CE, MAE*, boundCE*, etc.)
  5. Backpropagate and update weights
  6. Periodically evaluate on validation set

- **Design tradeoffs:**
  - Larger ε improves learning speed but reduces noise robustness
  - Smaller ε maintains robustness but may cause slow learning
  - Using bounded losses with bias vs. unbounded losses without bias
  - ResNet with heavy augmentation vs. MLP with minimal preprocessing

- **Failure signatures:**
  - Training accuracy increases but test accuracy plateaus or decreases (overfitting to noise)
  - Both training and test accuracy remain low throughout training (vanishing gradients)
  - Sudden drops in accuracy after learning rate decay steps
  - Loss values that don't decrease over epochs

- **First 3 experiments:**
  1. Train ResNet-32 on Cifar-10 with CE loss and no label noise; verify baseline performance (~91% accuracy)
  2. Train the same architecture with MAE* (ε=0.5) on Cifar-10 with 20% label noise; observe robustness compared to CE
  3. Train ResNet-34 on Cifar-100 with boundCE* (ε=2.5) and compare to CE performance; verify the paper's claim about outperforming CE even without added noise

## Open Questions the Paper Calls Out

### Open Question 1
How does the logit bias technique perform on other complex datasets beyond Cifar-100, such as ImageNet or datasets with more than 1000 classes?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of the logit bias technique on Cifar-100, but does not explore its performance on larger or more complex datasets.
- Why unresolved: The paper focuses on Cifar-10, Fashion-MNIST, and Cifar-100 datasets. It does not provide experimental results or theoretical analysis for larger datasets like ImageNet.
- What evidence would resolve it: Conducting experiments with the logit bias technique on larger datasets like ImageNet and comparing its performance to other noise-robust loss functions would provide valuable insights into its scalability and effectiveness.

### Open Question 2
How does the logit bias technique affect the learning dynamics and convergence speed of bounded loss functions compared to unbounded loss functions?
- Basis in paper: [inferred] The paper mentions that bounded loss functions can learn slower than unbounded ones like Cross Entropy, but it does not provide a detailed analysis of the learning dynamics and convergence speed with the logit bias technique.
- Why unresolved: The paper focuses on the final performance of the loss functions but does not provide a detailed analysis of the learning process and convergence behavior.
- What evidence would resolve it: Conducting experiments to compare the learning dynamics and convergence speed of bounded loss functions with and without the logit bias technique, and comparing them to unbounded functions, would provide insights into the impact of the technique on the learning process.

### Open Question 3
How does the logit bias technique perform in scenarios with non-symmetric label noise or class imbalance?
- Basis in paper: [inferred] The paper focuses on symmetric label noise scenarios and does not explore the performance of the logit bias technique in scenarios with non-symmetric label noise or class imbalance.
- Why unresolved: The paper's experiments and analysis are limited to symmetric label noise scenarios with equal class sizes. It does not provide insights into how the technique would perform in more complex noise scenarios or with imbalanced classes.
- What evidence would resolve it: Conducting experiments with the logit bias technique in scenarios with non-symmetric label noise and class imbalance, and comparing its performance to other noise-robust loss functions, would provide valuable insights into its robustness and adaptability to different noise scenarios.

## Limitations
- The analytic computation of ε relies on assumptions about expected activation distributions that may not hold across all architectures
- The empirical evaluation focuses primarily on image classification tasks with symmetric label noise
- The method introduces additional hyperparameters (ε values) that require tuning

## Confidence

**High confidence** in the core observation that bounded losses suffer from gradient vanishing in many-class settings

**Medium confidence** in the effectiveness of logit bias as a general solution, based on limited empirical validation

**Low confidence** in the universal applicability of the analytic ε computation method

## Next Checks

1. Test the logit bias technique on asymmetric label noise distributions to verify robustness beyond symmetric corruption

2. Evaluate performance on non-image datasets (text, tabular) to assess generalizability across domains

3. Investigate whether learned ε values vary significantly with network depth or architecture, challenging the assumption of architecture-independent optimal values