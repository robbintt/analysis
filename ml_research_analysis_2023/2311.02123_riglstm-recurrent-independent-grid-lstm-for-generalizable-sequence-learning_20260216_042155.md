---
ver: rpa2
title: 'RigLSTM: Recurrent Independent Grid LSTM for Generalizable Sequence Learning'
arxiv_id: '2311.02123'
source_url: https://arxiv.org/abs/2311.02123
tags:
- cells
- state
- lstm
- input
- hidden
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes recurrent independent Grid LSTM (RigLSTM),
  a novel recurrent unit designed for generalizable sequence learning tasks where
  testing environments may differ from training. RigLSTM integrates cell selection,
  input feature selection, hidden state selection, and soft state updating with Grid
  LSTM to exploit underlying modular structures.
---

# RigLSTM: Recurrent Independent Grid LSTM for Generalizable Sequence Learning

## Quick Facts
- arXiv ID: 2311.02123
- Source URL: https://arxiv.org/abs/2311.02123
- Authors: 
- Reference count: 40
- Primary result: RigLSTM achieves superior generalization when testing environments differ from training, with 59.60% accuracy on sequential MNIST at 24×24 resolution compared to 38.1% for RIM and 20.84% for GridLSTM

## Executive Summary
This paper proposes RigLSTM, a novel recurrent unit designed for generalizable sequence learning tasks where testing environments may differ from training. RigLSTM integrates cell selection, input feature selection, hidden state selection, and soft state updating with Grid LSTM to exploit underlying modular structures. The model activates a subset of LSTM cells at each time step, allowing them to independently select relevant inputs and hidden states from other cells. Extensive experiments across sequential image classification, bouncing ball video prediction, reinforcement learning, and multi-digit copying tasks demonstrate that RigLSTM achieves superior generalization performance compared to state-of-the-art methods when testing environments differ from training.

## Method Summary
RigLSTM implements multiple LSTM cells with dynamic selection mechanisms at each time step. The model performs cell selection by computing similarity scores between input features and hidden states, activating only the top Ka most relevant cells. Input features are transformed into K different views, with each activated cell selecting the top Kx most relevant features based on similarity with its hidden state. Hidden state selection allows cells to choose the top Kh most relevant states from other cells for communication. At the end of each time step, soft state updating combines the current hidden state with previous states using attention weights computed from input features and states of all cells. The model is trained using Adam optimizer with learning rate 0.0001 and evaluated on out-of-distribution data to measure generalization performance.

## Key Results
- On sequential MNIST with varying resolutions, RigLSTM achieves 59.60% accuracy at 24×24 resolution compared to 38.1% for RIM and 20.84% for GridLSTM
- For bouncing ball video prediction, RigLSTM maintains stable performance across 4, 5, and 6 ball scenarios while baselines degrade
- In reinforcement learning tasks, RigLSTM achieves higher averaged rewards in unseen environments compared to LSTM, RIM, and RMC baselines
- On multi-digit copying tasks with variable dormant phases, RigLSTM demonstrates superior sequence reproduction accuracy

## Why This Works (Mechanism)

### Mechanism 1
Cell selection allows the model to activate only a subset of LSTM cells relevant to the current input, reducing computational load and enabling specialization. At each time step, similarity scores between input features and hidden states of all cells are computed, with the top Ka cells with highest relevance activated while others remain inactive. The underlying modular structure of the task means only a subset of components (cells) are relevant at any given time step. This mechanism may degrade performance if the task lacks modular structure or requires all components to be active simultaneously.

### Mechanism 2
Input feature selection enables each activated cell to receive only relevant information from multiple transformed input views, enhancing specialization. Input features are transformed into K different views, with each activated cell selecting the top Kx most relevant features based on similarity with its hidden state. Different cells need different aspects of the input information to specialize in distinct functions. Feature selection may discard useful information if all input information is equally relevant to all cells.

### Mechanism 3
Soft state updating propagates information through time more effectively by considering both current inputs and states of other cells when combining previous and current hidden states. After regular LSTM update, the hidden state is combined with previous state using attention weights computed from current inputs and states of all cells. Information flow through time should be context-dependent rather than fixed residual connections. Soft state updating may introduce noise if the task requires pure memory without context-dependent updating.

## Foundational Learning

- Concept: Modular structure in sequential processes
  - Why needed here: The paper assumes sequential processes can be decomposed into interacting subsystems, which is the foundation for why RigLSTM's modular design works.
  - Quick check question: Can you identify a real-world sequential process that naturally decomposes into independent components that interact occasionally?

- Concept: Attention mechanisms for information selection
  - Why needed here: RigLSTM uses attention-like mechanisms (similarity scores) to select relevant inputs, hidden states, and cells.
  - Quick check question: How does the attention mechanism in RigLSTM differ from standard attention in transformer models?

- Concept: Gradient flow in recurrent networks
  - Why needed here: Understanding why information propagation through time is challenging explains the need for soft state updating to prevent vanishing/exploding gradients.
  - Quick check question: What are the main challenges in training deep recurrent networks, and how does residual connection help address them?

## Architecture Onboarding

- Component map: Input transformation → Cell selection → Input feature selection → Hidden state selection → Soft state updating → Regular LSTM cell computation
- Critical path: The information flows through all five selection mechanisms before reaching the LSTM cell computation, making each selection step critical for performance.
- Design tradeoffs: RigLSTM trades increased computational complexity for improved generalization by allowing cells to specialize and select relevant information.
- Failure signatures: Poor performance on tasks lacking modular structure, excessive memory usage due to multiple selection steps, slower inference compared to standard LSTMs.
- First 3 experiments:
  1. Implement RigLSTM with only cell selection and no input/hidden state selection on a simple sequential task to verify basic functionality.
  2. Add input transformation and feature selection while keeping hidden state selection disabled to test the impact of input specialization.
  3. Enable all selection mechanisms and soft state updating, then test on the sequential MNIST task with resolution changes to validate generalization improvements.

## Open Questions the Paper Calls Out

### Open Question 1
How does RigLSTM's performance scale with increasing numbers of LSTM cells (N) and activated cells (Ka) beyond the tested configurations? The paper tests RigLSTM with N=6 and Ka=5 for sequential MNIST, but suggests potential for larger configurations. The paper only explores a limited range of N and Ka values, leaving the optimal configuration for different task complexities unexplored.

### Open Question 2
What is the theoretical justification for the specific combination of input transformation, cell selection, input feature selection, hidden state selection, and soft state updating mechanisms? The paper proposes these components based on empirical observations but doesn't provide theoretical analysis of why this particular combination is optimal.

### Open Question 3
How does RigLSTM compare to other modular neural network architectures like Neural Module Networks or Routing Networks on tasks requiring systematic generalization? The paper mentions related modular architectures but doesn't directly compare RigLSTM to them.

### Open Question 4
What is the optimal strategy for determining the number of input feature vectors (K) and the selection parameters (Kx, Kh) for different task domains? The paper uses K=6, Kx=Kh=Ka for most experiments but doesn't explore how these hyperparameters should be adapted.

### Open Question 5
How does RigLSTM's performance degrade as the gap between training and testing environments increases beyond the tested scenarios? The paper tests generalization across resolution changes and environment variations but doesn't explore extreme domain shifts.

## Limitations

- Model complexity and interpretability challenges due to multiple selection mechanisms
- Task-specific hyperparameters lack clear guidance for adaptation to new domains
- Computational overhead from multiple selection steps compared to standard LSTMs

## Confidence

- **High Confidence**: Superior generalization performance when testing environments differ from training is well-supported by extensive experiments across four task domains
- **Medium Confidence**: Mechanism explanations are theoretically sound but rely on assumptions about modular structure that aren't formally proven
- **Low Confidence**: Claims about handling any generalizable sequence learning task aren't fully validated beyond specific types of distribution shifts

## Next Checks

- Implement controlled ablation study with individual selection mechanisms disabled to quantify each component's contribution
- Conduct experiments on tasks that explicitly violate the modular structure assumption to test break conditions
- Perform runtime and memory usage comparisons between RigLSTM and baselines across different batch sizes and sequence lengths