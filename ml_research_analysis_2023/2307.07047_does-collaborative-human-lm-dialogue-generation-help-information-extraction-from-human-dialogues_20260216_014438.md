---
ver: rpa2
title: Does Collaborative Human-LM Dialogue Generation Help Information Extraction
  from Human Dialogues?
arxiv_id: '2307.07047'
source_url: https://arxiv.org/abs/2307.07047
tags:
- agent
- user
- accident
- dialogue
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DIAL GEN is a human-in-the-loop dialogue generation framework that
  enables the creation of complex, privacy-preserving synthetic dialogues for information
  extraction from human-human conversations. By combining a language model with human
  reviewers, it iteratively generates subdialogues, ensuring coherence and consistency
  while covering desired content and fulfilling style specifications.
---

# Does Collaborative Human-LM Dialogue Generation Help Information Extraction from Human Dialogues?

## Quick Facts
- **arXiv ID**: 2307.07047
- **Source URL**: https://arxiv.org/abs/2307.07047
- **Reference count**: 29
- **Key outcome**: DIAL GEN achieves 25% relative improvement in F1 score for dialogue state tracking by augmenting real human dialogues with synthetic data generated through human-in-the-loop collaboration with a language model.

## Executive Summary
DIAL GEN is a human-in-the-loop dialogue generation framework that enables the creation of complex, privacy-preserving synthetic dialogues for information extraction from human-human conversations. By combining a language model with human reviewers, it iteratively generates subdialogues, ensuring coherence and consistency while covering desired content and fulfilling style specifications. Experiments on auto insurance call center dialogues show a 25% relative improvement in F1 score when augmenting a small set of real human conversations with synthetic data generated by DIAL GEN. The framework addresses the challenge of limited availability of real-world human-human interaction data due to privacy constraints, enabling development of more complex dialogue datasets representative of natural data.

## Method Summary
The DIAL GEN framework uses a human-in-the-loop approach to generate synthetic dialogues for information extraction tasks. It combines a language model (ChatGPT) with human reviewers who iteratively edit or regenerate subdialogues to ensure coherence and consistency. The process involves prompt engineering with sampled entity-slot-value triples from an ontology, followed by subdialogue generation, human review and editing, optional annotation, and appending to dialogue history. This approach allows generation of lengthy, complex dialogues while addressing common LM problems such as inconsistency and incoherence over long generations.

## Key Results
- 25% relative improvement in F1 score for dialogue state tracking when using DIAL GEN synthetic data
- Enhanced recall in DST models attributed to inclusion of a wider range of values not covered in real training data
- Generated dialogues cover more state change patterns (KEEP/UPDATE/CONCAT) than available in real data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Human-in-the-loop revision resolves coherence failures in long-form LM generation.
- Mechanism: The language model proposes subdialogues conditioned on the full dialogue history; human reviewers iteratively edit or regenerate turns that introduce inconsistencies, contradictions, or implausible flows, ensuring semantic coherence across the full dialogue length.
- Core assumption: Human reviewers can reliably detect and correct incoherence in domain-specific dialogue without introducing new errors.
- Evidence anchors:
  - [abstract] "Humans collaborate with an LM to generate lengthy, complex dialogues, alleviating many known LM problems such as inconsistency and incoherence over long generations."
  - [section 2.2] "Subdialogues are individually revised by a human trained to correct common LM errors... verify that required information is present... and edit the text to meet stylistic criteria."
- Break condition: If reviewers lack sufficient domain knowledge, they may miss critical coherence errors or introduce their own inconsistencies.

### Mechanism 2
- Claim: Prompt engineering with sampled entity-slot-value triples steers LM output toward desired structured content.
- Mechanism: Before subdialogue generation, the prompt includes randomly sampled ontology triples that must appear in the output; the LM attempts to weave these facts into the conversation, providing control over content coverage without hard-coding every possible slot.
- Core assumption: LM can effectively integrate arbitrary factual triples into fluent conversational text while maintaining natural dialogue flow.
- Evidence anchors:
  - [section 2.1] "We randomly sample entity-slot-value triples from the expert-authored ontology to steer the LM to generate required content in the output dialogue."
  - [section 2.1] "Story... uses the randomly sampled triplets to generate a story with the LM before the dialogue generation."
- Break condition: If triples are too complex or contradictory, LM may fail to generate coherent text or ignore some triples.

### Mechanism 3
- Claim: Synthetic dialogues capture rare state-change patterns that real data lacks due to annotation cost, improving model generalization.
- Mechanism: The framework explicitly encourages slot-value updates and multi-value slots during generation, producing examples of corrections, additions, and concatenations that are expensive to annotate in real data; models trained on this synthetic diversity better handle state-change prediction.
- Core assumption: Patterns of state changes in synthetic data transfer to real data despite stylistic differences between domains.
- Evidence anchors:
  - [abstract] "By incorporating the synthesized data, we observe a significant enhancement in our model's performance... with a relative improvement of 25% in the full dialogue state F1 score."
  - [section 5.3] "Incorporating DIAL GEN-AIC data yields higher recall... the increased recall can be attributed to the inclusion of a wider range of values in the DIAL GEN-AIC data, which are not covered by the AIC training set."
- Break condition: If synthetic data overrepresents rare patterns, model may overfit to synthetic distribution and underperform on real data.

## Foundational Learning

- Concept: Dialogue state tracking (DST) with referents and multi-value slots.
  - Why needed here: The target domain requires tracking information linked to multiple entities (Global, Caller, Other Driver) and slots that can hold several values, which differs from standard DST datasets.
  - Quick check question: What are the three referents used in the auto insurance claim dialogues, and how does a slot like "Damage Part" differ from single-value slots?

- Concept: Entity-centric scoring with partial credit for multi-span matching.
- Why needed here: Traditional DST metrics assume single values per slot and exact match; the domain requires handling lists and free-form text with possible partial matches.
- Quick check question: How does the proposed LCS-based scoring for free-form responses differ from exact match scoring?

- Concept: Human-in-the-loop data generation pipeline.
- Why needed here: Privacy constraints prevent direct use of real data; the pipeline generates synthetic data that preserves task complexity while avoiding personal information.
- Quick check question: What are the two main phases in the DIAL GEN generation process, and what role does the human reviewer play in each?

## Architecture Onboarding

- Component map: Language Model (ChatGPT) -> Prompt builder -> Human reviewer interface -> Annotation layer -> Dataset builder
- Critical path: Prompt construction → LM subdialogue generation → Human review and editing → Optional annotation → Append to dialogue history → Repeat until completion
- Design tradeoffs:
  - Longer subdialogues reduce iteration count but increase coherence risk and reviewer cognitive load
  - More sampled triples increase content coverage but may constrain LM fluency
  - Including full dialogue history ensures coherence but hits LM context limits
  - Optional annotation adds cost but enables DST model training
- Failure signatures:
  - Reviewer fatigue leading to skipped edits or inconsistent corrections
  - LM repeatedly generating contradictory information despite corrections
  - Subdialogues drifting from task description despite prompt cues
  - Annotation errors in tracking multi-value slot updates
- First 3 experiments:
  1. Test subdialogue generation with minimal context (last turn only) vs full history to measure coherence impact
  2. Vary number of sampled triples per prompt (1, 3, 5) to find sweet spot between coverage and fluency
  3. Compare DST model performance using only synthetic data vs mixed synthetic-real training data to measure transfer quality

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but based on the content, several areas warrant further investigation:
- How the framework handles privacy concerns beyond name replacement
- Performance comparison with other synthetic data generation methods
- Detailed analysis of complexity and naturalness differences between synthetic and real dialogues

## Limitations
- Performance heavily depends on human reviewer quality and consistency, with limited detail on training protocols
- 25% improvement demonstrated only on auto insurance domain, raising generalizability questions
- Trade-off between synthetic data quantity and quality not explicitly explored

## Confidence
- **High confidence**: The core mechanism of human-in-the-loop revision successfully addresses LM coherence failures, supported by direct evidence of reviewer-mediated correction processes.
- **Medium confidence**: The prompt engineering approach effectively steers LM output toward desired content, though the optimal number of sampled triples remains unclear.
- **Medium confidence**: Synthetic data improves model generalization for rare state-change patterns, but the extent of domain transferability is uncertain without multi-domain validation.

## Next Checks
1. **Reviewer consistency audit**: Conduct inter-annotator agreement analysis across multiple reviewers to quantify human reliability in detecting and correcting coherence errors.
2. **Domain transferability test**: Apply DIAL GEN to a different privacy-sensitive domain (e.g., medical consultations) and compare synthetic-real performance gains to the auto insurance baseline.
3. **Synthetic data sensitivity analysis**: Systematically vary the proportion of synthetic data in training (0%, 25%, 50%, 75%, 100%) to identify the optimal mix for balancing recall gains with potential stylistic artifacts.