---
ver: rpa2
title: Unsupervised Melody-to-Lyric Generation
arxiv_id: '2305.19228'
source_url: https://arxiv.org/abs/2305.19228
tags:
- lyrics
- music
- generation
- melody
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes LYRA, an unsupervised melody-to-lyric generation
  system that addresses the challenges of limited paired data and complex cross-modal
  relationships. LYRA uses a hierarchical framework that disentangles training from
  inference, leveraging pre-trained language models and compiling melody constraints
  during decoding.
---

# Unsupervised Melody-to-Lyric Generation

## Quick Facts
- arXiv ID: 2305.19228
- Source URL: https://arxiv.org/abs/2305.19228
- Reference count: 15
- Primary result: 24% relative overall quality improvement over supervised baselines in human ratings

## Executive Summary
This paper introduces LYRA, an unsupervised melody-to-lyric generation system that addresses the challenge of limited paired melody-lyric data. The system uses a hierarchical framework that disentangles training (purely text-based) from inference (melody-guided generation), leveraging pre-trained language models and compiling melody constraints during decoding. LYRA incorporates segmentation, rhythm alignment, and multi-task auxiliary learning to generate lyrics with desired syllable counts. Experiments demonstrate LYRA outperforms supervised baselines with a 24% relative overall quality improvement in human ratings, successfully generating singable, intelligible, and coherent lyrics without training on melody-lyric pairs.

## Method Summary
LYRA employs a two-stage hierarchical framework: an input-to-plan model generates keyword-based outlines from song titles, genres, and salient words, followed by a plan-to-lyrics model that generates complete lyrics conditioned on these outlines and syllable constraints. The system uses multi-task auxiliary learning incorporating syllable counting, phoneme translation, and controlled generation tasks. During inference, melodies are compiled into segmentation and rhythm alignment constraints that guide the generation process. The approach trains purely on monolingual lyric datasets while applying melody constraints only during inference, enabling unsupervised learning without requiring aligned melody-lyric pairs.

## Key Results
- LYRA achieves 24% relative overall quality improvement over supervised baselines in human evaluation
- Generated lyrics successfully align with melody rhythm with high stress-duration alignment percentages
- Syllable count control reaches over 90% success rate through multi-task auxiliary learning
- System generates coherent, intelligible, and creative lyrics without melody-lyric training pairs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Disentangling training from inference enables melody-to-lyric generation without parallel data
- Mechanism: Trains on large monolingual lyric datasets, applies melody constraints at inference without paired data
- Core assumption: Cross-modal mapping can be approximated through decoding constraints rather than learned from pairs
- Evidence anchors: Abstract states disentanglement enables circumventing shortage of parallel data; section 3 proposes method without aligned data
- Break condition: Decoding constraints fail to capture essential cross-modal relationships

### Mechanism 2
- Claim: Hierarchical planning improves lyric quality and controllability
- Mechanism: Two-stage approach generates keyword outline, then complete lyrics conditioned on outline and constraints
- Core assumption: Content planning provides structural scaffolding for coherence and topic control
- Evidence anchors: Section 3.1 describes input-to-plan model for topic relevance; section 3.2 explains learning sentence-level plans; section 6.1 shows syllable count success rate improvements
- Break condition: Outline generation fails to capture essential semantic relationships or syllable counting doesn't generalize

### Mechanism 3
- Claim: Multi-task auxiliary learning enables syllable count control
- Mechanism: Training on related tasks (syllable counting, phoneme translation) improves controlled syllable generation
- Core assumption: Auxiliary tasks transfer useful knowledge to controlled syllable generation
- Evidence anchors: Section 3.2 describes equipping plan-to-lyrics with word phonetics and syllable counting; section 6.1 notes phoneme translation task is not helpful; table 3 shows success rate improvement with multi-task training
- Break condition: Auxiliary tasks don't transfer effectively or model overfits to specific patterns

## Foundational Learning

- Concept: Cross-modal alignment constraints
  - Why needed here: Melody and lyrics must align in rhythm and phrasing for singability
  - Quick check question: Can you explain how note duration maps to syllable stress in music theory?

- Concept: Hierarchical text generation
  - Why needed here: Planning stage provides structure for coherent, controllable lyric generation
  - Quick check question: What are the benefits of planning-based generation versus direct generation in creative writing tasks?

- Concept: Multi-task learning with auxiliary objectives
  - Why needed here: Auxiliary tasks like syllable counting help model learn specific constraints needed for melody alignment
  - Quick check question: How does multi-task learning typically improve performance on the main task?

## Architecture Onboarding

- Component map: BART-large (input-to-plan) -> GPT-2 large (plan-to-lyrics) -> Melody constraint compiler

- Critical path:
  1. Training: Fine-tune input-to-plan on lyric datasets with outline generation task
  2. Training: Fine-tune plan-to-lyrics with multi-task auxiliary learning
  3. Inference: Compile melody into constraints
  4. Inference: Generate outline using input-to-plan
  5. Inference: Generate lyrics using plan-to-lyrics with melody constraints

- Design tradeoffs:
  - Monolingual training vs. paired data: Sacrifices direct cross-modal learning for scalability
  - Hard vs. soft rhythm constraints: Hard ensures alignment but may hurt text quality; soft provides balance
  - Number of auxiliary tasks: More tasks provide more knowledge but increase training complexity

- Failure signatures:
  - Low topic relevance scores indicate planning stage not capturing content control
  - High perplexity and cropped sentence ratios indicate text quality issues
  - Low stress-duration alignment percentages indicate melody constraint application problems

- First 3 experiments:
  1. Train input-to-plan with 1, 3, and 5 salient words to find optimal content control balance
  2. Test hard vs. soft rhythm constraints with varying α values to find optimal singability-text quality tradeoff
  3. Compare multi-task auxiliary learning with single-task training to quantify benefit of syllable counting and phoneme translation tasks

## Open Questions the Paper Calls Out
- How does LYRA performance change with different pre-trained language models (e.g., GPT-3, T5) as base model?
- How does LYRA performance change when incorporating additional melody constraints such as beat, tone, or pitch variations?
- How does LYRA performance change when generating longer sequences of lyrics with song structures such as verse, chorus, and bridge?

## Limitations
- Evaluation methodology compares against supervised baselines rather than unsupervised alternatives
- Multi-task learning claims partially supported with some tasks (phoneme translation) showing no benefit
- Hard constraint approach tradeoffs between singability and text quality not fully quantified

## Confidence

**High Confidence Claims:**
- Hierarchical framework architecture is technically sound and well-implemented
- System can generate lyrics that are singable and intelligible based on human evaluation
- Melody constraint compilation and application process is correctly described and functional

**Medium Confidence Claims:**
- 24% relative improvement represents genuine unsupervised learning capability
- Disentanglement of training from inference is key mechanism for unsupervised learning
- Multi-task auxiliary learning meaningfully improves syllable count control

**Low Confidence Claims:**
- System matches or exceeds supervised approaches in all relevant metrics
- Specific auxiliary tasks are optimal choices
- Hard constraint approach provides best balance of singability and text quality

## Next Checks

1. Direct unsupervised baseline comparison: Run LYRA against simple unsupervised approach (directly applying melody constraints to pre-trained language model without hierarchical framework or auxiliary tasks) to isolate contribution of proposed mechanisms.

2. Ablation of individual auxiliary tasks: Systematically test each auxiliary task (syllable counting, granular syllable counting, phoneme translation) in isolation to determine which actually contribute to performance and which are redundant or harmful.

3. Constraint strength sensitivity analysis: Conduct comprehensive study varying α from 0.0 to 1.0 in fine-grained increments to map full tradeoff curve between singability (stress-duration alignment) and text quality (perplexity, diversity, coherence) rather than testing extreme values.