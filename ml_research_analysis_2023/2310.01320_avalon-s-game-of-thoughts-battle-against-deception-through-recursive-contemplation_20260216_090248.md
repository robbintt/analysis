---
ver: rpa2
title: 'Avalon''s Game of Thoughts: Battle Against Deception through Recursive Contemplation'
arxiv_id: '2310.01320'
source_url: https://arxiv.org/abs/2310.01320
tags:
- player
- team
- game
- players
- mission
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of equipping large language
  models (LLMs) to identify and counteract deceptive information in multi-agent environments.
  Inspired by human recursive thinking and perspective-taking in the Avalon game,
  the authors propose a novel framework called Recursive Contemplation (ReCon).
---

# Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation

## Quick Facts
- **arXiv ID**: 2310.01320
- **Source URL**: https://arxiv.org/abs/2310.01320
- **Reference count**: 40
- **Primary result**: ReCon achieves 83.3% success rate in Avalon game vs 40% for Chain-of-Thought baseline

## Executive Summary
This study addresses the challenge of equipping large language models to identify and counteract deceptive information in multi-agent environments. Inspired by human recursive thinking and perspective-taking in the Avalon game, the authors propose a novel framework called Recursive Contemplation (ReCon). ReCon integrates formulation and refinement contemplation processes, each with first-order and second-order perspective transitions, to enhance LLMs' ability to discern deception without additional fine-tuning or data. Experiments using ChatGPT and Claude in the Avalon game show that ReCon significantly improves success rates compared to baseline Chain-of-Thought methods.

## Method Summary
The paper proposes a novel Recursive Contemplation (ReCon) framework that enhances LLMs' ability to identify and counteract deceptive information in multi-agent environments. ReCon integrates formulation and refinement contemplation processes, each with first-order and second-order perspective transitions, to improve the model's reasoning and communication strategies in the Avalon game. The framework operates through a sequence of thought generation, role inference, and perspective analysis to produce refined public statements that conceal private information while maintaining strategic effectiveness. The method is tested against a Chain-of-Thought baseline using ChatGPT and Claude models with temperature 0.6, evaluating performance through success rates and multi-dimensional analysis of game contributions.

## Key Results
- ReCon achieves 83.3% success rate in Avalon game compared to 40% for baseline CoT method
- Multi-dimensional analysis shows ReCon's superiority in concealment, logic, contribution, persuasiveness, information, and creativity metrics
- The framework significantly improves LLMs' ability to detect deception and maintain role confidentiality without additional fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Formulation contemplation allows LLMs to privately reason about hidden roles without exposing sensitive information.
- Mechanism: By generating internal thoughts first, then spoken content, the model avoids directly revealing private knowledge in its statements.
- Core assumption: The model can distinguish between internal reasoning and public communication.
- Evidence anchors:
  - [abstract] "formulation contemplation produces initial thoughts and speech"
  - [section 3.1] "formulation contemplation produces initial thoughts and spoken content"
  - [corpus] Weak: No direct corpus support for private vs public separation
- Break condition: If the model conflates internal thoughts with public statements, role exposure occurs.

### Mechanism 2
- Claim: First-order perspective transition enables the model to infer others' mental states from its own perspective.
- Mechanism: The model reasons about what roles other players might have based on observed game behavior and history.
- Core assumption: The model can simulate others' reasoning processes based on available evidence.
- Evidence anchors:
  - [abstract] "first-order allows an LLM agent to infer others' mental states"
  - [section 3.1] "first-order perspective transition by prompting the agent to deduce the roles of fellow players"
  - [corpus] Weak: No explicit corpus evidence for first-order reasoning success
- Break condition: If the model cannot accurately simulate others' reasoning, it will make incorrect role assumptions.

### Mechanism 3
- Claim: Second-order perspective transition helps the model refine its statements by considering how others perceive it.
- Mechanism: The model evaluates how its proposed speech would be interpreted by other roles and adjusts accordingly.
- Core assumption: The model can accurately predict others' interpretations of its statements.
- Evidence anchors:
  - [abstract] "second-order involves understanding how others perceive the agent's mental state"
  - [section 3.2] "second-order perspective transition involves LLMs reevaluating the initial version of spoken content"
  - [corpus] Weak: No direct corpus evidence for second-order reasoning improvement
- Break condition: If the model cannot accurately predict others' interpretations, refinement will not improve statements.

## Foundational Learning

- Concept: Recursive thinking in deceptive contexts
  - Why needed here: Enables the model to reason about deception at multiple levels of abstraction
  - Quick check question: Can the model reason about what others think about its own thoughts?

- Concept: Perspective-taking in multi-agent environments
  - Why needed here: Allows the model to simulate how different roles would interpret the same information
  - Quick check question: Does the model understand how Merlin's knowledge differs from a loyal servant's?

- Concept: Information concealment in social deduction games
  - Why needed here: Critical for maintaining strategic advantage while participating in discussions
  - Quick check question: Can the model communicate without revealing its hidden role?

## Architecture Onboarding

- Component map: Game state → Formulation (Thoughts → Speech) → First-order (Role inference) → Refinement (Perspective analysis) → Second-order (Content refinement) → Final output
- Critical path: Formulation → First-order → Refinement → Second-order → Final output
- Design tradeoffs:
  - More internal reasoning vs. more direct communication
  - Complexity of perspective transitions vs. computational cost
  - Granularity of role inference vs. accuracy
- Failure signatures:
  - Role exposure in public statements
  - Inconsistent reasoning between thought and speech
  - Failure to adjust statements based on perspective analysis
- First 3 experiments:
  1. Test formulation contemplation alone vs. baseline CoT
  2. Test first-order perspective transition impact on role inference accuracy
  3. Test refinement contemplation effectiveness in reducing role exposure

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions but discusses potential extensions including applying ReCon to other deceptive games and exploring multi-round scenarios where roles are revealed over time.

## Limitations
- Experimental setup limited to specific Avalon configuration with five roles and fixed game length
- Evaluation metrics derived from GPT-4 assessments introduce potential circularity and subjective bias
- Does not address performance in dynamic environments where roles or rules might change during gameplay

## Confidence
- **High Confidence**: The general framework design of Recursive Contemplation and its application to the Avalon game context
- **Medium Confidence**: The comparative performance improvements against Chain-of-Thought baseline
- **Low Confidence**: The specific numerical improvements in multi-dimensional metrics (concealment, logic, contribution, etc.) due to potential evaluator bias

## Next Checks
1. **External Evaluator Test**: Have human experts evaluate the same game transcripts to verify the GPT-4 assessments of concealment, logic, contribution, persuasiveness, information, and creativity metrics.

2. **Cross-Game Generalization**: Apply ReCon to other social deduction games (like Among Us or Werewolf) to test whether the recursive contemplation framework generalizes beyond the Avalon-specific implementation.

3. **Robustness Under Adversarial Conditions**: Test ReCon against deliberately deceptive strategies where other agents actively try to mislead or expose the LLM's role, measuring both success rates and information leakage.