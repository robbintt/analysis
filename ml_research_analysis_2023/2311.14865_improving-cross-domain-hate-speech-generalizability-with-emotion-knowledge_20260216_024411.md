---
ver: rpa2
title: Improving Cross-Domain Hate Speech Generalizability with Emotion Knowledge
arxiv_id: '2311.14865'
source_url: https://arxiv.org/abs/2311.14865
tags:
- cross-domain
- emotion
- hate
- speech
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of hate speech detection systems
  lacking generalizability across different online domains. To tackle this, the authors
  propose a multi-task learning framework that integrates emotion knowledge to enhance
  cross-domain hate speech detection.
---

# Improving Cross-Domain Hate Speech Generalizability with Emotion Knowledge

## Quick Facts
- arXiv ID: 2311.14865
- Source URL: https://arxiv.org/abs/2311.14865
- Reference count: 16
- Key outcome: Incorporating emotion knowledge improves cross-domain hate speech detection generalizability, with up to 18.1% improvement in F1 score using fBERT base model.

## Executive Summary
This study addresses the challenge of hate speech detection systems lacking generalizability across different online domains. The authors propose a multi-task learning framework that integrates emotion knowledge to enhance cross-domain hate speech detection. They experiment with two variants of the GoEmotions dataset (28-class and 6-class) and evaluate the impact of using BERT and fBERT as base models. Results show that incorporating emotion knowledge improves cross-domain generalizability, with the 6-class Ekman corpus (GEek) generally yielding more consistent improvements. The best performance was achieved using fBERT as the base model.

## Method Summary
The study uses a multi-task learning framework with hard parameter sharing between hate speech detection and emotion classification. The approach employs BERT and fBERT as base models, fine-tuned on six different hate speech datasets (Founta, Kaggle, Kumar, Offensive Reddit, Razavi, Waseem & Hovy) with emotion knowledge from the GoEmotions dataset. Two emotion corpora variants are used: GEgo (28-class) and GEek (6-class Ekman). The model is trained using negative log-likelihood loss for single-class prediction or binary cross-entropy loss for multi-labeled GEgo corpus, with evaluation focused on cross-dataset generalization performance.

## Key Results
- Emotion knowledge improves cross-domain hate speech detection generalizability
- GEek (6-class) yields more consistent improvements than GEgo (28-class)
- fBERT base model achieves highest absolute performance with emotion integration
- Up to 18.1% improvement in cross-domain F1 score with average increase of 8.5%

## Why This Works (Mechanism)

### Mechanism 1
- Emotion knowledge regularizes HS model representations to be more domain-general
- The auxiliary emotion task shares encoder parameters with HS detection, forcing the encoder to learn representations that explain both HS and emotion patterns
- Core assumption: HS and emotion have overlapping linguistic cues that can be jointly exploited
- Break condition: If HS and emotion domains are disjoint, joint training may hurt HS performance

### Mechanism 2
- Using fewer emotion categories (GEek) yields more consistent cross-domain gains
- A coarse-grained emotion schema captures broader affective patterns without overfitting to dataset-specific emotion distributions
- Core assumption: Fine-grained emotions may encode dataset-specific nuances that hurt generalization
- Break condition: If fine-grained emotions correlate strongly with HS across all domains, GEgo may outperform GEek

### Mechanism 3
- Base model domain adaptation interacts with emotion knowledge effectiveness
- fBERT, pre-trained on offensive language, already captures HS-specific patterns
- Core assumption: Pre-training domain match modulates the benefit of auxiliary tasks
- Break condition: If emotion features dominate over base model priors, base model choice may become irrelevant

## Foundational Learning

- **Multitask learning with hard parameter sharing**: Forces encoder to produce representations useful for both HS detection and emotion classification, improving generalization. Quick check: What happens to the encoder gradients during training—do they come from both tasks?

- **Cross-domain evaluation methodology**: Measures true generalization by training on one dataset and testing on others. Quick check: Why is it important to evaluate on datasets from different domains than the training set?

- **Emotion corpora selection and categorical scope**: Different emotion granularities capture different aspects of affective language; selecting the right scope impacts generalization. Quick check: How does using six broad emotions differ in effect from using 28 fine-grained emotions?

## Architecture Onboarding

- **Component map**: Input tokenizer → shared encoder (BERT/fBERT) → task-specific MLP heads (HS and emotion) → Emotion corpus (GEgo or GEek) supplies auxiliary labels

- **Critical path**: 1. Tokenize text, 2. Encode with shared Transformer, 3. Decode to HS and emotion predictions, 4. Compute combined loss, 5. Backpropagate through shared encoder

- **Design tradeoffs**: Hard sharing reduces parameters and enforces stronger regularization but may limit task-specific capacity; emotion granularity balances nuance capture against overfitting risk; base model choice affects starting performance and room for improvement

- **Failure signatures**: HS performance drops when emotion loss dominates; no cross-domain improvement (emotion task too easy or unrelated); overfitting to training domain (need stronger regularization or more diverse emotion data)

- **First 3 experiments**: 1. Train BERT-only baseline on Founta, evaluate on all datasets, 2. Train BERT + GEek multitask on Founta, compare cross-domain performance vs. baseline, 3. Repeat with fBERT to assess base model impact

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of emotion-integrated hate speech detection models vary across different types of online platforms (e.g., Twitter, Reddit, Facebook) and what factors contribute to these differences?

### Open Question 2
How does the integration of emotion knowledge impact the interpretability and explainability of hate speech detection models, and can this lead to more transparent decision-making processes?

### Open Question 3
What are the long-term implications of using emotion knowledge in hate speech detection models, and how might this approach need to be adapted as online communication evolves and new forms of hate speech emerge?

## Limitations
- Findings primarily based on English-language datasets from Western social media platforms
- Emotion corpora are English-only and may not capture emotion expression patterns in other languages or cultures
- Focuses on binary hate speech detection, oversimplifying the nuanced nature of harmful content

## Confidence
- **High Confidence**: Incorporating emotion knowledge improves cross-domain hate speech detection generalizability
- **Medium Confidence**: GEek (6-class) yields more consistent improvements than GEgo (28-class)
- **Low Confidence**: Emotion knowledge "regularizes" hate speech representations (mechanism not directly validated)

## Next Checks
1. Test the multi-task framework on non-English datasets to verify cross-linguistic benefits
2. Conduct ablation studies removing individual emotion categories to identify key contributors
3. Use representation analysis techniques to directly examine whether emotion knowledge causes learning of more domain-general representations