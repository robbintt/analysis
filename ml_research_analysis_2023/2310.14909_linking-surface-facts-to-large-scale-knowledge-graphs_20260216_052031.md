---
ver: rpa2
title: Linking Surface Facts to Large-Scale Knowledge Graphs
arxiv_id: '2310.14909'
source_url: https://arxiv.org/abs/2310.14909
tags:
- linking
- fact
- data
- facts
- entities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of linking surface-form Open Information
  Extraction (OIE) triples to canonical Knowledge Graph (KG) facts, aiming to bridge
  the gap between the high coverage but ambiguous surface facts from text and the
  precise but schema-limited KG facts. The proposed FaLB benchmark enables multi-faceted
  evaluation, including transductive, inductive, polysemous, and out-of-KG detection
  scenarios.
---

# Linking Surface Facts to Large-Scale Knowledge Graphs

## Quick Facts
- arXiv ID: 2310.14909
- Source URL: https://arxiv.org/abs/2310.14909
- Reference count: 40
- Primary result: OIE-to-KG linking achieves 97.7% transductive accuracy but struggles with inductive and polysemous cases; out-of-KG entity detection is feasible but predicate detection remains an open problem.

## Executive Summary
This paper addresses the challenge of linking surface-form Open Information Extraction (OIE) triples to canonical Knowledge Graph (KG) facts. The authors introduce the FaLB benchmark for multi-faceted evaluation, including transductive, inductive, polysemous, and out-of-KG detection scenarios. Their approach uses pre-trained language models to encode OIE slots and KG entries, followed by pre-ranking and re-ranking steps to link them. Experiments show strong transductive performance but highlight difficulties with inductive generalization and polysemy, while out-of-KG entity detection is feasible but predicate detection is not.

## Method Summary
The proposed method employs a two-stage approach: pre-ranking and re-ranking. The OIEpreranker independently embeds OIE slots and KG entries using RoBERTa-based encoders with contrastive loss training. This is followed by the Factreranker, which uses cross-attention over the top-k candidates from pre-ranking to resolve ambiguity and improve accuracy. Models are trained on synthetic data (SynthIE) generated from KG facts, demonstrating that OIE-to-KG linking can be learned without manual annotation beyond the KG. Entity alias augmentation is used to increase data diversity.

## Key Results
- Transductive linking achieves 97.7% accuracy, outperforming baselines.
- Pre-ranking + re-ranking improves performance on polysemous and inductive cases.
- Training on synthetic data (SynthIE) yields models competitive with those trained on human-annotated data (REBEL).
- Out-of-KG entity detection is feasible, but predicate detection remains an open problem.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pre-ranking followed by re-ranking improves accuracy on polysemous and inductive fact linking.
- Mechanism: Pre-ranking independently embeds OIE slots and KG entries, enabling efficient initial retrieval. Re-ranking then uses cross-attention over the top-k candidates to resolve ambiguity using the full context of the OIE triple and KG fact.
- Core assumption: Top-k candidates from pre-ranking contain the correct match, and contextual information in re-ranking resolves polysemy and inductive generalization gaps.
- Evidence anchors:
  - [abstract]: "we obtain high performance by training models solely on a synthetic variant... and that (iii) a dedicated OIE-to-KG fact re-ranking model improves the linking performance of both inductive and polysemous OIEs"
  - [section]: "For each OIE slot, we re-rank the OIEpreranker top-k most probable KG links... the Fact reranker brings a significant performance gain especially prominent for linking complete facts"
- Break condition: If the correct KG entry is not in the top-k of pre-ranking, or if the full context does not disambiguate the polysemous mentions, re-ranking fails to recover accuracy.

### Mechanism 2
- Claim: Training on synthetic data (SynthIE) yields models competitive with those trained on human-annotated data (REBEL).
- Mechanism: The LLM-generated sentences from SynthIE are paired with canonical KG facts, providing supervised signal for OIE-to-KG linking without manual annotation beyond the KG. Synthetic diversity (via alias augmentation) compensates for lack of human curation.
- Core assumption: LLM-generated sentences reliably entail the KG facts and maintain sufficient lexical diversity for generalization.
- Evidence anchors:
  - [abstract]: "we obtain high performance by training models solely on a synthetic variant of our dataset (i.e., with the KG as the only human-annotated data)"
  - [section]: "We observe that models trained on SynthIE are overall better OIE-to-KG fact linkers than models trained on REBEL... indicating that learning to link OIEs to KGs is possible using only synthetic data"
- Break condition: If synthetic sentences poorly reflect real-world surface forms, or if the entailment between sentence and KG fact is weak, model generalization will suffer.

### Mechanism 3
- Claim: Detecting out-of-KG entities is feasible, but detecting out-of-KG predicates is not.
- Mechanism: Entity detection leverages the large entity vocabulary to learn distinguishing features; predicate detection fails because the predicate set is small and models overfit to the limited training predicates.
- Core assumption: Entity sets are large and diverse, enabling zero-shot detection, while predicate sets are small and thus prone to overfitting.
- Evidence anchors:
  - [abstract]: "we show that (v) it is possible to detect Out-of-KG entities to an extent, however, the same does not hold for predicates: a task that our experiments identify as a difficult open problem"
  - [section]: "None of the models we evaluate are able to recognize whether an OIE relation has a corresponding KG predicate... the number of relations is limited (~600 during training) and therefore, the models overfit on this limited set"
- Break condition: If predicate vocabulary grows large or is sampled more evenly, or if zero-shot relation detection methods are used, predicate detection might become feasible.

## Foundational Learning

- Concept: Contrastive learning with in-batch and global negatives
  - Why needed here: Enables efficient training on large KGs without computing full softmax; ensures embeddings for matching pairs are close in latent space.
  - Quick check question: Why sample negatives from the whole KG during training rather than just in-batch negatives?
- Concept: Polysemy and contextual disambiguation
  - Why needed here: OIE mentions like "Michael Jordan" refer to multiple KG entities; disambiguation requires leveraging the relation and object in context.
  - Quick check question: How does the fact re-ranker use the full triple context to disambiguate polysemous mentions?
- Concept: Alias augmentation for data diversity
  - Why needed here: Surface forms in real text often use abbreviations, synonyms, or nicknames; augmentation exposes models to these variations.
  - Quick check question: Why is entity alias augmentation especially important for training but less critical for inference?

## Architecture Onboarding

- Component map:
  OIEpreranker (RoBERTa encoder + linear projection) -> Factreranker (RoBERTa cross-attention) -> Out-of-KG detection (confidence/entropy heuristics or query-key-value attention)
- Critical path: Extract OIE triple -> encode via OIEpreranker -> retrieve top-k KG facts -> re-rank with Factreranker -> output final KG fact
- Design tradeoffs:
  - Pre-ranking alone is fast but struggles with polysemy and inductive cases; re-ranking adds accuracy but increases latency.
  - Training on synthetic data saves annotation cost but may introduce domain shift; alias augmentation mitigates this.
  - Entity detection is feasible; predicate detection is notâ€”affects choice of out-of-KG detection strategy.
- Failure signatures:
  - Low re-ranking gain: top-k candidates from pre-ranking miss the correct KG fact.
  - Poor inductive performance: model overfits to training KG entities; requires stronger generalization or context use.
  - Out-of-KG predicate false positives: model cannot distinguish unseen predicates due to small predicate set and overfitting.
- First 3 experiments:
  1. Ablation: Run OIEpreranker with and without Factreranker on REBEL transductive split; measure gain.
  2. Synthetic data: Train OIEpreranker on REBEL vs. SynthIE; evaluate on inductive REBEL split; compare macro accuracy.
  3. Out-of-KG detection: Apply confidence@1 and entropy heuristics on OIEpreranker scores; measure entity vs. predicate detection accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does incorporating knowledge graph structure improve out-of-KG detection performance compared to using only language model embeddings?
- Basis in paper: [explicit] The authors acknowledge that leveraging KG structure could yield better representations for zero-shot samples and improve out-of-KG detection, but their current models ignore KG structure.
- Why unresolved: The paper does not experiment with incorporating KG structure into the model architecture or training process.
- What evidence would resolve it: Experiments comparing OIE-to-KG linking and out-of-KG detection performance between models using only language model embeddings versus models incorporating KG structure (e.g., through graph neural networks or knowledge graph embeddings).

### Open Question 2
- Question: How does the performance of OIE-to-KG linking models generalize across different languages and knowledge graphs beyond English and Wikidata?
- Basis in paper: [explicit] The authors note that their approach can be readily extended to other languages and knowledge graphs, but all their experiments are conducted on English data with Wikidata.
- Why unresolved: The paper does not provide any cross-lingual or cross-knowledge-graph experiments.
- What evidence would resolve it: Experiments evaluating the same OIE-to-KG linking models on datasets from different languages and knowledge graphs, comparing performance across languages and knowledge graphs.

### Open Question 3
- Question: What is the impact of using more diverse and realistic OIE triples on the performance of OIE-to-KG linking models?
- Basis in paper: [explicit] The authors observe that current datasets lack diversity in entity mentions and perform entity alias augmentation to increase diversity, but note that this augmentation only moderately impacts specific entity mentions.
- Why unresolved: The paper does not explore using OIE triples from more diverse sources or with more realistic surface forms beyond the entity alias augmentation.
- What evidence would resolve it: Experiments comparing OIE-to-KG linking performance using OIE triples from diverse sources (e.g., social media, news articles) with more varied surface forms against performance on current benchmark datasets.

## Limitations
- Out-of-KG predicate detection remains an open problem due to small predicate set and overfitting.
- Synthetic data may not fully capture the diversity of real-world surface forms, potentially limiting generalization.
- Experiments are limited to English Wikipedia and Wikidata, restricting external validity to other domains and languages.

## Confidence
- High Confidence: Transductive performance (97.7% accuracy) and general effectiveness of pre-ranking + re-ranking pipeline.
- Medium Confidence: Synthetic data sufficiency and alias augmentation benefits, though synthetic data alignment with real OIE distributions warrants further scrutiny.
- Low Confidence: Absolute statements about predicate detection impossibility and entity detection feasibility as the analysis provides plausible explanations but does not rule out alternative approaches.

## Next Checks
1. **Domain Transfer Test**: Apply the best-performing model (trained on SynthIE + alias augmentation) to OIE triples from a different domain (e.g., scientific literature or social media) and measure performance degradation compared to the Wikipedia-trained model.

2. **Predicate Detection Architecture Probe**: Implement a few-shot relation detection module using textual descriptions of KG predicates as conditioning context, and evaluate whether this enables out-of-KG predicate detection beyond the baseline's failure.

3. **Synthetic Data Quality Audit**: Conduct a manual annotation study comparing a sample of synthetic sentences from SynthIE against real OIE triples from REBEL, measuring lexical overlap, syntactic complexity, and entailment strength to quantify the domain shift.