---
ver: rpa2
title: Zero-Shot Medical Information Retrieval via Knowledge Graph Embedding
arxiv_id: '2310.20588'
source_url: https://arxiv.org/abs/2310.20588
tags:
- medical
- information
- retrieval
- knowledge
- document
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a zero-shot medical information retrieval approach
  called MedFusionRank, which addresses the challenge of retrieving relevant medical
  information from unstructured EHR data. The core method idea is to leverage a pre-trained
  BERT-style model to extract compact yet informative keywords from medical documents,
  and then enrich these keywords with domain knowledge by linking them to conceptual
  entities within a medical knowledge graph (MeSH).
---

# Zero-Shot Medical Information Retrieval via Knowledge Graph Embedding

## Quick Facts
- arXiv ID: 2310.20588
- Source URL: https://arxiv.org/abs/2310.20588
- Reference count: 35
- Primary result: MedFusionRank achieves MRR scores of 0.552 and 0.673 on NFCorpus and SCIFACT datasets respectively

## Executive Summary
This paper introduces MedFusionRank, a zero-shot medical information retrieval approach that addresses the challenge of retrieving relevant medical information from unstructured EHR data. The method leverages a pre-trained BERT-style model to extract informative keywords from medical documents and enriches them with domain knowledge by linking to conceptual entities within the MeSH knowledge graph. By fusing semantic similarity from medical embeddings with statistical matching from BM25, MedFusionRank overcomes limitations of traditional retrieval methods and achieves superior performance on two medical benchmark datasets.

## Method Summary
MedFusionRank extracts keywords from medical documents using a pre-trained RoBERTa model based on cosine similarity with the [CLS] token, then links these keywords to MeSH concepts for semantic enrichment. Node2Vec generates medical embeddings from the MeSH knowledge graph, which are used alongside document embeddings for retrieval. The system fuses BM25 scores with semantic similarity scores to improve overall performance, enabling effective zero-shot retrieval without task-specific fine-tuning.

## Key Results
- MedFusionRank outperforms existing models on NFCorpus and SCIFACT datasets across multiple evaluation metrics
- Achieved MRR scores of 0.552 on NFCorpus and 0.673 on SCIFACT
- Demonstrated effectiveness in retrieving relevant medical information from short or single-term queries
- Consistent performance improvements across Precision, nDCG, and Recall metrics

## Why This Works (Mechanism)

### Mechanism 1
- Keywords extracted by RoBERTa encode semantic context that can be enriched with MeSH knowledge. RoBERTa's contextual embeddings capture word-level semantics; cosine similarity with `<s>` token identifies informative keywords. These keywords are then aligned to MeSH concepts and embedded via Node2Vec, providing background knowledge absent in raw text.
- Core assumption: The top K keywords truly represent document content and MeSH nodes can be lexically matched to them.
- Evidence anchors: Utilizes RoBERTa for initial encoding and computes cosine similarity between special token and word representations; uses Node2Vec to generate medical embeddings from MeSH.
- Break condition: If keyword extraction fails to capture core semantics, enrichment adds noise rather than signal.

### Mechanism 2
- Fusing BM25 scores with semantic similarity from medical embeddings improves retrieval over either alone. BM25 provides exact term frequency matching; medical embeddings provide semantic matching via knowledge graph. Linear combination leverages both signals.
- Core assumption: The two score distributions are complementary and additive fusion is optimal.
- Evidence anchors: Proposes fusing scores from both approaches to improve overall performance; results consistently outperformed baseline methods across all evaluation metrics.
- Break condition: If semantic and lexical relevance diverge heavily, fusion can degrade performance.

### Mechanism 3
- CharLSTM outperforms prefix approximation for OOV word embeddings in medical domain. CharLSTM learns non-linear character-level mappings from in-vocabulary words, capturing sequential patterns in medical terminology better than simple prefix matching.
- Core assumption: Medical terms have meaningful character-level structures that CharLSTM can exploit.
- Evidence anchors: CharLSTM achieves better overall performance compared to Prefix Approximation; modeling sequential patterns and characters of medical terminology plays a more vital role in estimating representations for OOV words.
- Break condition: If medical vocabulary is dominated by regular morphology, simpler methods may suffice.

## Foundational Learning

- Knowledge graph embeddings (Node2Vec, TransE, etc.)
  - Why needed here: Provides semantic context for keywords beyond raw text, enabling zero-shot retrieval.
  - Quick check question: What is the objective function optimized by Node2Vec for generating embeddings?

- Zero-shot learning
  - Why needed here: Model retrieves relevant medical documents without task-specific fine-tuning on retrieval data.
  - Quick check question: How does zero-shot differ from few-shot in terms of training data requirements?

- BERT/RoBERTa contextual embeddings
  - Why needed here: Extracts informative keywords from medical documents by leveraging contextual semantics.
  - Quick check question: Why is the `<s>` token representation used for keyword importance scoring rather than word-piece embeddings?

## Architecture Onboarding

- Component map: Raw medical document → RoBERTa encoding → keyword extraction → MeSH alignment → Node2Vec embeddings → similarity scoring → ranking
- Critical path: Document → RoBERTa → keyword extraction → MeSH alignment → Node2Vec embeddings → similarity scoring → ranking
- Design tradeoffs:
  - Memory vs. accuracy: Storing all keyword embeddings vs. computing on the fly
  - Lexical matching vs. semantic entity linking for MeSH alignment
  - Simple fusion vs. learned combination of BM25 and semantic scores
- Failure signatures:
  - Low precision at top ranks: Keyword extraction not capturing relevance
  - High recall but poor ranking: Semantic and lexical signals misaligned
  - OOV terms dominate: Entity linking or embedding strategy insufficient
- First 3 experiments:
  1. Evaluate keyword extraction quality: Check top K keywords against human annotations.
  2. Ablation study: Semantic-only vs. BM25-only vs. fusion performance.
  3. OOV strategy comparison: Prefix approximation vs. CharLSTM on held-out medical terms.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the performance of the entity linking process be improved beyond simple lexical matching?
- Basis in paper: The paper mentions that "Future work should explore more sophisticated techniques to deal with the issue" of simple lexical entity linking limitations.
- Why unresolved: The paper acknowledges that lexical matching has known limitations like ambiguity and lack of semantic matching, but does not explore more advanced entity linking techniques.
- What evidence would resolve it: Experiments comparing different entity linking methods (e.g. semantic matching, contextual embeddings) on the same datasets would provide evidence of improved performance.

### Open Question 2
- Question: What is the impact of incorporating term frequency information into the retrieval process?
- Basis in paper: The paper states that "Despite the inclusion of background knowledge corresponding to each word in the document's keywords, factors such as term frequency should also be considered."
- Why unresolved: The paper proposes a method that considers medical knowledge but does not explicitly incorporate term frequency information, which is a key factor in traditional retrieval models like BM25.
- What evidence would resolve it: Experiments comparing the proposed method with and without term frequency information on the same datasets would demonstrate the impact of term frequency on retrieval performance.

### Open Question 3
- Question: How can the proposed method be adapted for real-time deployment on resource-constrained IoT devices?
- Basis in paper: The paper mentions plans to "implement an end-to-end prototype for real-time clinical decision support on medical IoT devices" and to "construct a vector database of the encoded document embeddings and load it directly onto the target hardware."
- Why unresolved: While the paper discusses future plans for deployment, it does not provide concrete details on how the method will be adapted for resource-constrained IoT devices.
- What evidence would resolve it: A working prototype demonstrating the proposed method running on a resource-constrained IoT device with real-time retrieval capabilities would provide evidence of successful adaptation.

## Limitations

- The keyword extraction mechanism relies heavily on RoBERTa's semantic understanding without quantitative validation of keyword relevance.
- Node2Vec hyperparameter settings for medical embedding generation are unspecified, which could significantly impact performance.
- The fusion strategy assumes linear complementarity between BM25 and semantic scores without validating whether learned combinations might perform better.

## Confidence

- **High confidence**: The overall retrieval performance improvements (MRR scores of 0.552 and 0.673 on benchmark datasets) are well-supported by experimental results.
- **Medium confidence**: Claims about keyword extraction quality and semantic enrichment are supported by methodology description but lack direct empirical validation.
- **Low confidence**: The assertion that Node2Vec + MeSH yields superior retrieval specifically lacks direct comparative evidence with other KG embedding methods.

## Next Checks

1. **Keyword extraction validation**: Manually annotate a subset of documents with their most relevant keywords and compare against the top 20 keywords extracted by RoBERTa. Calculate precision and recall of keyword extraction to quantify its effectiveness before enrichment.

2. **Embedding method comparison**: Implement an ablation study comparing Node2Vec-generated medical embeddings against other KG embedding approaches (e.g., TransE, DistMult) on the same MeSH graph to determine if Node2Vec is indeed optimal for this retrieval task.

3. **OOV strategy evaluation**: Create a held-out test set of medical terms (including abbreviations and rare conditions) and compare the performance of CharLSTM versus prefix approximation in generating embeddings for these OOV terms during retrieval tasks.