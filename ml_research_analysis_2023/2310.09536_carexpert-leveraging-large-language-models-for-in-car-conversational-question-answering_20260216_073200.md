---
ver: rpa2
title: 'CarExpert: Leveraging Large Language Models for In-Car Conversational Question
  Answering'
arxiv_id: '2310.09536'
source_url: https://arxiv.org/abs/2310.09536
tags:
- answer
- system
- carexpert
- user
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CarExpert is a modular, language-model-agnostic in-car conversational
  question-answering system designed to overcome hallucination and safety issues in
  LLM-based CQA. It employs controlled input filtering, document-grounded answer generation
  (both extractive and generative), and an extraction-score-based answer moderator
  to ensure safe, precise, and domain-specific responses.
---

# CarExpert: Leveraging Large Language Models for In-Car Conversational Question Answering

## Quick Facts
- arXiv ID: 2310.09536
- Source URL: https://arxiv.org/abs/2310.09536
- Reference count: 26
- Primary result: Modular LLM-based CQA system with extraction-score-based moderation outperforms baselines on document-grounded accuracy

## Executive Summary
CarExpert is a modular, language-model-agnostic in-car conversational question-answering system designed to overcome hallucination and safety issues in LLM-based CQA. It employs controlled input filtering, document-grounded answer generation (both extractive and generative), and an extraction-score-based answer moderator to ensure safe, precise, and domain-specific responses. Evaluated against state-of-the-art baselines, CarExpert achieves higher document-grounded accuracy and produces more natural, safe, and car-specific answers than off-the-shelf LLMs, with an extraction-score-based moderator yielding a 50/50 split between extractive and generative responses and outperforming cosine similarity-based moderation.

## Method Summary
CarExpert uses a modular pipeline with four main components: an Orchestrator for input filtering and clarification, a Retriever for semantic search over pre-processed car manual paragraphs, an Answer Generation module with both extractive (fine-tuned Albert-large) and generative (prompted GPT-3.5-turbo) capabilities, and an Answer Moderator that uses a weighted Levenshtein distance heuristic (Extraction Score) to select between generated responses. The system is trained and evaluated on car-specific data from owners' manuals, FAQs, and documentation, using human-annotated question-answer pairs for evaluation.

## Key Results
- CarExpert achieves higher document-grounded accuracy than baseline models (BM25, DPR, Sentence-transformer, GPT-3.5-turbo, Luminous-extended)
- The extraction-score-based answer moderator outperforms cosine similarity-based moderation
- The system produces a 50/50 split between extractive and generative answers, balancing grounding and naturalness
- CarExpert generates more natural, safe, and car-specific answers compared to off-the-shelf LLMs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Controlled input filtering via LLM-based orchestration prevents unsafe or irrelevant queries from being processed.
- Mechanism: The Orchestrator module uses a prompt-based filter to decline unsafe questions and request clarification for ambiguous ones, stopping further processing.
- Core assumption: An LLM can reliably classify user utterances as safe/unsafe and determine whether clarification is needed.
- Evidence anchors:
  - [abstract] "CarExpert employs LLMs to control the input... to ensure safe and domain-specific answers."
  - [section 2.1] "A prompt-based Orchestrator component is incorporated in CarExpert to tackle unsafe content and deal with multi-turn scenarios."
- Break condition: If the LLM fails to detect unsafe content or misclassifies a valid question, harmful or irrelevant content may be processed.

### Mechanism 2
- Claim: Extraction-score-based answer moderation selects the most document-grounded response, reducing hallucination.
- Mechanism: The Answer Moderator uses a weighted Levenshtein distance heuristic (Extraction Score) to choose between extractive and generative answers, favoring those syntactically close to retrieved paragraphs.
- Core assumption: A response closer in edit distance to retrieved documents is more likely to be accurate and less hallucinated.
- Evidence anchors:
  - [abstract] "an extraction-score-based answer moderator to ensure safe, precise, and domain-specific responses."
  - [section 2.4] "This moderation technique allows CarExpert to generate a controlled and document grounded answer by (i) grounding the system response to the retrieved documents, and (ii) filtering out incorrect and hallucinated responses."
- Break condition: If the retrieved paragraphs are themselves inaccurate or incomplete, the Extraction Score may still favor a response that is grounded in wrong information.

### Mechanism 3
- Claim: Retrieval-augmented generation with controlled prompts yields precise, natural, and car-specific answers.
- Mechanism: CarExpert retrieves top-3 relevant paragraphs, then uses prompt-engineered GPT-3.5-turbo for both abstractive summarization and informal talk, with separate templates for each task type.
- Core assumption: Prompting the LLM with retrieved context and clear task instructions will produce answers that are accurate, concise, and domain-specific.
- Evidence anchors:
  - [abstract] "employs LLMs to control the input, provide domain-specific documents to the extractive and generative answering components, and controls the output to ensure safe and domain-specific answers."
  - [section 2.3.1] "We design separate prompt templates for both the categories to handle various types of user utterances."
- Break condition: If the prompt templates are insufficient for a user's query type, or the LLM misinterprets the instructions, the answer may be inaccurate or overly verbose.

## Foundational Learning

- Concept: Prompt engineering and zero-shot/few-shot learning with LLMs.
  - Why needed here: CarExpert relies on carefully crafted prompts to guide GPT-3.5-turbo for different subtasks without fine-tuning, enabling domain-specific behavior.
  - Quick check question: Can you explain the difference between the "Abstractive Summarization" and "Informal Talk" prompt templates and when each is used?

- Concept: Vector embeddings and semantic search.
  - Why needed here: The Retriever uses pre-processed vector representations of car manual paragraphs to quickly find relevant documents for a user query.
  - Quick check question: What type of model (sparse, static, contextual, or hybrid) performed best in the ablation study for the Retriever component?

- Concept: Edit distance and text similarity metrics.
  - Why needed here: The Extraction Score moderation heuristic uses weighted Levenshtein distance to measure how closely a generated answer matches the retrieved paragraphs.
  - Quick check question: How does the Extraction Score differ from simple cosine similarity in selecting the final answer?

## Architecture Onboarding

- Component map:
  Orchestrator -> Semantic Search -> Answer Generation (extractive + generative) -> Answer Moderation -> Output

- Critical path:
  User utterance → Orchestrator filter → Semantic Search (retrieve top-3) → Answer Generation (both extractive and generative) → Answer Moderation (choose best) → Output

- Design tradeoffs:
  - Modularity vs. end-to-end optimization: Components can be swapped but are harder to jointly optimize.
  - Precision vs. recall in retrieval: Top-3 paragraphs balance speed and coverage.
  - Extractive vs. generative answers: Controlled split (50/50) ensures both grounding and naturalness.

- Failure signatures:
  - Unsafe content slipping through: Check Orchestrator prompt effectiveness.
  - Hallucinated answers: Check retrieval quality and moderation threshold.
  - Overly long or irrelevant answers: Review prompt templates and generation parameters.

- First 3 experiments:
  1. Swap the Retriever model (e.g., DPR → Sentence-transformer) and measure MRR@3 change.
  2. Change the Answer Moderator from Extraction Score to Cosine Similarity and compare accuracy.
  3. Modify the Orchestrator prompt to be stricter and test the impact on accepted vs. declined queries.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the specific error sources that propagate through the modular architecture of CarExpert?
- Basis in paper: [explicit] The paper discusses error analysis and identifies cases where the system failed, mentioning that the modular architecture helps in identifying the erroneous component.
- Why unresolved: The paper provides examples of errors but does not comprehensively analyze the specific error sources and their propagation through the system.
- What evidence would resolve it: A detailed analysis of error propagation through each module (Retriever, Reader, Generator, Answer Moderator) with specific examples and metrics.

### Open Question 2
- Question: How does the Extraction Score-based Answer Moderator perform compared to other potential moderation techniques?
- Basis in paper: [explicit] The paper compares the Extraction Score-based Answer Moderator with Cosine Similarity and shows that it outperforms the latter.
- Why unresolved: The paper only compares two moderation techniques. There might be other techniques that could perform better.
- What evidence would resolve it: A comprehensive comparison of the Extraction Score-based Answer Moderator with other potential moderation techniques using various metrics.

### Open Question 3
- Question: How does CarExpert handle highly complex and ambiguous queries?
- Basis in paper: [inferred] The paper mentions that the system may struggle with handling highly complex and ambiguous queries, potentially requiring external resolution modules.
- Why unresolved: The paper does not provide specific examples or strategies for handling such queries.
- What evidence would resolve it: Examples of highly complex and ambiguous queries and how CarExpert handles them, along with the performance metrics.

## Limitations
- The system's performance depends on the quality and consistency of pre-processed car manuals and documentation across manufacturers.
- The Orchestrator's safety filter, while effective, has not been tested against adversarial or edge-case queries for robustness.
- The system may struggle with highly complex and ambiguous queries, potentially requiring external resolution modules.

## Confidence
- Confidence in modular architecture design and extraction-score-based moderation effectiveness: **High**
- Confidence in prompt engineering approach and generalizability: **Medium**
- Confidence in long-term robustness of safety filter: **Low**

## Next Checks
1. Test the Orchestrator's safety filter against adversarial or edge-case queries to evaluate its robustness in blocking unsafe content.
2. Evaluate the system's performance across different car models and documentation sources to assess generalizability.
3. Conduct a longitudinal study to measure the system's accuracy and safety over extended periods of real-world use.