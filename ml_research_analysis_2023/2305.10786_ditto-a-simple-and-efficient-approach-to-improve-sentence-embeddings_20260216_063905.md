---
ver: rpa2
title: 'Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings'
arxiv_id: '2305.10786'
source_url: https://arxiv.org/abs/2305.10786
tags:
- bert
- sentence
- ditto
- embeddings
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Diagonal Attention Pooling (Ditto), a learning-free
  method to improve sentence embeddings from pre-trained language models (PLMs) such
  as BERT. The authors identify that BERT embeddings suffer from a bias towards uninformative
  words, limiting performance on semantic textual similarity (STS) tasks.
---

# Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings

## Quick Facts
- arXiv ID: 2305.10786
- Source URL: https://arxiv.org/abs/2305.10786
- Reference count: 7
- Primary result: BERT first-last Ditto achieves 64.77 on average STS tasks, comparable to BERT-flow's 66.55

## Executive Summary
This paper introduces Diagonal Attention Pooling (Ditto), a learning-free method that improves sentence embeddings from pre-trained language models (PLMs) by addressing their bias towards uninformative words. The authors discover that diagonal attention values in specific BERT attention heads correlate with word importance and can be used to weight word representations during averaging. Experiments show that Ditto consistently improves various PLMs on semantic textual similarity tasks without adding parameters or requiring learning, achieving performance comparable to more complex learned methods like BERT-flow and BERT-whitening.

## Method Summary
Ditto extracts diagonal attention values (self-attention from a word to itself) from selected attention heads in pre-trained language models, particularly focusing on heads that correlate with word importance measured by TF-IDF. These diagonal values are used as weights to compute a weighted average of word representations from the model, producing improved sentence embeddings. The method is applied as a post-processing operation to existing PLMs like BERT, RoBERTa, ELECTRA, and SBERT, requiring no additional training or parameters. Optimal attention heads are identified through development set tuning, and the resulting embeddings show better alignment between semantically related pairs and improved uniformity across the representation space.

## Key Results
- BERT first-last Ditto achieves 64.77 on average STS tasks, comparable to BERT-flow's 66.55
- Applying Ditto to static avg., last avg., and first-last avg. achieves absolute gains of +3.05, +9.20, and +8.07 on the Avg. score, respectively
- Ditto consistently improves various PLMs (BERT, RoBERTa, ELECTRA, SBERT) on STS tasks without adding parameters or requiring learning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Diagonal attention values in BERT capture word importance
- Mechanism: Certain self-attention heads in BERT have diagonal values that correlate with term importance measured by TF-IDF. By weighting word representations with these diagonal attention values, Ditto emphasizes informative words over uninformative ones.
- Core assumption: The diagonal attention values in specific BERT heads are meaningful indicators of word importance that can be leveraged to improve sentence embeddings.
- Evidence anchors: The paper shows moderate correlations (0.44-0.65) between diagonal attention and TF-IDF across BERT, RoBERTa, and ELECTRA, demonstrating the relationship exists but may not be extremely strong.

### Mechanism 2
- Claim: Weighted averaging with diagonal attention improves alignment and uniformity
- Mechanism: By weighting word representations with diagonal attention values, Ditto creates sentence embeddings that have better alignment between semantically related pairs and improved uniformity across the representation space, addressing the anisotropy problem.
- Core assumption: The anisotropy problem in BERT embeddings can be mitigated by adjusting the weighting of word representations based on their importance.
- Evidence anchors: The paper shows improvements in uniformity but mentions "larger degradations in alignment" compared to other methods, suggesting a tradeoff exists between these two metrics.

### Mechanism 3
- Claim: Learning-free postprocessing can match or exceed learned methods
- Mechanism: Ditto achieves comparable performance to methods like BERT-flow and BERT-whitening that require additional learning, demonstrating that simple postprocessing can be as effective as more complex learned approaches.
- Core assumption: The performance gap between learned and learning-free methods can be closed by leveraging existing model attention mechanisms.
- Evidence anchors: Ditto achieves 64.77 on average STS tasks while BERT-flow achieves 66.55, demonstrating comparable performance despite not requiring any learning.

## Foundational Learning

- Concept: Self-attention mechanism in transformers
  - Why needed here: Understanding how diagonal attention values are computed and what they represent is crucial for grasping Ditto's mechanism
  - Quick check question: What does the diagonal value in a self-attention matrix represent, and why might it indicate word importance?

- Concept: Term Frequency-Inverse Document Frequency (TF-IDF)
  - Why needed here: Ditto correlates diagonal attention with TF-IDF to validate that diagonal attention captures word importance
  - Quick check question: How does TF-IDF measure word importance, and why would it be a good proxy for evaluating diagonal attention's effectiveness?

- Concept: Anisotropy in vector representations
  - Why needed here: The paper's motivation is addressing the anisotropy problem in BERT embeddings, which affects semantic similarity tasks
  - Quick check question: What is the anisotropy problem in sentence embeddings, and how does it affect semantic textual similarity tasks?

## Architecture Onboarding

- Component map: Input sentence → BERT embedding layer → Transformer encoder → Diagonal attention extraction → Weighted averaging of hidden states → Output sentence embedding
- Critical path: The most critical path is extracting diagonal attention values from specific heads and using them to weight the hidden states during averaging
- Design tradeoffs: Learning-free simplicity vs. potentially suboptimal performance compared to learned methods; universal applicability vs. suboptimal performance on some PLMs
- Failure signatures: Performance degradation when diagonal attention doesn't correlate with word importance; poor results on PLMs where attention heads don't capture semantic information; overfitting to specific domains
- First 3 experiments:
  1. Verify that diagonal attention values correlate with TF-IDF on a held-out dataset
  2. Test different attention heads (l-h combinations) on STS-B development set to find optimal configuration
  3. Compare performance of Ditto vs. uniform averaging on a simple STS task to confirm improvement

## Open Questions the Paper Calls Out
None explicitly mentioned in the provided content.

## Limitations
- The core claim about diagonal attention values reliably capturing word importance rests on moderate correlation evidence (0.44-0.65) with TF-IDF, which suggests the relationship may not be robust across all domains or languages
- The method's effectiveness appears to depend heavily on selecting the right attention head for each PLM, but the paper doesn't provide clear guidance on how to identify optimal heads beyond development set tuning
- While Ditto shows strong performance on STS tasks, the paper reports "larger degradations in alignment" compared to some learned methods, indicating a potential tradeoff between uniformity and alignment that isn't fully explored

## Confidence

- **High Confidence**: Ditto's ability to improve sentence embeddings on STS tasks without additional parameters or learning - well-supported by quantitative results showing consistent gains across multiple PLMs and datasets
- **Medium Confidence**: The claim that diagonal attention values capture word importance - supported by correlation evidence but limited to specific BERT heads and potentially not generalizable to all PLMs or domains
- **Medium Confidence**: The assertion that learning-free methods can match learned approaches - while Ditto performs comparably to BERT-flow on average, the absolute performance gap (64.77 vs 66.55) suggests learned methods may still have advantages

## Next Checks

1. **Cross-domain robustness test**: Evaluate Ditto's performance on STS datasets from different domains (legal, biomedical, social media) to assess whether the diagonal attention-word importance relationship holds beyond the original datasets.

2. **Alternative importance metrics**: Compare diagonal attention correlation with other word importance measures (e.g., attention rollout, saliency methods) to validate whether the observed correlations are specific to TF-IDF or represent a more general phenomenon.

3. **Ablation on attention head selection**: Systematically test whether the performance gains persist when using randomly selected attention heads versus the "optimal" heads identified by development set tuning, to determine if the method's success depends critically on head selection.