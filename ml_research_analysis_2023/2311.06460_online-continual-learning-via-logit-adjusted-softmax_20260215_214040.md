---
ver: rpa2
title: Online Continual Learning via Logit Adjusted Softmax
arxiv_id: '2311.06460'
source_url: https://arxiv.org/abs/2311.06460
tags:
- learning
- online
- classes
- imbalance
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles catastrophic forgetting in online continual
  learning, specifically the inter-class imbalance problem where models become biased
  towards recently learned classes. The authors theoretically analyze that inter-class
  imbalance is entirely attributed to imbalanced class-priors, and the function learned
  from intra-class intrinsic distributions is the Bayes-optimal classifier.
---

# Online Continual Learning via Logit Adjusted Softmax

## Quick Facts
- arXiv ID: 2311.06460
- Source URL: https://arxiv.org/abs/2311.06460
- Reference count: 40
- Key outcome: LAS achieves 4.6% accuracy improvement over best baseline on CIFAR10 in online continual learning

## Executive Summary
This paper addresses catastrophic forgetting in online continual learning, specifically the inter-class imbalance problem where models become biased towards recently learned classes. The authors theoretically analyze that inter-class imbalance is entirely attributed to imbalanced class-priors, while the function learned from intra-class intrinsic distributions is the Bayes-optimal classifier. They propose Logit Adjusted Softmax (LAS), which adjusts model logits during training based on class-prior estimates to resist prior class bias and pursue the corresponding Bayes-optimum. LAS can be applied to both class-incremental and general continual learning setups with minimal computational overhead, demonstrating significant performance improvements over prior arts on various benchmarks.

## Method Summary
The authors propose Logit Adjusted Softmax (LAS) to address inter-class imbalance in online continual learning. LAS modifies the standard softmax cross-entropy loss by adding τ·log(πy,t) to logits, where πy,t represents class-prior estimates. A batch-wise estimator with sliding window is used to approximate time-varying class priors by computing the occurrence frequency of each label in recent input batches. The method is theoretically grounded in the observation that inter-class imbalance stems entirely from imbalanced class-priors when class-conditionals remain stable, making it effective for class-incremental learning scenarios.

## Key Results
- LAS achieves 4.6% accuracy improvement over best baseline on CIFAR10
- Consistent performance gains across CIFAR100, TinyImageNet, ImageNet, and iNaturalist benchmarks
- Robust performance across different task setups including class-IL, blurry, and general CL scenarios
- Minimal computational overhead compared to baseline methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Inter-class imbalance is entirely attributed to imbalanced class-priors in online continual learning
- Mechanism: By decomposing sample probability as class-conditional × class-prior, the authors show that recency bias stems solely from time-varying class-priors while class-conditionals remain stable
- Core assumption: Class-conditionals do not change across time (no domain drift)
- Evidence anchors: [abstract], [section 3] theoretical analysis

### Mechanism 2
- Claim: Logit Adjusted Softmax corrects prediction bias by adjusting logits based on class-prior estimates
- Mechanism: The method modifies softmax cross-entropy loss by adding τ·log(πy,t) to logits, effectively balancing contribution of each class regardless of frequency
- Core assumption: Class-prior estimates πy,t accurately approximate true P(y|ρt) in data stream
- Evidence anchors: [section 4.2] LAS formula, [section 4.3] estimator description

### Mechanism 3
- Claim: Batch-wise estimator with sliding window effectively tracks time-varying class-priors
- Mechanism: Class-prior πy,t computed as frequency of label y in input batches over past l time steps
- Core assumption: Short-term label frequencies in recent batches are representative of current class distribution
- Evidence anchors: [section 4.3] estimator formula, [section 6.4] sensitivity analysis

## Foundational Learning

- Concept: Bayes-optimal classifier minimizes class-balanced error
  - Why needed here: Theoretical foundation for why adjusting class-priors leads to optimal classification
  - Quick check question: If class-conditionals are stable, what classifier minimizes class-balanced error?

- Concept: Softmax cross-entropy loss formulation
  - Why needed here: Understanding how logit adjustment modifies standard loss function
  - Quick check question: How does adding τ·log(πy,t) to logits affect gradient with respect to model parameters?

- Concept: Catastrophic forgetting and recency bias
  - Why needed here: Understanding problem LAS solves in online continual learning
  - Quick check question: Why does model trained on imbalanced data streams tend to predict recent classes more often?

## Architecture Onboarding

- Component map: Feature extractor -> Linear classifier -> LAS adjustment layer -> Softmax loss
- Critical path: Incoming batch -> Class-prior estimates updated -> Logits adjusted using LAS formula -> Standard softmax cross-entropy loss computed on adjusted logits -> Backpropagation updates model parameters
- Design tradeoffs:
  - Sliding window length l: longer windows provide stability but slower adaptation to distribution changes
  - Temperature scalar τ: higher values increase margin between imbalanced classes but may hurt stability
  - Memory size: larger buffers provide better class-prior estimates but increase computational overhead
- Failure signatures:
  - Performance degradation when class distributions change rapidly
  - Overcorrection when τ is too high, leading to poor generalization
  - Memory overflow if buffer management not properly implemented
- First 3 experiments:
  1. Compare LAS with standard softmax on simple class-imbalanced dataset to verify bias correction
  2. Test different sliding window lengths on simulated non-stationary distribution to find optimal l
  3. Evaluate LAS integration with different replay strategies (ER, MIR, OCS) to measure performance gains

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop task-free domain-IL methods to efficiently address intra-class domain drift in online general CL scenarios?
- Basis in paper: [inferred] The authors acknowledge that their method cannot provide benefits when faced with domain-IL scenarios with only intra-class domain drift and no inter-class imbalance
- Why unresolved: Paper does not propose or evaluate any specific methods for handling intra-class domain drift in online general CL settings
- What evidence would resolve it: Developing and experimentally validating task-free domain-IL method that effectively addresses intra-class domain drift

### Open Question 2
- Question: What is optimal window length l for batch-wise estimator in LAS across different types of data streams?
- Basis in paper: [explicit] Authors mention window length l concerns sensitivity-stability trade-off with respect to estimation of class priors
- Why unresolved: Paper only provides general guidelines for choosing l based on rate of distribution fluctuations
- What evidence would resolve it: Conducting extensive experiments with varying window lengths on diverse data streams

### Open Question 3
- Question: How does LAS perform compared to other methods on extremely long sequential data streams with large number of classes?
- Basis in paper: [inferred] Authors demonstrate LAS effectiveness on challenging benchmarks like ImageNet and iNaturalist
- Why unresolved: Paper does not include experiments comparing LAS to other online CL methods on extremely long and high-dimensional data streams
- What evidence would resolve it: Conducting experiments on extremely long and high-dimensional data streams, comparing LAS to other state-of-the-art online CL methods

## Limitations

- Theoretical analysis assumes class-conditionals remain stable across time steps, which may not hold in real-world scenarios with domain drift
- Batch-wise estimator with sliding window may struggle with rapidly changing class distributions or very short data streams
- Temperature scalar τ requires careful tuning, with no systematic approach provided for selecting this hyperparameter across different problem domains

## Confidence

- High Confidence: The core claim that inter-class imbalance stems from class-prior imbalance (Mechanism 1)
- Medium Confidence: The effectiveness of the sliding window estimator for tracking class-priors (Mechanism 3)
- Medium Confidence: The overall performance improvements across benchmarks (4.6% accuracy gain)

## Next Checks

1. Test LAS on datasets with known domain drift to evaluate breakdown conditions when P(x|y, ρt) ≠ P(x|y, ρ0)
2. Conduct ablation studies systematically varying sliding window length l and temperature scalar τ across different data stream characteristics
3. Compare LAS performance against alternative class-prior estimation methods (e.g., exponential moving averages) to assess robustness of proposed estimator