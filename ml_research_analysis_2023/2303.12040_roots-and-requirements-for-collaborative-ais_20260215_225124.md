---
ver: rpa2
title: Roots and Requirements for Collaborative AIs
arxiv_id: '2303.12040'
source_url: https://arxiv.org/abs/2303.12040
tags:
- they
- human
- systems
- research
- intelligence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper identifies a critical gap in current AI systems: their
  inability to collaborate effectively with humans, which limits their adoption and
  trustworthiness. It traces the evolution of AI collaboration concepts from early
  intelligence augmentation visions to modern challenges, highlighting that despite
  decades of research and strategic calls for human-AI teaming, robust collaborative
  AIs remain elusive.'
---

# Roots and Requirements for Collaborative AIs

## Quick Facts
- arXiv ID: 2303.12040
- Source URL: https://arxiv.org/abs/2303.12040
- Authors: 
- Reference count: 0
- Key outcome: The paper identifies a critical gap in current AI systems: their inability to collaborate effectively with humans, which limits their adoption and trustworthiness.

## Executive Summary
This paper traces the evolution of AI collaboration concepts from early intelligence augmentation visions to modern challenges, identifying why robust collaborative AIs remain elusive despite decades of research. The authors argue that current AI systems fail at collaboration because they lack developmental learning from sensorimotor experiences and cannot handle the vast number of contextual exceptions that humans naturally navigate. Drawing on insights from psychology, developmental robotics, and AI history, the paper establishes ten fundamental challenges for human-AI collaboration and argues that effective collaboration requires AI systems that can learn incrementally like humans do, starting from embodied interaction.

## Method Summary
The paper provides a conceptual analysis tracing the evolution of AI collaboration concepts through historical research trajectories, presidential addresses, and interdisciplinary insights. It synthesizes theoretical arguments from psychology, developmental robotics, and AI history to identify ten fundamental challenges for human-AI collaboration. The methodology involves examining why current mainstream AI approaches cannot achieve expert-level collaborative performance and proposing developmentally-inspired approaches as a potential solution for bootstrapping collaborative AIs.

## Key Results
- Current AI systems cannot achieve expert-level collaborative performance due to inability to handle contextual exceptions and maintain common ground
- Ten fundamental challenges for human-AI collaboration are identified, focusing on common ground, mutual modeling, predictability, and shared task understanding
- The paper establishes the conceptual foundation for a follow-up paper proposing a roadmap for developmentally-inspired collaborative AI systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Current AI systems fail at collaboration because they lack developmental learning from sensorimotor experiences.
- Mechanism: Human collaborators build shared understanding incrementally through embodied interaction, while today's AIs are designed as tools with pre-programmed models that cannot adapt to contextual exceptions.
- Core assumption: Collaboration requires continuous common ground maintenance and model updating based on real-world feedback loops.
- Evidence anchors: [abstract] "current mainstream AI approaches... cannot achieve expert-level collaborative performance due to their inability to handle the vast number of contextual exceptions"
- Break condition: If AI systems can maintain common ground and adapt models without embodied developmental learning, this mechanism fails.

### Mechanism 2
- Claim: Effective collaboration requires mutual modeling where each party understands others' intentions, actions, and adaptations.
- Mechanism: Collaborators maintain mental models of teammates and tasks, using these to predict behavior and detect surprises. This enables coordinated action and repair of misunderstandings.
- Core assumption: Models are continuously updated through interaction and observation of teammate behavior.
- Evidence anchors: [section 2.2] "Challenge 2 stipulates that each collaborator has models of the others and the tasks that they are doing... People use models to make predictions about what happens next in activities."
- Break condition: If collaborative success can be achieved without detailed mutual modeling of intentions and task states, this mechanism fails.

### Mechanism 3
- Claim: The research trajectory shows a shift from isolated AI agents to collaborative AI requiring interdisciplinary approaches and system integration.
- Mechanism: Historical analysis of AAAI presidential addresses reveals increasing recognition that collaboration requires communication, coordination, and integration capabilities beyond traditional AI research scope.
- Core assumption: Evolution of AI research priorities reflects growing understanding of collaboration requirements.
- Evidence anchors: [section 3] "Bobrow observed... 'there has been increasing recognition of the importance of designing and analyzing system that do not make these isolation assumptions.'"
- Break condition: If collaboration can be achieved through isolated AI agents without interdisciplinary integration, this mechanism fails.

## Foundational Learning

- Concept: Common ground maintenance
  - Why needed here: Collaboration breaks down when parties have misaligned understanding of shared tasks and goals
  - Quick check question: What happens in the vacuum cleaner scenario when Bob and Steve don't maintain common ground about who is doing what?

- Concept: Mental modeling of tasks and teammates
  - Why needed here: Predictions about teammate behavior require understanding their intentions, capabilities, and current state
  - Quick check question: How does Macer's prediction about his dad needing help with the closet door demonstrate task modeling?

- Concept: Developmental learning through sensorimotor experience
  - Why needed here: Children learn collaboration incrementally through interaction, suggesting AIs need similar embodied learning foundations
  - Quick check question: Why can't current AI systems handle the "vast number of contextual exceptions" that humans navigate naturally?

## Architecture Onboarding

- Component map: Perception module → Memory system → Model builder → Prediction engine → Communication interface → Action selection system
- Critical path: Sensor input → Model update → Prediction → Action selection → Communication → Common ground check
- Design tradeoffs:
  - Real-time responsiveness vs. thorough model updating
  - Detailed prediction accuracy vs. computational efficiency
  - Autonomy in action selection vs. human control preferences
- Failure signatures:
  - Inability to detect when common ground is broken
  - Static models that don't update with new information
  - Actions that violate human expectations of predictability
- First 3 experiments:
  1. Test common ground maintenance by having AI and human coordinate on simple shared tasks with intentional misunderstandings introduced
  2. Evaluate mutual modeling by having AI predict human actions in novel scenarios and measuring prediction accuracy
  3. Assess developmental learning by measuring improvement in collaborative performance over repeated interactions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific competencies and behaviors must AI systems demonstrate to be considered effective collaborators, beyond current tool-based AI systems?
- Basis in paper: [explicit] The paper outlines ten fundamental challenges for human-AI collaboration and explicitly states that current AI systems fall short of meeting these challenges
- Why unresolved: The paper provides a theoretical framework but doesn't specify concrete technical requirements or implementation details for collaborative AI systems
- What evidence would resolve it: A detailed technical specification document or evaluation framework that defines measurable competencies for collaborative AI

### Open Question 2
- Question: How can AI systems acquire the vast amount of contextual knowledge and exceptions needed for expert-level collaboration, similar to how humans develop this knowledge incrementally from sensorimotor experiences?
- Basis in paper: [explicit] The paper argues that current mainstream AI approaches cannot achieve expert-level collaborative performance due to their inability to handle the vast number of contextual exceptions
- Why unresolved: The paper proposes developmental robotics as a potential approach but doesn't provide a concrete roadmap or demonstrate how this approach could scale
- What evidence would resolve it: Successful implementation and testing of developmental AI systems that can learn collaborative behaviors incrementally

### Open Question 3
- Question: What architectural and methodological changes are needed to create AI systems that can maintain common ground, repair misunderstandings, and adapt their behavior based on evolving team dynamics?
- Basis in paper: [explicit] The paper emphasizes the importance of common ground maintenance and highlights that current AI systems lack the ability to understand what others need to know
- Why unresolved: While the paper identifies this as a critical challenge, it doesn't provide specific architectural designs or implementation strategies
- What evidence would resolve it: Working prototypes of AI systems that can successfully maintain common ground in complex collaborative scenarios

## Limitations

- The analysis relies heavily on historical and conceptual arguments rather than empirical validation
- The ten challenges for human-AI collaboration are well-articulated but lack systematic evaluation against existing systems
- The claim that developmental learning is necessary for collaboration remains theoretical, with limited concrete evidence showing why alternative approaches cannot achieve similar results

## Confidence

- **High confidence**: The historical trajectory of AI collaboration research and the identification of fundamental challenges are well-supported by the literature cited
- **Medium confidence**: The argument that current mainstream AI approaches cannot achieve expert-level collaborative performance is persuasive but not definitively proven
- **Low confidence**: The specific claim that only developmentally-inspired approaches can bootstrap collaborative AIs is presented as a hypothesis for future work rather than a validated conclusion

## Next Checks

1. Systematically evaluate existing AI systems against each of the ten challenges to identify which are most critical barriers to implementation

2. Design controlled experiments comparing collaborative performance between AI systems with and without developmental learning capabilities, measuring key metrics like common ground maintenance and mutual modeling accuracy

3. Investigate whether current AI architectures can achieve collaborative competence through other mechanisms without requiring developmental learning from sensorimotor experiences