---
ver: rpa2
title: 'Learning with Complementary Labels Revisited: The Selected-Completely-at-Random
  Setting Is More Practical'
arxiv_id: '2311.15502'
source_url: https://arxiv.org/abs/2311.15502
tags:
- learning
- labels
- risk
- complementary-label
- complementary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a novel consistent complementary-label learning
  approach that does not rely on uniform distribution assumptions or additional ordinary-label
  training data. The method treats complementary-label learning as a set of negative-unlabeled
  binary classification problems using the one-versus-rest strategy.
---

# Learning with Complementary Labels Revisited: The Selected-Completely-at-Random Setting Is More Practical

## Quick Facts
- arXiv ID: 2311.15502
- Source URL: https://arxiv.org/abs/2311.15502
- Authors: 
- Reference count: 40
- Primary result: Novel consistent complementary-label learning approach without uniform distribution assumptions or additional ordinary-label training data

## Executive Summary
This paper revisits complementary-label learning by introducing the Selected-Completely-at-Random (SCAR) assumption as a more practical alternative to the traditional uniform distribution assumption. The authors propose a novel method that treats complementary-label learning as a set of negative-unlabeled binary classification problems using the one-versus-rest strategy. The approach provides theoretical guarantees including consistency and convergence rate while demonstrating superior empirical performance on both synthetic and real-world benchmark datasets.

## Method Summary
The proposed CONU method treats complementary-label learning as a set of negative-unlabeled binary classification problems by decomposing the multi-class problem into q independent binary problems using the one-versus-rest strategy. Under the SCAR assumption, the method constructs unbiased risk estimators that do not require uniform distribution assumptions or additional ordinary-label training data. A risk correction mechanism is introduced to prevent overfitting when using complex models. The approach can work with either known class priors or estimated ones using mixture proportion estimation techniques.

## Key Results
- PROVEN consistency and convergence rate of the proposed risk estimator under the SCAR assumption
- SUPERIOR accuracy improvements compared to state-of-the-art methods across various settings and models
- EFFECTIVE performance on both synthetic benchmarks (MNIST, CIFAR-10) and real-world datasets (CLCIFAR-10, CLCIFAR-20)
- ROBUSTNESS demonstrated across different model architectures and complementary label distributions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Complementary-label learning can be reformulated as a set of negative-unlabeled binary classification problems using the one-versus-rest strategy.
- Mechanism: By treating each class as a positive class in turn and all other classes as negative, the multi-class problem decomposes into q independent binary problems. The SCAR assumption ensures that examples with a given class as complementary label are sampled uniformly from non-positive examples, matching PU learning assumptions.
- Core assumption: SCAR assumption holds (Eq. 2), meaning complementary label generation is independent of features and true labels.
- Evidence anchors:
  - [abstract]: "we find that complementary-label learning can be expressed as a set of negative-unlabeled binary classification problems when using the one-versus-rest strategy"
  - [section 3.2]: "we show that the ordinary multi-class classification risk in Eq. (1) can be expressed using examples sampled from p (x|ȳk = 1) and p (x|ȳk = 0)"
  - [corpus]: Weak evidence - no direct neighbor mentions PU reformulation, but one neighbor discusses "SCAR assumption in PU learning" which supports the conceptual link.
- Break condition: If the SCAR assumption is violated (e.g., complementary labels depend on features or true labels), the PU equivalence fails.

### Mechanism 2
- Claim: The unbiased risk estimator (URE) provides consistent risk estimation without requiring uniform distribution assumption or anchor points.
- Mechanism: The risk is rewritten using densities conditioned on complementary label presence/absence, then approximated empirically using duplicated training instances to form negative and unlabeled datasets. Class priors can be estimated separately via mixture proportion estimation.
- Core assumption: Class priors πk are either known or estimable, and the reducibility assumption for class-prior estimation holds.
- Evidence anchors:
  - [abstract]: "The method treats complementary-label learning as a set of negative-unlabeled binary classification problems using the one-versus-rest strategy"
  - [section 3.2]: Derivation of unbiased risk estimator (Eq. 3) and explanation of how binary datasets DNk and DUk are constructed
  - [corpus]: No direct neighbor evidence, but class-prior estimation literature supports the feasibility.
- Break condition: If class priors cannot be estimated accurately (e.g., due to insufficient data or violation of reducibility), the risk estimator becomes biased.

### Mechanism 3
- Claim: Risk correction function g(z) mitigates overfitting when using complex models by bounding potentially negative risk terms.
- Mechanism: The risk correction function (e.g., absolute value) wraps potentially negative terms in the empirical risk estimator, creating an upper bound that prevents the loss from becoming negative during training with complex models.
- Core assumption: The risk correction function is Lipschitz continuous and the corrected estimator remains consistent despite bias.
- Evidence anchors:
  - [section 3.4]: Discussion of overfitting problems and introduction of risk correction approach (Eq. 9)
  - [section 3.4]: Theorems 4 and 5 proving bias consistency and estimation error bounds
  - [corpus]: No direct neighbor evidence, but overfitting mitigation in PU learning is well-established.
- Break condition: If the Lipschitz constant Lg is too large or the correction function is poorly chosen, the bias may dominate and hurt generalization.

## Foundational Learning

- Concept: Positive-Unlabeled (PU) Learning
  - Why needed here: The proposed method builds directly on PU learning theory to handle complementary labels without requiring uniform distribution assumptions.
  - Quick check question: In PU learning, what is the relationship between the observed unlabeled data and the true negative class?

- Concept: One-Versus-Rest (OVR) Strategy
  - Why needed here: The method decomposes multi-class complementary-label learning into q binary problems, each treated as a PU problem.
  - Quick check question: How does the OVR strategy handle class imbalance when applied to PU learning?

- Concept: Risk Consistency and Estimation Error Bounds
  - Why needed here: Theoretical guarantees are provided to show the method converges to the true risk and achieves Bayes error.
  - Quick check question: What is the difference between risk consistency and classifier consistency in this context?

## Architecture Onboarding

- Component map: Input -> Class Prior Estimation (optional) -> Risk Computation -> Model Training -> Prediction
- Critical path: Data → Class Prior Estimation (if needed) → Risk Computation → Model Training → Prediction
- Design tradeoffs:
  - Using class prior estimation adds complexity but enables fully unsupervised learning
  - Risk correction prevents overfitting but introduces bias that must be bounded
  - One-versus-rest decomposition is simple but may not capture class correlations
- Failure signatures:
  - Poor performance with inaccurate class priors (estimated πk far from true values)
  - Training loss becoming negative without risk correction
  - High variance in performance across different random seeds
- First 3 experiments:
  1. Test on MNIST with uniform complementary label generation and known class priors to verify basic functionality
  2. Test with estimated class priors (using mixture proportion estimation) to verify the full pipeline
  3. Test on real-world CLCIFAR-10 with multiple complementary labels to verify robustness to complex distributions

## Open Questions the Paper Calls Out

- Open Question 1: How does the performance of CONU compare to other methods when class priors are unknown and must be estimated from the data?
  - Basis in paper: [explicit] The paper mentions that class priors can be estimated using off-the-shelf mixture proportion estimation approaches, but does not provide experimental results comparing performance with estimated vs. known class priors.
  - Why unresolved: The paper only shows results with known class priors and a sensitivity analysis with slightly inaccurate priors, but doesn't compare to other methods in the case of unknown priors.
  - What evidence would resolve it: Experimental results comparing CONU's performance with estimated class priors to other methods' performance with either known or estimated class priors.

- Open Question 2: How does CONU perform when the assumption that complementary labels are generated completely at random is violated?
  - Basis in paper: [explicit] The paper introduces the SCAR assumption and mentions it is milder than uniform distribution assumption, but doesn't provide results for cases where this assumption is violated.
  - Why unresolved: The experimental results only show performance under the SCAR assumption, without testing robustness to violations of this assumption.
  - What evidence would resolve it: Experimental results showing CONU's performance when complementary labels are generated in a non-random manner, such as based on features or in a biased way.

- Open Question 3: How does the choice of risk correction function g(z) affect CONU's performance?
  - Basis in paper: [explicit] The paper mentions using the absolute value function as the risk correction function, but doesn't explore other options or analyze the impact of this choice.
  - Why unresolved: The paper doesn't provide any ablation studies or comparisons with different risk correction functions.
  - What evidence would resolve it: Experimental results comparing CONU's performance with different choices of risk correction functions (e.g., ReLU, clipped absolute value) to determine the impact on performance.

## Limitations
- The method's performance heavily depends on accurate class-prior estimation, which may be challenging in real-world scenarios with limited data.
- The risk correction mechanism introduces additional hyperparameters that require careful tuning.
- Experiments primarily focus on synthetic datasets and a single real-world dataset, leaving generalizability to diverse domains uncertain.

## Confidence

- High confidence: The theoretical framework connecting complementary-label learning to PU learning is sound and well-established.
- Medium confidence: The proposed unbiased risk estimator provides a valid alternative to uniform distribution assumptions.
- Low confidence: The practical performance advantages are significant and generalizable across diverse real-world applications.

## Next Checks

1. Conduct extensive experiments on diverse real-world datasets with varying class distributions and noise levels to assess robustness.
2. Evaluate the sensitivity of the method to class-prior estimation accuracy by systematically varying the quality of estimated priors.
3. Compare the computational efficiency of the proposed method against existing approaches, particularly for large-scale datasets and complex models.