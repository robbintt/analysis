---
ver: rpa2
title: Domain Generalisation via Risk Distribution Matching
arxiv_id: '2310.18598'
source_url: https://arxiv.org/abs/2310.18598
tags:
- risk
- domains
- distributions
- domain
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Risk Distribution Matching (RDM), a novel approach
  for domain generalisation that leverages risk distributions to characterise domains
  and achieve domain invariance. The key idea is to minimise the divergence between
  risk distributions across training domains, as a model trained on domain-invariant
  features will produce consistent risk distributions.
---

# Domain Generalisation via Risk Distribution Matching

## Quick Facts
- arXiv ID: 2310.18598
- Source URL: https://arxiv.org/abs/2310.18598
- Reference count: 40
- Key result: Achieves 56.3% accuracy on ColoredMNIST, outperforming ERM (27.9%) and other DG methods

## Executive Summary
This paper introduces Risk Distribution Matching (RDM), a novel approach for domain generalisation that leverages risk distributions to characterise domains and achieve domain invariance. The key insight is that models trained on domain-invariant features produce consistent risk distributions across domains. RDM uses the maximum mean discrepancy (MMD) distance to minimise the variance of risk distributions, with an efficient approximation that aligns only the worst-case domain with the aggregated distribution. Extensive experiments demonstrate superior generalisation capability over state-of-the-art DG methods.

## Method Summary
RDM extends standard empirical risk minimisation (ERM) by adding a distributional variance loss term computed via MMD distance between risk distributions across domains. The approach computes per-sample risks for each domain, then minimises the divergence between these risk distributions using an RBF kernel-based MMD metric. An efficient approximation focuses on aligning the worst-case domain (highest average risk) with the aggregated distribution. The final objective combines ERM loss with the matching coefficient-weighted distributional variance term.

## Key Results
- ColoredMNIST: 56.3% accuracy (vs ERM 27.9%, IRM 52.5%, CORAL 55.3%)
- DomainNet: 43.4% accuracy (vs ERM 40.9%, CORAL 41.5%, Fish 42.7%)
- Outperforms state-of-the-art methods on standard DG benchmark datasets
- Avoids high-dimensional challenges present in feature/gradient matching approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aligning risk distributions across domains leads to domain-invariant feature learning
- Mechanism: By minimizing the divergence between risk distributions (via MMD), the model learns features that produce similar prediction uncertainty across domains, reducing reliance on domain-specific cues
- Core assumption: Risk distributions effectively capture domain variation and can serve as a reliable domain representation
- Evidence anchors: Risk distributions highlight domain differences and reveal inherent complexities; consistent risk distributions emerge from domain-invariant features
- Break condition: If risk distributions fail to capture meaningful domain differences, the alignment would have little effect on generalization

### Mechanism 2
- Claim: Focusing on the worst-case domain's risk distribution provides an efficient approximation of full distributional variance minimization
- Mechanism: The worst-case domain typically has the most divergent risk distribution; aligning it with the aggregated distribution implicitly reduces variance across all domains
- Core assumption: The domain with highest average risk is the most divergent in terms of its full risk distribution
- Evidence anchors: Worst-case domain selected by maximum expected risk; optimizing this also reduces overall distributional variance
- Break condition: If the worst-case domain by average risk is not actually the most divergent in distribution, this approximation may fail

### Mechanism 3
- Claim: Scalar risk distributions avoid high-dimensional challenges present in feature/gradient matching methods
- Mechanism: By working in scalar space rather than high-dimensional representation space, RDM avoids issues with data sparsity, computational complexity, and unreliable statistical estimates
- Core assumption: Scalar risk distributions contain sufficient information to characterize domain differences
- Evidence anchors: RDM focuses on scalar risk distributions, sidestepping pitfalls of high-dimensional challenges
- Break condition: If scalar risk distributions lack sufficient information to distinguish domain characteristics, this approach would fail to capture important domain differences

## Foundational Learning

- Concept: Maximum Mean Discrepancy (MMD)
  - Why needed here: MMD provides a way to measure distance between risk distributions without requiring density estimation
  - Quick check question: What property of MMD makes it suitable for comparing distributions without knowing their densities?

- Concept: Reproducing Kernel Hilbert Space (RKHS) embeddings
  - Why needed here: RKHS allows us to represent probability distributions as points in a Hilbert space, enabling distance calculations
  - Quick check question: Why does using a characteristic kernel ensure that different distributions map to different points in RKHS?

- Concept: Distributional variance across domains
  - Why needed here: Minimizing variance of risk distributions across domains enforces consistency in model behavior
  - Quick check question: Under what condition does the distributional variance equal zero according to Theorem 1?

## Architecture Onboarding

- Component map: Base model -> ERM loss -> Risk distribution alignment module -> Worst-case domain selector -> Aggregated distribution calculator
- Critical path:
  1. Forward pass through base model
  2. Compute per-sample risks for each domain
  3. Calculate MMD between worst-case domain and aggregated distribution
  4. Combine with ERM loss for final objective
- Design tradeoffs:
  - Batch size vs. accurate risk distribution estimation (larger batches better for MMD)
  - Matching coefficient λ vs. ERM performance (trade-off between risk minimization and invariance)
  - RBF kernel bandwidth selection (fixed vs. learned)
- Failure signatures:
  - Training loss decreases but validation performance plateaus or degrades (overfitting to training domains)
  - MMD loss remains high throughout training (poor alignment)
  - Model becomes overly conservative (high average risk across all domains)
- First 3 experiments:
  1. Run ERM baseline on ColoredMNIST to establish baseline performance and observe risk distribution differences
  2. Implement RDM with λ=1 and small batch size, verify MMD computation is working
  3. Increase batch size and tune λ to find optimal balance between ERM and matching objectives

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of kernel function (other than RBF) affect the performance and efficiency of RDM in domain generalization?
- Basis in paper: The paper uses the RBF kernel as a characteristic kernel and mentions that "we employ the RBF kernel, a well-known characteristic kernel defined as k(x, x′) := exp(-1/2σ∥x - x′∥2), where σ > 0 is the bandwidth parameter."
- Why unresolved: The paper only uses the RBF kernel for experiments and does not explore other characteristic kernels or compare their performance.
- What evidence would resolve it: Experiments comparing RDM's performance using different characteristic kernels (e.g., Laplacian, inverse multiquadric) on benchmark datasets would show if RBF is optimal or if alternatives provide better results.

### Open Question 2
- Question: What is the theoretical relationship between the distributional variance metric VH({T1, ..., Tm}) and other domain generalization objectives like domain adversarial training or gradient matching?
- Basis in paper: The paper introduces VH({T1, ..., Tm}) as a novel metric for domain generalization and compares it empirically to other methods, but does not provide theoretical connections or analysis of relationships.
- Why unresolved: While empirical comparisons are provided, the paper lacks a theoretical framework that explains how distributional variance relates to other DG objectives or what properties make it effective.
- What evidence would resolve it: A theoretical analysis deriving conditions under which minimizing distributional variance is equivalent to or complementary to other DG objectives would clarify its role in the broader landscape of domain generalization methods.

### Open Question 3
- Question: How does RDM perform on datasets with continuous domain shifts rather than discrete domains, and what modifications would be needed?
- Basis in paper: The paper evaluates RDM on datasets with discrete domains (PACS, VLCS, OfficeHome, TerraIncognita, DomainNet) and mentions "domain difference can be induced by several factors, such as spurious correlations or variations in location or time," suggesting interest in continuous shifts.
- Why unresolved: All experiments use datasets with clear, discrete domain boundaries. The paper does not test RDM on datasets with gradual, continuous domain shifts or address how the method would need to be adapted for such scenarios.
- What evidence would resolve it: Experiments on datasets with continuous domain shifts (e.g., WILDS, FMoW) or synthetic data with gradual transitions between domains would show whether RDM can handle continuous shifts or if modifications like local risk distribution alignment are needed.

## Limitations
- Assumes risk distributions effectively capture domain differences, but this lacks strong empirical validation
- The worst-case approximation may fail when domains exhibit complex, non-linear relationships
- Relies on MMD with RBF kernels, introducing hyperparameter sensitivity particularly regarding bandwidth selection

## Confidence

- High confidence: The core mathematical formulation of RDM using MMD for distributional alignment is sound and properly derived
- Medium confidence: The empirical results showing improved performance over baselines are robust, though the 3-4% gains on DomainNet warrant further validation
- Low confidence: The theoretical claims about why scalar risk distributions are sufficient and superior to high-dimensional approaches lack direct empirical support

## Next Checks

1. **Ablation study on dimensionality**: Compare RDM performance when using alternative distributional representations (e.g., feature-based MMD, gradient-based distributions) against the scalar risk distribution approach to validate the claimed advantages of the scalar formulation.

2. **Stress testing worst-case approximation**: Systematically evaluate scenarios where the domain with highest average risk differs from the domain with most divergent risk distribution, measuring how this affects RDM's approximation quality and overall performance.

3. **Hyperparameter sensitivity analysis**: Conduct comprehensive experiments varying the matching coefficient λ across multiple orders of magnitude and testing different kernel bandwidth selection strategies to establish the robustness of RDM's performance to these critical hyperparameters.