---
ver: rpa2
title: Adaptive Latent Entity Expansion for Document Retrieval
arxiv_id: '2306.17082'
source_url: https://arxiv.org/abs/2306.17082
tags:
- expansion
- re-ranking
- retrieval
- entity
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of document retrieval for complex
  queries, where traditional methods often struggle due to vocabulary mismatch and
  insufficient precision in the top ranks. The authors propose Latent Entity Expansion
  (LEE), a hybrid word and entity-based expansion model that leverages fine-grained
  passage feedback from neural language model (NLM) re-ranking.
---

# Adaptive Latent Entity Expansion for Document Retrieval

## Quick Facts
- arXiv ID: 2306.17082
- Source URL: https://arxiv.org/abs/2306.17082
- Reference count: 40
- Key outcome: Hybrid word-entity expansion with NLM re-ranking improves recall by 6-12% and achieves state-of-the-art MAP/NDCG without second-stage re-ranking

## Executive Summary
This paper addresses document retrieval challenges for complex queries through Latent Entity Expansion (LEE), a hybrid expansion model that combines word and entity-based feedback with neural re-ranking. LEE leverages fine-grained passage feedback from T5-3b models to construct joint probabilistic expansions while incorporating entity dependencies. The adaptive component iteratively refines the re-ranking pool during scoring, eliminating the need for additional NLM re-ranking. Experiments on TREC Robust 2004 and CODEC datasets show significant improvements in recall and precision metrics, particularly for entity-centric queries.

## Method Summary
LEE operates through a two-stage pipeline: initial BM25 retrieval followed by T5-3b passage re-ranking, then hybrid word-entity expansion using the NLM feedback. The expansion model constructs joint probabilistic representations incorporating entity dependencies, grounding both documents and queries to a knowledge base via entity linking. The adaptive variant refines the query iteratively after each batch of documents is scored, avoiding additional re-ranking passes. The approach is evaluated on TREC Robust 2004 (528k newswire documents, 249 topics) and CODEC (750k web documents, 42 essay-style topics).

## Key Results
- LEE achieves 6-12% recall improvement over baselines
- State-of-the-art MAP and NDCG@20 results without second NLM re-ranking
- Hybrid word-entity expansion provides 2-8% additional NDCG improvement over individual models
- Particularly effective for entity-centric queries requiring explicit semantic modeling

## Why This Works (Mechanism)

### Mechanism 1
Combining NLM re-ranking before query expansion significantly improves the precision of the feedback set, which in turn enhances expansion effectiveness. The NLM acts as a high-precision filter, ensuring only the most relevant documents are used for feedback, reducing noise and allowing expansion models to focus on truly relevant terms and entities.

### Mechanism 2
LEE's hybrid word and entity expansion model is more effective than individual expansion models. By incorporating both words and entities, LEE captures a broader range of relevant information—entities provide explicit semantic links to knowledge bases while words capture nuanced, context-specific terms.

### Mechanism 3
Adaptive expansion iteratively refines the re-ranking pool, improving effectiveness without additional NLM re-ranking cost. After each batch of documents is re-ranked, LEE expands the query and retrieves the next batch, dynamically adapting to the evolving understanding of the information need.

## Foundational Learning

- **Concept: Pseudo-relevance feedback (PRF)**
  - Why needed here: PRF is the foundational technique LEE builds upon; understanding its assumptions and limitations is crucial for appreciating LEE's innovations
  - Quick check: What is the main assumption behind PRF, and what are its potential weaknesses?

- **Concept: Entity linking**
  - Why needed here: LEE relies on entity linking to ground documents and queries to a knowledge base; understanding how it works and its impact on retrieval is essential
  - Quick check: How does entity linking help address the vocabulary mismatch problem in information retrieval?

- **Concept: Neural language models (NLMs) for re-ranking**
  - Why needed here: LEE leverages NLM re-ranking to improve the precision of the feedback set; understanding how NLMs work and their strengths in re-ranking is crucial
  - Quick check: How do NLMs improve the precision of document ranking compared to traditional ranking models?

## Architecture Onboarding

- **Component map**: Entity Linking -> NLM Re-ranking -> Hybrid Expansion -> Retrieval -> (Adaptive Refinement)
- **Critical path**: Entity linking → NLM re-ranking → hybrid expansion → retrieval; adaptive component modifies this by iteratively refining the query after each batch
- **Design tradeoffs**: Trades computational cost for effectiveness—NLM re-ranking is expensive but improves feedback quality; adaptive component increases cost but avoids second re-ranking
- **Failure signatures**: May fail if entity linking is inaccurate, NLM re-ranker fails to identify relevant documents, or expanded query becomes too broad/loses focus
- **First 3 experiments**:
  1. Compare LEE effectiveness with and without NLM re-ranking to validate high-precision feedback importance
  2. Compare hybrid expansion model with individual word and entity expansion models
  3. Compare LEE with and without adaptive expansion to evaluate iterative query refinement impact

## Open Questions the Paper Calls Out

- How does the effectiveness of adaptive expansion with LEE compare to two rounds of neural re-ranking on long, complex queries in terms of both precision and recall?
- What is the impact of incorporating entity dependencies in the LEE model on its effectiveness across different types of queries and datasets?
- How does the effectiveness of LEE compare to other state-of-the-art expansion models when applied to document retrieval tasks with varying levels of complexity?

## Limitations

- Effectiveness relies heavily on entity linking quality and NLM re-ranker performance
- Adaptive expansion adds computational complexity without clear guidance on when benefits outweigh costs
- Results may not generalize across domains beyond newswire and web documents

## Confidence

- **High Confidence**: NLM re-ranking improves feedback precision (strong empirical evidence and established literature)
- **Medium Confidence**: Hybrid word-entity expansion superiority over individual models (based on ablation studies, limited to tested datasets)
- **Low Confidence**: Generalizability of adaptive expansion benefits across different document collections and query types (evaluated only on two datasets)

## Next Checks

1. **Entity Linking Quality Assessment**: Conduct detailed error analysis of entity linking output to quantify how errors propagate through LEE pipeline and affect final retrieval performance.

2. **Cross-Domain Robustness Test**: Evaluate LEE on significantly different domain (e.g., scientific literature or social media) to assess whether reported effectiveness gains transfer beyond newswire and web documents.

3. **Computational Cost-Benefit Analysis**: Measure actual runtime and resource requirements of adaptive expansion versus traditional two-stage approach across varying dataset sizes to determine practical deployment thresholds.