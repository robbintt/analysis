---
ver: rpa2
title: 'SLCA: Slow Learner with Classifier Alignment for Continual Learning on a Pre-trained
  Model'
arxiv_id: '2303.05118'
source_url: https://arxiv.org/abs/2303.05118
tags:
- learning
- continual
- pre-training
- split
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a simple yet effective approach for continual
  learning on a pre-trained model, which addresses the progressive overfitting problem
  by using a slow learner for the representation layer and further improves the classification
  layer through classifier alignment. The method achieves significant improvements
  over state-of-the-art approaches on various benchmarks, with up to 49.76%, 50.05%,
  44.69%, and 40.16% improvements on Split CIFAR-100, Split ImageNet-R, Split CUB-200,
  and Split Cars-196, respectively.
---

# SLCA: Slow Learner with Classifier Alignment for Continual Learning on a Pre-trained Model

## Quick Facts
- arXiv ID: 2303.05118
- Source URL: https://arxiv.org/abs/2303.05118
- Reference count: 40
- Key outcome: Up to 49.76%, 50.05%, 44.69%, and 40.16% improvements on Split CIFAR-100, Split ImageNet-R, Split CUB-200, and Split Cars-196 respectively

## Executive Summary
This paper addresses the progressive overfitting problem in continual learning on pre-trained models by proposing a slow learner approach that uses different learning rates for the representation and classification layers. The method significantly outperforms existing approaches by preserving the pre-trained knowledge while adapting to new tasks. It also introduces a classifier alignment technique that models class-wise feature distributions and aligns the classification layers post-hoc, further improving performance.

## Method Summary
The method consists of two main components: Slow Learner (SL) and Classifier Alignment (CA). The Slow Learner uses a small learning rate (0.0001) for the representation layer and a larger learning rate (0.01) for the classification layer to prevent progressive overfitting. After learning all tasks, the Classifier Alignment component models class-wise feature distributions as Gaussian distributions and performs post-hoc alignment of the classification layers. Logit normalization is applied during alignment to prevent overconfidence.

## Key Results
- Achieves up to 49.76% improvement on Split CIFAR-100 compared to state-of-the-art methods
- Shows 50.05% improvement on Split ImageNet-R
- Demonstrates 44.69% improvement on Split CUB-200
- Provides 40.16% improvement on Split Cars-196
- Maintains strong performance across different pre-training paradigms (supervised and self-supervised)

## Why This Works (Mechanism)

### Mechanism 1
Progressive overfitting occurs when the representation layer is updated too aggressively during sequential fine-tuning. The representation layer's parameters gradually drift away from their pre-trained state, losing generalizability for future tasks while overfitting to current incremental tasks. The pre-trained representation layer contains knowledge that needs to be preserved across incremental tasks.

### Mechanism 2
Classifier alignment through post-hoc modeling of class-wise distributions improves classification performance. After learning each task, the method collects feature representations for each class and models them as Gaussian distributions. During evaluation, generated features from these distributions are used to fine-tune the classifier, aligning it with the learned representations. Class-wise feature distributions remain relatively stable and can be modeled effectively.

### Mechanism 3
Logit normalization prevents overconfidence during classifier alignment. By normalizing the magnitude of network outputs during classifier alignment, the method prevents the classifier from becoming overconfident, which could impair generalizability. Overconfidence during classifier alignment can lead to poor generalization.

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: The paper addresses how to maintain performance on previously learned tasks while learning new ones
  - Quick check question: What happens to a neural network's performance on old tasks when it is trained on new data without any regularization?

- Concept: Pre-trained model fine-tuning strategies
  - Why needed here: The method builds on pre-trained models and explores different fine-tuning approaches
  - Quick check question: What are the key differences between fine-tuning all layers versus freezing some layers during transfer learning?

- Concept: Gaussian distribution modeling for feature representations
  - Why needed here: The classifier alignment strategy models class-wise feature distributions as Gaussians
  - Quick check question: What parameters define a multivariate Gaussian distribution, and how are they estimated from data?

## Architecture Onboarding

- Component map: Pre-trained backbone (ViT-B/16) -> Representation layer (θrps) with slow learning rate -> Classification layer (θcls) with fast learning rate -> Class-wise distribution modeling component -> Post-hoc classifier alignment module with logit normalization

- Critical path: 1. Pre-train representation layer on ImageNet-21K 2. Sequentially fine-tune with slow learner (different learning rates for representation and classification) 3. Collect class-wise feature distributions after each task 4. Perform post-hoc classifier alignment with logit normalization during evaluation

- Design tradeoffs: Learning rate separation (better preservation of pre-trained knowledge vs. potentially slower adaptation to new tasks), Post-hoc alignment (improved classifier performance vs. additional computational overhead during evaluation), Fixed representation layer in some baselines (simplicity vs. reduced adaptability)

- Failure signatures: Poor performance on new tasks (learning rate for representation layer may be too low), Catastrophic forgetting (classification layer may need more regularization), Overfitting to alignment data (logit normalization temperature may need adjustment)

- First 3 experiments: 1. Baseline sequential fine-tuning with uniform learning rate (0.005) on CIFAR-100 2. Slow learner implementation with learning rates 0.0001 (representation) and 0.01 (classification) on CIFAR-100 3. Full SLCA implementation with classifier alignment and logit normalization on CIFAR-100

## Open Questions the Paper Calls Out

### Open Question 1
How can we develop self-supervised pre-training paradigms that are more suitable for downstream continual learning? The paper identifies this as a promising direction but does not propose specific methods for achieving this goal. It remains unclear what architectural or training modifications would make self-supervised pre-training more amenable to continual learning.

### Open Question 2
How can we effectively combine upstream and downstream continual learning in a unified framework? Current approaches treat upstream pre-training and downstream continual learning as separate stages. The paper doesn't provide solutions for handling continual learning throughout both phases, which would be more realistic for real-world applications.

### Open Question 3
What is the optimal learning rate schedule for the representation layer in continual learning? While the paper shows that reducing the learning rate to 0.0001 for the representation layer is effective, it doesn't explore dynamic learning rate schedules or adaptive methods that could potentially perform even better.

## Limitations
- Classifier alignment mechanism is not fully specified, creating substantial reproducibility challenges
- Evaluation focuses primarily on image classification benchmarks, leaving open questions about generalizability to other domains
- Potential computational overhead introduced by the post-hoc alignment phase is not thoroughly addressed

## Confidence

**Confidence assessments:**
- High confidence: The slow learner mechanism (different learning rates for representation vs classification layers) and its effectiveness in preventing progressive overfitting
- Medium confidence: The classifier alignment strategy's specific implementation details and its contribution to performance gains
- Low confidence: The generalizability of results beyond image classification tasks and the practical applicability in real-world scenarios

## Next Checks

1. Implement and test the classifier alignment mechanism with the same hyperparameters to verify reported performance gains
2. Evaluate on additional task domains (e.g., NLP or robotics) to assess generalizability beyond image classification
3. Measure computational overhead of the post-hoc alignment phase and compare training/inference times with baseline approaches