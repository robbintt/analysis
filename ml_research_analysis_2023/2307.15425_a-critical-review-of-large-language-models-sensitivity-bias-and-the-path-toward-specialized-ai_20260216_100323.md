---
ver: rpa2
title: 'A Critical Review of Large Language Models: Sensitivity, Bias, and the Path
  Toward Specialized AI'
arxiv_id: '2307.15425'
source_url: https://arxiv.org/abs/2307.15425
tags:
- sdgs
- specialized
- description
- detection
- gpt-3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares OpenAI GPT-3.5 and a specialized SDG detection
  model on Finnish company descriptions. GPT-3.5 identified SDGs in 42.65% of companies
  (1.74 SDGs/company) vs.
---

# A Critical Review of Large Language Models: Sensitivity, Bias, and the Path Toward Specialized AI

## Quick Facts
- arXiv ID: 2307.15425
- Source URL: https://arxiv.org/abs/2307.15425
- Reference count: 4
- Key outcome: GPT-3.5 detected SDGs in 42.65% of Finnish companies vs 17.62% for specialized model; overlap only 10.46%

## Executive Summary
This study compares OpenAI GPT-3.5 and a specialized SDG detection model on Finnish company descriptions, revealing fundamental trade-offs between general-purpose language models and task-specific systems. GPT-3.5 demonstrated broader coverage (1.74 SDGs/company vs 1.12) but with potentially lower relevance, while the specialized model achieved higher precision through curated training data. The study highlights critical limitations of few-shot learning with LLMs, including token constraints and label adherence issues, while raising important questions about transparency, accountability, and the future development of hybrid AI systems.

## Method Summary
The research deployed GPT-3.5 via Google Sheets API to detect SDGs in 2,576 Finnish company descriptions, comparing results against a specialized model trained on SCOPUS data using TF-IDF/Word2Vec/Doc2Vec approaches. The specialized model employed lexical queries and taxonomy construction for precise classification, while GPT-3.5 used few-shot learning with 10 example abstracts (5 each for SDG2 and SDG7). Detection rates, average SDGs per company, and overlap metrics were calculated to assess performance differences, with additional experiments using GPT-3.5-generated descriptions to evaluate relevance impacts.

## Key Results
- GPT-3.5 detected SDGs in 42.65% of companies (1.74 SDGs/company) vs 17.62% (1.12 SDGs/company) for specialized model
- Overlap between models was only 10.46% for companies with detected SDGs
- GPT-3.5-generated descriptions increased detection to 48.27% with 2.89 SDGs/company but reduced relevance
- Few-shot learning with GPT-3.5 correctly identified only 34% of SDG labels despite high overall tagging rates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Specialized models achieve higher precision because their training is task-specific, reducing irrelevant detections
- Mechanism: By training on curated datasets with domain-specific features, the model learns to recognize only highly relevant indicators
- Core assumption: Task-specific training data better captures nuanced relationships between text and target concepts
- Evidence anchors: [abstract] "specialized training for precise, unbiased analysis is underlined"; [section] "Specialized language models...can significantly reduce the risk of introducing biases and inaccuracies"
- Break condition: If the specialized dataset is too narrow or biased, the model may miss valid cases or overfit to spurious patterns

### Mechanism 2
- Claim: Few-shot learning with LLMs is limited by token constraints and inability to enforce strict label adherence
- Mechanism: Token limits force small example sets that may not cover task diversity, and models may extrapolate beyond provided tags
- Core assumption: The model's training enables generalization but doesn't guarantee adherence to constrained label sets
- Evidence anchors: [section] "Due to the limited number of tokens GPT allows per API call...only two SDGs were chosen"; [section] "despite the tag list not including the other 15 SDGs, the model identified these SDGs"
- Break condition: If examples are too few or unrepresentative, the model may produce unreliable or overgeneralized outputs

### Mechanism 3
- Claim: General-purpose LLMs like GPT-3.5 cast wider net due to broad pretraining, capturing more cases but with lower specificity
- Mechanism: Exposure to diverse web data enables detection of SDG-related language even in tangentially related contexts
- Core assumption: General pretraining equips the model with broad pattern recognition but lacks task-specific filtering
- Evidence anchors: [abstract] "GPT-3.5 boasts broader coverage, it may identify SDGs with limited relevance"; [section] "On average, OpenAI GPT-3.5 identified 1.74 SDGs per description, while the specialized model detected 1.12 SDGs"
- Break condition: If specificity is critical, broader detection becomes a liability rather than an asset

## Foundational Learning

- Concept: Domain-specific feature engineering
  - Why needed here: The specialized SDG model relies on curated term lists and advanced taxonomies to identify relevant indicators
  - Quick check question: What types of features (lexical, semantic, contextual) would you prioritize when building a model for SDG detection?

- Concept: Token limit constraints in API-based inference
  - Why needed here: Few-shot learning is limited by the number of examples that can be passed due to token caps
  - Quick check question: How would you balance the number of examples and input length when constrained by token limits?

- Concept: Overlap metrics in classification tasks
  - Why needed here: The study uses non-restrictive intersection to measure agreement between models
  - Quick check question: What are the pros and cons of using non-restrictive vs. restrictive overlap metrics in multi-label classification?

## Architecture Onboarding

- Component map: Data ingestion → Preprocessing → Feature extraction (TF-IDF/Word2Vec/Doc2Vec) → Model training (SVM/Random Forest) → Prediction → Evaluation (precision, recall, overlap metrics)
- Critical path: Clean data → Build domain-specific features → Train model → Validate on held-out set → Deploy for inference
- Design tradeoffs: Specialized models are more precise but require curated datasets; general models are flexible but less focused and opaque
- Failure signatures: High false positive rates (overly broad detection), low recall (missing relevant cases), or unstable few-shot performance
- First 3 experiments:
  1. Compare detection rates and precision between GPT-3.5 and a specialized SDG model on a small curated dataset
  2. Test few-shot learning with GPT-3.5 using incrementally more examples to find the point of diminishing returns
  3. Evaluate overlap metrics across models to quantify agreement and divergence in SDG detection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the sensitivity and specificity trade-offs between specialized models and LLMs affect their performance in detecting specific types of textual content beyond SDGs, such as misinformation or bias?
- Basis in paper: [explicit] The paper discusses the broader applicability of findings to tasks demanding precision and accuracy
- Why unresolved: The study focuses on SDG detection and does not explore application to other content types or domains
- What evidence would resolve it: Comparative studies applying both specialized models and LLMs to various text classification tasks to measure sensitivity, specificity, and accuracy across different domains

### Open Question 2
- Question: What are the long-term implications of relying on LLMs for tasks requiring high transparency and accountability, especially in sectors where ethical considerations are paramount?
- Basis in paper: [explicit] The paper highlights the opacity of LLMs and suggests specialized models might be more reliable when transparency is critical
- Why unresolved: The paper does not explore broader ethical and accountability implications of using LLMs in sensitive sectors
- What evidence would resolve it: Case studies or longitudinal research on outcomes of using LLMs in high-stakes environments, focusing on transparency, accountability, and ethical decision-making

### Open Question 3
- Question: How can the development of hybrid models that combine the strengths of both LLMs and specialized models be optimized to balance coverage and precision in real-world applications?
- Basis in paper: [inferred] The paper suggests potential for hybrid models and encourages further research to balance capabilities
- Why unresolved: The paper does not provide specific methodologies or frameworks for developing such hybrid models
- What evidence would resolve it: Empirical studies testing hybrid models across various tasks, comparing performance to standalone LLMs and specialized models

## Limitations
- Limited transparency in specialized model's architecture and training data makes performance differences difficult to assess
- Narrow dataset focus (Finnish company descriptions) may not generalize to other domains or languages
- Few-shot learning experiment severely constrained by token limits (only 10 examples across two SDGs)
- Non-restrictive intersection metric may overstate agreement between models by counting any shared detections

## Confidence
- High Confidence: Claims about GPT-3.5's broader detection coverage (42.65% vs 17.62%) and higher average SDGs per company (1.74 vs 1.12)
- Medium Confidence: Mechanism explaining specialized models' higher precision through task-specific training
- Low Confidence: Claims about fundamental superiority of specialized models over LLMs for SDG detection

## Next Checks
1. Replicate comparison using diverse datasets from multiple domains to assess whether performance differences persist across contexts
2. Deconstruct the specialized model to identify which specific features contribute most to its precision advantage
3. Systematically vary the number and diversity of few-shot examples while measuring detection accuracy and label adherence