---
ver: rpa2
title: 'ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense
  Problem in Large Language Models'
arxiv_id: '2303.16421'
source_url: https://arxiv.org/abs/2303.16421
tags:
- knowledge
- commonsense
- chatgpt
- language
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the commonsense reasoning abilities of
  large language models (LLMs) like ChatGPT through a series of experiments across
  11 datasets covering diverse domains. The authors evaluate whether ChatGPT can answer
  commonsense questions, identify necessary knowledge, generate knowledge descriptions,
  and leverage knowledge for reasoning.
---

# ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models

## Quick Facts
- arXiv ID: 2303.16421
- Source URL: https://arxiv.org/abs/2303.16421
- Reference count: 19
- Key outcome: ChatGPT is knowledgeable but struggles to identify and leverage needed commonsense knowledge for specific questions, especially in social and temporal domains.

## Executive Summary
This paper investigates the commonsense reasoning abilities of large language models (LLMs) like ChatGPT through experiments across 11 diverse datasets. While ChatGPT achieves good QA accuracy overall, it struggles with social and temporal domains. The study finds that ChatGPT is knowledgeable and can generate most commonsense knowledge using knowledge prompts, but is an inexperienced problem solver that cannot precisely identify or effectively leverage needed knowledge for specific questions. These findings highlight the need for improved commonsense knowledge incorporation mechanisms in LLMs.

## Method Summary
The authors evaluate ChatGPT, GPT-3, and GPT-3.5 on 11 commonsense QA datasets spanning 8 domains. They use zero-shot and few-shot prompting to assess question answering accuracy, generate knowledge descriptions for a subset of questions, and manually evaluate the precision, recall, and F1 of generated knowledge. Correlation analysis is performed between knowledge quality and QA accuracy. The study also examines ChatGPT's ability to identify necessary knowledge and leverage it for reasoning by comparing performance with and without golden knowledge context.

## Key Results
- ChatGPT achieves good QA accuracy across most domains but struggles with social and temporal commonsense.
- ChatGPT can generate most commonsense knowledge using knowledge prompts, but descriptions are often noisy (26.25%) or overgeneralized (15.00%).
- ChatGPT cannot effectively leverage generated commonsense knowledge even when added to question context.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** ChatGPT possesses a substantial amount of memorized commonsense knowledge but struggles to identify the specific subset required for answering individual questions.
- **Mechanism:** The model encodes a broad corpus of general and domain-specific knowledge during pretraining. When queried, it attempts to retrieve relevant knowledge from this internal representation but lacks precise filtering to isolate the most pertinent facts.
- **Core assumption:** The knowledge exists in the model's latent space but retrieval is imprecise, leading to noise and overgeneralization.
- **Evidence anchors:**
  - [abstract] "ChatGPT is knowledgeable, and can accurately generate most of the commonsense knowledge using knowledge prompts."
  - [section 4] "ChatGPT is an inexperienced commonsense problem solver, which cannot precisely identify the needed commonsense knowledge for answering a specific question."
  - [corpus] Weak evidence; corpus neighbors focus on QA but not knowledge retrieval precision.
- **Break condition:** If retrieval mechanisms are too coarse or if knowledge is not well encoded for fine-grained filtering, the model will fail to isolate necessary knowledge.

### Mechanism 2
- **Claim:** Knowledge descriptions generated by ChatGPT are often noisy and overgeneralized, reducing their practical utility for downstream reasoning.
- **Mechanism:** During generation, the model prioritizes fluency and coverage over precision, resulting in verbose outputs that include irrelevant or overly broad statements.
- **Core assumption:** The generation process is optimized for surface coherence rather than task-specific relevance.
- **Evidence anchors:**
  - [abstract] "ChatGPT cannot precisely identify the needed commonsense for answering a specific question."
  - [section 5] "26.25% of the descriptions include irrelevant and misleading information, and 15.00% of the descriptions are overgeneralized."
  - [corpus] Weak evidence; corpus neighbors do not discuss knowledge description quality.
- **Break condition:** If the model is not guided to focus on task-relevant details, descriptions will remain too general to be actionable.

### Mechanism 3
- **Claim:** Even with access to accurate knowledge, ChatGPT's reasoning capabilities are insufficient for complex commonsense inference tasks.
- **Mechanism:** The model lacks explicit reasoning modules and relies on pattern matching and shallow inference, which fails on tasks requiring multi-step logic or negation handling.
- **Core assumption:** Reasoning is not explicitly modeled but emerges from distributed representations.
- **Evidence anchors:**
  - [abstract] "ChatGPT is an inexperienced commonsense problem solver, which cannot precisely identify the needed commonsense knowledge for solving a specific question."
  - [section 6] "ChatGPT cannot effectively leverage the generated commonsense knowledge if we only add them to the question context."
  - [corpus] Weak evidence; corpus neighbors focus on knowledge injection but not reasoning limitations.
- **Break condition:** If reasoning tasks require explicit symbolic manipulation or complex inference chains, the model's distributed representation approach will fail.

## Foundational Learning

- **Concept: Knowledge retrieval and filtering**
  - Why needed here: To understand why ChatGPT generates noisy or overgeneralized knowledge descriptions.
  - Quick check question: How does the model determine which knowledge facts are relevant to a given query?

- **Concept: Commonsense knowledge categories**
  - Why needed here: To map the model's performance across domains (physical, social, temporal, etc.) and identify weaknesses.
  - Quick check question: What distinguishes social commonsense from physical commonsense in terms of representation and retrieval?

- **Concept: Zero-shot and few-shot prompting**
  - Why needed here: To design prompts that elicit accurate knowledge descriptions and guide reasoning.
  - Quick check question: How does prompt structure affect the precision of knowledge generation?

## Architecture Onboarding

- **Component map:** Pretraining corpus -> Knowledge encoding -> Prompt processing -> Knowledge generation -> Reasoning attempt -> Answer output
- **Critical path:** Input question -> Prompt formulation -> Internal knowledge retrieval -> Knowledge description generation -> Contextual integration -> Final answer
- **Design tradeoffs:** Broad knowledge coverage vs. retrieval precision; generation fluency vs. description specificity; implicit reasoning vs. explicit symbolic modules
- **Failure signatures:** High knowledge F1 but low answer accuracy; noisy knowledge descriptions; inability to leverage provided knowledge
- **First 3 experiments:**
  1. Evaluate knowledge retrieval precision by asking the model to list necessary knowledge for a question and measuring overlap with human annotations.
  2. Test the effect of structured prompts (e.g., "List only the knowledge facts directly needed to answer this question") on description specificity.
  3. Compare reasoning performance with and without golden knowledge context to quantify the gap between knowledge possession and effective use.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the specific mechanisms by which ChatGPT can better identify necessary commonsense knowledge for answering a question?
- Basis in paper: [explicit] The paper states that ChatGPT struggles to precisely identify the needed commonsense knowledge for answering a specific question.
- Why unresolved: The paper does not provide specific mechanisms for improving ChatGPT's ability to identify necessary knowledge.
- What evidence would resolve it: Research and development of new methods or techniques that enable ChatGPT to better identify and leverage necessary commonsense knowledge for specific questions.

### Open Question 2
- Question: How can ChatGPT be improved to effectively leverage commonsense knowledge in context for reasoning and answering questions?
- Basis in paper: [explicit] The paper states that ChatGPT cannot effectively leverage the generated commonsense knowledge if we only add them to the question context.
- Why unresolved: The paper does not provide specific methods for improving ChatGPT's ability to leverage commonsense knowledge in context.
- What evidence would resolve it: Research and development of new methods or techniques that enable ChatGPT to better utilize and reason with commonsense knowledge in context.

### Open Question 3
- Question: What are the best strategies for injecting missing commonsense knowledge types, such as social and temporal commonsense, into ChatGPT?
- Basis in paper: [explicit] The paper states that ChatGPT still struggles with certain types of knowledge, including social and temporal commonsense.
- Why unresolved: The paper does not provide specific strategies for injecting missing commonsense knowledge types into ChatGPT.
- What evidence would resolve it: Research and development of new methods or techniques for injecting missing commonsense knowledge types into ChatGPT, particularly social and temporal commonsense.

## Limitations

- Manual evaluation of generated knowledge descriptions lacks specified criteria and inter-annotator agreement, raising reliability concerns.
- Exact prompt templates for each dataset are not fully detailed, hindering reproducibility and assessment of prompt impact.
- Evaluation focuses on a subset of questions without statistical significance or confidence intervals, limiting generalizability.
- Reasoning limitations are assessed qualitatively rather than through controlled experiments isolating reasoning from knowledge retrieval.

## Confidence

- **ChatGPT is knowledgeable but struggles with domain-specific knowledge identification**: Medium confidence. Supported by high knowledge F1 scores but low accuracy on social/temporal domains, though manual evaluation reliability is uncertain.
- **Generated knowledge descriptions are often noisy or overgeneralized**: Medium confidence. Backed by quantitative F1 analysis, but manual annotation criteria are unclear.
- **ChatGPT cannot effectively leverage provided knowledge for reasoning**: Low confidence. Based on qualitative observation rather than controlled reasoning task experiments.

## Next Checks

1. **Reproduce knowledge generation and evaluation**: Use the same datasets and sample questions to generate knowledge descriptions with ChatGPT, then apply standardized annotation guidelines to measure precision/recall/F1 and inter-annotator agreement.

2. **Controlled reasoning experiment**: For a set of questions, provide ChatGPT with both noisy and cleaned knowledge contexts (via human or model filtering), then compare answer accuracy to isolate the effect of knowledge quality on reasoning performance.

3. **Prompt ablation study**: Systematically vary prompt specificity (e.g., "List only the knowledge needed to answer this question" vs. open-ended) and measure the impact on knowledge precision and downstream QA accuracy to quantify the role of instruction following.