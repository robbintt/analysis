---
ver: rpa2
title: Alien Coding
arxiv_id: '2301.11479'
source_url: https://arxiv.org/abs/2301.11479
tags:
- oeis
- https
- programs
- loop
- sequence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a self-learning algorithm that synthesizes
  programs for integer sequences from the OEIS. It starts with random program generation
  and iteratively improves by training a neural machine translation model to map sequences
  to programs, then using this model to propose new candidate programs.
---

# Alien Coding

## Quick Facts
- arXiv ID: 2301.11479
- Source URL: https://arxiv.org/abs/2301.11479
- Reference count: 40
- One-line primary result: Self-learning algorithm discovers programs for 78,000+ OEIS sequences through iterative NMT training and beam search

## Executive Summary
This paper presents a self-learning algorithm that synthesizes programs for integer sequences from the OEIS. Starting from random program generation, the system iteratively trains a neural machine translation model to map sequences to programs, then uses this model to propose new candidate programs. Through 190 iterations of this self-learning loop, the algorithm discovers solutions for more than 78,000 OEIS sequences, significantly outperforming prior work. The system demonstrates the ability to evolve programs over time, achieving both size and speed optimizations, and invents novel programming techniques such as triangle coding for packing variable pairs.

## Method Summary
The algorithm uses a self-learning loop that alternates between three phases: (1) NMT training on sequence-program pairs discovered so far, (2) beam search inference to generate candidate programs for all OEIS sequences, and (3) program checking to validate and select the best solutions. The system employs a hybrid checking approach that first uses fast timeouts for all programs, then selectively checks promising candidates with longer timeouts. Multiple NMT models trained with different strategies are used in parallel to create a complementary portfolio. The programming language includes basic operators plus local and global macros, with Turing completeness achieved through the comprehension operator.

## Key Results
- Discovers programs for 78,118 OEIS sequences through 190 iterations
- Achieves both size and speed optimizations, with average program size reduction of 16.5% over 100 iterations
- Invents novel programming techniques like triangle coding for variable pair packing
- Demonstrates good generalization to larger indices beyond b-file data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The self-learning loop generates increasingly sophisticated programs by iteratively training an NMT model on newly discovered solutions and using it to propose new candidates.
- Mechanism: The system starts with random program generation, then enters a loop where it trains NMT on sequences-to-programs pairs, uses beam search to generate many candidate programs for each OEIS sequence, checks these candidates, and keeps the smallest/fastest ones for the next training iteration.
- Core assumption: NMT can effectively learn the mapping between integer sequences and their generating programs, and beam search can explore the space of possible programs effectively.
- Evidence anchors: The iterative improvement pattern is documented in section 5.1, showing increasing solution counts over iterations.

### Mechanism 2
- Claim: The hybrid checking approach efficiently validates program candidates by first using fast timeouts and then selectively checking promising candidates with longer timeouts.
- Mechanism: The checker uses a two-phase approach: first runs all programs with fast parameters, then identifies programs that generated partial sequences but didn't complete, and only checks the smallest such programs with slower parameters.
- Core assumption: Fast programs tend to generate longer prefixes, so selecting by smallest prefix length identifies the most promising candidates for extended checking.
- Evidence anchors: Section 2.5 describes the hybrid check methodology and its efficiency benefits.

### Mechanism 3
- Claim: The combination of multiple NMT models trained differently creates a complementary portfolio that outperforms single models.
- Mechanism: The system trains multiple models with different strategies (from scratch vs. continuous training, different data subsets) and uses them in parallel during inference.
- Core assumption: Different training strategies capture different aspects of the sequence-to-program mapping, and combining them provides better coverage.
- Evidence anchors: Section 5.2 shows that using multiple models increases unique candidates from 32.5M to 101.7M and adds more solutions.

## Foundational Learning

- Concept: Primitive recursive functions and Turing completeness
  - Why needed here: The programming language used must be expressive enough to represent all integer sequences while remaining computationally tractable.
  - Quick check question: Why does the comprehension operator make the language Turing-complete while the basic operators only provide primitive recursive functions?

- Concept: Neural machine translation with attention mechanisms
  - Why needed here: The core learning component is an NMT system that translates integer sequences into programs.
  - Quick check question: How does the "scaled Luong" attention mechanism help the NMT system focus on relevant parts of the input sequence when generating program tokens?

- Concept: Beam search and its width parameter
  - Why needed here: The system uses wide beam search (width 240) during inference to generate multiple candidate programs.
  - Quick check question: What happens to the quality and diversity of generated programs as you increase beam width from 10 to 240 to 1000?

## Architecture Onboarding

- Component map: OEIS dataset loader -> NMT training/inference pipeline -> program checker (hybrid mode) -> self-learning loop coordinator -> solution repository
- Critical path: NMT inference → program checking → solution selection
- Design tradeoffs: The system trades off between expressiveness and tractability in the programming language, between model size and inference speed in NMT, and between checking thoroughness and computational cost in the hybrid checker.
- Failure signatures: Common failures include NMT generating syntactically invalid programs, programs timing out during checking, programs generating wrong sequences, and the system plateauing when no new solutions are found.
- First 3 experiments:
  1. Run the system with only the basic language (no local/global macros) for 10 iterations and measure the number of solutions found vs. baseline.
  2. Compare single NMT model vs. portfolio approach by running two parallel experiments for 20 iterations each, measuring solution count and unique candidates.
  3. Test different beam search widths (50, 240, 500) by running three parallel inference jobs on the same training data, measuring the tradeoff between solution quality and GPU memory usage.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the use of local and global macros affect the efficiency and quality of the synthesized programs compared to not using them?
- Basis in paper: The paper mentions that humans benefit from introducing new names, concepts, and shortcuts, but it is unclear if it results in a clear improvement in the current alien setting.
- Why unresolved: The experiments with local and global macros are inconclusive, with each run adding less than 2800 solutions to nmt 1.
- What evidence would resolve it: A more comprehensive analysis comparing the performance of the system with and without the use of local and global macros.

### Open Question 2
- Question: What is the long-term behavior of the system as it continues to iterate and discover new solutions? Will it eventually plateau, or will it continue to find new and increasingly complex solutions?
- Basis in paper: The paper mentions that the average size and time of the solutions increase as new solutions are found, but there are exceptions where more efficient code is invented and propagated by the system.
- Why unresolved: The paper does not provide a definitive answer on the long-term behavior of the system.
- What evidence would resolve it: Running the system for a significantly longer period, potentially thousands of iterations, and analyzing the trends in the size, speed, and complexity of the solutions found.

### Open Question 3
- Question: How well do the solutions generalize to larger indices beyond those provided in the b-files of the OEIS?
- Basis in paper: The paper mentions that among the 78118 solutions, 40,577 of them have a b-file that contains 100 additional terms for their OEIS entry.
- Why unresolved: While the paper provides some data on the generalization of the solutions, it is unclear how well the solutions would perform on even larger indices or on indices not included in the b-files.
- What evidence would resolve it: Testing the solutions on a wider range of indices, including those not included in the b-files, and analyzing the performance and accuracy of the solutions.

## Limitations

- Reproducibility challenges due to unknown hardware configuration and complete source code availability
- Potential bias from using OEIS dataset, which contains already-studied and formalized sequences
- Uncertain scalability as the number of solved sequences grows, potentially leading to diminishing returns
- Claims of "alien coding" novelty require more rigorous mathematical analysis to verify true originality

## Confidence

**High Confidence (3/5):** The core mechanism of iterative self-learning with NMT training and beam search inference is well-supported by experimental results showing consistent improvement over 190 iterations.

**Medium Confidence (2/5):** The claim that the system discovers "novel programming techniques" is plausible but requires more rigorous mathematical analysis to confirm true novelty versus rediscovery of known methods.

**Low Confidence (1/5):** The assertion that the system achieves synthesis "without human bias" is difficult to verify and potentially overstated, given that the programming language and OEIS dataset were both created by humans.

## Next Checks

1. **Replicate the Core Loop:** Implement the basic self-learning loop (NMT training → beam search inference → program checking) using a simplified programming language and a subset of OEIS sequences (e.g., first 10,000). Run for 20 iterations and verify the pattern of increasing solution counts.

2. **Analyze Solution Novelty:** Take 100 randomly selected solved sequences from the final iteration and manually verify whether the discovered programs use genuinely novel techniques versus standard mathematical patterns. Compare these solutions against known OEIS programs and mathematical literature.

3. **Test Scaling Properties:** Run the system with varying beam search widths (50, 240, 500) on the same training data to quantify the tradeoff between solution quality and computational cost. Measure the marginal improvement in solutions per additional candidate generated.