---
ver: rpa2
title: Aspect category learning and sentimental analysis using weakly supervised learning
arxiv_id: '2312.15526'
source_url: https://arxiv.org/abs/2312.15526
tags:
- sentiment
- aspect
- review
- reviews
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of automatically labeling and
  analyzing vast amounts of e-commerce reviews to understand underlying aspects and
  sentiments. It proposes using weakly supervised learning, specifically the Snorkel
  framework, to generate labels for aspects and sentiments based on aspect terms,
  review sentiment scores, and ratings as weak signals.
---

# Aspect category learning and sentimental analysis using weakly supervised learning

## Quick Facts
- arXiv ID: 2312.15526
- Source URL: https://arxiv.org/abs/2312.15526
- Reference count: 35
- The CNN-BiLSTM hybrid model achieved 0.78 and 0.79 F1 scores on aspect and sentiment identification respectively

## Executive Summary
This paper addresses the challenge of automatically labeling and analyzing vast amounts of e-commerce reviews to understand underlying aspects and sentiments. It proposes using weakly supervised learning, specifically the Snorkel framework, to generate labels for aspects and sentiments based on aspect terms, review sentiment scores, and ratings as weak signals. Three hybrid models (BiLSTM, CNN-BiLSTM, and CNN-LSTM) are developed that leverage multiple inputs (review text, aspect terms, ratings) to learn aspect labels (Quality, Usability, Service, Size, Price) and sentiment labels (Positive, Negative, Mixed). The CNN-BiLSTM model achieved the best performance with 0.78 and 0.79 F1 scores on aspect and sentiment identification respectively, demonstrating the effectiveness of this approach for automating review analysis at scale.

## Method Summary
The method applies Snorkel's weak supervision framework to generate labels for aspect categories and sentiment using multiple weak signals: aspect terms, VADER sentiment scores, and numerical ratings. These probabilistic labels are then used to train hybrid deep learning models that combine CNN and LSTM architectures. The CNN layers extract local n-gram features while BiLSTM layers capture sequential dependencies in review text. Three variants are tested: BiLSTM, CNN-BiLSTM, and CNN-LSTM. The models are trained using Binary Cross Entropy with Sigmoid for multi-label aspect classification and Categorical Cross Entropy with Softmax for sentiment classification, evaluated using Macro F1 score, precision, recall, and Hamming loss.

## Key Results
- CNN-BiLSTM model achieved the best performance with 0.78 F1 score for aspect category identification and 0.79 F1 score for sentiment identification
- Multi-signal weak supervision (aspect terms, sentiment scores, ratings) generated sufficient labeled data to train deep learning models
- Hybrid CNN-BiLSTM architecture outperformed both pure BiLSTM and CNN-LSTM variants

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weak supervision reduces manual labeling burden by using labeling functions (LFs) that generate probabilistic labels from noisy signals.
- Mechanism: Snorkel's generative model learns the accuracy of each LF by analyzing their correlations and conflicts, then denoises the labels before passing them to a discriminative model.
- Core assumption: Labeling functions based on aspect terms and sentiment lexicons are sufficiently correlated with true labels to be useful weak signals.
- Evidence anchors:
  - [abstract] "Snorkel framework of WSL, which incorporates aspect terms, review sentiment scores, and review ratings as sources of weak signals."
  - [section 3.4] "Label functions are leveraged to categorize sentiments and aspect categories of reviews, using ratings and sentiment terms as weak signals for sentiment classification."
  - [corpus] Weak evidence: corpus shows many related papers but none specifically validating Snorkel's denoising in this context.

### Mechanism 2
- Claim: Hybrid CNN-BiLSTM architecture captures both local keyword patterns and sequential dependencies, improving aspect and sentiment classification.
- Mechanism: CNN layers extract n-gram features (local patterns) from review text, which are then fed into BiLSTM layers to model long-range dependencies; this combination outperforms single architectures.
- Core assumption: Reviews contain both keyword-level cues (e.g., "cheap", "broke") and context-dependent sentiment that requires sequential modeling.
- Evidence anchors:
  - [abstract] "CNN-BiLSTM model achieved the best performance with 0.78 and 0.79 F1 scores on aspect and sentiment identification respectively."
  - [section 3.5] "CNN-BiLSTM hybrid model... LSTM's output... serves as input for CNN to identify local features."
  - [corpus] Weak evidence: related papers use hybrid models but none report Snorkel + CNN-BiLSTM specifically.

### Mechanism 3
- Claim: Using multiple weak signals (aspect terms, sentiment scores, ratings) improves label coverage and robustness compared to single-signal approaches.
- Mechanism: Each signal provides independent evidence; Snorkel combines them, increasing the fraction of reviews with labels and reducing bias from any single noisy source.
- Core assumption: Aspect terms, sentiment Vader scores, and numerical ratings capture orthogonal aspects of review content.
- Evidence anchors:
  - [abstract] "incorporates aspect terms, review sentiment scores, and review ratings as sources of weak signals."
  - [section 3.4] "For sentiment labeling, positive, negative, or mixed labels are assigned based on the polarity score of sentiment terms and ratings."
  - [corpus] Weak evidence: related work uses single weak signals; no comparative study with multi-signal Snorkel.

## Foundational Learning

- Concept: Weak supervision and Snorkel
  - Why needed here: Manual labeling of millions of reviews is infeasible; Snorkel enables scalable labeling using programmatic heuristics.
  - Quick check question: What does Snorkel's generative model output before the discriminative model sees it?
    - Answer: Probabilistic labels for each data point.

- Concept: Multi-label vs multi-class classification
  - Why needed here: Aspect categories are multi-label (a review can mention multiple aspects), while sentiment is multi-class (exactly one sentiment per review).
  - Quick check question: Which activation function is used for multi-label aspect prediction?
    - Answer: Sigmoid.

- Concept: CNN + LSTM hybrid architectures
  - Why needed here: CNN captures local n-gram patterns; LSTM captures sequential context; together they improve performance on variable-length review text.
  - Quick check question: In the CNN-BiLSTM model, which layer processes the CNN output?
    - Answer: BiLSTM.

## Architecture Onboarding

- Component map: Review text → Tokenizer → Embedding (GloVe) → CNN layers → BiLSTM layers → Dense layers → Aspect sigmoid outputs + Sentiment softmax outputs
- Critical path: Data preprocessing → Snorkel labeling → Train hybrid model → Evaluate with Macro F1
- Design tradeoffs: More labeling functions increase coverage but also conflicts; deeper hybrid models may overfit on noisy labels
- Failure signatures: Low Macro F1 with high Hamming loss suggests noisy weak labels; low precision with high recall suggests overfitting to frequent classes
- First 3 experiments:
  1. Run Snorkel with only aspect-term LFs; inspect coverage and conflicts
  2. Train BiLSTM baseline on noisy labels; measure Macro F1
  3. Add CNN front-end to BiLSTM; compare performance to baseline

## Open Questions the Paper Calls Out

1. How would the performance of the proposed hybrid models change if the test data size were increased by manually labeling more reviews?
   - Basis: The paper states "Increasing the test data size by manually labeling the data will amplify the robustness of the results."
   - Why unresolved: Only 500 reviews were manually labeled for testing; larger test set could improve result robustness.
   - Evidence needed: Retesting with 5000+ manually labeled reviews and comparing performance metrics.

2. Would associating sentiment with corresponding aspects improve the model's performance compared to handling them separately?
   - Basis: The paper states "One main limitation of this approach is that the sentiment is not assigned to relevant aspects. Aspects and sentiments are dealt with separately."
   - Why unresolved: Current model treats aspect category learning and sentiment classification as separate tasks.
   - Evidence needed: Developing and testing a model that jointly learns aspect categories and aspect-specific sentiments.

3. How would the model perform on e-commerce reviews from different domains (e.g., books, movies) that were excluded in this study?
   - Basis: The study filtered to include only product-related reviews, excluding other domains.
   - Why unresolved: The approach's generalizability to excluded domains is unknown.
   - Evidence needed: Applying the methodology to reviews from excluded domains and comparing performance metrics.

## Limitations

- The effectiveness of Snorkel's generative model depends heavily on the quality and completeness of aspect term dictionaries and sentiment lexicons
- The hybrid CNN-BiLSTM architecture requires substantial hyperparameter tuning not fully specified in the paper
- Evaluation focuses on macro-averaged metrics which may mask poor performance on minority aspect categories or sentiment classes

## Confidence

- **High Confidence**: The claim that weakly supervised learning reduces manual labeling burden is well-supported by Snorkel's established framework and empirical results
- **Medium Confidence**: The assertion that CNN-BiLSTM hybrid model outperforms other architectures is supported by reported F1 scores but lacks comparative ablation studies
- **Low Confidence**: The claim that multiple weak signals significantly improve label coverage lacks direct comparative evidence against single-signal approaches

## Next Checks

1. Perform detailed error analysis on Snorkel-generated labels by manually inspecting a stratified sample of reviews across different coverage/conflict categories to quantify label quality and identify systematic biases.

2. Systematically remove CNN or LSTM components from the best-performing model and retrain to measure individual contribution of each architecture to reported F1 scores.

3. Conduct controlled experiments training models with only one weak signal at a time versus the multi-signal approach to quantify marginal benefit and identify which signals contribute most to label quality.