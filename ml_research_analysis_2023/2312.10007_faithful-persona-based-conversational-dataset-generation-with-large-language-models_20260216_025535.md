---
ver: rpa2
title: Faithful Persona-based Conversational Dataset Generation with Large Language
  Models
arxiv_id: '2312.10007'
source_url: https://arxiv.org/abs/2312.10007
tags:
- user
- persona
- conversation
- conversations
- attributes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a novel framework for generating large-scale,
  high-quality persona-based conversational datasets using Large Language Models (LLMs).
  The framework consists of three main components: user generation, user pairing,
  and conversation generation.'
---

# Faithful Persona-based Conversational Dataset Generation with Large Language Models

## Quick Facts
- arXiv ID: 2312.10007
- Source URL: https://arxiv.org/abs/2312.10007
- Reference count: 32
- Primary result: Proposes a framework generating 5k personas and 20k faithful dialogues via iterative Generator-Critic architecture

## Executive Summary
This paper introduces a novel framework for generating large-scale, high-quality persona-based conversational datasets using Large Language Models (LLMs). The approach employs a three-stage pipeline: user generation that expands seed personas into diverse profiles, user pairing based on semantic similarity, and conversation generation using a Generator-Critic architecture. The framework iteratively refines conversations by having expert LLMs evaluate generated content against policies including faithfulness, toxicity, and general quality. The resulting Synthetic-Persona-Chat dataset demonstrates superior performance compared to Persona-Chat in faithfulness, diversity, and next utterance prediction tasks.

## Method Summary
The framework consists of three main components: User Generation, User Pairing, and Conversation Generation. User Generation expands seed personas through query induction and bootstrapping, ensuring persona consistency via NLI checks. User Pairing matches profiles based on semantic similarity measured by shared persona categories. Conversation Generation employs a Generator-Critic architecture where an LLM generates candidate conversations iteratively, while a mixture of expert LLMs evaluate them against multiple policies. The best candidates are selected and added to the dataset, gradually improving quality through iterative refinement.

## Key Results
- Synthetic-Persona-Chat outperforms Persona-Chat in faithfulness, diversity, and next utterance prediction
- Turing test losing rate decreased from 17.2% to 8.8% over three iterations
- Framework produces 5k personas and 20k faithful dialogues
- Flexible architecture adaptable to different domains by modifying seed personas and critic policies

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Persona expansion via query induction bootstraps new attributes while maintaining semantic consistency
- **Mechanism**: Clusters seed persona attributes, generates queries for each cluster, then uses these queries as prompts to generate new attributes iteratively
- **Core assumption**: Two persona attributes in the same semantic category can be generated from the same query prompt
- **Evidence anchors**: Abstract mentions bootstrapping seed attributes; section describes query induction relying on semantic category assumption
- **Break condition**: Overly generic queries if clustering threshold is too high; overfitting to narrow attributes if too low

### Mechanism 2
- **Claim**: Generator-Critic architecture improves conversational quality iteratively by selective reinforcement
- **Mechanism**: Generator creates candidate conversations; Critic (mixture of experts) evaluates against policies; top candidates added to dataset for next iteration
- **Core assumption**: Iterative selection of high-quality samples will gradually improve Generator's output distribution
- **Evidence anchors**: Abstract describes Generator-Critic architecture; section outlines iterative dataset creation process
- **Break condition**: Generator may collapse to narrow conversation styles if Critic's policy set is too restrictive

### Mechanism 3
- **Claim**: User pairing based on semantic similarity improves conversation coherence
- **Mechanism**: Encodes user profiles with BERT; computes similarity as number of shared persona categories; pairs with similarity ≥ 2
- **Core assumption**: Conversations are more engaging when users share at least two persona categories
- **Evidence anchors**: Section quantifies semantic similarity by common persona categories; abstract mentions semantic similarity matching
- **Break condition**: Less coherent conversations if threshold is too low; dataset size shrinks excessively if too high

## Foundational Learning

- **Concept**: BERT-based persona attribute clustering
  - Why needed here: Clustering identifies semantic persona categories, enabling query induction for attribute expansion
  - Quick check question: How does cosine similarity between BERT embeddings determine cluster membership in this pipeline?

- **Concept**: Natural Language Inference (NLI) for persona consistency
  - Why needed here: Ensures user profiles do not contain contradictory attributes, preserving persona integrity
  - Quick check question: What inference check guarantees that a new persona attribute does not contradict any existing one in the user profile?

- **Concept**: Mixture of Experts (MoE) in critic evaluation
  - Why needed here: Allows modular policy enforcement (faithfulness, toxicity, quality) without a monolithic scoring model
  - Quick check question: How does majority voting among General Conversation Quality experts select the best candidate conversation?

## Architecture Onboarding

- **Component map**: User Generation → User Pairing → Conversation Generation
- **Critical path**: Persona expansion → user profile consistency check → semantic pairing → iterative Generator-Critic loop
- **Design tradeoffs**: Larger persona sets improve diversity but increase clustering and pairing cost; stricter faithfulness policies reduce toxic content but may limit conversation creativity
- **Failure signatures**: Persona expansion stalls (plateaus in persona set size); pairing similarity threshold too high (too few pairs for generation); overly strict Critic (Generator fails to produce candidates)
- **First 3 experiments**:
  1. Verify persona expansion increases attribute count by >100% while maintaining cluster coherence
  2. Test user pairing produces >80% of pairs with at least two shared categories
  3. Confirm one iteration of Generator-Critic yields higher FED scores than baseline generation

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the iterative process of conversation generation improve the quality of the dataset over time?
- **Basis in paper**: [explicit] The paper mentions that the Generator-Critic architecture is used to iteratively improve the quality of generated samples
- **Why unresolved**: While the paper mentions the iterative process, it does not provide detailed analysis or specific metrics showing how the quality improves with each iteration
- **What evidence would resolve it**: Detailed analysis or metrics showing the improvement in conversation quality with each iteration, such as changes in faithfulness, diversity, or human evaluation scores

### Open Question 2
- **Question**: What is the impact of the persona expansion module on the diversity and quality of the generated personas?
- **Basis in paper**: [explicit] The paper describes the persona expansion module and its role in creating diverse and consistent user profiles
- **Why unresolved**: The paper does not provide a detailed analysis of how the persona expansion module affects the diversity and quality of the generated personas
- **What evidence would resolve it**: Analysis or metrics showing the impact of the persona expansion module on the diversity and quality of the generated personas, such as the number of unique persona attributes or the similarity between generated personas

### Open Question 3
- **Question**: How does the size of the LLM used in the Generator affect the quality of the generated conversations?
- **Basis in paper**: [explicit] The paper mentions that a larger LLM (LLM2) was used to generate a variant of SPC and compares its performance to a smaller LLM
- **Why unresolved**: While the paper mentions the use of a larger LLM, it does not provide a detailed analysis of how the size of the LLM affects the quality of the generated conversations
- **What evidence would resolve it**: Analysis or metrics showing the impact of the size of the LLM on the quality of the generated conversations, such as changes in faithfulness, diversity, or human evaluation scores

## Limitations
- Framework's performance heavily depends on quality of seed personas and effectiveness of iterative refinement process
- Convergence properties of Generator-Critic architecture remain unclear - uncertain whether additional iterations continue improving quality
- Computational cost of iterative generation with multiple expert evaluations is not quantified, making scalability difficult to assess

## Confidence

- **High confidence**: Core architecture design (Generator-Critic with iterative refinement) and three-stage pipeline are clearly specified and methodologically sound
- **Medium confidence**: Reported improvements over Persona-Chat in faithfulness, diversity, and next utterance prediction are well-supported by experiments
- **Low confidence**: Semantic clustering approach for persona expansion and specific threshold choices lack sufficient empirical justification or sensitivity analysis

## Next Checks

1. **Convergence Analysis**: Run iterative generation process for 5+ iterations and plot quality metrics (FED scores, human evaluation scores) to determine if improvements plateau or continue

2. **Ablation Study**: Systematically remove each component (persona expansion, user pairing, each critic expert) and measure impact on final conversation quality

3. **Threshold Sensitivity**: Test user pairing with similarity thresholds of 1, 2, 3, and 4 to determine optimal balance between conversation coherence and dataset size