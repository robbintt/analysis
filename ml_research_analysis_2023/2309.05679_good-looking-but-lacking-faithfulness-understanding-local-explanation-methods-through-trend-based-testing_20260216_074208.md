---
ver: rpa2
title: 'Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods
  through Trend-based Testing'
arxiv_id: '2309.05679'
source_url: https://arxiv.org/abs/2309.05679
tags:
- explanation
- methods
- tests
- data
- backdoor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of evaluating the faithfulness
  of local explanation methods for deep learning models. The authors identify the
  "random dominance" problem in traditional faithfulness tests, where random selection
  of features can outperform explanation methods.
---

# Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing

## Quick Facts
- arXiv ID: 2309.05679
- Source URL: https://arxiv.org/abs/2309.05679
- Reference count: 40
- Key outcome: Introduces trend-based faithfulness tests to overcome random dominance in explanation evaluation, showing IG and SG-SQ-IG are most faithful across datasets.

## Executive Summary
This paper addresses the problem of evaluating the faithfulness of local explanation methods for deep learning models. Traditional faithfulness tests suffer from the "random dominance" problem, where random feature selection can outperform explanation methods. To overcome this, the authors propose three trend-based faithfulness tests—Evolving-Model-with-Backdoor Test (EMBT), Partial-Trigger Test (PTT), and Evolving-Model Test (EMT)—that measure the correlation between explanation results and known model behavior trends. These tests use in-distribution data and avoid the pitfalls of out-of-distribution perturbations. The authors evaluate ten popular explanation methods on image, natural language, and security tasks, demonstrating that their trend tests provide more accurate assessments than traditional tests. They find that data complexity has a greater impact on faithfulness than model complexity, and that IG and SG-SQ-IG consistently perform well.

## Method Summary
The authors propose three trend-based faithfulness tests to evaluate local explanation methods: EMBT, PTT, and EMT. These tests avoid the random dominance problem by evolving either the model or the sample in a controlled, in-distribution manner, and then measuring the Pearson correlation coefficient (PCC) between explanation trends and known model trends. EMBT injects a backdoor into a pre-trained model and records intermediate models during incremental training, PTT uses backdoor triggers to gradually transform samples, and EMT evaluates model behavior under varying loss conditions. The tests are applied to ten explanation methods across diverse datasets (MNIST, CIFAR-10, Tiny ImageNet, IMDB, Mimicus, DAMD, VulDeePecker, MSCOCO 2017), with faithfulness assessed via PCC between explanation importance and model trends.

## Key Results
- Trend-based tests avoid random dominance by keeping test samples in-distribution during model evolution.
- IG and SG-SQ-IG consistently show high faithfulness across different data complexities.
- Data complexity has a greater impact on faithfulness than model complexity.
- The trend tests effectively guide model debugging and detect spurious correlations in DL models.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Trend-based faithfulness tests avoid the random dominance problem by ensuring test samples remain in-distribution during model evolution.
- **Mechanism:** Instead of randomly perturbing features, the tests evolve either the model (EMBT, EMT) or the sample (PTT) in a controlled way, keeping both aligned with the original data distribution. Faithfulness is then assessed by correlating explanation trends with known trends in model behavior or input transformations.
- **Core assumption:** The evolved models or samples still operate within the learned data distribution and reflect meaningful shifts in model decision boundaries.
- **Evidence anchors:**
  - [abstract] "Instead of destructing important features, we gradually evolve either a model or a sample, and form a series of test pairs ⟨model,sample⟩."
  - [section 3.2] "EMBT adds a backdoor to the pre-trained model through incremental training... EMBT records the intermediate model in every c epochs during training."
  - [corpus] Weak: neighbor papers focus on faithfulness evaluation but do not describe in-distribution evolution; the approach here is unique.
- **Break condition:** If evolution causes out-of-distribution drift or the backdoor is not learned, PCC correlations become unreliable and tests lose validity.

### Mechanism 2
- **Claim:** Pearson correlation coefficient (PCC) effectively quantifies alignment between explanation trends and known model trends.
- **Mechanism:** After generating a sequence of models or samples, the tests compute importance feature coverage or loss variation trends. PCC measures consistency between these trends and the model's probability or loss evolution.
- **Core assumption:** The PCC captures meaningful alignment when both trends are monotonic or share similar directional changes.
- **Evidence anchors:**
  - [section 3.2] "To measure the correlation between two trends, we employ the Pearson correlation coefficient (PCC)... PCC is also widely used in the field of deep learning to measure the consistency between the two trends [7, 70]."
  - [section 4.2.1] Examples show high PCC values (e.g., 0.979 for Saliency vs. EMBT) correspond to better faithfulness.
  - [corpus] Weak: corpus papers mention faithfulness evaluation but do not detail PCC-based trend alignment; this is a novel contribution.
- **Break condition:** If trends are non-monotonic or noisy, PCC may underrepresent or overrepresent alignment, leading to false faithfulness scores.

### Mechanism 3
- **Claim:** Model and data complexity affect faithfulness differently; data complexity has a greater impact than model complexity.
- **Mechanism:** The tests show that as data complexity increases (e.g., from MNIST to Tiny ImageNet), many explanation methods degrade in faithfulness, while varying model parameter counts has less effect.
- **Core assumption:** Explanation method performance depends more on the richness and dimensionality of data than on the capacity of the underlying model.
- **Evidence anchors:**
  - [section 4.3] "Data complexity can be characterized by input size, the number of channels, and the number of categories... From the results, we can see that both IG... are better than the original Saliency."
  - [section 4.3] "The influence of model complexity is not as great as that of data complexity."
  - [corpus] Weak: corpus papers discuss faithfulness but not the relative impact of data vs. model complexity.
- **Break condition:** If model complexity interacts with data complexity in non-linear ways (e.g., certain architectures overfit simple data), the stated hierarchy may not hold.

## Foundational Learning

- **Concept: In-distribution vs. Out-of-distribution data**
  - Why needed here: Trend tests rely on keeping test samples within the learned data distribution to avoid adversarial effects and random dominance.
  - Quick check question: What happens to traditional tests when they generate out-of-distribution samples?
    - Answer: They suffer from random dominance and become unreliable.

- **Concept: Pearson correlation coefficient (PCC)**
  - Why needed here: PCC is used to measure how well explanation trends align with known model trends, providing a quantitative faithfulness score.
  - Quick check question: What does a high PCC between two trends indicate?
    - Answer: Strong positive correlation, meaning the trends move together in a consistent way.

- **Concept: Backdoor triggers in model training**
  - Why needed here: Backdoor triggers create a controlled, reversible way to evolve models and generate known trends for faithfulness testing.
  - Quick check question: Why are simple, constant backdoor triggers preferred?
    - Answer: They are easier to reverse and less likely to interfere with the original task accuracy.

## Architecture Onboarding

- **Component map:**
  - Input: Pre-trained model + dataset
  - Trend generator: EMBT (model evolution), EMT (loss-based), PTT (sample transformation)
  - Explanation module: Apply 10 explanation methods to each intermediate model/sample
  - Trend comparator: Compute PCC between explanation trends and known trends
  - Output: Faithfulness scores per method

- **Critical path:**
  1. Inject backdoor into model (EMBT) or prepare trigger-based transformations (PTT)
  2. Record intermediate models/samples at fixed intervals
  3. Generate explanations for each step
  4. Compute trends (backdoor coverage, loss variation, etc.)
  5. Calculate PCC to obtain faithfulness

- **Design tradeoffs:**
  - Higher number of checkpoints → more accurate trends but increased compute/time
  - Simple triggers → reliable trends but may not capture all feature importance
  - White-box methods → faster, more faithful; black-box → slower, less faithful

- **Failure signatures:**
  - Low PCC despite high explanation importance → OOD drift or unstable training
  - High PCC but poor downstream debugging → faithfulness ≠ human interpretability
  - Exploding variance in trends → need outlier filtering

- **First 3 experiments:**
  1. Run EMBT on MNIST with Saliency and IG; compare PCC vs. traditional tests
  2. Test PTT with different trigger patterns on CIFAR-10; check stability of PCC
  3. Apply EMT on Tiny ImageNet; verify loss-based trends correlate with explanation importance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the faithfulness and stability of explanation methods be simultaneously improved to resist adversarial attacks?
- Basis in paper: [explicit] The paper discusses that most explanation methods can be manipulated by adversarial attacks and that developing methods with both high faithfulness and stability is an important future direction.
- Why unresolved: Current explanation methods tend to prioritize either faithfulness or stability, but not both. The paper demonstrates that even highly faithful methods can be manipulated with larger perturbations.
- What evidence would resolve it: Developing and evaluating new explanation methods that achieve both high faithfulness (as measured by trend tests) and high stability (resistance to adversarial attacks within small perturbation budgets).

### Open Question 2
- Question: What are the specific characteristics of data and models that most significantly impact the faithfulness of explanation methods?
- Basis in paper: [explicit] The paper explores the impact of data complexity, model complexity, and parameters on faithfulness, finding that data complexity has a greater impact than model complexity.
- Why unresolved: While the paper identifies these factors, it doesn't provide a comprehensive framework for understanding how different characteristics interact to affect faithfulness across various scenarios.
- What evidence would resolve it: Systematic experiments varying multiple characteristics simultaneously and developing a predictive model for faithfulness based on these characteristics.

### Open Question 3
- Question: How can the trend tests be extended to evaluate explanation methods in more complex scenarios, such as multi-modal data or reinforcement learning environments?
- Basis in paper: [inferred] The trend tests are demonstrated on image, text, and security tasks, but there's potential for application to other domains. The paper mentions that explanations are used in various applications beyond those tested.
- Why unresolved: The current trend tests are designed for specific types of tasks and data. Extending them to more complex scenarios would require new approaches to creating meaningful trends.
- What evidence would resolve it: Developing and validating trend tests for multi-modal data fusion tasks or reinforcement learning environments, demonstrating their effectiveness in assessing faithfulness in these new contexts.

## Limitations

- The effectiveness of trend tests depends on the stability and simplicity of backdoor triggers; complex or unstable triggers may lead to unreliable faithfulness scores.
- The claim that data complexity has a greater impact than model complexity may not hold for all architectures, especially those with non-linear interactions between data and model capacity.
- The trend tests are validated primarily using synthetic backdoor triggers, so their real-world applicability to naturally occurring dataset shifts is not fully established.

## Confidence

- High: The technical approach of trend-based faithfulness tests is sound and addresses a well-identified limitation of traditional tests.
- Medium: The claim that data complexity has a greater impact than model complexity is supported by experiments but may not generalize to all architectures.
- Medium: The effectiveness of trend tests in real-world scenarios beyond synthetic backdoor triggers is not fully demonstrated.

## Next Checks

1. Test trend-based tests on a non-backdoor, naturally occurring dataset shift to confirm in-distribution evolution.
2. Replicate findings on a broader set of model architectures (e.g., Vision Transformers) to verify the data complexity vs. model complexity claim.
3. Conduct ablation studies on trigger simplicity and size to confirm the stability of backdoor-based trends.