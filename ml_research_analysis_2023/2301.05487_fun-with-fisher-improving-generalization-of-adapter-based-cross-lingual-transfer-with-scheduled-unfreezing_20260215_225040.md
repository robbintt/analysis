---
ver: rpa2
title: 'FUN with Fisher: Improving Generalization of Adapter-Based Cross-lingual Transfer
  with Scheduled Unfreezing'
arxiv_id: '2301.05487'
source_url: https://arxiv.org/abs/2301.05487
tags:
- unfreezing
- transfer
- learning
- mbert
- cross-lingual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies improving cross-lingual generalization in parameter-efficient
  task adapter training. It investigates scheduled unfreezing algorithms, originally
  proposed to mitigate catastrophic forgetting, and shows they can improve cross-lingual
  generalization in the CF-free setting.
---

# FUN with Fisher: Improving Generalization of Adapter-Based Cross-lingual Transfer with Scheduled Unfreezing

## Quick Facts
- arXiv ID: 2301.05487
- Source URL: https://arxiv.org/abs/2301.05487
- Reference count: 34
- This paper shows that scheduled unfreezing improves cross-lingual transfer performance by 2 points average across four datasets compared to standard adapter fine-tuning.

## Executive Summary
This paper investigates how scheduled unfreezing algorithms, originally designed to mitigate catastrophic forgetting, can improve cross-lingual generalization in parameter-efficient adapter training. The authors demonstrate that gradual unfreezing changes the learning dynamics of adapters compared to standard fine-tuning and correlates with better cross-lingual transfer performance. They propose a Fisher Information-based scheduled unfreezing algorithm (FUN) that achieves an average of 2 points improvement over four datasets compared to standard fine-tuning, providing evidence that the heuristic top-down unfreezing schedule implicitly maximizes Fisher Information during training.

## Method Summary
The method uses adapter-based cross-lingual transfer where a frozen multilingual base model (mBERT or XLM-R) is fine-tuned with language adapters trained separately for each language, followed by task adapters trained on English data only. The FUN algorithm calculates the trace of the Fisher Information Matrix (tr(F)) periodically during training to determine which adapter layer to unfreeze next, selecting the layer with the highest tr(F) score. This is compared against baseline methods including standard fine-tuning, gradual unfreezing (GU), and linear probing then fine-tuning (LPFT). The approach is evaluated on MLQA, XQuAD, XCOPA, and XNLI datasets with 9 target languages.

## Key Results
- Scheduled unfreezing methods close the gap to full fine-tuning and achieve stronger cross-lingual transfer performance
- FUN algorithm achieves an average of 2 points improvement over four datasets compared to standard fine-tuning
- Different scheduled unfreezing methods induce significantly different learning dynamics as measured by Fisher Information trace
- The top-down heuristic schedule (GU) implicitly maximizes Fisher Information during training

## Why This Works (Mechanism)

### Mechanism 1
Scheduled unfreezing improves cross-lingual generalization even in catastrophic forgetting free settings by changing learning dynamics through controlling the number of trainable parameters over time. This impacts how information is encoded during training, making it effective for distribution shift problems like cross-lingual transfer.

### Mechanism 2
Fisher Information dynamics during training correlate with cross-lingual generalization performance. Scheduled unfreezing induces different Fisher Information (tr(F)) curves compared to standard fine-tuning, with wider tr(F) curves and higher peaks during early learning correlating with better generalization.

### Mechanism 3
The tr(F)-based scheduled unfreezing algorithm (FUN) implicitly maximizes Fisher Information and recovers the performance of heuristic top-down scheduling. FUN selects the next layer to unfreeze based on ranked tr(F) during training, empirically recovering the top-down schedule and achieving comparable results.

## Foundational Learning

- **Concept**: Cross-lingual transfer as distribution shift
  - **Why needed here**: The paper's core hypothesis is that cross-lingual transfer is an extreme case of distribution shift, so understanding this concept is crucial for grasping why scheduled unfreezing works
  - **Quick check question**: What is the main assumption behind using methods designed for distribution shift in cross-lingual transfer?

- **Concept**: Catastrophic forgetting vs. catastrophic forgetting free learning
  - **Why needed here**: The paper explicitly operates in a CF-free setting using adapters, so understanding this distinction is essential for interpreting the results
  - **Quick check question**: How does adapter-based training avoid catastrophic forgetting compared to full fine-tuning?

- **Concept**: Fisher Information and its trace (tr(F))
  - **Why needed here**: tr(F) is the key metric used to study learning dynamics and propose the FUN algorithm, so understanding what it measures is fundamental
  - **Quick check question**: What does the trace of the Fisher Information Matrix (tr(F)) measure in the context of neural network training?

## Architecture Onboarding

- **Component map**: Base model (mBERT/XLM-R) -> frozen layers -> language adapters -> task adapters -> classifier head
- **Critical path**: 1) Initialize all components frozen, 2) Calculate tr(F) periodically, 3) Select next layer to unfreeze based on tr(F) ranking, 4) Unfreeze selected layer, 5) Continue training with updated trainable parameters
- **Design tradeoffs**: FUN trades computational overhead (calculating tr(F) periodically) for potentially better generalization and loses the simplicity of fixed heuristic schedules like GU but gains adaptability
- **Failure signatures**: Poor generalization despite FUN application, tr(F) calculations that don't correlate with performance, or FUN schedules that significantly deviate from GU without performance improvement
- **First 3 experiments**:
  1. Reproduce standard adapter training baseline on XNLI to establish performance floor
  2. Implement FUN with simple tr(F) calculation every 100 steps and compare to standard training
  3. Compare FUN to standard GU schedule on the same dataset to verify they recover similar performance

## Open Questions the Paper Calls Out

### Open Question 1
How does the relationship between the trace of the Fisher Information Matrix (tr(F)) and cross-lingual generalization performance vary across different types of distribution shifts beyond cross-lingual transfer? The study focuses on cross-lingual transfer as a specific type of distribution shift but does not explore how tr(F) correlates with generalization under other types of distribution shifts.

### Open Question 2
What is the theoretical justification for why gradual unfreezing implicitly maximizes Fisher Information during training in the CF-free setting? While the paper provides empirical evidence linking tr(F) maximization to improved generalization, it does not offer a theoretical explanation for why this relationship exists, especially in the CF-free setting.

### Open Question 3
How sensitive are the benefits of scheduled unfreezing and FUN to the specific architecture of task adapters and the base model? The paper experiments with different base models but does not systematically investigate how adapter architecture or base model characteristics affect the effectiveness of scheduled unfreezing and FUN.

## Limitations
- The theoretical claims about Fisher Information correlation with generalization are based on empirical observations without rigorous mathematical proof
- The performance gains (2 points average improvement) come with high variance across datasets
- The analysis is limited to adapter-based architectures, leaving open questions about applicability to full fine-tuning or other parameter-efficient methods

## Confidence
- **High Confidence**: The empirical demonstration that scheduled unfreezing improves cross-lingual transfer in adapter settings (validated across 4 datasets with 4 runs each)
- **Medium Confidence**: The Fisher Information correlation claims, as the correlation is observed but the causal mechanism remains speculative
- **Medium Confidence**: The theoretical justification for why FUN works, which relies on unproven assumptions about tr(F) maximization

## Next Checks
1. **Reproduce the Fisher Information calculation**: Implement the tr(F) computation independently to verify the reported curves in Figure 3 match the paper's results
2. **Test on additional adapter architectures**: Validate whether the FUN algorithm's benefits extend beyond the down-projection/adapter architecture to other designs like prefix-tuning or LoRA
3. **Measure computational overhead**: Benchmark the actual training time and memory costs of FUN compared to standard GU to quantify the tradeoff between adaptability and simplicity