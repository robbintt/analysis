---
ver: rpa2
title: Large Language Model for Multi-objective Evolutionary Optimization
arxiv_id: '2310.12541'
source_url: https://arxiv.org/abs/2310.12541
tags:
- moea
- evolutionary
- optimization
- individuals
- operators
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach for multiobjective optimization
  using large language models (LLMs). The key idea is to leverage the power of pre-trained
  LLMs as search operators within a decomposition-based evolutionary algorithm framework.
---

# Large Language Model for Multi-objective Evolutionary Optimization

## Quick Facts
- arXiv ID: 2310.12541
- Source URL: https://arxiv.org/abs/2310.12541
- Reference count: 40
- Primary result: Introduces MOEA/D-LLM and MOEA/D-LO algorithms using LLMs as search operators in multi-objective optimization

## Executive Summary
This paper proposes a novel approach for multi-objective optimization using large language models (LLMs) as search operators within a decomposition-based evolutionary algorithm framework. The authors decompose the original multi-objective problem into several single-objective subproblems and employ LLMs with prompt engineering to generate new individuals for each subproblem in a zero-shot manner. They also interpret LLM behavior by approximating it as a linear operator with randomness, leading to the MOEA/D-LO algorithm. Extensive experiments demonstrate that MOEA/D-LO achieves competitive performance compared to widely used multi-objective evolutionary algorithms (MOEAs) and ranks first in some cases.

## Method Summary
The paper introduces MOEA/D-LLM, which uses pre-trained LLMs as black-box search operators within a decomposition-based evolutionary algorithm (MOEA/D) framework. The method decomposes the original multi-objective problem into N single-objective subproblems and employs LLMs with prompt engineering to generate new individuals for each subproblem in a zero-shot manner. Additionally, the authors approximate LLM behavior as a linear operator with randomness, leading to the MOEA/D-LO algorithm. This white-box approach uses a learned linear operator as the search operator instead of traditional crossover or differential evolution operators.

## Key Results
- MOEA/D-LO achieves competitive performance compared to widely used MOEAs on various test instances
- The linear operator approximation effectively captures LLM behavior while providing interpretability
- Prompt engineering with in-context learning enables effective use of LLMs for optimization tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can be effectively used as black-box search operators in multi-objective evolutionary algorithms (MOEAs) by decomposing the problem into single-objective subproblems.
- Mechanism: The original MOP is decomposed into N single-objective subproblems using decomposition-based MOEA (MOEA/D). For each subproblem, a subset of population individuals is selected and used as in-context learning samples in a prompt to the LLM. The LLM generates new individuals that are evaluated and used to update the population and external population.
- Core assumption: LLMs can understand the optimization task from natural language prompts and generate valid new individuals that improve the subproblem's objective value.
- Evidence anchors:
  - [abstract] "By decomposing the original multiobjective problem into several single-objective subproblems and employing LLMs with prompt engineering, the proposed method, MOEA/D-LLM, generates new individuals for each subproblem in a zero-shot manner."
  - [section IV-A] "LLM is adopted for generating new individuals for each subproblem."
- Break condition: If the LLM fails to generate valid individuals or the generated individuals do not improve the subproblem's objective value, the MOEA will not converge to good solutions.

### Mechanism 2
- Claim: The behavior of LLMs can be approximated as a weighted linear operator with randomness, enabling a white-box interpretation of the search process.
- Mechanism: The input-output pairs of individuals from LLM interactions are collected. A linear regression model is used to learn the weight vector for each input individual. The weight is modeled as a polynomial function of the individual's rank in terms of objective value. Randomness is added to the weights to account for the inherent randomness in LLM outputs.
- Core assumption: The mapping from input individuals to new individuals generated by LLM can be approximated by a linear combination of the inputs with weights dependent on their ranks.
- Evidence anchors:
  - [section V-A] "We interpret the results of LLM as a mapping from input individuals to new individuals in a similar way."
  - [section V-C] "We use a weighted linear operator with an additional randomness term to approximate the results of LLMs."
- Break condition: If the linear approximation does not capture the true behavior of LLM, the MOEA/D-LO algorithm may not perform as well as expected.

### Mechanism 3
- Claim: The proposed MOEA/D-LO algorithm, which uses the learned linear operator with randomness, achieves competitive performance compared to widely used MOEAs.
- Mechanism: MOEA/D-LO uses the learned linear operator as the search operator instead of traditional crossover or differential evolution operators. The linear operator generates new individuals based on a weighted combination of input individuals, with weights learned from LLM behavior and randomness added.
- Core assumption: The learned linear operator with randomness can effectively explore the search space and generate high-quality solutions.
- Evidence anchors:
  - [abstract] "Experimental studies on different test benchmarks show that our proposed method can achieve competitive performance with widely used MOEAs."
  - [section VI-D] "Our proposed MOEA/D-LO demonstrates highly promising performance when compared to commonly used MOEAs."
- Break condition: If the linear operator fails to generate diverse and high-quality solutions, MOEA/D-LO will not outperform traditional MOEAs.

## Foundational Learning

- Concept: Decomposition-based multi-objective evolutionary algorithms (MOEA/D)
  - Why needed here: The paper uses MOEA/D as the framework to decompose the original MOP into single-objective subproblems, which are then solved using LLM as the search operator.
  - Quick check question: How does MOEA/D decompose the original MOP into subproblems, and how are these subproblems solved?

- Concept: In-context learning and prompt engineering for LLMs
  - Why needed here: The paper uses in-context learning by providing the LLM with a prompt containing the optimization task description, in-context samples, and expected outputs. The LLM generates new individuals based on this prompt.
  - Quick check question: What are the key components of the prompt used to guide the LLM in generating new individuals for each subproblem?

- Concept: Linear regression and polynomial regression
  - Why needed here: The paper uses linear regression to learn the weight vector for each input individual, and models the weight as a polynomial function of the individual's rank.
  - Quick check question: How does the paper use linear regression and polynomial regression to approximate the behavior of LLM as a weighted linear operator?

## Architecture Onboarding

- Component map:
  MOEA/D framework -> LLM black-box optimizer -> Linear operator with randomness -> MOEA/D-LO

- Critical path:
  1. Initialize MOEA/D with N subproblems and associated weight vectors.
  2. For each subproblem, select a subset of population individuals and create a prompt for the LLM.
  3. Use the LLM to generate new individuals based on the prompt.
  4. Update the reference point, population, and external population using the generated individuals.
  5. Repeat steps 2-4 until the maximum number of evaluations is reached.

- Design tradeoffs:
  - Using LLM as a black-box optimizer allows leveraging the power of pre-trained models without the need for manual design or training, but it limits interpretability and can be time-consuming.
  - Approximating LLM behavior as a linear operator with randomness enables a white-box interpretation and faster execution, but may not capture the full complexity of LLM outputs.

- Failure signatures:
  - LLM fails to generate valid individuals or generates individuals that do not improve the subproblem's objective value.
  - Linear approximation does not capture the true behavior of LLM, leading to poor performance of MOEA/D-LO.
  - MOEA/D-LO does not converge to good solutions or is outperformed by traditional MOEAs.

- First 3 experiments:
  1. Test MOEA/D-LLM on a simple bi-objective optimization problem (e.g., ZDT1) and compare the results with the original MOEA/D using a genetic algorithm.
  2. Collect data from LLM interactions and learn the linear operator with randomness. Test MOEA/D-LO on the same problem and compare the results with MOEA/D-LLM and the original MOEA/D.
  3. Conduct an ablation study by comparing MOEA/D-LO with different weight settings (e.g., random, equal, linear) and different input sizes to understand the impact of the learned linear operator and input size on performance.

## Open Questions the Paper Calls Out
- How can LLMs be effectively integrated with other MOEA paradigms beyond decomposition-based methods?
- What is the optimal number of input individuals for the LLM-based linear operator across different problem dimensions?
- How can historical search trajectories or reward information be effectively incorporated into LLM prompts to improve optimization performance?

## Limitations
- LLM-based method is computationally expensive due to API call costs and response times
- Linear operator approximation may not fully capture complex nonlinear LLM behavior
- Study relies on synthetic test problems rather than real-world multi-objective optimization applications

## Confidence
**High Confidence Claims:**
- LLMs can function as search operators in MOEAs when properly prompted
- The decomposition-based framework effectively reduces multi-objective problems to single-objective subproblems
- Performance metrics (HV and IGD) are appropriate for evaluating MOEA outcomes

**Medium Confidence Claims:**
- The linear operator with randomness adequately approximates LLM behavior
- MOEA/D-LO achieves competitive performance compared to established MOEAs
- The in-context learning approach generalizes across different problem types

**Low Confidence Claims:**
- The approach scales effectively to high-dimensional problems (beyond 3 objectives)
- Results would generalize to real-world optimization problems
- The method is computationally practical for large-scale applications

## Next Checks
1. Evaluate MOEA/D-LO on problems with 5+ objectives to verify performance scaling and identify computational bottlenecks.
2. Apply the method to an actual engineering optimization problem (e.g., structural design or scheduling) to assess practical utility beyond synthetic benchmarks.
3. Test the framework using open-source LLMs (e.g., LLaMA or BLOOM) to determine if results are specific to GPT-3.5 Turbo or generalizable to other language models.