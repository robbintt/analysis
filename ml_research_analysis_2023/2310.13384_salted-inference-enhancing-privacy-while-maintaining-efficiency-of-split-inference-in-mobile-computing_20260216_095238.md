---
ver: rpa2
title: 'Salted Inference: Enhancing Privacy while Maintaining Efficiency of Split
  Inference in Mobile Computing'
arxiv_id: '2310.13384'
source_url: https://arxiv.org/abs/2310.13384
tags:
- inference
- salted
- layer
- split
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Split inference partitions a DNN to run early layers at the edge
  and later layers in the cloud, enabling input privacy and computational efficiency
  but leaving DNN outputs exposed to the cloud. To address this limitation, we propose
  Salted DNNs, which add a lightweight salt input to an early layer of the DNN, enabling
  clients to control the semantic interpretation of outputs without sacrificing accuracy
  or efficiency.
---

# Salted Inference: Enhancing Privacy while Maintaining Efficiency of Split Inference in Mobile Computing

## Quick Facts
- arXiv ID: 2310.13384
- Source URL: https://arxiv.org/abs/2310.13384
- Reference count: 28
- Primary result: Salted DNNs achieve classification accuracy within 1-3% of standard DNNs while adding minimal computational overhead

## Executive Summary
Split inference partitions DNNs to run early layers at the edge and later layers in the cloud, enabling input privacy but exposing output semantics to the cloud server. This paper introduces Salted DNNs, which add a lightweight salt input to an early layer, enabling clients to control the semantic interpretation of outputs without sacrificing accuracy or efficiency. The approach uses modulo permutation to randomly reorder class labels during training, ensuring only clients who know the salt can decode true outputs. Experimental evaluations on CIFAR10 and PAMAP2 datasets demonstrate that Salted DNNs achieve classification accuracy very close to standard DNNs with only 1-3% reduction, while adding minimal computational overhead suitable for edge devices.

## Method Summary
The method involves adding a salt input `s` concatenated via transposed convolution to an early layer of the DNN. During training, a modulo mapping function M permutes output semantics based on the salt value, with the DNN learning to output in the permuted order corresponding to `s`. During inference, the client controls the salt value and runs the early part of the DNN locally, sending only intermediate features to the cloud server. The server computes salted outputs, which the client decodes using the inverse mapping function. This approach ensures only the client can interpret the correct order of outputs while maintaining split inference efficiency.

## Key Results
- Classification accuracy within 1-3% of standard DNNs on CIFAR10 and PAMAP2 datasets
- Minimal computational overhead suitable for edge devices
- General applicability to various DNN architectures including image and sensor data
- Effective output privacy through semantic permutation without formal privacy guarantees

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Salting early DNN layers disrupts semantic output ordering without compromising accuracy.
- **Mechanism:** A salt input `s` is concatenated via transposed convolution to an early layer, permuting the class ordering so that only a client who knows `s` can decode the true label.
- **Core assumption:** The salt layer's output cannot be reverse-engineered from intermediate activations `Z` due to subsequent non-linear layers.
- **Evidence anchors:**
  - [abstract] "Experimental evaluations conducted on both image and wearable sensor datasets show that Salted DNNs achieve classification accuracy very close to standard DNNs, with only a 1-3% reduction in accuracy, while adding minimal computational overhead suitable for edge devices."
  - [section] "Adding ùë† to early layers within DNNs aligns better with our objectives for private and efficient split inference. It also makes it harder for a curious server to infer the salt ùë† from ùëç and, as a result, to decode the output semantics."

### Mechanism 2
- **Claim:** The modulo mapping function M ensures uniform permutation of output semantics across classes.
- **Mechanism:** For each training sample with label `y`, the salt `s` maps the one-hot label to `Y^s = 1((y+s) % K)`, so the DNN learns to output in the permuted order corresponding to `s`.
- **Core assumption:** Modulo mapping produces a bijection for all `s ‚àà {1,...,S}` ensuring each class is equally likely to appear in any output position.
- **Evidence anchors:**
  - [section] "For each ùëå = 1ùë¶, the new label is ùëå ùë† = 1(ùë¶+ùë†)%ùêæ."
  - [abstract] "Our training algorithm randomly permutes output semantics based on a chosen salt value."

### Mechanism 3
- **Claim:** Split inference structure allows client-only control of salt while keeping inference efficient.
- **Mechanism:** The early part `Œ∏1` runs at the client with salt `s`; only intermediate features `Z` are sent to the server, which computes salted outputs `Y^s = Œ∏2(Z)`. The client decodes using `s` and the inverse mapping.
- **Core assumption:** Intermediate features `Z` do not leak `s` because they are produced after the salted layer but before final classification.
- **Evidence anchors:**
  - [section] "During the inference phase, the client exclusively controls the secret salt ùë†, thereby the client is the only party who can interpret the correct order for the outputs."
  - [abstract] "Experimental evaluations conducted on both image and sensor data demonstrate that Salted DNNs attain classification accuracy very close to standard DNNs, particularly when the Salted Layer is positioned within the early part to meet the requirements of split inference."

## Foundational Learning

- **Concept:** Split Inference
  - **Why needed here:** Provides baseline framework for partitioning DNN to protect input privacy while enabling edge-cloud collaboration.
  - **Quick check question:** In split inference, which part of the DNN is executed at the client side and why?

- **Concept:** Transposed Convolution
  - **Why needed here:** Expands scalar salt `s` into a tensor matching the salted layer's input dimension for concatenation.
  - **Quick check question:** Why must the salt input be expanded before concatenation in the salted layer?

- **Concept:** Modulo Permutation
  - **Why needed here:** Ensures each salt value yields a unique, deterministic reordering of output classes, enabling consistent training and decoding.
  - **Quick check question:** If K=10 classes and s=3, what class index does label 0 map to under modulo permutation?

## Architecture Onboarding

- **Component map:**
  - Client: Input data `X`, salt `s`, early DNN `Œ∏1`, inverse mapping function M‚Åª¬π
  - Server: Intermediate features `Z`, later DNN `Œ∏2`
  - Shared: Trained salted DNN parameters, modulo mapping function M

- **Critical path:**
  1. Client selects salt `s` and runs `Z = Œ∏1(X, s)`
  2. Client sends `Z` to server
  3. Server computes `Y^s = Œ∏2(Z)` and returns to client
  4. Client decodes output with `Y = M‚Åª¬π(s, Y^s)`

- **Design tradeoffs:**
  - Earlier salted layer ‚Üí better privacy but potentially lower accuracy
  - Later salted layer ‚Üí higher accuracy but weaker privacy
  - Number of salt values S ‚Üí larger S increases ambiguity but requires more training

- **Failure signatures:**
  - Accuracy drop > 3% suggests salted layer too early or S too large
  - Server can decode outputs ‚Üí salt leakage or cut layer too late
  - High communication overhead ‚Üí intermediate features `Z` too large

- **First 3 experiments:**
  1. Train standard LeNet on CIFAR10; record baseline accuracy
  2. Add salt to first convolutional layer; train Salted LeNet; compare accuracy and inference time
  3. Vary salt position (Conv1, Conv2, Conv3); evaluate accuracy-privacy tradeoff curve

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the proposed method guarantee formal privacy against a curious server attempting to infer the salt value from the cut layer outputs?
- **Basis in paper:** [explicit] The paper states: "This paper does not offer a formal privacy guarantee regarding the possibilities of inferring ùë† from ùëç" and acknowledges that "extracting ùë† directly from the output of the cut layer, ùëç, is not a trivial task" but does not provide a formal proof.
- **Why unresolved:** While the paper demonstrates that extracting the salt from intermediate features is difficult due to non-linear operations, it does not provide a rigorous mathematical proof or formal privacy analysis against potential inference attacks.
- **What evidence would resolve it:** A formal privacy proof showing the information-theoretic or computational bounds on a server's ability to infer the salt value from the cut layer outputs, or a demonstration of successful attacks under realistic threat models.

### Open Question 2
- **Question:** How does the accuracy of Salted DNNs scale with the number of classes beyond 100, and what are the practical limitations?
- **Basis in paper:** [explicit] The paper notes that experiments on CIFAR100 (100 classes) were unsuccessful and states: "We believe that for dealing with datasets containing a significantly greater number of classes, achieving high accuracy with Salted DNNs requires both more powerful DNNs and much larger training datasets."
- **Why unresolved:** The paper only tests on datasets with 10-13 classes and does not explore the scaling behavior with respect to class count. The relationship between salt permutations, class count, and model capacity remains unclear.
- **What evidence would resolve it:** Systematic experiments on datasets with varying numbers of classes (e.g., 10, 50, 100, 200) showing accuracy trends, along with analysis of the computational and model capacity requirements needed to maintain accuracy as class count increases.

### Open Question 3
- **Question:** What are the broader applications of Salted DNNs beyond split inference, particularly in adversarial robustness and uncertainty estimation?
- **Basis in paper:** [explicit] The paper mentions: "From a technical standpoint, our proposed Salted DNNs effectively convert a deterministic function (i.e., standard DNNs) into a randomized function" and suggests potential applications in Monte Carlo sampling for confidence estimation and possibly increased robustness to adversarial examples.
- **Why unresolved:** While the paper identifies these potential applications, it does not empirically evaluate them or provide theoretical justification for why randomization through salting would improve adversarial robustness or enable uncertainty estimation.
- **What evidence would resolve it:** Empirical studies comparing Salted DNNs to standard DNNs on adversarial robustness benchmarks and uncertainty estimation tasks, along with theoretical analysis of how the randomization mechanism affects these properties.

## Limitations

- The paper does not provide formal privacy guarantees regarding the possibility of inferring the salt value from intermediate features.
- Implementation details for the transposed convolution layer and salt concatenation method are underspecified, making reproduction challenging.
- The evaluation focuses primarily on accuracy metrics without providing runtime benchmarks or energy consumption measurements crucial for edge device deployment.

## Confidence

**High confidence** in the core privacy mechanism: The concept of using salt to permute output semantics is sound and the experimental results showing 1-3% accuracy reduction are specific and measurable.

**Medium confidence** in efficiency claims: While the paper states minimal computational overhead, it lacks concrete runtime measurements or comparisons to baseline split inference implementations.

**Medium confidence** in generalizability: The method is claimed to work across different DNN architectures, but only LeNet and EEGNet are tested. More diverse architecture evaluations would strengthen this claim.

## Next Checks

1. **Transposed Convolution Implementation**: Verify the exact parameters and architecture of the transposed convolution layer used to expand the salt input, ensuring dimensional compatibility with different target layers.

2. **Privacy Leakage Test**: Conduct experiments where an adversary attempts to infer the salt value from intermediate features Z alone, measuring the success rate across different cut layer positions.

3. **Cross-Architecture Evaluation**: Implement Salted DNNs on additional architectures beyond LeNet (e.g., ResNet, MobileNet) to validate the claimed generalizability and measure architecture-specific performance tradeoffs.