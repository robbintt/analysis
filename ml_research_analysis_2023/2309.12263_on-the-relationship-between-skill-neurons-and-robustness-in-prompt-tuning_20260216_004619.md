---
ver: rpa2
title: On the Relationship between Skill Neurons and Robustness in Prompt Tuning
arxiv_id: '2309.12263'
source_url: https://arxiv.org/abs/2309.12263
tags:
- neurons
- skill
- prompt
- adversarial
- roberta
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the robustness of Prompt Tuning in relation
  to "skill neurons", which are specific neurons in transformer feed-forward networks
  that are highly predictive of task labels. The authors run experiments with RoBERTa
  and T5, tuning prompts for various binary classification tasks.
---

# On the Relationship between Skill Neurons and Robustness in Prompt Tuning

## Quick Facts
- arXiv ID: 2309.12263
- Source URL: https://arxiv.org/abs/2309.12263
- Reference count: 9
- Key outcome: Prompts tuned for specific tasks are transferable to similar tasks but not robust to adversarial data, with T5 showing higher robustness than RoBERTa due to consistent skill neuron activation across data distributions.

## Executive Summary
This paper investigates the robustness of Prompt Tuning in relation to "skill neurons" - specific neurons in transformer feed-forward networks that are highly predictive of task labels. Through experiments with RoBERTa and T5 on various binary classification tasks, the authors demonstrate that while prompts are transferable to similar tasks, they lack robustness to adversarial data. Notably, T5 shows higher adversarial robustness than RoBERTa, which the authors attribute to T5's ability to consistently activate the same skill neurons on both adversarial and non-adversarial data.

## Method Summary
The authors use Prompt Tuning with 100 continuous tokens per prompt, training five prompts per dataset with different random seeds. They calculate neuron predictivities using baseline activations and accuracy measures, identifying skill neurons based on their predictive power for task labels. The study employs binary classification tasks including paraphrase detection, sentiment analysis, ethical judgment, and natural language inference, with adversarial versions of QQP, QNLI, and SST2. Suppression analysis is conducted to test skill neuron importance by setting activations to zero and measuring impact on model performance.

## Key Results
- Prompts tuned for specific tasks are transferable to tasks of the same type but not robust to adversarial data
- T5 exhibits higher adversarial robustness than RoBERTa
- T5's skill neurons identified on non-adversarial data remain highly predictive on adversarial data, while this consistency is absent in RoBERTa

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prompt Tuning activates task-specific "skill neurons" in transformer FFN layers
- Mechanism: Continuous prompt tokens modify input distribution, causing specific neurons to activate strongly for task-relevant patterns
- Core assumption: FFN layers contain neurons that can specialize to encode task-specific information
- Evidence anchors: Skill neurons identified as FFN neurons whose activations are highly predictive of task labels

### Mechanism 2
- Claim: Skill neurons are transferable across tasks of the same type but not robust to adversarial data
- Mechanism: Prompts activate task-specific skill neurons that can be reused for similar tasks, but adversarial data changes input distribution and breaks robustness
- Core assumption: Skill neuron activation depends on consistent input distribution
- Evidence anchors: Prompt Tuning robust to domain shifts but not adversarial data

### Mechanism 3
- Claim: T5's higher adversarial robustness stems from consistent skill neuron activation across data distributions
- Mechanism: Skill neurons identified on non-adversarial data remain predictive on adversarial data for T5, maintaining above-chance performance
- Core assumption: Consistency of skill neuron activation across data distributions is key to adversarial robustness
- Evidence anchors: Strong and significant correlations between predictivities on adversarial and non-adversarial data for T5

## Foundational Learning

- Concept: Feed-forward networks (FFNs) in transformers
  - Why needed here: Skill neurons are defined as neurons in FFNs whose activations are highly predictive of task labels
  - Quick check question: What is the role of the activation function in the FFN, and how does it affect the neuron's output?

- Concept: Prompt tuning and continuous prompt tokens
  - Why needed here: Prompt tuning is the parameter-efficient finetuning method used in the paper
  - Quick check question: How do continuous prompt tokens differ from discrete tokens, and why are they used in prompt tuning?

- Concept: Adversarial data and its impact on model robustness
  - Why needed here: The paper investigates robustness to adversarial data
  - Quick check question: What is the difference between adversarial data and domain-shifted data, and how do they impact model robustness differently?

## Architecture Onboarding

- Component map:
  Input sequence Xorig and continuous prompt tokens P -> Embedding layer (embeds Xorig into X and prepends P) -> Transformer layers (self-attention and FFN layers) -> Output prediction

- Critical path:
  1. Generate continuous prompt tokens P through prompt tuning
  2. Prepend P to input sequence in embedding space
  3. Pass modified input through transformer layers
  4. Identify skill neurons in FFN layers based on predictivity
  5. Analyze robustness of skill neurons to adversarial data

- Design tradeoffs:
  - Parameter efficiency vs. task performance: Prompt tuning only tunes small parameter set
  - Task-specificity vs. transferability: Skill neurons are task-specific but enable transfer to similar tasks
  - Robustness vs. sensitivity: Skill neurons are highly sensitive to input distribution

- Failure signatures:
  - Low skill neuron predictivity indicates ineffective use of prompt-tuned parameters
  - Lack of skill neuron consistency across data distributions indicates robustness issues
  - High sensitivity to prompt initialization suggests unstable training

- First 3 experiments:
  1. Replicate skill neuron identification process on new dataset using provided code
  2. Test transferability of prompts tuned for one task to another task of same type
  3. Evaluate robustness of prompts to adversarial data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does T5 exhibit higher adversarial robustness compared to RoBERTa, despite similar performance on non-adversarial tasks?
- Basis in paper: T5 has higher adversarial robustness and consistently activates same skill neurons on adversarial and non-adversarial data
- Why unresolved: Paper does not provide definitive explanation for T5's skill neuron consistency
- What evidence would resolve it: Experiments comparing internal mechanisms of T5 and RoBERTa explaining skill neuron consistency differences

### Open Question 2
- Question: How can the adversarial robustness of Prompt Tuning be improved for both T5 and RoBERTa?
- Basis in paper: Prompt Tuning is not robust to adversarial data, but T5 is more robust than RoBERTa
- Why unresolved: Paper does not explore methods to improve adversarial robustness
- What evidence would resolve it: Experiments testing techniques like data augmentation, adversarial training, or modified prompt tuning

### Open Question 3
- Question: Are skill neurons in the encoder more predictive and essential for task performance compared to skill neurons in the decoder?
- Basis in paper: Skill neuron analysis limited to encoder; suggests extending to decoder in future work
- Why unresolved: Current analysis only considers encoder skill neurons
- What evidence would resolve it: Experiments extending skill neuron analysis to decoder and comparing encoder vs. decoder skill neuron importance

## Limitations

- Adversarial datasets used are not fully described, making it unclear whether robustness differences stem from attack methodology or inherent model properties
- Correlation between skill neuron predictivities does not establish causation for adversarial robustness
- Limited scope of adversarial datasets and tasks prevents generalization to broader settings

## Confidence

- **High Confidence**: Identification of skill neurons as task-specific predictors and their transferability across similar tasks
- **Medium Confidence**: Claim that T5 is more robust to adversarial data than RoBERTa
- **Low Confidence**: Proposed mechanism linking skill neuron consistency to adversarial robustness

## Next Checks

1. Reconstruct or obtain exact adversarial datasets to verify robustness differences across different attack methodologies
2. Extend correlation analysis between skill neuron predictivities and actual model performance on adversarial data with regression analysis
3. Conduct controlled experiments comparing T5 and RoBERTa with matched architectures to isolate factors driving robustness differences