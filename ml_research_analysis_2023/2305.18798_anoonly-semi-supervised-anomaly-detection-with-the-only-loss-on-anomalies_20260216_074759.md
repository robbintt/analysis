---
ver: rpa2
title: 'AnoOnly: Semi-Supervised Anomaly Detection with the Only Loss on Anomalies'
arxiv_id: '2305.18798'
source_url: https://arxiv.org/abs/2305.18798
tags:
- anoonly
- anomaly
- normal
- data
- supervision
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a semi-supervised anomaly detection (SSAD)
  framework called AnoOnly to address the imbalanced supervision issue between normal
  and abnormal data. AnoOnly eliminates strict loss supervision for normal data and
  introduces batch normalization as a form of weak supervision to capture statistical
  characteristics and implicitly perform cluster learning.
---

# AnoOnly: Semi-Supervised Anomaly Detection with the Only Loss on Anomalies

## Quick Facts
- **arXiv ID**: 2305.18798
- **Source URL**: https://arxiv.org/abs/2305.18798
- **Reference count**: 40
- **Key outcome**: AnoOnly eliminates strict loss supervision on normal data and uses batch normalization for weak supervision, significantly improving SSAD performance across multiple datasets and demonstrating robustness to label noise.

## Executive Summary
AnoOnly addresses the imbalanced supervision challenge in semi-supervised anomaly detection by suspending strict loss supervision on normal data and introducing batch normalization (BN) as a form of weak supervision. This approach effectively rebalances the supervision volume between normal and abnormal data, allowing the model to focus more on anomaly discrimination. The framework demonstrates significant performance improvements when integrated with existing SSAD methods and shows strong robustness to label noise, achieving new state-of-the-art results across various image and text datasets.

## Method Summary
AnoOnly is a semi-supervised anomaly detection framework that removes strict loss supervision on normal data while maintaining anomaly loss supervision. It introduces batch normalization as weak supervision for normal data, where BN implicitly performs cluster learning by capturing statistical characteristics of normal data through running mean and variance. The framework integrates with existing SSAD methods like DeepSAD, DevNet, PReNet, and FEAWAD by modifying their loss functions to exclude normal data supervision while preserving anomaly supervision. The method leverages the statistical properties gathered by BN to guide normal data toward learned distributions without explicit loss terms.

## Key Results
- AnoOnly significantly enhances SSAD performance across multiple datasets (CIFAR-10, FashionMNIST, MNIST-C, MVTec-AD, SVHN, 20news, Agnews, Amazon, Imdb, Yelp)
- Achieves new state-of-the-art performance in both image-based and text-based anomaly detection tasks
- Demonstrates strong robustness to label noise, maintaining effectiveness even when data is contaminated
- Effective across various labeled anomaly ratios (1% to 25%) during training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Batch Normalization (BN) implicitly performs online cluster learning on normal data, providing weak supervision.
- Mechanism: BN computes running mean and variance of normal data during training, forming hyperspherical clusters centered at these statistics. The cluster centers update dynamically as the model trains, guiding normal data toward a learned distribution without explicit loss terms.
- Core assumption: Mini-batches are predominantly normal data, so BN statistics reflect normal data distribution.
- Evidence anchors:
  - [abstract] "weak supervision is instantiated through the utilization of batch normalization, which implicitly performs cluster learning on normal data"
  - [section] "the statistical characteristics (µB and σB) gathered by BN primarily reflect ample normal data"
  - [corpus] Weak - no directly related papers mention BN for anomaly detection in this way
- Break condition: If batch composition shifts toward anomaly-heavy samples, BN statistics will be corrupted and lose weak supervision effectiveness.

### Mechanism 2
- Claim: Removing strict loss supervision on normal data reduces supervision imbalance, allowing the model to focus on anomaly discrimination.
- Mechanism: By eliminating LN(DN;θ) and relying only on LA(DA;θ) for anomalies, the model's capacity is redirected from modeling normal data toward learning discriminative features for anomalies.
- Core assumption: Normal data is abundant but homogeneous, providing limited discriminative value compared to scarce anomalies.
- Evidence anchors:
  - [abstract] "suspends it and introduces a form of weak supervision for normal data"
  - [section] "the overwhelming supervision volume on normal data suppressing anomalies significantly biases model attention and capacity against anomaly perception"
  - [corpus] Weak - most related works focus on over-sampling or re-weighting rather than removing normal loss entirely
- Break condition: If normal data diversity is high or anomalies are extremely rare, removing normal loss could harm overall reconstruction and feature learning.

### Mechanism 3
- Claim: AnoOnly's design makes it natively robust to label noise because BN's implicit clustering is less affected by mislabeled anomalies.
- Mechanism: When anomalies contaminate the normal set, strict loss terms would confuse the model. BN's statistics, however, are dominated by the majority normal samples and thus remain relatively stable, providing consistent weak supervision.
- Core assumption: Label noise affects a small fraction of data, so majority statistics remain representative of true normal distribution.
- Evidence anchors:
  - [abstract] "our AnoOnly is natively robust to label noise when suffering from data contamination"
  - [section] "Since BN serves as implicit cluster learning to capture statistical characteristics that are less influenced by label noise"
  - [corpus] Weak - no directly related papers explicitly discuss label noise robustness via BN in anomaly detection
- Break condition: If contamination ratio is very high (e.g., >50%), BN statistics will be severely corrupted and weak supervision will fail.

## Foundational Learning

- Concept: Batch Normalization mechanics and gradient flow
  - Why needed here: BN's statistical capture and gradient contribution are central to AnoOnly's weak supervision
  - Quick check question: What happens to the gradient ∂LA/∂hi when batch contains mostly normal data vs. mixed data?

- Concept: Semi-supervised anomaly detection loss design
  - Why needed here: Understanding why standard SSAD methods use both LN and LA, and how AnoOnly modifies this
  - Quick check question: In DeepSAD, what is the role of the L2 norm in LN vs. the inverse L2 norm in LA?

- Concept: Cluster learning as weak supervision
  - Why needed here: BN implicitly clusters normal data; understanding explicit clustering helps interpret this mechanism
  - Quick check question: How does the hyperspherical cluster assumption in BN compare to explicit clustering losses like in DeepSAD?

## Architecture Onboarding

- Component map: Feature extractor E(·;θE) → BN layer → Anomaly detector D(·;θD)
- Critical path:
  1. Forward pass through E → BN normalizes → D scores anomalies
  2. Backward pass: LA gradient flows through BN → updates E and D
  3. BN updates running mean/variance for next batch
- Design tradeoffs:
  - Removing LN reduces normal data supervision but risks losing normal reconstruction ability
  - Using BN for weak supervision is efficient but batch-size sensitive
  - No explicit LN means normal detection precision may drop
- Failure signatures:
  - Performance collapse when batch size is very small (1-2)
  - Degraded results when anomaly contamination >20-30% of unlabeled data
  - Overfitting to anomalies if LA weight is too high relative to BN's influence
- First 3 experiments:
  1. Train DeepSAD with AnoOnly on CIFAR-10, compare AUCROC with and without BN
  2. Vary batch size (1, 4, 16, 64) and measure performance stability
  3. Inject synthetic label noise (10%, 30%, 50%) and test robustness relative to standard DeepSAD

## Open Questions the Paper Calls Out

- Open Question 1: How does the performance of AnoOnly compare to existing SSAD methods when the labeled anomaly ratio (γla) is very small (e.g., 1%)?
  - Basis in paper: [explicit] The paper states that "when only a handful of anomalies are labeled (γla ∈ [1%, 5%, 10%, 25%]) during training, our AnoOnly framework demonstrates remarkable superiority in taking full advantage of insufficient abnormal data."
  - Why unresolved: The paper does not provide specific performance comparisons for γla = 1%.
  - What evidence would resolve it: Experimental results comparing AnoOnly with existing SSAD methods at γla = 1%.

- Open Question 2: Can the weak supervision mechanism introduced by BN in AnoOnly be further improved by incorporating additional techniques or modifications?
  - Basis in paper: [explicit] The paper suggests exploring "alternative approaches to implement controllable weak supervision on normal data to further facilitate supervision rebalancing between heavily imbalanced normal and abnormal data."
  - Why unresolved: The paper does not explore alternative techniques or modifications to the weak supervision mechanism.
  - What evidence would resolve it: Experimental results comparing AnoOnly with and without additional techniques or modifications to the weak supervision mechanism.

- Open Question 3: How does AnoOnly perform in real-world scenarios where the data distribution is non-stationary and evolves over time?
  - Basis in paper: [inferred] The paper demonstrates the robustness of AnoOnly to label noise, which is a common issue in real-world scenarios. However, it does not explicitly evaluate the performance of AnoOnly in non-stationary data environments.
  - Why unresolved: The paper does not provide experimental results or analysis of AnoOnly's performance in non-stationary data environments.
  - What evidence would resolve it: Experimental results comparing AnoOnly's performance in non-stationary data environments with and without its application.

## Limitations

- The core claim that BN provides sufficient weak supervision lacks direct empirical ablation showing performance degradation when BN is removed
- The exact contribution of BN's implicit clustering versus reduced supervision imbalance is unclear
- Robustness to label noise is supported by experiments but lacks theoretical analysis of contamination thresholds where BN statistics become unreliable

## Confidence

- **High**: AnoOnly improves SSAD performance by removing strict normal loss and rebalancing supervision
- **Medium**: BN provides meaningful weak supervision through implicit clustering
- **Low**: AnoOnly is natively robust to label noise without further modification

## Next Checks

1. **Ablation study**: Train AnoOnly without BN (only LA on anomalies) to quantify BN's contribution to performance gains
2. **Batch size sensitivity**: Systematically vary batch sizes from 1 to 128 to identify the minimum batch size where BN remains effective
3. **Contamination threshold**: Test AnoOnly with increasing contamination ratios (0% to 80%) to empirically determine the failure point where BN statistics become unreliable