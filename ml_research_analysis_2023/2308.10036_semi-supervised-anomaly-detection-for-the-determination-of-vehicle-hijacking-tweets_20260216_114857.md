---
ver: rpa2
title: Semi-Supervised Anomaly Detection for the Determination of Vehicle Hijacking
  Tweets
arxiv_id: '2308.10036'
source_url: https://arxiv.org/abs/2308.10036
tags:
- would
- tweets
- cluster
- work
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a semi-supervised approach using unsupervised
  anomaly detection to identify vehicle hijacking-related tweets. The authors extracted
  tweets containing the keyword "hijacking" and processed them using TF-IDF vectorization.
---

# Semi-Supervised Anomaly Detection for the Determination of Vehicle Hijacking Tweets

## Quick Facts
- arXiv ID: 2308.10036
- Source URL: https://arxiv.org/abs/2308.10036
- Reference count: 20
- Primary result: CBLOF achieved 90% accuracy and 0.8 F1-score, slightly outperforming KNN (89% accuracy, 0.78 F1-score)

## Executive Summary
This study presents a semi-supervised approach using unsupervised anomaly detection to identify vehicle hijacking-related tweets. The authors extracted tweets containing the keyword "hijacking" and processed them using TF-IDF vectorization. Two anomaly detection algorithms were applied: K-Nearest Neighbour (KNN) and Cluster Based Outlier Factor (CBLOF). Results showed KNN achieved 89% accuracy and 0.78 F1-score, while CBLOF achieved 90% accuracy and 0.8 F1-score. The CBLOF method was selected as the preferred approach due to its slightly better performance and lower computational complexity. The work demonstrates the viability of unsupervised anomaly detection for filtering relevant hijacking tweets from social media data.

## Method Summary
The study collected Twitter data containing the keyword "hijacking" within 50km of Cape Town center, resulting in 426 total tweets (296 training, 130 test). Tweets were pre-processed using TF-IDF vectorization after removing stop words and the word "hijacking" itself. Two anomaly detection algorithms were implemented: KNN calculated average Euclidean distances from each test point to all points in the relevant cluster, while CBLOF measured distances from each test point to the centroid of the relevant cluster. Thresholds were determined as (1 + α) × max(average distances) for KNN (α = -0.01) and (1 + β) × max(distances) for CBLOF (β = -0.005). Performance was evaluated using accuracy, precision, recall, and F1-score metrics.

## Key Results
- KNN achieved 89% accuracy and 0.78 F1-score
- CBLOF achieved 90% accuracy and 0.8 F1-score
- CBLOF was selected as the preferred approach due to better performance and lower computational complexity
- Both methods successfully identified relevant hijacking tweets from social media data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: KNN anomaly detection succeeds because average distance to all k nearest neighbors in the relevant cluster acts as a global anomaly score.
- Mechanism: Each new tweet vector is compared to every vector in the relevant cluster, distances are averaged, and if the mean exceeds a threshold the tweet is labeled anomalous.
- Core assumption: The relevant tweet set forms a dense, cohesive cluster in TF-IDF space so that distances to neighbors are meaningful for anomaly scoring.
- Evidence anchors:
  - [abstract] States "KNN method produced an accuracy of 89%" and explains it calculates "the sum of distances to the k-nearest neighbours" for global anomaly detection.
  - [section II-A] Details the use of Euclidean distance and averaging across all k neighbors to compute a weight value.
  - [corpus] No direct support; the corpus papers focus on different domains and do not mention this specific KNN averaging approach.
- Break condition: If the relevant tweet set is too sparse or multi-modal, average distances become noisy and the threshold no longer cleanly separates outliers.

### Mechanism 2
- Claim: CBLOF anomaly detection works by measuring distance from a point to the centroid of a large cluster and scaling by cluster size.
- Mechanism: Treat the entire relevant tweet set as one large cluster, compute its centroid in TF-IDF space, and flag tweets whose distance to the centroid exceeds a threshold.
- Core assumption: One large homogeneous cluster adequately represents the normal tweet space, so outliers lie far from its centroid.
- Evidence anchors:
  - [abstract] Shows CBLOF achieving 90% accuracy and 0.8 F1-score, selecting it as preferred.
  - [section II-B] Explains outlier scoring as "distance to the centroid of its own cluster" multiplied by cluster size, with implementation using a single large cluster.
  - [corpus] No corpus evidence for this unweighted CBLOF variant; papers cited use standard or weighted CBLOF on different data.
- Break condition: If the relevant tweet set is heterogeneous, the single centroid will be a poor reference and distances will not reflect true anomaly status.

### Mechanism 3
- Claim: TF-IDF vectorization effectively separates relevant from irrelevant hijacking tweets by weighting distinctive terms.
- Mechanism: Convert each tweet into a weighted term vector, then feed these vectors to anomaly detectors; high weights for hijacking-specific terms pull relevant tweets into a tight cluster.
- Core assumption: Keywords like "hijacking" (removed during preprocessing) and related terms are strong indicators of relevance and vary significantly between relevant and irrelevant tweets.
- Evidence anchors:
  - [abstract] Mentions TF-IDF is used before anomaly detection and that relevant tweets are extracted from a larger dataset.
  - [section III-A] Explains TF-IDF weighting and removal of stop words, including "hijacking", to focus on discriminative features.
  - [corpus] No direct corpus support; the related papers use TF-IDF but not in this specific semi-supervised anomaly detection pipeline.
- Break condition: If irrelevant tweets also contain hijacking-related terms (e.g., retweets, news mentions), TF-IDF weighting may not separate classes cleanly.

## Foundational Learning

- Concept: Euclidean distance in high-dimensional vector spaces
  - Why needed here: Both KNN and CBLOF rely on distance calculations to score anomaly likelihood; misunderstanding the metric undermines the entire detection pipeline.
  - Quick check question: If tweet vectors are 100-dimensional, what is the Euclidean distance formula used to compare them?

- Concept: Clustering and centroid computation
  - Why needed here: CBLOF assumes a large cluster centroid represents the normal class; without grasping centroid calculation, the threshold logic is opaque.
  - Quick check question: How is the centroid of a set of TF-IDF vectors computed, and why does it serve as a reference for outlier detection?

- Concept: TF-IDF weighting and its effect on vector similarity
  - Why needed here: The preprocessing step determines the feature space in which anomaly detection operates; poor understanding leads to misinterpretation of detection results.
  - Quick check question: What happens to term weights if a word appears in most documents versus only a few, and how does this affect tweet clustering?

## Architecture Onboarding

- Component map: Tweet ingestion -> Keyword filtering ("hijacking") -> Manual labeling (relevant/irrelevant) -> TF-IDF vectorization -> Anomaly detection (KNN or CBLOF) -> Threshold tuning -> Classification output
- Critical path: Preprocess tweets -> Compute TF-IDF matrix -> Run anomaly detection -> Apply threshold -> Generate predictions -> Evaluate with Accuracy/Precision/Recall/F1
- Design tradeoffs:
  - Single large cluster assumption simplifies CBLOF but risks poor performance if relevant tweets are heterogeneous
  - Averaging all distances in KNN avoids k selection but may dilute sensitivity to local structure
  - Removing the keyword "hijacking" from TF-IDF features reduces noise but may discard useful discriminative signal
- Failure signatures:
  - Low precision with high recall suggests threshold too low, admitting many false positives
  - Uniform predictions (all relevant or all irrelevant) indicate threshold mis-calibration or feature space collapse
  - Poor F1-score despite high accuracy may signal class imbalance in the test set
- First 3 experiments:
  1. Verify TF-IDF output: print vector norms and top-weighted terms for a few relevant vs irrelevant tweets
  2. Test KNN with varying α: run with α = -0.01, -0.005, -0.001 and observe prediction shifts
  3. Test CBLOF with varying β: run with β = -0.005, -0.01, -0.001 and compare centroid distances and classification consistency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the performance of the semi-supervised anomaly detection approach compare to supervised learning methods on larger datasets?
- Basis in paper: [explicit] The paper states "In future, a comparison will be done between supervised learning methods and the unsupervised methods presented in this work on larger dataset."
- Why unresolved: The comparison between supervised and semi-supervised approaches on larger datasets has not been conducted yet.
- What evidence would resolve it: Conducting experiments comparing supervised learning methods (e.g., CNN, as mentioned in the paper) with the proposed semi-supervised anomaly detection approach on larger datasets, measuring performance metrics like accuracy, precision, recall, and F1-score.

### Open Question 2
- Question: How would the performance of the KNN and CBLOF algorithms change with different feature extraction methods beyond TF-IDF?
- Basis in paper: [explicit] The paper mentions that future work will involve optimization mechanisms, and the authors discuss the use of TF-IDF for feature extraction.
- Why unresolved: The paper only evaluates the performance of KNN and CBLOF using TF-IDF for feature extraction, leaving the impact of other feature extraction methods unexplored.
- What evidence would resolve it: Implementing and testing alternative feature extraction methods (e.g., word embeddings, semantic features) and comparing their performance with the current TF-IDF approach using the same anomaly detection algorithms.

### Open Question 3
- Question: How sensitive are the KNN and CBLOF algorithms to the selection of the threshold values (α and β) in real-world applications with varying data distributions?
- Basis in paper: [inferred] The paper discusses the importance of selecting appropriate threshold values (α and β) for both algorithms and how different values affect performance, but does not explore the sensitivity of these thresholds to real-world data variations.
- Why unresolved: The paper only tests a limited range of threshold values and does not investigate how these thresholds perform with data from different distributions or contexts.
- What evidence would resolve it: Conducting experiments with datasets from different domains and distributions to evaluate how the performance of KNN and CBLOF changes with varying threshold values, identifying the robustness and adaptability of the algorithms.

## Limitations
- Single-cluster assumption may oversimplify the true structure of relevant hijacking tweets
- Threshold optimization procedure lacks transparency and detailed methodology
- Preprocessing choice to remove "hijacking" keyword may eliminate discriminative information

## Confidence
- KNN and CBLOF implementation details: Medium
- Threshold optimization methodology: Low
- Generalizability to other datasets: Low

## Next Checks
1. Test both algorithms on a held-out validation set with different class ratios to verify threshold stability
2. Compare performance against baseline supervised classifiers using the same feature space
3. Analyze the distribution of TF-IDF vectors to confirm the single-cluster assumption is reasonable for this dataset