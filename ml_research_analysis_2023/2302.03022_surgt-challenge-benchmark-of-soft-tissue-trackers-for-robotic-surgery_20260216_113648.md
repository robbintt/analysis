---
ver: rpa2
title: 'SurgT challenge: Benchmark of Soft-Tissue Trackers for Robotic Surgery'
arxiv_id: '2302.03022'
source_url: https://arxiv.org/abs/2302.03022
tags:
- tracking
- bounding
- frames
- video
- case
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The SurgT challenge established the first benchmark for assessing
  soft-tissue trackers in robotic surgery. The challenge provided a dataset of 157
  stereo endoscopic videos from 20 clinical cases, with stereo camera calibration
  parameters.
---

# SurgT challenge: Benchmark of Soft-Tissue Trackers for Robotic Surgery

## Quick Facts
- **arXiv ID**: 2302.03022
- **Source URL**: https://arxiv.org/abs/2302.03022
- **Reference count**: 19
- **Primary result**: First benchmark for soft-tissue trackers in robotic surgery using unsupervised deep learning, with top EAO score of 0.617

## Executive Summary
The SurgT challenge established the first benchmark for assessing soft-tissue trackers in robotic surgery by providing a dataset of 157 stereo endoscopic videos from 20 clinical cases. The challenge encouraged development of unsupervised deep learning methods to track soft-tissue movement without manual annotations, addressing the lack of annotated surgical data. The top-performing method achieved an EAO score of 0.617 using ARFlow for unsupervised dense optical flow estimation, demonstrating that effective tracking is possible without supervised training data.

## Method Summary
The challenge provided 157 stereo endoscopic videos with stereo camera calibration parameters for developing unsupervised deep learning tracking algorithms. Participants were tasked with tracking soft-tissue movement represented by bounding boxes, evaluated using Expected Average Overlap (EAO) score. The top method used ARFlow for unsupervised dense optical flow estimation, trained with photometric consistency, forward-backward error, and regularization losses. Trackers were initialized at anchor points spaced approximately every 50 frames to reduce drift accumulation, and bounding boxes were projected into 3D space using stereo calibration for comprehensive evaluation.

## Key Results
- Top-performing method (ICVS-2Ai) achieved EAO score of 0.617 using ARFlow-based unsupervised optical flow
- Dataset contained 157 stereo endoscopic videos from 20 clinical cases with reliable calibration parameters
- ARFlow achieved best performance through self-supervised learning with photometric consistency and regularization losses
- Anchor-based initialization reduced tracking drift compared to single-shot initialization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Unsupervised deep learning methods can effectively track soft-tissue in surgical videos without manual annotations
- Mechanism: Self-supervised losses (photometric consistency, forward-backward error, regularization) enable learning optical flow from consecutive image pairs
- Core assumption: Temporal consistency between adjacent frames contains sufficient supervisory signal
- Evidence anchors:
  - [abstract] "This challenge was to encourage the development of unsupervised deep learning methods, given the lack of annotated data in surgery."
  - [section] "ARFlow, an unsupervised dense optical flow estimator... trained using three losses: a photometric loss applied on non-occluded pixels..."
  - [corpus] Weak - only surgical context; no direct comparison to natural-scene unsupervised tracking
- Break condition: Insufficient texture or motion cues in surgical scenes may cause self-supervision to fail

### Mechanism 2
- Claim: Stereo camera calibration enables 3D tracking by projecting 2D detections into 3D space
- Mechanism: Bounding boxes from left/right images are matched via epipolar geometry and disparity to triangulate 3D position
- Core assumption: Accurate rectification and calibration ensure keypoints obey horizontal epipolar geometry
- Evidence anchors:
  - [section] "Given that the input images are rectified... it is possible to project the target point into 3D... Using this disparity value, the keypoint is projected into the 3D space."
  - [section] "The quality of these parameters was checked by verifying that the keypoints respect horizontal epipolar geometry after stereo rectification."
  - [corpus] Weak - no direct evidence of calibration robustness in noisy surgical environments
- Break condition: Inaccurate calibration or non-rigid tissue deformation will degrade 3D tracking accuracy

### Mechanism 3
- Claim: Anchor-based initialization reduces sensitivity to tracking drift
- Mechanism: Trackers initialized at multiple anchor points spaced along video, with final score aggregated over all anchors
- Core assumption: Some anchor points will be in suitable conditions for reliable initialization
- Evidence anchors:
  - [section] "Successive anchors were roughly spaced by 50 frames, while always ensuring that anchor points are set on frames with clearly visible keypoints."
  - [section] "This ensures that only suitable initial tracking targets are given... instead of starting at a fixed predefined frame for all videos."
  - [corpus] Missing - no comparative study on anchor frequency impact
- Break condition: All anchor points falling in difficult frames (occlusion, blur) eliminates advantage over single-shot initialization

## Foundational Learning

- **Concept**: Intersection over Union (IoU) and its role in bounding box overlap metrics
  - Why needed here: EAO score is weighted average of IoU scores over time; essential for interpreting tracker performance
  - Quick check question: If predicted box has IoU = 0.2 with ground truth, does this count as tracking failure under 0.1 IoU threshold?

- **Concept**: Photometric consistency loss in self-supervised learning
  - Why needed here: ARFlow and similar methods rely on photometric consistency to learn optical flow without labels
  - Quick check question: What happens to photometric loss when tracked tissue is occluded by surgical instrument?

- **Concept**: Stereo rectification and disparity computation
  - Why needed here: 3D metrics require projecting 2D detections into 3D space; rectification and disparity are core to this pipeline
  - Quick check question: If left/right images are not perfectly rectified, how does this affect disparity calculation and 3D accuracy?

## Architecture Onboarding

- **Component map**: Data pipeline -> Stereo rectification -> Anchor point extraction -> Frame preprocessing -> Tracking engine (CSRT/TransT/UDT/ARFlow) -> Evaluation module (IoU computation -> 2D/3D failure detection -> Robustness/accuracy scoring -> EAO aggregation) -> Dataset interface

- **Critical path**: Load stereo pair and calibration → Rectify images → Initialize tracker at anchor → For each frame until failure or end: Predict bounding box(es) → Compute IoU/3D error → Check failure conditions → Aggregate scores across anchors

- **Design tradeoffs**:
  - 2D vs 3D tracking: 2D is faster but ignores depth; 3D gives richer info but requires accurate calibration
  - Anchor spacing: Closer anchors reduce drift but increase computation; farther anchors risk long drift sequences
  - Self-supervised vs supervised: No labels needed, but potentially lower accuracy; supervised can leverage large natural datasets but may not generalize

- **Failure signatures**:
  - IoU consistently < 0.1 for 10+ frames → 2D tracking failure
  - 3D error > 10 cm or disparity ≤ 0 for 10+ frames → 3D tracking failure
  - "ignore" frames clustered → dataset or annotation issue

- **First 3 experiments**:
  1. Baseline: Run CSRT on validation set, verify EAO ≈ 0.29; confirm evaluation pipeline
  2. Stereo check: Project left/right centroids into 3D using calibration; verify disparity consistency
  3. Self-supervision ablation: Train ARFlow with photometric loss only vs full loss; compare validation EAO

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the velocity of the tracked soft tissue in 3D space affect the performance of tracking algorithms?
- Basis in paper: [inferred] Validation subset had lower scores than test subset, with greater average 3D velocity in validation
- Why unresolved: Paper hypothesizes relationship between 3D velocity and tracking performance but lacks detailed analysis
- What evidence would resolve it: Comprehensive study comparing tracking performance across different 3D velocities of soft tissue

### Open Question 2
- Question: Would a tracker that jointly estimates the bounding boxes on both left and right views obtain better results than tracking each view separately?
- Basis in paper: [inferred] Paper suggests exploring joint estimation of bounding boxes on both views
- Why unresolved: No results or analysis on performance of joint estimation in stereo endoscopic videos
- What evidence would resolve it: Developing and testing tracking algorithm that jointly estimates bounding boxes on both views

### Open Question 3
- Question: How does the texture of the soft tissue surface around the bounding box affect the tracking performance?
- Basis in paper: [inferred] Case 5 of test subset was most challenging with low texture in image region around bounding box
- Why unresolved: No detailed analysis of impact of surface texture on tracking performance
- What evidence would resolve it: Study comparing tracking performance across different levels of surface texture

## Limitations
- Dataset limited to 20 clinical cases, potentially limiting generalizability across surgical procedures
- ARFlow-based approach assumes sufficient texture and motion cues, which may not hold in low-contrast or highly deformable tissue regions
- Anchor-based initialization strategy increases computational overhead without clear tradeoff analysis

## Confidence
- **High Confidence**: EAO metric definition and evaluation protocol are well-specified and reproducible
- **Medium Confidence**: Unsupervised learning mechanism works as described, but comparative performance against supervised approaches is lacking
- **Medium Confidence**: Stereo-based 3D tracking is technically sound, but calibration robustness in surgical environments needs validation
- **Low Confidence**: Optimal anchor spacing of 50 frames is heuristic without systematic analysis

## Next Checks
1. **Calibration Robustness Test**: Systematically degrade stereo calibration parameters (epipolar error, baseline variation) and measure EAO degradation to establish error tolerance thresholds
2. **Cross-Procedure Generalization**: Evaluate top-performing trackers on surgical videos from different procedures to assess domain adaptation requirements
3. **Supervised vs Unsupervised Benchmark**: Train equivalent tracker with synthetic annotations or transfer from natural video datasets to quantify performance gap and identify specific failure modes of self-supervision