---
ver: rpa2
title: Unifying Token and Span Level Supervisions for Few-Shot Sequence Labeling
arxiv_id: '2307.07946'
source_url: https://arxiv.org/abs/2307.07946
tags:
- span
- few-shot
- https
- network
- labeling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a Consistent Dual Adaptive Prototypical (CDAP)
  network for few-shot sequence labeling. The key idea is to unify token-level and
  span-level supervisions by jointly training two networks: a token-level network
  and a span-level network.'
---

# Unifying Token and Span Level Supervisions for Few-Shot Sequence Labeling

## Quick Facts
- arXiv ID: 2307.07946
- Source URL: https://arxiv.org/abs/2307.07946
- Reference count: 40
- Key outcome: CDAP model achieves state-of-the-art results, outperforming existing methods by 2.58% to 3.68% in F1 score on FewNERD dataset, 1.12% to 1.38% on SNIPS dataset, and 2.5% to 8.37% on Cross dataset.

## Executive Summary
This paper addresses the challenge of few-shot sequence labeling by proposing a Consistent Dual Adaptive Prototypical (CDAP) network that unifies token-level and span-level supervisions. The key insight is that token-level and span-level approaches have complementary weaknesses - token-level classification struggles with multi-token entity integrity while span-level classification suffers from sparse positive samples. By jointly training both networks and aligning their predictions through a consistent loss based on bidirectional Kullback-Leibler divergence with temperature, the model leverages the strengths of both granularities to improve overall performance.

## Method Summary
The CDAP model consists of two networks: a token-level network and a span-level network, both using Adaptive Prototypical Networks (APN). The token-level network classifies individual tokens using attention-weighted prototypes that emphasize support tokens relevant to each query. The span-level network classifies spans using a cross-attention module to model interactions between support and query spans, followed by a Transformer layer for enhancement. A consistent loss based on bidirectional KL divergence with temperature aligns the predictions of the two networks. During inference, a consistent greedy algorithm combines the predictions from both networks to produce final labels.

## Key Results
- Achieves new state-of-the-art results on FewNERD, SNIPS, and Cross benchmark datasets
- Outperforms existing methods by 2.58% to 3.68% in F1 score on FewNERD dataset
- Demonstrates effectiveness across 5-shot, 10-shot, and 20-shot settings on multiple datasets

## Why This Works (Mechanism)

### Mechanism 1
Joint training of token-level and span-level networks improves few-shot sequence labeling by addressing complementary weaknesses. Token-level classification struggles with multi-token entity integrity, while span-level classification struggles with sparse positive samples. By training both simultaneously and aligning their predictions via consistent loss, each compensates for the other's limitations.

### Mechanism 2
Adaptive prototypes improve few-shot performance by dynamically weighting support tokens based on query similarity. Instead of averaging all tokens of a class, the model computes attention weights between each query token and all support tokens of that class, then constructs a prototype as a weighted sum. This emphasizes informative tokens for the specific query.

### Mechanism 3
Cross-attention between support and query spans enhances span representation by modeling semantic interactions. The model computes attention between each span in the support set and all spans in the query set (and vice versa), then uses these attended representations as input to a Transformer layer for final enhancement.

## Foundational Learning

- Concept: Prototypical Networks
  - Why needed here: Understanding the baseline metric learning approach that this paper extends with adaptive weighting and dual granularity
  - Quick check question: How does a prototypical network compute class prototypes, and what assumption does this make about the data?

- Concept: Kullback-Leibler Divergence
  - Why needed here: The consistent loss uses bidirectional KL divergence with temperature to align predictions between networks
  - Quick check question: What does KL divergence measure, and why might bidirectional KL be preferred over unidirectional for alignment?

- Concept: Cross-Attention
  - Why needed here: The span-level network uses cross-attention to model interactions between support and query spans
  - Quick check question: How does cross-attention differ from self-attention, and what information does it capture?

## Architecture Onboarding

- Component map: BERT encoder → Token-level Adaptive Prototypical Network (with adaptive prototypes) → Span-level Adaptive Prototypical Network (with cross-attention, fine-grained O division) → Consistent Loss → Consistent Greedy Inference Algorithm
- Critical path: BERT encoding → dual network classification → consistent loss alignment → inference combination
- Design tradeoffs: Parameter efficiency vs. performance (adding span network increases parameters but improves results); computational complexity vs. accuracy (cross-attention and span enumeration increase cost)
- Failure signatures: Inconsistent predictions between networks suggest poor alignment; high FP-Span rate indicates boundary detection issues; poor performance on Inter setting suggests domain adaptation problems
- First 3 experiments:
  1. Verify that token-level network alone performs worse than full model on FewNERD development set
  2. Test different temperature values in consistent loss to find optimal alignment strength
  3. Compare inference using only span network vs. only token network vs. combined approach on development set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CDAP change when using different token-level and span-level network architectures beyond the Adaptive Prototypical Networks (APNs)?
- Basis in paper: [inferred] The paper demonstrates effectiveness using APNs but does not explore alternative architectures for token-level and span-level networks.
- Why unresolved: The paper only uses APNs for both networks, leaving open whether other architectures (e.g., Transformer-based, CNN-based) would yield better or worse performance.
- What evidence would resolve it: Experiments comparing CDAP with different token-level and span-level network architectures while keeping the consistent loss and inference algorithm fixed.

### Open Question 2
- Question: How does the proposed O class division strategy (based on left and right boundary tokens) perform on datasets with different entity density characteristics?
- Basis in paper: [explicit] The paper proposes a fine-grained O division strategy and compares it to Wang et al.'s method, but doesn't explore its effectiveness across datasets with varying entity densities.
- Why unresolved: The paper only evaluates the division strategy on FewNERD dataset, without testing its effectiveness on datasets with significantly different entity density patterns.
- What evidence would resolve it: Comparative experiments on datasets with varying entity densities (e.g., sparse vs. dense NER datasets) using different O division strategies.

### Open Question 3
- Question: What is the impact of CDAP's performance when applied to languages with different morphological characteristics or word segmentation challenges?
- Basis in paper: [inferred] The paper only evaluates CDAP on English datasets, leaving the model's effectiveness on other languages unexplored.
- Why unresolved: The paper demonstrates effectiveness on English datasets but doesn't investigate whether the model's performance is consistent across languages with different linguistic properties.
- What evidence would resolve it: Experiments applying CDAP to datasets in languages with varying morphological complexity and word segmentation requirements (e.g., Chinese, Arabic, or morphologically rich languages).

## Limitations

- The exact hyperparameter values (λ, β, γ, δ, T) are not explicitly provided, creating uncertainty in reproduction
- The specific implementation details of the Adaptive Prototypical Network and cross-attention module are vaguely specified
- The paper lacks ablations isolating the contribution of cross-attention and adaptive prototypes to overall performance

## Confidence

- **High**: The core mechanism of dual supervision (token + span) is logically sound and well-motivated by complementary weaknesses in granularity-specific approaches
- **Medium**: The adaptive prototype mechanism's benefits depend on the assumption that support tokens vary in relevance to queries, but lacks direct ablations comparing adaptive vs. fixed prototypes
- **Low**: The claim that cross-attention significantly enhances span representations is weakly supported with no ablations isolating cross-attention's contribution

## Next Checks

1. **Ablation on adaptive prototypes**: Train a variant of the token-level network without adaptive weighting (fixed averaging) and compare performance on FewNERD development set
2. **Cross-attention isolation**: Train a span-level network with and without cross-attention on FewNERD development set and compare performance to quantify cross-attention's marginal contribution
3. **Alternative alignment methods**: Replace bidirectional KL divergence with cosine similarity or Jensen-Shannon divergence in the consistent loss and evaluate if performance changes significantly