---
ver: rpa2
title: Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement
  Learning
arxiv_id: '2307.02689'
source_url: https://arxiv.org/abs/2307.02689
tags:
- action
- nesta
- learning
- games
- symbolic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of improving generalization in
  text-based reinforcement learning (RL) agents, which often struggle with unseen
  scenarios. The authors propose a neuro-symbolic approach called NESTA (NEuro Symbolic
  Textual Agent) that combines a semantic parser with a rule induction system to learn
  abstract, interpretable rules as policies.
---

# Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning

## Quick Facts
- arXiv ID: 2307.02689
- Source URL: https://arxiv.org/abs/2307.02689
- Reference count: 9
- One-line primary result: NESTA outperforms state-of-the-art BiKE+CBR agent on hard text-based games with up to 5x fewer training interactions

## Executive Summary
This paper addresses the challenge of generalization in text-based reinforcement learning agents, which often fail on unseen scenarios. The authors propose NESTA (NEuro Symbolic Textual Agent), a neuro-symbolic approach that combines semantic parsing with rule induction to learn abstract, interpretable rules as policies. By using Abstract Meaning Representation (AMR) as a semantic representation and transforming it into symbolic triples for Inductive Logic Programming (ILP), NESTA achieves significant improvements in generalization and sample efficiency compared to deep RL techniques. The method is evaluated on established text-based game benchmarks, showing better performance on hard games with fewer training interactions.

## Method Summary
NESTA uses a modular approach combining a semantic parser (AMR-to-triples) with an ILP-based rule learner (LNN) and action pruning. The system first converts text observations into AMR graphs, then transforms these into symbolic triples augmented with commonsense knowledge from ConceptNet. These triples are used by LNN-based ILP to learn Horn clauses as action rules through policy gradient optimization. An action parser prunes invalid actions based on lookahead analysis, and a consensus-based outlier rejection method filters noisy training samples. The entire pipeline is trained end-to-end on text-based games, with the semantic parser kept fixed and only the rule learner updated.

## Key Results
- NESTA outperforms BiKE+CBR agent by a large margin on hard text-based games in terms of normalized score and steps to reach goal
- Achieves up to 5x fewer training interactions compared to traditional text-based RL agents
- Demonstrates better generalization to unseen test games through entity-agnostic symbolic rules
- Shows improved sample efficiency by modularizing language understanding from RL policy learning

## Why This Works (Mechanism)

### Mechanism 1
Symbolic rules learned by ILP generalize better to unseen entities because they operate on abstract logical relations rather than entity-specific embeddings. The ILP system learns lifted Horn clauses from symbolic triples derived from AMR, making rules entity-agnostic and applicable to new objects without retraining.

### Mechanism 2
Modular separation of language understanding (AMR parsing) from policy learning (ILP) allows the system to leverage advances in semantic parsing while focusing ILP solely on reward optimization. This reduces the learning burden on ILP and improves sample efficiency.

### Mechanism 3
Outlier rejection via consensus-based noise filtering improves rule learning robustness by eliminating noisy samples caused by AMR errors or credit assignment issues. Multiple ILP models are trained on subsets of data, selecting the model with smallest training error to mitigate noise.

## Foundational Learning

- **Concept: Abstract Meaning Representation (AMR)** - Why needed: AMR provides a formal, graph-based semantic representation that can be deterministically converted to logical facts for ILP. Quick check: Can you explain how AMR nodes become predicates and edges become arguments in the triple conversion?
- **Concept: Inductive Logic Programming (ILP) with Logical Neural Networks (LNN)** - Why needed: ILP learns human-interpretable Horn clauses from examples, and LNN makes this process differentiable and reward-aware. Quick check: How does LNN's Łukasiewicz t-norm differ from standard neural activation functions?
- **Concept: Partially Observable Markov Decision Process (POMDP) formulation** - Why needed: Text-based games are naturally partially observable, requiring reasoning over incomplete state information. Quick check: Why can't we use a standard MDP formulation for text-based games?

## Architecture Onboarding

- **Component map**: Semantic Parser (AMR-to-triples) → Rule Learner (LNN-based ILP) → Pruner (action pruning) → Environment (text-based game)
- **Critical path**: Observation → AMR parsing → Symbolic fact extraction → ILP rule matching → Action probability → Pruned action selection → Environment step
- **Design tradeoffs**: Modular design allows leveraging advances in semantic parsing but introduces parsing latency; symbolic rules are interpretable but may be less expressive than neural policies
- **Failure signatures**: Poor generalization suggests AMR parsing errors; low sample efficiency suggests ILP not learning effective rules; high computational cost suggests inefficient LNN operations
- **First 3 experiments**:
  1. Run with a pre-trained AMR parser on a simple text-based game to verify symbolic fact extraction works correctly
  2. Train ILP rules on a single game with known optimal policy to verify rule learning capability
  3. Test generalization by training on one game configuration and testing on a different entity set to verify abstraction works

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does NESTA's performance scale to larger and more complex text-based games beyond the TWC benchmark?
- Basis in paper: The paper mentions that NESTA was evaluated on the TWC benchmark and shows good performance, but does not explore its scalability to larger games.
- Why unresolved: The paper does not provide evidence or analysis of NESTA's performance on more complex games beyond the TWC benchmark.
- What evidence would resolve it: Testing NESTA on a variety of larger and more complex text-based games and comparing its performance to other state-of-the-art methods.

### Open Question 2
- Question: How does the performance of NESTA change with different semantic parsers or AMR representations?
- Basis in paper: The paper uses a specific AMR parser (StructBART) and a deterministic AMR-to-triples approach, but does not explore the impact of using different parsers or AMR representations.
- Why unresolved: The paper does not provide evidence or analysis of how different semantic parsers or AMR representations affect NESTA's performance.
- What evidence would resolve it: Experimenting with different semantic parsers and AMR representations and comparing their impact on NESTA's performance.

### Open Question 3
- Question: How does the performance of NESTA change with different rule induction methods or ILP systems?
- Basis in paper: The paper uses Logical Neural Networks (LNN) as the rule induction system, but does not explore the impact of using different rule induction methods or ILP systems.
- Why unresolved: The paper does not provide evidence or analysis of how different rule induction methods or ILP systems affect NESTA's performance.
- What evidence would resolve it: Experimenting with different rule induction methods or ILP systems and comparing their impact on NESTA's performance.

### Open Question 4
- Question: How does the performance of NESTA change with different action pruning strategies or lookahead methods?
- Basis in paper: The paper uses a specific action pruning strategy based on lookahead, but does not explore the impact of using different action pruning strategies or lookahead methods.
- Why unresolved: The paper does not provide evidence or analysis of how different action pruning strategies or lookahead methods affect NESTA's performance.
- What evidence would resolve it: Experimenting with different action pruning strategies or lookahead methods and comparing their impact on NESTA's performance.

### Open Question 5
- Question: How does the performance of NESTA change with different noise rejection methods or outlier rejection strategies?
- Basis in paper: The paper uses a consensus-based noise rejection method, but does not explore the impact of using different noise rejection methods or outlier rejection strategies.
- Why unresolved: The paper does not provide evidence or analysis of how different noise rejection methods or outlier rejection strategies affect NESTA's performance.
- What evidence would resolve it: Experimenting with different noise rejection methods or outlier rejection strategies and comparing their impact on NESTA's performance.

## Limitations
- Performance is ultimately bounded by AMR parsing accuracy, creating a potential bottleneck
- Outlier rejection method is described but not fully specified, making robustness assessment difficult
- Evaluation focuses on relatively simple text-based games, leaving scalability to complex real-world scenarios unclear

## Confidence
- **High confidence**: The claim that symbolic rules generalize better to unseen entities due to their abstract, lifted nature is well-supported by experimental results
- **Medium confidence**: The assertion that modular separation leads to sample efficiency is plausible but not definitively proven
- **Low confidence**: The effectiveness of the consensus-based outlier rejection method is not fully validated due to incomplete specification

## Next Checks
1. **Parsing Accuracy Analysis**: Measure AMR parser accuracy on held-out validation set and correlate parsing errors with RL performance drops to quantify bottleneck
2. **Ablation Study on Outlier Rejection**: Remove outlier rejection step and retrain to measure its contribution to performance, isolating its effect from other components
3. **Stress Test on Novel Entities**: Train NESTA on games with limited entity vocabulary and test on games with completely unseen entities to rigorously evaluate generalization claims