---
ver: rpa2
title: Dynamic Visual Semantic Sub-Embeddings and Fast Re-Ranking
arxiv_id: '2309.08154'
source_url: https://arxiv.org/abs/2309.08154
tags:
- semantic
- image
- uncertainty
- different
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of accurately measuring similarity
  between images and text in cross-modal retrieval, particularly the issue of semantic
  ambiguity and redundancy arising from visual modality's richer semantic variations.
  The authors propose the Dynamic Visual Semantic Sub-Embdings (DVSE) framework to
  reduce information entropy by generating heterogeneous visual sub-embeddings through
  dynamic orthogonal constraints and employing variance-aware weighting to assign
  different optimization weights.
---

# Dynamic Visual Semantic Sub-Embeddings and Fast Re-Ranking

## Quick Facts
- arXiv ID: 2309.08154
- Source URL: https://arxiv.org/abs/2309.08154
- Authors: 
- Reference count: 35
- Primary result: Achieves 1-5% recall gains across MSCOCO, Flickr30K, and CUB Captions datasets using dynamic visual sub-embeddings and variance-aware weighting

## Executive Summary
This paper addresses the challenge of semantic ambiguity in image-text retrieval by proposing a Dynamic Visual Semantic Sub-Embeddings (DVSE) framework. The approach generates multiple heterogeneous visual sub-embeddings through dynamic orthogonal constraints and employs variance-aware weighting to reduce redundancy and improve semantic correspondence. A Fast Re-ranking (FR) strategy is introduced to enhance retrieval results through softmax normalization of similarity matrices. Experiments demonstrate significant performance improvements over existing methods, with consistent gains across multiple evaluation metrics and datasets.

## Method Summary
The DVSE framework extracts pre-trained BUTD features for images and Bi-GRU/BERT features for text, then generates K=4 heterogeneous visual sub-embeddings using MLPs with orthogonal constraints. A variance-aware weighting mechanism assigns different optimization weights based on uncertainty estimation from negative sample similarities. The Fast Re-ranking strategy applies softmax normalization to similarity matrices in both row and column directions to suppress hard negatives. The model is trained with triplet loss and evaluated on MSCOCO, Flickr30K, and CUB Captions datasets using Recall@1, Recall@5, and Recall@10 metrics.

## Key Results
- 1-5% absolute improvement in Recall@1 across all three datasets compared to state-of-the-art methods
- Consistent performance gains across multiple evaluation settings (image-to-text and text-to-image retrieval)
- Ablation studies confirm the effectiveness of both multi-view structure and variance-aware weighting components
- Fast Re-ranking strategy provides additional performance boost without significant computational overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic Visual Semantic Sub-Embeddings reduce information entropy by generating multiple heterogeneous visual sub-embeddings through dynamic orthogonal constraints.
- Mechanism: The framework generates K different views of visual embeddings from each image region using MLPs, each view capturing different semantic aspects. These views are then combined with textual embeddings and weighted by uncertainty-aware loss to focus optimization on diverse semantic variations.
- Core assumption: Different orthogonal projections of the same visual features can capture complementary semantic information.
- Evidence anchors:
  - [abstract] "we obtain a set of heterogeneous visual sub-embeddings through dynamic orthogonal constraint loss"
  - [section] "we use a two-layer MLP to extract multi-view features from each image region feature"
  - [corpus] Weak evidence; related papers discuss semantic variations but not specifically orthogonal constraint loss mechanisms
- Break condition: If the orthogonal projections become too similar or if the views start capturing redundant information rather than complementary aspects

### Mechanism 2
- Claim: Variance-aware weighting loss assigns different optimization weights to different semantic variations, reducing redundancy.
- Mechanism: The model calculates variance of similarity scores across all negative samples to estimate uncertainty, then uses this variance as weights for different view-text losses. Lower variance (higher confidence) views get higher weights.
- Core assumption: Variance in similarity scores across negative samples is a reliable proxy for uncertainty in semantic correspondence.
- Evidence anchors:
  - [abstract] "employ a variance-aware weighting to assign different optimization weights"
  - [section] "the variance term for each view-text is calculated as follows: œÉ¬≤‚Çñ,ùêº‚ÇãùëÜ = ùë£ùëéùëü (ùë† (ùêºùëñ,ùëò, ùëÜùëó ‚Ä≤ )| ùëó ‚Ä≤ = 1, ..., ùêµ, ùëó ‚Ä≤ ‚â† ùëñ)"
  - [corpus] No direct evidence; this appears to be a novel approach not covered in related papers
- Break condition: If variance-based uncertainty estimation becomes unreliable due to batch size effects or if the negative samples don't adequately represent the semantic space

### Mechanism 3
- Claim: Fast Re-ranking strategy improves retrieval results by normalizing similarity matrices using softmax criterion.
- Mechanism: The model applies softmax normalization to rows and columns of the similarity matrix, which suppresses the influence of hard negative samples by leveraging information from multiple retrievals.
- Core assumption: Normalizing the similarity matrix using softmax can effectively suppress hard negatives while preserving positive sample relationships.
- Evidence anchors:
  - [abstract] "develop a Fast Re-ranking strategy (FR) to efficiently evaluate the retrieval results and enhance the performance"
  - [section] "we apply the softmax criterion to matrix A. By normalizing each column of the matrix A, we obtain the matrix B"
  - [corpus] No direct evidence; re-ranking approaches exist but the specific normalization strategy appears novel
- Break condition: If the normalization parameter œÉ¬≤ is poorly tuned or if the assumption that hard negatives can be effectively suppressed breaks down

## Foundational Learning

- Concept: Multi-view representation learning
  - Why needed here: The method relies on generating multiple views of visual embeddings to capture diverse semantic aspects that single-view approaches miss
  - Quick check question: What happens to retrieval performance if you reduce the number of views from 4 to 1?

- Concept: Uncertainty estimation through variance
  - Why needed here: The framework uses variance of similarity scores as a proxy for uncertainty to weight different views differently during optimization
  - Quick check question: How does increasing batch size affect the variance calculation and subsequently the weighting of views?

- Concept: Softmax normalization for re-ranking
  - Why needed here: The re-ranking strategy applies softmax to similarity matrices to suppress hard negative samples and improve overall retrieval quality
  - Quick check question: What would happen to the re-ranking effectiveness if you normalize only rows but not columns?

## Architecture Onboarding

- Component map:
  - Image ‚Üí BUTD features ‚Üí Multi-view Generator ‚Üí Feature Aggregator ‚Üí K embeddings ‚Üí Similarity calculation ‚Üí Variance estimation ‚Üí Weight calculation ‚Üí Loss computation
  - Text ‚Üí Bi-GRU/BERT features ‚Üí Feature Aggregator ‚Üí Text embedding ‚Üí Similarity calculation

- Critical path: Image ‚Üí BUTD features ‚Üí Multi-view Generator ‚Üí Feature Aggregator ‚Üí K embeddings ‚Üí Similarity calculation ‚Üí Variance estimation ‚Üí Weight calculation ‚Üí Loss computation

- Design tradeoffs:
  - Number of views (K): More views capture more semantic variations but increase computation and risk of redundancy
  - Batch size: Larger batches provide more stable variance estimates but increase memory usage
  - Embedding dimension: Higher dimensions capture more information but increase computation and risk overfitting

- Failure signatures:
  - Performance degrades when K=1 (multi-view structure not contributing)
  - Accuracy drops with very large batch sizes (variance estimates become unstable)
  - Results become sensitive to the œÉ¬≤ parameter in re-ranking

- First 3 experiments:
  1. Vary K from 1 to 8 and measure impact on Recall@1 and Recall@SUM
  2. Test different batch sizes (64, 128, 256, 512) to find optimal variance estimation
  3. Compare re-ranking with and without column normalization to validate the two-directional approach

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in the main text. However, based on the discussion of future work, several areas for further research are implied:

- Exploring the scalability of the method to larger datasets and more complex retrieval tasks
- Investigating the impact of different feature extraction backbones on performance
- Extending the framework to handle multi-modal inputs beyond image-text pairs

## Limitations
- The orthogonal constraint loss mechanism is mentioned but not explicitly detailed in terms of implementation, making it difficult to verify whether it creates truly orthogonal projections or merely encourages diversity.
- The variance-based uncertainty weighting lacks sensitivity analysis to batch size variations, which could affect the reliability of the weighting scheme.
- The optimal temperature parameters for softmax normalization in the re-ranking strategy appear dataset-specific and may require tuning for different datasets.

## Confidence

- **High confidence** in the multi-view architecture effectiveness: The consistent performance improvements across three datasets (MSCOCO, Flickr30K, CUB Captions) with significant R@1 gains (1-5%) across multiple runs strongly support this claim.
- **Medium confidence** in the variance-aware weighting: While the mathematical formulation is clear and results are positive, the lack of alternative uncertainty measures comparison or sensitivity analysis to batch size limits definitive claims about this mechanism's superiority.
- **Medium confidence** in the Fast Re-ranking strategy: The softmax normalization approach is well-defined and shows consistent improvements, but the optimal temperature parameters (20 and 170) appear dataset-specific and may not generalize without tuning.

## Next Checks

1. **Ablation on uncertainty measures**: Replace variance-based weighting with entropy-based or confidence-based uncertainty measures and compare performance to isolate the effectiveness of the specific variance approach.

2. **Batch size sensitivity analysis**: Systematically vary batch sizes (32, 64, 128, 256) to measure impact on variance estimation stability and downstream retrieval performance, identifying optimal batch size ranges.

3. **Orthogonality verification**: Measure actual cosine similarity between the K=4 generated views to verify they are truly orthogonal vs. merely diverse, and assess correlation between orthogonality degree and performance gains.