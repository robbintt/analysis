---
ver: rpa2
title: On the link between generative semi-supervised learning and generative open-set
  recognition
arxiv_id: '2303.11702'
source_url: https://arxiv.org/abs/2303.11702
tags:
- samples
- space
- categories
- classi
- category
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study establishes a theoretical link between generative semi-supervised
  learning (SSL) and generative open-set recognition (OSR) using GANs. The key insight
  is that both SSL-GANs and OSR-GANs generate "bad-looking" samples in the complementary
  space (the area between and around classification boundaries) to regularize classifiers.
---

# On the link between generative semi-supervised learning and generative open-set recognition

## Quick Facts
- arXiv ID: 2303.11702
- Source URL: https://arxiv.org/abs/2303.11702
- Reference count: 40
- Primary result: Generative SSL and OSR share theoretical foundations through complementary space regularization

## Executive Summary
This study establishes a theoretical connection between generative semi-supervised learning (SSL) and generative open-set recognition (OSR) using GANs. The core insight is that both SSL-GANs and OSR-GANs generate "bad-looking" samples in the complementary space—the area between and around classification boundaries—to regularize classifiers. Through experimental comparison of state-of-the-art SSL-GANs (margin-GANs) and OSR-GANs (ARP-GANs), the research demonstrates that these models achieve superior SSL-OSR performance (CIFAR10: 96.35% accuracy | 91.75% AUROC) by generating samples with lower margins than labeled or novel categories. This unification provides a theoretical foundation for more practical and cost-efficient classifier training.

## Method Summary
The study compares FM-GANs and ARP-GANs under identical SSL-OSR conditions, implementing both models in shared codebase while training margin-GANs separately. The evaluation spans SVHN and CIFAR10 datasets with 100-400 labels per class, using CIFAR100 as novel category source. Key experiments include standard SSL benchmarks, supervised OSR tasks, and complex scenarios with mixed labeled/novel categories. The analysis focuses on embedding space characteristics, computing average margins for labeled, novel, and generated samples to validate their occupancy of complementary space.

## Key Results
- Margin-GANs achieve state-of-the-art SSL-OSR performance (CIFAR10: 96.35% accuracy | 91.75% AUROC)
- Generated samples from both SSL-GANs and OSR-GANs exhibit lower margins than labeled or novel categories
- K+1 category representations converge across different theoretical formulations despite distinct mathematical approaches
- The complementary space concept unifies SSL and OSR optimization objectives theoretically

## Why This Works (Mechanism)

### Mechanism 1
- Generated samples from both SSL-GANs and OSR-GANs occupy the complementary space between and around classification boundaries
- Both model types produce "bad-looking" samples that regularize classifiers by lowering confidence near decision boundaries
- These samples effectively represent the open space within the K+1 category through adversarial training
- Break condition: If generated samples move too close to labeled category centers, regularization effect diminishes

### Mechanism 2
- Margin-GANs achieve superior SSL-OSR performance through inverse cross-entropy loss minimizing classification margins for generated samples
- This pushes generated samples into complementary space, creating clearer separation between known, unknown, and generated samples
- Lower margins for generated samples consistently improve both SSL accuracy and OSR detection capability
- Break condition: Excessive margin minimization may cause generated samples to lose semantic similarity to real data

### Mechanism 3
- K+1 category in both SSL-GANs and OSR-GANs represents the same embedding space region despite different theoretical motivations
- FM-GANs use zero vector while ARP-GANs use reciprocal points, both capturing the region between labeled categories where novel samples appear
- Different mathematical formulations converge to similar embedding space representations when trained adversarially
- Break condition: Fundamental embedding space geometry differences due to architectural variations would prevent convergence

## Foundational Learning

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: The entire framework relies on adversarial training between generator and discriminator/classifier networks
  - Quick check question: Can you explain the minimax optimization problem in vanilla GANs and how it changes in SSL-GANs vs OSR-GANs?

- Concept: Semi-supervised Learning (SSL) principles
  - Why needed here: Understanding how unlabeled data is leveraged through consistency loss and pseudo-labeling is crucial for grasping the SSL-OSR connection
  - Quick check question: What's the difference between traditional pseudo-labeling and the teacher-student approach used in Margin-GANs?

- Concept: Open-set Recognition (OSR) evaluation metrics
  - Why needed here: AUROC and margin analysis are the primary evaluation tools, requiring understanding of how K+1 category setups work
  - Quick check question: How does thresholding the maximum probability score over K logits enable separation of novel categories in the K+1 category?

## Architecture Onboarding

- Component map: Generator → Discriminator/Classifier → K+1 category representation → Embedding space regularization
- Critical path: Generator produces complementary space samples → Classifier regularization → Embedding space convergence → Novel category detection
- Design tradeoffs: SSL optimization vs OSR optimization (Margin-GANs excel at SSL but ARP-GANs better at complex OSR), computational cost of three networks vs two networks, margin minimization strength vs sample quality
- Failure signatures: Generated samples occupying labeled category centers (overfitting), novel categories having margins similar to labeled categories (poor separation), KL divergence between real and generated distributions increasing
- First 3 experiments:
  1. CIFAR10 SSL with 400 labels per class - baseline SSL performance comparison between Margin-GANs and ARP-GANs
  2. CIFAR10 supervised with CIFAR100 as novel - pure OSR performance evaluation
  3. CIFAR10 with 6 labeled categories, 4 novel - complex OSR scenario testing category similarity effects

## Open Questions the Paper Calls Out

### Open Question 1
- What are the optimal margins for generated samples in complementary space to maximize both SSL and OSR performance?
- Basis: The study found discrepancies between margin-GANs (high SSL, low margins) and ARP-GANs (high OSR, high margins), suggesting a potential trade-off
- Why unresolved: Optimal margin balance remains unclear
- What evidence would resolve it: Systematic experiments varying margin thresholds and measuring resulting SSL/OSR performance across multiple datasets

### Open Question 2
- How does the size of the complementary space change as the number of categories increases, and how does this affect the effectiveness of SSL-OSR methods?
- Basis: The paper discusses how complementary space becomes more complex with higher K values but lacks empirical validation
- Why unresolved: Theoretical discussion about complementary space size with increasing categories not backed by experimental validation
- What evidence would resolve it: Experiments measuring model performance across datasets with varying numbers of categories (K=2, 5, 10, 20) while tracking complementary space characteristics

### Open Question 3
- Can the SSL-OSR framework be extended to handle class-incremental learning scenarios where novel categories need to be incorporated over time?
- Basis: The paper mentions OSR is a natural pre-step to achieving CIL but doesn't explore how SSL-OSR framework could support incremental learning
- Why unresolved: Study focuses on static SSL-OSR scenarios and doesn't address dynamic nature of CIL
- What evidence would resolve it: Development and testing of an SSL-OSR framework that can incrementally incorporate new categories while maintaining performance on existing categories

## Limitations

- Experimental scope remains narrow, focusing primarily on CIFAR10 and SVHN datasets with limited evaluation of more complex image datasets
- Theoretical link between complementary space and open space relies heavily on empirical observation rather than rigorous mathematical proof
- Assumption that different K+1 formulations converge to similar embedding representations needs further validation across diverse architectures and loss functions

## Confidence

- High confidence: Experimental results demonstrating Margin-GANs' superior SSL-OSR performance (96.35% accuracy, 91.75% AUROC on CIFAR10)
- Medium confidence: Theoretical mechanism explaining how "bad-looking" samples regularize classifiers in complementary space
- Medium confidence: Convergence assumption between different K+1 category implementations despite distinct mathematical formulations

## Next Checks

1. Extend experiments to include more challenging datasets (ImageNet, Places365) and real-world scenarios with significant domain shift
2. Conduct ablation studies isolating the effects of margin minimization vs consistency loss on SSL-OSR performance
3. Provide mathematical proof or more rigorous empirical validation of the convergence between complementary space and open space representations across different GAN architectures