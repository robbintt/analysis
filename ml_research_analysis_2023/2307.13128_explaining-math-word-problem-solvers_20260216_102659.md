---
ver: rpa2
title: Explaining Math Word Problem Solvers
arxiv_id: '2307.13128'
source_url: https://arxiv.org/abs/2307.13128
tags:
- words
- word
- accuracy
- mawps
- removed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates how neural math word problem (MWP) solvers
  make predictions by removing parts of speech and using input reduction. The authors
  show that models can still produce correct answers even after removing 62-68% of
  words, indicating they do not perform true semantic reasoning.
---

# Explaining Math Word Problem Solvers

## Quick Facts
- arXiv ID: 2307.13128
- Source URL: https://arxiv.org/abs/2307.13128
- Authors: 
- Reference count: 18
- Primary result: MWP solvers can produce correct answers with 62-68% of words removed, suggesting reliance on superficial patterns rather than semantic reasoning

## Executive Summary
This paper investigates how neural math word problem (MWP) solvers make predictions by systematically removing parts of speech and using input reduction techniques. The authors find that models can still produce correct answers even after removing 62-68% of words, indicating they do not perform true semantic reasoning. Removing single parts of speech (nouns, verbs, prepositions) causes only modest accuracy drops (2.1-16.6%). The MaWPS dataset exhibits low lexical diversity, with certain words appearing in 10-20% of problems of a given operation type. These findings suggest MWP solvers may rely on superficial patterns or trigger words rather than understanding the full problem semantics.

## Method Summary
The study uses RNN Seq2seq models trained on the MaWPS (2,373 MWPs) and ASDiv-A (1,218 MWPs) datasets. Numbers are replaced with placeholders like "number0" and "number1". The authors perform perturbation experiments by removing specific parts of speech (nouns, verbs, prepositions, adjectives) and evaluate model accuracy on these modified datasets. They also implement input reduction by iteratively removing the least important word based on confidence scores until the model produces incorrect predictions. The evaluation uses 5-fold cross-validation to assess model performance under various perturbation conditions.

## Key Results
- MWP solvers can still produce correct answers when 62-68% of words are removed from problems
- Removing single parts of speech causes only modest accuracy drops (2.1-16.6%)
- The MaWPS dataset has low lexical diversity, with certain words appearing in 10-20% of problems of a given operation type
- Models show more sensitivity to removing multiple parts of speech simultaneously than to removing any single part of speech

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Removing parts of speech from math word problems does not significantly degrade the model's ability to produce correct answers.
- Mechanism: The model relies on superficial patterns or trigger words rather than deep semantic understanding. When specific parts of speech (like nouns or verbs) are removed, the model can still infer the correct operation from remaining words or number tokens.
- Core assumption: The model is not performing true semantic reasoning but is instead matching input patterns to learned operations.
- Evidence anchors:
  - [abstract] The model can still manage to find a correct answer when given a nonsense question.
  - [section 4.2] Removal of any single part of speech does not appear to significantly affect either model.
  - [corpus] The model's ability to produce correct answers with significantly reduced input (62-68% of words removed) indicates reliance on superficial patterns.
- Break condition: If the model's accuracy drops significantly when removing any single part of speech or when removing more than 50% of words, the mechanism would break.

### Mechanism 2
- Claim: The model is more sensitive to the removal of multiple parts of speech simultaneously than to the removal of any single part of speech.
- Mechanism: The model uses a combination of parts of speech to determine the correct operation. Removing multiple parts of speech simultaneously reduces the available information for pattern matching.
- Core assumption: The model relies on the presence of multiple word types to make its predictions.
- Evidence anchors:
  - [section 4.2] The model's accuracy decreased by 31.2% when all nouns and verbs were removed, which is larger than the sum of the decreases from removing either part of speech alone.
  - [section 4.2] The MaWPS model was more affected by the removal of multiple parts of speech, indicating some overfitting to those words.
- Break condition: If the model's accuracy drops significantly when removing any single part of speech, the mechanism would break.

### Mechanism 3
- Claim: The model's performance is influenced by the lexical diversity of the training dataset.
- Mechanism: Low lexical diversity in the training dataset encourages the model to rely on the occurrence of specific words to classify problems into different operations.
- Core assumption: The model learns to associate specific words with specific operations due to their high frequency in the training data.
- Evidence anchors:
  - [section 5.2] The most popular words in the MaWPS dataset appear in 10-20% of all problems of a given type, indicating low lexical diversity.
  - [section 6.3] The model can still produce correct answers with over half of the information removed, suggesting reliance on specific words rather than semantic understanding.
- Break condition: If the model's performance is not significantly affected by the lexical diversity of the training dataset, the mechanism would break.

## Foundational Learning

- Concept: Parts of Speech and Their Functions
  - Why needed here: Understanding the role of different parts of speech in constructing the meaning of a sentence is crucial for analyzing the model's reliance on specific word types.
  - Quick check question: What is the function of nouns, verbs, and prepositions in a sentence, and how do they contribute to its overall meaning?

- Concept: Semantic Reasoning vs. Pattern Matching
  - Why needed here: Distinguishing between true semantic understanding and pattern matching is essential for interpreting the model's behavior when parts of speech are removed.
  - Quick check question: How can you tell if a model is performing semantic reasoning or simply matching input patterns to learned operations?

- Concept: Lexical Diversity and Its Impact on Model Performance
  - Why needed here: Understanding the relationship between lexical diversity in the training data and the model's reliance on specific words is crucial for interpreting the results of the word frequency analysis.
  - Quick check question: How does low lexical diversity in the training data affect the model's ability to generalize to new, unseen problems?

## Architecture Onboarding

- Component map: Input text -> Part-of-speech tagging and tokenization -> RNN Seq2seq model -> Mathematical equation output -> Accuracy evaluation
- Critical path: Input preprocessing (part-of-speech tagging and tokenization) -> Feeding the preprocessed input into the RNN Seq2seq model -> Generating the mathematical equation -> Evaluating the accuracy of the generated equation
- Design tradeoffs: Model complexity vs. interpretability (more complex models may achieve higher accuracy but are harder to interpret); Training data size vs. lexical diversity (larger datasets may improve model performance but may also introduce more bias if lexical diversity is low)
- Failure signatures: High accuracy on original dataset but low accuracy on perturbed datasets; Model's performance highly sensitive to removal of specific parts of speech; Model's performance not significantly affected by removal of more than 50% of words
- First 3 experiments:
  1. Remove common adjectives and evaluate the model's accuracy on the perturbed dataset.
  2. Remove all nouns and verbs simultaneously and evaluate the model's accuracy on the perturbed dataset.
  3. Use input reduction to iteratively remove the least important word and observe how many words can be removed before the model produces an incorrect answer.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent do neural MWP solvers rely on superficial patterns versus semantic reasoning when solving math word problems?
- Basis in paper: [explicit] The authors state that models can produce correct answers with 62-68% of words removed, suggesting they do not perform true semantic reasoning.
- Why unresolved: The study shows models can function with reduced input but doesn't definitively prove whether they use semantic reasoning when given complete problems or just trigger words.
- What evidence would resolve it: Testing models on systematically paraphrased problems while maintaining semantic content, or comparing performance on problems with and without semantically equivalent but lexically different phrasings.

### Open Question 2
- Question: What specific lexical patterns or trigger words do MWP solvers rely on most heavily for each operation type?
- Basis in paper: [explicit] The authors identify words that appear frequently in problems of specific operation types (10-20% frequency) but note these words don't appear to correlate with operations.
- Why unresolved: The frequency analysis shows common words but doesn't establish causation or determine which words are most predictive for model decisions.
- What evidence would resolve it: Controlled experiments removing individual high-frequency words and measuring impact on accuracy for each operation type, or training models on adversarially generated datasets with key words swapped.

### Open Question 3
- Question: How does increasing lexical diversity in MWP datasets affect model performance and reliance on trigger words?
- Basis in paper: [inferred] The authors note low lexical diversity in MaWPS and suggest creating more diverse datasets by using synonyms.
- Why unresolved: The current datasets have limited vocabulary diversity, making it unclear how models would perform with more varied linguistic expressions of the same mathematical concepts.
- What evidence would resolve it: Training and testing models on datasets with systematically increased lexical diversity (through synonym replacement or paraphrasing) and comparing performance and sensitivity to word removal.

## Limitations
- The findings are based on specific RNN Seq2seq models and may not generalize to other architectures like Transformers
- Part-of-speech tagging and word importance scoring mechanisms could introduce additional biases or errors
- The low lexical diversity finding, while suggestive, may not capture all aspects of dataset quality or model behavior

## Confidence

- Model reliance on superficial patterns: High
- Low lexical diversity in MaWPS dataset: High
- Semantic reasoning vs. pattern matching: Medium

## Next Checks

1. Test the same input reduction and part-of-speech removal experiments on a Transformer-based MWP solver to determine if the superficial pattern reliance is architecture-specific or a general phenomenon in neural MWP solvers

2. Create an augmented version of the MaWPS dataset with artificially increased lexical diversity and retrain the model to see if this reduces the trigger word effect and improves generalization

3. Design a controlled experiment where semantically equivalent problems use different trigger words to determine if the model truly relies on specific words or can generalize beyond lexical patterns