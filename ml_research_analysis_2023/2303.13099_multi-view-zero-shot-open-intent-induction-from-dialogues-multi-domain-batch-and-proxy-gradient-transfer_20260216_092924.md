---
ver: rpa2
title: 'Multi-View Zero-Shot Open Intent Induction from Dialogues: Multi Domain Batch
  and Proxy Gradient Transfer'
arxiv_id: '2303.13099'
source_url: https://arxiv.org/abs/2303.13099
tags:
- intent
- clustering
- dataset
- spectral
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of open intent induction in
  task-oriented dialogue systems, where new intents must be detected and induced without
  relying on predefined domain-specific training data. The authors propose a multi-view
  model combining three components: SBERT for general embedding (GE), Multi Domain
  Batch (MDB) for dialogue domain knowledge, and Proxy Gradient Transfer (PGT) for
  cluster-specialized semantics.'
---

# Multi-View Zero-Shot Open Intent Induction from Dialogues: Multi Domain Batch and Proxy Gradient Transfer

## Quick Facts
- arXiv ID: 2303.13099
- Source URL: https://arxiv.org/abs/2303.13099
- Reference count: 12
- Key outcome: Multi-view model combining SBERT, MDB, and PGT achieves up to 16% accuracy improvement on Banking and Finance datasets for zero-shot intent induction

## Executive Summary
This paper addresses the challenge of detecting and clustering new intents in task-oriented dialogue systems without relying on predefined domain-specific training data. The authors propose a multi-view approach that combines three components: SBERT for general embedding, Multi Domain Batch (MDB) for learning domain-agnostic dialogue knowledge, and Proxy Gradient Transfer (PGT) for cluster-specialized semantics. The method significantly outperforms baseline approaches on Banking and Finance datasets, with spectral clustering showing particular effectiveness for dialogue utterance grouping.

## Method Summary
The proposed method consists of three main components working in sequence. First, MDB trains a unified model on six different dialogue datasets in parallel using cosine softmax loss, learning domain-agnostic representations that prevent catastrophic forgetting. Second, PGT employs a Siamese network architecture to fine-tune the model for clustering by making the non-differentiable K-means operation differentiable through gradient transfer. Finally, the representations from all three components (GE, MDB, PGT) are concatenated and clustered using spectral clustering with Bayesian optimization for selecting the number of clusters K.

## Key Results
- MDB + PGT + Spectral clustering achieves up to 16% accuracy improvement over baseline methods on Banking and Finance datasets
- Spectral clustering consistently outperforms K-means when paired with the multi-view model
- MDB alone provides significant domain robustness, while PGT fine-tuning improves clustering-specific performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MDB improves clustering by learning domain-agnostic representations through parallel training on diverse dialogue datasets
- Mechanism: Parallel training with six dialogue datasets in cosine softmax loss framework captures common semantic patterns across domains
- Core assumption: Parallel training prevents catastrophic forgetting and enables generalization across domains
- Evidence anchors: Abstract states MDB "feeds diverse dialogue datasets to the model at once to tackle the multi-domain problem"; section 5.2 describes batching samples from six datasets

### Mechanism 2
- Claim: PGT improves clustering by fine-tuning the model to learn how to cluster through differentiable proxy gradients
- Mechanism: Siamese network architecture with one branch predicting hard cluster labels via K-means while the other generates soft labels
- Core assumption: The model can learn to produce representations that align with clustering objectives through gradient transfer
- Evidence anchors: Abstract describes PGT as "employing the Siamese network to fine-tune the model with a clustering method directly"; section 5.3 explains learning to interpret utterances in terms of clustering methods

### Mechanism 3
- Claim: Spectral clustering outperforms K-means for dialogue intent induction due to better handling of non-globular cluster shapes and connectivity
- Mechanism: Spectral clustering builds affinity matrix based on nearest neighbors and performs clustering in Laplacian embedding space
- Core assumption: Dialogue utterances form clusters with complex shapes that K-means cannot capture well
- Evidence anchors: Section 7 explains spectral clustering constructs affinity matrix using similarity based on nearest neighbors; section A.1 notes spectral clustering considers meaning of entire sentence filtering out noises

## Foundational Learning

- Concept: Siamese network architecture
  - Why needed here: Enables differentiable training for non-differentiable clustering objective by creating proxy learning signal
  - Quick check question: How does a Siamese network help when the target operation (K-means) has no gradient?

- Concept: Cosine softmax for multi-domain training
  - Why needed here: Allows parallel training across datasets with different label spaces without reconciling label vocabularies
  - Quick check question: Why use cosine similarity instead of dot product in final layer for multi-domain training?

- Concept: Spectral clustering and graph Laplacians
  - Why needed here: Captures cluster connectivity and handles non-globular shapes better than K-means, important for noisy dialogue data
  - Quick check question: What property of spectral clustering makes it more robust to noise than K-means?

## Architecture Onboarding

- Component map: GE (SBERT) -> MDB (Multi Domain Batch) -> PGT (Proxy Gradient Transfer) -> Spectral Clustering
- Critical path: 1) Train MDB module on six dialogue datasets in parallel 2) Initialize Siamese network with MDB weights 3) Run PGT fine-tuning using K-means clustering as target 4) Concatenate GE, MDB, and PGT representations 5) Apply spectral clustering with Bayesian optimization for K
- Design tradeoffs: Parallel multi-domain training increases batch complexity but improves generalization; Siamese network doubles parameter count during PGT but enables differentiable clustering; spectral clustering is computationally heavier than K-means but handles noise better
- Failure signatures: MDB fails with poor cross-domain generalization and catastrophic forgetting; PGT fails when gradients don't transfer effectively; spectral clustering fails when affinity matrix construction is unstable
- First 3 experiments: 1) Test MDB alone on single dataset vs sequential fine-tuning to verify domain robustness 2) Compare PGT vs standard supervised fine-tuning on small labeled dataset to verify clustering improvement 3) Run spectral clustering vs K-means on toy dataset with known non-globular clusters to verify connectivity handling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the inclusion of multiple domain knowledge through MDB impact the model's ability to generalize to unseen domains beyond the six datasets used in training?
- Basis in paper: The authors claim MDB allows model to learn multiple domain knowledge simultaneously, making it robust to domain changes without requiring additional training
- Why unresolved: Paper demonstrates improved performance on Banking and Finance datasets but does not test model on truly unseen domains or quantify generalization capability
- What evidence would resolve it: Experiments testing model on entirely new domains (e.g., healthcare, retail) not present in training datasets, along with quantitative measures of domain adaptation performance

### Open Question 2
- Question: What is the optimal combination of GE, MDB, and PGT modules for different types of dialogue data (e.g., formal vs. informal, short vs. long utterances)?
- Basis in paper: Authors show different module combinations yield varying performance improvements, with spectral clustering generally outperforming K-means
- Why unresolved: Paper presents ablation studies but does not systematically investigate how module effectiveness varies with dialogue characteristics
- What evidence would resolve it: Detailed analysis of module performance across dialogue datasets with varying characteristics and recommendations for module selection based on data properties

### Open Question 3
- Question: How does the PGT method compare to alternative fine-tuning approaches for clustering tasks, such as contrastive learning or supervised clustering?
- Basis in paper: Authors introduce PGT as novel method for fine-tuning models to improve clustering performance
- Why unresolved: Paper demonstrates PGT's effectiveness compared to baseline models but lacks direct comparisons with other state-of-the-art clustering fine-tuning methods
- What evidence would resolve it: Comparative experiments between PGT and alternative clustering fine-tuning methods using same datasets and evaluation metrics

## Limitations
- Limited evaluation on diverse domains beyond Banking and Finance datasets restricts generalizability claims
- No ablation studies isolating MDB vs PGT contributions make it difficult to assess individual component effectiveness
- No analysis of computational overhead from Siamese network architecture during inference

## Confidence
- High: MDB improves domain robustness through parallel multi-domain training (supported by clear experimental design and results)
- Medium: PGT successfully enables differentiable clustering training (mechanism described but limited empirical isolation)
- Medium: Spectral clustering outperforms K-means for dialogue data (supported by results but lacks theoretical explanation for dialogue-specific advantage)

## Next Checks
1. Run ablation study with only MDB (no PGT) vs only PGT (no MDB) on Banking dataset to quantify individual contributions
2. Test model on an additional domain (e.g., e-commerce or healthcare dialogues) to validate cross-domain generalization claims
3. Measure inference latency and memory usage differences between single SBERT and multi-view model to assess practical deployment costs