---
ver: rpa2
title: 'Towards Fast and Stable Federated Learning: Confronting Heterogeneity via
  Knowledge Anchor'
arxiv_id: '2312.02416'
source_url: https://arxiv.org/abs/2312.02416
tags:
- federated
- classes
- learning
- forgetting
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of forgetting in federated learning
  due to data heterogeneity. It systematically analyzes the forgetting degree of each
  class during local training and finds that both missing and non-dominant classes
  suffer severe forgetting, while dominant classes show performance improvement.
---

# Towards Fast and Stable Federated Learning: Confronting Heterogeneity via Knowledge Anchor

## Quick Facts
- arXiv ID: 2312.02416
- Source URL: https://arxiv.org/abs/2312.02416
- Authors: 
- Reference count: 40
- Primary result: FedKA improves accuracy by ~2% on Cifar10, ~3% on Cifar100, and ~1% on Tiny-ImageNet while achieving 2.3x-2.7x speedup in communication efficiency

## Executive Summary
This paper addresses the critical problem of catastrophic forgetting in federated learning due to data heterogeneity. The authors systematically analyze class-wise forgetting during local training and discover that both missing and non-dominant classes suffer severe performance degradation, while dominant classes improve. To mitigate this issue, they propose Federated Knowledge Anchor (FedKA), which constructs a shared dataset containing one sample per class and uses it to correct gradients during local training, preserving knowledge of underrepresented classes. Experiments demonstrate that FedKA achieves faster convergence and significantly better accuracy compared to existing methods.

## Method Summary
FedKA addresses federated learning heterogeneity by constructing a shared minimal dataset with one sample per class, which is used to create knowledge anchors for each client based on their missing and non-dominant classes. During local training, the algorithm applies L2 distance regularization between the logits of knowledge anchor samples predicted by the current global model and the updated local model. This gradient correction mechanism forces local models to preserve knowledge of underrepresented classes while still learning from their private data. The method is evaluated on CIFAR-10, CIFAR-100, and Tiny-ImageNet with Dirichlet-distributed non-IID data across 10 clients.

## Key Results
- FedKA outperforms baseline methods by approximately 2% on CIFAR-10, 3% on CIFAR-100, and 1% on Tiny-ImageNet
- Achieves 2.3x to 2.7x speedup in communication efficiency compared to FedAvg
- Demonstrates robust performance across varying levels of data heterogeneity and client participation rates
- Maintains stable convergence while preserving knowledge of missing and non-dominant classes

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Local models suffer catastrophic forgetting on non-dominant and missing classes, but improve performance on dominant classes.
- **Mechanism:** In heterogeneous federated learning, local models are trained on skewed class distributions. Classes with few or no samples (non-dominant and missing classes) are severely under-represented in local training, leading to performance degradation on these classes. Dominant classes, having more samples, improve during local training but at the expense of non-dominant classes.
- **Core assumption:** The forgetting degree formula accurately measures the degradation of class-specific performance after local training.
- **Evidence anchors:**
  - [abstract]: "Both missing and non-dominant classes suffer similar severe forgetting during local training, while dominant classes show improvement in performance."
  - [section 3.1]: "The forgetting degree τ of the non-dominant classes k ∈ Cn or the missing classes k ∈ Cm is always greater than 0 and close to 1, whereas the forgetting degree τ of the dominant classes k ∈ Cd is consistently negative."
  - [corpus]: Weak evidence. Related works focus on different mechanisms (e.g., spatial-temporal data heterogeneity, class-incremental learning) without directly addressing the class-wise forgetting phenomenon described here.

### Mechanism 2
- **Claim:** Reducing the number of samples for a dominant class below a certain threshold causes abrupt catastrophic forgetting.
- **Mechanism:** Dominant classes benefit from having many samples during local training, which helps preserve their performance. However, when the number of samples drops below a threshold, the local model cannot effectively leverage the few samples to prevent forgetting, leading to a sudden performance drop.
- **Core assumption:** There exists a sample threshold below which the local model cannot effectively prevent forgetting for a specific class.
- **Evidence anchors:**
  - [abstract]: "When dynamically reducing the sample size of a dominant class, catastrophic forgetting occurs abruptly when the proportion of its samples is below a certain threshold."
  - [section 3.2]: "The results demonstrate that reducing the number of samples has a trivial impact on the forgetting degree of non-dominant classes, indicating that clients cannot make full use of samples from these classes. However, reducing the number of samples from dominant classes significantly reduces the performance benefits obtained in local training, and catastrophic forgetting occurs when the number of samples falls below a certain threshold."
  - [corpus]: No direct evidence. Related works do not investigate the impact of sample reduction on dominant classes in the context of federated learning.

### Mechanism 3
- **Claim:** FedKA mitigates forgetting by using a shared minimal dataset as anchor points to preserve knowledge of non-dominant and missing classes.
- **Mechanism:** FedKA constructs a knowledge anchor by selecting one sample per class from a shared minimal dataset. This anchor is used to correct the gradient of each mini-batch during local training, encouraging the model to preserve the knowledge of non-dominant and missing classes. The L2 distance between the logits of the knowledge anchor predicted by the current global model and the updated local model is minimized.
- **Core assumption:** The shared minimal dataset accurately represents the global class distribution and can serve as effective anchor points for preserving knowledge.
- **Evidence anchors:**
  - [abstract]: "The knowledge anchor is then utilized to correct the gradient of each mini-batch towards the direction of preserving the knowledge of the missing and non-dominant classes."
  - [section 4]: "The core idea of FedKA is to utilize a minimal subset of the global data distribution as anchor points to force the local model to preserve the knowledge of non-dominant and missing classes."
  - [corpus]: Weak evidence. While related works discuss federated learning with class-incremental learning and prototype-based methods, they do not directly address the use of a shared minimal dataset as anchor points for preserving knowledge in the context of federated learning with heterogeneous data.

## Foundational Learning

- **Concept: Catastrophic forgetting in neural networks**
  - **Why needed here:** Understanding catastrophic forgetting is crucial for grasping the problem that FedKA addresses. In federated learning with heterogeneous data, local models tend to forget the knowledge of classes that are not well-represented in their local data.
  - **Quick check question:** What is the difference between catastrophic forgetting in continual learning and federated learning?

- **Concept: Federated learning with heterogeneous data**
  - **Why needed here:** FedKA is specifically designed to address the challenges of federated learning with heterogeneous data. Understanding the characteristics of heterogeneous data in federated learning (e.g., label skew, quantity skew) is essential for appreciating the motivation behind FedKA.
  - **Quick check question:** How does label skew affect the performance of federated learning models?

- **Concept: Knowledge distillation**
  - **Why needed here:** FedKA borrows the idea of knowledge distillation (specifically, Not-True-Distillation) to preserve the knowledge of non-dominant and missing classes. Understanding the principles of knowledge distillation is necessary for comprehending how FedKA works.
  - **Quick check question:** What is the main idea behind knowledge distillation, and how is it applied in FedKA?

## Architecture Onboarding

- **Component map:**
  - Shared minimal dataset -> Knowledge anchor construction -> Local training with gradient correction -> Global model aggregation

- **Critical path:**
  1. Construct the shared minimal dataset before training
  2. Each client constructs its knowledge anchor based on its data distribution
  3. During local training, use the knowledge anchor to correct the gradient of each mini-batch
  4. Aggregate the updated local models to obtain the global model

- **Design tradeoffs:**
  - Using a shared minimal dataset ensures that all clients have access to representative samples of all classes, but it may introduce privacy concerns if the samples are not carefully selected
  - The knowledge anchor size is limited to control communication overhead, but a smaller anchor may be less effective in preserving knowledge
  - The L2 distance between logits is used to preserve knowledge, but other distance metrics (e.g., KL divergence) could also be explored

- **Failure signatures:**
  - If the shared minimal dataset is not representative of the global class distribution, the knowledge anchor may not effectively preserve knowledge
  - If the knowledge anchor size is too small, it may not provide sufficient information to preserve knowledge of non-dominant and missing classes
  - If the weight of the knowledge anchor loss (β) is not properly tuned, the model may prioritize preserving knowledge over learning from local data, leading to suboptimal performance

- **First 3 experiments:**
  1. Evaluate the forgetting degree of each class during local training on a heterogeneous dataset (e.g., Cifar10 with Dirichlet distribution) to confirm the observations in section 3.1
  2. Dynamically reduce the number of samples for a dominant class and observe the forgetting degree to validate the findings in section 3.2
  3. Implement FedKA and compare its performance (accuracy, convergence speed) with baseline methods (e.g., FedAvg, FedProx) on heterogeneous datasets (e.g., Cifar10, Cifar100) to demonstrate its effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the proposed Federated Knowledge Anchor (FedKA) algorithm perform in real-world federated learning scenarios where data heterogeneity is even more severe than in the controlled experiments?
- **Basis in paper:** [explicit] The paper mentions that the algorithm is evaluated on popular benchmarks like Cifar10, Cifar100, and Tiny-ImageNet, but does not explicitly test it in real-world scenarios.
- **Why unresolved:** The paper focuses on controlled experiments and does not provide evidence of the algorithm's performance in real-world scenarios with more severe data heterogeneity.
- **What evidence would resolve it:** Conducting experiments in real-world federated learning scenarios with varying degrees of data heterogeneity would provide evidence of the algorithm's performance.

### Open Question 2
- **Question:** How does the proposed FedKA algorithm compare to other personalized federated learning methods in terms of model performance and communication efficiency?
- **Basis in paper:** [explicit] The paper mentions that personalized federated learning methods are a feasible solution to tackle data heterogeneity, but does not compare the proposed FedKA algorithm to these methods.
- **Why unresolved:** The paper focuses on comparing the proposed algorithm to generic federated learning methods and does not provide evidence of its performance compared to personalized methods.
- **What evidence would resolve it:** Conducting experiments to compare the proposed FedKA algorithm to personalized federated learning methods in terms of model performance and communication efficiency would provide evidence of its effectiveness.

### Open Question 3
- **Question:** How does the proposed FedKA algorithm perform when the number of classes in the classification problem increases?
- **Basis in paper:** [explicit] The paper mentions that the algorithm is evaluated on datasets with 10, 100, and 200 classes, but does not explicitly test it on datasets with a larger number of classes.
- **Why unresolved:** The paper focuses on evaluating the algorithm on datasets with a limited number of classes and does not provide evidence of its performance on datasets with a larger number of classes.
- **What evidence would resolve it:** Conducting experiments to evaluate the proposed FedKA algorithm on datasets with a larger number of classes would provide evidence of its scalability and effectiveness.

## Limitations

- The t-CNN architecture details are unspecified, which could affect reproducibility
- The sampling strategy for knowledge anchor construction is not clearly defined
- The hyperparameter β is not systematically explored, suggesting potential sensitivity

## Confidence

- Class-wise forgetting observation: High
- Threshold effect for dominant classes: Medium
- Knowledge anchor effectiveness: Medium

## Next Checks

1. Replicate the forgetting degree analysis on CIFAR-10 with Dirichlet distribution to verify the observed patterns for dominant vs non-dominant classes
2. Conduct an ablation study varying the knowledge anchor size to determine the minimum effective size and its impact on performance
3. Test FedKA with alternative distance metrics (KL divergence instead of L2) to assess the robustness of the knowledge preservation mechanism