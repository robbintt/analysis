---
ver: rpa2
title: 'Scaling User Modeling: Large-scale Online User Representations for Ads Personalization
  in Meta'
arxiv_id: '2311.09544'
source_url: https://arxiv.org/abs/2311.09544
tags:
- user
- embeddings
- online
- embedding
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Scaling User Modeling (SUM) is a framework for efficient online
  user representation learning in large-scale ads ranking systems like Meta's, which
  hosts hundreds of models with diverse constraints. SUM addresses the challenge of
  sub-optimal user representations, feature redundancy, data scarcity for specialized
  models, and the impracticality of tailoring user representation learning for each
  model.
---

# Scaling User Modeling: Large-scale Online User Representations for Ads Personalization in Meta

## Quick Facts
- arXiv ID: 2311.09544
- Source URL: https://arxiv.org/abs/2311.09544
- Reference count: 40
- Key outcome: SUM framework achieves significant online metric gains in Meta's ads ranking system by sharing user embeddings across hundreds of models

## Executive Summary
Scaling User Modeling (SUM) addresses the challenge of efficient user representation learning in large-scale ads ranking systems that host hundreds of diverse models. The framework introduces an upstream-downstream paradigm where a small number of sophisticated user models synthesize embeddings from massive user features, which are then shared across multiple downstream ranking models. SUM includes the SUM Online Asynchronous Platform (SOAP) that enables latency-free serving with frequent updates, complemented by average pooling techniques to stabilize embeddings during model updates.

## Method Summary
SUM employs a few designated upstream user models with advanced modeling techniques to synthesize user embeddings from massive amounts of user features. These embeddings serve as inputs to downstream online ads ranking models, enabling efficient representation sharing across hundreds of models. The framework introduces SOAP, a latency-free online serving system that decouples feature write path from read path, allowing complex models to be served without latency constraints. To maintain embedding freshness and overcome distribution shift from frequent updates, SUM uses recurrent training with average pooling over recent embeddings.

## Key Results
- SUM has been deployed to hundreds of production ads ranking models in Meta, processing hundreds of billions of user requests daily
- The framework yields significant online metric gains and improved infrastructure efficiency compared to traditional approaches
- Average pooling techniques effectively stabilize user embeddings during frequent model updates

## Why This Works (Mechanism)

### Mechanism 1
- Upstream user models generate high-quality embeddings that improve downstream ads ranking models without requiring retraining of those downstream models
- Core assumption: User embeddings capture sufficient information to improve downstream performance
- Evidence: SUM leverages a few designated upstream user models to synthesize user embeddings from massive amounts of user features with advanced modeling techniques, which then serve as inputs to downstream online ads ranking models

### Mechanism 2
- SOAP enables frequent updates of user embeddings while maintaining low latency for downstream models
- Core assumption: Slight staleness from reading previous embeddings is acceptable for downstream performance
- Evidence: SOAP is a latency-free online serving system that decouples feature write path from read path, removing latency limits for complex models

### Mechanism 3
- Average pooling of embeddings mitigates distribution shift caused by frequent model updates
- Core assumption: Distribution shift between consecutive model snapshots impacts downstream performance
- Evidence: SUM employs average pooling over 2 most recent cached embeddings and current computed embedding to reduce impact of embedding distribution shift

## Foundational Learning

- Deep learning architectures and limitations in production: Understanding sophisticated neural network models and their constraints is crucial for designing effective serving systems like SOAP
- Online advertising systems and personalization: Knowledge of unique challenges in large-scale advertising personalization is essential for appreciating SUM's value proposition
- Distributed systems and caching strategies: Understanding distributed systems concepts and caching strategies is crucial for designing low-latency serving systems

## Architecture Onboarding

- Component map: Upstream user models -> SOAP -> Downstream ads ranking models -> Feature Store
- Critical path: 1) User request arrives at downstream model, 2) Downstream model queries SOAP for user embeddings, 3) SOAP computes current embedding and writes to Feature Store, 4) SOAP reads previous embeddings, 5) SOAP returns average pooled embeddings, 6) Downstream model uses embeddings for ad ranking
- Design tradeoffs: Model complexity vs. serving latency, embedding freshness vs. serving overhead, storage cost vs. embedding quality
- Failure signatures: High latency in downstream models, degradation in ad performance, increased storage costs
- First 3 experiments: 1) Benchmark embedding quality by comparing downstream performance with and without SUM embeddings, 2) Stress test SOAP under high load to identify bottlenecks, 3) Analyze embedding distribution shift to measure average pooling impact

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Lack of detailed ablation studies showing individual component contributions to performance gains
- Limited comparison details against specific baseline methods and their performance characteristics
- Insufficient offline validation metrics and statistical significance measures for reported online results

## Confidence
- **High Confidence**: Core premise of sharing user embeddings across multiple models is well-supported with clear architectural description
- **Medium Confidence**: Effectiveness of average pooling for mitigating distribution shift is plausible but lacks quantitative evidence
- **Low Confidence**: Claim of consistently beating other user representations is not well-supported with limited comparison details

## Next Checks
1. Conduct controlled ablation studies disabling individual SUM components to quantify their independent contributions
2. Implement comprehensive offline benchmarks comparing SUM embeddings against alternative user representation methods
3. Perform statistical power analysis on online A/B test results to determine significance of observed metric improvements