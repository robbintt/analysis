---
ver: rpa2
title: Document-Level Machine Translation with Large Language Models
arxiv_id: '2304.02210'
source_url: https://arxiv.org/abs/2304.02210
tags:
- translation
- chatgpt
- discourse
- document-level
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper conducts an in-depth evaluation of large language models
  (LLMs) for document-level machine translation, focusing on three aspects: effects
  of context-aware prompts, comparison of translation models, and analysis of discourse
  modeling abilities. Experiments on various benchmarks show that ChatGPT and GPT-4
  achieve superior performance compared to commercial MT systems in terms of human
  evaluation and most document-level NMT methods in terms of d-BLEU.'
---

# Document-Level Machine Translation with Large Language Models

## Quick Facts
- arXiv ID: 2304.02210
- Source URL: https://arxiv.org/abs/2304.02210
- Authors: 
- Reference count: 14
- Key outcome: ChatGPT and GPT-4 achieve superior performance compared to commercial MT systems in human evaluation and most document-level NMT methods in d-BLEU

## Executive Summary
This paper conducts an in-depth evaluation of large language models (LLMs) for document-level machine translation, focusing on three aspects: effects of context-aware prompts, comparison of translation models, and analysis of discourse modeling abilities. Experiments on various benchmarks show that ChatGPT and GPT-4 achieve superior performance compared to commercial MT systems in terms of human evaluation and most document-level NMT methods in terms of d-BLEU. ChatGPT shows lower accuracy in contrastive testing than conventional translation models, but GPT-4 demonstrates strong discourse knowledge explanation abilities.

## Method Summary
The study evaluates LLMs (ChatGPT and GPT-4) for document-level translation using four latest benchmarks (mZPRT, WMT2022) and four commonly-used benchmarks (IWSLT2015, IWSLT2017, News Commentary v11, Europarl v7) across Chinese→English, English→German, and English→Russian language pairs. The evaluation employs both automatic metrics (BLEU, TER, COMET, d-BLEU) and discourse-specific metrics (CTT, AZPT), along with human evaluation on a 0-5 scale. The research investigates effects of discourse-aware prompts (P1: sentence-by-sentence, P2: document overview first, P3: multiple sentences per turn) and examines impact of training techniques like supervised fine-tuning and reinforcement learning from human feedback.

## Key Results
- GPT-4 outperforms ChatGPT, commercial MT systems, and most document-level NMT methods in human evaluation and d-BLEU scores
- ChatGPT's chat box enables effective document-level translation without explicit multi-sentence processing
- Combining multiple sentences in one conversational turn marginally enhances both translation quality and discourse awareness
- Supervised fine-tuning and reinforcement learning from human feedback consistently enhance LLMs' document translation capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPT's long-text modeling capability in the chat box enables effective document-level translation without explicit multi-sentence processing.
- Mechanism: The chat box maintains conversational context across turns, allowing ChatGPT to track discourse phenomena across document boundaries even when processing sentence-by-sentence.
- Core assumption: The model's attention mechanism can effectively maintain relevant context from previous sentences within the chat box memory window.
- Evidence anchors: "ChatGPT needs a prompt as guidance to trigger its translation ability. Thus, we enable prompts to guide ChatGPT to consider document-level contexts as long as possible."
- Break condition: If the document exceeds ChatGPT's maximum context window, or if critical discourse information falls outside the retained context span.

### Mechanism 2
- Claim: Supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) consistently enhance LLMs' document translation capabilities.
- Mechanism: These training techniques align the model's outputs with human preferences for translation quality and discourse awareness, improving both accuracy and fluency.
- Core assumption: Human feedback during training captures the nuanced requirements of document-level translation that standard pre-training may miss.
- Evidence anchors: "A combination of training techniques such as SFT and RLHF, has been consistently shown to enhance LLMs' document translation capabilities."
- Break condition: If the human feedback is noisy or inconsistent, or if the evaluation criteria don't align with actual user needs.

### Mechanism 3
- Claim: Combining multiple sentences in one conversational turn marginally enhances both translation quality and discourse awareness compared to sentence-by-sentence processing.
- Mechanism: Processing multiple sentences together provides richer context for resolving anaphora, maintaining consistency, and understanding discourse structure.
- Core assumption: Local discourse phenomena can be better resolved when adjacent sentences are processed together rather than in isolation.
- Evidence anchors: "Combining multiple sentences in one conversational turn can marginally enhance both translation quality and discourse awareness."
- Break condition: If the combined sentences exceed the model's processing capacity, or if the additional context introduces noise that confuses the translation.

## Foundational Learning

- Concept: Document-level translation vs. sentence-level translation
  - Why needed here: Understanding the distinction between these approaches is crucial for evaluating LLMs' capabilities in handling discourse phenomena.
  - Quick check question: What are the key differences between document-level and sentence-level translation in terms of coherence and context modeling?

- Concept: Discourse phenomena (anaphora, deixis, lexical consistency, zero pronouns)
  - Why needed here: These phenomena are central to evaluating whether LLMs can maintain coherence across document boundaries.
  - Quick check question: How do zero pronouns in pro-drop languages like Chinese create challenges for document-level translation?

- Concept: Automatic vs. human evaluation metrics
  - Why needed here: The paper highlights discrepancies between d-BLEU scores and human evaluation, requiring understanding of their complementary roles.
  - Quick check question: Why might human evaluation show better performance for LLMs even when d-BLEU scores are lower?

## Architecture Onboarding

- Component map: LLM-based translation system with context-aware prompts → evaluation pipeline (automatic metrics + human evaluation) → analysis modules (discourse phenomena, training techniques)
- Critical path: Prompt design → LLM inference → document-level evaluation → discourse analysis
- Design tradeoffs: Sentence-by-sentence processing offers stability but may miss local context; multi-sentence processing provides better context but risks exceeding model limits
- Failure signatures: Inconsistent terminology translation, poor handling of zero pronouns, degradation in coherence when context exceeds window size
- First 3 experiments:
  1. Compare sentence-by-sentence vs. multi-sentence processing using P1 vs. P3 prompts on a small document set
  2. Evaluate discourse phenomena handling (zero pronouns, terminology consistency) on Chinese→English benchmark
  3. Test context window limits by progressively increasing document length and measuring performance degradation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LLMs on document-level translation tasks vary across different domains and language pairs?
- Basis in paper: [explicit] The paper compares the performance of LLMs on various benchmarks covering three language pairs (Chinese⇒English, English⇒German, and English⇒Russian) and seven domains (news, social media, fiction, Q&A, TED, Europarl, and subtitles).
- Why unresolved: While the paper provides some insights into the performance of LLMs on different domains and language pairs, it does not provide a comprehensive analysis of the factors that contribute to the variation in performance across these tasks.
- What evidence would resolve it: A detailed analysis of the factors that contribute to the variation in performance of LLMs on document-level translation tasks across different domains and language pairs.

### Open Question 2
- Question: How do different training techniques (e.g., supervised fine-tuning, reinforcement learning from human feedback) impact the performance of LLMs on document-level translation tasks?
- Basis in paper: [explicit] The paper examines the impact of different training techniques, including supervised fine-tuning and reinforcement learning from human feedback, on the ability of LLMs to model discourse in document-level translation tasks.
- Why unresolved: While the paper provides some insights into the impact of these training techniques on the performance of LLMs, it does not provide a comprehensive analysis of the relative effectiveness of these techniques or the factors that contribute to their effectiveness.
- What evidence would resolve it: A detailed analysis of the relative effectiveness of different training techniques on the performance of LLMs on document-level translation tasks, including the factors that contribute to their effectiveness.

### Open Question 3
- Question: How can the performance of LLMs on document-level translation tasks be evaluated more effectively?
- Basis in paper: [explicit] The paper uses a combination of automatic and human evaluation methods to assess the performance of LLMs on document-level translation tasks, including general-purpose metrics, discourse-specific metrics, and human evaluation.
- Why unresolved: While the paper provides some insights into the effectiveness of these evaluation methods, it does not provide a comprehensive analysis of the strengths and weaknesses of these methods or the factors that contribute to their effectiveness.
- What evidence would resolve it: A detailed analysis of the strengths and weaknesses of different evaluation methods for assessing the performance of LLMs on document-level translation tasks, including the factors that contribute to their effectiveness.

## Limitations

- The actual maximum context window size for maintaining discourse information remains unclear, making the mechanism's reliability uncertain for long documents
- Discrepancies between automatic metrics (d-BLEU) and human evaluation raise questions about metric alignment and whether current evaluation frameworks adequately capture discourse-aware translation quality
- Performance improvements from SFT and RLHF may not generalize across all language pairs or domains due to unspecified domain/language of human feedback data

## Confidence

- **High confidence**: The superiority of GPT-4 over ChatGPT and commercial MT systems in both human evaluation and d-BLEU scores is well-supported by multiple benchmark comparisons
- **Medium confidence**: The claim that sentence-by-sentence processing in ChatGPT's chat box suffices for document-level translation, due to the model's inherent long-text modeling capability, is plausible but lacks quantitative validation of context retention
- **Low confidence**: The assertion that combining multiple sentences in one conversational turn "marginally enhances" translation quality and discourse awareness is weakly supported, with the paper providing minimal quantitative evidence for this marginal improvement

## Next Checks

1. **Context window validation**: Systematically test GPT-4's performance on progressively longer documents to empirically determine the maximum effective context window size and identify at what point discourse information loss begins affecting translation quality

2. **Cross-metric correlation analysis**: Conduct a detailed analysis correlating d-BLEU scores with human evaluation scores across different discourse phenomena types to understand why automatic metrics may undervalue LLM performance in document-level translation

3. **Training data influence isolation**: Design controlled experiments to isolate the impact of human feedback domain (e.g., general vs. document-level specific) on downstream translation performance, particularly for discourse-aware phenomena like zero pronoun resolution