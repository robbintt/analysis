---
ver: rpa2
title: Abrupt and spontaneous strategy switches emerge in simple regularised neural
  networks
arxiv_id: '2302.11351'
source_url: https://arxiv.org/abs/2302.11351
tags:
- block
- correct
- colour
- motion
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated whether insight-like learning phenomena,
  characterized by abrupt performance improvements, selective occurrence, and variable
  delays, can emerge from gradual gradient descent in artificial neural networks.
  Participants and regularised neural networks performed a perceptual decision task
  where a hidden colour regularity became predictive after initial training.
---

# Abrupt and spontaneous strategy switches emerge in simple regularised neural networks

## Quick Facts
- arXiv ID: 2302.11351
- Source URL: https://arxiv.org/abs/2302.11351
- Reference count: 40
- Only a subset of regularised neural networks discovered hidden regularities, exhibiting sudden performance jumps similar to human insight

## Executive Summary
This study demonstrates that insight-like learning phenomena - characterized by abrupt performance improvements, selective occurrence, and variable delays - can naturally emerge from simple neural network architectures with regularisation, gating, and noise. The research compared human participants and artificial neural networks on a perceptual decision task where a hidden color regularity became predictive after initial training. L1-regularised neural networks with gate modulation closely mimicked human insight-like behavior, while L2-regularised and non-regularised networks did not. The key mechanism involves noise accumulating in suppressed color weights during motion-only training, creating "silent knowledge" that can be suddenly unlocked when gates become active during the motion+color phase.

## Method Summary
The study used a perceptual decision task where both humans (N=99) and neural networks (N=99 L1-regularised, plus L2 and non-regularised variants) learned to classify moving dot stimuli based on motion direction and color. Networks had two inputs with multiplicative gates and L1 regularization on gates only, trained with stochastic gradient descent plus gradient noise. The task consisted of 4 blocks of motion-only training followed by 5 blocks where both motion and color were predictive. Performance was measured on low coherence trials, and networks were classified as "insight" based on sudden, selective, and delayed performance improvements using sigmoid fitting and percentile thresholds.

## Key Results
- L1-regularised networks closely matched human insight-like behavior in selectivity (only a subset showed sudden improvements) and delay (variable time to discovery)
- L2-regularised and non-regularised networks showed no insight-like behavior, switching immediately when color became predictive
- The insight mechanism relied on gradient noise accumulating to create "silent knowledge" in suppressed color weights, later unlocked by gate activation
- Regularization parameter λ affected both selectivity and delay of insight-like behavior in networks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: L1-regularisation forces input gates toward zero, creating a "silent knowledge" effect where useful features are stored in weights but not used in behavior
- Mechanism: When color information becomes predictive during the motion+color phase, the pre-existing non-zero color weights combined with accumulated gradient noise allow sudden gate activation
- Core assumption: Gradient noise can accumulate to non-zero weights during periods when gates are suppressed
- Evidence anchors:
  - [abstract]: "noise in gradient updates, which allowed accumulation of 'silent knowledge' stored in suppressed colour weights"
  - [section]: "Networks received two inputs, xm and xc, corresponding to the stimulus motion and colour, respectively, and had one output, ŷ. Importantly, each input had one associated multiplicative gate (gm,gc)"
  - [corpus]: Weak evidence - no direct mention of silent knowledge accumulation
- Break condition: If noise is too small or regularisation too strong, gates remain suppressed and no insight occurs

### Mechanism 2
- Claim: L1-regularisation creates non-linear learning dynamics through the multiplicative interaction between gates and weights
- Mechanism: The interaction between wc and gc leads to quadratic and cubic gradient dynamics, causing sudden transitions when gates become active
- Core assumption: Multiplicative gating with L1-regularisation produces non-linear dynamics that differ from linear learning
- Evidence anchors:
  - [section]: "Multiplying the weights w with the regularised gate weights g leads to smaller weights and therefore initially slower increases of the colour weights wc and respective gate weights gc"
  - [section]: "This implies that the evolution of the colour weights and gates will exhibit non-linear quadratic and cubic dynamics"
  - [corpus]: No direct evidence about non-linear dynamics from multiplicative gating
- Break condition: If using L2-regularisation instead, the dynamics become more gradual and insight-like behavior disappears

### Mechanism 3
- Claim: Regularisation parameter λ affects the delay and selectivity of insight-like behavior
- Mechanism: Smaller λ values allow earlier gate activation and more insight-like switches, while larger λ values delay and reduce the occurrence of insight
- Core assumption: The strength of regularisation directly controls the trade-off between gate suppression and insight emergence
- Evidence anchors:
  - [section]: "The regularisation parameter λ thus affects two of the key characteristics of human insight – selectivity and delay"
  - [section]: "The number of L1-regularised insight networks linearly decreased with increasing λ"
  - [corpus]: No evidence about λ's specific effects on insight delay
- Break condition: If λ is set to zero, all networks show immediate insight-like behavior with no delay

## Foundational Learning

- Concept: Gradient descent with noise
  - Why needed here: The core mechanism relies on gradient noise accumulating to create "silent knowledge" that enables insight
  - Quick check question: What happens to the network's weights when gradient noise is added during training?

- Concept: Regularization and its effects
  - Why needed here: L1 vs L2 regularization fundamentally changes the learning dynamics and insight emergence
  - Quick check question: How does L1 regularization differ from L2 regularization in terms of gate weight behavior?

- Concept: Multiplicative gating mechanisms
  - Why needed here: The interaction between gates and weights creates the non-linear dynamics necessary for insight-like behavior
  - Quick check question: What is the mathematical relationship between input, weight, and gate in the network output?

## Architecture Onboarding

- Component map:
  Input layer (xm, xc) -> Gate layer (gm, gc) -> Weight layer (wm, wc) -> Output (sign activation)

- Critical path: Motion training → Motion+Color phase → Gate activation → Insight-like behavior
- Design tradeoffs: L1 vs L2 regularization (selectivity vs performance), noise level vs insight frequency
- Failure signatures: No insight behavior (all networks switch immediately), too few insights (high λ), no learning (too much noise)
- First 3 experiments:
  1. Vary λ from 0.001 to 0.1 and measure insight frequency and delay
  2. Compare L1 vs L2 regularization on the same network architecture
  3. Test different noise levels (σξ from 0 to 0.1) to find the threshold for insight emergence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific neural mechanisms in biological brains correspond to the gate modulation and L1 regularization observed in artificial networks?
- Basis in paper: [explicit] The paper mentions that regularisation has been implied in synaptic scaling and cognitive control, but does not identify specific neural correlates for gate modulation.
- Why unresolved: The paper establishes computational parallels but does not investigate neurobiological substrates for the artificial network components.
- What evidence would resolve it: Neuroimaging or electrophysiological studies showing neural signatures corresponding to the multiplicative gating and sparse regularization effects observed in the networks.

### Open Question 2
- Question: Under what conditions would L1 regularization be more beneficial than L2 regularization for learning efficiency and generalization?
- Basis in paper: [explicit] The paper notes that L2-regularized networks performed better on the task but questions when L1 would be most beneficial, suggesting it might require more complex tasks.
- Why unresolved: The study only tested a single relatively simple task, leaving open the question of task complexity requirements.
- What evidence would resolve it: Comparative studies of L1 vs L2 networks across tasks of varying complexity and transfer learning demands.

### Open Question 3
- Question: Does the noise that contributes to insight-like behavior in networks correspond to specific types of neural noise in biological systems?
- Basis in paper: [explicit] The paper identifies noise in gradient updates as crucial for insight-like behavior but does not specify what type of biological noise this might represent.
- Why unresolved: The study uses artificial Gaussian noise without connecting it to specific biological noise sources like synaptic variability or stochastic firing.
- What evidence would resolve it: Experiments manipulating specific types of neural noise (synaptic, channel noise, etc.) and measuring effects on learning dynamics and insight-like behavior in biological systems.

## Limitations
- The mechanistic explanation for how L1 regularization specifically enables insight-like behavior while L2 does not, though plausible, lacks rigorous mathematical validation of the gradient dynamics.
- Critical implementation details for reproducing the findings are missing, particularly around sigmoid fitting procedures, control distribution generation, and the accuracy-matching procedure between human and network data.
- The study only tested a single relatively simple task, leaving open questions about when L1 regularization would be more beneficial than L2 for learning efficiency and generalization.

## Confidence
- **High Confidence:** The basic experimental design and core results showing that L1-regularized networks exhibit insight-like behavior similar to humans, while L2 and non-regularized networks do not.
- **Medium Confidence:** The mechanism explaining how "silent knowledge" accumulation through gradient noise and gate suppression leads to insight-like behavior. The mathematical arguments are plausible but not fully validated.
- **Medium Confidence:** The claim that L1-regularization is necessary and sufficient for insight-like behavior, as the comparison is primarily with L2 and non-regularized variants rather than a broader exploration of regularization types.

## Next Checks
1. **Mathematical Analysis of Gradient Dynamics:** Derive and analyze the exact gradient update equations for the L1-regularized gated network to confirm the predicted non-linear dynamics and identify the conditions for abrupt gate activation.

2. **Sensitivity Analysis of Regularization Parameters:** Systematically vary the regularization parameter λ and gradient noise level σ to map the parameter space where insight-like behavior emerges and identify any phase transitions or critical thresholds.

3. **Alternative Regularization Schemes:** Test whether other forms of regularization (e.g., elastic net, group L1) or alternative architectures (e.g., different gate implementations) can also produce insight-like behavior to validate that the specific mechanism proposed is necessary.