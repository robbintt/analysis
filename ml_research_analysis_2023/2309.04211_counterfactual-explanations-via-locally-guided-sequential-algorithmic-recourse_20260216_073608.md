---
ver: rpa2
title: Counterfactual Explanations via Locally-guided Sequential Algorithmic Recourse
arxiv_id: '2309.04211'
source_url: https://arxiv.org/abs/2309.04211
tags:
- recourse
- counterfactual
- data
- patient
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces LOCAL FACE, a method for generating counterfactual
  explanations with algorithmic recourse in black-box machine learning models. The
  key idea is to break down the transition from factual to counterfactual instances
  into sequential, feasible steps by leveraging locally-acquired data density information
  at each stage.
---

# Counterfactual Explanations via Locally-guided Sequential Algorithmic Recourse

## Quick Facts
- arXiv ID: 2309.04211
- Source URL: https://arxiv.org/abs/2309.04211
- Reference count: 37
- Key outcome: Introduces LOCAL FACE method for generating counterfactual explanations through sequential, density-guided paths while preserving privacy and model protection

## Executive Summary
This paper presents LOCAL FACE, a novel method for generating counterfactual explanations with algorithmic recourse in black-box machine learning models. The approach breaks down the transition from factual to counterfactual instances into sequential, feasible steps by leveraging locally-acquired data density information. The method consists of three stages: exploring to find accessible counterfactuals, exploiting to build local graphs of data points, and enhancing to find optimal feasible paths. The approach is evaluated on a readiness-for-discharge prediction task for ICU patients, demonstrating the ability to generate actionable and interpretable counterfactual paths that clinicians can use for decision-making.

## Method Summary
The LOCAL FACE method operates through a three-stage process to generate counterfactual explanations. First, the explore stage uses iterative nearest-neighbor queries guided by probability density to locate counterfactuals within dense data regions. Second, the exploit stage constructs a local graph connecting factual and counterfactual points using density-weighted edges. Finally, the enhance stage finds optimal recourse paths through the graph using shortest-path algorithms. The method is designed to be model-agnostic and privacy-preserving by only accessing necessary local data regions and not relying directly on model gradients.

## Key Results
- Successfully generates actionable and interpretable counterfactual paths for ICU patient discharge prediction
- Preserves user privacy by only leveraging data specifically required for constructing recourse
- Protects model by offering transparency solely in regions deemed necessary for intervention
- Demonstrated effectiveness in cases where model and clinician disagree on discharge decisions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Local data density exploration allows discovery of accessible counterfactuals without requiring full dataset access.
- Mechanism: The explore stage uses iterative nearest-neighbor queries guided by probability density to locate counterfactuals within dense data regions, ensuring feasibility.
- Core assumption: Dense regions of the data manifold contain more feasible transitions for counterfactual explanations.
- Evidence anchors:
  - [abstract] "Our explainer preserves the privacy of users by only leveraging data that it specifically requires to construct actionable algorithmic recourse"
  - [section 3.1] "we propose an alternative search technique that maximises the likelihood that a path between x and x′ exists"
  - [corpus] Weak evidence; neighboring papers discuss privacy-preserving recourse but lack direct density-guided search methods
- Break condition: If the data manifold is highly sparse or the decision boundary is far from dense regions, the method may fail to find accessible counterfactuals.

### Mechanism 2
- Claim: Sequential path construction through locally-built graphs ensures feasible and actionable recourse.
- Mechanism: The exploit stage constructs a local graph connecting factual and counterfactual points using density-weighted edges, while the enhance stage finds optimal paths using shortest-path algorithms.
- Core assumption: Feasibility of transitions can be approximated by local data density, and optimal paths through dense regions are more actionable.
- Evidence anchors:
  - [abstract] "Our approach relies on moving through areas of dense data, solving the feasibility problem"
  - [section 3.2] "each node vt+1 we add to the graph G ought to be aligned with the direction from the previous node and the counterfactual"
  - [corpus] Neighboring papers on algorithmic recourse mention feasibility but lack the specific local graph construction approach
- Break condition: If the local graph construction fails to capture relevant transitions due to density threshold misconfiguration, the method may produce suboptimal recourse.

### Mechanism 3
- Claim: Model-agnostic approach preserves privacy and reduces susceptibility to model changes.
- Mechanism: By only accessing necessary local data regions and not relying directly on model gradients, the method maintains privacy and robustness to model changes.
- Core assumption: Black-box models can be explained effectively without full transparency, and local density information is sufficient for constructing meaningful recourse.
- Evidence anchors:
  - [abstract] "protects the model by offering transparency solely in the regions deemed necessary for the intervention"
  - [section 2] "Most CFE methods look to find desirable candidates for x′ with respect to the model itself"
  - [corpus] Privacy-preserving algorithmic recourse papers support this claim but lack the specific local density approach
- Break condition: If the model's decision boundary has complex non-linear structures not captured by local density, the method may produce less accurate recourse.

## Foundational Learning

- Concept: Counterfactual explanations and algorithmic recourse
  - Why needed here: The paper builds on these concepts to create sequential, feasible counterfactual paths
  - Quick check question: What is the difference between a counterfactual explanation and algorithmic recourse?

- Concept: Local data density as a proxy for feasibility
  - Why needed here: The method uses local density to guide the search for accessible counterfactuals and construct feasible paths
  - Quick check question: How does local data density relate to the feasibility of counterfactual explanations?

- Concept: Graph-based pathfinding algorithms
  - Why needed here: The method constructs local graphs and uses shortest-path algorithms to find optimal recourse
  - Quick check question: What graph algorithm is used to find the optimal path through the local graph?

## Architecture Onboarding

- Component map: Explore stage -> Exploit stage -> Enhance stage
- Critical path:
  1. Input factual instance
  2. Explore stage to find counterfactual
  3. Exploit stage to build local graph
  4. Enhance stage to find optimal path
  5. Output recourse matrix and counterfactual

- Design tradeoffs:
  - Privacy vs. accuracy: Limiting data access preserves privacy but may reduce recourse quality
  - Computational efficiency vs. path optimality: Using local graphs speeds up computation but may miss global optima
  - Density threshold tuning: Balancing between feasibility and accessibility of counterfactuals

- Failure signatures:
  - Inability to find accessible counterfactuals in sparse regions
  - Suboptimal paths due to local graph construction issues
  - Inconsistent recourse quality across different data regions

- First 3 experiments:
  1. Verify counterfactual discovery on simple synthetic datasets with known dense regions
  2. Test path feasibility by checking if generated recourse steps are achievable in the data manifold
  3. Compare privacy preservation by measuring data access patterns against baseline methods

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the LOCAL FACE method perform when applied to datasets with higher dimensionality or more complex feature interactions?
- Basis in paper: [inferred] The paper discusses the application of LOCAL FACE to a readiness-for-discharge prediction task for ICU patients, but does not explore its performance on datasets with higher dimensionality or more complex feature interactions.
- Why unresolved: The paper focuses on a specific use case and does not provide evidence of the method's performance on diverse datasets.
- What evidence would resolve it: Testing the LOCAL FACE method on datasets with varying dimensions and feature complexities, and comparing its performance to other counterfactual explanation methods.

### Open Question 2
- Question: How does the inclusion of non-physiological factors, such as organ support, medication, and other interventions, impact the performance of the readiness-for-discharge model and the generated counterfactual explanations?
- Basis in paper: [explicit] The paper mentions that vital signs can be affected by organ support, medication, and other interventions, but this information is not available in the current dataset.
- Why unresolved: The current study does not incorporate these factors, which could potentially strengthen both the model and the explanatory recourse.
- What evidence would resolve it: Incorporating non-physiological factors into the dataset and retraining the model to assess the impact on its performance and the quality of the generated counterfactual explanations.

### Open Question 3
- Question: How effective is the LOCAL FACE method in identifying and handling cases where the model's prediction disagrees with the clinician's decision?
- Basis in paper: [explicit] The paper discusses the application of LOCAL FACE to cases where the model and clinician disagree, but does not provide a quantitative assessment of its effectiveness in these scenarios.
- Why unresolved: The paper presents qualitative examples but lacks a systematic evaluation of the method's performance in handling disagreements between the model and clinician.
- What evidence would resolve it: Conducting a quantitative analysis of the method's performance in cases of disagreement between the model and clinician, including metrics such as the proportion of cases where the method successfully identifies the source of disagreement and provides actionable recourse.

## Limitations
- Scalability concerns in high-dimensional feature spaces
- Sensitivity to hyperparameter choices for density thresholds and graph construction
- Limited formal privacy analysis and guarantees
- Uncertain performance on datasets with complex, non-linear decision boundaries

## Confidence

- Local density as feasibility proxy: Medium - supported by theoretical arguments but limited empirical validation
- Sequential path construction: High - methodologically sound with clear implementation path
- Privacy preservation: Medium - claims are plausible but lack comprehensive formal proofs
- Model-agnostic robustness: Medium - reasonable but not extensively tested across diverse model architectures

## Next Checks

1. Conduct sensitivity analysis on density threshold parameters to quantify their impact on counterfactual quality and feasibility
2. Perform formal privacy analysis using differential privacy metrics to verify the claimed privacy preservation
3. Test the method on benchmark datasets with known ground truth counterfactuals to validate path optimality and actionability