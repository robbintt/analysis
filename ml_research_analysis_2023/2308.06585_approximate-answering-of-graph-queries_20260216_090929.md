---
ver: rpa2
title: Approximate Answering of Graph Queries
arxiv_id: '2308.06585'
source_url: https://arxiv.org/abs/2308.06585
tags:
- query
- queries
- graph
- knowledge
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This chapter surveys methods for approximate query answering over
  knowledge graphs, which aim to answer queries as if the graph were complete despite
  missing data. It defines key concepts, describes evaluation datasets and metrics,
  and reviews several major approaches: continuous query decomposition (CQD), graph
  query embedding (GQE), Query2Box, BetaE, message passing query embedding (MPQE),
  StarQE, and BIQE.'
---

# Approximate Answering of Graph Queries

## Quick Facts
- arXiv ID: 2308.06585
- Source URL: https://arxiv.org/abs/2308.06585
- Reference count: 33
- One-line primary result: Survey of methods for approximate query answering over knowledge graphs with focus on embedding-based approaches

## Executive Summary
This chapter surveys methods for approximate query answering over knowledge graphs, addressing the challenge of answering queries as if the graph were complete despite missing data. It provides a comprehensive overview of the field, defining key concepts, describing evaluation datasets and metrics, and reviewing several major approaches including continuous query decomposition (CQD), graph query embedding (GQE), Query2Box, BetaE, message passing query embedding (MPQE), StarQE, and BIQE. The chapter highlights the tradeoffs between different approaches in terms of expressiveness, supported graph types, and inference capabilities, while identifying key challenges such as scalability, limited operator support, and the need for handling literals and cycles in queries.

## Method Summary
The chapter synthesizes various approximate query answering methods that leverage knowledge graph embeddings to answer queries over incomplete graphs. These methods map entities and relations into continuous vector spaces and use operations like addition, multiplication, and intersection to compute query embeddings. Different approaches vary in their handling of logical operators - some use specialized operators for conjunction and projection, while others employ message passing architectures for greater generalization. Probabilistic embedding spaces like Beta distributions enable handling of negation and uncertainty. The chapter describes evaluation using standard knowledge graph datasets (FB15k-237, NELL995) with metrics including MRR, hits@k, AUROC, and APS.

## Key Results
- Multiple approaches exist for approximate query answering, each with different tradeoffs in expressiveness and scalability
- Message passing architectures offer better generalization across query structures compared to specialized operator-based methods
- Probabilistic embedding spaces enable handling of logical negation and uncertainty that point embeddings cannot capture
- Current methods face significant limitations in handling literals, cycles, and scaling to large knowledge graphs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph embeddings enable approximate query answering by learning distributed representations that encode missing graph structure.
- Mechanism: Knowledge graph nodes and relations are mapped into continuous vector spaces. Queries are then answered by performing vector operations (e.g., addition, multiplication, intersection) on these embeddings to approximate the missing links.
- Core assumption: The embedding space captures relational patterns such that vector operations correspond to logical operations in the graph domain.
- Evidence anchors:
  - [abstract] "aim to answer queries as if the graph were complete despite missing data"
  - [section] "systems built around knowledge graphs can leverage the information in them through the use of graph queries"
  - [corpus] Weak - corpus papers focus on more recent neural approaches rather than basic embedding mechanisms
- Break condition: If the embedding space does not preserve the semantic relationships needed for the query operations, or if the graph contains noise that corrupts the learned patterns.

### Mechanism 2
- Claim: Message passing architectures generalize better across different query structures compared to specialized operator-based methods.
- Mechanism: Instead of defining explicit projection and intersection operators, message passing networks propagate information through the query graph using learned aggregation functions. This allows the same architecture to handle various query patterns without redesigning operators.
- Core assumption: The message passing framework can learn to approximate any required logical operation through sufficient training examples.
- Evidence anchors:
  - [abstract] "differ in expressiveness, supported graph types, and inference capabilities"
  - [section] "the projection and intersection operators can be generalized into a message passing operation"
  - [corpus] Weak - corpus papers are newer and don't directly address the generalization advantage
- Break condition: If the training data lacks sufficient diversity to learn the necessary message passing patterns, or if the query structures become too complex for effective message propagation.

### Mechanism 3
- Claim: Probabilistic embedding spaces (e.g., Beta distributions) enable better handling of logical negation and uncertainty compared to point embeddings.
- Mechanism: Instead of representing entities and queries as single points, they are embedded as probability distributions. This allows operations like negation to be modeled as distribution transformations, which is not possible with point embeddings.
- Core assumption: The probabilistic representation can capture both the set membership and uncertainty aspects needed for logical operations.
- Evidence anchors:
  - [abstract] "BetaE...handle conjunction, disjunction, and negation at the same time"
  - [section] "BetaE is a query embedding method with a probabilistic embedding space...can faithfully handle a broader set of logical operators"
  - [corpus] Weak - corpus doesn't provide evidence for this specific mechanism
- Break condition: If the distributional assumptions (e.g., independence) don't hold for the actual query patterns, or if the computation becomes intractable for large queries.

## Foundational Learning

- Concept: Knowledge graph structure and query patterns
  - Why needed here: Understanding how KGs represent facts and how queries traverse them is essential for grasping why approximate methods are needed
  - Quick check question: What is the difference between a multi-hop query and an intersection query in terms of their graph patterns?

- Concept: Embedding learning and vector operations
  - Why needed here: The core of these methods relies on learning meaningful vector representations and defining operations that correspond to logical query operations
  - Quick check question: How would you represent a conjunction of two facts using vector operations on entity embeddings?

- Concept: Message passing and graph neural networks
  - Why needed here: Modern approaches use message passing as a general framework for computing query embeddings, replacing specialized operators
  - Quick check question: What is the key difference between a GNN applied to a knowledge graph versus a standard graph?

## Architecture Onboarding

- Component map: Entity embedding layer → Query embedding computation (operator-based or message passing) → Scoring layer → Ranking output
- Critical path: Embedding computation → Query embedding → Scoring → Ranking
- Design tradeoffs: Operator-based methods offer interpretability but limited expressiveness; message passing offers generalization but may be less interpretable
- Failure signatures: Poor performance on unseen query patterns, overfitting to training queries, inability to handle literals or cycles
- First 3 experiments:
  1. Implement a simple operator-based method (like GQE) on a small dataset and test on chain queries
  2. Replace the operators with a message passing architecture and compare performance on complex queries
  3. Add a probabilistic embedding component (like BetaE) and evaluate on queries requiring negation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we improve the scalability of approximate query answering methods given the computational costs of generating and evaluating large numbers of queries?
- Basis in paper: [explicit] "Another issue is that real-world KGs as well as the benchmark KGs are characterized by popular nodes that can skew the distribution of queries due to their high in or out degree. In the paper by Alivanistos et al. [3] (appendix C), the authors showed that if the 3i test queries would be generated naively, one could achieve a Hits@10 performance of 0.93 by always predicting the top 10 answers in descending popularity, urging the authors to remove high degree nodes."
- Why unresolved: The paper notes that generating a complete set of queries can become intractable and that naive generation can lead to skewed results, but does not propose a solution for this scalability issue.
- What evidence would resolve it: A method that can efficiently generate a representative sample of queries without bias towards popular nodes, and demonstrates improved performance on complex queries compared to naive generation methods.

### Open Question 2
- Question: How can approximate query answering methods be extended to handle queries with cycles, which are currently not supported by most approaches?
- Basis in paper: [explicit] "A prominent example are queries which have cycles in them. While some of the methods (e.g., the message passing based ones) could in principle compute an embedding for these, there is little theoretical basis supporting the idea, and it has not been evaluated."
- Why unresolved: The paper identifies that while some methods could theoretically handle cyclic queries, there is no theoretical foundation or empirical evaluation to support this claim.
- What evidence would resolve it: A theoretical framework that proves the feasibility of handling cyclic queries in approximate query answering, along with experimental results showing improved performance on cyclic queries compared to existing methods.

### Open Question 3
- Question: How can literal values be effectively incorporated into approximate query answering methods, given their infinite nature and the need for different handling compared to entities?
- Basis in paper: [explicit] "Examples can be time, strings, numerical values indicating pressure or temperature, etc. These literals require different handling compared to entities. One of the issues is that the set of literals is infinite, rather than taken from a finite set."
- Why unresolved: The paper highlights the challenge of incorporating literal values into AQA methods due to their infinite nature and the need for different handling, but does not propose a solution.
- What evidence would resolve it: A method that can effectively encode and reason with literal values in AQA, demonstrating improved performance on queries involving literals compared to existing methods that ignore or inadequately handle literals.

## Limitations

- Limited operator support in most methods, with many unable to handle disjunction, negation, or complex logical combinations
- Scalability constraints prevent application to large-scale knowledge graphs, with most methods limited to medium-sized datasets like FB15k-237
- Inability to handle literals and cycles in queries, which limits practical applicability to real-world knowledge graphs

## Confidence

- **High Confidence**: The characterization of current methods' limitations (scalability, operator support, handling of literals/cycles) is well-supported by the surveyed literature and represents consensus in the field.
- **Medium Confidence**: The assessment of mechanism effectiveness (embedding-based vs message passing vs probabilistic) is reasonable but depends on specific query patterns and datasets not fully explored in the chapter.
- **Low Confidence**: Claims about future research directions are speculative and not grounded in concrete evidence from the surveyed works.

## Next Checks

1. **Operator Expressiveness Test**: Implement CQD and BetaE on a benchmark with queries requiring disjunction and negation to quantify the performance gap and validate the claimed expressiveness limitations.

2. **Scalability Benchmark**: Test representative methods (CQD, GQE, BetaE) on progressively larger knowledge graphs (from FB15k-237 to full-scale KGs) to empirically verify the scalability constraints mentioned in the chapter.

3. **Cycle Handling Evaluation**: Design a dataset with cyclic queries and evaluate current methods' ability to handle them, as this is explicitly identified as an open challenge requiring validation.