---
ver: rpa2
title: 'SSL4EO-L: Datasets and Foundation Models for Landsat Imagery'
arxiv_id: '2306.09424'
source_url: https://arxiv.org/abs/2306.09424
tags:
- landsat
- datasets
- dataset
- data
- cloud
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SSL4EO-L, the first dataset designed for
  self-supervised learning (SSL) in Earth observation using Landsat imagery. It contains
  5 million image patches from three Landsat sensors and two product levels, making
  it the largest Landsat dataset in history.
---

# SSL4EO-L: Datasets and Foundation Models for Landsat Imagery

## Quick Facts
- arXiv ID: 2306.09424
- Source URL: https://arxiv.org/abs/2306.09424
- Reference count: 40
- Key outcome: First dataset for self-supervised learning on Landsat imagery with 5M patches; MoCo outperforms ImageNet pre-training by up to 6.6% accuracy and 7.15 mIoU

## Executive Summary
This paper introduces SSL4EO-L, the first dataset specifically designed for self-supervised learning (SSL) on Landsat imagery. The dataset contains 5 million image patches from three Landsat sensors and two product levels, making it the largest Landsat dataset to date. The authors modernize two existing cloud detection datasets and create new benchmark datasets for Landsat 4-5 TM and Landsat 7 ETM+ SR. Through extensive experiments, they demonstrate that pre-training foundation models using SSL4EO-L and fine-tuning on downstream semantic segmentation tasks consistently outperforms models initialized with ImageNet weights.

## Method Summary
The authors created SSL4EO-L by downloading all available Landsat data from Google Earth Engine, sampling 250K locations across the continental US at four different seasons, resulting in 5M unlabeled image patches. They pre-trained ResNet and ViT backbones using SimCLR v1 and MoCo v2 on this dataset, then fine-tuned U-Net decoders on benchmark datasets including NLCD/CDL land cover and L7 Irish/L8 Biome cloud detection. The pre-training used batch size 1024 for 200 epochs, with downstream fine-tuning using early stopping for 20-100 epochs.

## Key Results
- MoCo consistently outperforms ImageNet pre-trained models, sometimes by as much as 6.6% overall accuracy and 7.15 mIoU
- SSL4EO-L is the largest Landsat dataset in history with 5M image patches
- The parallel corpus structure between TOA and SR products enables multimodal data fusion studies

## Why This Works (Mechanism)

### Mechanism 1
Pre-training on large, diverse, unlabeled Landsat imagery via SSL improves downstream semantic segmentation performance compared to ImageNet initialization. MoCo contrastive learning learns generalizable features from seasonal, multimodal Landsat patches that capture domain-specific spectral patterns (e.g., agricultural cycles, vegetation types). The diversity and scale of SSL4EO-L (5M patches, 4 seasons, 3 sensors, 2 product levels) provide sufficient domain coverage for effective representation learning.

### Mechanism 2
The parallel corpus structure between TOA and SR products enables multimodal data fusion studies without retraining separate models. Same geographic and seasonal patches across TOA/SR allow direct transfer and fusion experiments, preserving spectral consistency across processing levels. TOA and SR products are sufficiently aligned in space/time to act as valid positive pairs for contrastive learning.

### Mechanism 3
Using seasonal contrast as a data augmentation strategy improves SSL representation quality for remote sensing imagery. Sampling images from the same location at different seasons provides natural positive pairs that encode temporal and phenological variation, strengthening learned invariances. Seasonal changes in vegetation and land use are predictable and consistent enough to serve as effective SSL augmentations.

## Foundational Learning

- **Self-supervised learning via contrastive methods (e.g., MoCo, SimCLR)**: Why needed: Labeled Landsat datasets are scarce and expensive; SSL leverages the abundance of free unlabeled imagery to learn useful features without manual annotation. Quick check: What is the role of the momentum encoder in MoCo, and why is it important for contrastive learning stability?
- **Multitemporal and multimodal data sampling for diversity**: Why needed: Landsat sensors have different spectral bands and resolutions; sampling across sensors and seasons ensures learned features are robust to these variations. Quick check: How does sampling 4 seasonal images per location help improve model generalization compared to single-date sampling?
- **Foundation model pre-training and transfer learning**: Why needed: Pre-trained models can be fine-tuned on small labeled datasets for specific tasks (e.g., cloud detection, land cover), drastically reducing the need for large annotated datasets. Quick check: Why freeze the backbone during fine-tuning on small downstream datasets, and what are the risks if you don't?

## Architecture Onboarding

- **Component map**: GEE -> TorchGeo -> SSL4EO-L datasets (5M patches, 264x264 px, uint8) -> Pre-training: MoCo v2 or SimCLR v1 on ResNet or ViT backbones, 200 epochs, batch size 1024 -> Fine-tuning: U-Net with frozen backbone, 20-100 epochs, early stopping, learning rate tuned -> Evaluation: NLCD/CDL land cover, L7 Irish/L8 Biome cloud masks, overall accuracy, mIoU
- **Critical path**: 1) Download SSL4EO-L via TorchGeo (huggingface link), 2) Pre-train model (MoCo preferred) for 200 epochs, 3) Fine-tune on target downstream dataset, 4) Evaluate with standard metrics
- **Design tradeoffs**: Larger backbones (ResNet-50, ViT) yield better accuracy but require more GPU memory and training time; MoCo generally outperforms SimCLR on RS imagery but may need more careful hyperparameter tuning; TOA vs SR: SR preferred for land cover, but TOA enables atmospheric applications; both supported
- **Failure signatures**: Poor downstream accuracy: Possible causes include insufficient pre-training diversity, incorrect scaling, or class imbalance in fine-tuning data; Convergence issues in pre-training: Check batch size, augmentation settings, and SSL method choice; Memory errors: Reduce batch size, use smaller backbone, or enable gradient checkpointing
- **First 3 experiments**: 1) Pre-train ResNet-18 on OLI/TIRS TOA using MoCo for 50 epochs (quick sanity check), 2) Fine-tune on L8 Biome cloud detection, compare to ImageNet baseline, 3) Repeat (1) and (2) for ETM+ SR, then compare performance across sensors

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of SSL models on Landsat imagery vary with different pre-training dataset sizes, and what is the optimal size for balancing performance gains and computational costs? The paper mentions that SSL4EO-L is the largest Landsat dataset in history (5M image patches), but does not explore the impact of dataset size on model performance.

### Open Question 2
Can the SSL4EO-L dataset be effectively used for other remote sensing tasks beyond semantic segmentation, such as object detection or instance segmentation? The paper focuses on semantic segmentation tasks, but the large and diverse SSL4EO-L dataset could potentially be useful for other tasks.

### Open Question 3
How does the performance of SSL models on Landsat imagery compare to models trained on other high-resolution satellite imagery, such as Sentinel-2 or Maxar? The paper mentions that a lot of recent work focuses on Sentinel-2, Maxar, and Planet satellites, but does not compare the performance of SSL models on Landsat to these other satellite imagery sources.

### Open Question 4
What is the impact of different SSL techniques (e.g., SimCLR, MoCo, BYOL) on the performance of Landsat foundation models, and are there any techniques that consistently outperform others? The paper mentions that MoCo and BYOL tend to learn better representations on RS imagery, but does not provide a comprehensive comparison of different SSL techniques on Landsat imagery.

## Limitations
- Claims about SSL4EO-L being the first and largest dataset for Landsat SSL are not directly compared to other existing datasets
- Improvement margins are presented without confidence intervals or statistical significance tests
- The paper does not discuss potential biases in the dataset sampling strategy or how geographic coverage might affect generalization

## Confidence

- **High Confidence**: The technical feasibility of creating SSL4EO-L from GEE data and its availability via TorchGeo
- **Medium Confidence**: The superiority of MoCo over ImageNet pre-training for Landsat semantic segmentation
- **Low Confidence**: Claims about SSL4EO-L being the first dataset of its kind and the absolute magnitude of performance improvements

## Next Checks

1. Replicate the MoCo pre-training on a subset of SSL4EO-L (e.g., 1M patches) and compare downstream performance on L8 Biome with both confidence intervals and statistical significance testing
2. Test the parallel corpus assumption by measuring spatial and temporal alignment errors between TOA and SR products at the same locations
3. Evaluate model performance on geographically diverse validation sets outside the original sampling regions to assess true generalization capability