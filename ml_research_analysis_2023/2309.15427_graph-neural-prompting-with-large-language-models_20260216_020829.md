---
ver: rpa2
title: Graph Neural Prompting with Large Language Models
arxiv_id: '2309.15427'
source_url: https://arxiv.org/abs/2309.15427
tags:
- knowledge
- graph
- question
- llms
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Graph Neural Prompting (GNP), a novel method
  to enhance large language models (LLMs) with grounded knowledge from knowledge graphs
  (KGs). GNP employs a graph neural network encoder, cross-modality pooling, a domain
  projector, and a self-supervised link prediction objective to learn beneficial knowledge
  from KGs and integrate it into pre-trained LLMs as soft prompts.
---

# Graph Neural Prompting with Large Language Models

## Quick Facts
- **arXiv ID**: 2309.15427
- **Source URL**: https://arxiv.org/abs/2309.15427
- **Reference count**: 8
- **Primary result**: GNP improves LLM performance by +13.5% when frozen and +1.8% when tuned, outperforming existing methods and matching or surpassing full fine-tuning in 10 out of 12 evaluations.

## Executive Summary
This paper introduces Graph Neural Prompting (GNP), a novel method that enhances large language models with grounded knowledge from knowledge graphs for improved reasoning performance. GNP uses a graph neural network encoder to extract relevant subgraph knowledge, aligns it with text through cross-modality attention, and generates soft prompts that guide LLM inference. The approach demonstrates significant performance gains on commonsense and biomedical reasoning tasks, outperforming baseline methods in both frozen and tuned LLM settings.

## Method Summary
GNP encodes grounded knowledge from knowledge graphs into soft prompts for LLMs through four key components: a GNN encoder that processes relevant subgraphs, cross-modality pooling that aligns graph and text embeddings, a domain projector that maps graph embeddings to the LLM's embedding space, and a self-supervised link prediction objective. The method generates unique prompts for each question instance based on its specific subgraph, and can be used with both frozen and tuned LLMs. Training involves maximizing likelihood loss plus link prediction loss, with performance evaluated across multiple commonsense and biomedical reasoning datasets.

## Key Results
- GNP achieves +13.5% accuracy improvement when LLMs are frozen and +1.8% when tuned across 6 datasets
- Outperforms existing KG integration methods including KAPING, Prompt Tuning, and LoRA
- Matches or surpasses full fine-tuning in 10 out of 12 evaluations across different LLM sizes
- Shows consistent improvements on both commonsense (OBQA, ARC, PIQA, RiddleSense) and biomedical (PubMedQA, BioASQ) tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GNP improves LLM performance by encoding grounded knowledge from KGs into soft prompts.
- Mechanism: GNP uses a GNN to encode relevant subgraph knowledge, cross-modality pooling to align graph embeddings with text, and a domain projector to map graph embeddings to the LLM's embedding space, creating a soft prompt that guides LLM inference.
- Core assumption: The subgraph retrieved based on question entities contains sufficient relevant knowledge to improve reasoning.
- Evidence anchors:
  - [abstract] "GNP encompasses various designs, including a standard graph neural network encoder, a cross-modality pooling module, a domain projector, and a self-supervised link prediction objective."
  - [section] "GNP encodes the pertinent grounded knowledge and complex structural information to derive Graph Neural Prompt, an embedding vector that can be sent into LLMs to provide guidance and instructions."
  - [corpus] Weak corpus coverage - no direct evidence found.
- Break condition: If the subgraph retrieval fails to capture relevant entities, the soft prompt becomes ineffective noise.

### Mechanism 2
- Claim: The self-supervised link prediction objective enhances model comprehension of relationships between entities.
- Mechanism: During training, edges are masked in the subgraph, and the model is trained to predict these masked edges using DistMult scoring, encouraging the model to learn structural knowledge beyond the downstream task.
- Core assumption: Learning to predict missing links in KGs improves the model's ability to reason about entity relationships in downstream tasks.
- Evidence anchors:
  - [abstract] "Finally, a self-supervised link prediction objective is introduced to enhance the model comprehension of relationships between entities and capture graph knowledge in a self-supervised manner."
  - [section] "We mask out some edges in G′ and enforce the model to predict them. This encourages the model to learn to use the partial graph content and structure to reason about the missing links."
  - [corpus] Weak corpus coverage - no direct evidence found.
- Break condition: If the masked link prediction task becomes too easy or too hard, it may not provide useful learning signals.

### Mechanism 3
- Claim: GNP's instance-level prompting is more effective than dataset-level prompting.
- Mechanism: GNP generates a unique soft prompt for each question by encoding its specific subgraph, whereas dataset-level prompting uses the same prompt for all instances.
- Core assumption: Different questions require different guidance from KGs, and instance-level prompting can provide more relevant guidance.
- Evidence anchors:
  - [section] "A salient property of GNP is the learning of Graph Neural Prompt for each data instance, i.e., various questions yield different retrieved subgraphs, resulting in unique prompts."
  - [section] "Given its distinction from the dataset-level prompt (DLP) that is utilized by Prompt Tuning, we present the outcomes of integrating DLP for further investigation."
  - [corpus] Weak corpus coverage - no direct evidence found.
- Break condition: If most questions in a dataset require similar guidance, instance-level prompting may not provide significant benefits over dataset-level prompting.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: GNNs are used to encode the subgraph knowledge into node embeddings that capture both entity features and structural relationships.
  - Quick check question: How does a GNN differ from a standard neural network in handling graph-structured data?

- Concept: Cross-Modality Attention
  - Why needed here: Cross-modality attention aligns the graph embeddings with text embeddings, identifying the most relevant nodes for each question.
  - Quick check question: What is the purpose of using text embeddings as keys and values in the cross-modality attention mechanism?

- Concept: Self-Supervised Learning
  - Why needed here: The link prediction task is a self-supervised objective that encourages the model to learn structural knowledge without requiring labeled data.
  - Quick check question: How does the link prediction task encourage the model to learn about entity relationships?

## Architecture Onboarding

- Component map: Subgraph retrieval -> GNN encoder -> Cross-modality pooling -> Domain projector -> Soft prompt generation -> LLM inference
- Critical path: Subgraph retrieval → GNN encoding → Cross-modality pooling → Domain projector → Soft prompt generation → LLM inference
- Design tradeoffs: The model balances between encoding rich graph knowledge (using GNNs) and maintaining compatibility with pre-trained LLMs (using domain projector and soft prompts). The self-supervised link prediction objective adds training complexity but improves structural understanding.
- Failure signatures: Poor performance may indicate ineffective subgraph retrieval, misalignment between graph and text embeddings, or insufficient training of the link prediction task.
- First 3 experiments:
  1. Validate subgraph retrieval by checking if retrieved subgraphs contain entities mentioned in the correct answers.
  2. Test the impact of different GNN layers on performance across datasets to find optimal architecture.
  3. Evaluate the contribution of the self-supervised link prediction objective by comparing with and without it.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the limitations of GNP when applied to knowledge graphs with highly heterogeneous structures or domains?
- Basis in paper: [inferred] The paper discusses the effectiveness of GNP across commonsense and biomedical reasoning tasks, but does not explicitly explore its performance on highly heterogeneous knowledge graphs.
- Why unresolved: The paper focuses on evaluating GNP on specific tasks and datasets, but does not investigate its robustness or limitations when dealing with knowledge graphs of varying structures or domains.
- What evidence would resolve it: Experiments demonstrating GNP's performance on a diverse range of knowledge graphs with different structures and domains, including those with high heterogeneity, would provide insights into its limitations and potential areas for improvement.

### Open Question 2
- Question: How does the performance of GNP scale with the size of the knowledge graph?
- Basis in paper: [inferred] The paper evaluates GNP on different knowledge graphs, but does not explicitly analyze its performance scaling with the size of the knowledge graph.
- Why unresolved: The paper focuses on comparing GNP's performance across different tasks and settings, but does not investigate how its performance is affected by the size of the knowledge graph.
- What evidence would resolve it: Experiments evaluating GNP's performance on knowledge graphs of varying sizes, from small to large-scale, would provide insights into its scalability and potential bottlenecks.

### Open Question 3
- Question: What are the potential biases introduced by GNP when using knowledge graphs for language modeling?
- Basis in paper: [inferred] The paper discusses the benefits of using knowledge graphs to enhance language modeling, but does not explicitly address potential biases that may arise from incorporating KG information.
- Why unresolved: The paper focuses on demonstrating GNP's effectiveness, but does not investigate the potential biases or limitations introduced by relying on knowledge graphs for language modeling.
- What evidence would resolve it: Studies analyzing the biases and limitations introduced by GNP when using knowledge graphs, including potential amplification of existing biases in the KG data, would provide insights into its fairness and ethical implications.

## Limitations

- Effectiveness heavily depends on quality of subgraph retrieval - if relevant entities are not captured, soft prompts become ineffective
- Computational overhead of GNN encoding for each instance may limit scalability to real-time applications
- Self-supervised link prediction objective's contribution to downstream reasoning lacks direct empirical validation

## Confidence

**High confidence**: The core mechanism of using GNNs to encode graph knowledge and generating instance-specific soft prompts is well-established. The architectural design and training procedure are clearly specified, and the performance improvements over baseline methods are consistently demonstrated across multiple datasets and LLM sizes.

**Medium confidence**: The effectiveness of the cross-modality attention mechanism for aligning graph and text embeddings is assumed based on standard attention principles, but the specific implementation details and their impact on performance are not fully explored. The ablation studies showing the contribution of individual components provide supporting evidence but do not isolate the exact mechanisms of improvement.

**Low confidence**: The claim that the self-supervised link prediction objective significantly enhances model comprehension of entity relationships lacks direct empirical support. While the objective is theoretically sound, its actual contribution to downstream reasoning tasks is not independently validated through ablation studies.

## Next Checks

1. **Subgraph retrieval validation**: Conduct a systematic analysis of retrieved subgraphs by measuring the overlap between entities in the subgraph and entities mentioned in correct answers across all datasets. This will quantify how often the retrieval mechanism successfully captures relevant knowledge.

2. **Link prediction objective ablation**: Perform an ablation study comparing GNP with and without the self-supervised link prediction objective across all datasets to isolate its contribution to performance improvements, particularly in biomedical tasks where structural knowledge may be more critical.

3. **Instance-level vs dataset-level prompting analysis**: Conduct a controlled experiment varying the granularity of prompting (instance-level, question-type level, dataset-level) to determine the optimal level of prompt specificity and identify scenarios where instance-level prompting provides diminishing returns.