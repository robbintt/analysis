---
ver: rpa2
title: Federated Learning in the Presence of Adversarial Client Unavailability
arxiv_id: '2305.19971'
source_url: https://arxiv.org/abs/2305.19971
tags:
- fedavg
- clients
- fedprox
- learning
- client
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies federated learning under adversarial client\
  \ unavailability, where an adversary can adaptively silence specific clients during\
  \ training. The authors introduce the notion of \u03F5-adversary dropout fraction\
  \ to quantify unavailability levels and show that simple variants of FedAvg and\
  \ FedProx, without being designed specifically for adversarial unavailability, achieve\
  \ minimax-optimal performance."
---

# Federated Learning in the Presence of Adversarial Client Unavailability

## Quick Facts
- arXiv ID: 2305.19971
- Source URL: https://arxiv.org/abs/2305.19971
- Reference count: 40
- Primary result: Simple variants of FedAvg and FedProx achieve minimax-optimal performance under adversarial client unavailability

## Executive Summary
This paper studies federated learning when an adversary can adaptively silence specific clients during training. The authors introduce the notion of ϵ-adversary dropout fraction to quantify unavailability levels and prove that simple variants of FedAvg and FedProx achieve minimax-optimal performance without being designed specifically for adversarial unavailability. The theoretical analysis reveals that while heterogeneity parameter B affects convergence speed, parameter G directly impacts the final estimation error. Experiments on CIFAR-10 and synthetic datasets validate that these variants outperform baseline algorithms and Byzantine-resilient methods in highly adversarial environments with up to 80% client unavailability.

## Method Summary
The paper analyzes federated learning under adversarial client unavailability, where an adversary can silence clients during training. The proposed method uses simple variants of FedAvg and FedProx algorithms with modified aggregation factors and learning rate scheduling. The analysis focuses on both non-convex and strongly-convex objectives, deriving convergence rates and error bounds that depend on the adversary's power (ϵ), heterogeneity parameters (B, G), and noise levels (σ²). The key insight is that these simple variants naturally achieve optimal performance without requiring Byzantine-robust modifications.

## Key Results
- For non-convex objectives, variants converge to estimation error O(ϵ(G² + σ²)) with convergence speed O(1/√T)
- For strongly-convex objectives, variants achieve estimation error O(ϵ(G² + σ²)/μ²) with convergence speed O(1/T)
- These bounds are proven to be minimax-optimal, meaning no algorithm can achieve better performance under adversarial unavailability
- The heterogeneity parameter B affects convergence speed but not final estimation error, while G directly impacts the error bound

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial client unavailability introduces selection bias that accumulates over training rounds, but this bias can be bounded using heterogeneity constraints and dropout fraction limits.
- Mechanism: When the adversary selects non-responsive clients, the remaining participating clients form a biased subset. This selection bias affects the gradient estimation at each round. However, by bounding the total number of dropped data points (Assumption 2) and leveraging the (B,G)-heterogeneity condition (Assumption 1), we can derive uniform concentration bounds on the selection bias that persist throughout training.
- Core assumption: The adversary's power is limited by the ϵ-adversary dropout fraction, preventing arbitrary manipulation of the gradient direction.
- Evidence anchors:
  - [abstract]: "We prove that this estimation error is minimax-optimal" and "Our proofs build upon a tight analysis of the selection bias that persists in the entire learning process"
  - [section 4.1]: "Two main ingredients in our analysis are: 1) the power of the adversary is limited as specified by Assumption 2; 2) the dissimilarity among the clients is bounded given by Assumption 1"
  - [corpus]: No direct evidence found in corpus - this appears to be a novel theoretical contribution
- Break condition: If the adversary could drop more than ϵ fraction of clients or if the heterogeneity bounds B or G were violated, the concentration bounds would fail and selection bias could grow unbounded.

### Mechanism 2
- Claim: Simple variants of FedAvg and FedProx achieve minimax-optimal error bounds without being designed specifically for adversarial unavailability.
- Mechanism: The key insight is that the standard FedAvg and FedProx algorithms, when properly configured with appropriate learning rates and aggregation factors, naturally achieve optimal convergence rates under adversarial dropout. The algorithm's inherent properties allow it to tolerate the selection bias introduced by the adversary while maintaining convergence guarantees.
- Core assumption: The learning rate scheduling and aggregation factor β can be chosen appropriately to balance convergence speed and error tolerance.
- Evidence anchors:
  - [abstract]: "simple variants of FedAvg or FedProx, albeit completely agnostic to ϵ, converge to an estimation error on the order of ϵ(G² + σ²)"
  - [section 4.1]: "These convergence speeds are on par with the centralized settings [GL13,NJLS09], and are the best possible for any first-order method that has only access to noisy gradients"
  - [corpus]: No direct evidence found in corpus - this appears to be a novel theoretical contribution
- Break condition: If the learning rates are not properly scheduled or if the aggregation factor β is chosen incorrectly, the algorithm may fail to converge or achieve suboptimal error bounds.

### Mechanism 3
- Claim: The heterogeneity parameter B affects convergence speed but not the final estimation error, while G directly impacts the error bound.
- Mechanism: Through careful analysis of the convergence proof, we can separate the effects of B and G on different aspects of the algorithm's performance. B influences the rate at which the algorithm approaches the error floor, while G determines the magnitude of that error floor itself.
- Core assumption: The separation of B and G's effects is maintained throughout the convergence analysis.
- Evidence anchors:
  - [abstract]: "Interestingly, among the two heterogeneity parameters B and G, only G appears in the estimation error O(ϵ(G² + σ²)). Our analysis reveals that B instead influences the convergence speed"
  - [section 5]: "The lower bound in Theorem 4 does not depend on the other dissimilarity parameter B"
  - [corpus]: No direct evidence found in corpus - this appears to be a novel theoretical insight
- Break condition: If the relationship between B, G, and the convergence properties were more complex than assumed, the separation of their effects might not hold, potentially leading to different convergence behaviors.

## Foundational Learning

- Concept: Minimax optimality in optimization
  - Why needed here: The paper establishes that the proposed algorithms achieve the best possible error bounds under adversarial unavailability, which requires understanding what "optimal" means in this context
  - Quick check question: What does it mean for an algorithm to be minimax-optimal, and how is this different from achieving a specific error bound?

- Concept: Concentration inequalities for biased samples
  - Why needed here: The analysis of selection bias requires bounding the deviation of gradients from biased client subsets, which relies on concentration inequalities adapted to adversarial sampling
  - Quick check question: How do standard concentration inequalities need to be modified when dealing with adversarial rather than random sampling?

- Concept: Heterogeneity characterization in federated learning
  - Why needed here: The (B,G)-heterogeneity condition provides the mathematical framework for quantifying differences between client objectives, which is crucial for both algorithm design and theoretical analysis
  - Quick check question: How does the (B,G)-heterogeneity condition relate to other common measures of data heterogeneity in federated learning?

## Architecture Onboarding

- Component map:
  Parameter server -> Clients (computing gradients) -> Adversary (selecting unavailable clients) -> Algorithm variants (FedAvg/FedProx with modified aggregation)

- Critical path:
  1. Parameter server samples K clients uniformly at random
  2. Adversary selects subset St of participating clients within ϵ constraints
  3. Participating clients compute local updates
  4. Parameter server aggregates updates using formula (2)
  5. Repeat until convergence or maximum rounds

- Design tradeoffs:
  - Local update steps (s): Higher s accelerates training but increases objective inconsistency
  - Learning rate scheduling: Must balance convergence speed with stability under adversarial dropout
  - Aggregation factor β: Compensates for missing clients but affects convergence rate
  - Heterogeneity bounds: Tighter bounds enable better performance but may not hold in practice

- Failure signatures:
  - Divergence: Learning rates too high or β too small relative to heterogeneity
  - Slow convergence: Insufficient local steps or overly conservative learning rates
  - High final error: ϵ too large relative to B and G bounds, or heterogeneity assumptions violated
  - Oscillations: Poor learning rate scheduling or inappropriate choice of local update steps

- First 3 experiments:
  1. Baseline comparison: Run FedAvg/FedProx variants against naive versions on CIFAR-10 with ϵ = 0.8 to verify smoother convergence and better final accuracy
  2. Byzantine resilience test: Compare against centered clipping and geometric median methods on highly imbalanced synthetic data to demonstrate superior performance under adversarial dropout
  3. Heterogeneity sensitivity: Vary B and G parameters on synthetic data to confirm that B affects convergence speed while G affects final error bound as predicted by theory

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the adversarial client unavailability model extend to Byzantine attacks that also inject malicious values, and what theoretical bounds would apply in that case?
- Basis in paper: [explicit] The paper explicitly states that their adversarial unavailability model is a special case of Byzantine attacks without malicious value injection, and notes that existing Byzantine-resilient results are not applicable due to the changing set of faulty clients.
- Why unresolved: The paper only analyzes adversarial client unavailability without value injection. Extending the analysis to full Byzantine attacks would require handling both the selection bias and the value injection, which the current techniques do not address.
- What evidence would resolve it: A theoretical analysis showing minimax bounds for the combined case of adversarial selection and value injection, along with convergence rates for simple FedAvg/FedProx variants under such attacks.

### Open Question 2
- Question: Can the FedAvg/FedProx variants be modified to achieve better convergence rates under adversarial unavailability without sacrificing the minimax optimality?
- Basis in paper: [explicit] The paper shows that simple FedAvg/FedProx variants achieve minimax-optimal bounds but does not explore whether more sophisticated modifications could improve convergence rates while maintaining optimality.
- Why unresolved: The analysis focuses on simple variants and their optimality, but does not investigate whether algorithmic modifications could yield faster convergence in practice.
- What evidence would resolve it: Empirical and theoretical results demonstrating that modified algorithms (e.g., with adaptive learning rates or momentum) achieve faster convergence while preserving the minimax bounds.

### Open Question 3
- Question: How do the convergence bounds change when the heterogeneity parameters B and G are time-varying or adversarial?
- Basis in paper: [inferred] The paper assumes fixed heterogeneity parameters B and G under Assumption 1, but real-world federated learning often involves non-stationary data distributions where these parameters may vary.
- Why unresolved: The analysis relies on static heterogeneity assumptions, which may not hold in dynamic environments. Extending the theory to time-varying or adversarial heterogeneity would require new techniques.
- What evidence would resolve it: Theoretical results characterizing convergence under time-varying B and G, along with empirical validation on non-stationary datasets.

### Open Question 4
- Question: What is the impact of partial client participation on the generalization performance of federated learning models in highly adversarial settings?
- Basis in paper: [explicit] The experiments show that the proposed variants achieve better training loss and test accuracy than baselines in adversarial settings, but do not directly analyze generalization bounds.
- Why unresolved: The paper focuses on optimization error but does not provide generalization guarantees under adversarial unavailability.
- What evidence would resolve it: Generalization bounds relating the adversarial dropout fraction to test error, supported by experiments on diverse datasets.

## Limitations
- Theoretical analysis relies on idealized heterogeneity bounds (B, G) and noise levels (σ²) that may not hold precisely in real-world deployments
- Minimax optimality proofs assume worst-case adversaries within the ϵ constraint, but practical adversaries might exhibit exploitable patterns
- Convergence analysis focuses on last-iterate error rather than averaged iterates, which may be more relevant for practical applications

## Confidence
- Minimax optimality claims: High - supported by formal lower bound proofs and matching upper bounds
- Mechanism explanations: Medium - theoretical reasoning is sound but some assumptions require empirical validation
- Experimental results: Medium - single dataset experiments with synthetic heterogeneity limits generalizability

## Next Checks
1. **Heterogeneity sensitivity validation**: Systematically vary B and G parameters across multiple orders of magnitude on both CIFAR-10 and additional datasets to empirically confirm the theoretical separation of their effects on convergence speed vs. final error
2. **Adversary strategy robustness**: Implement and test against alternative adversary models (random dropout, targeted attacks based on model parameters) to verify performance bounds hold beyond the worst-case analysis
3. **Practical hyperparameter optimization**: Conduct extensive hyperparameter sweeps for learning rates and aggregation factors across different ϵ values to establish practical guidelines for deployment