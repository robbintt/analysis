---
ver: rpa2
title: Deep Backtracking Counterfactuals for Causally Compliant Explanations
arxiv_id: '2310.07665'
source_url: https://arxiv.org/abs/2310.07665
tags: []
core_contribution: This paper introduces Deep Backtracking Counterfactuals (DeepBC),
  a method for generating counterfactual explanations in deep structural causal models.
  The core idea is to frame counterfactual generation as a constrained optimization
  problem in the latent space of a causal model, ensuring causal compliance by keeping
  all structural relationships intact while tracing changes back to latent variables.
---

# Deep Backtracking Counterfactuals for Causally Compliant Explanations

## Quick Facts
- arXiv ID: 2310.07665
- Source URL: https://arxiv.org/abs/2310.07665
- Reference count: 36
- Key outcome: Introduces DeepBC, a method for generating counterfactual explanations in deep structural causal models by optimizing in the latent space to ensure causal compliance

## Executive Summary
This paper presents Deep Backtracking Counterfactuals (DeepBC), a novel approach for generating counterfactual explanations in deep structural causal models. The method frames counterfactual generation as a constrained optimization problem in the latent space, ensuring causal compliance by maintaining structural relationships while tracing changes back to latent variables. DeepBC offers three key advantages: versatility in handling complex causal relationships and high-dimensional data, causal compliance through its backtracking approach, and modularity for easy domain adaptation. The method is evaluated on Morpho-MNIST and CelebA datasets, demonstrating its ability to generate realistic counterfactuals while preserving causal relationships and outperforming interventional approaches.

## Method Summary
DeepBC generates counterfactual explanations by optimizing in the latent space of a deep structural causal model. The method assumes invertibility of structural equations and uses either Langevin Monte Carlo sampling or constrained optimization to find counterfactuals that satisfy causal constraints while minimizing a distance function to the factual instance. Individual deep generative models (VAEs and normalizing flows) are trained for each structural equation, and counterfactuals are generated by solving a constrained optimization problem that enforces causal relationships. The modular design allows for easy adaptation to new domains by substituting individual components without relearning the entire model.

## Key Results
- DeepBC successfully generates counterfactuals that preserve causal relationships in Morpho-MNIST and CelebA datasets
- The method outperforms interventional approaches in terms of causal compliance and realism of generated counterfactuals
- DeepBC demonstrates versatility in handling complex causal relationships between multiple variables and high-dimensional data
- The modular design allows for easy adaptation to new domains through substitution of individual components

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DeepBC generates causally compliant counterfactuals by optimizing in the latent space of a deep structural causal model
- Mechanism: The method traces changes back to latent variables while preserving all structural relationships, avoiding interventional modifications
- Core assumption: The structural causal model's reduced form is invertible and differentiable
- Evidence anchors:
  - [abstract] "framing counterfactual generation as a constrained optimization problem in the latent space of a causal model, ensuring causal compliance by keeping all structural relationships intact"
  - [section 2.2] "we make the simplifying assumption that fi(xpa(i), Â· ) is invertible for any fixed xpa(i)"
  - [corpus] Weak - the related papers discuss counterfactual explanations but don't directly address the latent space optimization approach
- Break condition: If the structural equations are not invertible or the latent space doesn't capture causal relationships well

### Mechanism 2
- Claim: DeepBC provides versatility by supporting complex causal relationships between multiple variables
- Mechanism: The method can handle high-dimensional data (like images) and multiple variables with flexible antecedent choices
- Core assumption: The causal graph structure is known and can be represented by the deep generative components
- Evidence anchors:
  - [abstract] "versatile (handling complex causal relationships and high-dimensional data)"
  - [section 3.2] "DeepBC naturally supports complex causal relationship between multiple variables that are potentially high dimensional"
  - [corpus] Weak - the related papers mention counterfactual explanations but focus more on generating explanations rather than handling complex causal structures
- Break condition: If the causal graph becomes too complex or the deep generative models cannot capture the relationships

### Mechanism 3
- Claim: DeepBC offers modularity by allowing easy adaptation to new domains through substitution of individual components
- Mechanism: Each structural equation fi can be replaced independently without relearning the entire model
- Core assumption: Domain shifts manifest sparsely, meaning many modules behave similarly across domains
- Evidence anchors:
  - [abstract] "modular (allowing for easy adaptation to new domains)"
  - [section 3.2] "DeepBC offers adaptability to new domains through the straightforward substitution of individual components fi, without the need for relearning the remaining modules"
  - [corpus] Weak - the related papers don't discuss modularity or domain adaptation in the context of counterfactual explanations
- Break condition: If domain shifts affect multiple structural equations simultaneously or the modular structure breaks down

## Foundational Learning

- Concept: Structural Causal Models (SCMs)
  - Why needed here: DeepBC relies on SCMs to represent causal relationships and generate counterfactuals
  - Quick check question: What are the key components of a structural causal model and how do they differ from statistical models?

- Concept: Latent variable models and generative models
  - Why needed here: DeepBC uses deep generative models (like VAEs and normalizing flows) to model the structural equations in the latent space
  - Quick check question: How do conditional normalizing flows and conditional VAEs differ in their approach to modeling conditional distributions?

- Concept: Counterfactual reasoning and backtracking
  - Why needed here: DeepBC implements backtracking counterfactuals, which trace changes back to latent variables rather than intervening on the causal structure
  - Quick check question: What is the key difference between interventional and backtracking counterfactuals, and why is backtracking more suitable for certain applications?

## Architecture Onboarding

- Component map: SCM with deep generative components (VAEs and normalizing flows) -> Latent space representation -> Optimization module -> Evaluation module

- Critical path:
  1. Train individual deep generative models for each structural equation
  2. Construct the full structural causal model
  3. Implement the DeepBC optimization algorithm
  4. Generate and evaluate counterfactuals

- Design tradeoffs:
  - Choice between Langevin Monte Carlo and constrained optimization for generating counterfactuals
  - Balance between causal compliance and realism in generated counterfactuals
  - Trade-off between computational efficiency and accuracy in the optimization process

- Failure signatures:
  - Poor reconstruction of factual examples indicates issues with the deep generative models
  - Counterfactuals that violate causal relationships suggest problems with the structural causal model
  - Slow convergence or poor optimization results may indicate issues with the optimization algorithm

- First 3 experiments:
  1. Generate counterfactuals for Morpho-MNIST with thickness as the antecedent to verify causal compliance
  2. Test the modularity by replacing the structural equation for one attribute in CelebA and regenerating counterfactuals
  3. Compare DeepBC counterfactuals with interventional counterfactuals to demonstrate the benefits of the backtracking approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DeepBC compare to other causal counterfactual methods when dealing with non-linear causal relationships and high-dimensional data?
- Basis in paper: [inferred] The paper mentions that DeepBC can handle complex causal relationships and high-dimensional data, but doesn't provide a direct comparison with other causal counterfactual methods.
- Why unresolved: The paper focuses on comparing DeepBC with non-causal counterfactual explanation methods, leaving a gap in understanding its performance relative to other causal approaches.
- What evidence would resolve it: A comparative study of DeepBC against other causal counterfactual methods (e.g., based on causal graphs or structural causal models) on a range of datasets with varying complexity and dimensionality.

### Open Question 2
- Question: How does the choice of distance function in DeepBC affect the interpretability and quality of the generated counterfactuals?
- Basis in paper: [explicit] The paper mentions that DeepBC allows for varying distance functions to obtain counterfactuals with different properties, such as sparsity.
- Why unresolved: While the paper demonstrates the versatility of DeepBC in handling different distance functions, it doesn't explore the implications of these choices on the interpretability and quality of the generated counterfactuals.
- What evidence would resolve it: An empirical study analyzing the impact of different distance functions on the interpretability and quality of counterfactuals generated by DeepBC, potentially using human evaluation or downstream task performance as metrics.

### Open Question 3
- Question: Can DeepBC be extended to handle unobserved confounders in the causal model?
- Basis in paper: [explicit] The paper assumes causal sufficiency (no unobserved confounders) in its theoretical framework.
- Why unresolved: The assumption of causal sufficiency might limit the applicability of DeepBC in real-world scenarios where unobserved confounders are likely to exist.
- What evidence would resolve it: A theoretical extension of DeepBC to handle unobserved confounders, potentially through the use of latent variables or other causal inference techniques, along with empirical validation on datasets with known unobserved confounders.

## Limitations

- The invertibility assumption for structural equations may not hold for all real-world causal relationships, potentially limiting the method's applicability
- The effectiveness of modularity depends heavily on domain sparsity assumptions, which may not hold in complex domains with widespread covariate shifts
- The computational complexity of the optimization-based approach may become prohibitive for very large causal graphs or high-dimensional data

## Confidence

- **High**: The core mechanism of using latent space optimization for generating causally compliant counterfactuals is well-supported by the theoretical framework and experimental results
- **Medium**: The claims about versatility and modularity are supported by the experimental results but require more extensive validation across diverse domains
- **Medium**: The computational efficiency claims relative to alternative methods are based on limited experiments and may vary with problem scale

## Next Checks

1. Test DeepBC on causal graphs with non-invertible structural equations to assess robustness beyond the theoretical assumptions
2. Evaluate the modularity claim by systematically introducing domain shifts that affect multiple structural equations simultaneously
3. Conduct scalability experiments with increasingly complex causal graphs and higher-dimensional data to validate computational efficiency claims