---
ver: rpa2
title: 'Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions
  with Adaptive Imitation Learning'
arxiv_id: '2310.07918'
source_url: https://arxiv.org/abs/2310.07918
tags:
- learning
- policy
- decision
- patients
- interpretable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Contextualized Policy Recovery (CPR), a method
  for interpretable imitation learning that models complex human decision-making processes
  as a collection of simple, context-specific policies. CPR addresses the fundamental
  tradeoff between accuracy and interpretability in existing policy learning approaches
  by reframing the problem as multi-task learning, where each context defines a unique
  task.
---

# Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning

## Quick Facts
- **arXiv ID**: 2310.07918
- **Source URL**: https://arxiv.org/abs/2310.07918
- **Reference count**: 40
- **Primary result**: CPR achieves state-of-the-art performance on two medical decision tasks while providing interpretable context-specific decision models

## Executive Summary
Contextualized Policy Recovery (CPR) addresses the fundamental tradeoff between accuracy and interpretability in policy learning by reframing the problem as multi-task learning. Instead of learning a single universal policy, CPR learns a black-box generator function that encodes contextual information and produces linear observation-to-action mappings for each specific context. This allows CPR to generate interpretable decision models on-demand as contexts change, maintaining both accuracy and transparency. The method demonstrates that contextualized policies can capture complex decision dynamics while maintaining interpretability, closing the performance gap between interpretable and black-box approaches in policy learning.

## Method Summary
CPR models complex human decision-making processes as a collection of simple, context-specific policies rather than a single universal policy. The method uses a black-box context encoder (typically an RNN or LSTM) to process patient history and generate context embeddings, which are then used to produce linear observation-to-action mappings for each specific context. These linear policies are interpretable at the individual patient level while the context encoder captures the complexity of decision dynamics. The entire system is trained jointly using binary cross-entropy loss with L1 regularization on policy coefficients, allowing the model to recover interpretable context-specific decision models that match or exceed black-box performance.

## Key Results
- CPR achieves +22% AUROC improvement over previous state-of-the-art on antibiotic prescription prediction in intensive care units
- CPR achieves +7.7% AUROC improvement over previous state-of-the-art on MRI prescription prediction for Alzheimer's patients
- CPR matches or exceeds black-box model performance while providing interpretable context-specific decision models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: CPR achieves state-of-the-art performance by reframing policy learning as multi-task learning where each context defines a unique task.
- **Mechanism**: Instead of learning a single universal policy that must handle all contexts, CPR learns a black-box generator function that encodes contextual information and produces linear observation-to-action mappings for each specific context. This allows the model to leverage simple, interpretable linear models while still capturing complex decision dynamics.
- **Core assumption**: Human decisions are dynamic and change drastically under different contexts, making universal policies inherently limited in both accuracy and interpretability.
- **Evidence anchors**: [abstract] "reframes the problem of modeling complex decision processes as a multi-task learning problem, where each context poses a unique task and complex decision policies can be constructed piece-wise from many simple context-specific policies"
- **Break condition**: If contexts are not well-defined or if the same decision policy applies across all contexts, the multi-task formulation becomes unnecessary and may add complexity without benefit.

### Mechanism 2
- **Claim**: CPR maintains interpretability while matching black-box performance by using context-specific linear policies.
- **Mechanism**: Each context-specific policy is modeled as a linear observation-to-action mapping, making the decision process transparent and interpretable at the level of individual patients. The black-box context encoder generates these linear coefficients dynamically as contexts change.
- **Core assumption**: Linear models can capture the essential decision dynamics when properly contextualized, and the complexity can be handled by the context encoder rather than the policy itself.
- **Evidence anchors**: [abstract] "models each context-specific policy as a linear observation-to-action mapping, and generates new decision models on-demand as contexts are updated with new observations"
- **Break condition**: If the true decision process requires highly non-linear relationships that cannot be approximated by linear models even with perfect contextualization, performance will suffer.

### Mechanism 3
- **Claim**: CPR's modular design allows it to be tailored to specific tasks while maintaining interpretability.
- **Mechanism**: Both the context encoder (g) and the observation-to-action function (f) can be freely chosen according to the given task, allowing flexibility in architecture design while preserving the interpretable policy representation.
- **Core assumption**: The separation between context encoding and policy generation is sufficient to maintain interpretability regardless of the specific models chosen for each component.
- **Evidence anchors**: [abstract] "CPR is compatible with fully offline and partially observable decision environments, and can be tailored to incorporate any recurrent black-box model or interpretable decision model"
- **Break condition**: If the chosen components violate the differentiability requirement or if the modular separation breaks down (e.g., context encoder becomes too complex), interpretability may be compromised.

## Foundational Learning

- **Concept**: Multi-task learning and context-specific modeling
  - Why needed here: The core innovation relies on treating each context as a separate learning task, which requires understanding how multi-task learning frameworks work and how to share information across tasks while maintaining task-specific capabilities
  - Quick check question: How does multi-task learning differ from meta-learning in the context of contextualized policies?

- **Concept**: Linear models and interpretability
  - Why needed here: CPR's interpretability comes from using linear observation-to-action mappings, so understanding the strengths and limitations of linear models in capturing decision dynamics is crucial
  - Quick check question: What are the key interpretability advantages of linear models compared to non-linear alternatives in policy learning?

- **Concept**: Recurrent neural networks and context encoding
  - Why needed here: The context encoder uses RNN/LSTM architectures to capture temporal dependencies in patient histories, requiring understanding of how these architectures process sequential data
  - Quick check question: How do RNNs and LSTMs differ in their ability to capture long-term dependencies in context information?

## Architecture Onboarding

- **Component map**: 
  - Context encoder (g): RNN/LSTM processes patient history and generates context embeddings
  - Policy generator: Linear layer maps context embeddings to policy coefficients
  - Observation-to-action function (f): Logistic regression uses policy coefficients to predict actions
  - Joint optimization: Binary cross-entropy loss with L1 regularization on policy coefficients

- **Critical path**: 
  1. Process patient history through context encoder to generate context embedding
  2. Generate context-specific policy coefficients from context embedding
  3. Apply linear policy to current observations to predict action probabilities
  4. Optimize all components jointly using imitation learning loss

- **Design tradeoffs**:
  - Linear vs non-linear policies: Linear policies ensure interpretability but may limit representational capacity
  - RNN vs LSTM for context encoding: LSTMs better capture long-term dependencies but are more complex
  - L1 vs L2 regularization: L1 promotes sparsity in policy coefficients, enhancing interpretability

- **Failure signatures**:
  - Poor performance on holdout data: Context encoder may not be capturing relevant information
  - Unstable policy coefficients: Regularization may be too weak or context encoder may be too noisy
  - No improvement over global models: Contexts may not be sufficiently distinct or informative

- **First 3 experiments**:
  1. Train CPR on a simple synthetic dataset with known context-dependent policies to verify it recovers true parameters
  2. Compare CPR performance against global logistic regression on a real medical dataset to establish baseline improvement
  3. Analyze policy coefficient stability across similar contexts to verify consistent interpretation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CPR perform in online policy inference settings where actions can influence future observations?
- Basis in paper: [explicit] The paper states CPR is "directly portable to online policy inference with only subtle training modifications" but does not provide experimental validation of this claim.
- Why unresolved: The experiments focus exclusively on offline settings, leaving the performance and adaptation mechanisms in online environments unexplored.
- What evidence would resolve it: Empirical studies comparing CPR's performance and adaptation speed in online versus offline settings, including metrics like regret and policy convergence rates.

### Open Question 2
- Question: What is the impact of increasing the dimensionality of contextual features on CPR's performance and interpretability?
- Basis in paper: [inferred] The paper demonstrates CPR's effectiveness with relatively low-dimensional features (7 for MIMIC, few for ADNI) but does not explore scalability with high-dimensional contexts.
- Why unresolved: The relationship between context dimensionality and the quality of generated interpretable policies remains unclear, particularly regarding computational efficiency and potential overfitting.
- What evidence would resolve it: Systematic experiments varying context feature dimensions while monitoring AUROC, AUPRC, and interpretability metrics across different medical datasets.

### Open Question 3
- Question: How sensitive is CPR to the choice of the lasso regularization parameter λ across different medical domains?
- Basis in paper: [explicit] The paper mentions selecting λ from [0.0001, 0.001, 0.01, 0.1] but does not analyze sensitivity or provide guidelines for choosing λ in different clinical contexts.
- Why unresolved: Without sensitivity analysis, practitioners cannot determine appropriate λ values for new domains, limiting CPR's practical applicability.
- What evidence would resolve it: Comprehensive sensitivity analysis showing how λ affects both performance metrics and the stability of recovered context-specific policies across diverse medical decision tasks.

## Limitations
- CPR's effectiveness may be limited in highly complex medical scenarios involving multi-stage treatments or highly interdependent decisions
- The method's performance depends heavily on the quality and definition of contextual features, which may be challenging to identify in some domains
- Current validation is limited to two specific medical decision tasks, raising questions about generalizability across diverse clinical domains

## Confidence
- **High Confidence**: The core mechanism of using context-specific linear policies with a black-box generator is well-supported by both theoretical framing and empirical results (+22% AUROC on antibiotic prediction, +7.7% AUROC on MRI prediction)
- **Medium Confidence**: The generalizability of CPR across diverse medical domains remains to be fully established, as current validation is limited to two specific tasks
- **Medium Confidence**: The interpretability claims are strong for linear policies but may be less clear for the black-box context encoder component

## Next Checks
1. **Cross-domain validation**: Apply CPR to a third medical decision task (e.g., chemotherapy prescription or surgical intervention decisions) to test generalizability beyond the current two domains
2. **Policy stability analysis**: Conduct systematic analysis of how policy coefficients vary across similar contexts to quantify the consistency and reliability of interpretability claims
3. **Black-box comparison rigor**: Implement and compare against a comprehensive suite of black-box models (deep ensembles, attention-based models) using identical training procedures to ensure fair performance benchmarking