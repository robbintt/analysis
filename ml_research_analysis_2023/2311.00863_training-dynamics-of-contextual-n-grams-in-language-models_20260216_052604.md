---
ver: rpa2
title: Training Dynamics of Contextual N-Grams in Language Models
arxiv_id: '2311.00863'
source_url: https://arxiv.org/abs/2311.00863
tags:
- german
- neuron
- context
- neurons
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies the training dynamics of contextual n-grams
  in language models, focusing on circuits involving a German language neuron. The
  key findings are: A contextual n-gram circuit was identified, where late-layer neurons
  detect and continue German n-grams, but only activate if a German language neuron
  in a prior layer is active.'
---

# Training Dynamics of Contextual N-Grams in Language Models

## Quick Facts
- arXiv ID: 2311.00863
- Source URL: https://arxiv.org/abs/2311.00863
- Authors: 
- Reference count: 5
- Key outcome: Language models learn contextual n-grams through gradual integration of pre-existing circuits rather than sudden phase transitions

## Executive Summary
This paper investigates how contextual n-grams form in language models by studying circuits involving a German language neuron. The research reveals that language models first learn independent circuits for language detection and n-gram prediction, which later integrate to form contextual representations. Surprisingly, this integration occurs gradually without reducing loss, and many early context neurons are quickly unlearned despite having little impact on final performance. These findings challenge assumptions about how language models represent contextual information and suggest more complex optimization dynamics than previously understood.

## Method Summary
The study analyzes Pythia 70M model checkpoints using sparse probing to identify German context neurons and track their development across training. Researchers measure neuron importance through mean ablation and direct logit attribution, examining how German trigrams depend on context neurons over time. The analysis focuses on 100 training checkpoints, using European Parliament multilingual data from The Pile to create balanced German and English validation sets. Cross-entropy loss is measured with and without neuron ablation, and direct/indirect effects are calculated to understand circuit formation dynamics.

## Key Results
- A contextual n-gram circuit was identified where late-layer neurons detect and continue German n-grams only when a prior German language neuron is active
- Both German detection and n-gram prediction circuits formed early in training but remained independent before gradually integrating later
- Many highly accurate German context neurons formed early but were quickly unlearned despite minimal impact on loss when ablated

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contextual n-grams form through gradual integration of pre-existing circuits rather than sudden phase transitions
- Mechanism: The model first learns independent circuits for German language detection and n-gram prediction. These circuits are initially disconnected. During later training stages, the model gradually creates connections between them, resulting in contextual n-grams that only activate when the German neuron is active
- Core assumption: Language model components can develop functional independence before forming integrated circuits
- Evidence anchors:
  - [abstract] "both the constituent n-gram circuits and the German detection circuit... form with independent functions early in training... Only after both circuits have already formed do they fit together into a second-order circuit."
  - [section] "we observed that almost all trigrams are learned at the same time, around checkpoint 10... During the same phase transition, we also observed the formation of German context neurons."
  - [corpus] Weak evidence - related work discusses circuit formation but not this specific gradual integration pattern
- Break condition: If independent circuit formation doesn't occur before integration, or if integration happens suddenly rather than gradually

### Mechanism 2
- Claim: Many context neurons form early but are quickly unlearned, despite having little impact on loss when ablated
- Mechanism: The model initially explores many possible contextual representations. Most are abandoned during training as the model settles on a few key circuits. This exploration phase creates temporary neurons that don't contribute significantly to final performance
- Core assumption: Language models benefit from initial exploration of multiple circuit architectures before specialization
- Evidence anchors:
  - [abstract] "we find that many context neurons form simultaneously early in training but are later unlearned."
  - [section] "we found a surprisingly large number of highly accurate German context neurons (229 neurons with a maximum F1 of 0.85 or higher at some point throughout training)... most of the early context neurons were only context neurons for a very short period of time before being unlearned."
  - [corpus] Weak evidence - related work on class-selective neurons shows similar patterns of temporary neuron formation
- Break condition: If early context neurons consistently contribute to performance, or if exploration phase is eliminated

### Mechanism 3
- Claim: The gradual formation of contextual n-gram circuits doesn't reduce loss, suggesting different optimization objectives than standard circuit formation
- Mechanism: While standard circuit formation reduces loss through improved predictions, contextual n-gram formation appears to serve other purposes like reducing interference or managing internal representations. This explains why loss doesn't decrease during their formation
- Core assumption: Language models optimize for objectives beyond just prediction accuracy
- Evidence anchors:
  - [abstract] "the contextual n-gram circuit itself does not seem to form in a phase transition, and does not increase n-gram prediction performance beyond what was learned in the n-gram phase transition."
  - [section] "the contextual n-gram circuit itself does not seem to form in a phase transition, and does not increase n-gram prediction performance beyond what was learned in the n-gram phase transition."
  - [corpus] Weak evidence - related work doesn't directly address circuits that don't reduce loss
- Break condition: If contextual n-gram formation consistently reduces loss, or if no alternative optimization objectives exist

## Foundational Learning

- Concept: Transformer attention mechanisms and residual connections
  - Why needed here: Understanding how information flows through layers is crucial for analyzing circuit formation and neuron interactions
  - Quick check question: How does mean ablation differ from standard ablation in transformer models?

- Concept: Sparse probing and neuron interpretability
  - Why needed here: The paper relies on sparse probing to identify German neurons, which is central to understanding circuit formation
  - Quick check question: What advantages does sparse probing offer over other neuron interpretation methods?

- Concept: Causal mediation analysis
  - Why needed here: The paper uses direct and indirect effects to understand how neurons influence model outputs
  - Quick check question: How do direct and indirect effects differ in their impact on model predictions?

## Architecture Onboarding

- Component map: Pythia 70M model with 12 layers, focusing on Layer 3 Neuron 669 (L3N669) as the primary German context neuron, plus late-layer neurons forming contextual n-gram circuits
- Critical path: Neuron activation → context detection → n-gram recognition → output prediction, with emphasis on the gradual connection formation between context and n-gram circuits
- Design tradeoffs: Early exploration of multiple context neurons vs. specialization in few key circuits; direct boosting of German tokens vs. indirect contextual effects
- Failure signatures: Phase transitions occurring at wrong checkpoints, n-grams not depending on context neurons when they should, loss not plateauing after initial learning
- First 3 experiments:
  1. Replicate neuron identification using sparse probing on English/German activation data
  2. Measure direct vs indirect effects of L3N669 ablation across training checkpoints
  3. Test n-gram dependency on context neurons by comparing predictions with and without context neuron activation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do contextual n-gram circuits form gradually from existing components rather than through sudden phase transitions, and what is their functional purpose if they don't reduce loss?
- Basis in paper: [explicit] The paper discusses how the contextual n-gram circuit forms gradually after its constituent circuits are already present, and notes that this second-order circuit formation does not correspond to a reduction in loss, raising questions about its purpose
- Why unresolved: The paper identifies this as a mystery and speculates about potential purposes like reducing superposition interference, but does not provide definitive evidence
- What evidence would resolve it: Experiments ablating the contextual n-gram circuit to measure impact on loss and other metrics, or studying whether the circuit reduces interference from superposition in practice

### Open Question 2
- Question: What causes the large number of highly accurate German context neurons that form early in training but are quickly unlearned, despite having little impact on loss when ablated?
- Basis in paper: [explicit] The paper notes that many highly accurate German context neurons form during a phase transition early in training, but most are quickly unlearned and have little impact on loss when ablated, raising questions about why they form at all
- Why unresolved: The paper does not provide a clear explanation for this phenomenon, only noting its similarity to class-selective neurons found in image classification models
- What evidence would resolve it: Studying the training dynamics and loss landscape around these neurons to understand why they form and are later unlearned, or experiments to test their impact on other metrics beyond loss

### Open Question 3
- Question: Is the simultaneous phase transition in which both the n-gram circuit and German detection circuit are learned primarily caused by the learning rate warm-up, or is it a natural phase transition?
- Basis in paper: [inferred] The paper suggests that the universal phase transition could plausibly be caused by the learning rate warm-up used in the Pythia models, raising the question of whether it's an idiosyncrasy of the optimizer or a natural phase transition
- Why unresolved: The paper does not definitively determine the cause of this phase transition
- What evidence would resolve it: Experiments training models with different learning rate schedules or without warm-up to see if the phase transition still occurs, or analyzing the loss landscape to understand the underlying cause of the transition

## Limitations
- Findings are based on a single model architecture (Pythia 70M) and specific language pair (German/English)
- Paper doesn't explore potential latent utility of early context neurons beyond standard ablation metrics
- Limited investigation into whether observed patterns represent fundamental optimization strategies or experimental artifacts

## Confidence
- High confidence: The identification of independent circuit formation for German detection and n-gram prediction
- Medium confidence: The interpretation that contextual n-gram formation serves purposes beyond loss reduction
- Medium confidence: The claim about extensive early exploration of context neurons

## Next Checks
1. Test whether the gradual circuit integration pattern holds across different model sizes (e.g., Pythia 160M, 410M) and language pairs to assess generalizability
2. Design experiments to probe potential latent functions of early context neurons, such as measuring their impact on gradient flow or internal representation stability rather than just final output loss
3. Investigate whether forcing contextual dependency earlier in training (through architectural modifications or training interventions) affects the emergence of language-specific representations or overall model performance