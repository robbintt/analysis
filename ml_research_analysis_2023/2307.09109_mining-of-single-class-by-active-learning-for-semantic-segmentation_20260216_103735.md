---
ver: rpa2
title: Mining of Single-Class by Active Learning for Semantic Segmentation
arxiv_id: '2307.09109'
source_url: https://arxiv.org/abs/2307.09109
tags:
- accuracy
- learning
- patches
- class
- active
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MiSiCAL introduces a lightweight active learning method for semantic
  segmentation that selects image patches from underrepresented classes without retraining
  the segmentation model between selections. The method uses a Double Deep Q-Network
  (DDQN) that takes BALD uncertainty and class presence features as input to optimize
  patch selection for specific classes.
---

# Mining of Single-Class by Active Learning for Semantic Segmentation

## Quick Facts
- **arXiv ID:** 2307.09109
- **Source URL:** https://arxiv.org/abs/2307.09109
- **Authors:** [Not specified in source]
- **Reference count:** 40
- **Primary result:** MiSiCAL outperforms random sampling on 150 of 171 COCO10k classes while strongest baseline outperforms random on only 101 classes

## Executive Summary
MiSiCAL introduces a lightweight active learning method for semantic segmentation that selects image patches from underrepresented classes without retraining the segmentation model between selections. The method uses a Double Deep Q-Network (DDQN) that takes BALD uncertainty and class presence features as input to optimize patch selection for specific classes. By leveraging fixed representations from a pretrained segmentation model, MiSiCAL achieves significant computational efficiency for large batch sizes while maintaining strong performance improvements for difficult classes like SKIS and FORK.

## Method Summary
MiSiCAL employs a Double Deep Q-Network that learns to select patches containing underrepresented classes by exploiting correlations with more frequently occurring classes. The method trains a semantic segmentation model once on an initial dataset, then uses its fixed BALD uncertainty and class presence features as inputs to the DDQN. The DDQN learns through reinforcement learning to weight these features optimally without manual tuning. Categorical rewards based on class presence guide the selection process, and a multistep prioritized experience replay buffer stores training data. The approach avoids costly model retraining between selections, making it particularly efficient for large batch sizes.

## Key Results
- Outperforms random sampling on 150 of 171 COCO10k classes
- Achieves significant improvements for difficult underrepresented classes like SKIS and FORK
- Strong efficiency for large batch sizes due to fixed model representations
- Strongest baseline outperforms random on only 101 classes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MiSiCAL outperforms random sampling on 150 of 171 COCO10k classes by exploiting correlations between underrepresented classes and more frequently occurring classes.
- Mechanism: The DDQN learns to select patches containing underrepresented classes by recognizing co-occurrence patterns with other classes that are easier for the segmentation model to identify.
- Core assumption: There exist strong correlations between underrepresented classes and other classes that the DDQN can exploit.
- Evidence anchors: [abstract] "MiSiCAL is able to outperform a random policy on 150 out of 171 COCO10k classes"
- Break condition: If class correlations are weak or the segmentation model performs poorly on all co-occurring classes.

### Mechanism 2
- Claim: The fixed representations from the pretrained segmentation model enable efficient large-batch selection without repeated model retraining.
- Mechanism: The segmentation model is trained once on the initial dataset, then its fixed features are used throughout the active learning process.
- Core assumption: The fixed representations from the initial model training are sufficiently informative for patch selection across the entire active learning process.
- Evidence anchors: [abstract] "MiSiCAL is especially helpful in the case of very large batch sizes since it does not require repeated model training sessions"
- Break condition: If the initial model becomes too outdated or the dataset distribution shifts significantly.

### Mechanism 3
- Claim: The DDQN learns an optimal weighting between BALD uncertainty and class presence features without manual tuning.
- Mechanism: The DDQN takes both BALD uncertainty and class presence features as input and learns through reinforcement learning to weight these features appropriately.
- Core assumption: The optimal weighting between uncertainty and class presence features can be learned through reinforcement learning.
- Evidence anchors: [abstract] "Using reinforcement learning (RL) to directly learn an active learning policy...was introduced in the NLP literature and showed great promise"
- Break condition: If the reward signal is too sparse or noisy, the DDQN may fail to learn effective feature weighting.

## Foundational Learning

- **Deep Q-Learning and Double Deep Q-Networks**: The DDQN forms the core of the patch selection algorithm, learning to maximize rewards based on patch features. *Quick check:* What is the key difference between DQN and DDQN that helps prevent overestimation of Q-values?

- **Active Learning and Uncertainty Sampling**: Understanding traditional AL methods provides context for why MiSiCAL's approach is novel and advantageous. *Quick check:* How does BALD uncertainty differ from entropy in measuring model uncertainty?

- **Semantic Segmentation and IoU Metrics**: The method optimizes segmentation performance for specific classes using IoU as the evaluation metric. *Quick check:* Why is IoU a more appropriate metric than pixel accuracy for evaluating segmentation performance?

## Architecture Onboarding

- **Component map**: Initial dataset preparation (DL,init) -> Pretrained segmentation model (fixed during AL) -> Feature extraction (BALD + class presence) -> DDQN for patch selection -> Reward calculation based on class presence -> Replay buffer with prioritized experience replay -> Target network for stable Q-value updates

- **Critical path**: 1. Train segmentation model on DL,init 2. Extract fixed features for all patches 3. Pretrain DDQN on DL,init 4. Iteratively select patches and update DDQN 5. Evaluate class-specific IoU performance

- **Design tradeoffs**: Fixed model vs. continuous retraining (saves computation but may become outdated), Patch-based vs. whole-image selection (more efficient but requires careful context handling), Categorical rewards vs. continuous rewards (simpler but may lose granularity)

- **Failure signatures**: DDQN loss not converging or oscillating, Selected patches not containing target class despite high Q-values, Class-specific IoU not improving despite successful patch acquisition, Buffer prioritization leading to sampling bias

- **First 3 experiments**: 1. Verify that the pretrained segmentation model provides stable BALD and class presence features across the dataset 2. Test DDQN performance on a simplified version with synthetic data and known correlations 3. Compare categorical vs. continuous reward schemes on a small subset of classes to validate reward design

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would MiSiCAL perform on datasets with significant class imbalance compared to balanced datasets?
- Basis in paper: [inferred] The paper mentions that MiSiCAL exploits correlations between classes and benefits from the logarithm of pixel counts correlating with class IoU, but does not explicitly test on highly imbalanced datasets like Cityscapes.
- Why unresolved: The paper primarily tests on COCO10k, which has some class imbalance but is not as extreme as datasets like Cityscapes.
- What evidence would resolve it: Testing MiSiCAL on highly imbalanced datasets like Cityscapes or ADE20K and comparing its performance to other active learning methods.

### Open Question 2
- Question: Can MiSiCAL's performance be improved by incorporating additional uncertainty metrics beyond BALD and entropy?
- Basis in paper: [explicit] The paper uses BALD uncertainty and class presence features as inputs to the DDQN but mentions that other uncertainty metrics exist.
- Why unresolved: The paper focuses on BALD and entropy as the primary uncertainty metrics, leaving open the question of whether incorporating additional metrics could enhance performance.
- What evidence would resolve it: Implementing MiSiCAL with additional uncertainty metrics and comparing its performance to the original version.

### Open Question 3
- Question: How sensitive is MiSiCAL to the choice of hyperparameters like the discount factor γ and the soft update rate β?
- Basis in paper: [explicit] The paper discusses the impact of γ and β on the DDQN's behavior and performance but does not provide a comprehensive sensitivity analysis.
- Why unresolved: While the paper explores some hyperparameter choices, it does not systematically vary these parameters to determine their optimal ranges.
- What evidence would resolve it: Conducting a thorough hyperparameter sensitivity analysis by varying γ and β across a wide range of values.

## Limitations
- Reliance on strong correlations between underrepresented and frequently occurring classes may not hold for all datasets
- Fixed representations from initial model may become outdated if dataset distribution shifts
- Limited evidence about reward signal quality and convergence behavior of the DDQN

## Confidence
- **High Confidence**: Computational efficiency claims for large batch sizes, supported by elimination of repeated model retraining
- **Medium Confidence**: Overall improvement in class-specific IoU metrics, based on reported 150/171 class improvements
- **Low Confidence**: Mechanism by which DDQN learns optimal feature weighting without manual tuning, due to limited evidence about reward signal quality

## Next Checks
1. Quantify actual correlation coefficients between underrepresented and frequently occurring classes in COCO10k to validate assumed correlations
2. Track how BALD uncertainty and class presence features evolve as more patches are selected, testing whether fixed representations remain informative
3. Compare categorical versus continuous reward schemes in controlled experiment with small subset of classes to determine optimal reward design