---
ver: rpa2
title: 'CrossEAI: Using Explainable AI to generate better bounding boxes for Chest
  X-ray images'
arxiv_id: '2310.19835'
source_url: https://arxiv.org/abs/2310.19835
tags:
- bounding
- chest
- heatmap
- gradient
- x-ray
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of generating accurate bounding
  boxes for disease localization in chest X-ray images. Existing methods using heatmap-based
  approaches produce bounding boxes that are often larger than the ground truth and
  contain significant non-disease areas, resulting in low Intersection over Union
  (IoU) scores.
---

# CrossEAI: Using Explainable AI to generate better bounding boxes for Chest X-ray images

## Quick Facts
- arXiv ID: 2310.19835
- Source URL: https://arxiv.org/abs/2310.19835
- Reference count: 14
- Primary result: 9% improvement in average IoU over ChexRadiNet for chest X-ray disease localization

## Executive Summary
This paper addresses the challenge of generating accurate bounding boxes for disease localization in chest X-ray images. Existing heatmap-based methods produce bounding boxes that are often larger than ground truth and contain significant non-disease areas. The proposed CrossEAI method combines gradient maps from Guided Backpropagation with heatmaps from Grad-CAM++ through weighted averaging, producing more precise bounding boxes that are closer to ground truth. Evaluated on the NIH ChestX-ray8 dataset, CrossEAI achieves a 9% improvement in average IoU across all diseases compared to the state-of-the-art method ChexRadiNet, while also matching the performance of models that use 80% of ground truth bounding box information during training.

## Method Summary
CrossEAI combines gradient-based visualization (Guided Backpropagation) with class-discriminative heatmaps (Grad-CAM++) to generate precise bounding boxes for chest X-ray disease localization. The method uses a ResNet-50 backbone with triplet attention trained through self-supervised contrastive learning on patient metadata. Gradient maps provide high-resolution structural details while heatmaps filter non-disease areas, and their weighted combination produces a class-discriminative, high-resolution map. A dynamic programming algorithm then generates optimal bounding boxes by expanding candidate rectangles and selecting the one with maximum average intensity within the masked region. The method achieves comparable performance to supervised approaches without requiring ground truth bounding box supervision during training.

## Key Results
- Achieves 9% improvement in average IoU across all diseases compared to ChexRadiNet
- Generates smaller, more focused bounding boxes with better disease localization
- Matches performance of models trained with 80% ground truth bounding box information
- Successfully localizes 8 different diseases in chest X-ray images without using ground truth bounding boxes during training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weighted averaging of Guided Backpropagation and Grad-CAM++ produces better bounding boxes by combining high-resolution detail with class-discriminative localization
- Mechanism: Guided Backpropagation provides high-resolution gradient maps that highlight fine-grained structural details, while Grad-CAM++ generates class-discriminative heatmaps that focus on disease-relevant regions. The weighted combination preserves high-resolution detail while filtering out non-disease areas using the heatmap's discriminative properties.
- Core assumption: The weighted combination effectively filters noise while preserving disease-relevant details, and the dynamic programming approach can reliably extract optimal bounding boxes
- Evidence anchors: Abstract states "weighted average of Guided Backpropagation and Grad-CAM++" generates bounding boxes "closer to the ground truth"; section confirms "high-resolution due to contribution of gradient map" and "class-discriminative because the low intensity areas in the heatmap filter the high gradient from other class"
- Break condition: Poor choice of weighting parameter t, excessive noise in gradient map, or failure of heatmap to properly discriminate disease regions

### Mechanism 2
- Claim: CrossEAI achieves comparable performance to supervised methods without using ground truth bounding box information
- Mechanism: The method leverages self-supervised contrastive learning for disease classification, which learns discriminative features without requiring precise localization supervision. Explainable AI components then extract localization information from these learned features through gradient and activation analysis.
- Core assumption: The classification model learns sufficient discriminative features that contain implicit localization information, which can be extracted through gradient-based methods
- Evidence anchors: Abstract states "we achieve same performance in general as the model that uses 80% of the ground truth bounding box information for training"; section describes contrastive learning using patient metadata
- Break condition: Failure of contrastive learning to learn disease-discriminative features, or inability of gradient-based methods to extract meaningful spatial information

### Mechanism 3
- Claim: Dynamic programming with candidate rectangle expansion produces optimal bounding boxes from the combined heatmaps
- Mechanism: The algorithm generates multiple candidate rectangles from the combined map, then expands them uniformly while monitoring the ratio of included pixels, selecting the rectangle with maximum average intensity within the masked region as the final bounding box
- Core assumption: The highest average intensity rectangle corresponds to the most disease-relevant region, and the expansion criteria effectively balances coverage with precision
- Evidence anchors: Section describes using "dynamic programming to generate maximum area rectangles as candidate bounding box" and selecting "the rectangle with the maximum average pixel intensity mapped in the masked new map"
- Break condition: If intensity distribution doesn't correlate with disease presence, or if expansion threshold doesn't properly balance precision and recall

## Foundational Learning

- Concept: Gradient-based visualization methods (Guided Backpropagation vs Grad-CAM++)
  - Why needed here: Understanding the complementary strengths of these methods is crucial for grasping why their combination works better than either alone
  - Quick check question: What is the key difference between Guided Backpropagation and Grad-CAM++ in terms of what they preserve vs what they filter?

- Concept: Contrastive learning for medical image classification
  - Why needed here: The paper uses patient-based supervised contrastive learning as the classification backbone, which is essential for understanding how the model learns without localization supervision
  - Quick check question: How does the contrastive loss help the model learn disease-discriminative features when no bounding box supervision is provided?

- Concept: Intersection over Union (IoU) as an evaluation metric
  - Why needed here: IoU is the primary metric for evaluating bounding box quality, and understanding its calculation is essential for interpreting the results
  - Quick check question: If a predicted bounding box has area 100 and overlaps with ground truth by 40 pixels, what is the IoU if the ground truth area is 50?

## Architecture Onboarding

- Component map: Image → ResNet-50 → Classification + Contrastive Loss → Guided Backprop + Grad-CAM++ → Weighted Average → Thresholding → Dynamic Programming → Bounding Box
- Critical path: Image → ResNet-50 → Classification + Contrastive Loss → Guided Backprop + Grad-CAM++ → Weighted Average → Thresholding → Dynamic Programming → Bounding Box
- Design tradeoffs:
  - Using heatmap alone would provide class discrimination but lose fine details
  - Using gradient map alone would provide details but include non-disease areas
  - The weighted combination requires tuning the parameter t for optimal performance
  - Not using ground truth bounding boxes for training reduces supervision requirements but may limit maximum achievable accuracy
- Failure signatures:
  - Bounding boxes consistently larger than ground truth suggests over-weighting of gradient map
  - Bounding boxes missing disease regions suggests under-weighting of gradient map or poor thresholding
  - Poor IoU across all diseases suggests fundamental issues with either the classification model or the localization algorithm
- First 3 experiments:
  1. Ablation study: Test bounding box quality using only Guided Backpropagation, only Grad-CAM++, and the weighted combination to verify the improvement mechanism
  2. Parameter sensitivity: Systematically vary the weighting parameter t and threshold percentage to find optimal values for different disease types
  3. Comparison with ground truth supervision: Train a model with 80% ground truth bounding boxes and compare IoU performance to evaluate the cost-benefit tradeoff of unsupervised localization

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several implicit questions arise from the methodology and results that would benefit from further investigation.

## Limitations
- Dynamic programming algorithm for bounding box generation lacks detailed specification, creating uncertainty in exact reproduction
- Fixed weighting parameter t=0.30 may not be optimal across all disease types and imaging conditions
- Reliance on high-quality gradient maps and heatmaps assumes these visualization techniques accurately reflect disease-relevant features for all pathologies
- Limited number of ground truth annotations (880 images) in NIH ChestX-ray8 dataset constrains robustness validation

## Confidence
**High Confidence**: The core mechanism of combining gradient maps with heatmaps through weighted averaging is well-established in explainable AI literature. The 9% IoU improvement over ChexRadiNet and comparable performance to supervised methods are supported by quantitative metrics.

**Medium Confidence**: The dynamic programming bounding box generation algorithm's specific implementation details and parameter choices are not fully specified, creating uncertainty in exact reproduction. The generalizability across different chest X-ray datasets and disease types requires further validation.

**Low Confidence**: The contrastive learning framework's effectiveness without localization supervision and its ability to learn disease-discriminative features for all 8 target diseases needs more extensive testing across diverse populations.

## Next Checks
1. **Ablation Study**: Systematically evaluate bounding box quality using only Guided Backpropagation, only Grad-CAM++, and the weighted combination across all 8 disease types to quantify the contribution of each component.

2. **Parameter Sensitivity Analysis**: Conduct a grid search over the weighting parameter t (0.1-0.9) and intensity threshold (25-50%) to identify optimal values for different disease categories and assess robustness.

3. **Cross-Dataset Validation**: Test the method on an independent chest X-ray dataset with ground truth annotations to evaluate generalization beyond the NIH ChestX-ray8 dataset and assess performance consistency across different imaging protocols and patient populations.