---
ver: rpa2
title: When is Agnostic Reinforcement Learning Statistically Tractable?
arxiv_id: '2310.06113'
source_url: https://arxiv.org/abs/2310.06113
tags:
- policy
- learning
- which
- bound
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the sample complexity of agnostic reinforcement
  learning (RL) where the goal is to learn a near-optimal policy with respect to a
  given policy class without modeling assumptions on the underlying Markov Decision
  Process (MDP). The authors introduce a new complexity measure called the spanning
  capacity that depends only on the policy class and is independent of the MDP dynamics.
---

# When is Agnostic Reinforcement Learning Statistically Tractable?

## Quick Facts
- arXiv ID: 2310.06113
- Source URL: https://arxiv.org/abs/2310.06113
- Authors: 
- Reference count: 40
- Key outcome: This paper introduces spanning capacity as a complexity measure for agnostic RL, showing it characterizes learnability under a generative model but not online RL, necessitating an additional sunflower property for the latter.

## Executive Summary
This paper studies the sample complexity of agnostic reinforcement learning, where the goal is to find a near-optimal policy within a given policy class without modeling assumptions on the MDP. The authors introduce a new complexity measure called spanning capacity that depends only on the policy class and show it characterizes the minimax sample complexity for agnostic PAC RL under a generative model. However, they also provide a surprising negative result showing that bounded spanning capacity alone is insufficient for online RL, revealing a separation between generative and online interaction models. To address this, the authors propose an additional sunflower property on the policy class that, together with bounded spanning capacity, enables statistically efficient online RL via a new algorithm called POPLER.

## Method Summary
The paper introduces spanning capacity as a measure of the maximum number of state-action pairs reachable by any policy in the class within any deterministic MDP. For generative model RL, the authors show that spanning capacity characterizes the minimax sample complexity for agnostic PAC learning. For online RL, they demonstrate a lower bound showing bounded spanning capacity alone is insufficient, and propose the sunflower property as a sufficient condition for efficient online learning. The POPLER algorithm leverages importance sampling and reachable state identification techniques to estimate policy values under the sunflower property.

## Key Results
- Spanning capacity characterizes the minimax sample complexity for agnostic PAC RL under a generative model.
- Bounded spanning capacity alone is insufficient for online RL, revealing a separation between generative and online interaction models.
- The sunflower property, together with bounded spanning capacity, enables statistically efficient online RL via the POPLER algorithm.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The spanning capacity characterizes the minimax sample complexity for agnostic PAC RL under a generative model.
- Mechanism: The spanning capacity measures the maximum number of state-action pairs reachable by any policy in the class within any deterministic MDP. This directly bounds the size of the trajectory tree needed to estimate policy values unbiasedly, since each trajectory tree can only explore states reachable by the policy class.
- Core assumption: The policy class has bounded spanning capacity and the underlying MDP is deterministic or can be effectively "derandomized" for the analysis.
- Evidence anchors:
  - [abstract] "With a generative model, we show that for any policy class Π, bounded spanning capacity characterizes PAC learnability."
  - [section] "The spanning capacity precisely captures the intuition that trajectories obtained by running any π ∈ Π have 'low complexity.'"
- Break condition: If the policy class has unbounded spanning capacity, the trajectory tree method requires exponentially many samples in the horizon, matching the worst-case lower bound.

### Mechanism 2
- Claim: Bounded spanning capacity alone is insufficient for online RL, revealing a separation between generative and online interaction models.
- Mechanism: In online RL, the learner cannot "reset" to explore different parts of the state space efficiently. The lower bound construction uses a family of combination locks where policies differ substantially on a large subset of states, making it impossible to learn efficiently via low-variance importance sampling.
- Core assumption: The online interaction model does not allow the learner to revisit states arbitrarily, unlike the generative model.
- Evidence anchors:
  - [abstract] "We show there exists a policy class Π with a bounded spanning capacity that requires a superpolynomial number of samples to learn."
  - [section] "In the vanilla combination lock, it becomes easy to learn π⋆ via trajectory data, since once the learner observes a jump to the 'bad' chain, they can immediately eliminate many candidate policies."
- Break condition: If the online interaction model allowed arbitrary state resets or if the policy class had additional structure (like the sunflower property), the separation might not hold.

### Mechanism 3
- Claim: The sunflower property, together with bounded spanning capacity, enables statistically efficient online RL via the POPLER algorithm.
- Mechanism: The sunflower property allows policies to be partitioned into a core set and petals, where petals only differ from the core in structured ways. This enables importance sampling with controlled bias and variance, and guides exploration to find reachable states efficiently.
- Core assumption: The policy class can be decomposed into a small core set and petals with bounded size, and the spanning capacity is bounded.
- Evidence anchors:
  - [abstract] "On the positive side, we identify an additional sunflower structure, which in conjunction with bounded spanning capacity enables statistically efficient online RL via a new algorithm called POPLER."
  - [section] "POPLER leverages importance sampling as well as reachable state identification techniques to estimate the values of policies."
- Break condition: If the policy class does not have the sunflower property, or if the core set or petals are too large, the sample complexity bound degrades.

## Foundational Learning

- Concept: Markov Decision Processes (MDPs) and policy-based reinforcement learning.
  - Why needed here: The paper studies the sample complexity of learning near-optimal policies in MDPs, so understanding the MDP framework and policy evaluation is fundamental.
  - Quick check question: What is the difference between the value function V^π and the state-action value function Q^π?

- Concept: Agnostic PAC learning and sample complexity.
  - Why needed here: The paper's goal is to find an ε-suboptimal policy with respect to a given policy class, without modeling assumptions, which is the agnostic PAC learning objective. Understanding sample complexity bounds is crucial.
  - Quick check question: What is the relationship between the VC dimension and the sample complexity of agnostic PAC learning in supervised learning?

- Concept: Importance sampling and trajectory trees.
  - Why needed here: The paper uses importance sampling for policy evaluation and trajectory trees for exploration in the generative model. These are key technical tools.
  - Quick check question: How does the variance of the importance sampling estimator scale with the number of actions and horizon?

## Architecture Onboarding

- Component map: Spanning capacity measure -> Generative model bounds -> Online RL lower bound -> Sunflower property -> POPLER algorithm
- Critical path: To understand the paper, one should first grasp the spanning capacity and its role in characterizing learnability under the generative model. Then, understand why spanning capacity alone is insufficient for online RL via the lower bound. Finally, see how the sunflower property enables efficient online learning via POPLER.
- Design tradeoffs: The paper trades off between generality (agnostic RL without modeling assumptions) and statistical efficiency (polynomial sample complexity). The sunflower property is a structural assumption that enables efficiency but may not hold for all policy classes.
- Failure signatures: If the spanning capacity is unbounded, the generative model lower bound applies. If the sunflower property does not hold, the online RL lower bound applies. If the policy class is too complex, the POPLER algorithm may not be computationally efficient.
- First 3 experiments:
  1. Verify the spanning capacity bound for a simple policy class like singletons or contextual bandits.
  2. Implement the POPLER algorithm and test it on a policy class with the sunflower property.
  3. Construct a policy class that satisfies the sunflower property but has large spanning capacity, and verify the sample complexity bound degrades.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is there a complexity measure that tightly characterizes the minimax sample complexity for online RL agnostic PAC learning, combining both spanning capacity and the sunflower property?
- Basis in paper: [explicit] The authors discuss the sunflower property as a sufficient condition for efficient online RL but leave open whether it is also necessary or if it can be relaxed.
- Why unresolved: The paper shows that bounded spanning capacity alone is insufficient and that the sunflower property is sufficient, but does not prove if the sunflower property is necessary or if a weaker condition could suffice.
- What evidence would resolve it: A proof showing that any policy class with bounded spanning capacity but not the sunflower property requires superpolynomial sample complexity in online RL, or a new complexity measure that unifies spanning capacity and the sunflower property and is both necessary and sufficient.

### Open Question 2
- Question: Can coverability alone characterize instance-dependent sample complexity for agnostic PAC RL in the generative model setting?
- Basis in paper: [inferred] The authors note that spanning capacity is the worst-case coverability and ask if coverability of the underlying MDP and policy class characterizes instance-dependent complexity under the generative model.
- Why unresolved: The paper focuses on minimax complexity and does not investigate instance-dependent bounds, leaving open whether coverability is sufficient for instance-dependent characterizations.
- What evidence would resolve it: An algorithm achieving instance-dependent bounds scaling with the coverability coefficient of the specific MDP and policy class, or a lower bound showing that coverability is insufficient for some MDP-policy class pairs.

### Open Question 3
- Question: How does the availability of Q* feedback (expert feedback) affect the sample complexity of agnostic PAC RL when the optimal policy is not in the policy class?
- Basis in paper: [explicit] The authors investigate this in Appendix I, showing that Q* feedback cannot circumvent the spanning capacity lower bound when the optimal policy is not in the class.
- Why unresolved: The analysis is limited to showing that spanning capacity is still a barrier, but does not explore whether other types of expert feedback or structural assumptions could improve sample complexity.
- What evidence would resolve it: An algorithm using Q* feedback that achieves sample complexity independent of spanning capacity under additional assumptions, or a lower bound showing that no feedback model can circumvent the spanning capacity barrier without realizability.

### Open Question 4
- Question: What are the computational complexity implications of the sunflower property for designing efficient agnostic PAC RL algorithms?
- Basis in paper: [inferred] The authors note that their POPLER algorithm runs in time polynomial in |Π|, S, A, H, which can be prohibitive, and suggest exploring computationally efficient or oracle-efficient algorithms.
- Why unresolved: The paper does not address the computational complexity of verifying the sunflower property or implementing POPLER for large-scale problems.
- What evidence would resolve it: An algorithm that efficiently verifies the sunflower property or a reduction showing that solving the sunflower property verification is as hard as solving the agnostic RL problem itself.

## Limitations
- The sunflower property, while enabling efficient online learning, may not hold for many practical policy classes, potentially limiting the applicability of the POPLER algorithm.
- The computational efficiency of the POPLER algorithm for large-scale problems is not well-characterized.
- The paper focuses on statistical efficiency (sample complexity) and does not explicitly analyze the computational complexity of the algorithms.

## Confidence

**High Confidence:**
- The characterization of spanning capacity as necessary and sufficient for agnostic PAC learnability under the generative model is well-supported by the theoretical analysis and matches intuitive expectations about trajectory tree complexity.
- The construction of the online RL lower bound using combination locks effectively demonstrates the separation between generative and online models.

**Medium Confidence:**
- The sufficiency of the sunflower property in conjunction with bounded spanning capacity for online RL is theoretically sound but relies on assumptions about the policy class structure that may not always hold in practice.
- The sample complexity bounds for the POPLER algorithm are derived under idealized conditions and may degrade in practice due to implementation challenges or approximation errors.

**Low Confidence:**
- The computational efficiency of the POPLER algorithm for large-scale problems is not well-characterized, leaving open questions about its practical applicability.

## Next Checks

1. **Verify the spanning capacity calculation on diverse policy classes**: Implement the spanning capacity measure and test it on various policy classes beyond the simple examples provided (contextual bandits, tabular MDPs). This will help assess the generality of the spanning capacity as a complexity measure.

2. **Experimentally validate the POPLER algorithm**: Implement the POPLER algorithm and evaluate its performance on synthetic MDPs where the sunflower property holds. Measure both statistical efficiency (sample complexity) and computational efficiency to assess practical feasibility.

3. **Test the robustness of the sunflower property assumption**: Construct policy classes that satisfy the sunflower property but have varying degrees of complexity (e.g., different core set sizes, petal structures). Evaluate whether the POPLER algorithm's sample complexity bounds degrade as expected when the sunflower property is only approximately satisfied.