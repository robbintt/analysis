---
ver: rpa2
title: Ensembled Prediction Intervals for Causal Outcomes Under Hidden Confounding
arxiv_id: '2306.09520'
source_url: https://arxiv.org/abs/2306.09520
tags:
- causal
- outcome
- intervals
- sensitivity
- coverage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes Caus-Modens, a method for estimating tighter
  prediction intervals for causal outcomes under hidden confounding. Caus-Modens uses
  an ensemble of outcome predictors and modulates their weights based on a sensitivity
  model to bound the impact of hidden confounders.
---

# Ensembled Prediction Intervals for Causal Outcomes Under Hidden Confounding

## Quick Facts
- arXiv ID: 2306.09520
- Source URL: https://arxiv.org/abs/2306.09520
- Reference count: 16
- Key outcome: Caus-Modens achieves tighter prediction intervals for causal outcomes under hidden confounding by optimizing ensemble weights based on sensitivity models.

## Executive Summary
Caus-Modens is a novel method for estimating tighter prediction intervals for causal outcomes when hidden confounding is present. The approach uses an ensemble of outcome predictors and modulates their weights based on a sensitivity model to bound the impact of hidden confounders. By optimizing ensemble weights to maximize the upper quantile and minimize the lower quantile of predictions, Caus-Modens produces individual causal outcome intervals that achieve better coverage efficiency than state-of-the-art conformal methods. The method is evaluated on three benchmarks, including a novel usage of GPT-4, demonstrating tighter outcome intervals while maintaining target coverage.

## Method Summary
Caus-Modens constructs prediction intervals by training an ensemble of outcome predictors on observational data, then modulating their weights using a sensitivity model for hidden confounding. The method employs a greedy optimization algorithm to find ensemble weights that maximize the (1-α/2) quantile and minimize the (α/2) quantile of the ensemble predictions. This approach leverages the structure of the ensemble to extrapolate to causal outcomes rather than relying solely on empirical performance as in conformal methods. The optimized ensemble is then used to construct outcome intervals that are evaluated on causal test sets with interventions.

## Key Results
- Caus-Modens achieves tighter outcome intervals compared to conformal methods while maintaining target coverage levels
- The method demonstrates effectiveness across three benchmarks, including a novel GPT-4 based evaluation
- Coverage efficiency improves as measured by smaller interval sizes needed to achieve target coverage (90%, 95%, 99%)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Caus-Modens tightens outcome intervals by optimizing ensemble weights to maximize the upper quantile and minimize the lower quantile of predictions.
- Mechanism: Uses a sensitivity model to bound the impact of hidden confounders and modulates ensemble weights to maximize the (1-α/2) quantile and minimize the (α/2) quantile of ensemble predictions.
- Core assumption: The ensemble of predictors captures empirical uncertainties from observational data and can be reweighted to approximate the distribution of causal outcomes.
- Evidence anchors: [abstract], [section]

### Mechanism 2
- Claim: The greedy optimization algorithm for quantile maximization is optimal under the given constraints.
- Mechanism: The algorithm transfers weights between ensemble components to maximize the β-quantile until no further improvement is possible under the sensitivity bounds.
- Core assumption: The optimality condition ensures that no pair of components can improve the quantile by transferring weight between them.
- Evidence anchors: [section]

### Mechanism 3
- Claim: Caus-Modens achieves tighter intervals than conformal methods by leveraging the structure of the ensemble rather than relying solely on empirical performance.
- Mechanism: Conformal methods use the observed distribution to size intervals, which can be overly conservative under hidden confounding. Caus-Modens uses the ensemble structure to extrapolate to causal outcomes.
- Core assumption: The ensemble's inductive biases and learned structure help it generalize better to causal outcomes than conformal methods that only consider empirical performance.
- Evidence anchors: [section]

## Foundational Learning

- Concept: Bayesian posterior predictive distribution
  - Why needed here: Caus-Modens relies on drawing an ensemble of predictors from a posterior to capture empirical uncertainties.
  - Quick check question: What does the posterior predictive distribution represent in the context of causal inference?

- Concept: Sensitivity models for hidden confounding
  - Why needed here: Caus-Modens uses a sensitivity model to bound the impact of hidden confounders and modulate ensemble weights.
  - Quick check question: How do sensitivity models allow for partial identification of causal effects under hidden confounding?

- Concept: Quantile regression and prediction intervals
  - Why needed here: Caus-Modens constructs outcome intervals by optimizing ensemble quantiles rather than using conformal prediction.
  - Quick check question: What is the difference between conformal prediction intervals and the outcome intervals constructed by Caus-Modens?

## Architecture Onboarding

- Component map: Ensemble of outcome predictors -> Sensitivity model for hidden confounding -> Greedy optimization algorithm for quantile maximization -> Causal test set with interventions

- Critical path:
  1. Train an ensemble of outcome predictors on observational data
  2. Specify a sensitivity model and obtain weight bounds
  3. Apply the greedy optimization algorithm to find optimal ensemble weights
  4. Construct outcome intervals using the optimized ensemble
  5. Evaluate intervals on a causal test set with interventions

- Design tradeoffs:
  - Ensemble size vs. computational cost
  - Tightness of sensitivity bounds vs. conservativeness of intervals
  - Optimality of greedy algorithm vs. computational efficiency

- Failure signatures:
  - Intervals fail to achieve target coverage on causal test set
  - Sensitivity bounds are too loose, resulting in overly conservative intervals
  - Ensemble fails to capture relevant empirical uncertainties

- First 3 experiments:
  1. Reproduce IHDP benchmark results to verify correctness
  2. Vary ensemble size to assess impact on interval tightness
  3. Compare Caus-Modens to conformal methods on a simple synthetic dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can Caus-Modens be regularized to produce sharper partial identification in non-binary treatment domains?
- Basis in paper: The paper mentions that future work could investigate regularization techniques for Caus-Modens to improve sharpness, particularly in non-binary treatment domains.
- Why unresolved: The current formulation of Caus-Modens does not include any regularization techniques, and the paper does not provide specific suggestions for how to regularize the method.
- What evidence would resolve it: Experimental results demonstrating the effectiveness of various regularization techniques on Caus-Modens applied to non-binary treatment domains, showing improved sharpness of the outcome intervals compared to unregularized Caus-Modens.

### Open Question 2
- Question: What are the theoretical implications of using Caus-Modens with non-parametric sensitivity models?
- Basis in paper: The paper discusses sensitivity models in general terms but focuses on parametric models. It does not explore the implications of using non-parametric sensitivity models with Caus-Modens.
- Why unresolved: The paper does not provide a theoretical analysis of how Caus-Modens would behave with non-parametric sensitivity models, leaving this as an open area for future research.
- What evidence would resolve it: A theoretical analysis showing the properties and limitations of Caus-Modens when combined with non-parametric sensitivity models, potentially including convergence guarantees or bounds on the performance of the method.

### Open Question 3
- Question: How does the performance of Caus-Modens scale with the size of the ensemble?
- Basis in paper: The paper mentions that for the IHDP benchmark, the size of the ensemble beyond 16 predictors ceased to impact the coverage cost. However, it does not provide a systematic study of how the performance scales with ensemble size.
- Why unresolved: The paper does not explore the relationship between ensemble size and the performance of Caus-Modens, leaving this as an open question for future research.
- What evidence would resolve it: A systematic study showing how the coverage cost and other performance metrics of Caus-Modens vary with the size of the ensemble, potentially including an analysis of the computational trade-offs involved in using larger ensembles.

## Limitations
- Effectiveness fundamentally tied to quality of sensitivity model specification and bounds
- Greedy optimization algorithm may not find global optimum in high-dimensional ensemble spaces
- Performance may depend on specific benchmark characteristics and sensitivity model specifications

## Confidence
- **High confidence**: The core mechanism of ensemble modulation for interval optimization is well-supported by theoretical analysis and empirical results.
- **Medium confidence**: The superiority of Caus-Modens over conformal methods is demonstrated, but may depend on specific benchmark characteristics and sensitivity model specifications.
- **Low confidence**: The generalizability of results to domains with different ensemble architectures or sensitivity model structures remains to be fully established.

## Next Checks
1. **Robustness to Sensitivity Model Specification**: Test Caus-Modens with intentionally misspecified sensitivity models to quantify the impact on interval performance.
2. **Ensemble Architecture Variations**: Evaluate Caus-Modens with different ensemble architectures (e.g., varying depth, width, activation functions) to assess the stability of performance improvements across architectural choices.
3. **Real-World Application**: Apply Caus-Modens to a real-world causal inference problem with hidden confounding to validate the practical utility and limitations of the approach beyond synthetic and semi-synthetic benchmarks.