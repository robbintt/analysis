---
ver: rpa2
title: 'MerA: Merging Pretrained Adapters For Few-Shot Learning'
arxiv_id: '2308.15982'
source_url: https://arxiv.org/abs/2308.15982
tags:
- adapters
- pretrained
- mera
- adapter
- adapterfusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of few-shot learning with pretrained
  language models, where adapter tuning often underperforms despite being parameter-efficient.
  The authors propose Merging Pretrained Adapters (MerA), which fuses multiple pretrained
  adapters into a single one through model fusion using optimal transport-based alignment.
---

# MerA: Merging Pretrained Adapters For Few-Shot Learning

## Quick Facts
- **arXiv ID**: 2308.15982
- **Source URL**: https://arxiv.org/abs/2308.15982
- **Reference count**: 4
- **Key outcome**: Merging pretrained adapters through optimal transport-based alignment improves few-shot learning performance, achieving up to 2.7% accuracy gains on GLUE tasks compared to standard adapter tuning.

## Executive Summary
This paper addresses the challenge of few-shot learning with pretrained language models, where adapter tuning often underperforms despite being parameter-efficient. The authors propose Merging Pretrained Adapters (MerA), which fuses multiple pretrained adapters into a single one through model fusion using optimal transport-based alignment. This approach avoids the high parameter cost of AdapterFusion while leveraging knowledge from multiple tasks. Experiments on GLUE benchmark tasks show MerA outperforms both standard adapter tuning and AdapterFusion, achieving up to 2.7% average accuracy improvement. With a same-track setting that merges adapters from similar task categories, MerA further surpasses full fine-tuning by substantial margins (e.g., 3.5% on MRPC, 5.0% on MNLI).

## Method Summary
MerA fuses multiple pretrained adapters into a single adapter through optimal transport-based alignment, which preserves functional neuron correspondence across tasks better than simple averaging. The method uses optimal transport to align neurons between adapters from different tasks based on either weights or activations, ensuring that corresponding functional units are merged rather than randomly averaging parameters. A same-track setting merges adapters from tasks within the same NLP track (e.g., QA, NLI, Sentiment), providing superior performance gains. The merged adapter serves as an informed initialization for downstream task fine-tuning, carrying distilled knowledge from multiple pretraining tasks.

## Key Results
- MerA achieves up to 2.7% average accuracy improvement on GLUE tasks compared to standard adapter tuning
- Same-track merging further improves performance, surpassing full fine-tuning by substantial margins (3.5% on MRPC, 5.0% on MNLI)
- MerA outperforms AdapterFusion while being more parameter-efficient
- The method is effective across different fine-tuning strategies including prompt-based approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Merging adapters through optimal transport-based alignment preserves functional neuron correspondence across tasks better than simple averaging.
- Mechanism: The method uses optimal transport to align neurons between adapters from different tasks based on either weights ("Wts.") or activations ("Acts."), ensuring that corresponding functional units are merged rather than randomly averaging parameters that may have different roles.
- Core assumption: Neuron correspondence can be meaningfully established through weight or activation similarity metrics, allowing for functionally aligned merging rather than naive parameter averaging.
- Evidence anchors:
  - [abstract]: "We further propose to align adapters' parameters through optimal transport based on weights ('Wts.') and activations ('Acts.')"
  - [section]: "Inspired by Solomon et al. (2015); Singh and Jaggi (2020), we align adapters' parameters via optimal transport based on weights ('Wts.') and activations ('Acts.')"
- Break condition: If the functional correspondence between neurons cannot be established through weight or activation similarity, the alignment process will merge mismatched parameters, potentially degrading performance.

### Mechanism 2
- Claim: Merging adapters from tasks within the same NLP track provides superior performance gains compared to merging across different tracks.
- Mechanism: Adapters trained on tasks from the same track share domain-specific knowledge patterns, so merging them creates a more coherent and effective single adapter that captures this shared knowledge more effectively.
- Core assumption: Tasks within the same NLP track (e.g., QA, NLI, Sentiment) share sufficient underlying knowledge structures that merging their adapters provides meaningful performance benefits.
- Evidence anchors:
  - [abstract]: "we also introduce a simple yet effective technique, referred to as the 'same-track' setting, that merges adapters from the same track of pretraining tasks"
  - [section]: "Table 3 compares MerA merged from different tracks, where we can see significant improvements when the pretraining tasks are on the same track as the downstream task"
- Break condition: If tasks within the same track have conflicting knowledge requirements or the track definition is too broad, merging may not provide the expected benefits or could even degrade performance.

### Mechanism 3
- Claim: MerA provides better initialization for downstream tasks compared to randomly initialized adapters or no adapters.
- Mechanism: The merged adapter carries distilled knowledge from multiple pretraining tasks, providing a more informed starting point for fine-tuning on the target task compared to random initialization.
- Core assumption: The knowledge distilled through merging multiple adapters provides meaningful inductive bias that accelerates and improves downstream task learning.
- Evidence anchors:
  - [section]: "Compared to 'Adapter' and 'Baseline', MerA ensures a superior initial state for the target tasks and achieves significant accuracy improvement, e.g., 2.4% in MNLI and 0.98% in SST-2"
  - [abstract]: "With the implementation of the 'same-track' setting, we observe even more impressive gains, surpassing the performance of full fine-tuning and adapter tuning by a substantial margin"
- Break condition: If the merged adapter's knowledge is too generic or misaligned with the target task's requirements, it may provide no initialization benefit or could even bias the model in suboptimal directions.

## Foundational Learning

- Concept: Optimal Transport Theory
  - Why needed here: The merging process relies on optimal transport to align parameters between different adapters, requiring understanding of how to compute transport plans between probability distributions.
  - Quick check question: How does optimal transport differ from simple distance metrics like L2 when aligning high-dimensional parameter spaces?

- Concept: Parameter-Efficient Fine-Tuning
  - Why needed here: Understanding why adapter-based approaches are preferred over full fine-tuning requires knowledge of the computational and memory trade-offs in large language model adaptation.
  - Quick check question: What is the parameter ratio between a standard adapter and the full model it's inserted into, and why does this matter for deployment?

- Concept: Task Categorization in NLP
  - Why needed here: The same-track setting requires understanding how NLP tasks can be meaningfully grouped into categories that share underlying knowledge structures.
  - Quick check question: What are the key linguistic and structural features that differentiate QA tasks from NLI tasks, and how might this affect adapter merging?

## Architecture Onboarding

- Component map: Multiple pretrained adapters -> Optimal transport alignment (weights or activations) -> Parameter aggregation (summation, averaging, or transport-aligned merging) -> Single merged adapter -> Downstream task fine-tuning

- Critical path:
  1. Load pretrained adapters from target tasks
  2. Apply optimal transport alignment between adapter pairs
  3. Merge aligned parameters using chosen aggregation method
  4. Integrate merged adapter into target PLM
  5. Fine-tune on downstream task

- Design tradeoffs:
  - Alignment method: Weight-based vs activation-based optimal transport - weight-based is faster but activation-based may capture more functional correspondence
  - Merging strategy: Simple averaging vs optimal transport - optimal transport provides better alignment but increases computational cost
  - Track selection: Broader vs narrower task categorization - broader categories provide more adapters to merge but may include less relevant knowledge

- Failure signatures:
  - Performance worse than single adapter: Likely indicates misalignment in optimal transport or incompatible task knowledge
  - No improvement over random initialization: Suggests merged knowledge is too generic or the merging process is not preserving useful information
  - Memory errors during alignment: Indicates computational complexity of optimal transport is too high for available resources

- First 3 experiments:
  1. Compare simple averaging vs optimal transport merging on a single task pair to validate alignment benefits
  2. Test same-track vs cross-track merging on tasks with known similarities to validate track-based benefits
  3. Measure zero-shot performance of merged adapters vs random initialization to validate initialization benefits

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the discussion, several unresolved issues emerge:

- How does MerA perform when merging adapters from tasks in different domains or with conflicting objectives?
- What is the optimal number of pretrained adapters to merge for maximizing MerA's performance?
- How does MerA's performance scale with model size and task complexity?

## Limitations

- The optimal transport alignment procedure is not fully specified, making exact reproduction challenging
- Limited discussion of computational overhead compared to simpler methods
- No analysis of when same-track merging might fail or provide negative results

## Confidence

- **High confidence** in the general framework of merging pretrained adapters for few-shot learning
- **Medium confidence** in the specific benefits of optimal transport-based alignment due to limited methodological detail
- **Medium confidence** in same-track merging benefits, as evidence is primarily from aggregate results rather than controlled experiments

## Next Checks

1. Implement and compare the four merging methods (Sum, Avg, Wts, Acts) on a simple task pair to validate the alignment benefits claimed
2. Conduct controlled experiments testing same-track vs cross-track merging on tasks with known similarities to quantify the track-based benefits
3. Measure the computational overhead of optimal transport alignment compared to simple averaging methods to assess practical viability