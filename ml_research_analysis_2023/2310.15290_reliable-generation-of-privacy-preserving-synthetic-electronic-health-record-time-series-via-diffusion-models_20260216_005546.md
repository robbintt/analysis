---
ver: rpa2
title: Reliable Generation of Privacy-preserving Synthetic Electronic Health Record
  Time Series via Diffusion Models
arxiv_id: '2310.15290'
source_url: https://arxiv.org/abs/2310.15290
tags:
- time
- measurement
- value
- data
- rate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces TIME DIFF, a diffusion model that generates
  synthetic EHR time series data using mixed sequence diffusion (Gaussian for numerical
  and multinomial for discrete features). Experiments on six datasets (MIMIC-III/IV,
  eICU, HiRID, Stocks, Energy) show TIME DIFF significantly outperforms seven baselines
  in data utility, achieving up to 95.4% lower discriminative scores and close-to-real
  predictive scores on EHR data.
---

# Reliable Generation of Privacy-preserving Synthetic Electronic Health Record Time Series via Diffusion Models

## Quick Facts
- arXiv ID: 2310.15290
- Source URL: https://arxiv.org/abs/2310.15290
- Reference count: 40
- Key outcome: Introduces TIME DIFF, a diffusion model that generates synthetic EHR time series data using mixed sequence diffusion, achieving up to 95.4% lower discriminative scores and close-to-real predictive scores across six datasets.

## Executive Summary
This paper presents TIME DIFF, a novel diffusion model for generating privacy-preserving synthetic electronic health record (EHR) time series data. The method addresses the challenge of handling both numerical and discrete features in medical time series by combining Gaussian diffusion for numerical features with multinomial diffusion for discrete features. TIME DIFF uses a bidirectional RNN architecture to capture temporal dependencies while preserving measurement timing information through missing value indicators. The approach demonstrates significant improvements in data utility compared to seven baselines while providing privacy protection against nearest neighbor attribute attacks.

## Method Summary
TIME DIFF employs mixed sequence diffusion to generate both real-valued and discrete time series features directly without post-processing. The method uses Gaussian diffusion for numerical features and multinomial diffusion for discrete features, trained with a combination of LN and LC losses. A bidirectional RNN (BRNN) architecture encodes sequential information while being flexible to input sequence length. Missing value indicators are treated as discrete time series alongside actual data, encoding both presence/absence and measurement timing. The model is trained to minimize reconstruction error while preserving temporal dependencies and privacy characteristics of the original EHR data.

## Key Results
- Achieves up to 95.4% lower discriminative scores compared to seven baselines on MIMIC-III/IV, eICU, and HiRID datasets
- Maintains close-to-real predictive scores (e.g., 0.8704 vs 0.8668 on eICU) for in-hospital mortality prediction tasks
- Provides faster training than GAN-based methods while outperforming them in data utility metrics
- Demonstrates strong performance across diverse datasets including both EHR (MIMIC-III/IV, eICU, HiRID) and non-EHR (Stocks, Energy) time series

## Why This Works (Mechanism)

### Mechanism 1
The mixed sequence diffusion approach enables simultaneous generation of both real-valued and discrete time series without post-processing. Gaussian diffusion is applied to numerical features while multinomial diffusion is applied to discrete features, with the model trained to minimize both LN and LC losses. This works because both numerical and discrete features can be modeled as noisy sequences where noise follows either Gaussian or categorical distributions. The break condition occurs if discrete variables have very high cardinality or non-stationary distributions that the multinomial diffusion cannot capture.

### Mechanism 2
The bidirectional RNN architecture effectively captures temporal dependencies in EHR time series. The BRNN encodes the entire sequence and outputs hidden states containing temporal dynamics, which are then scaled and shifted by diffusion step embeddings. This assumes that temporal dynamics of EHR time series can be sufficiently captured by a recurrent architecture with bidirectional context. The break condition is when temporal dependencies are highly non-linear or require long-range context beyond what BRNN can capture.

### Mechanism 3
The missing value indicator mask M preserves measurement timing information during generation. M is treated as a discrete time series and generated alongside actual data, encoding both presence/absence and measurement timing. This works because missing values in EHR data carry meaningful information about measurement patterns and patient status. The break condition occurs if missingness patterns are highly irregular or dependent on unobserved factors that the model cannot capture.

## Foundational Learning

- **Diffusion probabilistic models**: Core generative mechanism relies on understanding how noise is gradually added and removed from data. Quick check: What is the key difference between the forward and reverse processes in diffusion models?
- **Multinomial diffusion**: Required to handle discrete variables in EHR data without post-processing. Quick check: How does multinomial diffusion differ from Gaussian diffusion in terms of the noise distribution?
- **Bidirectional RNNs**: Architecture choice for encoding temporal dependencies in time series. Quick check: What advantage does a bidirectional RNN have over a unidirectional RNN for time series generation?

## Architecture Onboarding

- **Component map**: Input → Missing indicator mask M → Diffusion step embedding → Time-conditional BRNN → Output (predictions for both Gaussian and multinomial diffusions)
- **Critical path**: Data → BRNN hidden states → Diffusion step conditioning → Output predictions → Loss calculation
- **Design tradeoffs**: BRNN vs NCDE (computational efficiency vs continuous time modeling), Gaussian vs multinomial diffusion (simplicity vs direct discrete generation)
- **Failure signatures**: Poor discriminative scores indicate overfitting, high predictive scores indicate mode collapse, training instability suggests learning rate or architecture issues
- **First 3 experiments**:
  1. Train on MIMIC-III with λ=0.01, verify discriminative score < 0.1
  2. Compare Gaussian vs multinomial diffusion on discrete features using ablation study
  3. Test runtime efficiency vs TimeGAN on eICU dataset

## Open Questions the Paper Calls Out

- **How does TIME DIFF perform on irregularly sampled time series data with large gaps between measurements?**: The paper mentions missing value representation but does not evaluate performance on irregular sampling patterns. All experiments used regularly sampled data, and the paper does not report results for irregularly sampled data. Performance metrics (predictive/discriminative scores) on datasets with irregular sampling patterns would resolve this.

- **What is the computational complexity of TIME DIFF compared to other methods as sequence length increases?**: The paper mentions BRNN is chosen over NCDE for computational efficiency but does not provide complexity analysis. Runtime comparisons are only provided for fixed dataset sizes, not for varying sequence lengths. Theoretical analysis of time and space complexity as a function of sequence length would resolve this.

- **How does TIME DIFF's privacy protection compare to formal differential privacy guarantees?**: The paper acknowledges TIME DIFF provides some privacy protection but should not replace official audits. No formal privacy analysis or comparison to differential privacy frameworks is provided. Privacy analysis showing relationship between model parameters and privacy loss metrics would resolve this.

## Limitations

- The evaluation focuses primarily on discriminative and predictive scores, which may not fully capture all aspects of data utility
- The privacy analysis using NNAA risk provides some assurance but does not account for potential reconstruction attacks or membership inference vulnerabilities
- Experiments are conducted on six datasets, which, while diverse, may not represent all possible EHR data distributions

## Confidence

- **High confidence**: The mixed sequence diffusion approach effectively generates both numerical and discrete features without post-processing (supported by comparative experiments showing superior performance over baselines)
- **Medium confidence**: The BRNN architecture sufficiently captures temporal dependencies in EHR data (based on strong empirical results but limited architectural comparison)
- **Medium confidence**: Missing value indicators provide meaningful information for generation (supported by design rationale but not explicitly validated through ablation studies)

## Next Checks

1. Conduct a comprehensive privacy analysis including membership inference and reconstruction attacks to verify the claimed privacy guarantees
2. Perform an ablation study comparing BRNN with alternative architectures like NCDE to validate the architectural choice
3. Test the model's robustness to different missingness mechanisms (MAR, MNAR) to assess generalizability across real-world scenarios