---
ver: rpa2
title: Co-Design of Out-of-Distribution Detectors for Autonomous Emergency Braking
  Systems
arxiv_id: '2307.13419'
source_url: https://arxiv.org/abs/2307.13419
tags:
- detector
- risk
- design
- system
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "We co-designed an OOD detector and object detector for a vision\
  \ based AEBS, using a risk model to capture the effect of their design parameters\
  \ on each other\u2019s performance. Our Bayesian optimization-based methodology\
  \ found a combination that reduced risk by 42.3% while maintaining equivalent resource\
  \ utilization to the baseline system."
---

# Co-Design of Out-of-Distribution Detectors for Autonomous Emergency Braking Systems

## Quick Facts
- arXiv ID: 2307.13419
- Source URL: https://arxiv.org/abs/2307.13419
- Reference count: 40
- We co-designed an OOD detector and object detector for a vision based AEBS, using a risk model to capture the effect of their design parameters on each other’s performance. Our Bayesian optimization-based methodology found a combination that reduced risk by 42.3% while maintaining equivalent resource utilization to the baseline system.

## Executive Summary
This paper presents a co-design methodology for out-of-distribution (OOD) detectors and object detectors in autonomous emergency braking systems (AEBS). The approach uses Bayesian optimization to jointly optimize the structural parameters and thresholds of both detectors, guided by a risk model that captures the impact of design choices on functional performance, resource utilization, and safety. The methodology reduces system risk by 42.3% compared to a baseline while maintaining the same resource utilization, demonstrating the benefits of co-design over optimizing each component in isolation.

## Method Summary
The co-design methodology uses Bayesian optimization with Gaussian process surrogate models to efficiently explore the joint design space of an object detector (YOLOv7 tiny) and an OOD detector (β-VAE or reconstruction-based). The risk function combines the probability and severity of false positives, false negatives, and deadline misses from both components. The optimization searches for structural parameters (input sizes, architecture type) and decision thresholds that minimize risk while satisfying a resource utilization constraint. The methodology was evaluated on a CARLA simulator dataset with 50,000 images across 5 rain levels.

## Key Results
- Co-designed system reduced risk by 42.3% compared to baseline while maintaining equivalent resource utilization
- β-VAE OOD detector achieved better risk reduction than reconstruction-based OOD detector
- Bayesian optimization found near-optimal configurations in 30-50 iterations, avoiding exhaustive search

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Co-design reduces system risk by allowing complementary parameter tuning of the OOD detector and object detector.
- Mechanism: By jointly optimizing structural parameters (input size, architecture type) and thresholds, the system trades object detector false positives against OOD detector false positives, achieving a lower combined risk than optimizing either component in isolation.
- Core assumption: The risk function is convex enough in the design space that a small number of evaluations can locate a near-optimal configuration.
- Evidence anchors:
  - [abstract] "Our Bayesian optimization-based methodology found a combination that reduced risk by 42.3% while maintaining equivalent resource utilization to the baseline system."
  - [section] "However, evaluating the risk for one pair involves training two separate DNNs, which means exploring the design space of all parameter combinations is prohibitively expensive, so we propose a design methodology to minimize the training time needed to find a satisfactory solution."

### Mechanism 2
- Claim: Bayesian optimization with surrogate models enables efficient exploration of the high-dimensional design space.
- Mechanism: The methodology partitions the search space, trains an initial set of configurations, fits Gaussian process models to predict risk for untested points, and uses an acquisition function (expected improvement) to guide the selection of the next configuration to evaluate.
- Core assumption: The Gaussian process surrogate can capture the structure of the risk function sufficiently to guide the search.
- Evidence anchors:
  - [section] "Since we are dealing with a possibly non-convex, noisy risk function, we propose a modified version of Bayesian optimization [23] to find the parameters Λ and T , that minimize risk."
  - [section] "The Λ that maximizes the acquisition function is determined numerically using the conjugate gradient method and then used to train a new EC and OOD detector."

### Mechanism 3
- Claim: Risk as a unified objective captures both functional performance and timing constraints, enabling true co-design.
- Mechanism: The risk function combines the probability of false positives and false negatives (from both the object detector and OOD detector) weighted by their severity, and includes deadline misses as failure modes. This allows the optimizer to balance accuracy, speed, and safety in a single metric.
- Core assumption: The risk model accurately reflects real-world consequences of different failure modes (e.g., false positives causing rear-end collisions vs. false negatives causing head-on collisions).
- Evidence anchors:
  - [abstract] "We use risk, the combination of severity and occurrence of a failure, to model the effect of both components' design parameters on each other's functional and non-functional performance, as well as their impact on system safety."
  - [section] "We define risk mathematically in (1), where R is the system's total risk, E is the set of all hazardous events that can occur, P(x) denotes the probability of event x, and S(x) denotes its severity."

## Foundational Learning

- Concept: Fault Tree Analysis (FTA)
  - Why needed here: FTA is used to decompose top-level system failures (E0, E1) into combinations of component failures (false positives, false negatives, deadline misses), enabling the calculation of failure probabilities from individual component metrics.
  - Quick check question: Can you write the logical expression for the top event "no action when hazard is present" in terms of the intermediate events for the object detector and OOD detector?

- Concept: Bayesian Optimization
  - Why needed here: Bayesian optimization with surrogate models is necessary to efficiently explore the high-dimensional design space (multiple hyperparameters for both the object detector and OOD detector) without exhaustively training every possible configuration.
  - Quick check question: What is the role of the acquisition function in Bayesian optimization, and why is "expected improvement" a good choice for this problem?

- Concept: Risk Modeling for Binary Classifiers
  - Why needed here: The paper develops a risk model that combines the severity and probability of failures for a binary classifier (like an AEBS), which is then extended to the co-design problem by including the OOD detector's contribution.
  - Quick check question: How does the risk model change when an OOD detector is added to a binary classifier, and why does this allow for risk reduction?

## Architecture Onboarding

- Component map: Image -> OOD Detector -> Object Detector -> Decision Logic -> Action
- Critical path: Input image → OOD Detector (first) → Object Detector → Decision Logic → Action. The OOD detector runs first to maximize the chance of a safety override before the object detector commits to a decision.
- Design tradeoffs:
  - Input size vs. accuracy vs. execution time for both detectors
  - Threshold tuning: higher thresholds reduce false positives but may increase false negatives
  - OOD detector architecture: β-VAE (faster, disentangled) vs. reconstruction-based (potentially more accurate but slower)
  - Sampling frequency vs. risk: higher frequency allows faster response but increases deadline miss probability
- Failure signatures:
  - High false positive rate: unnecessary braking, reduced availability
  - High false negative rate: missed hazards, increased risk of collision
  - High deadline miss rate: system unavailable for that cycle, increased risk of missing a hazard
  - OOD detector misclassifying ID samples as OOD: unnecessary braking
  - OOD detector misclassifying OOD samples as ID: missed safety override
- First 3 experiments:
  1. Train baseline YOLO object detector with varying input sizes and thresholds, measure FPR, FNR, and deadline miss rate.
  2. Train β-VAE and reconstruction-based OOD detectors with varying input sizes, measure OOD detection accuracy and execution time.
  3. Run co-design optimization starting from the baseline, vary both YOLO and OOD detector parameters, track risk and average utilization, compare to baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the assumption of independence across time for the OOD detector and EC outputs affect the validity of the risk model in real-world scenarios?
- Basis in paper: [explicit] The paper states "We assume the results of the OOD detector and EC are independent across time when determining the probabilities used in the risk analysis."
- Why unresolved: This assumption simplifies the risk calculation but may not hold in practice as previous control actions affect future samples and environmental conditions may persist between consecutive samples.
- What evidence would resolve it: Empirical data comparing the performance of the risk model with and without the independence assumption on real-world datasets would help validate or refute this assumption.

### Open Question 2
- Question: How would incorporating multimodal sensor data into the AEBS affect the risk reduction potential of the co-design methodology?
- Basis in paper: [inferred] The paper mentions "Additionally, this work did not include a study of multimodal AEBSs."
- Why unresolved: Multimodal sensor data is common in robotic and transportation systems and could potentially provide additional information for risk reduction.
- What evidence would resolve it: Testing the co-design methodology on a multimodal AEBS system and comparing the risk reduction potential to the monocular vision-based system would provide insights into the benefits of incorporating multimodal data.

### Open Question 3
- Question: How can the co-design methodology be adapted to handle edge cases and out-of-distribution samples in real-world datasets?
- Basis in paper: [explicit] The paper acknowledges the limitation "Most importantly, there is an implicit assumption that the datasets used for training and validation incorporate the same distribution of edge cases that the system will experience during operation."
- Why unresolved: Collecting edge case scenarios and out-of-distribution samples can be dangerous or costly, and simulation may not guarantee validity for physical systems.
- What evidence would resolve it: Developing and testing strategies for generating or collecting edge case data that can be safely used to train and validate the co-designed system would help address this limitation.

## Limitations

- Data fidelity: CARLA simulator images may not fully capture real-world complexity or adversarial conditions
- Risk model completeness: Does not account for system state, temporal dependencies, or cascading effects of component failures
- Generalizability: Results specific to Jetson Nano platform and YOLOv7 tiny + β-VAE architecture combination

## Confidence

- High confidence: Bayesian optimization methodology, fault tree decomposition, and basic risk calculation framework
- Medium confidence: Co-design approach reduces risk in specific AEBS configuration tested, 42.3% improvement reproducible under same conditions
- Low confidence: Approach generalizes to other object detector/OOD detector combinations, hardware platforms, or real-world driving datasets

## Next Checks

1. Ablation study on risk function components: Systematically remove or modify severity weights and failure modes to quantify their impact on the optimized configuration

2. Real-world dataset validation: Evaluate co-designed system on real-world driving dataset (e.g., nuScenes, KITTI) to assess performance degradation due to domain shift

3. Baseline comparison with random search: Run Bayesian optimization framework with random search acquisition function to confirm improvement is due to surrogate model guidance