---
ver: rpa2
title: Mutual Enhancement of Large and Small Language Models with Cross-Silo Knowledge
  Transfer
arxiv_id: '2312.05842'
source_url: https://arxiv.org/abs/2312.05842
tags:
- data
- performance
- cross
- language
- slms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes CrossLM, a cross-silo knowledge transfer framework
  for mutual enhancement between large and small language models (LLMs and SLMs) without
  sharing private data. In CrossLM, SLMs trained on clients with private data guide
  the LLM to generate high-quality task-specific synthetic data, which is then used
  to enhance both the LLM and SLMs.
---

# Mutual Enhancement of Large and Small Language Models with Cross-Silo Knowledge Transfer

## Quick Facts
- **arXiv ID**: 2312.05842
- **Source URL**: https://arxiv.org/abs/2312.05842
- **Reference count**: 39
- **Key outcome**: CrossLM achieves 5.8%-7.8% SLM accuracy improvement and 18.3%-13.6% LLM accuracy improvement while preserving generalization capability

## Executive Summary
This paper proposes CrossLM, a cross-silo knowledge transfer framework that enables mutual enhancement between large language models (LLMs) and small language models (SLMs) without sharing private data. The framework leverages SLMs trained on clients with private data to guide the LLM in generating high-quality task-specific synthetic data, which is then used to enhance both the LLM and SLMs. Experiments demonstrate significant improvements in task-specific performance for both model types while preserving the LLM's generalization capability, as evidenced by minimal increases in perplexity.

## Method Summary
CrossLM implements a client-server collaborative training framework where clients train SLMs on private task-specific data and transfer them to a central server hosting an LLM. The LLM uses SLMs as evaluators to generate and refine high-quality synthetic data through a reward-based mechanism. Both the LLM and SLMs are then enhanced using this synthetic data, with the LLM's generalization preserved through KL divergence regularization. The enhanced models are returned to clients, creating a bidirectional knowledge transfer loop that improves task-specific performance for all participants without requiring data sharing.

## Key Results
- SLMs achieve 5.8% to 7.8% accuracy improvement on task-specific datasets
- LLMs obtain 18.3% to 13.6% absolute accuracy improvement on average
- LLM perplexity increases by only a small margin, indicating preservation of generalization capability
- CrossLM successfully handles heterogeneous SLM architectures (BERT-base and DistilBERT)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CrossLM uses SLMs as task-specific evaluators to provide reward signals for improving LLM-generated synthetic data quality.
- Mechanism: Each trained SLM on a client evaluates the quality of synthetic data generated by the LLM using reward r(xs, ys) = 2 * Si(ys|xs) - 1, where Si(ys|xs) is the probability the SLM assigns to the correct label. This reward guides the LLM through quality-driven generation loss.
- Core assumption: The SLM's classification accuracy on the task is sufficiently higher than the LLM's, making it a reliable evaluator.
- Evidence anchors: Abstract states SLMs give feedback on synthetic data quality used as supervised signal; section describes feedback mechanism for enhancing NLG performance.
- Break condition: If the SLM's performance is not significantly better than the LLM's, the feedback becomes unreliable and may degrade generation quality.

### Mechanism 2
- Claim: CrossLM preserves the LLM's generalization capability through probability regularization during task-specific enhancement.
- Mechanism: A Kullback-Leibler (KL) divergence loss Lr is added to minimize the difference between output probability distributions of the enhanced LLM and original pre-trained LLM, constraining parameter changes.
- Core assumption: The original pre-trained LLM has strong generalization capabilities that should be preserved while enhancing task-specific performance.
- Evidence anchors: Abstract mentions perplexity increases only slightly, indicating generalization preservation; section describes probability regularization loss to constrain parameter changes.
- Break condition: If regularization strength (γ3) is too high, it may prevent sufficient task-specific improvement; if too low, the LLM may lose generalization.

### Mechanism 3
- Claim: CrossLM enables mutual enhancement through asynchronous knowledge transfer between heterogeneous SLMs and LLM without sharing private data.
- Mechanism: Clients train SLMs locally, transfer to server where LLM generates synthetic data guided by SLM feedback, then both models are enhanced with generated data and returned to clients, creating bidirectional knowledge transfer.
- Core assumption: The LLM's generative capability is sufficiently strong to create useful synthetic data when guided by SLMs, and SLMs can effectively learn from this synthetic data.
- Evidence anchors: Abstract states SLMs promote LLM to generate high-quality data and both are enhanced with generated data; section describes client-server collaborative training framework.
- Break condition: If knowledge transfer is unidirectional or asynchronous updates cause model drift, mutual enhancement fails.

## Foundational Learning

- Concept: Cross-silo federated learning with heterogeneous client models
  - Why needed here: Framework involves multiple clients with different computational resources and model architectures that need to collaboratively enhance a central LLM without sharing raw data.
  - Quick check question: What are the key challenges when training heterogeneous models in a federated learning setup?

- Concept: Knowledge distillation and synthetic data generation
  - Why needed here: Framework relies on LLM generating synthetic data for task-specific training, and SLMs providing feedback to improve generation process, which is essentially knowledge distillation.
  - Quick check question: How does using synthetic data generated by a stronger model help in training weaker models?

- Concept: Parameter-efficient fine-tuning and regularization
  - Why needed here: Framework needs to enhance both LLMs and SLMs without full fine-tuning of large models, and must preserve LLM's generalization through regularization techniques.
  - Quick check question: What is the purpose of adding KL divergence regularization when fine-tuning pre-trained models?

## Architecture Onboarding

- Component map: Clients (SLMs) -> Server (LLM) -> Clients (Enhanced SLMs)
- Critical path: Client SLM training → SLM transfer to server → LLM synthetic data generation with SLM feedback → LLM and SLM enhancement → Enhanced SLM return to client
- Design tradeoffs:
  - Model heterogeneity vs. training complexity: Supporting different SLM architectures increases flexibility but requires handling heterogeneous model structures
  - Asynchronous vs. synchronous updates: Asynchronous training allows clients to train at own pace but may introduce staleness in knowledge transfer
  - Synthetic data quality vs. quantity: Higher quality synthetic data (filtered by diversity and SLM feedback) may reduce usable data but improves training effectiveness
- Failure signatures:
  - SLMs show no improvement after receiving enhanced versions: Indicates issues with synthetic data quality or training process
  - LLM perplexity increases significantly: Suggests regularization is insufficient or task-specific training is overfitting
  - Inconsistent performance across clients: May indicate issues with asynchronous training approach or heterogeneous model handling
- First 3 experiments:
  1. Baseline test: Train each SLM independently on private data and measure task-specific accuracy to establish baseline performance
  2. CrossLM with single client: Train one SLM, transfer to server, generate synthetic data, enhance both models, and measure improvement to validate core mechanism
  3. CrossLM with heterogeneous SLMs: Train multiple clients with different SLM architectures, transfer to server, and verify framework can handle model heterogeneity while achieving mutual enhancement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CrossLM scale with the number of clients participating in the federated learning process?
- Basis in paper: Paper discusses setup with 4 clients but does not explore how performance scales with more clients
- Why unresolved: Paper does not provide experimental results for varying numbers of clients
- What evidence would resolve it: Experiments with different numbers of clients (e.g., 2, 4, 8, 16) measuring task-specific performance would provide insights into scalability

### Open Question 2
- Question: How does the asynchronous training strategy in CrossLM affect overall training efficiency and convergence compared to synchronous training?
- Basis in paper: Paper mentions CrossLM uses asynchronous training strategy where LLM is trained whenever it receives an SLM from a client
- Why unresolved: Paper does not compare asynchronous training with synchronous training in terms of efficiency and convergence
- What evidence would resolve it: Experiments comparing training time, resource utilization, and convergence rates of CrossLM with both asynchronous and synchronous training strategies

### Open Question 3
- Question: How does the choice of synthetic data generation strategy affect the quality of generated data and overall performance of CrossLM?
- Basis in paper: Paper mentions existing strategies can be used to increase diversity of generated dataset but does not explore impact of different generation strategies
- Why unresolved: Paper does not experiment with different synthetic data generation strategies or evaluate their impact
- What evidence would resolve it: Experiments with different synthetic data generation strategies comparing their impact on generated data quality and task-specific performance

## Limitations

- Specific mechanism by which SLMs provide feedback to improve LLM-generated synthetic data quality lacks direct empirical validation
- Evidence for preserving LLM generalization through KL regularization is limited to perplexity measurements rather than comprehensive generalization benchmarks
- Effectiveness of mutual enhancement across heterogeneous SLM architectures is demonstrated but not deeply analyzed

## Confidence

- **High confidence**: Overall framework design and experimental methodology are sound
- **Medium confidence**: Mechanism of using SLMs as evaluators for synthetic data quality is plausible but needs more rigorous validation
- **Medium confidence**: Preservation of generalization capability through regularization is supported by limited evidence

## Next Checks

1. Evaluate SLM evaluator reliability: Compare SLM's classification accuracy against LLM's on the same task to verify SLMs are better evaluators. Test whether unreliable SLM feedback degrades LLM generation quality.

2. Generalization benchmark testing: After CrossLM enhancement, evaluate LLM on multiple diverse benchmark datasets beyond task-specific ones to quantify generalization preservation. Compare against baseline fine-tuning approaches.

3. Knowledge transfer effectiveness analysis: Measure mutual enhancement by comparing: (a) LLM performance when guided by different SLM qualities, (b) SLM improvement from synthetic data vs. private data, and (c) performance degradation when removing SLM feedback component.