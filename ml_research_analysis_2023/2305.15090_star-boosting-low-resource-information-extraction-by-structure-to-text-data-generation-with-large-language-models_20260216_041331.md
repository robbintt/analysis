---
ver: rpa2
title: 'STAR: Boosting Low-Resource Information Extraction by Structure-to-Text Data
  Generation with Large Language Models'
arxiv_id: '2305.15090'
source_url: https://arxiv.org/abs/2305.15090
tags:
- event
- data
- argument
- trigger
- extraction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes STAR, a method to generate training data for
  event extraction using large language models (LLMs). STAR addresses the problem
  of low-resource event extraction by generating synthetic data points from limited
  seed demonstrations.
---

# STAR: Boosting Low-Resource Information Extraction by Structure-to-Text Data Generation with Large Language Models

## Quick Facts
- arXiv ID: 2305.15090
- Source URL: https://arxiv.org/abs/2305.15090
- Reference count: 15
- Primary result: STAR-generated data significantly improves event extraction performance, especially for argument classification, and is even more effective than human-curated data in some cases.

## Executive Summary
This paper addresses the challenge of low-resource event extraction by proposing STAR, a structure-to-text data generation method that leverages large language models (LLMs) to generate synthetic training data. The key innovation is to first generate structured event information and then use LLMs to create corresponding text passages, rather than directly inducing structure from text. STAR employs fine-grained task-specific instructions, generates diverse trigger and argument candidates, and includes a self-refinement mechanism to improve data quality. Experiments on the ACE05 dataset demonstrate that STAR significantly outperforms traditional few-shot methods and can even surpass human-curated data in certain aspects of event extraction.

## Method Summary
STAR is a structure-to-text data generation method that first generates complex event structures (triggers and arguments) and then uses LLMs to create corresponding passages. The approach employs task-specific instructions at multiple granularities, generates diverse candidate triggers and arguments, and includes a self-refinement mechanism where the LLM iteratively improves its own generated text. This inverse generation approach (Y→X) leverages LLMs' strengths in conditional text generation rather than structure induction, addressing the data sparsity problem in low-resource event extraction scenarios.

## Key Results
- STAR significantly improves event extraction performance compared to traditional few-shot methods
- STAR-generated data is particularly effective for argument classification tasks
- In some cases, STAR-generated data outperforms human-curated data in event extraction quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The inverse data generation approach (Y→X) leverages LLMs' strengths in conditional text generation to produce higher quality training data than direct structure induction (X→Y).
- Mechanism: By providing ground-truth event structures (Y) as input and asking the LLM to generate corresponding passages (X), the approach shifts from a structure induction task (where LLMs struggle) to a conditional text generation task (where LLMs excel). This reformulation reduces errors in the generated data.
- Core assumption: LLMs can reliably generate coherent text passages given structured event information as input.
- Evidence anchors:
  - [abstract] "We propose to synthesize data instances given limited seed demonstrations to boost low-resource event extraction performance. We propose STAR, a structure-to-text data generation method that first generates complicated event structures (Y) and then generates input passages (X), all with Large Language Models."
  - [section 3.2] "We use task instruction for multiple task granularities to provide detailed definitions and recipes for the LLM to generate passages containing the structured event information."
- Break condition: If the LLM cannot generate coherent passages that contain the specified event structures, or if the generated passages consistently contain hallucinated information not present in the event structure.

### Mechanism 2
- Claim: The self-refinement mechanism with self-reflection improves data quality through iterative error identification and correction.
- Mechanism: After initial passage generation, the system identifies potential errors across multiple quality dimensions using LLM-generated questions. It then provides natural language feedback to the LLM, prompting it to refine the generation. This iterative process continues until the passage meets quality standards.
- Core assumption: The LLM can accurately identify errors in its own generated text and provide meaningful feedback for improvement.
- Evidence anchors:
  - [abstract] "We design fine-grained step-by-step instructions and the error cases and quality issues identified through self-reflection can be self-refined."
  - [section 3.3] "In the t-th refinement iteration, we first identify the potential errors and quality issues of X′t−1 from a diverse set of quality dimensions, then the issues are feedback to the LLM by providing a template-based natural language intervention hi along with the generated passage of previous iteration X′t−1, so that the LLM could refine the generation result and produce Xt."
- Break condition: If the self-reflection process fails to identify real errors or if the LLM cannot incorporate the feedback to improve the generated passages.

### Mechanism 3
- Claim: Fine-grained task-specific instructions and diverse trigger/argument candidates improve the quality and diversity of generated data.
- Mechanism: The approach uses detailed instructions at task, event type, and instance levels to guide the LLM. It also generates diverse trigger and argument candidates through targeted prompts, addressing data imbalance and improving generalizability.
- Core assumption: Detailed instructions can effectively communicate task requirements to the LLM, and diverse candidate generation can address data sparsity issues.
- Evidence anchors:
  - [section 3.2] "We use task instruction for multiple task granularities to provide detailed definitions and recipes for the LLM to generate passages containing the structured event information."
  - [section 3.1] "We first generate a pool of valid seed words for trigger of each event type, and for arguments of each (event type, argument role) combination."
- Break condition: If the instructions are insufficient to guide proper generation, or if the diverse candidates do not lead to improved model performance.

## Foundational Learning

- Concept: Conditional text generation with LLMs
  - Why needed here: The core mechanism of STAR relies on LLMs' ability to generate coherent text given structured input, which is essential for the inverse data generation approach.
  - Quick check question: Can you explain how conditional text generation differs from standard language modeling, and why it might be more effective for this task?

- Concept: Self-reflection and iterative refinement in AI systems
  - Why needed here: The self-refinement mechanism is crucial for improving the quality of generated data by identifying and correcting errors through multiple iterations.
  - Quick check question: How does self-reflection in AI systems differ from external evaluation, and what are the potential advantages and limitations of this approach?

- Concept: Task-specific instruction engineering for LLMs
  - Why needed here: Effective instruction design is critical for guiding the LLM to generate high-quality, task-relevant data across different event types and granularities.
  - Quick check question: What are the key components of effective instructions for LLMs, and how might they differ based on the complexity of the task?

## Architecture Onboarding

- Component map:
  Structure Generation Module -> Instruction Engine -> Inverse Generation Pipeline -> Self-Reflection Module -> Refinement Loop -> Data Output Formatter

- Critical path:
  1. Generate diverse event structures (Y)
  2. Create detailed instructions for the target event type
  3. Generate initial passage (X0) using LLM
  4. Apply self-reflection to identify issues
  5. Refine passage through iterative self-correction
  6. Output final (X, Y) data point

- Design tradeoffs:
  - Quality vs. Quantity: More iterations of self-refinement improve quality but reduce the number of generated data points
  - Instruction Complexity vs. LLM Performance: More detailed instructions may improve quality but could also confuse the LLM or exceed context limits
  - Diversity vs. Specificity: Generating diverse candidates improves generalizability but may introduce noise

- Failure signatures:
  - Generated passages consistently missing required event information
  - Self-reflection failing to identify obvious errors
  - LLM struggling with complex instructions or context
  - Refinement loop getting stuck in repetitive cycles without improvement

- First 3 experiments:
  1. Generate data for a single event type with varying numbers of refinement iterations to assess the impact on quality
  2. Compare the performance of models trained on STAR-generated data vs. human-curated data for a specific event extraction task
  3. Test the system's ability to generate diverse trigger and argument candidates by analyzing the variety in generated structures across multiple runs

## Open Questions the Paper Calls Out
None explicitly stated in the provided material.

## Limitations
- The quality of generated data heavily depends on the LLM's ability to follow detailed instructions and the effectiveness of the self-reflection mechanism
- The inverse generation approach (Y→X) reduces some structural induction errors but introduces new risks of hallucination and generation drift
- The method requires significant prompt engineering expertise and multiple quality control iterations, which may limit practical deployment in resource-constrained settings

## Confidence
- **High confidence**: The inverse data generation approach improves over direct structure induction, as evidenced by both quantitative results and qualitative analysis of error patterns
- **Medium confidence**: The self-refinement mechanism consistently improves data quality, though the exact mechanisms of error identification and correction remain somewhat opaque
- **Medium confidence**: STAR-generated data matches or exceeds human-curated data quality for certain tasks, but this finding is based on a single dataset and may not generalize across domains

## Next Checks
1. **Cross-dataset generalization test**: Evaluate STAR's performance on event extraction datasets beyond ACE05 (e.g., ERE, TAC-KBP) to assess whether the quality improvements transfer across different domains and annotation schemas.

2. **Human evaluation of generated quality**: Conduct blinded human assessments comparing STAR-generated passages against human-curated data to verify the claimed quality parity, focusing specifically on hallucination rates and structural coherence.

3. **Error analysis of self-reflection**: Systematically analyze the self-reflection mechanism's error identification accuracy by comparing LLM-identified issues against human-annotated quality problems, measuring both precision and recall of error detection.