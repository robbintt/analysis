---
ver: rpa2
title: 'SEPSIS: I Can Catch Your Lies -- A New Paradigm for Deception Detection'
arxiv_id: '2312.00292'
source_url: https://arxiv.org/abs/2312.00292
tags:
- lies
- layer
- loss
- deception
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents SEPSIS, a novel framework for detecting lies
  of omission using natural language processing techniques. The authors curated a
  large annotated dataset of 876,784 samples by combining a fake news dataset with
  scraped news headlines from The Times of India.
---

# SEPSIS: I Can Catch Your Lies -- A New Paradigm for Deception Detection

## Quick Facts
- arXiv ID: 2312.00292
- Source URL: https://arxiv.org/abs/2312.00292
- Reference count: 40
- Key outcome: Proposed SEPSIS model achieves F1 score of 0.87 for detecting lies of omission across four layers

## Executive Summary
This paper introduces SEPSIS, a novel framework for detecting lies of omission in text using natural language processing techniques. The authors created a large annotated dataset of 876,784 samples by combining fake news data with news headlines, then labeled each sample across four layers: type of omission, colors of lies, intent of lies, and topic of lies. The framework employs a multi-task learning pipeline that merges fine-tuned language models in a dataless manner to address the deception detection task. The proposed model demonstrates strong performance with an F1 score of 0.87, showing effectiveness across all four classification layers.

## Method Summary
SEPSIS uses a multi-task learning pipeline that combines fine-tuned T5 models through a dataless merging approach. The framework classifies deception across four layers simultaneously - type of omission (speculation, bias, distortion, sounds factual, opinion), colors of lies (black, white, gray, red), intent of lies (to influence, gain social prestige, etc.), and topic of lies (political, educational, religious, etc.). The approach employs task-specific loss functions optimized for each layer's characteristics, including distribution-balanced, cross-entropy, focal, and dice losses. Data augmentation is performed using 5W semantic role labeling to identify and replace key information elements with deceptive/null content.

## Key Results
- SEPSIS achieves F1 score of 0.87 across all four deception detection layers
- Task-specific loss functions outperform generic losses, with each layer benefiting from different loss types
- The dataless merging of fine-tuned T5 models creates a shared representation that captures task relationships effectively
- Significant correlations identified between lies of omission and propaganda techniques, such as between loaded language and opinion

## Why This Works (Mechanism)

### Mechanism 1
Dataless merging of fine-tuned T5 models improves performance by creating a generalized representation that captures task relationships without requiring task-specific training data. The shared architecture and weights allow the model to learn common patterns across deception detection tasks.

### Mechanism 2
Task-specific loss functions outperform generic losses because different layers have different statistical properties (class imbalance, label distributions) that require specialized optimization. This approach ensures each classification layer is optimized according to its unique characteristics.

### Mechanism 3
5W semantic role labeling enables effective mask infilling for generating deceptive content by identifying who, what, when, where, and why elements in text. This allows targeted replacement with deceptive/null information to create realistic lies of omission.

## Foundational Learning

- Concept: Multi-task learning and its advantages
  - Why needed here: The SEPSIS task involves classifying deception across four related layers simultaneously
  - Quick check question: What are the main benefits of multi-task learning compared to training separate models for each task?

- Concept: Loss function selection for imbalanced datasets
  - Why needed here: The deception dataset has class imbalance across multiple layers, requiring specialized loss functions
  - Quick check question: How does focal loss address class imbalance differently than standard cross-entropy loss?

- Concept: Semantic role labeling and its applications
  - Why needed here: The 5W mask infilling technique relies on identifying semantic roles to target specific information for omission
  - Quick check question: What is the difference between syntactic parsing and semantic role labeling?

## Architecture Onboarding

- Component map: Input text → T5 model merging → Transformer encoder → Four task-specific heads (type, color, intent, topic)
- Critical path: Text input → merged T5 representation → transformer encoding → all four classification heads
- Design tradeoffs: Model merging reduces memory but may cause interference; task-specific losses improve performance but add complexity; data augmentation increases coverage but may introduce noise
- Failure signatures: Low performance on one layer suggests task interference; high variance indicates unstable training; poor generalization suggests overfitting
- First 3 experiments: 1) Train baseline T5 on single task, 2) Train all four T5 models separately, 3) Implement model merging and compare against separate models

## Open Questions the Paper Calls Out

### Open Question 1
How does SEPSIS performance change when applied to different domains beyond news headlines? The paper only tested on news data, leaving open whether the model generalizes to other types of deceptive communication like social media posts or political speeches.

### Open Question 2
How does SEPSIS handle deceptive content that combines multiple techniques, such as a statement that is both speculative and contains loaded language? The paper does not discuss how well it handles complex, multi-faceted deception.

### Open Question 3
How does SEPSIS accuracy compare to human annotators when identifying deception in real-world scenarios? While the paper mentions human annotators created the dataset, it does not benchmark SEPSIS's performance against human accuracy on new data.

## Limitations

- Data composition uncertainty: Dataset combines fake news with Times of India headlines without specified proportions, raising domain bias concerns
- Evaluation scope constraints: Limited to single dataset without cross-validation on independent test sets
- Annotation subjectivity: Human labeling introduces potential inconsistency without inter-annotator agreement scores

## Confidence

- High Confidence: Dataset curation methodology and basic multi-task learning pipeline implementation
- Medium Confidence: Effectiveness of task-specific loss functions and dataless merging technique
- Low Confidence: Generalizability of 5W mask infilling approach and relationship between lies of omission and propaganda techniques

## Next Checks

1. Cross-Dataset Validation: Test SEPSIS on independent deception detection datasets (LIAR, Deception Analysis Dataset) to assess generalization and identify overfitting

2. Ablation Study on Model Components: Systematically remove or replace individual components to quantify their contributions to the 0.87 F1 score and identify redundancy

3. Human Evaluation Study: Conduct blind evaluations with human annotators to compare SEPSIS predictions against human judgment on a sample of deceptive headlines, measuring agreement rates and identifying systematic errors