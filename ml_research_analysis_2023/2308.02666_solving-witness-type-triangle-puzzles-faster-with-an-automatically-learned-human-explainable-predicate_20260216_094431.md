---
ver: rpa2
title: Solving Witness-type Triangle Puzzles Faster with an Automatically Learned
  Human-Explainable Predicate
arxiv_id: '2308.02666'
source_url: https://arxiv.org/abs/2308.02666
tags:
- puzzle
- predicate
- path
- search
- square
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We accelerate A search for Witness-type triangle puzzles by automatically
  learning a human-explainable predicate that predicts whether a partial path is incompletable.
  We use Inductive Logic Programming to synthesize predicates from puzzle data and
  prove that our learned predicate has no false positives, allowing safe pruning while
  preserving search completeness.
---

# Solving Witness-type Triangle Puzzles Faster with an Automatically Learned Human-Explainable Predicate

## Quick Facts
- arXiv ID: 2308.02666
- Source URL: https://arxiv.org/abs/2308.02666
- Authors: 
- Reference count: 3
- One-line primary result: We accelerate A* search for Witness-type triangle puzzles by automatically learning a human-explainable predicate that predicts whether a partial path is incompletable.

## Executive Summary
This paper presents a novel approach to accelerate A* search for solving Witness-type triangle puzzles by automatically learning human-readable predicates that predict whether partial paths are incompletable. The method uses Inductive Logic Programming (ILP) with the Popper system to synthesize logical rules from puzzle data, then proves these rules have no false positives, enabling safe pruning while preserving search completeness. Empirically, the learned predicate achieves a 6× speedup in both solution time and node expansions over baseline search that only checks local constraints.

## Method Summary
The method involves generating triangle Witness puzzles, enumerating paths to create positive (incompletable) and negative (completable) examples, and using Popper ILP to learn predicates from this data. A triage-based filtering strategy selects the best-performing predicates across progressively larger filter sets to ensure generalization. The final predicate is integrated into A* search to prune incompletable partial paths while maintaining completeness guarantees through the proven absence of false positives.

## Key Results
- Learned predicate achieves 6× speedup in solution time and node expansions over baseline
- Predicate generalizes well to larger puzzles beyond training instances
- Approach enables solving instances that baseline search cannot complete within fixed time limits
- Method demonstrates how machine learning of interpretable rules can enhance combinatorial puzzle solving

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A learned predicate with no false positives can safely prune partial paths from A* search while preserving completeness.
- Mechanism: The predicate labels incompletable partial paths as True. Since no true solution prefixes are ever labeled True, pruning them does not eliminate any valid solutions. This allows A* to avoid expanding known-dead paths while still guaranteeing a solution if one exists.
- Core assumption: The learned predicate must be verified to have zero false positives for this pruning to be safe.
- Evidence anchors:
  - [abstract] "we prove that our learned predicate has no false positives, allowing safe pruning while preserving search completeness."
  - [section 2.2] "When π is constant...we have the standard A* algorithm...An interesting case occurs when π has no false positives...In this case, we can safely use π to prune partial paths that π predicts are incompletable (never putting them in the queue) while still maintaining a complete search."
- Break condition: If the predicate incorrectly labels any prefix of a solution as incompletable, the search becomes incomplete and may fail to find a solution.

### Mechanism 2
- Claim: Inductive Logic Programming (ILP) can learn human-readable predicates that capture domain-specific pruning rules beyond simple local constraint checking.
- Mechanism: Popper uses background knowledge and training examples to synthesize logical rules that predict incompletability. These rules are expressed in Prolog, making them interpretable and analyzable for correctness.
- Core assumption: The puzzle data contains patterns that can be generalized into logical rules; background knowledge is sufficiently expressive.
- Evidence anchors:
  - [abstract] "We use Inductive Logic Programming to synthesize predicates from puzzle data and prove that our learned predicate has no false positives."
  - [section 4.1] "To automatically generate incompletability predicates, we employ inductive logic programming (ILP)...Popper uses answer set programming to generate predicates based on background knowledge."
- Break condition: If the background knowledge is too limited or the data too sparse, Popper may fail to learn meaningful predicates or may overfit to training instances.

### Mechanism 3
- Claim: A triage-based filtering strategy selects predicates that generalize well beyond their training instances.
- Mechanism: Predicates are first learned on a small training set, then evaluated on progressively larger filter sets. Only the top-performing predicates survive each round, ensuring the final predicate (π○) generalizes to unseen puzzles.
- Core assumption: Performance on larger filter sets correlates with generalization to the test set.
- Evidence anchors:
  - [section 4.2] "We begin by evaluating each of the generated incompletability predicates on Pfilter1...We then choose the k1 predicates with the highest time speedup...Finally, we evaluate the remaining k2 predicates on the largest filter set of puzzles, Pfilter3 and the single highest-speedup predicate π○ is picked."
  - [section 5.3] "Since we learn each predicate for a single puzzle instance we want to find a top performing predicate that generalizes well to other puzzle instances."
- Break condition: If the filter sets are not representative of the test set distribution, the selected predicate may not perform well in practice.

## Foundational Learning

- Concept: Witness triangle puzzles as constraint satisfaction problems
  - Why needed here: Understanding the puzzle structure is essential for formulating the search problem and defining what makes a path completable.
  - Quick check question: In a Witness triangle puzzle, what are the three conditions a path must satisfy to be a solution?

- Concept: A* search algorithm and heuristic functions
  - Why needed here: The baseline solver uses A* with Manhattan distance heuristic; the learned predicate modifies the open list ordering and pruning behavior.
  - Quick check question: How does using a binary predicate to sort the open list differ from using it to prune nodes in A*?

- Concept: Inductive Logic Programming (ILP) and Popper system
  - Why needed here: ILP is the core technique for learning human-readable predicates; Popper is the specific system used.
  - Quick check question: What role do positive and negative examples play in Popper's learning process?

## Architecture Onboarding

- Component map:
  Popper ILP engine -> Predicate triage pipeline -> A* search implementation -> Puzzle generators -> Evaluation harness

- Critical path:
  1. Generate training puzzle instances
  2. For each instance, enumerate paths and label examples
  3. Run Popper to learn candidate predicates
  4. Filter predicates using triage on filter sets
  5. Select best predicate π○
  6. Integrate π○ into A* and evaluate on test set

- Design tradeoffs:
  - Popper learning time vs. predicate quality (longer learning may yield better predicates)
  - Predicate complexity vs. runtime overhead (complex predicates may slow down search)
  - Filter set sizes vs. filtering accuracy (larger sets improve selection but increase cost)

- Failure signatures:
  - No predicates survive triage → likely too strict filtering or insufficient learning time
  - Predicate performs worse than baseline → overfitting to training data or poor generalization
  - Search fails to find solutions → predicate has false positives or implementation bug

- First 3 experiments:
  1. Run Popper on a small training set and inspect the learned predicates for interpretability.
  2. Evaluate a learned predicate on a small filter set and compare time/expansion speedups to baseline.
  3. Integrate a verified predicate into A* and confirm it preserves completeness on a known solvable puzzle.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the learned predicate compare to predicates synthesized using genetic algorithms or simulated annealing?
- Basis in paper: [explicit] The paper mentions future work will compare the approach to other types of program synthesis like genetic algorithms and simulated annealing.
- Why unresolved: The current study only evaluates the performance of the predicate learned using inductive logic programming with Popper. No direct comparison is made to predicates synthesized using other methods.
- What evidence would resolve it: Running experiments where the same Witness puzzle instances are solved using predicates synthesized via genetic algorithms and simulated annealing, and comparing the time and expansion speedups against the results achieved with the Popper-learned predicate.

### Open Question 2
- Question: Can the learned predicate be automatically converted from Prolog to Python without manual re-implementation to gain performance benefits?
- Basis in paper: [explicit] The paper states that future work will explore automatically converting predicates from Prolog to Python to gain performance benefits without the effort of a manual re-implementation.
- Why unresolved: The current study required manual re-implementation of the learned Prolog predicate in Python for use in the A* search algorithm. The feasibility and effectiveness of automatic conversion is not demonstrated.
- What evidence would resolve it: Developing and evaluating an automatic conversion tool that takes the Prolog predicate learned by Popper and generates an equivalent Python implementation, and measuring any performance gains in the A* search.

### Open Question 3
- Question: How applicable is the approach presented in this paper to other puzzle types in The Witness beyond triangle puzzles?
- Basis in paper: [explicit] The paper mentions future work will investigate applicability of the approach to other puzzle types in The Witness beyond triangle puzzles.
- Why unresolved: The current study focuses solely on triangle Witness puzzles. The generalizability of the approach to other puzzle types is not explored.
- What evidence would resolve it: Applying the approach of learning predicates using inductive logic programming to other puzzle types in The Witness, such as hex, square, or star puzzles, and evaluating the performance gains in solving those puzzles compared to a baseline search.

## Limitations
- Scalability to larger puzzles (m,n > 4) is not fully characterized
- Computational overhead of Popper ILP learning is not thoroughly measured
- Triaging approach assumes filter set performance correlates with test set generalization

## Confidence
- Predicate correctness and safety: High
- Empirical speedups: High
- Generalization beyond training puzzles: Medium

## Next Checks
1. Test the learned predicate on puzzles with m,n = 5-8 to verify if the 6× speedup holds or degrades gracefully with puzzle size.

2. Measure the computational overhead of evaluating the learned predicate at each node expansion to determine if the net speedup remains positive for larger puzzles.

3. Implement a simpler heuristic learning approach (e.g., decision trees or neural networks) and compare generalization performance against the ILP-based method to isolate the benefit of human-explainable predicates.