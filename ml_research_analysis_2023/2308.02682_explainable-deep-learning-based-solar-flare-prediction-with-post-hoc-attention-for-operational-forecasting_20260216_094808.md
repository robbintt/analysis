---
ver: rpa2
title: Explainable Deep Learning-based Solar Flare Prediction with post hoc Attention
  for Operational Forecasting
arxiv_id: '2308.02682'
source_url: https://arxiv.org/abs/2308.02682
tags:
- flare
- prediction
- solar
- flares
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a deep learning-based full-disk solar flare\
  \ prediction model trained on line-of-sight magnetogram images to predict \u2265\
  M1.0-class flares within 24 hours. To handle class imbalance, the authors use custom\
  \ data augmentation and sample weighting, and evaluate using True Skill Statistic\
  \ (TSS) and Heidke Skill Score (HSS)."
---

# Explainable Deep Learning-based Solar Flare Prediction with post hoc Attention for Operational Forecasting

## Quick Facts
- arXiv ID: 2308.02682
- Source URL: https://arxiv.org/abs/2308.02682
- Reference count: 38
- Primary result: Deep learning model predicts ≥M1.0-class solar flares within 24 hours using full-disk magnetogram images with TSS=0.51±0.05 and HSS=0.38±0.08

## Executive Summary
This paper presents a deep learning-based solar flare prediction model trained on line-of-sight magnetogram images to predict ≥M1.0-class flares within 24 hours. The model uses a modified AlexNet architecture with custom input layers and addresses class imbalance through data augmentation and sample weighting. To provide interpretability, the authors employ gradient-based attention methods—Guided Grad-CAM, Deep SHAP, and Integrated Gradients—to generate post hoc explanations of predictions. The model demonstrates notable performance in predicting near-limb flares, achieving approximately 74% recall for X-class and 50% recall for M-class flares beyond ±70° longitude, while providing consistent attribution maps that align with active region characteristics.

## Method Summary
The approach extends AlexNet with a custom 3x3 convolutional layer to handle single-channel 512x512 magnetogram inputs, using pre-trained weights with adaptive pooling for size compatibility. The model is trained on SDO/HMI full-disk magnetograms from 2010-2018, addressing the 1:6 FL:NF class imbalance through three-fold augmentation of the minority class and inverse frequency-based sample weighting. Training uses SGD optimization with NLL loss and dynamic learning rates, evaluated via 4-fold cross-validation. Predictions are interpreted using three gradient-based attribution methods—Guided Grad-CAM, Deep SHAP, and Integrated Gradients—to validate that model decisions align with physically meaningful magnetic features.

## Key Results
- Model achieves TSS=0.51±0.05 and HSS=0.38±0.08 on 24-hour flare prediction task
- Near-limb flare prediction shows ~74% recall for X-class and ~50% recall for M-class flares beyond ±70° longitude
- Attribution maps from three different gradient-based methods consistently highlight active region magnetic features as important for predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The model can accurately predict near-limb solar flares by learning from full-disk magnetogram images rather than limited central AR patches.
- Mechanism: Full-disk images provide spatial context beyond ±70° longitude where AR-based models suffer from projection effects. The CNN architecture processes the entire 512x512 magnetogram, allowing the model to detect subtle magnetic patterns associated with flaring regions regardless of solar limb position.
- Core assumption: The model can learn meaningful magnetic field representations from compressed 8-bit JP2 images that preserve shape-based parameters like size, directionality, and inversion lines.
- Evidence anchors: Abstract shows "compelling performance for flares appearing on near-limb locations" with ~74% X-class and ~50% M-class correct predictions; related work focuses on central regions only.

### Mechanism 2
- Claim: Gradient-based attribution methods (Guided Grad-CAM, Deep SHAP, Integrated Gradients) provide consistent explanations that validate the model's decision-making process.
- Mechanism: These methods compute pixel-level importance scores by backpropagating gradients from the prediction through the network. The consistency across three different methods increases confidence that the highlighted regions truly influence predictions.
- Core assumption: The model's predictions are primarily driven by magnetic features rather than noise or artifacts, and these features are spatially localized enough for attribution methods to identify.
- Evidence anchors: Abstract mentions using three post hoc attention methods; results show visualization of attribution maps is consistent across all three methods; related papers use similar attribution methods but focus on AR patches rather than full-disk.

### Mechanism 3
- Claim: Class imbalance handling through data augmentation and sample weighting enables effective training on the skewed FL:NF ratio.
- Mechanism: Augmenting the minority FL class three times while weighting the loss function inversely to class frequencies ensures the model sees balanced examples during training, preventing it from simply predicting "no flare" for all inputs.
- Core assumption: The augmented data preserves the statistical properties of real flaring events and doesn't introduce artifacts that would mislead the model.
- Evidence anchors: Paper describes augmenting FL-class data three times and adjusting class weights inversely proportional to class frequencies after augmentations; related papers mention class imbalance but don't detail augmentation strategies.

## Foundational Learning

- Concept: Solar flare classification and space weather impact
  - Why needed here: Understanding the difference between M-class and X-class flares and their terrestrial impacts provides context for why accurate prediction matters operationally
  - Quick check question: What is the approximate X-ray flux threshold that distinguishes M-class from X-class flares?

- Concept: Convolutional neural networks and transfer learning
  - Why needed here: The model extends AlexNet with custom input layers, requiring understanding of CNN architecture, pre-trained weights, and adaptive pooling for different input sizes
  - Quick check question: Why is adaptive average pooling necessary when using pre-trained AlexNet weights with 512x512 input images?

- Concept: Evaluation metrics for imbalanced classification
  - Why needed here: TSS and HSS are specifically chosen over accuracy due to the 1:6 FL:NF ratio, requiring understanding of confusion matrix-derived metrics
  - Quick check question: How does TSS differ from accuracy when evaluating models on imbalanced datasets?

## Architecture Onboarding

- Component map: Input layer (512x512 magnetogram) → 3x3 Conv (3 channels) → AlexNet backbone (6 conv layers, 3 max-pool, 1 avg-pool, 2 FC layers) → Log-softmax output (2 classes)
- Critical path: Data preprocessing → CNN feature extraction → Classification → Attribution mapping for interpretation
- Design tradeoffs: Full-disk vs AR-based approach (completeness vs precision), compressed vs raw magnetograms (efficiency vs detail), gradient-based vs perturbation attribution (speed vs robustness)
- Failure signatures: Low recall on near-limb events indicates projection effect handling issues; inconsistent attributions across methods suggest model instability; high false positives indicate border class confusion
- First 3 experiments:
  1. Test model performance on artificially limb-shifted AR patches to verify near-limb prediction capability
  2. Compare attribution consistency when removing one of the three gradient methods to identify most informative approach
  3. Evaluate augmentation impact by training with and without augmentation on a balanced subset of the data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do model predictions and attributions change when incorporating spatiotemporal patterns instead of purely spatial patterns from magnetogram images?
- Basis in paper: [inferred] The authors mention that "at this point, the models are only looking at the spatial patterns in our data, and we intend to widen this work toward spatiotemporal models to improve the performance."
- Why unresolved: The current model uses static magnetogram images without considering temporal evolution of active regions, which may contain important predictive information about flare onset.
- What evidence would resolve it: Performance metrics (TSS, HSS) and attribution maps comparing the current spatial-only model with a spatiotemporal model incorporating time-series magnetogram data.

### Open Question 2
- Question: Can the interference from bordering class flares (C-class to M-class) be effectively addressed through improved labeling schemes or model architecture modifications?
- Basis in paper: [explicit] The authors note that "out of 25,150 C-class flares, 9,240 flares led to incorrect predictions, accounting for approximately 37% of the total C-class flares" and discuss the problem of distinguishing bordering class flares.
- Why unresolved: The binary classification approach creates ambiguity for flares near the M1.0 threshold, leading to high false positive rates that current methods cannot adequately address.
- What evidence would resolve it: Comparative analysis of prediction accuracy using multi-class classification, regression approaches, or enhanced labeling schemes that better handle border cases.

### Open Question 3
- Question: What specific magnetic field characteristics in near-limb regions enable the model to predict flares despite projection effects, and how do these differ from central disk features?
- Basis in paper: [explicit] The authors demonstrate that their model can "tangibly locate and predict near-limb solar flares" with "∼74% of the X-class and ∼50% of the M-class flares" predicted correctly beyond ±70° longitude.
- Why unresolved: While the model successfully predicts near-limb flares, the specific magnetic features or patterns that enable this success remain uncharacterized, particularly given the known distortions in limb measurements.
- What evidence would resolve it: Detailed analysis of attribution patterns showing which magnetic field characteristics (polarity inversion lines, magnetic complexity, flux emergence patterns, etc.) are most predictive for near-limb versus central disk regions.

## Limitations

- Compressed 8-bit JP2 magnetogram images may lose critical magnetic field information compared to raw data, though the model still achieves reasonable performance
- Gradient-based attribution methods may not capture complex spatial interactions or subtle magnetic features that influence predictions
- Class imbalance handling through augmentation and weighting raises questions about whether augmented data truly represents real flaring conditions without introducing artifacts

## Confidence

- **High**: Model achieves TSS=0.51±0.05 and HSS=0.38±0.08 on full-disk prediction task
- **Medium**: Near-limb flare prediction performance (74% X-class, 50% M-class recall) with attribution consistency
- **Low**: Generalization to raw magnetogram data and long-term operational deployment stability

## Next Checks

1. **Projection Effect Validation**: Test model performance on artificially limb-shifted active region patches to verify the claimed capability of predicting near-limb flares, addressing the core mechanism assumption about spatial context learning.

2. **Attribution Method Comparison**: Systematically remove each attribution method (Guided Grad-CAM, Deep SHAP, Integrated Gradients) to quantify which provides the most informative explanations and test the robustness of the consistency claim across methods.

3. **Raw Data Performance**: Evaluate the same model architecture using uncompressed HMI magnetogram data to determine if the 8-bit compression significantly impacts prediction accuracy or attribution quality, validating the core assumption about compressed data sufficiency.