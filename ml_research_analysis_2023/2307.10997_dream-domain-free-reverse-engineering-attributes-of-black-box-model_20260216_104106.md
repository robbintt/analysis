---
ver: rpa2
title: 'DREAM: Domain-free Reverse Engineering Attributes of Black-box Model'
arxiv_id: '2307.10997'
source_url: https://arxiv.org/abs/2307.10997
tags:
- domain
- training
- learning
- attributes
- black-box
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the problem of inferring model attributes
  of a black-box model without requiring access to its training dataset. The authors
  cast this as an out-of-distribution (OOD) generalization problem and propose a novel
  framework called DREAM.
---

# DREAM: Domain-free Reverse Engineering Attributes of Black-box Model

## Quick Facts
- arXiv ID: 2307.10997
- Source URL: https://arxiv.org/abs/2307.10997
- Reference count: 40
- Key outcome: Achieves 52.38% and 53.49% average accuracy on PACS-modelset and MEDU-modelset respectively for domain-agnostic black-box model attribute inference.

## Executive Summary
This paper addresses the challenge of inferring model attributes of a black-box model without access to its training dataset. The authors propose DREAM (Domain-agnostic Reverse Engineering the Attributes of black-box Model), a novel framework that casts the problem as an out-of-distribution (OOD) generalization task. DREAM uses a multi-discriminator generative adversarial network to learn domain-invariant features from probability outputs of white-box models trained on multi-domain data. The framework demonstrates that these invariant features enable accurate attribute inference across unseen training domains, outperforming baseline methods.

## Method Summary
DREAM tackles the problem of domain-agnostic reverse engineering by treating it as an OOD generalization challenge. The framework queries white-box models with fixed inputs to obtain probability outputs, then uses a multi-discriminator GAN to learn domain-invariant features from these outputs. A domain-agnostic reverse model is trained on these invariant features to classify model attributes. The approach is evaluated on two datasets (PACS and MEDU) with 10,000 models per domain, demonstrating superior performance compared to baseline methods for attribute classification.

## Key Results
- Achieves 52.38% average accuracy on PACS-modelset for attribute classification
- Achieves 53.49% average accuracy on MEDU-modelset for attribute classification
- Outperforms baseline methods including KENNEN and other OOD generalization techniques
- Demonstrates effectiveness across multiple target domains (Photo, Cartoon, Sketch)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-invariant features enable accurate attribute inference across unseen training domains.
- Mechanism: Multi-discriminator GAN learns to align output distributions from different domains so the generator produces embeddings where domain-specific differences are minimized. The domain-agnostic reverse model trained on these embeddings can generalize to any target domain.
- Core assumption: Model output distributions encode model attributes consistently enough across domains to allow cross-domain generalization after alignment.
- Evidence anchors: [abstract] "We introduce a multi-discriminator generative adversarial network to learn domain-invariant features from the outputs of white-box models trained on multi-domain data."

### Mechanism 2
- Claim: Probability outputs from white-box models trained on different domains contain sufficient information to infer target black-box model attributes.
- Mechanism: The framework queries white-box models on a fixed set of inputs, collecting probability distributions as "fingerprints" of model architecture. These fingerprints from multiple domains are processed to extract invariant features that correlate with architecture attributes.
- Core assumption: Model architecture (e.g., number of layers, activation functions) affects probability outputs in a detectable and consistent way across different training datasets.
- Evidence anchors: [section] "Given a black-box model B, model attribute reverse engineering in [8] aims to build a meta-classifier Φ : B → A, where A is the set of model attributes including model architecture, optimizer, and training hyperparameters, etc."

### Mechanism 3
- Claim: OOD generalization techniques can be adapted from image/video domains to model probability outputs for reverse engineering.
- Mechanism: The multi-discriminator GAN architecture, inspired by domain adaptation methods, is applied to align distributions of probability vectors rather than images, enabling learning of domain-invariant representations suitable for classification.
- Core assumption: Techniques effective for learning invariant features from visual data can be transferred to structured probability data with appropriate architectural adjustments.
- Evidence anchors: [abstract] "Since the data we concentrate on is related to the outputs of machine learning models, e.g., probability values, how to design an effective OOD learning method over this type of data has not been explored."

## Foundational Learning

- Concept: Out-of-distribution (OOD) generalization
  - Why needed here: The target black-box model is trained on an unknown domain; the method must generalize beyond the source domains used for training.
  - Quick check question: What is the difference between in-distribution and out-of-distribution generalization in machine learning?

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: The multi-discriminator GAN is used to align feature distributions across domains, creating domain-invariant representations.
  - Quick check question: In a GAN, what is the role of the discriminator and how does it influence the generator?

- Concept: Model fingerprinting via query responses
  - Why needed here: The probability outputs from querying models serve as a compact representation of the model's architecture and behavior, which can be analyzed to infer attributes.
  - Quick check question: How can a fixed set of input queries be used to extract distinguishing features from different machine learning models?

## Architecture Onboarding

- Component map:
  - Query Generator -> White-box Models -> Multi-Discriminator GAN -> Domain-Agnostic Reverse Model -> Target Black-box Model

- Critical path:
  1. Enumerate white-box models with all attribute combinations on source domains
  2. Query each white-box model with fixed inputs to obtain probability outputs
  3. Train multi-discriminator GAN to learn domain-invariant embeddings
  4. Train domain-agnostic reverse model on the learned features to classify model attributes
  5. For target black-box model: query with same inputs, embed with GAN, classify with reverse model

- Design tradeoffs:
  - Number of domains vs. diversity of training data: More domains improve generalization but increase training cost
  - Number of queries vs. information richness: More queries provide more detail but increase inference latency
  - GAN complexity vs. stability: More discriminators improve alignment but can cause training instability

- Failure signatures:
  - High variance in accuracy across target domains suggests poor domain alignment
  - Performance close to random indicates insufficient information in probability outputs
  - Slow or unstable GAN training suggests poor choice of architecture or hyperparameters

- First 3 experiments:
  1. Train DREAM on PACS-modelset (Photo, Cartoon, Sketch) and test on each held-out domain to measure domain generalization
  2. Compare DREAM accuracy to KENNEN baseline when target domain differs from training domains
  3. Vary the number of queries (e.g., 50, 100, 200) to find the point of diminishing returns in accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the trade-off parameter λ affect the performance of DREAM on different model attributes?
- Basis in paper: [explicit] The paper mentions that λ is tuned from {0.001, 0.01, 0.1, 1, 10} based on the validation set and that the results for each model attribute do not show evident fluctuation when changing λ.
- Why unresolved: While the paper provides a range for λ and states that the results do not fluctuate significantly, it does not provide a detailed analysis of how different values of λ affect the performance of DREAM on different model attributes.
- What evidence would resolve it: A more detailed analysis of the performance of DREAM with different values of λ on each model attribute would resolve this question.

### Open Question 2
- Question: How does the performance of DREAM compare to other OOD generalization methods on model attribute inference tasks?
- Basis in paper: [explicit] The paper compares DREAM to three typical OOD generalization methods (SelfReg, MixStyle, MMD, and SD) and shows that DREAM outperforms these methods in terms of average accuracy of model attribute classification.
- Why unresolved: While the paper provides a comparison of DREAM to other OOD generalization methods, it does not provide a detailed analysis of the strengths and weaknesses of each method on different model attribute inference tasks.
- What evidence would resolve it: A more detailed analysis of the performance of DREAM and other OOD generalization methods on different model attribute inference tasks would resolve this question.

### Open Question 3
- Question: How does the performance of DREAM change with the size of the training dataset?
- Basis in paper: [inferred] The paper mentions that the performance of DREAM slightly fluctuates from the size of 1K to 5K, and does not consistently increase when the size increases. The paper suggests that this could be due to the difficulty of the problem or the nature of the OOD problem.
- Why unresolved: While the paper provides some insight into how the performance of DREAM changes with the size of the training dataset, it does not provide a detailed analysis of the relationship between the two.
- What evidence would resolve it: A more detailed analysis of the performance of DREAM with different sizes of training datasets would resolve this question.

## Limitations

- The reported accuracy (52.38% and 53.49%) is relatively low compared to in-distribution scenarios, suggesting room for improvement
- The framework requires substantial computational resources (10,000 white-box models per domain) which may limit practical applicability
- Performance on real-world black-box models is not demonstrated, leaving questions about robustness to practical noise and adversarial scenarios

## Confidence

**High Confidence**: The mechanism by which probability outputs can encode model attributes is well-established in prior work. The framework's overall design—using domain-invariant features for cross-domain generalization—follows established OOD principles.

**Medium Confidence**: The specific implementation using multi-discriminator GANs for aligning probability distributions is novel but lacks ablation studies to isolate the contribution of each component. The accuracy numbers are reported without variance measures or comparison to random baselines.

**Low Confidence**: Claims about practical applicability to real-world black-box models are not substantiated. The scalability of training 10,000+ models per domain and the framework's robustness to different query distributions remain unclear.

## Next Checks

1. **Ablation Study**: Run experiments removing the GAN component to determine if domain-invariant features are truly necessary, and test different numbers of discriminators to find the optimal configuration.

2. **Statistical Significance Testing**: Repeat experiments 10+ times with different random seeds and report mean accuracy with 95% confidence intervals, comparing against random guessing baselines.

3. **Real-World Model Testing**: Apply the framework to a small set of open-source pre-trained models (e.g., from torchvision.models) to assess performance on models not synthesized from enumerated attribute combinations.