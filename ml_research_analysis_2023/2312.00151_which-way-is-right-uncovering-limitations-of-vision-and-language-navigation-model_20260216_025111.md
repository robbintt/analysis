---
ver: rpa2
title: 'Which way is `right''?: Uncovering limitations of Vision-and-Language Navigation
  model'
arxiv_id: '2312.00151'
source_url: https://arxiv.org/abs/2312.00151
tags:
- tokens
- training
- navigation
- instructions
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how spatial and directional language cues
  in navigation instructions are used by Vision-and-Language Navigation (VLN) models.
  The authors conduct a series of token masking experiments to understand whether
  path-ranking models rely on different parts of speech when making navigation decisions.
---

# Which way is `right'?: Uncovering limitations of Vision-and-Language Navigation model

## Quick Facts
- **arXiv ID:** 2312.00151
- **Source URL:** https://arxiv.org/abs/2312.00151
- **Reference count:** 40
- **Primary result:** Path-ranking VLN models rely almost exclusively on noun tokens and largely disregard spatial and directional language cues.

## Executive Summary
This paper investigates how Vision-and-Language Navigation (VLN) models use spatial and directional language cues through systematic token masking experiments. The authors discover that top-performing path-ranking models primarily attend to noun tokens representing objects and landmarks, while largely ignoring spatial and directional words. In contrast, sequential models utilize both noun and directional cues. To address this limitation, the paper proposes two training methods—data augmentation via path shuffling and spatial language loss—which improve model performance and increase reliance on spatial tokens. These findings reveal a significant gap between sequential and path-ranking VLN approaches and suggest that current path-ranking models may be exploiting dataset biases rather than truly understanding spatial instructions.

## Method Summary
The paper conducts systematic token masking experiments on VLN models (VLN-BERT, AirBert, and Recurrent-VLN-BERT) to understand how different linguistic cue sets contribute to navigation decisions. Tokens are partitioned by part-of-speech and predefined directional words, then systematically masked to measure performance impact. The authors propose two training methods: path shuffling, which creates new paths by rearranging original paths to reduce object reliance, and spatial language loss, which forces the model to learn spatial token relationships by masking 100% of spatial and directional tokens during final training epochs. These methods are evaluated on the R2R dataset's val-unseen split using Success Rate and Success Rate weighted by Path Length metrics.

## Key Results
- Path-ranking models show 12.5% SR drop when masking nouns but only 2.8% SR drop when masking spatial tokens
- Sequential models show more balanced performance drops across token types, indicating use of both object and spatial cues
- Spatial language loss and path shuffling training methods improve performance and increase reliance on spatial tokens
- Models trained with these methods show better generalization to spatial token masking compared to baseline models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Path-ranking models rely almost exclusively on noun tokens for navigation decisions, largely ignoring spatial and directional cues.
- Mechanism: The path-ranking inference procedure provides the model with the entire navigation path when predicting alignment with instructions. This allows the model to perform pattern matching on noun tokens representing unique objects and landmarks in the environment, rather than needing to understand spatial relationships or directional language.
- Core assumption: The Matterport3D environments contain sufficiently unique objects and visual landmarks that models can identify and match to nouns in instructions without needing spatial understanding.
- Evidence anchors:
  - [abstract] "Surprisingly, they find that top-performing path-ranking models almost exclusively attend to noun tokens and largely disregard spatial and directional words."
  - [section] "The inference procedure in path-ranking VLN models is that they have access to the entire navigation path when predicting alignment with the navigation instruction. We hypothesize that this framework allows the model to focus only on noun words to do pattern matching and disregard extraneous information such as positional panoramic information of the path."

### Mechanism 2
- Claim: Sequential models attend to multiple token types including spatial and directional cues, unlike path-ranking models.
- Mechanism: Sequential models only have access to neighboring environment information at each decision point, preventing them from using future object information. This forces them to rely on spatial and directional tokens to make immediate navigation decisions rather than pattern matching on objects they haven't encountered yet.
- Core assumption: The sequential inference procedure inherently requires understanding of spatial relationships since the model cannot see ahead in the path.
- Evidence anchors:
  - [abstract] "In contrast, sequential models do utilize directional cues."
  - [section] "The inference procedure in sequential VLN models is that the agents only have access to the neighboring environment information when predicting alignment with the navigation instruction, rather than the entire path."

### Mechanism 3
- Claim: Training with spatial language loss (SLL) increases model reliance on spatial tokens by forcing explicit learning of masked spatial words.
- Mechanism: During SLL training, 100% of spatial and directional tokens are masked during the final 10 epochs, forcing the model to learn the relationship between spatial language and navigation actions. This overcomes the density imbalance where spatial tokens are rarely masked during standard MLM training.
- Core assumption: The model can learn spatial understanding when explicitly forced to predict masked spatial tokens in context.
- Evidence anchors:
  - [section] "In these last 10 epochs, 100% of spatial and directional tokens are masked over each instruction and no other tokens are masked. Additionally, no image tokens are masked creating a purely masked language modeling objective."
  - [section] "We hypothesize this may be limiting the agent from learning a advanced representation of spatial tokens."

## Foundational Learning

- Concept: Part-of-speech tagging and linguistic cue sets
  - Why needed here: The paper partitions text tokens into different cue sets by their part of speech and predefined directional words to understand which linguistic elements models attend to.
  - Quick check question: How would you define the set of spatial tokens used in this paper based on the qualitative analysis of R2R instructions?

- Concept: Ablation experiments and masking techniques
  - Why needed here: The paper uses token masking experiments to systematically remove or replace different linguistic cue sets and measure performance impact.
  - Quick check question: What is the key difference between masking tokens versus swapping directional tokens (e.g., replacing "left" with "right")?

- Concept: Path-ranking vs sequential inference procedures
  - Why needed here: The paper contrasts how these two VLN approaches access information during inference, which explains their different token attention patterns.
  - Quick check question: What information does a path-ranking model have access to that a sequential model does not during inference?

## Architecture Onboarding

- Component map: Instruction text → Token masking/ablation → Transformer encoding → Path/image feature processing → Alignment prediction → Success rate evaluation
- Critical path: Input instruction → token masking/ablation → transformer encoding → path/image feature processing → alignment prediction → success rate evaluation on validation splits
- Design tradeoffs: Path-ranking models trade off understanding of spatial language for higher success rates by leveraging complete path information, while sequential models must understand spatial relationships but may suffer from cascading errors
- Failure signatures: High success rate with noun masking but significant drops with spatial token masking indicates the model is pattern matching on objects rather than understanding spatial relationships. Performance drops across all token types in sequential models suggest proper multi-modal understanding
- First 3 experiments:
  1. Run the noun masking ablation to verify the model's heavy reliance on object tokens
  2. Test the spatial token masking to quantify the model's disregard for directional information
  3. Implement the directional token swap experiment to measure if the model follows specific navigational phrases rather than just object references

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do path-ranking models perform better with noun masking compared to directional masking, while sequential models show the opposite trend?
- Basis in paper: [explicit] The paper directly compares the performance of path-ranking and sequential models under different masking conditions, showing that path-ranking models are almost exclusively dependent on nouns while sequential models use both nouns and directional cues.
- Why unresolved: The paper hypothesizes that the difference in inference procedures (path-ranking models see the entire path while sequential models only see neighboring nodes) might explain this, but does not provide definitive evidence.
- What evidence would resolve it: Experiments that systematically vary the amount of future path information available to both model types, or controlled studies isolating the effect of different masking conditions on model performance.

### Open Question 2
- Question: Can the observed limitations of path-ranking models be mitigated by modifying the training procedure, such as incorporating spatial language loss or data augmentation techniques?
- Basis in paper: [explicit] The paper proposes two training methods - spatial language loss and data augmentation via path shuffling - to address the reliance on nouns and increase the use of directional cues.
- Why unresolved: While the paper shows some improvement in performance with these methods, it does not provide a comprehensive analysis of their effectiveness or explore other potential training strategies.
- What evidence would resolve it: Extensive experiments comparing the performance of path-ranking models trained with different combinations of training methods, including spatial language loss, data augmentation, and other techniques.

### Open Question 3
- Question: Is the observed reliance on nouns in path-ranking models a fundamental limitation of the path-ranking paradigm, or can it be overcome with more sophisticated model architectures or training strategies?
- Basis in paper: [inferred] The paper suggests that the difference in inference procedures between path-ranking and sequential models might be a key factor in the observed limitations, but does not explore alternative model architectures or training strategies.
- Why unresolved: The paper focuses on the comparison between path-ranking and sequential models, but does not investigate the potential of other model architectures or training approaches to address the reliance on nouns.
- What evidence would resolve it: Experiments comparing the performance of path-ranking models with different architectures (e.g., attention mechanisms, memory networks) or training strategies (e.g., curriculum learning, meta-learning) to determine if the reliance on nouns can be overcome.

## Limitations
- The findings are constrained by biases in the R2R dataset where paths frequently contain unique landmarks
- The study focuses on a limited set of high-performing models and does not comprehensively evaluate newer transformer-based architectures
- The masking experiments do not fully disentangle whether models are learning semantic relationships versus exploiting statistical correlations

## Confidence
- **High Confidence**: The core finding that path-ranking models rely predominantly on noun tokens while sequential models utilize spatial and directional cues is well-supported by systematic masking experiments
- **Medium Confidence**: The proposed training methods (path shuffling and spatial language loss) demonstrate measurable improvements but their long-term impact on model generalization requires further validation
- **Low Confidence**: The assertion that path-ranking models are "exploiting dataset biases" is somewhat speculative without direct evidence showing how these models would perform in environments with fewer unique landmarks

## Next Checks
1. **Cross-dataset validation**: Evaluate the trained models on a different VLN dataset (e.g., R4R or CVDN) to test whether improvements in spatial token reliance generalize beyond the R2R environment

2. **Counterfactual environment test**: Create or identify navigation scenarios where object landmarks are ambiguous or absent, forcing models to rely on spatial language, to directly test whether path-ranking models fail when pattern matching is insufficient

3. **Long-horizon navigation test**: Evaluate model performance on extended navigation tasks (longer than typical R2R paths) to determine if observed token reliance patterns scale with path complexity and whether sequential models maintain their spatial understanding advantage