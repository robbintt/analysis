---
ver: rpa2
title: 'Canvas: End-to-End Kernel Architecture Search in Neural Networks'
arxiv_id: '2304.07741'
source_url: https://arxiv.org/abs/2304.07741
tags:
- canvas
- kernel
- search
- accuracy
- tensor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new paradigm of Kernel Architecture Search
  (KAS), which constructs effective and efficient tensor computation kernels, the
  basic building blocks in neural networks (NNs). KAS reviews Neural Architecture
  Search (NAS) from a system perspective and uses system techniques to search for
  novel kernel designs with high accuracy and high performance.
---

# Canvas: End-to-End Kernel Architecture Search in Neural Networks

## Quick Facts
- arXiv ID: 2304.07741
- Source URL: https://arxiv.org/abs/2304.07741
- Reference count: 40
- Primary result: Achieves 1.5× average speedups over state-of-the-art with acceptable accuracy loss

## Executive Summary
Canvas introduces Kernel Architecture Search (KAS), a novel approach that treats runtime performance as the primary constraint when searching for tensor computation kernels to replace standard convolutions in neural networks. The system builds on the insight that NAS should be viewed from a system perspective, using system techniques to discover kernel designs with optimal accuracy-performance tradeoffs. By sampling from a rich set of fine-grained primitives to stochastically construct kernel micro-DAGs, Canvas can automatically generate new kernels that achieve significant speedups while maintaining competitive accuracy on standard benchmarks.

## Method Summary
Canvas implements an end-to-end framework that constructs candidate kernels through stochastic sampling of fine-grained primitives to build micro-DAGs. The system handles tensor dimension flexibility through two levels of dynamic variable solvers that ensure structural legality while maximizing utilization of analytical budgets. Generated kernels are evaluated in a distributed infrastructure that measures both runtime performance and accuracy, with candidates pruned based on user-specified constraints. The approach supports replacing standard convolutions with generated kernels in common neural networks, achieving improved performance through architectural innovation at the kernel level.

## Key Results
- Achieves average 1.5× speedups compared to previous state-of-the-art methods
- Successfully rediscovers many manually designed kernels from the past
- Produces new kernel structures that may inspire future machine learning innovations
- Reduces model sizes to 0.1-0.6× of original sizes with approximately 1% accuracy loss

## Why This Works (Mechanism)

### Mechanism 1
Canvas generates novel kernel architectures by stochastically constructing micro-DAGs from fine-grained primitives. The system iteratively samples primitives to grow a micro-DAG, starting from the input tensor shape [C,H,W] and extending to N nodes. This random sampling allows exploration of a large design space of kernel structures. The core assumption is that a diverse set of fine-grained primitives can compose to create effective kernel architectures that replace standard convolutions.

### Mechanism 2
Canvas uses a two-level dynamic variable solver to handle tensor dimension flexibility while ensuring structural legality. During sampling, free dimensions from FC primitives are represented as dynamic variables. The solver by shape matching assigns values to variables to ensure broadcasting legality. The solver by constraints assigns remaining values to maximize utilization of analytical budgets (FLOPs, parameters). The core assumption is that the problem of matching tensor dimensions in a micro-DAG can be reduced to solving for dynamic variables that satisfy divisibility constraints.

### Mechanism 3
Canvas treats runtime performance as the primary constraint, searching for kernels that maximize accuracy within performance limits. The system evaluates candidate kernels against user-specified constraints (FLOPs, parameters, runtime, accuracy). It uses distributed evaluation to measure performance and accuracy, pruning candidates that don't meet thresholds. The core assumption is that runtime performance constraints can effectively guide the search toward kernels that offer good speed-accuracy tradeoffs.

## Foundational Learning

- Concept: Micro-DAG representation of tensor computations
  - Why needed here: Understanding how kernels are represented as directed acyclic graphs of tensor transformations is fundamental to grasping Canvas's approach.
  - Quick check question: How does a micro-DAG differ from a standard computation graph in neural networks?

- Concept: Fine-grained primitive operations
  - Why needed here: Canvas's primitive library forms the building blocks for kernel construction, so understanding what operations are available is crucial.
  - Quick check question: What are the three classes of primitives in Canvas, and what role does each play?

- Concept: Dynamic variable substitution and constraint solving
  - Why needed here: The solvers that assign values to free dimensions are key innovations that enable flexible kernel design while maintaining legality.
  - Quick check question: How does Theorem 1 simplify the problem of substituting values for dynamic variables in broadcast operations?

## Architecture Onboarding

- Component map: Primitive library (rearrangement, arithmetic, blending primitives) -> Micro-DAG random sampler -> Solver by shape matching -> Solver by constraints -> Code generator (PyTorch and TVM implementations) -> Distributed evaluator -> Selection

- Critical path: Sampler → Variable solvers → Code generation → Distributed evaluation → Selection

- Design tradeoffs:
  - Fine-grained vs. coarse-grained primitives: finer granularity offers more flexibility but larger search space
  - Runtime vs. accuracy prioritization: Canvas prioritizes runtime, which may sacrifice some accuracy
  - Search efficiency vs. exploration: Random sampling is efficient but may miss optimal solutions compared to more sophisticated search algorithms

- Failure signatures:
  - If the sampler produces mostly invalid kernels (broadcast dimension mismatches)
  - If the solvers cannot find legal assignments for dynamic variables
  - If the distributed evaluation infrastructure cannot keep up with the sampling rate

- First 3 experiments:
  1. Replace all convolutions in ResNet-18 with Canvas-generated kernels using default constraints
  2. Vary the FLOPs budget constraint to see how it affects the discovered kernels and performance
  3. Compare Canvas's results on a simple network like VGG-16 vs. a more complex one like MobileNet-V2 to understand scalability

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance-first constraint approach in KAS compare to accuracy-first approaches in terms of overall model effectiveness across diverse neural network architectures? While the paper demonstrates KAS's effectiveness on specific CNN architectures, it does not provide a comprehensive comparison across diverse neural network types or explore how the performance-first approach might impact different architectural paradigms.

### Open Question 2
What are the theoretical limits of KAS in terms of the trade-off between model compression and accuracy degradation, and how do these limits vary with different constraint budgets? The paper provides empirical results for specific constraint budgets but does not investigate how the trade-off between compression and accuracy degrades as constraints become more stringent, nor does it establish theoretical bounds for these relationships.

### Open Question 3
How does the scalability of Canvas's distributed evaluation infrastructure perform with increasing numbers of GPU nodes, and what are the bottlenecks in this scaling? While the paper claims superior scalability, it does not present experimental data on how evaluation throughput scales with the number of GPU nodes, nor does it identify potential bottlenecks in the distributed system.

## Limitations
- Evaluation primarily limited to image classification tasks, unclear generalizability to other domains
- Search space may not capture all possible kernel architectures, particularly those requiring more complex topological structures
- Reliance on runtime performance as primary constraint could optimize for specific hardware characteristics rather than achieving genuinely superior architectural designs

## Confidence
- High Confidence (8/10): The core mechanism of stochastic micro-DAG sampling and dynamic variable solving is well-specified and the experimental results on standard benchmarks are reproducible
- Medium Confidence (6/10): The claim that Canvas can "inspire future machine learning innovations" is plausible but not directly demonstrated
- Low Confidence (4/10): The generalizability of the approach to non-vision tasks and scalability to extremely large networks remain uncertain

## Next Checks
1. Evaluate Canvas-generated kernels on non-vision tasks (e.g., Transformer-based language models or speech recognition networks) to assess cross-domain applicability
2. Implement a controlled experiment comparing Canvas's random sampling with more sophisticated search algorithms to quantify the efficiency tradeoff
3. Conduct ablation studies varying the primitive library composition to determine which primitive types contribute most significantly to performance gains