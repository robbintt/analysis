---
ver: rpa2
title: Label Selection Approach to Learning from Crowds
arxiv_id: '2308.10396'
source_url: https://arxiv.org/abs/2308.10396
tags:
- layer
- label
- proposed
- learning
- selection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel method called Label Selection Layer
  for learning from noisy labels in crowdsourcing scenarios. The key idea is to automatically
  determine whether to use a worker's label for training using a selector network,
  inspired by SelectiveNet.
---

# Label Selection Approach to Learning from Crowds

## Quick Facts
- **arXiv ID**: 2308.10396
- **Source URL**: https://arxiv.org/abs/2308.10396
- **Reference count**: 33
- **Key outcome**: Proposed Label Selection Layer (LSL) improves learning from noisy crowdsourced labels, showing competitive or better performance than Crowd Layer on classification and NER tasks.

## Executive Summary
This paper introduces the Label Selection Layer (LSL), a novel method for learning from noisy crowdsourced labels without requiring explicit noise models. Inspired by SelectiveNet, LSL uses a selector network to automatically determine which annotations to use for training. The method is flexible and can be applied to various supervised learning problems by adding a selector network and modifying the objective function. Experimental results demonstrate LSL's effectiveness in multi-class classification and named entity recognition tasks, though its performance on regression tasks remains untested.

## Method Summary
The Label Selection Layer (LSL) is a novel approach to learning from noisy crowdsourced labels that doesn't require explicit noise models. It consists of a base DNN model augmented with a selector network that learns to assign weights to annotations based on their reliability. The selector can be implemented in four variations: Simple, Class-wise, Target-wise, and Feature-based. LSL modifies the loss function to incorporate selector weights, effectively filtering out low-quality annotations during training. The method is trained using standard optimization techniques and can be applied to various supervised learning tasks.

## Key Results
- LSL achieves competitive or superior performance compared to Crowd Layer on multi-class classification tasks.
- The method demonstrates high precision in structured output prediction tasks like named entity recognition.
- LSL's performance on regression tasks is not reported, suggesting potential limitations in this setting.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Label Selection Layer improves training by automatically filtering out low-quality annotations from crowd workers.
- Mechanism: The selector network learns a weight for each annotation indicating its reliability. Annotations with low weights contribute less to the loss, effectively filtering out noise.
- Core assumption: The model can learn to distinguish between reliable and unreliable annotations based on features of the input data and the worker's behavior.
- Evidence anchors:
  - [abstract]: "The proposed method trains a prediction model by automatically determining whether to use a worker's label for training using a selector network."
  - [section]: "The proposed method only selects reliable labels for training."
- Break condition: If the selector network fails to learn meaningful patterns, it may not effectively filter out noise, potentially harming performance.

### Mechanism 2
- Claim: The proposed method is more flexible than Crowd Layer because it doesn't require a generative model of annotation noise.
- Mechanism: By not assuming a specific noise model, the method can adapt to various tasks without needing to redesign the noise model for each new problem.
- Core assumption: The selector network can learn the necessary patterns to handle different types of annotation noise without explicit modeling.
- Evidence anchors:
  - [abstract]: "A major advantage of the proposed method is that it can be applied to almost all variants of supervised learning problems by simply adding a selector network and changing the objective function for existing models, without explicitly assuming a model of the noise in crowd annotations."
  - [section]: "This advantage is particularly demonstrated in rather complex tasks such as structured output prediction."
- Break condition: If the task has a very specific and complex noise structure that requires explicit modeling, the method may underperform compared to approaches with tailored noise models.

### Mechanism 3
- Claim: The proposed method can improve performance on structured output prediction tasks like NER.
- Mechanism: By selectively using high-quality annotations, the model can learn better representations for complex outputs that require more nuanced understanding.
- Core assumption: The selector network can effectively identify high-quality annotations even in tasks with complex output structures.
- Evidence anchors:
  - [section]: "The experimental results show that the performance of the proposed method is almost equivalent to or better than the Crowd Layer, which is one of the state-of-the-art methods for Deep Learning from Crowds, except for the regression problem case."
  - [section]: "The proposed method demonstrates high precision in complex tasks such as structured output prediction."
- Break condition: If the structured output task has very subtle quality differences between annotations, the selector network may struggle to learn effective selection criteria.

## Foundational Learning

- Concept: Understanding of supervised learning and deep learning models.
  - Why needed here: The paper builds upon standard supervised learning frameworks and introduces modifications to deep neural networks.
  - Quick check question: What is the difference between a feature extractor and an output layer in a deep neural network?

- Concept: Knowledge of crowdsourcing and label noise.
  - Why needed here: The paper addresses the problem of learning from noisy labels collected through crowdsourcing platforms.
  - Quick check question: How does label noise in crowdsourced data differ from random label noise?

- Concept: Familiarity with selective prediction and reject option frameworks.
  - Why needed here: The proposed method is inspired by SelectiveNet, which was developed for selective prediction problems.
  - Quick check question: What is the main goal of selective prediction in machine learning?

## Architecture Onboarding

- Component map:
  - Base DNN model (feature extractor + output layer)
  - Label Selection Layer (selector network)
  - Loss function (modified to incorporate selector weights)
  - Training loop (optimizer and hyperparameters)

- Critical path:
  1. Input data and annotations
  2. Feature extraction
  3. Label selection (via selector network)
  4. Loss computation (weighted by selector outputs)
  5. Backpropagation and parameter updates

- Design tradeoffs:
  - Simple vs. complex selector networks (fewer parameters vs. more expressive power)
  - Different selector variations (class-wise, target-wise, feature-based) for different task types
  - Hyperparameter tuning (selector threshold, regularization strength)

- Failure signatures:
  - Selector network not learning (constant selector outputs)
  - Performance worse than baseline without selection
  - Overfitting to selector weights (high variance in selector outputs)

- First 3 experiments:
  1. Implement Simple Label Selection Layer on a basic classification task with known label noise.
  2. Compare performance of different selector variations (Simple, Class-wise, Target-wise, Feature-based) on a structured output task like NER.
  3. Analyze the correlation between selector outputs and actual annotation quality to validate the selection mechanism.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions. However, potential areas for further research include:
1. Extending the method to handle regression tasks effectively
2. Exploring the method's performance on other structured output prediction tasks beyond named entity recognition
3. Investigating the method's scalability to larger datasets and more complex annotation scenarios

## Limitations
- The method's performance on regression tasks is not reported, suggesting potential limitations in this setting.
- Experimental results are limited to three datasets, which may not fully represent the method's generalizability.
- The computational overhead introduced by the selector network is not discussed.

## Confidence
- **High confidence**: LSL's ability to improve performance in multi-class classification tasks by automatically filtering noisy annotations.
- **Medium confidence**: LSL's effectiveness in structured output prediction tasks like NER, as performance gains are demonstrated but the complexity of these tasks may introduce unaccounted variables.
- **Low confidence**: Claims about LSL's superiority in regression tasks, as results for this setting are not reported.

## Next Checks
1. Implement LSL on a regression dataset to verify the authors' claim that the method is not suitable for this task type.
2. Conduct ablation studies to quantify the contribution of different selector variants (Simple, Class-wise, Target-wise, Feature-based) across all task types.
3. Evaluate LSL's performance on a larger-scale crowdsourcing dataset to assess scalability and computational efficiency compared to Crowd Layer.