---
ver: rpa2
title: Reducing Causality to Functions with Structural Models
arxiv_id: '2307.07524'
source_url: https://arxiv.org/abs/2307.07524
tags:
- causes
- cexo
- causal
- death
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel reductive definition of causality based
  on Structural Functional Models (SFM). The core idea is to define causality as mathematical
  functions that map causes to effects, represented using directed acyclic graphs
  and structural equations.
---

# Reducing Causality to Functions with Structural Models

## Quick Facts
- arXiv ID: 2307.07524
- Source URL: https://arxiv.org/abs/2307.07524
- Reference count: 18
- Primary result: Presents a reductive definition of causality using Structural Functional Models (SFM) that aligns with intuitions and handles philosophical thought experiments

## Executive Summary
This paper introduces Structural Functional Models (SFM) as a formal, reductive definition of causality based on mathematical functions mapping causes to effects. SFM uses directed acyclic graphs with structural equations to represent causal relationships, and employs delta compression and contrastive forward inference to generate intuitive causal utterances like "X causes Y." The framework is compatible with but not reducible to probability theory, and is shown to handle various philosophical thought experiments on causation. The authors compile a dataset of causal scenarios and demonstrate that SFM provides a non-circular, formally precise definition of causality that matches human intuitions.

## Method Summary
The method defines causality through Structural Functional Models (SFM) - tuples containing nodes, domains, directed edges, and structural functions. The approach uses delta compression to identify minimal changes between actual and contrastive worlds, and contrastive forward inference to compute causal utterances. The framework distinguishes between exo-nodes (independent assignments) and endo-nodes (functionally determined), enabling causal reasoning through topological evaluation of structural functions. The method is evaluated on a compiled dataset of philosophical causal scenarios, comparing generated causal utterances against intuitive judgments.

## Key Results
- SFM provides a formal definition of causality as mathematical functions that map causes to effects
- Delta compression and contrastive forward inference produce intuitive causal utterances matching human judgments
- SFM is compatible with probability theory but maintains functional determination as primary
- The framework handles various philosophical thought experiments on causation including overdetermination and preemption

## Why This Works (Mechanism)

### Mechanism 1
Causal utterances can be generated by mapping assignments to effects using delta compression and contrastive forward inference. Given an actual world and a contrastive world, identify changed nodes (C), encode only the delta between them, and apply forward inference restricted to descendants of changed nodes. This works because changes in values of exo-nodes propagate deterministically through structural functions to endo-nodes in a finite acyclic graph.

### Mechanism 2
SFM generalizes both deterministic causal models and probabilistic models through structural functions. Randomness can be represented as deterministic functions with random variable inputs via probability integral transform. This works because probability merely adds "weights" to possible worlds, so causal mechanisms are deterministic and true in every realization.

### Mechanism 3
Actual causality can be reduced to identifying minimal changes in exo-node assignments that propagate to endo-node changes. For a given SFM and actual world, find contrastive world(s), compute changed nodes C, and define actual causes as wa|Cexo that lead to wa|Cendo through forward inference. This works because there exists a well-defined set of "actual causes" that can be algorithmically identified through contrastive analysis.

## Foundational Learning

- **Concept**: Functional determination vs. functional dependency
  - Why needed here: Distinguishes between influence (node-level) and causation (value-level) relationships
  - Quick check question: If X = f(Y) where f(x)=2x, is {X:4} functionally determined by {Y:2}? What about {X} functionally depending on {Y}?

- **Concept**: Directed acyclic graphs and topological ordering
  - Why needed here: Enables forward inference by providing computational order for evaluating structural functions
  - Quick check question: Given edges A→B, B→C, C→D, what is one valid topological order? Why can't we have A→B and B→A simultaneously?

- **Concept**: Delta compression and contrastive analysis
  - Why needed here: Reduces causal utterances to minimal changes while preserving information about causal relationships
  - Quick check question: If w0={A:1,B:2,C:3} and w1={A:1,B:7,C:3}, what is C and what is the causal utterance?

## Architecture Onboarding

- **Component map**: SFM consists of nodes (exo/endogenous), domains, edges (parent-child relationships), and structural functions; inference uses topological sort + function evaluation; learning involves selecting appropriate SFM from empirical data
- **Critical path**: Assignment → Topological sort → Function evaluation (forward inference) → Delta compression → Causal utterance generation
- **Design tradeoffs**: Expressiveness vs. guaranteed satisfiability (finite acyclic SFM), computational efficiency vs. handling complex dependencies (delta compression), simplicity vs. modeling power (single SFM vs. SFM-intersection)
- **Failure signatures**: Cyclic dependencies causing infinite regress, non-functional relationships violating right-uniqueness, inconsistent human intuitions about actual causes in complex scenarios
- **First 3 experiments**:
  1. Implement VFI on simple SFM (A→B→C with linear functions) and verify topological ordering produces correct assignments
  2. Test CFI on same SFM with contrastive assignments to verify reduced computation for non-descendants
  3. Apply SFM to OR firing squad problem (Assassin1, Assassin2 → Death) and verify causal utterances match intuitions

## Open Questions the Paper Calls Out

### Open Question 1
Can SFM handle cyclic causal relationships that are actually satisfiable, or is the restriction to acyclic models too limiting? The paper discusses why SFM is restricted to finite acyclic models to avoid the "possibly-unsatisfiable-laws objection" and notes that this restricts the kinds of functional dependencies that can be modeled. This remains unresolved because the authors acknowledge this is a limitation but argue it's necessary for guaranteed satisfiability and simplicity. A comprehensive study comparing SFM's performance on cyclic vs. acyclic models across various real-world causal scenarios would resolve this question.

### Open Question 2
How can SFM be effectively learned from empirical data, especially when the underlying causal relationships are complex and not easily identifiable? The paper briefly mentions that learning causal models from statistical data is covered elsewhere, but focuses on philosophical cases where the possible worlds and laws-of-nature are fully specified. This remains unresolved because the authors don't provide a detailed algorithm or methodology for learning SFM from empirical data. A concrete algorithm for learning SFM from data, along with experimental results showing its effectiveness on benchmark datasets compared to existing causal learning methods, would resolve this question.

### Open Question 3
How can SFM be extended to handle continuous-time causal relationships, such as those described by differential equations? The paper mentions that SFM-intersection-proper can represent autonomous differential equations, but SFM itself cannot. This remains unresolved because the authors acknowledge the limitation of SFM for continuous-time causal relationships but don't provide a clear path for extending the model to handle them. A formal definition of continuous-time SFM, along with algorithms for inference and learning in this extended framework, validated on real-world continuous-time causal systems, would resolve this question.

## Limitations
- SFM is restricted to finite acyclic models, limiting its ability to handle cyclic causal relationships
- The framework requires fully specified possible worlds and laws-of-nature, making empirical learning challenging
- No direct empirical validation against human causal intuitions beyond theoretical examples

## Confidence

**High Confidence**: The formal definition of Structural Functional Models (SFM) as tuples containing nodes, domains, edges, and structural functions is rigorously specified and mathematically sound.

**Medium Confidence**: The claim that SFM can handle various philosophical thought experiments is supported by examples in the paper, but the depth of coverage and edge cases are not fully explored.

**Low Confidence**: The assertion that SFM provides a "precise, non-circular definition of causality" that aligns with all intuitions requires more empirical validation.

## Next Checks

1. **Dataset Validation**: Construct a diverse set of causal scenarios (at least 50) covering different types of causal relationships (deterministic, probabilistic, overdetermined, preempted) and test whether SFM consistently produces intuitively correct causal utterances.

2. **Empirical vs. Theoretical Alignment**: Conduct a formal study comparing SFM-generated causal utterances against human judgments in a controlled setting, measuring agreement rates and identifying systematic discrepancies.

3. **Scalability Analysis**: Implement the inference algorithms on increasingly complex SFM (10→50→100 nodes) and measure computational complexity, identifying break points where delta compression or contrastive inference become intractable.