---
ver: rpa2
title: Towards Robust Aspect-based Sentiment Analysis through Non-counterfactual Augmentations
arxiv_id: '2306.13971'
source_url: https://arxiv.org/abs/2306.13971
tags:
- data
- original
- sentiment
- arts
- robustness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of improving robustness in aspect-based
  sentiment analysis (ABSA) models, which often suffer from performance degradation
  when faced with out-of-distribution data due to learning spurious patterns. The
  proposed method, Causally Relevant Representation (CRR), uses non-counterfactual
  data augmentation to generate noisy yet cost-effective augmentations that preserve
  semantics associated with the target aspect.
---

# Towards Robust Aspect-based Sentiment Analysis through Non-counterfactual Augmentations

## Quick Facts
- arXiv ID: 2306.13971
- Source URL: https://arxiv.org/abs/2306.13971
- Authors: 
- Reference count: 5
- Key outcome: CRR achieves new SOTA on ABSA robustness benchmark, improving ARS by 5.52% on Laptop and 3.82% on Restaurant datasets

## Executive Summary
This paper addresses the challenge of improving robustness in aspect-based sentiment analysis (ABSA) models, which often fail on out-of-distribution data due to learning spurious correlations. The proposed Causally Relevant Representation (CRR) method uses non-counterfactual data augmentation to generate noisy but cost-effective augmentations that preserve semantics associated with target aspects. By modeling invariances between original and augmented data, CRR encourages models to focus on core predictive features while ignoring spurious information. Experiments demonstrate significant improvements over strong pre-trained baselines on standard and robustness-specific datasets.

## Method Summary
CRR trains ABSA models to be invariant to spurious feature changes by combining cross-entropy loss with a KL divergence term that measures prediction consistency between original and augmented inputs. The method uses ADDDIFFMIX augmentation to create noisy versions of training data that preserve aspect-related semantics while modifying spurious context. During training, the model learns to maintain stable prediction distributions across these augmentations, effectively ignoring spurious correlations. The approach is implemented as an additional regularization term in the loss function and is applied during fine-tuning of pre-trained RoBERTa-large models.

## Key Results
- CRR establishes new state-of-the-art on the ABSA robustness benchmark
- Achieves 5.52% improvement in ARS on Laptop dataset and 3.82% on Restaurant dataset
- Demonstrates good transferability across domains with only 10% target data needed for adaptation
- Outperforms baseline RoBERTa by 2.34% accuracy (5.52% ARS) on Laptop and 1.46% accuracy (3.82% ARS) on Restaurant

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CRR improves robustness by promoting prediction invariance between original and augmented data
- Mechanism: Trains model to ignore spurious features by enforcing prediction distribution stability under augmentations that only modify spurious information
- Core assumption: Spurious features can be manipulated without affecting true causal features that determine labels
- Evidence anchors: [abstract], [section 2.1]
- Break condition: If augmentation modifies core features instead of only spurious features

### Mechanism 2
- Claim: Non-counterfactual augmentation suffices to learn core predictive features without explicit causal structure
- Mechanism: Uses cost-effective augmentations that manipulate spurious features while preserving aspect semantics
- Core assumption: Augmentations preserving aspect semantics but modifying spurious context encourage focus on core features
- Evidence anchors: [abstract], [section 2.1], [section 2.3]
- Break condition: If augmentations fail to preserve aspect semantics or introduce too much noise

### Mechanism 3
- Claim: Method generalizes to unseen domains by learning representations invariant under spurious feature interventions
- Mechanism: Enforces invariance under spurious feature changes, capturing causal relationships stable across distributions
- Core assumption: Representations invariant under spurious interventions in training domain remain invariant in unseen domains
- Evidence anchors: [abstract], [section 2.1], [section 4.3]
- Break condition: If domain shift introduces new spurious correlations not present in training

## Foundational Learning

- Concept: Causal inference and graphical models
  - Why needed here: Essential to understand distinction between core features (C) that causally determine labels and spurious features (S) that correlate due to dataset biases
  - Quick check question: What is the difference between a correlation and a causal relationship in ABSA?

- Concept: Data augmentation techniques
  - Why needed here: Method depends on generating augmentations that modify spurious features while preserving aspect-related semantics
  - Quick check question: How does ADDDIFFMIX augmentation differ from counterfactual augmentation?

- Concept: Regularization and loss functions
  - Why needed here: Introduces KL divergence regularization to enforce prediction invariance between original and augmented data
  - Quick check question: What role does KL divergence play in CRR loss vs standard cross-entropy?

## Architecture Onboarding

- Component map: Input data -> ADDDIFFMIX augmentation -> RoBERTa-large encoder -> MLP classifier -> Loss computation (CE + KL divergence)
- Critical path: 1) Load batch, 2) Generate augmented version, 3) Forward pass on both, 4) Compute cross-entropy on both, 5) Compute KL divergence, 6) Backpropagate combined loss
- Design tradeoffs: KL divergence vs JS divergence choice; augmentation strength balancing; regularization weight α tuning
- Failure signatures: Overfitting to original data; augmentation noise overwhelming signal; regularization weight causing underfitting
- First 3 experiments: 1) Baseline RoBERTa on original data only, 2) RoBERTa with ADDDIFFMIX only (no invariance loss), 3) RoBERTa with CRR at different α values

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CRR performance change with different augmentation types beyond ADDDIFFMIX?
- Basis in paper: [explicit] Paper compares ADDDIFF and ADDDIFFMIX but notes other operations possible
- Why unresolved: Only evaluates one specific augmentation strategy
- What evidence would resolve it: Systematic evaluation with various augmentation strategies and their combinations

### Open Question 2
- Question: What is exact mechanism by which KL divergence regularization improves robustness?
- Basis in paper: [explicit] Mentions testing KL divergence in other direction and JS divergence with similar results
- Why unresolved: No detailed analysis of why specific KL divergence direction was chosen
- What evidence would resolve it: Ablation studies comparing different divergence measures and representation analysis

### Open Question 3
- Question: How does CRR perform in zero-shot or few-shot learning scenarios?
- Basis in paper: [inferred] Demonstrates good transfer but only uses 10% target data for fine-tuning
- Why unresolved: Doesn't test generalization to completely unseen domains with no prior exposure
- What evidence would resolve it: Evaluation in zero-shot/few-shot settings on new domains with minimal data

## Limitations

- Core assumption that augmentations only modify spurious features is difficult to verify empirically
- Method's effectiveness may be dataset-specific, particularly for SemEval2014 datasets used
- Additional complexity through KL divergence regularization requires careful hyperparameter tuning
- Evaluation doesn't fully verify whether learned representations capture causal relationships vs memorizing augmentation patterns

## Confidence

**High confidence**: Experimental results showing CRR outperforming baseline RoBERTa on both original and robustness benchmarks with consistent improvements across multiple metrics and datasets.

**Medium confidence**: Claim that CRR "establishes new state-of-the-art" on ABSA robustness benchmark - improvements shown but comparison limited to specific model architectures.

**Low confidence**: Theoretical framing around causal invariance and claim that CRR learns truly invariant representations - provides theoretical motivation but limited empirical validation.

## Next Checks

1. Ablation study testing CRR with different augmentation strategies (ADDDIFF only, ADDDIFFMIX only, random perturbations) to verify improvements stem from invariance principle rather than specific patterns

2. Cross-dataset generalization evaluation testing CRR-trained models on completely different ABSA datasets (MAMS, Twitter) to verify invariance transfers beyond SemEval2014 domain

3. Feature attribution analysis using LIME or integrated gradients to compare which features baseline vs CRR models attend to on ARTs examples, empirically verifying different feature focus