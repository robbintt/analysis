---
ver: rpa2
title: 'DDxT: Deep Generative Transformer Models for Differential Diagnosis'
arxiv_id: '2312.01242'
source_url: https://arxiv.org/abs/2312.01242
tags:
- pathology
- sequence
- diagnosis
- acute
- pathologies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DDxT, a generative Transformer model for
  automated differential diagnosis (DDx) that addresses the need for an intelligent
  system to narrow down possible pathologies from patient information and symptoms.
  Unlike prior RL-based approaches, DDxT uses a simpler supervised and self-supervised
  learning paradigm with a Transformer encoder-decoder architecture to autoregressively
  generate a sequence of likely pathologies and predict the actual pathology using
  a neural network classifier.
---

# DDxT: Deep Generative Transformer Models for Differential Diagnosis

## Quick Facts
- arXiv ID: 2312.01242
- Source URL: https://arxiv.org/abs/2312.01242
- Reference count: 38
- Key outcome: DDxT achieves 99.82% mean accuracy and 0.9472 mean F1 score for DDx generation, and 99.98% mean accuracy with 0.9949 mean F1 score for pathology classification on DDXPlus dataset.

## Executive Summary
DDxT introduces a generative Transformer model for automated differential diagnosis that addresses the need for intelligent systems to narrow down possible pathologies from patient information and symptoms. Unlike prior reinforcement learning approaches, DDxT uses a simpler supervised and self-supervised learning paradigm with a Transformer encoder-decoder architecture to autoregressively generate likely pathologies and predict the actual pathology using a neural network classifier. Experiments on the DDXPlus dataset demonstrate superior performance compared to previous methods, showing robustness across pathologies with high precision and recall.

## Method Summary
DDxT employs a 6-layer transformer encoder-decoder architecture where the encoder processes patient context (age, gender, symptoms) and the decoder autoregressively generates a ranked sequence of likely pathologies. The model uses categorical cross-entropy loss for both the decoder output (DDx sequence) and classifier output (final pathology), optimized jointly. Input preprocessing converts patient records into tokenized sequences with special tokens for sequence boundaries, and the model outputs a ranked differential diagnosis sequence along with a final pathology prediction.

## Key Results
- DDx generation achieves 99.82% mean accuracy and 0.9472 mean F1 score
- Pathology classification achieves 99.98% mean accuracy with 0.9949 mean F1 score
- Significantly outperforms previous RL-based methods on DDXPlus dataset
- Shows high precision and recall across pathologies, with limitations for certain conditions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The transformer decoder can autoregressively generate a ranked differential diagnosis sequence more effectively than reinforcement learning-based symptom acquisition.
- Mechanism: By using a generative decoder with positional embeddings, the model preserves the order of pathologies, ensuring higher-probability conditions are predicted first, which matches the ground truth DDx ordering.
- Core assumption: The ground truth DDx sequence is sorted by probability, so preserving this order improves F1 score.
- Evidence anchors:
  - [abstract]: "The ground truth DDx output sequence is organized in descending order of the probability score of each pathology"
  - [section 3.1]: "The ground truth DDx output sequence is organized in descending order of the probability score of each pathology, i.e., the order of prediction is significant and the pathology with a higher probability needs to be predicted first"

### Mechanism 2
- Claim: Concatenating encoder and decoder global average pooled features improves final pathology classification accuracy.
- Mechanism: The encoder captures patient context while the decoder captures likely pathologies; combining both provides richer information for the classifier.
- Core assumption: Both encoder and decoder features are complementary and necessary for accurate final pathology prediction.
- Evidence anchors:
  - [section 3.2]: "The final layer of the encoder holds the processed context information of the evidence... and the final layer of the decoder holds the information of all the possible likely pathologies. Therefore, combining both features will be quite advantageous in predicting the actual pathology."

### Mechanism 3
- Claim: Supervised and self-supervised learning signals are sufficient to achieve high performance without reinforcement learning.
- Mechanism: The model is trained with categorical cross-entropy on both the decoder output and classifier output, optimizing both tasks jointly.
- Core assumption: The dataset labels are accurate and sufficient for training without interactive RL.
- Evidence anchors:
  - [abstract]: "a generative approach trained with simpler supervised and self-supervised learning signals can achieve superior results"
  - [section 3.3]: "A categorical cross-entropy loss is employed for both the decoder output and the classifier which are added together to compute the final loss."

## Foundational Learning

- Concept: Sequence generation with positional embeddings
  - Why needed here: To maintain the ranking order of differential diagnoses (most likely to least likely) which is critical for evaluation.
  - Quick check question: If positional embeddings are removed, how would the model's DDx sequence evaluation change?

- Concept: Encoder-decoder architecture in transformers
  - Why needed here: The encoder processes patient context, and the decoder generates the differential diagnosis sequence, mimicking a physician's reasoning process.
  - Quick check question: What would happen if we only used the encoder for both context and generation?

- Concept: Multi-task learning with joint loss
  - Why needed here: Simultaneously optimizing for DDx generation and final pathology classification improves overall performance.
  - Quick check question: If we trained only on DDx generation loss, how would final pathology accuracy be affected?

## Architecture Onboarding

- Component map:
  - Input preprocessing: age, gender, initial evidence, evidence → tokenized sequence
  - Encoder: 6-layer transformer encoder processing patient context
  - Decoder: 6-layer transformer decoder generating DDx sequence autoregressively
  - Classifier: GAP on encoder + decoder features → 2-layer MLP → pathology prediction
  - Loss: sum of categorical cross-entropy from decoder and classifier

- Critical path: Input → Encoder → Decoder → DDx sequence; Input → Encoder → Decoder → Classifier → Final pathology

- Design tradeoffs:
  - Fixed sequence lengths (80 encoder, 40 decoder) simplify batching but may truncate long cases.
  - Global average pooling loses spatial information but reduces parameters and avoids overfitting.
  - Joint training balances DDx generation and classification but may require careful loss weighting.

- Failure signatures:
  - Low DDx precision: model generating plausible but incorrect pathologies; check token embeddings and decoder training.
  - Low final pathology accuracy: encoder not capturing context well; check input tokenization and encoder depth.
  - Mode collapse in generation: decoder stuck in repetitive patterns; check attention masks and positional embeddings.

- First 3 experiments:
  1. Ablation: Remove positional embeddings from decoder; measure change in DDx F1 score.
  2. Ablation: Remove classifier branch; measure change in final pathology accuracy.
  3. Data perturbation: Add noise to input sequences; measure robustness of DDx generation and classification.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the performance differences between DDxT and RL-based methods when dealing with pathologies that have lower precision scores, such as Acute and Chronic rhinosinusitis?
- Basis in paper: [explicit] The paper mentions that certain conditions like Acute and Chronic rhinosinusitis obtain lower precision scores.
- Why unresolved: The paper compares the overall performance of DDxT with RL-based methods but does not provide specific performance metrics for individual pathologies, especially those with lower precision.
- What evidence would resolve it: Detailed performance metrics for individual pathologies, particularly those with lower precision scores, comparing DDxT with RL-based methods.

### Open Question 2
- Question: How does the accuracy of DDxT change with variations in the quality and completeness of patient information input?
- Basis in paper: [inferred] The paper assumes the fidelity of the data and mentions that the performance of the system has a dependency on the correct rendering of accurate information by an authorized user or another automated system.
- Why unresolved: The paper does not explore how variations in the quality and completeness of patient information affect the accuracy of DDxT.
- What evidence would resolve it: Experiments or studies showing the performance of DDxT with varying levels of data quality and completeness in patient information.

### Open Question 3
- Question: Can DDxT be effectively adapted for use in under-resourced communities with limited access to comprehensive medical histories and diagnostic tools?
- Basis in paper: [explicit] The paper suggests that DDxT could be beneficial for lower-performing doctors or those in under-resourced communities.
- Why unresolved: The paper does not provide evidence or studies on the effectiveness of DDxT in under-resourced settings or with limited access to medical data.
- What evidence would resolve it: Case studies or trials of DDxT in under-resourced communities, focusing on its adaptability and effectiveness with limited medical data.

## Limitations
- Evaluation based entirely on synthetic DDXPlus data rather than real clinical cases, raising generalizability concerns
- Suspiciously high pathology classification accuracy (99.98%) suggesting potential overfitting or dataset artifacts
- Lower precision for specific conditions like Acute and Chronic rhinosinusitis indicates systematic weaknesses
- Heavy dependency on accurate input data not fully explored for robustness

## Confidence

- **High confidence**: The transformer architecture and training methodology is technically sound and well-documented
- **Medium confidence**: Claims that supervised learning outperforms RL-based approaches need external validation on real clinical data
- **Low confidence**: Perfect pathology classification accuracy (99.98%) seems unrealistic and suggests potential evaluation methodology issues

## Next Checks
1. Cross-dataset validation: Test DDxT on real clinical case datasets (e.g., MIMIC-III) to verify performance holds outside synthetic data
2. Error analysis on weak conditions: Systematically analyze model predictions for Acute and Chronic rhinosinusitis cases to identify error sources
3. Input perturbation robustness: Evaluate model performance when patient input data contains controlled amounts of noise or missing information