---
ver: rpa2
title: Boosting the Cross-Architecture Generalization of Dataset Distillation through
  an Empirical Study
arxiv_id: '2312.05598'
source_url: https://arxiv.org/abs/2312.05598
tags:
- distillation
- dataset
- performance
- cross-architecture
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of poor cross-architecture generalization
  in dataset distillation, where synthetic datasets are biased towards the distillation
  model's architecture, leading to poor performance when evaluated on different architectures.
  The proposed method, ELF (EvaLuation with distillation Feature), mitigates this
  issue by leveraging bias-free intermediate features from the distillation model
  to guide the training of the evaluation model.
---

# Boosting the Cross-Architecture Generalization of Dataset Distillation through an Empirical Study

## Quick Facts
- arXiv ID: 2312.05598
- Source URL: https://arxiv.org/abs/2312.05598
- Reference count: 10
- Primary result: ELF improves cross-architecture generalization in dataset distillation by using bias-free intermediate features from the distillation model to guide evaluation model training.

## Executive Summary
This paper addresses the critical problem of poor cross-architecture generalization in dataset distillation, where synthetic datasets are inherently biased toward the architecture used during distillation. The proposed ELF method (EvaLuation with distillation Feature) leverages bias-free intermediate features from the distillation model to guide the training of evaluation models, enabling them to retain performance while being architecture-agnostic. Through extensive experiments on CIFAR-10/100, Tiny ImageNet, and ImageNet datasets, ELF demonstrates significant improvements across multiple baseline dataset distillation methods, including DSA, MTT, and TESLA.

## Method Summary
The ELF method mitigates inductive bias in synthetic datasets by utilizing intermediate features from the distillation model as supervision during evaluation model training. The approach extracts feature maps from the distillation model's intermediate layers, which are considered "bias-free" since they're derived from the original dataset rather than the synthetic one. These features are then used to supervise both the front and rear sections of the evaluation model through a combined loss function. The evaluation model learns to predict labels based on both its own learned features and disturbed features from the distillation model, reducing architectural bias while maintaining classification performance.

## Key Results
- ELF improves MTT's accuracy by 12.19% when evaluating VGG11-IN on CIFAR-10
- Significant cross-architecture performance gains across CIFAR-10/100, Tiny ImageNet, and ImageNet datasets
- Effective improvements demonstrated across multiple baseline methods (DSA, MTT, TESLA)
- Enables evaluation models to retain performance while being architecture-agnostic

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic datasets undergo inductive bias toward the distillation model architecture, leading to poor cross-architecture generalization.
- Mechanism: The distillation process optimizes synthetic samples to fit the training procedure of a specific model architecture, causing them to perform poorly when evaluated on different architectures.
- Core assumption: The synthetic dataset's effectiveness is tied to the architectural similarity between distillation and evaluation models.
- Evidence anchors:
  - [abstract]: "the synthetic datasets undergo an inductive bias towards the distillation model"
  - [section]: "the synthetic dataset retains an inductive bias towards the distillation model"
  - [corpus]: Weak - corpus papers focus on dataset distillation improvements but don't explicitly discuss architectural inductive bias.
- Break condition: If the synthetic dataset is architecture-agnostic from the start, or if the distillation process explicitly targets architecture-invariant features.

### Mechanism 2
- Claim: Using intermediate features from the distillation model as supervision reduces the inductive bias.
- Mechanism: The distillation model's intermediate features are extracted from the original dataset, making them free from the synthetic dataset's inductive bias. By using these features to guide the evaluation model's training, the evaluation model learns from unbiased knowledge.
- Core assumption: Intermediate features from the distillation model are architecture-invariant and contain the essential information needed for evaluation.
- Evidence anchors:
  - [abstract]: "utilizes features from intermediate layers of the distillation model for the cross-architecture evaluation"
  - [section]: "the feature maps from distillation model are invulnerable to the inductive bias"
  - [corpus]: Weak - corpus papers discuss dataset distillation but don't specifically mention using intermediate features for cross-architecture generalization.
- Break condition: If the intermediate features are also affected by the synthetic dataset's inductive bias, or if the evaluation model cannot effectively learn from these features.

### Mechanism 3
- Claim: ELF improves cross-architecture generalization by learning to predict labels based on disturbed features from the distillation model.
- Mechanism: The evaluation model is trained using a combination of its own classification loss and losses based on the distillation model's intermediate features, allowing it to learn to predict labels using both its own features and the disturbed features.
- Core assumption: The evaluation model can effectively combine its own learned features with the disturbed features from the distillation model to improve generalization.
- Evidence anchors:
  - [abstract]: "the distillation features play as disturbed variables to refine the performance of evaluation model in predicting labels"
  - [section]: "the distillation features play as disturbed variables to refine the performance of evaluation model in predicting labels"
  - [corpus]: Weak - corpus papers discuss dataset distillation but don't specifically mention using disturbed features for cross-architecture generalization.
- Break condition: If the evaluation model cannot effectively combine its own learned features with the disturbed features, or if the disturbed features are not beneficial for the evaluation task.

## Foundational Learning

- Concept: Dataset Distillation
  - Why needed here: Understanding the concept of dataset distillation is crucial to grasp the problem of cross-architecture generalization and the proposed solution.
  - Quick check question: What is the main goal of dataset distillation, and how does it differ from traditional dataset creation?

- Concept: Inductive Bias
  - Why needed here: The concept of inductive bias is central to understanding why synthetic datasets perform poorly on different architectures.
  - Quick check question: What is inductive bias in machine learning, and how can it affect the generalization of a model?

- Concept: Feature Extraction and Supervision
  - Why needed here: Understanding how features are extracted from intermediate layers and used as supervision is key to grasping the proposed method.
  - Quick check question: How can features from one model be used to supervise the training of another model, and what are the potential benefits and challenges of this approach?

## Architecture Onboarding

- Component map: Distillation Model -> Feature Extraction -> Evaluation Model Training -> Cross-Architecture Evaluation
- Critical path: Extract intermediate features from distillation model → Use features to supervise evaluation model training → Evaluate on different architectures
- Design tradeoffs: The main tradeoff is between the complexity of the ELF method and the potential improvement in cross-architecture generalization. The method introduces additional complexity in terms of feature extraction and supervision, but it can significantly improve performance.
- Failure signatures: Potential failure modes include the distillation model's features being affected by inductive bias, the evaluation model being unable to effectively learn from the disturbed features, or the disturbed features not being beneficial for the evaluation task.
- First 3 experiments:
  1. Implement the ELF method on a simple dataset (e.g., CIFAR-10) with a small number of images per class to verify the basic functionality and performance improvement.
  2. Test the ELF method with different evaluation architectures (e.g., ResNet, VGG) to assess the cross-architecture generalization improvement.
  3. Compare the ELF method with baseline dataset distillation methods to quantify the performance gain in terms of cross-architecture generalization.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can ELF be effectively applied to DD methods beyond the parameter-matching, distribution-matching, and meta-learning paradigms explored in the paper?
- Basis in paper: [explicit] The paper focuses on improving the cross-architecture performance of DD methods from these three groups, but does not explore other DD paradigms.
- Why unresolved: The paper does not investigate the applicability of ELF to DD methods outside the studied paradigms.
- What evidence would resolve it: Testing ELF on DD methods from other paradigms and comparing the results with the current baselines.

### Open Question 2
- Question: How does ELF perform when the distillation model and evaluation model have vastly different architectures, such as a ConvNet and a transformer?
- Basis in paper: [inferred] The paper demonstrates ELF's effectiveness for improving cross-architecture generalization, but the evaluation models considered are still relatively similar in structure (e.g., different variants of ConvNets and ResNets).
- Why unresolved: The paper does not explore extreme architectural differences between the distillation and evaluation models.
- What evidence would resolve it: Conducting experiments with distillation and evaluation models having significantly different architectures and comparing the results with the current findings.

### Open Question 3
- Question: What is the impact of ELF on the privacy and security aspects of DD, particularly in terms of information leakage from the distillation features?
- Basis in paper: [inferred] The paper does not discuss the potential privacy and security implications of using distillation features in ELF.
- Why unresolved: The paper focuses on the performance aspect of ELF without considering its privacy and security implications.
- What evidence would resolve it: Analyzing the privacy and security aspects of ELF, such as the potential for information leakage through the distillation features, and comparing it with existing DD methods.

## Limitations

- The method's effectiveness may vary significantly depending on the specific architectures used for distillation and evaluation, with limited validation on highly diverse architectural families.
- The scalability of ELF to larger, more complex real-world datasets and applications remains untested, potentially limiting its practical utility.
- The paper does not address potential privacy and security implications of using distillation features, which could be a concern in sensitive applications.

## Confidence

- **High Confidence**: The core mechanism of using intermediate features to reduce inductive bias is well-motivated and supported by experimental results. The improvement in cross-architecture generalization is consistently observed across multiple baseline methods and datasets.
- **Medium Confidence**: The claim that ELF can significantly improve cross-architecture generalization is supported by experiments, but the extent of improvement may vary depending on the specific architectures and datasets used.
- **Low Confidence**: The claim that ELF is universally applicable to all dataset distillation methods is not thoroughly validated, as the experiments focus on a limited set of baseline methods.

## Next Checks

1. **Architectural Robustness**: Test ELF with a wider range of architectures, including more diverse models like EfficientNet or MobileNet, to assess its generalization across different architectural families.

2. **Hyperparameter Sensitivity Analysis**: Conduct a comprehensive study on the sensitivity of ELF's performance to the trade-off parameters λf ront and λrear, and provide guidelines for their optimal selection.

3. **Real-World Applicability**: Evaluate ELF on real-world datasets or tasks, such as medical imaging or autonomous driving, to assess its practical utility and scalability beyond benchmark datasets.