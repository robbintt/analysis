---
ver: rpa2
title: Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation
arxiv_id: '2310.16964'
source_url: https://arxiv.org/abs/2310.16964
tags:
- critic
- text
- data
- generation
- base
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a novel approach to mitigate hallucinations
  in data-to-text generation by incorporating a specialized text critic classifier
  into the decoding process. The critic assesses the coherence between the generated
  text and the input data, guiding the generation on-the-fly without modifying the
  underlying language model or requiring additional training data.
---

# Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation

## Quick Facts
- arXiv ID: 2310.16964
- Source URL: https://arxiv.org/abs/2310.16964
- Reference count: 26
- The paper proposes a method to mitigate hallucinations in data-to-text generation by incorporating a specialized text critic classifier into the decoding process, improving hallucination metrics while maintaining text quality.

## Executive Summary
The paper addresses the challenge of hallucination in neural data-to-text generation, where generated text lacks grounding in the input data. It proposes a novel approach that incorporates a specialized text critic classifier into the decoding process to guide generation on-the-fly. The critic assesses the coherence between the generated text and the input data, influencing the next token selection without modifying the underlying language model or requiring additional training data. Experiments on WebNLG and OpenDialKG benchmarks show that the proposed approach improves hallucination metrics (NLI, BLEURT) while maintaining text quality (BLEU, METEOR, BERTScore). Manual evaluation confirms reduced hallucinations, particularly for complex instances.

## Method Summary
The method involves training a text critic classifier using synthetic negative examples created by perturbing tokens in references or using unconditional LM outputs. During decoding, the critic's output is combined with the language model's probability distribution to influence the next token selection. The approach operates on word probabilities and can be combined with any model and decoding strategy. The critic weight λ is set to 0.25 for WebNLG and 1 for OpenDialKG, with a linear warmup for the first five tokens to address initial inaccuracy.

## Key Results
- The proposed critic-driven decoding approach improves hallucination metrics (NLI, BLEURT) on WebNLG and OpenDialKG benchmarks.
- The method maintains text quality, as evidenced by stable BLEU, METEOR, and BERTScore scores.
- Manual evaluation confirms reduced hallucinations, particularly for complex instances, with the base critic variant achieving the best overall performance.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The critic provides real-time coherence guidance during decoding, reducing hallucinations without modifying the underlying LM.
- **Mechanism**: The critic classifier evaluates the match between the generated text prefix and the input data at each decoding step. Its output is combined with the LM's probability distribution to influence the next token selection. This creates a feedback loop where the critic's assessment of coherence modulates the generation process on-the-fly.
- **Core assumption**: The critic can accurately assess the coherence between partial text outputs and the input data representation.
- **Evidence anchors**:
  - [abstract]: "Our method does not need any changes to the underlying LM's architecture or training procedure and can thus be combined with any model and decoding operating on word probabilities."
  - [section]: "The critic is modelled as a binary classifier, conditioned on the data, past tokens and the token currently being decoded. It is thus run at each decoding step, and it is evaluating the viability of the current prefix of the generation output."
  - [corpus]: Found 25 related papers, average neighbor FMR=0.444, average citations=0.0. (Weak evidence from corpus; no direct citations to this specific mechanism)
- **Break condition**: The critic becomes ineffective if it cannot accurately distinguish between coherent and hallucinatory text prefixes, or if the computational overhead makes real-time evaluation impractical.

### Mechanism 2
- **Claim**: Training the critic on synthetic negative examples allows it to learn hallucination detection without requiring additional human-labeled data.
- **Mechanism**: The critic is trained using positive examples from the base LM's training data and synthetic negative examples created by perturbing tokens in the references or using unconditional LM outputs. This creates a training set that teaches the critic to identify when text deviates from the input data.
- **Core assumption**: Synthetic negative examples are representative enough of real hallucinations to train an effective critic.
- **Evidence anchors**:
  - [section]: "Negative examples must be synthesized and are crucial for training the critic, as they teach it how to detect that the generated text starts deviating from the input data (i.e. hallucinations). Therefore, we explore five ways of generating negative examples."
  - [section]: "All critic model variants are trained by optimizing binary cross-entropy loss."
  - [corpus]: Weak evidence; no direct citations supporting the effectiveness of synthetic negative examples for hallucination detection.
- **Break condition**: The synthetic negative examples fail to capture the complexity and diversity of real hallucinations, leading to a critic that cannot generalize well to actual generation scenarios.

### Mechanism 3
- **Claim**: The weighted combination of critic and LM probabilities provides a tunable balance between text quality and hallucination reduction.
- **Mechanism**: The final probability for the next token is computed as a weighted sum of the critic's confidence in the match and the LM's probability, controlled by parameter λ. This allows adjusting the trade-off between maintaining text quality (higher BLEU/METEOR scores) and reducing hallucinations (higher NLI/BLEURT scores).
- **Core assumption**: A linear combination of the critic and LM probabilities is an effective way to balance these competing objectives.
- **Evidence anchors**:
  - [section]: "In practice, our implementation operates on logarithms rather than raw probabilities and uses an additional weight λ that adjusts the influence of the critic on the final result."
  - [section]: "The critic weight λ = 0.25 (see Eq. 4) was used for all the models for WebNLG and λ = 1 for OpenDialKG."
  - [section]: "We found that the output of the critic can be noisy when evaluating the match between the data and only a few initial tokens of the text. Therefore, we add a simple linear warmup for λ for the first five tokens."
  - [corpus]: Weak evidence; no direct citations supporting this specific weighting approach.
- **Break condition**: The fixed weighting scheme (λ = 0.25) is suboptimal for all datasets and contexts, or the linear warmup does not adequately address the critic's initial inaccuracy.

## Foundational Learning

- **Concept**: Probability factorization and Bayes' rule application
  - Why needed here: The method relies on reformulating the generation probability to include the critic's assessment, which requires understanding how conditional probabilities can be decomposed and recombined.
  - Quick check question: How does the probability factorization P(y|x,c) lead to the formula that combines P(c|y≤i,x) and P(yi|y≤i-1,x)?

- **Concept**: Binary classification and cross-entropy loss
  - Why needed here: The critic is trained as a binary classifier to distinguish between coherent and hallucinatory text prefixes, requiring understanding of classification objectives and training procedures.
  - Quick check question: What is the role of binary cross-entropy loss in training the critic, and why is it appropriate for this task?

- **Concept**: Auto-regressive generation and decoding algorithms
  - Why needed here: The method modifies the decoding process by incorporating the critic's output at each step, requiring understanding of how auto-regressive models generate text token by token.
  - Quick check question: How does the critic-driven decoding algorithm differ from standard greedy decoding, and what computational considerations arise from this difference?

## Architecture Onboarding

- **Component map**: Base conditional language model (e.g., BART) -> Text critic classifier (XLM-RoBERTa with classification head) -> Decoder -> Synthetic data generator

- **Critical path**:
  1. Train base LM on data-to-text dataset
  2. Generate synthetic negative examples for critic training
  3. Train critic classifier on positive and negative examples
  4. During decoding, at each step:
     - Compute LM probabilities for next tokens
     - Run critic on top k tokens to get coherence scores
     - Combine probabilities using weighted formula
     - Select next token based on modified probabilities

- **Design tradeoffs**:
  - Computational cost vs. hallucination reduction: Running the critic at each decoding step adds overhead, but this is mitigated by only evaluating top k tokens
  - Critic accuracy vs. training data quality: Synthetic negative examples may not fully capture the complexity of real hallucinations, potentially limiting critic effectiveness
  - Weight λ tuning: Finding the optimal balance between text quality and hallucination reduction requires careful tuning and may vary across datasets

- **Failure signatures**:
  - Critic-driven decoding produces significantly worse text quality metrics (BLEU, METEOR) compared to baseline, indicating over-correction
  - Automatic hallucination metrics (NLI, BLEURT) do not improve despite critic integration, suggesting critic ineffectiveness
  - Manual evaluation reveals no reduction in hallucinations despite automatic metric improvements, indicating metric limitations
  - Decoding becomes prohibitively slow due to critic evaluation overhead, making the approach impractical for real-time applications

- **First 3 experiments**:
  1. Implement baseline decoding with greedy search and establish text quality and hallucination metrics
  2. Train a basic critic using the "base" negative example generation method and integrate it with decoding, comparing performance to baseline
  3. Experiment with different values of λ (e.g., 0.1, 0.25, 0.5, 1.0) to find the optimal balance between text quality and hallucination reduction, analyzing the trade-offs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the critic-driven decoding approach perform on datasets significantly different from WebNLG and OpenDialKG in terms of structure and domain?
- Basis in paper: [inferred] The paper notes that the critic's performance may degrade if the underlying training data is too noisy, and the experiments are limited to two specific datasets.
- Why unresolved: The paper only evaluates the approach on WebNLG and OpenDialKG, leaving the generalizability to other domains untested.
- What evidence would resolve it: Testing the critic-driven decoding on diverse datasets with varying structures and domains, such as E2E or CommonGen, would provide insights into its broader applicability.

### Open Question 2
- Question: What is the impact of the critic's accuracy on the final text quality, and how does it vary with the length of the generated text?
- Basis in paper: [explicit] The paper mentions that the critic's accuracy grows rapidly with the length of the prefix, reaching a high level around the length of 5 tokens, but it doesn't explore how this affects longer texts.
- Why unresolved: While the paper discusses the critic's performance on short prefixes, it doesn't investigate how accuracy changes for longer generated texts or its impact on text quality.
- What evidence would resolve it: Conducting experiments to measure the critic's accuracy at different stages of text generation and correlating it with text quality metrics for longer outputs would clarify this relationship.

### Open Question 3
- Question: How does the critic-driven decoding approach scale with larger models or more complex datasets?
- Basis in paper: [inferred] The paper uses BART-base and XLM-RoBERTa-base models, and while it mentions computational costs, it doesn't explore scalability with larger models or more complex datasets.
- Why unresolved: The experiments are conducted with relatively small models, and the paper doesn't address how the approach would perform with larger models or more complex datasets.
- What evidence would resolve it: Testing the approach with larger models (e.g., GPT-3, T5) and more complex datasets would reveal scalability issues and potential limitations.

## Limitations
- The effectiveness of synthetic negative examples for training the critic is not thoroughly validated, raising questions about their ability to capture the full complexity of real hallucinations.
- The computational overhead of running the critic at each decoding step is not quantified, potentially limiting the approach's applicability to large-scale or real-time applications.
- The fixed critic weight λ = 0.25 may not be optimal across different datasets and contexts, suggesting potential overfitting to the specific benchmarks used.

## Confidence
- **High Confidence**: The core mechanism of combining critic and LM probabilities is sound and well-implemented. The experimental results showing improved hallucination metrics while maintaining text quality are convincing.
- **Medium Confidence**: The approach's generalization to other data-to-text tasks and datasets is plausible but not fully established. The synthetic negative example generation methods show promise but may have limitations in capturing real-world hallucination patterns.
- **Low Confidence**: The scalability and computational efficiency of the method for real-time applications is not addressed, and the long-term stability of the critic-driven decoding approach across extended generation tasks is unknown.

## Next Checks
1. **Synthetic Data Quality Analysis**: Conduct an ablation study comparing the five different synthetic negative example generation methods to determine which approach most effectively captures realistic hallucinations and leads to the best critic performance.

2. **Computational Overhead Benchmarking**: Measure and analyze the exact computational overhead introduced by the critic evaluation at each decoding step, including wall-clock time comparisons between baseline and critic-driven decoding across different sequence lengths.

3. **Cross-Dataset Generalization Test**: Apply the method to a different data-to-text dataset (such as DART or E2E) to evaluate whether the fixed critic weight λ = 0.25 remains optimal or requires dataset-specific tuning.