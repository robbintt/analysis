---
ver: rpa2
title: Contrastive Learning-based Imputation-Prediction Networks for In-hospital Mortality
  Risk Modeling using EHRs
arxiv_id: '2308.09896'
source_url: https://arxiv.org/abs/2308.09896
tags:
- imputation
- time
- learning
- patient
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of predicting in-hospital mortality
  risk using electronic health records (EHRs), which are inherently irregular with
  missing values and varying time intervals between records. The proposed method introduces
  a novel contrastive learning-based imputation-prediction network that groups similar
  patients through graph analysis and uses their information, along with personal
  contextual data, to impute missing values.
---

# Contrastive Learning-based Imputation-Prediction Networks for In-hospital Mortality Risk Modeling using EHRs

## Quick Facts
- arXiv ID: 2308.09896
- Source URL: https://arxiv.org/abs/2308.09896
- Reference count: 40
- Primary result: Outperforms state-of-the-art methods on MIMIC-III and eICU datasets for both imputation (MAE 0.3563) and mortality prediction (AUROC 0.8533)

## Executive Summary
This paper introduces a novel contrastive learning-based imputation-prediction network for modeling in-hospital mortality risk using electronic health records. The approach addresses the challenge of irregular, missing EHR data by grouping similar patients through graph analysis and using their information, along with personal contextual data, to impute missing values. By integrating contrastive learning into the network architecture, the method enhances patient representation learning and improves predictive performance on classification tasks.

## Method Summary
The method employs a multi-stage process: first, it learns personalized patient representations using multi-channel feed-forward networks for values and time intervals, then fuses them with contextual features via attention mechanisms. Second, it constructs a similarity graph between patients using cosine similarity and a learnable threshold, then aggregates information from similar patients using graph convolutional networks. Finally, it integrates supervised and unsupervised contrastive learning losses to shape the embedding space, improving both imputation accuracy and mortality prediction performance.

## Key Results
- Achieved MAE of 0.3563 for imputation on MIMIC-III compared to 0.3988 for best baseline
- Obtained AUROC of 0.8533 for mortality prediction on MIMIC-III compared to 0.8461 for best baseline
- Demonstrated consistent improvement over state-of-the-art methods on both MIMIC-III and eICU datasets

## Why This Works (Mechanism)

### Mechanism 1
- Graph-based patient stratification enables imputation to leverage contextually similar patient information rather than population-wide statistics
- Core assumption: Patients with similar trajectories and characteristics will have comparable patterns in their time-series data
- Evidence: Similarity matrix Λ with learnable threshold φ applied before GCN layers
- Break condition: If similarity measure fails to capture clinical relevance or threshold is poorly chosen

### Mechanism 2
- Contrastive learning improves both tasks by enforcing similarity within strata and dissimilarity across classes
- Core assumption: Patients with same outcome share latent representation space
- Evidence: Supervised contrastive loss for prediction, unsupervised for imputation
- Break condition: If augmentation is too weak/strong or temperature τ is poorly set

### Mechanism 3
- Multi-channel FFNs separately embed values and intervals before cross-attention fusion
- Core assumption: Value and interval information have distinct but complementary patterns
- Evidence: Separate FFN(v) and FFN(t) followed by attention-based cross module
- Break condition: If FFNs are too shallow or share capacity poorly

## Foundational Learning

- Concept: Graph Neural Networks (GCN) and attention mechanisms
  - Why needed: To aggregate patient similarity information and fuse multi-modal embeddings effectively
  - Quick check: What is the difference between a standard GCN layer and the variant used here with a learnable edge threshold?

- Concept: Contrastive learning (supervised and unsupervised variants)
  - Why needed: To shape the embedding space so that similar patients or patient views are closer
  - Quick check: How does the temperature parameter τ affect the strength of contrastive penalties?

- Concept: Time-series embedding with missing value indicators
  - Why needed: To encode irregular sampling intervals and missingness patterns inherent in EHR data
  - Quick check: Why does the model compute δ(l) and δ(n) separately rather than a single time-delta?

## Architecture Onboarding

- Component map: Input -> embeddings -> similarity graph -> GCN aggregation -> fusion -> contrastive loss -> output
- Critical path: Input → embeddings → similarity graph → GCN aggregation → fusion → contrastive loss → output
- Design tradeoffs:
  - Similarity threshold tuning for graph sparsity vs. information flow
  - Temperature τ in contrastive loss for gradient stability vs. embedding discrimination
  - FFN depth for representation capacity vs. overfitting
- Failure signatures:
  - Low MAE but poor AUROC: graph may be capturing too local similarity
  - High variance in metrics: threshold φ or τ not well tuned
  - Slow convergence: GCN layers too deep relative to graph connectivity
- First 3 experiments:
  1. Run ablation with Oursα (no graph stratification) to confirm improvement from similarity-based imputation
  2. Run ablation with Oursβ (no contrastive loss) to confirm improvement from contrastive representation shaping
  3. Vary threshold φ and τ systematically on validation set to find stable operating points

## Open Questions the Paper Calls Out

### Open Question 1
- How does the graph analysis-based patient stratification perform with smaller datasets where patient similarity might be less distinct?
- Basis: Paper demonstrates effectiveness on large-scale datasets without examining scalability
- What evidence would resolve: Experiments on datasets with varying patient counts, particularly under 1000 patients

### Open Question 2
- What is the computational overhead of the contrastive learning component compared to non-contrastive variants?
- Basis: Paper mentions hyper-parameter for penalty strength but doesn't discuss computational costs
- What evidence would resolve: Detailed timing comparisons including training and inference benchmarks

### Open Question 3
- How sensitive is the approach to the choice of threshold φ in patient similarity calculation?
- Basis: Paper states "learnable threshold φ" but doesn't provide sensitivity analysis
- What evidence would resolve: Experiments varying φ across a range of values and showing impact on both tasks

## Limitations
- Relies heavily on accurate patient stratification through graph similarity, which may not generalize to rare diseases
- Effectiveness of learnable threshold φ for filtering similarity edges not fully validated across diverse clinical subgroups
- Model's performance gains are relatively modest (~0.007 AUROC improvement), raising questions about practical clinical utility

## Confidence
- High confidence in graph-based imputation mechanism's potential to improve missing data handling
- Medium confidence in contrastive learning integration's contribution, as improvements are incremental
- Low confidence in generalizability of threshold φ tuning across different EHR datasets without extensive validation

## Next Checks
1. Perform ablation studies with Oursα and Oursβ to isolate contributions of graph stratification and contrastive learning
2. Systematically vary similarity threshold φ and temperature τ parameters to assess robustness
3. Test the method on a third, independent EHR dataset to evaluate generalization beyond MIMIC-III and eICU