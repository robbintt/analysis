---
ver: rpa2
title: 'Stochastic Online Instrumental Variable Regression: Regrets for Endogeneity
  and Bandit Feedback'
arxiv_id: '2302.09357'
source_url: https://arxiv.org/abs/2302.09357
tags:
- regret
- regression
- online
- o2sls
- bound
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of online instrumental variable
  (IV) regression in the presence of endogeneity, where noise and covariates are correlated.
  The authors propose Online Two-Stage Least Squares (O2SLS) to estimate the true
  model parameters in a sequential data setting.
---

# Stochastic Online Instrumental Variable Regression: Regrets for Endogeneity and Bandit Feedback

## Quick Facts
- arXiv ID: 2302.09357
- Source URL: https://arxiv.org/abs/2302.09357
- Reference count: 40
- One-line primary result: Proposes O2SLS for online IV regression achieving O(d² log²T) identification regret and O(γ√dT logT) oracle regret, and OFUL-IV for linear bandits achieving O(d√T logT) regret.

## Executive Summary
This paper addresses the challenge of online instrumental variable (IV) regression in the presence of endogeneity, where noise and covariates are correlated. The authors propose Online Two-Stage Least Squares (O2SLS) to estimate true model parameters in a sequential data setting. O2SLS leverages the two-stage IV regression approach, using the first stage to predict endogenous variables and the second stage to estimate the structural parameters. Theoretical analysis shows that O2SLS achieves O(d² log²T) identification regret and O(γ√dT logT) oracle regret after T interactions, where d is the dimension of covariates, and γ is the bias due to endogeneity. The paper also extends O2SLS to design OFUL-IV, a linear bandit algorithm for handling endogeneity, which achieves O(d√T logT) regret. Experiments demonstrate that OFUL-IV outperforms traditional algorithms like OFUL in terms of estimation error and regret in datasets with endogeneity.

## Method Summary
The paper proposes O2SLS, an online extension of two-stage least squares (2SLS) regression, to handle endogeneity in sequential data settings. O2SLS uses instrumental variables (IVs) to predict endogenous variables in the first stage and estimates structural parameters in the second stage. The authors also extend O2SLS to design OFUL-IV, a linear bandit algorithm that leverages O2SLS to estimate parameters and build confidence bounds, achieving O(d√T logT) regret. The theoretical analysis establishes O(d² log²T) identification regret and O(γ√dT logT) oracle regret for O2SLS, where γ measures the bias due to endogeneity.

## Key Results
- O2SLS achieves O(d² log²T) identification regret and O(γ√dT logT) oracle regret after T interactions.
- OFUL-IV, an extension of O2SLS for linear bandits, achieves O(d√T logT) regret.
- Experiments show OFUL-IV outperforms traditional algorithms like OFUL in terms of estimation error and regret in datasets with endogeneity.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: O2SLS leverages two-stage least squares in an online fashion to handle endogeneity by first regressing the endogenous variables on the IVs and then using those predictions to estimate the structural parameters.
- **Mechanism**: At each time step, O2SLS updates the first-stage regression to predict the endogenous variable using the current IVs, then uses that prediction in the second-stage regression to update the estimate of the true parameter β. This cascades two regression steps, ensuring that the noise and covariates remain independent in the second stage.
- **Core assumption**: The IVs satisfy relevance (correlated with endogenous variables) and exogeneity (independent of the second-stage noise) conditions.
- **Evidence anchors**:
  - [abstract] "O2SLS leverages the two-stage IV regression approach, using the first stage to predict endogenous variables and the second stage to estimate the structural parameters."
  - [section] "This formulation leads us to the 2SLS estimator: ˆβ2SLS = (Z⊤nXn)−1Z⊤nyn."
- **Break condition**: If the relevance condition fails (IVs not correlated with endogenous variables), the first-stage regression will be uninformative and O2SLS will not recover the true parameter.

### Mechanism 2
- **Claim**: O2SLS achieves identification regret O(d² log²T) and oracle regret O(γ√dT logT + d² log²T), where γ measures the bias due to endogeneity.
- **Mechanism**: The identification regret arises from the error in estimating βt in each stage, while the oracle regret also includes the impact of the correlated noise between stages. The d² log²T term comes from performing d linear regressions in the first stage and using those predictions in the second stage, while the γ√dT logT term is the cost of handling endogeneity.
- **Core assumption**: The first-stage noise is component-wise sub-Gaussian and the second-stage noise is sub-Gaussian.
- **Evidence anchors**:
  - [abstract] "O2SLS achieves O(d² log²T) identification and O(γ√dT logT) oracle regret after T interactions."
  - [section] "Theorem 4.1 (Identiﬁcation Regret of O2SLS). If Assumption 3.1 holds true, then for bounded IVs ∥z∥2 ≤ L²z, if ηt is the ση-sub-Gaussian second stage noise and ϵt is the component-wise σϵ-sub-Gaussian first stage noise, the regret of O2SLS at step T >1 satisfies..."
- **Break condition**: If the noise in either stage is not sub-Gaussian, the concentration bounds used in the analysis may not hold, leading to looser regret bounds or failure of the algorithm.

### Mechanism 3
- **Claim**: OFUL-IV extends OFUL to handle endogeneity by using O2SLS to estimate parameters and build confidence bounds, achieving O(d√T logT) regret.
- **Mechanism**: OFUL-IV maintains a confidence set around the O2SLS estimate of β and selects actions optimistically within this set. This balances exploration and exploitation while accounting for endogeneity.
- **Core assumption**: The same IV assumptions as O2SLS (relevance and exogeneity) hold in the bandit setting.
- **Evidence anchors**:
  - [abstract] "Then, we leverage O2SLS as an oracle to design OFUL-IV, a linear bandit algorithm for handling endogeneity, which achieves O(d√T logT) regret."
  - [section] "OFUL-IV uses O2SLS to estimate the parameters, and corresponding confidence bounds on β to balance exploration–exploitation."
- **Break condition**: If the IVs are invalid (e.g., weak or not exogenous), the O2SLS estimates will be biased, leading to poor performance of OFUL-IV.

## Foundational Learning

- **Concept**: Two-Stage Least Squares (2SLS) regression
  - Why needed here: O2SLS is the online extension of 2SLS, and understanding 2SLS is crucial for grasping how O2SLS handles endogeneity.
  - Quick check question: What are the two stages in 2SLS, and how do they address endogeneity?

- **Concept**: Instrumental Variables (IVs)
  - Why needed here: IVs are the key to addressing endogeneity in both O2SLS and OFUL-IV. Understanding their properties (relevance and exogeneity) is essential.
  - Quick check question: What are the relevance and exogeneity conditions for IVs, and why are they important?

- **Concept**: Online learning and regret analysis
  - Why needed here: The paper analyzes O2SLS and OFUL-IV in terms of identification and oracle regrets, which are key concepts in online learning.
  - Quick check question: What is the difference between identification regret and oracle regret, and why are both important in this context?

## Architecture Onboarding

- **Component map**: O2SLS: First-stage regression (predict endogenous variables using IVs) → Second-stage regression (estimate structural parameters); OFUL-IV: O2SLS parameter estimation → Confidence bound construction → Optimistic action selection
- **Critical path**: For O2SLS: First-stage update → Second-stage update → Regret calculation. For OFUL-IV: O2SLS update → Confidence bound update → Action selection → Regret calculation.
- **Design tradeoffs**: O2SLS trades off computational complexity (two regression steps) for handling endogeneity, while OFUL-IV trades off the need for valid IVs for improved performance in the presence of endogeneity.
- **Failure signatures**: Poor performance of O2SLS or OFUL-IV may indicate invalid IVs (weak or not exogenous), non-sub-Gaussian noise, or violations of the relevance condition.
- **First 3 experiments**:
  1. Validate O2SLS on a synthetic dataset with known endogeneity and IVs, comparing its performance to standard online regression methods.
  2. Test OFUL-IV on a linear bandit problem with endogeneity, comparing its regret to OFUL and other bandit algorithms.
  3. Investigate the impact of IV strength (relevance) on the performance of O2SLS and OFUL-IV, varying the correlation between IVs and endogenous variables.

## Open Questions the Paper Calls Out
- How does the performance of O2SLS and OFUL-IV change under different levels of endogeneity, i.e., varying correlation between noise and covariates?
- Can O2SLS and OFUL-IV be extended to handle over-identified or weakly identified instrumental variables?
- How can instrumental variables be optimally identified online while simultaneously performing O2SLS?

## Limitations
- The validity of the instrumental variables assumptions (relevance and exogeneity) is crucial for the success of O2SLS and OFUL-IV, and may be difficult to verify in practice.
- The analysis assumes sub-Gaussian noise in both stages, which may not hold in practice and could lead to looser regret bounds or failure of the algorithms.
- The paper focuses on linear models and does not address non-linear relationships between variables, limiting the applicability of the proposed methods in real-world scenarios with complex data structures.

## Confidence
- **High**: The theoretical analysis of O2SLS and OFUL-IV, as well as the experimental results demonstrating their performance compared to baseline algorithms.
- **Medium**: The claims about the algorithms' ability to handle endogeneity, as they rely on the validity of instrumental variables assumptions, which may be difficult to verify in practice.
- **Medium**: The regret bounds, as they assume sub-Gaussian noise and may not hold for other noise distributions.

## Next Checks
1. Investigate the impact of invalid or weak instrumental variables on the performance of O2SLS and OFUL-IV by varying the strength of the IVs and assessing how the algorithms' performance degrades as the IV assumptions become less satisfied.
2. Experiment with non-sub-Gaussian noise distributions (e.g., heavy-tailed or skewed noise) to evaluate the robustness of O2SLS and OFUL-IV and the tightness of their regret bounds under different noise conditions.
3. Extend the analysis to non-linear models (e.g., using kernel methods or neural networks) to assess the potential of the proposed methods in handling more complex data structures and non-linear relationships between variables.