---
ver: rpa2
title: 'Sum-of-Parts: Self-Attributing Neural Networks with End-to-End Learning of
  Feature Groups'
arxiv_id: '2310.16316'
source_url: https://arxiv.org/abs/2310.16316
tags:
- attributions
- features
- feature
- error
- attribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper identifies a fundamental limitation in feature attribution
  methods: they can incur exponentially large error when features are correlated.
  To overcome this, the authors propose Sum-of-Parts (SOP), a model that uses grouped
  feature attributions.'
---

# Sum-of-Parts: Self-Attributing Neural Networks with End-to-End Learning of Feature Groups

## Quick Facts
- arXiv ID: 2310.16316
- Source URL: https://arxiv.org/abs/2310.16316
- Reference count: 30
- Primary result: Sum-of-Parts achieves zero insertion/deletion error on correlated feature problems by using grouped attributions instead of individual feature attributions.

## Executive Summary
This paper addresses a fundamental limitation in feature attribution methods: they incur exponentially large error when features are correlated. The authors propose Sum-of-Parts (SOP), a model that uses grouped feature attributions to overcome this problem. SOP consists of two modules: GroupGen, which generates groups of features using sparse attention, and GroupSelect, which assigns scores to groups using a second sparse attention mechanism. This approach is faithful by construction because the prediction only depends on the selected groups. On ImageNet and PASCAL VOC, SOP outperforms other attribution methods on insertion/deletion tests, especially when evaluated in a grouped manner. The authors also apply SOP to cosmology, discovering that voids and clusters in weak lensing maps have different impacts on cosmological parameters Ωm and σ8, which was previously unknown.

## Method Summary
Sum-of-Parts is a self-attributing neural network that learns to generate and score groups of features for attribution. The architecture consists of two main components: GroupGen, which uses sparse attention to create groups of features, and GroupSelect, which uses another sparse attention layer to assign scores to these groups. The final prediction is computed as a weighted sum of group scores, ensuring faithfulness by construction. The model is trained end-to-end using a standard cross-entropy loss, with sparsemax operators ensuring interpretability through sparsity in both attention layers. The approach is evaluated on ImageNet, PASCAL VOC, and weak lensing maps from the CosmoGridV1 dataset.

## Key Results
- SOP achieves zero insertion/deletion error on synthetic monomial/binomial datasets where traditional feature attributions fail exponentially.
- On ImageNet (10-class subset) and PASCAL VOC, SOP outperforms LIME, SHAP, RISE, Grad-CAM, IntGrad, and FRESH baselines on both standard and grouped insertion/deletion AUC metrics.
- In cosmology applications, SOP automatically discovers that voids and clusters in weak lensing maps have different impacts on cosmological parameters Ωm and σ8.

## Why This Works (Mechanism)

### Mechanism 1
Feature attributions fail exponentially in deletion/insertion tests when features are correlated. In settings with correlated features (e.g., monomials or binomials), any feature attribution must distribute credit across multiple correlated features, causing exponential error accumulation in subset tests. The model prediction depends on exact subsets of features being present/absent simultaneously. Evidence includes Theorem 2.3 stating exponential growth of deletion error and the key property of highly correlated features posing an insurmountable challenge. This breaks if feature interactions are sparse or if the model uses only additive combinations of features.

### Mechanism 2
Grouped attributions can achieve zero insertion/deletion error on correlated feature problems. By assigning scores to groups of features instead of individuals, grouped attributions can model interactions without splitting credit across correlated features. The prediction depends on groups of features being present together, not individual features. Evidence shows grouped attributions can succinctly describe earlier settings from Theorems 2.3 and 2.5 with zero insertion and deletion error. This breaks if groups overlap too much or if feature interactions are non-monotonic.

### Mechanism 3
SOP's two-module architecture (GroupGen + GroupSelect) enables faithful-by-construction attributions. GroupGen creates sparse groups via self-attention with sparsemax, GroupSelect assigns scores via another sparse attention layer; the final prediction is a weighted sum of group scores, guaranteeing faithfulness. The core assumption is that sparse attention can generate semantically meaningful groups and the weighted sum aggregation preserves prediction fidelity. Evidence includes the statement that grouped attribution is faithful-by-construction and the use of sparsemax for interpretability. This breaks if sparsemax fails to produce meaningful sparsity or if the backbone model's embeddings are not discriminative enough.

## Foundational Learning

- **Self-attention and sparsemax operators**: GroupGen and GroupSelect both rely on self-attention to produce sparse, interpretable groups. Quick check: What does sparsemax do that softmax does not, and why is that important for interpretability?
- **Grouped versus individual feature attributions**: Understanding why grouped attributions overcome the exponential error barrier. Quick check: In a monomial setting, why does a grouped attribution with one group achieve zero deletion error while any feature attribution does not?
- **Insertion and deletion tests for faithfulness**: SOP is evaluated using both standard and grouped insertion/deletion metrics. Quick check: How does a grouped insertion test differ from a standard pixel-wise insertion test?

## Architecture Onboarding

- **Component map**: Input → GroupGen (sparse attention → groups) → Backbone (embeddings) → GroupSelect (sparse attention → scores/logits) → Weighted sum → Output
- **Critical path**: Forward pass: GroupGen → Backbone → GroupSelect → weighted sum; Loss/backprop: standard cross-entropy on weighted sum output; sparsemax gradients flow through both attention layers
- **Design tradeoffs**: More groups → better expressiveness but risk of overlap and redundancy; Sparsemax vs softmax → sparsity and interpretability vs smoothness of gradients; Fixed group count vs adaptive grouping → control vs flexibility
- **Failure signatures**: All groups have similar scores → GroupGen not producing discriminative groups; Very few active groups → GroupSelect too aggressive, missing important features; Large performance drop vs baseline → groups not preserving enough information
- **First 3 experiments**: 1) Train SOP on synthetic monomial dataset and verify zero deletion error; 2) Compare grouped vs standard insertion/deletion AUC on ImageNet with fixed group size; 3) Visualize learned groups on weak lensing maps and check if voids/clusters emerge automatically.

## Open Questions the Paper Calls Out

### Open Question 1
Does the exponential error bound for feature attributions hold for dimensions d > 20, or is there a different asymptotic behavior? The paper states the proof technique has been computationally verified only up to d ≤ 20 and conjectures a general result for d > 20. This remains unresolved because the computational complexity of verifying the lower bound increases exponentially with dimension. A theoretical proof extending the lower bound to arbitrary dimensions, or an empirical study using approximate methods to estimate the bound for larger d, would resolve this.

### Open Question 2
How do grouped attributions perform compared to feature attributions when the number of groups is limited or when groups overlap significantly? The paper demonstrates that grouped attributions can overcome the exponential error bound, but does not explore the impact of group constraints or overlap. This remains unresolved because the paper focuses on theoretical advantages without considering practical limitations. Experiments comparing grouped attributions with varying numbers of groups and levels of overlap would resolve this.

### Open Question 3
Can the Sum-of-Parts model be extended to other types of data beyond images and weak lensing maps, such as text or graphs? The paper applies the model to ImageNet, PASCAL VOC, and weak lensing maps, but does not explore other data modalities. This remains unresolved because the paper demonstrates effectiveness on specific datasets without investigating generalizability. Experiments applying the model to text classification or graph neural networks would resolve this.

## Limitations
- The theoretical claims about exponential error are based on stylized monomial/binomial examples that may not generalize to real-world data distributions.
- Experimental validation uses relatively small subsets (10 classes for ImageNet), limiting generalizability of the vision benchmark results.
- The cosmology application, while novel, serves more as a proof-of-concept demonstration than a rigorous validation of SOP's attribution quality.

## Confidence
- Theoretical claims about exponential error: **Medium** (mathematically rigorous but based on stylized examples)
- Experimental results on vision benchmarks: **Medium-High** (good performance but limited dataset scope)
- Cosmology application findings: **Low-Medium** (novel but not rigorously validated)

## Next Checks
1. Test SOP on diverse correlation structures beyond monomials/binomials using synthetic datasets with varying degrees of feature correlation to map the boundary between tractable and intractable attribution problems.

2. Conduct ablation studies on the sparse attention mechanisms: compare sparsemax vs softmax, vary group counts, and measure the trade-off between sparsity and attribution quality across different dataset characteristics.

3. Evaluate SOP's attributions against ground-truth causal relationships in controlled synthetic datasets where the true feature importance is known, to verify that grouped attributions actually capture meaningful interactions rather than just fitting the insertion/deletion metrics.