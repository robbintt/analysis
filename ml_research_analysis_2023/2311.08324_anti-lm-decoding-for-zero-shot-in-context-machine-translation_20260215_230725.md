---
ver: rpa2
title: Anti-LM Decoding for Zero-shot In-context Machine Translation
arxiv_id: '2311.08324'
source_url: https://arxiv.org/abs/2311.08324
tags:
- construit
- wifi
- decoding
- interphone
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of zero-shot in-context machine
  translation with large language models, which are poorly calibrated and exhibit
  strong prior bias. The authors introduce an Anti-Language Model decoding objective
  with exponential decay, which penalizes the probability of generating tokens that
  continue the source language sentence.
---

# Anti-LM Decoding for Zero-shot In-context Machine Translation

## Quick Facts
- **arXiv ID**: 2311.08324
- **Source URL**: https://arxiv.org/abs/2311.08324
- **Reference count**: 14
- **Primary result**: Anti-LM decoding improves zero-shot in-context machine translation BLEU scores by up to 20 points over maximum likelihood decoding

## Executive Summary
This paper addresses the challenge of zero-shot in-context machine translation using large language models (LLMs) that are poorly calibrated and exhibit strong prior bias toward the source language. The authors introduce Anti-Language Model (Anti-LM) decoding, which penalizes the probability of generating tokens that continue the source language sentence. By modifying the decoding objective with an exponential decay factor, the approach significantly improves translation quality across three model types and sizes, three language directions, and two decoding methods. Experiments show up to 20 BLEU point improvement over the default maximum likelihood objective, primarily by addressing the "failure to translate" case where models generate source language instead of target language.

## Method Summary
The method introduces an Anti-LM decoding objective that modifies standard maximum likelihood decoding by subtracting the log probability of source language continuation, conditioned on the source sentence. This contrastive objective uses an exponential decay factor γt to reduce the influence of the Anti-LM penalty over time, allowing natural translation progression while preventing early source language dominance. The approach requires computing source sentence logits only once per input, making it computationally efficient. The method is evaluated with greedy decoding and beam search across three multilingual LLM architectures (XGLM, Bloom, Llama 2) with varying sizes on the FLORES-101 dataset for three language directions (en↔fr, en↔de, en↔pt).

## Key Results
- Anti-LM decoding achieves up to 20 BLEU point improvement over maximum likelihood decoding for zero-shot in-context translation
- The approach shows consistent gains across three model types (XGLM, Bloom, Llama 2), three sizes (2.9B, 7.5B, 7B), and three language directions
- Performance improvements are particularly strong for addressing "failure to translate" cases where models generate source language instead of target language
- The method outperforms other state-of-the-art decoding objectives like PMI while maintaining lower computational overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Anti-LM decoding reduces source language dominance in zero-shot translation by penalizing token continuations of the source sentence
- Mechanism: The Anti-LM objective subtracts log p(y1|x) from the standard decoding objective, where y1 represents the first generated token conditioned on the source sentence x. This penalizes tokens that would continue the source language sequence, effectively discouraging the model from generating the source language instead of translating it.
- Core assumption: The primary failure mode in zero-shot translation is the model generating the source language instead of translating to the target language, and this behavior is driven by the strong prior bias of the source language.
- Evidence anchors: [abstract]: "Experiments across three model types and sizes, three language directions, and two decoding methods (greedy and beam search) show that this approach outperforms other state-of-the-art decoding objectives, with up to 20 BLEU point improvement over the default maximum likelihood objective"; [section]: "We hypothesise that poor translations may be due to a strong prior bias of the dominant source language, but that this bias should diminish over future decoding steps"

### Mechanism 2
- Claim: Exponential decay factor γt reduces the influence of Anti-LM over future timesteps, allowing natural translation progression
- Mechanism: The discount factor γt is applied to the Anti-LM penalty term, which decreases over time. This allows the model to strongly penalize source language continuations early in the generation process while gradually reducing this constraint as the translation progresses, enabling more natural target language generation.
- Core assumption: The initial bias toward source language continuation is strongest at the beginning of generation and naturally diminishes as the model generates more target language tokens.
- Evidence anchors: [abstract]: "Anti-LM modifies the original logits by taking the difference of the next token logits, conditioned on the source sentence to be translated"; [section]: "We use a discount factor γt to reduce the influence of the Anti-LM (ALM) on future timesteps"

### Mechanism 3
- Claim: Contrastive decoding objectives work by creating a competition between target language generation and source language continuation
- Mechanism: The Anti-LM objective creates a contrastive signal by penalizing tokens that would continue the source sentence. This creates competition between generating target language tokens (which should have high probability) and source language continuations (which are penalized), effectively steering the model toward translation.
- Core assumption: LLMs can be effectively guided through contrastive objectives that create competition between different generation paths, and this competition can overcome the model's inherent biases.
- Evidence anchors: [abstract]: "One of the most effective approaches to handling this bias is to adopt a contrastive decoding objective, which accounts for the prior probability of generating the next token by conditioning on some context"; [section]: "Our work falls under the category of contrastive objectives, which were popularised by Li et al. (2015)"

## Foundational Learning

- **Autoregressive language model generation**: Understanding how LLMs generate text token-by-token is crucial for grasping how decoding objectives modify generation behavior. *Quick check*: How does an autoregressive model generate text, and what role does the decoding objective play in this process?

- **Contrastive learning and decoding objectives**: Anti-LM is a specific type of contrastive decoding objective, so understanding the broader category helps explain its mechanism. *Quick check*: What is the difference between standard maximum likelihood decoding and contrastive decoding objectives?

- **Language model calibration and bias**: The paper addresses how poorly calibrated LLMs exhibit strong prior bias, which is the fundamental problem Anti-LM aims to solve. *Quick check*: Why are pre-trained LLMs poorly calibrated for zero-shot translation tasks, and how does this manifest in their outputs?

## Architecture Onboarding

- **Component map**: Source sentence → Anti-LM penalty calculation → Modified logits → Token sampling → Target sentence generation
- **Critical path**: The Anti-LM objective modifies the decoding process by introducing a contrastive penalty that must be calculated once per source sentence before generation begins
- **Design tradeoffs**: Anti-LM trades computational overhead (one-time calculation of source sentence logits) for improved translation quality, versus the potential for over-constraining generation if parameters are poorly tuned
- **Failure signatures**: Generation of source language instead of target language, empty generations, missing named entities in translations
- **First 3 experiments**:
  1. Implement basic Anti-LM decoding with γ=0.3 and α=0.1 on a small dataset to verify it reduces source language generation
  2. Compare Anti-LM against PMI decoding on the same dataset to measure relative effectiveness
  3. Test different decay factors γ to find optimal balance between early source language suppression and later generation freedom

## Open Questions the Paper Calls Out
None explicitly identified in the paper text.

## Limitations
- Evaluation limited to three language pairs (English↔French, English↔German, English↔Portuguese) from FLORES-101 dataset
- Focus on zero-shot in-context translation without fine-tuning or adaptation, limiting scope to scenarios without task-specific training data
- Comparison with other decoding objectives provides breadth but may not capture all relevant baselines in the rapidly evolving field

## Confidence
**High Confidence**: The empirical findings that Anti-LM decoding significantly improves translation quality over maximum likelihood decoding (up to 20 BLEU points) are well-supported by systematic experiments across multiple model types, sizes, and language directions.

**Medium Confidence**: The theoretical mechanism explaining why Anti-LM works (penalizing source language continuation through contrastive objectives) is plausible and consistent with the empirical results, but the exact contribution of each component is not fully isolated.

**Low Confidence**: The generalizability of Anti-LM to other zero-shot tasks beyond translation, and its effectiveness when combined with fine-tuning or other adaptation methods, remains untested.

## Next Checks
1. **Ablation Study of Decay Factor**: Systematically vary the exponential decay parameter γ across a wider range (e.g., 0.1 to 0.9) to determine the sensitivity of Anti-LM performance to this hyperparameter and identify whether the current choice (γ=0.3) is near-optimal or could be substantially improved.

2. **Cross-Domain Evaluation**: Test Anti-LM decoding on out-of-domain translation tasks beyond FLORES-101 (e.g., news, medical, or legal text) to assess whether the performance gains generalize to different domains and whether domain-specific hyperparameters might be needed.

3. **Comparison with Fine-tuned Models**: Evaluate Anti-LM against zero-shot translation performance of models that have been fine-tuned on translation data to determine whether Anti-LM can close the gap between zero-shot and fine-tuned performance, or whether it primarily addresses a different subset of translation errors.