---
ver: rpa2
title: $\textit{Swap and Predict}$ -- Predicting the Semantic Changes in Words across
  Corpora by Context Swapping
arxiv_id: '2310.10397'
source_url: https://arxiv.org/abs/2310.10397
tags:
- swap
- word
- sscd
- semantic
- distance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Swapping-based Semantic Change Detection (SSCD),
  an unsupervised method for predicting whether a word's meaning changes between two
  text corpora. The method randomly swaps contexts containing the target word between
  corpora and measures changes in contextualised word embedding distributions using
  pretrained MLMs.
---

# $\textit{Swap and Predict}$ -- Predicting the Semantic Changes in Words across Corpora by Context Swapping

## Quick Facts
- arXiv ID: 2310.10397
- Source URL: https://arxiv.org/abs/2310.10397
- Authors: 
- Reference count: 39
- Primary result: Unsupervised semantic change detection method achieving Spearman correlation coefficients of 0.552 (English), 0.547 (German), 0.127 (Swedish), 0.460 (Latin), and 0.470 (Liverpool FC) across five datasets

## Executive Summary
This paper introduces Swapping-based Semantic Change Detection (SSCD), an unsupervised method that predicts semantic changes in words across text corpora by leveraging context swapping and pretrained MLMs. The method randomly swaps contexts containing target words between corpora and measures changes in contextualised word embedding distributions. SSCD achieves significant performance improvements over strong baselines while requiring no fine-tuning, making it computationally efficient. The approach demonstrates strong results across multiple languages and datasets, outperforming previous context-swapping methods.

## Method Summary
SSCD operates by extracting all sentences containing a target word from two corpora, generating contextualised embeddings using a pretrained MLM, and fitting Gaussian distributions to these embeddings. The method calculates baseline distances between distributions, then performs multiple rounds of random context swapping between corpora to measure distribution stability. Semantic change is quantified as the difference between baseline and swapped distances. An unsupervised hyperparameter selection method determines optimal swap rates by minimizing the expected swap distance (eswap).

## Key Results
- Achieves Spearman correlation coefficients of 0.552 (English), 0.547 (German), 0.127 (Swedish), 0.460 (Latin), and 0.470 (Liverpool FC) across five datasets
- Outperforms previous context-swapping approaches while requiring no fine-tuning
- Demonstrates computational efficiency through use of pretrained MLMs without additional training
- Shows consistent improvement over baselines in 4/5 datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Swapping contexts between corpora preserves semantic distributions when meaning is unchanged but disrupts them when meaning has changed
- Mechanism: Random context swapping tests distributional invariance - if meaning is stable, swapping should not significantly alter the distance between contextualised embedding distributions
- Core assumption: The distributional hypothesis holds - similar meanings produce similar embedding distributions
- Break condition: If swapping introduces systematic bias or if the corpora have fundamentally different domain distributions unrelated to semantic change

### Mechanism 2
- Claim: Multiple random swaps provide more reliable estimates than single-point estimates
- Mechanism: Repeated sampling and swapping creates a distribution of distance measurements, reducing variance from corpus noise and word frequency effects
- Core assumption: The law of large numbers applies - averaging over multiple random swaps converges to the true semantic change signal
- Break condition: If the underlying distributions are too different (e.g., completely different domains) that swapping creates artificial semantic drift

### Mechanism 3
- Claim: Using pretrained MLMs without fine-tuning captures sufficient semantic information for change detection
- Mechanism: Pretrained contextual embeddings already encode rich semantic information that can distinguish meaning changes without requiring task-specific training
- Core assumption: Pretrained MLMs have learned general semantic representations that transfer to temporal semantic change detection
- Break condition: If the pretrained MLM was trained on data too temporally distant from the target corpora, or if the semantic changes involve domain-specific terminology not well-represented in pretraining

## Foundational Learning

- Concept: Distributional hypothesis - words appearing in similar contexts have similar meanings
  - Why needed here: Forms the theoretical foundation for why contextualised embeddings can represent word meaning and why distribution distances indicate semantic change
  - Quick check question: If two words have identical contextual distributions, what does the distributional hypothesis predict about their meanings?

- Concept: Multivariate Gaussian distribution modeling of sibling embeddings
  - Why needed here: Captures both mean and variance of contextualised embeddings, providing richer semantic representation than point estimates
  - Quick check question: Why might using only the mean of sibling embeddings be insufficient for detecting semantic change?

- Concept: Divergence and distance metrics for distribution comparison
  - Why needed here: Different metrics (KL divergence, Jeffrey's divergence, various distances) capture different aspects of distribution differences
  - Quick check question: What's the key difference between symmetric (Jeffrey's) and asymmetric (KL) divergence measures?

## Architecture Onboarding

- Component map: Input corpora → Context extraction → MLM embedding generation → Gaussian distribution fitting → Distance calculation → Context swapping (multiple iterations) → Semantic change scores

- Critical path: 
  1. Extract all sentences containing target word from both corpora
  2. Generate contextualised embeddings using pretrained MLM
  3. Fit Gaussian distributions to sibling embeddings
  4. Calculate baseline distance between distributions
  5. Perform multiple rounds of context swapping and distance calculation
  6. Compute semantic change score as difference between baseline and swapped distances

- Design tradeoffs:
  - Swap rate vs. computational cost: Higher swap rates provide more samples but increase computation
  - Embedding layer choice: Using last four layers balances context richness and stability
  - Distribution modeling: Diagonal covariance matrices trade accuracy for numerical stability

- Failure signatures:
  - Low variance in swapped distances suggests insufficient sampling or very stable meanings
  - High variance suggests noisy embeddings or insufficient swap rate
  - Systematic bias in one direction suggests corpus imbalance or domain shift

- First 3 experiments:
  1. Baseline validation: Run with swap rate = 0 to verify it produces the same results as non-swapping methods
  2. Swap rate sensitivity: Test different swap rates (0.1, 0.4, 0.7, 1.0) on a small word subset to find optimal rate
  3. Corpus size effect: Compare performance on balanced vs. imbalanced corpus pairs to understand size sensitivity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SSCD perform on extremely short time spans (e.g., seasonal changes within months)?
- Basis in paper: The paper mentions seasonal semantic changes as a limitation and notes that current datasets don't include such rapid changes
- Why unresolved: The authors acknowledge this limitation but don't provide any experimental results on such time spans, likely because appropriate datasets don't exist yet
- What evidence would resolve it: Experiments on time-stamped corpora with seasonal patterns (e.g., product reviews, weather reports) showing SSCD's performance on detecting meaning changes within months rather than years

### Open Question 2
- Question: Can SSCD be effectively combined with supervised methods like XL-LEXEME to improve performance while maintaining computational efficiency?
- Basis in paper: The authors note that SSCD and supervised methods are independent and suggest it would be "an interesting future research direction to explore the possibility of using SSCD at inference time with pre-trained XL-LEXEME"
- Why unresolved: The authors identify this as a future direction but don't provide any experimental validation of this combination
- What evidence would resolve it: Experiments showing the performance of a hybrid system where XL-LEXEME is fine-tuned on sense-labeled data, then SSCD is applied during inference using multiple contexts per word to compute more reliable scores

### Open Question 3
- Question: How sensitive is SSCD to social biases encoded in MLMs, and can these biases affect semantic change detection?
- Basis in paper: The authors acknowledge in their Ethics Statement that "the sets of sibling embeddings used in our proposed method are obtained from MLMs that may contain such social biases" and note this needs further evaluation before real-world deployment
- Why unresolved: The authors explicitly state this hasn't been evaluated and raise concerns about potential bias impact on SCD results
- What evidence would resolve it: Experiments measuring how SSCD scores differ when applied to corpora containing biased language (e.g., gendered terms) versus neutral corpora, or when using debiased versus standard MLMs

## Limitations
- Performance on Swedish is notably lower (0.127) than other languages, suggesting potential language-specific limitations
- Reliance on distributional invariance assumptions may break down with domain shifts rather than semantic change
- Hyperparameter selection method lacks empirical validation across diverse corpus pairs
- Short-term semantic changes (seasonal patterns) are not well-represented in current evaluation datasets

## Confidence
- **High confidence**: Core methodology of context swapping and distribution distance measurement (Spearman correlations consistently above 0.4 for 4/5 datasets)
- **Medium confidence**: Claims about computational efficiency and no fine-tuning requirement (methodologically clear but not extensively benchmarked)
- **Medium confidence**: Language-agnostic applicability (supported by multilingual BERT use but Swedish results raise questions)
- **Low confidence**: Unsupervised hyperparameter selection effectiveness (proposed but not thoroughly validated)

## Next Checks
1. **Language-specific validation**: Test SSCD on additional languages beyond the five studied, particularly focusing on languages structurally different from those in the training set to assess true language-agnostic capabilities

2. **Domain shift disentanglement**: Design experiments to separate semantic change from domain shift effects by comparing performance on temporally-aligned corpora from different domains versus temporally-shifted corpora from the same domain

3. **Hyperparameter sensitivity analysis**: Conduct systematic experiments varying the number of repetitions (beyond the fixed 20) and swap rates to empirically determine optimal values and establish convergence criteria