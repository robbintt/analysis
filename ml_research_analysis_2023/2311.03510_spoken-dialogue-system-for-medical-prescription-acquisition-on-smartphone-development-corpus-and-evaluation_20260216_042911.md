---
ver: rpa2
title: 'Spoken Dialogue System for Medical Prescription Acquisition on Smartphone:
  Development, Corpus and Evaluation'
arxiv_id: '2311.03510'
source_url: https://arxiv.org/abs/2311.03510
tags:
- dialogue
- system
- drug
- prescription
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the first spoken medical prescription dialogue
  system designed to reduce prescription errors and physician time spent on data entry.
  The system employs a natural language interface accessible via smartphone, allowing
  physicians to record prescriptions verbally at the point of care.
---

# Spoken Dialogue System for Medical Prescription Acquisition on Smartphone: Development, Corpus and Evaluation

## Quick Facts
- arXiv ID: 2311.03510
- Source URL: https://arxiv.org/abs/2311.03510
- Reference count: 40
- Key outcome: First spoken medical prescription dialogue system reduces physician time on data entry with 76% task success rate for physicians

## Executive Summary
This paper introduces the first spoken medical prescription dialogue system designed to reduce prescription errors and physician time spent on data entry. The system employs a natural language interface accessible via smartphone, allowing physicians to record prescriptions verbally at the point of care. The core method includes defining a comprehensive semantic taxonomy for prescriptions, training NLU models using synthetic data generation to address data scarcity, and developing a modular dialogue system with drug disambiguation and error-checking features. The system was evaluated with 55 participants, achieving a task success rate of 76% for physicians and 72% for other experts, with average prescription times of 66.15 and 35.64 seconds, respectively. All evaluation data were recorded and annotated to form PxCorpus, the first spoken drug prescription dataset made publicly available for the research community.

## Method Summary
The system development followed an iterative process beginning with defining a semantic taxonomy of 39 slot-labels covering drug names, dosage, form, route, and other prescription elements based on French e-prescribing regulations. Synthetic training data was generated using a context-free grammar applied to textbook prescriptions and casual speech examples. NLU models (including CRF, Tri-CRF, Att-RNN, and Flaubert) were trained for slot-filling and intent detection. A modular dialogue system was implemented with ASR, NLU, drug disambiguation using UCD codes, dialogue state tracking, and a transformer-based dialogue policy. The system was evaluated in real-world conditions with 55 participants using a mobile prototype, with all data collected and annotated to create the PxCorpus dataset.

## Key Results
- Task success rate: 76% for physicians, 72% for other experts
- Average prescription time: 66.15 seconds for physicians, 35.64 seconds for other experts
- NLU accuracy: 94% intent detection, 90% slot F1 score
- PxCorpus: First publicly available spoken drug prescription dataset with 1,416 casual speech examples and evaluation data from 55 participants

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The system reduces physician time spent on data entry by allowing voice-based prescription input at the point of care.
- Mechanism: A spoken dialogue system replaces manual keyboard entry with natural language interaction, enabling real-time data capture during patient visits.
- Core assumption: Physicians can verbalize prescriptions more quickly than typing them on complex HIS interfaces.
- Evidence anchors:
  - [abstract] The system allows prescribers to record prescriptions verbally, a form of interaction closer to their usual practice.
  - [section] The system enables clinicians to prescribe at the point of care which would save time and would enable better mobility.
- Break condition: If voice input accuracy is too low or physicians prefer keyboard entry, adoption rates will be poor.

### Mechanism 2
- Claim: Semantic extraction and drug disambiguation improve prescription safety by ensuring correct drug identification and compliance with e-prescribing regulations.
- Mechanism: The system extracts structured semantic information from spoken utterances and matches it to a national drug database, using contextual clues for disambiguation when multiple candidates exist.
- Core assumption: The extracted semantic slots (drug name, dosage, form, route, etc.) are sufficient to uniquely identify the intended medication in most cases.
- Evidence anchors:
  - [section] Our API allows slots to be associated with a unique UCD (Unité Commune de Dispensation) code.
  - [section] If multiple answers are returned then the user is prompted to select an item from the list of possible drugs.
- Break condition: If the semantic taxonomy is incomplete or the drug database lacks sufficient detail, disambiguation will fail frequently.

### Mechanism 3
- Claim: Dialogue-based error checking and mandatory information gathering reduce prescription errors and adverse drug events.
- Mechanism: The system uses a modular dialogue policy to request missing information, confirm details with the prescriber, and check for contraindications before final validation.
- Core assumption: The dialogue policy can handle the majority of prescription scenarios and effectively guide prescribers through the information collection process.
- Evidence anchors:
  - [section] The system uses the dialogue to request mandatory information, correct errors or warn of particular situations.
  - [section] Before the validation, the identified slots are not visualized. The dialogue system tries to associate the semantics with a drug or proposes a list of drugs when there are several candidates.
- Break condition: If the dialogue policy is too rigid or fails to handle edge cases, prescribers may bypass it or make errors.

## Foundational Learning

- Concept: Slot-filling approach in spoken language understanding
  - Why needed here: To extract structured semantic information (drug name, dosage, frequency, etc.) from natural language utterances for prescription processing.
  - Quick check question: What are the key semantic slots needed to represent a medical prescription, and how do they map to the e-prescribing software requirements?

- Concept: Data augmentation for low-resource NLP
  - Why needed here: To train NLU models without large annotated datasets of spoken prescriptions, using synthetic data generation based on a context-free grammar.
  - Quick check question: How does the context-free grammar generate realistic prescription examples, and what are the trade-offs compared to collecting real data?

- Concept: Dialogue state tracking and policy in goal-oriented systems
  - Why needed here: To manage the conversation flow, track what information has been collected, and determine the next system action to gather missing details or confirm the prescription.
  - Quick check question: How does the transformer-based dialogue policy decide which action to take based on the current utterance, dialogue history, and state?

## Architecture Onboarding

- Component map: ASR → Text transcription of spoken prescriptions → NLU → Intent detection and slot-filling for semantic extraction → Drug Disambiguation → Matching extracted semantics to national drug database (UCD codes) → Dialogue State Tracker → Tracking collected information and determining next steps → Dialogue Policy → Choosing system actions (request info, confirm, warn, etc.) → Natural Language Generation (NLG) → Converting system actions to spoken responses → Text-to-Speech (TTS) → Delivering system responses to prescriber → External Services → Drug database lookup, e-prescription software validation

- Critical path: ASR → NLU → Drug Disambiguation → Dialogue Policy → NLG → TTS → E-prescription validation

- Design tradeoffs:
  - Modularity vs. performance: Separate modules allow easier maintenance but may introduce error propagation; end-to-end approaches could be more robust but harder to debug.
  - Synthetic data vs. real data: Synthetic data generation enables rapid prototyping but may not capture all real-world variations in prescription language.
  - Mobile vs. desktop: Mobile deployment enables point-of-care use but may have constraints on processing power and screen size.

- Failure signatures:
  - ASR errors leading to incorrect text input → NLU fails to extract correct slots
  - Incomplete semantic taxonomy → Drug disambiguation fails to find a unique match
  - Dialogue policy confusion → System asks for redundant information or misses mandatory fields
  - Integration issues with e-prescription software → Validation fails or contraindications not caught

- First 3 experiments:
  1. Test ASR accuracy on a sample of spoken prescriptions to identify common recognition errors.
  2. Evaluate NLU slot-filling performance on synthetic and real data to measure coverage and precision.
  3. Validate drug disambiguation accuracy by comparing system matches to ground truth drug identifiers.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the spoken medical prescription system perform in real clinical settings with actual patient data, including contraindications and drug interactions?
- Basis in paper: [explicit] The paper mentions this as a future direction: "A direct perspective of this work would be to evaluate the system in a full ecological context. This would confirm the evaluations of the system (which were realistically performed, but did not involve real prescription cases in a real ecological situation) while adding the patient dimension."
- Why unresolved: The current evaluation did not involve actual patient data or integration with electronic health records (EHRs) that contain patient-specific information like allergies or current medications.
- What evidence would resolve it: An evaluation study in a real hospital setting where the system is integrated with EHRs and used by physicians to prescribe medications for actual patients, measuring task success rates, time efficiency, and error reduction compared to traditional methods.

### Open Question 2
- Question: Can generative adversarial networks (GANs) outperform the current data augmentation method for improving NLU models in low-resource medical prescription dialogue systems?
- Basis in paper: [explicit] The paper suggests this as a future research direction: "Now that we have realistic data, it would be interesting to test generative adversarial networks (GANs) for NLU or dialogue data generation."
- Why unresolved: The current data augmentation method uses a context-free grammar-based generator, and the paper suggests GANs as a potential improvement but does not test this approach.
- What evidence would resolve it: A comparative study where GANs are used to generate synthetic medical prescription data and the resulting NLU models are evaluated against models trained with the current augmentation method, measuring improvements in slot-filling accuracy and intent detection.

### Open Question 3
- Question: Would a joint learning approach that optimizes all modules of the dialogue system simultaneously lead to better performance while maintaining modularity?
- Basis in paper: [explicit] The paper identifies this as an open research question: "It would therefore be interesting to explore these approaches to both increase performance and keep the modularity that is very important for software maintenance."
- Why unresolved: The current system uses a modular pipeline approach where each module (ASR, NLU, DST, etc.) is trained separately, and the paper suggests exploring joint learning approaches but does not implement them.
- What evidence would resolve it: Implementation and evaluation of a joint learning framework where multiple dialogue system modules are optimized together, compared against the current modular approach in terms of overall system performance (task success rate, dialogue efficiency) while maintaining the ability to independently update or replace individual modules.

## Limitations

- Evaluation conducted primarily with French speakers, limiting generalizability to other languages and healthcare systems
- Use of synthetic data generation may not capture full variability of real-world prescription language
- System performance on complex prescriptions involving multiple drugs or rare medications was not explicitly evaluated

## Confidence

- High confidence in the system architecture and modular design approach
- Medium confidence in the synthetic data generation methodology
- Medium confidence in the evaluation results due to limited sample size and single-language focus
- Low confidence in the system's generalizability to non-French healthcare contexts

## Next Checks

1. Conduct cross-language evaluation by adapting the semantic taxonomy and drug database to at least one additional language (e.g., English) and measuring performance drop
2. Perform ablation study on synthetic vs. real data by collecting a small set of real spoken prescriptions and comparing NLU performance
3. Test system robustness on complex prescription scenarios involving multiple medications, rare drugs, and ambiguous formulations to identify edge cases not handled by the current dialogue policy