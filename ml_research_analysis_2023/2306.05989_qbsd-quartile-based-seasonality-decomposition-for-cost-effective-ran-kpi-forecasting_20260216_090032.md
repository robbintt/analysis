---
ver: rpa2
title: 'QBSD: Quartile-Based Seasonality Decomposition for Cost-Effective RAN KPI
  Forecasting'
arxiv_id: '2306.05989'
source_url: https://arxiv.org/abs/2306.05989
tags:
- forecasting
- data
- time
- qbsd
- series
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes QBSD (Quartile-Based Seasonality Decomposition),
  a forecasting method designed for cost-effective and efficient prediction of time
  series data, specifically targeting telecom KPIs. QBSD addresses the limitations
  of existing forecasting methods that prioritize accuracy at the expense of computational
  performance, particularly in data-intensive systems with numerous time series variables.
---

# QBSD: Quartile-Based Seasonality Decomposition for Cost-Effective RAN KPI Forecasting

## Quick Facts
- arXiv ID: 2306.05989
- Source URL: https://arxiv.org/abs/2306.05989
- Reference count: 40
- Primary result: QBSD achieves competitive forecast accuracy while significantly outperforming state-of-the-art methods in runtime efficiency for telecom KPI forecasting

## Executive Summary
This paper introduces QBSD (Quartile-Based Seasonality Decomposition), a novel forecasting method designed to balance forecast accuracy with computational efficiency for telecom Key Performance Indicators (KPIs). QBSD addresses the limitations of existing methods that prioritize accuracy at the expense of computational performance, particularly in data-intensive systems with numerous time series variables. The method leverages quartile-based seasonality decomposition to capture dynamic operating ranges that vary with time, providing both forecasts and time-sensitive upper and lower operating ranges crucial for anomaly detection.

## Method Summary
QBSD employs a live single-step forecasting approach that continuously updates model parameters as new data becomes available, eliminating the need for separate fit and predict stages. The method compiles a contextual subset for each timestamp by gathering values at identical timestamps within a moving window, then calculates quartiles Q1 and Q3 to derive the interquartile range (IQR). The forecast is generated as the mean of values between Q1 and Q3, while the IQR represents the expected deviation at that specific time. This approach is specifically designed for rolling forecasts on live data without requiring scheduled retraining.

## Key Results
- QBSD achieves competitive forecast accuracy (MAE, MSE, RMSE, MAPE, R2) compared to state-of-the-art methods
- QBSD significantly outperforms baseline methods in runtime efficiency across various datasets
- QBSD provides time-sensitive upper and lower operating ranges that enhance anomaly detection capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: QBSD achieves competitive forecast accuracy while significantly outperforming state-of-the-art methods in runtime efficiency.
- Mechanism: By using a live single-step forecasting approach with quartile-based seasonality decomposition, QBSD eliminates the need for separate fit and predict stages, reducing computational overhead.
- Core assumption: The contextual subset compilation and quartile calculation can be performed efficiently for each timestamp, and the mean of values between Q1 and Q3 provides an adequate forecast.
- Evidence anchors: [abstract] states "QBSD achieves competitive forecast accuracy while significantly outperforming state-of-the-art methods in terms of runtime efficiency." [section 3.1] describes the algorithm and its efficiency.

### Mechanism 2
- Claim: QBSD captures time-sensitive upper and lower operating ranges along with the forecast, crucial for anomaly detection in time series data.
- Mechanism: By computing quartiles (Q1 and Q3) for each timestamp based on a contextual subset, QBSD derives the interquartile range (IQR) which represents the expected deviation at that specific time.
- Core assumption: The distribution of values within the contextual subset adequately represents the expected operating range at each timestamp.
- Evidence anchors: [abstract] mentions "QBSD also provides time-sensitive upper and lower operating ranges along with the forecast, which is crucial for anomaly detection in time series data." [section 3.1] describes the calculation of quartiles and IQR.

### Mechanism 3
- Claim: QBSD is designed for rolling forecasts on live data without requiring scheduled retraining.
- Mechanism: The algorithm continuously updates model parameters as new data becomes available, using a moving window approach.
- Core assumption: The historical data within the context window is representative of the current patterns and can be used to generate accurate forecasts without periodic retraining.
- Evidence anchors: [section 3] states: "It is designed for rolling forecast on live data. This method uses a moving window approach that continuously updates the model parameters as new data becomes available."

## Foundational Learning

- Concept: Time series forecasting and decomposition
  - Why needed here: QBSD is a time series forecasting method that decomposes data based on seasonality and operating ranges.
  - Quick check question: What are the key components of time series decomposition, and how do they relate to forecasting?

- Concept: Anomaly detection in time series data
  - Why needed here: QBSD is specifically designed for anomaly detection in time series data, providing time-sensitive operating ranges.
  - Quick check question: How does the detection of anomalies in time series data differ from traditional anomaly detection methods?

- Concept: Computational complexity and efficiency in machine learning algorithms
  - Why needed here: QBSD aims to balance accuracy and computational complexity, outperforming state-of-the-art methods in runtime efficiency.
  - Quick check question: What are the key factors that contribute to the computational complexity of time series forecasting algorithms, and how can they be optimized?

## Architecture Onboarding

- Component map: Data preprocessing -> Contextual subset compilation -> Quartile calculation (Q1, Q3) -> IQR derivation -> Forecast generation (mean between Q1 and Q3) -> Anomaly detection (Z-scores on residuals)

- Critical path: The critical path involves the compilation of the contextual subset, quartile calculation, and forecast generation for each timestamp.

- Design tradeoffs:
  - Accuracy vs. computational efficiency: QBSD prioritizes efficiency while maintaining competitive accuracy.
  - Simplicity vs. flexibility: QBSD has minimal parameters and avoids complex hyperparameter tuning, but may not capture all nuances in highly complex datasets.

- Failure signatures:
  - Inaccurate forecasts: If the contextual subset does not adequately represent the data patterns, or if the quartile-based approach fails to capture the underlying trends.
  - Inefficient computation: If the contextual subset compilation or quartile calculation becomes computationally expensive for large datasets or high-frequency data.

- First 3 experiments:
  1. Test QBSD on a simple time series dataset with known patterns (e.g., daily electricity demand) and compare its performance with other forecasting methods.
  2. Evaluate QBSD's ability to capture time-sensitive operating ranges by introducing anomalies in a synthetic dataset and assessing its detection accuracy.
  3. Measure the computational efficiency of QBSD on a large-scale dataset with multiple time series variables, comparing its runtime with state-of-the-art methods.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of QBSD compare to hybrid models that combine multiple forecasting techniques?
- Basis in paper: [explicit] The paper mentions that hybrid models aim to combine the strengths of multiple forecasting techniques to improve overall performance, but it does not compare QBSD to any hybrid models.
- Why unresolved: The paper focuses on comparing QBSD to state-of-the-art and popular forecasting methods, but it does not include any hybrid models in the comparison.
- What evidence would resolve it: An experimental comparison of QBSD with hybrid models on the same datasets used in the paper.

### Open Question 2
- Question: Can QBSD be extended to handle multivariate time series forecasting?
- Basis in paper: [inferred] The paper focuses on univariate time series forecasting and mentions that there are domains that require multivariate forecasting to model the joint-distributions of the variables concerned.
- Why unresolved: The paper does not explore the possibility of extending QBSD to handle multivariate time series forecasting.
- What evidence would resolve it: A study that extends QBSD to handle multivariate time series forecasting and evaluates its performance on relevant datasets.

### Open Question 3
- Question: How does the choice of the context window size k affect the performance of QBSD?
- Basis in paper: [explicit] The paper mentions that the size of the context window was manually adjusted for each dataset, but it does not provide a systematic analysis of how the choice of k affects the performance of QBSD.
- Why unresolved: The paper does not explore the sensitivity of QBSD to the choice of the context window size k.
- What evidence would resolve it: An experimental study that systematically varies the context window size k and evaluates the performance of QBSD on relevant datasets.

## Limitations

- The efficiency gains of QBSD may diminish for high-frequency data or when the contextual subset size grows substantially.
- The generalizability of QBSD across different domains beyond telecom KPIs remains uncertain.
- The anomaly detection performance evaluation is limited to a binary classification setup without exploring different threshold selection strategies or imbalanced datasets.

## Confidence

- **High Confidence**: The core mechanism of QBSD (contextual subset compilation, quartile calculation, and forecast generation) is clearly specified and reproducible.
- **Medium Confidence**: Claims about computational efficiency advantages and forecast accuracy relative to baseline methods are supported by experiments but lack detailed scalability analysis.
- **Low Confidence**: Generalizability across domains and robustness to different data characteristics are not thoroughly explored.

## Next Checks

1. **Scalability Analysis**: Evaluate QBSD's computational efficiency on datasets with varying frequencies (minute-level vs. hourly vs. daily) and different contextual window sizes to identify potential performance bottlenecks.

2. **Cross-Domain Validation**: Test QBSD on time series datasets from diverse domains (e.g., financial, environmental, industrial) to assess its generalizability and identify any domain-specific limitations.

3. **Anomaly Detection Robustness**: Conduct experiments with imbalanced datasets and different threshold selection strategies to evaluate QBSD's anomaly detection performance under varying conditions and data distributions.