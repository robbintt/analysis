---
ver: rpa2
title: 'A 3M-Hybrid Model for the Restoration of Unique Giant Murals: A Case Study
  on the Murals of Yongle Palace'
arxiv_id: '2309.06194'
source_url: https://arxiv.org/abs/2309.06194
tags:
- restoration
- murals
- mural
- image
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces the 3M-Hybrid model for the restoration
  of unique giant murals, focusing on the Yongle Palace murals. The model addresses
  two major challenges: the scarcity and distinctive style of the murals, which introduce
  domain bias, and the giant size of the murals, which results in a wider range of
  defect types and sizes.'
---

# A 3M-Hybrid Model for the Restoration of Unique Giant Murals: A Case Study on the Murals of Yongle Palace

## Quick Facts
- arXiv ID: 2309.06194
- Source URL: https://arxiv.org/abs/2309.06194
- Reference count: 31
- Key outcome: 3M-Hybrid model improves SSIM by 14.61% and PSNR by 4.73% over representative CNN models for Yongle Palace mural restoration

## Executive Summary
This paper introduces the 3M-Hybrid model for restoring unique giant murals, specifically addressing the challenges posed by Yongle Palace murals. The model tackles domain bias from distinctive artistic styles and the complexity of restoring large murals with diverse defect types through a multi-frequency strategy, hybrid CNN-VIT architecture, and multi-scale/multi-perspective processing. Experimental results demonstrate significant improvements over traditional CNN approaches, with the model effectively handling both the artistic uniqueness and massive scale of these cultural artifacts.

## Method Summary
The 3M-Hybrid model addresses mural restoration through three integrated strategies. First, a multi-frequency decomposition separates high and low-frequency features for independent processing, leveraging the prominent frequency characteristics of Yongle Palace murals. Second, a hybrid CNN-VIT network combines convolutional neural networks with a pre-trained Vision Transformer to balance domain-specific learning with generalizable feature extraction. Third, a multi-scale and multi-perspective approach processes the giant murals at three different scales (original, 4/5, 3/5) from 16 different viewpoints to minimize seams and structural distortions during restoration.

## Key Results
- PSNR improved by 4.73% and SSIM by 14.61% compared to best representative CNN model
- Successfully restored 10 test giant murals with varying dimensions
- Effective handling of both small details and large structural elements through multi-scale processing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Separating high and low frequency features improves restoration accuracy for murals with strong textural and structural elements
- Mechanism: The multi-frequency strategy independently processes low-frequency (color blocks) and high-frequency (edges) information, allowing specialized feature learning before merging
- Core assumption: Yongle Palace murals contain prominent, separable low and high frequency information that benefits from independent learning
- Evidence anchors:
  - [abstract] "based on the characteristic that the mural data frequency is prominent in the distribution of low and high frequency features, high and low frequency features are separately abstracted for complementary learning"
  - [section] "the images encompass abundant large-scale color blocks representing low-frequency information and well-defined contour lines representing high-frequency information"
- Break condition: If the mural lacks clear separation between low and high frequency content, or if the frequency decomposition fails to preserve essential structural information

### Mechanism 2
- Claim: Integrating a pre-trained Vision Transformer with CNN improves feature extraction while mitigating domain bias
- Mechanism: The hybrid CNN-VIT network combines the CNN's efficiency on small datasets with the transformer's global feature extraction, using a pre-trained VIT model to reduce domain bias
- Core assumption: Pre-trained transformer models provide generalizable global features that can be adapted to mural restoration despite limited training data
- Evidence anchors:
  - [abstract] "we integrate a pre-trained Vision Transformer model (VIT) into the CNN module, allowing us to leverage the benefits of a large model while mitigating domain bias"
  - [section] "we employ a combination of CNN as the backbone and Transformer as an enhanced feature extractor to address mural restoration tasks"
- Break condition: If the domain shift between ImageNet and murals is too large for the pre-trained VIT to provide meaningful feature extraction

### Mechanism 3
- Claim: Multi-perspective and multi-scale strategies effectively handle giant mural restoration by addressing seams and structural distortion
- Mechanism: Multi-perspective segmentation creates 16 different viewpoints to average out seams, while multi-scale resizing (original, 4/5, 3/5) preserves both detail and structural information
- Core assumption: Seams can be minimized by averaging multiple perspectives, and structural information can be recovered by combining multiple scales
- Evidence anchors:
  - [abstract] "we mitigate seam and structural distortion issues resulting from the restoration of large defects by employing a multi-scale and multi-perspective strategy, including data segmentation and fusion"
  - [section] "by adopting a multi-scale approach, the murals are downsized to 4/5 and 3/5 of the original size... The mural at the original size is responsible for detail restoration, while the downsized murals offer structural information at different scales"
- Break condition: If the averaging process fails to align perspectives properly, or if scale differences introduce new artifacts that cannot be reconciled

## Foundational Learning

- Concept: Frequency domain decomposition
  - Why needed here: Murals contain distinct low-frequency color blocks and high-frequency edges that benefit from separate processing
  - Quick check question: What are the primary visual characteristics that distinguish low and high frequency components in mural images?

- Concept: Transfer learning adaptation
  - Why needed here: Limited mural data requires leveraging pre-trained models while addressing domain-specific challenges
  - Quick check question: How does integrating pre-trained VIT with CNN help address the domain bias problem in mural restoration?

- Concept: Multi-scale image processing
  - Why needed here: Giant murals require both detailed and structural information preservation across different scales
  - Quick check question: What is the purpose of processing the mural at 4/5 and 3/5 of the original size in addition to the full size?

## Architecture Onboarding

- Component map: Input → Multi-frequency decomposition → Hybrid CNN-VIT restoration (low, high, full frequency) → Merge block → Multi-perspective segmentation (16 viewpoints) → Multi-scale processing (3 scales) → Fusion → Output
- Critical path: Multi-frequency strategy → Hybrid CNN-VIT network → Multi-perspective and multi-scale assembly
- Design tradeoffs: Accuracy vs. computational cost in using multiple frequency channels and scales; complexity vs. performance in hybrid architecture
- Failure signatures: Persistent seams in final output (multi-perspective failure); loss of fine details or structural distortion (multi-scale failure); poor restoration quality on frequency-specific defects
- First 3 experiments:
  1. Test frequency decomposition on sample murals to verify clear separation of low and high frequency information
  2. Validate hybrid CNN-VIT performance on small mural patches compared to pure CNN and VIT approaches
  3. Verify seam reduction by comparing single perspective vs. multi-perspective restoration on test patches

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed 3M-Hybrid model perform compared to other state-of-the-art image restoration models on different types of murals beyond Yongle Palace?
- Basis in paper: [inferred] The paper mentions that most existing mural restoration research focuses on Dunhuang murals and lacks dedicated research on Yongle Palace murals. The authors compare their model to four representative CNN models but do not explore other mural types
- Why unresolved: The paper focuses specifically on Yongle Palace murals and does not provide a comprehensive comparison with other mural types
- What evidence would resolve it: Conducting experiments on various mural types and comparing the 3M-Hybrid model's performance to other state-of-the-art models would provide insights into its generalizability and effectiveness across different mural restoration tasks

### Open Question 2
- Question: How does the 3M-Hybrid model handle the restoration of extremely large defects in murals, and what is the upper limit of defect size it can effectively repair?
- Basis in paper: [explicit] The paper mentions that the giant size of Yongle Palace murals results in a wider range of defect types and sizes, posing challenges for restoration models. The authors propose a multi-scale strategy to address oversized defects, but the specific performance limits are not mentioned
- Why unresolved: The paper does not provide quantitative results or analysis on the model's performance in handling extremely large defects
- What evidence would resolve it: Conducting experiments with progressively larger defects and analyzing the model's performance in terms of restoration quality, computational efficiency, and limitations would provide insights into its capabilities and potential constraints

### Open Question 3
- Question: How does the 3M-Hybrid model perform when applied to real-world mural restoration projects, considering factors such as lighting conditions, surface textures, and preservation requirements?
- Basis in paper: [inferred] The paper presents experimental results on synthetic data and simulated defects, but does not address the challenges and complexities of real-world mural restoration projects
- Why unresolved: The paper focuses on the model's performance in controlled experimental settings and does not explore its practical application in real-world scenarios
- What evidence would resolve it: Conducting field tests and evaluating the model's performance on actual murals in various environmental conditions, as well as considering preservation requirements and expert assessments, would provide insights into its real-world applicability and limitations

## Limitations

- Domain-specific focus on Yongle Palace murals may limit generalizability to other artistic styles
- Reliance on pre-trained Vision Transformer introduces uncertainty about performance on unique artistic styles
- Multi-perspective and multi-scale fusion strategy lacks rigorous quantitative validation of seam reduction

## Confidence

- **High confidence**: The multi-frequency strategy's effectiveness for separating and processing distinct visual components (low-frequency color blocks vs. high-frequency edges) is well-supported by the architectural description and aligns with established image processing principles
- **Medium confidence**: The hybrid CNN-VIT architecture's benefits are theoretically sound, but the specific implementation details and weight assignment between components are not fully specified, limiting reproducibility
- **Low confidence**: The multi-perspective and multi-scale fusion strategy's effectiveness in eliminating seams is demonstrated empirically but lacks rigorous quantitative validation of the seam reduction process itself

## Next Checks

1. Apply the multi-frequency strategy to murals outside the Yongle Palace dataset to verify the assumption that low and high frequency features are consistently separable and beneficial across different mural styles

2. Conduct controlled experiments comparing pure CNN, pure Vision Transformer, and the hybrid approach on the same mural restoration tasks to quantify the specific contribution of each component

3. Measure and report the actual seam artifacts in the final assembled murals using quantitative metrics (e.g., edge detection differences at segment boundaries) rather than relying solely on qualitative visual inspection