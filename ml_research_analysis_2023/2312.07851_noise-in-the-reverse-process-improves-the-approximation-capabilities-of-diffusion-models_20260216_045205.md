---
ver: rpa2
title: Noise in the reverse process improves the approximation capabilities of diffusion
  models
arxiv_id: '2312.07851'
source_url: https://arxiv.org/abs/2312.07851
tags:
- neural
- approximation
- solution
- equation
- vector
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the role of noise in reverse processes
  of score-based generative models (SGMs) through a control-theoretic lens. By framing
  trajectory approximation as a control problem, it establishes that neural stochastic
  differential equations (SDEs) can achieve stronger approximation guarantees in L2
  norm compared to deterministic neural ODEs, even when the reference vector field
  or score function is not Lipschitz continuous.
---

# Noise in the reverse process improves the approximation capabilities of diffusion models

## Quick Facts
- arXiv ID: 2312.07851
- Source URL: https://arxiv.org/abs/2312.07851
- Authors: 
- Reference count: 9
- Key outcome: Neural stochastic differential equations achieve stronger L2 norm trajectory approximation than deterministic neural ODEs in diffusion models, even without Lipschitz continuity assumptions.

## Executive Summary
This paper establishes that noise in reverse processes of score-based generative models provides a powerful regularizing effect, enabling stronger approximation guarantees in L2 norm compared to deterministic approaches. Through a control-theoretic lens, the work demonstrates that neural SDEs can approximate trajectories more effectively than neural ODEs, even when the reference vector field is not Lipschitz continuous. The analysis characterizes the class of distributions that can be sampled using score matching and shows that these approximation properties are preserved even with limited-width neural networks, where weights act as control inputs.

## Method Summary
The paper frames trajectory approximation as a control problem, analyzing neural SDEs as control systems in probability density space. The theoretical framework uses Sobolev spaces, Fokker-Planck equations, and controllability theory to establish approximation guarantees. The approach relaxes traditional Lipschitz continuity requirements by working on bounded domains with compact connected supports, enabling analysis of broader distribution classes. The limited-width analysis treats weights as control inputs, establishing controllability properties for neural SDEs even with constrained network architectures.

## Key Results
- Neural SDEs achieve L2 norm trajectory approximation that surpasses Wasserstein metric approximation achieved by neural ODEs
- The approximation property is preserved when network width is limited to the input dimension, with weights acting as control inputs
- The class of distributions that can be sampled using score matching is characterized, relaxing the Lipschitz requirement on gradient of the data distribution

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural SDEs achieve L2 norm trajectory approximation that surpasses Wasserstein metric approximation achieved by neural ODEs.
- Mechanism: The noise in neural SDEs provides a regularizing effect that prevents irregular behavior of approximating densities in L2 norm, even when the reference vector field is not Lipschitz continuous.
- Core assumption: The noise in the neural SDE provides sufficient regularization to overcome the sensitivity of density approximations to vector field derivatives.
- Evidence anchors:
  - [abstract] "neural SDEs exhibit a powerful regularizing effect, enabling L2 norm trajectory approximation surpassing the Wasserstein metric approximation achieved by neural ODEs"
  - [section] "However, as we will show in this paper, this problem does not arise in the stochastic case, due to the regularization effect of noise"
- Break condition: The regularization effect fails when the noise level is too small or the initial condition lacks sufficient smoothness.

### Mechanism 2
- Claim: Limited-width neural SDEs preserve approximation properties when weights act as control inputs.
- Mechanism: By framing the problem as a controllability problem for neural SDEs in probability density space, the stochasticity enables steering the system toward desired solutions despite limited representation capability.
- Core assumption: The stochastic component provides sufficient degrees of freedom to compensate for the limited width of the neural network.
- Evidence anchors:
  - [abstract] "this approximation property is preserved when network width is limited to the input dimension of the network. In this limited width case, the weights act as control inputs, framing our analysis as a controllability problem for neural SDEs in probability density space"
  - [section] "The idea is that one can still achieve approximation by weakly approximating the vector fields in a time averaged sense"
- Break condition: The system becomes uncontrollable when the noise intensity drops below a threshold relative to the complexity of the target distribution.

### Mechanism 3
- Claim: Neural SDEs can sample from a broader class of distributions than previously possible, relaxing the Lipschitz requirement on data distribution gradients.
- Mechanism: By working on bounded domains and allowing data distributions with compact connected supports, the approach eliminates the need for Lipschitz continuity assumptions on score functions.
- Core assumption: The bounded domain and compactness of supports provide sufficient structure to enable approximation without Lipschitz gradients.
- Evidence anchors:
  - [abstract] "Applying this result, we establish the class of distributions that can be sampled using score matching in SGMs, relaxing the Lipschitz requirement on the gradient of the data distribution in existing literature"
  - [section] "By considering diffusion processes on bounded domains, we are able to additionally allow for data distributions with compact connected supports"
- Break condition: The approximation fails when distributions have disconnected supports or require sampling from regions outside the bounded domain.

## Foundational Learning

- Concept: Fokker-Planck equation and its weak solution formulation
  - Why needed here: The analysis fundamentally relies on understanding how probability densities evolve under the influence of vector fields and noise
  - Quick check question: What is the relationship between the Fokker-Planck equation and the stochastic differential equation governing the underlying process?

- Concept: Sobolev spaces and weak derivatives
- Why needed here: The regularity analysis and approximation proofs depend on understanding function spaces beyond just L2, particularly for establishing convergence properties
- Quick check question: How does the choice of Sobolev space (H1 vs L2) affect the regularity requirements for the vector fields in the approximation theorem?

- Concept: Controllability theory for stochastic systems
  - Why needed here: The limited-width analysis explicitly frames the approximation problem as a controllability problem for neural SDEs
  - Quick check question: What distinguishes controllability for stochastic systems from deterministic ones in the context of density evolution?

## Architecture Onboarding

- Component map: Forward process (data to noise) -> Reverse process (neural SDE with control weights) -> Approximation layer (score matching) -> Regularization (noise term)
- Critical path: Define target distribution → Construct exact vector field → Approximate with limited-width neural SDE → Verify L2 convergence → Sample from approximate process
- Design tradeoffs:
  - Higher noise levels improve approximation but may slow convergence
  - Limited width reduces computational cost but requires careful control input design
  - Bounded domains enable stronger guarantees but restrict applicable distributions
- Failure signatures:
  - Divergence of approximating densities (indicates insufficient regularization)
  - Oscillatory behavior in density approximations (suggests numerical instability)
  - Slow convergence rates (may indicate suboptimal control input design)
- First 3 experiments:
  1. Verify L2 vs Wasserstein convergence for a simple 1D Gaussian distribution using both neural ODE and SDE approaches
  2. Test limited-width approximation on a 2D distribution with known exact vector field
  3. Compare sampling quality from bounded vs unbounded domains for distributions with disconnected supports

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the presence of noise in the forward process of diffusion models affect the expressivity and sample quality compared to deterministic forward processes?
- Basis in paper: [inferred] The paper discusses the smoothing effect of noise in the reverse process but does not explore the role of noise in the forward process.
- Why unresolved: The paper focuses on the reverse process and does not provide an analysis of the forward process.
- What evidence would resolve it: Empirical studies comparing diffusion models with stochastic and deterministic forward processes, and theoretical analysis of the forward process's impact on the model's expressivity.

### Open Question 2
- Question: Can the approximation capabilities of neural SDEs be further improved by using different activation functions or network architectures?
- Basis in paper: [explicit] The paper assumes a specific activation function and network architecture but does not explore the impact of other choices.
- Why unresolved: The paper does not provide an analysis of how different activation functions or network architectures affect the approximation capabilities of neural SDEs.
- What evidence would resolve it: Empirical studies comparing the performance of neural SDEs with different activation functions and network architectures, and theoretical analysis of their impact on the approximation capabilities.

### Open Question 3
- Question: How does the choice of the domain boundary condition (e.g., Neumann vs. Dirichlet) affect the approximation capabilities of neural SDEs in diffusion models?
- Basis in paper: [inferred] The paper assumes a Neumann boundary condition but does not discuss the impact of other choices.
- Why unresolved: The paper does not provide an analysis of how different boundary conditions affect the approximation capabilities of neural SDEs.
- What evidence would resolve it: Empirical studies comparing the performance of neural SDEs with different boundary conditions, and theoretical analysis of their impact on the approximation capabilities.

## Limitations
- The analysis is purely theoretical without empirical validation of practical performance
- Bounded domain assumptions may limit applicability to real-world unbounded data distributions
- Limited-width analysis may not fully capture practical constraints of finite neural network architectures

## Confidence
- High Confidence: The theoretical framework establishing L2 norm trajectory approximation for neural SDEs is mathematically rigorous and well-supported by proofs
- Medium Confidence: The claim that noise provides a regularizing effect is theoretically justified but requires empirical validation
- Low Confidence: The practical implications of these theoretical results for real-world generative modeling tasks are not established

## Next Checks
1. Implement a minimal neural SDE and neural ODE framework to compare L2 vs Wasserstein convergence on benchmark distributions
2. Design experiments to measure the actual regularization effect of noise on density approximation stability
3. Evaluate sampling quality from neural SDEs on real-world distributions with complex geometries