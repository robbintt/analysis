---
ver: rpa2
title: Federated Prompt Learning for Weather Foundation Models on Devices
arxiv_id: '2305.14244'
source_url: https://arxiv.org/abs/2305.14244
tags:
- weather
- forecasting
- prompts
- learning
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of federated weather forecasting
  across heterogeneous, geographically distributed sensors. The proposed FedWing framework
  uses lightweight adaptive prompts to represent spatial-temporal patterns and encode
  location-specific information, enabling personalized model updates while maintaining
  communication efficiency.
---

# Federated Prompt Learning for Weather Foundation Models on Devices

## Quick Facts
- arXiv ID: 2305.14244
- Source URL: https://arxiv.org/abs/2305.14244
- Authors: 
- Reference count: 40
- Primary result: FedWing achieves lower MAE and RMSE than state-of-the-art federated learning baselines for weather forecasting across heterogeneous, geographically distributed sensors

## Executive Summary
This paper addresses federated weather forecasting across heterogeneous, geographically distributed sensors by proposing the FedWing framework. The approach uses lightweight adaptive prompts to represent spatial-temporal patterns and encode location-specific information, enabling personalized model updates while maintaining communication efficiency. Dynamic Graph Modeling constructs spatial-temporal correlations among clients based on prompts and geographic information. Experiments on three real-world weather datasets demonstrate that FedWing outperforms state-of-the-art federated learning baselines, achieving lower MAE and RMSE in both univariate and multivariate forecasting tasks while effectively handling statistical heterogeneity.

## Method Summary
FedWing employs a foundation model fine-tuning approach using adaptive prompts instead of full parameter updates. The framework consists of three types of adaptive prompts: temporal (PT), inter-variable (PV), and spatial (PS) prompts that capture different aspects of weather patterns. During local training, clients optimize these prompts using a multi-level regularization loss that balances personalization with global consistency. The server constructs dynamic graphs based on cosine similarity of prompts and geographic proximity (Haversine distance) to determine which clients should collaborate. This graph-based aggregation enables more effective knowledge sharing among geographically and meteorologically similar clients while reducing communication overhead compared to traditional federated learning approaches.

## Key Results
- FedWing outperforms state-of-the-art federated learning baselines (FedAvg, FedProx, FedDF, LG-FedAvg, LG-FedAvg-MV) on three real-world weather datasets
- Achieves lower MAE and RMSE in both univariate and multivariate forecasting tasks across all tested datasets
- Reduces communication overhead by transmitting lightweight prompts instead of full model parameters
- Effectively handles statistical heterogeneity among clients while preserving privacy
- Demonstrates strong performance even with limited participation rates (C=0.3)

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Prompts for Spatial-Temporal Encoding
Adaptive prompts encode both spatial and temporal information from local data while enabling lightweight communication between clients and server. The lightweight prompts (PT, PV, PS) replace full model parameters in federated communication, reducing transmission overhead while preserving spatial-temporal representation. This works because prompts can effectively capture the essential spatial-temporal patterns needed for accurate weather forecasting. If prompts cannot capture complex spatial-temporal correlations, forecasting accuracy will degrade significantly.

### Mechanism 2: Dynamic Graph Modeling Based on Prompt Similarity
Dynamic Graph Modeling constructs spatial-temporal correlations among clients based on prompt similarity and geographic information. The server builds dynamic graphs using cosine similarity of prompts and Haversine distance, then performs attention-based aggregation to update client models. This works because clients with similar prompt representations and geographic proximity have correlated weather patterns worth sharing. If geographic correlation does not reflect weather pattern similarity, the graph-based aggregation will be ineffective.

### Mechanism 3: Multi-Level Regularization for Personalization
Multi-level regularization terms in the local loss function enable personalized model updates while maintaining global consistency. The local loss combines prediction error with regularization terms measuring distance between local, personalized, neighboring, and global prompts. This works because regularization on prompt similarity can effectively balance personalization with knowledge sharing. If regularization weights are not properly tuned, models may either overfit locally or fail to personalize effectively.

## Foundational Learning

- Concept: Federated Learning fundamentals (client-server architecture, communication rounds, aggregation)
  - Why needed here: The entire framework relies on federated learning principles for privacy-preserving collaborative training
  - Quick check question: What is the difference between FedAvg and FedProx, and when would you choose one over the other?

- Concept: Spatial-temporal modeling (capturing both spatial correlations and temporal dynamics)
  - Why needed here: Weather data inherently has both spatial patterns (geographic correlation) and temporal patterns (time series dynamics)
  - Quick check question: How does a spatial-temporal graph convolution network differ from a standard temporal convolution network?

- Concept: Foundation model fine-tuning techniques (prompt tuning vs. full fine-tuning)
  - Why needed here: The approach uses a pre-trained foundation model with lightweight prompt tuning instead of full parameter updates
  - Quick check question: What are the trade-offs between prompt tuning and adapter-based tuning in terms of parameter efficiency and performance?

## Architecture Onboarding

- Component map: Foundation Model -> Adaptive Prompts (PT, PV, PS) -> Local Training Module -> Dynamic Graph Modeling -> Communication Protocol
- Critical path: Local data → Adaptive Prompt Generation → Local Training (with regularization) → Prompt Upload → Dynamic Graph Construction → Prompt Aggregation → Updated Prompts Download → Next Round
- Design tradeoffs:
  - Parameter efficiency vs. model expressiveness (prompts vs. full parameters)
  - Geographic correlation vs. weather pattern correlation (Haversine vs. prompt similarity)
  - Personalization vs. global consistency (regularization weights)
- Failure signatures:
  - Degraded forecasting accuracy despite training completion
  - Communication overhead not reduced as expected
  - Graph connectivity issues (isolated clients or overly dense graphs)
- First 3 experiments:
  1. Baseline comparison: Run FedAvg with full parameter communication vs. FedWing with prompt communication on a small dataset to verify communication efficiency
  2. Ablation study: Test FedWing performance with and without each type of adaptive prompt (PT, PV, PS) to validate their individual contributions
  3. Graph sensitivity: Vary the subgraph step parameter (SG) and measure impact on forecasting accuracy to find optimal correlation scope

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of FedWing scale when applied to datasets with thousands or tens of thousands of weather stations, rather than the hundreds used in the current experiments? The paper mentions that the current experiments are conducted on datasets with hundreds of ground-based weather stations, but the number of ground-based equipment in a given region far exceeds this amount, and the authors lack sufficient computational power to apply their approach to scenarios involving thousands or tens of thousands of equipment.

### Open Question 2
How does the FedWing framework handle scenarios where location information (latitude and longitude) is not available for each weather station, such as in cross-country or global-scale forecast systems? The paper states that the proposed method assumes the central server has access to the location information of each weather station within the region, but in a cross-country or global-scale forecast system, specific latitude and longitude information may not be available due to relevant protocols.

### Open Question 3
How does the performance of FedWing compare to other state-of-the-art federated learning algorithms when applied to weather forecasting tasks on larger datasets with more weather stations? The paper compares the performance of FedWing to other state-of-the-art federated learning algorithms on three real-world weather datasets with hundreds of weather stations, but does not provide any results or analysis on how the performance of FedWing compares to these algorithms on larger datasets with more weather stations.

## Limitations

- Unclear implementation details for adaptive prompt updating mechanism (Algorithm 1)
- Missing definition of the "additional regularization term G(·)" for graph sparsity enforcement
- No specification of foundation model architecture choice or pre-training procedure
- Limited validation on geographic regions or weather phenomena beyond the tested datasets

## Confidence

- Adaptive prompt effectiveness for spatial-temporal encoding: **Medium**
- Dynamic graph modeling based on prompt similarity: **Medium**
- Multi-level regularization for personalization: **Medium**

## Next Checks

1. **Prompt contribution ablation**: Systematically disable each prompt type (PT, PV, PS) in the FedWing framework and measure performance degradation to quantify individual contributions to forecasting accuracy.

2. **Graph construction sensitivity**: Conduct experiments varying the subgraph step parameter (SG) and measure impact on both communication efficiency and forecasting accuracy to identify optimal correlation scope.

3. **Geographic vs. prompt correlation validation**: Test FedWing performance when using only geographic information (Haversine distance) versus only prompt similarity for graph construction to determine which correlation source is more effective for weather forecasting.