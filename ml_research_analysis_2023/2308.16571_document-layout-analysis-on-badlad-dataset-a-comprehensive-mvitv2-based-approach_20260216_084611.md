---
ver: rpa2
title: 'Document Layout Analysis on BaDLAD Dataset: A Comprehensive MViTv2 Based Approach'
arxiv_id: '2308.16571'
source_url: https://arxiv.org/abs/2308.16571
tags:
- document
- training
- layout
- transformer
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper trains MViTv2-B with Cascade Mask R-CNN on BaDLAD dataset
  for Bengali document layout analysis. After 36 epochs in three phases, it achieves
  a Dice score of 0.90348, training loss of 0.2125, and mask loss of 0.19.
---

# Document Layout Analysis on BaDLAD Dataset: A Comprehensive MViTv2 Based Approach

## Quick Facts
- arXiv ID: 2308.16571
- Source URL: https://arxiv.org/abs/2308.16571
- Reference count: 5
- The model achieved a Dice score of 0.90348 and mAP of 56.381 on the BaDLAD dataset

## Executive Summary
This paper presents a document layout analysis approach using MViTv2-B with Cascade Mask R-CNN on the BaDLAD dataset for Bengali documents. The model was trained for 36 epochs in three phases, achieving a Dice score of 0.90348 and outperforming traditional CNN approaches in the Kaggle competition "DL Sprint 2.0". The work demonstrates the effectiveness of transformer-based MViTv2 architecture for Bengali document layout analysis while exploring various augmentation strategies and inference techniques.

## Method Summary
The approach uses MViTv2-B as the backbone with Cascade Mask R-CNN for instance segmentation on the BaDLAD dataset. Training was conducted in three consecutive 12-epoch phases with decreasing learning rates (8×10^-5, 4×10^-5, 2×10^-5) using the AdamW optimizer. Data augmentation included random brightness, contrast, saturation adjustments, and limited rotation (±5°). The model was implemented using Detectron2 framework with images resized to 1024×1024 resolution and batch size of 16.

## Key Results
- Achieved Dice score of 0.90348 and mAP of 56.381 on BaDLAD dataset
- Outperformed traditional CNN approaches in Kaggle competition "DL Sprint 2.0"
- Demonstrated superior performance in detecting text-boxes, paragraphs, and tables in Bengali documents

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MViTv2-B + Cascade Mask R-CNN provides superior detection performance compared to traditional CNN approaches.
- Mechanism: The multiscale vision transformer backbone captures hierarchical spatial features at multiple scales, while the cascade R-CNN refines detections through progressive thresholds, leading to better mask and box predictions.
- Core assumption: The BaDLAD dataset contains diverse document layouts that benefit from multiscale feature extraction.
- Evidence anchors:
  - [abstract] "We have trained MViTv2 transformer model architecture with cascaded mask R-CNN on BaDLAD dataset... Our work demonstrates transformer-based MViTv2's effectiveness for Bengali document layout analysis."
  - [section II.A] "The MViTv2-B variant outperforms the Swin-B model by a significant margin, boasting a marked increase of +2.5 and +2.3 in AP box and AP mask, respectively."

### Mechanism 2
- Claim: Three-phase training with decreasing learning rates improves model convergence and final performance.
- Mechanism: Early phases with higher learning rates allow rapid exploration of parameter space, while later phases with reduced rates enable fine-tuning and stability.
- Core assumption: The model can leverage knowledge from earlier phases when initialized in later phases.
- Evidence anchors:
  - [section II.D] "Our training was strategically organized into three consecutive cycles, each spanning 12 epochs... The model's parameters were efficiently transferred between training cycles... with the final parameters of each 12-epoch run serving as the starting point for the subsequent run."
  - [section III] "After a total training of 36 epochs in 3 phases, our model scored a Dice score of 0.90095 on the public test set and a total loss of 0.2125 and a mask loss of 0.19."

### Mechanism 3
- Claim: Limited rotation augmentation (±5°) improves performance on slightly tilted scanned documents without degrading upright document detection.
- Mechanism: Small rotations simulate real-world scanning variations while avoiding confusion from full 90°/180° rotations that are rare in test data.
- Core assumption: Most rotated images in the dataset have small tilt angles rather than arbitrary orientations.
- Evidence anchors:
  - [section V.A] "We noticed a much more prevalent pattern of rotations in the dataset... Since much of the documents are scanned documents, they are slightly tilted at a small angle. To incorporate this variation we augmented our images using a random rotation in the range [−5°, 5°]."
  - [section V.A] "However we observed that this augmentation as well as horizontal or vertical flips lead to poorer results. Since rotated images are rare in the test set, we choose to train our model to primarily focus on upright images."

## Foundational Learning

- Concept: Transformer architecture and self-attention mechanisms
  - Why needed here: Understanding how MViTv2's multiscale vision transformer processes document images differently from CNNs is crucial for architecture selection and troubleshooting.
  - Quick check question: How does the self-attention mechanism in MViTv2 enable it to capture long-range dependencies in document layouts compared to CNN's local receptive fields?

- Concept: Instance segmentation and cascade refinement
  - Why needed here: The cascade R-CNN component progressively refines bounding box predictions, which is key to understanding the improvement in mask AP scores.
  - Quick check question: What is the role of multiple detection heads with increasing IoU thresholds in cascade R-CNN, and how does this improve segmentation accuracy?

- Concept: Data augmentation strategies and their impact on model generalization
  - Why needed here: The paper explores various augmentation techniques (rotation, brightness, contrast) and their effects, requiring understanding of how augmentation influences model robustness.
  - Quick check question: Why did random rotation augmentation in the range {0°, 90°, 180°, 270°} lead to poorer results, while limited rotation (±5°) improved performance?

## Architecture Onboarding

- Component map:
  Input image -> Preprocessing (resize, normalization) -> Data augmentation -> MViTv2-B backbone -> Cascade R-CNN heads -> Detection/mask output -> Loss computation -> AdamW optimization

- Critical path:
  1. Input image preprocessing (resize to 1024×1024, color normalization)
  2. Data augmentation application
  3. Forward pass through MViTv2-B backbone
  4. Cascade R-CNN detection and mask prediction
  5. Loss computation (total loss, mask loss)
  6. Backward pass with learning rate scheduling
  7. Parameter updates and checkpointing

- Design tradeoffs:
  - MViTv2-B vs. CNN backbones: Higher accuracy but increased computational cost
  - Limited rotation augmentation vs. full rotation coverage: Better performance on tilted documents but reduced robustness to arbitrary rotations
  - Three-phase training vs. single training cycle: Improved convergence but longer training time
  - 1024×1024 resolution vs. native document resolution: Uniform input size but potential loss of detail

- Failure signatures:
  - High mask loss but low box loss: Model struggles with precise boundary delineation
  - Poor performance on small text-boxes and paragraphs: Resolution or scale issues in feature extraction
  - Degradation after rotation augmentation: Model overfits to upright documents or augmentation parameters are incorrect
  - Training instability: Learning rate too high or insufficient warmup

- First 3 experiments:
  1. Train baseline model with MViTv2-B + Cascade R-CNN for 12 epochs at 224×224 resolution to establish performance baseline
  2. Test different rotation augmentation ranges (±5° vs. {0°, 90°, 180°, 270°}) while keeping other parameters constant
  3. Compare inference performance on sliced vs. full-resolution images for small object detection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does explicit rotation detection and preprocessing impact model performance on arbitrarily rotated Bengali document images?
- Basis in paper: [explicit] The paper notes that rotated images are rare in the test set and mentions that a more comprehensive approach would be to train a separate model to recognize rotations and preprocess them during inference.
- Why unresolved: The authors chose not to implement this approach due to time constraints and instead focused on training the model on upright images with slight tilt corrections.
- What evidence would resolve it: Training and evaluating a dedicated rotation detection model alongside the MViTv2-B model, then comparing performance metrics (Dice score, mAP) on a test set containing various rotation angles would provide concrete evidence of the impact.

### Open Question 2
- Question: What is the impact of copy-paste augmentation on the model's ability to detect small text-boxes and paragraphs in Bengali documents?
- Basis in paper: [explicit] The paper acknowledges that copy-paste augmentation has proven to significantly improve a model's capacity to detect small objects and mentions that they couldn't train with this augmentation due to time constraints.
- Why unresolved: The authors did not have sufficient time to implement and evaluate the copy-paste augmentation technique during their study.
- What evidence would resolve it: Implementing copy-paste augmentation during training and comparing the resulting model's performance (especially in detecting small text-boxes and paragraphs) against the current model would provide quantitative evidence of its effectiveness.

### Open Question 3
- Question: How does image slicing into overlapping windows affect inference performance for detecting small features in Bengali document layout analysis?
- Basis in paper: [explicit] The authors explored slicing input images into overlapping windows to improve recognition of small features but found no noticeable improvement and introduced issues with recognizing larger features across multiple segments.
- Why unresolved: While the authors conducted initial experiments with image slicing, they did not optimize the slicing parameters (window size, overlap ratio) or investigate alternative approaches to mitigate the issues they encountered.
- What evidence would resolve it: Systematically testing different slicing configurations and developing methods to handle features spanning multiple slices would provide evidence of whether image slicing can be optimized for better performance in detecting small document elements.

## Limitations

- Limited validation on arbitrarily rotated documents due to focus on slightly tilted scanned documents
- Performance degradation on small text-boxes and paragraphs due to resolution limitations
- Lack of copy-paste augmentation which could improve detection of small objects

## Confidence

- High confidence: The three-phase training methodology and its implementation details are well-documented and reproducible
- Medium confidence: The effectiveness of limited rotation augmentation is demonstrated but requires broader validation across diverse document orientations
- Medium confidence: The overall performance metrics (Dice score 0.90348, mAP 56.381) are verifiable through competition submissions but lack comprehensive ablation studies

## Next Checks

1. Conduct controlled ablation studies comparing MViTv2-B with popular CNN backbones (ResNet, Swin) on the same training protocol to isolate the contribution of the transformer architecture
2. Test the model on document datasets with varied rotation angles to validate whether limited rotation augmentation generalizes beyond slightly tilted scanned documents
3. Perform detailed analysis of model performance on different document element sizes (text-boxes, paragraphs, tables) to identify potential resolution-related failure modes