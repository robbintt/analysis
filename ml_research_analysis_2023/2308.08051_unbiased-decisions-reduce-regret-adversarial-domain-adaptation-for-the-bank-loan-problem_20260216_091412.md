---
ver: rpa2
title: 'Unbiased Decisions Reduce Regret: Adversarial Domain Adaptation for the Bank
  Loan Problem'
arxiv_id: '2308.08051'
source_url: https://arxiv.org/abs/2308.08051
tags:
- classifier
- data
- de-biased
- adversarial
- adopt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the Bank Loan Problem (BLP), where binary classification
  decisions are made in near real-time based on limited data, with true labels only
  observed for accepted cases. This leads to self-reinforcing bias in the labeled
  training set.
---

# Unbiased Decisions Reduce Regret: Adversarial Domain Adaptation for the Bank Loan Problem

## Quick Facts
- arXiv ID: 2308.08051
- Source URL: https://arxiv.org/abs/2308.08051
- Authors: 
- Reference count: 12
- One-line primary result: AdOpt outperforms state-of-the-art methods on cumulative regret and fairness in selective-label classification

## Executive Summary
This paper addresses the Bank Loan Problem where binary classification decisions are made in near real-time based on limited data, with true labels only observed for accepted cases. This leads to self-reinforcing bias in the labeled training set. The authors introduce Adversarial Optimism (AdOpt), a method that combines adversarial domain adaptation with pseudo-label optimism to mitigate this bias. AdOpt learns an unbiased representation of the data using adversarial domain adaptation, reducing the distributional shift between accepted and all data points. Experiments show that AdOpt significantly outperforms state-of-the-art methods on challenging benchmark problems, including Census Income, Credit, FICO, and MNIST datasets.

## Method Summary
AdOpt combines adversarial domain adaptation with pseudo-label optimism to address bias in the Bank Loan Problem. The method trains a generator, classifier, and discriminator to learn a domain-invariant representation that reduces distributional shift between accepted and all data points. The de-biased classifier then filters incoming queries to identify likely positives, which are used with pseudo-label optimism to make accept/reject decisions. This approach mitigates the self-reinforcing bias that occurs when only accepted cases provide true labels.

## Key Results
- AdOpt significantly outperforms state-of-the-art methods on cumulative regret across Census Income, Credit, FICO, and MNIST datasets
- The method demonstrates improved fairness, satisfying the equality of odds definition more closely than other approaches
- AdOpt achieves lower regret and reduced bias in predictions across different subgroups compared to baseline methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial domain adaptation learns a representation that reduces distributional shift between accepted and all data points.
- Mechanism: A generator Gθ encodes data to a shared space where a discriminator cannot distinguish between source (accepted) and target (all) domains, while a classifier preserves accuracy on source data. This forces the representation to be domain-invariant.
- Core assumption: The source and target domains share a latent space where class boundaries are preserved, and adversarial training can find it.
- Evidence anchors:
  - [abstract] "AdOpt learns an unbiased representation of the data using adversarial domain adaptation, reducing the distributional shift between accepted and all data points."
  - [section] "Adversarial domain adaptation approach is to simultaneously train a generator Gθ : Rd → Rd′ that encodes the data, a classifier Cψ : Rd′ → {0, 1}, and a discriminator Dϕ : Rd′ → {0, 1} that discriminates between the encodings of samples from S and T."
  - [corpus] Weak evidence; neighboring papers discuss domain adaptation but not in this specific selective-label context.
- Break condition: If source and target domains have non-overlapping supports or the class boundaries are fundamentally different, the adversarial objective cannot find a meaningful invariant representation.

### Mechanism 2
- Claim: The adversarially de-biased classifier overpredicts positive labels for incoming queries, mitigating self-reinforcing false rejections.
- Mechanism: Because the training data is biased toward positives (accepted), the classifier learns to assign higher probabilities to positive labels for incoming data, counteracting the historical bias against false negatives.
- Core assumption: The proportion of positives in accepted data diverges from the true population due to historical acceptance decisions.
- Evidence anchors:
  - [abstract] "AdOpt learns an unbiased but informative representation of past data, by reducing the distributional shift between the set of accepted data points and all data points seen thus far."
  - [section] "Equation (4) states that the percentage of positive predictions on the transformed labelled set Gθ(S) is the same as on Gθ(T). In the BLP setting...P (Cψ(Gθ(x)) = 1) is going to be close to P (ytrue(x) = 1 |x ∈ At)."
  - [corpus] Weak evidence; no direct support for optimism in selective-label settings.
- Break condition: If the true positive rate in accepted data does not diverge from the population, or if the classifier overfits to noise, optimism may lead to excessive false positives.

### Mechanism 3
- Claim: Combining adversarial de-biasing with pseudo-label optimism (AdOpt) outperforms either method alone by filtering pseudo-label candidates.
- Mechanism: AdOpt uses the de-biased classifier to identify likely positives among rejected queries, then applies pseudo-label optimism only to those candidates, reducing false positives while maintaining exploration.
- Core assumption: The de-biased classifier has higher recall than the biased classifier, so it can effectively filter candidates for pseudo-labeling.
- Evidence anchors:
  - [abstract] "AdOpt proposes an alternative to this approach by first filtering the incoming queries using the adversarially de-biased classifier to assess the probability of a query being a true positive."
  - [section] "Using the de-biased classifier for assigning pseudo-labels enables AdOpt to explore faster. The de-biased classifier possesses increased recall."
  - [corpus] No direct evidence; assumption based on internal logic.
- Break condition: If the de-biased classifier's recall advantage is small or unstable, the filtering step may not improve over random selection.

## Foundational Learning

- Concept: Domain adaptation and distributional shift
  - Why needed here: The paper addresses bias due to distributional shift between accepted and all data points; understanding domain adaptation is key to grasping how adversarial methods reduce this shift.
  - Quick check question: What is the main goal of adversarial domain adaptation in this context?
- Concept: Contextual bandits and regret minimization
  - Why needed here: The Bank Loan Problem is framed as a contextual bandit task where the objective is to maximize reward (minimize regret) by making optimal accept/reject decisions.
  - Quick check question: How is regret defined in the Bank Loan Problem?
- Concept: Fairness definitions (equality of odds)
  - Why needed here: The paper evaluates whether the de-biased classifier improves fairness by satisfying equality of odds (similar TPR and FPR across subgroups).
  - Quick check question: What does equality of odds require in terms of TPR and FPR?

## Architecture Onboarding

- Component map:
  - Generator Gθ -> Classifier Cψ -> Discriminator Dϕ -> Biased model -> Pseudo-label model
- Critical path: For each batch, train adversarial triad → use de-biased classifier to filter → apply pseudo-label optimism → make final accept/reject decisions
- Design tradeoffs:
  - Number of adversarial training epochs per batch (more epochs = better de-biasing but slower runtime)
  - Batch size for target domain sampling (larger = more stable but memory intensive)
  - Trade-off between recall and precision in de-biased classifier (affects false positive rate)
- Failure signatures:
  - High regret: de-biased classifier fails to mitigate distributional shift or filtering step ineffective
  - Low precision: adversarial training overfits or pseudo-label optimism too aggressive
  - Unstable fairness metrics: de-biased representation does not generalize across subgroups
- First 3 experiments:
  1. Run AdOpt on MNIST with digit 5 as positive class; verify regret decreases over time.
  2. Compare recall/precision of biased vs de-biased classifier on Census Income dataset.
  3. Test AdOpt with varying adversarial training epochs (e.g., 1, 5, 10) to find optimal balance.

## Open Questions the Paper Calls Out
None specified in the provided text.

## Limitations
- The adversarial domain adaptation component's architecture and hyperparameters are not fully specified, making faithful reproduction challenging.
- The effectiveness of the de-biased classifier's optimism mechanism depends on the extent of historical bias in the data, which may vary across real-world applications.
- The claim that AdOpt "significantly outperforms" baselines is supported by synthetic benchmarks but lacks external validation on truly unseen domains.

## Confidence
- High: The core mechanism of using adversarial training to learn a domain-invariant representation is theoretically sound and has precedent in domain adaptation literature.
- Medium: The empirical results showing reduced regret and improved fairness are convincing within the tested datasets but may not generalize to all selective-label problems.
- Low: The assumption that the de-biased classifier's optimism will consistently mitigate self-reinforcing bias across diverse data distributions is not yet validated.

## Next Checks
1. Implement a sensitivity analysis on the number of adversarial training epochs to quantify the trade-off between de-biasing quality and computational efficiency.
2. Test AdOpt on a new selective-label dataset with known bias patterns to assess generalizability beyond the four benchmark datasets.
3. Conduct an ablation study isolating the impact of the pseudo-label optimism step versus the adversarial de-biasing step on final regret and fairness metrics.