---
ver: rpa2
title: Zero-Shot Robustification of Zero-Shot Models
arxiv_id: '2309.04344'
source_url: https://arxiv.org/abs/2309.04344
tags:
- insight
- harmful
- shot
- zero-shot
- helpful
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ROBO SHOT, a zero-shot approach to improve
  the robustness of zero-shot models against inherited biases. The method extracts
  insights from language models about harmful and helpful concepts and uses them to
  modify the input embeddings by removing harmful components and amplifying helpful
  ones.
---

# Zero-Shot Robustification of Zero-Shot Models

## Quick Facts
- arXiv ID: 2309.04344
- Source URL: https://arxiv.org/abs/2309.04344
- Authors: 
- Reference count: 40
- Primary result: ROBO SHOT improves worst-group accuracy by 15.98% on average across nine tasks while minimally impacting overall accuracy.

## Executive Summary
This paper introduces ROBO SHOT, a novel zero-shot approach to improve the robustness of zero-shot models against inherited biases. The method extracts insights from language models about harmful and helpful concepts for a given task and uses them to modify input embeddings by removing harmful components and amplifying helpful ones. ROBO SHOT achieves significant improvements in worst-group accuracy across diverse image and NLP classification tasks while maintaining overall performance, offering a promising direction for robust zero-shot learning without requiring labeled data or model fine-tuning.

## Method Summary
ROBO SHOT works by first querying a language model with task descriptions to obtain positive (helpful) and negative (harmful) insights. These insights are embedded and used to identify harmful and helpful subspaces in the zero-shot model's latent space. The input embeddings are then modified by removing harmful components through vector rejection and amplifying helpful components. This process shifts embeddings away from decision boundaries influenced by spurious correlations, improving robustness to distribution shifts. The approach is theoretically grounded with a simple model of biases in zero-shot embeddings and empirically validated across nine diverse classification tasks.

## Key Results
- ROBO SHOT achieves an average improvement of 15.98% on worst-group accuracy across nine image and NLP classification tasks.
- The method maintains minimal decrease in overall accuracy compared to zero-shot baselines.
- ROBO SHOT is compatible with various pretrained zero-shot models (CLIP, ALIGN, AltCLIP) and language models (ChatGPT, Flan-T5, GPT2, LLaMA).

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language models contain actionable insights that can be used to improve zero-shot model robustness without labeled data or fine-tuning.
- Mechanism: ROBO SHOT queries language models with task descriptions to obtain positive and negative insights, which are embedded and used to identify harmful and helpful subspaces in the zero-shot model's latent space. The input embeddings are then modified to remove harmful components and amplify helpful ones.
- Core assumption: Zero-shot models' latent spaces can be decomposed into harmful, helpful, and benign subspaces, and language models can identify these components through task descriptions.
- Evidence anchors:
  - [abstract] "First, we use language models (LMs) to obtain useful insights from task descriptions. These insights are embedded and used to remove harmful and boost useful components in embeddings—without any supervision."
  - [section] "Using just the task description, ROBO SHOT obtains positive and negative insights from a language model... It uses embeddings of these noisy insights to recover harmful, beneficial, and benign subspaces of zero-shot latent representation spaces."
- Break condition: If language models cannot provide useful insights about harmful/helpful concepts for a task, or if the zero-shot model's latent space cannot be meaningfully decomposed into these subspaces.

### Mechanism 2
- Claim: Removing harmful components and boosting helpful components in embeddings can correct zero-shot classification errors caused by spurious correlations.
- Mechanism: ROBO SHOT uses vector rejection to remove harmful components from input embeddings and amplification to boost helpful components. This shifts embeddings away from decision boundaries influenced by spurious correlations.
- Core assumption: Spurious correlations manifest as harmful components in embeddings that can be identified and removed, and helpful components can be amplified to improve classification.
- Evidence anchors:
  - [abstract] "Representations are then modified to neutralize and emphasize their harmful and beneficial components, respectively."
  - [section] "ROBO SHOT applies simple vector rejection to mitigate or remove harmful components... Similarly, it boosts helpful components."
- Break condition: If harmful and helpful components are too entangled in the embedding space, or if removing harmful components also removes useful information.

### Mechanism 3
- Claim: The amount of improvement from ROBO SHOT depends on the severity of harmful correlations and the quality of insights obtained from language models.
- Mechanism: The theoretical model shows that the post-ROBO SHOT coefficient for harmful concepts scales down at a rate inversely proportional to the harmful coefficients of insight embeddings, and the helpful coefficients scale up inversely proportional to noise in insight embeddings.
- Core assumption: The zero-shot model's failure modes can be modeled as Gaussian noise in benign components and harmful/helpful components with varying signal-to-noise ratios.
- Evidence anchors:
  - [abstract] "Theoretically, we provide a simple and tractable model for biases in zero-shot embeddings and give a result characterizing under what conditions our approach can boost performance."
  - [section] "Theorem 4.1... implies the harmful coefficients decrease when the insight embeddings have less noise."
- Break condition: If harmful correlations are too severe relative to the signal in insight embeddings, or if the noise in insight embeddings is too high.

## Foundational Learning

- Concept: Vector rejection (orthogonal projection)
  - Why needed here: Core operation for removing harmful components from embeddings
  - Quick check question: Given vectors x and v, what is the formula for the component of x orthogonal to v?

- Concept: Cosine similarity and embedding spaces
  - Why needed here: Understanding how embeddings represent concepts and how similarity relates to classification
  - Quick check question: What does a high cosine similarity between two embeddings indicate about their relationship?

- Concept: Gaussian distributions and noise models
  - Why needed here: Theoretical analysis assumes Gaussian noise in embedding components
  - Quick check question: What are the mean and variance parameters of a Gaussian distribution?

## Architecture Onboarding

- Component map: Task description → Language model queries → Insight embeddings → Zero-shot model → Input embeddings → Modified embeddings → Robust predictions
- Critical path: Task description → LM queries → Insight embeddings → Embedding modification → Classification
- Design tradeoffs: Simpler than fine-tuning (no labeled data, no training) but potentially less powerful; relies on LM quality and task descriptiveness
- Failure signatures: Minimal improvement over baseline, degraded performance on some tasks, high variance in results
- First 3 experiments:
  1. Run ROBO SHOT on Waterbirds dataset with CLIP model - expect significant WG improvement
  2. Test with different LMs (ChatGPT, Flan-T5, GPT2) on same task - expect performance to correlate with LM quality
  3. Apply only harmful removal vs only helpful boosting vs both - expect combined approach to perform best

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise relationship between the amount of noise in insight embeddings and the effectiveness of ROBO SHOT?
- Basis in paper: [explicit] The paper provides a theoretical analysis in Section 4, showing that the effectiveness of ROBO SHOT scales inversely with the noise rate in insight embeddings. However, the analysis is limited to a simplified model and does not fully characterize the relationship in real-world scenarios.
- Why unresolved: The paper's theoretical analysis is based on a simplified model and does not fully capture the complexity of real-world data. Additionally, the experiments only test a limited range of noise levels.
- What evidence would resolve it: A comprehensive empirical study testing ROBO SHOT's effectiveness across a wide range of noise levels in insight embeddings, using various datasets and models.

### Open Question 2
- Question: How does ROBO SHOT perform when applied to zero-shot models with different architectures and training objectives?
- Basis in paper: [inferred] The paper demonstrates ROBO SHOT's effectiveness on various multimodal and language models, but the analysis is limited to a specific set of models and tasks.
- Why unresolved: The paper's experiments are limited to a specific set of models and tasks, and it is unclear how ROBO SHOT would perform on other architectures or with different training objectives.
- What evidence would resolve it: Extensive experiments testing ROBO SHOT on a wide range of zero-shot models with different architectures and training objectives, using various datasets and tasks.

### Open Question 3
- Question: Can ROBO SHOT be used to improve the robustness of zero-shot models against other types of biases beyond spurious correlations?
- Basis in paper: [inferred] The paper focuses on improving robustness against spurious correlations, but it is unclear whether ROBO SHOT can be adapted to address other types of biases, such as fairness-related biases.
- Why unresolved: The paper's analysis and experiments are limited to spurious correlations, and it is unclear whether the method can be extended to other types of biases.
- What evidence would resolve it: Experiments testing ROBO SHOT's effectiveness in improving robustness against various types of biases, including fairness-related biases, using diverse datasets and tasks.

## Limitations

- The method relies heavily on the quality and relevance of language model insights, which may not generalize well across diverse tasks or domains.
- The theoretical analysis makes simplifying assumptions about Gaussian noise and linear subspaces that may not hold in real-world zero-shot models.
- The empirical evaluation focuses on specific datasets with known spurious correlations, leaving performance on other types of biases or distribution shifts unclear.

## Confidence

- High Confidence: The core algorithmic approach of using language model insights to modify embeddings is well-specified and reproducible. The implementation details for vector rejection and amplification are clearly described.
- Medium Confidence: The theoretical analysis provides a useful framework for understanding ROBO SHOT's behavior, but its assumptions may not fully capture real-world complexities. The empirical results show promising improvements, but the evaluation scope is limited to specific datasets.
- Low Confidence: The generalizability of ROBO SHOT to diverse tasks and domains is uncertain. The method's reliance on language model quality introduces significant variability in performance.

## Next Checks

1. Cross-Domain Evaluation: Test ROBO SHOT on datasets from diverse domains (e.g., medical imaging, satellite imagery) to assess its generalizability beyond the current evaluation set.

2. Language Model Sensitivity Analysis: Systematically vary the language models used for insight extraction and measure the impact on ROBO SHOT's performance to quantify its dependence on LM quality.

3. Real-World Deployment Simulation: Create a simulated deployment environment with streaming data and evolving distribution shifts to evaluate ROBO SHOT's robustness over time and its ability to handle unknown biases.