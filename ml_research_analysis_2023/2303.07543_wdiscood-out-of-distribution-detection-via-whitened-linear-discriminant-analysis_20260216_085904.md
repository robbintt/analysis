---
ver: rpa2
title: 'WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminant Analysis'
arxiv_id: '2303.07543'
source_url: https://arxiv.org/abs/2303.07543
tags:
- space
- data
- detection
- feature
- classi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes WDiscOOD, a method for out-of-distribution
  (OOD) detection in deep neural networks. The core idea is to project features into
  two subspaces using Whitened Linear Discriminant Analysis: a discriminative subspace
  where in-distribution (ID) classes are maximally separated, and a residual subspace
  where ID classes are closely clustered.'
---

# WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminant Analysis

## Quick Facts
- arXiv ID: 2303.07543
- Source URL: https://arxiv.org/abs/2303.07543
- Reference count: 40
- Primary result: Achieves 87.23% average AUROC on ResNet-50 and 94.44% on ViT-B/16 for OOD detection on ImageNet-1k benchmark

## Executive Summary
This paper proposes WDiscOOD, a method for out-of-distribution detection that uses Whitened Linear Discriminant Analysis (WLDA) to project features into two subspaces: a discriminative subspace where in-distribution classes are maximally separated, and a residual subspace where they are closely clustered. OOD samples are detected by measuring deviations from ID patterns in both subspaces. The method is evaluated on the large-scale ImageNet-1k benchmark with six diverse OOD datasets, showing superior performance over existing methods on both CNN and vision transformer architectures.

## Method Summary
WDiscOOD applies Whitened Linear Discriminant Analysis to project image features into two complementary subspaces. The discriminative subspace (WD) maximizes separation between in-distribution classes, while the residual subspace (WDR) clusters them closely. OOD detection is performed by computing distances in both subspaces - the distance to nearest class centroid in WD space and distance to dataset centroid in WDR space - and combining them into a final score. The method requires computing within-class and between-class scatter matrices, applying whitening transformations, and performing eigenvalue decomposition to obtain the projection matrices.

## Key Results
- Achieves 87.23% average AUROC on ResNet-50 and 94.44% on ViT-B/16 for OOD detection
- Outperforms existing methods including MSP, Energy, ODIN, Mahalanobis, and KNN
- Shows superior performance on contrastive visual encoders like SupCon and CLIP
- The Whitened Discriminative Residual Subspace is particularly effective for OOD detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Whitened Linear Discriminant Analysis (WLDA) disentangles discriminative and residual information in the feature space, improving OOD detection.
- Mechanism: WLDA projects features into two subspaces: the discriminative subspace (WD) where in-distribution (ID) classes are maximally separated, and the residual subspace (WDR) where ID classes are closely clustered. OOD samples are detected by measuring deviations from ID patterns in both subspaces.
- Core assumption: The residual subspace captures shared information among ID classes that is distinct from OOD samples.
- Evidence anchors:
  - [abstract] "Specifically, our approach utilizes Whitened Linear Discriminative Anaysis to project features into two subspaces - the discriminative and residual subspaces - in which the ID classes are maximally separated and closely clustered, respectively."
  - [section] "We utilize Whitened Linear Discriminative Analysis (WLDA) to project visual features into two subspaces: a discriminative subspace and a residual subspace."
  - [corpus] Weak corpus evidence; only general OOD detection papers found, none specifically discussing WLDA subspaces.
- Break condition: If OOD samples share similar residual patterns with ID classes, the WDR space becomes less effective at distinguishing them.

### Mechanism 2
- Claim: Combining class-specific and class-agnostic information improves OOD detection performance.
- Mechanism: The method computes a weighted sum of distances in both subspaces: distance to nearest class centroid in WD space and distance to dataset centroid in WDR space. This combines discriminative and residual information for OOD detection.
- Core assumption: Both discriminative and residual information contribute complementary signals for OOD detection.
- Evidence anchors:
  - [abstract] "The OOD score is then determined by combining the deviation from the input data to the ID pattern in both subspaces."
  - [section] "The final proposed scoring function unifies the information from both subspaces by computing a weighted sum of the scores in each space."
  - [corpus] Weak corpus evidence; no direct support for this specific combination approach.
- Break condition: If one subspace dominates the other, the weighted sum may not optimally combine the information.

### Mechanism 3
- Claim: Data whitening before LDA improves numerical conditioning and feature decorrelation, enhancing OOD detection.
- Mechanism: The feature is whitened using within-class covariance matrix before LDA, eliminating correlation between feature elements and improving numerical conditioning.
- Core assumption: Decorrelated features improve LDA's ability to separate discriminative and residual information.
- Evidence anchors:
  - [section] "We begin by whitening the feature prior to conducting LDA. The application of whitened LDA has been extensively studied and implemented across various domains."
  - [section] "Data whitening eliminates the correlation between feature elements and enhances the feature's capability to encode data similarity."
  - [corpus] Weak corpus evidence; whitening is mentioned in general ML contexts but not specifically for OOD detection.
- Break condition: If whitening over-normalizes features, it may remove important discriminative information.

## Foundational Learning

- Concept: Linear Discriminant Analysis (LDA)
  - Why needed here: LDA is the core technique for projecting features into discriminative and residual subspaces.
  - Quick check question: What is the objective of LDA and how does it achieve this through scatter matrices?

- Concept: Principal Component Analysis (PCA)
  - Why needed here: Understanding PCA helps contrast it with LDA and understand why LDA is better suited for OOD detection.
  - Quick check question: How does LDA differ from PCA in terms of what it optimizes for?

- Concept: Feature whitening
  - Why needed here: Whitening is applied before LDA to improve numerical conditioning and decorrelate features.
  - Quick check question: What is the mathematical operation of whitening and how does it affect feature covariance?

## Architecture Onboarding

- Component map:
  - Image features from penultimate layer → Whitening transformation → LDA projection → WD and WDR subspaces → Distance computation → Score combination

- Critical path:
  - Feature extraction → Whitening → LDA projection → Distance computation → Score combination

- Design tradeoffs:
  - More discriminants improve separation but increase computation
  - Whitening improves conditioning but may remove some information
  - Equal weighting of subspaces vs. learned weighting

- Failure signatures:
  - Poor OOD detection performance suggests subspaces not well-separated
  - Numerical instability in LDA suggests whitening parameters need tuning
  - OOD samples clustering with ID samples suggests insufficient discriminative information

- First 3 experiments:
  1. Test OOD detection performance with and without whitening to verify its impact
  2. Vary the number of discriminants and measure impact on OOD detection accuracy
  3. Test different weighting schemes for combining WD and WDR scores

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does WDiscOOD perform on other large-scale vision benchmarks beyond ImageNet-1k, such as COCO or LVIS?
- Basis in paper: [inferred] The paper demonstrates superior performance on ImageNet-1k but does not evaluate on other large-scale benchmarks.
- Why unresolved: The paper focuses on ImageNet-1k as the primary benchmark, leaving performance on other datasets unexplored.
- What evidence would resolve it: Testing WDiscOOD on COCO, LVIS, or other large-scale datasets with diverse OOD evaluation would provide insights into its generalizability.

### Open Question 2
- Question: Can WDiscOOD be adapted for real-time or resource-constrained applications where computational efficiency is critical?
- Basis in paper: [inferred] The paper does not discuss computational efficiency or real-time applicability of WDiscOOD.
- Why unresolved: While the method shows strong performance, its computational requirements for subspace projections and distance calculations are not addressed.
- What evidence would resolve it: Benchmarking WDiscOOD's runtime and memory usage on edge devices or in streaming scenarios would clarify its practical deployment potential.

### Open Question 3
- Question: How does WDiscOOD handle OOD detection in multi-modal or video data, where temporal or cross-modal relationships are important?
- Basis in paper: [inferred] The paper focuses on static image data and does not explore multi-modal or video applications.
- Why unresolved: The method is designed for image feature spaces, but its extension to sequential or multi-modal data remains unexplored.
- What evidence would resolve it: Evaluating WDiscOOD on video datasets or multi-modal tasks (e.g., image-text pairs) would test its adaptability to richer data structures.

## Limitations

- The method assumes OOD samples can be distinguished through residual patterns in whitened LDA space, which may not hold for OOD datasets sharing structural characteristics with ID classes
- Performance shows variability across different OOD datasets, with the residual subspace being less effective for some datasets like Places and OpenImage-O
- Computational overhead from whitening and LDA projection steps may limit scalability for very large datasets or real-time applications

## Confidence

- High confidence: The core mechanism of using whitened LDA to create discriminative and residual subspaces is theoretically sound and well-supported by the mathematical formulation.
- Medium confidence: The empirical results showing superior performance on benchmark datasets are convincing but require independent replication.
- Medium confidence: The claim that the residual subspace is particularly effective for OOD detection needs more extensive validation across diverse OOD datasets.

## Next Checks

1. **Ablation study on whitening**: Test OOD detection performance with and without the whitening step to quantify its contribution to overall performance, as this component is critical but its specific impact is not clearly isolated in the current results.

2. **Cross-dataset generalization**: Evaluate the method on additional OOD datasets that share different levels of semantic similarity with ImageNet-1k to better understand the limits of the residual subspace approach.

3. **Computational efficiency analysis**: Measure the exact computational overhead introduced by the whitening and LDA projection steps and assess whether the performance gains justify the additional computation, particularly for real-time applications.