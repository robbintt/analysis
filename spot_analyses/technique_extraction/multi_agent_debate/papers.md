- [2402.03578](https://arxiv.org/abs/2402.03578): [LLM Multi-Agent Systems: Challenges and Open Problems](../../../ml_research_analysis_2025/2402.03578_llm-multi-agent-systems-challenges-and-open-problems_20260209_013233.md)
- [2409.14051](https://arxiv.org/abs/2409.14051): [GroupDebate: Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion](../../../ml_research_analysis_2025/2409.14051_groupdebate-enhancing-the-efficiency-of-multi-agent-debate-using-group-discussion_20260210_232428.md)
- [2502.01344](https://arxiv.org/abs/2502.01344): [PSSD: Making Large Language Models Self-denial via Human Psyche Structure](../../../ml_research_analysis_2025/2502.01344_pssd-making-large-language-models-self-denial-via-human-psyche-structure_20260210_164545.md)
- [2502.01477](https://arxiv.org/abs/2502.01477): [Achieving Time Series Reasoning Requires Rethinking Model Design, Tasks Formulation, and Evaluation](../../../ml_research_analysis_2025/2502.01477_achieving-time-series-reasoning-requires-rethinking-model-design-tasks-formulation-and-evaluation_20260210_170742.md)
- [2502.08514](https://arxiv.org/abs/2502.08514): [Faithful, Unfaithful or Ambiguous? Multi-Agent Debate with Initial Stance for Summary Evaluation](../../../ml_research_analysis_2025/2502.08514_faithful-unfaithful-or-ambiguous-multi-agent-debate-with-initial-stance-for-summary-evaluation_20260210_095102.md)
- [2502.08916](https://arxiv.org/abs/2502.08916): [PathFinder: A Multi-Modal Multi-Agent System for Medical Diagnostic Decision-Making Applied to Histopathology](../../../ml_research_analysis_2025/2502.08916_pathfinder-a-multi-modal-multi-agent-system-for-medical-diagnostic-decision-making-applied-to-histopathology_20260211_011208.md)
- [2502.12995](https://arxiv.org/abs/2502.12995): [Free Argumentative Exchanges for Explaining Image Classifiers](../../../ml_research_analysis_2025/2502.12995_free-argumentative-exchanges-for-explaining-image-classifiers_20260210_084037.md)
- [2502.13164](https://arxiv.org/abs/2502.13164): [Multi-Agent Actor-Critic Generative AI for Query Resolution and Analysis](../../../ml_research_analysis_2025/2502.13164_multi-agent-actor-critic-generative-ai-for-query-resolution-and-analysis_20260210_125333.md)
- [2502.18531](https://arxiv.org/abs/2502.18531): [Enhancing Hepatopathy Clinical Trial Efficiency: A Secure, Large Language Model-Powered Pre-Screening Pipeline](../../../ml_research_analysis_2025/2502.18531_enhancing-hepatopathy-clinical-trial-efficiency-a-secure-large-language-model-powered-pre-screening-pipeline_20260211_011105.md)
- [2502.18864](https://arxiv.org/abs/2502.18864): [Towards an AI co-scientist](../../../ml_research_analysis_2025/2502.18864_towards-an-ai-co-scientist_20260210_120459.md)
- [2503.05977](https://arxiv.org/abs/2503.05977): [Is Your Video Language Model a Reliable Judge?](../../../ml_research_analysis_2025/2503.05977_is-your-video-language-model-a-reliable-judge_20260210_231832.md)
- [2503.13169](https://arxiv.org/abs/2503.13169): [Collaborative AI Enhances Image Understanding in Materials Science](../../../ml_research_analysis_2025/2503.13169_collaborative-ai-enhances-image-understanding-in-materials-science_20260211_000931.md)
- [2503.15272](https://arxiv.org/abs/2503.15272): [MAMM-Refine: A Recipe for Improving Faithfulness in Generation with Multi-Agent Collaboration](../../../ml_research_analysis_2025/2503.15272_mamm-refine-a-recipe-for-improving-faithfulness-in-generation-with-multi-agent-collaboration_20260210_204405.md)
- [2503.22038](https://arxiv.org/abs/2503.22038): [Debate-Driven Multi-Agent LLMs for Phishing Email Detection](../../../ml_research_analysis_2025/2503.22038_debate-driven-multi-agent-llms-for-phishing-email-detection_20260211_011610.md)
- [2503.23673](https://arxiv.org/abs/2503.23673): [WHERE and WHICH: Iterative Debate for Biomedical Synthetic Data Augmentation](../../../ml_research_analysis_2025/2503.23673_where-and-which-iterative-debate-for-biomedical-synthetic-data-augmentation_20260210_150022.md)
- [2504.00374](https://arxiv.org/abs/2504.00374): [When Persuasion Overrides Truth in Multi-Agent LLM Debates: Introducing a Confidence-Weighted Persuasion Override Rate (CW-POR)](../../../ml_research_analysis_2025/2504.00374_when-persuasion-overrides-truth-in-multi-agent-llm-debates-introducing-a-confidence-weighted-persuasion-override-rate-cw-por_20260211_005428.md)
- [2504.02128](https://arxiv.org/abs/2504.02128): [Achieving Unanimous Consensus in Decision Making Using Multi-Agents](../../../ml_research_analysis_2025/2504.02128_achieving-unanimous-consensus-in-decision-making-using-multi-agents_20260211_010501.md)
- [2504.04855](https://arxiv.org/abs/2504.04855): [BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents](../../../ml_research_analysis_2025/2504.04855_biasinspector-detecting-bias-in-structured-data-through-llm-agents_20260209_162217.md)
- [2504.05358](https://arxiv.org/abs/2504.05358): [Debate-Feedback: A Multi-Agent Framework for Efficient Legal Judgment Prediction](../../../ml_research_analysis_2025/2504.05358_debate-feedback-a-multi-agent-framework-for-efficient-legal-judgment-prediction_20260210_122538.md)
- [2504.12735](https://arxiv.org/abs/2504.12735): [The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent Systems](../../../ml_research_analysis_2025/2504.12735_the-athenian-academy-a-seven-layer-architecture-model-for-multi-agent-systems_20260209_231031.md)
- [2505.00981](https://arxiv.org/abs/2505.00981): [Multi-agents based User Values Mining for Recommendation](../../../ml_research_analysis_2025/2505.00981_multi-agents-based-user-values-mining-for-recommendation_20260210_171011.md)
- [2505.11811](https://arxiv.org/abs/2505.11811): [BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering](../../../ml_research_analysis_2025/2505.11811_belle-a-bi-level-multi-agent-reasoning-framework-for-multi-hop-question-answering_20260210_001741.md)
- [2505.14886](https://arxiv.org/abs/2505.14886): [Strategic Planning and Rationalizing on Trees Make LLMs Better Debaters](../../../ml_research_analysis_2025/2505.14886_strategic-planning-and-rationalizing-on-trees-make-llms-better-debaters_20260211_033019.md)
- [2505.14996](https://arxiv.org/abs/2505.14996): [MAS-ZERO: Designing Multi-Agent Systems with Zero Supervision](../../../ml_research_analysis_2025/2505.14996_mas-zero-designing-multi-agent-systems-with-zero-supervision_20260210_050132.md)
- [2505.16477](https://arxiv.org/abs/2505.16477): [Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery](../../../ml_research_analysis_2025/2505.16477_advancing-the-scientific-method-with-large-language-models-from-hypothesis-to-discovery_20260210_085324.md)
- [2505.17492](https://arxiv.org/abs/2505.17492): [PD$^3$: A Project Duplication Detection Framework via Adapted Multi-Agent Debate](../../../ml_research_analysis_2025/2505.17492_pd-3-a-project-duplication-detection-framework-via-adapted-multi-agent-debate_20260211_084030.md)
- [2505.18581](https://arxiv.org/abs/2505.18581): [Removal of Hallucination on Hallucination: Debate-Augmented RAG](../../../ml_research_analysis_2025/2505.18581_removal-of-hallucination-on-hallucination-debate-augmented-rag_20260210_004218.md)
- [2505.21503](https://arxiv.org/abs/2505.21503): [Silence is Not Consensus: Disrupting Agreement Bias in Multi-Agent LLMs via Catfish Agent for Clinical Decision Making](../../../ml_research_analysis_2025/2505.21503_silence-is-not-consensus-disrupting-agreement-bias-in-multi-agent-llms-via-catfish-agent-for-clinical-decision-making_20260210_153826.md)
- [2505.21784](https://arxiv.org/abs/2505.21784): [Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation](../../../ml_research_analysis_2025/2505.21784_towards-safety-reasoning-in-llms-ai-agentic-deliberation-for-policy-embedded-cot-data-creation_20260208_114813.md)
- [2505.22846](https://arxiv.org/abs/2505.22846): [RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation](../../../ml_research_analysis_2025/2505.22846_rocqstar-leveraging-similarity-driven-retrieval-and-agentic-systems-for-rocq-generation_20260210_162808.md)
- [2505.23559](https://arxiv.org/abs/2505.23559): [SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents](../../../ml_research_analysis_2025/2505.23559_safescientist-toward-risk-aware-scientific-discoveries-by-llm-agents_20260208_185732.md)
- [2506.00549](https://arxiv.org/abs/2506.00549): [Towards Multi-dimensional Evaluation of LLM Summarization across Domains and Languages](../../../ml_research_analysis_2025/2506.00549_towards-multi-dimensional-evaluation-of-llm-summarization-across-domains-and-languages_20260210_022649.md)
- [2506.02689](https://arxiv.org/abs/2506.02689): [MASTER: Enhancing Large Language Model via Multi-Agent Simulated Teaching](../../../ml_research_analysis_2025/2506.02689_master-enhancing-large-language-model-via-multi-agent-simulated-teaching_20260210_004504.md)
- [2506.03541](https://arxiv.org/abs/2506.03541): [Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement](../../../ml_research_analysis_2025/2506.03541_debate-reflect-and-distill-multi-agent-feedback-with-tree-structured-preference-optimization-for-efficient-language-model-enhancement_20260211_091930.md)
- [2506.05213](https://arxiv.org/abs/2506.05213): [LLM-First Search: Self-Guided Exploration of the Solution Space](../../../ml_research_analysis_2025/2506.05213_llm-first-search-self-guided-exploration-of-the-solution-space_20260208_134312.md)
- [2506.06020](https://arxiv.org/abs/2506.06020): [When to Trust Context: Self-Reflective Debates for Context Reliability](../../../ml_research_analysis_2025/2506.06020_when-to-trust-context-self-reflective-debates-for-context-reliability_20260211_025720.md)
- [2506.06800](https://arxiv.org/abs/2506.06800): [On the Adaptive Psychological Persuasion of Large Language Models](../../../ml_research_analysis_2025/2506.06800_on-the-adaptive-psychological-persuasion-of-large-language-models_20260210_121511.md)
- [2506.06910](https://arxiv.org/abs/2506.06910): [Causal Graph based Event Reasoning using Semantic Relation Experts](../../../ml_research_analysis_2025/2506.06910_causal-graph-based-event-reasoning-using-semantic-relation-experts_20260208_235127.md)
- [2506.08292](https://arxiv.org/abs/2506.08292): [From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium](../../../ml_research_analysis_2025/2506.08292_from-debate-to-equilibrium-belief-driven-multi-agent-llm-reasoning-via-bayesian-nash-equilibrium_20260210_055251.md)
- [2506.11825](https://arxiv.org/abs/2506.11825): [Revealing Political Bias in LLMs through Structured Multi-Agent Debate](../../../ml_research_analysis_2025/2506.11825_revealing-political-bias-in-llms-through-structured-multi-agent-debate_20260211_000822.md)
- [2506.12657](https://arxiv.org/abs/2506.12657): [Synthetic Socratic Debates: Examining Persona Effects on Moral Decision and Persuasion Dynamics](../../../ml_research_analysis_2025/2506.12657_synthetic-socratic-debates-examining-persona-effects-on-moral-decision-and-persuasion-dynamics_20260211_004203.md)
- [2506.12699](https://arxiv.org/abs/2506.12699): [SoK: The Privacy Paradox of Large Language Models: Advancements, Privacy Risks, and Mitigation](../../../ml_research_analysis_2025/2506.12699_sok-the-privacy-paradox-of-large-language-models-advancements-privacy-risks-and-mitigation_20260210_024517.md)
- [2506.18102](https://arxiv.org/abs/2506.18102): [InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating](../../../ml_research_analysis_2025/2506.18102_inspiredebate-multi-dimensional-subjective-objective-evaluation-guided-reasoning-and-optimization-for-debating_20260211_040211.md)
- [2506.18424](https://arxiv.org/abs/2506.18424): [A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction](../../../ml_research_analysis_2025/2506.18424_a-large-language-model-based-multi-agent-framework-for-analog-circuits-sizing-relationships-extraction_20260210_031447.md)
- [2506.22653](https://arxiv.org/abs/2506.22653): [URSA: The Universal Research and Scientific Agent](../../../ml_research_analysis_2025/2506.22653_ursa-the-universal-research-and-scientific-agent_20260210_070603.md)
- [2507.03928](https://arxiv.org/abs/2507.03928): [CortexDebate: Debating Sparsely and Equally for Multi-Agent Debate](../../../ml_research_analysis_2025/2507.03928_cortexdebate-debating-sparsely-and-equally-for-multi-agent-debate_20260211_001619.md)
- [2507.05755](https://arxiv.org/abs/2507.05755): [An autonomous agent for auditing and improving the reliability of clinical AI models](../../../ml_research_analysis_2025/2507.05755_an-autonomous-agent-for-auditing-and-improving-the-reliability-of-clinical-ai-models_20260210_231215.md)
- [2507.06980](https://arxiv.org/abs/2507.06980): [Are They All Good? Evaluating the Quality of CoTs in LLM-based Code Generation](../../../ml_research_analysis_2025/2507.06980_are-they-all-good-evaluating-the-quality-of-cots-in-llm-based-code-generation_20260210_013012.md)
- [2507.08664](https://arxiv.org/abs/2507.08664): [Introspection of Thought Helps AI Agents](../../../ml_research_analysis_2025/2507.08664_introspection-of-thought-helps-ai-agents_20260210_142515.md)
- [2507.09174](https://arxiv.org/abs/2507.09174): [RAMA: Retrieval-Augmented Multi-Agent Framework for Misinformation Detection in Multimodal Fact-Checking](../../../ml_research_analysis_2025/2507.09174_rama-retrieval-augmented-multi-agent-framework-for-misinformation-detection-in-multimodal-fact-checking_20260210_232045.md)
- [2507.11198](https://arxiv.org/abs/2507.11198): [Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding](../../../ml_research_analysis_2025/2507.11198_temperature-and-persona-shape-llm-agent-consensus-with-minimal-accuracy-gains-in-qualitative-coding_20260210_234523.md)
- [2507.12370](https://arxiv.org/abs/2507.12370): [Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate](../../../ml_research_analysis_2025/2507.12370_beyond-single-models-enhancing-llm-detection-of-ambiguity-in-requests-through-debate_20260210_123329.md)
- [2507.14306](https://arxiv.org/abs/2507.14306): [Manimator: Transforming Research Papers into Visual Explanations](../../../ml_research_analysis_2025/2507.14306_manimator-transforming-research-papers-into-visual-explanations_20260210_232917.md)
- [2507.19090](https://arxiv.org/abs/2507.19090): [Debating Truth: Debate-driven Claim Verification with Multiple Large Language Model Agents](../../../ml_research_analysis_2025/2507.19090_debating-truth-debate-driven-claim-verification-with-multiple-large-language-model-agents_20260211_010610.md)
- [2507.21028](https://arxiv.org/abs/2507.21028): [Multi-Agent-as-Judge: Aligning LLM-Agent-Based Automated Evaluation with Multi-Dimensional Human Evaluation](../../../ml_research_analysis_2025/2507.21028_multi-agent-as-judge-aligning-llm-agent-based-automated-evaluation-with-multi-dimensional-human-evaluation_20260208_134411.md)
- [2508.02584](https://arxiv.org/abs/2508.02584): [MArgE: Meshing Argumentative Evidence from Multiple Large Language Models for Justifiable Claim Verification](../../../ml_research_analysis_2025/2508.02584_marge-meshing-argumentative-evidence-from-multiple-large-language-models-for-justifiable-claim-verification_20260210_233158.md)
- [2508.02994](https://arxiv.org/abs/2508.02994): [When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs](../../../ml_research_analysis_2025/2508.02994_when-ais-judge-ais-the-rise-of-agent-as-a-judge-evaluation-for-llms_20260210_145125.md)
- [2508.04032](https://arxiv.org/abs/2508.04032): [Enhancing Serendipity Recommendation System by Constructing Dynamic User Knowledge Graphs with Large Language Models](../../../ml_research_analysis_2025/2508.04032_enhancing-serendipity-recommendation-system-by-constructing-dynamic-user-knowledge-graphs-with-large-language-models_20260210_154851.md)
- [2508.06110](https://arxiv.org/abs/2508.06110): [PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion](../../../ml_research_analysis_2025/2508.06110_paneltr-zero-shot-table-reasoning-framework-through-multi-agent-scientific-discussion_20260211_004940.md)
- [2508.07671](https://arxiv.org/abs/2508.07671): [EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration](../../../ml_research_analysis_2025/2508.07671_empathia-multi-faceted-human-ai-collaboration-for-refugee-integration_20260210_234240.md)
- [2508.08115](https://arxiv.org/abs/2508.08115): [TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork](../../../ml_research_analysis_2025/2508.08115_teammedagents-enhancing-medical-decision-making-of-llms-through-structured-teamwork_20260210_142710.md)
- [2508.08265](https://arxiv.org/abs/2508.08265): [TurQUaz at CheckThat! 2025: Debating Large Language Models for Scientific Web Discourse Detection](../../../ml_research_analysis_2025/2508.08265_turquaz-at-checkthat-2025-debating-large-language-models-for-scientific-web-discourse-detection_20260210_160656.md)
- [2508.11933](https://arxiv.org/abs/2508.11933): [CAMF: Collaborative Adversarial Multi-agent Framework for Machine Generated Text Detection](../../../ml_research_analysis_2025/2508.11933_camf-collaborative-adversarial-multi-agent-framework-for-machine-generated-text-detection_20260210_170830.md)
- [2508.13743](https://arxiv.org/abs/2508.13743): [Sycophancy under Pressure: Evaluating and Mitigating Sycophantic Bias via Adversarial Dialogues in Scientific QA](../../../ml_research_analysis_2025/2508.13743_sycophancy-under-pressure-evaluating-and-mitigating-sycophantic-bias-via-adversarial-dialogues-in-scientific-qa_20260211_001619.md)
- [2508.21720](https://arxiv.org/abs/2508.21720): [PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation](../../../ml_research_analysis_2025/2508.21720_posterforest-hierarchical-multi-agent-collaboration-for-scientific-poster-generation_20260211_022700.md)
- [2509.01277](https://arxiv.org/abs/2509.01277): [Communicative Agents for Slideshow Storytelling Video Generation based on LLMs](../../../ml_research_analysis_2025/2509.01277_communicative-agents-for-slideshow-storytelling-video-generation-based-on-llms_20260210_024409.md)
- [2509.01412](https://arxiv.org/abs/2509.01412): [Vis-CoT: A Human-in-the-Loop Framework for Interactive Visualization and Intervention in LLM Chain-of-Thought Reasoning](../../../ml_research_analysis_2025/2509.01412_vis-cot-a-human-in-the-loop-framework-for-interactive-visualization-and-intervention-in-llm-chain-of-thought-reasoning_20260210_041243.md)
- [2509.03793](https://arxiv.org/abs/2509.03793): [SAMVAD: A Multi-Agent System for Simulating Judicial Deliberation Dynamics in India](../../../ml_research_analysis_2025/2509.03793_samvad-a-multi-agent-system-for-simulating-judicial-deliberation-dynamics-in-india_20260210_231313.md)
- [2509.07022](https://arxiv.org/abs/2509.07022): [Preventing Another Tessa: Modular Safety Middleware For Health-Adjacent AI Assistants](../../../ml_research_analysis_2025/2509.07022_preventing-another-tessa-modular-safety-middleware-for-health-adjacent-ai-assistants_20260208_114807.md)
- [2509.08016](https://arxiv.org/abs/2509.08016): [Video Parallel Scaling: Aggregating Diverse Frame Subsets for VideoLLMs](../../../ml_research_analysis_2025/2509.08016_video-parallel-scaling-aggregating-diverse-frame-subsets-for-videollms_20260210_130812.md)
- [2509.11035](https://arxiv.org/abs/2509.11035): [Free-MAD: Consensus-Free Multi-Agent Debate](../../../ml_research_analysis_2025/2509.11035_free-mad-consensus-free-multi-agent-debate_20260210_152108.md)
- [2509.11656](https://arxiv.org/abs/2509.11656): [MALLM: Multi-Agent Large Language Models Framework](../../../ml_research_analysis_2025/2509.11656_mallm-multi-agent-large-language-models-framework_20260210_053121.md)
- [2509.13356](https://arxiv.org/abs/2509.13356): [CogniAlign: Survivability-Grounded Multi-Agent Moral Reasoning for Safe and Transparent AI](../../../ml_research_analysis_2025/2509.13356_cognialign-survivability-grounded-multi-agent-moral-reasoning-for-safe-and-transparent-ai_20260210_014401.md)
- [2509.14034](https://arxiv.org/abs/2509.14034): [Enhancing Multi-Agent Debate System Performance via Confidence Expression](../../../ml_research_analysis_2025/2509.14034_enhancing-multi-agent-debate-system-performance-via-confidence-expression_20260210_202123.md)
- [2509.14998](https://arxiv.org/abs/2509.14998): [A Knowledge-driven Adaptive Collaboration of LLMs for Enhancing Medical Decision-making](../../../ml_research_analysis_2025/2509.14998_a-knowledge-driven-adaptive-collaboration-of-llms-for-enhancing-medical-decision-making_20260210_202043.md)
- [2509.15172](https://arxiv.org/abs/2509.15172): [Self-Improvement of Language Models by Post-Training on Multi-Agent Debate](../../../ml_research_analysis_2025/2509.15172_self-improvement-of-language-models-by-post-training-on-multi-agent-debate_20260210_125621.md)
- [2509.15568](https://arxiv.org/abs/2509.15568): [LiteLong: Resource-Efficient Long-Context Data Synthesis for LLMs](../../../ml_research_analysis_2025/2509.15568_litelong-resource-efficient-long-context-data-synthesis-for-llms_20260210_100511.md)
- [2509.17395](https://arxiv.org/abs/2509.17395): [FinDebate: Multi-Agent Collaborative Intelligence for Financial Analysis](../../../ml_research_analysis_2025/2509.17395_findebate-multi-agent-collaborative-intelligence-for-financial-analysis_20260210_142507.md)
- [2509.20502](https://arxiv.org/abs/2509.20502): [MARS: toward more efficient multi-agent collaboration for LLM reasoning](../../../ml_research_analysis_2025/2509.20502_mars-toward-more-efficient-multi-agent-collaboration-for-llm-reasoning_20260210_143225.md)
- [2509.21129](https://arxiv.org/abs/2509.21129): [EvoMail: Self-Evolving Cognitive Agents for Adaptive Spam and Phishing Email Defense](../../../ml_research_analysis_2025/2509.21129_evomail-self-evolving-cognitive-agents-for-adaptive-spam-and-phishing-email-defense_20260211_002905.md)
- [2509.23055](https://arxiv.org/abs/2509.23055): [Peacemaker or Troublemaker: How Sycophancy Shapes Multi-Agent Debate](../../../ml_research_analysis_2025/2509.23055_peacemaker-or-troublemaker-how-sycophancy-shapes-multi-agent-debate_20260210_124939.md)
- [2509.23537](https://arxiv.org/abs/2509.23537): [Beyond the Strongest LLM: Multi-Turn Multi-Agent Orchestration vs. Single LLMs on Benchmarks](../../../ml_research_analysis_2025/2509.23537_beyond-the-strongest-llm-multi-turn-multi-agent-orchestration-vs-single-llms-on-benchmarks_20260210_060314.md)
- [2509.23768](https://arxiv.org/abs/2509.23768): [From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning](../../../ml_research_analysis_2025/2509.23768_from-what-to-why-a-multi-agent-system-for-evidence-based-chemical-reaction-condition-reasoning_20260210_181503.md)
- [2510.01279](https://arxiv.org/abs/2510.01279): [TUMIX: Multi-Agent Test-Time Scaling with Tool-Use Mixture](../../../ml_research_analysis_2025/2510.01279_tumix-multi-agent-test-time-scaling-with-tool-use-mixture_20260210_144812.md)
- [2510.01295](https://arxiv.org/abs/2510.01295): [The Social Laboratory: A Psychometric Framework for Multi-Agent LLM Evaluation](../../../ml_research_analysis_2025/2510.01295_the-social-laboratory-a-psychometric-framework-for-multi-agent-llm-evaluation_20260210_165131.md)
- [2510.03194](https://arxiv.org/abs/2510.03194): [CoDA: Agentic Systems for Collaborative Data Visualization](../../../ml_research_analysis_2025/2510.03194_coda-agentic-systems-for-collaborative-data-visualization_20260210_160406.md)
- [2510.04311](https://arxiv.org/abs/2510.04311): [On the Importance of Task Complexity in Evaluating LLM-Based Multi-Agent Systems](../../../ml_research_analysis_2025/2510.04311_on-the-importance-of-task-complexity-in-evaluating-llm-based-multi-agent-systems_20260208_130942.md)
- [2510.04488](https://arxiv.org/abs/2510.04488): [Multi-Agent Collaborative Intelligence: Dual-Dial Control for Reliable LLM Reasoning](../../../ml_research_analysis_2025/2510.04488_multi-agent-collaborative-intelligence-dual-dial-control-for-reliable-llm-reasoning_20260210_102509.md)
- [2510.05059](https://arxiv.org/abs/2510.05059): [Staircase Streaming for Low-Latency Multi-Agent Inference](../../../ml_research_analysis_2025/2510.05059_staircase-streaming-for-low-latency-multi-agent-inference_20260209_235325.md)
- [2510.05611](https://arxiv.org/abs/2510.05611): [MADIAVE: Multi-Agent Debate for Implicit Attribute Value Extraction](../../../ml_research_analysis_2025/2510.05611_madiave-multi-agent-debate-for-implicit-attribute-value-extraction_20260210_183512.md)
- [2510.05935](https://arxiv.org/abs/2510.05935): [LLM-FS-Agent: A Deliberative Role-based Large Language Model Architecture for Transparent Feature Selection](../../../ml_research_analysis_2025/2510.05935_llm-fs-agent-a-deliberative-role-based-large-language-model-architecture-for-transparent-feature-selection_20260208_130950.md)
- [2510.06843](https://arxiv.org/abs/2510.06843): [SID: Multi-LLM Debate Driven by Self Signals](../../../ml_research_analysis_2025/2510.06843_sid-multi-llm-debate-driven-by-self-signals_20260210_233306.md)
- [2510.07488](https://arxiv.org/abs/2510.07488): [Can Lessons From Human Teams Be Applied to Multi-Agent Systems? The Role of Structure, Diversity, and Interaction Dynamics](../../../ml_research_analysis_2025/2510.07488_can-lessons-from-human-teams-be-applied-to-multi-agent-systems-the-role-of-structure-diversity-and-interaction-dynamics_20260210_033337.md)
- [2510.09049](https://arxiv.org/abs/2510.09049): [MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction](../../../ml_research_analysis_2025/2510.09049_mec-3-o-multi-expert-consensus-for-code-time-complexity-prediction_20260211_005416.md)
- [2510.10002](https://arxiv.org/abs/2510.10002): [Deliberative Dynamics and Value Alignment in LLM Debates](../../../ml_research_analysis_2025/2510.10002_deliberative-dynamics-and-value-alignment-in-llm-debates_20260210_202204.md)
- [2510.12697](https://arxiv.org/abs/2510.12697): [Multi-Agent Debate for LLM Judges with Adaptive Stability Detection](../../../ml_research_analysis_2025/2510.12697_multi-agent-debate-for-llm-judges-with-adaptive-stability-detection_20260210_180806.md)
- [2510.15081](https://arxiv.org/abs/2510.15081): [A Generalizable Rhetorical Strategy Annotation Model Using LLM-based Debate Simulation and Labelling](../../../ml_research_analysis_2025/2510.15081_a-generalizable-rhetorical-strategy-annotation-model-using-llm-based-debate-simulation-and-labelling_20260210_160704.md)
- [2510.16645](https://arxiv.org/abs/2510.16645): [Unleashing Diverse Thinking Modes in LLMs through Multi-Agent Collaboration](../../../ml_research_analysis_2025/2510.16645_unleashing-diverse-thinking-modes-in-llms-through-multi-agent-collaboration_20260210_135038.md)
- [2510.20963](https://arxiv.org/abs/2510.20963): [Towards Scalable Oversight with Collaborative Multi-Agent Debate in Error Detection](../../../ml_research_analysis_2025/2510.20963_towards-scalable-oversight-with-collaborative-multi-agent-debate-in-error-detection_20260211_003626.md)
- [2510.22967](https://arxiv.org/abs/2510.22967): [MAD-Fact: A Multi-Agent Debate Framework for Long-Form Factuality Evaluation in LLMs](../../../ml_research_analysis_2025/2510.22967_mad-fact-a-multi-agent-debate-framework-for-long-form-factuality-evaluation-in-llms_20260211_001811.md)
- [2510.23271](https://arxiv.org/abs/2510.23271): [Mubeen AI: A Specialized Arabic Language Model for Heritage Preservation and User Intent Understanding](../../../ml_research_analysis_2025/2510.23271_mubeen-ai-a-specialized-arabic-language-model-for-heritage-preservation-and-user-intent-understanding_20260211_003906.md)
- [2511.01014](https://arxiv.org/abs/2511.01014): [IF-CRITIC: Towards a Fine-Grained LLM Critic for Instruction-Following Evaluation](../../../ml_research_analysis_2025/2511.01014_if-critic-towards-a-fine-grained-llm-critic-for-instruction-following-evaluation_20260210_142730.md)
- [2511.01188](https://arxiv.org/abs/2511.01188): [ZoFia: Zero-Shot Fake News Detection with Entity-Guided Retrieval and Multi-LLM Interaction](../../../ml_research_analysis_2025/2511.01188_zofia-zero-shot-fake-news-detection-with-entity-guided-retrieval-and-multi-llm-interaction_20260210_144151.md)
- [2511.02606](https://arxiv.org/abs/2511.02606): [A Multi-Agent Psychological Simulation System for Human Behavior Modeling](../../../ml_research_analysis_2025/2511.02606_a-multi-agent-psychological-simulation-system-for-human-behavior-modeling_20260210_024232.md)
- [2511.03958](https://arxiv.org/abs/2511.03958): [Multi-Agent Collaborative Framework For Math Problem Generation](../../../ml_research_analysis_2025/2511.03958_multi-agent-collaborative-framework-for-math-problem-generation_20260210_155632.md)
- [2511.04700](https://arxiv.org/abs/2511.04700): [Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation](../../../ml_research_analysis_2025/2511.04700_separate-the-wheat-from-the-chaff-winnowing-down-divergent-views-in-retrieval-augmented-generation_20260209_162304.md)
- [2511.05375](https://arxiv.org/abs/2511.05375): [Reasoning Is All You Need for Urban Planning AI](../../../ml_research_analysis_2025/2511.05375_reasoning-is-all-you-need-for-urban-planning-ai_20260210_081820.md)
- [2511.05528](https://arxiv.org/abs/2511.05528): [SMAGDi: Socratic Multi Agent Interaction Graph Distillation for Efficient High Accuracy Reasoning](../../../ml_research_analysis_2025/2511.05528_smagdi-socratic-multi-agent-interaction-graph-distillation-for-efficient-high-accuracy-reasoning_20260210_143540.md)
- [2511.06396](https://arxiv.org/abs/2511.06396): [Efficient LLM Safety Evaluation through Multi-Agent Debate](../../../ml_research_analysis_2025/2511.06396_efficient-llm-safety-evaluation-through-multi-agent-debate_20260210_103915.md)
- [2511.06496](https://arxiv.org/abs/2511.06496): [A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving](../../../ml_research_analysis_2025/2511.06496_a-low-rank-method-for-vision-language-model-hallucination-mitigation-in-autonomous-driving_20260209_230011.md)
- [2511.07267](https://arxiv.org/abs/2511.07267): [Beyond Detection: Exploring Evidence-based Multi-Agent Debate for Misinformation Intervention and Persuasion](../../../ml_research_analysis_2025/2511.07267_beyond-detection-exploring-evidence-based-multi-agent-debate-for-misinformation-intervention-and-persuasion_20260211_024522.md)
- [2511.08317](https://arxiv.org/abs/2511.08317): [Automatic Paper Reviewing with Heterogeneous Graph Reasoning over LLM-Simulated Reviewer-Author Debates](../../../ml_research_analysis_2025/2511.08317_automatic-paper-reviewing-with-heterogeneous-graph-reasoning-over-llm-simulated-reviewer-author-debates_20260211_033855.md)
- [2511.11040](https://arxiv.org/abs/2511.11040): [Key Decision-Makers in Multi-Agent Debates: Who Holds the Power?](../../../ml_research_analysis_2025/2511.11040_key-decision-makers-in-multi-agent-debates-who-holds-the-power_20260210_143724.md)
- [2511.11108](https://arxiv.org/abs/2511.11108): [Analysing Personal Attacks in U.S. Presidential Debates](../../../ml_research_analysis_2025/2511.11108_analysing-personal-attacks-in-u-s-presidential-debates_20260210_233507.md)
- [2511.11169](https://arxiv.org/abs/2511.11169): [Refine and Align: Confidence Calibration through Multi-Agent Interaction in VQA](../../../ml_research_analysis_2025/2511.11169_refine-and-align-confidence-calibration-through-multi-agent-interaction-in-vqa_20260210_074324.md)
- [2511.11182](https://arxiv.org/abs/2511.11182): [Multi-agent Undercover Gaming: Hallucination Removal via Counterfactual Test for Multimodal Reasoning](../../../ml_research_analysis_2025/2511.11182_multi-agent-undercover-gaming-hallucination-removal-via-counterfactual-test-for-multimodal-reasoning_20260210_133442.md)
- [2511.11306](https://arxiv.org/abs/2511.11306): [iMAD: Intelligent Multi-Agent Debate for Efficient and Accurate LLM Inference](../../../ml_research_analysis_2025/2511.11306_imad-intelligent-multi-agent-debate-for-efficient-and-accurate-llm-inference_20260210_234310.md)
- [2511.12208](https://arxiv.org/abs/2511.12208): [Debate over Mixed-knowledge: A Robust Multi-Agent Reasoning Framework for Incomplete Knowledge Graph Question Answering](../../../ml_research_analysis_2025/2511.12208_debate-over-mixed-knowledge-a-robust-multi-agent-reasoning-framework-for-incomplete-knowledge-graph-question-answering_20260209_232047.md)
- [2511.19417](https://arxiv.org/abs/2511.19417): [Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration](../../../ml_research_analysis_2025/2511.19417_be-my-eyes-extending-large-language-models-to-new-modalities-through-multi-agent-collaboration_20260209_022101.md)
- [2511.20086](https://arxiv.org/abs/2511.20086): [More Bias, Less Bias: BiasPrompting for Enhanced Multiple-Choice Question Answering](../../../ml_research_analysis_2025/2511.20086_more-bias-less-bias-biasprompting-for-enhanced-multiple-choice-question-answering_20260210_064351.md)
- [2511.21460](https://arxiv.org/abs/2511.21460): [MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning](../../../ml_research_analysis_2025/2511.21460_madra-multi-agent-debate-for-risk-aware-embodied-planning_20260209_202721.md)
- [2511.22854](https://arxiv.org/abs/2511.22854): [CRAwDAD: Causal Reasoning Augmentation with Dual-Agent Debate](../../../ml_research_analysis_2025/2511.22854_crawdad-causal-reasoning-augmentation-with-dual-agent-debate_20260208_185732.md)
- [2512.00349](https://arxiv.org/abs/2512.00349): [Debate with Images: Detecting Deceptive Behaviors in Multimodal Large Language Models](../../../ml_research_analysis_2025/2512.00349_debate-with-images-detecting-deceptive-behaviors-in-multimodal-large-language-models_20260211_003911.md)
- [2512.01909](https://arxiv.org/abs/2512.01909): [Latent Debate: A Surrogate Framework for Interpreting LLM Thinking](../../../ml_research_analysis_2025/2512.01909_latent-debate-a-surrogate-framework-for-interpreting-llm-thinking_20260210_143704.md)
- [2512.02282](https://arxiv.org/abs/2512.02282): [DialogGuard: Multi-Agent Psychosocial Safety Evaluation of Sensitive LLM Responses](../../../ml_research_analysis_2025/2512.02282_dialogguard-multi-agent-psychosocial-safety-evaluation-of-sensitive-llm-responses_20260210_044413.md)
- [2512.02405](https://arxiv.org/abs/2512.02405): [WISE: Weighted Iterative Society-of-Experts for Robust Multimodal Multi-Agent Debate](../../../ml_research_analysis_2025/2512.02405_wise-weighted-iterative-society-of-experts-for-robust-multimodal-multi-agent-debate_20260210_143909.md)
- [2512.02485](https://arxiv.org/abs/2512.02485): [UCAgents: Unidirectional Convergence for Visual Evidence Anchored Multi-Agent Medical Decision-Making](../../../ml_research_analysis_2025/2512.02485_ucagents-unidirectional-convergence-for-visual-evidence-anchored-multi-agent-medical-decision-making_20260210_114846.md)
- [2512.02530](https://arxiv.org/abs/2512.02530): [Aetheria: A multimodal interpretable content safety framework based on multi-agent debate and collaboration](../../../ml_research_analysis_2025/2512.02530_aetheria-a-multimodal-interpretable-content-safety-framework-based-on-multi-agent-debate-and-collaboration_20260210_034811.md)
- [2512.07132](https://arxiv.org/abs/2512.07132): [DART: Leveraging Multi-Agent Disagreement for Tool Recruitment in Multimodal Reasoning](../../../ml_research_analysis_2025/2512.07132_dart-leveraging-multi-agent-disagreement-for-tool-recruitment-in-multimodal-reasoning_20260210_121720.md)
- [2512.08345](https://arxiv.org/abs/2512.08345): [The High Cost of Incivility: Quantifying Interaction Inefficiency via Multi-Agent Monte Carlo Simulations](../../../ml_research_analysis_2025/2512.08345_the-high-cost-of-incivility-quantifying-interaction-inefficiency-via-multi-agent-monte-carlo-simulations_20260211_025535.md)
- [2512.09935](https://arxiv.org/abs/2512.09935): [Exploring Health Misinformation Detection with Multi-Agent Debate](../../../ml_research_analysis_2025/2512.09935_exploring-health-misinformation-detection-with-multi-agent-debate_20260211_031401.md)
- [2512.16279](https://arxiv.org/abs/2512.16279): [QuadSentinel: Sequent Safety for Machine-Checkable Control in Multi-agent Systems](../../../ml_research_analysis_2025/2512.16279_quadsentinel-sequent-safety-for-machine-checkable-control-in-multi-agent-systems_20260210_074144.md)
- [2512.18094](https://arxiv.org/abs/2512.18094): [Rethinking Multi-Agent Intelligence Through the Lens of Small-World Networks](../../../ml_research_analysis_2025/2512.18094_rethinking-multi-agent-intelligence-through-the-lens-of-small-world-networks_20260210_061114.md)
- [2512.20845](https://arxiv.org/abs/2512.20845): [MAR:Multi-Agent Reflexion Improves Reasoning Abilities in LLMs](../../../ml_research_analysis_2025/2512.20845_mar-multi-agent-reflexion-improves-reasoning-abilities-in-llms_20260210_100859.md)
- [2512.22625](https://arxiv.org/abs/2512.22625): [The Wisdom of Deliberating AI Crowds: Does Deliberation Improve LLM-Based Forecasting?](../../../ml_research_analysis_2025/2512.22625_the-wisdom-of-deliberating-ai-crowds-does-deliberation-improve-llm-based-forecasting_20260210_160406.md)
- [2512.23518](https://arxiv.org/abs/2512.23518): [Single LLM Debate, MoLaCE: Mixture of Latent Concept Experts Against Confirmation Bias](../../../ml_research_analysis_2025/2512.23518_single-llm-debate-molace-mixture-of-latent-concept-experts-against-confirmation-bias_20260210_155841.md)
- [2512.23717](https://arxiv.org/abs/2512.23717): [HarmTransform: Transforming Explicit Harmful Queries into Stealthy via Multi-Agent Debate](../../../ml_research_analysis_2025/2512.23717_harmtransform-transforming-explicit-harmful-queries-into-stealthy-via-multi-agent-debate_20260211_002509.md)
- [2512.24008](https://arxiv.org/abs/2512.24008): [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](../../../ml_research_analysis_2025/2512.24008_spark-search-personalization-via-agent-driven-retrieval-and-knowledge-sharing_20260210_094416.md)
- [2512.25015](https://arxiv.org/abs/2512.25015): [MAMA-Memeia! Multi-Aspect Multi-Agent Collaboration for Depressive Symptoms Identification in Memes](../../../ml_research_analysis_2025/2512.25015_mama-memeia-multi-aspect-multi-agent-collaboration-for-depressive-symptoms-identification-in-memes_20260208_140222.md)
- [2601.08308](https://arxiv.org/abs/2601.08308): [AgriAgent: Contract-Driven Planning and Capability-Aware Tool Orchestration in Real-World Agriculture](../../../ml_research_analysis_2025/2601.08308_agriagent-contract-driven-planning-and-capability-aware-tool-orchestration-in-real-world-agriculture_20260210_065041.md)
- [2601.09667](https://arxiv.org/abs/2601.09667): [Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning](../../../ml_research_analysis_2025/2601.09667_collaborative-multi-agent-test-time-reinforcement-learning-for-reasoning_20260210_000019.md)
- [2601.11903](https://arxiv.org/abs/2601.11903): [AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems](../../../ml_research_analysis_2025/2601.11903_aema-verifiable-evaluation-framework-for-trustworthy-and-controlled-agentic-llm-systems_20260210_132909.md)
- [2601.12091](https://arxiv.org/abs/2601.12091): [Mitigating Cultural Bias in LLMs via Multi-Agent Cultural Debate](../../../ml_research_analysis_2025/2601.12091_mitigating-cultural-bias-in-llms-via-multi-agent-cultural-debate_20260210_121717.md)
- [2601.12560](https://arxiv.org/abs/2601.12560): [Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents](../../../ml_research_analysis_2025/2601.12560_agentic-artificial-intelligence-ai-architectures-taxonomies-and-evaluation-of-large-language-model-agents_20260208_192918.md)
- [2601.14349](https://arxiv.org/abs/2601.14349): [MARBLE: Multi-Agent Reasoning for Bioinformatics Learning and Evolution](../../../ml_research_analysis_2025/2601.14349_marble-multi-agent-reasoning-for-bioinformatics-learning-and-evolution_20260210_144012.md)
- [2601.15436](https://arxiv.org/abs/2601.15436): [Not Your Typical Sycophant: The Elusive Nature of Sycophancy in Large Language Models](../../../ml_research_analysis_2025/2601.15436_not-your-typical-sycophant-the-elusive-nature-of-sycophancy-in-large-language-models_20260210_004952.md)
- [2601.15488](https://arxiv.org/abs/2601.15488): [Multi-Persona Thinking for Bias Mitigation in Large Language Models](../../../ml_research_analysis_2025/2601.15488_multi-persona-thinking-for-bias-mitigation-in-large-language-models_20260209_152458.md)
- [2601.21257](https://arxiv.org/abs/2601.21257): [MoCo: A One-Stop Shop for Model Collaboration Research](../../../ml_research_analysis_2025/2601.21257_moco-a-one-stop-shop-for-model-collaboration-research_20260210_061002.md)
- [2601.21469](https://arxiv.org/abs/2601.21469): [Adaptive Confidence Gating in Multi-Agent Collaboration for Efficient and Optimized Code Generation](../../../ml_research_analysis_2025/2601.21469_adaptive-confidence-gating-in-multi-agent-collaboration-for-efficient-and-optimized-code-generation_20260208_123545.md)
- [2601.21936](https://arxiv.org/abs/2601.21936): [AgenticSimLaw: A Juvenile Courtroom Multi-Agent Debate Simulation for Explainable High-Stakes Tabular Decision Making](../../../ml_research_analysis_2025/2601.21936_agenticsimlaw-a-juvenile-courtroom-multi-agent-debate-simulation-for-explainable-high-stakes-tabular-decision-making_20260210_181210.md)
- [2601.22297](https://arxiv.org/abs/2601.22297): [Prepare Reasoning Language Models for Multi-Agent Debate with Self-Debate Reinforcement Learning](../../../ml_research_analysis_2025/2601.22297_prepare-reasoning-language-models-for-multi-agent-debate-with-self-debate-reinforcement-learning_20260210_123158.md)
- [2602.00454](https://arxiv.org/abs/2602.00454): [Cross-Modal Memory Compression for Efficient Multi-Agent Debate](../../../ml_research_analysis_2025/2602.00454_cross-modal-memory-compression-for-efficient-multi-agent-debate_20260210_181405.md)
- [2602.01011](https://arxiv.org/abs/2602.01011): [Multi-Agent Teams Hold Experts Back](../../../ml_research_analysis_2025/2602.01011_multi-agent-teams-hold-experts-back_20260210_040726.md)
