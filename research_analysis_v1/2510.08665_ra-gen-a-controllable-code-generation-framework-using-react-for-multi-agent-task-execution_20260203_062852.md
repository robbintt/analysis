---
title: 'RA-Gen: A Controllable Code Generation Framework Using ReAct for Multi-Agent
  Task Execution'
arxiv_id: '2510.08665'
source_url: https://arxiv.org/abs/2510.08665
generated_at: '2026-02-03T06:28:52'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# RA-Gen: A Controllable Code Generation Framework Using ReAct for Multi-Agent Task Execution

*Aofan Liu; Haoxuan Li; Bin Wang; Ao Yang; Hui Li*

---

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Security Rate** | **94.8%** (SVEN Dataset) |
| **Core Paradigm** | ReAct (Reasoning + Acting) |
| **Architecture** | Multi-Agent System (4 Agents) |
| **Languages** | C, Python |
| **Validation Tool** | CodeQL |
| **Quality Score** | 8/10 |

---

## üìù Executive Summary

Current Large Language Model (LLM)-based code generation systems suffer from critical limitations regarding security, controllability, and interpretability. While capable of producing syntactically correct code, these models often operate as "black boxes," generating outputs that may contain security vulnerabilities or fail to adhere to specific user constraints. This lack of transparency and verifiable safety measures poses significant risks for software deployment, as developers cannot easily trust or control the automated generation process. The paper addresses the urgent need for a framework that not only generates functional code but also ensures its security and allows for human oversight during the generation process.

The researchers introduce **RA-Gen**, a novel multi-agent framework built upon the ReAct (Reasoning + Acting) paradigm to facilitate controllable and interpretable code generation. Technically, the system employs a collaborative architecture comprising four specialized agents: the **Planner** (task decomposition), **Searcher** (knowledge integration), **CodeGen** (code synthesis), and **Extractor** (structured data retrieval). The core innovation lies in the application of the ReAct loop, which decouples problem-solving into iterative cycles of reasoning traces and task-specific actions. This architecture bridges the gap between the LLM's internal static knowledge and dynamic external tools‚Äîspecifically integrating CodeQL for static analysis. By exposing intermediate reasoning steps and tool interactions, RA-Gen allows the system to self-correct and verify code security against real-world standards in real-time.

Empirical evaluation demonstrates that RA-Gen establishes a new benchmark for secure code generation. On the SVEN dataset, the framework achieved a remarkable **94.8% security rate** using CodeQL validation, significantly outperforming existing approaches. The system demonstrated robust multi-language capabilities, effectively mitigating specific Common Weakness Enumerations (CWEs) in both C and Python. In C, the system addressed CWE-190 (Integer Overflow), CWE-022 (Path Traversal), and CWE-476 (NULL Pointer Dereference), while in Python, it tackled CWE-125 (Out-of-bounds Read), CWE-787 (Out-of-bounds Write), and CWE-089 (SQL Injection). Performance metrics across these categories ranged from 50% to 90%, with iterative testing steps (0, 1, and 2) confirming that the ReAct reasoning loop consistently improved code quality and compliance over time.

This research significantly advances the field of AI-assisted software engineering by demonstrating that safety and controllability can be effectively integrated into automated code generation. By establishing a new standard for security rates in controllable frameworks, RA-Gen provides a viable pathway for adopting LLMs in high-stakes development environments where security is paramount. The transparent reasoning process inherent in the ReAct paradigm addresses the "trust gap" often associated with AI models, fostering greater user confidence. Furthermore, the successful integration of static analysis tools like CodeQL with generative AI paves the way for future hybrid systems that combine the creativity of LLMs with the rigorous verification standards of traditional software engineering tools.

---

## üîë Key Findings

*   **High Security Standard:** The framework achieved a **94.8% security rate** on the SVEN dataset using CodeQL validation, outperforming existing approaches.
*   **Multi-Language Effectiveness:** Demonstrated robust capabilities in code generation across multiple programming languages (C and Python).
*   **Enhanced Accuracy:** Integrating internal LLM knowledge with external tools via the ReAct paradigm significantly enhanced generation accuracy.
*   **User Trust:** The transparent reasoning process fostered user trust and improved the controllability of the generation process.

---

## üõ†Ô∏è Methodology

The researchers proposed **RA-Gen**, a multi-agent system based on the ReAct paradigm to facilitate controllable and interpretable code generation. The methodology utilizes a collaborative architecture of four specialized agents:

1.  **Planner:** Responsible for decomposing complex tasks into manageable sub-tasks.
2.  **Searcher:** Integrates knowledge and tools via the ReAct paradigm to gather necessary information.
3.  **CodeGen:** Synthesizes the actual code based on the plan and gathered context.
4.  **Extractor:** Retrieves structured data from the generated output or external sources.

This architecture enables dynamic interactions between LLMs and external resources, ensuring a structured and verifiable workflow.

---

## ‚öôÔ∏è Technical Details

*   **Core Paradigm:** Utilizes the **ReAct (Reasoning + Acting)** paradigm, decoupling problem-solving into iterative loops of reasoning traces and task-specific actions.
*   **Multi-Agent Architecture:** Breaks down complex code generation tasks into executable sub-tasks through agent collaboration.
*   **Tool Integration:** A key component is the integration of internal LLM knowledge with external tools, specifically using **CodeQL** for static analysis to verify code security.
*   **Transparency:** The system emphasizes controllability and transparency by exposing intermediate reasoning steps and tool interactions.
*   **Language Support:** Supports multiple programming languages, specifically **C** and **Python**.

---

## üìà Experimental Results

The framework was rigorously tested against specific Common Weakness Enumerations (CWEs) in both C and Python across iterative steps (0, 1, 2).

**Overall Performance:**
*   **Security Rate:** 94.8% on SVEN dataset.

**Vulnerability Mitigation:**

| Language | Target CWEs | Focus Areas |
| :--- | :--- | :--- |
| **C** | ‚Ä¢ CWE-190 (Integer Overflow/Underflow)<br>‚Ä¢ CWE-022 (Path Traversal)<br>‚Ä¢ CWE-476 (NULL Pointer Dereference) | Quality, Security, Compliance |
| **Python** | ‚Ä¢ CWE-125 (Out-of-bounds Read)<br>‚Ä¢ CWE-787 (Out-of-bounds Write)<br>‚Ä¢ CWE-089 (SQL Injection) | Iterative improvements |

*   **Performance Metrics:** Ranged from **50% to 90%** across categories.
*   **Iterative Improvement:** Testing confirmed that performance improved over iterative steps (0, 1, 2), validating the efficacy of the ReAct reasoning loop.

---

## üèÜ Research Contributions

*   **Safety & Controllability:** Addressed critical safety and controllability limitations in current LLM-based code generation systems.
*   **Agent Architecture:** Introduced a specialized four-agent system (Planner, Searcher, CodeGen, Extractor) for a structured workflow.
*   **Novel Application:** Pioneered the novel application of the ReAct paradigm in code generation to bridge static knowledge with dynamic real-time information.
*   **Benchmarking:** Established a new standard for security rates in controllable code generation frameworks via empirical evidence on the SVEN dataset.

---
*Report based on 40 citations. Quality Score: 8/10*