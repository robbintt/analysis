---
title: Effect of Model Merging in Domain-Specific Ad-hoc Retrieval
arxiv_id: '2509.21966'
source_url: https://arxiv.org/abs/2509.21966
generated_at: '2026-02-03T18:27:06'
quality_score: 9
citation_count: 29
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Effect of Model Merging in Domain-Specific Ad-hoc Retrieval

*Taiga Sasaki; Takehiro Yamamoto; Hiroaki Ohshima; Sumio Fujita*

---

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 9/10
> *   **Technique:** Linear Interpolation (Model Merging)
> *   **Base Architecture:** `e5-mistral-7b-instruct`
> *   **Domain Models:** `BioMistral-7b` (Medical), `japanese-stablelm-base-gamma-7b` (Japanese)
> *   **Key Advantage:** No fine-tuning required; robust in low-data scenarios
> *   **Tooling:** Implemented via MergeKit

---

## Executive Summary

This research addresses the persistent challenge of adapting general-purpose dense retrieval models to specialized domains, such as medicine or specific languages, where generic models often fail to capture necessary context and terminology. Traditional domain adaptation typically relies on resource-intensive fine-tuning methods, such as Low-Rank Adaptation (LoRA), which require substantial computational power and large volumes of in-domain training data to be effective. This creates a barrier to entry for high-performance retrieval in niche or low-resource fields where data is scarce. The authors investigate how to achieve high retrieval effectiveness without the prohibitive costs associated with standard backpropagation-based fine-tuning pipelines.

The key innovation is a parameter-efficient approach to domain adaptation using model merging via linear interpolation. The authors combine a general retrieval model (`e5-mistral-7b-instruct`) with a domain-specific pre-trained model (e.g., `BioMistral-7b` for medical or `japanese-stablelm-base-gamma-7b` for Japanese) by partitioning the 32-layer Mistral architecture into lower (layers 1-16) and upper (layers 17-32) segments. Using the MergeKit framework, they optimize distinct interpolation hyperparameters ($\alpha_{lower}$, $\alpha_{upper}$) via grid search for each segment, rather than using a uniform average. The process strictly retains the tokenizer and embedding weights of the source retrieval model to preserve its core retrieval capabilities, effectively "injecting" domain knowledge from the non-retrieval model without any task-specific fine-tuning or backpropagation.

The study reports quantitative results that validate the method's efficacy across both domains. In the medical domain (TREC-CDS 2017), the merged model achieved an nDCG@10 of 0.358, significantly outperforming the original source retrieval modelâ€™s score of 0.327. In the Japanese domain (NTCIR-15), the merged model attained an nDCG@10 of 0.686, compared to the base modelâ€™s 0.644. The approach proves particularly robust in low-resource settings; when training data was limited to 1% of the available corpus, the merged model maintained its performance (nDCG@10 0.358), substantially outperforming a LoRA fine-tuned baseline (nDCG@10 0.296) which degraded due to data scarcity. While full-data LoRA fine-tuning slightly edged out the merged model in some high-resource scenarios, the optimal hyperparameters for merging were found to be asymmetric, with specific $\alpha$ values varying by segment to best balance domain knowledge and retrieval capability.

This work offers significant practical implications for the field of information retrieval by establishing a new, cost-effective paradigm for rapid domain adaptation. By demonstrating that domain-specific models can be constructed without expensive retraining, the authors provide a viable solution for deploying specialized search systems in scenarios with tight computational budgets or limited training data. The successful validation across two distinct domains confirms that merging retrieval models with non-retrieval domain-specific models is a generalizable strategy, lowering the barrier to entry for high-performance retrieval in specialized fields.

---

## Key Findings

*   **Superior Effectiveness:** Model merging can produce domain-specific retrieval models that are more effective than the original source retrieval model.
*   **Alternative to LoRA:** The technique serves as a practical alternative to LoRA fine-tuning, particularly when only a limited amount of training data is available.
*   **Capability Combination:** The proposed approach successfully combines the capabilities of retrieval and domain-specific non-retrieval models without requiring additional fine-tuning.
*   **Generalizability:** Effectiveness was validated across two distinct domains (medical and Japanese), suggesting the method is broadly applicable.

---

## Technical Implementation

The study proposes a method to create domain-specific retrieval models without backpropagation by merging two pre-trained models.

### Architecture & Configuration
*   **Base Retrieval Model:** `e5-mistral-7b-instruct`
*   **Domain-Specific Models:**
    *   Medical: `BioMistral-7b`
    *   Japanese: `japanese-stablelm-base-gamma-7b`
*   **Layer Segmentation:** The Mistral architecture (32 layers) is split into two segments:
    *   **Lower Segment:** Layers 1â€“16
    *   **Upper Segment:** Layers 17â€“32

### Merging Strategy
*   **Method:** Linear interpolation of weights using the MergeKit framework.
*   **No Fine-tuning:** No backpropagation or task-specific fine-tuning is performed.
*   **Tokenizer Retention:** Tokenizer and token embedding weights are strictly adopted from the source retrieval model to preserve retrieval functionality.
*   **Hyperparameters:** Two distinct interpolation parameters are optimized via grid search:
    *   $\alpha_{lower}$: Interpolation strength for the lower segment.
    *   $\alpha_{upper}$: Interpolation strength for the upper segment.

---

## Methodology

The study employs a rigorous experimental design to validate the proposed merging technique:

*   **Technique:** Utilizes linear interpolation to merge the weights of a source retrieval model with a domain-specific non-retrieval model.
*   **Domains:** Experiments were conducted in the **Medical** and **Japanese** domains to test versatility.
*   **Comparisons:**
    1.  **Merged Model vs. Source:** Comparing the new model against the original general retrieval model.
    2.  **Merged Model vs. LoRA:** Comparing against a standard Low-Rank Adaptation fine-tuned baseline.
*   **Data Conditions:** Evaluation covered both **full data** and **limited data** settings to test robustness against data scarcity.

---

## Performance Results

Quantitative evaluation demonstrates the robustness of the merging approach, particularly in data-scarce environments.

### Medical Domain (TREC-CDS 2017)
*   **Merged Model nDCG@10:** 0.358
*   **Source Model nDCG@10:** 0.327
*   **Result:** Significant improvement over the base model.

### Japanese Domain (NTCIR-15)
*   **Merged Model nDCG@10:** 0.686
*   **Source Model nDCG@10:** 0.644
*   **Result:** Consistent improvement across languages.

### Low-Resource Setting (1% Training Data)
*   **Merged Model nDCG@10:** 0.358 (Maintained performance)
*   **LoRA Baseline nDCG@10:** 0.296 (Performance degradation)
*   **Result:** The merged model significantly outperforms LoRA when data is scarce.

---

## Research Contributions

*   **Resource Efficiency:** Demonstrates a method for domain adaptation that eliminates the need for additional fine-tuning, drastically reducing computational costs.
*   **Low-Resource Application:** Provides a viable solution for domain-specific ad-hoc retrieval in scenarios where data is scarce, outperforming or matching standard adaptation techniques like LoRA under these constraints.
*   **Cross-Domain Validation:** Offers empirical evidence that merging retrieval models with non-retrieval domain-specific models is a successful strategy for enhancing retrieval effectiveness in specialized fields.

---

**References:** 29 citations
**Analysis Quality Score:** 9/10