# Colliding with Adversaries at ECML-PKDD 2025 Model Robustness Competition 1st Prize Solution

* Dimitris Stefanopoulos; Andreas Voskou*

---

> ### ðŸ“Š Quick Facts
>
> | Metric | Details |
> | :--- | :--- |
> | **Event** | ECML-PKDD 2025 "Colliding with Adversaries" Challenge |
> | **Rank** | **1st Prize** (Task 2) |
> | **Performance** | **80%** Mixed Accuracy |
> | **Margin** | +2 percentage points over 2nd place |
> | **Training Data** | ~15.15 Million Artificial Samples |
> | **Domain** | High Energy Physics (Tabular Data) |
> | **Attack Vector** | Random Distribution Shuffle Attack (RDSA) |

---

## Executive Summary

This research addresses the critical vulnerability of machine learning models in High Energy Physics (HEP) to adversarial data corruption, specifically the **Random Distribution Shuffle Attack (RDSA)**. In particle physics experiments, accurate binary classification is essential for distinguishing between signal and background events, such as differentiating top-jets from W-boson-jets. RDSA threatens this process by corrupting the underlying statistical properties of tabular data, causing standard models to fail. The paper presents the 1st prize-winning solution to Task 2 of the "Colliding with Adversaries" challenge at ECML-PKDD 2025, focusing on the need for algorithms that can maintain high performance on both clean data and data subjected to sophisticated distributional attacks.

### Innovation
The solution, termed **Method-Aware Robustness (Anti-RDSA)**, introduces a two-phase strategy combining massive synthetic data generation with a specialized neural architecture. The first phase involves a custom data augmentation technique derived from the RDSA mechanism; it generates a training corpus of 15 million samples by computing feature histograms and replacing variable values with samples from empirical distributions, creating 50 variants per original sample. The second phase utilizes a robust Artificial Neural Network (ANN) featuring a Feature Embedding Block that leverages shared weights across features of the same physical type (e.g., transverse momentum, azimuthal angle). This weight-sharing mechanism allows the model to learn robust representations by treating similar physical variables consistently, coupled with a Dense Fusion Tail for final classification via an ensemble of four averaged classifiers.

### Results
The proposed model achieved a **Mixed Accuracy Score of 80%**, calculated as the average of Clean Accuracy and Adversarial Accuracy, securing first place in the competition. This performance marked a significant improvement over the second-place model, outperforming it by a margin of two percentage points. The final training dataset consisted of approximately 15.15 million samples, derived from the original data combined with DataGen1 (using 100/200 bins and 5 variables) and DataGen2 (100/200 bins and 10 variables) augmentation strategies. While the authors observed that improvements on public test sets did not fully transfer to hidden sets regarding pure Adversarial Accuracy, the massive data augmentation strategy successfully provided the generalization capabilities required to top the leaderboard.

### Impact
This work establishes a high-performance benchmark for robust binary classification in the HEP domain, proving that resilience against specific adversarial attacks like RDSA can be systematically engineered. The introduction of a feature embedding architecture with weight sharing offers a novel structural approach to mitigating adversarial noise in tabular scientific data. Beyond the context of the competition, the research provides a validated methodology for defending against distribution-corrupting attacks, influencing future work in adversarial robustness and data-centric AI for safety-critical scientific applications.

---

## Key Findings

*   **Competition Victory:** The proposed solution secured the **1st prize** in Task 2 of the "Colliding with Adversaries" challenge at ECML-PKDD 2025.
*   **High Robustness:** The model achieved a mixed accuracy score of **80%** on a binary classification task, effectively handling both clean data and data corrupted by the Random Distribution Shuffle Attack (RDSA).
*   **Significant Margin:** The solution outperformed the second-place model by a significant margin of **two percentage points**.
*   **Scale of Data:** The generation of **15 million** artificial training samples was crucial in enabling the model to learn robust representations against the specific attack vector.

---

## Methodology

The solution implements a **two-phase strategy** focused on adversarial resilience:

*   **Phase 1: Data Generation**
    Utilizes a custom methodology derived from the Random Distribution Shuffle Attack (RDSA) to synthesize a large-scale training dataset. This process involves computing feature histograms and generating variants to teach the model how to handle distribution shifts.

*   **Phase 2: Robust Model Architecture (ANN)**
    The architecture is composed of two main components:
    1.  **Feature Embedding Block:** Uses shared weights among features of the same physical type to ensure consistent representation.
    2.  **Dense Fusion Tail:** Integrates the embeddings and performs the final binary classification prediction.

---

## Technical Details

### Approach Overview
**Name:** Method-Aware Robustness (Anti-RDSA)
**Task:** Binary classification (two top-jets vs. two W-boson-jets) on HEP tabular data.
**Input Dimensions:** 87 features.

### Data Augmentation Strategy
The approach employs a massive data augmentation technique to generate synthetic adversarial examples. By computing feature histograms, the system creates 50 variants for each sample by replacing values for random variables with samples from the empirical distribution.

| Phase | Split | Bins (`n_bins`) | Variables (`n_vars`) |
| :--- | :--- | :--- | :--- |
| **DataGen1** | Train | 100 | 5 |
| | Val/Test | 200 | 5 |
| **DataGen2** | Train | 100 | 10 |
| | Val/Test | 200 | 10 |

### Model Architecture
*   **Ensemble Method:** Combines 4 classifiers via averaging.
*   **Feature Embedding:** Utilizes shared weights for specific physical variable types:
    *   Transverse momentum
    *   Azimuthal angle
    *   Pseudorapidity
*   **Prediction Head:** Dense Fusion Tail (MLP).

---

## Results & Contributions

### Performance Metrics
*   **Mixed Accuracy Score:** 80%
*   **Training Dataset Size:** ~15.15 million samples (Original + DataGen1 + DataGen2).
*   **Observation:** While improvements on public test sets did not fully transfer to hidden sets regarding purely Adversarial Accuracy, the massive data augmentation strategy successfully addressed the required generalization capabilities necessary to win the competition.

### Research Contributions
*   **Architecture Innovation:** Introduction of a novel feature embedding architecture that leverages weight sharing to mitigate the impact of adversarial noise in High Energy Physics (HEP) data.
*   **Training Strategy:** Demonstration of an effective adversarial training strategy using a custom derivation of RDSA to generate massive synthetic datasets.
*   **Benchmarking:** Establishment of a high-performance benchmark (80% accuracy) for robust binary classification tasks in the HEP domain against the Random Distribution Shuffle Attack.

---

**Document Quality Score:** 8/10
**References:** 8 citations