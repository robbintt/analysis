---
title: Labels Generated by Large Language Models Help Measure People's Empathy in
  Vitro
arxiv_id: '2501.00691'
source_url: https://arxiv.org/abs/2501.00691
generated_at: '2026-02-04T15:36:12'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Labels Generated by Large Language Models Help Measure People's Empathy in Vitro

*Md Rakibul Hasan; Yue Yao; Md Zakir Hossain; Aneesh Krishna; Imre Rudas; Shafin Rahman; Tom Gedeon*

***

### ðŸ“Š Quick Facts

| Metric | Details |
| :--- | :--- |
| **New SOTA Performance** | **PCC:** 0.648 (vs 0.629)<br>**CCC:** 0.597<br>**RMSE:** 0.092 |
| **Dataset** | NewsEmp / NewsEmp24 |
| **Model Architecture** | RoBERTa |
| **Key LLMs Used** | Llama, GPT-4 |
| **Prompt Strategy** | Scale-Aware (Based on Batsonâ€™s 6 components) |
| **Statistical Significance** | Data augmentation: $p \le 0.0001$ |
| **Zero-shot Baseline** | GPT-4 PCC: 0.581 |
| **LLM-to-LLM Consistency** | $\alpha = 0.80â€“0.99$ |

***

## Executive Summary

> **Context:** The accurate computation of empathy from text has historically been hindered by label noise in crowdsourced datasets. Because empathy is subjective, human annotators often produce inconsistent or inaccurate labels, limiting the performance of machine learning models.
>
> **Solution:** This research proposes an **"in-vitro"** framework, repurposing Large Language Models (LLMs) from task solvers to data curators. By utilizing LLMs (specifically Llama and GPT-4) to generate high-quality training labels via "Scale-Aware" prompts, the authors address the bottleneck of noisy data.
>
> **Outcome:** The RoBERTa model trained on this LLM-refined data achieved a new **State-of-the-Art (SOTA)** on the NewsEmp24 benchmark. The study validates the "in-vitro" approach as a powerful alternative to traditional labeling, highlighting LLMs' potential in dataset curation and noise mitigation. Additionally, the work provides insights into demographic biases and releases the **LLMPathy** dataset and code for reproducibility.

***

## Key Findings

*   **Superior Accuracy:** LLM-generated labels yield statistically significant accuracy improvements over noisy crowdsourced labels for empathy computing.
*   **New SOTA:** A RoBERTa model trained on these labels achieved a new State-of-the-Art (SOTA) Pearson correlation coefficient (PCC) of **0.648** on the NewsEmp benchmarks, surpassing the previous best of 0.629.
*   **Validation of "In-Vitro":** The study successfully validates the efficacy of using LLMs for data generation and correction as a powerful alternative to the traditional "in-vivo" approach.
*   **Noise Mitigation:** Both strategiesâ€”**Noisy Label Correction** and **Training Data Augmentation**â€”successfully mitigated the misrepresentation of underlying empathy in crowdsourced datasets.
*   **LLM vs. Human Performance:** LLM labels outperformed human labels in **12 out of 18** test cases.
*   **Consistency Variance:** While LLM-to-LLM consistency was high ($\alpha = 0.80â€“0.99$), LLM-to-Crowd consistency was notably low ($\alpha = 0.19â€“0.27$).

***

## Methodology

The researchers adopted an **'in-vitro' paradigm**, shifting the focus from using LLMs as inference engines to using them as high-quality data generators during preprocessing.

*   **LLM-as-a-Service:** Utilized to synthesize labels using psychology-based scale-aware prompts.
*   **Data Strategies:**
    1.  **Label Noise Correction:** Replacing inaccurate crowdsourced labels directly with LLM-generated ones.
    2.  **Training Data Augmentation:** Supplementing the existing dataset with additional LLM-generated labels.
*   **Model Architecture:** A RoBERTa pre-trained language model was trained specifically on the refined labels.
*   **Evaluation:** Included a comparative analysis of standard metrics and a specific examination of demographic biases to ensure fairness.

***

## Technical Details

The paper introduces a specific framework designed to handle the nuances of psychological data.

| Component | Description |
| :--- | :--- |
| **Framework** | **"In-Vitro" Framework:** Uses LLMs (Llama, GPT-4) during preprocessing for Label Noise Correction and Training Data Augmentation. |
| **Prompting Strategy** | **Scale-Aware:** Based on Batsonâ€™s definition of empathy, breaking the construct down into six emotional components: *sympathetic, moved, compassionate, tender, warm, softhearted*. |
| **Architecture** | LLMs generate labels $\rightarrow$ Labels train a RoBERTa model. |
| **Evaluation Metrics** | **PCC** (Pearson Correlation Coefficient), **CCC** (Concordance Correlation Coefficient), **RMSE** (Root Mean Square Error), and **Silhouette Score**. |

***

## Results

The experimental results demonstrate the robustness of the proposed approach.

*   **Benchmark Performance:** Achieved new SOTA on NewsEmp24:
    *   **PCC:** 0.648
    *   **CCC:** 0.597
    *   **RMSE:** 0.092
*   **Statistical Significance:** Data augmentation showed higher significance ($p \le 0.0001$) compared to noise correction alone.
*   **Consistency Analysis:**
    *   **LLM-to-LLM:** High consistency ($\alpha = 0.80â€“0.99$).
    *   **LLM-to-Crowd:** Low consistency ($\alpha = 0.19â€“0.27$), suggesting the crowd labels were indeed noisy.
*   **Demographic Bias:** Analysis revealed prediction instability in Race, Age, and Income categories. Specifically, negative CCC was observed for Hispanic/Latino and "Other" racial groups, indicating areas for future improvement in equity.

***

## Contributions

This research makes four primary contributions to the field of NLP and computational psychology:

1.  **Noise Mitigation:** Directly addresses the critical issue of label noise in crowdsourced empathy datasets, advancing the technical capability of predicting psychology-based outcomes from text.
2.  **Paradigm Shift:** Expands the utility of LLMs by demonstrating their value in data curation and label refinement ('in-vitro') rather than strictly as inference engines.
3.  **Equity Framework:** By analyzing demographic biases, the work provides a framework for developing more equitable empathy computing models.
4.  **Open Science:** Released the code and the LLM-generated labels (dubbed **LLMPathy**) to facilitate further research and ensure reproducibility.

***

**Document Quality Score:** 9/10  
**References:** 40 citations