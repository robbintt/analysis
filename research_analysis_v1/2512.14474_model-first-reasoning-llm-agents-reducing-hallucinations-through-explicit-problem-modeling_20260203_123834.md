---
title: 'Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit
  Problem Modeling'
arxiv_id: '2512.14474'
source_url: https://arxiv.org/abs/2512.14474
generated_at: '2026-02-03T12:38:34'
quality_score: 9
citation_count: 8
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling
*Annu Rana; Gaurav Kumar*

---

### Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 9/10 |
| **Medical Scheduling Success** | 92% (MFR) vs 45% (ReAct) |
| **Constraint Violation Reduction** | 40% reduction vs. Chain-of-Thought |
| **Key Insight** | Failures stem from "representational deficiencies," not reasoning limits |
| **Validation Domains** | Medical, Route Planning, Resource Allocation, Logic, Procedural |
| **Total References** | 8 |

---

> ## Executive Summary
>
> Current LLM agents struggle with complex, multi-step planning tasks, frequently exhibiting "hallucinations" in the form of constraint violations and invalid states. The authors identify a critical gap in existing methodologies like Chain-of-Thought (CoT) and ReAct: they rely on implicit state tracking, which often fails to maintain a consistent representation of the problem environment.
>
> To bridge this gap, the authors introduce **Model-First Reasoning (MFR)**, a novel two-phase prompting paradigm inspired by classical AI planning and PDDL. The technical innovation lies in decoupling representation from reasoning. First, the LLM constructs an explicit formal model (entities, state variables, actions, constraints). Second, it generates solutions strictly adhering to this model, eliminating reliance on error-prone implicit latent state tracking.
>
> Empirical validation across five distinct domains demonstrates that MFR significantly outperforms standard CoT and ReAct baselines. In medical scheduling tasks, MFR achieved a **92% success rate** compared to only **45% for ReAct**. Furthermore, the framework demonstrated robust error reduction, **decreasing constraint violations by 40%** relative to Chain-of-Thought baselines. This research represents a paradigmatic shift, moving the focus from improving raw reasoning capability to enforcing explicit representation.

---

## Key Findings

*   **Superior Performance:** Model-First Reasoning (MFR) significantly reduces constraint violations and improves solution quality compared to existing methods like Chain-of-Thought (CoT) and ReAct across complex multi-step planning tasks.
*   **Criticality of Explicit Modeling:** Ablation studies confirm that the explicit modeling phase is the critical driver behind the performance gains, distinguishing it from implicit approaches.
*   **Root Cause of Failures:** The results suggest that many LLM planning failures are due to "representational deficiencies" (a lack of explicit problem structure) rather than inherent limitations in the model's reasoning capabilities.
*   **Broad Applicability:** The method was validated successfully across diverse domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis.

## Methodology

The researchers propose **Model-First Reasoning (MFR)**, a two-phase paradigm inspired by classical AI planning.

### Phase 1: Explicit Modeling
Before attempting to solve the problem, the LLM first constructs a formal, explicit model of the problem space. This involves defining and structuring specific entities, state variables, available actions, and constraints.

### Phase 2: Solution Generation
Using the explicitly defined model as a foundation, the LLM generates the solution plan. This approach contrasts with existing strategies that rely on implicit state tracking.

**Evaluation:**
The methodology was evaluated against Chain-of-Thought and ReAct baselines, with ablation studies performed to isolate the impact of the modeling phase.

## Technical Details

The paper proposes Model-First Reasoning (MFR), a two-phase prompting paradigm designed to address representational deficiencies in standard LLM prompting without architectural changes or fine-tuning.

*   **Phase 1 (Explicit Modeling):** Requires the LLM to define relevant entities, state variables, actions (including preconditions and effects), and constraints to create a representational scaffold.
*   **Phase 2 (Constrained Reasoning):** Requires the LLM to generate solutions strictly within the boundaries of this explicit model.
*   **Theoretical Grounding:** This approach contrasts with Chain-of-Thought and ReAct by avoiding implicit latent state tracking and is theoretically grounded in cognitive science and classical AI (PDDL).

## Results

Empirically validated across domains such as medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR demonstrated significant improvements:

*   **Reduced Constraint Violations:** Significant increase in solution quality compared to Chain-of-Thought and ReAct, particularly in complex multi-step planning tasks.
*   **Ablation Confirmation:** Studies confirmed that the explicit modeling phase is the primary driver of performance improvements.
*   **Diagnostic Findings:** Suggest that LLM planning failures are primarily caused by a lack of explicit problem structure rather than a lack of reasoning capability.
*   **Reframing Hallucination:** Hallucination is effectively reframed as reasoning over an undefined or unstable problem space.

## Contributions

*   **Novel Paradigm:** Introduction of the Model-First Reasoning (MFR) framework, which integrates classical AI planning principles (explicit state representation) into LLM agent workflows.
*   **Theoretical Insight:** A shift in the understanding of LLM limitations, proposing that the issue is often representation rather than reasoning, thereby highlighting explicit modeling as a necessary component for robust AI agents.
*   **Interpretability and Robustness:** Demonstration that explicit modeling leads to more interpretable and reliable agent behaviors by reducing hallucinations in planning scenarios.
*   **Reproducibility:** The contribution of a fully documented suite of prompts, evaluation procedures, and task datasets to support further research and validation.