# Single-agent or Multi-agent Systems? Why Not Both?

*Mingyan Gao; Yanzi Li; Banruo Liu; Yifan Yu; Phillip Wang; Ching-Yu Lin; Fan Lai*

| **Quick Facts** | |
|:---|:---|
| **Quality Score** | 6/10 |
| **References** | 40 citations |
| **Meta-Controller Accuracy** | 94% selection accuracy |
| **Performance Gain** | +28% task completion vs single-agent |
| **Latency Reduction** | -22% vs multi-agent baselines |
| **Scalability** | 500+ concurrent tasks (p < 0.001) |
| **Communication Efficiency** | 60% reduction vs flat multi-agent |
| **Coordination Overhead** | Capped at 12% of total compute |

---

## Executive Summary

Distributed AI practitioners face a costly architectural binary: single-agent systems sacrifice 50% performance on composite tasks due to poor decomposition, while multi-agent architectures waste 35-40% of computational resources on coordination overhead alone. This forces inefficient operational defaults—either monolithic agents that struggle with cross-domain reasoning or premature multi-agent adoption that incurs prohibitive communication costs and scalability bottlenecks.

The "Why Not Both" (WNB) architecture replaces static pre-deployment selection with a lightweight meta-controller trained via supervised learning on oracle topology labels (94% selection accuracy). Performing real-time complexity analysis of dependency graphs and expertise requirements, the system dynamically routes tasks through either unified single-agent reasoning or specialized multi-agent worker coalitions with hierarchical state sharing. This hybrid approach reduces inter-agent communication volume by 60% compared to flat multi-agent systems, caps coordination costs at 12% of total compute, and incurs less than 8% inference overhead per routing decision.

Experimental validation across 10,000 trial episodes on SWE-bench, WebArena, and custom multi-domain benchmarks demonstrates that WNB achieves 28% higher task completion rates than pure single-agent baselines while reducing average end-to-end latency by 22% compared to multi-agent configurations. The system scales to 500+ concurrent tasks (versus 180 for single-agent and 320 for multi-agent baselines) with statistical significance (p < 0.001). However, the meta-controller exhibits a 6% error rate on tasks with ambiguous decomposition boundaries, and the approach requires substantial offline oracle annotation costs for initial training.

Establishing the first rigorous, empirically-grounded framework for dynamic architectural adaptation, this work challenges the prevailing assumption that single-versus-multi-agent choices must be static binary commitments. While influential for modular AI orchestration and LLM pipeline design, limitations include unquantified long-term training expenses, generalization gaps to novel task distributions outside the training domain, and undefined recovery mechanisms for meta-controller mispredictions, suggesting future research must address sample-efficient training and failure-mode resilience.

---

## Key Findings

* **The Architectural Binary Problem**: Current systems force a costly trade-off between single-agent architectures (sacrificing 50% performance on composite tasks due to poor decomposition) and multi-agent systems (wasting 35-40% of computational resources on coordination overhead).

* **Dynamic Hybrid Superiority**: The WNB architecture eliminates static pre-deployment commitments, instead using real-time analysis to select the optimal execution path on a per-task basis.

* **Significant Communication Savings**: Hierarchical state sharing and intelligent coalition formation reduce inter-agent communication volume by **60%** compared to traditional flat multi-agent hierarchies.

* **Controlled Overhead**: Coordination costs are strictly capped at **12%** of total computational budget, with routing decisions adding less than **8%** inference overhead per task.

* **Scalability Breakthrough**: System handles **500+ concurrent tasks**—outperforming both single-agent (180 tasks) and multi-agent (320 tasks) baselines by substantial margins.

* **Edge Case Vulnerability**: Meta-controller exhibits a **6% error rate** when processing tasks with ambiguous decomposition boundaries, indicating room for improvement in boundary detection.

---

## Methodology

**Core Architecture: "Why Not Both" (WNB)**

The proposed system introduces a **lightweight meta-controller** that acts as an intelligent router between two execution modalities:

1. **Unified Single-Agent Reasoning**: For tasks requiring coherent, cross-domain synthesis
2. **Specialized Multi-Agent Coalitions**: For tasks benefiting from parallel expertise decomposition

**Training Protocol**
* **Supervised Learning**: Meta-controller trained on oracle topology labels
* **Selection Accuracy**: Achieves **94% accuracy** in architectural routing decisions
* **Annotation Cost**: Requires substantial offline oracle annotation for initial training phase

**Real-Time Analysis Pipeline**
* **Dependency Graph Analysis**: Performs complexity analysis of task structures in real-time
* **Expertise Requirement Mapping**: Identifies necessary domain specializations before execution
* **Dynamic Routing**: Selects execution path based on computed efficiency estimates

**State Management**
* **Hierarchical State Sharing**: Optimized communication protocol between agents when multi-agent mode is selected
* **Coalition Formation**: Dynamic grouping of worker agents based on task requirements

---

## Technical Details

| Component | Specification |
|:---|:---|
| **Meta-Controller Type** | Supervised learning classifier on oracle topology labels |
| **Selection Mechanism** | Real-time complexity analysis of dependency graphs |
| **Inference Overhead** | <8% per routing decision |
| **Communication Architecture** | Hierarchical state sharing (vs. flat multi-agent) |
| **Communication Reduction** | 60% volume reduction vs. standard multi-agent |
| **Coordination Cost Cap** | 12% of total compute budget |
| **Error Rate** | 6% on ambiguous decomposition boundaries |
| **Training Data** | Oracle-annotated topology labels |

**Architectural Constraints**
* **Cold Start Requirements**: Dependent on high-quality oracle annotations for initial training
* **Boundary Sensitivity**: Performance degrades on tasks with unclear single/multi-agent boundaries
* **Recovery Mechanisms**: Undefined fallback protocols for meta-controller mispredictions

---

## Results

**Experimental Scope**
* **Trial Volume**: 10,000 episodes
* **Benchmarks**: SWE-bench, WebArena, custom multi-domain benchmarks
* **Statistical Significance**: p < 0.001

**Performance Metrics**

| Metric | WNB Architecture | Single-Agent Baseline | Multi-Agent Baseline |
|:---|:---|:---|:---|
| **Task Completion Rate** | Baseline +28% | Baseline | +12% |
| **End-to-End Latency** | -22% vs multi-agent | +35% | Baseline |
| **Concurrent Task Capacity** | **500+ tasks** | 180 tasks | 320 tasks |
| **Coordination Overhead** | 12% | N/A | 35-40% |

**Key Achievements**
* Outperforms pure single-agent approaches by **28%** in task completion rates
* Reduces latency by **22%** compared to multi-agent configurations
* Scales to **500+ concurrent tasks**, demonstrating superior resource utilization
* Maintains statistical significance (p < 0.001) across all benchmark domains

---

## Contributions

* **First Empirical Framework for Dynamic Adaptation**: Establishes the first rigorous, empirically-grounded methodology for runtime architectural selection in distributed AI systems.

* **Paradigm Challenge**: Refutes the prevailing industry assumption that single-versus-multi-agent commitments must be static, pre-deployment decisions.

* **Operational Efficiency**: Demonstrates that hybrid architectures can simultaneously reduce communication overhead *and* improve task completion rates, breaking the traditional trade-off paradigm.

* **Practical Impact**: Provides an influential blueprint for modular AI orchestration and LLM pipeline design, applicable to production-scale distributed systems.

---

## Limitations & Assessment

**Critical Limitations**
* **Training Cost Opacity**: Long-term training expenses remain unquantified, raising concerns about total cost of ownership.
* **Generalization Gaps**: Performance degradation on novel task distributions outside the training domain.
* **Failure Mode Gaps**: Undefined recovery mechanisms for meta-controller mispredictions create potential system reliability risks.
* **Annotation Burden**: Requires substantial upfront investment in oracle labeling for initial training.

**Quality Assessment: 6/10**

While the WNB architecture presents a compelling technical solution to a genuine operational pain point, the quality score reflects concerns regarding:
* Unaddressed long-term maintenance costs
* Limited generalization guarantees
* Absence of error recovery protocols
* High initial annotation requirements

**Future Research Directions**
* Development of sample-efficient training methods to reduce oracle annotation dependencies
* Implementation of robust failure-mode resilience and automatic recovery mechanisms
* Extension to novel task distributions through meta-learning or few-shot adaptation techniques