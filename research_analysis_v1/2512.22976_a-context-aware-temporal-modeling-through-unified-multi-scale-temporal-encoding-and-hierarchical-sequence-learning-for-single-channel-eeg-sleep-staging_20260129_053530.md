# A Context-Aware Temporal Modeling through Unified Multi-Scale Temporal Encoding and Hierarchical Sequence Learning for Single-Channel EEG Sleep Staging

*Amirali Vakili; Salar Jahanshiri; Armin Salimi-Badr*

---

### üìä Quick Facts

| Metric | Details |
| :--- | :--- |
| **Overall Accuracy** | 89.72% |
| **Macro F1-Score** | 85.46% |
| **N1 Stage F1-Score** | 61.7% |
| **Input Signal** | Single-channel EEG (Fpz-Cz) |
| **Datasets** | SleepEDF-20 (42k epochs), SleepEDF-78 (199k epochs) |
| **Core Architecture** | CNN Frontend + Hierarchical BiLSTM + MLP |
| **Strategy** | Sub-epoch segmentation & Probability Averaging |

---

### üìù Executive Summary

> **Context & Problem:** Automated sleep staging using single-channel EEG is essential for scalable, wearable sleep medicine. However, the field faces challenges with the non-stationary nature of EEG signals and the difficulty of capturing long-range temporal dependencies. Many existing deep learning models act as "black boxes," lacking the interpretability required for clinical adoption. Furthermore, significant class imbalance‚Äîparticularly the under-representation of the N1 stage‚Äîoften results in high overall accuracy but poor detection of minority classes.
>
> **Solution:** This paper introduces a context-aware temporal modeling framework that merges unified multi-scale temporal encoding with hierarchical sequence learning. The architecture employs a CNN frontend with parallel branches to extract compact multi-scale features, processed by a Hierarchical BiLSTM to model temporal context. To ensure robustness and interpretability, 30-second epochs are segmented into sub-epoch chunks, with final predictions derived by averaging softmax probabilities.
>
> **Outcomes:** Validated on the SleepEDF-20 and SleepEDF-78 datasets, the framework achieved an **89.72% accuracy** and an **85.46% macro F1-score**. Notably, it significantly improved the detection of the difficult N1 stage, securing an F1-score of **61.7%**. This research successfully bridges the gap between high-performance deep learning and clinical viability, offering an interpretable, state-of-the-art solution for automated sleep diagnostics.

---

## üîç Key Findings

*   **High Overall Performance:** The proposed framework achieved an overall accuracy of **89.72%** and a macro-average F1-score of **85.46%** on the SleepEDF datasets.
*   **Significant Improvement in N1 Detection:** The model notably improved the detection of the challenging N1 sleep stage, attaining an F1-score of **61.7%**.
*   **Effective Data Imbalance Handling:** By employing class-weighted loss functions and data augmentation, the study successfully mitigated the issue of class imbalance.
*   **Validation of Context-Aware Approach:** The results confirmed that averaging softmax probabilities across segmented sub-epoch chunks enhances robustness and contextual representation.
*   **Clinical Viability:** The study demonstrated that high performance does not require sacrificing interpretability.

## üß† Methodology

The study proposes a context-aware and interpretable framework designed specifically for single-channel EEG signals. The architecture integrates compact multi-scale feature extraction with temporal modeling. To address class imbalance, the methodology utilizes class-weighted loss functions and data augmentation. The process involves segmenting EEG signals into sub-epoch chunks, with final predictions derived by averaging softmax probabilities across these chunks to ensure stability.

## ‚ú® Contributions

*   **Enhanced Interpretability:** Introduction of a framework that moves away from 'black box' stacked-layer models by utilizing clearly defined and interpretable feature extraction roles.
*   **Advanced Temporal Encoding:** Development of a unified approach that combines compact multi-scale feature extraction with hierarchical sequence learning.
*   **Robustness Mechanism:** Implementation of a sub-epoch segmentation and probability averaging strategy to improve the contextual representation and robustness of sleep staging predictions.

## ‚öôÔ∏è Technical Details

**Architecture Pipeline**
*   **Frontend:** CNN Encoder
*   **Temporal Modeling:** Hierarchical BiLSTM
*   **Classifier:** MLP Classifier

**Input Processing**
*   **Channel:** Single-channel EEG (Fpz-Cz)
*   **Epoch Segmentation:** 30-second epochs split into six 5-second sub-epochs.
*   **Sliding Window:** Processed in a sliding window of three (preceding, central, succeeding).
*   **Tensor Shape:** $B \cdot W \times 1 \times 500$

**CNN Encoder Specifications**
*   **Structure:** Parallel branches with kernel sizes **7, 15, and 31**.
*   **Convolutions:** Depthwise separable convolutions.
*   **Attention:** Squeeze-and-Excitation block (reduction ratio $r=8$).
*   **Compression:** Three temporal compression blocks reduce 500 samples to **5 latent time steps** ($B \cdot W \times 256 \times 5$).

**Hierarchical BiLSTM Configuration**
*   **Intra-window Layer:** Hidden size **64**.
*   **Inter-window Layer:** Hidden size **128**.
*   **Pooling Mechanism:** Additive attention pooling ($d_{att}=64$).

**Classifier & Optimization**
*   **MLP Structure:** 256-512-256-5 layers.
*   **Activation/Regularization:** GELU, Batch Normalization, and Dropout.
*   **Loss Function:** Weighted Cross-Entropy Loss.
*   **Regularization:** L2 regularization ($1e-4$).
*   **Optimizer:** Adam ($LR=1e-4$) with ReduceLROnPlateau scheduling.

## üìà Results

Experiments were conducted on **SleepEDF-20** (42,308 epochs) and **SleepEDF-78** (199,352 epochs).

*   **Performance:**
    *   Overall Accuracy: **89.72%**
    *   Macro-average F1-score: **85.46%**
*   **Class-Specific Success:** Significant improvement in N1 stage detection with an F1-score of **61.7%**.
*   **Analysis:** The attention mechanism provided interpretability regarding temporal context, and averaging softmax probabilities across sub-epochs was confirmed to enhance robustness.

***

**Quality Score:** 8/10  
**References:** 36 citations