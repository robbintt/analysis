---
title: Reward function compression facilitates goal-dependent reinforcement learning
arxiv_id: '2509.0681'
source_url: https://arxiv.org/abs/2509.06810
generated_at: '2026-02-03T06:50:10'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Reward function compression facilitates goal-dependent reinforcement learning

*Gaia Molinaro; Anne G. E. Collins*

| **Quick Facts** | |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **Total Citations** | 40 |
| **Study Scope** | 6 Behavioral Experiments |
| **Key Sample Size** | 51 Participants (Exp 2) |
| **Core Mechanism** | Reward Function Compression |

---

## Executive Summary

> This research addresses the fundamental bottleneck in goal-dependent reinforcement learning: the high cognitive cost associated with evaluating outcomes relative to specific goals. While standard reinforcement learning relies on stable, pre-learned values, goal-dependent learning requires the active comparison of outcomes to current goals, a process that heavily taxes working memory (WM). The paper investigates how human learners maintain efficiency as the size and complexity of the goal space increaseâ€”a challenge that often leads to parametric performance degradation in both biological and artificial systems.
>
> The authors introduce a novel theoretical framework centered on "reward function compression," proposing a dual-memory system architecture for goal-dependent learning. Technically, the model posits that learning transitions from an active, resource-intensive valuation process in Working Memory (WM) to a "compressed" representation stored in Long-Term Memory (LTM). This compression is contingent on the structure of the goal space; if goals share underlying structure, the reward function can be simplified into a stable format that supports automatic valuation. By offloading complex calculations to LTM, the brain frees WM resources, allowing for efficient decision-making even in large goal spaces.
>
> The findings are supported by six behavioral experiments and computational modeling. Results showed that learning accuracy was significantly higher in "Compressible" blocks compared to "Incompressible" blocks. Experiment 1 further established a positive correlation between faster reward processing and better learning performance. This study significantly advances the understanding of human motivation by elucidating the neurocognitive transition from effortful control to automaticity and offers valuable insights for designing more resource-efficient artificial intelligence systems.

---

## Key Findings

*   **Goal Space Impact:** Learning efficiency is parametrically impaired by the size of the goal space; larger spaces demand significantly more cognitive resources.
*   **Compression Benefit:** Performance improves specifically when the structure of the goal space allows for the compression of reward information.
*   **Processing Speed:** There is a positive correlation between faster reward processing (lower Reaction Times) and better learning performance, supporting the theory that automatic valuation frees up working memory resources.
*   **Memory Transition:** Efficient goal-directed learning relies on the transition from active working memory processing to a "compressed" reward function stored in long-term memory.

---

## Technical Details

**System Architecture**
*   **Dual-Memory Model:** Proposes a system consisting of **Working Memory (WM)** for active outcome valuation and **Long-Term Memory (LTM)** for storing compressed reward functions.
*   **Process Flow:** The process transitions from active, resource-heavy processing in WM to compressed, efficient processing in LTM.

**Experimental Paradigm**
*   **Comparison:** Contrasts Standard RL ('Points' blocks with numeric feedback) against Goal-Dependent RL ('Goals' blocks with abstract feedback).
*   **Stimuli:** Uses geometric figures varying on binary dimensions (Shape, Color, Fill).

**Compressibility Protocol (Experiment 2)**
*   **Compressible Condition:** A single feature distinguishes the Goal, allowing for easy compression.
*   **Incompressible Condition:** Requires a conjunctive rule (combination of features), preventing compression.

---

## Methodology

The study employs a mixed-method approach to validate the theoretical framework:

1.  **Experimental Validation**
    *   Conducted a series of **six behavioral experiments**.
    *   Designed specifically to manipulate and measure the effects of goal space size and structure on learning efficiency.

2.  **Computational Modeling**
    *   Leveraged computational modeling to interpret behavioral data.
    *   Provided quantitative support for the proposed cognitive mechanisms of reward function compression.
    *   Model simulations using learning rates derived from Reaction Times successfully tracked participant behavior.

---

## Results

*   **Experiment 1:** Demonstrated a positive correlation between faster reward processing (lower RTs) and better learning. Performance notably degraded as the number of goal pairs increased.
*   **Experiment 2 ($n=51$):**
    *   Learning accuracy was significantly higher in **Compressible blocks** compared to Incompressible blocks.
    *   **Statistical Significance:** $t(50) = 3.31$, $p = 0.002$.
*   **Model Validation:** Simulations confirmed that automatic valuation mechanisms effectively free up working memory resources, aligning with observed behavioral data.

---

## Contributions

*   **Theoretical Framework:** Introduces a novel cognitive model proposing that goal-dependent learning is initially constrained by working memory capacity but becomes efficient through the compression of complex goals into simplified, stable reward functions stored in long-term memory.
*   **Neuroscientific Insight:** Sheds light on the cognitive mechanisms underlying human motivation and offers new perspectives on the neuroscience of intrinsic motivation.
*   **Practical Application:** Provides a basis for improving behavioral techniques and interventions aimed at helping individuals achieve their goals more effectively by optimizing how reward information is processed.

---

**References:** 40 citations