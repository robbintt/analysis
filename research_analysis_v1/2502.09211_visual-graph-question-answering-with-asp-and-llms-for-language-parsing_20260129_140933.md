# Visual Graph Question Answering with ASP and LLMs for Language Parsing

*Jakob Johannes Bauer; Thomas Eiter; Nelson Higuera Ruiz; Johannes Oetsch*

---

> ### **Quick Facts**
>
> *   **System Architecture:** NSGRAPH (Modular Neuro-Symbolic)
> *   **Overall Accuracy:** 73% (Baseline)
> *   **Training Strategy:** Zero-shot (No task-specific fine-tuning)
> *   **Core Components:** OCR, Large Language Models (LLMs), Answer-Set Programming (ASP)
> *   **Dataset:** VGQA (Derived from CLEGR)
> *   **Focus:** Transit and Metro Network Visuals

---

## Executive Summary

**Problem**  
This paper addresses **Visual Graph Question Answering (VGQA)**, a novel domain requiring AI systems to interpret and reason over graph structures presented as raw images—specifically metro and transit networks—rather than relying on pre-defined symbolic data. Standard Visual Question Answering (VQA) models typically excel at identifying objects in natural scenes but lack the capability to process the structured, topological relationships inherent in technical diagrams. Conversely, traditional graph reasoning methods cannot process raw pixel inputs. This research is critical because it bridges the semantic gap between visual perception and logical inference, enabling machines to automate the interpretation of complex scientific and engineering diagrams without manual symbolic transcription.

**Innovation**  
The key innovation is **NSGRAPH**, a modular neuro-symbolic architecture that decouples perception from logical reasoning using a strict zero-shot learning strategy. Technically, the system operates through three distinct pipelines: a **Visual Module** that employs optical graph recognition scripts for topology extraction alongside EasyOCR for text labeling; a **Language Module** that utilizes Large Language Models (LLMs) to parse natural language questions into structured functional program trees; and a **Reasoning Module** implemented via Answer-Set Programming (ASP). This design allows the system to leverage the robust pattern recognition of deep learning for input parsing while delegating complex deductive tasks to logic programming, all without requiring task-specific fine-tuning or training on the target dataset.

**Results**  
Experimental evaluation was conducted on a newly introduced dataset derived from the CLEGR benchmark, augmented with visual representations of transit networks. The NSGRAPH system established a strong baseline for VGQA tasks, achieving an overall average accuracy of **73%**. Crucially, the results demonstrate that the system can successfully handle complex queries requiring multi-step logical inference (such as determining connectivity or pathfinding) based solely on the structured knowledge extracted by the neural components. This performance validates the feasibility of performing high-level reasoning directly on visual graph data without intermediate human symbolic conversion.

**Impact**  
The significance of this research lies in its empirical validation of a neuro-symbolic framework that synergistically combines the generative capabilities of LLMs with the rigorous explainability of Answer-Set Programming. By demonstrating that complex visual reasoning tasks can be decomposed into modular, pretrained components, the study offers a scalable path toward AI systems that are both robust and transparent. This work advances the field by reducing the dependency on massive, task-specific labeled datasets for logical reasoning and provides a foundational architecture for future applications in automated technical analysis and scientific document understanding.

---

## Key Findings

*   **High Baseline Accuracy:** The proposed modular neuro-symbolic approach achieved a baseline overall average accuracy of **73%** on the Visual Graph QA dataset.
*   **Zero-Shot Efficiency:** The system demonstrates that complex VQA tasks can be solved effectively using a combination of pretrained models (OCR and LLMs) without requiring further task-specific training or fine-tuning.
*   **Neuro-Symbolic Validation:** The results provide empirical evidence supporting the potential of integrating logic programming (ASP) with neural modules.
*   **Visual to Logical Feasibility:** The study proves the feasibility of answering questions about images of graph structures (specifically transit networks) rather than symbolic graph representations.

---

## Methodology

The researchers utilized a **modular neuro-symbolic architecture** that separates the input processing into distinct specialized components:

*   **Visual Parsing:** Utilized optical graph recognition to identify structural components within the image.
*   **Label Extraction:** Employed a pretrained optical character recognition (OCR) neural network to extract text labels.
*   **Language Processing:** Leveraged Large Language Models (LLMs) to process and interpret natural language questions.
*   **Logical Reasoning:** Implemented final inference based on the extracted structured data using Answer-Set Programming (ASP).

---

## Technical Details

| Component | Description |
| :--- | :--- |
| **System Name** | NSGRAPH |
| **Architecture** | Modular Neuro-Symbolic System (combines neural perception with symbolic reasoning). |
| **Visual Module** | Uses Optical Graph Recognition scripts and **EasyOCR** for topology and labeling. |
| **Language Module** | Uses **Large Language Models (LLMs)**. |
| **Reasoning Module** | Uses **Answer-Set Programming (ASP)**. |
| **Data Representation** | Questions are represented as functional program trees. |
| **Dataset** | **VGQA** dataset derived from CLEGR; contains images of transit networks with station and edge attributes. |
| **Training Strategy** | Zero-shot; relies exclusively on pretrained models without task-specific fine-tuning. |

---

## Contributions

*   **Novel Problem Definition:** Addressed **Visual Graph Question Answering (VGQA)**, requiring interpretation of graph images rather than symbolic data.
*   **Dataset Generation:** Introduced a new dataset based on existing data, augmented with images of graphs resembling metro/transit lines.
*   **Framework Development:** Presented a unique neuro-symbolic framework bridging optical graph recognition, OCR, LLMs, and logic-based reasoning (ASP).
*   **Interpretability Insights:** Contributed insights into how modular neuro-symbolic systems can combine pretrained models with logic programming to enhance AI interpretability and explainability.

---

## Results

The **NSGRAPH system** achieved a baseline overall average accuracy of **73%** on the Visual Graph QA (VGQA) dataset. The results demonstrate the feasibility of answering questions about visual graph structures rather than requiring symbolic graph representations. Furthermore, the system successfully handles complex queries requiring multi-step reasoning without explicit training on those specific logical operations.

---

**Quality Score:** 9/10  
**References:** 40 citations