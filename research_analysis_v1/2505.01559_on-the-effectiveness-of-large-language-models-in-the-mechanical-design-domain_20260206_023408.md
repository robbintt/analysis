---
title: On the effectiveness of Large Language Models in the mechanical design domain
arxiv_id: '2505.01559'
source_url: https://arxiv.org/abs/2505.01559
generated_at: '2026-02-06T02:34:08'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# On the effectiveness of Large Language Models in the mechanical design domain

*Daniele Grandi; Fabian Riquelme*

---

> ### ðŸ“Š Quick Facts
>
> *   **Dataset**: ABC Dataset (~1M CAD models $\to$ 61,725 usable assemblies)
> *   **Unique Names**: 48,644
> *   **Binary Classification Accuracy**: 0.62
> *   **Zero-Shot Top-1 Accuracy**: 0.386
> *   **Quality Score**: 8/10
> *   **Citations**: 40

---

## Executive Summary

While Large Language Models (LLMs) have demonstrated remarkable capabilities in general-purpose language processing, their effectiveness in specialized, technical domains remains largely unproven. This paper addresses the critical gap in understanding how LLMs handle semantic data within the mechanical design context, specifically the language used to name assemblies and parts in Computer-Aided Design (CAD) models.

This evaluation is vital because mechanical engineering vocabulary and syntax differ significantly from general text, raising questions about whether standard architectures can learn these technical relationships or if they will simply overfit to the data due to the domain's high specificity and limited datasets.

The study introduces a rigorous evaluation framework utilizing the ABC dataset, which comprises approximately 1 million CAD models processed down to 61,725 unique assemblies. The authors developed two distinct technical tasks to assess model viability: a binary sentence-pair classification task and a zero-shot classification task.

The core technical innovation lies in the specific fine-tuning architecture applied to a pre-trained BERT encoder, enhanced with a multi-head attention layer and a dense layer. To combat the prevalent issue of catastrophic forgetting and over-fitting in domain-specific adaptation, the researchers systematically identified optimal hyperparameters, specifically determining that low learning rates ($\le 1\text{e}-4$), specific dropout adjustments, and sequence length optimization were essential for retaining learned features while adapting to mechanical design data.

The study yielded concrete performance metrics that highlight both the potential and the limitations of current LLMs in this domain. In the binary sentence-pair classification task, the fine-tuned model achieved an accuracy of 0.62, a result directly attributed to the strategies employed to mitigate over-fitting. In the zero-shot classification task, designed to test generalization to unseen data, the model achieved a top-1 classification accuracy of 0.386, significantly outperforming baseline methods.

This research provides a foundational benchmark for the application of LLMs within mechanical engineering, moving beyond theoretical generalizations to empirical evidence of performance on technical semantic data. By pinpointing specific failure modes and the architectural adjustments required to handle engineering language, the study offers a clear pathway for future development of engineering-focused AI tools.

---

## Key Findings

*   **Performance in Binary Classification**: A fine-tuned model achieved an accuracy of **0.62** on a binary sentence-pair classification task by employing techniques to combat over-fitting.
*   **Zero-Shot Superiority**: The model significantly outperformed baselines in a zero-shot classification task, achieving a top-1 classification accuracy of **0.386**.
*   **Optimization Strategies**: The study identified specific hyperparameters and architectural adjustmentsâ€”learning rates, dropout values, sequence length, and the addition of a multi-head attention layerâ€”that were critical to fighting over-fitting and improving performance.
*   **Domain-Specific Challenges**: The results illuminated specific failure modes that occur when large language models attempt to learn from language within the mechanical design domain.

---

## Methodology

The study utilized the ABC dataset, leveraging semantic data consisting of designer-assigned names for overall assemblies and individual part names. The data underwent pre-processing to prepare it for evaluation.

Two distinct tasks were developed to evaluate model architectures on domain-specific data:
1.  A binary sentence-pair classification task.
2.  A zero-shot classification task.

The approach involved fine-tuning models with a specific focus on mitigating over-fitting, achieved through the modification of learning rates, dropout values, sequence length, and the integration of a multi-head attention layer.

---

## Technical Details

| Component | Specification & Implementation |
| :--- | :--- |
| **Dataset** | ABC Dataset (~1 million CAD models) processed through a cleaning pipeline (deduplication and RegEx). |
| **Final Data Volume** | 61,725 assemblies (48,644 unique names). |
| **Task 1 Architecture** | Pre-trained BERT encoder processes sentence pairs (constructed via template) $\to$ Multi-head Attention Layer $\to$ Dense Layer. |
| **Fine-Tuning Strategy** | Prevention of catastrophic forgetting via hyperparameter testing. |
| **Learning Rates Tested** | $1 \times 10^{-2}$, $1 \times 10^{-3}$, and $1 \times 10^{-4}$ (values $\le 1\text{e}-4$ identified as effective). |
| **Task 2 Architecture** | Contrastive pre-training applied to a text encoder to create embeddings from batches of 100 unseen part and assembly name sentences. |

---

## Results

*   **Binary Sentence-Pair Classification**: Achieved an accuracy of **0.62** through techniques combating over-fitting.
*   **Zero-Shot Classification**: Achieved a Top-1 Classification Accuracy of **0.386**, significantly outperforming baseline methods.
*   **Data Processing**: Reduction from 88,886 initial assemblies to 61,725 final assemblies, with 48,644 having unique names.
*   **Optimization Analysis**: Identified low learning rates, dropout adjustments, and sequence length optimization as critical factors for success in the mechanical design domain.

---

## Contributions

*   **Domain-Specific Evaluation**: Provided a comprehensive assessment of Large Language Model (LLM) performance specifically within the mechanical engineering domain, moving beyond general-purpose language tasks.
*   **Benchmarking Technical Language**: Established performance benchmarks for processing semantic engineering data (assembly and part names) using both fine-tuned and zero-shot methodologies.
*   **Failure Analysis**: Contributed to the understanding of how LLMs struggle with technical domain language by identifying specific failure modes, offering a pathway for future improvements in engineering-focused AI applications.

---

**References:** 40 citations | **Quality Score:** 8/10