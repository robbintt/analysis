---
title: 'Memoria: A Scalable Agentic Memory Framework for Personalized Conversational
  AI'
arxiv_id: '2512.12686'
source_url: https://arxiv.org/abs/2512.12686
generated_at: '2026-02-03T13:25:08'
quality_score: 6
citation_count: 14
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Memoria: A Scalable Agentic Memory Framework for Personalized Conversational AI

*Samarth Sarin; Lovepreet Singh; Bhaskarjit Sarmah; Dhagash Mehta*

---

### ðŸ“Š Quick Facts

| Metric | Details |
| :--- | :--- |
| **Quality Score** | 6/10 |
| **Total Citations** | 14 |
| **Core Architecture** | Hybrid (Dynamic Summarization + Weighted KG) |
| **Primary Objective** | Bridging stateless LLMs and agentic memory systems |

---

> ### ðŸ“ Executive Summary
>
> Standard Large Language Model (LLM) interfaces operate as **stateless systems**, lacking the architectural mechanisms to maintain persistent memory or long-term personalization across sessions. This limitation creates a significant technical barrier for developing adaptive conversational AI, as models cannot recall user-specific traits or preferences without exhausting limited context windows. The inability to bridge the gap between static, stateless processing and the requirement for dynamic, agent-like persistence remains a critical bottleneck for the industrial-scale deployment of personalized AI.
>
> To address this, the authors introduce **Memoria**, a modular framework that operationalizes "agentic memory" through a hybrid architecture. The system integrates two distinct components: a **Dynamic Session-Level Summarization** module that manages immediate dialogue context for short-term coherence, and a **Weighted Knowledge Graph (KG)-Based User Modeling** engine. This KG incrementally captures and structures user traits, preferences, and behavioral patterns as entities and relationships. By retrieving only relevant subsets of this structured data during inference, the system technically resolves the conflict between maintaining rich, persistent user context and adhering to the strict token constraints of large language models.
>
> Validation experiments confirmed that the Memoria framework successfully maintains both short-term coherence and long-term personalization without exceeding token limits. The system demonstrated the capacity to accurately model complex user data as structured entities and relationships, functioning reliably within the limitations of current LLM context windows. By retrieving relevant information efficiently, the framework proved capable of executing operations without context overflow, validating its practicality for handling persistent, user-centric interactions in real-time scenarios.

---

## Key Findings

*   **Hybrid Architecture Success:** The integration of dynamic session-level summarization with a weighted knowledge graph allows the system to maintain both short-term coherence and long-term personalization without exceeding token constraints.
*   **Bridging the Gap:** Memoria successfully bridges the gap between standard stateless LLM interfaces and advanced agentic memory systems.
*   **Industry Scalability:** The framework offers a practical, scalable solution for deploying personalized conversational AI in industry settings.
*   **Structured Data Modeling:** The system effectively captures and models user traits, preferences, and behavioral patterns as structured entities and relationships.

---

## Methodology

The research proposes Memoria, a modular memory framework designed to augment LLM-based conversational systems. The methodology relies on a hybrid architecture comprising two complementary components:

1.  **Dynamic Session-Level Summarization:** Used to process immediate dialogue context and ensure short-term coherence.
2.  **Weighted Knowledge Graph (KG)-Based User Modelling:** An engine that incrementally captures and stores user traits, preferences, and behavioral patterns as structured entities and relationships.

---

## Technical Details

*   **Architecture Type:** Hybrid architecture combining dynamic session-level summarization with a weighted knowledge graph.
*   **Data Representation:** User-specific information (traits, preferences) is modeled as structured entities and relationships.
*   **Token Management:** The system manages token constraints by retrieving relevant information to maintain context.
*   **System Role:** Acts as a bridge between stateless LLM interfaces and agentic memory systems.

---

## Research Contributions

*   **Conceptualization of Agentic Memory:** The paper defines and operationalizes 'agentic memory' as a mechanism for agent-like persistence.
*   **Development of the Memoria Framework:** Introduction of a modular, interpretable memory framework that provides LLMs with context-rich and persistent memory capabilities.
*   **Resolution of Token Constraints:** A technical contribution addressing the challenge of maintaining long-term context and personalization within the strict token limits of large language models.
*   **Enabler for Adaptive Agents:** Providing the foundational memory layer required for LLMs to function as truly interactive, adaptive, and personalized agents.

---

## Results & Validation

*   **Coherence & Personalization:** The system successfully maintained short-term coherence and long-term personalization simultaneously.
*   **Operational Efficiency:** Operations were performed efficiently without exceeding token constraints.
*   **Industry Readiness:** The framework was validated as a practical and scalable solution suitable for industry deployment.
*   **Data Accuracy:** Proved effective in the accurate capture and modeling of complex user data.