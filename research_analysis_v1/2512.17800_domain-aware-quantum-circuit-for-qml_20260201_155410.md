# Domain-Aware Quantum Circuit for QML
*Gurinder Singh; Thaddeus Pellegrini; Kenneth M. Merz*

---

### ðŸ“Š Quick Facts

| **Metric** | **Value** |
| :--- | :--- |
| **Target Hardware** | IBM Kingston |
| **Qubit Count** | 16 Logical, 22 Physical (6 Ancilla) |
| **Trainable Parameters** | 512 |
| **Execution Time** | ~41 seconds / circuit |
| **Expressibility ($D_{KL}$)** | $7.5 \times 10^{-3}$ (at 48 ECR gates) |
| **Quality Score** | 8/10 |

---

## Executive Summary

This research addresses critical bottlenecks hindering the application of Quantum Machine Learning (QML) to image classification on Noisy Intermediate-Scale Quantum (NISQ) hardware. Specifically, it targets the "**barren plateau**" phenomenon, where gradient magnitudes vanish exponentially with increasing circuit depth, rendering optimization infeasible. Additionally, the paper tackles the susceptibility of generic quantum circuits to hardware noise and decoherence, which often degrades performance on real devices.

The authors argue that without integrating domain-specific knowledge into the circuit architecture, training quantum models for complex tasks like computer vision remains impractical. The key innovation is the **Domain-Aware Quantum Circuit (DAQC)**, a locality-preserving topology that integrates classical image priors directly into the quantum structure. The method employs "Locality-Preserving Encoding," where input images are downsampled and partitioned into non-overlapping $4 \times 4$ patches arranged in a zigzag DCT-style order.

Benchmarked on an IBM Kingston QPU, DAQC achieved superior performance compared to Quantum Circuit Search baselines and competitive results against classical deep learning models. The architecture demonstrated robust expressibility, with the Kullback-Leibler divergence ($D_{KL}$) decreasing as depth increased, indicating a rich optimization landscape without saturation. Operations were sustained despite significant gate errors and dephasing times, facilitated by a comprehensive error mitigation stack.

This work establishes a new high-performance standard for hybrid QML-classical image classification, suggesting that the viability of NISQ-era QML depends less on increasing circuit depth and more on **hardware-conscious designs** that respect data locality and device topology.

---

## Key Findings

*   **Superior Benchmarking:** The Domain-Aware Quantum Circuit (DAQC) achieves superior results on real quantum hardware for QML image classification, performing competitively with classical deep learning baselines.
*   **Baseline Outperformance:** Significantly outperforms existing Quantum Circuit Search baselines.
*   **Barren Plateau Mitigation:** Successfully mitigates barren plateaus by reducing long-range two-qubit operations and maintaining short-range correlations.
*   **Noise Robustness:** Demonstrates robustness to hardware noise through optimized depth and entanglement alignment with device connectivity.
*   **Optimization Landscape:** Improves the optimization landscape, offering a practical solution to the gradient vanishing problem common in high-dimensional quantum circuits.

---

## Methodology

The research proposes a hardware-conscious approach to Quantum Machine Learning, moving away from generic ansÃ¤tze toward domain-aware architectures.

1.  **Domain-Aware Architecture:** Leverages classical image priors to inform the quantum circuit structure.
2.  **Locality-Preserving Encoding:** Utilizes non-overlapping DCT-style zigzag windows to map image data onto qubits, preserving local spatial relationships.
3.  **Interleaved Cycles:** The system employs a repeating structure of three stages:
    *   **Feature Encoding**
    *   **Entanglement:** Strictly between neighboring pixels (adjacent qubits) to align with hardware connectivity.
    *   **Training:** Trainable one-qubit rotations.
4.  **Receptive Field Expansion:** Expands the effective receptive field through staged locality-preserving flow.
5.  **Hybrid Readout:** Pairs a quantum feature extractor with a linear classical readout layer for classification.

---

## Technical Details

### Data Pre-processing & Scaling
*   **Downsampling:** Input images are reduced (e.g., $28 \times 28$ to $16 \times 16$).
*   **Patch Partitioning:** Images are split into non-overlapping $4 \times 4$ patches.
*   **Ordering:** Patches arranged in zigzag order (DCT-style).
*   **Normalization:** Data normalized to $[0, \pi]$ for angle encoding.

### Architecture & Training
*   **Cycle Composition:** $T$ interleaved cycles of feature encoding, local entanglement, and trainable rotations.
*   **Entanglement:** Uses hardware-native **ECR gates** on adjacent qubits.
*   **Readout:** 1-local Pauli-Z expectation values mapped to logits via a linear layer.
*   **Loss Function:** Cross-Entropy loss minimization.
*   **Optimizer:** Adam (Learning Rate: 0.005, Epochs: 250).
*   **Compute Resource:** NVIDIA A100 simulator for training.

### Hardware Configuration (IBM Kingston)
*   **Qubit Utilization:** 16 Logical, 22 Physical (6 Ancilla).
*   **Transpilation:** Optimization Level 3.
*   **Error Mitigation Stack:**
    *   Dynamical Decoupling
    *   Pauli Twirling
    *   TREX
    *   Zero-Noise Extrapolation (ZNE)

---

## Results

### Expressibility Metrics
*   **Metric:** Kullback-Leibler divergence ($D_{KL}$) on 16 qubits.
*   **Progression:** $D_{KL}$ decreased from $\approx 1.15 \times 10^{-2}$ at shallow depth (16 ECR gates) to $7.5 \times 10^{-3}$ at 48 ECR gates.
*   **Saturation:** Saturation occurred between 48â€“64 ECR gates, indicating a robust optimization landscape.

### Hardware Characteristics
*   **Relaxation Time ($T_1$):** Median 260 $\mu$s.
*   **Dephasing Time ($T_2$):** Median 130 $\mu$s.
*   **Gate Errors:** Median $3 \times 10^{-4}$ (single-qubit) and $2 \times 10^{-3}$ (two-qubit).
*   **Readout Error:** $1 \times 10^{-2}$.
*   **Execution:** ~41 seconds per circuit (32,000 shots).

### Final Configuration
*   **Logical Qubits:** 16
*   **Cycles:** 16 (Entanglement at $t=1, 5, 9, 13$)
*   **Embedding Features:** 256
*   **Parameters:** 512 trainable parameters

---

## Contributions

*   **Novel Topology:** Introduces a locality-preserving quantum circuit topology that integrates domain knowledge via DCT-style windows.
*   **Barren Plateau Solution:** Improves the optimization landscape by solving the barren plateau problem through short-range correlations.
*   **NISQ-Efficiency:** Presents a NISQ-efficient, hardware-conscious design that minimizes long-range operations.
*   **Performance Standard:** Establishes a new high-performance standard for hybrid QML-classical image classification on real hardware.

---
**Quality Score:** 8/10 | **References:** 40 citations
