# MTMD: A Multi-Task Multi-Domain Framework for Unified Ad Lightweight Ranking at Pinterest

*Xiao Yang; Peifeng Yin; Abe Engle; Jinfeng Zhuang; Ling Leng*

***

> ### **Quick Facts: Key Metrics**
> *   **Performance:** Offline loss reduction of **12%–36%**; Online CPC reduction of **2%**.
> *   **Efficiency:** Single MTMD model replaced **9** distinct production models.
> *   **Architecture:** Two-Tower paradigm with Mixture-of-Experts (MoE).
> *   **Scale:** Trained on hundreds of millions of samples over 20–60 days.
> *   **Inference:** Optimized for low latency via single expert activation per request.

***

## Executive Summary

Large-scale recommender systems face the complex challenge of accommodating diverse ad products, user surfaces, and optimization objectives. Historically, these requirements have been met by training and maintaining separate models for each specific domain (e.g., Home Feed, Search, Related Pins) and task (e.g., CTR, CVR). While functional, this fragmented approach results in high operational overhead, hinders efficient knowledge sharing, and introduces inconsistencies in model serving.

This paper addresses these issues by unifying heterogeneous prediction tasks into a single, efficient "lightweight ranking" architecture. The authors propose the **Multi-Task Multi-Domain (MTMD) framework**, built upon a Two-Tower architecture to facilitate fast inference via dot products. The core innovation is a novel **Mixture-of-Experts (MoE)** design that decouples shared knowledge from domain-specific specialization. This architecture utilizes Domain Experts equipped with Squeeze-and-Excitation (SE) blocks and per-domain Batch-Norm, while a Domain Adaptation Module promotes effective knowledge transfer between experts.

Experimental evaluation on hundreds of millions of samples demonstrated substantial offline improvements, with **Log Mean Absolute Error (LogMAE) reductions ranging from 12% to 36%**. In online A/B testing, the framework delivered a **2% reduction in Cost Per Click (CPC)**. Operationally, the model successfully consolidated infrastructure by replacing nine distinct production models with a single unified architecture. This work establishes a precedent for unified modeling in advertising technology, proving that constrained multi-task optimization can reduce infrastructure complexity while simultaneously improving core business metrics.

***

## Key Findings

*   **Significant Loss Reduction:** The MTMD framework achieved a reduction in offline loss values by **12% to 36%** across various domains.
*   **Online Business Impact:** Demonstrated a **2% reduction in Cost Per Click (CPC)** during online A/B testing.
*   **Operational Consolidation:** A single MTMD model successfully replaced **9 distinct production models**, simplifying the deployment pipeline and maximizing value for the platform, advertisers, and users.
*   **Unified Handling:** The model effectively handles diverse ad types, surfaces, and products within one unified architecture, overcoming the limitations of fragmented modeling.

***

## Methodology

The authors propose a Multi-Task Multi-Domain (MTMD) architecture grounded in the **Two-Tower paradigm** (Query Tower and Item Tower). The approach focuses on unifying heterogeneous data and optimization goals through the following mechanisms:

*   **Mixture-of-Experts (MoE):** Utilized to decouple specialized knowledge (domain-specific) from common knowledge (shared across the platform).
*   **Domain Adaptation Module:** Introduced specifically to facilitate knowledge transfer between experts, ensuring that learnings from one domain can benefit others.
*   **Constrained Optimization:** Applied specific constraints to task modeling to ensure stability across the simultaneous optimization of multiple objectives.
*   **Unified Architecture:** Replaces the traditional "one model per domain" approach with a holistic system capable of handling multiple prediction tasks within a single inference pass.

***

## Technical Details

### Core Architecture
The MTMD framework is designed as a unified model replacing fragmented domain-specific models for lightweight ranking. It employs a **Two-Tower architecture** to facilitate fast inference via dot products between the Query Tower and Item Tower.

### Domain Definitions
The system categorizes inputs into three distinct dimensions:
*   **Surfaces:** Home Feed, Search, Related Pins.
*   **Ad Products:** Standard, Shopping.
*   **Prediction Tasks:** CTR (Click-Through Rate), GCTR (Glance CTR), OCTR (One-Click CTR), CVR (Conversion Rate), Relevance.

### Expert Structure
The architecture features a sophisticated expert mix to balance specialization and generalization:
*   **Domain Experts:** Equipped with **Squeeze-and-Excitation (SE) Blocks** and per-domain Batch-Norm to capture specific nuances.
*   **Task-Specific Experts:** Utilize both Deep and Shallow Feed-Forward Networks (FFNs).
*   **Shared Experts:** Capture knowledge common to all domains.
*   **Efficiency:** Inference is optimized by activating only a **single domain expert** per request, rather than the entire network, significantly reducing latency.

### Optimization Strategy
*   **Constrained Multi-Task Learning:** Uses a conditional formulation to handle competing objectives.
*   **Asymmetric Embeddings:** Utilizes different embedding dimensions for different tasks (e.g., CTR: 128 dimensions, GCTR/OCTR: 32 dimensions).
*   **Loss Functions:** Utilizes **KL-Divergence loss** against heavyweight ranker predictions to ensure consistency with the broader ranking ecosystem.

***

## Contributions

*   **Unified Modeling Method:** Demonstrated a viable unified multi-domain modeling approach specifically for lightweight ranking layers in large-scale ads systems.
*   **Novel MoE Architecture:** Introduced a mixture-of-experts architecture specifically designed to balance specialized domain knowledge with shared global knowledge.
*   **Domain Adaptation:** Proposed a dedicated module to promote knowledge transfer between experts, improving data efficiency across sparse domains.
*   **Optimization Strategy:** Established a multi-task optimization strategy using modeling constraints for joint holistic optimization, ensuring stability across diverse tasks.

***

## Results

### Offline Evaluation
Experimental evaluation involved training on hundreds of millions of samples (ranging from 20 to 60 days). The model achieved consistent reductions in **Log Mean Absolute Error (LogMAE)**:

*   **Home Feed Standard:** CTR improvement of **20.25%**, GCTR improvement of **36.66%**.
*   **Related Pins Standard:** CTR improvement of **23.38%**, OCTR improvement of **36.58%**.
*   **Search Shopping:** CTR improvement of **16.84%**.
*   **Overall:** LogMAE reductions ranged from **12% to 36%** across various domains.

### Online A/B Testing
*   **Business Metric:** Delivered a **2% reduction in Cost Per Click (CPC)**.
*   **Infrastructure:** Successfully replaced **9 distinct production models** with a single unified model, validating the operational efficacy of the approach.