---
title: 'Sensorium Arc: AI Agent System for Oceanic Data Exploration and Interactive
  Eco-Art'
arxiv_id: '2511.15997'
source_url: https://arxiv.org/abs/2511.15997
generated_at: '2026-02-03T13:23:01'
quality_score: 8
citation_count: 39
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Sensorium Arc: AI Agent System for Oceanic Data Exploration and Interactive Eco-Art

*Noah Bissell; Ethan Paley; Joshua Harrison; Juliano Calil; Myungin Lee*

---

> ### **Quick Facts**
> *   **Quality Score:** 8/10
> *   **References:** 39 Citations
> *   **Core Framework:** Retrieval-Augmented Generation (RAG)
> *   **Development Engine:** Unity
> *   **Key Models:** Llama-3.2-3B, Gemma 3 12B
> *   **Hardware Interface:** Arduino-based "Nautilus" Module

---

## Executive Summary

High-dimensional oceanographic datasets often remain abstract, creating cognitive barriers that hinder public engagement with critical ecological information. This research addresses the challenge of translating complex scientific datasets into an interface that offers both intellectual and affective access. The authors identify a gap in traditional visualization methods, which frequently fail to engage users emotionally, thereby limiting environmental education and the potential for a meaningful connection to the natural world.

The core innovation is **"Sensorium Arc,"** a modular multi-agent system grounded in a Retrieval-Augmented Generation (RAG) framework that operationalizes the personification of the ocean. Developed in collaboration with the Center for the Study of the Force Majeure, the system integrates an Arduino-based hardware interface—the **'Nautilus' Module**—equipped with a distance sensor, active noise-canceling microphone, LEDs, and a motor, with a software stack built within the Unity engine. The architecture is decomposed into four layers: Input Processing, LLM Pipeline, Response Processing, and Audio-visual Layers. It utilizes specific model configurations to optimize distinct tasks: Llama-3.2-3B serves as the Decider agent, Gemma 3 12B acts as the Responder agent, and all-MiniLM-L12-v2 handles retrieval. This setup enables semantic parsing of spoken dialogue to dynamically trigger context-aware visualizations and audio playback based on temporal, spatial, or thematic cues.

Experimental evaluations demonstrated that the multi-agent architecture eliminated prompt interference issues inherent in single-model setups, thereby enhancing system stability and debuggability. While upgrading the Responder agent from Llama-3.2-3B to the larger Gemma 3 12B model improved response quality, it introduced measurable latency caused by resource contention between LLM inference and Unity's real-time rendering requirements. Functionally, the hardware interface performed reliably within defined parameters, with the distance sensor consistently triggering interactions at the configured 50 cm threshold. Qualitative user feedback confirmed the system's efficacy in facilitating affective connections to marine data, indicating successful integration of scientific insight with ecological poetics.

This research establishes a new paradigm for human-machine-ecosystem interaction that prioritizes poetic and emotional engagement alongside rigorous data visualization. By providing a technical blueprint for combining retrieval-augmented LLMs with semantic parsing, the paper offers a scalable framework for creating responsive, multimodal environments capable of reacting to the nuance of human speech in real-time. The work significantly advances the field of eco-art by demonstrating how AI can transform static datasets into "living narratives," bridging the disconnect between quantitative scientific insight and qualitative human experience.

---

## Key Findings

*   **Conversational Mediation:** The system demonstrates that conversational AI agents can successfully mediate affective and intuitive access to high-dimensional environmental data.
*   **Living Narratives:** The project proves that complex ocean data can be reimagined not as an abstract dataset but as a "living narrative," enhancing user engagement through storytelling.
*   **Dynamic Integration:** The system effectively integrates natural spoken conversation with dynamic, context-aware audiovisual triggers.
*   **Emotional & Intellectual Connection:** Findings suggest that blending scientific insight with ecological poetics in AI responses allows users to connect with marine data on both an intellectual and emotional level.

---

## Methodology

The research utilizes a **modular multi-agent system** grounded in a retrieval-augmented generation (RAG) framework using large language models (LLMs). The system enables real-time, natural spoken conversations where the AI agent embodies the persona of the ocean.

The methodology employs keyword detection and semantic parsing to analyze user dialogue continuously. Based on semantic analysis, the system dynamically triggers specific data visualizations and audiovisual playback corresponding to temporal, spatial, or thematic cues. The development process was guided by eco-aesthetic philosophy and collaborative input from the **Center for the Study of the Force Majeure**.

---

## Technical Details

### System Architecture
*   **Environment:** Unity Engine
*   **Structure:** Decomposed into four layers:
    1.  Input Processing
    2.  LLM Pipeline
    3.  Response Processing
    4.  Audio-visual Layers

### AI Stack & Models
*   **Decider Agent:** Llama-3.2-3B
*   **Responder Agent:** Llama-3.2-3B or Gemma 3 12B
*   **Retrieval Model:** all-MiniLM-L12-v2
*   **Data Corpus:** Combination of marine science datasets and eco-art literature

### Hardware Interface ('Nautilus' Module)
*   **Base:** Arduino-based
*   **Sensors:** Distance sensor (50 cm threshold), Microphone with active noise cancellation
*   **Actuators/Feedback:** LEDs, Motor

---

## Results

*   **Architecture Performance:** The multi-agent approach improved performance and debuggability compared to single-model architectures, which suffered from prompt interference.
*   **Model Trade-offs:** Upgrading to the larger Gemma 3 12B model enhanced response quality but introduced significant latency.
*   **Hardware Bottlenecks:** A hardware bottleneck was observed due to resource contention between LLM inference and Unity's real-time rendering.
*   **Sensor Reliability:** The distance sensor effectively triggered interactions at the 50 cm range.
*   **User Experience:** Qualitative results indicated the system successfully provided affective access to environmental data, addressing user desires for direct dialogue.

---

## Contributions

*   **New Interaction Paradigm:** The paper proposes a new paradigm for human-machine-ecosystem interaction that prioritizes poetic and emotional engagement alongside data visualization.
*   **Eco-Art Framework:** It contributes to the field of eco-art by providing a technical framework (Sensorium Arc) that operationalizes the personification of natural entities for educational and artistic purposes.
*   **Technical Blueprint:** The research offers a technical blueprint for combining retrieval-augmented LLMs with semantic parsing to create responsive, multimodal environments that react to the nuance of human speech in real-time.