---
title: Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration
arxiv_id: '2505.23187'
source_url: https://arxiv.org/abs/2505.23187
generated_at: '2026-02-03T07:28:14'
quality_score: 6
citation_count: 18
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration

*Yilong Li; Chen Qian; Yu Xia; Ruijie Shi; Yufan Dang; Zihao Xie; Ziming You; Weize Chen; Cheng Yang; Weichuan Liu; Ye Tian; Xuantang Xiong; Lei Han; Zhiyuan Liu; Maosong Sun*

---

### ðŸ“Š Quick Facts

| **Metric** | **Detail** |
| :--- | :--- |
| **Framework** | MAEL (Multi-Agent Experiential Learning) |
| **Architecture** | Undirected Computational Graph (Agents = Neurons) |
| **Core Mechanism** | Retrieval-Augmented Generation (RAG) + Reward-Based Experience |
| **Workflow** | Decompose â†’ Solve â†’ Critique â†’ Aggregate |
| **Benchmarks** | MMLU, GSM-8K, HumanEval, CommonGen-Hard, SRDD |
| **Baselines** | GPT-4o-mini, Claude-3.5-sonnet, AutoGen, EvoMac |
| **Quality Score** | 6/10 |

---

## ðŸ“ Executive Summary

Current Large Language Model (LLM)-based multi-agent systems are fundamentally hindered by **task isolation**, a structural inefficiency that treats each task as an independent event. This approach leads to significant computational redundancy and a failure to retain or transfer knowledge from prior problem-solving experiences. Because agents cannot learn from past successes, existing frameworks suffer from limited scalability and poor sample efficiency. Overcoming this isolation is critical for evolving multi-agent systems from static, task-specific tools into adaptive, learning-centric architectures capable of lifelong learning.

To address this, the authors introduce the **Multi-Agent Cross-task Experiential Learning (MAEL)** framework, which formalizes multi-agent collaboration as an undirected computational graph where agents function as neurons and experience pools serve as learnable weights. The methodology employs a divide-and-conquer strategy integrated with a solver-critique pattern (`Decompose -> Solve -> Critique -> Aggregate`). The system operates via two phases:

1.  **The Experiential Learning Phase:** Quantifies step quality using rewards ($R_{solve}$, $R_{decompose}$, $R_{critique}$) to populate experience pools.
2.  **The Inference Phase:** Agents utilize Retrieval-Augmented Generation (RAG) to retrieve high-reward historical experiences, calculating relevance through a composite score of semantic similarity and historical reward ($\alpha = 0.5$) to guide real-time decision-making.

The framework was rigorously evaluated against state-of-the-art baselines, including **GPT-4o-mini**, **Claude-3.5-sonnet**, **AutoGen**, and **EvoMac**, across five diverse benchmarks: MMLU, GSM-8K, HumanEval, CommonGen-Hard, and SRDD. Performance was assessed using task-specific metrics, including Accuracy for MMLU and GSM-8K, pass@k for HumanEval, and Composite/Overall scores for CommonGen-Hard and SRDD. The experimental design isolated the impact of cross-task learning by comparing retrieval strategiesâ€”MAEL_Task (task-wise) and MAEL_Step (step-wise)â€”against a no-experience baseline (MAELâˆ…Exp). The results validated that leveraging cross-task experience through these retrieval mechanisms significantly enhances sample efficiency and solution quality, establishing MAEL's superiority over traditional non-experiential methods.

The significance of MAEL lies in its graph-structured formalization of multi-agent collaboration, which bridges the gap between isolated task execution and lifelong learning. By enabling agents to actively retrieve and utilize high-reward past experiences, the framework enhances individual reasoning and collaborative dynamics without requiring external model retraining. This approach reduces computational redundancy and establishes a new inference paradigm, paving the way for more efficient, scalable, and intelligent multi-agent systems in complex problem-solving environments.

---

## ðŸ”‘ Key Findings

*   **Inefficiency in Current Systems:** Existing LLM-based multi-agent systems suffer from task isolation and redundant computations, limiting their scalability and efficiency.
*   **MAEL Framework:** The proposed Multi-Agent Cross-task Experiential Learning (MAEL) framework enables agents to learn from prior tasks by retrieving high-reward experiences as few-shot examples.
*   **Performance Improvements:** MAEL demonstrates faster convergence and higher-quality solutions compared to traditional methods that do not leverage past experience.
*   **Enhanced Collaboration:** Explicit experience accumulation significantly enhances both individual agent reasoning and overall collaboration quality.

---

## âœ¨ Contributions

*   **Framework Introduction:** Introduced the MAEL framework to specifically address the isolation limitation inherent in current multi-agent systems.
*   **Graph-Structured Formalization:** Provided a formalization of multi-agent collaboration using a graph-structured representation.
*   **Step Quality Quantification:** Developed a mechanism for quantifying step quality via rewards to curate specific experience pools for agents.
*   **New Inference Paradigm:** Established a new inference paradigm where agents actively retrieve past high-reward experiences to optimize real-time decision-making.

---

## ðŸ› ï¸ Methodology

The authors propose the **Multi-Agent Cross-task Experiential Learning (MAEL)** framework, which models task-solving workflows as a **graph-structured collaboration network**. The methodology is defined by two distinct phases:

### 1. Experiential Learning Phase
*   Focuses on the accumulation of knowledge.
*   Step quality is quantified via specific rewards.
*   High-quality steps are stored in agent experience pools for future use.

### 2. Inference Phase
*   Focuses on the application of knowledge.
*   Agents retrieve high-reward, task-relevant experiences from their pools.
*   These retrieved experiences act as few-shot examples to guide subsequent reasoning steps.

---

## âš™ï¸ Technical Details

### System Architecture
*   **MAS as Graph:** Treats the Multi-Agent System (MAS) as an undirected computational graph.
*   **Components:**
    *   **Agents:** Act as neurons.
    *   **Experience Pools:** Function as learnable weights.
*   **Initialization:** Tasks are initiated from the agent with the highest closeness centrality.

### Workflow Strategy
*   **Pattern:** Solver-Critique Pattern.
*   **Sequence:** `Decompose -> Solve -> Critique -> Aggregate`.

### Phase 1: Experiential Learning (Offline)
*   **Forward Pass:** Calculates step-level rewards.
    *   Examples: `R_solve`, `R_decompose`, `R_critique`.
*   **Backward Pass:** Updates experience pools with tuples `(s_t, a_t, r_t)` representing state, action, and reward.

### Phase 2: Inference (Online)
*   **Mechanism:** Utilizes Retrieval-Augmented Generation (RAG).
*   **Embeddings:** Uses `text-embedding-ada-002`.
*   **Relevance Score:** Combines semantic similarity and historical reward.
    *   Formula factor: `alpha = 0.5`.
*   **Retrieval Strategies:**
    1.  **MAELâˆ…Exp:** No experience retrieved (Baseline).
    2.  **MAEL_Task:** Task-wise retrieval.
    3.  **MAEL_Step:** Step-wise retrieval.

---

## ðŸ“ˆ Results

The experimental validation covered five distinct benchmarks comparing MAEL against strong baselines including GPT-4o-mini, Claude-3.5-sonnet, AutoGen, and EvoMac.

*   **Benchmarks & Metrics:**
    *   **MMLU:** Measured by Accuracy.
    *   **GSM-8K:** Measured by Accuracy.
    *   **HumanEval:** Measured by pass@k.
    *   **CommonGen-Hard:** Measured by Composite Metric.
    *   **SRDD:** Measured by Overall Score.
*   **Outcome:**
    *   While specific quantitative percentages (e.g., exact accuracy figures) were not included in the provided text, the results indicate that MAEL achieves higher sample efficiency and solution quality.
    *   The study successfully validated that leveraging cross-task experience via step-wise and task-wise retrieval strategies provides a significant advantage over non-experiential methods.

---

## ðŸ“š References
*   18 Citations