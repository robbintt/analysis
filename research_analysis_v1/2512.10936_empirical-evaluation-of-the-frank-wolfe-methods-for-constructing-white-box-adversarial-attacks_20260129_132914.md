# Empirical evaluation of the Frank-Wolfe methods for constructing white-box adversarial attacks
*Kristina Korotkova; Aleksandr Katrutsa*

---

### ðŸ“Š Quick Facts
| Metric | Value |
| :--- | :--- |
| **Quality Score** | 9/10 |
| **Citations** | 40 |
| **Datasets Used** | MNIST, CIFAR-10 |
| **Models Tested** | Logistic Regression, ResNet-56 (CNN), Vision Transformer (ViT) |
| **Key Performance Gain** | 4.5x faster than PGD baselines (on $l_1$-constrained attacks) |
| **Sparsity Result** | Modified only ~5% of pixels on MNIST |

---

> ### ðŸ“ Executive Summary
>
> **The Problem**
> The paper addresses the computational bottlenecks inherent in generating white-box adversarial attacks, specifically focusing on the inefficiency of projection-based methods like Projected Gradient Descent (PGD). While standard practice relies on projecting perturbations onto constrained norm balls to ensure pixel changes remain imperceptible, the authors identify that these projection steps represent a significant performance drag. This is particularly acute for $l_1$ norms, where the lack of closed-form projection solutions forces the use of expensive iterative sub-procedures. This inefficiency limits the scalability of attack generation and hinders the practical evaluation of robustness, especially in research involving sparse perturbations.
>
> **The Innovation**
> The key innovation is the reformulation of adversarial attack generation as a constrained optimization problem solved via projection-free Frank-Wolfe (FW) methods. Instead of calculating a computationally heavy projection back into the feasible set after each gradient step, the FW approach utilizes a Linear Minimization Oracle (LMO). This oracle selects the atom within the constraint set that minimizes the linear approximation of the loss, and the perturbation is updated via a convex combination. To mitigate the classic "zig-zagging" convergence issues of standard FW and to accelerate the attainment of sparse solutions, the study implements and evaluates several advanced variants: Momentum FW (FWm), Away-steps FW (AFW), and Pairwise FW (PFW).
>
> **The Outcome**
> The study empirically validated the proposed methods on MNIST and CIFAR-10 datasets across Logistic Regression, ResNet-56 (CNN), and Vision Transformer (ViT) architectures. The results demonstrated that projection-free FW methods achieve attack success rates comparable to standard projection-based baselines while offering substantial efficiency gains. Specifically, for $l_1$-constrained attacks on CIFAR-10 (ResNet-56), the FW variants reduced computation time by approximately 4.5 times compared to PGD baselines. In terms of sparsity, the FW methods yielded significantly superior results on MNIST, generating adversarial examples that modified only ~5% of pixels. Furthermore, on Vision Transformers, the AFW and PFW variants converged up to twice as fast as standard PGD. This work bridges the gap between advanced numerical optimization techniques and adversarial machine learning, providing a rigorous empirical analysis of Frank-Wolfe methods in a security context.

---

## Key Findings
*   **Optimization Formalization:** The construction of adversarial attacks can be effectively formalized as a numerical optimization problem suitable for analysis via advanced optimization techniques.
*   **Projection-Free Alternative:** Modified Frank-Wolfe methods serve as a viable projection-free alternative for generating white-box adversarial attacks.
*   **Benchmarking:** The performance of these projection-free methods was benchmarked against standard approaches that rely on projection operations or geometrical intuition.
*   **Architecture Validation:** The proposed methods were validated across a diverse range of neural network architectures, including multiclass logistic regression, CNNs, and Vision Transformers (ViT).

## Methodology
The study treats adversarial attack construction as a specific optimization challenge viewed through a numerical optimization lens. It proposes utilizing advanced projection-free optimization methods, specifically modified Frank-Wolfe algorithms.

The approach is evaluated against standard baseline methods based on projection operations and geometrical intuition. Numerical experiments were conducted on:
*   **Datasets:** MNIST and CIFAR-10
*   **Models:** Multiclass logistic regression, CNNs, and Vision Transformers.

## Technical Details
The approach formulates adversarial example generation as a constrained numerical optimization problem to maximize cross-entropy loss $L(x+\delta|f_\theta)$ subject to $\|\delta\|_p \le \epsilon$.

### Core Algorithm
It employs the projection-free Frank-Wolfe (FW) algorithm for white-box image classification attacks using:
1.  **Linear Minimization Oracle (LMO):** Solves $v^* = \text{argmin}_{v \in S} \langle \nabla_\delta L, v \rangle$.
2.  **Update Step:** Perturbations are updated via convex combination.

### Norm Constraints & Sparsity
*   Closed-form LMO solutions are provided for $l_\infty$, $l_2$, and $l_1$ norms.
*   Notably, $l_1$ constraints produce sparse perturbations.

### Algorithm Variants
To standard FW performance, the study analyzed advanced variants:
*   **Momentum FW (FWm):** Used to reduce zig-zagging.
*   **Away-steps FW (AFW):** Used for active set management.
*   **Pairwise FW (PFW):** Used for sparser representations.

## Results
The experiment evaluates **Test Accuracy**, **Runtime per image**, and **Sparsity** across Logistic Regression (MNIST), ResNet-56 (CIFAR-10), and Vision Transformer (CIFAR-10) models.

### Performance Highlights
*   **Efficiency:** For $l_1$-constrained attacks, FW methods offer significant speed advantages over PGD baselines due to the high computational cost of projection in $l_1$.
*   **Sparsity:** On the MNIST dataset, FW methods produced much sparser attacks, modifying significantly fewer pixels than baseline methods.
*   **Modern Architecture Performance:** On Vision Transformers, AFW and PFW variants demonstrated convergence speeds up to twice as fast as standard PGD.

### Constraint Analysis
The paper hypothesizes and tests that $l_1$-constrained problems will favor projection-free methods due to the lack of closed-form projection solutions.

## Contributions
*   **Introduction of Methods:** Introduced modified Frank-Wolfe (projection-free) methods to the domain of adversarial attack construction as a viable alternative to projection-based norms.
*   **Comprehensive Analysis:** Provided a detailed analysis combining theoretical findings with numerical performance metrics.
*   **Broad Applicability:** Demonstrated the applicability of these optimization techniques to modern deep learning architectures, specifically including Vision Transformers alongside traditional CNNs and logistic regression models.