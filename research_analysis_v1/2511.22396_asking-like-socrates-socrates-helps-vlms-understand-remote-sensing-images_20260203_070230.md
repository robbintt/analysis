---
title: 'Asking like Socrates: Socrates helps VLMs understand remote sensing images'
arxiv_id: '2511.22396'
source_url: https://arxiv.org/abs/2511.22396
generated_at: '2026-02-03T07:02:30'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Asking like Socrates: Socrates helps VLMs understand remote sensing images

*Run Shao; Ziyu Li; Zhaoyang Zhang; Linrui Xu; Xinran He; Hongyuan Yuan; Bolei He; Yongxing Dai; Yiming Yan; Yijun Chen; Wang Guo; Haifeng Li*

---

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Paradigm** | RS-EoT (Remote Sensing Evidence-of-Thought) |
| **Architecture** | SocraticAgent (Multi-Agent Self-Play) |
| **Training Strategy** | Two-Stage Progressive Reinforcement Learning |
| **RSVQA-HR Accuracy** | **84.8%** |
| **RSVQA-LR Accuracy** | **96.2%** |
| **Quality Score** | 9/10 |
| **Citations** | 40 References |

---

> ### üìù Executive Summary
>
> This research addresses the critical failure of current Vision-Language Models (VLMs) when applied to remote sensing (RS) imagery, a domain characterized by complex, high-density, and large-scale visuals. The authors identify a phenomenon termed the **"Glance Effect,"** where standard VLMs rely on single-pass, coarse perception that results in "pseudo reasoning." Instead of grounding answers in visual evidence, these models often hallucinate or rely on linguistic priors, failing to capture the intricate details required for accurate RS analysis.
>
> To overcome the Glance Effect, the paper introduces **RS-EoT** (Remote Sensing Evidence-of-Thought), a novel paradigm that shifts the model from passive perception to active, iterative visual evidence seeking. Technically, the system employs **SocraticAgent**, a multi-agent framework utilizing self-play to synthesize high-quality reasoning traces. This agent operates in alternating cycles: generating reasoning hypotheses and then actively seeking specific visual evidence to verify or refute them. The model is trained using a **Two-Stage Progressive Reinforcement Learning (RL)** strategy. The first stage applies RL to fine-grained grounding tasks to strictly enforce visual-text alignment, while the second stage generalizes these capabilities to open-ended Visual Question Answering (VQA).
>
> The implementation of RS-EoT yielded **State-of-the-Art (SOTA)** performance across standard Remote Sensing VQA and grounding benchmarks. The significance of this work extends beyond remote sensing, offering a theoretical and practical blueprint for mitigating hallucination in multimodal AI by defining the "Glance Effect" and introducing a language-driven, iterative evidence-seeking paradigm.

---

## üîë Key Findings

*   **Identification of the "Glance Effect":** The study diagnoses that current VLMs fail in remote sensing tasks due to single, coarse perception, which leads to "pseudo reasoning" rather than genuine understanding.
*   **Efficacy of Iterative Evidence Seeking:** The RS-EoT paradigm successfully mitigates the Glance Effect by enforcing iterative cycles of reasoning and visual inspection, forcing the model to verify its hypotheses.
*   **State-of-the-Art Performance:** RS-EoT achieves superior performance on standard Remote Sensing Visual Question Answering (VQA) and grounding benchmarks compared to existing baselines.
*   **Validation of Genuine Reasoning:** The model demonstrates distinct, repeated cycles of generating reasoning hypotheses and seeking visual verification, confirming it moves beyond superficial pattern matching.

---

## üõ†Ô∏è Methodology

The research proposes **RS-EoT** (Remote Sensing Evidence-of-Thought), a language-driven, iterative paradigm designed to replace single-pass perception with active visual evidence-seeking.

**Core Components:**

1.  **SocraticAgent:**
    *   A self-play multi-agent system used to synthesize reasoning traces.
    *   Operates through alternating cycles of generating reasoning steps and conducting visual inspections.

2.  **Two-Stage Progressive Reinforcement Learning (RL):**
    *   **Stage 1:** Applies RL to fine-grained **Grounding** tasks to strictly link reasoning to visual evidence.
    *   **Stage 2:** Applies RL to **RS VQA** tasks to generalize these capabilities to broader, open-ended understanding.

---

## ‚öôÔ∏è Technical Details

The approach introduces a framework designed to mitigate the 'Glance Effect' in Vision-Language Models (VLMs) by enforcing an iterative cycle of reasoning rather than single-pass inference.

**The "Glance Effect" & Pseudo Reasoning**
*   **Problem:** VLMs often treat complex images with a single glance, leading to hallucinations based on linguistic priors rather than visual facts.
*   **Solution:** RS-EoT replaces this with an iterative process of generating reasoning hypotheses, actively seeking visual evidence for verification, and refining understanding.

**The SocraticAgent Framework**
*   Utilizes a multi-agent architecture where agents interact via self-play.
*   This interaction generates high-quality training data that mimics the Socratic method of questioning and verification.

**Progressive Training Strategy**
*   **Localization:** The model first learns to precisely locate objects (Grounding), anchoring text to specific pixels.
*   **Generalization:** The model then applies this strict grounding to answer open-ended questions (VQA), ensuring the reasoning is rooted in the visual data.

---

## üìà Results

The RS-EoT paradigm demonstrated significant improvements in both quantitative metrics and qualitative reasoning capabilities.

*   **SOTA Achievement:** Achieved State-of-the-Art (SOTA) performance on Remote Sensing Visual Question Answering (VQA) and Grounding benchmarks.
*   **RSVQA-HR Dataset:** Achieved an accuracy of **84.8%**, significantly outperforming existing baselines.
*   **RSVQA-LR Dataset:** Achieved an accuracy of **96.2%**, demonstrating robustness across varying image resolutions.
*   **Grounding Tasks:** Showed substantial improvements in intersection-over-union (IoU) scores.
*   **Qualitative Validation:** Confirmed the model's ability to correct superficial understanding through repeated cycles of hypothesis generation and visual verification.

---

## üéÅ Contributions

*   **Theoretical Insight:** Provided a diagnosis for multimodal reasoning model failures by defining the "Glance Effect" and distinguishing genuine reasoning from pseudo reasoning.
*   **Novel Paradigm:** Introduced RS-EoT as a shift from passive perception to active, iterative visual evidence seeking for large-scale remote sensing imagery.
*   **Architectural Innovation:** Developed SocraticAgent, a multi-agent framework using self-play to generate high-quality training data.
*   **Training Strategy:** Established a progressive RL training strategy that bridges the gap between precise localization (grounding) and general semantic understanding (VQA).

---

**Document Rating:** 9/10 | **References:** 40 Citations