---
title: Towards Verifiably Safe Tool Use for LLM Agents
arxiv_id: '2601.08012'
source_url: https://arxiv.org/abs/2601.08012
generated_at: '2026-02-03T12:59:15'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Towards Verifiably Safe Tool Use for LLM Agents
*Aarya Doshi; Yining Hong; Congying Xu; Eunsuk Kang; Alexandros Kapravelos; Christian K√§stner*

> ### üìä Quick Facts
> *   **Quality Score:** 9/10
> *   **References:** 40 Citations
> *   **Core Focus:** Formal Safety Guarantees for LLM Agents
> *   **Methodology:** STPA + Information Flow Control (IFC)
> *   **Key Output:** Enhanced Model Context Protocol (MCP)

---

## üìã Executive Summary

### Problem
LLM-based agents utilizing external tools face critical security vulnerabilities, including sensitive data leaks and unintended record overwrites, which current ad hoc safeguards cannot reliably prevent. As agents gain autonomy, the risk of unintended interactions between tools and data increases, creating a need for safety measures that go beyond simple heuristic checks. While formal methods like Information Flow Control (IFC) offer theoretical guarantees, they are often impractical for implementation due to their reliance on extensive human annotation and manual effort. Consequently, there is a significant gap in the field between the need for rigorous, verifiable safety and the capabilities of current, reactive guardrails that often require constant user confirmation.

### Innovation
The authors propose a hybrid safety framework that combines safety engineering with formal verification to automate the enforcement of security constraints. The key innovation is a three-step methodology:
1.  **System-Theoretic Process Analysis (STPA):** Adapted for LLM agents to systematically identify hazards and generate formal safety requirements.
2.  **Requirement Formalization:** Translating requirements into enforceable specifications governing data flows and tool sequences.
3.  **Enhanced MCP Implementation:** A specialized framework mandating structured labels on tool capabilities, confidentiality levels, and trust levels.

By integrating IFC with this labeled metadata, the system can deterministically prevent unsafe data flows and unconstrained tool composition without requiring continuous human oversight.

### Results
As this paper establishes a theoretical framework and defines the problem space, it does not present experimental results, quantitative metrics, or benchmarking data. The authors validate the approach through qualitative analysis and a motivating example involving a calendar agent to illustrate how the framework identifies risks and enforces constraints. The primary qualitative outcomes demonstrate that safety specifications can be effectively enforced through structured metadata, theoretically reducing reliance on constant user confirmation and mitigating security fatigue. The work provides the architectural foundation for safety but leaves empirical performance evaluation to future research.

### Impact
This research represents a significant architectural shift in the design of LLM agents, moving the industry from reactive reliability fixes to proactive, formally guaranteed safety. By bridging the gap between abstract safety engineering (STPA) and enforceable formal methods (IFC), the authors lower the barrier to implementing rigorous security in autonomous systems. The enhanced MCP framework offers a practical path for developers to construct high-assurance agents capable of handling sensitive data while maintaining autonomy. Ultimately, this work lays the groundwork for creating AI agents that can be trusted in critical environments, shifting the focus of safety from patching vulnerabilities to systemic prevention.

---

## üîë Key Findings

*   **Critical Risks in Tool Use:** LLM-based agents utilizing tools are prone to unintended interactions causing critical risks like sensitive data leaks and record overwrites, which current safeguards cannot guarantee against.
*   **Impracticality of Current Methods:** Existing formal methods like Information Flow Control (IFC) are often impractical for implementation due to reliance on extensive human annotation.
*   **Shift to Proactive Safety:** It is possible to move LLM agent safety from ad hoc reliability fixes to proactive guardrails backed by formal guarantees, reducing reliance on constant user confirmation.
*   **Structured Labeling:** Safety specifications can be effectively enforced by requiring structured labels on tool capabilities, confidentiality, and trust levels.

---

## üõ†Ô∏è Methodology

The proposed methodology follows a structured, formal process involving three distinct steps:

1.  **Hazard Analysis**
    Utilizing **System-Theoretic Process Analysis (STPA)** to systematically identify potential hazards within agent workflows.

2.  **Requirement Formalization**
    Safety requirements derived from STPA are formalized into enforceable specifications governing data flows and tool sequences.

3.  **Framework Implementation**
    Utilization of a **capability-enhanced Model Context Protocol (MCP)** framework that mandates structured labels to define tool capabilities, confidentiality levels, and trust levels.

---

## ‚öôÔ∏è Technical Details

**Framework Architecture**
The paper proposes a hybrid safety framework combining safety engineering (STPA) with formal Information Flow Control (IFC). It targets task-specific agents using the Model Context Protocol (MCP) and aims to provide deterministic safety guarantees by preventing unsafe flows and unconstrained tool composition.

**STPA Adaptation Workflow**
The framework adapts STPA for requirement derivation via a specific 4-step workflow:
1.  Stakeholder Identification
2.  Value-to-Loss Mapping
3.  Causal Analysis
4.  Requirement Generation

**IFC Enforcement**
IFC enforces constraints using structured labels on data and tools. This integration allows the system to automatically validate safety requirements without manual intervention during runtime.

---

## üìÅ Contributions

*   **STPA-Driven Safety Process:** A novel workflow applying System-Theoretic Process Analysis (STPA) to LLM agents to identify hazards and generate formal safety specifications for data flows and tool usage.
*   **Enhanced Model Context Protocol (MCP):** A specialized MCP framework requiring structured metadata (labels) for capabilities, confidentiality, and trust to facilitate the enforcement of safety constraints.
*   **Architectural Shift in Autonomy:** A contribution to the design philosophy of LLM agents, shifting from reactive reliability measures to proactive, formally guaranteed safety.

---

## üìà Results & Evaluation

*   **Experimental Data:** The provided text does not contain experimental results or quantitative metrics.
*   **Framework Validation:** It establishes the theoretical framework and problem space.
*   **Qualitative Claims:** Claims include reducing reliance on constant user confirmation and mitigating security fatigue.
*   **Illustrative Example:** A motivating example of a calendar agent is provided to illustrate risks, but no benchmarking or evaluation data is available.