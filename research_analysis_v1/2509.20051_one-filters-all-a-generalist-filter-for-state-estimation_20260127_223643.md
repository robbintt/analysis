---
title: 'One Filters All: A Generalist Filter for State Estimation'
arxiv_id: '2509.20051'
source_url: https://arxiv.org/abs/2509.20051
generated_at: '2026-01-27T22:36:43'
quality_score: 7
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# One Filters All: A Generalist Filter for State Estimation

***Zeyu He, Shiqi Liu, Tianyi Zhang, Shengbo Eben, Wenhan Cao, Chang Liu***
*Tsinghua University*

---

## üìä Quick Facts

| Metric | Details |
| :--- | :--- |
| **Quality Score** | 7/10 |
| **Total Citations** | 40 |
| **Model Scale Tested** | 7B to 70B Parameters |
| **Core Innovation** | System-as-Prompt (SaP) & Modality Alignment |
| **Key Application** | Non-linear dynamical systems & Robotics |

---

## üìù Executive Summary

State estimation in non-linear dynamical systems remains a critical bottleneck in robotics and control. Traditional model-based filters, such as Kalman or Particle filters, require precise mathematical models and often fail under complex dynamics. Conversely, learning-based approaches like Neural Filters offer flexibility but lack generalization, typically necessitating retraining for every new environment. This reliance on system-specific tuning prevents the deployment of autonomous systems in unpredictable, real-world physical conditions.

This paper introduces **LLM-Filter**, a framework that utilizes frozen Large Language Models (LLMs) as general-purpose filters by bridging continuous time-series data with the discrete text domain. The technical core relies on **"Text Prototype Embedding"** and **"Modality Alignment"** to map raw sensor data into semantic embeddings compatible with the LLM's input space. A key innovation is the **"System-as-Prompt" (SaP)** strategy, which encodes task instructions and system definitions directly into the prompt context.

LLM-Filter demonstrated superior performance over state-of-the-art learning-based baselines on chaotic benchmarks including the Duffing oscillator and Van der Pol systems. The framework exhibited robust zero-shot generalization and validated distinct scaling-law behavior. This research establishes the "foundation model of filtering," marking a paradigm shift from specialized algorithm design to the use of general-purpose foundation models in control theory.

---

## üîë Key Findings

*   **Superior Performance:** LLM-Filter outperforms state-of-the-art learning-based approaches in classical dynamical systems (e.g., Duffing oscillator, Van der Pol) by leveraging LLM reasoning.
*   **Exceptional Generalization:** Achieves high accuracy in unseen or altered environments through the **System-as-Prompt (SaP)** design without retraining.
*   **Scaling Laws:** The framework exhibits scaling-law behavior where estimation accuracy improves consistently as model size (7B ‚Üí 70B) and training time increase.
*   **Frozen Model Viability:** Demonstrates that effective state estimation is possible using frozen LLMs by embedding noisy observations into text prototypes.

---

## üß† Methodology

The research proposes `LLM-Filter`, a general framework for optimal filtering designed to estimate hidden states within dynamical systems.

*   **Text Prototype Embedding:** A mechanism used to connect raw numerical data with the language model's semantic space.
*   **Modality Alignment:** A technique to fit dynamical system data to a frozen LLM, allowing the model to process continuous sensor data.
*   **System-as-Prompt (SaP):** A novel prompt structure designed to help the LLM apply its reasoning capabilities to physical system estimation tasks by embedding task instructions and system definitions directly into the context.

---

## ‚öôÔ∏è Technical Details

The LLM-Filter framework operates on standard state-space models governed by state transition and observation equations.

**Core Mechanisms:**
1.  **Data Embedding:** The system uses a modality alignment mechanism to embed continuous sensor data into text prototypes. This allows the LLM to process numerical time-series data that it cannot natively interpret.
2.  **Reasoning via SaP:** The `System-as-Prompt` strategy includes specific task instructions and system definitions, enabling generalization across unseen environments without the need for weight updates in the LLM.
3.  **Optimization Strategy:**
    *   **Frozen Weights:** The LLM weights remain strictly frozen throughout the process.
    *   **Extraction:** State estimates are extracted from discrete text tokens generated by the model.
    *   **Loss Function:** An L2 loss function is optimized on the modality alignment parameters to minimize the error between the model's output and ground truth states.

---

## üìà Results & Performance

The study validates the LLM-Filter framework through rigorous testing against chaotic benchmarks and varying environment conditions.

*   **Benchmarking:** LLM-Filter outperformed current state-of-the-art learning-based baselines (such as Neural Filters) on complex, chaotic systems.
*   **Zero-Shot Robustness:** The framework maintained low Root Mean Square Error (RMSE) in unseen environments where competing baselines diverged, requiring no retraining.
*   **Scaling Behavior:** Estimation error decreased consistently with increased model size and training duration, confirming that filtering capability scales predictably with computational resources.

---

## üèÜ Core Contributions

1.  **Unified Foundation Model:** The proposal of LLM-Filter as a "**foundation model of filtering**" to provide a unified approach to state estimation, replacing the need for numerous specialized filters.
2.  **Cross-Modal Application:** Demonstrating that LLMs can effectively handle scientific and engineering problems via proper alignment of modalities (text/sensor data).
3.  **Prompt-Based Adaptation:** The advancement of zero-shot generalization, enabling filters to adapt to changed environments strictly through prompt-based instructions rather than re-training.