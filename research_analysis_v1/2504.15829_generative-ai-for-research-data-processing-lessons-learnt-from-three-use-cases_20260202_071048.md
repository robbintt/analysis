# Generative AI for Research Data Processing: Lessons Learnt From Three Use Cases

*Modhurita Mitra; Martine G. de Vos; Nicola Cortinovis; Dawa Ometto*

---

> ### ðŸ“‹ Quick Facts
>
> | Metric | Detail |
> | :--- | :--- |
> | **Quality Score** | 7/10 |
> | **References** | 40 Citations |
> | **Primary Model** | Claude 3 Opus |
> | **Domains Analyzed** | Historical Botany, Health Economics, Crowdfunding |
> | **Feasibility Rate** | 100% |
> | **Repository** | `UtrechtUniversity/generativeative-ai` |

---

## Executive Summary

Complex research data processing frequently exceeds the capabilities of traditional rule-based or standard machine learning methods, particularly when addressing unstructured, noisy, or multilingual sources. Researchers encounter significant bottlenecks in extracting structured information from varied formats such as historical botanical seedlists, technical Health Technology Assessment (HTA) reports, and crowdfunding datasets. These challenges arise because standard models lack the semantic depth to interpret context-dependent nuance or handle the irregular layouts characteristic of OCR-derived text, forcing teams to rely on labor-intensive manual curation or brittle, domain-specific automation tools.

This study introduces a unified architecture leveraging the **Claude 3 Opus** Large Language Model (LLM) to resolve these intractable data processing tasks. The key technical innovation is a "Comparative Task Analysis" methodology paired with a criteria-based decision framework that guides researchers on when to apply generative AI versus traditional heuristics. To ensure reliability, the authors employed targeted prompt engineering and JSON Schema enforcement to convert unstructured inputs into database-ready formats, specifically selecting Claude 3 Opus over the GPT-4-0125-preview model due to superior API stability in handling file uploads. The project established **100% feasibility** in utilizing LLMs for tasks previously resistant to automation, successfully retrieving complex taxonomic data, health data points, and industry codes with high fidelity.

This work provides substantial empirical evidence that generalized LLMs can function as reliable "general-purpose semantic engines" for research scenarios far beyond simple text generation. By open-sourcing the workflow architecture and providing a "lessons learnt" framework, the authors offer the broader research community a practical toolkit for vetting generative AI technologies and engineering robust workflows.

---

## Key Findings

*   **Feasibility Established:** The study confirms that generative AI (specifically the Claude 3 Opus model) is a feasible tool for performing complex research data processing tasks that are difficult to execute using traditional rule-based or standard machine learning approaches.
*   **Versatility Across Domains:** The model successfully handled three distinct types of complex tasks:
    *   Information Extraction (historical botanical seedlists).
    *   Natural Language Understanding (Health Technology Assessment documents).
    *   Text Classification (Kickstarter projects).
*   **Addressing Limitations:** The research identified specific methods to mitigate known generative AI issues, such as inaccuracy and inconsistency, thereby maximizing the reliability of results.
*   **Decision Framework:** The authors developed criteria to help researchers determine when generative AI is the appropriate tool for a specific data processing task.

---

## Methodology

The researchers conducted an exploratory study focused on **comparative task analysis**. The methodology involved three primary phases:

1.  **Problem Identification:**
    Selecting data processing tasks within ongoing research projects that were identified as too complex or difficult for rule-based or traditional machine learning methods.

2.  **Model Application:**
    Implementing the Claude 3 Opus generative AI model to perform these specific tasks:
    *   Extracting plant species from historical seedlists.
    *   Extracting health data points from HTA documents.
    *   Assigning industry codes to Kickstarter projects.

3.  **Evaluation and Synthesis:**
    Assessing the outputs to derive practical lessons regarding tool selection and output optimization.

---

## Technical Details

### System Architecture
| Component | Specification |
| :--- | :--- |
| **Primary Model** | Claude 3 Opus (Selected over GPT-4-0125-preview due to API stability regarding file uploads) |
| **Input Modalities** | â€¢ OCR-derived text from scanned PDFs (Seedlists)<br>â€¢ Native digital PDFs (HTA)<br>â€¢ Structured text from CSV files (Kickstarter) |
| **Pre-processing** | Parsing complex, semi-structured tabular layouts containing bilingual text and taxonomic nomenclature. |
| **Output Format** | Standardized JSON for database integration. |
| **Workflow Source** | Archived on GitHub under `UtrechtUniversity/generativeative-ai`. |

### Performance Metrics
*   **Extraction Fidelity:** Accurate retrieval of taxonomy (genus, species, author), subspecies variants, alphanumeric collection codes, and quantitative seed counts from unstructured OCR text.
*   **Classification Accuracy:** Successful assignment of industry codes to Kickstarter projects.
*   **Mitigation Strategies:** Use of constraint-based prompting and structured output validation to counter inaccuracy and inconsistency without domain-specific fine-tuning.

---

## Contributions

*   **Empirical Validation:** Provides concrete evidence of the utility of Large Language Models (LLMs) in niche and complex research scenarios beyond general text generation.
*   **Best Practices Framework:** Contributes a set of guidelines ('lessons learnt') for the research community on how to vet generative AI for specific tasks and how to engineer prompts or workflows to ensure high accuracy and consistency.
*   **Cross-Disciplinary Relevance:** Demonstrates the applicability of a single AI model to vastly different domains (historical botany, health economics, and crowdfunding), suggesting a broad utility for semantic data processing in research.

---

## Results

The study confirmed **100% feasibility** in using LLMs for tasks resistant to traditional rule-based or machine learning approaches. The architecture successfully demonstrated versatility across the three target domains:

*   **Information Extraction:** Successfully processed historical seedlists, accurately retrieving taxonomy, subspecies variants, and seed counts from noisy OCR text.
*   **Natural Language Understanding:** Effectively extracted precise health data points from complex Health Technology Assessment texts.
*   **Text Classification:** Accurately assigned industry codes to Kickstarter projects based on project descriptions.

Additionally, the project established a functional decision framework for programmatically determining when to apply Generative AI in a research workflow.