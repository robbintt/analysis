# Large language models for behavioral modeling: A literature survey

*Muhammad Laiq*

***

> ### üìä QUICK FACTS
> *   **Selection Pool**: 14 primary studies (from 113 initial hits)
> *   **Primary Focus**: Sequence Diagrams (78.6%)
> *   **Dominant Architecture**: GPT Models (11 of 14 studies)
> *   **Evaluation Metric**: Researcher-led (50%)
> *   **Quality Score**: 8/10

***

## üìù EXECUTIVE SUMMARY

The application of Large Language Models (LLMs) in software engineering, specifically for automating behavioral modeling through UML sequence and use case diagrams, offers significant potential yet remains a fragmented body of knowledge. Despite growing interest in transforming natural language requirements into structural models, a critical absence of consolidated literature reviews obscures the overall effectiveness, reliability, and limitations of current AI-driven techniques. This lack of a cohesive overview makes it difficult for researchers and practitioners to accurately assess the technology's maturity or identify distinct gaps in current methodologies.

To address this void, the authors executed a semi-systematic literature survey employing a term-based search strategy across specific databases, including Google Scholar, to identify an initial pool of 113 papers, which were filtered down to 14 primary studies. The study‚Äôs pivotal innovation is the introduction of a standardized four-layer categorization framework‚Äîcomprising an Input Layer, Model Layer, Output Layer, and Validation Layer. This framework is necessary to standardize comparisons across disparate studies that utilize varying terminology and architectural approaches. By decomposing the technical landscape into these distinct layers, the authors provided a unified structure for analyzing how textual requirements are transformed into behavioral models, enabling a consistent evaluation of otherwise incomparable systems.

Analysis of the selected studies reveals distinct trends, with sequence diagrams dominating the field at 78.6% of studies compared to use case diagrams at 64.3%. Regarding technology, proprietary GPT models were the predominant choice, utilized in 11 studies, while open-source alternatives like DeepSeek-Coder and CodeLlama appeared in only 5 studies. Evaluation rigor emerged as a major constraint, as 50% of the studies relied solely on the researchers' own assessments. Only two studies employed automated "LLM-as-a-judge" techniques, and very few involved domain experts, highlighting a significant deficiency in external validation despite the technical hype.

By providing the first known comprehensive overview of LLM-based behavioral modeling, this paper serves as a foundational roadmap for future research and a critical resource for educators and practitioners. The findings underscore that while LLMs demonstrate promising diagram-generation capabilities, the field is currently constrained by an over-reliance on the GPT family and a lack of rigorous, expert-based validation. Consequently, the study advocates for a shift toward broader model evaluation and the integration of human review processes to enhance the trustworthiness and maturity of AI-generated software designs.

***

## üîë KEY FINDINGS

*   **Promising Performance:** LLMs show promising results in generating high-level software design artifacts, specifically use case and sequence diagrams.
*   **Validation Deficit:** There is a significant lack of expert-based evaluations to validate the quality of generated diagrams.
*   **Narrow Model Selection:** Current research relies heavily on GPT-based models, indicating a narrow selection of architectures and a lack of diversity in testing.
*   **Literature Gap:** There is a significant scarcity of published overviews or surveys in this domain, making this work a foundational text.

***

## üõ†Ô∏è METHODOLOGY

The authors employed a **semi-systematic review** process outlined below:

1.  **Identification:** Utilized Google Scholar with specific term-based queries regarding "LLMs" and "UML sequence or use case diagrams."
2.  **Filtering:** Filtered 113 initial hits to select 14 primary studies that met specific criteria.
3.  **Analysis:** Analyzed the selected studies to assess the effectiveness of LLMs in generating behavioral diagrams.
4.  **Categorization:** Applied a standardized framework to categorize studies by task, model, data source, and evaluation approach.

***

## ‚öôÔ∏è TECHNICAL DETAILS

The study proposes a **four-layer framework** to categorize the surveyed systems:

*   **Input Layer**
    *   Predominantly uses natural language inputs.
    *   Sources: System Descriptions or Requirement Documents.

*   **Model Layer**
    *   **Proprietary:** Heavily relies on GPT architectures (GPT-3.5, GPT-4, GPT-4o).
    *   **Open Source:** Limited use of models like DeepSeek-Coder and CodeLlama.

*   **Output Layer**
    *   Focuses on generating behavioral modeling artifacts.
    *   Artifacts: Sequence Diagrams and Use Case Diagrams.

*   **Validation Layer**
    *   Split between two distinct approaches:
        *   **Human-centric:** Manual review by researchers.
        *   **Automated:** Algorithmic checks (less common).

***

## üìà RESULTS

The analysis of the 14 primary studies yielded the following data points:

*   **Task Distribution:**
    *   **Sequence Diagrams:** 78.6% of studies (Most researched).
    *   **Use Case Diagrams:** 64.3% of studies.
*   **Model Usage:**
    *   **Proprietary GPT Models:** Utilized in 11 studies.
    *   **Other/Open Source Models:** Utilized in only 5 studies.
*   **Evaluation Methods:**
    *   **Researchers:** Primary evaluation method in 50% of studies.
    *   **Automated ('LLM-as-a-judge'):** Used in only 2 studies.
    *   **Domain Experts:** Notably absent.
*   **Input Data:** System Descriptions were the most common data source.

***

## üöÄ CONTRIBUTIONS

*   **Foundational Overview:** Provided the first known overview of research utilizing LLMs for behavioral modeling, effectively filling a gap in the literature.
*   **Practical Guidance:** Informed practitioners and educators regarding the current effectiveness and limitations of LLMs in this domain.
*   **Gap Identification:** Highlighted specific research gaps, including the over-reliance on GPT models and the lack of domain expert evaluation.
*   **Future Roadmap:** Proposed a roadmap calling for broader LLM evaluation and the integration of expert-based validation processes.

***

### üìö BIBLIOMETRICS

*   **References:** 32 citations
*   **Quality Score:** 8/10