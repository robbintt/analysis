---
title: 'MaskSearch: A Universal Pre-Training Framework to Enhance Agentic Search Capability'
arxiv_id: '2505.20285'
source_url: https://arxiv.org/abs/2505.20285
generated_at: '2026-02-03T12:45:26'
quality_score: 7
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# MaskSearch: A Universal Pre-Training Framework to Enhance Agentic Search Capability

*Weiqi Wu; Xin Guan; Shen Huang; Yong Jiang; Pengjun Xie; Fei Huang; Jiuxin Cao; Hai Zhao; Jingren Zhou*

---

## üìä Quick Facts

| Metric | Details |
| :--- | :--- |
| **Framework Name** | MaskSearch |
| **Core Objective** | Retrieval Augmented Mask Prediction (RAMP) |
| **Training Data** | 10 million CoT trajectories (14 billion tokens) |
| **Training Strategy** | Hybrid: Supervised Fine-tuning (SFT) + Reinforcement Learning (RL) |
| **RL Method** | Dynamic Sampling Policy Optimization (DAPO) |
| **Quality Score** | 7/10 |
| **References** | 40 citations |

---

## üìù Executive Summary

### **Problem**
Current Large Language Model (LLM)-based search agents struggle with generalization, often overfitting to task-specific data and failing to adapt to novel domains or complex, multi-step reasoning scenarios. This limitation arises because most existing agents rely on supervised fine-tuning on narrow datasets, which does not inherently teach the model the universal mechanics of tool usage or information retrieval. Consequently, deploying agents that can robustly navigate open-domain environments without extensive retraining remains a significant challenge in the development of autonomous agentic systems.

### **Innovation**
The paper introduces **MaskSearch**, a universal pre-training framework designed to endow LLMs with intrinsic agentic search capabilities. The core technical innovation is the **Retrieval Augmented Mask Prediction (RAMP)** task, which modifies the standard pre-training objective by masking salient spans (entities, dates, ontologies) in the input. To reconstruct these masked spans, the model is forced to proactively utilize search tools to query an external knowledge corpus. The training pipeline employs a sophisticated two-stage approach: first, pre-training on RAMP using data generated by a multi-agent system (Planner, Rewriter, Observer) via a Self-Evolve Distillation strategy that utilizes a **Curriculum Learning** method to scale difficulty; second, refining the model using Dynamic Sampling Policy Optimization (DAPO), a reinforcement learning method with hybrid rewards to optimize search behavior.

### **Results**
The research validates the framework's efficacy through the successful creation of a massive-scale dataset comprising **10 million Chain-of-Thought (CoT) trajectories** and **14 billion tokens**, utilizing a masking strategy of 1 to 4 spans. Empirical evidence indicates that MaskSearch achieves substantial performance improvements over existing methods in open-domain multi-hop question answering. The model demonstrates robust generalization, successfully outperforming baselines on both in-domain and out-of-domain downstream tasks without the need for human-annotated fine-tuning data, confirming its ability to acquire complex agentic capabilities like task decomposition and precise tool utilization.

### **Impact**
MaskSearch represents a pivotal advancement in the pursuit of generalist AI agents, offering a scalable solution to the brittleness of current search systems. By shifting the focus from task-specific supervision to universal pre-training objectives that require tool interaction, this framework provides a blueprint for developing LLMs that are inherently capable of complex reasoning and information seeking. The successful integration of multi-agent data generation, knowledge distillation, and hybrid reinforcement learning (DAPO) sets a new standard for training pipelines, potentially reducing the industry's reliance on expensive human-annotated data while enhancing the reliability of agents in complex, real-world environments.

---

## üîë Key Findings

*   **Significant Performance Enhancement:** The MaskSearch framework substantially improves the performance of Large Language Model (LLM)-based search agents.
*   **Universal Capability Acquisition:** By utilizing the Retrieval Augmented Mask Prediction (RAMP) task, models successfully acquire universal retrieval and reasoning capabilities rather than being limited to task-specific characteristics.
*   **Generalization Across Domains:** The framework demonstrates robust effectiveness on both in-domain and out-of-domain downstream tasks, highlighting its generalizability.
*   **Efficacy of Hybrid Training:** The combination of Supervised Fine-tuning (using multi-agent data generation) and Reinforcement Learning (using DAPO with hybrid rewards) proves effective for refining agentic search behaviors.

---

## üõ†Ô∏è Methodology

The research proposes **MaskSearch**, a two-stage training framework designed to build universal search capabilities.

**1. Pre-training Stage (RAMP)**
*   Introduces the **Retrieval Augmented Mask Prediction (RAMP)** task.
*   The model learns to use search tools to fill in masked spans within large-scale pre-training data.

**2. Supervised Fine-tuning (SFT) Phase**
*   Employs a hybrid approach combining agent-based and distillation-based methods.
*   Data is generated by a **multi-agent system** consisting of:
    *   **Planner**
    *   **Rewriter**
    *   **Observer**
*   Utilizes a self-evolving teacher model for data generation.

**3. Reinforcement Learning (RL) Stage**
*   Refines the model using the **DAPO** framework.
*   Implements a **hybrid reward system** to optimize performance.
*   **Curriculum Learning** strategy is implemented, progressing from easier to more challenging instances.

---

## ‚öôÔ∏è Technical Details

MaskSearch is a universal pre-training framework designed to enhance agentic search capabilities in Large Language Models (LLMs) to generalize across domains.

**Architecture**
*   **Unified System:** Consists of a Retriever (Search Tool) and a Language Model.
*   **External Knowledge:** Utilizes Wikipedia as the external corpus.

**Retrieval-Augmented Mask Prediction (RAMP)**
*   **Objective:** Predict $n$ masked spans in an input sequence by proactively retrieving information.
*   **Span Identification:** Salient spans (entities, dates, ontologies, etc.) are identified using Qwen-Turbo.
*   **Masking Strategy:** Randomly selects $k$ spans where $0 < k < 5$.

**Training Pipeline**

| Stage | Description | Key Metrics |
| :--- | :--- | :--- |
| **Stage I** | **Pre-training on RAMP** using SFT and RL. Data generation employs a multi-agent system to synthesize CoT trajectories using **Self-Evolve Distillation** with curriculum learning. The RL component uses **DAPO** with hybrid rewards. | 10M CoT Trajectories<br>14 Billion Tokens |
| **Stage II** | **Downstream Task Adaptation** via standard SFT on target datasets. | N/A |

---

## üìà Results

*Note: The provided analysis text ends before the Experimental Results section, so specific quantitative benchmark scores are not included.*

**Training Metrics**
*   Constructed a dataset comprising **10 million CoT trajectories**.
*   Total token count: **14 billion tokens**.
*   Masking strategy generates tasks with between **1 and 4 masked spans**.

**Qualitative Outcomes**
*   Achieves robust generalization on both **in-domain** and **out-of-domain** downstream tasks.
*   Provides substantial improvements in performance compared to existing methods.
*   Successfully acquires universal retrieval and reasoning capabilities, specifically:
    *   Task decomposition
    *   Tool utilization

---

## üèÜ Contributions

*   **Novel Pre-training Framework:** Introduction of MaskSearch, a universal framework designed to overcome the limitations of task-specific data and enhance the agentic search capabilities of LLMs.
*   **New Learning Objective:** Proposal of the Retrieval Augmented Mask Prediction (RAMP) task, which forces the model to learn tool usage for information reconstruction.
*   **Advanced Training Pipeline:** Development of a sophisticated data generation and training pipeline that integrates multi-agent systems, knowledge distillation, and hybrid reinforcement learning (DAPO).
*   **Validation in Complex Scenarios:** Comprehensive evaluation in the context of open-domain multi-hop question answering, providing empirical evidence of the framework's ability to handle complex, multi-step reasoning tasks.