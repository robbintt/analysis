# Visual Language Models show widespread visual deficits on neuropsychological tests

*Gene Tangtartharakul; Katherine R. Storrs*

---

> ### ðŸ“Š Quick Facts
> *   **Tests Conducted:** `51`
> *   **Psychological Batteries:** `6`
> *   **Models Assessed:** `3` State-of-the-art VLMs
> *   **Comparison:** Human normative data
> *   **Resolutions:** Up to `512x512` pixels
> *   **Quality Score:** `8/10`

---

## Executive Summary

This paper addresses a fundamental "**recognition without understanding**" paradox in artificial intelligence. While state-of-the-art Visual Language Models (VLMs) excel at high-level reasoning, they lack the elemental visual conceptsâ€”such as orientation, position, continuity, and **occlusion**â€”that form the foundation of human perception. Standard benchmarks fail to detect these low- and mid-level perceptual deficits, creating a dangerous disconnect between assumed and actual model capabilities. This challenges the prevailing assumption that neural networks automatically acquire robust visual features through large-scale training, potentially masking severe vulnerabilities in high-stakes environments.

To rigorously diagnose these failures, the researchers adapted **51** human neuropsychological tests drawn from **six** established clinical batteries. The study assessed **three** state-of-the-art VLMs against normative data from healthy adults. Technically, this involved converting physical clinical datasets (measured in centimeters) into digital pixel space and utilizing the MindSet framework to generate procedural data.

The results confirm a distinct performance gap: VLMs exhibit clinically significant deficits in foundational visual abilities despite their high-level competence. The systems consistently failed robustness checks involving "Fragmented" and "Frankenstein" image conditions. These findings suggest that simply scaling up existing architectures may not suffice; future systems may require explicit architectural changes to develop elemental perceptual processes.

---

## Key Findings

*   **High-Level vs. Low-Level Discrepancy:** State-of-the-art VLMs excel at complex reasoning tasks but struggle significantly with elemental visual concepts such as orientation, position, continuity, and occlusion.
*   **Clinically Significant Deficits:** When compared to human normative data, the models exhibited performance deficits in low- and mid-level visual abilities that would be considered clinically significant in a human context.
*   **Recognition Without Understanding:** The study demonstrates that artificial systems can achieve complex object recognition without developing the foundational visual concepts that humans possess naturally.

---

## Methodology

The study employs a **neuropsychological assessment framework** to systematically evaluate visual capabilities, moving beyond standard benchmarks. Key methodological components include:

*   **Test Battery:** A comprehensive set of **51 tests** drawn from six established clinical and experimental psychological batteries.
*   **Subjects:** Three state-of-the-art VLMs were assessed.
*   **Benchmarking:** Performance was characterized relative to normative performance data from healthy adults.

---

## Technical Details

The implementation of the study involved adapting offline clinical tools for a digital, AI-native context:

*   **Test Adaptation:** Offline neuropsychological tests (specifically BORB and L-POST) were converted for digital evaluation.
    *   Physical measurements (cm) were converted to pixel space.
    *   Stimuli were re-rendered at higher resolutions.
*   **Task Modification:** Drawing subtests were omitted in favor of binary or multiple-choice visual discrimination tasks.
*   **Data Generation:**
    *   Combined adapted clinical datasets with procedurally generated datasets using the **MindSet framework**.
    *   Data ranged from high-level semantic objects to low-level geometric primitives.
*   **Prompting:** A standardized **zero-shot prompting strategy** was employed to mimic clinical instructions.
*   **Robustness Testing:** Evaluated using 'Fragmented' and 'Frankenstein' image conditions to assess global form processing.

### Experimental Configuration & Parameters

*   **Canvas Sizes:**
    *   Matching tasks: `512x512` pixels
    *   Gap position tasks: `200x200` pixels
*   **Specific Dimensions:**
    *   Lines: `200` px
    *   Gaps: `20` px
*   **Trial Counts:**
    *   BORB subtests: `30â€“40` trials
    *   ImageNet-based tasks: `36â€“72` trials
    *   2D Transforms: `70` trials
    *   MindSet datasets: `20â€“60` trials
*   **Scoring System:**
    *   Binary system (`1` point per correct answer).
    *   Hierarchical tolerance accepting basic-level category identification.
    *   Forced-choice responses for judgment tasks.

---

## Results

*   **Quantitative Analysis:** The study evaluated models across 51 tests with trial counts ranging from 20 to 72 per dataset. Scoring utilized a hierarchical tolerance system to ensure fair assessment of category identification.
*   **Robustness Failures:** The systems consistently failed robustness checks involving "Fragmented" and "Frankenstein" image conditions.
*   **Global Form Processing:** The failures on specific image conditions highlighted an inability to process global form and continuity.
*   **Empirical Evidence:** The study provided concrete empirical evidence of a disconnect between human and machine vision, proving that architectural success in high-level reasoning does not imply the acquisition of robust low-level visual foundations.

---

## Contributions

*   **Methodological Innovation:** Introduces the application of validated human clinical and experimental test batteries as a rigorous method for diagnosing specific perceptual failures in AI systems.
*   **Evidence of Disconnect:** Provides empirical evidence of a disconnect between human and machine vision, highlighting that architectural success in high-level reasoning does not imply the acquisition of robust low-level visual foundations.
*   **Deficit Profiling:** Offers a detailed profile of selective visual deficits in VLMs, linking model failures to specific neuropsychological conditions.

---

**Quality Score:** 8/10  
**References:** 0 citations