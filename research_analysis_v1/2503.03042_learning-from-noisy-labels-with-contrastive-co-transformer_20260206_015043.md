---
title: Learning from Noisy Labels with Contrastive Co-Transformer
arxiv_id: '2503.03042'
source_url: https://arxiv.org/abs/2503.03042
generated_at: '2026-02-06T01:50:43'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Learning from Noisy Labels with Contrastive Co-Transformer

*Yan Han; Soumava Kumar Roy; Mehrtash Harandi; Lars Petersson*

---

> **ðŸ“‘ Quick Facts**
>
> *   **Framework Name:** Contrastive Co-Transformer (CCT)
> *   **Core Innovation:** Shifts from CNN to Transformer backbone for noise robustness
> *   **Training Strategy:** Hybrid loss (Contrastive + Classification)
> *   **Data Handling:** Utilizes 100% of samples (no discarding)
> *   **Performance:** State-of-the-art on 6 benchmarks
> *   **Quality Score:** 8/10

---

## Executive Summary

The research addresses the pervasive challenge of training deep learning models with noisy labels, a common issue in real-world datasets where annotations are often imperfect. Convolutional Neural Networks (CNNs), the traditional backbone for computer vision, are highly susceptible to overfitting when presented with noisy data, leading to poor generalization. Existing solutions often rely on sample selection or "curriculum learning" techniques that discard potentially noisy samples, which results in a significant loss of valuable training data.

This paper matters because it establishes a method to learn robust representations from noisy data without sacrificing data utility, addressing a critical bottleneck for scaling deep learning applications where perfect labeling is expensive or impossible.

The key innovation is the **"Contrastive Co-Transformer" (CCT)** framework, which shifts the architectural paradigm from CNNs to Transformers, demonstrating that the latter possess inherent robustness to label noise. The CCT framework integrates co-training principles with a dual-loss optimization strategy that combines contrastive loss for feature learning and classification loss for prediction. Technically, the approach utilizes two Transformer networks that teach each other, but unlike previous co-teaching methods, it does not discard data. Instead, it employs a hybrid objective function to effectively utilize all samplesâ€”both clean and noisyâ€”throughout the training process.

This results in a simple, fast, and computationally efficient framework that avoids the complexity of sample selection heuristics. The proposed framework achieved state-of-the-art performance across six benchmark datasets, consistently outperforming baselines such as Co-Teaching, JoCoR, and MentorNet. This study significantly influences the field of weakly supervised learning by challenging the dominance of CNNs in handling noisy labels and establishing Transformers as a more robust architectural alternative.

---

## Key Findings

*   **Superior Performance:** The proposed Contrastive Co-Transformer framework outperforms existing state-of-the-art methods in learning from noisy labels across six benchmark datasets, including Clothing1M.
*   **Transformer Robustness:** The study highlights that Transformers exhibit robustness to label noise, unlike Convolutional Neural Networks (CNNs) which tend to overfit when noisy samples are present.
*   **Full Data Utilization:** The approach is capable of effectively utilizing all samples within a dataset, regardless of whether they are clean or noisy, without the need to discard data.
*   **Efficiency:** The framework is described as simple and fast, achieving significant performance margins without excessive computational complexity.
*   **Effectiveness of Combined Loss:** The combination of contrastive loss and classification loss is identified as a successful training strategy for Transformers in weakly supervised learning scenarios.

---

## Methodology

The research employs a **Contrastive Co-Transformer** framework built upon the fundamental principles of Co-Training. The methodology shifts away from traditional CNNs to leverage the robustness of Transformers.

### Technical Approach
*   **Architecture:** Utilizing Transformers as the primary backbone for feature extraction and learning.
*   **Loss Function:** Training the model using a hybrid objective function that combines contrastive loss (to learn robust feature representations) and classification loss (to handle the label prediction).
*   **Data Handling:** The framework is designed to ingest the entire dataset (inclusive of both clean and noisy labels) rather than relying on sample selection or discarding techniques.

---

## Contributions

1.  **Novel Framework:** Introduction of the "Contrastive Co-Transformer," a new, simple, and fast framework that integrates contrastive learning with co-training for noisy label environments.
2.  **Architecture Shift:** Demonstrating the efficacy of Transformers over CNNs for handling label noise, providing evidence that Transformers are less prone to overfitting on noisy samples.
3.  **Optimization Strategy:** Proposing a dual-loss training mechanism (contrastive + classification) that enables the effective use of all training data, even when label reliability is low.
4.  **State-of-the-Art Results:** Validating the proposed approach through extensive experiments, setting new performance benchmarks on corrupted data from six standard datasets.

---

## Technical Details

| Component | Specification |
| :--- | :--- |
| **Framework Name** | Contrastive Co-Transformer (CCT) |
| **Core Backbone** | Transformer architectures (instead of CNNs) selected for inherent robustness to label noise and avoidance of overfitting. |
| **Training Strategy** | Employs a hybrid loss function combining contrastive loss with standard classification loss; designed to utilize all samples (both clean and noisy) without discarding data. |
| **Computational Efficiency** | Described as simple and fast. |
| **Comparison** | Serves a similar role to Co-Teaching (CT) and JoCoR (JC) but improves upon them using the Transformer backbone and contrastive learning. |

---

## Results

**Metric:** Test Set Accuracy (%) averaged over 5 runs.
**Baselines:** F-correction, Decoupling, MentorNet, Co-Teaching, JoCoR, and Cross Entropy.

### Performance Highlights

*   **MNIST:** CCT achieved best performance across all conditions.
    *   Symmetric 80%: **85.6%**
    *   Symmetric 50%: **96.2%**
*   **CIFAR-10:** CCT outperformed baselines in most setups.
    *   Symmetric 50%: **80.1%**
*   **CIFAR-100:** CCT showed high noise resilience.
    *   Symmetric 80%: **15.5%**
    *   Symmetric 50%: **44.3%**
*   **Fine-Grained Datasets (CUB200-2011 & CARS196):**
    *   CUB200-2011 (Symmetric 50%): **57.2%**
    *   CARS196 (Symmetric 50%): **69.6%**

### Summary
CCT is particularly effective in high-noise regimes (50% and 80%), consistently securing top rank across most datasets.

---

**Quality Score:** 8/10
**References:** 40 citations