---
title: 'ExPairT-LLM: Exact Learning for LLM Code Selection by Pairwise Queries'
arxiv_id: '2511.10855'
source_url: https://arxiv.org/abs/2511.10855
generated_at: '2026-01-27T21:17:58'
quality_score: 5
citation_count: 17
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# ExPairT-LLM: Exact Learning for LLM Code Selection by Pairwise Queries

*Pairwise Queries, Tom Yuviler, Exact Learning, Code Selection, Dana Drachsler*

---

### ðŸ“Š Quick Facts

| **Metric** | **Detail** |
| :--- | :--- |
| **Quality Score** | 5/10 |
| **References** | 17 Citations |
| **Core Focus** | LLM Code Selection |
| **Method** | Exact Learning / Pairwise Queries |

---

## Executive Summary

> This paper addresses the challenge of selecting the correct solution among multiple candidates generated by Large Language Models (LLMs) for a single coding task. Current methods relying on isolated evaluation or probabilistic scoring fail to capture subtle semantic errors or logic flaws. The authors emphasize the need for "Exact" selection capabilities to deterministically distinguish between correct and incorrect program logic, aiming to reduce hallucinations in automated software engineering.
>
> The authors introduce **ExPairT-LLM**, a novel system that integrates Exact Learning theory with LLM capabilities through an interactive pairwise querying mechanism. Unlike standard prompt engineering approaches, ExPairT-LLM establishes a rigorous feedback loop with an external User or Oracle to ground evaluations in execution truth.
>
> The system uses "Pairwise Equivalence Queries," instructing the LLM to act as a discriminator that generates distinguishing inputs (counter-examples) highlighting behavioral differences between candidate programs, supported by "Pairwise Membership Queries" to verify specific behaviors. The system's effectiveness was validated through qualitative analysis demonstrating precise semantic bug detection and the ability to handle complex structured inputs. ExPairT-LLM successfully generated distinguishing test cases that exposed logical divergences matching task specifications. Notably, the system generated the input `test_list=[(0, 10)]`, which effectively differentiated between a standard maximum difference calculation and an absolute value calculation, confirming its capacity to produce concrete counter-examples that validate nuanced program behaviors.
>
> This research establishes a theoretical bridge between Exact Learning frameworks and practical LLM applications, transforming code selection into an interactive, verified process. By relying on external oracle validation to differentiate logic, ExPairT-LLM provides a rigorous methodology for automated code verification that directly mitigates model hallucination.

---

## Key Findings

*   **Core Challenge:** Addresses the difficulty of **Code Selection in LLMs**, specifically picking the best code solution from multiple generated candidates.
*   **Primary Goal:** Achieves **'Exact' selection capabilities** to improve the accuracy of choosing correct code implementations.
*   **Problem Statement:** Current isolated evaluation methods fail to capture subtle semantic errors; the proposed method aims to fix this by grounding selection in execution truth.
*   **Outcome:** The system successfully identifies semantic differences (bugs) by generating concrete counter-examples.

---

## Methodology

The paper proposes **ExPairT-LLM**, a system built upon the theory of Exact Learning. Instead of evaluating code snippets in isolation, the system utilizes an interactive, iterative process:

1.  **Refinement via Comparison:** The system refines its choice by asking a user or "Oracle" to compare two code snippets against one another.
2.  **Interactive Querying:** It utilizes a feedback loop to deterministically distinguish between correct and incorrect program logic.
3.  **Discrimination:** The core mechanism involves distinguishing between two candidate programs based on a task defined by a docstring.

---

## Technical Details

The approach implements an **Exact Learning framework** adapted specifically for LLM code selection.

### Core Components

*   **Pairwise Equivalence Query**
    *   **Function:** Acts as a discriminator for candidate programs.
    *   **Inputs:** Partial docstring and source code for two programs.
    *   **Mechanism:** Instructs the LLM to find a valid **'distinguishing input'** (counter-example) that induces different outputs between the two programs.
    *   **Prompt Engineering:** Enforces strict output formatting and suppresses Chain-of-Thought to focus on structural differentiation.

*   **Pairwise Membership Query**
    *   **Function:** Verifies specific program behavior for given inputs.

### Operational Logic

*   **Target Scenario:** Distinguishing between logic calculating `max(a - b)` versus `max(abs(b - a))`.
*   **Processing:** The system can handle structured inputs, such as lists of tuples, to test logical divergences.

---

## Results

*   **Quantitative Data:** The provided text does not contain quantitative experimental results or benchmark scores (e.g., accuracy, Pass@k).
*   **Qualitative Success:**
    *   **Bug Detection:** Demonstrated success in identifying semantic differences between logic flows.
    *   **Example Case:** Successfully generated the input `test_list=[(0, 10)]` to differentiate between a standard max difference calculation and an absolute value max difference calculation.
    *   **Complexity:** Showed capability in handling structured inputs like lists of tuples.

---

## Contributions

*   **System Development:** Created the **ExPairT-LLM** system.
*   **Theoretical Application:** Successfully applied **Exact Learning theory** and **Pairwise Queries** to the domain of LLM code selection.
*   **Process Innovation:** Transformed code selection into an interactive, verified process using external oracle validation.