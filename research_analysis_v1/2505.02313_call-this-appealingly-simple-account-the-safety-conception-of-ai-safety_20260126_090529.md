---
title: Call this appealingly simple account The Safety Conception of AI safety
arxiv_id: '2505.02313'
source_url: https://arxiv.org/abs/2505.02313
generated_at: '2026-01-26T09:05:29'
quality_score: 8
citation_count: 18
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Call this appealingly simple account The Safety Conception of AI safety

*The Safety, What Do, Rutgers University, Jacqueline Harding, Stanford University, What Is, Cameron Domenico, We Want*

---

### Quick Facts

| Metric | Details |
| :--- | :--- |
| **Methodology** | Conceptual Engineering |
| **Core Definition** | The Safety Conception (Harm-based) |
| **Taxonomy Categories** | 3 (Non-empirical, Empirical Understanding, Empirical Prevention) |
| **Key Metrics** | 7 Harm Taxonomies, Model-agnostic Benchmarks, Agency Benchmarks |
| **Quality Score** | 8/10 |
| **Citations** | 18 References |

---

## Executive Summary

> The field of AI safety currently suffers from a lack of operational consensus, leading to fragmentation between sub-disciplines and arbitrary barriers to defining valid research. This problem manifests as a tension where the field is increasingly restricted to catastrophic risk scenarios or confined strictly to engineering paradigms. Consequently, significant research areasâ€”such as bias mitigation and privacy protectionâ€”are frequently marginalized as separate ethical concerns rather than integrated components of safety. This lack of a unifying definition hinders the field's ability to collectively evaluate research priorities and validate efforts aimed at mitigating immediate and non-catastrophic harms.
>
> To resolve this, the authors introduce **"The Safety Conception,"** a constitutive definition established through conceptual engineering that characterizes AI safety research strictly as any effort aiming to prevent or reduce harms caused by AI systems. The innovation lies in a technical taxonomic framework that unifies disparate methodologies into three categories: non-empirical research on harms (e.g., instrumental convergence), empirical research on understanding systems (e.g., red-teaming, robustness), and empirical research on prevention. This framework operates inclusively regarding the type or scale of harm, while explicitly excluding normative studies that focus on broader concepts like justice or power without being directly framed as harm prevention.
>
> **Impact:** The analysis identifies that despite the logical appeal of the Safety Conception, the field remains divided by two main tensions: a scope restriction favoring catastrophic risks over current social harms, and methodological constraints that limit safety to engineering approaches. By integrating technical safety research with ethical and social issues, the Safety Conception fosters descriptive continuity between central engineering challenges and marginal issues like bias. This unified framework allows researchers to evaluate the merits of diverse safety efforts on a level playing field, ultimately promoting a more inclusive and effective approach to preventing AI-related harms.

---

## Key Findings

*   **Constitutive Definition:** The paper proposes that AI safety should be constitutively defined as research aiming to prevent or reduce harms caused by AI systems.
*   **Field Tension:** This definition stands in contrast to current trends that focus exclusively on catastrophic risks or frame the field strictly as safety engineering.
*   **Descriptive Continuity:** The concept bridges the gap between central topics and marginal issues (like bias and privacy), treating them as parts of a cohesive whole.
*   **Normative Justification:** The framework shifts evaluation criteria to actual merits of harm prevention rather than relying on arbitrary disciplinary distinctions.

---

## Methodology

The authors utilize **Conceptual Engineering**, a philosophical methodology designed to assess and evaluate concepts. By applying this method, the authors determine the best conceptualization of 'AI safety' by considering both:

1.  **Descriptive Implications:** How the term is currently used and what it covers.
2.  **Normative Implications:** How the term *should* be used to achieve the field's goals effectively.

---

## Technical Details

### The Safety Conception
The paper establishes a constitutive definition: **AI safety research** is defined as work aiming to prevent or reduce harms caused by AI systems, regardless of harm type or scale.

### Taxonomic Framework
The research establishes a framework comprising three distinct categories:

1.  **Non-empirical research on harms:** Works concerning theoretical risks (e.g., instrumental convergence).
2.  **Empirical research on understanding systems:** Includes model evaluation, safety evaluation, adversarial robustness, and red-teaming.
3.  **Empirical research on preventing/mitigating harm:** Active measures to reduce identified risks.

### Exclusions
The framework explicitly excludes normative research not framed specifically as harm reduction. Examples of excluded topics include:
*   Studies on power dynamics.
*   Transparency treated as an intrinsic value.
*   Accountability focused solely on justice rather than harm mitigation.

---

## Contributions

*   **Conceptual Clarification:** Defends a broad, harm-based definition of AI safety that clears up ambiguity in the field.
*   **Field Integration:** Successfully bridges the gap between disparate areas of studyâ€”such as technical safety and ethical issuesâ€”through a shared foundation in harm reduction.
*   **Normative Evaluation Framework:** Provides a structure for prioritizing research that eliminates arbitrary categorization and recognizes all valid efforts to mitigate AI harms.

---

## Results

The study highlights a discrepancy between the proposed Safety Conception and the current state of the field:

*   **Lack of Consensus:** There is a lack of operational consensus within the field despite the prevalence of the Safety Conception logic.
*   **Identified Tensions:**
    1.  **Scope Restriction:** The field is increasingly focusing on catastrophic risks rather than current social harms.
    2.  **Methodological Constraints:** There is a trend limiting the field strictly to engineering paradigms.
*   **Operational Metrics:** The analysis references specific tools to operationalize the framework, including:
    *   **Harm taxonomies:** (referencing 7 types)
    *   **Model-agnostic benchmarks**
    *   **Dangerous capability tests:** (e.g., chemical synthesis evaluations)
    *   **Agency benchmarks**
    *   **Evaluation parameters:** Defined by specific threat models.