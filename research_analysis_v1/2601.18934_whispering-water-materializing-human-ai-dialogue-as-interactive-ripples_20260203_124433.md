---
title: 'Whispering Water: Materializing Human-AI Dialogue as Interactive Ripples'
arxiv_id: '2601.18934'
source_url: https://arxiv.org/abs/2601.18934
generated_at: '2026-02-03T12:44:33'
quality_score: 8
citation_count: 23
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Whispering Water: Materializing Human-AI Dialogue as Interactive Ripples

*Ruipeng Wang; Tawab Safi; Yunge Wen; Christina Cunningham; Hoi Ling Tang; Behnaz Farahi*

---

> **Executive Summary**
>
> Current Human-Computer Interaction (HCI) paradigms rely heavily on screen-based interfaces, which often lack the sensory richness required to facilitate deep emotional connection or vulnerability. This research addresses the limitation of traditional graphical user interfaces (GUIs) in supporting intimate, self-reflective dialogue, arguing that conventional systems fail to leverage the expressive potential of physical materials. 
>
> The study seeks to bridge the gap between digital cognition and physical experience by creating a system where AI interactions are not merely displayed on a monitor but are embodied within a yielding, dynamic medium capable of expressing the nuance of human emotion. The core innovation is the "Whispering Water" installation, a multi-agent system that translates human-AI dialogue into physical cymatic patterns on a water surface.
>
> Technically, the system employs a proprietary algorithm that decomposes human speech into component waves and reconstructs them acoustically via submerged hardware. The architecture utilizes a dual-stream processing method: a semantic stream feeds dialogue into a situated multi-agent system (utilizing diverse LLMs) to generate context-aware responses, while a sentiment analysis stream utilizes emotion2vec+ to map emotional tone to specific frequency bands. This design allows the "mood" of the conversation to physically prime the liquid state, while machine reasoning is rendered as emergent ripples.
>
> By successfully materializing digital dialogue as tangible ripples, the research establishes a framework for using sensory-rich materials to foster emotional vulnerability and self-exploration in human-AI interactions.

---

### ðŸ“Š Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **Citations** | 23 references |
| **AI Agents** | 6 (Claude Sonnet 4.5, GPT-4.5, Gemini 2.0) |
| **Water Capacity** | 2 gallons |
| **Max Input Time** | 15 seconds |
| **Response Limit** | 150 characters |
| **Interaction Rounds** | 4 |

---

## Key Findings

*   **Materialized Dialogue:** The 'Whispering Water' installation successfully translates human-AI dialogue into physical cymatic patterns on water, moving interaction beyond digital screens.
*   **Situated AI Identities:** The system utilizes a multi-agent architecture where AI identities are situated through discourse, employing dynamic voice profiles and semantic responses visualized as conversational ripples.
*   **Novel Wave Algorithm:** A proprietary algorithm was developed that decomposes human speech into component waves and reconstructs them physically in water, allowing speech sentiment to prime the liquid state.
*   **Emotional Engagement:** The installation facilitates emotional vulnerability and self-exploration through a structured four-phase ritual.

## Methodology

The researchers developed an interactive installation centered on a water surface interface acting as a medium for confession. The system operates through a distinct process:

*   **Four-Phase Ritual:** The interaction is structured as a ritualistic process guiding the user through stages of confession and reflection.
*   **Dual-Stream Processing:**
    *   **Sentiment Analysis:** Speech sentiment is analyzed in real-time to directly alter the water's physical state (turbulence/frequency).
    *   **Semantic Processing:** Content is fed into a multi-agent system to generate context-aware responses.
*   **Physical Reconstruction:** A proprietary algorithm decomposes speech waves to reconstruct them physically on water, rendering machine reasoning as emergent physical phenomena. Specific voice profiles are chosen by agents based on discourse context.

## Contributions

*   **Novel Algorithm:** Introduction of a novel algorithm that establishes a translation between speech audio and the physics of material form.
*   **HCI Paradigm Shift:** Advancement in HCI presenting a new paradigm for human-AI interaction that moves beyond screens to yielding, sensory-rich materials for emotional contexts.
*   **Generative Multi-Agent Design:** Contribution to the design of generative multi-agent systems where agent identity is situated through ongoing discourse and visualized through dynamic physical ripples.

## Technical Details

### System Architecture
*   **AI Models:** Multi-agent architecture utilizing six AI agents (Claude Sonnet 4.5, GPT-4.5, Gemini 2.0).
*   **Processing Model:** Employed a situated discourse model with asynchronous processing.

### Software & Signal Processing
*   **Speech Analysis:** Utilizes emotion2vec+ for sentiment-to-frequency mapping.
*   **Cymatic Translation:** Features signal processing through speech decomposition and acoustic superposition.
*   **Voice Synthesis:** ElevenLabs TTS for dynamic voice profiles.
*   **Control:** Lighting controlled via Arduino and TouchDesigner.

### Hardware Implementation
*   **Interface:** Audio managed via a Focusrite Scarlett 18i20 interface.
*   **Actuation:** Six subwoofers driven by three amplifiers.
*   **Enclosure:** 72x12x32 inch water basin.

## Results

The system demonstrated specific operational constraints and behaviors during testing:

*   **Physical Limits:** The system holds 2 gallons of water.
*   **Interaction Protocol:**
    *   Records spoken input for a maximum of 15 seconds.
    *   Limits individual agent responses to 150 characters.
*   **Sentiment Mapping Frequency Bands:**
    *   **Low Sentiment:** 20â€“40 Hz
    *   **Mid-Range Sentiment:** 50â€“70 Hz
    *   **High Sentiment:** 80â€“100 Hz
*   **Operational Workflow:**
    *   Comprises 4 dialogue rounds.
    *   **Rounds 1-3:** Sequential actuation.
    *   **Round 4:** Simultaneous actuation of 6 waves to represent collective conclusions.