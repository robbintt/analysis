# Robust Machine Unlearning for Quantized Neural Networks via Adaptive Gradient Reweighting with Similar Labels

*Yujia Tong; Yuze Wang; Jingling Yuan; Chuang Hu*

---

> ### ðŸ“Š Quick Facts
>
> *   **Focus:** Machine Unlearning for Quantized Neural Networks (QNNs)
> *   **Proposed Framework:** Q-MUL
> *   **Key Innovations:** Similar Labels (SL) Assignment & Adaptive Gradient Reweighting (AGR)
> *   **Test Model:** ResNet18 (4-bit weights and activations)
> *   **Dataset:** CIFAR-100
> *   **Top Performance:** Avg. Gap of 6.00% (PACT), 8.26% (DSQ)
> *   **Quality Score:** 9/10

---

## Executive Summary

This research addresses the critical lack of effective machine unlearning (MU) methods for quantized neural networks (QNNs). While machine unlearning is essential for complying with privacy regulations like the "right to be forgotten," existing approximate unlearning techniquesâ€”designed for full-precision modelsâ€”fail when applied to quantized models. This failure stems from the discrete optimization constraints inherent in quantization, which exacerbate two specific issues: **noise amplification** caused by mismatched labels and **gradient imbalance** between the data to be forgotten and the data to be retained.

As QNNs are increasingly deployed on resource-constrained edge devices, the inability to effectively remove data from them poses a significant privacy and security risk. The authors introduce **Q-MUL**, the first dedicated unlearning framework specifically designed for quantized neural networks.

To overcome the limitations of discrete parameter spaces, Q-MUL employs two technical innovations. First, **Similar Labels (SL)** Assignment replaces random label noise with semantically consistent alternatives, minimizing destructive noise injection. Second, **Adaptive Gradient Reweighting (AGR)** dynamically aligns parameter updates to correct gradient imbalance. The framework was validated on ResNet18 architectures (4-bit weights/activations) using CIFAR-100, significantly outperforming baselines like Random Labels and SalUn while maintaining accuracy comparable to the gold-standard Retrain baseline. This work represents a foundational shift in privacy-preserving deep learning, bridging the gap between efficient model quantization and the legal necessity of data removal.

---

## Key Findings

*   **Failure of Standard Methods:** Existing machine unlearning methods are ineffective when applied to quantized neural networks (QNNs).
*   **Root Causes Identified:** Failures are specifically driven by:
    *   Noise amplification resulting from label mismatches.
    *   Gradient imbalance between the "forgotten" and "retained" data subsets.
*   **Noise Mitigation:** Utilizing semantically consistent 'Similar Labels' effectively minimizes noise injection during the unlearning process.
*   **Superior Performance:** The proposed Q-MUL framework consistently outperforms current state-of-the-art approaches on benchmark datasets.

---

## Methodology

The researchers propose **Q-MUL**, the first unlearning framework specifically designed for quantized neural networks. It addresses the challenges of discrete optimization and constrained parameter spaces through two specific technical innovations:

1.  **Similar Labels Assignment:** A method designed to reduce noise by utilizing semantically consistent label alternatives rather than random ones.
2.  **Adaptive Gradient Reweighting:** A mechanism to dynamically align parameter updates and correct gradient imbalances between data classes.

The approach is rigorously validated by a theoretical analysis of quantized model vulnerabilities.

---

## Technical Details

### Problem Statement
Q-MUL addresses the failure of existing approximate Machine Unlearning (MU) methods in Quantized Neural Networks (QNNs). The primary technical hurdles are:
*   **Noise Amplification:** Exacerbated by the discrete nature of QNNs.
*   **Gradient Imbalance:** The conflicting optimization requirements for forgetting vs. retaining data.

### Proposed Solution Components
*   **Similar Labels (SL):** Minimizes noise by replacing standard random noise injection (often used in unlearning) with labels that are semantically consistent with the original data.
*   **Adaptive Gradient Reweighting (AGR):** Dynamically balances the gradient contributions of the "forget" and "retain" sets to stabilize the optimization process.

### Experimental Setup
*   **Architecture:** ResNet18
*   **Quantization:** 4-bit weights and activations
*   **Quantization Methods Tested:** PACT (Learned Step Size Quantization) and DSQ (Differentiable Soft Quantization).

---

## Contributions

*   **Framework Introduction:** Introduced Q-MUL, the first dedicated unlearning framework created expressly for quantized neural networks.
*   **Challenge Formalization:** Identified and formally defined the specific challenges of applying machine unlearning to quantized models, specifically noise amplification and gradient imbalance.
*   **Theoretical Foundation:** Developed the theoretical foundations required to explain and analyze quantized model vulnerabilities regarding privacy.
*   **Algorithmic Innovation:** Contributed two novel algorithmic components: Similar Labels assignment and Adaptive Gradient Reweighting.

---

## Results

**Performance on CIFAR-100 with ResNet18 (4w4a):**

*   **Q-MUL vs. Baselines:** Q-MUL significantly outperformed baselines like Random Labels and SalUn.
*   **Average Gap (AG) Metrics:**
    *   **PACT:** 6.00%
    *   **DSQ:** 8.26%
*   **Accuracy Maintenance:** Successfully maintained Test Accuracy close to the Retrain baseline (the gold standard).

**Ablation Studies:**
*   **SimilarLabels Efficacy:** Reduced the Retain Accuracy (RA) gap from **3.52%** to **2.09%**.
*   **AGR Efficacy:** Improved Forget Accuracy and Retain Accuracy (RA) metrics by **3.97%** and **5.81%** respectively.

**Generalizability:**
*   When applied to full-precision models, Q-MUL achieved a competitive average gap of **5.46%**.

---

**References:** 40 citations
**Quality Score:** 9/10