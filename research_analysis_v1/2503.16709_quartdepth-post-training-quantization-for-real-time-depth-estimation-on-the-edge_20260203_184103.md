---
title: 'QuartDepth: Post-Training Quantization for Real-Time Depth Estimation on the
  Edge'
arxiv_id: '2503.16709'
source_url: https://arxiv.org/abs/2503.16709
generated_at: '2026-02-03T18:41:03'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# QuartDepth: Post-Training Quantization for Real-Time Depth Estimation on the Edge

*Xuan Shen; Weize Ma; Jing Liu; Changdi Yang; Rui Ding; Quanyi Wang; Henghui Ding; Wei Niu; Yanzhi Wang; Pu Zhao; Jun Lin; Jiuxiang Gu*

---

> ### üìä Quick Facts
>
> *   **Target Precision:** 4-bit (W4A4)
> *   **Hardware Platform:** Custom ASIC (Matrix Multiply Units & Vector Compute Units)
> *   **Core Backbone:** ViT-Large (Metric3D)
> *   **Speedup:** Up to **5.5x** vs Float32 baseline
> *   **Datasets:** NYUv2, KITTI
> *   **Calibration Data:** Low sensitivity (16‚Äì128 samples)

---

## üìù Executive Summary

State-of-the-art Monocular Depth Estimation (MDE) models rely heavily on complex Vision Transformers and full-precision floating-point arithmetic, creating substantial computational burdens that exceed the capabilities of resource-constrained edge devices. The reliance on standard floating-point computation introduces critical bottlenecks in memory bandwidth, energy consumption, and latency, rendering real-time deployment on Application-Specific Integrated Circuits (ASICs) infeasible.

This paper addresses the necessity of enabling high-accuracy depth estimation on edge hardware by aggressively reducing the precision of model weights and activations, thereby mitigating the prohibitive costs associated with current high-performance models. The authors introduce **QuartDepth**, a hardware-software co-design framework that utilizes Post-Training Quantization (PTQ) to achieve aggressive 4-bit precision for both weights and activations (W4A4).

The software layer employs a three-step pipeline to counter accuracy degradation: **LogNP Polishing** to smooth decoder outliers, a **Compensation Method** to address activation precision loss, and **Weight Reconstruction**. This algorithmic approach is tightly integrated with a custom, programmable ASIC accelerator featuring Matrix Multiply Units (MMUs) and Vector Compute Units (VCUs), architected to support kernel fusion and customized instruction sets that maximize dataflow efficiency.

Evaluations conducted on the ViT-Large backbone within Metric3D, using the NYUv2 and KITTI datasets, demonstrate that QuartDepth maintains near-identical accuracy to the Float32 baseline (AbsRel of 0.097 vs. 0.096). In terms of performance, the framework achieved significant latency speedups ranging from **2.6x to 5.5x** compared to the Float32 baseline across various hardware configurations. Ablation studies confirmed the method's robustness, showing low sensitivity to calibration sample sizes and hardware scalability, while outperforming existing methods like BrecQ.

QuartDepth successfully bridges the gap between high-performance foundational depth models and the strict constraints of edge-device deployment, establishing the feasibility of real-time, energy-sensitive computer vision applications on the edge.

---

## üîë Key Findings

*   **Edge Deployment Achieved:** The QuartDepth framework enables the deployment of complex Monocular Depth Estimation (MDE) models on resource-limited ASICs.
*   **Aggressive Quantization:** Successfully quantizes both weights and activations to **4-bit precision**, significantly reducing model size and computational costs.
*   **Hardware Efficiency:** Integration with a customized hardware accelerator results in fast inference speeds and improved energy efficiency compared to standard implementations.
*   **Accuracy Retention:** Despite low-bit precision, the framework maintains competitive accuracy through specific software-based error mitigation techniques.

---

## üõ†Ô∏è Methodology

The research utilizes a Post-Training Quantization (PTQ) approach tailored for hardware acceleration on ASICs. The methodology is divided into two distinct layers:

### 1. Algorithmic Optimization
A software pipeline designed to minimize quantization errors:
*   **Activation Polishing:** Applied before activation quantization to prepare the data.
*   **Compensation Algorithm:** Applied after activation quantization to mitigate precision loss.
*   **Weight Reconstruction:** Optimizes weights to further reduce error margins.

### 2. Hardware Architecture
A physical implementation designed to support the quantized model:
*   **Flexible Accelerator:** A programmable hardware accelerator designed specifically for this framework.
*   **Kernel Fusion:** Supports kernel fusion to enhance overall throughput.
*   **Custom Instructions:** Uses customized instruction programmability to improve efficiency.

---

## üöÄ Contributions

1.  **QuartDepth Framework:** Introduction of a specialized PTQ framework bridging high-performance foundational depth estimation models and edge-device ASIC constraints.
2.  **Novel Mitigation Techniques:** Development of Quantization Mitigation Techniques (activation polishing, compensation, and weight reconstruction) to mitigate performance degradation from 4-bit quantization.
3.  **Hardware-Software Co-Design:** Proposal of a dedicated hardware accelerator architecture supporting kernel fusion and programmable instructions.
4.  **Real-Time Enablement:** Demonstration that state-of-the-art depth estimation is viable for real-time, energy-sensitive applications on edge hardware.

---

## ‚öôÔ∏è Technical Details

*   **Framework Type:** Post-Training Quantization (PTQ)
*   **Target Task:** Monocular Depth Estimation (MDE)
*   **Precision:** Aggressive 4-bit (W4A4) for deployment on ASICs
*   **Software Algorithms:**
    *   **"LogNP Polishing":** Smooths decoder outliers.
    *   **"Compensation Method":** Mitigates activation precision loss.
    *   **"Weight Reconstruction":** Reduces weight quantization error.
*   **Hardware Specs:**
    *   Flexible, programmable ASIC accelerator.
    *   **Matrix Multiply Units (MMUs):** Handle heavy matrix operations.
    *   **Vector Compute Units (VCUs):** Handle variable dataflows.

---

## üìà Results

### Experimental Setup
*   **Model:** ViT-Large backbone within Metric3D
*   **Datasets:** NYUv2 and KITTI
*   **Metrics:** AbsRel and $\delta$ (delta accuracy)
*   **Benchmark:** Compared against BrecQ

### Performance Metrics
*   **Accuracy:** Maintained near-identical accuracy to Float32 baseline (AbsRel 0.097 vs 0.096).
*   **Speedup:** Significant latency reductions versus Float32 baseline with speedup multipliers of:
    *   5.5x
    *   3.4x
    *   4.5x
    *   3.0x
    *   2.6x
    *   3.5x
    *(Across different configurations)*

### Ablation Studies
*   **Calibration Sensitivity:** Analyzed sample counts (16, 32, 64, 128). The W4A4 model showed low sensitivity to resource constraints compared to Float32.
*   **Scalability:** Hardware scalability tested on 2, 4, and 8 cores.

---

**Quality Score:** 8/10  
**References:** 40 citations