# Linguists should learn to love speech-based deep learning models
*Marianne de Heer Kloots; Paul Boersma; Willem Zuidema*

***

> ### üìë Executive Summary
>
> The paper addresses a fundamental **"modality bias"** in current cognitive science and linguistics, specifically critiquing frameworks proposed by researchers like Futrell and Mahowald that rely exclusively on text-based Large Language Models (LLMs). The authors argue that human language is evolutionary and functionally rooted in speech; consequently, research confined to written text fails to capture the full spectrum of linguistic phenomena. This limitation is critical because it excludes phonetic, prosodic, and auditory features, preventing linguists from answering fundamental questions about human language capabilities and processing.
>
> The key innovation is a **paradigmatic shift from text-centric to speech-centric modeling**, positioning audio-based deep learning models as the necessary bridge between technological systems and linguistic theories. Rather than proposing a specific new architecture, the authors advocate conceptually for replacing discrete text inputs with continuous audio signals in deep learning pipelines. This approach leverages the potential of self-supervised learning on raw audio, allowing models to capture nuances of spoken language‚Äîsuch as intonation and timing‚Äîthat are invisible to text-only systems, thereby enabling a more accurate interface between AI and biological language processing.
>
> As this research is a theoretical commentary and critical analysis, it does not present empirical experimental results or quantitative metrics. Instead, the primary outcome of the work is the identification of text reliance as a critical flaw in existing frameworks. The authors qualitatively demonstrate that current text-based approaches reach an asymptote in explanatory power, concluding that the integration of audio models is a mandatory requirement for advancing the field, rather than an optional addition.
>
> This work holds significant implications for the future of computational linguistics by broadening the interdisciplinary scope to include the auditory dimension of language. It challenges the field to move beyond the convenience of text corpora and embrace the complexity of speech-based modeling. The paper urges linguists to view deep learning not just as a tool for processing text, but as a means to model the physical reality of spoken language, potentially reshaping future research directions in both cognitive science and natural language processing.

***

## ‚ö° Quick Facts

| Metric | Details |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **Citations** | 0 |
| **Methodology** | Theoretical Argumentation |
| **Empirical Data** | None |

***

## üîë Key Findings

*   **Framework Limitations**: The current framework proposed by Futrell and Mahowald is limited by its exclusive focus on generative text-based Large Language Models (LLMs).
*   **Beyond Written Text**: Fundamental questions regarding human language cannot be fully addressed through the analysis of written text alone.
*   **Scope of Phenomena**: Many linguistically interesting phenomena fall outside the scope of text-based systems (e.g., prosody, intonation).
*   **The Critical Missing Component**: Audio-based deep learning models are identified as a critical missing component for bridging technology-oriented systems and explanation-oriented linguistic theories.

## üõ†Ô∏è Methodology

The paper employs a **theoretical argumentation and commentary approach**, utilizing a critical analysis rather than empirical experimentation.

*   **Critical Analysis**: It evaluates the limitations of an existing framework (specifically that of Futrell and Mahowald).
*   **Argumentation**: It argues for a necessary shift in research focus from text to speech.

## üí° Contributions

*   **Identification of Modality Bias**: Highlights the significant limitation of relying solely on text-based LLMs when attempting to interface with human linguistics.
*   **Advocacy for Speech-Based Models**: Makes a strong case for the integration of audio-based deep learning models.
*   **Broadening Interdisciplinary Scope**: Expands the potential intersection between technological deep learning systems and linguistic theories to include the auditory dimension of language.

## ‚öôÔ∏è Technical Details

The technical scope of the paper is conceptual rather than architectural.

*   **Primary Focus**: Audio-based deep learning models.
*   **Architectures**: Specific architectures (e.g., Transformers, CNNs) are not detailed.
*   **Structures**: Encoder-decoder structures are not specified.
*   **Learning Objectives**: Specific self-supervised learning objectives are not mentioned.
*   **Preprocessing**: Data preprocessing pipelines are not discussed.

*Note: The authors focus on the conceptual necessity of audio models rather than proposing a specific technical implementation.*

## üìä Results

This paper is a theoretical work and does not contain experimental results.

*   **Quantitative Metrics**: None. No quantitative metrics are provided.
*   **Qualitative Outcomes**:
    *   Identification of text reliance as a critical flaw in existing frameworks.
    *   Demonstration that current text-based approaches reach an asymptote in explanatory power.
    *   Conclusion that integration of audio models is a mandatory requirement for advancing the field.