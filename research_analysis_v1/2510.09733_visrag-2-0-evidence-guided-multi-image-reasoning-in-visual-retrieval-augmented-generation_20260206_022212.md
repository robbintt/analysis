---
title: 'VisRAG 2.0: Evidence-Guided Multi-Image Reasoning in Visual Retrieval-Augmented
  Generation'
arxiv_id: '2510.09733'
source_url: https://arxiv.org/abs/2510.09733
generated_at: '2026-02-06T02:22:12'
quality_score: 8
citation_count: 35
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# VisRAG 2.0: Evidence-Guided Multi-Image Reasoning in Visual Retrieval-Augmented Generation

*Yubo Sun; Chunyi Peng; Yukun Yan; Shi Yu; Zhenghao Liu; Chi Chen; Zhiyuan Liu; Maosong Sun*

---

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 8/10
> *   **Citations:** 35
> *   **Key Innovation:** Reward-Scoped Group Relative Policy Optimization (RS-GRPO)
> *   **Avg. Performance Gain:** +27% over backbone VLMs
> *   **Training Data:** 60k SFT samples / 4k RL samples
> *   **Top Benchmark Win:** +29.67% accuracy on SlideVQA

---

## Executive Summary

Current Visual Retrieval-Augmented Generation (VRAG) systems face a critical limitation when handling multi-image inputs: they struggle to reliably perceive and integrate evidence distributed across different visuals. This deficiency often leads to hallucinations or inaccurate answers, as models fail to ground their reasoning in specific, question-relevant details found in separate images.

Addressing this gap is essential for advancing complex visual question answering (VQA), where accurate conclusions frequently depend on synthesizing disparate pieces of information from multiple sources rather than analyzing a single image in isolation.

The researchers introduce **EVisRAG**, an end-to-end framework that restructures the reasoning process into two distinct phases:
1.  **Observation and Recording:** The model explicitly identifies and records evidence from each image.
2.  **Aggregation and Derivation:** The model synthesizes this evidence to generate a final answer.

To optimize this pipeline, the authors developed **Reward-Scoped Group Relative Policy Optimization (RS-GRPO)**, a novel training algorithm that assigns fine-grained rewards to specific token scopes (format, perception, and derivation). This technique solves the credit assignment problem inherent in long reasoning chains, allowing for the joint optimization of visual perception and reasoning capabilities.

Evaluated across five VQA benchmarks, EVisRAG demonstrated substantial performance improvements over existing state-of-the-art models. It outperformed the Qwen2.5-VL-7B backbone with an average accuracy gain of **+19.51%** and an F1 score gain of **+27.45%**. Additionally, EVisRAG surpassed the best baseline, OpenVLThinker-7B. Notably, the framework showed exceptional strength in specific tasks, recording a **+29.67%** accuracy improvement on SlideVQA.

This research significantly advances the field by demonstrating that grounding visual reasoning in explicit evidence aggregation drastically reduces hallucinations and improves reliability.

---

## Key Findings

*   **Significant Performance Improvement:** EVisRAG outperforms backbone Vision-Language Models (VLMs) by an average of **27%** across multiple visual question answering benchmarks.
*   **Precise Multi-Image Perception:** Unlike current VRAG systems, EVisRAG precisely perceives and localizes question-relevant evidence across multiple images.
*   **Reduction in Hallucinations:** The framework achieves strong grounding and accuracy by deriving answers from aggregated evidence rather than hallucinating.
*   **Optimization via RS-GRPO:** The proposed Reward-Scoped Group Relative Policy Optimization (RS-GRPO) training algorithm is crucial for jointly optimizing the model's visual perception and reasoning abilities.

---

## Methodology

The researchers propose EVisRAG, an end-to-end framework designed to facilitate evidence-guided multi-image reasoning. The methodology operates in two distinct phases:

1.  **Observation and Recording:** The model observes retrieved images and records per-image evidence.
2.  **Aggregation and Derivation:** The model derives the final answer from the aggregated evidence.

To train the framework, the authors introduce **Reward-Scoped Group Relative Policy Optimization (RS-GRPO)**. This technique binds fine-grained rewards to scope-specific tokens to jointly optimize visual perception and reasoning capabilities.

---

## Technical Details

### Framework Pipeline
EVisRAG proposes an Evidence-Guided Multi-Image Reasoning paradigm consisting of a four-step pipeline:
1.  **Observe**
2.  **Record Evidence**
3.  **Reason**
4.  **Answer**

### Optimization Algorithm (RS-GRPO)
A two-stage optimization algorithm combining Supervised Fine-Tuning (SFT) with Reinforcement Learning (RL).

*   **RL Stage:** Assigns three fine-grained rewards to specific token scopes to solve the credit assignment problem in long reasoning chains:
    *   $R_{format}$: Ensures the output adheres to the required structure.
    *   $R_{perception}$: Evaluates the accuracy of the observed evidence.
    *   $R_{derivation}$: Evaluates the logic used to derive the final answer.

### Training Data
The model was trained on:
*   **60,000** SFT samples
*   **4,000** RL samples
*   *Source Data:* Derived from ChartQA and InfoVQA datasets.

---

## Results

Evaluated on five VQA benchmarks using Accuracy and F1 Score, EVisRAG achieved significant improvements over baselines.

### vs. Backbone (Qwen2.5-VL-7B)
*   **Accuracy Gain:** +19.51% (75.01% vs. 55.50%)
*   **F1 Score Gain:** +27.45% (77.86% vs. 50.41%)

### vs. Best Baseline (OpenVLThinker-7B)
*   **Accuracy Gain:** +9.74% (75.01% vs. 65.27%)
*   **F1 Score Gain:** +10.73% (77.86% vs. 67.13%)

### Notable Individual Benchmark Gains
*   **SlideVQA:** +29.67% accuracy improvement
*   **DocVQA:** +13.71% accuracy improvement

---

## Contributions

*   **Addressing the VRAG Gap:** Addresses the gap in current Visual Retrieval-Augmented Generation (VRAG) systems regarding their inability to reliably perceive and integrate evidence across multiple images.
*   **EVisRAG Framework:** Introduces EVisRAG, an end-to-end framework that grounds reasoning by explicitly structuring the process around observing evidence and aggregating it before deriving an answer.
*   **RS-GRPO Development:** Develops RS-GRPO, a new reinforcement learning policy optimization method that utilizes fine-grained, scope-specific rewards to enhance the training of VLMs for complex visual reasoning tasks.