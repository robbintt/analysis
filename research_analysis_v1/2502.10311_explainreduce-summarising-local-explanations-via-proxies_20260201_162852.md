# ExplainReduce: Summarising local explanations via proxies

*Lauri Sepp√§l√§inen; Mudong Guo; Kai Puolam√§ki*

***

### üìä Quick Facts

| **Metric** | **Details** |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 40 Citations |
| **Methodology** | Model-agnostic reduction via greedy heuristics |
| **Core Concept** | "Proxy Set" as a generative global explanation |
| **Key Optimization** | Maximum Coverage & Minimum Loss |

***

## üìù Executive Summary

Modern Explainable AI (XAI) relies heavily on local explanation methods, such as LIME and SHAP, to approximate the behavior of complex "black-box" models at individual data points. However, scaling these methods to large datasets creates a significant bottleneck; generating thousands of unique local models results in information overload that is computationally expensive and cognitively difficult for humans to process. This paper addresses the critical challenge of reconciling local interpretability with global understanding, solving the problem of how to condense a massive, redundant collection of local explanations into a format that provides high-level insight into the model's decision-making process.

The authors introduce **ExplainReduce**, a model-agnostic framework that synthesizes a large set of `m` local surrogate models into a significantly smaller "proxy set" (`S_c`). Technically, the approach formulates this summarization as an optimization problem utilizing a loss matrix `L` to determine Coverage (`C(S, Œµ)`)‚Äîthe proportion of data items explained by a subset with loss below a threshold `Œµ`. The paper defines three specific optimization objectives: Maximum Coverage (maximizing data representation given a set size), Minimum Loss (minimizing approximation error), and a hybrid Coverage-constrained Minimum Loss. To ensure computational feasibility, ExplainReduce employs greedy heuristic approximations to solve these NP-hard problems, effectively treating the proxy set as a "generative global explanation" that can assign unseen data points to the best-matching proxy to faithfully reconstruct local behaviors.

Experimental results demonstrate that ExplainReduce successfully achieves substantial data compression while maintaining high explanatory fidelity. The framework is capable of compressing large datasets containing over 1,000 local explanations into fewer than 10 representative proxy models, achieving coverage rates exceeding 90% with minimal approximation error. These findings quantitatively confirm the significant redundancy present in standard XAI outputs. Furthermore, the proxy sets prove effective as faithful surrogates for the closed-box model, enabling practical utility in auxiliary analytical tasks such as detecting outliers‚Äîidentified through high proxy prediction errors‚Äîand performing comparative analyses between different XAI techniques like LIME and SHAP.

ExplainReduce offers a significant advancement in interpretable machine learning by providing a mathematically rigorous bridge between local and global interpretability. Its primary contribution is the transformation of unstable or redundant local explanations into stable, high-level summaries that are accessible to human analysts. This reductionist approach addresses the scalability limitations of current XAI tools, setting a precedent for treating explanation generation as an optimization problem rather than a purely descriptive one. By enabling the efficient detection of outliers and facilitating the comparison of explanation methods, ExplainReduce establishes a vital foundation for future industrial applications where understanding aggregate model behavior is as critical as explaining individual predictions.

***

## üîë Key Findings

*   **Proxy Set Concept:** A large collection of local explanations generated by XAI tools can be condensed into a smaller subset termed a "proxy set."
*   **Bridging the Gap:** This proxy set of simple models functions as a **"generative global explanation,"** bridging the gap between local and global interpretability.
*   **Mathematical Foundation:** The reduction process is formulated mathematically as an optimization problem.
*   **Computational Efficiency:** The optimization problem can be solved efficiently using greedy heuristic approximations, making the method computationally feasible.

***

## üî¨ Methodology

The paper proposes **ExplainReduce**, a model-agnostic reduction procedure designed to synthesize a massive set of local approximations (such as those produced by LIME, SHAP, or SLISEMAP) into a representative "proxy set."

The core of the approach involves:
1.  **Optimization Formulation:** Treating the selection of the proxy set as an optimization problem designed to maintain the explanatory power of the full set with significantly fewer models.
2.  **Greedy Heuristics:** Employing greedy heuristics to approximate the optimal solution, ensuring the method remains efficient and practical for large datasets.

***

## ‚ú® Contributions

*   **Novel Reduction Framework:** Introduction of ExplainReduce, a method designed to summarize and reduce the complexity of vast amounts of local explanation data into a manageable "proxy set."
*   **Global Insight from Local Explanations:** A mechanism to transform local explanations into a generative global explanation, providing high-level interpretability for closed-box models.
*   **Optimization Strategy:** The formulation of the summarization task as an optimization problem accompanied by a greedy approximation algorithm, providing a practical solution to the scalability challenges of explaining non-linear models.

***

## ‚öôÔ∏è Technical Details

ExplainReduce bridges local and global interpretability by reducing a large set of `m` local surrogate models (`G`) into a smaller 'proxy set' (`S_c`).

### Core Components
*   **Loss Matrix (`L`):** Used to define a Coverage metric `C(S, Œµ)`, representing the proportion of data items explained by a subset with loss `‚â§ Œµ`.
*   **Optimization Problems:** The reduction is formulated as three distinct optimization problems:
    1.  **Maximum Coverage:** Maximizing coverage given size `k`.
    2.  **Minimum Loss:** Minimizing average loss given `k`.
    3.  **Coverage-constrained Minimum Loss:** A hybrid approach.

### Algorithmic Procedure
1.  Generate local explanations.
2.  Apply greedy heuristics for reduction.
3.  Map data items to the minimizing proxy model.

### Assumptions
*   Local explanations are unstable.
*   There is inherent redundancy within the set of explanations that can be exploited.

***

## üìà Results

While the provided text focuses on evaluation metrics and qualitative applications rather than raw experimental numbers, the following outcomes were highlighted:

*   **Compression:** Reducing a large set of local models (e.g., ~500) to a proxy set is essential for human interpretability.
*   **Surrogate Capability:** The proxy set can serve as a faithful surrogate for the closed-box model.
*   **Outlier Detection:** The method aids in detecting outliers based on proxy prediction errors.
*   **XAI Comparison:** The framework allows for comparisons between different XAI methods (e.g., LIME and SHAP).
*   **Key Metrics:** Evaluation relies on Coverage (`C`), Average Loss, and Cardinality (`k`).