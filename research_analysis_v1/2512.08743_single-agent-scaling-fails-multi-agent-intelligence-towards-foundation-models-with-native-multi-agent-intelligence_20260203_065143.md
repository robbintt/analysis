---
title: 'Single-Agent Scaling Fails Multi-Agent Intelligence: Towards Foundation Models
  with Native Multi-Agent Intelligence'
arxiv_id: '2512.08743'
source_url: https://arxiv.org/abs/2512.08743
generated_at: '2026-02-03T06:51:43'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Single-Agent Scaling Fails Multi-Agent Intelligence: Towards Foundation Models with Native Multi-Agent Intelligence

*Shuyue Hu; Haoyang Yan; Yiqun Zhang; Yang Chen; Dongzhan Zhou; Lei Bai*

---

> ðŸ“Œ **Quick Facts**
>
> *   **Quality Score:** 8/10
> *   **Models Analyzed:** 41 Large Language Models (Qwen & LLaMA families)
> *   **Parameter Range:** 0.5B to 235B
> *   **Benchmarks:** 7 distinct benchmarks (e.g., MATH-500, ToMBench)
> *   **References:** 40 citations

---

## Executive Summary

This research addresses the prevailing assumption in the AI community that scaling Foundation Models (FMs) in single-agent contexts will naturally result in robust multi-agent intelligence. As AI systems move toward complex, collaborative applications, relying on "spontaneous emergence"â€”where sophisticated multi-agent behaviors supposedly arise automatically from models trained solely on single-agent tasksâ€”presents a significant bottleneck. The problem is critical because current scaling laws, which predict performance improvements based on parameter count and training data for individual models, fail to account for the unique requirements of multi-agent environments, such as coordination, negotiation, and non-stationarity.

The core innovation of this paper is the establishment of a functional blueprint for **"Native Multi-Agent Intelligence,"** shifting the focus from external scaffolding to intrinsic model capabilities. Technically, the authors define this intelligence through four architectural pillars: Multi-Agent Understanding, Multi-Agent Planning, Efficient Communication, and Multi-Agent Adaptation. To validate this framework, the researchers conducted a large-scale empirical evaluation analyzing a cohort of 41 Large Language Models (LLMs), assessing their performance across 7 distinct benchmarks designed to test the correlation between single-agent proficiency and multi-agent intelligence.

The experiments provide empirical evidence disproving the hypothesis that single-agent scaling translates to multi-agent success. While single-agent tasks showed significant performance gains with scale, multi-agent tasks exhibited diminishing returns. For instance, scaling the Qwen model from approximately 0.5B to 8B parameters resulted in a surge in Single-Agent (SA) accuracy, yet Multi-Agent (MA) Understanding improved only marginally. Most notably, planning capabilities showed negligible improvement across model generations. The data confirms that high SA accuracy is not a reliable predictor of MA planning capability.

Ultimately, this work lays the groundwork for the next generation of AI systems capable of genuine collaboration and complex social reasoning by redirecting focus from brute-force parameter increases to the necessity of dataset construction and novel training paradigms designed natively for agent interaction.

---

## Key Findings

*   **Ineffectiveness of Single-Agent Scaling:** Scaling Foundation Models (FMs) in single-agent contexts does not automatically translate to robust multi-agent intelligence.
*   **Empirical Validation:** Testing 41 Large Language Models (LLMs) against 7 benchmarks shows current scaling laws fall short in multi-agent scenarios.
*   **Core Capability Definition:** Successful multi-agent intelligence relies on four pillars: understanding, planning, efficient communication, and adaptation.
*   **The 'Spontaneous Emergence' Gap:** Complex multi-agent behaviors do not merely emerge from models designed solely for single-agent tasks.

---

## Methodology

The study employs a **large-scale empirical evaluation strategy** to test the correlation between single-agent proficiency and multi-agent intelligence. The research process involved:

1.  **Cohort Analysis:** Researchers analyzed a cohort of 41 Large Language Models (LLMs) from the Qwen and LLaMA families.
2.  **Benchmarking:** Performance was assessed across 7 distinct and challenging benchmarks designed to test multi-agent capabilities.
3.  **Correlation Testing:** The study aimed to determine if improvements in single-agent metrics (like MATH or MMLU) predict success in multi-agent environments.

---

## Technical Details: Blueprint for Native Multi-Agent Intelligence

The paper proposes a functional blueprint shifting from external scaffolding to intrinsic capabilities. The architecture is defined by the following four pillars:

| Pillar | Technical Requirements |
| :--- | :--- |
| **1. Multi-Agent Understanding** | Requires **Theory of Mind** to reason about beliefs, desires, and social norms. |
| **2. Multi-Agent Planning** | Handles non-stationary behaviors via decentralized planning and negotiation strategies. |
| **3. Efficient Communication** | Utilizes structured protocols or learned tokens for high-bandwidth information exchange. |
| **4. Multi-Agent Adaptation** | Enables real-time strategy revision and continuous belief updating. |

**Evaluation Framework:**
*   Compared Single-Agent (SA) vs. Multi-Agent (MA) performance.
*   Deployed 41 models (0.5B to 235B parameters) via **vLLM**.

---

## Results

Experiments definitively disproved that single-agent capabilities translate to multi-agent intelligence via scaling.

### Quantitative Performance Gap

| Model Scale | Single-Agent (SA) Accuracy Change | Multi-Agent (MA) Understanding Change |
| :--- | :--- | :--- |
| **Qwen ~8B** | ðŸ“ˆ Surged (0.23 â†’ **0.64**) | ðŸ“‰ Modest (0.44 â†’ **0.55**) |
| **Qwen ~72B** | ðŸ“ˆ Improved (0.42 â†’ **0.71**) | ðŸ“‰ Minor (0.57 â†’ **0.67**) |

### Planning & Strategy Outcomes
*   **Planning Stagnation:** Planning tasks showed negligible improvements, stabilizing between **0.2 and 0.35** across generations.
*   **Decline:** Some instances showed slight decline in planning capabilities as model size increased.
*   **Predictability:** High SA accuracy (0.6â€“0.8) did not reliably predict MA planning capability, indicating **diminishing returns** for multi-agent tasks under current scaling laws.

---

## Contributions

*   **Conceptual Framework:** Establishes a framework for 'Native Multi-Agent Intelligence' by identifying four essential capabilities required for intrinsic agent interaction.
*   **Empirical Disproof:** Provides significant empirical evidence challenging the hypothesis that single-agent scaling is sufficient for multi-agent applications.
*   **Research Roadmap:** Outlines a strategic path forward for the community, proposing key research directions in:
    *   Dataset construction
    *   Evaluation methodologies
    *   Training paradigms
    *   Safety considerations

---

**Paper Quality:** 8/10 | **References:** 40 citations