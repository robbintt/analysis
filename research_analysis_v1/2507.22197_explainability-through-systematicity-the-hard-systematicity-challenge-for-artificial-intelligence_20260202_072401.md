# Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence

*Matthieu Queloz*

---

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 9/10 |
| **References** | 29 Citations |
| **Analysis Type** | Conceptual & Philosophical |
| **Primary Focus** | AI Rationality, Benchmarking, Connectionism |

---

## üìù Executive Summary

> Current research in artificial intelligence often prioritizes narrow "explainability," but this paper argues that true rationality requires a broader, more rigorous ideal: **systematicity**. The central problem is the perceived inadequacy of connectionist models (neural networks) to satisfy the "systematicity of thought," a challenge historically posed by Fodor and Pylyshyn against the viability of connectionism. The author contends that focusing solely on explanation is insufficient; AI systems must demonstrate a holistic capacity to integrate information‚Äîincluding compositionality, consistency, coherence, comprehensiveness, and parsimony‚Äîto function as truly rational agents. Resolving the tension between sub-symbolic neural architectures and the demand for structured, systematic reasoning is critical for advancing AI from mere pattern matching to robust, reliable intelligence.

> The paper‚Äôs key innovation is the introduction of the **Hard Systematicity Challenge (HSC)**, a new evaluative benchmark that applies five specific rationales for systematization to AI models. Technically, the author achieves this by distinguishing four separate senses of "systematicity of thought," demonstrating that Fodor‚Äôs specific syntactic version is actually less demanding than the requirements for general rational thought. The framework rejects the classical "Language of Thought" (Mentalese) hypothesis in favor of Gareth Evans‚Äôs "Generality Constraint," proposing that systematicity emerges from conceptual abilities acquired through enculturation rather than innate syntactic symbol manipulation. This creates a normative framework where systematicity is treated as a dynamic property regulated by specific underlying rationales, rather than a static architectural requirement.

> As this work is primarily a conceptual and philosophical analysis, it does not present original experimental data, quantitative metrics, or empirical results. Instead, the results are theoretical: the author successfully derives a taxonomy that categorizes systematicity into distinct senses and resolves the historical conflict between connectionism and systematicity. The paper contextualizes these findings by reviewing external empirical state-of-the-art research, such as Meta-Learning for Compositionality (MLC) and Neurocompositional Computing, illustrating how current models fit within the proposed taxonomy while highlighting the gap that remains before achieving the "hard" systematicity benchmark.

---

## üîë Key Findings

*   **Systematicity as an Ideal:** Systematicity is identified as a broader ideal than explainability, encompassing compositionality, consistency, coherence, comprehensiveness, and parsimonious principles.
*   **Resolving Historical Conflicts:** The perceived conflict between connectionism and the 'systematicity of thought' is resolved by distinguishing four senses of the phrase, revealing the Fodorian notion is less demanding than that required for rational thought.
*   **The Hard Systematicity Challenge:** The text defines a specific benchmark called the 'hard systematicity challenge' by applying five rationales for systematization to AI models.
*   **Dynamic Regulation:** The demand for systematicity in AI is dynamic and must be regulated by the underlying rationales for systematization rather than being static.

---

## üß™ Methodology

The paper employs a conceptual and philosophical analysis approach, utilizing three primary strategies:

1.  **Conceptual Distinction:** Developing a framework differentiating four senses of 'the systematicity of thought'.
2.  **Comparative Analysis:** Contrasting the Fodorian notion with historical conceptions.
3.  **Rationale Transfer:** Identifying five rationales for human systematization and applying them to Artificial Intelligence.

---

## ‚öôÔ∏è Technical Details

The conceptual framework presented reframes AI explainability through the lens of 'systematicity' via the following components:

*   **Proposed Dimensions:** Five dimensions of systematicity are proposed:
    *   Consistency
    *   Coherence
    *   Comprehensiveness
    *   Parsimonious principles
    *   Compositionality
*   **Theoretical Contrast:**
    *   **Classical Computational Theory of Mind (CCTM):** Utilizes rule-governed symbol manipulation.
    *   **Connectionist Theory (Neural Networks):** Uses sub-symbolic distributed nodes.
*   **The Benchmark:** Introduces the 'Hard Systematicity Challenge' as a dynamic benchmark requiring model outputs to be integrated into a systematic body of thought.
*   **Theoretical Alignment:**
    *   **Rejects:** The 'Language of Thought' (Mentalese).
    *   **Supports:** Gareth Evans's 'Generality Constraint'.
*   **Origin of Systematicity:** Argues that systematicity arises from conceptual abilities acquired through enculturation rather than innate syntactic symbols.

---

## üìà Contributions

*   **Redefinition:** Redefines systematicity from mere compositional sensitivity to a holistic integration including consistency, coherence, comprehensiveness, and parsimony.
*   **Taxonomy:** Provides a taxonomy of systematicity that categorizes four distinct senses of the systematicity of thought.
*   **New Benchmark:** Introduces the 'hard systematicity challenge' as a new evaluative benchmark for AI models, focusing on structural and rational coherence.
*   **Normative Framework:** Establishes a normative framework for regulation that offers a dynamic method for determining the necessary degree of systematicity in AI based on specific rationales.

---

## üìä Results

The provided text sections contain **no original experimental results, quantitative metrics, or empirical data**. The paper is a conceptual analysis but cites external empirical works to contextualize the state of the art.

*   **Contextual Citations:** Mentions *Meta-Learning for Compositionality (MLC)* and *Neurocompositional Computing*.
*   **Benchmark Status:** Specific datasets, evaluation protocols, and metrics for the 'hard systematicity challenge' benchmark are not included in the provided text.

---

**References:** 29 citations