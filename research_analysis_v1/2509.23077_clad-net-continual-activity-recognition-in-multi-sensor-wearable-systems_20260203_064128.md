---
title: 'CLAD-Net: Continual Activity Recognition in Multi-Sensor Wearable Systems'
arxiv_id: '2509.23077'
source_url: https://arxiv.org/abs/2509.23077
generated_at: '2026-02-03T06:41:28'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# CLAD-Net: Continual Activity Recognition in Multi-Sensor Wearable Systems

*Reza Rahimi Azghan; Gautham Krishna Gudur; Mohit Malu; Edison Thomaz; Giulia Pedrielli; Pavan Turaga; Hassan Ghasemzadeh*

---

> ### ðŸ“Š Quick Facts
> *   **Model Type:** Hybrid Framework (Transformer + CNN)
> *   **Primary Mechanism:** Knowledge Distillation & Cross-Attention
> *   **PAMAP2 Accuracy:** 91.36%
> *   **Forgetting Rate:** 8.78%
> *   **Label Efficiency:** Effective with only 10-20% labeled data
> *   **Quality Score:** 9/10

---

## Executive Summary

Human Activity Recognition (HAR) systems using multi-sensor wearables typically rely on the assumption that data distributions remain stationary. However, in real-world deployments, this assumption is frequently violated due to sensor drift, changes in user demographics, and environmental variations. This non-stationarity leads to "catastrophic forgetting," where models trained on new data streams lose the ability to recognize previously learned activities. This paper addresses the critical challenge of enabling HAR systems to learn continually from sequential data distributions without requiring the storage of extensive historical data, a necessity for long-term, autonomous wearable systems.

The authors propose CLAD-Net ("Continual Learning with Attention and Distillation"), a hybrid framework that decouples representation learning from task-specific classification. The architecture utilizes a dual-component design: a Self-Supised Transformer acting as "long-term memory" and a Supervised CNN serving as the activity classifier. The Transformer employs cross-attention mechanisms to model spatial-temporal dependencies and suppress noise across sensors, capturing robust global representations. To mitigate catastrophic forgetting, the CNN utilizes knowledge distillationâ€”minimizing the divergence between the model's current output and its previous knowledgeâ€”combined with subject-wise fine-tuning. Features from both modules are fused via concatenation, and the total loss function combines Cross-Entropy with L2 distillation loss.

CLAD-Net demonstrated superior performance compared to established continual learning baselines, including Experience Replay, Elastic Weight Consolidation (EWC), and Learning without Forgetting (LwF). On the PAMAP2 dataset, the framework achieved a final accuracy of 91.36% with a low forgetting rate of 8.78%. Performance on the DnSA dataset was even stronger, reaching 99.00% accuracy with a forgetting measure of only 1.58. Additionally, the model proved effective in semi-supervised scenarios, maintaining high performance with only 10-20% labeled data. Ablation studies confirmed that both the knowledge distillation component and the self-supervised Transformer are essential, with cross-attention mechanisms proving significantly more effective than self-attention for handling multi-sensor data.

This research significantly advances the state of the art in wearable computing by providing a robust solution for non-stationary data streams. By effectively handling distribution shifts without relying on memory-intensive rehearsal methods, CLAD-Net offers a scalable and privacy-preserving approach to continual learning. The architecture's ability to maintain high accuracy with minimal labeled data further reduces the operational burden of deploying HAR systems in resource-constrained environments. Consequently, this work establishes a new standard for adaptive, long-term activity recognition systems capable of operating reliably in dynamic real-world conditions.

---

## Key Findings

*   **High Accuracy & Low Forgetting:** CLAD-Net achieved a final accuracy of **91.36%** on the PAMAP2 dataset while maintaining a low forgetting rate of only **8.78%**.
*   **Superiority Over Baselines:** The framework outperformed established continual learning methods, including Experience Replay and Elastic Weight Consolidation (EWC).
*   **Semi-Supervised Success:** In semi-supervised settings, the model maintained strong performance with only **10-20% labeled data**.
*   **Module Necessity:** Ablation studies confirmed that specific modules within the proposed architectureâ€”specifically the self-supervised transformer and knowledge distillationâ€”are essential for the system's overall performance.

---

## Methodology

The research proposes **CLAD-Net** ("Continual Learning with Attention and Distillation"), a hybrid framework designed to handle non-stationary data distributions in wearable sensor systems. The methodology employs a dual-component architecture:

1.  **Self-Supised Transformer ("Long-term Memory"):** Utilizes cross-attention mechanisms across sensors to capture global patterns and suppress noise.
2.  **Supervised CNN ("Activity Classifier"):** Uses subject-wise fine-tuning and knowledge distillation to mitigate catastrophic forgetting during task-specific execution.

---

## Technical Details

### Architecture Components
*   **Transformer Module:** Functions as long-term memory. It employs **cross-attention** to model spatial-temporal dependencies and suppress noise across body-mounted sensors.
*   **CNN Module:** A task-specific execution component consisting of **3 layers with Layer Normalization**. It utilizes Knowledge Distillation to prevent catastrophic forgetting.
*   **Feature Fusion:** Features from both modules are fused via concatenation before the final classification.

### Loss Function
The total loss function combines Cross-Entropy loss and L2 distillation loss:
$$L_{total} = L_{CE} + \lambda \cdot L_{distill}$$

### Data Pipeline
*   **Preprocessing:** Normalization and window segmentation.
*   **Augmentation:** Includes Random Noise, Zero Masking, and Time Warping to improve model robustness.

---

## Contributions

*   **Robust CL Framework:** Introduction of a robust Continual Learning Framework for Human Activity Recognition (HAR) that addresses the violation of stationary data assumptions in multi-sensor environments.
*   **Novel Architecture Integration:** Unique integration of self-supervised transformers for representation learning and supervised CNNs for classification.
*   **Mitigation of Catastrophic Forgetting:** A comprehensive approach to handling distribution shifts without requiring extensive historical data storage.
*   **Label Efficiency:** Specifically demonstrated efficacy in label-scarce scenarios.

---

## Results

CLAD-Net was evaluated on **PAMAP2** and **DnSA** datasets, demonstrating significant improvements over baselines (LwF, EWC, Experience Replay, and ConvBoost).

| Dataset | Final Accuracy | Forgetting Measure | Comparison Performance |
| :--- | :--- | :--- | :--- |
| **PAMAP2** | **91.36%** | **8.78** | Highest accuracy, lowest forgetting vs. baselines. |
| **DnSA** | **99.00%** | **1.58** | Significantly outperformed ConvBoost in reducing forgetting. |

**Additional Results:**
*   **Semi-Supervised:** With 10-20% labeled data, CLAD-Net demonstrated lower forgetting than LwF.
*   **Ablation Studies:**
    *   Removing Knowledge Distillation or the Self-Supervised Transformer degraded performance.
    *   **Cross-attention** was confirmed to be superior to self-attention.

---

**References:** 40 citations