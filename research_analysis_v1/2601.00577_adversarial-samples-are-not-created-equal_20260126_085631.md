---
title: Adversarial Samples Are Not Created Equal
arxiv_id: '2601.00577'
source_url: https://arxiv.org/abs/2601.00577
generated_at: '2026-01-26T08:56:31'
quality_score: 7
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Adversarial Samples Are Not Created Equal

*Amy R. Wagoner, Jennifer Crawford, Stella Biderman, Amol Khanna, Fred Lu (Booz Allen)*

---

> ### **Quick Facts**
> | Metric | Value |
> | :--- | :--- |
> | **Quality Score** | 7/10 |
> | **Citations** | 40 |
> | **Dataset Studied** | ImageNet |
> | **Key Metric** | >90% Attack Success Rate (ASR) |
> | **Core Innovation** | Frequency Domain Analysis (DFT) |

## Executive Summary

The paper addresses the critical unpredictability of adversarial example transferability in black-box attack scenarios, seeking to understand the characteristics that distinguish highly transferable attacks from model-specific ones. The key innovation involves applying frequency domain analysis, specifically the Discrete Fourier Transform (DFT), to categorize adversarial perturbations.

Research reveals that attacks constrained to the low-frequency spectrum align more closely with natural image features and thus transfer more effectively. Empirical results on the ImageNet dataset demonstrate that low-frequency perturbations achieve an Attack Success Rate (ASR) of over 90% across diverse black-box architectures, while also rendering common input transformation defenses ineffective. This work significantly impacted the field by shifting the analytical focus to the frequency domain, establishing transferability as a spectral property, and highlighting the need for defenses that account for the spectral composition of adversarial threats.

## Key Findings

*   **Frequency Dependency:** Adversarial perturbations categorized in the low-frequency spectrum are significantly more transferable than those in mid-to-high frequencies.
*   **Natural Feature Alignment:** Low-frequency attacks align more closely with natural image features, making them harder for black-box models to distinguish from legitimate data.
*   **High Attack Success Rate:** Low-frequency perturbations achieved an ASR exceeding **90%** on the ImageNet dataset across various architectures.
*   **Defense Evasion:** The study demonstrates that current input transformation defenses are largely ineffective against these low-frequency adversarial samples.
*   **Paradigm Shift:** The work establishes adversarial transferability as a spectral property rather than just a spatial or gradient-based phenomenon.

## Technical Details

### Methodology & Analysis
*   **Core Technique:** Application of **Discrete Fourier Transform (DFT)** to analyze and categorize adversarial perturbations.
*   **Domain Analysis:** Shift of focus from the spatial domain to the **frequency domain** to evaluate perturbation characteristics.
*   **Spectral Categorization:** Constrained attacks to specific frequency bands (low, mid, high) to isolate the impact of spectral composition on transferability.

### Empirical Results
*   **Benchmark Dataset:** ImageNet.
*   **Transferability:** Demonstrated robust transferability across diverse black-box architectures specifically for low-frequency constraints.
*   **Defense Resistance:** Validated the inefficacy of common input transformation defenses against the proposed attack vector.

## Contributions

*   Identified the spectral composition (low-frequency constraint) as the defining characteristic for highly transferable adversarial examples.
*   Provided empirical evidence overriding previous assumptions regarding the nature of transferability in black-box attacks.
*   Highlighted a critical vulnerability in current defense mechanisms, suggesting future defenses must account for spectral features to be effective.