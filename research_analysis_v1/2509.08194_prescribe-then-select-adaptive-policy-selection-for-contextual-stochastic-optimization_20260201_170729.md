# Prescribe-then-Select: Adaptive Policy Selection for Contextual Stochastic Optimization

*Caio de Prospero Iglesias; Kimberly Villalobos Carballo; Dimitris Bertsimas*

---

> ### **Quick Facts**
> * **Framework:** Prescribe-then-Select (PS)
> * **Core Method:** Ensembles of Optimal Policy Trees (OPT)
> * **Validation Domains:** Single-stage Newsvendor, Two-stage Shipment Planning
> * **Performance Gain:** Up to **15%** cost reduction (Shipment Planning)
> * **Quality Score:** 9/10
> * **Citations:** 19

---

## Executive Summary

In Contextual Stochastic Optimization (CSO), practitioners typically rely on a single static policy—such as Sample Average Approximation (SAA) or Predictive-Optimization—to make decisions across the entire covariate space. However, this paper addresses a critical limitation: no single policy exhibits uniform dominance across all scenarios.

Performance often varies significantly depending on the region of the covariate space, creating a **heterogeneity problem** where applying one rigid policy leads to suboptimal results. This variation means that a policy performing well in one context may fail in another, necessitating a more adaptive approach to decision-making.

To overcome this, the authors propose the **"Prescribe-then-Select" (PS) framework**, a modular two-phase architecture designed to combine multiple candidate policies optimally while strictly adhering to feasibility constraints.

*   **The Prescribe Phase:** Constructs a library of feasible policies derived from various paradigms (e.g., SAA, Point-Prediction).
*   **The Select Phase:** Utilizes an ensemble of Optimal Policy Trees (OPT) as a meta-policy. Technically, this phase partitions the covariate space into disjoint, axis-aligned regions and assigns the optimal policy from the library to each region. Unlike standard ensemble methods, the OPT meta-policy is trained via cross-validation to tune the tree depth and splits, minimizing expected cost through coordinate descent without averaging infeasible decisions.

The efficacy of the PS framework was empirically validated on a single-stage newsvendor problem and a two-stage shipment planning problem, demonstrating quantifiable superiority over baselines. In heterogeneous regimes where performance varies across the covariate space, the framework consistently outperformed the best single static policy, achieving cost reductions of approximately **12.5%** in the newsvendor experiments and up to **15%** in the shipment planning scenarios. Conversely, in homogeneous regimes where one policy dominates, the PS framework effectively converged to selecting that single dominant policy, resulting in performance parity and successfully avoiding overfitting.

This research significantly advances the field of stochastic optimization by bridging the gap between diverse modeling methodologies and proving that dynamic switching is both viable and beneficial. By guaranteeing that all candidate policies in the library satisfy hard operational constraints, the PS framework ensures that the observed percentage improvements are actualizable in real-world logistics and inventory management.

---

## Key Findings

*   **Performance Heterogeneity:** In Contextual Stochastic Optimization (CSO), multiple candidate policies rarely exhibit uniform dominance. Performance varies significantly across different regions of the covariate space.
*   **Superiority of PS Framework:** The Prescribe-then-Select (PS) framework consistently outperforms the best single static policy, particularly in heterogeneous regimes.
*   **Adaptive Convergence:** In scenarios where the covariate space lacks heterogeneity (homogeneous regimes), the PS framework effectively converges to selecting the single dominant policy, avoiding overfitting.
*   **Empirical Validation:** The efficacy of the approach was validated on the single-stage newsvendor problem and the two-stage shipment planning problem.

---

## Methodology

The authors propose a modular, two-phase framework titled **Prescribe-then-Select (PS)**:

1.  **Prescribe Phase:**
    *   Involves constructing a library of candidate policies.
    *   Ensures all policies in the library satisfy hard feasibility constraints.

2.  **Select Phase:**
    *   Involves learning a data-driven meta-policy.
    *   Dynamically selects the optimal policy from the library based on observed covariates.
    *   Implemented using ensembles of Optimal Policy Trees trained via cross-validation.

---

## Technical Details

The paper proposes the Prescribe-then-Select (PS) framework for Contextual Stochastic Optimization (CSO) to address performance heterogeneity. The architecture consists of two distinct stages:

*   **Stage 1 (Prescribe):**
    *   Constructs a library of candidate policies ($\Pi_M$).
    *   Includes Sample Average Approximation (SAA), Point-Prediction Policies (PPt-kNN, PPt-RF), and Predictive-Prescriptive Policies.

*   **Stage 2 (Select):**
    *   Uses Optimal Policy Trees (OPT) as a meta-policy.
    *   Partitions the covariate space into disjoint regions using depth-constrained, axis-aligned splits.
    *   Assigns the optimal policy to each region.
    *   The optimization minimizes expected cost via coordinate descent.

**Theoretical Guarantees:**
*   **Lemma 1:** Guarantees the framework performs at least as well as the best single static policy.
*   Specific improvements of $\Delta \cdot \Pr(X \in R)$ are achievable in specific regions.

---

## Contributions

*   **New Paradigm:** Introduction of the 'Prescribe-then-Select' paradigm, which resolves the limitation of single policy selection by adaptively switching between policies based on contextual information.
*   **Methodological Advance:** A methodological contribution in using ensembles of Optimal Policy Trees as a meta-selector, allowing for the integration of diverse modeling paradigms while strictly adhering to feasibility constraints.
*   **Validation:** Providing evidence that a data-driven selection strategy can theoretically and practically match or exceed the performance of individual specialized policies across varying degrees of data heterogeneity.

---

## Results

The experiments were conducted on a **Single-stage Newsvendor Problem** and a **Two-stage Shipment Planning Problem**.

*   **Heterogeneous Regimes:** The PS framework consistently outperformed the best single static policy. It successfully adapted to region-specific optimal policies. Quantitatively, this resulted in cost reductions of approx. 12.5% (Newsvendor) and up to 15% (Shipment Planning).
*   **Homogeneous Regimes:** The PS framework effectively converged to selecting the single dominant policy. This resulted in performance parity with the best baseline, successfully avoiding overfitting.