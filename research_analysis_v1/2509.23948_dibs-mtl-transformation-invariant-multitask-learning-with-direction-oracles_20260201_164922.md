# DiBS-MTL: Transformation-Invariant Multitask Learning with Direction Oracles

*Surya Murthy; Kushagra Gupta; Mustafa O. Karabag; David Fridovich-Keil; Ufuk Topcu*

***

### ðŸ“Š Quick Facts

| Metric | Details |
| :--- | :--- |
| **Focus** | Transformation-Invariant Multitask Learning (MTL) |
| **Method** | Direction-based Bargaining Solution (DiBS) |
| **Quality Score** | 6/10 |
| **References** | 29 Citations |
| **Key Innovation** | Invariance to nonaffine task loss transformations |

***

> **EXECUTIVE SUMMARY**
>
> This paper addresses the critical instability in Multi-task Learning (MTL) known as "task domination," where disparate loss scales overwhelm the optimization process and invalidate standard heuristic balancing techniques. To mitigate this, the authors introduce **DiBS-MTL**, a novel framework derived from cooperative game theory that utilizes "direction oracles" and normalized task gradients to achieve scaling invariance and robust optimization.
>
> Empirical evaluations on benchmarks such as **NYU-v2** and **Meta-World MT10** demonstrate that DiBS-MTL offers superior stability compared to state-of-the-art baselines, effectively avoiding the catastrophic performance drops caused by skewed loss transformations. The work makes a significant theoretical impact by bridging cooperative game theory and nonconvex deep learning, providing the first rigorous proof of convergence to a Pareto stationary point and establishing a viable path toward eliminating manual loss balancing in multi-task systems.

***

## Key Findings

*   **Robustness to Loss Scaling:** DiBS-MTL is invariant to monotonic nonaffine task loss transformations, effectively preventing tasks with arbitrarily scaled losses from dominating the training process.
*   **Theoretical Convergence:** The authors provide rigorous theoretical backing, proving that a subsequence of DiBS iterates converges to a **Pareto stationary point**, even within complex nonconvex settings.
*   **Superior Empirical Robustness:** The method achieves competitive performance on standard benchmarks while maintaining robustness to nonaffine transformations that typically cause severe degradation in existing MTL methods.

***

## Methodology

The research pivots away from standard heuristic weighted averaging, utilizing the **Direction-based Bargaining Solution (DiBS)** derived from cooperative bargaining theory.

*   **DiBS-MTL Framework:** The authors propose a computationally efficient adaptation of DiBS specifically for the MTL setting.
*   **Direction Oracles:** The approach relies on direction oracles to locate Pareto stationary solutions, ensuring the optimization process is driven by the direction of gradients rather than their magnitude.
*   **Nonconvex Optimization:** The method is explicitly designed to address nonconvex optimization scenarios, functioning effectively without sensitivity to loss scaling.

***

## Contributions

The paper makes three primary contributions to the field:

1.  **Bridging Theory and Practice for DiBS:** Provides the first theoretical analysis of DiBS behavior in nonconvex MTL settings, formally proving convergence to Pareto stationary points.
2.  **Solving the Task Domination Problem:** Introduces a transformation-invariant solution to the persistent challenge of task domination caused by disparate loss scaling.
3.  **Algorithm Proposal:** Presents DiBS-MTL, a novel and computationally efficient algorithm that applies cooperative bargaining principles to multi-task learning.

***

## Technical Details

The approach formulates Multitask Learning (MTL) as a centralized cooperative bargaining game. The technical specifications are as follows:

*   **Core Mechanism:**
    *   Utilizes the **Direction-based Bargaining Solution (DiBS)**.
    *   Invariant to monotonic, non-affine transformations of task losses.
    *   Relies on normalized gradients and local minima locations to ensure invariance.

*   **Objective:**
    *   The primary goal is to find a Pareto stationary point.
    *   Mathematically defined by the weighted sum of gradients equaling zero.

*   **Algorithm Implementation (DiBS-MTL):**
    *   Uses a single-step approximation for practical efficiency.
    *   **Update Rule:** The update is calculated as the negative sum of normalized task gradients, scaled by an epsilon ($\epsilon$) budget parameter.

*   **Theoretical Guarantees:**
    *   **Theorem 1:** Guarantees asymptotic convergence to a Pareto stationary point.
    *   Validated under Robbins-Monro conditions in nonconvex settings.
    *   Does not require the assumption of linearly independent gradients.

***

## Results

The paper evaluates the proposed method through extensive experimentation, though specific numerical results are not detailed in the provided text.

*   **Experimental Setup:**
    *   **Datasets:** NYU-v2, Meta-World MT10, standard benchmarks, and synthetic examples.
    *   **Evaluation Criteria:** Convergence rates, performance against state-of-the-art methods, and robustness to non-affine task loss transformations.

*   **Primary Outcome:**
    *   The key metric is **robustness**. The experiments successfully demonstrate that DiBS-MTL maintains performance under skewed or transformed losses, whereas existing methods experience significant degradation.