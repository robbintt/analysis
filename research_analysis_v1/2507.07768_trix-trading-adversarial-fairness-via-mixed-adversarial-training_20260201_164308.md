# TRIX: Trading Adversarial Fairness via Mixed Adversarial Training
*Tejaswini Medi; Steffen Jung; Margret Keuper*

---

> **Executive Summary**
>
> This research addresses the critical issue of **"adversarial unfairness"** inherent in standard Adversarial Training (AT). While AT is designed to improve model robustness against attacks, the authors demonstrate that applying uniform attack strength across all classes leads to significant robustness disparities. Specifically, "**strong**" classes (those with easily distinguishable features) become highly robust as their non-robust features are quickly suppressed, while "**weak**" classes remain susceptible to adversarial examples. This creates vulnerable sub-populations within the model, posing a significant risk for deploying these systems in safety-critical or equitable environments.
>
> The paper introduces **TRIX** (Trading Adversarial Fairness via Mixed Adversarial Training), a feature-aware framework built upon the TRADES paradigm. The key technical innovation is a **class-based feature-conditional policy**, which adaptively switches adversarial modes based on class strength rather than applying a uniform strategy:
> *   **Weak Classes:** Utilizes stronger **untargeted** adversaries (maximizing KL divergence) to enforce focused robustness.
> *   **Strong Classes:** Employs weaker **targeted** adversaries (minimizing Cross-Entropy loss) to promote feature diversity and prevent over-suppression.
>
> Evaluation on **CIFAR-10** using strong attacks such as PGD and AutoAttack ($\epsilon=8/255$) validates the framework's effectiveness. Compared to the TRADES baseline, TRIX:
> *   Reduced the Standard Deviation of class-wise robust accuracy from $\approx 6.6\%$ to $3.3\%$.
> *   Dramatically improved worst-case performance, raising Minimum Robust Accuracy from $44.8\%$ to $50.3\%$.
> *   Crucially, this boost in the performance floor for vulnerable classes (e.g., cats, birds) was achieved **without compromising** the model's overall Average Robust Accuracy.
>
> This work establishes a new precedent for equitable machine learning, ensuring that robustness is distributed fairly across all classes rather than concentrating on the majority or easily distinguishable features.

---

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 40 Citations |
| **Dataset** | CIFAR-10 |
| **Attacks Tested** | PGD, AutoAttack |
| **Base Paradigm** | TRADES |

---

## üîë Key Findings

*   **Adversarial Unfairness:** Standard Adversarial Training (AT) creates robustness disparities where **strong classes** become robust while **weak classes** remain susceptible.
*   **Class-Specific Needs:** Strong classes do not require strong adversaries during training (non-robust features are suppressed quickly), whereas weak classes explicitly require stronger adversaries to reduce vulnerabilities.
*   **Performance Improvement:** TRIX significantly improves worst-case class accuracy on both clean and adversarial data, reducing inter-class robustness disparities without compromising overall model accuracy.
*   **Robustness Validation:** The framework demonstrates effectiveness against strong adversarial attacks, specifically **PGD** (Projected Gradient Descent) and **AutoAttack**.

---

## üõ†Ô∏è Methodology

**TRIX (Trading Adversarial Fairness via Mixed Adversarial Training)** is a feature-aware adversarial training framework designed to address class-wise vulnerability disparities. Its methodology relies on two core components:

1.  **Adaptive Adversary Assignment:**
    *   **Strong Classes:** Assigned *weaker targeted adversaries* to promote feature diversity.
    *   **Weak Classes:** Assigned *stronger untargeted adversaries* to enhance focused robustness.
2.  **Dynamic Optimization:**
    *   Incorporates **per-class loss weighting** and **perturbation strength adjustments**.
    *   These adjustments emphasize weak classes during the optimization process to balance the model's defense.

---

## ‚öôÔ∏è Technical Details

The paper proposes TRIX, a framework built on the **TRADES paradigm** that utilizes a **Mixed Adversarial Objective**.

*   **Core Mechanism:** It implements a **class-based feature-conditional policy $\pi(y)$** to dynamically switch between adversarial modes based on the class's strength.
*   **Untargeted Mode (For Weak Classes):**
    *   **Objective:** Maximizes KL divergence.
    *   **Purpose:** To enforce robustness on vulnerable classes.
*   **Targeted Mode (For Strong Classes):**
    *   **Objective:** Minimizes Cross-Entropy loss.
    *   **Purpose:** To refine decision boundaries and maintain feature diversity.

---

## ‚úÖ Contributions

*   **Problem Formalization:** Highlighted and defined the issue of **'adversarial unfairness'** inherent in uniform AT objectives, linking it to class-wise feature distinguishability.
*   **Novel Training Framework:** Introduced **TRIX**, which innovates by mixing targeted and untargeted attacks adaptively according to class strength rather than applying a uniform attack strategy.
*   **Validation of Fairness-Robustness Trade-off:** Provided empirical evidence that prioritizing weak classes through adaptive training preserves overall accuracy while significantly boosting worst-case performance.

---

## üìà Results

Evaluated on **CIFAR-10** using PGD and AutoAttack ($\epsilon=8/255$), TRIX demonstrated superior performance compared to the TRADES baseline:

*   **Reduced Disparity:** Successfully reduced disparity metrics (Standard Deviation, Min-Max Gap, Variance).
*   **Improved Worst-Case Performance:** Significantly improved **Minimum Accuracy** on both clean and adversarial data.
*   **Performance Floor:** Raised the performance floor for historically vulnerable classes (e.g., **cat**, **bird**) without compromising the overall **Average Accuracy**.