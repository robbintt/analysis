---
title: On the effectiveness of Large Language Models in the mechanical design domain
arxiv_id: '2505.01559'
source_url: https://arxiv.org/abs/2505.01559
generated_at: '2026-02-06T02:45:02'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# On the effectiveness of Large Language Models in the mechanical design domain

*Daniele Grandi; Fabian Riquelme*

---

### ðŸ“Š Quick Facts

| Metric | Value |
| :--- | :--- |
| **Binary Classification Accuracy** | 0.62 (62%) |
| **Zero-Shot Top-1 Accuracy** | 0.386 (38.6%) |
| **Dataset** | ABC Dataset (1M CAD models) |
| **Core Architecture** | BERT (Transformer-based) |
| **Quality Score** | 9/10 |
| **References** | 40 Citations |

---

## Executive Summary

> This research addresses the critical gap in evaluating Large Language Models (LLMs) within highly technical, specialized domains, specifically mechanical design. While general-purpose LLMs have demonstrated success in natural language processing, their ability to interpret the precise semantic relationships and technical jargon inherent to mechanical engineering remains unproven. This matters because the integration of AI into CAD and engineering workflows depends heavily on a model's capacity to understand domain-specific language without misinterpreting design intent. The study seeks to determine if existing architectures can effectively handle the linguistic nuances of mechanical design or if they suffer from significant limitations and failure modes when applied to this specialized context.

The study introduces a novel evaluation framework leveraging the ABC Dataset, shifting focus from 3D geometric analysis to the utilization of semantic metadataâ€”specifically designer-assigned assembly and part names. The researchers developed two unsupervised tasks: a binary sentence-pair classification and a zero-shot classification task to assess model comprehension. Technically, the innovation lies in the architectural modification of a standard Transformer-based model (BERT) by integrating multi-head attention layers and a custom Dense output layer. To combat the common issue of catastrophic forgetting and over-fitting on specialized data, the authors implemented a rigorous fine-tuning strategy that optimizes hyperparameters, including learning rates (1e-2 to 1e-4), dropout values, and sequence lengths.

The fine-tuned model achieved a binary sentence-pair classification accuracy of 0.62, a notable improvement made possible by the specific regularization techniques employed to mitigate over-fitting. In the zero-shot classification task, the model utilizing a contrastively pre-trained text encoder achieved a top-1 accuracy of 0.386, significantly outperforming established baseline models. Beyond performance metrics, the study quantitatively identified specific failure modes that arise when general-purpose LLMs attempt to process mechanical engineering language. The results confirm that while baseline models are insufficient, the addition of multi-head attention layers and precise hyperparameter tuning are necessary to achieve viable performance in this domain.

This research provides the mechanical engineering community with a crucial benchmark for assessing LLM effectiveness, validating the utility of semantic metadata as a training resource for AI models. The findings highlight that standard off-the-shelf models cannot simply be dropped into engineering workflows; instead, effective performance requires deliberate architectural changes and optimization to handle technical vocabulary. By outlining specific failure modes and successful regularization strategies, the paper offers a roadmap for future research in developing robust, domain-specific AI tools, ultimately facilitating the more reliable automation of design tasks and semantic data processing in mechanical engineering.

---

## Key Findings

*   **High Classification Accuracy:** A fine-tuned model achieved a **0.62 accuracy** on a binary sentence-pair classification task by employing specific regularization techniques to combat over-fitting.
*   **Superior Zero-Shot Performance:** In the zero-shot classification task, the model significantly outperformed established baselines, achieving a top-1 classification accuracy of **0.386**.
*   **Identified Failure Modes:** The study identified specific failure modes that emerge when Large Language Models (LLMs) attempt to learn and process language within the mechanical engineering domain.
*   **Necessity of Architectural Modifications:** Effective performance in this domain requires architectural modifications, specifically the addition of multi-head attention layers alongside adjustments to learning rates, dropout values, and sequence length.

---

## Methodology

The study focused on evaluating semantic data rather than geometric data.

*   **Data Source:** Utilized semantic data from the **ABC dataset**, specifically focusing on designer-assigned assembly names and individual semantic part names.
*   **Preprocessing:** The data underwent significant pre-processing to prepare it for evaluation.
*   **Task Development:** Two unsupervised tasks were developed to evaluate model architectures on domain-specific data:
    1.  A binary sentence-pair classification task.
    2.  A zero-shot classification task.
*   **Fine-Tuning Strategy:** To address over-fitting, the research implemented a strategy involving:
    *   Modification of hyperparameters (learning rates, dropout values, sequence length).
    *   Augmentation of the model architecture with a multi-head attention layer.

---

## Technical Details

### Dataset & Processing
*   **Source:** ABC Dataset (1 million CAD models from OnShape).
*   **Focus:** Semantic metadata (part and assembly names) rather than 3D geometry.
*   **Pipeline:** Extraction and cleaning of assembly/part names.
*   **Final Volume:** 61,725 assemblies (48,644 unique).
*   **Formatting:** Data formatted into sentence pairs using a specific template.

### Model Architecture
*   **Base:** Transformer-based (BERT).
*   **Modifications:** Custom output layer adding **multi-head attention layers** and a Dense layer for binary classification.
*   **Zero-Shot Flow:** Employs a contrastively pre-trained text encoder.

### Optimization & Hyperparameters
*   **Goal:** Address catastrophic forgetting and over-fitting.
*   **Key Variables:**
    *   Learning Rate: 1e-2, 1e-3, 1e-4
    *   Dropout values
    *   Sequence length

---

## Contributions

*   **Domain-Specific Benchmarking:** Provided an evaluation of LLM effectiveness specifically within the mechanical design domain.
*   **Utilization of Semantic Metadata:** Demonstrated how to leverage semantic engineering data (part and assembly names) to train and assess AI models.
*   **Optimization Insights:** Contributed a set of effective techniques (parameter tuning and architectural changes) for fine-tuning models on specialized technical data to prevent over-fitting.
*   **Failure Analysis:** Shed light on the limitations and specific failure modes of LLMs when interpreting technical language in mechanical engineering contexts.

---

## Results

*   **Binary Sentence-Pair Classification:** Achieved an accuracy of **0.62 (62%)**, relying on regularization to mitigate over-fitting.
*   **Zero-Shot Classification:** Achieved a Top-1 accuracy of **0.386 (38.6%)**, significantly outperforming established baseline models.
*   **Model Behavior:** Identified failure modes of general-purpose LLMs on mechanical engineering language.
*   **Architectural Requirements:** Confirmed that architectural modifications, specifically the addition of multi-head attention layers, are necessary for effective performance.

---

*Report analysis based on 40 citations.*