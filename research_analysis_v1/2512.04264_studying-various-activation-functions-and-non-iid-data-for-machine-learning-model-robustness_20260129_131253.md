# Studying Various Activation Functions and Non-IID Data for Machine Learning Model Robustness

*Long Dang; Thushari Hapuarachchi; Kaiqi Xiong; Jing Lin*

**Quality Score:** 8/10

---

### üìä Quick Facts

| Metric | Value |
| :--- | :--- |
| **Primary Focus** | Federated Learning & Adversarial Robustness (FGSM) |
| **Optimal Activation Function** | ReLU (out of 10 tested) |
| **Peak Robust Accuracy (Centralized)** | 67.96% (CIFAR-10) |
| **Effective Data Sharing Rate** | 40% |
| **Baseline Outperformed** | CalFAT Algorithm |
| **Citations** | 40 |

---

## üìë Executive Summary

> This research addresses the critical challenge of maintaining machine learning model robustness against adversarial attacks, specifically Fast Gradient Sign Method (FGSM) attacks, while operating within the constraints of Federated Learning (FL). While adversarial training is an established method for improving model resilience in centralized settings, its effectiveness deteriorates significantly in decentralized environments where data is heterogeneous (Non-IID).
>
> The paper highlights a crucial gap in understanding how fundamental architectural choices, such as the selection of activation functions, impact robustness, and seeks to solve the instability introduced by Non-IID data distributions in federated adversarial training. The authors introduce a centralized adversarial training framework that synthesizes multiple optimization techniques, including architectural modifications, soft labeling, simplified data augmentation, and dynamic learning rate adjustments.
>
> Technically, the study conducts a comprehensive empirical evaluation of ten distinct activation functions to isolate their impact on model defense. Furthermore, the researchers extend this framework to a federated setting to diagnose the specific vulnerabilities caused by data heterogeneity. To rectify the performance degradation associated with Non-IID data, the paper proposes and validates a data sharing mechanism designed to harmonize local data distributions without compromising the core principles of privacy-preserving learning.
>
> Experimental results on CIFAR-10 demonstrate that ReLU provides the highest adversarial robustness among the ten evaluated activation functions. In centralized tests, the proposed framework achieved a natural accuracy of 77.08% and a robust accuracy of 67.96%, outperforming the CalFAT baseline. However, extending the training to a federated environment resulted in a pronounced decline in robust accuracy, particularly under Non-IID conditions. The proposed data sharing mechanism effectively counteracted this drop; specifically, a 40% data sharing rate recovered robust accuracy to 54.79%, significantly closing the gap between centralized and federated performance.
>
> The significance of this work lies in its dual contribution to both architectural optimization and federated learning security. By validating ReLU as the optimal activation function for robustness, the study provides a clear directive for model design in security-critical applications. Moreover, the paper exposes the fragility of standard adversarial training in Non-IID federated settings and offers a practical, quantifiable mitigation strategy through data sharing.

---

## üîç Key Findings

*   **Activation Function Superiority:** Among ten tested functions, **ReLU** generally yielded the best performance for improving ML model robustness.
*   **Federated Learning Vulnerability:** Extending adversarial training to federated learning results in a significant decrease in robust accuracy. This degradation is exacerbated when working with Non-IID data.
*   **Data Sharing Efficacy:** A data sharing mechanism effectively mitigates the performance drop caused by Non-IID data. A **40% sharing rate** was identified as optimal, achieving **54.79% robust accuracy**.
*   **Benchmark Success:** The proposed centralized approach achieved **77.08% natural accuracy** and **67.96% robust accuracy** on CIFAR-10 against FGSM attacks, successfully outperforming the CalFAT algorithm.

---

## üõ†Ô∏è Methodology

The researchers developed a robust testing environment based on the following protocols:

1.  **Framework Proposal:** introduced a centralized adversarial training framework that integrates:
    *   Model architecture changes
    *   Soft labeling
    *   Simplified data augmentation
    *   Varying learning rates
2.  **Comparative Analysis:** Conducted experiments testing ten different activation functions to assess their individual impact on robustness.
3.  **Federated Adaptation:** Adapted the method for federated learning environments to test performance under both IID (Independent and Identically Distributed) and Non-IID data distributions.
4.  **Mitigation Strategy:** Implemented and tested a data sharing strategy specifically designed to address the challenges posed by Non-IID data.

---

## ‚öôÔ∏è Technical Details

*   **Core Domain:** Federated Learning (FL) integrated with Adversarial Training.
*   **Threat Model:** Defensive measures focused on **FGSM (Fast Gradient Sign Method)** attacks.
*   **Problem Solved:** Instability and performance degradation caused by **Non-IID data distributions**.
*   **Solution Mechanism:** **Data Sharing Mechanism** to harmonize local data distributions.
*   **Optimization:** Evaluated ten activation functions; **ReLU** was identified as the optimal choice for robustness.
*   **Benchmark:** Performance evaluated against the **CalFAT** algorithm.

---

## ‚ú® Contributions

*   **Enhanced Protocol:** Development of an improved adversarial training protocol that combines multiple optimization techniques (architecture, labeling, augmentation).
*   **Comprehensive Evaluation:** A thorough assessment of ten distinct activation functions specifically regarding their resistance to adversarial examples.
*   **Federated Vulnerability Analysis:** Investigation into the specific weaknesses of adversarial training within federated learning, explicitly highlighting the negative impact of Non-IID data.
*   **Mitigation Validation:** Introduction and empirical validation of a data sharing mechanism as a practical solution to restore robust accuracy in Non-IID federated learning settings.

---

## üìà Results

*   **Activation Functions:** ReLU yielded the best performance for robustness among the tested activation functions.
*   **Federated vs. Centralized:** Extending adversarial training to the federated setting resulted in a significant decrease in robust accuracy, particularly with Non-IID data.
*   **Data Sharing Impact:** A **40% data sharing rate** effectively mitigated this performance drop, achieving **54.79% robust accuracy**.
*   **CIFAR-10 Performance:** In a centralized setting against FGSM on CIFAR-10, the model achieved:
    *   **77.08%** Natural Accuracy
    *   **67.96%** Robust Accuracy
    *   *Result:* Outperformed the CalFAT baseline.

---

**References:** 40 citations