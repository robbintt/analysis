# Efficient Multi-Task Learning via Generalist Recommender

*Luyang Wang; Cangcheng Tang; Chongyang Zhang; Jun Ruan; Kai Huang; Jason Dai*

---

### üìä Quick Facts

| **Metric** | **Detail** |
| :--- | :--- |
| **CTR Lift** | +0.93% (Online A/B) |
| **CVR Lift** | +2.05% (Online A/B) |
| **Architecture** | Sparse Mixture-of-Experts (MoE) |
| **Quality Score** | 8/10 |
| **References** | 26 Citations |
| **Application** | Major Telecom Platform |

---

## üìù Executive Summary

Multi-Task Learning (MTL) in industrial recommendation systems faces a critical scalability bottleneck: performance typically degrades as the number of tasks increases due to negative transfer and parameter conflicts. Traditional approaches force a trade-off between accuracy and computational efficiency, compelling practitioners to maintain siloed single-task models. This fragmentation increases operational complexity and prevents the leveraging of shared data representations, leading to persistent data sparsity issues for difficult tasks like Conversion Rate (CVR) prediction. The industry requires a unified architecture that can scale capabilities across multiple tasks without compromising inference speed or prediction accuracy.

The authors propose **GRec (Generalist Recommender)**, a novel MTL architecture inspired by Large Language Models (LLMs) that utilizes a Sparse Mixture-of-Experts (MoE) framework. The system employs a hybrid input processor combining NLP heads for text, Parallel Transformers with Multi-Query Single-Key-Value (MQSKV) Attention to reduce computational complexity, and a Wide and Deep structure for memorization. The core innovation is the **"Task-Sentence MoE Layer,"** which introduces a specialized routing mechanism. This mechanism constructs composite "sentences" by grouping main tasks (e.g., CTR, CVR) with auxiliary flow tasks and calculates gating functions based on averaged task ID embeddings. This design dynamically allocates experts to specific task combinations, prevents data imbalance, and stabilizes training without significantly increasing parameter counts.

GRec demonstrated substantial quantitative improvements in both offline and online experiments. In offline evaluations, GRec outperformed strong baselines such as MMoE and PLE, achieving higher Area Under the Curve (AUC) and Group AUC (GAUC) across multiple datasets. Crucially, during online A/B testing on a major telecom platform handling high-traffic volumes, GRec achieved a relative lift of **0.93% in Click-Through Rate (CTR)** and a **2.05% increase in Conversion Rate (CVR)**. The architecture successfully addressed scalability limitations, showing no performance degradation as the number of tasks increased, while maintaining efficient inference latency suitable for real-time production environments.

This research provides a validated, production-ready blueprint for large-scale industrial recommendation systems, effectively bridging the gap between academic theory and engineering application. By demonstrating that LLM-inspired architectures and efficient routing mechanisms can be effectively adapted for recommendation tasks, GRec validates the "generalist recommender" concept. This work sets a precedent for future systems to move away from resource-intensive siloed models toward unified, scalable solutions, offering a clear path to reduce operational costs while improving prediction accuracy across diverse business objectives.

---

## üîë Key Findings

*   **Scalability Solution:** GRec successfully addresses the scalability limitations of Multi-Task Learning (MTL), preventing performance degradation as the number of tasks increases.
*   **Performance Improvements:** The model demonstrated significant performance gains in both offline evaluations and online A/B experiments.
*   **Production Viability:** The system is robust and production-ready, having handled high traffic volumes on a major telecom website and application.
*   **Computational Efficiency:** Its architecture efficiently scales capabilities across multiple tasks without compromising speed, thanks to a specialized routing mechanism.
*   **Operational Simplicity:** GRec lowers operational complexity compared to maintaining multiple siloed single-task models.

---

## ‚öôÔ∏è Technical Details

GRec is a Multi-Task Learning (MTL) architecture inspired by Large Language Models (LLMs) that utilizes a Sparse Mixture-of-Experts (MoE) to scale efficiently without performance degradation.

**Core Architectural Components:**
*   **Wide and Deep Layer:** Processes multi-modal inputs including categorical embeddings, numerical features, text (via a pretrained Transformer), and images (via CLIP). These are concatenated to form a unified item embedding.
*   **Parallel Transformer Layer:** Utilizes **Multi-Query Single-Key-Value (MQSKV) Attention** to reduce attention block size and computational complexity by sharing Key and Value projections.
*   **Task-Sentence MoE Layer:** A key innovation featuring a "Task-Sentence Routing" strategy.
    *   **Mechanism:** Combines main tasks (e.g., CVR, CTR) with auxiliary flow tasks (e.g., EUP, AAL) into a composite "sentence."
    *   **Stability:** Calculates the gating function based on the average of task ID embeddings to maintain stability and avoid data imbalance.

---

## üß™ Methodology

The authors developed an end-to-end Generalist Recommender (GRec) inspired by Large Language Models (LLMs). The architecture utilizes a hybrid approach to process multi-modal inputs through three distinct components:

1.  **NLP Heads:** Designed to process natural language inputs.
2.  **Parallel Transformers:** utilized to handle sequential dependencies.
3.  **Wide and Deep Structure:** employed for memorization and generalization capabilities.

These inputs are aggregated using a newly proposed **task-sentence level routing mechanism** to dynamically handle multiple tasks within a single model.

---

## üìà Results

*   **Offline Evaluation:** Outperformed strong baselines (including MMoE and PLE) in terms of AUC and GAUC.
*   **Online A/B Testing:**
    *   Achieved a **0.93% relative lift in CTR**.
    *   Achieved a **2.05% relative lift in CVR**.
*   **Scalability:** Successfully prevented performance degradation as the number of tasks scaled up.
*   **Inference:** Maintained efficient latency suitable for high-traffic real-time environments.
*   **Data Sparsity:** Reduced data sparsity issues, particularly for CVR tasks, by leveraging interconnections between use cases.

---

## üöÄ Contributions

*   **Framework Introduction:** Introduced GRec, a framework for generalist recommenders that solves the trade-off between accuracy and scalability in MTL systems.
*   **Novel Routing Mechanism:** Proposed the "task-sentence level routing mechanism" for managing multi-task outputs without performance loss.
*   **Production Blueprint:** Contributed a validated, production-ready architecture that integrates NLP, Transformer, and Wide & Deep components as a blueprint for large-scale industrial applications.