---
title: 'VISAT: Benchmarking Adversarial and Distribution Shift Robustness in Traffic
  Sign Recognition with Visual Attributes'
arxiv_id: '2510.26833'
source_url: https://arxiv.org/abs/2510.26833
generated_at: '2026-02-03T18:38:01'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# VISAT: Benchmarking Adversarial and Distribution Shift Robustness in Traffic Sign Recognition with Visual Attributes

*Simon Yu; Peilin Yu; Hongbo Zheng; Huajie Shao; Han Zhao; Lui Sha*

---

> ### üìä Quick Facts
> *   **Dataset Size:** 302,829 instances (242,263 Train / 30,283 Val / 30,283 Test)
> *   **Classes Covered:** 401 Traffic Sign Classes
> *   **Novel Attributes:** 4 Types (Color, Shape, Symbol, Text)
> *   **Architectures Tested:** ResNet-152 (RBFT), ViT-B/32 (VBFT), and MTL variants
> *   **Key Vulnerability:** Targeted PGD attacks surge error rates from ~7% to ~100%
> *   **Benchmark Scope:** Dual-perspective (Adversarial PGD + Distribution Shift ImageNet-C)

---

## üìù Executive Summary

Traffic sign recognition is a fundamental safety component of autonomous driving systems, yet current benchmarks fail to evaluate the holistic robustness required for real-world deployment. Specifically, existing datasets do not adequately assess performance against adversarial attacks, distribution shifts, or the spurious correlations that plague Multi-Task Learning (MTL). As reliance on deep learning grows in safety-critical cyber-physical systems, the inability to quantify how models react to targeted perturbations and environmental corruptions represents a significant vulnerability. This paper addresses these gaps by establishing that standard base models lack the necessary resilience, necessitating a rigorous framework to evaluate their reliability under both synthetic and realistic stressors.

The authors introduce **VISAT**, a novel benchmark suite and dataset built by extending the Mapillary Traffic Sign Dataset with 302,829 instances annotated across four visual attributes: color, shape, symbol, and text. The benchmark technically evaluates ResNet-152 and ViT-B/32 architectures against Multi-Task Learning variants extended with task-specific heads and weighted Cross-Entropy loss. VISAT employs Projected Gradient Descent (PGD) to generate adversarial inputs and utilizes ImageNet-C corruption techniques (Noise, Blur, Weather, Digital) to simulate distribution shifts. Uniquely, the methodology incorporates synthetic alterations, specifically color quantization, to probe and expose the stability of feature correlations within MTL networks.

Empirical analysis reveals that standard base models are critically vulnerable to adversarial interference, with targeted PGD attacks causing error rates to surge from approximately 7% to nearly 100% (RBFT: 7.50% to 99.96%; VBFT: 6.99% to 100.00%), demonstrating high attack transferability between models. Under distribution shifts, Vision Transformers consistently outperformed Residual Networks; for instance, on Noise corruption, ViT-B/32 achieved a 13.65% error rate compared to ResNet-152‚Äôs 36.26%, while on Weather corruption, ViT-B/32 recorded 23.63% versus ResNet-152‚Äôs 30.13%. Furthermore, the application of color quantization confirmed that MTL models rely on unstable spurious correlations among tasks, highlighting distinct fragility in multi-task robustness compared to single-task baselines.

The release of VISAT provides a standardized open framework for the comprehensive assessment of traffic sign recognition systems, offering a critical tool for the research community. By quantifying the susceptibility of state-of-the-art architectures to adversarial and natural corruptions, and by validating the existence of spurious correlations in MTL, this work guides the future development of more resilient models. These insights are pivotal for improving the safety and reliability of autonomous driving technologies.

---

## üîë Key Findings

*   **Existence of Spurious Correlations in MTL:** Investigation into attribute-specific Multi-Task Learning (MTL) networks revealed the presence of spurious correlations among tasks when subjected to adversarial attacks.
*   **Impact of Synthetic Alterations:** The use of synthetic alterations, specifically color quantization, further exposed and confirmed the existence of spurious correlations within MTL tasks.
*   **Comparative Robustness:** The study highlights distinct differences in performance between base models and MTL models when evaluated against state-of-the-art adversarial attacks and realistic data corruptions.
*   **Vulnerability to Distribution Shifts:** The application of ImageNet-C corruption techniques demonstrated that both base and MTL models face significant robustness challenges under natural variations and realistic data corruption.

---

## üß™ Methodology

The study follows a rigorous benchmarking protocol divided into dataset construction, adversarial testing, and corruption analysis:

1.  **Dataset Construction:** The VISAT dataset extends the Mapillary Traffic Sign Dataset (MTSD) by annotating instances with four novel visual attributes: **Color**, **Shape**, **Symbol**, and **Text**.
2.  **Adversarial Benchmarking:** The team utilized **Projected Gradient Descent (PGD)** to generate adversarial inputs to test model security against targeted attacks.
3.  **Distribution Shift Benchmarking:** To simulate real-world degradation, the study employed **ImageNet-C** corruption techniques, covering Noise, Blur, Weather, and Digital categories.
4.  **Model Evaluation:** The research compared standard base models (ResNet-152 and ViT-B/32) against attribute-specific Multi-Task Learning (MTL) networks.
5.  **Synthetic Analysis:** Color quantization techniques were employed to probe the correlations between tasks and identify stability issues in MTL representations.

---

## ‚öôÔ∏è Technical Details

### Dataset Specifications
*   **Source:** Extension of Mapillary Traffic Sign Dataset (MTSD).
*   **Volume:** 302,829 total instances (242,263 train / 30,283 val / 30,283 test).
*   **Classes:** 401 traffic sign classes.
*   **Preprocessing:** Full-frame images sliced into patches.
*   **Attributes:** 4 Types formulated at the class level:
    *   Color
    *   Shape
    *   Symbol
    *   Text

### Model Architectures
*   **Base Models:**
    *   ResNet-152 (RBFT)
    *   ViT-B/32 (VBFT)
*   **MTL Variants:**
    *   RMFT (ResNet Multi-Task)
    *   VMFT (ViT Multi-Task)
    *   Extended with 4 task heads + linear variants.
*   **Loss Function:** Weighted Cross-Entropy:
    `L_MTL = sum(L_CE(pred_i, y_i) / log|S_i|)`

### Evaluation Metrics
*   **Primary Metrics:** Error rate (epsilon), clean error, attacked error, relative error degradation.
*   **Corruptions:** 15 types from ImageNet-C (Noise, Blur, Weather, Digital).

---

## üìà Results

### Adversarial Attacks (PGD)
Base models showed extreme vulnerability to targeted attacks, with error rates approaching 100%.
*   **ResNet-152 (RBFT):** Error increased from **7.50% (Clean)** to **99.96% (Attacked)**.
*   **ViT-B/32 (VBFT):** Error increased from **6.99% (Clean)** to **100.00% (Attacked)**.
*   **Transferability:** Attacks demonstrated high transferability between different model architectures.

### Distribution Shifts (ImageNet-C)
ViT-B/32 consistently demonstrated superior robustness compared to ResNet-152 across corruption categories.

| Corruption Type | ResNet-152 (RBFT) Error | ViT-B/32 (VBFT) Error |
| :--- | :--- | :--- |
| **Noise** | 36.26% | **13.65%** |
| **Weather** | 30.13% | **23.63%** |
| **Digital** | 13.81% | **12.65%** |
| **Blur** | 8.50% | **7.58%** |

### Synthetic Analysis
*   **Spurious Correlations:** Confirmed in MTL tasks via synthetic alterations (color quantization), indicating that MTL models rely on unstable features for attribute prediction.

---

## üèÜ Contributions

*   **VISAT Dataset and Benchmark Suite:** The release of a novel, open dataset and comprehensive framework specifically designed to evaluate robustness in traffic sign recognition.
*   **Dual-Perspective Benchmarking:** Introduction of two distinct benchmarks that address the two critical challenges of adversarial attacks and distribution shifts within a single framework.
*   **Attribute-Based Analysis:** The creation and integration of specific visual attributes (color, shape, symbol, text) to facilitate the study of Multi-Task Learning (MTL) in the context of autonomous driving.
*   **Insight into MTL Failure Modes:** Provision of new insights into how spurious correlations affect MTL networks, aiding the development of more robust models for real-world cyber-physical systems and autonomous driving applications.

---

**Quality Score:** 8/10  
**References:** 40 citations