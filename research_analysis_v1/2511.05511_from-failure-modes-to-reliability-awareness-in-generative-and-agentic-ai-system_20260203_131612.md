---
title: From Failure Modes to Reliability Awareness in Generative and Agentic AI System
arxiv_id: '2511.05511'
source_url: https://arxiv.org/abs/2511.05511
generated_at: '2026-02-03T13:16:12'
quality_score: 7
citation_count: 4
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# From Failure Modes to Reliability Awareness in Generative and Agentic AI System

*Janet; Lin; Liangwei Zhang*

---

### ðŸ“Š Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Core Framework** | 11-Layer Failure Stack |
| **Key Domains** | 4 (Foundational, Core Intelligence, Operational, Agentic) |
| **Methodology** | Dual-framework integrated with Dependability-Centred Asset Management (DCAM) |
| **Risk Models** | Bottom-Up & Top-Down Cascading Faults |
| **Quality Score** | 7/10 |
| **References** | 4 Citations |

---

## Executive Summary

Generative and Agentic AI systems introduce complex failure modes that propagate systemically across the entire technology stack, rendering traditional reliability engineering insufficient. The critical challenge is the disconnect between granular technical vulnerabilitiesâ€”ranging from physical hardware faults to high-level cognitive errorsâ€”and an organization's ability to recognize and manage them. As AI systems evolve from static pipelines to autonomous agents, vulnerabilities cascade bidirectionally, allowing localized faults to trigger widespread, systemic consequences that current governance frameworks are ill-equipped to handle.

To address this, the authors introduce an **"11-Layer Failure Stack"** integrated with Dependability-Centred Asset Management (DCAM), providing a structured hierarchy to map vulnerabilities. The framework organizes the stack into four distinct domains: the **Foundational Domain** (Hardware, Power & Energy, System Software, AI Frameworks), the **Core Intelligence Domain** (Models, Data), the **Operational Domain** (Applications, Execution, Monitoring, Learning), and the **Agentic Layer**. Technically, the system models bidirectional fault propagation (Bottom-Up and Top-Down cascades) within this structure and utilizes Paradigm-Specific Risk Profiling to differentiate risks between Conventional (Pipeline), Generative (Content), and Agentic (Autonomy) systems.

The research establishes a comprehensive taxonomy that categorizes systemic vulnerabilities across these 11 distinct layers, providing a structured Comparative Risk Mapping for different AI paradigms. Key findings include the identification of unique risk profiles, such as "Energy-hungry autonomy at edge" for Agentic AI, distinguishing them from conventional failures. A central operational component is **"Awareness Mapping,"** a diagnostic tool that quantifies reliability awareness as a measurable maturity score; it functions by assessing an organization's recognition of technical failures against the established 11-layer taxonomy, thereby explicitly defining the lack of organizational awareness as a specific vulnerability.

This work provides a strategic roadmap for trustworthy AI deployment by explicitly connecting technical architecture with executive governance. By positioning reliability awareness as a strategic asset, the framework empowers organizations to diagnose deficiencies in their risk recognition and improve resilience planning. The integration of the 11-layer stack with asset management principles offers a standardized approach for both engineers and decision-makers to manage lifecycle risks, ensuring that governance capabilities evolve in tandem with the increasing complexity of AI systems.

---

## Key Findings

*   **Systemic Propagation of Failures:** Failures in generative and agentic AI systems cascade across layers, causing systemic consequences rather than isolated errors.
*   **Spectrum of Vulnerability:** Vulnerabilities exist across an 11-layer stack ranging from physical foundations to high-level cognitive functions.
*   **Awareness as a Strategic Asset:** Organizational reliability awareness serves as a strategic input for AI governance and resilience planning.
*   **Integration of Technical and Organizational Views:** A critical link exists between technical layered failures and an organization's maturity in recognizing risks.

---

## Methodology

The study utilizes a **dual-framework approach** integrated with asset management principles. This approach comprises three main components:

1.  **Diagnostic Structuring:** Utilization of an **'11-layer failure stack'** to categorize and visualize vulnerabilities.
2.  **Maturity Assessment:** Implementation of **'awareness mapping'** to quantify and score risk recognition capabilities.
3.  **System Integration:** Incorporation into **Dependability-Centred Asset Management (DCAM)** to bridge the gap between technical analysis and organizational preparedness.

---

## Technical Details

### The 11-Layer Failure Stack Architecture
The proposed framework maps vulnerabilities across four hierarchical domains:

*   **Foundational Domain**
    *   Hardware
    *   Power & Energy
    *   System Software
    *   AI Frameworks
*   **Core Intelligence Domain**
    *   Models
    *   Data
*   **Operational Domain**
    *   Applications
    *   Execution
    *   Monitoring
    *   Learning
*   **Agentic Layer**
    *   Agentic AI

### Systemic Propagation Mechanism
The framework emphasizes bidirectional cascading faults:
*   **Bottom-Up Propagation:** Physical/hardware faults affecting higher-level logic.
*   **Top-Down Propagation:** Cognitive/Agentic errors causing stress on foundational layers.

### Paradigm-Specific Risk Profiling
The system analyzes risks based on the AI paradigm:
*   **Conventional (Pipeline-Centred)**
*   **Generative (Content-Centred)**
*   **Agentic (Autonomy-Centred)**

---

## Contributions

*   **The 11-Layer Failure Stack:** A structured framework providing a granular view of AI system vulnerabilities across the entire technology stack.
*   **Awareness Mapping Framework:** A conceptual tool that treats reliability awareness as a measurable maturity score for diagnosing governance gaps.
*   **Governance and Resilience Roadmap:** A strategic model positioning awareness mapping as a roadmap for achieving trustworthy AI deployment by linking failure modes to organizational maturity.

---

## Results

The paper presents qualitative and theoretical findings rather than empirical experimental data. Key outputs include:

*   **Taxonomy Establishment:** A categorization of systemic vulnerabilities into 11 distinct layers.
*   **Comparative Risk Mapping:** Identification of specific risks such as **'Energy-hungry autonomy at edge'** for Agentic AI.
*   **Awareness Mapping Definition:** The formal definition of lack of organizational awareness as a vulnerability.
*   **DCAM Integration:** Positioning the framework within the paradigm of Dependability-Centred Asset Management (DCAM) to link technical failure taxonomy with lifecycle strategies.

---

## Evaluation

**Quality Score:** 7/10  
**References:** 4 citations