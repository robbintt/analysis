# InfoQ: Mixed-Precision Quantization via Global Information Flow

*Authors: Mehmet Emre Akbulut; Hazem Hesham Yousef Shalby; Fabrizio Pittorino; Manuel Roveri*

---

## üìã Quick Facts

| Metric | Value |
| :--- | :--- |
| **Accuracy Gain** | Up to 1% improvement on ImageNet (MobileNetV2 & ResNet18) |
| **Data Efficiency** | Requires **100x less data** than current methods |
| **Training Strategy** | Training-free and retraining-free search phase |
| **Core Methodology** | Global Sensitivity Criterion + Integer Linear Programming (ILP) |
| **Correlation Metric** | $r = 0.95$ and $r = 0.90$ (SMI vs. Accuracy Degradation) |
| **Quality Score** | 9/10 |

---

## üìù Executive Summary

Current approaches to Mixed-Precision Quantization (MPQ) face significant challenges in balancing model compression with accuracy retention. Most existing methods rely on local sensitivity proxies, such as the Hessian trace, to determine which layers can tolerate lower bit-widths. However, this research argues that these local metrics are fundamentally suboptimal because they fail to capture the global cascading effects of quantization errors on the network's overall performance. Furthermore, state-of-the-art search techniques typically require massive datasets and extensive retraining, resulting in prohibitive computational costs and resource overhead.

The paper introduces **InfoQ**, a novel framework that shifts the quantization paradigm from local heuristics to a global perspective based on inter-layer information flow. Grounded in the Information Bottleneck principle, InfoQ assesses a layer‚Äôs sensitivity by performing a single forward pass to measure the change in mutual information between inputs and downstream layers when that layer is quantized.

To handle the complexity of high-dimensional data, the method employs Sliced Mutual Information (SMI) via random projections and input space compression. These sensitivity scores are then used to formulate the bit-width allocation as an Integer Linear Programming (ILP) problem, which a solver optimizes to meet resource budgets. Crucially, this search phase is entirely training-free and retraining-free.

Evaluations on ImageNet demonstrate that InfoQ outperforms current state-of-the-art methods, achieving up to a **1% accuracy improvement** on MobileNetV2 and ResNet18, particularly under high compression rates. Beyond accuracy gains, the framework exhibits exceptional efficiency, requiring two orders of magnitude less data than existing search or criterion-based methods. The study also validated the theoretical robustness of the approach, finding a strong linear correlation between the proposed SMI-based sensitivity metrics and actual accuracy degradation, with correlation coefficients of $r = 0.95$ and $r = 0.90$.

InfoQ establishes a new efficiency benchmark for MPQ by demonstrating that high-accuracy compression can be achieved with significantly reduced computational overhead. The ability to perform effective, training-free quantization search with minimal data requirements has significant practical implications, streamlining the deployment of neural networks on resource-constrained edge devices.

---

## üîë Key Findings

*   **Performance Gains:** InfoQ achieves up to a **1% accuracy improvement** on ImageNet for MobileNetV2 and ResNet18 compared to state-of-the-art methods, even under high compression rates.
*   **Extreme Data Efficiency:** The framework requires **two orders of magnitude less data** than current methods by utilizing a training-free and retraining-free search phase.
*   **Critique of Local Proxies:** Relying on local sensitivity proxies (such as the Hessian) is suboptimal because they fail to account for global cascading effects.
*   **Global Robustness:** Measuring layer sensitivity based on the impact on global information flow (mutual information) provides a more robust signal than local layer properties.

---

## ‚öôÔ∏è Methodology

InfoQ proposes a distinct workflow for determining optimal mixed-precision configurations without the need for intensive retraining:

1.  **Global Information Flow Measurement:** The method assesses a layer by quantizing it at various bit-widths and performing a single forward pass. It measures the resulting change in mutual information (MI) in subsequent layers.
2.  **Training-Free Search:** The entire search phase is executed without updating weights (training-free) and without fine-tuning (retraining-free).
3.  **Sensitivity Scoring:** Sensitivity scores are derived strictly from the information changes observed during the forward passes.
4.  **Optimization Formulation:** The bit-width allocation problem is formulated as an Integer Linear Programming (ILP) problem. A solver is then used to allocate specific bit-widths to layers to minimize the total sensitivity score while strictly adhering to the defined resource budget.

---

## üõ† Technical Details

The framework is built upon several specific technical components designed to optimize the quantization search:

*   **Global Sensitivity Criterion:** Instead of using local proxies like the Hessian trace, the approach utilizes a global criterion based on the impact of quantization error on the network's overall information flow.
*   **Information Bottleneck Principle:** The method is founded on this principle, measuring:
    *   Mutual information between input and downstream layers: $I(X; L_j)$
    *   Mutual information between downstream layers and labels: $I(L_j; Y)$
*   **Optimization Strategy:** Bit-width allocation is framed as an **Integer Linear Programming (ILP)** problem to ensure mathematical optimality within constraints.
*   **Sliced Mutual Information (SMI):** To handle high-dimensional data efficiently, the method employs SMI. This involves projecting vectors onto one-dimensional random projections to estimate mutual information.
*   **Input Space Compression:** A pre-trained encoder is used to compress the input space, further facilitating efficient processing.

---

## üìä Results

The experimental validation of InfoQ highlights its effectiveness and robustness:

*   **ImageNet Performance:** Achieved up to 1% accuracy improvement on MobileNetV2 and ResNet18 relative to SOTA methods, specifically noted under high compression rates.
*   **Search Efficiency:** Demonstrated high data efficiency, requiring two orders of magnitude less data than existing search or criterion-based methods.
*   **Metric Validation:** Experimental analysis confirmed a strong linear correlation ($r = 0.95$ and $r = 0.90$) between the proposed SMI-based sensitivity metrics and actual accuracy degradation. This indicates that global information flow is a highly robust signal for determining layer sensitivity.

---

## üöÄ Contributions

*   **Paradigm Shift:** Introduces a fundamental shift from using local heuristics for quantization sensitivity to a global perspective based on inter-layer information flow.
*   **Novel Framework:** Presents the InfoQ Framework, a unique, training-free bit-width search framework that combines mutual information estimation with Integer Linear Programming.
*   **New Benchmark:** Establishes a new efficiency benchmark for Search in Mixed-Precision Quantization (MPQ), demonstrating that high-accuracy compression is possible with significantly reduced computational overhead and data requirements.

---
**References:** 40 citations | **Quality Score:** 9/10