---
title: 'Rational Retrieval Acts: Leveraging Pragmatic Reasoning to Improve Sparse
  Retrieval'
arxiv_id: '2505.03676'
source_url: https://arxiv.org/abs/2505.03676
generated_at: '2026-01-26T16:24:23'
quality_score: 8
citation_count: 34
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Rational Retrieval Acts: Leveraging Pragmatic Reasoning to Improve Sparse Retrieval

*Benjamin Piwowarski, Pablo Piantanida, Gabriel Ben, Arthur Satouf*

---

> ### üìä Quick Facts
> | Metric | Detail |
> | :--- | :--- |
> | **Methodology** | Rational Retrieval Acts (RRA) framework |
> | **Core Innovation** | Adaptation of Rational Speech Acts (RSA) to Sparse IR |
> | **Key Benchmark** | BEIR (Out-of-domain datasets) |
> | **Performance** | State-of-the-Art (SOTA) results |
> | **Memory Complexity** | Reduced from $O(|\mathcal{T}| \times |\mathcal{D}|)$ to $O(|\mathcal{T}| + |\mathcal{D}|)$ |
> | **Quality Score** | **8/10** |
> | **References** | 34 Citations |

---

## Executive Summary

### üö® Problem
Sparse neural information retrieval (IR) methods and traditional models like BM25 are fundamentally limited by their treatment of document representations in isolation. By failing to account for the broader document collection and the complex interplay of term weights across the corpus, these methods miss the contrastive value of specific tokens within the global context. This independence assumption hinders the model's ability to effectively distinguish documents, creating a performance bottleneck that is particularly acute in out-of-domain scenarios where generalization is critical.

### üí° Innovation
The authors introduce **"Rational Retrieval Acts" (RRA)**, a framework that adapts the Rational Speech Acts (RSA) linguistic model to sparse IR. Technically, RRA maps tokens to utterances and documents to meanings, employing a pragmatic reasoning pipeline consisting of a Literal Listener ($L_0$), a Pragmatic Speaker ($S_1$), and a Pragmatic Listener ($L_1$). This mechanism dynamically modulates token-document interactions by considering the influence of the entire document collection, thereby generating refined, collection-aware representations without relying on dense computations.

### üìà Results
The integration of the RSA framework, specifically in the **S-RRA model (SPLADE + RSA)**, achieves state-of-the-art results on the BEIR benchmark for out-of-domain datasets. The study provides specific quantitative evidence regarding the model's behavior, noting that performance is highly sensitive to the hyperparameter $\alpha$, which controls rational token selection. Specifically, evaluations on the TREC-COVID dataset showed a variance of up to 10 points in nDCG@10 based on the tuning of this parameter.

### üåç Impact
This research represents a significant cross-disciplinary advancement, successfully applying pragmatic reasoning from linguistics to the domain of information retrieval. By demonstrating that considering document context and inter-term relationships can substantially enhance sparse retrieval, the authors challenge the status quo of representation isolation. The proposed RRA framework offers a viable path for future architectures to achieve collection-aware efficiency without the high computational cost typically associated with dense retrieval methods.

---

## Key Findings

*   **Limitations of Current Models:** Existing sparse neural IR methods and traditional models like BM25 fail to account for the broader document collection and complex interplay of term weights.
*   **Adaptation of RSA:** The Rational Speech Acts (RSA) framework can be successfully adapted to Information Retrieval to handle token dimensionality.
*   **Dynamic Modulation:** RSA improves representation by dynamically modulating token-document interactions based on other documents.
*   **Benchmark Success:** Integration of RSA achieves state-of-the-art results on BEIR benchmark out-of-domain datasets.

---

## Methodology

The researchers adapted the **Rational Speech Acts (RSA)** framework, a linguistic model originally designed to minimize communicated features for object identification. 

In the context of this study, the approach dynamically modulates token-document interactions by considering the influence of the entire document collection. This allows for better contrast and refined document representations rather than treating documents in isolation. By shifting from an isolated view to a collection-aware view, the model creates a more contextualized understanding of token importance.

---

## Technical Details

The paper proposes **Rational Retrieval Acts (RRA)**, which maps tokens to utterances and documents to meanings. The architecture employs a specific reasoning pipeline and optimization techniques:

**The Pragmatic Reasoning Pipeline**
The framework utilizes a single-iteration pipeline comprising three main agents:
1.  **Literal Listener ($L_0$):** Represents the base IR model.
2.  **Pragmatic Speaker ($S_1$):** Models rational token selection, controlled by the hyper-parameter $\alpha$.
3.  **Pragmatic Listener ($L_1$):** Produces the final representation.

**Memory Optimization**
To handle memory constraints associated with large vocabularies and document collections, the framework decomposes zero-weight entries into separable global token and document importance factors.
*   **Original Complexity:** $|\mathcal{T}| \times |\mathcal{D}|$
*   **Optimized Complexity:** $|\mathcal{T}| + |\mathcal{D}|$

**Scoring Function**
The final scoring function integrates query weights with the pragmatic representations (derived from $L_1$) and the global factors mentioned above.

---

## Results

*   **Parameter Sensitivity:** Key metrics, specifically **nDCG@10**, show significant sensitivity to the $\alpha$ parameter. On the TREC-COVID dataset, variance reached up to **10 points** depending on this setting.
*   **Validation Protocol:** A robust validation protocol was established using 500 sampled documents and synthetic queries generated by **LLaMA3-8B** for parameter selection.
*   **SOTA Performance:** The **S-RRA model** (SPLADE + RSA) achieved State-of-the-Art (SOTA) results on the BEIR benchmark for out-of-domain datasets.

---

## Contributions

*   **Cross-Disciplinary Application:** Introduced a novel cross-disciplinary application of the RSA framework to sparse neural information retrieval.
*   **Collection-Aware Representation:** Developed a mechanism that addresses limitations of sparse models by considering document context and inter-term relationships.
*   **Empirical Validation:** Provided empirical validation of consistent performance improvements across multiple architectures, specifically demonstrating state-of-the-art capability on out-of-domain benchmarks.