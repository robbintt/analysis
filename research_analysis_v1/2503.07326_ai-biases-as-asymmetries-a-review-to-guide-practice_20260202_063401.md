# AI Biases as Asymmetries: A Review to Guide Practice

*Gabriella Waters; Phillip Honenberger*

---

> ### üìã Quick Facts
>
> *   **Quality Score:** 9/10
> *   **Document Type:** Theoretical Review / Conceptual Framework
> *   **Methodology:** Philosophical Analysis & Taxonomy Construction
> *   **Core Metric:** Symmetry Standard Violations
> *   **Citations:** 0

---

## üìù Executive Summary

This research addresses the fundamental limitation in current AI governance where bias is predominantly conceptualized merely as a statistical error to be minimized. The authors argue that this "bias-as-error" paradigm is insufficient because it fails to distinguish between harmful inaccuracies and biases that are technically necessary or functionally beneficial. Without a more rigorous definition, practitioners lack the normative guidance required to determine which biases should be eliminated and which should be preserved, leading to a development pipeline where mitigation strategies are often applied indiscriminately without context.

The key innovation is the reconceptualization of **AI bias as a "violation of a symmetry standard"** rather than a simple error. Technically, the authors construct a normative framework using a $5 \times 3$ matrix that maps symmetry violations (bias types) against stages of the AI development pipeline: Model Selection, Inputs, In-processing, Outputs, and Applications.

Within this matrix, biases are classified into three distinct categories: Error Biases, Inequality Biases (subdivided into Type b1: proportional distributive parity and Type b2: FPR/FNR/accuracy parity), and Process Biases (subdivided into Type a: cognitive, Type c: inductive, and Type d: bias-variance).

As a theoretical review, the paper presents qualitative findings derived from the evaluation of industry-standard metrics using the proposed matrix logic. The analysis yields specific conditional classifications:
*   **Inductive biases (Type c)** are identified as "Necessary" for model function.
*   **Error biases** are rated "Good" during the Model Selection phase to facilitate trade-offs but "Bad" in Outputs.
*   **Discriminatory biases (Type b2)** are evaluated as "Bad usually" within the In-processing and Outputs stages.

This work significantly influences the field by establishing a structured protocol for managing bias that moves beyond total elimination toward nuanced decision-making, empowering developers and ethicists to make informed trade-offs between technical performance and moral requirements.

---

## üîë Key Findings

*   **Reconceptualization of Bias:** AI bias should be reconceptualized from a mere error to an integral component of systems that is sometimes preferable.
*   **Definition via Symmetry:** Biases are best defined as violations of a symmetry standard for precise measurement.
*   **Taxonomy of Biases:** AI biases are categorized into three primary types:
    1.  Error biases
    2.  Inequality biases
    3.  Process biases
*   **Context-Dependent Value:** The moral and technical value of bias is context-dependent, varying significantly across the development pipeline.
*   **Normative Guidance:** There is a critical need for normative guidance to distinguish biases that should be accepted from those that should be eliminated.

---

## üõ†Ô∏è Methodology

The authors employ a **conceptual review and theoretical framework analysis**. Rather than presenting experimental data, the paper utilizes philosophical definitions of symmetry to construct a taxonomic system for analyzing AI systems.

---

## ‚ö° Technical Details

The paper proposes a conceptual framework that redefines AI bias and utilizes a structured matrix approach for analysis.

### Core Concept
*   **Definition:** AI bias is defined as a **violation of a symmetry standard**.

### The Matrix Framework
*   **Structure:** A $5 \times 3$ matrix mapping symmetry violations (bias types) against AI development pipeline stages.
*   **Pipeline Stages:**
    1.  Model Selection
    2.  Inputs
    3.  In-processing
    4.  Outputs
    5.  Applications

### Classification of Bias Types

| Category | Sub-Types | Description |
| :--- | :--- | :--- |
| **1. Error Biases** | ‚Äî | Standard statistical inaccuracies. |
| **2. Inequality Biases** | **Type b1:** Proportional distributive parity | Distributional disparities. |
| | **Type b2:** FPR/FNR/accuracy parity | Performance metric disparities. |
| **3. Process Biases** | **Type a:** Cognitive | Mental model influences. |
| | **Type c:** Inductive | Learning algorithm assumptions. |
| | **Type d:** Bias-variance | Trade-offs in model complexity. |

### Evaluation Logic
The framework applies qualitative categories to individual cells within the matrix to determine the status of a bias at a specific stage:
*   **X** (Not applicable)
*   **Bad mostly**
*   **Good**
*   **Necessary usually**
*   **Good or Bad** (Context specific)

---

## üìä Contributions

*   **New Protocols:** Provides new protocols for conceptualizing and measuring bias beyond the traditional 'bias-as-error' model.
*   **Normative Framework:** Offers a normative framework for managing bias by deciding which biases to keep or remove based on context.
*   **Classification System:** Introduces a comprehensive three-part classification system (error, inequality, and process biases) to standardize analysis.

---

## üß™ Results

As this paper is a theoretical review, it contains no empirical experimental results. Instead, it provides qualitative findings based on the analysis of industry metrics used to define asymmetries.

### Metrics Analyzed
*   Proportional Distributive Parity
*   False Positive Rate Balance
*   False Negative Rate Balance
*   Accuracy Parity
*   Accuracy

### Qualitative Evaluations
*   **Inductive Biases:** Classified as **"Necessary"** for model function.
*   **Error Biases:** Rated **"Good"** in Model Selection (for trade-offs), but **"Bad"** in Outputs.
*   **Discriminatory Biases (b2):** Evaluated as **"Bad usually"** in In-processing and Outputs stages.