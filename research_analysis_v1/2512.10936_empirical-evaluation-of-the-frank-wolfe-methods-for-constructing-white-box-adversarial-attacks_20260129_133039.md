# Empirical evaluation of the Frank-Wolfe methods for constructing white-box adversarial attacks

*Kristina Korotkova; Aleksandr Katrutsa*

***

### ðŸ“‹ Quick Facts
| Metric | Detail |
| :--- | :--- |
| **Focus** | Projection-free optimization for adversarial attacks |
| **Key Algorithm** | Modified Frank-Wolfe (FW), Momentum FW, Away-Steps FW |
| **Datasets** | MNIST, CIFAR-10 |
| **Architectures** | Logistic Regression, CNNs (ResNet-56), Vision Transformers (ViT) |
| **Norm Constraints** | $\ell_1, \ell_2, \ell_\infty$ (Focus on $\ell_1$ for sparsity) |
| **Quality Score** | 8/10 |

***

## Executive Summary

Evaluating neural network robustness through white-box adversarial attacks is essential for understanding model vulnerability, yet standard methodologies like Projected Gradient Descent (PGD) face computational bottlenecks when optimizing under non-Euclidean constraints. Specifically, generating attacks within an $\ell_1$-norm ball is critical for evaluating robustness against sparse perturbations, but requires expensive projection steps involving sorting and thresholding. These projections act as a computational hurdle, hindering the practical assessment of model resilience and making the generation of interpretable, sparse attacks inefficient.

This paper introduces modified **Frank-Wolfe (FW) methods** as a projection-free alternative to PGD for generating adversarial attacks. The approach reformulates the problem to utilize a **Linear Minimization Oracle (LMO)** rather than a projection operator. Technically, the LMO selects vertices of the constraint set that align with the loss gradient, updating the perturbation via convex combination. The authors implement several FW variantsâ€”including **Momentum FW (FWm)**, **Away-Steps FW (AFW)**, and **Pairwise FW (PFW)**â€”to enhance convergence. This structural shift fundamentally alters how constraints are handled; for $\ell_1$ norms, the method exploits the geometry of the constraint set to naturally induce sparsity by operating on vertices, whereas PGD typically generates dense perturbations that require explicit sparsification.

The framework was validated across distinct datasets and modern architectures to ensure rigorous performance assessment.
*   **MNIST:** Multiclass logistic regression (92.68% baseline accuracy).
*   **CIFAR-10:** ResNet-56 (94.37% baseline accuracy) and Vision Transformer (97.28% baseline accuracy).

Evaluation metrics covering Test Accuracy, Runtime, and Sparsity confirmed that Frank-Wolfe variants achieve attack success rates comparable to standard PGD. Crucially, under $\ell_1$ constraints, the FW methods demonstrated **superior sparsity performance and runtime efficiency**, effectively bypassing the sorting overhead required by projection-based algorithms.

This research establishes projection-free optimization as a theoretically sound and practical tool for adversarial robustness evaluation, particularly for constraints where projection is computationally prohibitive. By demonstrating that Frank-Wolfe methods can successfully attack complex architectures like Vision Transformers while naturally enforcing sparsity, the work provides researchers with a more efficient mechanism for analyzing model vulnerabilities.

***

## Key Findings

*   **Optimization Formalism:** The study confirms that adversarial attack construction can be effectively formalized and solved as a numerical optimization problem.
*   **Viable Alternative:** Modified Frank-Wolfe methods (projection-free) are presented as a viable alternative to standard projection-based methods (like PGD).
*   **Broad Applicability:** Theoretical and numerical evaluation demonstrates the applicability of these methods across diverse neural network architectures, including vision Transformers (**ViT**).
*   **Validated Performance:** Numerical experiments on MNIST and CIFAR-10 datasets validate the performance of the approach against multiclass logistic regression, CNNs, and ViTs.

## Methodology

The authors treat the construction of adversarial attacks as a specific numerical optimization problem. The core methodological shift involves utilizing **modified Frank-Wolfe methods**â€”advanced projection-free optimization algorithmsâ€”as opposed to standard projection-based methods.

The methodology includes:
*   **Theoretical Analysis:** Comparing the properties of projection-free vs. projection-based optimization.
*   **Numerical Experimentation:** Benchmarking against standard baselines.
*   **Datasets:** MNIST and CIFAR-10.
*   **Models:** Multiclass logistic regression, Convolutional Neural Networks (CNNs), and Vision Transformers (ViT).

## Technical Details

### Problem Formalization
The approach formalizes attack generation as maximizing cross-entropy loss $L(x+\delta|f_\theta)$ constrained within a norm-ball $\|\delta\|_p \le \epsilon$ for $p \in \{1, 2, \infty\}$.

### Projection-Free Algorithm
Instead of using Projected Gradient Descent (PGD), the approach utilizes Projection-Free Frank-Wolfe (FW) methods to avoid computationally expensive projections onto the $\ell_1$-ball.

### Core Mechanics
1.  **Linear Minimization Oracle (LMO):** Solves $v^* \in \arg \min_{v \in S} \langle \nabla_\delta L, v \rangle$.
2.  **Update Step:** The perturbation is updated via $\delta_{k+1} = (1 - \gamma_k)\delta_k + \gamma_k v^*$.

### Norm Solutions
*   **Closed-form LMO:** Solutions are detailed for $\ell_\infty$, $\ell_2$, and $\ell_1$ norms.
*   **Sparsity:** The $\ell_1$ solution specifically induces sparsity, a key advantage for interpretable attacks.

### Algorithm Variants
To enhance convergence and solution representation, the authors implement several variants:
*   **FWm:** Momentum Frank-Wolfe
*   **AFW:** Away-Steps Frank-Wolfe
*   **PFW:** Pairwise Frank-Wolfe

## Results

The text details the experimental setup and baseline model statistics. While specific adversarial attack figures were noted as excluded from the provided text, the following baselines were defined:

| Model | Dataset | Baseline Accuracy | Parameters |
| :--- | :--- | :--- | :--- |
| Logistic Regression | MNIST | 92.68% | 0.008M |
| ResNet-56 | CIFAR-10 | 94.37% | 0.86M |
| Vision Transformer | CIFAR-10 | 97.28% | 85.81M |

**Evaluation Metrics:**
*   **Test Accuracy:** Post-attack accuracy to measure success.
*   **Runtime:** Computational efficiency.
*   **Sparsity:** Count of nonzero pixels (crucial for $\ell_1$ attacks).
*   **Visual Analysis:** Qualitative inspection of perturbations.

## Contributions

*   **Methodological Introduction:** Introduces and adapts modified Frank-Wolfe methods (projection-free) specifically for the task of generating white-box adversarial attacks.
*   **Theoretical Comparison:** Provides a theoretical and numerical comparison between projection-free Frank-Wolfe methods and standard approaches that rely on projection operations or geometrical intuition.
*   **Architecture Extension:** Extends the evaluation of adversarial attack methods to include modern architectures like Vision Transformers (ViT) alongside traditional CNNs and logistic regression.

***
**References:** 40 citations | **Quality Score:** 8/10