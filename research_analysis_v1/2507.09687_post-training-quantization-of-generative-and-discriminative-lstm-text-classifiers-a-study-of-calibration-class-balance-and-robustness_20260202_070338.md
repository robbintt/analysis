# Post-Training Quantization of Generative and Discriminative LSTM Text Classifiers: A Study of Calibration, Class Balance, and Robustness

*Md Mushfiqur Rahaman; Elliot Chang; Tasmiah Haque; Srinjoy Das*

> **üìÑ Quick Facts & Metrics**
> *   **Quality Score:** 8/10
> *   **References:** 40 Citations
> *   **Primary Tool:** Brevitas Quantization Library
> *   **Key Metrics:** Classification Accuracy, KS Statistics
> *   **Bitwidth Range:** 3-bit to 8-bit
> *   **Focus:** Edge Computing, Model Quantization, Calibration Data

---

## üìã Executive Summary

This research addresses the critical challenge of deploying LSTM-based text classifiers on resource-constrained edge devices using Post-Training Quantization (PTQ). While PTQ is essential for minimizing the memory and computational footprint of deep learning models, the efficacy of quantization varies drastically across architectures. The paper identifies a significant gap in understanding the differing responses of generative versus discriminative LSTMs to low-precision constraints, particularly regarding the quality of calibration data and the presence of input noise. This distinction is vital for engineers who must maintain high accuracy on edge hardware where full-precision execution is unfeasible and calibration data often consists of passively collected, unlabeled, and class-imbalanced samples.

The key innovation is a rigorous comparative framework that systematically evaluates PTQ effects on discriminative and generative LSTM architectures using the Brevitas quantization library. Technically, the authors isolate the influence of calibration data composition‚Äîspecifically class balance‚Äîby applying PTQ across aggressive bitwidths ranging from 8-bit down to 3-bit under clean and noisy input conditions. To validate internal dynamics and move beyond surface-level accuracy metrics, the study employs nonparametric hypothesis testing, specifically Kolmogorov-Smirnov (KS) tests. This statistical approach quantifies shifts in activation distributions and weight adjustments, allowing the authors to pinpoint the physical layer phenomena responsible for performance degradation.

The study reveals a stark divergence in robustness: discriminative LSTM classifiers remain stable across all tested bitwidths, whereas generative LSTMs exhibit high sensitivity. Quantitatively, generative classifiers suffer substantial performance degradation at lower bitwidths (specifically 3-bit and 4-bit), often collapsing when calibration data is class-imbalanced. The research identifies the primary mechanism for this failure as weight clipping resulting from insufficient weight adaptation; class imbalance in calibration datasets causes the quantization scale factors to skew, effectively clipping the weights of minority classes. Furthermore, while generative models are robust to input noise at full precision, they fail under quantization. KS statistics confirmed significant distributional shifts in activations (increased D-statistic distances) under these adverse conditions, correlating directly with the observed accuracy deltas and validating the hypothesis that quantization magnifies the vulnerability of generative models to calibration defects.

These findings provide critical deployment insights for the field of edge AI and natural language processing, establishing that calibration data is a decisive factor in quantization success. The paper demonstrates that for generative models, which require evenly distributed class samples to adapt weights effectively at low bitwidths, random or passive calibration data is often insufficient. For practitioners, this work serves as a guideline for architecture selection and data preparation: discriminative LSTMs are safer candidates for aggressive PTQ, whereas generative LSTMs demand curated, class-balanced calibration data to avoid catastrophic failure in production environments involving noise or hardware constraints.

---

## üîë Key Findings

*   **Divergent Robustness:** Discriminative LSTM classifiers remain robust under Post-Training Quantization (PTQ), whereas generative LSTM classifiers exhibit high sensitivity to bitwidth variations, calibration data, and input noise.
*   **Impact of Class Imbalance:** Generative classifiers are susceptible to class imbalance in calibration data, where uneven sample distribution leads to insufficient weight adaptation at lower bitwidths.
*   **Mechanism of Degradation:** Performance degradation in generative classifiers stems from insufficient weight adjustments when exposed to class-imbalanced calibration datasets.
*   **Environment Suitability:** Despite being robust to noise in full precision, generative classifiers may fail under quantization on edge devices without careful calibration.

---

## üß™ Methodology

The researchers conducted a comparative study using the **Brevitas quantization library** to apply Post-Training Quantization (PTQ) to generative and discriminative LSTM-based text classification models. The evaluation framework assessed models across multiple bitwidths and under two input conditions:

1.  **Regular Data:** Standard inputs to baseline performance.
2.  **Noisy Data:** Inputs with introduced noise to test robustness.

The methodology specifically analyzed the impact of **calibration data composition** by comparing evenly and unevenly distributed class samples. To validate results and investigate internal dynamics, the authors utilized test statistics derived from **nonparametric hypothesis testing** to examine weight adjustments and activation profiles.

---

## ‚öôÔ∏è Technical Details

**Input Processing Pipeline**
*   **Tokenization & Embeddings:** Utilized Word2Vec, GloVe, and SpaCy for text vectorization.

**Architectures Analyzed**
*   **Discriminative LSTM:** `Embedding Layer ‚Üí L-layer LSTM Encoder ‚Üí Fully Connected Output Layer`
*   **Generative LSTM:** Standard generative architectures for text classification tasks.

**Quantization Protocol**
*   **Library:** Brevitas
*   **Method:** Post-Training Quantization (PTQ)
*   **Precision Range:** 8-bit down to 3-bit
*   **Calibration Data:** Passively collected, unlabeled, and often class-imbalanced data.

**Statistical Validation**
*   **Method:** Kolmogorov-Smirnov (KS) Tests
*   **Purpose:** To quantify shifts in activation distributions and validate weight adaptation.

---

## üìä Results

*   **Robustness Divergence:** Discriminative LSTMs remain robust under PTQ, whereas Generative LSTMs exhibit high sensitivity to bitwidth changes, calibration data composition, and input noise.
*   **Performance Degradation:** Generative classifiers suffer significant performance degradation at lower bitwidths (3-bit, 4-bit) due to insufficient weight adaptation caused by class imbalance in calibration data.
*   **Edge Device Implications:** While generative classifiers are robust to noise in full precision, they are prone to failure under quantization on edge devices compared to their full-precision behavior.
*   **Evaluation Metrics:**
    *   Classification Accuracy
    *   KS Statistics for activation distribution shifts
    *   Bitwidth precision

---

## üöÄ Contributions

*   **Critical PTQ Analysis:** Provides a detailed comparative analysis of PTQ effects on generative versus discriminative models, addressing trade-offs for edge computing optimization.
*   **Calibration Data Guidelines:** Establishes the critical role of calibration data quality, demonstrating that class imbalance during calibration correlates with insufficient weight adaptation for generative LSTMs.
*   **Deployment Insights:** Offers practical insights for deploying text classifiers on resource-constrained edge devices by defining the noise and quantization conditions for success or failure.
*   **Rigorous Validation:** Introduces a rigorous statistical approach using nonparametric hypothesis testing to quantify quantization effects on model weights and activations.