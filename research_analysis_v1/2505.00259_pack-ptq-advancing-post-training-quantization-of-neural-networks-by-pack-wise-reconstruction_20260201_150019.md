# Pack-PTQ: Advancing Post-training Quantization of Neural Networks by Pack-wise Reconstruction

*Changjun Li; Runqing Jiang; Zhuo Song; Pengpeng Yu; Ye Zhang; Yulan Guo*

---

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 7/10 |
| **References** | 40 Citations |
| **Focus Area** | Post-Training Quantization (PTQ) |
| **Key Configuration** | W3/A3 (Weight 3-bit / Activation 3-bit) |
| **ResNet18 Top-1** | **69.44%** (vs 58.8% BRECQ) |
| **MobileNetV2 Top-1** | **70.21%** (vs 37.4% BRECQ) |
| **Data Modalities** | 2D Image & 3D Point Cloud |

---

## üìù Executive Summary

**Challenge:** Post-training quantization (PTQ) is critical for deploying large-scale neural networks on edge devices. However, existing methods fail to maintain accuracy in aggressive low-bit regimes (specifically W3/A3). The core limitation of current state-of-the-art approaches is reliance on **block-wise reconstruction**, which treats individual network blocks as independent units. This isolation neglects critical cross-block dependencies, leading to severe error accumulation and model collapse.

**Solution:** **Pack-PTQ** introduces a paradigm shift by replacing the isolated block with non-overlapping groups called **"packs."** By treating multiple contiguous blocks as a unified entity during optimization, the method preserves cross-block dependencies. The framework utilizes Hessian-guided Adaptive Packing for intelligent partitioning and Sensitivity-based Mixed-Precision Assignment to dynamically allocate bit-widths (e.g., 4-bit for sensitive, 3-bit for non-sensitive areas).

**Impact:** Extensive experiments on ImageNet demonstrate that Pack-PTQ recovers accuracy to near-floating-point levels. For instance, on ResNet18, Pack-PTQ achieved **69.44%** (vs. 69.76% FP), while the leading baseline collapsed to 58.8%. This research bridges the gap between PTQ and Quantization-Aware Training (QAT), offering a cost-effective solution for real-world, high-performance edge deployment.

---

## üîë Key Findings

*   **Cross-Block Dependency Preservation:** Existing block-wise reconstruction methods suffer from significant accuracy degradation in low-bit scenarios because they neglect dependencies between blocks. Pack-PTQ solves this by using non-overlapping "packs" as the base unit for reconstruction.
*   **Mixed-Precision Strategy:** The method implements a mixed-precision quantization strategy that assigns specific bit-widths to packs based on their distinct sensitivity levels, further enhancing model performance.
*   **Superior Accuracy Recovery:** In W3/A3 settings, Pack-PTQ significantly recovers accuracy, rising from the 30-50% range (standard methods) to the 60-70%+ range on difficult tasks.
*   **Multi-Modality Validation:** The method is validated across both 2D image (ImageNet) and 3D point cloud classification tasks, outperforming state-of-the-art methods like BRECQ, Q-Drop, NoisyQuant, and SPQ.

---

## üõ†Ô∏è Methodology

The proposed **Pack-PTQ** framework departs from traditional block-wise reconstruction, consisting of two primary stages:

1.  **Hessian-guided Adaptive Packing**
    *   A mechanism designed to partition standard blocks into non-overlapping groups called "packs."
    *   Captures dependencies across blocks to estimate quantization parameters more accurately.

2.  **Sensitivity-based Mixed-Precision Assignment**
    *   Optimizes performance by assigning varied bit-widths to different packs according to their specific sensitivity to quantization errors.
    *   Utilizes sensitivity analysis to determine where higher precision is required.

---

## ‚ö° Technical Details

*   **Reconstruction Unit Shift:** Moves optimization from individual blocks to 'packs' to capture cross-block dependencies in low-bit scenarios ($\min L(w_{pack})$).
*   **Hessian-guided Clustering:** Blocks are clustered into packs based on importance scores derived from:
    *   Model loss
    *   Gradients
    *   Local loss landscape
*   **Quantization Formula:** Utilizes Uniform Affine Quantization:
    $$x_q = \text{clamp}(\text{floor}(x/s + z), 0, 2^k - 1)$$
*   **Precision Strategy:** Assigns heterogeneous bit-widths (e.g., 4-bit for sensitive packs, 3-bit for non-sensitive).

---

## üèÜ Contributions

*   **Reformulation of Reconstruction Units:** Introduces a paradigm shift in PTQ by moving from block-wise to pack-wise reconstruction.
*   **Optimized Partitioning Strategy:** Contributes a Hessian-guided adaptive packing mechanism to intelligently form non-overlapping packs.
*   **Advanced Bit-width Allocation:** Contributes a pack-based mixed-precision quantization approach that dynamically allocates bit-widths based on pack sensitivity.
*   **Broad Empirical Validation:** Provides comprehensive evidence of efficacy across diverse data modalities, including 2D image and 3D point cloud classification.

---

## üìà Performance Results

Evaluated under **W3/A3** settings on ImageNet and 3D point cloud data across architectures including ResNet18, MobileNetV2, DeiT-T, and Swin-S.

*   **Comparison with Packing Strategies:** Pack-PTQ outperformed 'No Packing', Random Packing, and Fixed-size Packing strategies.
*   **ResNet18:** Achieved **69.44%** Top-1 accuracy (FP baseline: 69.76%), significantly outperforming BRECQ (58.8%).
*   **MobileNetV2:** Achieved **70.21%**, a stark improvement over BRECQ, which fell to **37.4%**.
*   **Vision Transformers:**
    *   **DeiT-T:** **73.09%**
    *   **Swin-S:** **80.54%**
*   **3D Point Cloud:** Maintained superiority on classification tasks, validating generalization capabilities.