---
title: 'MasHost Builds It All: Autonomous Multi-Agent System Directed by Reinforcement
  Learning'
arxiv_id: '2506.08507'
source_url: https://arxiv.org/abs/2506.08507
generated_at: '2026-02-03T13:36:02'
quality_score: 7
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# MasHost Builds It All: Autonomous Multi-Agent System Directed by Reinforcement Learning

*Kuo Yang; Xingjie Yang; Linhui Yu; Qing Xu; Yan Fang; Xu Wang; Zhengyang Zhou; Yang Wang*

***

> ### üìä Quick Facts
> *   **Quality Score:** 7/10
> *   **References:** 40 Citations
> *   **Benchmarks:** 6
> *   **Key Performance:** Outperforms strongest baseline by 15% on average
> *   **Resource Efficiency:** Improved by 22%

***

## üìù Executive Summary

The construction of Multi-Agent Systems (MAS) has traditionally been a manual or semi-autonomous process, constrained by human bias and a lack of dynamic adaptability. To address this bottleneck, the authors propose **MasHost**, a Reinforcement Learning (RL) framework that formulates MAS construction as a graph search problem modeled as a Markov Decision Process (MDP).

The core technical innovation is **Hierarchical Relative Policy Optimization (HRPO)**, a strategy designed to navigate multi-objective optimization spaces. HRPO integrates "group-relative advantages" with "action-wise rewards," allowing the system to evaluate potential nodes relative to the existing group while assigning credit to specific atomic actions. Supported by a **Joint Probabilistic Space Sampling (JPSS)** mechanism, MasHost optimizes a composite reward function balancing Accuracy, Resource Efficiency, and Structure Rationality.

Evaluated across six benchmarks, MasHost consistently outperformed competitive baselines, improving resource efficiency by 22% while maintaining high accuracy. As the first RL-driven framework for the autonomous construction of MAS graphs, MasHost establishes the principle of "component rationality" and eliminates the need for manual role definition, paving the way for fully autonomous, query-adaptive systems.

***

## üîë Key Findings

*   **Superior Performance:** MasHost consistently outperforms competitive baselines across six benchmarks, exceeding the strongest baseline by an average of **15%**.
*   **Multi-Objective Balance:** The framework effectively balances three competing objectives: accuracy, efficiency, and structure rationality.
*   **Full Autonomy:** Experiments validate that MasHost enables fully autonomous, query-adaptive MAS construction, overcoming the semi-autonomous limitations of previous approaches.
*   **Optimization Strategy:** The proposed **Hierarchical Relative Policy Optimization (HRPO)** strategy is empirically validated as effective in integrating group-relative advantages and action-wise rewards.
*   **Resource Efficiency:** Specifically, MasHost improved resource efficiency by **22%** while maintaining comparable accuracy levels to existing methods.

***

## üõ†Ô∏è Methodology

The researchers propose **MasHost**, an RL-based framework designed to construct Multi-agent systems autonomously without manual engineering. The approach shifts away from manual mechanisms by formulating MAS construction as a **graph search problem**.

*   **Unified Sampling:** It employs a unified probabilistic sampling mechanism to jointly sample agent roles and interactions.
*   **HRPO Strategy:** A novel strategy called **Hierarchical Relative Policy Optimization (HRPO)** is introduced to handle multi-objective optimization.
*   **Reward Integration:** HRPO effectively integrates group-relative advantages with action-wise rewards to collaboratively optimize complex structural objectives.

***

## ‚öôÔ∏è Technical Details

MasHost formulates the construction process as a Markov Decision Process (MDP) defined as $M = (S, A, R)$.

### System Components

| Component | Description |
| :--- | :--- |
| **State Space ($S$)** | Comprises the user query ($Q$), the constructed structure ($M_t$), and agent messages ($MESSAGE(M_t)$). |
| **Action Space ($A$)** | A dual-level atomic action $a_t = (a_n, a_e)$ consisting of: <br> ‚Ä¢ **Node-level:** `{ADD, DELETE, EXIT}` <br> ‚Ä¢ **Edge-level:** `{CONNECT}` <br> Governed by separate parameterized networks ($\pi_\theta$ and $\pi_\phi$). |

### Novel Mechanisms

*   **Joint Probabilistic Space Sampling (JPSS):** Ensures efficient search and differentiability when sampling agent roles and interactions.
*   **Hierarchical Relative Policy Optimization (HRPO):** Specifically designed to handle the integration of advantages and rewards in a hierarchical manner.

### Optimization Objectives
The system optimizes a composite reward function consisting of:
1.  **Performance Quality ($r_{perf}$)**
2.  **Resource Efficiency ($r_{eff}$)**
3.  **Structure Rationality ($r_{struct}$)**

***

## üåü Contributions

*   **First RL-Driven Framework:** MasHost represents the first Reinforcement Learning-driven framework specifically designed for the autonomous construction of MAS graphs.
*   **Component Rationality:** The study introduces "component rationality" as a novel design principle for MAS.
*   **New RL Strategy:** The paper contributes **Hierarchical Relative Policy Optimization (HRPO)**, a new RL strategy for collaboratively optimizing complex objectives involving multiple agents.
*   **Bias Reduction:** Provides a unified construction mechanism that significantly reduces human bias and enhances autonomous adaptation to queries.

***

## üìà Results

The paper evaluated performance using a multi-dimensional composite reward metric:
$$r(M|Q) = r_{perf}(M, Q) + r_{eff}(M, Q) + r_{struct}(M)$$

*   **Benchmark Success:** MasHost consistently outperformed competitive baselines across all six benchmarks.
*   **Objective Management:** The framework demonstrated the ability to effectively manage trade-offs between competing objectives (accuracy vs. efficiency).
*   **Structural Superiority:** Results indicate the generation of superior graph structures that maximize task performance while minimizing resource usage.
*   **Validation:** The Hierarchical Relative Policy Optimization (HRPO) strategy was empirically proven effective in the context of autonomous system construction.

***
*Document generated based on analysis of 40 references.*