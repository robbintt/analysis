---
title: Procedural Knowledge Improves Agentic LLM Workflows
arxiv_id: '2511.07568'
source_url: https://arxiv.org/abs/2511.07568
generated_at: '2026-01-27T21:16:13'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Procedural Knowledge Improves Agentic LLM Workflows

*Mark Roberts, Vincent Hsiao, et al.*

---

> ### üìä Quick Facts
> - **Quality Score:** 8/10
> - **References:** 40 Citations
> - **Core Mechanism:** Hierarchical Task Networks (HTNs)
> - **Key Statistic:** 81.4% success rate (GPT-oss 120b with HTN) vs 0% without.
> - **Paradigm Shift:** Curation of procedural expertise is now equal to tool support and prompt engineering.

---

## üìë Executive Summary

This research addresses the critical limitation of Large Language Models (LLMs) in performing complex, multi-step agentic workflows that require **implicit planning**. While LLMs possess broad world knowledge, they frequently fail to decompose high-level, abstract objectives into executable sequences of primitive actions without extensive external guidance. This deficiency often leads to reasoning failures, such as infinite loops or invalid state transitions, when models attempt to solve problems requiring strict adherence to procedural logic. The study highlights that increasing model parameter count alone is an inefficient solution to this bottleneck, prompting a need for architectural interventions that explicitly encode domain-dependent processes.

The key innovation is the introduction of **"ProcLLM,"** a framework that integrates explicit procedural knowledge into LLM agents using **Hierarchical Task Networks (HTNs)**. Technically, the system models procedural reasoning as a finite-horizon deterministic Markov Decision Process (MDP). It utilizes a `FindFirstRelevantMethod` strategy to recursively decompose complex tasks into primitive subtasks based on defined Methods (comprising head, task, preconditions, and subtasks). The workflow functions within a file-system-based environment where a decomposer-LLM breaks down tasks, an action-LLM generates Python code or tool calls, and a verify-LLM rigorously checks domain preconditions before execution.

Empirical evaluation across Travel Planning (TP), Recipe Generator, Blocks World, and Unit Movement benchmarks demonstrated that HTN augmentation dramatically outperforms baseline LLMs. In the Travel Planning benchmark, a Nemotron 70b model equipped with hand-coded HTNs achieved a **53.5% success rate** on Flight tasks compared to a negligible **2.3% without HTNs**. Similarly, a GPT-oss 120b model reached **81.4% success** with HTNs versus **0% without**. The data revealed that smaller models (20b‚Äì70b) augmented with procedural knowledge could surpass the performance of significantly larger baseline models (120b).

This paper significantly influences the field by validating that architectural enhancements can be more effective than brute-force scaling for agentic reasoning.

---

## üîë Key Findings

*   **Performance via HTNs:** Integrating domain-dependent procedural knowledge using Hierarchical Task Networks (HTNs) dramatically improves LLM performance on implicit planning tasks.
*   **Efficiency over Scale:** Smaller models (20b‚Äì70b) augmented with HTNs can **outperform** larger baseline models (120b).
*   **Human vs. LLM Knowledge:** Hand-coded HTNs offer the highest gains, but LLM-generated HTNs also improve performance over baselines.
*   **Strategic Curation:** The curation of procedural expertise from humans, documents, or LLMs is a viable and critical strategy for system improvement.

---

## üß™ Methodology

Researchers formalized and evaluated an agentic LLM workflow using a **Hierarchical Task Network (HTN)** structure to encode procedural knowledge. The study design included the following specific configurations:

*   **Configurations:** Two primary modes were tested‚Äî**Hand-coded HTNs** (human-generated) and **LLM-generated HTNs**.
*   **Baseline Comparison:** These configurations were empirically compared against a baseline condition with no procedural augmentation (No-TN).
*   **Variable Testing:** The study utilized LLMs of varying sizes (20b, 70b, and 120b parameters) to assess whether architectural logic could offset parameter scale.
*   **Evaluation Metrics:** Performance was measured based on success rates on complex tasks, efficiency (runtime/iterations), and error reduction (specifically infinite loops).

---

## üõ† Technical Details

The **ProcLLM** framework integrates explicit procedural knowledge into LLM agents using the following technical specifications:

### Core Architecture
*   **Planning Model:** Hierarchical Task Networks (HTNs) modeled as a finite-horizon deterministic Markov Decision Process (MDP).
*   **Decomposition Strategy:** `FindFirstRelevantMethod` is used to break down complex tasks.
*   **Method Definition:** Methods are defined using the structure: (head, task, pre, subtasks).

### Environment & Workflow
*   **Environment:** File-system based. Key files include `ProblemSpec`, `Request`, `ToolsSpec`, `Notes`, `Solver`, and `Answer`.
*   **Workflow Steps:**
    1.  **Recursive Task Decomposition:** Breaking high-level tasks into subtasks.
    2.  **Action Generation:** An action-LLM generates executable steps.
    3.  **Verification:** A verify-LLM checks domain preconditions before execution.
*   **Capabilities:** The system supports writing arbitrary Python code for tool-use.

---

## üìà Results

Experiments were conducted on four benchmarks: **Travel Planning (TP)**, **Recipe Generator (RG)**, **Blocks World (BW)**, and **Unit Movement (UM)**. The results compared **Human-TN**, **LLM-TN**, and **No-TN** conditions.

### Travel Planning (TP) Highlights
*   **Nemotron 70b:**
    *   With Human-TN: **53.5%** success (Flight 1)
    *   With No-TN: **2.3%** success
*   **GPT-oss 120b:**
    *   With Human-TN: **81.4%** success
    *   With No-TN: **0%** success

### General Performance
*   **Reliability:** Human-TN reduced runtime and iteration counts.
*   **Stability:** The use of HTNs eliminated failure from infinite loops in TP, BW, and UM, demonstrating better complexity scaling.
*   **Comparative:** LLM-TN consistently outperformed No-TN but generally underperformed compared to Human-TN.

---

## üìù Contributions

1.  **Formalized Implementation:** The study provides a formalized implementation of agentic LLM workflows using traditional AI planning concepts (HTNs) to address implicit planning limitations.
2.  **Architecture over Scale:** It validates that architectural enhancements (procedural knowledge) can reduce the need for massive parameter counts.
3.  **New Development Paradigm:** Establishes a new paradigm where the **curation of procedural expertise** is a critical pillar for LLM improvement, standing alongside tool support and prompt engineering.
4.  **Classical AI Integration:** Successfully demonstrates how embedding domain-specific structure (classical AI planning) into modern LLMs reduces computational overhead and improves reliability.