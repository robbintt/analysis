# Generative AI and Creativity: A Systematic Literature Review and Meta-Analysis

*Niklas Holzner; Sebastian Maier; Stefan Feuerriegel*

***

> ### ðŸ“Š Quick Facts
> *   **Quality Score:** 9/10
> *   **Studies Analyzed:** 28
> *   **Total Participants:** 8,214
> *   **Methodology:** Systematic Literature Review (SLR) & Random-Effects Meta-Analysis
> *   **Key Metric:** Hedges' $g$ (Standardized effect size)
> *   **Primary Trade-off:** High Performance vs. Low Diversity

***

## Executive Summary

Generative AI is rapidly permeating creative industries, yet the empirical understanding of its true capabilities and limitations relative to human cognition remains fragmented. This paper addresses the urgent need to quantify the impact of GenAI on creative output, specifically investigating whether these tools function as equivalent replacements for human ingenuity or as effective augmentative instruments.

The research introduces a rigorous quantitative meta-analytical framework adhering to PRISMA 2020 guidelines. The authors employ a random-effects meta-analysis model to account for statistical heterogeneity across different models, tasks, and demographics. Utilizing Hedgesâ€™ $g$ to correct for small-sample bias, the study filters strictly for between-subject experiment designs. Creativity is operationalized through mixed-methods assessment, including standard tasks like the Alternate Uses Task (AUT) and Divergent Association Task (DAT), evaluated via both objective NLP metrics and subjective human ratings.

The meta-analysis reveals three statistically distinct outcomes regarding GenAI's creative efficacy:
1.  **Standalone Parity:** GenAI achieves statistical parity with humans.
2.  **Augmented Performance:** Humans collaborating with GenAI significantly outperform those working alone.
3.  **Diversity Reduction:** AI assistance significantly restricts the breadth of ideation.

This research positions GenAI as a powerful augmentative tool rather than a replacement. By quantifying the trade-off between increased output quality and reduced idea diversity, the study highlights the risk of creative homogenization in AI-assisted workflows.

***

## Key Findings

The study identified several critical insights regarding the performance and impact of Generative AI on creative processes:

*   **Standalone Parity:** GenAI has achieved statistical parity with humans in standalone creative performance, with an effect size of **$g = -0.05$**. This indicates that algorithms can now match average human creative output.
*   **Collaborative Boost:** Humans collaborating with GenAI significantly outperform those working alone, yielding a positive small-to-medium effect size of **$g = 0.27$**.
*   **The Diversity Gap:** The use of GenAI significantly reduces the diversity of ideas generated. This resulted in a large negative effect size of **$g = -0.86$**, suggesting a risk of creative homogenization.
*   **Variable Effectiveness:** The impact of GenAI is not uniform; effectiveness varies significantly across different models, specific task types, and participant demographics.

***

## Methodology & Technical Framework

The research utilizes a quantitative meta-analysis framework based on a systematic literature review.

### Data Sources & Standards
*   **Guidelines:** Adheres to PRISMA 2020 standards.
*   **Databases:** Web of Science, SSRN, and arXiv.
*   **Scope:** English publications from the last five years.
*   **Inclusion Criteria:** Strictly filtered for between-subject experiment designs reporting sufficient statistics.

### Statistical Model
*   **Analysis Type:** Random-effects meta-analysis model to account for heterogeneity.
*   **Effect Size Metric:** Hedges' $g$ (used to correct for small-sample bias).
*   **Sample Size:** 28 studies ($n=28$) with 8,214 total participants ($m=8214$).

### Operationalized Variables
The study evaluated creativity using the following tasks and metrics:

| Task Type | Assessment Method |
| :--- | :--- |
| **Alternate Uses Task (AUT)** | Subjective human ratings & Objective NLP metrics |
| **Consequences Task (CT)** | Subjective human ratings & Objective NLP metrics |
| **Divergent Association Task (DAT)** | Subjective human ratings & Objective NLP metrics |
| **Forward Flow (FF)** | Subjective human ratings & Objective NLP metrics |

***

## Results

The study evaluated performance using Hedges' $g$ effect sizes across three distinct dimensions:

1.  **Standalone GenAI Creativity (GenAI vs. Humans)**
    *   **Result:** $g = -0.05$
    *   **Interpretation:** Indicates statistical parity. GenAI can match average human creative performance without human assistance.

2.  **Human-Augmented Creativity (Humans with AI vs. Humans alone)**
    *   **Result:** $g = 0.27$
    *   **Interpretation:** A positive small-to-medium effect, confirming that AI support acts as a effective augmentation tool for human performance.

3.  **Idea Diversity (Humans with AI vs. Humans alone)**
    *   **Result:** $g = -0.86$
    *   **Interpretation:** A large negative effect, highlighting a significant limitation where GenAI restricts the spectrum and variety of ideas generated.

***

## Contributions

This paper offers several significant contributions to the field of AI and creativity:

*   **Holistic Synthesis:** Provides a comprehensive synthesis of empirical evidence regarding GenAI's impact on creativity, moving beyond qualitative narratives.
*   **Quantified Trade-off:** Explicitly quantifies the trade-off of AI augmentation, noting that while performance increases (*quality*), idea diversity (*exploration*) decreases.
*   **Strategic Positioning:** Positions GenAI as an augmentative tool designed to support human ideation rather than a replacement for it, providing a baseline for future research and practitioner implementation.

**References:** 40 citations