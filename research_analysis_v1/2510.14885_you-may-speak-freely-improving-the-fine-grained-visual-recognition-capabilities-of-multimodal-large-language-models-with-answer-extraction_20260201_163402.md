# You May Speak Freely: Improving the Fine-Grained Visual Recognition Capabilities of Multimodal Large Language Models with Answer Extraction

*Logan Lawrence; Oindrila Saha; Megan Wei; Chen Sun; Subhransu Maji; Grant Van Horn*

---

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Proposed Method** | `nlg2choice` (Answer Extraction) |
| **Focus** | Fine-Grained Visual Classification (FGVC) |
| **Datasets Evaluated** | 7 (e.g., CUB-200-2011, Stanford Cars) |
| **Key Efficiency Gain** | >50% reduction in computational cost |
| **Key Performance Gain** | ~500% relative increase on FGVC Aircraft |
| **Quality Score** | 7/10 |
| **References** | 40 Citations |

---

## üìù Executive Summary

Multimodal Large Language Models (MLLMs) face significant challenges in **Fine-Grained Visual Classification (FGVC)** due to the limitations of the standard Answer Generation (AG) paradigm, which often leads to hallucinations and failures in high-choice scenarios. To address this, the authors introduce `nlg2choice`, an Answer Extraction (AE) framework that decouples visual understanding from label selection. By first generating free-form natural language descriptions and then mapping them to valid class labels using efficient constrained decoding, the method successfully transforms a generative task into a retrieval task. Evaluations across seven standard FGVC datasets demonstrate that `nlg2choice` substantially improves classification accuracy while simultaneously reducing computational costs through early stopping mechanisms.

---

## üîë Key Findings

*   **Performance:** The proposed `nlg2choice` method improves performance on Fine-Grained Visual Classification (FGVC) tasks across **seven different datasets**.
*   **High-Choice Handling:** The approach effectively handles the challenge of high-choice Multiple Choice Questions (MCQs), where choice counts range from **hundreds to thousands** and options are highly related.
*   **Efficiency:** In retrieval-based settings, the use of an **early stopping method** significantly improves throughput by avoiding the computational cost of calculating probabilities over the entire choice set.
*   **Robustness:** The method demonstrates robust performance that holds regardless of how users phrase tasks in natural language (prompt invariance).

---

## üß¨ Methodology

The authors introduce `nlg2choice`, a simple two-stage method designed to bridge open-ended generation with precise classification:

### Stage 1: Open-ended Generation
The Multimodal Large Language Model (MLLM) is prompted with an open-ended question regarding the visual task. It operates with **minimal constraints** to allow for descriptive freedom regarding the image content.

### Stage 2: Constrained Decoding
The output from the first stage is processed using text-only constrained decoding. This stage maps the free-form response to the most likely choice from the **valid label set**.

### Optimization for Retrieval
For retrieval settings, the method employs an **early stopping technique** when computing the probability that the constrained response takes a specific choice. This reduces the computational overhead associated with massive label sets.

---

## ‚öôÔ∏è Technical Details

The paper proposes an **Answer Extraction (AE)** approach named `nlg2choice` as an alternative to standard *Answer Generation (AG)* for MLLMs in Fine-Grained Visual Classification.

**Workflow Architecture:**
1.  **Generation:** Create a free-form natural language description of the image.
2.  **Matching:** Semantically match this description against a set of predefined choices.
3.  **Selection:** Select the choice with the highest similarity.

**Optimization & Design:**
*   **Early Stopping:** Halts calculations once a top candidate's confidence threshold is met, significantly reducing computational cost for large choice sets.
*   **Invariant Architecture:** Designed to be invariant to specific prompt phrasing, ensuring consistency across varied user inputs.

---

## üìà Results

The method was evaluated comprehensively on standard FGVC benchmarks, yielding the following outcomes:

**Accuracy & Performance**
*   Evaluated on seven datasets including **CUB-200-2011**, **Stanford Cars**, and **FGVC Aircraft**.
*   Demonstrated consistent accuracy improvements over standard MLLM baselines.
*   Particularly effective in generating rare or long-tailed class names and distinguishing between fine-grained classes (e.g., a **~500% relative increase on FGVC Aircraft**).

**Efficiency Metrics**
*   Significant gains in inference throughput.
*   Reduced computational overhead by avoiding full choice set processing (cost reduction of **over 50%**).

**Qualitative Analysis**
*   Confirmed qualitative robustness, showing stable performance regardless of prompt phrasing variations.

---

## ‚ú® Contributions

*   **Addressing the FGVC Evaluation Gap:** The research addresses the critical lack of evaluation methods for auto-regressive models in Fine-Grained Visual Classification, distinct from standard language-only or low-choice tasks.
*   **Scalable Choice Extraction:** Provides a viable solution for extending LLM choice extraction to retrieval-based problems with massive choice sets (hundreds to thousands of options), which was previously considered computationally prohibitive.
*   **Robust Zero-Shot Classification:** Validates a framework that maintains high performance in both classification and retrieval metrics while remaining flexible to various natural language prompt implementations.