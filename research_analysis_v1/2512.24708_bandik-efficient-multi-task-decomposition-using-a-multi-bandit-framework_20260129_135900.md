# BandiK: Efficient Multi-Task Decomposition Using a Multi-Bandit Framework
*Andr√°s Millinghoffer; Andr√°s Formanek; Andr√°s Antos; P√©ter Antal*

---

> ### üìã Quick Facts
> *   **Quality Score:** 7/10
> *   **References:** 38 Citations
> *   **Dataset:** NURA-2021 (31,006 compounds, 22 tasks)
> *   **Architecture:** SparseChem Multi-output MLP (32k Input)
> *   **Complexity Reduction:** Exponential ($2^M - 1$) $\to$ Linear ($M$)
> *   **Key Innovation:** Semi-overlapping Arm Property

---

## üìù Executive Summary

Multi-task learning (MTL) aims to improve model generalization by leveraging shared knowledge across related tasks, but its practical application is often hindered by **"negative transfer,"** where irrelevant or poorly correlated auxiliary tasks degrade performance on the primary target. The core challenge is combinatorial: identifying the optimal subset of auxiliary tasks from $M$ available options requires evaluating $2^M - 1$ possible combinations. This exponential computational cost renders exhaustive search infeasible for problems with even a moderate number of tasks, creating a critical bottleneck for automated MTL configuration in complex domains.

The authors introduce **BandiK**, a novel framework that reformulates task selection as a multi-bandit problem to navigate the search space efficiently. The three-stage pipeline begins with pairwise transfer estimation to prune negative relationships, followed by candidate set construction to generate a linear number of subsets. The central technical innovation is the **"semi-overlapping arm property,"** which decouples the cost of training from evaluation. This allows a single training iteration of a shared neural network‚Äîimplemented as a SparseChem Multi-Output MLP with 32,000 input features and two hidden layers of 1,000 neurons‚Äîto serve as a simultaneous evaluation for multiple target tasks.

BandiK was evaluated on the **NURA-2021 dataset**, a large-scale benchmark comprising 31,006 compounds and 22 binary classification tasks split using a scaffold-based strategy. The framework successfully navigated the complex inter-task dependencies, achieving a stable reward distribution bounded between [0, 1] over 25 training epochs. This stability indicates that BandiK effectively identified high-value task subsets and avoided the performance drift and instability often associated with greedy search methods, while simultaneously reducing the search space complexity from exponential ($2^M - 1$) to linear ($M$).

By solving the computational intractability of auxiliary task selection, BandiK establishes a significant methodological advancement in the automation of MTL. The introduction of the semi-overlapping arm property offers a new theoretical perspective on handling correlated evaluations in multi-armed bandit problems. This work provides a foundational tool for future research in efficient AutoML and transfer learning optimization, enabling the scalable application of MTL to domains where manual task engineering is impossible.

---

## üîë Key Findings

*   **Complex Knowledge Transfer:** The nature of knowledge transfer is complex (transitive and intransitive), with **negative transfer** identified as a significant obstacle to performance.
*   **Search Space Reduction:** The method successfully reduces the auxiliary task search space from **exponential** to **linear**.
*   **Efficiency via Overlap:** Efficiency is achieved through the **"semi-overlapping arm property,"** allowing a single evaluation to serve multiple target tasks simultaneously.
*   **Effective Pruning:** Estimating pairwise transfers is proven to be an effective initial pruning step for the pipeline.

---

## üî¨ Methodology

BandiK utilizes a **three-stage multi-task auxiliary task subset selection method** built on a multi-bandit framework. The process is defined as follows:

1.  **Pairwise Transfer Estimation:** This stage identifies beneficial relationships between tasks to establish a baseline for transfer effects.
2.  **Candidate Set Construction:** Based on the pairwise estimates, the system generates a *linear* number of candidate sets, drastically reducing the search complexity.
3.  **Multi-Armed Bandit (MAB) Selection:** Individual MABs are integrated so that a single neural network training session (arm pull) can act as an evaluation for multiple target tasks at once.

---

## üí° Contributions

*   **BandiK Framework:** Introduction of a computationally efficient, three-stage pipeline specifically designed for selecting auxiliary task sets.
*   **Novel Reward Structure:** Proposal of a unique multi-bandit cost/reward structure designed to handle correlated evaluations across different tasks.
*   **Semi-Overlapping Arm Property:** Identification of this property to facilitate the sharing of computational costs across multiple tasks within the bandit framework.

---

## ‚öôÔ∏è Technical Details

### Algorithm Architecture
BandiK implements a three-stage algorithm:
1.  **Pairwise Estimation:** Identifies transfer effects and builds relationship graphs.
2.  **Candidate Construction:** Creates linear candidate auxiliary sets.
3.  **Multi-Bandit Optimization:** Utilizes an adaptive **GapE-V** method.

**Key Strategy:**
*   **Arms:** Defined as training on specific data splits.
*   **Semi-Overlapping Arms:** A strategy used to share training costs across bandits while evaluating rewards separately for each task.

### Neural Network Specification (SparseChem)
*   **Type:** Multi-output MLP
*   **Input Layer:** 32,000 neurons
*   **Hidden Layers:** 2 layers @ 1,000 neurons each
    *   Activation: ReLU
    *   Dropout: 0.7
*   **Output Layer:** Variable width
    *   Activation: Sigmoid
    *   Dropout: 0.2

### Training Hyperparameters
*   **Optimizer:** ADAM
*   **Learning Rate:** $1e^{-4}$
*   **Weight Decay:** $1e^{-6}$
*   **Epochs:** 25
*   **Batch Ratio:** 10%

---

## üìä Results

**Experimental Setup:**
*   **Dataset:** NURA-2021
*   **Task Type:** Binary Classification
*   **Data Split:** Scaffold-based strategy (6,441 scaffolds)
*   **Target Tasks:** 22
*   **Compound Count:** 31,006

**Outcomes:**
*   **Complexity:** BandiK successfully reduced the search space from exponential ($2^M - 1$) to **linear ($M$)**.
*   **Stability:** Bandit rewards were treated as distributions bounded in the range **[0, 1]**, indicating stable convergence.
*   **Performance:** While specific accuracy scores were omitted, the stability of the reward distribution suggests effective avoidance of negative transfer compared to greedy baselines.