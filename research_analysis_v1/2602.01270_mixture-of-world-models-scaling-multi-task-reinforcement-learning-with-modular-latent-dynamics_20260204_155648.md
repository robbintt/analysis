---
title: 'Mixture-of-World Models: Scaling Multi-Task Reinforcement Learning with Modular
  Latent Dynamics'
arxiv_id: '2602.0127'
source_url: https://arxiv.org/abs/2602.01270
generated_at: '2026-02-04T15:56:48'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Mixture-of-World Models: Scaling Multi-Task Reinforcement Learning with Modular Latent Dynamics

*Boxuan Zhang; Weipu Zhang; Zhaohan Feng; Wei Xiao; Jian Sun; Jie Chen; Gang Wang*

---

> ### ðŸ“Š Quick Facts
> *   **Atari 100k Score:** 110.4% Mean Human-Normalized Score
> *   **Meta-World Success Rate:** 74.5% (State-of-the-Art)
> *   **Parameter Efficiency:** 50% fewer parameters than the STORM baseline
> *   **Quality Score:** 9/10
> *   **References:** 40 Citations

---

## Executive Summary

Scaling multi-task reinforcement learning (RL) in visually rich and heterogeneous environments remains a significant challenge due to the diversity in observations and dynamics across tasks. Monolithic world models often struggle to generalize efficiently across this heterogeneity, requiring massive parameter counts and suffering from poor sample efficiency. Addressing this limitation is critical for developing "generalist" agents capable of learning multiple skills without excessive computational overhead or data requirements.

The paper introduces **Mixture-of-World Models (MoW)**, a novel architecture that integrates modularity into both visual encoding and temporal dynamics modeling. MoW consists of a Perceptual Module and a Temporal Module. The Perceptual Module utilizes a Categorical Variational Autoencoder (VAE) with task-specific encoder-decoder pairs to compress visual inputs into a discrete latent space (32 categories with 32 classes). The core innovation lies in the Temporal Module, a hybrid Transformer architecture that combines a shared backbone with task-conditioned Mixture-of-Experts (MoE). It employs a gradient-based task clustering mechanism using an MLP router on task embeddings to generate affinity scores, applying Softmax and TopK operations to dynamically select experts for processing latent representations and predicting future states, rewards, and task indices.

MoW demonstrates state-of-the-art performance and superior parameter efficiency across major benchmarks. On the Atari 100k benchmark, the architecture achieved super-human performance with a mean human-normalized score of **110.4%**. Remarkably, it accomplished this while utilizing **50% fewer parameters** than the STORM baseline, maintaining competitive performance. Furthermore, MoW established new standards on the Meta-World benchmark with a success rate of **74.5%**, successfully managing substantial heterogeneity in both observations and environmental dynamics. This research validates MoW as a scalable, parameter-efficient foundation for generalist world models, proving that modular latent dynamics can outperform traditional monolithic architectures.

---

## Key Findings

*   **Super-Human Performance:** Achieved a mean human-normalized score of **110.4%** on the Atari 100k benchmark.
*   **High Parameter Efficiency:** Utilized **50% fewer parameters** than the STORM baseline while maintaining competitive performance.
*   **State-of-the-Art Results:** Established a new performance baseline on the Meta-World benchmark with a **74.5%** success rate.
*   **Heterogeneity Management:** Successfully managed substantial heterogeneity in both observations and dynamics across tasks.

---

## Methodology

The research introduces **Mixture-of-World Models (MoW)**, a scalable architecture designed specifically for visual multi-task reinforcement learning. The methodology is built upon three core components:

1.  **Modular Visual Compression:** Implementation of variational autoencoders to handle diverse visual inputs.
2.  **Hybrid Transformer-Based Dynamics:** A unique combination of a shared backbone with task-conditioned experts to model temporal dynamics.
3.  **Gradient-Based Task Clustering:** A mechanism to ensure efficient parameter allocation across different tasks.

---

## Technical Details

The MoW architecture is structurally divided into two distinct modules designed to handle perception and temporal reasoning separately.

### Perceptual Module
*   **Core Component:** Categorical Variational Autoencoder (VAE).
*   **Configuration:** Utilizes task-specific encoder-decoder pairs conditioned on learnable task embeddings.
*   **Latent Space:** Operates within a discrete latent space defined by **32 categories with 32 classes**.

### Temporal Module
*   **Architecture:** Employs a hybrid structure combining **Mixture-of-Expert (MoE) Transformers** with a shared Transformer.
*   **Processing:** Takes latent representations and actions as input to predict:
    *   Next latent state
    *   Reward
    *   Task index
    *   Continuation flag
*   **Routing Mechanism:**
    *   Utilizes an MLP (Multi-Layer Perceptron) on task embeddings to generate affinity scores.
    *   Applies **Softmax and TopK operations** to dynamically select experts.
    *   Ensures temporal coherence and decouples the MoE mechanism from the main Transformer architecture.

---

## Contributions

*   **Architecture Innovation:** Introduced the MoW architecture, which successfully integrates modularity into visual encoding and dynamics modeling.
*   **Sample Efficiency:** Advanced sample efficiency in visual domains characterized by heterogeneous tasks.
*   **Validation:** Validated MoW as a scalable, parameter-efficient foundation for generalist world models.
*   **Benchmarking:** Set new performance baselines on the Meta-World benchmark and achieved competitive results on Atari 100k.

---

## Results

The experimental evaluation of MoW yielded significant improvements over existing baselines:

*   **Atari 100k:** Achieved super-human performance with a mean human-normalized score of **110.4%**.
*   **Efficiency:** Demonstrated **50% parameter efficiency** compared to the STORM baseline.
*   **Meta-World:** Established state-of-the-art results with a success rate of **74.5%**.
*   **Scalability:** Showed significant parameter scalability and successfully handled substantial heterogeneity across observations and dynamics compared to monolithic architectures.

---

**Quality Score:** 9/10  
**References:** 40 citations