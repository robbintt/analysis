# On the Complexity of Global Necessary Reasons to Explain Classification
*Marco Calautti; Enrico Malizia; Cristian Molinaro*

---

> ### üìä Quick Facts
>
> | Metric | Details |
> | :--- | :--- |
> | **Quality Score** | 8/10 |
> | **References** | 7 Citations |
> | **Focus** | Global Explainable AI (XAI) |
> | **Classifiers Analyzed** | BDDs, Perceptrons, MLPs |
> | **Methodology** | Theoretical / Complexity Analysis |
> | **Key Complexity Classes** | L, NL, $\Sigma_2^p$-complete |

---

## üìù Executive Summary

This paper addresses the computational feasibility of generating global explanations for binary classifiers, a critical challenge in Explainable AI (XAI). While local explanations clarify individual predictions, global explanations aim to describe a classifier‚Äôs overall behavior across the entire input space. The core problem is that extracting "global necessary reasons"‚Äîdefined as the minimal conditions required for a classifier to assign a specific class‚Äîcan be computationally prohibitive.

Establishing the precise complexity boundaries is essential for determining whether global explainability is theoretically achievable and practical for deployment, distinguishing between problems that are efficiently solvable and those that are computationally intractable. The key innovation is a rigorous formalization and complexity-theoretic analysis of explanation extraction across three major families of classifiers: Binary Decision Diagrams (BDDs), Perceptrons (PRC), and Multi-Layer Perceptrons (MLPs).

The authors propose a logical framework where explanations are conjunctions of literals in a language $L[n]$, evaluated against two natural minimality preorders: subset-based ($\subseteq$) and size-based ($\leq$). A significant technical breakthrough establishes that minimality checking does not require the expensive verification of exponential subsets. Instead, the authors prove that checking minimality is equivalent to verifying a linear number of single literals (**Theorem 4.1**).

This finding renders the two criteria equivalent in practice and enables the design of a generic algorithmic framework that significantly simplifies the search for global reasons. The study delivers precise complexity classifications for explanation verification tasks across different model architectures:

*   **Perceptrons:** Both checking necessary reasons and verifying minimality are classified within Complexity Class **L** (Logarithmic Space), indicating highly efficient solvability.
*   **Binary Decision Diagrams (BDDs):** Checking non-necessity is placed in **NL** (Nondeterministic Logarithmic Space).
*   **Multi-Layer Perceptrons (MLPs):** The problem is classified as **$\Sigma_2^p$-complete**, establishing it as intractable in the general case.

The research quantifies the reduced computational cost for tractable cases, demonstrating that minimality checking is reduced to a complexity of $O(n^2)$ by examining individual literals rather than candidate subsets. This work significantly advances the theoretical underpinnings of XAI by mapping the computational landscape of global explainability.

---

## üîë Key Findings

*   **Focus on Global vs. Local**
    The study addresses global explanations (explaining a classifier's overall behavior) rather than local explanations.
*   **Definition of Explanations**
    The paper characterizes explanations as **'minimal' necessary conditions** for a classifier to assign a specific class.
*   **Complexity Assessment**
    The research identifies that computational difficulty varies based on minimality criteria and classifier family.

---

## üî¨ Methodology

**Theoretical Analysis**
The authors employ a formal, theoretical approach rather than an empirical one.

**Computational Complexity Theory**
The core method involves conducting a thorough complexity analysis to determine feasibility.

**Comparative Evaluation**
The analysis evaluates the problem across 'natural' minimality criteria and established families of classifiers.

---

## üß† Contributions

*   **Formalization of Global Explanations**
    Establishes a formal definition for global explanations based on minimal necessary conditions, advancing theoretical understanding.
*   **Complexity Classification**
    Provides a comprehensive complexity analysis mapping computational boundaries and challenges for different classifiers.

---

## ‚öôÔ∏è Technical Details

**Scope and Domain**
*   **Target:** Global Explainable AI (XAI) for binary classifiers.
*   **Classifier Families:** Binary Decision Diagrams (BDDs), Perceptrons (PRC), and Multi-Layer Perceptrons (MLPs).
*   **Input Space:** Binary instances $\{0, 1\}^n$.

**Logical Framework**
*   **Language:** Explanations are expressed in a logical language $L[n]$ consisting of conjunctions of literals (supporting equalities/inequalities between variables).
*   **Objective:** Derive 'global necessary reasons'.

**Minimality Criteria**
Minimality is assessed using:
1.  Size-based preorder ($\leq$)
2.  Subset-based preorder ($\subseteq$)

**Theoretical Breakthroughs**
*   **Theorem 4.1:** Establishes that minimality checking requires only verifying single literals rather than exponential subsets.
*   **Algorithmic Framework:**
    *   *Algorithm 1:* Generic framework for minimality.
    *   *Algorithm 2:* Non-deterministic procedure specifically for BDDs.

---

## üìà Results

The primary results are computational complexity classifications for explanation tasks across the analyzed classifiers:

### Perceptrons (PRC)
*   **Task:** Checking necessary reasons (`IsNecessary[PRC]`) and minimality (`IsMinNessary[PRC]`).
*   **Complexity Class:** **L** (Logarithmic Space).
*   **Implication:** Highly efficient solvability.

### Binary Decision Diagrams (BDDs)
*   **Task:** Checking non-necessity.
*   **Complexity Class:** **NL** (Nondeterministic Logarithmic Space).
*   **Method:** Decidable by a nondeterministic procedure using logarithmic space.

### Multi-Layer Perceptrons (MLPs)
*   **Complexity Class:** **$\Sigma_2^p$-complete** (Intractable in the general case).

### General Theoretical Findings
*   **Equivalence:** The equivalence of $\leq$-minimality and $\subseteq$-minimality.
*   **Optimization:** A characterization that reduces minimality checking complexity to **$O(n^2)$** by examining individual literals.