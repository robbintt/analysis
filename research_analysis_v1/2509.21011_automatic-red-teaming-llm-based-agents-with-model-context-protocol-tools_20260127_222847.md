---
title: Automatic Red Teaming LLM-based Agents with Model Context Protocol Tools
arxiv_id: '2509.21011'
source_url: https://arxiv.org/abs/2509.21011
generated_at: '2026-01-27T22:28:47'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Automatic Red Teaming LLM-based Agents with Model Context Protocol Tools

*Authors: Automatic Red, Changjiang Li, Protocol Tools, Large Language, Context Protocol, Model Context, Tianyu Du, Binbin Zhao, Ping He, Shouling Ji*

---

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **Citations** | 40 References |
| **Tools Evaluated** | 53 tools across three MCP servers |
| **Top Success Rate (GSR)** | 93.1% on Alpaca server |
| **Primary Attack Vectors** | Incorrect Parameter Invocation (IPI), Output Result Manipulation (ORM) |
| **Critical Defense Targets** | MCP-Scan, A.I.G. |

---

## üìã Executive Summary

> **Overview:** This research addresses a critical security vulnerability in Large Language Model (LLM)-based agents that utilize external tools via the Model Context Protocol (MCP). As agents increasingly rely on these tools to interact with the real world, they become susceptible to **"Tool Poisoning Attacks,"** where malicious actors manipulate tool definitions to induce harmful behaviors in black-box scenarios.

**Core Problem & Attack Vectors:**
The paper identifies two primary attack vectors that subvert agent control, even when the underlying LLM is secure:
*   **Incorrect Parameter Invocation (IPI):** Tricks agents into executing commands with unintended arguments.
*   **Output Result Manipulation (ORM):** Alters data returned to the agent to deceive it.

**Proposed Solution (AutoMalTool):**
The authors introduce **AutoMalTool**, a multi-agent red-teaming framework designed to automatically discover and optimize exploits. The system utilizes:
*   **Four Core Components:** An Initial Generator, an Oracle (Evasiveness Evaluator), an Effectiveness Evaluator, and a Tool Optimizer.
*   **Failure Analysis:** A "Failure Reasoner" analyzes why an attack failed (e.g., safety refusals) and iteratively adjusts the malicious description.
*   **Stealth Technique:** Uses **Unicode Token Manipulation** to obfuscate malicious intent, bypassing semantic detectors while remaining executable by the backend.

**Conclusion:**
The study establishes that model sophistication does not equate to security (e.g., GPT-4o was more susceptible than GPT-4-turbo in some tests). It signals an urgent need for dynamic, runtime-based security protocols rather than relying on static defenses.

---

## üîë Key Findings

*   **No Abstract Available:** No key findings could be extracted as the abstract was not provided.
*   **Security Disconnect:** Higher model sophistication does not guarantee better security resistance.
*   **Evasion Capabilities:** AutoMalTools successfully evaded State-of-the-Art (SOTA) detectors.
*   **Attack Efficacy:** Incorrect Parameter Invocation (IPI) was generally more successful than Output Result Manipulation (ORM).

---

## üõ† Technical Details

**Framework: AutoMalTool**
A multi-agent framework for the automatic red teaming of LLM-based agents using MCP tools.

**System Architecture:**
1.  **Initial Generator:** Extracts tool information and generates malicious tasks.
2.  **Oracle (Evasiveness Evaluator):** Filters tools based on detection mechanisms to ensure bypass capabilities.
3.  **Effectiveness Evaluator:** Tests tools in a simulated environment using a Behavior Judger.
4.  **Tool Optimizer:** Refines tools using a Failure Reasoner to improve success rates.

**Operational Algorithm:**
1.  Iteratively generates malicious descriptions.
2.  Checks for **evasiveness** (can it bypass detectors?).
3.  Checks for **effectiveness** (does it work in the sim environment?).
4.  Optimizes the tool until it passes both checks.

**Target & Technique:**
*   **Scenario:** Tool Poisoning Attacks in a black-box scenario.
*   **Technique:** Unicode Token Manipulation (facilitates attacks by evading semantic detection).

---

## üìà Results

**Evaluation Scope:**
*   **Tools:** 53 tools across Alpaca, WhatsApp, and Filesystem MCP servers.
*   **Target Agents:** Claude Desktop, Cline.
*   **Target Models:** Claude Opus 4.1, DeepSeekV3.1, GPT-4.1, GPT-5-chat-latest.
*   **Defenses:** MCP-Scan, A.I.G.

**Performance Metrics:**
*   **Generation Success Rate (GSR):**
    *   Alpaca: **93.1%**
    *   WhatsApp: **89.7%**
    *   Filesystem: **72.3%**
*   **Effective Success Rate (ESR):**
    *   **Peak Performance:** Cline (GPT-5-chat-latest) reached **78.3%** on WhatsApp; Claude Desktop (Claude Opus 4) reached **71.4%** on Alpaca.
    *   **IPI vs. ORM:** IPI was generally more successful. ORM results were lower (e.g., 33.3% for Claude Opus 4.1).

**Operational Analysis:**
*   **Iterations:** Successful attacks converged within **1‚Äì6 optimization iterations**.
*   **Overhead:** Costs and time correlated with server complexity.

---

## üìù Methodology & Contributions

**Methodology**
*   *No methodology description could be extracted as the abstract was not provided.*

**Contributions**
*   *No contributions could be extracted as the abstract was not provided.*