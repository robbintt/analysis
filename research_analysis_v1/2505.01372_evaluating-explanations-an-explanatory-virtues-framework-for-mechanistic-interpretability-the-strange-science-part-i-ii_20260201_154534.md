# Evaluating Explanations: An Explanatory Virtues Framework for Mechanistic Interpretability -- The Strange Science Part I.ii

*Kola Ayonrinde; Louis Jaburi*

---

> ### **Quick Facts**
>
> *   **Quality Score:** 8/10
> *   **References:** 37 citations
> *   **Core Contribution:** A pluralist Explanatory Virtues Framework.
> *   **Key Validation:** Theoretical validation of Compact Proofs.
> *   **Primary Goal:** Establishing a universal standard for evaluating causal explanations in Mechanistic Interpretability (MI).

---

## Executive Summary

The field of Mechanistic Interpretability (MI) currently faces a fundamental epistemological crisis: the absence of a universal standard for evaluating the quality of causal explanations. Without rigorous metrics to determine what constitutes a "good" explanation, researchers struggle to verify that internal circuit analyses genuinely reflect model behavior rather than merely correlating with it. This lack of evaluative rigor acts as a primary constraint on scientific progress, preventing the field from developing unified theories and limiting the ability of safety engineers to monitor, predict, and steer advanced AI systems effectively.

To resolve this, the authors introduce a **"pluralist Explanatory Virtues Framework"** grounded in the philosophy of science, synthesizing Bayesian, Kuhnian, Deutschian, and Nomological perspectives. Technically, the framework evaluates MI explanations as scientific theories by mandating four validity criteria: Model-level, Ontic, Causal-Mechanistic, and Falsifiable. It decomposes explanatory virtues into Empirical Virtues (Accuracy) and Theoretical Virtues (Precision). Accuracy is further broken down into Descriptiveness and Co-Explanation, while Precision is decomposed into Power and Unification. This structure enables the systematic qualitative analysis of explanation-generating methods against established philosophical standards.

The framework was applied to analyze four prominent MI methods: Clustering, Sparse Autoencoders (SAEs), Causal Circuit Analysis, and Compact Proofs. The analysis revealed that current dominant approaches frequently neglect critical virtues, specifically Simplicity, Unification, Co-Explanation, and Nomological consistency. In contrast, Compact Proofs were theoretically validated as a highly potent approach that inherently satisfies multiple explanatory virtues. The study defines seven specific metrics for future evaluation pipelines: Accuracy, Precision, Descriptiveness, Co-Explanation, Power, Unification, and Simplicity, providing a concrete rubric for assessing interpretability research.

This research establishes a vital bridge between philosophical rigor and AI safety engineering by offering a standardized approach to validate interpretability methods. By shifting the focus from isolated, ad-hoc analyses to unifying explanations and universal principles, the framework provides a roadmap for maturing MI into a robust scientific discipline. The identification of "Compact Proofs" as a superior method and the imperative to define "explanatory simplicity" offer immediate, actionable direction for researchers. Ultimately, this work is significant because it provides the evaluative infrastructure necessary to trust that interpretability techniques can yield the reliable insights required for AI alignment.

---

## Key Findings

*   **Promise of Compact Proofs:** Identified as a highly promising approach within Mechanistic Interpretability (MI) because they inherently satisfy multiple explanatory virtues.
*   **Unification Principles:** Effective explanations should focus on unifying distinct phenomena and deriving universal principles applicable to neural networks.
*   **Defining Simplicity:** There is a critical need to clearly define "explanatory simplicity" to advance the evaluation of MI explanations.
*   **Evaluation Standard:** Progress in MI is currently constrained by the absence of a universal standard for evaluating the quality of causal explanations.

---

## Methodology

The study employed the following approaches to develop and test the framework:

1.  **Philosophical Synthesis:** Development of a "pluralist Explanatory Virtues Framework" by integrating four perspectives from the Philosophy of Science:
    *   Bayesian
    *   Kuhnian
    *   Deutschian
    *   Nomological
2.  **Systematic Evaluation & Qualitative Analysis:** The framework was utilized to assess existing explanation-generating methods in MI, specifically highlighting Compact Proofs, to determine what constitutes a good explanation.

---

## Technical Details

### The Explanatory Virtues Framework
The paper proposes a framework to evaluate MI explanations as scientific theories. A valid MI explanation must satisfy four specific validity criteria:

*   **Model-level**
*   **Ontic**
*   **Causal-Mechanistic**
*   **Falsifiable**

### Decomposition of Virtues
The framework decomposes concepts hierarchically to provide granular evaluation metrics:

**1. Bayesian Concepts**
*   **Theoretical Virtues:** Focused on Precision (distinct from ML Precision).
    *   *Decomposed into:* Power, Unification.
*   **Empirical Virtues:** Focused on Accuracy.
    *   *Decomposed into:* Descriptiveness, Co-Explanation.

**2. Key Metrics for Evaluation**
*   Accuracy
*   Precision
*   Descriptiveness
*   Co-Explanation
*   Power
*   Unification
*   Simplicity

### Analyzed Methods
The framework was used to analyze the following MI techniques:
*   Clustering
*   Sparse Autoencoders (SAEs)
*   Causal Circuit Analysis
*   Compact Proofs

---

## Results

The application of the framework yielded the following outcomes:

*   **Analysis of Current Methods:** The framework analyzed Clustering, Sparse Autoencoders (SAEs), Causal Circuit Analysis, and Compact Proofs.
*   **Identified Gaps:** Current MI methods frequently neglect **Simplicity**, **Unification**, **Co-Explanation**, and **Nomological virtues**.
*   **Validation of Compact Proofs:** Highlighted as a promising approach that aligns well with good explanation criteria.
*   **Metrics Definition:** Established key metrics (Accuracy, Precision, Descriptiveness, etc.) for future evaluation pipelines.

---

## Contributions

*   **Explanatory Virtues Framework:** Introduction of a novel, universal framework for evaluating explanations in MI grounded in the philosophy of science.
*   **Research Roadmap:** Proposal of three specific research directions: defining explanatory simplicity, focusing on unifying explanations, and deriving universal principles.
*   **Validation of Compact Proofs:** Theoretical validation of Compact Proofs as a potent method that aligns with good explanation criteria.
*   **Safety Implications:** Establishing a link between improved MI evaluation and the ability to monitor, predict, and steer AI systems, contributing to AI safety.