# Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering

*Yuyang Hong; Jiaqi Gu; Qi Yang; Lubin Fan; Yue Wu; Ying Wang; Kun Ding; Shiming Xiang; Jieping Ye*

---

> ### ‚ö° Quick Facts
> *   **Proposed Model:** Wiki-PRF
> *   **Base Model:** Qwen2.5-VL-7B
> *   **Key Innovation:** 3-Stage RAG Pipeline (Processing, Retrieval, Filtering)
> *   **Training Method:** Reinforcement Learning (Answer & Format Rewards)
> *   **Top Score - E-VQA:** 36.0
> *   **Top Score - InfoSeek:** 42.8
> *   **References:** 40 citations
> *   **Quality Score:** 9/10

---

## üìë Executive Summary

Knowledge-based Visual Question Answering (KB-VQA) requires models to answer questions about images by integrating visual perception with external knowledge, a task that often suffers from the "hallucination" inherent in large Vision Language Models (VLMs). While Retrieval-Augmented Generation (RAG) offers a solution by fetching relevant information, standard RAG pipelines struggle to generate precise queries from complex visual inputs and often retrieve noisy, irrelevant documents. This creates a critical gap where models fail to reason effectively because they lack accurate, context-aware knowledge retrieval, limiting the reliability of VLMs in real-world applications requiring factual accuracy.

The researchers introduce Wiki-PRF, a novel three-stage multimodal RAG framework designed to optimize knowledge retrieval through dynamic tool use and relevance filtering. Technically, the framework comprises a Processing stage where a policy model agent dynamically invokes visual tools‚Äîsuch as captioning, grounding, and flipping‚Äîto extract fine-grained visual features. This is followed by a Retrieval stage that integrates these refined visual features with text queries to search a knowledge base, and a Filtering stage where the agent actively removes irrelevant content. A key technical distinction is the use of Reinforcement Learning (RL) to train the policy model; by utilizing reward signals based on answer accuracy and format consistency, the model learns to optimize its reasoning capabilities and tool invocation strategies more effectively than standard supervised methods.

Wiki-PRF achieved state-of-the-art performance on two primary KB-VQA benchmarks, demonstrating the efficacy of the RL-trainable pipeline. specifically, the model scored 36.0 on the E-VQA dataset and 42.8 on the InfoSeek dataset. Beyond raw accuracy, the experiments confirmed significant improvements in the model's reasoning capabilities, the precision of its tool invocation, and its ability to filter out irrelevant noise compared to baseline methods.

This work significantly advances the field of multimodal AI by demonstrating that VLMs can effectively act as policy agents to manage their own retrieval pipeline. By successfully applying reinforcement learning to the RAG process, the study establishes a new paradigm for mitigating hallucinations and improving factual consistency in vision-language tasks. The Wiki-PRF framework provides a robust blueprint for future research into "agentic" AI systems, where models dynamically select tools and filter information to solve complex, knowledge-intensive problems.

---

## üîç Key Findings

*   **State-of-the-Art Performance:** Wiki-PRF achieved leading results on benchmark datasets for knowledge-based visual question answering.
*   **Quantitative Improvements:** The model demonstrated significant score improvements, achieving **36.0** on the E-VQA dataset and **42.8** on the InfoSeek dataset.
*   **Effective RL Training:** The reinforcement learning training approach successfully enhanced the model's reasoning capabilities, tool invocation accuracy, and ability to filter irrelevant content. This was achieved by utilizing answer accuracy and format consistency as specific reward signals.

---

## üß† Methodology

The researchers proposed **Wiki-PRF**, a three-stage method designed to improve Retrieval-Augmented Generation (RAG) for KB-VQA tasks.

1.  **Processing Stage:** Dynamically invokes visual tools to extract precise multimodal information.
2.  **Retrieval Stage:** Integrates visual and text features to perform multimodal knowledge retrieval.
3.  **Filtering Stage:** Eliminates noise through relevance filtering.

A Visual Language Model (VLM) is optimized using a reinforcement learning framework with reward signals derived from answer accuracy and format consistency.

---

## ‚öôÔ∏è Technical Details

Wiki-PRF is a three-stage multimodal Retrieval-Augmented Generation (RAG) pipeline for Knowledge-based VQA. The system architecture consists of the following components:

*   **Core Components:**
    *   Knowledge Base
    *   Base VLM (Qwen2.5-VL-7B)
    *   Policy Model (VLM-PRF)

*   **Stage 1: Processing**
    *   Utilizes VLM-PRF as a policy agent.
    *   Dynamically invokes tools for fine-grained retrieval:
        *   **Captioning**
        *   **Grounding**
        *   **Flipping**

*   **Stage 2: Retrieval**
    *   Searches the Knowledge Base using refined visual and text queries generated in Stage 1.

*   **Stage 3: Filtering**
    *   Utilizes VLM-PRF to identify and remove irrelevant content from the retrieved information.

*   **Training Mechanism:**
    *   The model is trained using **Reinforcement Learning (RL)**.
    *   Reward signals are derived from two sources:
        *   **Answer Reward**
        *   **Format Reward**

---

## ‚ú® Contributions

*   **Framework Introduction:** Introduced the Wiki-PRF framework, a three-stage architecture that addresses limitations in multimodal query quality and result relevance.
*   **Retrieval Methodology:** Developed an enhanced multimodal retrieval methodology using dynamic tool invocation and visual-text feature integration.
*   **Training Strategy:** Created an advanced reinforcement learning training strategy for VLMs that utilizes accuracy and format consistency rewards to improve complex reasoning and filtering.

---

## üìä Results

Wiki-PRF achieved state-of-the-art performance on the E-VQA benchmark with a score of **36.0** and on the InfoSeek benchmark with a score of **42.8**.

Experimental results also indicate notable improvements in:
*   Reasoning capabilities
*   Tool invocation accuracy
*   Content filtering effectiveness

---