---
title: 'ThreatGPT: An Agentic AI Framework for Enhancing Public Safety through Threat
  Modeling'
arxiv_id: '2509.05379'
source_url: https://arxiv.org/abs/2509.05379
generated_at: '2026-02-03T07:06:10'
quality_score: 8
citation_count: 30
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# ThreatGPT: An Agentic AI Framework for Enhancing Public Safety through Threat Modeling

*Sharif Noor Zisad; Ragib Hasan*

---

### üìã Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 30 Citations |
| **Core Technology** | Agentic AI, Few-Shot Learning |
| **Key Frameworks** | STRIDE, MITRE ATT&CK, CVE, NIST, CISA |

---

> ### üí° Executive Summary
>
> Cybersecurity threat modeling is essential for protecting public safety infrastructure, yet it remains an inaccessible discipline largely reserved for security experts. This specialization creates a dangerous gap: non-technical stakeholders, such as system architects and public safety officials, are often unable to identify potential vulnerabilities during the critical design and deployment phases. Consequently, critical systems may be deployed with inadequate security postures because the technical barrier to entry for rigorous threat analysis is too high, leaving public safety assets vulnerable to exploitation.
>
> To address this, the authors introduce **ThreatGPT**, an "agentic" AI framework designed to function as an autonomous assistant for security analysis. Unlike static tools that require manual querying, this agentic system actively manages the threat modeling workflow by utilizing a Unified Integration Layer to synthesize disparate security standards‚Äîincluding STRIDE, MITRE ATT&CK, CVE reports, NIST, and CISA‚Äîinto a single interface.
>
> Technically, the framework employs **Few-Shot Learning** techniques on Large Language Models (LLMs) to process natural language descriptions of system components. This allows the AI to autonomously map user inputs to relevant security frameworks, generate detailed threat models, trace exploit vectors, and propose mitigation strategies without requiring the user to navigate complex technical databases. The study validates the framework‚Äôs efficacy through qualitative evaluation. ThreatGPT establishes a foundational architecture for integrating agentic AI into public safety infrastructure, shifting threat modeling from a siloed expert task to a collaborative, design-phase process.

---

## üîë Key Findings

*   **Development of an Agentic AI Assistant (ThreatGPT):** Created to assist non-experts in analyzing security threats within public safety systems.
*   **Integration of Multiple Security Frameworks:** Combines STRIDE, MITRE ATT&CK, CVE reports, NIST, and CISA into a single, user-selectable interface.
*   **Implementation of Few-Shot Learning:** Generates context-aware threat models from minimal user input.
*   **Comprehensive Threat Visualization:** Highlights system failures, explains exploit vectors, and suggests actionable prevention strategies.

---

## üõ†Ô∏è Technical Details

*   **System Architecture:** Agentic AI Framework (ThreatGPT).
*   **Unified Integration Layer:** Consolidates diverse security databases (STRIDE, MITRE ATT&CK, CVE Reports, NIST & CISA) into one cohesive interface.
*   **Machine Learning Technique:** Utilizes Few-Shot Learning to generate context-aware models from sparse data.
*   **Visualization Component:** Designed to identify system failures, trace exploit vectors, and generate prevention strategies.

---

## üìä Methodology

The methodology involves creating an 'agentic' AI assistant that bridges the gap between technical cybersecurity data and non-technical users using natural language processing and machine learning. The process allows users to:

1.  Describe system components in natural language.
2.  Select specific security frameworks to tailor the analysis.
3.  Utilize few-shot learning algorithms to process inputs.
4.  Generate smart threat models for various public safety scenarios.

---

## üèÜ Contributions

*   **Democratization of Cybersecurity Analysis:** Lowers the barrier to entry for threat modeling, enabling non-experts to perform security analyses.
*   **Human-AI Collaboration for Public Safety:** Combines AI computational power with human judgment for critical infrastructure contexts.
*   **Automated and Adaptive Security Mitigation:** Provides threat identification, mitigation strategies, and explanations of attack vectors to enhance response speed and confidence.

---

## üìà Results

The provided text does not include specific quantitative metrics. However, qualitative results indicate:

*   **Non-Expert Usability:** The framework assists non-experts in analyzing security threats effectively.
*   **Learning Efficiency:** Validates Few-Shot Learning efficiency by generating comprehensive models from minimal input.
*   **Context Awareness:** Demonstrates the ability to correlate user-specific scenarios with integrated security frameworks.