# GreedyPixel: Fine-Grained Black-Box Adversarial Attack Via Greedy Algorithm

*Hanrui Wang; Ching-Chun Chang; Chun-Shien Lu; Christopher Leckie; Isao Echizen*

---

> ### üìã Quick Facts
> *   **Quality Score:** 9/10
> *   **Citations:** 40
> *   **Datasets:** CIFAR-10, ImageNet
> *   **Query Budget:** 20,000
> *   **Threat Model:** $L_\infty$ ($\epsilon = 4/255$)
> *   **Sparsity:** 1% (CIFAR-10), 0.1% (ImageNet)

---

## üìë Executive Summary

This research addresses the fundamental tension between practicality and precision in black-box adversarial attacks. While black-box attacks are critical for real-world security evaluations where internal model gradients are inaccessible, existing methods often fail to match the perturbation efficiency and success rates of white-box attacks. GreedyPixel bridges this gap by introducing a fine-grained, gradient-free attack strategy that utilizes a novel greedy optimization algorithm.

Unlike traditional score-based or transfer-based attacks, GreedyPixel employs a brute-force-style, per-pixel search guided by a priority map derived from a surrogate model. This iteratively selects and evaluates pixel coordinates based on query feedback to maximize adversarial loss. The algorithm is theoretically robust, guaranteeing monotonic loss reduction and convergence to a coordinate-wise optimum while maintaining strict pixel-wise sparsity. Validated against a wide range of modern architectures‚Äîincluding CNNs and Vision Transformers‚ÄîGreedyPixel sets a new standard for gradient-free optimization, proving that black-box attacks can achieve the precision previously thought exclusive to white-box methods.

---

## üîç Key Findings

*   **State-of-the-Art Performance:** Achieved superior results on CIFAR-10 and ImageNet, surpassing existing methods (e.g., Square, BruSLe) across both CNNs and Vision Transformers.
*   **Bridged the Gap:** Successfully closes the distance between the practicality of black-box attacks and the high precision of white-box attacks.
*   **High Visual Quality:** Produces perturbations that are visually imperceptible, validating high quality via the Learned Perceptual Image Patch Similarity (LPIPS) metric.
*   **Optimization Guarantees:** Ensures monotonic loss reduction and guarantees convergence to a coordinate-wise optimum.
*   **Sparse Perturbations:** Maintains pixel-wise sparsity by modifying only a minimal subset of pixels.

---

## üß™ Methodology

GreedyPixel employs a fine-grained, gradient-free black-box attack strategy relying on a greedy optimization algorithm. The workflow is characterized by three core components:

1.  **Surrogate Guidance:** Utilization of a surrogate-derived priority map to guide the initial pixel selection process.
2.  **Iterative Refinement:** The perturbation process is refined iteratively based on direct query feedback from the target model.
3.  **Coordinate Evaluation:** Pixel coordinates are evaluated directly without gradient information to ensure a monotonic decrease in the loss function, operating under a strictly black-box setting.

---

## ‚öôÔ∏è Technical Details

*   **Algorithm Type:** Greedy algorithm for black-box adversarial attacks.
*   **Objective:** Maximize adversarial loss while minimizing the number of modified pixels (sparsity).
*   **Search Constraints:** The search is constrained by empirical findings showing that successful attacks exploit extreme perturbation bounds ($\pm \epsilon$).
*   **Sparsity Constraints:**
    *   **CIFAR-10:** 1% of pixels (approx. 10 pixels).
    *   **ImageNet:** 0.1% of pixels (approx. 50 pixels).
*   **Visual Quality Metric:** Assessed using Learned Perceptual Image Patch Similarity (LPIPS).
*   **Theoretical Properties:**
    *   Guarantees monotonic loss reduction.
    *   Ensures convergence to a coordinate-wise optimum without gradient access.

---

## üìä Results

Experiments were conducted using an $L_\infty$ threat model with $\epsilon = 4/255$ and a query budget of 20,000.

**Architectures Tested:**
*   **CIFAR-10:** WideResNet, PreActResNet-18, XCiT-S12.
*   **ImageNet:** ResNet-50, VGG19-BN, ViT-Base-Patch16, ConvNeXt, Swin.

**Performance Analysis:**
*   **Extreme Value Reliance:** Analysis of 1,000 effective adversarial examples revealed a heavy reliance on extreme perturbation bounds ($\pm 4/255$).
    *   **Average across datasets:** 56.33% of pixels used extreme values.
    *   **CIFAR-10:** 70.43%.
    *   **ImageNet:** 42.23%.
*   **Comparison:** Outperformed Square and BruSLe, delivering higher success rates and better visual quality.

---

## üöÄ Contributions

*   **Trade-off Resolution:** Addresses the fundamental conflict between precision and flexibility in black-box attack scenarios.
*   **Theoretical Framework:** Introduces a novel optimization framework with robust theoretical properties (monotonic loss reduction and convergence) in a strictly black-box setting.
*   **Broad Applicability:** Demonstrates versatility by validating effectiveness against a wide spectrum of modern deep learning architectures, including both standard CNNs and Vision Transformers.

---
**Report generated based on 40 cited references.**