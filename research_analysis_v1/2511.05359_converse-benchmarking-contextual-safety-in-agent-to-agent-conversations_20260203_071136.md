---
title: 'ConVerse: Benchmarking Contextual Safety in Agent-to-Agent Conversations'
arxiv_id: '2511.05359'
source_url: https://arxiv.org/abs/2511.05359
generated_at: '2026-02-03T07:11:36'
quality_score: 8
citation_count: 19
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# ConVerse: Benchmarking Contextual Safety in Agent-to-Agent Conversations

*Amr Gomaa; Ahmed Salem; Sahar Abdelnabi*

---

> ### ðŸ“Š Quick Facts
>
> * **Benchmark Name:** ConVerse
> * **Total Attacks:** 864 contextually grounded attacks
> * **Attack Types:** 611 Privacy, 253 Security
> * **Target Domains:** Travel, Real Estate, Insurance
> * **Personas Simulated:** 12 distinct user profiles
> * **Models Evaluated:** 7 State-of-the-Art models
> * **Peak Vulnerability:** 88% (Privacy), 60% (Security)
> * **Data Generator:** Claude Sonnet 4.0

---

## Executive Summary

The proliferation of autonomous multi-agent systems has introduced critical security vulnerabilities that current safety alignments are ill-equipped to handle. While state-of-the-art models are rigorously tested against isolated adversarial prompts, this paper addresses the gap in "contextual safety" within multi-turn, multi-agent environments.

The authors highlight that existing safety measures frequently fail in autonomous settings where agents must collaborate with external services, creating a surface for privacy leaks and security breaches. This is a pressing concern because malicious actors can bypass traditional safety filters by embedding harmful requests within plausible, context-rich discourse rather than using overt attacks.

To address these challenges, the researchers introduce **ConVerse**, the first dynamic benchmark specifically designed to evaluate safety in multi-agent ecosystems. Technically, ConVerse simulates realistic interactions between a User Assistant Agent and a potentially malicious External Service Agent across travel, real estate, and insurance domains. The benchmark employs a Contextual Integrity Framework to categorize data flows and utilizes 12 distinct user personas to generate 864 contextually grounded attacks.

Evaluations of seven state-of-the-art models against the ConVerse benchmark reveal alarming susceptibility to exploitation. Furthermore, the study uncovered a troubling "capability-safety trade-off," identifying a negative correlation where stronger, more capable models consistently leaked more private information than their less capable counterparts. This research represents a paradigm shift in how the industry conceptualizes AI safety, moving from a model-centric view to an ecosystem-centric perspective.

---

## Key Findings

*   **High Vulnerability Rates:** State-of-the-art models exhibit significant weaknesses, with privacy attacks succeeding up to **88%** of the time and security breaches occurring up to **60%** of the time.
*   **Capability-Safety Trade-off:** There is a distinct negative correlation between model capability and safety; stronger models tend to leak more information than weaker ones.
*   **Failure of Current Measures:** Existing safety alignments fail to mitigate risks effectively in autonomous, multi-turn, multi-agent settings.
*   **Contextual Bypass:** Malicious requests embedded within plausible discourse are significantly more effective at bypassing safety filters than isolated prompts.

---

## Methodology

The researchers developed **ConVerse**, a dynamic benchmark designed to simulate realistic, autonomous, multi-turn agent-to-agent conversations. The study utilized the following approach:

*   **Scope:** 864 contextually grounded attacks across three specific domains: **Travel**, **Real Estate**, and **Insurance**.
*   **Simulation:** The methodology simulates interactions involving 12 distinct user personas to ensure diversity in context.
*   **Categorization:** Attacks are organized using specific taxonomies:
    *   **Privacy:** Utilizes a three-tier abstraction.
    *   **Security:** Focuses on tool use and preference manipulation.
*   **Evaluation:** Seven state-of-the-art models were tested against these exploits to measure their resilience.

---

## Technical Details

The ConVerse benchmark utilizes a sophisticated multi-agent setup to stress-test safety protocols in realistic environments.

**Architecture & Setup**
*   **Agents:** Involves a User Assistant Agent and a potentially malicious External Service Agent.
*   **Focus:** "Contextually grounded attacks" embedded in multi-turn dialogues without modifying system prompts.
*   **External Agent Capabilities:** Accesses between 158â€“184 options per domain.

**Data Framework**
The benchmark employs a **Contextual Integrity Framework** to categorize data flow:
*   **Unrelated Data:** 34.4%
*   **Related but Private:** 29.3%
*   **Related and Useful:** 36.3%

**Dataset Composition**
*   **Generation:** Components generated via Claude Sonnet 4.0.
*   **AI Assistant Tasks:** Manages complex tasks, rich personal profiles, and tool access.
*   **Attack Breakdown:**
    *   **Total:** 864 attacks
    *   **Privacy:** 611 attacks
    *   **Security:** 253 attacks

---

## Results

The evaluation of state-of-the-art models against the ConVerse benchmark yielded critical insights into the current state of AI safety:

*   **Privacy Leakage:** Vulnerability rates reached as high as **88%**.
*   **Security Breaches:** Vulnerability rates reached as high as **60%**.
*   **Attack Vector Effectiveness:** Malicious requests integrated into plausible conversation flows proved far more effective at bypassing filters than isolated, direct prompts.
*   **Capability vs. Safety:** A negative correlation was observed, confirming that models with higher capabilities were more prone to leaking information.

---

## Contributions

This paper makes four primary contributions to the field of AI safety:

1.  **New Benchmark:** Introduction of **ConVerse**, the first dynamic benchmark specifically designed for multi-agent ecosystem safety.
2.  **Unified Framework:** A comprehensive safety framework that combines privacy and security assessments within interactive conversations.
3.  **Paradigm Shift:** A redefinition of safety as an emergent property of the communication ecosystem, rather than just a feature of individual models.
4.  **Resource Availability:** A comprehensive dataset of 864+ contextually rich attacks made available for future research.

---

## References & Assessment

*   **Citations:** 19
*   **Quality Score:** 8/10