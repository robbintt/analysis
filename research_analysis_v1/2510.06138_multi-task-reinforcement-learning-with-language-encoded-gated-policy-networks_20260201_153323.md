# Multi-Task Reinforcement Learning with Language-Encoded Gated Policy Networks

*Author: Rushiv Arora*

***

> ### üìå Quick Facts
>
> *   **Algorithm:** LEXPOL (Lexical Policy Networks)
> *   **Framework:** Block-Contextual Markov Decision Process (BC-MDP)
> *   **Benchmark:** MetaWorld MT50 (50 robotics tasks)
> *   **Top Performance:** ~**82.4%** Success Rate
> *   **Sample Efficiency:** Reaches 75% success in **1.5M** steps
> *   **Key Innovation:** Language-conditioned gating over policy outputs

***

## üìë Executive Summary

This research addresses the challenge of scaling Reinforcement Learning (RL) agents to perform a wide variety of distinct tasks efficiently, a critical hurdle in the development of general-purpose robotics systems. Traditional multi-task RL approaches often struggle with sample efficiency and negative interference, or they require substantial task-specific fine-tuning when encountering new objectives. The paper focuses on the need for a unified policy architecture that can generalize across diverse environments‚Äîspecifically the complex, manipulation-heavy tasks found in the MetaWorld benchmark‚Äîwithout requiring the agent to learn every new behavior from scratch.

The core innovation is the introduction of **LEXPOL (Lexical Policy Networks)**, a language-conditioned mixture-of-policies architecture built upon the Block-Contextual Markov Decision Process (BC-MDP). Technically, LEXPOL employs a BERT-based Context Encoder to process natural-language task descriptions into embeddings, which are then fed into a Gating MLP. This gating mechanism applies softmax attention to dynamically select and blend action outputs from $k$ independent sub-policies (experts) trained via SAC. Unlike prior methods such as CARE, which gate state representations, LEXPOL gates directly over policy outputs. This design supports both end-to-end training and a "Frozen-Experts" regime, where pre-trained skills are composed dynamically without updating the underlying policy weights.

In evaluations across the MetaWorld MT50 benchmark, LEXPOL demonstrated statistically significant improvements over strong multi-task baselines. The model achieved a mean success rate of approximately **82.4%**, notably outperforming the CARE baseline (76.5%) and the multi-task SAC baseline (53.1%). Regarding sample efficiency, defined here as the speed of convergence to high performance, LEXPOL reached a 75% success rate in roughly **1.5 million environment steps**, compared to 2.2 million steps for CARE, demonstrating superior learning speed. These quantitative results validate the architecture's ability to maintain high performance across diverse tasks without the need for task-specific retraining.

The significance of this work lies in establishing natural language as a highly effective compositional interface for skill indexing and recombination within deep RL. By demonstrating that a language-conditioned gating strategy enables the zero-shot composition of existing skills, the research provides a pathway toward more modular and reusable AI systems. This approach reduces the computational cost associated with learning new tasks and suggests that future RL agents can leverage semantic understanding to manipulate and repurpose learned policies, effectively bridging the gap between linguistic instructions and motor control.

***

## üîç Key Findings

*   **Performance:** LEXPOL matches or exceeds the performance of strong multi-task baselines on MetaWorld benchmarks regarding both success rate and sample efficiency.
*   **Generalization:** The model achieves high performance across diverse tasks without the need for task-specific retraining.
*   **Compositionality:** The learned language gate can compose fixed expert policies to produce correct behaviors for novel task descriptions and unseen task combinations.
*   **Language as Interface:** Natural-language descriptions are proven to be effective tools for indexing and recombining reusable skills within a single policy network.

***

## üß© Methodology

The approach utilizes **Lexical Policy Networks (LEXPOL)**, a language-conditioned mixture-of-policies architecture designed to solve multi-task reinforcement learning problems.

1.  **Text Encoding:** A text encoder processes task metadata (natural-language descriptions) to generate a dense representation of the task.
2.  **Learned Gating:** A learned gating module utilizes the text representation to dynamically select or blend among multiple sub-policies (experts).
3.  **End-to-End Training:** The system is trained end-to-end across tasks, allowing for the simultaneous optimization of the sub-policies and the gating mechanism.

***

## ‚öôÔ∏è Technical Details

The paper introduces LEXPOL, a multi-task reinforcement learning algorithm built on the **Block-Contextual Markov Decision Process (BC-MDP)**.

**Architecture Components:**
*   **Context Encoder:** Utilizes BERT and MLP layers to process natural language into embeddings.
*   **Mixture of Policies:** Comprises $k$ independent SAC-trained networks that share the same state input.
*   **Gating MLP:** Applies softmax attention to aggregate policy action vectors based on the context embedding.

**Key Distinctions:**
*   Unlike CARE, LEXPOL gates over **policy outputs** rather than state representations.
*   Training supports both **end-to-end learning** and a **'Frozen-Experts' regime** where pre-trained skills are composed without weight updates.

***

## üìä Results

The model was evaluated on the **MetaWorld benchmark (50 robotics tasks)** against strong baselines like CARE and multi-task SAC.

*   **Success Rate:** LEXPOL achieved a mean success rate of **~82.4%**, outperforming CARE (76.5%) and multi-task SAC (53.1%).
*   **Sample Efficiency:** LEXPOL reached a 75% success rate in roughly **1.5 million** environment steps, compared to 2.2 million steps for CARE.
*   **Zero-Shot Generalization:** Crucially, the 'Frozen-Experts' experiments demonstrated zero-shot compositionality, where the model successfully composed fixed sub-policies to execute behaviors for novel task descriptions and unseen combinations.

***

## ‚ú® Contributions

*   Introduced **LEXPOL**, integrating natural language encoding with a gated mixture-of-policies to solve multi-task reinforcement learning problems.
*   Empirically validated that a language-conditioned gating strategy can achieve state-of-the-art or competitive sample efficiency and success rates in complex benchmarks like MetaWorld.
*   Provided evidence that natural language can function as a **compositional interface**, allowing a network to recombine existing skills to solve novel tasks without learning new policies from scratch.

***

**Quality Score:** 8/10 | **References:** 6 citations