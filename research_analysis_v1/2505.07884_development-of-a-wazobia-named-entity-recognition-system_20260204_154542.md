---
title: Development of a WAZOBIA-Named Entity Recognition System
arxiv_id: '2505.07884'
source_url: https://arxiv.org/abs/2505.07884
generated_at: '2026-02-04T15:45:42'
quality_score: 9
citation_count: 0
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Development of a WAZOBIA-Named Entity Recognition System

*S. E Emedem; I. E Onyenwe; E. G Onyedinma*

---

> ### ðŸ“Š Quick Facts
>
> *   **Overall F1-Score:** 0.9564
> *   **Target Languages:** Hausa, Yoruba, Igbo
> *   **Architecture:** Hybrid (BiLSTM + BERT + CRF)
> *   **Dataset Size:** 60 Articles (20 per language)
> *   **Key Feature:** Multimodal input via OCR integration
> *   **Tech Stack:** Python, PyTorch, Flask, Tesseract

---

## Executive Summary

This research addresses the critical scarcity of advanced Natural Language Processing (NLP) tools for under-resourced African languages, specifically the three major Nigerian languages: **Hausa**, **Yoruba**, and **Igbo**. While Named Entity Recognition (NER) is fundamental for downstream tasks like information retrieval and machine translation, these low-resource languages have historically lacked robust annotated datasets and specialized architectures.

The core innovation is the **WAZOBIA-NER system**, a hybrid deep learning architecture integrating Bidirectional Long Short-Term Memory (BiLSTM) networks with a fine-tuned multilingual BERT model, capped with a Conditional Random Field (CRF) layer. By leveraging transfer learning and Optical Character Recognition (OCR) via Tesseract, the system processes both text and textual images. The system demonstrated high efficacy, achieving an **overall F1-score of 0.9564**. This study establishes a benchmark for applying modern deep learning to low-resource contexts, proving that data scarcity can be overcome through hybrid architectures and transfer learning.

---

## Key Findings

*   **High Performance:** The WAZOBIA-NER system achieved a robust **F1-score of 0.9564** across Hausa, Yoruba, and Igbo.
*   **Architecture Efficacy:** Combining state-of-the-art models (BiLSTM and BERT fine-tuned with RNN) with a CRF layer yields highly effective entity extraction results.
*   **Multimodal Capability:** The system successfully supports multimodal input through **OCR integration**, allowing for the processing of textual images.
*   **Feasibility Validated:** The research proves the feasibility of developing robust NER tools for under-resourced African languages using current NLP frameworks and transfer learning techniques.

---

## Methodology

The research followed a structured pipeline to develop and evaluate the WAZOBIA-NER system:

1.  **Dataset Compilation:** Comprehensive annotated datasets were compiled for Hausa, Yoruba, and Igbo, focusing on three entity types: **Persons**, **Organizations**, and **Locations**.
2.  **Architectural Exploration:** The study explored multiple architectures, including Conditional Random Fields (CRF), Bidirectional Long Short-Term Memory (BiLSTM), and BERT fine-tuned with RNN.
3.  **Image Processing:** Optical Character Recognition (OCR) was employed to process and extract text from textual images.
4.  **Evaluation:** The model was rigorously assessed using standard metrics: Precision, Recall, F1-score, and Accuracy.

---

## Technical Details

| Component | Description |
| :--- | :--- |
| **Core Architecture** | Hybrid Deep Learning Model (BiLSTM + Fine-tuned Multilingual BERT + CRF Layer) |
| **Learning Strategy** | Transfer Learning |
| **Multimodal Input** | Supported via OCR (Tesseract) |
| **Dataset Split** | 80% Training / 20% Testing |
| **Entity Classes** | Person (PER), Organization (ORG), Location (LOC) |

**Technology Stack:**
*   **Languages & Frameworks:** Python 3.8, PyTorch
*   **NLP Libraries:** NLTK, Spacy, Scikit-learn
*   **Web & Database:** Flask, SQLite, Bootstrap

---

## Results

The system's performance was evaluated over a training period of 5 epochs on a total of 60 articles.

*   **Overall Performance:** Achieved an F1-score of **0.9564**.
*   **Training Dynamics:**
    *   **Losses:** Decreased significantly after the first epoch.
    *   **Precision:** Peaked at **Epoch 4**.
    *   **Recall & F1-score:** Peaked at **Epoch 2**.
    *   **Accuracy:** Peaked at **Epoch 3**.

---

## Contributions

This study makes several significant strides in the field of African NLP:

*   **Bridging the Linguistic Gap:** Directly addresses the lack of tools for under-resourced Nigerian languages.
*   **Resource Creation:** Contributes new annotated datasets for Hausa, Yoruba, and Igbo to support future research.
*   **Novel Tool:** Delivers the WAZOBIA-NER system, a unique tool combining high-accuracy deep learning with OCR functionality.
*   **Benchmarking:** Establishes a benchmark for the feasibility of applying transfer learning and modern deep learning architectures to low-resource language contexts.

---

**Document Quality Score:** 9/10  
**References:** 0 citations