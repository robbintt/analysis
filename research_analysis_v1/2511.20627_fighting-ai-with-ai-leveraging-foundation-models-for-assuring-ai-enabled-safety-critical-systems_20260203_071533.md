---
title: 'Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled
  Safety-Critical Systems'
arxiv_id: '2511.20627'
source_url: https://arxiv.org/abs/2511.20627
generated_at: '2026-02-03T07:15:33'
quality_score: 8
citation_count: 16
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems

*Anastasia Mavridou; Divya Gopinath; Corina S. PƒÉsƒÉreanu*

---

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 16 Citations |
| **Core Models** | LLMs (REACT), VLMs/CLIP (SemaLens) |
| **Logic Standard** | Linear Temporal Logic on finite traces (LTLf) |
| **Case Study** | NASA Rover Workflow |

---

## üìù Executive Summary

The integration of Deep Neural Networks (DNNs) into safety-critical systems presents a formidable assurance challenge, primarily due to the opacity of neural architectures and the semantic gap between high-level human requirements and low-level network representations. Traditional verification methods are often ineffective for AI components, and these difficulties are exacerbated by persistent Requirements Engineering bottlenecks, specifically the ambiguity of natural language and the labor-intensive process of formalizing requirements into logic.

This paper addresses the critical need for reliable verification mechanisms that can bridge the divide between informal human intent and the complex, black-box nature of AI implementations in high-stakes environments. The authors propose a **"fighting AI with AI" strategy**, introducing a unified pipeline that leverages Foundation Models to solve assurance problems inherent in other AI systems.

The innovation comprises two complementary frameworks:
1.  **REACT:** Utilizes Large Language Models (LLMs) to automate the translation of informal natural language requirements into formal specifications (Linear Temporal Logic on finite traces, or LTLf), employing a multi-module process of authoring, validating, and formalizing.
2.  **SemaLens:** Employs Vision Language Models (VLMs), specifically CLIP, to perform semantic analysis on visual perception systems. By converting formal specifications into Deterministic Finite Automata (DFAs), SemaLens enables spatial and temporal reasoning over visual data, using embedding similarity and text-conditional diffusion models to generate test cases and monitor system behavior against high-level semantic concepts.

The proposed pipeline was evaluated using the CLIP ViT-B/16 model. In a case study involving a NASA Rover workflow, the REACT framework successfully processed informal inputs to prune candidate requirements down to a single, consistent requirement. Furthermore, the SemaLens monitor demonstrated the ability to evaluate image sequences temporally; it successfully returned a "True" verdict starting from the third image in the sequence, confirming that the system satisfied the specified property within the observed timeframe.

This research represents a significant advancement in the field of AI safety by establishing a comprehensive end-to-end pipeline that connects informal specification with validated implementation. By automating the formalization bottleneck and enabling semantic-level monitoring of perception systems, the work shifts the paradigm from manual, intractable verification to AI-assisted assurance.

---

## üîë Key Findings

*   **System Opacity & Semantic Gap:** The integration of DNNs into safety-critical systems creates fundamental assurance challenges due to opacity and the gap between high-level requirements and low-level network representations.
*   **Ineffectiveness of Traditional Methods:** Traditional verification approaches are often ineffective for AI components.
*   **RE Bottlenecks:** Persistent Requirements Engineering issues, such as natural language ambiguity and formalization bottlenecks, compound verification difficulties.
*   **The "Fighting AI with AI" Solution:** Leveraging Foundation Models (specifically LLMs and VLMs) offers a viable solution to bridge the gap between informal human concepts and formal AI representations.
*   **Unified Pipeline Success:** A unified pipeline utilizing AI for verification can successfully transition systems from informal natural language requirements to validated, monitored implementations.

---

## üî¨ Methodology

The authors propose a "fighting AI with AI" strategy centered on two complementary components designed to cover the entire assurance lifecycle:

### REACT (Requirements Engineering with AI for Consistency and Testing)
This component employs **Large Language Models (LLMs)** to tackle the "front-end" of the assurance problem. Its primary function is to translate informal, ambiguous natural language requirements into rigorous, verifiable formal specifications.

### SemaLens (Semantic Analysis of Visual Perception using large Multi-modal models)
This component utilizes **Vision Language Models (VLMs)** to address the "back-end" of the problem. It performs semantic analysis on DNN-based perception systems, enabling them to be tested and monitored using human-understandable concepts rather than just pixel-level data.

---

## üß© Contributions

The research delivers three primary contributions to the field of AI safety and verification:

1.  **REACT Framework:** A novel framework that applies LLMs to Requirements Engineering to automate the conversion of informal text into formal specifications.
2.  **SemaLens Approach:** A new approach that uses VLMs to perform semantic analysis on visual perception systems, enabling testing and monitoring based on high-level semantic concepts.
3.  **Integrated Assurance Pipeline:** A comprehensive end-to-end pipeline that connects informal requirement specification with the validation of AI-enabled implementations specifically for safety-critical domains.

---

## ‚öôÔ∏è Technical Details

The paper proposes a unified pipeline comprising REACT and SemaLens to bridge the gap between natural language and AI representations.

### REACT Architecture
*   **Author Module:** Uses LLMs to translate natural language into "Restricted English" to reduce ambiguity.
*   **Validate Module:** Implements a Human-in-the-Loop process for formal validation of the restricted requirements.
*   **Formalize Module:** Translates the validated restricted English into Linear Temporal Logic on finite traces (**LTLf**).

### SemaLens Architecture
*   **Core Model:** Utilizes Vision-Language Models (specifically **CLIP**) to monitor DNNs.
*   **Logic Conversion:** Converts LTLf specifications into **Deterministic Finite Automata (DFAs)** to facilitate spatial and temporal reasoning.
*   **Predicate Evaluation:** Evaluates predicates via embedding similarity.
*   **Test Generation:** Uses text-conditional diffusion models to generate synthetic test images for validation.

---

## üìà Results

The proposed system was evaluated against specific metrics and a real-world workflow scenario:

*   **Configuration:** The system utilized the **CLIP ViT-B/16** model with a cosine similarity threshold of **0.4** for predicate evaluation.
*   **NASA Rover Workflow:** In this case study, REACT successfully pruned candidate requirements to a single, consistent RE requirement.
*   **Monitoring Performance:** The monitor evaluated the image sequence and returned a **True verdict starting from the third image**, indicating the property was satisfied within the observed timeframe.