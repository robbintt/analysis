# HGQ: High Granularity Quantization for Real-time Neural Networks on FPGAs

*Chang Sun; Zhiqiang Que; Thea K. Ã…rrestad; Vladimir Loncar; Jennifer Ngadiuba; Wayne Luk; Maria Spiropulu*

---

> ### ðŸ“Š Quick Facts
> 
> | Metric | Detail |
> | :--- | :--- |
> | **Innovation** | Per-parameter bit-width optimization via Gradient Descent |
> | **Latency Target** | < 1 Âµs (Sub-microsecond) |
> | **Resource Metric** | Effective Bit Operations (EBOPs) |
> | **Hardware Target** | FPGAs with Heterogeneous Arbitrary Precision |
> | **Validation** | CERN ATLAS & CMS Trigger Systems |
> | **Accuracy Impact** | Negligible loss despite aggressive optimization |
> | **Quality Score** | 9/10 |

---

## Executive Summary

The deployment of complex neural networks on Field-Programmable Gate Arrays (FPGAs) for real-time applications is severely constrained by limited hardware resources and the critical need for ultra-low latency. This challenge is particularly acute in high-energy physics experiments (e.g., CERN), where inference systems must execute within sub-microsecond timeframes. Existing compression techniques often fail because they utilize uniform or layer-wise quantization, which does not fully exploit an FPGA's capability for heterogeneous arbitrary precision arithmetic.

To address this, the paper introduces **High Granularity Quantization (HGQ)**, a quantization-aware training framework that optimizes bit-widths at the *per-parameter* level. Technically, HGQ implements a gradient descent-based optimization algorithm that treats the bit-width of each individual weight and activation as a learnable parameter. To facilitate differentiation, discrete bit-widths are relaxed into continuous values using Straight Through Estimators (STE) and surrogate gradients. The framework employs a custom loss function combining standard model loss, L1 regularization, and a novel hardware resource metric called **Effective Bit Operations (EBOPs)**. EBOPs estimates FPGA resource usage (LUT/DSP) by modeling multiplication as shift-and-add logic, guiding the model toward a hardware-efficient topology.

The implementation achieves an "orders of magnitude" reduction in resource consumption and latency while maintaining accuracy. It successfully meets the rigorous sub-microsecond (< 1 Âµs) requirements for CERNâ€™s LHC experiments (ATLAS and CMS) and demonstrated approximately 300 ns latency capabilities for Belle II triggers. By releasing open-source tooling, this work bridges the gap between state-of-the-art ML and hardware limits, setting a new standard for FPGA-accelerated inference.

---

## Key Findings

*   **Significant Resource Reduction:** HGQ achieves an orders of magnitude reduction in both resource consumption and latency compared to existing network compression methods.
*   **Accuracy Preservation:** The framework maintains model accuracy across several benchmark tasks despite aggressive optimization for hardware constraints.
*   **Deployment Feasibility:** It enables the deployment of complex neural network models on FPGAs that were previously infeasible due to strict resource or latency constraints.
*   **Sub-microsecond Latency:** The system successfully meets sub-microsecond inference latency requirements, specifically validating performance in CERN ATLAS and CMS trigger systems.

---

## Methodology

HGQ utilizes a quantization-aware training framework specifically designed for FPGA deployments. The core technical innovation employs gradient descent to optimize parameter bit-widths. Unlike conventional methods that optimize layer-wise or globally, HGQ determines the optimal bit-width for each individual parameter independently.

This high-granularity approach allows the model to target hardware platforms that support **heterogeneous arbitrary precision arithmetic**, maximizing the efficiency of the FPGA fabric.

---

## Technical Details

### HGQ Scheme
*   **Granularity:** Implements per-parameter quantization for weights and activations with **learnable bit-widths** (where zero bits implies pruning).
*   **Representation:** Uses a hardware-efficient fixed-point representation (compatible with `ac_fixed`/`ap_fixed`), defined by signedness, integer bits, and fractional bits.

### Operational Modes
*   **Rounding:**
    *   **RND (Round-to-nearest):** Used for stability.
    *   **TRN (Truncation):** Introduces bias but has lower overhead.
*   **Overflow:**
    *   **SAT (Clipping):** Used for stability during training.
    *   **WRAP (Modulo):** Used for minimal hardware overhead during deployment.
    *   *Note:* HGQ tracks fractional bits during training and profiles integer bits during deployment.

### Optimization Strategy
*   **Differentiability:** Utilizes **Straight Through Estimator (STE)** and **Surrogate Gradients** to handle discrete quantization operations.
*   **Relaxation:** Bit-widths are relaxed to continuous values during training to facilitate gradient descent.
*   **Loss Function:** Composed of three parts:
    1.  Base Model Loss
    2.  **EBOPs** (Resource penalty)
    3.  L1 Regularization on bit-widths

### Hardware Resource Estimation
*   **Metric:** Introduces **Effective Bit Operations (EBOPs)** to estimate FPGA resources.
*   **Logic:** Models multiplication operations as shift-and-add logic, correlating highly with LUT and DSP usage on the chip.

---

## Contributions

*   **Novel Optimization Algorithm:** Introduction of a gradient descent-based method for per-parameter bit-width optimization within a quantization-aware training loop.
*   **Hardware-Specific Design:** A framework tailored to exploit heterogeneous arbitrary precision arithmetic available on modern FPGAs, moving beyond standard uniform quantization.
*   **Open-Source Tooling:** Release of a high-performance optimization tool that bridges the gap between advanced machine learning models and strict real-time hardware constraints.
*   **Real-World Validation:** Successful application and deployment in next-generation trigger systems for high-energy physics experiments (CERN ATLAS and CMS), facilitating advanced real-time data selection.

---

## Performance Results

### Latency Performance
*   Designed for sub-microsecond (< 1 Âµs) to few-microsecond inference latency.
*   Successfully meets sub-microsecond decision latency requirements for CERN LHC (ATLAS & CMS) Level-1 triggers.
*   Capable of meeting ~300 ns latency requirements for Belle II neural network-based triggers.

### Resource and Efficiency Metrics
*   Claims **'orders of magnitude'** reduction in resource consumption and latency compared to existing compression methods.
*   Enables deployment of complex neural network models on FPGAs previously infeasible due to resource caps.

### Accuracy
*   Maintains model accuracy across benchmark tasks despite aggressive optimization for latency.

---

**Paper References:** 40 Citations | **Quality Score:** 9/10