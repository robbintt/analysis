---
title: GPQA (Medical)
arxiv_id: '2504.00869'
source_url: https://arxiv.org/abs/2504.00869
generated_at: '2026-01-27T16:29:20'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# GPQA (Medical)

*Bullets Op, Xiaoke Huang, Xianfeng Tang, Santa Cruz, Time Scaling, Hui Liu, Yuyin Zhou, Amazon Research, Large Language, Juncheng Wu*

---

> ### ðŸ“Œ Quick Facts
>
> | Metric | Detail |
> | :--- | :--- |
> | **Quality Score** | 9/10 |
> | **References** | 40 Citations |
> | **Optimal Token Budget** | ~4,000 Tokens |
> | **Performance Highlight** | 32B models match 70B-scale performance |
> | **Primary Bottleneck** | Insufficient domain knowledge |

---

## Executive Summary

This research addresses the computational inefficiency of deploying massive Large Language Models (70B+ parameters) for complex medical question answering. While large models currently set the standard for accuracy in medical domains, their significant size creates high barriers for practical deployment due to infrastructure costs and latency.

The authors investigate whether smaller, lightweight models (under 10B parameters) can achieve comparable performance by leveraging **"test-time scaling"**â€”essentially, trading increased inference computation time for improved reasoning capabilitiesâ€”to bridge the performance gap without the parametric overhead.

The key innovation is the systematic manipulation of the "thinking" token budget during inference using an approach referred to as 'm1'. By allowing the model to generate extended chains of thought before arriving at a final answer, the authors effectively increase the compute time at inference. The study utilizes a "Budget Forcing" technique involving iterative prompts to compel the model to utilize the allocated token budget, encouraging mechanisms like double-checking.

**Conclusion:** The study establishes a diminishing return on reasoning depth; the primary bottleneck for medical AI is insufficient domain knowledge rather than reasoning capability. Consequently, the study shifts the focus toward the necessity of "enriched medical knowledge" through improved data scale and model capacity, positing that increased inference compute cannot fully compensate for fundamental gaps in training data.

---

## Key Findings

*   **Performance Gains:** Increasing the 'thinking' token budget at inference significantly improves medical reasoning, allowing models under **10B parameters** to achieve state-of-the-art performance.
*   **Parity Achieved:** **32B models** were able to match the performance of 70B-scale models through optimized inference compute.
*   **Optimal Budget:** There is an optimal reasoning token budget of approximately **4K tokens**. Exceeding this causes 'overthinking' and leads to performance degradation.
*   **Budget Forcing Issues:** 'Budget forcing' techniques (like iterative prompts) encourage double-checking but do **not** reliably improve accuracy and can actually introduce errors.
*   **Core Bottleneck:** The primary limitation is insufficient medical knowledge rather than reasoning depth. Solutions necessitate improved data scale and model capacity.

---

## Methodology

The authors employed a structured approach to evaluate the impact of inference computation on medical reasoning:

1.  **The 'm1' Approach:** Used to manipulate the 'thinking' token budget during inference, effectively increasing computation time.
2.  **Budget Forcing:** Exploration of iterative prompting to extend computation and force the model to use allocated tokens.
3.  **Comprehensive Evaluation:** Conducted across diverse medical tasks, comparing lightweight fine-tuned models against larger state-of-the-art models.
4.  **Failure Analysis:** Performed case-by-case analysis to understand where and why models failed.

---

## Technical Details

| Aspect | Specification |
| :--- | :--- |
| **Core Strategy** | Inference-time optimization via thinking token budget adjustment. |
| **Token Range Tested** | 128 to 8,192 tokens. |
| **Budget Forcing** | Utilizes iterative prompts to force budget usage and encourage double-checking. |
| **Identified Bottleneck** | Insufficient domain knowledge. |
| **Conclusion** | Reasoning cannot fully compensate for knowledge gaps; requires better data scale and capacity. |

---

## Results

Experiments demonstrated that with optimized token budgets, smaller models surpassed existing baselines.

*   **Model Performance:** Models <10B achieved SOTA; 32B models matched 70B models.
*   **Overthinking Threshold:** Performance degraded beyond 4,000 tokens.

### Accuracy Ranges Across Medical Datasets

| Dataset | Accuracy Range |
| :--- | :---: |
| **PubMedQA** | 72.5% â€“ 80.0% |
| **MedQA USLME** | 65% â€“ 75% |
| **MedMCQA** | 57% â€“ 69% |
| **GPQA Medical** | 56% â€“ 68% |
| **Lancet** | 48% â€“ 64% |
| **MedBullets Op4** | 48% â€“ 64% |
| **MMLU-Pro Medical** | 40% â€“ 56% |

---

## Contributions

*   **First Comprehensive Investigation:** Applies test-time scaling specifically to the domain of medical reasoning.
*   **Computational Efficiency:** Demonstrates that optimized test-time compute allows small models to surpass baselines, reducing the computational burden for medical QA.
*   **Knowledge vs. Reasoning:** Establishes that while test-time scaling is beneficial, its full realization depends on 'enriched medical knowledge' through better data and capacity rather than reasoning depth alone.