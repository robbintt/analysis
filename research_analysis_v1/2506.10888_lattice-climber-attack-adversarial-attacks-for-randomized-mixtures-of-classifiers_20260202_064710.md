# Lattice Climber Attack: Adversarial attacks for randomized mixtures of classifiers

*Lucas Gnecco-Heredia; Benjamin Negrevergne; Yann Chevaleyre*

---

### ðŸ“Š Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 7/10 |
| **References** | 40 Citations |
| **Core Focus** | Randomized Mixtures, Adversarial Robustness, Geometrical Analysis |
| **Key Innovation** | Lattice Climber Attack Algorithm |
| **Theoretical Basis** | Binary Linear Setting Guarantees |

---

## Executive Summary

This research addresses the critical challenge of generating adversarial attacks against finite mixtures of randomized classifiersâ€”ensembles that select deterministic classifiers according to a mixed strategy. This problem is significant because standard attack methodologies, specifically Expectation Over Transformations (EOT)â€”implemented as EOL-PGD in evaluationsâ€”and Adaptive Random Coordinate (ARC), are fundamentally ill-suited for these architectures. These methods frequently fail to generate valid perturbations because they cannot adequately navigate the complex geometric structure of classifier vulnerabilities within an $\ell_p$-norm ball of size $\epsilon$. Consequently, robustness evaluations relying on these standard techniques may be inaccurate, leaving substantial security gaps in randomized defense systems.

The key innovation is the **"Lattice Climber Attack,"** a novel algorithm derived from a rigorous set-theoretic and geometrical analysis of the attack space. The authors formulate the attack as a problem of "climbing a lattice" to identify a perturbation $\delta$ within an $\ell_p$-norm ball that maximizes the expected zero-one loss. The approach is built upon two necessary geometric properties: ***effectiveness*** (consistency in finding an attack) and ***maximality*** (maximizing the number of classifiers in the mixture that are simultaneously fooled). Unlike current methods, which are often greedy or misaligned, the Lattice Climber is technically designed to satisfy both criteria, with theoretical guarantees for convergence specifically established within the binary linear setting.

Empirical validation on both synthetic and real datasets demonstrates that the Lattice Climber Attack achieves superior performance by successfully navigating geometric scenarios where baselines fail. The results, evaluated using metrics such as Expected Zero-One Loss and $\ell_p$ norms ($p=2$ and $p=\infty$), indicate distinct failure modes for existing methods:

*   **EOL-PGD** fails to generate valid perturbations when classifier vulnerabilities are disjoint (low alignment).
*   **ARC** succeeds at low alignment but lacks maximality in medium alignment scenariosâ€”failing to fool all classifiers simultaneously.

In contrast, the Lattice Climber consistently identifies perturbations that satisfy both effectiveness and maximality, maximizing the expected zero-one loss across varying geometric constraints.

---

## Key Findings

*   **Inadequacy of Current Methods:** Existing adversarial attack methods are fundamentally ill-suited for attacking finite mixtures of classifiers.
*   **Geometrical Properties:** Analysis reveals two necessary properties for effective attacks:
    *   **Effectiveness:** The ability to consistently find a valid attack.
    *   **Maximality:** The ability to maximize the number of classifiers attacked simultaneously.
*   **Dual Failure:** Current attack methodologies fail to satisfy both effectiveness and maximality properties simultaneously.
*   **Superior Performance:** The proposed 'Lattice Climber Attack' demonstrates superior empirical performance compared to existing baselines.
*   **Theoretical Backing:** Theoretical guarantees for the 'Lattice Climber Attack' are established within the binary linear setting.

---

## Technical Details

*   **Target Architecture:** Finite mixtures of randomized classifiers utilizing a mixed strategy over a set of deterministic classifiers $h=\{h_1...h_m\}$.
*   **Loss Function:** Adapted to an expected zero-one loss.
*   **Problem Formulation:**
    *   Conceptualized as "climbing a lattice" using a set-theoretic perspective.
    *   Objective: Find a perturbation $\delta$ within an $\ell_p$-norm ball $B_p(x, \epsilon)$ that maximizes expected loss.
*   **Core Properties:**
    *   *Effectiveness:* Consistency in finding an attack.
    *   *Maximality:* Maximizing the number of classifiers attacked.
*   **Critique of Baselines:**
    *   **EOT/EOL-PGD:** Fails when vulnerabilities are disjoint (low alignment).
    *   **ARC:** Greedy approach that lacks maximality in scenarios of medium alignment.

---

## Methodology

1.  **Geometrical Analysis:** The authors employ a geometrical analysis to formalize the problem of attacking classifier mixtures.
2.  **Criteria Definition:** They define specific evaluation criteria: effectiveness and maximality.
3.  **Algorithm Derivation:** The 'Lattice Climber Attack' algorithm is derived, with theoretical guarantees applicable to the binary linear context.
4.  **Empirical Validation:** Experiments are conducted on both synthetic and real datasets to demonstrate practical performance against baselines (EOL-PGD and ARC).

---

## Contributions

*   **Principled Approach:** Introduction of a principled approach specifically for attacking randomized mixtures of classifiers.
*   **Benchmarks:** Definition of geometry-based properties (effectiveness and maximality) that serve as benchmarks for evaluating adversarial attacks.
*   **Gap Identification:** Identification of the failure of existing attack methods to meet these rigorous standards.
*   **State-of-the-Art Method:** Development of the 'Lattice Climber Attack', a theoretically backed method for evaluating the robustness of classifier mixtures.

---

## Results

*   **Evaluation Metrics:** Expected Zero-One Loss and $\ell_p$ norms ($p=2$ and $p=\infty$).
*   **Baseline Performance:** Experimental findings indicate that ARC significantly reduces robustness estimates compared to EOL-PGD.
*   **Geometric Comparisons:**
    *   **EOL-PGD:** Fails with low alignment (disjoint vulnerabilities) but succeeds with high alignment.
    *   **ARC:** Succeeds with low alignment but fails to find perturbations that fool all classifiers simultaneously (lacks maximality) in cases of medium alignment or small common vulnerability regions.
*   **Lattice Climber:** While specific quantitative results were not included in the text, the algorithm is shown to navigate scenarios where baselines fail, satisfying both effectiveness and maximality.