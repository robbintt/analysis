---
title: 'MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning'
arxiv_id: '2505.22694'
source_url: https://arxiv.org/abs/2505.22694
generated_at: '2026-02-03T19:17:46'
quality_score: 9
citation_count: 14
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning

*Dacao Zhang; Kun Zhang; Shimao Chu; Le Wu; Xin Li; Si Wei*

---

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 9/10 |
| **References** | 14 Citations |
| **Core Innovation** | Rank-Task Alignment via Mixture of Experts |
| **Inference Cost** | Zero additional cost vs. standard LoRA |
| **Key Competitors** | LoRA, DyLoRA, AdaLoRA, SoRA |

---

## üìù Executive Summary

Parameter-Efficient Fine-Tuning (PEFT) methods, particularly Low-Rank Adaptation (LoRA), suffer from critical rigidity in multi-task learning scenarios due to their reliance on fixed rank configurations. Standard LoRA enforces a suboptimal trade-off by applying a single static rank across all tasks, ignoring the fact that distinct tasks often require different rank capacities to maximize performance. Existing adaptive LoRA variants are largely designed for single-task optimization or incur high computational overhead by training separate modules for each task.

The authors introduce **MoRE (Mixture of Low-Rank Experts)**, a novel framework that applies a mixture-of-experts approach to LoRA for multi-task learning. The core innovation is **"Rank-Task Alignment,"** facilitated by an **"Adaptive Rank Selector"**‚Äîa dynamic router that identifies the task context and activates the specific low-rank expert best suited for the input. To correct prior misconceptions, the architecture utilizes distinct parameter matrices ($A$ and $B$) for each expert, ensuring granular control over capacity.

Experimental evaluations on T5-base illustrated the limitations of static LoRA, showing that optimal performance is highly rank-dependent. MoRE addressed these inconsistencies by dynamically adapting to task requirements, significantly outperforming standard LoRA as well as adaptive variants like DyLoRA, AdaLoRA, and SoRA. Crucially, despite the added architectural complexity of dynamic routing, MoRE demonstrated **zero additional inference costs** compared to standard LoRA methods. This work successfully bridges the gap between multi-task flexibility and inference efficiency, establishing a new paradigm for building capable, multi-task LLMs that remain cost-effective to deploy.

---

## üîë Key Findings

*   **Superior Performance:** MoRE significantly outperforms traditional LoRA and its variants (DyLoRA, AdaLoRA, SoRA) across multiple multi-task benchmarks and LLM architectures.
*   **Cost Efficiency:** The framework incurs **no additional inference costs** compared to standard LoRA methods, successfully decoupling adaptability from latency.
*   **Adaptive Efficiency:** Enhances the adaptability and efficiency of PEFT methods by jointly training low-rank experts rather than treating tasks in isolation.
*   **Limitations of Current Methods:** Highlights that existing LoRA improvements are limited by their focus on single-task scenarios or inefficiently training separate modules for each task.

---

## üõ†Ô∏è Methodology

The paper proposes **MoRE (Mixture of Low-Rank Experts)**, a framework designed to overcome the rigidity of static ranks in multi-task Parameter-Efficient Fine-Tuning.

*   **Low-Rank Experts:** The approach involves aligning different ranks of a LoRA module with different tasks. This allows specific tasks to utilize the rank capacity that best suits their complexity.
*   **Adaptive Rank Selector:** A mechanism designed to dynamically identify and activate the appropriate low-rank expert for a given task.
*   **Joint Training:** These components are trained jointly to optimize the model for multiple tasks simultaneously, ensuring the router learns to select the optimal expert efficiently.

---

## ‚úÖ Contributions

The research makes four primary contributions to the field of PEFT and LLMs:

1.  **Novel Framework:** Introduction of MoRE, a Multi-Task PEFT Framework that shifts the paradigm from individual modules to a mixture-of-experts approach.
2.  **Rank-Task Alignment:** A strategy mapping specific LoRA ranks to specific tasks, allowing for granular parameter utilization based on task difficulty.
3.  **Dynamic Selection Mechanism:** An adaptive rank selector that ensures correct routing during both fine-tuning and inference.
4.  **Efficiency Preservation:** Demonstrates that multi-task fine-tuning can be achieved without sacrificing the inference efficiency characteristic of standard LoRA methods.

---

## ‚öôÔ∏è Technical Details

### Architecture Components
MoRE addresses the rigidity of standard LoRA through a dynamic architectural design:

*   **Target Layers:** Modifications applied to Attention and Feed-Forward Networks (FFN).
*   **Task Embeddings:** Contextual representations used to inform the routing decision.
*   **Rank Experts (Adaptive Rank Selector):** Specialized modules designed to handle specific rank requirements.
*   **Router:** Directs inputs to the correct expert based on task context.
*   **Distinct Parameter Matrices:** Utilizes specific $A$ and $B$ matrices for each expert (rather than sharing them) to ensure granular control.

### Training Strategy
*   **Joint Training:** Experts and the router are trained simultaneously.
*   **Contrastive Learning:** Employed to enhance the separation and selection of experts.
*   **Balanced Data Sampling:** Ensures that all tasks are represented adequately during the training process.

---

## üìà Results

Experiments conducted on **T5-base** revealed that standard LoRA performance is highly sensitive to rank selection, validating the need for MoRE's adaptive approach.

### LoRA Rank Sensitivity (T5-base)
| Benchmark | Optimal Rank | Performance Score |
| :--- | :---: | :---: |
| **MRPC** | 1 | 89.7 |
| **RTE** | 4 | 80.5 |
| **SST-2** | 4 | 94.8 |
| **CoLA** | 8 | 63.3 |

### Comparative Performance
*   **Vs. Static LoRA:** MoRE addressed the inconsistencies shown above, adapting dynamically to requirements.
*   **Vs. Adaptive Variants:** MoRE significantly outperformed DyLoRA, AdaLoRA, and SoRA across various multi-task benchmarks.
*   **Efficiency:** Despite the complex routing, MoRE maintained zero additional inference costs compared to standard LoRA baselines.