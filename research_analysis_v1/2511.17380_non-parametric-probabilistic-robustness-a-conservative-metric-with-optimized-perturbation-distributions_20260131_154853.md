# Non-Parametric Probabilistic Robustness: A Conservative Metric with Optimized Perturbation Distributions

*Zheng Wang; Yi Zhang; Siddartha Khastgir; Carsten Maple; Xingyu Zhao*

---

### ðŸ“Š Quick Facts

| **Metric** | **Detail** |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **Citations** | 40 |
| **Datasets** | CIFAR-10, CIFAR-100, Tiny ImageNet |
| **Architectures** | ResNet, WideResNet, VGG |
| **Key Drop (Indep.)** | 99.99% $\to$ 20.11% |
| **Method Type** | Non-parametric / GMM-based |

---

> ### ðŸ“ Executive Summary
>
> Current evaluations of neural network safety, specifically Probabilistic Robustness (PR), rely on the unrealistic assumption that the distribution of perturbationsâ€”such as noise or adversarial shiftsâ€”is fixed and known *a priori*. In real-world deployments, the nature of these perturbations is often uncertain or subject to distributional shifts. Consequently, existing PR formulations tend to provide over-optimistic estimates of model security, failing to account for worst-case scenarios and potentially leaving safety-critical systems vulnerable to unexpected inputs.
>
> The authors introduce **Non-Parametric Probabilistic Robustness (NPPR)**, a novel metric that reframes robustness evaluation by treating the perturbation distribution as a variable to be optimized rather than a fixed parameter. Technically, the method utilizes a data-driven, non-parametric approach featuring a Gaussian Mixture Model (GMM) combined with Multilayer Perceptron (MLP) heads and bicubic up-sampling. This architecture enables the system to learn the worst-case perturbation distribution directly from data, allowing it to adapt to both input-independent and input-dependent scenarios without requiring prior knowledge of the threat model.
>
> Extensive experiments on **CIFAR-10**, **CIFAR-100**, and **Tiny ImageNet** using architectures like ResNet and VGG demonstrate that NPPR yields significantly more conservative robustness estimates than state-of-the-art baselines, quantifying the risk previously hidden by idealized assumptions. In input-independent scenarios, NPPR reduced robustness estimates from a baseline of ~99.99% to as low as 20.11%, while perturbation intensity metrics surged from near-zero to approximately 0.9.
>
> This work establishes a vital theoretical link between **Adversarial Robustness** and **Probabilistic Robustness**, positioning NPPR as a critical advancement for the reliable certification of AI systems. By demonstrating that robustness must be evaluated under distributional uncertainty, the paper argues against the reliance on predefined perturbation models.

---

## Key Findings

*   **Limitation of Current Methods:** Existing Probabilistic Robustness (PR) formulations are fundamentally limited by the unrealistic assumption that perturbation distributions are fixed and known.
*   **Conservative Estimates:** The proposed Non-parametric Probabilistic Robustness (**NPPR**) yields significantly more conservative PR estimatesâ€”**up to 40% lower**â€”compared to state-of-the-art methods.
*   **Broad Validation:** Practicality is validated through extensive experiments on datasets (**CIFAR-10, CIFAR-100, Tiny ImageNet**) and architectures (**ResNet, WideResNet, VGG**).
*   **Scenario Handling:** The estimator effectively handles both **input-dependent** and **input-independent** perturbation scenarios.
*   **Theoretical Framework:** Theoretical relationships have been established linking Adversarial Robustness (AR), PR, and NPPR, contextualizing the contribution within the wider landscape.

---

## Methodology

The proposed method shifts the paradigm of robustness evaluation by adopting a **non-parametric statistical modeling** approach. Instead of relying on predefined perturbation models, the system learns optimized perturbation distributions directly from data.

*   **Core Mechanism:** Implementation of an NPPR estimator utilizing a **Gaussian Mixture Model (GMM)**.
*   **Architecture Enhancement:** The GMM is combined with **Multilayer Perceptron (MLP)** heads to improve learning capacity.
*   **Processing:** Integration of **bicubic up-sampling** to effectively handle various perturbation scenarios and resolutions.

---

## Technical Details

The paper proposes a fundamental shift in how perturbation distributions are treated in robustness analysis.

| **Aspect** | **Description** |
| :--- | :--- |
| **Core Concept** | Treats the perturbation distribution as a **variable to be optimized** rather than a fixed, known parameter (Standard PR). |
| **Optimization Goal** | Seeks the **worst-case perturbation distribution** within specific constraints using a trainable mechanism. |
| **Scope** | Capable of handling both **Input-Independent** and **Input-Dependent** perturbations. |
| **Linkage** | Establishes a theoretical bridge connecting Adversarial Robustness (AR), standard Probabilistic Robustness (PR), and NPPR. |

---

## Results & Performance

Experiments demonstrated that NPPR (Trainable) yields significantly more conservative robustness estimates compared to baselines across various scenarios.

### Input-Independent Perturbations
The baseline robustness was approximately **99.99%**. Under NPPR configurations, this dropped dramatically:

*   **Config 3:** 54.43%
*   **Config 7:** 31.49%
*   **Config 12:** 20.11%

Additionally, perturbation intensity metrics (Metric 3) increased drastically under NPPR, rising from near-zero to **~0.9**, indicating a much higher perceived threat level.

### Input-Dependent Scenarios
In scenarios where perturbations depend on the input:
*   **Baseline Robustness:** 52.25%
*   **Non-trainable Method:** 40.95%

This highlights the method's ability to uncover substantial vulnerabilities in standard models that remain invisible to traditional evaluation metrics.

---

## Contributions

1.  **New Metric:** Introduction of **Non-parametric Probabilistic Robustness (NPPR)**, a novel metric for evaluating robustness under distributional uncertainty without requiring prior knowledge of perturbation distributions.
2.  **Data-Driven Mechanism:** Development of a mechanism to learn perturbation distributions from data specifically for conservative robustness evaluation.
3.  **Robust Estimator:** Creation of a robust **GMM-based estimator** incorporating MLP heads and bicubic up-sampling.
4.  **Theoretical Framework:** Provision of a theoretical framework that contextualizes NPPR within the existing landscape of robustness definitions, specifically relating it to Adversarial Robustness and standard Probabilistic Robustness.