# On damage of interpolation to adversarial robustness in regression

*Jingfu Peng; Yuhong Yang*

---

> ### üìä Quick Facts
>
> *   **Quality Score:** 9/10
> *   **References:** 22 Citations
> *   **Analysis Type:** Nonparametric Regression
> *   **Threat Model:** Future X-attacks ($\ell_p$-ball)
> *   **Key Metric:** Adversarial $L_2$-Risk ($R_r$)

---

## üìù Executive Summary

Recent studies on "benign overfitting" have demonstrated that interpolating estimators‚Äîmodels that achieve near-zero training error, such as over-parameterized deep neural networks (DNNs)‚Äîcan achieve optimal standard generalization. However, the critical theoretical question of whether this benign behavior persists under adversarial attacks has remained unresolved.

This paper addresses the gap between standard generalization and adversarial robustness in nonparametric regression. Specifically, it investigates whether models that perfectly fit noisy training data can maintain performance when subjected to subtle perturbations of input features at test time ($X$-attacks), a vital concern for deploying reliable machine learning systems in hostile environments.

The authors employ a statistical minimax risk framework to conduct an algorithm-independent analysis of adversarial robustness within a nonparametric regression setting. The setup assumes data is generated from a $(\beta, L)$-H√∂lder smooth function $Y = f^*(X) + \xi$ and analyzes $\delta$-interpolating estimators $I(\delta)$, where the maximum training error is bounded by $\delta$. The study specifically examines the "exact fitting" case ($\delta=0$), typical of over-parameterized DNNs, under a threat model where test inputs are perturbed within an $\ell_p$-ball of radius $r$.

A key conceptual innovation introduced is the **"curse of sample size,"** a phenomenon describing how increased data volume can paradoxically degrade robustness in high-interpolation regimes, with performance quantified using the Adversarial $L_2$-Risk ($R_r$).

The research derives precise minimax convergence rates, showing that while interpolation does not harm standard generalization (rate $n^{-2\beta / (2\beta + d)}$), it is fundamentally suboptimal for adversarial robustness. The optimal adversarial rate of $r^{2(1 \wedge \beta)} + n^{-2\beta / (2\beta + d)}$ is unattainable by exact fitting estimators; in the high interpolation regime ($\delta=0$), the adversarial risk may fail to converge to zero entirely as $n \to \infty$. Validating these theoretical findings, the authors include numerical experiments that confirm interpolation destroys robustness guarantees and illustrate the "curse of sample size."

This paper provides definitive theoretical evidence resolving the debate on "benign overfitting" in adversarial contexts: interpolation is not benign but rather detrimental to robustness. By establishing that perfect fitting damages a model's ability to withstand input perturbations, the study challenges the prevailing notion that zero training error is a desirable trait for secure systems.

---

## üîë Key Findings

*   **Fundamental Suboptimality:** Interpolating estimators are fundamentally suboptimal under subtle future X-attacks, regardless of their performance in standard generalization.
*   **Damage of Perfect Fitting:** Perfect fitting damages adversarial robustness, in stark contrast to its benign nature in standard generalization tasks.
*   **Curse of Sample Size:** The study reveals a "curse of sample size" phenomenon in the high interpolation regime, where increasing data can hurt robustness.
*   **Failure of Guarantees:** Interpolation fails to provide robustness guarantees against adversarial perturbations, despite yielding benign squared error loss results.
*   **DNN Limitations:** Over-parameterized Deep Neural Networks (DNNs) are inherently suboptimal for achieving optimal adversarial robustness due to their interpolating nature.

---

## ‚öôÔ∏è Technical Details

**Framework & Analysis**
*   **Approach:** Statistical minimax risk framework for algorithm-independent analysis.
*   **Domain:** Nonparametric regression.

**Data Generation**
*   **Model:** $Y = f^*(X) + \xi$
*   **Constraints:** $f^*$ belongs to a $(\beta, L)$-H√∂lder smooth class.

**Estimators**
*   **Type:** $\delta$-interpolating estimators $I(\delta)$ with max training error $\le \delta$.
*   **Scope:** Includes the exact fitting case ($\delta=0$), which encompasses over-parameterized DNNs.

**Threat Model & Evaluation**
*   **Attack Type:** Future $X$-attacks on test inputs.
*   **Constraint:** Perturbations within an $\ell_p$-ball of radius $r$.
*   **Metric:** Adversarial $L_2$-Risk ($R_r$).

---

## üî¨ Results & Analysis

The study theoretically derives minimax convergence rates, highlighting a sharp divergence between standard and adversarial performance:

*   **Standard Minimax Rate:**
    $$ n^{-2\beta / (2\beta + d)} $$
*   **Optimal Adversarial Rate:**
    $$ r^{2(1 \wedge \beta)} + n^{-2\beta / (2\beta + d)} $$

**Critical Observations:**

1.  **Generalization vs. Robustness:** Interpolation does not damage standard generalization, but adversarial robustness is significantly affected.
2.  **Convergence Failure:** High interpolation (exact fitting) causes the adversarial risk to exceed optimal rates and potentially fail to converge as $n \to \infty$.
3.  **Sample Size Phenomena:** The research identifies the "curse of sample size," where increasing the sample size deteriorates robustness.
4.  **Inherent Suboptimality:** Standard interpolating methods (like DNNs) are structurally incapable of achieving optimal robustness without deviating from perfect fitting.

---

## üöÄ Contributions

*   **Resolves Theoretical Debate:** The paper answers the question of whether "benign overfitting" extends to adversarial settings with a definitive negative.
*   **Formal Evidence on Interpolation:** Provides formal proof that interpolation is disadvantageous for adversarial robustness in regression.
*   **Conceptual Innovation:** Introduces the "curse of simple size" to explain model failures in high interpolation regimes.
*   **Methodological Validation:** Uses numerical experiments to empirically validate the theoretical conclusions regarding minimax rates.

---

*Report generated based on analysis of 22 references.*