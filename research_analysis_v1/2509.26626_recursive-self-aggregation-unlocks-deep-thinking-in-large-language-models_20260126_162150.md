---
title: Recursive Self-Aggregation Unlocks Deep Thinking in Large Language Models
arxiv_id: '2509.26626'
source_url: https://arxiv.org/abs/2509.26626
generated_at: '2026-01-26T16:21:50'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Recursive Self-Aggregation Unlocks Deep Thinking in Large Language Models
*Johan Obando, Sarthak Mittal, Siddarth Venkatraman, Bhavya Kailkhura, Vineet Jain, Brian R. Bartoldson, Glen Berseth, Guillaume Lajoie, Vedant Shah, Yoshua Bengio*

---

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 8/10
> *   **References:** 40 citations
> *   **Core Method:** Recursive Self-Aggregation (RSA)
> *   **Training Innovation:** Aggregation-Aware Reinforcement Learning
> *   **Key Performance:** Qwen3-4B matches DeepSeek-R1 and o3-mini on math/coding benchmarks
> *   **Compute Strategy:** Hybrid parallel & sequential scaling

---

## Executive Summary

This research addresses the critical challenge of optimizing inference-time compute to enhance complex reasoning capabilities in Large Language Models (LLMs). Existing methods primarily rely on either parallel sampling (generating diverse solutions) or sequential refinement (iterative self-correction), often failing to utilize valuable partial information contained in incorrect or incomplete reasoning chains. The authors introduce **Recursive Self-Aggregation (RSA)**, a hybrid test-time scaling algorithm inspired by evolutionary processes.

RSA operates by maintaining a population of candidate reasoning chains and iteratively refining them. In each step, the model samples distinct subsets of the population to generate new, aggregated solutions. Crucially, this method bootstraps from partially correct intermediate steps within full reasoning chains rather than relying solely on final answer verification. To further enhance this capability, the authors developed an "aggregation-aware" reinforcement learning objective that explicitly trains models to synthesize and combine separate solution attempts.

Evaluations across rigorous benchmarks such as **AIME-25**, **HMMT-25**, **Reasoning Gym**, and **LiveCodeBench-v6** demonstrate that RSA delivers substantial absolute improvements in Pass@1 accuracy. Notably, the small **Qwen3-4B-Instruct model**, when fine-tuned with aggregation-aware RL and augmented with RSA, matched or exceeded the performance of significantly larger state-of-the-art models, including **DeepSeek-R1** and **o3-mini (high)**. This research establishes a unified paradigm for inference scaling, proving that small models can achieve frontier-level reasoning performance through optimized test-time computation aggregation.

---

## Key Findings

*   **Hybrid Superiority:** RSA effectively combines parallel and sequential inference-time scaling, outperforming standalone strategies on benchmarks such as AIME-25, HMMT-25, Reasoning Gym, LiveCodeBench-v6, and SuperGPQA.
*   **Small Model Competitiveness:** The method enables small models like **Qwen3-4B-Instruct-2507** to achieve performance competitive with significantly larger reasoning models, including DeepSeek-R1 and o3-mini.
*   **Compute Scalability:** RSA delivers substantial performance gains that scale with the compute budget, showing consistent results across diverse tasks and model sizes.
*   **RL Enhancement:** Utilizing a novel "aggregation-aware" reinforcement learning approach to train models on how to combine solutions yields significant additional performance improvements.

---

## Methodology

The authors propose **Recursive Self-Aggregation (RSA)**, a test-time scaling method inspired by evolutionary algorithms. The approach operates through iterative refinement, maintaining a population of candidate reasoning chains and aggregating subsets to yield a new population of improved solutions.

Key aspects of the methodology include:

*   **Exploitation of Reasoning Chains:** RSA bootstraps from partially correct intermediate steps rather than focusing solely on final answers, extracting value from failed attempts.
*   **Hybrid Integration:** It bridges the gap between generating multiple solutions in parallel and refining them sequentially.
*   **Specialized Training:** The authors integrate a novel **aggregation-aware reinforcement learning objective** to train models specifically to combine solutions effectively, optimizing the policy for the merging of reasoning paths.

---

## Technical Details

**Algorithm Overview**
Recursive Self-Aggregation (RSA) is a hybrid test-time scaling algorithm that treats reasoning as an evolutionary process, combining parallel generation with sequential refinement.

**The RSA Process**
*   **Initialization:** The algorithm initializes a population of **$N$** candidates.
*   **Iteration:** It iterates for **$T$** steps.
*   **Aggregation Step:** In each step, **$N$** aggregation sets of **$K$** distinct candidates are sampled.
*   **Generation:** The LLM generates a refined candidate for each set to form the next population.
*   **Verification:** Uses implicit verification and hybrid scaling logic to improve the population over time.

**Key Parameters**
*   **$N$:** Total population size.
*   **$K$:** Aggregation batch size (number of candidates combined per step).
*   **$T$:** Number of refinement steps.

**Training Protocol**
*   **Method:** Aggregation-Aware Reinforcement Learning.
*   **Objective:** Optimizes a mix of standard and aggregation prompts.
*   **Constraint:** Maximizes expected reward subject to a **KL-divergence constraint** to prevent drift from the base model.

---

## Contributions

*   **New Scaling Paradigm:** Introduction of a hybrid scaling paradigm that bridges the gap between parallel (sampling multiple solutions) and sequential (self-refinement) scaling.
*   **Intermediate Step Utilization:** Demonstration that leveraging information embedded in reasoning chainsâ€”specifically by bootstrapping from partially correct intermediate stepsâ€”allows for more effective aggregation than using final answers alone.
*   **Efficiency Performance:** Evidence that through RSA, smaller parameter models (4B) can rival the reasoning capabilities of state-of-the-art large models without requiring a proportional increase in model size.
*   **Synthetic Training:** Development and validation of an aggregation-aware reinforcement learning approach to enhance a model's ability to synthesize solutions.

---

## Results

Evaluations based on Pass@1 accuracy showed significant absolute percentage point improvements across benchmarks:

**Mathematical Reasoning**
*   **AIME-25 Math:** +32.1% (Nemotron), +27.2% (Qwen3-4B)
*   **HMMT-25 Math:** +25.9% (Nemotron), +20.4% (Qwen3-4B)

**General Reasoning**
*   **Reasoning Gym Games:** +15.1% (Qwen3-30B)

**State-of-the-Art Comparison**
*   Notably, the small **Qwen3-4B-Instruct** model, when using RSA and RL fine-tuning, matched or exceeded the performance of large models like **DeepSeek-R1** and **o3-mini (high)** on AIME-25, HMMT-25, and coding tasks.
*   **Aggregation-Aware RL** further amplified the performance gains provided by the base RSA method.