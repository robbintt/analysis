---
title: 'Through the Judge''s Eyes: Inferred Thinking Traces Improve Reliability of
  LLM Raters'
arxiv_id: '2510.25860'
source_url: https://arxiv.org/abs/2510.25860
generated_at: '2026-01-27T22:26:39'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters

*Tianhao Wang, Xingjian Zhang, Suliang Jin, Tianhong Gao*

---

> ### **Quick Facts**
> | Metric | Detail |
> | :--- | :--- |
> | **Quality Score** | 9/10 |
> | **References** | 40 Citations |
> | **Top Improvement** | 161% increase in ICC (Short Story Complexity) |
> | **Key Method** | Rejection Sampling & Reasoning Language Models (RLMs) |
> | **Cost Efficiency** | Eliminates need for manual reasoning curation |

---

## Executive Summary

### **Problem**
The research addresses the critical challenge of low reliability in Large Language Model (LLM)-based evaluation, particularly regarding subjective tasks where human judgment is nuanced. As LLMs increasingly replace human annotators for efficiency, their lack of interpretability and inconsistency with human reasoning remains a significant bottleneck. Many existing valuable datasets contain only final labels without the underlying reasoning traces (explanations), limiting the ability to train models to understand the *why* behind a score. This opacity hinders the deployment of LLMs as trustworthy evaluators in complex domains requiring high fidelity to human thought processes.

### **Innovation**
The paper introduces a human-LLM collaborative framework that leverages Reasoning Language Models (RLMs) and rejection sampling to infer latent "thinking traces" from label-only datasets. The methodology involves a Generator Model creating multiple candidate reasoning traces for a given input; these traces are filtered via rejection sampling, retaining only those where the model's predicted label matches the ground truth. The retained, reconstructed traces augment the original dataset, transforming it into a rich resource for training. This augmented data is applied through a dual strategy: using Supervised Fine-Tuning (SFT) on open-source models to internalize reasoning, and synthesizing refined annotation guidelines (codebooks) to steer the behavior of proprietary, black-box models.

### **Results**
Evaluation across datasets such as HANNA, Kaggle, and SummEval demonstrated marked improvements in both consistency and error reduction. In Short Story Complexity evaluations, the method achieved a 161% increase in Intraclass Correlation Coefficient (ICC) and a 58% reduction in Mean Squared Error (MSE). Similarly, Student Essay evaluations showed a 41% decrease in MSE. While the approach proved robust across various trace generators, results were variable for highly subjective metrics like "Engagement," and specific trade-offs were observed between ranking consistency (Kendall's Tau) and absolute score accuracy in News Summary tasks.

### **Impact**
This work offers a significant practical advancement by providing a cost-efficient, scalable mechanism to obtain high-quality reasoning data without the prohibitive expense of manual curation. By enabling LLMs to act as proxies for hidden human reasoning, the framework facilitates the transformation of static, label-only corpora into dynamic, insight-rich resources. This capability enhances cross-model consistency and improves the reliability of automated evaluation systems, establishing a new standard for training and deploying LLMs as "judges" in subjective assessment scenarios.

---

## Key Findings

*   **Enhanced Agreement:** Achieved superior LLM-Human agreement across multiple diverse datasets.
*   **Consistency:** Increased cross-model consistency through refined guidelines and inferred reasoning.
*   **Proxy Reasoning:** Demonstrated that LLMs can effectively act as proxies for hidden human reasoning to augment datasets.
*   **Subjective Mastery:** Showed superior LLM reliability in complex subjective evaluation tasks compared to baseline models.

---

## Methodology

The study employed a human-LLM collaborative framework designed to infer reasoning traces from datasets containing only labels. The core process relies on **Rejection Sampling**, executed through the following steps:

1.  **Generation:** A Generator Model creates multiple candidate reasoning traces for a specific input.
2.  **Filtering:** The system applies rejection sampling, filtering candidates to retain only those where the predicted label matches the ground truth.
3.  **Reconstruction:** The retained traces are reconstructed to create a clean, augmented dataset.

This dataset is applied via a **dual strategy**:
*   **Fine-Tuning:** Used to train open-source LLMs to act as sophisticated raters.
*   **Guideline Synthesis:** Used to create annotation guidelines (codebooks) that steer the behavior of proprietary LLMs.

---

## Technical Details

### **Framework Architecture**
*   **Core Components:** Reasoning Language Models (RLMs) and Rejection Sampling.
*   **Pipeline:** Generate Candidates $\rightarrow$ Match Ground Truth $\rightarrow$ Reconstruct Trace $\rightarrow$ Augment Data.
*   **Application A:** Supervised Fine-Tuning (SFT) on open-weight models.
*   **Application B:** Codebook refinement for proprietary (black-box) models.

### **Evaluation Metrics**
*   **Kendall's Tau:** Used to measure ranking consistency.
*   **Mean Squared Error (MSE):** Used to measure absolute score accuracy.
*   **Intraclass Correlation Coefficient (ICC3):** Used to measure reliability among raters.

---

## Experimental Results

The proposed method was tested across several datasets, including **HANNA**, **Kaggle**, and **SummEval**.

*   **Short Story Complexity:**
    *   **161% increase** in ICC.
    *   **58% decrease** in MSE.
*   **Student Essays:**
    *   **41% reduction** in MSE.
*   **News Summary Tasks:**
    *   Showed robustness across different trace generators.
    *   Noted trade-offs between ranking consistency (Kendall's Tau) and absolute score accuracy.
*   **Subjective Metrics:**
    *   Gains were less uniform for highly subjective metrics such as "Engagement."

---

## Contributions

*   **Novel Method:** Introduces a first-of-its-kind method to transform label-only corpora into thinking-trace-augmented resources.
*   **Practical Reliability:** Provides a concrete solution to the persistent problem of low reliability in LLM-based subjective evaluation.
*   **Cost Efficiency:** Offers a scalable approach to obtaining high-quality reasoning data without the need for expensive manual curation.