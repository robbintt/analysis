---
title: 'LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time
  Adaptation on Edge Devices'
arxiv_id: '2503.15889'
source_url: https://arxiv.org/abs/2503.15889
generated_at: '2026-02-03T19:07:43'
quality_score: 9
citation_count: 26
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time Adaptation on Edge Devices

*Cynthia Dong; Hong Jia; Young D. Kwon; Georgios Rizos; Cecilia Mascolo*

---

### üìä Quick Facts

| Metric | Value |
| :--- | :--- |
| **Error Reduction** | 15.7% lower than SoA TTA methods |
| **Peak Memory Usage** | 11.2 MB (ResNet18) |
| **Inference Speed** | Within an order-of-magnitude of normal inference |
| **Target Hardware** | Raspberry Pi Zero 2W (Edge Devices) |
| **Key Innovation** | Partial Fusion Quantization Strategy |
| **Quality Score** | 9/10 |

---

## üìù Executive Summary

Deploying Test-Time Adaptation (TTA) on edge devices presents a significant challenge due to the conflict between the high computational demands of existing adaptation algorithms and the strict resource constraints of edge hardware. Current state-of-the-art TTA methods typically rely on backpropagation and require the maintenance of historical state (batch statistics), which necessitates substantial memory and processing power. This renders them unsuitable for low-resource environments like IoT sensors or mobile devices, where power consumption and latency are critical bottlenecks.

LeanTTA introduces a **backpropagation-free, stateless framework** specifically designed for quantized models on edge architectures. The core technical innovation is a "Partial Fusion Quantization Strategy" that decouples adaptation from weight updates by dynamically updating normalization statistics instead of model gradients. By replacing Batch Normalization layers with "LeanTTA layers" during calibration and resetting statistics after each sample, the system eliminates the need to store historical data or large batch buffers.

Validated on visual and audio modalities, LeanTTA demonstrated robust performance under both abrupt and gradual domain shifts. When benchmarked on a Raspberry Pi Zero 2W, the framework achieved a **15.7% reduction in error** compared to state-of-the-art TTA methods while recording a peak memory usage of only **11.2 MB**. This research establishes a new standard for the trade-off between accuracy and system efficiency, effectively bridging the gap between theoretical TTA algorithms and practical hardware deployment.

---

## üîë Key Findings

*   **Significant Accuracy Improvement:** The framework achieved a **15.7% reduction in error** compared to state-of-the-art Test-Time Adaptation methods.
*   **High Memory Efficiency:** Demonstrated exceptional resource constraints with a peak memory usage of only **11.2 MB** for ResNet18.
*   **Rapid Inference:** Operated at speeds within an order-of-magnitude of normal inference, minimizing latency overhead.
*   **Robustness:** Proved effective across various sensor modalities (Visual and Audio) under realistic constraints, handling both abrupt and gradual domain shifts.

---

## üî¨ Methodology

LeanTTA utilizes a **backpropagation-free and stateless framework** designed specifically for quantized test-time adaptation on edge hardware. The core methodology focuses on minimizing computational costs through the following strategies:

*   **Dynamic Normalization:** Instead of using gradient-based updates, the method dynamically updates normalization statistics.
*   **Dependency Removal:** It removes the dependency on large batch sizes and historical data storage, making it suitable for streaming data on edge devices.
*   **Optimization:** Performance is further optimized by combining partial adaptation with quantized module fusion.

---

## üöÄ Contributions

The research makes four primary contributions to the field of Edge AI:

1.  **Quantization-Compatible TTA:** Introduces a TTA method enabling deployment on low-resource edge devices.
2.  **Stateless Design:** Proposes a stateless and batch-independent design to eliminate backpropagation and historical state management.
3.  **Novel Integration:** Presents the first integration of partial adaptation with quantized module fusion.
4.  **New Efficiency Standard:** Establishes a new benchmark for the trade-off between accuracy and system efficiency.

---

## ‚öôÔ∏è Technical Details

The architecture of LeanTTA is built around a specialized quantization strategy to enable efficient adaptation.

### Architecture & Strategy
*   **Partial Fusion Quantization Strategy:**
    *   **Deeper Layers:** Convolution and Batch Normalization (Conv + BN) layers are fused for efficiency.
    *   **Shallower Layers:** Remain separate to function as adaptive components.
*   **LeanTTA Layers:** During calibration, Batch Normalization layers in the unfused sections are replaced with "LeanTTA layers."
*   **Stateless Operation:** The system resets normalization layers of unfused layers after processing test samples.
*   **Storage Efficiency:** Does not store BN parameters for fused layers, reducing memory footprint.

### Process Flow
1.  **Calibration:** Performed on source data.
2.  **Separation & Fusion:** Layers are split and fused according to the strategy.
3.  **Quantization:** The model is quantized for deployment.
4.  **Adaptation:** Inference is performed, and statistics are updated *only* in the unfused layers.

### Tools & Hardware
*   **Quantization Engine:** Utilizes QNNPACK, optimized for ARM architectures.

---

## üìà Results

The performance of LeanTTA was validated through rigorous testing on **Raspberry Pi Zero 2W**, measuring both latency and energy consumption (Wh).

*   **Error Rate:** Achieved a **15.7% reduction** compared to state-of-the-art methods.
*   **Memory:** Peak usage of **11.2 MB** (ResNet18).
*   **Latency:** Operated within an order-of-magnitude of normal inference speeds.
*   **Modalities Validated:**
    *   **Visual:** MobileNetV2 and ResNet18 on CIFAR-C.
    *   **Audio:** VGGish.
*   **Shift Handling:** Successfully handled both abrupt and gradual domain shifts.

---
**Quality Score:** 9/10  
**References:** 26 citations