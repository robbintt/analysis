---
title: "$\u03C0_\\texttt{RL}$: Online RL Fine-tuning for Flow-based Vision-Language-Action\
  \ Models"
arxiv_id: '2510.25889'
source_url: https://arxiv.org/abs/2510.25889
generated_at: '2026-02-03T13:03:03'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# $\pi_\texttt{RL}$: Online RL Fine-tuning for Flow-based Vision-Language-Action Models

*Kang Chen; Zhihao Liu; Tonghe Zhang; Zhen Guo; Si Xu; Hao Lin; Hongzhi Zang; Xiang Li; Quanlu Zhang; Zhaofei Yu; Guoliang Fan; Tiejun Huang; Yu Wang; Chao Yu*

***

> ## üìä Quick Facts
>
> | Metric | Value |
> | :--- | :--- |
> | **Quality Score** | 8/10 |
> | **Top Performance Gain** | +29.3% (94.5% vs 65.2% SFT baseline on LIBERO-Spatial) |
> | **Speed Improvement** | 2x faster wall-clock update time (428.6s vs ~814s) |
> | **Optimal Noise Level** | 0.8 (Achieved 98.1% success) |
> | **References** | 40 Citations |

***

## üìã Executive Summary

Large-scale flow-based Vision-Language-Action (VLA) models, such as $\pi_0$ and $\pi_{0.5}$, have demonstrated strong capabilities in robotic manipulation, yet applying Reinforcement Learning (RL) to fine-tune these models has remained an intractable challenge. The core obstacle is the mathematical difficulty of computing action log-likelihoods within continuous flow-matching frameworks, which are essential for standard RL optimization objectives. Consequently, the field has relied on labor-intensive Supervised Fine-Tuning (SFT), which requires massive amounts of human-annotated data and scales inefficiently. Addressing this barrier is critical for enabling robotic agents to improve autonomously through real-world interaction rather than manual curation.

This paper introduces $\pi_{\texttt{RL}}$, a novel framework that mathematically bridges flow-based generative models and online RL. The authors propose a dual-approach architecture to resolve the likelihood bottleneck: "**Flow-Noise**," which models the denoising trajectory as a discrete-time Markov Decision Process (MDP) with a learnable noise network to enable exact log-likelihood computation; and "**Flow-SDE**," which utilizes a two-layer MDP formulation coupled with Ordinary Differential Equation (ODE)-to-Stochastic Differential Equation (SDE) conversion. This integration allows the denoising process to be coupled directly with agent-environment interaction, significantly enhancing exploration efficiency. Additionally, the framework employs a four-layer MLP critic positioned after the action expert ($V_{expert}$) to ensure theoretical alignment.

Empirical evaluations demonstrate that $\pi_{\texttt{RL}}$ delivers substantial performance improvements over base SFT models across various benchmarks. On the LIBERO-Spatial dataset, RL fine-tuning achieved a success rate of **94.5%**, a marked increase over the SFT baseline of **65.2%**. The proposed Hybrid Two-Layer MDP optimized computational efficiency, reducing wall-clock update time by 50% to **428.6 seconds** compared to the standard 814 seconds. While generalization tests yielded gains in out-of-distribution (OOD) scenarios like ManiSkill and CALVIN, performance fluctuated in MetaWorld tasks. Hyperparameter ablations identified optimal configurations, specifically a noise level of 0.8, which achieved a peak success rate of **98.1%**.

The significance of this research lies in successfully unlocking online RL for flow-based VLA architectures, overcoming previous mathematical limitations regarding log-likelihoods. By demonstrating that automated RL fine-tuning can outperform labor-intensive SFT scaling, $\pi_{\texttt{RL}}$ offers a more efficient pathway to developing robust robotic policies. This work suggests that integrating RL into the training loop of foundation models can automate data collection and improve generalization, paving the way for more adaptive and self-improving robotic systems that require less human intervention.

***

## üîç Key Findings

*   **Solving the Intractable:** Successfully addresses the challenge of applying RL to large-scale flow-based Vision-Language-Action models ($\pi_0$ and $\pi_{0.5}$) by resolving complex action log-likelihood issues.
*   **Exact Computation:** Demonstrates exact log-likelihood computation via the **'Flow-Noise'** method, utilizing a discrete-time MDP and a learnable noise network.
*   **Enhanced Exploration:** Proves efficient exploration via the **'Flow-SDE'** method by integrating denoising with agent-environment interaction using a two-layer MDP and ODE-to-SDE conversion.
*   **Performance Validation:** Confirms that online RL fine-tuning yields significant performance improvements over base models in both in-distribution (ID) and out-of-distribution (OOD) settings.

***

## üõ† Methodology

The proposed framework, $\pi_{\texttt{RL}}$, utilizes a dual-approach architecture to overcome mathematical barriers in flow-based models:

1.  **Flow-Noise**
    *   Models the denoising trajectory as a **discrete-time MDP**.
    *   Implements a learnable noise network.
    *   **Goal:** Enable exact log-likelihood computation.

2.  **Flow-SDE**
    *   Integrates the denoising process with agent-environment interaction.
    *   Utilizes a **two-layer MDP** formulation.
    *   Converts ODEs to SDEs (Stochastic Differential Equations).
    *   **Goal:** Enhance exploration efficiency.

***

## ‚ú® Contributions

*   **Bridging the Gap:** Develops the $\pi_{\texttt{RL}}$ methodology to bridge RL and flow-based models, overcoming mathematical barriers regarding log-likelihoods.
*   **Novel Formulations:** Introduces two key algorithmic formulations:
    *   *Flow-Noise MDP* for likelihood estimation.
    *   *Flow-SDE two-layer MDP* for interaction dynamics.
*   **Efficacy of Automated RL:** Provides empirical evidence that RL fine-tuning is superior to labor-intensive supervised fine-tuning (SFT) scaling for automating data collection and improving robustness.

***

## ‚öôÔ∏è Technical Details

**Core Methods**

*   **Flow-Noise:** Discrete-time MDP with a learnable noise network designed for exact log-likelihoods.
*   **Flow-SDE:** Two-layer MDP with ODE-to-SDE conversion designed for computational efficiency.

**Architecture Optimization**

*   **Critic Design:** Optimized by selecting a **four-layer MLP** over a one-layer MLP.
*   **Placement:** Critic placed after the action expert ($V_{expert}$) to ensure theoretical alignment.

**Performance Enhancements**

*   **Speedup:** The two-layer MDP formulation achieved a **2x speedup** in wall-clock update time.
*   **Stochasticity:** Injection strategies using fixed noise or learnable noise (with log-variance bounds) yielded comparable performance.

***

## üìà Results

*   **Generalization Tests:**
    *   Showed performance gains in **ManiSkill** and **CALVIN** OOD scenarios.
    *   Noted fluctuations in **MetaWorld** tasks.
*   **Efficiency:**
    *   The Hybrid Two-Layer MDP reduced update time to **428.6 seconds** (compared to ~814s standard).
*   **Hyperparameter Ablations (LIBERO-Spatial):**
    *   **Noise Level 0.8:** 98.1% success.
    *   **Denoise Steps 2:** 97.0% success.
    *   **Action Chunk Size 10:** 95.5% success.
*   **Overall Performance:**
    *   RL fine-tuning achieved **94.5%** evaluation success.
    *   Significant improvement over the SFT baseline of **65.2%** on LIBERO-Spatial.

***

**Quality Score:** 8/10  
**References:** 40 citations