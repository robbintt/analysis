# Developing Visual Augmented Q&A System using Scalable Vision Embedding Retrieval & Late Interaction Re-ranker

*Rachna Saxena; Abhijeet Kumar; Suresh Shanmugam*

---

### üìë Executive Summary

This research addresses the critical challenge of scaling Retrieval-Augmented Generation (RAG) systems for visually rich documents, such as PDFs containing infographics, charts, and tables. While traditional text-only retrieval models fail to capture visual semantics, and naive approaches feeding entire documents into Multimodal LLMs (MLLMs) struggle with restrictive context windows, Late Interaction models like ColPali offer superior accuracy. However, these advanced models introduce prohibitive computational costs and lack native support in standard vector databases. This creates a significant infrastructure bottleneck, preventing enterprises from adopting high-precision visual Q&A systems that depend on complex layout and graphical information.

The authors propose a two-stage architecture optimized for enterprise environments, utilizing a "Hybrid Search Retrieval" strategy that combines metadata filtering with embedding retrieval to generate initial candidates. The core innovation is a **"flattened" storage strategy** designed to bypass current vector database limitations. Instead of relying on unsupported multi-vector page matrices, the system indexes **1,030 individual patches (128 dimensions each)** per page, tagging them with File ID, Page number, and Patch Number. During retrieval, the query is encoded into a matrix to perform a token-level similarity search against these flattened patches using a **0.9 similarity threshold**. Relevant patches are aggregated to identify candidate pages, and the full page matrices are reconstructed on-the-fly for ColPali re-ranking, before Claude Sonnet 3.5 generates the final answer.

Presented as an architectural proposal for scalable visual Q&A, the system demonstrates operational feasibility through specific configuration parameters rather than traditional benchmark metrics like Recall@K or precise latency figures. The implementation successfully leverages the flattened storage strategy to enforce a 0.9 similarity threshold for token-level filtering, which successfully narrows the search space to strictly relevant pages. By reconstructing full page matrices only for these filtered candidates, the architecture is designed to maintain the retrieval quality of Late Interaction models while significantly reducing the input load on the final MLLM reader, effectively solving the context reduction problem for large document sets.

The primary significance of this work lies in its pragmatic approach to enterprise viability, offering a production-ready path to deploy Late Interaction mechanisms for visual retrieval without incurring unsustainable computational costs. By decoupling the retrieval layer from the re-ranking layer, the solution enables organizations to utilize widely adopted vector databases like OpenSearch rather than waiting for native multi-vector support or investing in proprietary infrastructure. This approach democratizes access to state-of-the-art multi-modal search, bridging the gap between text-only models and complex visual information to enable comprehensive extraction from enterprise documents.

---

> ### ‚ö° Quick Facts Sidebar
>
> | Metric | Detail |
> | :--- | :--- |
> | **Quality Score** | 6/10 |
> | **References** | 19 Citations |
> | **Architecture** | Two-Stage RAG |
> | **Database** | OpenSearch (HNSW) |
> | **Vision Model** | ColPali (PaliGemma) |
> | **Generator** | Claude Sonnet 3.5 |
> | **Patches per Page** | 1,030 |
> | **Dimensions** | 128 |
> | **Similarity Threshold** | 0.9 |

---

## üîë Key Findings

*   **Scalability and Efficiency:** The proposed multi-step implementation achieves significant speedups in the vision retrieval process, making it a scalable solution for large document sets.
*   **Performance Stability:** Despite optimizations for efficiency, the system maintains stability and does not degrade the quality of retrieval performance compared to standard methods.
*   **Enterprise Viability:** The design is pragmatically suited for enterprise production environments, addressing the high computational costs often associated with late interaction mechanisms.
*   **Effective Context Reduction:** The approach successfully solves the "needle in a haystack" problem for Multimodal LLMs (MLLMs) by narrowing the search space to relevant pages before generation.

## ‚ú® Core Contributions

*   **Optimization of Late Interaction for Vision Retrieval:** Addresses critical bottlenecks in using late interaction mechanisms for RAG-based multi-modal Q&A, specifically the lack of native support in vector databases and the high space footprint.
*   **Bypassing Vector Database Limitations:** By using a custom implementation that decouples the initial retrieval from the re-ranking process, the method overrides the current inability of many popular vector databases to perform efficient multi-vector retrieval.
*   **Integration of Visual Elements in Q&A:** Bridges the gap between text-only models and complex visual information (infographics, charts, tables), enabling more comprehensive information extraction without inflating context length excessively.

## üõ†Ô∏è Methodology

The research follows a distinct three-phase pipeline:

1.  **Hybrid Search Retrieval:**
    The system utilizes a widely adopted hybrid search approach that combines metadata filtering with embedding retrieval to generate an initial set of candidates.

2.  **Late Interaction Re-ranking:**
    To refine results without relying on native multi-vector support in databases, a state-of-the-art late interaction re-ranker is applied to select the best-matching pages.

3.  **MLLM Generation:**
    Finally, Multimodal Large Language Models (MLLMs) are prompted as "readers" to generate answers specifically from the contextualized, re-ranked pages retrieved in the previous steps.

## ‚öôÔ∏è Technical Details

The paper proposes a robust two-stage RAG architecture with the following specifications:

*   **Retrieval Engine:** OpenSearch vector database utilizing HNSW for Approximate Nearest Neighbor (ANN) search.
*   **Re-ranking Model:** ColPali (built on PaliGemma).
*   **Representation Strategy:** Document pages are represented as matrices of **1,030 patches** with **128 dimensions** each.
*   **Storage Strategy ("Flattened"):** Each patch is stored as a separate vector entry, tagged with:
    *   File ID
    *   Page Number
    *   Patch Number
*   **Retrieval Process:**
    *   Queries are encoded into a matrix.
    *   Token-level search is performed with a **0.9 similarity threshold**.
    *   Patches are aggregated to identify candidate pages.
    *   Full page matrices `(1030, 128)` are reconstructed dynamically.
*   **Final Generation:** Re-ranked pages are passed to **Claude Sonnet 3.5** for answer generation.

## üìä Results & Outcomes

*   **Performance Metrics:** Specific quantitative metrics such as Recall@K or precise latency are absent from the provided text.
*   **Claimed Efficiency:** The abstract claims significant speedups in vision retrieval compared to standard ColPali while maintaining retrieval quality without degradation.
*   **Operational Success:** The system successfully solves the "needle in a haystack" problem by narrowing the search space to reduce context window requirements.
*   **Constraints:** Operational constraints involve indexing 1,030 vectors per page and using a hardcoded 0.9 similarity threshold.
*   **Qualitative Assessment:** The design is considered enterprise-viable as it lowers computational costs and avoids proprietary lock-in while preserving full visual context.