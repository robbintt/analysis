---
title: 'Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with
  Large Language Models'
arxiv_id: '2512.00590'
source_url: https://arxiv.org/abs/2512.00590
generated_at: '2026-02-06T01:48:04'
quality_score: 9
citation_count: 23
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models

*Alla Chepurova; Aydar Bulatov; Mikhail Burtsev; Yuri Kuratov*

---

## ðŸ“Š Quick Facts

> **Quality Score:** 9/10 | **Citations:** 23
>
> **Key Performance Metrics:**
> *   **Answer Coverage:** 96% (MuSiQue)
> *   **Reasoning (HotpotQA):** 76.0 F1
> *   **Reasoning (MuSiQue):** 59.8 F1
> *   **Retention Rate (MINE-1):** 86%
> *   **Token Efficiency:** < 1,000 tokens (3Ã— more efficient than AriGraph, 20Ã— more efficient than GraphRAG)

---

## Executive Summary

Existing methods for constructing Knowledge Graphs (KGs) using Large Language Models (LLMs) frequently suffer from low intrinsic quality, producing noisy outputs that lack ontology consistency and contain significant entity duplication. Furthermore, KGs are typically utilized merely as auxiliary tools within Retrieval-Augmented Generation (RAG) systems to retrieve unstructured text, rather than serving as standalone, structured knowledge bases.

This paper addresses these critical gaps by investigating whether high-quality, compact KGs constructed with strict ontology alignment can function as a sufficient primary knowledge source for complex reasoning tasks, thereby reducing reliance on large volumes of unstructured context.

The authors introduce **Wikontic**, a novel three-stage pipeline designed to generate ontology-aware KGs that align with Wikidata standards. The methodology begins with **Extraction**, where an LLM identifies candidate triplets and contextual qualifiers. It proceeds to **Constraint Enforcement**, utilizing an Ontology Database derived from Wikidataâ€”filtered for 2,464 factual properties and employing recursive taxonomy expansionâ€”to validate relations and types via cosine similarity. The pipeline concludes with **Normalization and Deduplication**, which standardizes entity references to eliminate redundancy.

Wikontic demonstrates state-of-the-art performance and competitive reasoning capabilities across several benchmarks. On the MuSiQue dataset, the system achieved a **96% answer coverage rate**. When reasoning using only these triplets, Wikontic achieved a **76.0 F1 score on HotpotQA** and **59.8 F1 on MuSiQue**. Additionally, it set a new benchmark on MINE-1 with an **86% retention rate**.

The significance of this research lies in its validation of "structure-only reasoning," challenging the conventional assumption that large textual contexts are necessary for effective RAG systems. By demonstrating that compact, ontology-aligned KGs can support complex reasoning with high fidelity, Wikontic offers a scalable and cost-effective alternative for integrating structured knowledge into LLMs.

---

## Key Findings

*   **High Answer Coverage:** The Wikontic pipeline generates highly relevant Knowledge Graphs (KGs) where the correct answer entity appears in **96%** of the generated triplets on the MuSiQue dataset.
*   **Competitive Reasoning Performance:** A triplets-only setup (without textual context) matches or surpasses standard Retrieval-Augmented Generation (RAG) baselines, achieving **76.0 F1 on HotpotQA** and **59.8 F1 on MuSiQue**.
*   **Superior Information Retention:** Wikontic achieves state-of-the-art performance on the MINE-1 benchmark with an **86% retention rate**, outperforming prior KG construction methods.
*   **Operational Efficiency:** The pipeline is highly cost-effective, requiring less than **1,000 output tokens** for KG construction (approx. 3Ã— fewer than AriGraph and less than 1/20 of GraphRAG).

---

## Methodology

The authors propose Wikontic, a multi-stage pipeline designed to construct ontology-aware KGs from open-domain text. This approach shifts focus from using KGs merely as auxiliary tools for text retrieval to constructing high-quality, compact, and well-connected structured knowledge bases.

The methodology consists of three core steps:

1.  **Extraction:** Identifying candidate triplets that include qualifiers to capture detailed relationships.
2.  **Constraint Enforcement:** Applying Wikidata-based type and relation constraints to ensure data aligns with an established ontology.
3.  **Normalization:** Standardizing entity references to reduce duplication and ensure connectivity.

---

## Technical Details

Wikontic is a multi-stage pipeline designed to construct ontology-aware Knowledge Graphs (KGs) from unstructured text using Large Language Models (LLMs) and Wikidata constraints.

### System Architecture
*   **Ontology Database:** Derived from Wikidata, filtered for 2,464 factual properties using a recursive hierarchy (P31/P279) for taxonomy expansion.
*   **Search Capabilities:** Powered by Contriever embeddings and Atlas MongoDB vector search.

### Pipeline Stages

1.  **Candidate Triplet Extraction**
    *   An LLM extracts subject-relation-object triplets.
    *   Simultaneously extracts entity types and contextual qualifiers.

2.  **Ontology-aware Refinement**
    *   **Retrieval:** Retrieves candidate types.
    *   **Validation:** Validates relations based on Wikidata constraints (ranking by cosine similarity).
    *   **Reconstruction:** Reconstructs the triplet backbone.

3.  **Entity Normalization & Deduplication**
    *   Merges surface forms to handle varying references to the same entity.
    *   Removes duplicate triplets to ensure graph compactness.

---

## Contributions

*   **Advancement of KG Quality:** The paper addresses the underexplored "intrinsic quality" of LLM-generated KGs by introducing a pipeline that ensures ontology consistency and reduces entity duplication.
*   **Validation of Structure-Only Reasoning:** The work demonstrates that high-quality, structured triplets can serve as a sufficient knowledge source for complex reasoning tasks, challenging the necessity of large textual contexts in RAG systems.
*   **Scalability and Efficiency:** By significantly reducing the token overhead for graph construction, the research offers a scalable solution for integrating structured knowledge into LLMs without prohibitive computational costs.

---

## Results

The performance of Wikontic was evaluated across multiple benchmarks, highlighting both the quality of the graphs and the efficiency of the pipeline.

### Reasoning Performance
*   **MuSiQue Dataset:** 96% of generated triplets contained the correct answer entity.
*   **Triplets-Only Reasoning:**
    *   **HotpotQA:** 76.0 F1
    *   **MuSiQue:** 59.8 F1
*   **MINE-1 Benchmark:** Achieved state-of-the-art performance with an 86% retention rate.

### Operational Efficiency
*   **Token Usage:** Wikontic requires fewer than 1,000 output tokens.
*   **Comparison:**
    *   ~3Ã— fewer tokens than AriGraph.
    *   <1/20 of the tokens required by GraphRAG.