# Rethinking Few-Shot Adaptation of Vision-Language Models in Two Stages

*Matteo Farina; Massimiliano Mancini; Giovanni Iacca; Elisa Ricci*

---

### ðŸ“‘ Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 9/10 |
| **Citations** | 40 |
| **Base Architecture** | CLIP (ViT-B/16) |
| **Proposed Framework** | Two-Stage Few-Shot Adaptation (2SFS) |
| **Budget Split Factor** | 0.6 |
| **Shots Configuration** | 16 |
| **Key PEFT Strategies** | LoRA, BitFit, LayerNorm |

---

> ### ðŸ“‹ Executive Summary
>
> Current approaches to adapting Vision-Language Models (VLMs) to few-shot scenarios predominantly rely on Parameter-Efficient Fine-Tuning (PEFT). While effective, standard methods typically utilize the entire computational budget in a single, monolithic training phase. This paper addresses the inefficiency of this approach, highlighting that existing strategies fail to account for the distinct, sequential phases of learning that occur during adaptation. As VLMs are increasingly deployed in resource-constrained environments, optimizing the adaptation process to maximize generalization while strictly managing computational overhead is a critical challenge for the field.
>
> The key innovation is the **Two-Stage Few-Shot Adaptation (2SFS)** framework, which is built upon an analysis revealing the "biphasic" learning dynamics of PEFT. Technically, 2SFS splits a fixed computational budget into two sequential stages:
> 1.  **Stage 1:** Optimizes PEFT parameters (such as LayerNorm or LoRA) to learn a generalizable, task-level feature extractor, stopping at a specific performance "breakpoint."
> 2.  **Stage 2:** These feature extractor parameters are frozen, and the remaining budget is used solely to train a linear classifier for concept specialization.
>
> Additionally, the method employs a **selective inference mechanism** that processes novel categories via the adapted text encoder while retrieving base category embeddings directly from the classifier, allowing for efficient handling of both known and unknown classes.
>
> The 2SFS scheme matches or surpasses state-of-the-art performance across 11 benchmarks while maintaining robust, fixed hyperparameters. Compared to a Stage 1-only baseline, the method yielded significant accuracy gains on several datasets: **+11.2% on Stanford Cars**, **+10.6% on FGVC Aircraft**, **+5.5% on SUN397**, **+4.8% on UCF-101**, and **+4.4% on DTD**. On the ImageNet benchmark, the optimal configuration achieved approximately **74.0% Harmonic Mean accuracy**. While minor performance regressions were noted on Food-101 (-1.4%) and Oxford Pets (-0.4%), the overall robustness analysis confirmed that the "breakpoint" phenomenon occurs consistently across various datasets and PEFT strategies.

---

## Key Findings

*   **Biphasic Learning Dynamics:** Analysis of Parameter-Efficient Fine-tuning (PEFT) reveals distinct learning phases composed of task-level feature extraction followed by specialization to specific concepts.
*   **State-of-the-Art Performance:** The proposed Two-Stage Few-Shot Adaptation (2SFS) matches or surpasses existing performance across multiple benchmarks using **fixed hyperparameters**.
*   **Consistent Robustness:** Unlike established methods, the 2SFS scheme maintains consistent performance and robustness when shifting between different settings without the need for re-tuning.
*   **Budget Efficiency:** Splitting a fixed computational budget between feature extractor learning and linear classifier training proves more effective than standard prompt or adapter methods.

---

## Methodology

The paper introduces the **Two-Stage Few-Shot Adaptation (2SFS)** framework designed to operate under a fixed computational budget. The process is divided into two distinct phases:

1.  **Stage 1 (Feature Extraction):** Focuses on learning a task-specific feature extractor using **Parameter-Efficient Fine-tuning (PEFT)** on base classes.
2.  **Stage 2 (Classifier Training):** Involves training a linear classifier on top of the frozen extractor generated in Stage 1.

**Selective Inference:**
At test time, a unique selective inference mechanism is utilized:
*   **Novel Categories:** Embedded using the adapted text encoder.
*   **Base Categories:** Embeddings are retrieved directly from the classifier.

This approach is validated across 'all-to-all' and 'base-to-novel' scenarios using PEFT strategies like LoRA, BitFit, and LayerNorm.

---

## Technical Details

*   **Method Name:** Two-Stage Few-Shot Adaptation (2SFS)
*   **Core Theory:** Exploits observed 'biphasic' learning dynamics of Parameter-Efficient Fine-Tuning (PEFT).
*   **Stage 1 Details:** Optimizes PEFT parameters (e.g., LayerNorm) to learn generalizable task-level features. Stops before a performance "breakpoint".
*   **Stage 2 Details:** PEFT parameters are frozen to train a linear classifier (Specialization).
*   **Architecture:** CLIP (ViT-B/16)
*   **Scope:** Few-Shot Adaptation (FSA) covering 'all-to-all' and 'base-to-novel' scenarios.
*   **Optimal Hyperparameters:** Budget Split Factor set to **0.6**; **16 shots**.

---

## Results

The 2SFS scheme demonstrated robust performance across 11 benchmarks. Compared to a "Stage 1 Only" (LayerNorm) baseline, the following significant accuracy gains were observed:

*   **Stanford Cars:** +11.2%
*   **FGVC Aircraft:** +10.6%
*   **SUN397:** +5.5%
*   **UCF-101:** +4.8%
*   **DTD:** +4.4%

**General Performance:**
*   Achieved approximately **74.0% Harmonic Mean** accuracy on ImageNet.
*   **Failure Cases:** Minor regressions observed on Food-101 (-1.4%) and Oxford Pets (-0.4%).
*   **Robustness:** Analysis confirms the 'breakpoint' phenomenon occurs consistently across various datasets and PEFT strategies.

---

## Contributions

*   **PEFT Dynamics Analysis:** Provides a comprehensive analysis of PEFT learning dynamics in few-shot scenarios, identifying the separation between feature extraction and concept specialization.
*   **2SFS Framework:** Introduces the Two-Stage Few-Shot Adaptation (2SFS) framework to explicitly model the identified learning phases by separating feature extractor and classifier optimization.
*   **Selective Inference:** Develops a selective inference mechanism that allows for efficient, distinct processing of novel and base categories during testing.
*   **Validation & Robustness:** Validates the method's robustness over state-of-the-art techniques across diverse backbones and datasets without the need for hyperparameter tuning.