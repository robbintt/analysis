---
title: A Representation Sharpening Framework for Zero Shot Dense Retrieval
arxiv_id: '2511.05684'
source_url: https://arxiv.org/abs/2511.05684
generated_at: '2026-02-06T04:06:51'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: fireworks_ai
    name: glm-4p7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# A Representation Sharpening Framework for Zero Shot Dense Retrieval

*Dhananjay Ashok; Suraj Nair; Mutasem Al-Darabsah; Choon Hui Teo; Tarun Agarwal; Jonathan May*

---

> ### üìä Quick Facts
> * **Quality Score:** 9/10
> * **References:** 40 Citations
> * **Core Metric:** NDCG@10
> * **Performance Gain:** +6.9% average improvement on BEIR
> * **Status:** New State-of-the-Art (SOTA) on BRIGHT Benchmark
> * **Key Innovation:** Training-free representation sharpening

---

## üìë Executive Summary

Pre-trained dense retrieval (DR) models face a critical limitation in zero-shot settings: they struggle to distinguish between documents that are semantically similar. Without fine-tuning on the specific target corpus, the embeddings generated by these models often lack the granularity required to effectively separate relevant documents from their neighbors. This represents a significant barrier to deploying retrieval systems across new domains or languages, as reliance on extensive model retraining is often computationally prohibitive.

The authors introduce **"Representation Sharpening" (ConSharp)**, a training-free framework that sharpens document embeddings during inference to enhance discriminability. Instead of retraining, the method generates contrastive queries specifically designed to distinguish a document from others within its local neighborhood. The document embedding is dynamically shifted towards these contrastive queries using the formula $d^* = d + \alpha \cdot g(q, Q_d)$, where $g$ represents a convex combination weighted by similarity.

To ensure practical deployment, the authors devised an indexing-time approximation that utilizes unsupervised clustering (e.g., KMeans) on subsampled neighborhoods to select contrastive references, preserving performance gains without introducing inference latency. Evaluations using the NDCG@10 metric demonstrate the framework's efficacy across multiple benchmarks. On the BEIR benchmark, ConSharp improved NDCG@10 by an average of 6.9% compared to traditional inference and the Doc2Query baseline across Contriever, Qwen3, and E5-Mistral models. Specifically, it achieved scores of 40.67 (Contriever), 50.37 (Qwen3), and 45.54 (E5-Mistral). Furthermore, the method established a new state-of-the-art on the BRIGHT benchmark, achieving top performance on 8 out of 11 subsets, and consistently improved performance across over 20 datasets and multiple languages.

This work significantly advances the field by demonstrating that substantial performance gains in zero-shot retrieval can be achieved without expensive fine-tuning. By addressing the specific failure mode of pretrained DRs‚Äînamely the inability to represent fine-grained semantic differences‚Äîthe framework offers a scalable, plug-and-play enhancement for existing systems. The successful elimination of inference-time costs through indexing-time approximations makes this a highly practical solution, ensuring that high-performance zero-shot retrieval remains viable for real-world, latency-sensitive applications.

---

## üîë Key Findings

*   **Consistent Outperformance:** The representation sharpening framework consistently outperforms traditional retrieval methods across over 20 datasets spanning multiple languages.
*   **Benchmark Leadership:** The proposed method established a new state-of-the-art (SOTA) on the BRIGHT benchmark.
*   **Broad Compatibility:** The framework is compatible with and enhances the performance of prior zero-shot dense retrieval approaches.
*   **Optimized Efficiency:** An indexing-time approximation was successfully developed to preserve the majority of performance gains while eliminating additional inference-time costs.

---

## üõ† Methodology

The authors introduce a **training-free representation sharpening framework**. Instead of fine-tuning the model, this approach augments a document's representation by incorporating information that specifically helps distinguish it from semantically similar documents within the corpus. To ensure practical efficiency, the authors also devised an indexing-time approximation strategy that maintains performance benefits without adding overhead during inference.

---

## ‚öôÔ∏è Technical Details

The **"Representation Sharpening"** framework aims to enhance zero-shot dense retrieval by sharpening document embeddings during inference without retraining.

**Core Mechanism:**
It utilizes contrastive query generation to create queries that distinguish a document from similar ones. The document embedding is dynamically shifted towards the embeddings of these contrastive queries.

**Mathematical Formulation:**
$$d^* = d + \alpha \cdot g(q, Q_d)$$
*Where $g$ is a convex combination weighted by similarity.*

**Process Implementation:**
*   **Contrastive Reference Selection:** During indexing, the framework subsamples the local neighborhood, applies unsupervised clustering (e.g., KMeans), and selects one document per cluster.
*   **Deployment Efficiency:** Deployment is efficient as it requires Language Model access only during the indexing phase for query generation.

---

## üìà Results

The primary evaluation metric is **NDCG@10**.

**BEIR Benchmark Performance:**
Across 6 datasets and three Dense Retriever variants (Contriever, Qwen3, E5-Mistral), the "ConSharp" method improved NDCG@10 by an average of **6.9%** compared to traditional inference and the Doc2Query baseline.

*   **Contriever:** 40.67
*   **Qwen3:** 50.37
*   **E5-Mistral:** 45.54

**BRIGHT Benchmark:**
The framework achieved State-of-the-Art (SOTA) performance on **8 out of 11** subsets.

**Generalizability:**
The method proved generalizable, consistently improving all tested training-free, zero-shot dense retrieval methods across multiple languages and domains.

---

## üö© Research Contributions

*   **Addressing Zero-Shot Limitations:** The work provides a solution to the specific failure mode of pretrained dense retrievers (DRs) in zero-shot settings, where models struggle to represent semantic differences between similar documents due to lack of target corpus training.
*   **Performance without Training:** The authors demonstrate that significant performance gains can be achieved in zero-shot dense retrieval through a training-free augmentation process, reducing the dependency on extensive model retraining.
*   **Efficiency Optimization:** The contribution includes a method to balance the performance-cost tradeoff via indexing-time approximations, making high-performance zero-shot retrieval viable without increased inference latency.